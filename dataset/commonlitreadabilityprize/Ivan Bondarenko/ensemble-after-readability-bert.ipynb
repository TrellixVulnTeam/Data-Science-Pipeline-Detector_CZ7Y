{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import codecs\nimport copy\nimport csv\nimport gc\nfrom itertools import chain\nimport os\nimport pickle\nimport random\nfrom typing import Dict, List, Tuple, Union\nimport warnings","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport nltk\nimport numpy as np\nfrom sklearn.manifold import TSNE\nfrom sklearn.preprocessing import StandardScaler\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom transformers import AutoConfig, AutoTokenizer, TFAutoModel","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(tf.__version__)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MaskCalculator(tf.keras.layers.Layer):\n    def __init__(self, output_dim, **kwargs):\n        self.output_dim = output_dim\n        super(MaskCalculator, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        super(MaskCalculator, self).build(input_shape)\n\n    def call(self, inputs, **kwargs):\n        return tf.keras.backend.permute_dimensions(\n            x=tf.keras.backend.repeat(\n                x=tf.keras.backend.cast(\n                    x=tf.keras.backend.greater(\n                        x=inputs,\n                        y=0\n                    ),\n                    dtype='float32'\n                ),\n                n=self.output_dim\n            ),\n            pattern=(0, 2, 1)\n        )\n\n    def compute_output_shape(self, input_shape):\n        assert len(input_shape) == 1\n        shape = list(input_shape)\n        shape.append(self.output_dim)\n        return tuple(shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_attention_mask(token_indices: np.ndarray, padding_id: int) -> np.ndarray:\n    attention = np.zeros(token_indices.shape, dtype=np.int32)\n    for sample_idx in range(token_indices.shape[0]):\n        for token_idx in range(token_indices.shape[1]):\n            if token_indices[sample_idx, token_idx] == padding_id:\n                break\n            attention[sample_idx, token_idx] = 1\n    return attention","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calc_text_features(texts: List[List[str]], tok: AutoTokenizer) -> np.ndarray:\n    f = np.zeros((len(texts), 9), dtype=np.float32)\n    for idx, sentences in enumerate(texts):\n        f[idx, 0] = len(sentences)\n        words = []\n        pure_words = []\n        for cur_sent in sentences:\n            words_in_sentence = nltk.word_tokenize(cur_sent)\n            words += words_in_sentence\n            pure_words += list(filter(lambda it: it.isalpha(), words_in_sentence))\n        f[idx, 1] = len(words) / f[idx, 0]\n        f[idx, 2] = len(pure_words) / f[idx, 0]\n        f[idx, 3] = len(' '.join(sentences))\n        f[idx, 4] = len(pure_words)\n        f[idx, 5] = np.mean([len(w) for w in pure_words])\n        for w in pure_words:\n            syllables = tok.tokenize(w)\n            f[idx, 6] += len(syllables) \n            f[idx, 7] += sum(map(lambda it: len(it), syllables))\n        f[idx, 7] /= f[idx, 6]\n        f[idx, 8] = f[idx, 6] / f[idx, 4]\n    return f","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_for_training(\n    fname: str,\n    tok: AutoTokenizer\n) -> List[Dict[str, Tuple[List[str], float, float, np.ndarray]]]:\n    loaded_header = []\n    id_col_idx = -1\n    text_col_idx = -1\n    target_col_idx = -1\n    std_col_idx = -1\n    line_idx = 1\n    data = dict()\n    set_of_texts = set()\n    with codecs.open(fname, mode='r', encoding='utf-8') as fp:\n        data_reader = csv.reader(fp, quotechar='\"', delimiter=',')\n        for row in data_reader:\n            if len(row) > 0:\n                err_msg = f'File {fname}: line {line_idx} is wrong!'\n                if len(loaded_header) == 0:\n                    loaded_header = copy.copy(row)\n                    try:\n                        text_col_idx = loaded_header.index('excerpt')\n                    except:\n                        text_col_idx = -1\n                    if text_col_idx <= 0:\n                        raise ValueError(err_msg + ' Field \"excerpt\" is not found!')\n                    try:\n                        id_col_idx = loaded_header.index('id')\n                    except:\n                        id_col_idx = -1\n                    if id_col_idx < 0:\n                        raise ValueError(err_msg + ' Field \"id\" is not found!')\n                    try:\n                        target_col_idx = loaded_header.index('target')\n                    except:\n                        target_col_idx = -1\n                    if target_col_idx < 0:\n                        raise ValueError(err_msg + ' Field \"target\" is not found!')\n                    try:\n                        std_col_idx = loaded_header.index('standard_error')\n                    except:\n                        std_col_idx = -1\n                    if std_col_idx < 0:\n                        err_msg2 = f'{err_msg} Field \"standard_error\" is not found!'\n                        raise ValueError(err_msg2)\n                else:\n                    sample_id = row[id_col_idx]\n                    if sample_id != sample_id.strip():\n                        raise ValueError(err_msg + f' {sample_id} is wrong sample ID!')\n                    if sample_id in data:\n                        err_msg2 = f'{err_msg} {sample_id} is not unique sample ID!'\n                        raise ValueError(err_msg2)\n                    text = row[text_col_idx].replace('\\r', '\\n')\n                    if len(text) == 0:\n                        raise ValueError(err_msg + f' Text {sample_id} is empty!')\n                    sentences = []\n                    for paragraph in map(lambda it: it.strip(), text.split('\\n')):\n                        if len(paragraph) > 0:\n                            sentences += nltk.sent_tokenize(paragraph)\n                    if len(sentences) == 0:\n                        raise ValueError(err_msg + f' Text {sample_id} is empty!')\n                    text = ' '.join([cur_sent.lower() for cur_sent in sentences])\n                    if text in set_of_texts:\n                        raise ValueError(err_msg + f' Text {sample_id} is not unique!')\n                    set_of_texts.add(text.lower())\n                    try:\n                        target_val = float(row[target_col_idx])\n                        ok = True\n                    except:\n                        target_val = 0.0\n                        ok = False\n                    if not ok:\n                        err_msg2 = err_msg\n                        err_msg2 += f' {row[target_col_idx]} is wrong target for ' \\\n                                    f'text {sample_id}.'\n                        raise ValueError(err_msg2)\n                    try:\n                        std_val = float(row[std_col_idx])\n                        ok = (std_val > 0.0)\n                    except:\n                        std_val = 0.0\n                        ok = False\n                    if not ok:\n                        err_msg2 = err_msg\n                        err_msg2 += f' {row[std_col_idx]} is wrong standard error' \\\n                                    f' for text {sample_id}.'\n                        warnings.warn(err_msg2)\n                    else:\n                        data[sample_id] = (\n                            [tok.cls_token] + tok.tokenize(text) + [tok.sep_token],\n                            target_val, std_val,\n                            calc_text_features([sentences], tok)\n                        )\n            line_idx += 1\n    return data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data_for_testing(fname: str, tok: AutoTokenizer, batch_size: int):\n    loaded_header = []\n    id_col_idx = -1\n    text_col_idx = -1\n    target_col_idx = -1\n    std_col_idx = -1\n    line_idx = 1\n    data = dict()\n    with codecs.open(fname, mode='r', encoding='utf-8') as fp:\n        data_reader = csv.reader(fp, quotechar='\"', delimiter=',')\n        for row in data_reader:\n            if len(row) > 0:\n                err_msg = f'File {fname}: line {line_idx} is wrong!'\n                if len(loaded_header) == 0:\n                    loaded_header = copy.copy(row)\n                    try:\n                        text_col_idx = loaded_header.index('excerpt')\n                    except:\n                        text_col_idx = -1\n                    if text_col_idx <= 0:\n                        raise ValueError(err_msg + ' Field \"excerpt\" is not found!')\n                    try:\n                        id_col_idx = loaded_header.index('id')\n                    except:\n                        id_col_idx = -1\n                    if id_col_idx < 0:\n                        raise ValueError(err_msg + ' Field \"id\" is not found!')\n                else:\n                    sample_id = row[id_col_idx]\n                    if sample_id != sample_id.strip():\n                        raise ValueError(err_msg + f' {sample_id} is wrong sample ID!')\n                    if sample_id in data:\n                        err_msg2 = f'{err_msg} {sample_id} is not unique sample ID!'\n                        raise ValueError(err_msg2)\n                    text = row[text_col_idx].replace('\\n', ' ').replace('\\r', ' ')\n                    text = ' '.join(text.split()).strip()\n                    if len(text) == 0:\n                        raise ValueError(err_msg + f' Text {sample_id} is empty!')\n                    features = calc_text_features([nltk.sent_tokenize(text)], tok) \n                    data[sample_id] = (\n                        [tok.cls_token] + tok.tokenize(text.lower()) + [tok.sep_token],\n                        features\n                    )\n                    if len(data) >= batch_size:\n                        yield data\n                        del data\n                        data = dict()\n            line_idx += 1\n    if len(data) > 0:\n        yield data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vectorize_data(\n    data: Union[List[Dict[str, Tuple[List[str], np.ndarray]]],\n                List[Dict[str, Tuple[List[str], float, float, np.ndarray]]]],\n    tokenizer: AutoTokenizer, fe: tf.keras.Model, scaler: StandardScaler,\n    max_seq_len: int, batch_size: int\n) -> Tuple[Union[Dict[str, int], Dict[str, Tuple[int, float, float]]], np.ndarray]:\n    tokenized_data = dict()\n    all_tokens_matrix = []\n    additional_features = []\n    for sample_idx, cur_ID in enumerate(sorted(list(data.keys()))):\n        if len(data[cur_ID]) == 2:\n            tokens = data[cur_ID][0]\n            token_ids = tokenizer.convert_tokens_to_ids(\n                [tokenizer.cls_token] + tokens + [tokenizer.sep_token]\n            )\n            ndiff = max_seq_len - len(token_ids)\n            if ndiff > 0:\n                token_ids += [tokenizer.pad_token_id for _ in range(ndiff)]\n            elif ndiff < 0:\n                token_ids = token_ids[:max_seq_len]\n            tokenized_data[cur_ID] = len(all_tokens_matrix)\n            all_tokens_matrix.append(token_ids)\n            additional_features.append(data[cur_ID][1])\n        else:\n            tokens = data[cur_ID][0]\n            token_ids = tokenizer.convert_tokens_to_ids(\n                [tokenizer.cls_token] + tokens + [tokenizer.sep_token]\n            )\n            ndiff = max_seq_len - len(token_ids)\n            if ndiff > 0:\n                token_ids += [tokenizer.pad_token_id for _ in range(ndiff)]\n            elif ndiff < 0:\n                token_ids = token_ids[:max_seq_len]\n            tokenized_data[cur_ID] = (\n                len(all_tokens_matrix),\n                data[cur_ID][1],\n                data[cur_ID][2]\n            )\n            all_tokens_matrix.append(token_ids)\n            additional_features.append(data[cur_ID][3])\n    n_samples = len(all_tokens_matrix)\n    while len(all_tokens_matrix) % batch_size != 0:\n        all_tokens_matrix.append(all_tokens_matrix[-1])\n        additional_features.append(additional_features[-1])\n    all_tokens_matrix = np.array(all_tokens_matrix, dtype=np.int32)\n    attentions = generate_attention_mask(all_tokens_matrix, tokenizer.pad_token_id)\n    additional_features = scaler.transform(np.vstack(additional_features))\n    features = fe.predict(\n        [all_tokens_matrix, attentions, additional_features],\n        batch_size=batch_size\n    )[:n_samples]\n    return tokenized_data, features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_feature_extractor(fe_dir_name: str) -> Tuple[tf.keras.Model, StandardScaler,\n                                                      int, int]:\n    batch_size = 32\n    max_seq_len = 256\n    scaler_name = os.path.join(fe_dir_name, 'output_scaler.pkl')\n    assert os.path.isfile(scaler_name)\n    nn_weights_name = os.path.join(fe_dir_name, 'regression_nn.h5')\n    assert os.path.isfile(nn_weights_name)\n    with open(scaler_name, 'rb') as fp:\n        text_feature_scaler, _ = pickle.load(fp)\n    feature_vector_size = text_feature_scaler.scale_.shape[0]\n    transformer_config = AutoConfig.from_pretrained(fe_dir_name)\n    print('Transformer Configuration')\n    print('=========================')\n    transformer_model = TFAutoModel.from_config(\n        config=transformer_config,\n        name='DistilTransformer'\n    )\n    united_emb_layer = tf.keras.layers.Dense(\n        units=256, input_dim=transformer_config.hidden_size,\n        activation='tanh',\n        kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42),\n        bias_initializer='zeros' \n    )\n    print(transformer_config)\n    left_tokens = tf.keras.layers.Input(shape=(max_seq_len,), batch_size=batch_size,\n                                        dtype=tf.int32, name='word_ids')\n    left_attention = tf.keras.layers.Input(shape=(max_seq_len,), batch_size=batch_size,\n                                           dtype=tf.int32, name='attention_mask')\n    left_features = tf.keras.layers.Input(shape=(feature_vector_size,), dtype=tf.float32,\n                                          batch_size=batch_size, name='features')\n    left_sequence_output = transformer_model([left_tokens, left_attention])[0]\n    left_output_mask = MaskCalculator(\n        output_dim=transformer_config.hidden_size, trainable=False,\n        name='OutMaskCalculator'\n    )(left_attention)\n    left_masked_output = tf.keras.layers.Multiply(\n        name='OutMaskMultiplicator'\n    )([left_output_mask, left_sequence_output])\n    left_masked_output = tf.keras.layers.Masking(\n        name='OutMasking'\n    )(left_masked_output)\n    left_output = tf.keras.layers.GlobalAvgPool1D(name='AvePool')(left_masked_output)\n    left_output = tf.keras.layers.LayerNormalization(\n        name='Emdedding'\n    )(left_output)\n    left_output = tf.keras.layers.Concatenate(\n        name='Concat'\n    )([left_output, left_features])\n    left_output = tf.keras.layers.Dropout(\n        rate=0.3, seed=42, name='Dropout1' \n    )(left_output)\n    left_output = united_emb_layer(left_output)\n    regression_layer = tf.keras.layers.Dense(\n        units=1, input_dim=256, activation=None,\n        kernel_initializer=tf.keras.initializers.GlorotNormal(seed=42),\n        bias_initializer='zeros',\n        kernel_regularizer=tf.keras.regularizers.l1_l2(l1=1e-5, l2=1e-4),\n        name='RegressionLayer'\n    )\n    left_regression_output = regression_layer(left_output)\n    regression_model = tf.keras.Model(\n        inputs=[left_tokens, left_attention, left_features],\n        outputs=left_regression_output,\n        name='RegressionModel'\n    )\n    regression_model.build(input_shape=[(batch_size, max_seq_len),\n                                        (batch_size, max_seq_len),\n                                        (batch_size, feature_vector_size)])\n    feature_extraction_model = tf.keras.Model(\n        inputs=[left_tokens, left_attention, left_features],\n        outputs=left_output,\n        name='FeatureExtractionModel'\n    )\n    feature_extraction_model.build(input_shape=[(batch_size, max_seq_len),\n                                                (batch_size, max_seq_len),\n                                                (batch_size, feature_vector_size)])\n    regression_model.load_weights(nn_weights_name)\n    return feature_extraction_model, text_feature_scaler, max_seq_len, batch_size","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mixup(X: np.ndarray, y_mean: np.ndarray, y_std: np.ndarray,\n          mixup_coeff: float, n_samples: int) -> Tuple[np.ndarray, np.ndarray]:\n    assert (mixup_coeff > 0.0) and (mixup_coeff < 1.0)\n    assert len(X.shape) == 2\n    assert len(y_mean.shape) == 1\n    assert len(y_std.shape) == 1\n    assert X.shape[0] == y_mean.shape[0]\n    assert y_mean.shape[0] == y_std.shape[0]\n    X_new = np.empty((n_samples, X.shape[1]), dtype=np.float64)\n    y_new = np.empty((n_samples,), dtype=np.float64)\n    for sample_idx in range(n_samples):\n        idx1 = random.randint(0, X.shape[0] - 1)\n        idx2 = random.randint(0, X.shape[0] - 1)\n        X_new[sample_idx] = (1.0 - mixup_coeff) * X[idx1] + mixup_coeff * X[idx2]\n        y_new[sample_idx] = (1.0 - mixup_coeff) * np.random.normal(\n            loc=y_mean[idx1], scale=y_std[idx1]\n        )\n        y_new[sample_idx] += mixup_coeff * np.random.normal(\n            loc=y_mean[idx2], scale=y_std[idx2]\n        )\n    return X_new, y_new","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_regressor(labels: Dict[str, Tuple[int, float, float]], features: np.ndarray,\n                    IDs_for_training: List[str],\n                    IDs_for_validation: List[str], batch_size: int,\n                    ensemble_idx: int) -> tf.keras.Model:\n    X_train = []\n    y_train_mean = []\n    y_train_std = []\n    X_val = []\n    y_val = []\n    for cur_id in IDs_for_training:\n        sample_idx, target_mean, target_std = labels[cur_id]\n        X_train.append(features[sample_idx:(sample_idx + 1)])\n        y_train_mean.append(target_mean)\n        y_train_std.append(target_std)\n    X_train = np.vstack(X_train)\n    y_train_mean = np.array(y_train_mean, dtype=np.float32)\n    y_train_std = np.array(y_train_std, dtype=np.float32)\n    for cur_id in IDs_for_validation:\n        sample_idx, target, _ = labels[cur_id]\n        X_val.append(features[sample_idx:(sample_idx + 1)])\n        y_val.append(target)\n    X_val = np.vstack(X_val)\n    y_val = np.array(y_val, dtype=np.float32)\n    regressor = tf.keras.Sequential(\n        layers=[\n            tf.keras.layers.InputLayer(\n                input_shape=(features.shape[1],),\n                dtype=tf.float32,\n                name=f'input_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.AlphaDropout(\n                rate=0.1, seed=ensemble_idx * 10,\n                name=f'dropout1_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.Dense(\n                units=400, activation='selu',\n                kernel_initializer=tf.keras.initializers.LecunNormal(\n                    seed=(ensemble_idx + 1) * 10\n                ),\n                name=f'dense1_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.AlphaDropout(\n                rate=0.1, seed=ensemble_idx * 20,\n                name=f'dropout2_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.Dense(\n                units=400, activation='selu',\n                kernel_initializer=tf.keras.initializers.LecunNormal(\n                    seed=(ensemble_idx + 1) * 20\n                ),\n                name=f'dense2_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.AlphaDropout(\n                rate=0.1, seed=ensemble_idx * 30,\n                name=f'dropout3_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.Dense(\n                units=300, activation='selu',\n                kernel_initializer=tf.keras.initializers.LecunNormal(\n                    seed=(ensemble_idx + 1) * 30\n                ),\n                name=f'dense3_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.AlphaDropout(\n                rate=0.1, seed=ensemble_idx * 40,\n                name=f'dropout4_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.Dense(\n                units=300, activation='selu',\n                kernel_initializer=tf.keras.initializers.LecunNormal(\n                    seed=(ensemble_idx + 1) * 40\n                ),\n                name=f'dense4_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.AlphaDropout(\n                rate=0.1, seed=ensemble_idx * 50,\n                name=f'dropout5_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.Dense(\n                units=200, activation='selu',\n                kernel_initializer=tf.keras.initializers.LecunNormal(\n                    seed=(ensemble_idx + 1) * 50\n                ),\n                name=f'dense5_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.AlphaDropout(\n                rate=0.1, seed=ensemble_idx * 60,\n                name=f'dropout6_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.Dense(\n                units=100, activation='selu',\n                kernel_initializer=tf.keras.initializers.LecunNormal(\n                    seed=(ensemble_idx + 1) * 60\n                ),\n                name=f'dense6_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.AlphaDropout(\n                rate=0.1, seed=ensemble_idx * 70,\n                name=f'dropout7_nn{ensemble_idx}'\n            ),\n            tf.keras.layers.Dense(\n                units=1, activation=None,\n                kernel_initializer=tf.keras.initializers.LecunNormal(\n                    seed=(ensemble_idx + 1) * 70\n                ),\n                name=f'dense7_nn{ensemble_idx}'\n            )\n        ],\n        name=f'FinalRegressor{ensemble_idx}'\n    )\n    radam = tfa.optimizers.RectifiedAdam(learning_rate=1e-3)\n    ranger = tfa.optimizers.Lookahead(radam, sync_period=6, slow_step_size=0.5)\n    regressor.compile(optimizer=ranger, loss=tf.keras.losses.MeanSquaredError(),\n                      metrics=[tf.keras.metrics.RootMeanSquaredError()])\n    print(f'Estimator {ensemble_idx}')\n    print('====================')\n    print('')\n    regressor.summary()\n    X_train, y_train = mixup(X_train, y_train_mean, y_train_std, 0.1, 50000)\n    steps_per_epoch = min(5 * X_val.shape[0], X_train.shape[0]) // batch_size\n    steps_per_trainset = X_train.shape[0] // batch_size\n    n_epochs = steps_per_trainset // steps_per_epoch\n    print('')\n    print(f'steps_per_trainset = {steps_per_trainset}')\n    print(f'steps_per_epoch = {steps_per_epoch}')\n    print(f'n_epochs = {n_epochs}')\n    print('')\n    callbacks = [\n        tf.keras.callbacks.EarlyStopping(\n            monitor=\"val_root_mean_squared_error\",\n            patience=3,\n            verbose=True,\n            restore_best_weights=True\n        )\n    ]\n    tf_trainset = tf.data.Dataset.from_tensor_slices(\n        (X_train, y_train)\n    ).repeat().shuffle(50000).batch(batch_size)\n    tf_validset = tf.data.Dataset.from_tensor_slices(\n        (X_val, y_val)\n    ).batch(batch_size)\n    history = regressor.fit(tf_trainset, validation_data=tf_validset,\n                            callbacks=callbacks, epochs=n_epochs,\n                            steps_per_epoch=steps_per_epoch, batch_size=batch_size)\n    show_training_process(history, \"root_mean_squared_error\",\n                          ensemble_idx, f'of regressor {ensemble_idx}')\n    return regressor","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_training_process(history: tf.keras.callbacks.History, metric_name: str,\n                          figure_id: int, additional_info: str):\n    val_metric_name = 'val_' + metric_name\n    possible_metrics = list(history.history.keys())\n    if metric_name not in history.history:\n        err_msg = f'The metric \"{metric_name}\" is not found!'\n        err_msg += f' Available metrics are: {possible_metrics}.'\n        raise ValueError(err_msg)\n    fig = plt.figure(figure_id, figsize=(7, 7))\n    metric_values = history.history[metric_name]\n    plt.plot(list(range(len(metric_values))), metric_values,\n             label='Training {0}'.format(metric_name))\n    if val_metric_name in history.history:\n        val_metric_values = history.history['val_' + metric_name]\n        assert len(metric_values) == len(val_metric_values)\n        plt.plot(list(range(len(val_metric_values))), val_metric_values,\n                 label='Validation {0}'.format(metric_name))\n    plt.xlabel('Epochs')\n    plt.ylabel(metric_name)\n    if len(additional_info.strip()) == 0:\n        plt.title('Training process')\n    else:\n        plt.title('Training process ' + additional_info.strip())\n    plt.legend(loc='best')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def do_predictions(regressor: List[tf.keras.Model], batch_size: int, features: np.ndarray,\n                   data: Union[Dict[str, int], Dict[str, Tuple[int, float, float]]],\n                   identifiers: Union[List[str], None]=None) -> Dict[str, float]:\n    if identifiers is None:\n        identifiers_ = sorted(list(data.keys()))\n    else:\n        identifiers_ = sorted(identifiers)\n    indices = list(map(\n        lambda it: data[it] if isinstance(data[it], int) else data[it][0],\n        identifiers_\n    ))\n    X = features[indices]\n    predictions = regressor[0].predict(X, batch_size=batch_size).reshape((len(indices),))\n    for cur in regressor[1:]:\n        predictions += cur.predict(X, batch_size=batch_size).reshape((len(indices),))\n    predictions /= float(len(regressor))\n    return dict(map(lambda idx: (identifiers_[idx], predictions[idx]),\n                    range(len(indices))))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(42)\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PRETRAINED_MODEL_DIR = '/kaggle/input/tf-readability-distilbert'\nprint(f'{PRETRAINED_MODEL_DIR} {os.path.isdir(PRETRAINED_MODEL_DIR)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_tokenizer = AutoTokenizer.from_pretrained(PRETRAINED_MODEL_DIR)\nfeature_extractor, input_scaler, max_text_len, minibatch_size = load_feature_extractor(\n    PRETRAINED_MODEL_DIR\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATA_DIR = '/kaggle/input/commonlitreadabilityprize'\nMODEL_DIR = '/kaggle/working'\nprint(f'{DATA_DIR} {os.path.isdir(DATA_DIR)}')\nprint(f'{MODEL_DIR} {os.path.isdir(MODEL_DIR)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset_name = os.path.join(DATA_DIR, 'train.csv')\nprint(f'{trainset_name} {os.path.isfile(trainset_name)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testset_name = os.path.join(DATA_DIR, 'test.csv')\nprint(f'{testset_name} {os.path.isfile(testset_name)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_name = os.path.join(MODEL_DIR, 'submission.csv')\nprint(f'{submission_name} {os.path.isfile(submission_name)}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_for_training = load_data_for_training(trainset_name,\n                                           pretrained_tokenizer)\nassert len(data_for_training) > 100","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_for_training, features_for_training = vectorize_data(\n    data=data_for_training,\n    tokenizer=pretrained_tokenizer,\n    fe=feature_extractor,\n    scaler=input_scaler,\n    max_seq_len=max_text_len,\n    batch_size=minibatch_size\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_IDs = list(data_for_training.keys())\nrandom.shuffle(all_IDs)\nn_train_size = int(round(len(all_IDs) * 0.7))\nn_val_size = int(round(len(all_IDs) * 0.15))\nidentifiers_for_training = all_IDs[:n_train_size]\nidentifiers_for_validation = all_IDs[n_train_size:(n_train_size + n_val_size)]\nidentifiers_for_final_testing = all_IDs[(n_train_size + n_val_size):]\ndel all_IDs","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=1\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 1 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=2\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 2 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=3\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 3 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=4\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 4 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=5\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 5 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=6\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 6 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=7\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 7 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=8\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 8 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=9\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 9 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=10\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 10 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=11\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 11 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=12\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 12 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=13\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 13 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=14\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 14 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=15\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 15 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=16\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 16 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=17\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 17 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=18\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 18 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=19\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 19 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=20\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 20 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=21\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 21 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=22\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 22 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=23\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 23 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=24\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 24 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ensemble.append(\n    build_regressor(\n        labels=data_for_training,\n        features=features_for_training,\n        IDs_for_training=identifiers_for_training,\n        IDs_for_validation=identifiers_for_validation,\n        batch_size=minibatch_size * 4,\n        ensemble_idx=25\n    )\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble[-1:], batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of item 25 = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions_for_testing = do_predictions(\n    regressor=ensemble, batch_size=minibatch_size * 4,\n    data=data_for_training, features=features_for_training,\n    identifiers=identifiers_for_final_testing\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"error = 0.0\nfor cur_id in identifiers_for_final_testing:\n    difference = predictions_for_testing[cur_id] - data_for_training[cur_id][1]\n    error += (difference * difference)\nerror /= float(len(identifiers_for_final_testing))\nerror = np.sqrt(error)\nprint(f'RMSE of ensemble = {error}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with codecs.open(submission_name, mode='w', encoding='utf-8') as fp:\n    data_writer = csv.writer(fp, quotechar='\"', delimiter=',')\n    data_writer.writerow(['id', 'target'])\n    for data_part in load_data_for_testing(testset_name, pretrained_tokenizer,\n                                           minibatch_size * 32):\n        data_for_submission, features_for_submission = vectorize_data(\n            data=data_part,\n            tokenizer=pretrained_tokenizer,\n            fe=feature_extractor,\n            scaler=input_scaler,\n            max_seq_len=max_text_len,\n            batch_size=minibatch_size\n        )\n        predictions_for_submission = do_predictions(\n            regressor=ensemble, batch_size=minibatch_size * 4,\n            data=data_for_submission, features=features_for_submission\n        )\n        for cur_id in predictions_for_submission:\n            data_writer.writerow([cur_id, f'{predictions_for_submission[cur_id]}'])\n        del predictions_for_submission\n        del data_for_submission, features_for_submission\n        gc.collect()","metadata":{},"execution_count":null,"outputs":[]}]}