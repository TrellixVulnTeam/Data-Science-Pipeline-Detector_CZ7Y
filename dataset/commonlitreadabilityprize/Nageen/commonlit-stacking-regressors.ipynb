{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-08T12:04:03.2445Z","iopub.execute_input":"2021-07-08T12:04:03.245274Z","iopub.status.idle":"2021-07-08T12:04:03.284249Z","shell.execute_reply.started":"2021-07-08T12:04:03.245125Z","shell.execute_reply":"2021-07-08T12:04:03.282644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code installs the spacy pretrained embeddings","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!mkdir -p /tmp/pip/cache/","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:04:12.005434Z","iopub.execute_input":"2021-07-08T12:04:12.005925Z","iopub.status.idle":"2021-07-08T12:04:12.768029Z","shell.execute_reply.started":"2021-07-08T12:04:12.005856Z","shell.execute_reply":"2021-07-08T12:04:12.766538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!cp ../input/spacyword2vec/en_core_web_md-2.3.1.xyz /tmp/pip/cache/en_core_web_md-2.3.1.tar.gz","metadata":{"execution":{"iopub.status.busy":"2021-07-07T14:04:58.872644Z","iopub.execute_input":"2021-07-07T14:04:58.872991Z","iopub.status.idle":"2021-07-07T14:05:01.586111Z","shell.execute_reply.started":"2021-07-07T14:04:58.872943Z","shell.execute_reply":"2021-07-07T14:05:01.585228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp ../input/spacy-encore-web-large/en_core_web_lg-2.2.5.tar.xyz /tmp/pip/cache/en_core_web_lg-2.2.5.tar.gz","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:05:24.645389Z","iopub.execute_input":"2021-07-08T12:05:24.645761Z","iopub.status.idle":"2021-07-08T12:05:33.879808Z","shell.execute_reply.started":"2021-07-08T12:05:24.645725Z","shell.execute_reply":"2021-07-08T12:05:33.878547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install /tmp/pip/cache/en_core_web_md-2.3.1.tar.gz","metadata":{"execution":{"iopub.status.busy":"2021-07-07T14:05:02.593827Z","iopub.execute_input":"2021-07-07T14:05:02.594229Z","iopub.status.idle":"2021-07-07T14:05:16.058822Z","shell.execute_reply.started":"2021-07-07T14:05:02.59419Z","shell.execute_reply":"2021-07-07T14:05:16.057757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /tmp/pip/cache/en_core_web_lg-2.2.5.tar.gz","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:05:38.692256Z","iopub.execute_input":"2021-07-08T12:05:38.692647Z","iopub.status.idle":"2021-07-08T12:08:00.027264Z","shell.execute_reply.started":"2021-07-08T12:05:38.692613Z","shell.execute_reply":"2021-07-08T12:08:00.025953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install ../input/textstat/Pyphen-0.10.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-07-07T14:03:31.765068Z","iopub.execute_input":"2021-07-07T14:03:31.765444Z","iopub.status.idle":"2021-07-07T14:03:38.037675Z","shell.execute_reply.started":"2021-07-07T14:03:31.765404Z","shell.execute_reply":"2021-07-07T14:03:38.036767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install ../input/textstat/textstat-0.7.0-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2021-07-07T14:04:05.740862Z","iopub.execute_input":"2021-07-07T14:04:05.741183Z","iopub.status.idle":"2021-07-07T14:04:11.824583Z","shell.execute_reply.started":"2021-07-07T14:04:05.741151Z","shell.execute_reply":"2021-07-07T14:04:11.823491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Import the required libraries","metadata":{}},{"cell_type":"code","source":"import spacy\n#import en_core_web_md\nimport en_core_web_lg\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Lasso, Ridge\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom catboost import CatBoostRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\nimport nltk\nfrom nltk import pos_tag, word_tokenize\nfrom sklearn.base import BaseEstimator, TransformerMixin\n#from textstat import flesch_reading_ease, flesch_kincaid_grade","metadata":{"execution":{"iopub.status.busy":"2021-07-08T12:09:01.367292Z","iopub.execute_input":"2021-07-08T12:09:01.367707Z","iopub.status.idle":"2021-07-08T12:09:04.459877Z","shell.execute_reply.started":"2021-07-08T12:09:01.367674Z","shell.execute_reply":"2021-07-08T12:09:04.459034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nltk.download('averaged_perceptron_tagger')\nnltk.download('punkt')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T14:05:46.803924Z","iopub.execute_input":"2021-07-07T14:05:46.804271Z","iopub.status.idle":"2021-07-07T14:06:26.869576Z","shell.execute_reply.started":"2021-07-07T14:05:46.804241Z","shell.execute_reply":"2021-07-07T14:06:26.868666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-07T14:06:26.871098Z","iopub.execute_input":"2021-07-07T14:06:26.871355Z","iopub.status.idle":"2021-07-07T14:06:26.999627Z","shell.execute_reply.started":"2021-07-07T14:06:26.87133Z","shell.execute_reply":"2021-07-07T14:06:26.998766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df['flesch_reading_ease'] = df['excerpt'].apply(lambda x: flesch_reading_ease(x))\n#df['flesch_kincaid_grade'] = df['excerpt'].apply(lambda x: flesch_kincaid_grade(x))","metadata":{"execution":{"iopub.status.busy":"2021-07-07T14:06:55.98184Z","iopub.execute_input":"2021-07-07T14:06:55.982581Z","iopub.status.idle":"2021-07-07T14:07:04.452164Z","shell.execute_reply.started":"2021-07-07T14:06:55.982538Z","shell.execute_reply":"2021-07-07T14:07:04.451149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create another feature which has the POS tag for every word in the given excerpt.","metadata":{}},{"cell_type":"code","source":"def get_pos_tags(row):\n  word_tokenized = word_tokenize(row)\n  pos_tags = pos_tag(row)\n  pos_text = \" \".join([x[1] for x in pos_tags])\n  return pos_text \ndf['pos_tag'] = df['excerpt'].apply(get_pos_tags)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nlp = spacy.load('en_core_web_lg')\ndef get_tok_lefts(row):\n  out = nlp(row)\n  #tokens = ''\n  #for token in out.doc:\n  #  tokens = tokens + ' ' + token.dep_\n  return np.array([len(list(token.lefts)) for token in out.doc if not token.is_punct]).sum()\n\n\ndef get_tok_rights(row):\n  out = nlp(row)\n  #tokens = ''\n  #for token in out.doc:\n  #  tokens = tokens + ' ' + token.dep_\n  return np.array([len(list(token.rights)) for token in out.doc if not token.is_punct]).sum()","metadata":{"execution":{"iopub.status.busy":"2021-07-08T13:56:35.654718Z","iopub.execute_input":"2021-07-08T13:56:35.655414Z","iopub.status.idle":"2021-07-08T13:56:35.665191Z","shell.execute_reply.started":"2021-07-08T13:56:35.655306Z","shell.execute_reply":"2021-07-08T13:56:35.664493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['token_lefts'] = df['excerpt'].apply(get_tok_lefts)\ndf['token_rights'] = df['excerpt'].apply(get_tok_rights)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create a class that is used to convert the text to word embeddings","metadata":{}},{"cell_type":"code","source":"class WordVectorTransformer(TransformerMixin, BaseEstimator):\n  def __init__(self, model='en_core_web_md'):\n    self.model = model\n\n  def fit(self, X, y=None):\n    return self\n\n  def transform(self, X):\n    #nlp = en_core_web_md.load()\n    nlp = en_core_web_lg.load()\n    #print(X)\n    embed_text = np.concatenate([nlp(doc).vector.reshape(1,-1) for doc in X])\n    #print(f'{embed_text.shape},{embed_text}')\n    return embed_text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df[['excerpt','pos_tag','token_lefts','token_rights']]#,'flesch_reading_ease']]\ny = df['target']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Using Column Transformer from sklearn. The first transformer converts the excerpt into a embedding. The second transformer converts the POS tagged text using Tfidf Vectorizer","metadata":{}},{"cell_type":"code","source":"column_transform = ColumnTransformer([('tfidf',WordVectorTransformer(),'excerpt'),\n                                      ('tfidf_pos',CountVectorizer(), 'pos_tag')],\n                                     remainder=\"passthrough\"\n                                     )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The final pipeline is built using the Stacking Regressor from sklearn. Ridge regressor, XGboost, Light GBM and CatBoost regressors are used in the stacking ensemble.","metadata":{}},{"cell_type":"code","source":"model = Pipeline([('preprocess', column_transform),\n                    ('model', StackingRegressor([\n                                              ('ridge', Ridge(alpha=0.8, solver='sag', max_iter=2000)),\n                                              ('xgb',XGBRegressor()),\n                                              ('lgbm',LGBMRegressor()),\n                                              ('catboost',CatBoostRegressor())\n                                              ])\n                    )\n                    ])\n\nmodel.fit(X, y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\ndf_test['pos_tag'] = df_test['excerpt'].apply(get_pos_tags)\n#df_test['flesch_reading_ease'] = df_test['excerpt'].apply(lambda x: flesch_reading_ease(x))\ndf_test['token_lefts'] = df_test['excerpt'].apply(get_tok_lefts)\ndf_test['token_rights'] = df_test['excerpt'].apply(get_tok_rights)\nX_test = df_test[['excerpt','pos_tag','token_lefts','token_rights']]#,'flesch_reading_ease']]\npreds = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': df_test['id'],\n                       'target': preds})","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}