{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install contractions\n!pip install textacy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-26T00:47:19.240236Z","iopub.execute_input":"2021-07-26T00:47:19.240768Z","iopub.status.idle":"2021-07-26T00:48:03.697565Z","shell.execute_reply.started":"2021-07-26T00:47:19.240666Z","shell.execute_reply":"2021-07-26T00:48:03.696225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport re\nimport html\nimport unicodedata\nimport contractions\nfrom textacy.similarity.edits import hamming\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nnp.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:48:08.111129Z","iopub.execute_input":"2021-07-26T00:48:08.111603Z","iopub.status.idle":"2021-07-26T00:48:18.687489Z","shell.execute_reply.started":"2021-07-26T00:48:08.111562Z","shell.execute_reply":"2021-07-26T00:48:18.686122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:48:20.70763Z","iopub.execute_input":"2021-07-26T00:48:20.708083Z","iopub.status.idle":"2021-07-26T00:48:20.796433Z","shell.execute_reply.started":"2021-07-26T00:48:20.708045Z","shell.execute_reply":"2021-07-26T00:48:20.795235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Searching for Similar Texts\n\n---\n\nFor this task, we will compute the similarity between two strings using the Hamming distance, which gives the number of characters in the corresponding string indices that differ, including characters in the longer string that have no correspondence in the shorter one. In my case, the choice is based mainly on execution speed - it calculates the pairwise similarity between all excertps in the training dataset in 30 seconds, while other [document similarity metrics (Levenshtein, Jaro, character ngrams)](https://textacy.readthedocs.io/en/0.11.0/api_reference/similarity.html) from the same library that I have tested perform the same tasks with a time consumption from 1.5 to 12 hours. If you have any other solutions that helped you find more duplicates, I would appreciate it if you share them in the comments. Also, if you would like more information about the train dataset visit [CommonLit: In-Depth EDA + Baseline](https://www.kaggle.com/oleksandrsirenko/commonlit-in-depth-eda-baseline/notebook).","metadata":{}},{"cell_type":"code","source":"def compute_similarity(df, metric):\n    for i in tqdm(range(len(df))):\n        target_str = df.iloc[i]['excerpt']\n        col_name = df.iloc[i]['id']\n        df[col_name] = df.excerpt.apply(lambda compare_str: metric(target_str, compare_str))\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:48:22.912442Z","iopub.execute_input":"2021-07-26T00:48:22.912813Z","iopub.status.idle":"2021-07-26T00:48:22.918221Z","shell.execute_reply.started":"2021-07-26T00:48:22.912783Z","shell.execute_reply":"2021-07-26T00:48:22.917497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sim_df = compute_similarity(train_df, hamming)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:48:24.622142Z","iopub.execute_input":"2021-07-26T00:48:24.622759Z","iopub.status.idle":"2021-07-26T00:48:54.193874Z","shell.execute_reply.started":"2021-07-26T00:48:24.622707Z","shell.execute_reply":"2021-07-26T00:48:54.192652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_duplicates(df, similarity=0.3):\n    cols = df.id.values.tolist()\n    doc = {col: df.loc[(df[col] >= similarity) & (df.id != col)][['id', col]].values.tolist() for col in cols}\n    return {k: v for k, v in doc.items() if len(v) >= 1}","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:48:57.177718Z","iopub.execute_input":"2021-07-26T00:48:57.178118Z","iopub.status.idle":"2021-07-26T00:48:57.185533Z","shell.execute_reply.started":"2021-07-26T00:48:57.178087Z","shell.execute_reply":"2021-07-26T00:48:57.18393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_duplicates(sim_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:48:59.198181Z","iopub.execute_input":"2021-07-26T00:48:59.19875Z","iopub.status.idle":"2021-07-26T00:49:05.383596Z","shell.execute_reply.started":"2021-07-26T00:48:59.19871Z","shell.execute_reply":"2021-07-26T00:49:05.382439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.loc[train_df.id.isin(['da2dbbc70', 'dab96a9ab', 'd2556a097', '0684bb254'])][['id', 'target', 'excerpt']].values.tolist()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:49:08.407924Z","iopub.execute_input":"2021-07-26T00:49:08.408398Z","iopub.status.idle":"2021-07-26T00:49:08.421296Z","shell.execute_reply.started":"2021-07-26T00:49:08.408354Z","shell.execute_reply":"2021-07-26T00:49:08.419889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop Duplicates\n\n---\n\nAs we can see, the first pair of excerpts(`da2dbbc70`, `dab96a9ab`) are almost identical and have close targets values (**-0.811519925,  -0.855847764**), they differ only in the presence of a short monologue in quotes at the end of the second passage. I think we can drop any of these texts here. Another pair of similar excerpts (`d2556a097`, `0684bb254`) are completely the same but have significantly different targets (**0.810874254, 0.10280278**). Here I prefer to drop the last one because subjectively text is simple, which corresponds to a more positive target value.","metadata":{}},{"cell_type":"code","source":"drop_ids = ['da2dbbc70', '0684bb254']\ntrain_df = train_df.loc[~train_df.id.isin(drop_ids)][['id', 'excerpt', 'target', 'standard_error']].reset_index(drop=True)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:49:21.088209Z","iopub.execute_input":"2021-07-26T00:49:21.088677Z","iopub.status.idle":"2021-07-26T00:49:21.157036Z","shell.execute_reply.started":"2021-07-26T00:49:21.088638Z","shell.execute_reply":"2021-07-26T00:49:21.155662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Text Cleaning\n\n---\n\nIn this part, we will try to clean the text without further processing such as tokenization, lemmatization, stemming, etc. The goal is to purify the text by handling the artifacts, normalize it, correct clitics, and return in the same format. The refined text can then be used for further processing according to the chosen model, tokenizer, or preparation techniques.","metadata":{}},{"cell_type":"code","source":"RE_LINEBREAK = re.compile(r\"(\\r\\n|[\\n\\v])+\")\nRE_HYPHEN = re.compile(r'-(?!\\w)|(?<!\\w)-') # all hyphens except ones between words\nRE_SINGLE_QUOTE = re.compile(r'[\\u2039\\u203a\\u2018\\u2019\\u201a\\u201b\\u275b\\u275c\\u275f\\u02bc\\u0060]')\nRE_DOUBLE_QUOTE = re.compile(r'[\\u00ab\\u00bb\\u201c\\u201d\\u201e\\u201f\\u2e42\\u301d\\u301d\\u301f]')\nRE_CURRENCY_SYMBOL = re.compile(r\"[$¢£¤¥ƒ֏؋৲৳૱௹฿៛ℳ元円圆圓﷼\\u20A0-\\u20C0]\")\nRE_NUMBER = re.compile(r'\\d+')\nRE_SPACES = re.compile(r'\\s{2,}') # 2+ spaces\nRE_WORD = re.compile(r\"([\\w']+)\") # words including contractions\nRE_SENTENCE = re.compile(r'(?<=[.])\\s')\nRE_CONTRACTIONS = re.compile(r\"([\\w]+['][\\w]+)\")\nRE_PUNCT = re.compile(r'[^\\w\\s.,!?\\-]') # all punctuation except .,!?-","metadata":{"execution":{"iopub.status.busy":"2021-07-26T00:49:26.651295Z","iopub.execute_input":"2021-07-26T00:49:26.651652Z","iopub.status.idle":"2021-07-26T00:49:26.663008Z","shell.execute_reply.started":"2021-07-26T00:49:26.651621Z","shell.execute_reply":"2021-07-26T00:49:26.661781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# {'NAME': (PATTERN, REPL)}\nPATTERNS = {\n    'RE_LINEBREAK': (RE_LINEBREAK, ' '),\n    'RE_SINGLE_QUOTE': (RE_SINGLE_QUOTE, '\\u0027'),\n    'RE_DOUBLE_QUOTE': (RE_DOUBLE_QUOTE, '\\u0022'),\n    'RE_CURRENCY_SYMBOL': (RE_CURRENCY_SYMBOL,'_CUR_ '),\n    'RE_NUMBER': (RE_NUMBER, ' _NUM_'),\n    'RE_HYPHEN': (RE_HYPHEN, ' '),\n    'RE_PUNCT': (RE_PUNCT, ''),\n    'RE_SPACES': (RE_SPACES, ' ')\n}","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:01.173648Z","iopub.execute_input":"2021-07-26T01:04:01.174021Z","iopub.status.idle":"2021-07-26T01:04:01.179674Z","shell.execute_reply.started":"2021-07-26T01:04:01.173989Z","shell.execute_reply":"2021-07-26T01:04:01.178643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impurity(text, patterns):\n    to_clean = []\n    for _, pattern in patterns.items():\n        to_clean.append(len(pattern[0].findall(text)))\n    contr_len = sum([len(i) for i in RE_CONTRACTIONS.findall(text)])    \n    to_clean.append(contr_len)\n    return sum(to_clean) / len(text)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:04.245136Z","iopub.execute_input":"2021-07-26T01:04:04.24567Z","iopub.status.idle":"2021-07-26T01:04:04.253442Z","shell.execute_reply.started":"2021-07-26T01:04:04.245636Z","shell.execute_reply":"2021-07-26T01:04:04.252315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check impurity before the cleaning\ntrain_df['impurity'] = train_df['excerpt'].apply(lambda x: impurity(x, PATTERNS))\ntrain_df[['excerpt', 'impurity']].sort_values(by='impurity', ascending=False).head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:06.651864Z","iopub.execute_input":"2021-07-26T01:04:06.652274Z","iopub.status.idle":"2021-07-26T01:04:08.231215Z","shell.execute_reply.started":"2021-07-26T01:04:06.652227Z","shell.execute_reply":"2021-07-26T01:04:08.230053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impurity_summary(df):\n    n_impure = df.loc[df.impurity > 0].shape[0]\n    impure_percent = np.round((n_impure * 100 / df.shape[0]), 2)\n    mean_impurity = np.round(df.impurity.mean() * 100, 2)\n    print(f'Total number of impure excerpts in train dataset is: {n_impure} or {impure_percent}%')\n    print(f'Mean impurity: {mean_impurity}%')\n    \nimpurity_summary(train_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:21.689544Z","iopub.execute_input":"2021-07-26T01:04:21.689894Z","iopub.status.idle":"2021-07-26T01:04:21.699647Z","shell.execute_reply.started":"2021-07-26T01:04:21.689864Z","shell.execute_reply":"2021-07-26T01:04:21.698366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_accents(text):\n    return \"\".join(\n        char for char in unicodedata.normalize(\"NFKD\", text) \n        if not unicodedata.combining(char)\n    )","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:24.339612Z","iopub.execute_input":"2021-07-26T01:04:24.339959Z","iopub.status.idle":"2021-07-26T01:04:24.346257Z","shell.execute_reply.started":"2021-07-26T01:04:24.339929Z","shell.execute_reply":"2021-07-26T01:04:24.345343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean(text, patterns):\n    text = html.unescape(text)\n    text = remove_accents(text)\n    for name, (pattern, repl) in patterns.items():\n        if name == 'RE_PUNCT':\n            text = contractions.fix(text)\n            text = RE_PUNCT.sub('', text)\n            continue\n        else:\n            text = pattern.sub(repl, text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:31.776617Z","iopub.execute_input":"2021-07-26T01:04:31.77707Z","iopub.status.idle":"2021-07-26T01:04:31.784008Z","shell.execute_reply.started":"2021-07-26T01:04:31.777032Z","shell.execute_reply":"2021-07-26T01:04:31.782863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['clean_text'] = train_df['excerpt'].apply(lambda x: clean(x, PATTERNS))","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:37.394733Z","iopub.execute_input":"2021-07-26T01:04:37.395165Z","iopub.status.idle":"2021-07-26T01:04:39.525225Z","shell.execute_reply.started":"2021-07-26T01:04:37.39513Z","shell.execute_reply":"2021-07-26T01:04:39.523684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Check impurity after the cleaning\ntrain_df['impurity'] = train_df['clean_text'].apply(lambda x: impurity(x, PATTERNS))\ntrain_df[['clean_text', 'impurity']].sort_values(by='impurity', ascending=False).head()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:41.906396Z","iopub.execute_input":"2021-07-26T01:04:41.90681Z","iopub.status.idle":"2021-07-26T01:04:43.470835Z","shell.execute_reply.started":"2021-07-26T01:04:41.906775Z","shell.execute_reply":"2021-07-26T01:04:43.469475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impurity_summary(train_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T01:04:47.245306Z","iopub.execute_input":"2021-07-26T01:04:47.245711Z","iopub.status.idle":"2021-07-26T01:04:47.254591Z","shell.execute_reply.started":"2021-07-26T01:04:47.245675Z","shell.execute_reply":"2021-07-26T01:04:47.253065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Summary\n\n---\n\nIn general, we can say that the text is initially quite clean. According to the current scoring function, the mean impurity across the training dataset was only 1.59%. But even this can influence the model performance and provide a better LB score. Feel free to fork, modify and improve the solution to suit your needs, and don't forget to upvote if you like it))","metadata":{}}]}