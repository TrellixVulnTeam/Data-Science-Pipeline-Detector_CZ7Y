{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#defaul libraries\n#https://docs.python.org/ja/\nimport os\nimport math\nimport random\nimport pprint\nimport time\nimport typing\nimport json\nimport glob\nimport warnings\nimport gc\n\nimport numpy as np #https://numpy.org/\nimport pandas as pd #https://pandas.pydata.org/\nimport sklearn #https://scikit-learn.org/stable/\n\nimport matplotlib.pyplot as plt #https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.html\n%matplotlib inline\nfrom tqdm import tqdm #https://tqdm.github.io/\n\nimport torch #https://pytorch.org/\nimport transformers #https://huggingface.co/transformers/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-18T08:53:47.987901Z","iopub.execute_input":"2021-07-18T08:53:47.9884Z","iopub.status.idle":"2021-07-18T08:53:47.999154Z","shell.execute_reply.started":"2021-07-18T08:53:47.988357Z","shell.execute_reply":"2021-07-18T08:53:47.997656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/getting-started/140636\n\nimport torch\nfrom numba import cuda\n\n# !pip install GPUtil\n# from GPUtil import showUtilization as gpu_usage\n\ndef free_gpu_cache():\n#     print(\"Initial GPU Usage\")\n#     gpu_usage()                             \n\n    torch.cuda.empty_cache()\n\n#     cuda.select_device(0)\n#     cuda.close()\n#     cuda.select_device(0)\n\n#     print(\"GPU Usage after emptying the cache\")\n#     gpu_usage()\n\n#free_gpu_cache()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.001082Z","iopub.execute_input":"2021-07-18T08:53:48.001643Z","iopub.status.idle":"2021-07-18T08:53:48.009329Z","shell.execute_reply.started":"2021-07-18T08:53:48.001605Z","shell.execute_reply":"2021-07-18T08:53:48.008511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG():\n    \n    input_path=\"../input/commonlitreadabilityprize\"\n    debug=False\n    seed=3\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n    batch_size=16\n    epochs=10\n    learning_rate=2e-5\n    kFold=5\n\n    #高速化関連\n    #https://qiita.com/sugulu_Ogawa_ISID/items/62f5f7adee083d96a587\n\n    #GPU 遅くなるらしい↓\n    torch.backends.cudnn.deterministic = True\n\n    #イテレーションごとのnnの順伝搬および誤差関数の 計算手法がある程度一定であれば、torch.backends.cudnn.benchmark = Trueで GPU での計算が高速化\n    torch.backends.cudnn.benchmark = False\n\n\ndef set_seed(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    #tf.random.set_seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nset_seed(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.011582Z","iopub.execute_input":"2021-07-18T08:53:48.012043Z","iopub.status.idle":"2021-07-18T08:53:48.021921Z","shell.execute_reply.started":"2021-07-18T08:53:48.01201Z","shell.execute_reply":"2021-07-18T08:53:48.021166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def color(string,fg='DEFAULT',bg='DEFAULT',fg_rgb=None,bg_rgb=None,style='END'):\n    colors=['BLACK','RED','GREEN','YELLOW','BLUE','PURPLE','CYAN','WHITE','8','DEFAULT']\n    styles=['END','BOLD','2','3','UNDERLINE','5','6','REVERSE','INVISIBLE','9']\n\n    fg=f'\\033[3{colors.index(fg)}m'\n    bg=f'\\033[4{colors.index(bg)}m'\n    style=f'\\033[0{styles.index(style)}m'\n\n    if fg_rgb:fg=f\"\\033[38;2;{fg_rgb[0]};{fg_rgb[1]};{fg_rgb[2]}m\"\n    if bg_rgb:bg=f\"\\033[48;2;{bg_rgb[0]};{bg_rgb[1]};{bg_rgb[2]}m\"\n\n    return style+fg+bg+str(string)+'\\033[0m'","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.023389Z","iopub.execute_input":"2021-07-18T08:53:48.023887Z","iopub.status.idle":"2021-07-18T08:53:48.032305Z","shell.execute_reply.started":"2021-07-18T08:53:48.023831Z","shell.execute_reply":"2021-07-18T08:53:48.031527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(os.path.join(CFG.input_path,\"train.csv\"),index_col='id',usecols=['id','excerpt', 'target'])\ntest=pd.read_csv(os.path.join(CFG.input_path,\"test.csv\"),index_col='id',usecols=['id','excerpt'])\nsample_submission=pd.read_csv(os.path.join(CFG.input_path,\"sample_submission.csv\"),index_col='id')\n\nif CFG.debug:train=train[:len(train)//30]\n\ntest['target']=0\n\ndf=pd.concat([train,test])","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.033497Z","iopub.execute_input":"2021-07-18T08:53:48.033898Z","iopub.status.idle":"2021-07-18T08:53:48.084587Z","shell.execute_reply.started":"2021-07-18T08:53:48.033802Z","shell.execute_reply":"2021-07-18T08:53:48.083831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.085718Z","iopub.execute_input":"2021-07-18T08:53:48.086066Z","iopub.status.idle":"2021-07-18T08:53:48.101324Z","shell.execute_reply.started":"2021-07-18T08:53:48.086032Z","shell.execute_reply":"2021-07-18T08:53:48.100093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=transformers.RobertaTokenizer.from_pretrained(\"../input/clrp-roberta-base/clrp_roberta_base\")","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.10305Z","iopub.execute_input":"2021-07-18T08:53:48.103536Z","iopub.status.idle":"2021-07-18T08:53:48.192774Z","shell.execute_reply.started":"2021-07-18T08:53:48.103496Z","shell.execute_reply":"2021-07-18T08:53:48.191951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['token_len']=df.excerpt.apply(tokenizer.encode).apply(len)\n#df['token_len_']=df.excerpt.str.split().apply(len)\n\nmax_len=max(df['token_len'])\nmax_len","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.195972Z","iopub.execute_input":"2021-07-18T08:53:48.196233Z","iopub.status.idle":"2021-07-18T08:53:48.466502Z","shell.execute_reply.started":"2021-07-18T08:53:48.196205Z","shell.execute_reply":"2021-07-18T08:53:48.465766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=df[:len(train)].copy()\ntest=df[len(train):].copy()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.468047Z","iopub.execute_input":"2021-07-18T08:53:48.468297Z","iopub.status.idle":"2021-07-18T08:53:48.473836Z","shell.execute_reply.started":"2021-07-18T08:53:48.468272Z","shell.execute_reply":"2021-07-18T08:53:48.472718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.475489Z","iopub.execute_input":"2021-07-18T08:53:48.475863Z","iopub.status.idle":"2021-07-18T08:53:48.494554Z","shell.execute_reply.started":"2021-07-18T08:53:48.4758Z","shell.execute_reply":"2021-07-18T08:53:48.493786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.495791Z","iopub.execute_input":"2021-07-18T08:53:48.496182Z","iopub.status.idle":"2021-07-18T08:53:48.507656Z","shell.execute_reply.started":"2021-07-18T08:53:48.496146Z","shell.execute_reply":"2021-07-18T08:53:48.506464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommonLit_DataSet(torch.utils.data.Dataset):\n    def __init__(self,sentences,targets):\n        self.sentences=sentences\n        self.targets=targets\n\n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self,idx):\n        \n        enc=tokenizer(\n            self.sentences[idx].replace('\\n', ''),\n            add_special_tokens=True,\n            return_attention_mask=True,\n            padding='max_length',\n            max_length=max_len,\n        )\n        return {\n            'ids':torch.tensor(enc['input_ids'],dtype=torch.long),\n            'mask':torch.tensor(enc['attention_mask'],dtype=torch.long),\n            #'token_type_ids':torch.tensor(enc['token_type_ids'],dtype=torch.long),\n            'targets':torch.tensor(self.targets[idx],dtype=torch.float)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.509456Z","iopub.execute_input":"2021-07-18T08:53:48.509928Z","iopub.status.idle":"2021-07-18T08:53:48.519095Z","shell.execute_reply.started":"2021-07-18T08:53:48.509821Z","shell.execute_reply":"2021-07-18T08:53:48.517933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(torch.nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.mse = torch.nn.MSELoss()\n        self.eps = eps\n        \n    def forward(self,yhat,y):\n        loss = torch.sqrt(self.mse(yhat,y) + self.eps)\n        return loss\n    \nloss_fun=RMSELoss()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.520654Z","iopub.execute_input":"2021-07-18T08:53:48.521075Z","iopub.status.idle":"2021-07-18T08:53:48.529461Z","shell.execute_reply.started":"2021-07-18T08:53:48.521037Z","shell.execute_reply":"2021-07-18T08:53:48.528616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#とりあえず学習できるように\ndef train_val_test(model,dataloader,phase,optimizer=None,scheduler=None,scaler=None):# モデルを学習させる関数\n    \n    #assert((phase=='train')==bool(optimizer))#学習時にoptimizer必須\n    \n    model.train() if phase=='train' else model.eval()   # モデルのモード\n    model.to(CFG.device)\n    \n    preds=[]\n    losses=[]\n    \n    # データローダーからミニバッチを取り出すループ\n    for enc in dataloader[phase]:\n        \n        # optimizerを初期化\n        if phase=='train':optimizer.zero_grad()\n       \n        # 順伝搬（forward）計算\n        with torch.set_grad_enabled(phase=='train'):\n            \n            # non_blocking=TrueでPinned MemoryからGPUに転送中もCPUが動作できるらしい。\n            ids = enc[\"ids\"].to(CFG.device,non_blocking=True) \n            mask = enc[\"mask\"].to(CFG.device,non_blocking=True)\n            \n            with torch.cuda.amp.autocast():\n                outputs = model(ids,mask)[\"logits\"].squeeze(-1)\n\n                if phase!='test':\n                    loss_val = loss_fun(outputs, enc[\"targets\"].to(CFG.device,non_blocking=True))  # 損失を計算\n                    losses.append(loss_val.item())\n\n                    # 訓練時はバックプロパゲーション\n                    if phase == 'train':\n    #                     loss_val.backward()\n    #                     optimizer.step()\n                        scaler.scale(loss_val).backward() # ロスのバックワード\n                        scaler.step(optimizer) # オプティマイザーの更新\n                        scaler.update() # スケーラーの更新\n                    \n                        scheduler.step() # 学習率の更新 ここに入れるべき？　まだ使わない\n\n        preds.extend(outputs.detach().cpu().numpy())\n\n#         del ids,mask#####,outputs\n#         if phase!='test':del loss_val\n#         torch.cuda.empty_cache()\n        gc.collect()\n    \n    #if phase!='test':return preds,np.mean(losses)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.530649Z","iopub.execute_input":"2021-07-18T08:53:48.531323Z","iopub.status.idle":"2021-07-18T08:53:48.543278Z","shell.execute_reply.started":"2021-07-18T08:53:48.531283Z","shell.execute_reply":"2021-07-18T08:53:48.542304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/chumajin/bert-v-s-roberta-english\n\nfrom sklearn.model_selection import KFold\nfrom transformers import get_linear_schedule_with_warmup\n\n\ndef initialize(seed,fold):\n    \n    set_seed(seed)\n    \n    kf=KFold(n_splits=CFG.kFold,shuffle=True,random_state=CFG.seed)\n    train_index, valid_index = list(kf.split(train))[fold]\n\n    dataset={\n        'train':CommonLit_DataSet(train.iloc[train_index].excerpt, train.iloc[train_index].target),\n        'valid':CommonLit_DataSet(train.iloc[valid_index].excerpt, train.iloc[valid_index].target),\n        'test':CommonLit_DataSet(test.excerpt,test.target),\n    }\n    \n    dataloader={\n        'train':\n        torch.utils.data.DataLoader(\n            dataset['train'],\n            batch_size=CFG.batch_size,\n            shuffle=True,\n            num_workers=2,#os.cpu_count(),\n            pin_memory=True\n        ),\n        'valid':\n        torch.utils.data.DataLoader(\n            dataset['valid'],\n            batch_size=CFG.batch_size,\n            shuffle=False,\n            num_workers=2,#os.cpu_count(),\n            pin_memory=True\n        ),\n        'test':\n        torch.utils.data.DataLoader(\n            dataset['test'],\n            batch_size=CFG.batch_size,\n            shuffle=False,\n            num_workers=2,#os.cpu_count(),\n            pin_memory=True\n        )\n    }\n    \n    model = transformers.RobertaForSequenceClassification.from_pretrained(\"../input/clrp-roberta-base/clrp_roberta_base\",num_labels=1)\n    optimizer = transformers.AdamW(model.parameters(), CFG.learning_rate,betas=(0.9, 0.999), weight_decay=1e-2) # AdamW optimizer\n    \n    train_steps = int(len(train)/CFG.batch_size*CFG.epochs)\n    scheduler = get_linear_schedule_with_warmup(optimizer, int(train_steps*0.1), train_steps)\n    \n    scaler = torch.cuda.amp.GradScaler() # GPUでの高速化。\n    \n    return dataset,dataloader,model,optimizer,scheduler,scaler\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.544541Z","iopub.execute_input":"2021-07-18T08:53:48.544934Z","iopub.status.idle":"2021-07-18T08:53:48.559782Z","shell.execute_reply.started":"2021-07-18T08:53:48.544897Z","shell.execute_reply":"2021-07-18T08:53:48.558986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_validation():\n\n    for fold in range(CFG.kFold):\n        print('fold',fold)\n        losses={\n            'train':[],\n            'valid':[]\n        }\n    \n        dataset,dataloader,model,optimizer,scheduler,scaler=initialize(CFG.seed,fold)\n        bestscore=100\n\n        for epoch in range(CFG.epochs):\n            print(\"epoch=\",epoch)\n\n            preds=train_val_test(model,dataloader,'train',optimizer,scheduler,scaler)\n            plt.scatter(dataset['train'].targets,preds,color='blue',s=5)\n            \n            loss=np.sqrt(sklearn.metrics.mean_squared_error(preds,list(dataset['train'].targets)))\n            print(color(\"train\",bg=\"BLUE\",style='BOLD')+':'+color(f\"{loss}\",\"BLUE\"))\n            losses['train'].append(loss)\n\n            preds=train_val_test(model,dataloader,'valid')\n            plt.scatter(dataset['valid'].targets,preds,color='red',s=5)\n            \n            \n            loss=np.sqrt(sklearn.metrics.mean_squared_error(preds,list(dataset['valid'].targets)))\n            print(color(\"val  \",bg=\"RED\",style='BOLD')+':'+color(f\"{loss}\",\"RED\"))\n            losses['valid'].append(loss)\n            \n            if bestscore > loss:\n                bestscore = loss\n                print(color(\"BEST SCORE\",bg='YELLOW')+' :',color(bestscore,'YELLOW'))\n                \n                torch.save(\n                    {\n                        'state_dict': model.state_dict(),\n                        'optimizer_dict': optimizer.state_dict(),\n                        'bestscore':bestscore,\n                        'seed':CFG.seed\n                    },\n                    \"Roberta_fold\"+str(fold)+\".pth\"\n                )\n            #print(preds)\n            \n            plt.plot([i/10 for i in range(-40,20,1)],[i/10 for i in range(-40,20,1)],linestyle='dashed',color='green')\n            plt.show()\n            \n        plt.plot(losses['train'],color='blue')\n        plt.plot(losses['valid'],color='red')\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.561273Z","iopub.execute_input":"2021-07-18T08:53:48.561726Z","iopub.status.idle":"2021-07-18T08:53:48.577282Z","shell.execute_reply.started":"2021-07-18T08:53:48.56169Z","shell.execute_reply":"2021-07-18T08:53:48.576172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ncross_validation()","metadata":{"execution":{"iopub.status.busy":"2021-07-18T08:53:48.578879Z","iopub.execute_input":"2021-07-18T08:53:48.579275Z","iopub.status.idle":"2021-07-18T09:05:28.848091Z","shell.execute_reply.started":"2021-07-18T08:53:48.5792Z","shell.execute_reply":"2021-07-18T09:05:28.847123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_models=[\"Roberta_fold0.pth\",\"Roberta_fold1.pth\",\"Roberta_fold2.pth\",\"Roberta_fold3.pth\",\"Roberta_fold4.pth\"]\n\npreds=pd.DataFrame(columns=best_models)\npreds['id']=test.index\npreds=preds.set_index('id')\n\npreds\n\nfor pth in best_models:\n    \n    \n    model = transformers.RobertaForSequenceClassification.from_pretrained(\"../input/clrp-roberta-base/clrp_roberta_base\",num_labels=1)\n    model.load_state_dict(torch.load(pth)[\"state_dict\"])\n    \n    score=torch.load(pth)[\"bestscore\"]\n    \n#     if score>0.54:\n#         preds.drop(pth, axis=1)\n#         continue\n        \n    print(score)\n\n    \n    dataloader={'test':torch.utils.data.DataLoader(\n            CommonLit_DataSet(test.excerpt,test.target),\n            batch_size=CFG.batch_size,\n            shuffle=False,\n            num_workers=2,#os.cpu_count(),\n            pin_memory=True\n    )}\n    \n    preds[pth]=train_val_test(model,dataloader,'test')","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:05:28.849907Z","iopub.execute_input":"2021-07-18T09:05:28.850542Z","iopub.status.idle":"2021-07-18T09:07:26.362647Z","shell.execute_reply.started":"2021-07-18T09:05:28.850498Z","shell.execute_reply":"2021-07-18T09:07:26.361617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:07:26.365103Z","iopub.execute_input":"2021-07-18T09:07:26.365458Z","iopub.status.idle":"2021-07-18T09:07:26.382528Z","shell.execute_reply.started":"2021-07-18T09:07:26.365411Z","shell.execute_reply":"2021-07-18T09:07:26.38174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.DataFrame(columns=['target'])\nsubmission['id']=test.index\nsubmission=submission.set_index('id')\nsubmission.target=preds.mean(axis=1)\nsubmission","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:07:26.3837Z","iopub.execute_input":"2021-07-18T09:07:26.38426Z","iopub.status.idle":"2021-07-18T09:07:26.412404Z","shell.execute_reply.started":"2021-07-18T09:07:26.384222Z","shell.execute_reply":"2021-07-18T09:07:26.411346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=id)","metadata":{"execution":{"iopub.status.busy":"2021-07-18T09:07:26.413635Z","iopub.execute_input":"2021-07-18T09:07:26.41412Z","iopub.status.idle":"2021-07-18T09:07:26.437084Z","shell.execute_reply.started":"2021-07-18T09:07:26.414083Z","shell.execute_reply":"2021-07-18T09:07:26.436208Z"},"trusted":true},"execution_count":null,"outputs":[]}]}