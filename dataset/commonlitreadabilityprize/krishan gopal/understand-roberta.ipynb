{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random, os, warnings, math\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.backend as K\nfrom tensorflow.keras import optimizers, losses, metrics, Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom transformers import TFAutoModelForSequenceClassification, TFAutoModel, AutoTokenizer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-19T06:22:59.921887Z","iopub.execute_input":"2021-06-19T06:22:59.922251Z","iopub.status.idle":"2021-06-19T06:23:07.573542Z","shell.execute_reply.started":"2021-06-19T06:22:59.922175Z","shell.execute_reply":"2021-06-19T06:23:07.572712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Implementation","metadata":{}},{"cell_type":"code","source":"PATH = '../input/commonlitreadabilityprize/'\n#BASE_MODEL = '../input/huggingface-bert/bert-base-uncased/'\n","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:23:22.576596Z","iopub.execute_input":"2021-06-19T06:23:22.576957Z","iopub.status.idle":"2021-06-19T06:23:22.581339Z","shell.execute_reply.started":"2021-06-19T06:23:22.57691Z","shell.execute_reply":"2021-06-19T06:23:22.580306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_SEQUENCE_LENGTH = 512\n\ndf_train = pd.read_csv(PATH+'train.csv')\ndf_test = pd.read_csv(PATH+'test.csv')\ndf_sub = pd.read_csv(PATH+'sample_submission.csv')\nprint('train shape =', df_train.shape)\nprint('test shape =', df_test.shape)\n\noutput_categories = df_train['target']\ninput_categories =df_train['excerpt']\nprint('\\noutput categories:\\n\\t', output_categories)\nprint('\\ninput categories:\\n\\t', input_categories)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:23:24.399794Z","iopub.execute_input":"2021-06-19T06:23:24.400163Z","iopub.status.idle":"2021-06-19T06:23:24.528118Z","shell.execute_reply.started":"2021-06-19T06:23:24.40013Z","shell.execute_reply":"2021-06-19T06:23:24.527125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fix_length(tokens, max_sequence_length=512):\n    length = len(tokens)\n    if length > max_sequence_length:\n        tokens = tokens[:max_sequence_length-1]\n    return tokens\n\n# function for tokenizing the input data for transformer.\ndef transformer_inputs(text,tokenizer,MAX_SEQUENCE_LENGTH = 512):\n\n    text_tokens = tokenizer.tokenize(str(text))\n    text_tokens = fix_length(text_tokens)\n    ids_q = tokenizer.convert_tokens_to_ids([\"[CLS]\"] + text_tokens)\n    padded_ids = (ids_q + [tokenizer.pad_token_id] * (MAX_SEQUENCE_LENGTH - len(ids_q)))[:MAX_SEQUENCE_LENGTH]\n    #token_type_ids = ([0] * MAX_SEQUENCE_LENGTH)[:MAX_SEQUENCE_LENGTH]\n    attention_mask = ([1] * len(ids_q) + [0] * (MAX_SEQUENCE_LENGTH - len(ids_q)))[:MAX_SEQUENCE_LENGTH]\n\n    return padded_ids,attention_mask\n\n# function for creating the input_ids, masks and segments for the bert input\ndef input_for_model(df, tokenizer):\n    print(f'generating input for transformer...')\n    input_ids,input_attention_masks = [], []\n    for text in df['excerpt'].values:\n        ids, mask = transformer_inputs(text,tokenizer)\n        input_ids.append(ids)\n        input_attention_masks.append(mask)\n    \n    return (\n        np.asarray(input_ids, dtype=np.int32),\n        np.asarray(input_attention_masks, dtype=np.int32))\n\ndef compute_output_arrays(df, columns):\n    return np.asarray(df[columns])","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:28:32.796853Z","iopub.execute_input":"2021-06-19T06:28:32.797215Z","iopub.status.idle":"2021-06-19T06:28:32.806009Z","shell.execute_reply.started":"2021-06-19T06:28:32.797183Z","shell.execute_reply":"2021-06-19T06:28:32.804944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_fn(encoder, seq_len):\n    input_ids = L.Input(shape=(seq_len,), dtype=tf.int32, name='input_ids')\n    input_attention_mask = L.Input(shape=(seq_len,), dtype=tf.int32, name='attention_mask')\n    \n    outputs = encoder({'input_ids': input_ids, \n                       'attention_mask': input_attention_mask})\n    \n    model = Model(inputs=[input_ids, input_attention_mask], outputs=outputs)\n\n    optimizer = optimizers.Adam(lr=LEARNING_RATE)\n    model.compile(optimizer=optimizer, \n                  loss=losses.MeanSquaredError(), \n                  metrics=[metrics.RootMeanSquaredError()])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:24:04.06474Z","iopub.execute_input":"2021-06-19T06:24:04.065072Z","iopub.status.idle":"2021-06-19T06:24:04.071163Z","shell.execute_reply.started":"2021-06-19T06:24:04.06504Z","shell.execute_reply":"2021-06-19T06:24:04.070108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 8 \nLEARNING_RATE = 1e-5 \nEPOCHS = 35\nES_PATIENCE = 7\nPATIENCE = 2\nN_FOLDS = 5\nSEQ_LEN = 512 #300\nBASE_MODEL = '/kaggle/input/huggingface-roberta/roberta-base/'\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:28:42.324208Z","iopub.execute_input":"2021-06-19T06:28:42.32456Z","iopub.status.idle":"2021-06-19T06:28:42.411251Z","shell.execute_reply.started":"2021-06-19T06:28:42.324518Z","shell.execute_reply":"2021-06-19T06:28:42.410332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = TFAutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)\nmodel = model_fn(encoder, 512)\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-18T19:50:27.980326Z","iopub.execute_input":"2021-06-18T19:50:27.980593Z","iopub.status.idle":"2021-06-18T19:50:48.236299Z","shell.execute_reply.started":"2021-06-18T19:50:27.980567Z","shell.execute_reply":"2021-06-18T19:50:48.235507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#gkf = GroupKFold(n_splits=5).split(X=df_train.excerpt, groups=df_train.excerpt)\nimport tqdm\ninputs=input_for_model(df_train,tokenizer)\ntest_inputs=input_for_model(df_test,tokenizer)\noutputs=compute_output_arrays(df_train,'target')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:28:34.684753Z","iopub.execute_input":"2021-06-19T06:28:34.685094Z","iopub.status.idle":"2021-06-19T06:28:37.898442Z","shell.execute_reply.started":"2021-06-19T06:28:34.685061Z","shell.execute_reply":"2021-06-19T06:28:37.897489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=42\nskf = KFold(n_splits=N_FOLDS, shuffle=True, random_state=seed)\nvalid_preds = [];\nvalid_labels = [];\nhistory_list = [];\ntest_preds = []\n\n\nfor fold,(train_idx,valid_idx) in enumerate(skf.split(df_train)):\n    print(f'\\nFOLD: {fold+1}')\n    print(f'TRAIN: {len(train_idx)} VALID: {len(valid_idx)}')\n    # Model\n    K.clear_session()\n\n    encoder = TFAutoModelForSequenceClassification.from_pretrained(BASE_MODEL, num_labels=1)\n    model = model_fn(encoder, SEQ_LEN)\n        \n    model_path = f'model_{fold}.h5'\n    \n    es = EarlyStopping(monitor='val_root_mean_squared_error', mode='min', \n                       patience=ES_PATIENCE, restore_best_weights=True, verbose=1)\n    checkpoint = ModelCheckpoint(model_path, monitor='val_root_mean_squared_error', mode='min', \n                                 save_best_only=True, save_weights_only=True)\n    train_inputs=[inputs[i][train_idx] for i in range(2)]\n    train_outputs=outputs[train_idx].reshape((-1,1)).flatten()\n\n    valid_inputs = [inputs[i][valid_idx] for i in range(2)]\n    valid_outputs = outputs[valid_idx].reshape((-1,1)).flatten()\n    valid_labels.append(valid_outputs)\n   \n    \n    history = model.fit(train_inputs, train_outputs, batch_size=8,\n                validation_data=(valid_inputs, valid_outputs), \n                    steps_per_epoch=50, \n                    callbacks=[es, checkpoint], \n                    epochs=35,  \n                    verbose=2).history\n    history_list.append(history)\n    # Save last model weights\n    model.load_weights(model_path)\n    \n    # Results\n    print(f\"#### FOLD {fold+1} OOF RMSE = {np.min(history['val_root_mean_squared_error']):.4f}\")\n\n    \n    \n    valid_preds.append(model.predict(valid_inputs)['logits'])\n    test_preds.append(model.predict(test_inputs)['logits'])\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-19T06:29:02.651836Z","iopub.execute_input":"2021-06-19T06:29:02.652192Z","iopub.status.idle":"2021-06-19T07:33:40.427967Z","shell.execute_reply.started":"2021-06-19T06:29:02.65216Z","shell.execute_reply":"2021-06-19T07:33:40.426838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_metrics(history):\n    metric_list = list(history.keys())\n    size = len(metric_list)//2\n    fig, axes = plt.subplots(size, 1, sharex='col', figsize=(20, size * 5))\n    axes = axes.flatten()\n    \n    for index in range(len(metric_list)//2):\n        metric_name = metric_list[index]\n        val_metric_name = metric_list[index+size]\n        axes[index].plot(history[metric_name], label='Train %s' % metric_name)\n        axes[index].plot(history[val_metric_name], label='Validation %s' % metric_name)\n        axes[index].legend(loc='best', fontsize=16)\n        axes[index].set_title(metric_name)\n\n    plt.xlabel('Epochs', fontsize=16)\n    sns.despine()\n    plt.show()\n\n\nfor fold, history in enumerate(history_list):\n    print(f'\\nFOLD: {fold+1}')\n    plot_metrics(history)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:50:47.06881Z","iopub.execute_input":"2021-06-19T07:50:47.069221Z","iopub.status.idle":"2021-06-19T07:50:48.680857Z","shell.execute_reply.started":"2021-06-19T07:50:47.069184Z","shell.execute_reply":"2021-06-19T07:50:48.680062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_true = np.concatenate(valid_labels)\ny_preds = np.concatenate(valid_preds)\n\n\nfor fold, history in enumerate(history_list):\n    print(f\"FOLD {fold+1} RMSE: {np.min(history['val_root_mean_squared_error']):.4f}\")\n    \nprint(f'OOF RMSE: {mean_squared_error(y_true, y_preds, squared=False):.4f}')","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:50:52.448143Z","iopub.execute_input":"2021-06-19T07:50:52.448522Z","iopub.status.idle":"2021-06-19T07:50:52.456277Z","shell.execute_reply.started":"2021-06-19T07:50:52.448491Z","shell.execute_reply":"2021-06-19T07:50:52.455283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission","metadata":{}},{"cell_type":"code","source":"submission = df_test[['id']]\ndf_sub['target'] = np.mean(test_preds, axis=0)\ndf_sub.to_csv('submission.csv', index=False)\ndisplay(df_sub.head(10))","metadata":{"execution":{"iopub.status.busy":"2021-06-19T07:50:55.447668Z","iopub.execute_input":"2021-06-19T07:50:55.448004Z","iopub.status.idle":"2021-06-19T07:50:55.732496Z","shell.execute_reply.started":"2021-06-19T07:50:55.44796Z","shell.execute_reply":"2021-06-19T07:50:55.731504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}