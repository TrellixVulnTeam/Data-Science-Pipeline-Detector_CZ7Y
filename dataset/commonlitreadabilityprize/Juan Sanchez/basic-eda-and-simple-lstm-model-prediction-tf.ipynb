{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport random\nimport nltk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras import layers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T03:13:52.510678Z","iopub.execute_input":"2021-05-31T03:13:52.511043Z","iopub.status.idle":"2021-05-31T03:13:52.515618Z","shell.execute_reply.started":"2021-05-31T03:13:52.511012Z","shell.execute_reply":"2021-05-31T03:13:52.514581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def master_seed(seed):\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n\nmaster_seed(31416)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:52.517097Z","iopub.execute_input":"2021-05-31T03:13:52.517583Z","iopub.status.idle":"2021-05-31T03:13:52.54245Z","shell.execute_reply.started":"2021-05-31T03:13:52.517545Z","shell.execute_reply":"2021-05-31T03:13:52.541654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntrain_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:52.54548Z","iopub.execute_input":"2021-05-31T03:13:52.54586Z","iopub.status.idle":"2021-05-31T03:13:52.592688Z","shell.execute_reply.started":"2021-05-31T03:13:52.545824Z","shell.execute_reply":"2021-05-31T03:13:52.591626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:52.594461Z","iopub.execute_input":"2021-05-31T03:13:52.594853Z","iopub.status.idle":"2021-05-31T03:13:52.614342Z","shell.execute_reply.started":"2021-05-31T03:13:52.594817Z","shell.execute_reply":"2021-05-31T03:13:52.613324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print sample text along with target variable \n\nfor i in range(20):\n    \n    print(train_df.iloc[i,3], train_df.iloc[i,4], '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:52.615812Z","iopub.execute_input":"2021-05-31T03:13:52.616217Z","iopub.status.idle":"2021-05-31T03:13:52.636369Z","shell.execute_reply.started":"2021-05-31T03:13:52.616184Z","shell.execute_reply":"2021-05-31T03:13:52.629342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#comparing the most comple excerpt and the simplest one\n#Bigger values on the target column are related to easier readability\nmostcomplex_index = train_df['target'].idxmin()\nsimplest_index = train_df['target'].idxmax()\n\nprint('The simplest excerpt:\\n')\nprint(train_df.iloc[simplest_index,3], '\\n')\nprint('With a target value of: {}'.format(train_df.iloc[simplest_index,4]), '\\n')\n\nprint('The most complex excerpt:\\n')\nprint(train_df.iloc[mostcomplex_index,3], '\\n')\nprint('With a target value of: {}'.format(train_df.iloc[mostcomplex_index,4]), '\\n')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:52.637536Z","iopub.execute_input":"2021-05-31T03:13:52.63793Z","iopub.status.idle":"2021-05-31T03:13:52.648166Z","shell.execute_reply.started":"2021-05-31T03:13:52.637884Z","shell.execute_reply":"2021-05-31T03:13:52.647114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def remove_small(word_list):\n    \n    _list = []\n    \n    for st in word_list:\n        \n        if len(st) > 3:\n            \n            _list.append(st)\n            \n    return _list\n\ndef tokenize(ser):\n    \n    full_tokens = []\n    cleaned_tokens = []\n    \n    for pr in ser:\n        \n        temp = nltk.word_tokenize(pr)\n        full_tokens.extend(temp)\n        cleaned_tokens.extend(remove_small(temp))\n        \n    return cleaned_tokens, full_tokens, set(full_tokens)    \n\ndef remove_stopwords(word_list):\n    \n    stop_words = set(nltk.corpus.stopwords.words('english'))\n    output = [w for w in word_list if w not in stop_words]\n    return output \n\ndef create_vectorizer(text_list, sequence_length, batch_size):\n    \n    vectorizer = tf.keras.layers.experimental.preprocessing.TextVectorization(max_tokens = 33000,\n                                                                    output_sequence_length = sequence_length)\n    text_array = np.array(text_list)\n    \n    text_ds = tf.data.Dataset.from_tensor_slices(text_array).batch(batch_size)\n    \n    vectorizer.adapt(text_ds)\n    \n    return vectorizer\n\n\ndef create_vector_mapping_dict(path_to_glove_file):\n\n    path_to_glove_file = path_to_glove_file\n\n    embeddings_index = {}\n    with open(path_to_glove_file) as f:\n        for line in f:\n            word, coefs = line.split(maxsplit=1)\n            coefs = np.fromstring(coefs, \"f\", sep=\" \")\n            embeddings_index[word] = coefs\n\n    print(\"Found %s word vectors.\" % len(embeddings_index))\n    \n    return embeddings_index\n\ndef create_embedding_matrix(len_voc, embedding_dim, word_index, embedding_index):\n\n    num_tokens = len_voc + 2\n    embedding_dim = embedding_dim\n    hits = 0\n    misses = 0\n\n    # Prepare embedding matrix\n    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n    for word, i in word_index.items():\n        embedding_vector = embedding_index.get(word)\n        if embedding_vector is not None:\n            # Words not found in embedding index will be all-zeros.\n            # This includes the representation for \"padding\" and \"OOV\"\n            embedding_matrix[i] = embedding_vector\n            hits += 1\n        else:\n            misses += 1\n    print(\"Converted %d words (%d misses)\" % (hits, misses))\n    \n    return embedding_matrix\n\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:52.651266Z","iopub.execute_input":"2021-05-31T03:13:52.651962Z","iopub.status.idle":"2021-05-31T03:13:52.666056Z","shell.execute_reply.started":"2021-05-31T03:13:52.651926Z","shell.execute_reply":"2021-05-31T03:13:52.665247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl, fll, unq = tokenize(train_df['excerpt'])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:52.668022Z","iopub.execute_input":"2021-05-31T03:13:52.668431Z","iopub.status.idle":"2021-05-31T03:13:58.179389Z","shell.execute_reply.started":"2021-05-31T03:13:52.668385Z","shell.execute_reply":"2021-05-31T03:13:58.178538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('The number of unique words is {}'.format(len(unq)))\nprint('The total number of words in all the texts is {}'.format(len(fll)))","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:58.180793Z","iopub.execute_input":"2021-05-31T03:13:58.181144Z","iopub.status.idle":"2021-05-31T03:13:58.186581Z","shell.execute_reply.started":"2021-05-31T03:13:58.181105Z","shell.execute_reply":"2021-05-31T03:13:58.185654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = plt.figure(figsize = (7,7))\nb = pd.Series(cl)\nb.value_counts().iloc[:20].plot(kind = 'barh')\nplt.title('Most Common Words with stop words')\nplt.xlabel('Occurences')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:58.187845Z","iopub.execute_input":"2021-05-31T03:13:58.188335Z","iopub.status.idle":"2021-05-31T03:13:58.549601Z","shell.execute_reply.started":"2021-05-31T03:13:58.188299Z","shell.execute_reply":"2021-05-31T03:13:58.548845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cl_stop = remove_stopwords(cl)\n_ = plt.figure(figsize = (7,7))\nb = pd.Series(cl_stop)\nb.value_counts().iloc[:20].plot(kind = 'barh')\nplt.title('Most Common Words without stop words')\nplt.xlabel('Occurences')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:58.551715Z","iopub.execute_input":"2021-05-31T03:13:58.552206Z","iopub.status.idle":"2021-05-31T03:13:58.874417Z","shell.execute_reply.started":"2021-05-31T03:13:58.552165Z","shell.execute_reply":"2021-05-31T03:13:58.873632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_ = plt.figure(figsize = (7,7))\nsns.histplot(train_df['target'])\nplt.title('Readibility Train data Histogram')\nplt.xlabel('Readibility')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:58.87568Z","iopub.execute_input":"2021-05-31T03:13:58.876047Z","iopub.status.idle":"2021-05-31T03:13:59.046352Z","shell.execute_reply.started":"2021-05-31T03:13:58.876011Z","shell.execute_reply":"2021-05-31T03:13:59.045382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# looking at the length of texts by words\n\nword_count = []\n\nfor para in train_df['excerpt']:\n    \n    word_count.append(len(nltk.word_tokenize(para)))\n    \n_ = plt.figure(figsize = (7,7))\nsns.histplot(word_count)\nplt.title('Word Count histogram')\nplt.xlabel('Number of words in Exerpt')","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:13:59.047781Z","iopub.execute_input":"2021-05-31T03:13:59.048134Z","iopub.status.idle":"2021-05-31T03:14:04.739561Z","shell.execute_reply.started":"2021-05-31T03:13:59.048098Z","shell.execute_reply":"2021-05-31T03:14:04.738652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vectorizer = create_vectorizer(train_df['excerpt'], 250, 128)\nvoc = vectorizer.get_vocabulary()\nword_index = dict(zip(voc, range(len(voc))))\nembedding_index = create_vector_mapping_dict('../input/glove6b/glove.6B.300d.txt')\nemb_matrix = create_embedding_matrix(len(voc), 300, word_index, embedding_index)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:14:04.74077Z","iopub.execute_input":"2021-05-31T03:14:04.741105Z","iopub.status.idle":"2021-05-31T03:14:34.246777Z","shell.execute_reply.started":"2021-05-31T03:14:04.741078Z","shell.execute_reply":"2021-05-31T03:14:34.24581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_dim = 300\nnum_tokens = len(voc) + 2\n\n\nembedding_layer = layers.Embedding(\n    num_tokens,\n    embedding_dim,\n    embeddings_initializer=tf.keras.initializers.Constant(emb_matrix),\n    trainable=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:14:34.248084Z","iopub.execute_input":"2021-05-31T03:14:34.248593Z","iopub.status.idle":"2021-05-31T03:14:34.254793Z","shell.execute_reply.started":"2021-05-31T03:14:34.248553Z","shell.execute_reply":"2021-05-31T03:14:34.253895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#defining the model \n\ninputs = tf.keras.Input(shape = (250,))\n\ninterm = embedding_layer(inputs)\ninterm = layers.LSTM(128, dropout = 0.2, recurrent_dropout = 0.2)(interm)\ninterm = layers.Dense(64, activation = 'relu')(interm)\ninterm = layers.Dense(32, activation = 'relu')(interm)\noutputs = layers.Dense(1, activation = 'linear')(interm)\n\nmodel = tf.keras.Model(inputs, outputs)\n\nmodel.compile(optimizer = 'adam', loss = 'MSE')\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:14:34.256105Z","iopub.execute_input":"2021-05-31T03:14:34.256491Z","iopub.status.idle":"2021-05-31T03:14:34.496196Z","shell.execute_reply.started":"2021-05-31T03:14:34.256454Z","shell.execute_reply":"2021-05-31T03:14:34.495342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"points = train_df.shape[0]\nsplit = 0.8\n\nx_train = train_df['excerpt'][:int(points*split)]\nx_val = train_df['excerpt'][int(points*split):]\ny_train = train_df['target'][:int(points*split)]\ny_val = train_df['target'][int(points*split):]\n\nx_train = vectorizer(x_train)\nx_val = vectorizer(x_val)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:14:34.497535Z","iopub.execute_input":"2021-05-31T03:14:34.498075Z","iopub.status.idle":"2021-05-31T03:14:34.685986Z","shell.execute_reply.started":"2021-05-31T03:14:34.498037Z","shell.execute_reply":"2021-05-31T03:14:34.685009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"callback_list = [tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_loss\",\n    min_delta=0,\n    patience=1,\n    verbose=0,\n    mode=\"auto\",\n    baseline=None,\n    restore_best_weights=True,\n)]\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:14:34.688932Z","iopub.execute_input":"2021-05-31T03:14:34.689512Z","iopub.status.idle":"2021-05-31T03:14:34.695119Z","shell.execute_reply.started":"2021-05-31T03:14:34.689477Z","shell.execute_reply":"2021-05-31T03:14:34.694018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(x_train, y_train, batch_size = 128, validation_data = (x_val, y_val), epochs = 20, callbacks = callback_list)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:14:34.697252Z","iopub.execute_input":"2021-05-31T03:14:34.697924Z","iopub.status.idle":"2021-05-31T03:15:25.162997Z","shell.execute_reply.started":"2021-05-31T03:14:34.697886Z","shell.execute_reply":"2021-05-31T03:15:25.162198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nx_test = vectorizer(test_df['excerpt'])\nresults = model.predict(x_test)\nids = test_df['id']\nresults = pd.Series(np.squeeze(results, 1))\nsubmission = pd.concat([ids, results], axis = 1)\nsubmission.rename({0:'target'}, axis = 1, inplace = True)\nsubmission.to_csv('submission.csv', index = False)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-31T03:15:25.164348Z","iopub.execute_input":"2021-05-31T03:15:25.164685Z","iopub.status.idle":"2021-05-31T03:15:25.468094Z","shell.execute_reply.started":"2021-05-31T03:15:25.16465Z","shell.execute_reply":"2021-05-31T03:15:25.467261Z"},"trusted":true},"execution_count":null,"outputs":[]}]}