{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T04:57:35.056372Z","iopub.execute_input":"2021-08-03T04:57:35.056724Z","iopub.status.idle":"2021-08-03T04:57:35.06607Z","shell.execute_reply.started":"2021-08-03T04:57:35.056696Z","shell.execute_reply":"2021-08-03T04:57:35.064763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\ntrain = train_data.iloc[:, 3].values\nlabel = train_data.iloc[:, 4].values\ntest = test_data.iloc[:, 3].values","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:35.068347Z","iopub.execute_input":"2021-08-03T04:57:35.06889Z","iopub.status.idle":"2021-08-03T04:57:35.111628Z","shell.execute_reply.started":"2021-08-03T04:57:35.068852Z","shell.execute_reply":"2021-08-03T04:57:35.110756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"standard_error = train_data.iloc[:, 5].values\nstd_error = np.array(standard_error)\nprint(std_error.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:35.113583Z","iopub.execute_input":"2021-08-03T04:57:35.113953Z","iopub.status.idle":"2021-08-03T04:57:35.119542Z","shell.execute_reply.started":"2021-08-03T04:57:35.113916Z","shell.execute_reply":"2021-08-03T04:57:35.118475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.scatter(label, std_error)\nplt.ylim([0.4,0.7])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:35.121798Z","iopub.execute_input":"2021-08-03T04:57:35.122324Z","iopub.status.idle":"2021-08-03T04:57:35.256095Z","shell.execute_reply.started":"2021-08-03T04:57:35.122285Z","shell.execute_reply":"2021-08-03T04:57:35.255061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = np.array(label)\ntrain = np.array(train)\ntest = np.array(test)\n\nprint(label.shape)\nprint(train.shape)\nprint(test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:35.257595Z","iopub.execute_input":"2021-08-03T04:57:35.257953Z","iopub.status.idle":"2021-08-03T04:57:35.264125Z","shell.execute_reply.started":"2021-08-03T04:57:35.257915Z","shell.execute_reply":"2021-08-03T04:57:35.262996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport tensorflow as tf\nimport re\nimport pandas as pd","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:35.265645Z","iopub.execute_input":"2021-08-03T04:57:35.266492Z","iopub.status.idle":"2021-08-03T04:57:35.274625Z","shell.execute_reply.started":"2021-08-03T04:57:35.266453Z","shell.execute_reply":"2021-08-03T04:57:35.273837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def word_to_vec(inputs):\n    tokenizer = Tokenizer(filters='', oov_token='<OOV>') # this tokenizer will filters nothing.\n    tokenizer.fit_on_texts(inputs)\n\n    tensor = tokenizer.texts_to_sequences(inputs)\n    tensor = pad_sequences(tensor, padding='post')\n\n    return tensor, tokenizer","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:35.275777Z","iopub.execute_input":"2021-08-03T04:57:35.276304Z","iopub.status.idle":"2021-08-03T04:57:35.284473Z","shell.execute_reply.started":"2021-08-03T04:57:35.276268Z","shell.execute_reply":"2021-08-03T04:57:35.283628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tensor, train_token = word_to_vec(train)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:35.287358Z","iopub.execute_input":"2021-08-03T04:57:35.287624Z","iopub.status.idle":"2021-08-03T04:57:36.152675Z","shell.execute_reply.started":"2021-08-03T04:57:35.287599Z","shell.execute_reply":"2021-08-03T04:57:36.1518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_len = train_tensor[0, :].shape[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.155687Z","iopub.execute_input":"2021-08-03T04:57:36.156054Z","iopub.status.idle":"2021-08-03T04:57:36.161649Z","shell.execute_reply.started":"2021-08-03T04:57:36.156017Z","shell.execute_reply":"2021-08-03T04:57:36.160865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER_SIZE = len(train_tensor)\nBATCH_SIZE = 64\nsteps_per_epoch = len(train_tensor)//BATCH_SIZE\nembedding_dim = 50\nunits = 60\nvocab_train = len(train_token.word_index)+1\n\n#dataset = tf.data.Dataset.from_tensor_slices((train_tensor, label)).shuffle(BUFFER_SIZE)\n#dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.16491Z","iopub.execute_input":"2021-08-03T04:57:36.165196Z","iopub.status.idle":"2021-08-03T04:57:36.173177Z","shell.execute_reply.started":"2021-08-03T04:57:36.165164Z","shell.execute_reply":"2021-08-03T04:57:36.172227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Attention(tf.keras.layers.Layer):\n    def __init__(self, units):\n        super(Attention, self).__init__()\n\n        self.s = tf.keras.layers.Dense(units, kernel_regularizer=tf.keras.regularizers.L2(0.001))\n        self.t = tf.keras.layers.Dense(units, kernel_regularizer=tf.keras.regularizers.L2(0.001))\n        self.a = tf.keras.layers.Dense(1, kernel_regularizer=tf.keras.regularizers.L2(0.001))\n\n    def call(self, query, value):\n        #query: (None, 255, 1024)\n        #value: (None, 1024)\n        \n        value = tf.expand_dims(value, 1)\n        #query: (None, 255, 1024)\n        #value: (1, 1024)\n        \n        score = self.a(tf.keras.activations.relu(self.s(query) + self.t(value)))\n        \n        attention_weights = tf.keras.activations.softmax(score, axis=1) \n\n        attention = attention_weights * value\n        attention = tf.reduce_sum(attention, axis=1) \n            \n        return attention, attention_weights","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.174296Z","iopub.execute_input":"2021-08-03T04:57:36.174748Z","iopub.status.idle":"2021-08-03T04:57:36.185186Z","shell.execute_reply.started":"2021-08-03T04:57:36.17471Z","shell.execute_reply":"2021-08-03T04:57:36.183971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"attention = Attention(units)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.186597Z","iopub.execute_input":"2021-08-03T04:57:36.186994Z","iopub.status.idle":"2021-08-03T04:57:36.196942Z","shell.execute_reply.started":"2021-08-03T04:57:36.186957Z","shell.execute_reply":"2021-08-03T04:57:36.196036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encoder \nencoder = tf.keras.Input(shape=(max_len, ))\nenc_embd = tf.keras.layers.Embedding(vocab_train, embedding_dim)(encoder)\nencoder_gru = tf.keras.layers.GRU(units, return_sequences=True, return_state=True, kernel_regularizer=tf.keras.regularizers.L2(0.001))\noutput_e, hidden_e = encoder_gru(enc_embd)\n\n# attention\nattention_value, attention_weights = attention(output_e, hidden_e)\n\n# concatenate the attention and hidden_e layer\ncontext_vector = tf.concat([attention_value, hidden_e], axis=-1)\n\nattention_layer = tf.keras.layers.Dense(context_vector.shape[1] , activation='relu', kernel_regularizer=tf.keras.regularizers.L2(0.001))\nattention_ = attention_layer(context_vector)\n\n# output\nfinal_output = tf.keras.layers.Dense(1, activation='linear', kernel_regularizer=tf.keras.regularizers.L2(0.001))\noutput_f = final_output(context_vector)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.198616Z","iopub.execute_input":"2021-08-03T04:57:36.199037Z","iopub.status.idle":"2021-08-03T04:57:36.468162Z","shell.execute_reply.started":"2021-08-03T04:57:36.198998Z","shell.execute_reply":"2021-08-03T04:57:36.467322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.Model(encoder, output_f)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.469849Z","iopub.execute_input":"2021-08-03T04:57:36.470111Z","iopub.status.idle":"2021-08-03T04:57:36.478954Z","shell.execute_reply.started":"2021-08-03T04:57:36.470082Z","shell.execute_reply":"2021-08-03T04:57:36.478127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(model.summary())","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.480434Z","iopub.execute_input":"2021-08-03T04:57:36.480821Z","iopub.status.idle":"2021-08-03T04:57:36.491317Z","shell.execute_reply.started":"2021-08-03T04:57:36.480785Z","shell.execute_reply":"2021-08-03T04:57:36.49001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.493032Z","iopub.execute_input":"2021-08-03T04:57:36.49346Z","iopub.status.idle":"2021-08-03T04:57:36.505731Z","shell.execute_reply.started":"2021-08-03T04:57:36.493426Z","shell.execute_reply":"2021-08-03T04:57:36.50481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_tensor.shape, label.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.507252Z","iopub.execute_input":"2021-08-03T04:57:36.507664Z","iopub.status.idle":"2021-08-03T04:57:36.513482Z","shell.execute_reply.started":"2021-08-03T04:57:36.507606Z","shell.execute_reply":"2021-08-03T04:57:36.512485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(train_tensor, label, epochs=20, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:57:36.515049Z","iopub.execute_input":"2021-08-03T04:57:36.516213Z","iopub.status.idle":"2021-08-03T04:58:38.202321Z","shell.execute_reply.started":"2021-08-03T04:57:36.516172Z","shell.execute_reply":"2021-08-03T04:58:38.201488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(label[0:3])\nprint(model.predict(train_tensor[0:3]))","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:58:38.203629Z","iopub.execute_input":"2021-08-03T04:58:38.203976Z","iopub.status.idle":"2021-08-03T04:58:38.582729Z","shell.execute_reply.started":"2021-08-03T04:58:38.20394Z","shell.execute_reply":"2021-08-03T04:58:38.581733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = train_token.texts_to_sequences(test)\ntest = pad_sequences(test, maxlen=max_len, padding='post')","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:58:38.584311Z","iopub.execute_input":"2021-08-03T04:58:38.584843Z","iopub.status.idle":"2021-08-03T04:58:38.591451Z","shell.execute_reply.started":"2021-08-03T04:58:38.584803Z","shell.execute_reply":"2021-08-03T04:58:38.590477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:58:38.592748Z","iopub.execute_input":"2021-08-03T04:58:38.593296Z","iopub.status.idle":"2021-08-03T04:58:38.607318Z","shell.execute_reply.started":"2021-08-03T04:58:38.593239Z","shell.execute_reply":"2021-08-03T04:58:38.606312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['target'] = model.predict(test) #model.predict(padded_test)\nprint(test_df['target'])\ntest_df[['id','target']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T04:58:38.609354Z","iopub.execute_input":"2021-08-03T04:58:38.609586Z","iopub.status.idle":"2021-08-03T04:58:38.663939Z","shell.execute_reply.started":"2021-08-03T04:58:38.609564Z","shell.execute_reply":"2021-08-03T04:58:38.663044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}