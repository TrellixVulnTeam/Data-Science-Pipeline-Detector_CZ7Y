{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# This notebook generates target samples as described in [this discussion](https://www.kaggle.com/c/commonlitreadabilityprize/discussion/257470)\n\nThe notebook will output a csv file with two versions of target samples\n\nTo use them in your training notebook:  \n1. read in the output csv file instead of the commonlit train.csv  \n2. when you read in the csv file, use `pd.read_csv(<path_to_output_csv>, converters={'samples': eval, 'samples2': eval})`  \n3. in the \\_\\_get\\_\\_item() in your pytorch dataset, after `target = self.target[index]`, add `target = target[np.random.randint(1,100,1)[0]]`\n                ","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport scipy.stats\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-04T02:35:27.888591Z","iopub.execute_input":"2021-08-04T02:35:27.889409Z","iopub.status.idle":"2021-08-04T02:35:28.927681Z","shell.execute_reply.started":"2021-08-04T02:35:27.889238Z","shell.execute_reply":"2021-08-04T02:35:28.926482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper for \"generate_samples\" function\ndef probability_of_value(value, dist):\n    dist_mean = dist.mean()\n    if value > dist_mean:\n        prob = (1 - dist.cdf(value)) * 2\n    elif value <= dist_mean:\n        prob = dist.cdf(value) * 2\n    \n    return prob","metadata":{"execution":{"iopub.status.busy":"2021-08-04T02:35:32.014541Z","iopub.execute_input":"2021-08-04T02:35:32.015016Z","iopub.status.idle":"2021-08-04T02:35:32.022018Z","shell.execute_reply.started":"2021-08-04T02:35:32.014973Z","shell.execute_reply":"2021-08-04T02:35:32.020484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# helper for \"sample_with_standard_error_noise\" function\ndef generate_samples(\n    target,\n    standard_error,\n    standard_error_range,\n    all_targets,\n    sample_num,\n    random_noise\n):\n\n    # this will hold the samples to return\n    valid_samples = []\n    \n    # edge case\n    if target == 0.0:\n        return [0.0 for i in range(sample_num)]\n    \n    # get the limits, and filter targets to that\n    bottom_limit = target - (standard_error * standard_error_range)\n    top_limit = target + (standard_error * standard_error_range)\n    targets_in_range = all_targets[(all_targets >= bottom_limit) & (all_targets <= top_limit)]\n    num_targets = len(targets_in_range) // 3\n    \n    # create distribution\n    dist = scipy.stats.norm(target, standard_error)\n    \n    # now we create them\n    while len(valid_samples) < sample_num:\n        # just any samples from the range\n        samples = list(targets_in_range.sample(num_targets))\n        for sample in samples:\n            # ok how probable is it?\n            sample_prob = probability_of_value(sample, dist)\n            # should we keep it?\n            if sample_prob > random.random():\n                random_noise_div = 1.0 / random_noise\n                valid_samples.append(sample+(random.random()/random_noise_div-(random_noise/2)))\n    \n    return valid_samples[:sample_num]","metadata":{"execution":{"iopub.status.busy":"2021-08-04T02:35:33.077569Z","iopub.execute_input":"2021-08-04T02:35:33.077955Z","iopub.status.idle":"2021-08-04T02:35:33.089296Z","shell.execute_reply.started":"2021-08-04T02:35:33.077922Z","shell.execute_reply":"2021-08-04T02:35:33.087749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_with_standard_error_noise(\n    df,\n    standard_error_range,\n    sample_num,\n    random_noise,\n    target_col=\"target\",\n    standard_error_col=\"standard_error\",\n    samples_col=\"samples\"\n):\n    all_targets = df[target_col].copy()\n    \n    working_df = df.copy()\n    working_df[samples_col] = working_df.apply(\n        lambda x: generate_samples(\n                      x[target_col],\n                      x[standard_error_col],\n                      standard_error_range,\n                      all_targets,\n                      sample_num,\n                      random_noise\n                  ), axis=1\n    )\n    \n    return working_df   ","metadata":{"execution":{"iopub.status.busy":"2021-08-04T02:35:42.749717Z","iopub.execute_input":"2021-08-04T02:35:42.750383Z","iopub.status.idle":"2021-08-04T02:35:42.758904Z","shell.execute_reply.started":"2021-08-04T02:35:42.750316Z","shell.execute_reply":"2021-08-04T02:35:42.75761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read training data\ntrain_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-04T02:35:44.807086Z","iopub.execute_input":"2021-08-04T02:35:44.807487Z","iopub.status.idle":"2021-08-04T02:35:44.899557Z","shell.execute_reply.started":"2021-08-04T02:35:44.807451Z","shell.execute_reply":"2021-08-04T02:35:44.898125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# adding sample y values\ntrain_df = sample_with_standard_error_noise(\n    df=train_df,\n    standard_error_range=0.5,\n    sample_num=100,\n    random_noise=0.1,\n    samples_col=\"samples\"\n)\ntrain_df = sample_with_standard_error_noise(\n    df=train_df,\n    standard_error_range=0.375,\n    sample_num=100,\n    random_noise=0.075,\n    samples_col=\"samples2\"\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T02:35:47.04771Z","iopub.execute_input":"2021-08-04T02:35:47.048073Z","iopub.status.idle":"2021-08-04T02:39:56.47614Z","shell.execute_reply.started":"2021-08-04T02:35:47.048041Z","shell.execute_reply":"2021-08-04T02:39:56.47474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T02:39:56.480948Z","iopub.execute_input":"2021-08-04T02:39:56.481592Z","iopub.status.idle":"2021-08-04T02:39:56.518157Z","shell.execute_reply.started":"2021-08-04T02:39:56.481538Z","shell.execute_reply":"2021-08-04T02:39:56.516615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(\"train_df_with_target_samples.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-04T02:39:56.521895Z","iopub.execute_input":"2021-08-04T02:39:56.522291Z","iopub.status.idle":"2021-08-04T02:39:57.714813Z","shell.execute_reply.started":"2021-08-04T02:39:56.522237Z","shell.execute_reply":"2021-08-04T02:39:57.713513Z"},"trusted":true},"execution_count":null,"outputs":[]}]}