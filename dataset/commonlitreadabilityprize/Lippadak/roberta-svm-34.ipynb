{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook uses below given notebooks to make predictions.\n\n1. Pretrain Roberta Model: https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n2. Finetune Roberta Model: https://www.kaggle.com/maunish/clrp-pytorch-roberta-finetune\n3. Inference Notebook: https://www.kaggle.com/maunish/clrp-pytorch-roberta-inference\n4. Roberta + SVM: this notebook","metadata":{"papermill":{"duration":0.020272,"end_time":"2021-06-22T13:08:45.301725","exception":false,"start_time":"2021-06-22T13:08:45.281453","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# !ls ../input/autonlp-finetune-save-weights/model0.bin","metadata":{"papermill":{"duration":0.019403,"end_time":"2021-06-22T13:08:45.340117","exception":false,"start_time":"2021-06-22T13:08:45.320714","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:39:47.969079Z","iopub.execute_input":"2021-07-02T16:39:47.969388Z","iopub.status.idle":"2021-07-02T16:39:47.97476Z","shell.execute_reply.started":"2021-07-02T16:39:47.969316Z","shell.execute_reply":"2021-07-02T16:39:47.972638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import (\n    Dataset, DataLoader, \n    SequentialSampler, RandomSampler\n)\n\nfrom transformers import (\n    get_cosine_schedule_with_warmup, \n    get_cosine_with_hard_restarts_schedule_with_warmup,\n    get_linear_schedule_with_warmup\n)\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification)\nfrom transformers import AdamW\n\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":7.802351,"end_time":"2021-06-22T13:08:53.16252","exception":false,"start_time":"2021-06-22T13:08:45.360169","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:39:48.034253Z","iopub.execute_input":"2021-07-02T16:39:48.034505Z","iopub.status.idle":"2021-07-02T16:39:59.340773Z","shell.execute_reply.started":"2021-07-02T16:39:48.03448Z","shell.execute_reply":"2021-07-02T16:39:59.339861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.34236Z","iopub.execute_input":"2021-07-02T16:39:59.342668Z","iopub.status.idle":"2021-07-02T16:39:59.437495Z","shell.execute_reply.started":"2021-07-02T16:39:59.342632Z","shell.execute_reply":"2021-07-02T16:39:59.436679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import model_selection\ndef create_folds(data, num_splits):\n    data[\"kfold\"] = -1\n    kf = model_selection.KFold(n_splits=num_splits, shuffle=True, random_state=2021)\n    for f, (t_, v_) in enumerate(kf.split(X=data)):\n        data.loc[v_, 'kfold'] = f\n    return data\ntrain_data = create_folds(train_data, num_splits=5)\ntest_data = create_folds(test_data, num_splits=5)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.439146Z","iopub.execute_input":"2021-07-02T16:39:59.439403Z","iopub.status.idle":"2021-07-02T16:39:59.462641Z","shell.execute_reply.started":"2021-07-02T16:39:59.439378Z","shell.execute_reply":"2021-07-02T16:39:59.461962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnum_bins = 12\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\ntarget = train_data['target'].to_numpy()\n# bins = train_data.kfold.to_numpy()\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"papermill":{"duration":0.118506,"end_time":"2021-06-22T13:09:07.331163","exception":false,"start_time":"2021-06-22T13:09:07.212657","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:39:59.464473Z","iopub.execute_input":"2021-07-02T16:39:59.464913Z","iopub.status.idle":"2021-07-02T16:39:59.476055Z","shell.execute_reply.started":"2021-07-02T16:39:59.464877Z","shell.execute_reply":"2021-07-02T16:39:59.475223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model_name = '../input/robertalarge'","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.478591Z","iopub.execute_input":"2021-07-02T16:39:59.478861Z","iopub.status.idle":"2021-07-02T16:39:59.485301Z","shell.execute_reply.started":"2021-07-02T16:39:59.478837Z","shell.execute_reply":"2021-07-02T16:39:59.484519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"configuration = {\n    'batch_size':16,\n    'max_len':256,\n    'nfolds':5,\n    'seed':21,\n    'model_name': '../input/k/sujithkpanoor/required-data/renjith/',\n}\n\ndef seed_everything(seed=21):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=configuration['seed'])","metadata":{"papermill":{"duration":0.035465,"end_time":"2021-06-22T13:09:07.387108","exception":false,"start_time":"2021-06-22T13:09:07.351643","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:39:59.486577Z","iopub.execute_input":"2021-07-02T16:39:59.487266Z","iopub.status.idle":"2021-07-02T16:39:59.497329Z","shell.execute_reply.started":"2021-07-02T16:39:59.487229Z","shell.execute_reply":"2021-07-02T16:39:59.496519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n#                                 return_token_type_ids=True,\n                                return_tensors='pt',\n                                max_length=configuration['max_len'],\n                                padding='max_length',\n                                truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"papermill":{"duration":0.030442,"end_time":"2021-06-22T13:09:07.43847","exception":false,"start_time":"2021-06-22T13:09:07.408028","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:39:59.498572Z","iopub.execute_input":"2021-07-02T16:39:59.499024Z","iopub.status.idle":"2021-07-02T16:39:59.507459Z","shell.execute_reply.started":"2021-07-02T16:39:59.498985Z","shell.execute_reply":"2021-07-02T16:39:59.504949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"papermill":{"duration":0.032298,"end_time":"2021-06-22T13:09:07.490784","exception":false,"start_time":"2021-06-22T13:09:07.458486","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:39:59.510486Z","iopub.execute_input":"2021-07-02T16:39:59.511018Z","iopub.status.idle":"2021-07-02T16:39:59.517406Z","shell.execute_reply.started":"2021-07-02T16:39:59.510984Z","shell.execute_reply":"2021-07-02T16:39:59.516293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        self.roberta = AutoModel.from_pretrained(configuration['model_name'])    \n        self.head = AttentionHead(1024,1024,1)\n        self.linear = nn.Linear(1024,1)\n        self.dropout = nn.Dropout(0.2)\n#         self.linear2 = nn.Linear(512,1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n        x = self.linear(x)\n        x = self.dropout(x)\n#         x = self.linear2(x)\n        return x","metadata":{"papermill":{"duration":0.033803,"end_time":"2021-06-22T13:09:07.544602","exception":false,"start_time":"2021-06-22T13:09:07.510799","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:39:59.519621Z","iopub.execute_input":"2021-07-02T16:39:59.520318Z","iopub.status.idle":"2021-07-02T16:39:59.527805Z","shell.execute_reply.started":"2021-07-02T16:39:59.52028Z","shell.execute_reply":"2021-07-02T16:39:59.527013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoConfig\ndef make_model(model_name=configuration['model_name'], num_labels=1):\n    tokenizer = AutoTokenizer.from_pretrained(configuration['model_name'])\n    config = AutoConfig.from_pretrained(model_name)\n    config.update({'num_labels':num_labels})\n    model = CommonLitModel(model_name, config=config)\n    return model, tokenizer\n\ndef make_optimizer(model, optimizer_name=\"AdamW\"):\n    optimizer_grouped_parameters = get_optimizer_params(model)\n    kwargs = {\n            'lr':5e-5,\n            'weight_decay':0.01,\n            # 'betas': (0.9, 0.98),\n            # 'eps': 1e-06\n    }\n    if optimizer_name == \"LAMB\":\n        optimizer = Lamb(optimizer_grouped_parameters, **kwargs)\n        return optimizer\n    elif optimizer_name == \"Adam\":\n        from torch.optim import Adam\n        optimizer = Adam(optimizer_grouped_parameters, **kwargs)\n        return optimizer\n    elif optimizer_name == \"AdamW\":\n        optimizer = AdamW(optimizer_grouped_parameters, **kwargs)\n        return optimizer\n    else:\n        raise Exception('Unknown optimizer: {}'.format(optimizer_name))\n\ndef make_scheduler(optimizer, decay_name='linear', t_max=None, warmup_steps=None):\n    if decay_name == 'step':\n        scheduler = optim.lr_scheduler.MultiStepLR(\n            optimizer,\n            milestones=[30, 60, 90],\n            gamma=0.1\n        )\n    elif decay_name == 'cosine':\n        scheduler = lrs.CosineAnnealingLR(\n            optimizer,\n            T_max=t_max\n        )\n    elif decay_name == \"cosine_warmup\":\n        scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=warmup_steps,\n            num_training_steps=t_max\n        )\n    elif decay_name == \"linear\":\n        scheduler = get_linear_schedule_with_warmup(\n            optimizer, \n            num_warmup_steps=warmup_steps, \n            num_training_steps=t_max\n        )\n    else:\n        raise Exception('Unknown lr scheduler: {}'.format(decay_type))    \n    return scheduler    \n\ndef make_loader(\n    data, \n    tokenizer, \n    max_len,\n    batch_size,\n    fold=0\n):\n    train_set, valid_set = data[data['kfold']!=fold], data[data['kfold']==fold]\n    train_dataset = DatasetRetriever(data, tokenizer, max_len)\n    valid_dataset = DatasetRetriever(valid_set, tokenizer, max_len)\n\n#     train_sampler = RandomSampler(train_dataset)\n    train_loader = DataLoader(\n        train_dataset, \n        batch_size=batch_size, \n#         sampler=train_sampler, \n        pin_memory=True, \n        drop_last=False, \n        num_workers=4\n    )\n\n#     valid_sampler = SequentialSampler(valid_dataset)\n    valid_loader = DataLoader(\n        valid_dataset, \n        batch_size=batch_size // 2, \n#         sampler=valid_sampler, \n        pin_memory=True, \n        drop_last=False, \n        num_workers=4\n    )\n\n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.529206Z","iopub.execute_input":"2021-07-02T16:39:59.529589Z","iopub.status.idle":"2021-07-02T16:39:59.544591Z","shell.execute_reply.started":"2021-07-02T16:39:59.529555Z","shell.execute_reply":"2021-07-02T16:39:59.543803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_optimizer_params(model):\n    # differential learning rate and weight decay\n    param_optimizer = list(model.named_parameters())\n    learning_rate = 5e-5\n    no_decay = ['bias', 'gamma', 'beta']\n    group1=['layer.0.','layer.1.','layer.2.','layer.3.']\n    group2=['layer.4.','layer.5.','layer.6.','layer.7.']    \n    group3=['layer.8.','layer.9.','layer.10.','layer.11.']\n    group_all=['layer.0.','layer.1.','layer.2.','layer.3.','layer.4.','layer.5.','layer.6.','layer.7.','layer.8.','layer.9.','layer.10.','layer.11.']\n    optimizer_parameters = [\n        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.01},\n        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.01, 'lr': learning_rate/2.6},\n        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.01, 'lr': learning_rate},\n        {'params': [p for n, p in model.roberta.named_parameters() if not any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.01, 'lr': learning_rate*2.6},\n        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and not any(nd in n for nd in group_all)],'weight_decay': 0.0},\n        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group1)],'weight_decay': 0.0, 'lr': learning_rate/2.6},\n        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group2)],'weight_decay': 0.0, 'lr': learning_rate},\n        {'params': [p for n, p in model.roberta.named_parameters() if any(nd in n for nd in no_decay) and any(nd in n for nd in group3)],'weight_decay': 0.0, 'lr': learning_rate*2.6},\n        {'params': [p for n, p in model.named_parameters() if \"roberta\" not in n], 'lr':1e-3, \"momentum\" : 0.99},\n    ]\n    return optimizer_parameters","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.545918Z","iopub.execute_input":"2021-07-02T16:39:59.546347Z","iopub.status.idle":"2021-07-02T16:39:59.562484Z","shell.execute_reply.started":"2021-07-02T16:39:59.546313Z","shell.execute_reply":"2021-07-02T16:39:59.561733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommonLitModel(nn.Module):\n    def __init__(\n        self, \n        model_name, \n        config,  \n        multisample_dropout=False,\n        output_hidden_states=False\n    ):\n        super(CommonLitModel, self).__init__()\n        self.config = config\n        self.roberta = AutoModel.from_pretrained(\n            model_name, \n            output_hidden_states=output_hidden_states\n        )\n        self.head = AttentionHead(1024,1024,1)\n        self.layer_norm = nn.LayerNorm(config.hidden_size)\n        if multisample_dropout:\n            self.dropouts = nn.ModuleList([\n                nn.Dropout(0.5) for _ in range(5)\n            ])\n        else:\n            self.dropouts = nn.ModuleList([nn.Dropout(0.3)])\n        #self.regressor = nn.Linear(config.hidden_size*2, 1)\n        self.regressor = nn.Linear(config.hidden_size, 1)\n        self._init_weights(self.layer_norm)\n        self._init_weights(self.regressor)\n \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n \n    def forward(\n        self, \n        input_ids=None,\n        attention_mask=None,\n        token_type_ids=None,\n        labels=None\n    ):\n        outputs = self.roberta(\n            input_ids,\n            attention_mask=attention_mask,\n            token_type_ids=token_type_ids,\n        )\n        sequence_output = outputs[1]\n        sequence_output = self.layer_norm(sequence_output)\n \n        # max-avg head\n        # average_pool = torch.mean(sequence_output, 1)\n        # max_pool, _ = torch.max(sequence_output, 1)\n        # concat_sequence_output = torch.cat((average_pool, max_pool), 1)\n \n        # multi-sample dropout\n        for i, dropout in enumerate(self.dropouts):\n            if i == 0:\n                logits = self.regressor(dropout(sequence_output))\n            else:\n                logits += self.regressor(dropout(sequence_output))\n        \n        logits /= len(self.dropouts)\n \n        # calculate loss\n        loss = None\n        if labels is not None:\n            # regression task\n            loss_fn = torch.nn.MSELoss()\n            logits = logits.view(-1).to(labels.dtype)\n            loss = torch.sqrt(loss_fn(logits, labels.view(-1)))\n        \n        output = (logits,) + outputs[2:]\n        return ((loss,) + output) if loss is not None else output","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.563822Z","iopub.execute_input":"2021-07-02T16:39:59.564225Z","iopub.status.idle":"2021-07-02T16:39:59.580334Z","shell.execute_reply.started":"2021-07-02T16:39:59.564191Z","shell.execute_reply":"2021-07-02T16:39:59.579523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_examples_to_features(data, tokenizer, max_len, is_test=False):\n    data = data.replace('\\n', '')\n    tok = tokenizer.encode_plus(\n        data, \n        max_length=max_len, \n        truncation=True,\n        return_attention_mask=True,\n        return_token_type_ids=True\n    )\n    curr_sent = {}\n    padding_length = max_len - len(tok['input_ids'])\n    curr_sent['input_ids'] = tok['input_ids'] + ([tokenizer.pad_token_id] * padding_length)\n    curr_sent['token_type_ids'] = tok['token_type_ids'] + \\\n        ([0] * padding_length)\n    curr_sent['attention_mask'] = tok['attention_mask'] + \\\n        ([0] * padding_length)\n    return curr_sent","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.581632Z","iopub.execute_input":"2021-07-02T16:39:59.582021Z","iopub.status.idle":"2021-07-02T16:39:59.590604Z","shell.execute_reply.started":"2021-07-02T16:39:59.581986Z","shell.execute_reply":"2021-07-02T16:39:59.58984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DatasetRetriever(Dataset):\n    def __init__(self, data, tokenizer, max_len, is_test=False):\n        self.data = data\n        if 'excerpt' in self.data.columns:\n            self.excerpts = self.data.excerpt.values.tolist()\n        else:\n            self.excerpts = self.data.text.values.tolist()\n#         self.targets = self.data.target.values.tolist()\n        self.tokenizer = tokenizer\n        self.is_test = is_test\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, item):\n#         excerpt, label = self.excerpts[item], self.targets[item]\n        excerpt = self.excerpts[item]\n        features = convert_examples_to_features(\n            excerpt, self.tokenizer, \n            self.max_len, self.is_test\n        )\n        return {\n            'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n            'token_type_ids':torch.tensor(features['token_type_ids'], dtype=torch.long),\n            'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n#             'label':torch.tensor(label, dtype=torch.double),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.591901Z","iopub.execute_input":"2021-07-02T16:39:59.592259Z","iopub.status.idle":"2021-07-02T16:39:59.602216Z","shell.execute_reply.started":"2021-07-02T16:39:59.592224Z","shell.execute_reply":"2021-07-02T16:39:59.601344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Evaluator:\n    def __init__(self, model, scalar=None):\n        self.model = model\n        self.scalar = scalar\n\n    def evaluate(self, data_loader, tokenizer):\n        preds = []\n        self.model.eval()\n        total_loss = 0\n        with torch.no_grad():\n            for batch_idx, batch_data in enumerate(data_loader):\n                input_ids, attention_mask, token_type_ids = batch_data['input_ids'], \\\n                    batch_data['attention_mask'], batch_data['token_type_ids']\n                input_ids, attention_mask, token_type_ids = input_ids.cuda(), \\\n                    attention_mask.cuda(), token_type_ids.cuda()\n                \n                if self.scalar is not None:\n                    with torch.cuda.amp.autocast():\n                        outputs = self.model(\n                            input_ids=input_ids,\n                            attention_mask=attention_mask,\n                            token_type_ids=token_type_ids\n                        )\n                else:\n                    outputs = self.model(\n                        input_ids=input_ids,\n                        attention_mask=attention_mask,\n                        token_type_ids=token_type_ids\n                    )\n                \n                logits = outputs[0].detach().cpu().numpy().squeeze().tolist()\n                preds += logits\n        return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.603574Z","iopub.execute_input":"2021-07-02T16:39:59.603925Z","iopub.status.idle":"2021-07-02T16:39:59.613549Z","shell.execute_reply.started":"2021-07-02T16:39:59.603892Z","shell.execute_reply":"2021-07-02T16:39:59.612618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def config(fold,model_name):\n    torch.manual_seed(2021)\n    torch.cuda.manual_seed(2021)\n    torch.cuda.manual_seed_all(2021)\n    epochs = 8\n    max_len = 256\n    batch_size = 16\n\n    model, tokenizer = make_model(model_name=model_name, num_labels=1)\n    train_loader, valid_loader = make_loader(\n        train_data, tokenizer, max_len=max_len,\n        batch_size=batch_size, fold=fold\n    )\n\n    import math\n    num_update_steps_per_epoch = len(train_loader)\n    max_train_steps = epochs * num_update_steps_per_epoch\n    warmup_proportion = 0\n    if warmup_proportion != 0:\n        warmup_steps = math.ceil((max_train_steps * 2) / 100)\n    else:\n        warmup_steps = 0\n\n    optimizer = make_optimizer(model, \"AdamW\")\n    scheduler = make_scheduler(\n        optimizer, decay_name='cosine_warmup', \n        t_max=max_train_steps, \n        warmup_steps=warmup_steps\n    )    \n\n    if torch.cuda.device_count() >= 1:\n        print('Model pushed to {} GPU(s), type {}.'.format(\n            torch.cuda.device_count(), \n            torch.cuda.get_device_name(0))\n        )\n        model = model.cuda() \n    else:\n        raise ValueError('CPU training is not supported')\n\n    # scaler = torch.cuda.amp.GradScaler()\n    scaler = None\n\n    result_dict = {\n        'epoch':[], \n        'train_loss': [], \n        'val_loss' : [], \n        'best_val_loss': np.inf\n    }\n    return (\n        model, tokenizer, \n        optimizer, scheduler, \n        scaler, train_loader, \n        valid_loader, result_dict, \n        epochs\n    )","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.614914Z","iopub.execute_input":"2021-07-02T16:39:59.61554Z","iopub.status.idle":"2021-07-02T16:39:59.626308Z","shell.execute_reply.started":"2021-07-02T16:39:59.615506Z","shell.execute_reply":"2021-07-02T16:39:59.625523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_test_loader(\n    data, \n    tokenizer, \n    max_len,\n    batch_size,\n):\n    \n    test_dataset = DatasetRetriever(data, tokenizer, max_len, is_test=True)\n    test_sampler = SequentialSampler(test_dataset)\n    test_loader = DataLoader(\n        test_dataset, \n        batch_size=batch_size // 2, \n        sampler=test_sampler, \n        pin_memory=False, \n        drop_last=False, \n        num_workers=0\n    )\n\n    return test_loader","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.627525Z","iopub.execute_input":"2021-07-02T16:39:59.627914Z","iopub.status.idle":"2021-07-02T16:39:59.636477Z","shell.execute_reply.started":"2021-07-02T16:39:59.62788Z","shell.execute_reply":"2021-07-02T16:39:59.635691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(fold=0, model_name=None, path=None):\n#     model, tokenizer, test_loader, scaler = config(fold, model_name, load_model_path)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n    \n    model, tokenizer, optimizer, scheduler, scaler, train_loader, valid_loader, result_dict, epochs = config(fold,model_name)    \n    model.load_state_dict(torch.load(path))\n    model.to(device)  \n    \n    test_loader = make_test_loader(\n        test_data, tokenizer, max_len=configuration['max_len'],\n        batch_size=configuration['batch_size']\n    )\n    \n    import time\n\n    evaluator = Evaluator(model, scaler)\n\n    test_time_list = []\n\n    torch.cuda.synchronize()\n    tic1 = time.time()\n\n    preds = evaluator.evaluate(test_loader, tokenizer)\n\n    torch.cuda.synchronize()\n    tic2 = time.time() \n    test_time_list.append(tic2 - tic1)\n    \n    del model, tokenizer, test_loader, scaler\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.639153Z","iopub.execute_input":"2021-07-02T16:39:59.639385Z","iopub.status.idle":"2021-07-02T16:39:59.649014Z","shell.execute_reply.started":"2021-07-02T16:39:59.639363Z","shell.execute_reply":"2021-07-02T16:39:59.648211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !ls ../input/autonlp-finetune-save-weights/\n","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.650295Z","iopub.execute_input":"2021-07-02T16:39:59.65068Z","iopub.status.idle":"2021-07-02T16:39:59.658344Z","shell.execute_reply.started":"2021-07-02T16:39:59.650645Z","shell.execute_reply":"2021-07-02T16:39:59.657542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\npred_df1 = pd.DataFrame()\npred_df2 = pd.DataFrame()\n# pred_df3 = pd.DataFrame()\n# pred_df4 = pd.DataFrame()\n# pred_df5 = pd.DataFrame()\n# pred_df6 = pd.DataFrame()\nfor fold in tqdm(range(5)):\n    pred_df1[f'fold{fold}'] = run(fold, configuration['model_name'], '../input/autonlptwoweights/model0.bin')\n    pred_df2[f'fold{fold+5}'] = run(fold, configuration['model_name'], '../input/autonlptwoweights/model1.bin')\n#     pred_df3[f'fold{fold+5}'] = run(fold, configuration['model_name'], '../input/autonlp-finetune-save-weights/model0.bin')\n#     pred_df4[f'fold{fold+10}'] = run(fold, configuration['model_name'], '../input/autonlp-finetune-save-weights/model0.bin')\n#     pred_df5[f'fold{fold+15}'] = run(fold, configuration['model_name'], '../input/autonlp-finetune-save-weights/model0.bin')\n#     pred_df6[f'fold{fold+20}'] = run(fold, configuration['model_name'], '../input/autonlp-finetune-save-weights/model0.bin')","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:39:59.660786Z","iopub.execute_input":"2021-07-02T16:39:59.661173Z","iopub.status.idle":"2021-07-02T16:42:06.892732Z","shell.execute_reply.started":"2021-07-02T16:39:59.661141Z","shell.execute_reply":"2021-07-02T16:42:06.890179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# res =  (pred_df1.mean(axis=1) + pred_df3.mean(axis=1) + pred_df4.mean(axis=1) + pred_df5.mean(axis=1) + pred_df6.mean(axis=1))/5\n# res","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:42:06.894067Z","iopub.execute_input":"2021-07-02T16:42:06.894431Z","iopub.status.idle":"2021-07-02T16:42:06.897957Z","shell.execute_reply.started":"2021-07-02T16:42:06.894393Z","shell.execute_reply":"2021-07-02T16:42:06.897106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# def get_embeddings(df,path,fold,model_name,plot_losses=True, verbose=True):\n#     device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n#     print(f\"{device} is used\")\n            \n# #     train_loader, valid_loader = make_loader(\n# #         df, tokenizer, max_len=256,\n# #         batch_size=16, fold=fold\n# #     )\n#     model, tokenizer, optimizer, scheduler, scaler, train_loader, valid_loader, result_dict, epochs = config(fold,model_name)    \n#     model.load_state_dict(torch.load(path))\n#     model.to(device)\n#     model.eval()\n    \n# #     tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n    \n# #     ds = CLRPDataset(df,tokenizer)\n#     ds = DatasetRetriever(df, tokenizer, 256)\n#     dl = DataLoader(ds,\n#                   batch_size = 128,\n#                   shuffle=False,\n#                   num_workers = 4,\n#                   pin_memory=True,\n#                   drop_last=False\n#                  )\n        \n#     embeddings = list()\n#     with torch.no_grad():\n#         for i, batch_data in enumerate(dl):\n#             input_ids, attention_mask, token_type_ids = batch_data['input_ids'], batch_data['attention_mask'], batch_data['token_type_ids']\n#             input_ids, attention_mask, token_type_ids = input_ids.cuda(), attention_mask.cuda(), token_type_ids.cuda()\n# #             inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in batch_data.items()}\n#             outputs = model(\n#                         input_ids=input_ids,\n#                         attention_mask=attention_mask,\n#                         token_type_ids=token_type_ids\n# #                         labels=labels\n#             )\n# #             outputs = list(model(**inputs))[0]\n# #             outputs = outputs.detach().cpu().numpy()\n# #             print(outputs[0])\n#             embeddings.extend(outputs[0])\n# #             print(outputs[0])\n# #             print(\"======\")\n# #             print(outputs[1])\n# #             embeddings.extend(outputs[1])\n\n#     return (np.array(embeddings)).reshape(-1, 1)","metadata":{"papermill":{"duration":0.033978,"end_time":"2021-06-22T13:09:07.599016","exception":false,"start_time":"2021-06-22T13:09:07.565038","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:42:06.899314Z","iopub.execute_input":"2021-07-02T16:42:06.899857Z","iopub.status.idle":"2021-07-02T16:42:06.914502Z","shell.execute_reply.started":"2021-07-02T16:42:06.899822Z","shell.execute_reply":"2021-07-02T16:42:06.913668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# t1 = '../input/autonlptwoweights/model0.bin'\n# train_embeddings1 =  get_embeddings(train_data, t1, 0, configuration['model_name'])\n# test_embeddings1 = get_embeddings(test_data, t1, 0, configuration['model_name'])\n\n# t2 = '../input/autonlptwoweights/model1.bin'\n# train_embeddings2 =  get_embeddings(train_data, t2, 1, configuration['model_name'])\n# test_embeddings2 = get_embeddings(test_data, t2, 1, configuration['model_name'])\n\n# t3 = '../input/robertabasesaveweights/model2.bin'\n# train_embeddings3 =  get_embeddings(train_data, t3,2,'../input/roberta-base')\n# test_embeddings3 = get_embeddings(test_data, t3,2, '../input/roberta-base')\n\n# t4 = '../input/robertabasesaveweights/model3.bin'\n# train_embeddings4 =  get_embeddings(train_data, t4,3, '../input/roberta-base')\n# test_embeddings4 = get_embeddings(test_data, t4,3, '../input/roberta-base')\n\n# t5 = '../input/robertabasesaveweights/model4.bin'\n# train_embeddings5 =  get_embeddings(train_data, t5,4, '../input/roberta-base')\n# test_embeddings5 = get_embeddings(test_data, t5,4, '../input/roberta-base')","metadata":{"papermill":{"duration":216.616565,"end_time":"2021-06-22T13:12:44.236096","exception":false,"start_time":"2021-06-22T13:09:07.619531","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:42:06.918181Z","iopub.execute_input":"2021-07-02T16:42:06.91845Z","iopub.status.idle":"2021-07-02T16:42:06.926196Z","shell.execute_reply.started":"2021-07-02T16:42:06.918425Z","shell.execute_reply":"2021-07-02T16:42:06.925351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## svm","metadata":{"papermill":{"duration":0.043995,"end_time":"2021-06-22T13:12:44.326103","exception":false,"start_time":"2021-06-22T13:12:44.282108","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n#     scores = list()\n#     preds = np.zeros((X_test.shape[0]))\n    \n#     kfolds = StratifiedKFold(n_splits=5, random_state=configuration['seed'], shuffle=True)\n#     for k, (train_idx,valid_idx) in enumerate(kfolds.split(X,bins)):\n# #     for fold in tqdm(range(5), total=5):\n# #         train_loader, val_loader = make_loader(train_data, tokenizer, 256, 16, fold=fold)\n#         model = SVR(C=C,kernel=kernel,gamma='auto')\n#         X_train,y_train = X[train_idx], y[train_idx]\n#         X_valid,y_valid = X[valid_idx], y[valid_idx]\n        \n#         model.fit(X_train,y_train)\n#         prediction = model.predict(X_valid)\n#         score = rmse_score(prediction,y_valid)\n#         print(f'Fold {k} , rmse score: {score}')\n#         scores.append(score)\n#         preds += model.predict(X_test)\n        \n#     print(\"mean rmse\",np.mean(scores))\n#     return np.array(preds)/nfolds","metadata":{"papermill":{"duration":0.058476,"end_time":"2021-06-22T13:12:44.428164","exception":false,"start_time":"2021-06-22T13:12:44.369688","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:42:06.927832Z","iopub.execute_input":"2021-07-02T16:42:06.92826Z","iopub.status.idle":"2021-07-02T16:42:06.934536Z","shell.execute_reply.started":"2021-07-02T16:42:06.928226Z","shell.execute_reply":"2021-07-02T16:42:06.93355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 0.22552367492969502","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:42:06.935727Z","iopub.execute_input":"2021-07-02T16:42:06.936116Z","iopub.status.idle":"2021-07-02T16:42:06.945822Z","shell.execute_reply.started":"2021-07-02T16:42:06.936081Z","shell.execute_reply":"2021-07-02T16:42:06.945054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\n# svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\n# svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\n# svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\n# svm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)","metadata":{"papermill":{"duration":15.024236,"end_time":"2021-06-22T13:12:59.496094","exception":false,"start_time":"2021-06-22T13:12:44.471858","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:42:06.94715Z","iopub.execute_input":"2021-07-02T16:42:06.947576Z","iopub.status.idle":"2021-07-02T16:42:06.955418Z","shell.execute_reply.started":"2021-07-02T16:42:06.947541Z","shell.execute_reply":"2021-07-02T16:42:06.954558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# pred_df2","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:45:31.76965Z","iopub.execute_input":"2021-07-02T16:45:31.769987Z","iopub.status.idle":"2021-07-02T16:45:31.781455Z","shell.execute_reply.started":"2021-07-02T16:45:31.769951Z","shell.execute_reply":"2021-07-02T16:45:31.780392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# p = pred_df2 + pred_df1\n# p","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:45:49.583877Z","iopub.execute_input":"2021-07-02T16:45:49.584227Z","iopub.status.idle":"2021-07-02T16:45:49.601186Z","shell.execute_reply.started":"2021-07-02T16:45:49.584198Z","shell.execute_reply":"2021-07-02T16:45:49.60026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm = list((pred_df1['fold0'] + pred_df2['fold5'] )/2)","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:47:14.669329Z","iopub.execute_input":"2021-07-02T16:47:14.669648Z","iopub.status.idle":"2021-07-02T16:47:14.674734Z","shell.execute_reply.started":"2021-07-02T16:47:14.669619Z","shell.execute_reply":"2021-07-02T16:47:14.673914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm = (pred_df1.mean(axis=1) + pred_df2.mean(axis=1))/2","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:42:06.964472Z","iopub.execute_input":"2021-07-02T16:42:06.964715Z","iopub.status.idle":"2021-07-02T16:42:06.974783Z","shell.execute_reply.started":"2021-07-02T16:42:06.964693Z","shell.execute_reply":"2021-07-02T16:42:06.973917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample['svm_preds1'] = svm_preds1\n# sample['svm_preds2'] = svm_preds2\n# # # sample['svm_preds3'] = svm_preds3\n# # # sample['svm_preds4'] = svm_preds4\n# # # sample['svm_preds5'] = svm_preds5\n# sample['pred_df1'] = pred_df1.mean(axis=1)\n# sample['pred_df2'] = pred_df2.mean(axis=1)\n# # sample['pred_df3'] = pred_df3.mean(axis=1)\n# # sample['pred_df4'] = pred_df4.mean(axis=1)\n# # sample['pred_df5'] = pred_df5.mean(axis=1)\n# # sample['pred_df6'] = pred_df6.mean(axis=1)\n# # sample.to_csv('test.csv',index=False)\n# sample","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:42:06.975955Z","iopub.execute_input":"2021-07-02T16:42:06.976311Z","iopub.status.idle":"2021-07-02T16:42:06.982619Z","shell.execute_reply.started":"2021-07-02T16:42:06.976275Z","shell.execute_reply":"2021-07-02T16:42:06.98188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# result = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5 + pred_df1.mean(axis=1) + pred_df3.mean(axis=1) + pred_df4.mean(axis=1) + pred_df5.mean(axis=1) + pred_df6.mean(axis=1))/10","metadata":{"execution":{"iopub.status.busy":"2021-07-02T16:42:06.984117Z","iopub.execute_input":"2021-07-02T16:42:06.984474Z","iopub.status.idle":"2021-07-02T16:42:06.990626Z","shell.execute_reply.started":"2021-07-02T16:42:06.984439Z","shell.execute_reply":"2021-07-02T16:42:06.989867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5","metadata":{"papermill":{"duration":0.123941,"end_time":"2021-06-22T13:12:59.682823","exception":false,"start_time":"2021-06-22T13:12:59.558882","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:42:06.99183Z","iopub.execute_input":"2021-07-02T16:42:06.992462Z","iopub.status.idle":"2021-07-02T16:42:07.001094Z","shell.execute_reply.started":"2021-07-02T16:42:06.992406Z","shell.execute_reply":"2021-07-02T16:42:07.000352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample.target = svm\nsample.to_csv('submission.csv',index=False)\nsample","metadata":{"papermill":{"duration":0.124283,"end_time":"2021-06-22T13:12:59.916887","exception":false,"start_time":"2021-06-22T13:12:59.792604","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-07-02T16:47:18.67378Z","iopub.execute_input":"2021-07-02T16:47:18.674125Z","iopub.status.idle":"2021-07-02T16:47:18.688271Z","shell.execute_reply.started":"2021-07-02T16:47:18.674096Z","shell.execute_reply":"2021-07-02T16:47:18.687278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":0.051695,"end_time":"2021-06-22T13:13:00.291028","exception":false,"start_time":"2021-06-22T13:13:00.239333","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}