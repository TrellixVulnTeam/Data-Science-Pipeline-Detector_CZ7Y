{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# from IPython.core.magic import register_cell_magic\nimport os\nfrom pathlib import Path\n\n## define custom magic to save most useful classes and use them in inference notebook \n## instead of copying the code every time you have changes in the classes\n# @register_cell_magic\n# def write_and_run(line, cell):\n#     argz = line.split()\n#     file = argz[-1]\n#     mode = 'w'\n#     if len(argz) == 2 and argz[0] == '-a':\n#         mode = 'a'\n#     with open(file, mode) as f:\n#         f.write(cell)\n#     get_ipython().run_cell(cell)\n    \nPath('/kaggle/working/scripts').mkdir(exist_ok=True)\nmodels_dir = Path('/kaggle/working/models')\nmodels_dir.mkdir(exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:12:06.30045Z","iopub.execute_input":"2021-07-14T18:12:06.300813Z","iopub.status.idle":"2021-07-14T18:12:06.307555Z","shell.execute_reply.started":"2021-07-14T18:12:06.300783Z","shell.execute_reply":"2021-07-14T18:12:06.306583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%write_and_run scripts/imports.py\n\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\n# import seaborn as sns\n\nfrom tqdm import tqdm\n# import matplotlib.pyplot as plt\nfrom sklearn.model_selection import KFold\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.utils.data import RandomSampler, SequentialSampler, Sampler\nfrom torch.nn.functional import mse_loss\nfrom transformers import AutoModel,AutoTokenizer,get_cosine_schedule_with_warmup, AutoConfig, AdamW\n\n# import matplotlib.pyplot as plt\n# import seaborn as sns\n# plt.style.use('seaborn-talk')\n# print(plt.style.available)\nfrom time import time\n# from colorama import Fore, Back, Style\n# r_ = Fore.RED\n# b_ = Fore.BLUE\n# g_ = Fore.GREEN\n# y_ = Fore.YELLOW\n# w_ = Fore.WHITE\n# bb_ = Back.BLACK\n# sr_ = Style.RESET_ALL\n\n","metadata":{"_uuid":"d9a1a99e-de9d-4024-9715-bab69dafd9d6","_cell_guid":"17ca5c94-c7c7-49a0-8822-05b59ceaaa5e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-14T18:12:06.30942Z","iopub.execute_input":"2021-07-14T18:12:06.309774Z","iopub.status.idle":"2021-07-14T18:12:06.321635Z","shell.execute_reply.started":"2021-07-14T18:12:06.309739Z","shell.execute_reply":"2021-07-14T18:12:06.320824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%write_and_run scripts/config.py\n\nclass Config:\n    model_name = '../input/roberta-base/'\n    pretrained_model_path = '../input/roberta-base'\n    output_hidden_states = True\n    epochs = 4\n    evaluate_interval = 10\n    batch_size = 32\n    device = 'cuda'\n    seed = 42\n    max_len = 256\n    lr = 2e-5\n    wd = 0.01\n    eval_schedule = [(float('inf'), 16), (0.5, 8), (0.49, 4), (0.48, 2), (0.47, 1), (0, 0)]\n\n    ","metadata":{"_uuid":"3d4bc2bb-36f6-4d6a-aa6c-b9ec39f40c45","_cell_guid":"757a446c-b2dc-4eea-91d6-8f8bcd1155c3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-14T18:12:06.324637Z","iopub.execute_input":"2021-07-14T18:12:06.324885Z","iopub.status.idle":"2021-07-14T18:12:06.335819Z","shell.execute_reply.started":"2021-07-14T18:12:06.324862Z","shell.execute_reply":"2021-07-14T18:12:06.334894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=Config.seed)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:12:06.338435Z","iopub.execute_input":"2021-07-14T18:12:06.33868Z","iopub.status.idle":"2021-07-14T18:12:06.347328Z","shell.execute_reply.started":"2021-07-14T18:12:06.338657Z","shell.execute_reply":"2021-07-14T18:12:06.346424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = pd.read_csv('../input/k/chamecall/train-val-split/train.csv')\n# val_df = pd.read_csv('../input/k/chamecall/train-val-split/val.csv')\n\nkfold_df = pd.read_csv('../input/k/chamecall/train-val-split/kfold.csv')\n# aux_df = pd.read_csv('../input/clrauxdata/aux_data_embed.csv', index_col='index', converters={'aux_text': eval})","metadata":{"_uuid":"f7aa8d00-0b7b-4704-b00c-45c214001ecb","_cell_guid":"89d2d6a9-c024-4852-a1cc-2892d7e2aab9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-14T18:12:06.350372Z","iopub.execute_input":"2021-07-14T18:12:06.350615Z","iopub.status.idle":"2021-07-14T18:12:06.388289Z","shell.execute_reply.started":"2021-07-14T18:12:06.350592Z","shell.execute_reply":"2021-07-14T18:12:06.387511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:12:06.391001Z","iopub.execute_input":"2021-07-14T18:12:06.391283Z","iopub.status.idle":"2021-07-14T18:12:06.400625Z","shell.execute_reply.started":"2021-07-14T18:12:06.391257Z","shell.execute_reply":"2021-07-14T18:12:06.399822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%write_and_run scripts/dataset.py\n\nfrom torch.utils.data import Dataset\nimport torch\n\ndef convert_examples_to_features(text, tokenizer, max_len):\n\n    tok = tokenizer.encode_plus(\n        text, \n        max_length=max_len, \n        truncation=True,\n        padding='max_length',\n    )\n    return tok\n\n\nclass CLRPDataset(Dataset):\n    def __init__(self, data, tokenizer, max_len, is_test=False):\n        self.data = data\n        self.excerpts = self.data.excerpt.tolist()\n        if not is_test:\n            self.targets = self.data.target.tolist()\n            \n        self.tokenizer = tokenizer\n        self.is_test = is_test\n        self.max_len = max_len\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, item):\n        if not self.is_test:\n            excerpt = self.excerpts[item]\n            label = self.targets[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer, self.max_len\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n                'label':torch.tensor(label, dtype=torch.float),\n            }\n        else:\n            excerpt = self.excerpts[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer, self.max_len\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n            }","metadata":{"_uuid":"f34eca01-c56c-4b8f-8c8c-5188ac148878","_cell_guid":"740b0f57-cad8-4758-995b-c2119dc3eac3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-14T18:12:06.401941Z","iopub.execute_input":"2021-07-14T18:12:06.402343Z","iopub.status.idle":"2021-07-14T18:12:06.416425Z","shell.execute_reply.started":"2021-07-14T18:12:06.402307Z","shell.execute_reply":"2021-07-14T18:12:06.41564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%write_and_run scripts/model.py\n\nimport torch\nimport torch.nn as nn\n\n\nclass AttentionHead(nn.Module):\n    def __init__(self, h_size, hidden_dim=512):\n        super().__init__()\n        self.W = nn.Linear(h_size, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        \n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n\nclass CLRPModel(nn.Module):\n    def __init__(self,transformer,config):\n        super(CLRPModel,self).__init__()\n        self.h_size = config.hidden_size\n        self.transformer = transformer\n        self.head = AttentionHead(self.h_size)\n        self.linear = nn.Linear(self.h_size, 1)\n              \n    def forward(self, input_ids, attention_mask):\n        transformer_out = self.transformer(input_ids, attention_mask)\n        x = self.head(transformer_out.last_hidden_state)\n        x = self.linear(x)\n        return x\n\n    \n","metadata":{"_uuid":"024b10c3-9bdc-48a6-be51-cd8f8a064738","_cell_guid":"3fff34f9-07fe-4b91-a284-a06ce99fd43f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-14T18:12:06.421323Z","iopub.execute_input":"2021-07-14T18:12:06.421886Z","iopub.status.idle":"2021-07-14T18:12:06.434457Z","shell.execute_reply.started":"2021-07-14T18:12:06.42185Z","shell.execute_reply":"2021-07-14T18:12:06.433562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_optimizer(model):\n    named_parameters = list(model.named_parameters())    \n    \n    roberta_parameters = named_parameters[:197]    \n    attention_parameters = named_parameters[199:203]\n    regressor_parameters = named_parameters[203:]\n        \n    attention_group = [params for (name, params) in attention_parameters]\n    regressor_group = [params for (name, params) in regressor_parameters]\n\n    parameters = []\n    parameters.append({\"params\": attention_group})\n    parameters.append({\"params\": regressor_group})\n\n    for layer_num, (name, params) in enumerate(roberta_parameters):\n        weight_decay = 0.0 if \"bias\" in name else 0.01\n\n        lr = Config.lr\n\n        if layer_num >= 69:        \n            lr = Config.lr * 2.5\n\n        if layer_num >= 133:\n            lr = Config.lr * 5\n\n        parameters.append({\"params\": params,\n                           \"weight_decay\": weight_decay,\n                           \"lr\": lr})\n\n    return optim.AdamW(parameters)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:12:06.436193Z","iopub.execute_input":"2021-07-14T18:12:06.436578Z","iopub.status.idle":"2021-07-14T18:12:06.448365Z","shell.execute_reply.started":"2021-07-14T18:12:06.436529Z","shell.execute_reply":"2021-07-14T18:12:06.447487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass AvgCounter:\n    def __init__(self):\n        self.reset()\n        \n    def update(self, loss, n_samples):\n        self.loss += loss * n_samples\n        self.n_samples += n_samples\n        \n    def avg(self):\n        return self.loss / self.n_samples\n    \n    def reset(self):\n        self.loss = 0\n        self.n_samples = 0\n\nclass EvaluationScheduler:\n    def __init__(self, evaluation_schedule, penalize_factor=1, max_penalty=8):\n        self.evaluation_schedule = evaluation_schedule\n        self.evaluation_interval = self.evaluation_schedule[0][1]\n        self.last_evaluation_step = 0\n        self.prev_loss = float('inf')\n        self.penalize_factor = penalize_factor\n        self.penalty = 0\n        self.prev_interval = -1\n        self.max_penalty = max_penalty\n\n    def step(self, step):\n        # should we to make evaluation right now\n        if step >= self.last_evaluation_step + self.evaluation_interval:\n            self.last_evaluation_step = step\n            return True\n        else:\n            return False\n        \n            \n    def update_evaluation_interval(self, last_loss):\n        # set up evaluation_interval depending on loss value\n        cur_interval = -1\n        for i, (loss, interval) in enumerate(self.evaluation_schedule[:-1]):\n            if self.evaluation_schedule[i+1][0] < last_loss < loss:\n                self.evaluation_interval = interval\n                cur_interval = i\n                break\n        if last_loss > self.prev_loss and self.prev_interval == cur_interval:\n            self.penalty += self.penalize_factor\n            self.penalty = min(self.penalty, self.max_penalty)\n            self.evaluation_interval += self.penalty\n        else:\n            self.penalty = 0\n            \n        self.prev_loss = last_loss\n        self.prev_interval = cur_interval\n        \n          \n        \ndef make_dataloader(data, tokenizer, is_train=True, is_test=False):\n    dataset = CLRPDataset(data, tokenizer=tokenizer, max_len=Config.max_len,is_test=is_test)\n    if is_train:\n        sampler = RandomSampler(dataset)\n    else:\n        sampler = SequentialSampler(dataset)\n    if is_test:\n        batch_dataloader = DataLoader(dataset, sampler=sampler, batch_size=16, pin_memory=True)\n    else:\n        batch_dataloader = DataLoader(dataset, sampler=sampler, batch_size=Config.batch_size, pin_memory=True)\n\n        \n    return batch_dataloader\n                   \n            \nclass Trainer:\n    def __init__(self, train_dl, val_dl, model, optimizer, scheduler, criterion, model_num):\n        self.train_dl = train_dl\n        self.val_dl = val_dl\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.device = Config.device\n        self.batches_per_epoch = len(self.train_dl)\n        self.criterion = criterion\n        self.model_num = model_num\n                \n    def run(self):\n        record_info = {\n            'train_loss': [],\n            'val_loss': [],\n        }\n        \n        best_val_loss = float('inf')\n        evaluation_scheduler = EvaluationScheduler(Config.eval_schedule)\n        train_loss_counter = AvgCounter()\n        step = 0\n        \n        for epoch in range(Config.epochs):\n            \n#             print(f'{r_}Epoch: {epoch+1}/{Config.epochs}{sr_}')\n#             start_epoch_time = time()\n            \n            for batch_num, batch in enumerate(self.train_dl):\n                train_loss = self.train(batch)\n#                 print(f'{epoch+1}#[{step+1}/{len(self.train_dl)}]: train loss - {train_loss.item()}')\n\n                train_loss_counter.update(train_loss, len(batch))\n                record_info['train_loss'].append((step, train_loss.item()))\n\n                if evaluation_scheduler.step(step):\n                    val_loss = self.evaluate()\n                    \n                    record_info['val_loss'].append((step, val_loss.item()))        \n#                     print(f'\\t\\t{epoch+1}#[{batch_num+1}/{self.batches_per_epoch}]: train loss - {train_loss_counter.avg()} | val loss - {val_loss}',)\n                    train_loss_counter.reset()\n\n                    if val_loss < best_val_loss:\n#                         print(f\"\\t\\t{g_}Val loss decreased from {best_val_loss} to {val_loss}{sr_}\")\n                        best_val_loss = val_loss\n                        torch.save(self.model, models_dir / f'best_model_{self.model_num}.pt')\n                        \n                    evaluation_scheduler.update_evaluation_interval(val_loss.item())\n                        \n\n                step += 1\n#             end_epoch_time = time()\n#             print(f'{bb_}{y_}The epoch took {end_epoch_time - start_epoch_time} sec..{sr_}')\n\n        return record_info, best_val_loss\n            \n\n    def train(self, batch):\n        self.model.train()\n        sent_id, mask, labels = batch['input_ids'].to(self.device), batch['attention_mask'].to(self.device), batch['label'].to(self.device), \n        self.model.zero_grad() \n        preds = self.model(sent_id, mask)\n        train_loss = self.criterion(preds, labels.unsqueeze(1))\n        \n        train_loss.backward()\n        self.optimizer.step()\n        self.scheduler.step()\n        del sent_id, mask, labels\n        return torch.sqrt(train_loss)\n\n    def evaluate(self):\n        self.model.eval()\n        val_loss_counter = AvgCounter()\n\n        for step,batch in enumerate(self.val_dl):\n            sent_id, mask, labels = batch['input_ids'].to(self.device), batch['attention_mask'].to(self.device), batch['label'].to(self.device)\n            with torch.no_grad():\n                preds = self.model(sent_id, mask)\n                loss = self.criterion(preds,labels.unsqueeze(1))\n                val_loss_counter.update(torch.sqrt(loss), len(labels))\n        del sent_id, mask, labels\n        return val_loss_counter.avg()\n    \n    \ndef mse_loss(y_true,y_pred):\n    return nn.functional.mse_loss(y_true,y_pred)","metadata":{"_uuid":"0a678160-5a09-49b1-8f51-fce52d18992e","_cell_guid":"7428183c-f79b-452c-af9f-1b76b4684032","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-07-14T18:12:06.45056Z","iopub.execute_input":"2021-07-14T18:12:06.45104Z","iopub.status.idle":"2021-07-14T18:12:06.478472Z","shell.execute_reply.started":"2021-07-14T18:12:06.451003Z","shell.execute_reply":"2021-07-14T18:12:06.477578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_scores = []\n\nfor model_num in range(1): \n#     print(f'{bb_}{w_}  Model#{model_num+1}  {sr_}')\n\n    tokenizer = AutoTokenizer.from_pretrained(Config.model_name)\n    config = AutoConfig.from_pretrained(Config.pretrained_model_path)\n    config.update({\n            \"hidden_dropout_prob\": 0.0,\n            \"layer_norm_eps\": 1e-7\n            }) \n\n    train_dl = make_dataloader(kfold_df[kfold_df.fold!=model_num], tokenizer)\n    val_dl = make_dataloader(kfold_df[kfold_df.fold==model_num], tokenizer, is_train=False)\n\n#     train_dl = make_dataloader(train_df, tokenizer)\n#     val_dl = make_dataloader(val_df, tokenizer, is_train=False)\n\n#     transformer = AutoModel.from_pretrained(Config.pretrained_model_path, config=config)  \n#     model = CLRPModel(transformer, config)\n    model = torch.load('../input/standard-error-model-1/models/best_model_0.pt')\n    model = model.to(Config.device)\n    optimizer = create_optimizer(model)\n    scheduler = get_cosine_schedule_with_warmup(\n            optimizer,\n            num_training_steps=Config.epochs * len(train_dl),\n            num_warmup_steps=200)  \n\n    criterion = mse_loss\n\n    trainer = Trainer(train_dl, val_dl, model, optimizer, scheduler, criterion, model_num)\n    record_info, best_val_loss = trainer.run()\n    best_scores.append(best_val_loss)    \n    \n    steps, train_losses = list(zip(*record_info['train_loss']))\n#     plt.plot(steps, train_losses, label='train_loss')\n#     steps, val_losses = list(zip(*record_info['val_loss']))\n#     plt.plot(steps, val_losses, label='val_loss')\n#     plt.legend()\n#     plt.show()\n    \n    del model\n    \n# print('Best val losses:', best_scores)\n# print('Avg val loss:', np.array(best_scores).mean())\n# !date '+%A %W %Y %X' > execution_time","metadata":{"_uuid":"5e857d09-968b-4593-a035-c066e1690120","_cell_guid":"24f14f18-7620-41dc-be98-522e589a14d7","jupyter":{"outputs_hidden":false},"collapsed":false,"execution":{"iopub.status.busy":"2021-07-14T18:12:06.480227Z","iopub.execute_input":"2021-07-14T18:12:06.480688Z","iopub.status.idle":"2021-07-14T18:18:59.262407Z","shell.execute_reply.started":"2021-07-14T18:12:06.480653Z","shell.execute_reply":"2021-07-14T18:18:59.261058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(Config.model_name)\n","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.263976Z","iopub.execute_input":"2021-07-14T18:18:59.264365Z","iopub.status.idle":"2021-07-14T18:18:59.442026Z","shell.execute_reply.started":"2021-07-14T18:18:59.264325Z","shell.execute_reply":"2021-07-14T18:18:59.440944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('./models/best_model_0.pt')\nmodel = model.to(Config.device)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.443395Z","iopub.execute_input":"2021-07-14T18:18:59.443936Z","iopub.status.idle":"2021-07-14T18:18:59.767931Z","shell.execute_reply.started":"2021-07-14T18:18:59.443893Z","shell.execute_reply":"2021-07-14T18:18:59.766944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tokenizer = AutoTokenizer.from_pretrained(Config.model_name)\n# config = AutoConfig.from_pretrained(Config.pretrained_model_path)\n# config.update({\n#             \"hidden_dropout_prob\": 0.0,\n#             \"layer_norm_eps\": 1e-7\n#             }) \n# transformer = AutoModel.from_pretrained(Config.pretrained_model_path, config=config)  \n# model = CLRPModel(transformer, config)\n# model = torch.load('./models/best_model_0.pt')\n# model = model.to(Config.device)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.769356Z","iopub.execute_input":"2021-07-14T18:18:59.769906Z","iopub.status.idle":"2021-07-14T18:18:59.7747Z","shell.execute_reply.started":"2021-07-14T18:18:59.769863Z","shell.execute_reply":"2021-07-14T18:18:59.773547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_dl","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.776323Z","iopub.execute_input":"2021-07-14T18:18:59.776725Z","iopub.status.idle":"2021-07-14T18:18:59.788756Z","shell.execute_reply.started":"2021-07-14T18:18:59.776686Z","shell.execute_reply":"2021-07-14T18:18:59.787877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dl = make_dataloader(test_df, tokenizer, is_test=True, is_train=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.791648Z","iopub.execute_input":"2021-07-14T18:18:59.791996Z","iopub.status.idle":"2021-07-14T18:18:59.808244Z","shell.execute_reply.started":"2021-07-14T18:18:59.791966Z","shell.execute_reply":"2021-07-14T18:18:59.807448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.zeros((sent_id.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.810494Z","iopub.execute_input":"2021-07-14T18:18:59.810905Z","iopub.status.idle":"2021-07-14T18:18:59.817819Z","shell.execute_reply.started":"2021-07-14T18:18:59.81087Z","shell.execute_reply":"2021-07-14T18:18:59.816786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_list = list()\nfor step,batch in enumerate(test_dl):\n    sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n    with torch.no_grad():\n        preds = model(sent_id, mask)\n#         print(preds)\n        preds_list.extend(preds.tolist())\n#         loss = self.criterion(preds,labels.unsqueeze(1))\n#         val_loss_counter.update(torch.sqrt(loss), len(labels))\n    del sent_id, mask","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.819394Z","iopub.execute_input":"2021-07-14T18:18:59.819677Z","iopub.status.idle":"2021-07-14T18:18:59.899949Z","shell.execute_reply.started":"2021-07-14T18:18:59.819634Z","shell.execute_reply":"2021-07-14T18:18:59.899004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# torch.reshape(torch.tensor(preds_list), (-1,))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.901367Z","iopub.execute_input":"2021-07-14T18:18:59.901704Z","iopub.status.idle":"2021-07-14T18:18:59.905015Z","shell.execute_reply.started":"2021-07-14T18:18:59.901669Z","shell.execute_reply":"2021-07-14T18:18:59.904216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* [-0.4926],\n*         [-0.5650],\n*         [-0.4469],\n*         [-2.5100],\n*         [-1.8222],\n*         [-1.2933],\n*         [-0.0675]],`\n* ","metadata":{}},{"cell_type":"code","source":"sample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.906349Z","iopub.execute_input":"2021-07-14T18:18:59.906909Z","iopub.status.idle":"2021-07-14T18:18:59.919665Z","shell.execute_reply.started":"2021-07-14T18:18:59.906872Z","shell.execute_reply":"2021-07-14T18:18:59.918847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample['target'] = torch.reshape(torch.tensor(preds_list), (-1,))\nsample.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:18:59.920938Z","iopub.execute_input":"2021-07-14T18:18:59.921308Z","iopub.status.idle":"2021-07-14T18:18:59.933746Z","shell.execute_reply.started":"2021-07-14T18:18:59.921275Z","shell.execute_reply":"2021-07-14T18:18:59.93296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"execution":{"iopub.status.busy":"2021-07-14T18:21:07.065957Z","iopub.execute_input":"2021-07-14T18:21:07.066346Z","iopub.status.idle":"2021-07-14T18:21:07.080445Z","shell.execute_reply.started":"2021-07-14T18:21:07.066316Z","shell.execute_reply":"2021-07-14T18:21:07.079462Z"},"trusted":true},"execution_count":null,"outputs":[]}]}