{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"https://www.deepl.com/translator を用いて翻訳しました.","metadata":{}},{"cell_type":"markdown","source":"**BERT**は、現在、様々な自然言語処理（NLP）タスクを解決するために広く使用されている最もホットなモデルアーキテクチャの一つです。そのため、このモデルについての深い知識を得ることは非常に重要です。BERTに関するブログやチュートリアルなどをいくつか見つけることができます。しかし、完全なモデルを理解するための完全なパッケージを見つけることは非常に稀です。このノートでは、いくつかの人気ブログ記事とチュートリアルを統合して、完全なパッケージを作ろうとしています。 このノートで、BERTの理解が深まることを願っています。これらのブログポストとチュートリアルのリンクは、[References](#8) に記載されている.\n\n\n\n<h2><center>Let's Start</center></h2>  \n\n今日はbertについてお話ししましょう。\n\n$\\;\\;\\;\\;\\;\\;\\;\\;$ \n<center><img src=\"https://i.gr-assets.com/images/S/compressed.photo.goodreads.com/books/1557559619l/5674402.jpg\"/ width=\"300\" height=\"300\" ></center>\n\n$\\;\\;\\;\\;\\;\\;\\;\\;$\n\nいやいや、Google BERTの話をしようと思っています。","metadata":{}},{"cell_type":"markdown","source":"<a class=\"anchor\" id=\"0.1\"></a>\n#  Table of Contents\ni.  [BERT, What is BERT !](#1)\n\nii.  [High Level Overview of BERT](#2)\n\niii.  [How BERT comes and why it becomes so popular ?](#3)\n\n   - [Limitation of Transformer](#3.1)\n   - [Transfer Learning of NLP](#3.2)\n   - [Fully Replacement of LSTM](#3.3)\n\n\niv. [What is inside the BERT ?](#4)\n\n   - [From Word to Vectors](#4.1)\n   - [Encoder from the Transformer](#4.2) \n   - [Maksed Language Modeling](#4.3)\n   - [Next Sentence Prediction ](#4.4)\n\n\nv. [BERT as Transfer Learning in NLP](#5)\n\n\nvi. [BERT for Different NLP tasks](#6)\n\n   - [Sentence Pair Classification Task](#6.1)\n   - [Single Sentence Classfication Task](#6.2)\n   - [Question Answering Task](#6.3)\n   - [Single Sentence Tagging Task](#6.4)\n\n\nvii. [Applications](#7)\n\n\nviii. [References](#8) \n\n","metadata":{}},{"cell_type":"markdown","source":"# 1. BERT, What is BERT ! <a class=\"anchor\" id=\"1\"></a>\n\n**BERT** (**B**idirectional **E**ncoder **R**epresentations from **T**ransformers) は、2018年にGoogle AI Languageの研究者が発表した自然言語処理（NLP）のすごい研究です。ニューラル機械翻訳、質問応答（SQuAD v1.1）、文節ペア分類タスク（MNLI）、文節分析、テキスト要約など、さまざまなNLPタスクにおける最先端の結果を提示し、機械学習コミュニティに一石を投じました。\nBERTの略語から、次の特徴のようなものがわかります。\n\n   1. Bi-directional (双方向性)\n   2. Using Encoder Representation (エンコーダの表現)\n   3. Transformer based architecture \n\nつまり、基本的にBERTの主要な技術革新は、一般的な注目モデルであるTransformerの双方向トレーニングを言語モデリングに適用することです。これは、テキストシーケンスを左から右に見たり、左から右、右から左のトレーニングを組み合わせたりした従来の取り組みとは対照的です。この論文の結果は、双方向に学習された言語モデルは、単一方向の言語モデルに比べて、言語の文脈や流れをより深く理解できることを示しています。この論文では、Masked Language Modelling（MLM）と名付けられた新しい技術を詳細に説明しています。この技術は、これまで不可能だったモデルの双方向トレーニングを可能にするものです。この資料では、その詳細を後ほどご紹介します。\n\n\n\n$\\;\\;\\;\\;\\;\\;$ \n\n<center><img src = \"data:image/jpeg;base64,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\" width = 350 height = 450 /><\\center>\n\n$\\;\\;\\;\\;\\;\\;$ \n\n\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"# 2. High Level Overview of BERT <a class=\"anchor\" id=\"2\"></a>\n\nここで、BERT* アーキテクチャの概要を説明します。これは、トランスフォーマー*をベースにしたモデル・アーキテクチャであり、NLPタスクを扱う上で新しい時代を切り開くものです。前回のセッションでは、*Transformer*について学びました。トランスフォーマーは、*Encoder-Decoder*モデル・アーキテクチャで、*positional encoding*、*self-attention*、*multi-head attention*、また、*Residual connection*を使用します。\n\n$\\;\\;\\;\\;\\;\\;$ \n\n<center><img src = \"https://glassboxmedicine.files.wordpress.com/2019/08/figure1modified.png?w=451&h=647\" width = 400 height = 400 /> <\\center>\n\n$\\;\\;\\;\\;\\;\\;$ \n\nBERTは、Transformerの構造のうち、「Encoder」の部分のみを使用し、「Decoder」の部分は使用しません。\nBERTもTransformerと同様、postional encoding、self attention、multi head attention、Residual Connectionを採用しています。\n  つまり、BERTは基本的に「**Stacking of Encoders**」であり、エンコーダはTransformerのものを使用しています。\n\n$\\;\\;\\;\\;\\;\\;$ \n\n<center><img src = \"http://jalammar.github.io/images/bert-encoders-input.png\" width = 700 height = 400 /><\\center>\n\n$\\;\\;\\;\\;\\;\\;$ \n\nThere are two types of BERT.\n \n 1.$BERT$ $base$\n    \n 2.$BERT$ $large$\n\n\nbert_baseでは、12個のエンコーダを重ねて使用しています。一方、bert_largeでは24個のエンコーダを重ねて使用します。また、フィードフォワードネットワークとはタイプ（隠れニューロンの数）が異なります。bert_baseでは768個のニューロンがフィードフォワードネットワークに使用されているのに対し、bert_largeでは1024個の隠れユニットが使用されています。\n\n$\\;\\;\\;\\;\\;\\;$ \n\n<center> <img src = \"http://jalammar.github.io/images/bert-base-bert-large-encoders.png\" width = 600 height = 350 /> <\\center>\n    \n$\\;\\;\\;\\;\\;\\;$ \n    \n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"# 3. How BERT comes and why it becomes so popular ? <a class=\"anchor\" id=\"3\"></a>\n\n現在では、BERTは、さまざまなNLPタスクの解決に取り組むための最初の選択肢となっています。なぜBERTはNLPコミュニティでそれほど人気があるのでしょうか？それは、SOTA（State Of The Art）モデルであるということだけではなく、その背景にはいくつかの理由があります。その理由は、大きく3つに分けられます。\n        \n   1. Limitations of Transformer \n   2. Transfer Learning in NLP\n   3. Fully replacement of LSTM\n \n\n### 1. Limitations of Transformer <a class=\"anchor\" id=\"3.1\"></a>\n\n間違いなく、NLPにおけるトランスフォーマーの発明は、NLPコミュニティにおける最も強力で効率的な研究の一つです。NLPタスクを別の方法で記述することで、NLPモデルを独立して学習することができます。その結果、*並列化*が可能となり、LSTM/GRUベースのモデルよりも学習プロセスがはるかに速くなります。LSTM/GRUモデルは、機械翻訳などのさまざまなタスクで実現されているため、LSTMの代替品として考えている関係者もいるようです。これは、TransformerがLSTMよりも長期的な依存関係を扱うことができるという事実によって、さらに悪化しました。\n\n\n機械翻訳のようないくつかのNLPタスクを解決することができるエンコーダ-デコーダアーキテクチャのためにうまく設計されています。しかし、エンコーダ-デコーダアーキテクチャを使用しないタスクは、**テキスト分類、文ペアタスク**などのように、もっとたくさんあります。このようなタスクでは、「トランスフォーマ」をどのように使えばよいのでしょうか。ここにトランスフォーマーの限界があります。この制限のために、LSTMに置き換えることができません。\n\n\n### 2.  Transfer Learning in NLP <a class=\"anchor\" id=\"3.2\"></a>\n\n転移学習(Transfer Learning)とは、事前に学習したモデルを新しい問題に再利用することです。比較的少ないデータで深いニューラルネットワークを学習できるため、現在、深層学習で非常に人気があります。ほとんどの現実世界の問題は、そのような複雑なモデルを訓練するための何百万ものラベル付きデータポイントを持っていないのが普通なので、これはデータサイエンスの分野で非常に有用です。\n\n転移学習は、学習プロセスの高速化だけでなく、効率的なモデルの構築にも利用されています。コンピュータビジョンのタスクでは、転移学習が広く使われています。膨大な量の画像データを用いてロバストなモデルを学習し、最適な重みを見つけ出します。そして、そのモデルは、事前に学習されたモデルとして、下流のコンピュータビジョンタスクに使用することができます。そのため、いくつかのNNレイヤーを追加し、事前に学習したモデルを微調整することで、その下流のタスクに対して効率的なモデルを簡単に構築することができます。コンピュータビジョンにおける事前学習済みモデルには、VGG-16、ResNet、ImageNet、LeNet、Efficient netなどがあります。\n\nコンピュータビジョンでは、何百万ものデータを使ってよく訓練されたモデルがあり、それらを使って物体認識タスクを簡単に行うことができます。ロバストで非常に正確なモデルを20行のコードで構築することができます。事前に学習されたモデルをインポートして、いくつかのレイヤーを微調整するだけで、望みの結果を得ることができます。\n\n\n$\\;\\;\\;\\;\\;\\;$ \n\n<center><img src = \"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAQ4AAAC7CAMAAACjH4DlAAABFFBMVEX///87ZZnk49ivrK20srP19fXn5tvLycnr6uHo7fb39/MAAABJbJrw7+jt7OXw8OvN1uO7yNkvXpXa4e12ja72+f12jquWqcOBl7S+ydno7vLg5u1XdqLK1N5de6SquctKbJaYqcWarMFqhq2MoLswX5bn5uba2NlphKlyjrOst9Dc29spV4x+lrMAR4USToqbmJnNy8K/vb68ubJnYmSLiImxv9LX1szBvrZIQUOmo6RuaWuRjY9BaZzU2+UARYV9eXWempWtqqIWCA4qISVdV1k7MzZrZmhRSkw/ODsAOn+gnpd2cW2Df3sRAAYjGBwSQnaut8JvhrK8xuCQosV9mcGdttbQ1umgoqxiboaBkKempq3Qm5lGAAAbMElEQVR4nO2dC2OiPLrHQyt1WHnPAsIAgljloiiK2oqtFdo6baeznU7PzrRvd/d8/+9xknDxrkxbp76z/meqEC6Bn8mTkIQ8AOy0006/UsLcwoI1uD4bsGrjxGohxT54tQB+vZqET/uEWvIJ2oiup4a/xRpoBmEAQwDWByUvXCs4CrxWw2m1/FJ0kopPEESNgeeQKHws12qZdbSUl8M9jDg+w20RDDpL0221aAbGq07GWzIJmiacApDVVsvlBbwvkInNAZhWUfYcUWYqPuPRJr4upYXv0tCA5OTxPowLWAd4bnhrhVYeUBwtU0rJUcM7EX1Zlousw3iaWwAFwmcVxeNouJHV8A55J4pOdGRKdAR4Sp2h8mWxjuINb1ZpQYCKLPuSzALerSgUoykOjlN2fxUO+EO7MBFUaLjE4d9fMk30BXEYHEoICQ7OxT8VwuHXwkNrEQ4VfbLonlUR0Hp4YhWiEF18Bt6NUj6BUAug4IrheuUQxcuG8YZY6BI6jIqu7R1xaBW8ymAsKHXYkoNuI8Lh/9nCybyleM50Pp/AIRmyG22k4O6aI6FDHKcYhmkhqqYaH4niVUv4tEyIBWZBwWWj7eEv8C44KLSALrDigxCHDnSukOAw4Y+WR9dN6dL0KSp+qVKRZYhDcGSej4M1AzgigiPqeiUMUhyiBAOcyA4B8RDlkiheEcWLcIxv3zFYz2MNB/wyhTgISW8ZeI0Nk2iIA2iEMMYBDaGCcNDYuigsy4bmpGLWarWK7Ei2y4PDcnxmiS+0BBWCcJiyHccmcjCGVmSk4ZHGZLwoLUAcJT8+Bef7Pk37vxyH33Sx3Swhw2GoCQ6g0hM4gORSZIvScEHBEr7J4VNEmYV7RBy1pBSxpSIXHclOlA1iKx9Z5dl4JWR4IQ6Pi/cNMwvzDpmFxomcMGn4a8CgGAdQVXhHMQ5gO4FLVeKbk8KCI7EdOrKeRHJitgzXOZmug3xrwtr49VqcoWBmoZsT8eYxDqWVj7a/nylVWjBDsy6LsgC0eAkOgTa5MQ5Q45y8EBUMVGTyEhyCI45LjaaDU0qJg4Y3zAcgIBAVosRgowywxVBaLDo2jNfGOIAWm9p3LFlKsHSjw5QetArlGAfkMZE6IA/4E7ItVHdiuFp0U0nJIkOrILeasJikbLjosOj86JxEPYwL8WkpwEDsAVOqw3jrsBSO4mVaBYxDMFVU1xPfo97xDwaERr3my/8Iy3tAS9B+8NHdCgSsg4FSbM8O86ii2iKcVlzA4OISeC2AjIsAArrFOS01D5R/oETfRFUPPTwX4zqOi0h4jus75x7OdhrNnsfxNoGJi3u+5fiuU2hhHOz5ZhFMSRGiBwRBKcTPCUIBhiRrBUGgxs8Q4ULAFsdPH3hJwDUuhQS4cqkkIcJ4F/gty5EVCVhGSOKlxmcqhNsLDAtTLSWMz7zTTjvttNNOO+20zfI+ppSx/ly/gXimkE7++nNtlV7Wrs5TBTmVCFZef7Ytkiyt32dePFWyS+tVr3ue/x4dGS9W0Y2yt+GixgICPuhJBM0k2ysLj4I4ZPgglEYao6zqOXp3KUZtQhrhYB4VJwiKIHDhQ7QtJu1QoHbOLDoHxMECjk8jqTnbBLxVYlzT5MxQ6JsgcGNT1PthOArgy7gDACVy3V2c9TEOGvX4pVBgr+xZfF+VOULTx1Kj1IEbhARXrhmAdzgF9V+IS2nEOAxaSyFd135hG/VPSuTMydXYdvAaEBTZ8QkO8JKDcojh0stoJDjyS7bPSl2/yztpBoccWVKBds9lWgSgxdQqpRZqbDJaSwvJGEcgoL5oeo18n/AJb9m53lflaRzjYjBQcAMbyu1Rr38AlinBUdBTRsssLqLeXTM4XqZJHLKaRrSvqj9hUP/2JkoR0dviEHRQT5sN9PQVsr/tvYlSxPT2OFhYtU0hg+AlMeX5MY4DpPAz+d5D/8dhe7Pbx8spcYgbwMHLSjqlfaJDOA46nc5J/6Df73c6/f4eXD7poNU99A8FncDvvT20+agDw476J32kI7xT5+D9cHykQIFJI4KRl9vnCUEcB/2jvVFneDe6uzw5ujvqHx1ddkaXo6OLTufg6wiGHd13vnY6exejYefuaHh5uTe6v7v/cAS/70YXo8v3xAGrslIlnVINwMKZ5e5kNDrq343g/9HRZf/kaDQ66Vwe3Y0O4B9EANncjfY6l3edEUTQQWuXkNpo1L88ubtLiWMTtgPhoNYfhUWn2WlsOxZpzk5MqN8Pv9Nmlk3hSNujlx7Hq4RNaYqS9i+BA3x4C/09RUR/DRy/TOKySvrP6M1wZDO/XtUVOORlbd0Wib/IjeIYWCmPeks19idW5h7ww5riw6fc/eBbbgiO22D/GlQfcjlw07VyWQgmA/+yU2d8Ixxkdulum1R34jcWOcKekEY4IY/rDGhfWDlw1gaZY/DQBlVwmrmBJEA7l7EebqZO+EY4rOrS3d5I3dPTa7B/27U+Z4aDLAkuTk+7oDqRJkWT4CYUNw5iHMeDB4zjcyOHgm6v7vEhw09Xt9OxrMEhUIHs1ctQdU8OpmskvxZHZgCz+xX8Yb+SXy/aKO8PMtM4OGKy5Y6OGgcxjqucFaaOCMftDU5W1sO3/elYVuKgdNflaM3mpSavazTnuvaEwf7FONCFD2+HZPYMounClf05HJP7Jx0LOLN87oHhMfh6Aa56ZBd86R4fo4t+uB3mpnmswqG4/HRXgqDozphHWhzk7CKJv8m5rSuFcYBTMGz34O2dgQU4pkuWuNX/GOEgc1XyJndjAes09wmcdsmHATT/XwDoTeeWVTjoBWUVryWL6XD0rGNykMked0/J9nH27MwCn7NnGXBjne5ne4PP2evqaSozjHGQ8H66gCQbKLrVOBbUO1aVsJHmcXyMcQSLRmcKrTGtJDBYgWNofSY/n2W/NC6+Do6zPWuAcHS7141eIzsc3DaOrfZg1QXGyuzPhqzG8TLNtndM4DDsRQdoSVPpGIfYXI7jOnOWafcGw0y7OvjcvYCpowfOMhfZ4ZD83Nsfdo+zyDCuV4QjkyUHIIxs3pSmOc9qrcDBLWx+9xIKYxx1t7bxWliIo9G+vh/0wtz1a3HkXYFivIph6xpqMdZ026h4DEW5cXHrO1AcBz8Igtt4d2WUOqwrstsLISAcxaR5rhC//fQq8VR9MY5AI0x0t6izM5RponsniFrUReVPVnmcTQ/0DXFks1+t6tchqlNiHP/rJIIX8fpYluHwXGKZzKhLj46bxUq26SzsD39LhTjIr0Owb93j5IFxTFVDXx/LEhwFmApMh5tnwaFfIXy1bWw7So7cQAMKxEWqVIxCkLQoovXwI1wTSvAowzCidfjfEMMtpekLnS9ZEI5/FhPZb5NZpm1HPqx3eBxhSoo3x4Nj8zDa0MgeJiep5FHJUmSicQBJeLTKFL3H8vcfzA9VM3TuSeXo7+VH/IuqnHCYZ0W4I/p5nbLKcW7Jg1mUI9SZ3uDFODZtSiMcdQ4nPcmcpmGi99Y4IhwzcThxmghHqCJ8zPkTPuPE5gTiMHWb13X1UZAJQzd/gGfVVOt1vUwXNJpW9ZqOWf+pERzj+ZymOjqzFsdMvaO8QRylEEdzBgcH66nCOhy84bGyDJHoXoJDlcGzrmn18tP3Z0rVy7Yqyc8ylecEjfZNk67RkDJNaOj1a1Oqq4zkaGBKCY6bK/LlOMib25Xbl+Mw+aA0n1m8QDdX45CTNx8FTUhwlOtl/fGxrKrlAqU9PfoqA555tg5xPNmcK+Vp4Jh/0opmEiYn8S7zyC3BQX7LRTgGK3EsrotXc7mVNSRsSv1xJX0idSw3pUtwhK8CPwWCEgTFIE8BMSyCijCz0Lb34/HpR7n8DA2TXS7rdt2GUUAcnGsEgUew8AfgRFbjeD4sJ7TonsjwK0kdZHyjc7Zj+hFu8UCDzOoHpMohIU8+s0Q4Ko65Qs4KHGyFLQYKRVEKNCEVJcLxvVz2HvlHqlAowG36k2Rr+hNNExCHSpUUWzJhFiQIFzRtj+fK9RBHBrXpwWfRbzcTOKrx88BqHMXWTNGUUiV5QeoIjJVSluIoKhPPkgpAr0gjHI911WaeJVkJytL3p0e7bP94tstU2YE4gC45f8KCPa86XL1cZp9MmjbrhA6tA8RxDXHkriYyS25JZhFNQmqO+9VrhLOIh7WuQaFE6z54nMEBhCCfzwdz4zhgcBBEwXM4kO34J6iwcYlSyst5tMwU2Tqj6QVQLyuKxzzz6pNdz+f1EAe0FqpdYzhCoijb0WgdlTJcYKLhN1b4h/JHkjqOr8EyHLONg/MPXVbuYR2PAoUzS20KB+vCem/ypn8iz4X1dLe4CodXiSEyJSXGUa6rNANkoyAwzwKjPtYZqgBL3u/IdpiEr9K6YyqSTTuUAdMJ4TD207KSJdE8jvGQHFqlFz5HNZK0tUJcXZ3FISMzOv9MiytmHLMcRwnWu+JxuXCRCXF4ugRLVuCVKUDVy4/qkwy3yWWe5gT1WSRg8UoLpoq+iXzFgUXtYWhKF+EY9pbgmO1YaC661UaKR++A0ZXpgvbFOCjdtr1o0INo27g9DaYOn1Z/PAOZDygqgFVUg/eegzpTV2FmITiRcnyabRIcBWu8psxqTsEwzSU4rKSoXFOy8ODlejQqNhoMBVnw+IFVdmH+W5hZYPCKzCKwoBAP/IBH4yII4oA/tlx+9sr1+iNfLv+gPP1HWX2WUcnCcaICK6E0/acK84lqFmHcLOQyM3QvSR3Jwnxmmdx/SadkNlUbt+LVbeCxYxyCLDPJG71joWBGXmFKgRj8M8ZRKhaxcYc46HpQ901ahhWP76r6Pa88SirxTGkws0i2JMP8YRNNH5qRR03kXQIumMtwJFqNY7GqaWwHvlFVKU/gSKHDiWWMA2MQqHFvTPTadcB4MCXoj5xa11VbfVT157xX10xYVYU4Kobb9Dg1TzB+SUdVMaYC6yB55gWmdP01W59u1u+EZRia/FM4ZlvSi3wFPc/PP+LzjOe6Liw8HJjVHEKDVS5CtX3OgaEF1XUd1Yab4JoBax6OJtVQodZa+AhHXl9kL6ywrXm17Xi9vHqhpqDCJZ3mOxYWjut/o4sLcVSr9/e9r2F63zSOwLaJV+HYpOK20mtA3rcxhU10LMyIp0BzS3EMUN2UvLqw9tuDfVRTbW8eh+jDimHKfadwbHxAQ/b29gJCqFbJBkA9tMe3t1mQfevWsHk1XzRyMFXX0ZtrMtZN4dA/fgzf9vq48l0wezr2/ffQ5AVsIrMA1E2fUlv24uSGcPxVNYNjroAnx9XRtIMo/sqafYSrh983n67hYx8JznK56vUQXN+DQS43tL4B0HvIoVFEqJTKvMcFb1ZzD/hhO/5D4yZL5sDwC2lZjVwmB7K5KiyRchAHbinYzw3Im2+/X3opc2bzMW69fHy0oxbdq94DCW/+CtcE7nP74AJRQGPEeqcXKHDw7ermPUaBbliyi94nnmscvGof92DqeMA4EIUxjuNMA6Ca3af3qSVsWIyNp6OMX+okODxc58Ea3EIcvVOYWTCFbK6BMgsZZRbr5ks791vymFLRDZvDrh4eoO0gwXEul8U4QBuZ0lyuN0RjkUHmgQTtq9/PdsxIrs0EjAtacspU/PYksHbz7O2000477bTTTjvttNNOO+20006vkcc3JakpMc2mEU8uFQ4frEStDgW+AP8IlQVCU2o2ecWAn00eGE1JjBsmRHSo3EThoUciPHpGaTYlNDg1HvfmiaBUAVLUi8Lg4JJGqOIWdYKxhsHZhug55aYT9dw6eAx0hQuvUjkvCI7KVs5ZwbUNw6BMvQy/AKGXtVY0AA27rREJFI5BaLipk3ENyeQEQEQj3wwVNHVgR2NhWBee2zQrsqe25saxvaeQbyqWQ+8z4PThubgHt+IQkbO0AnZslQ/dmcTTZgI0YV89mtUxxJGM+cm7+KW7APl6Ug1AO+EoUUMDTRvY0fsM2MVLCKq0VbMhonkwEQ7A47GTRB1PTVhRdcwD4QgdfM3gKCFXWGEKmsFhh7OjYhx1DdBP4Sv1EQ6dxk2hEIexlZMwJzh8bALc0B1YRQUq8n4HcQDa9JAnE9cLAgaYZYZhApw62KnUQaMBqSSaVVRhEAmMQzfgaZUWmoAiwiEJ2PUNPNbZyhkhQxxenca2A6Zu7A4MzR6LQhAOIDpuHaZtx3VblI/GchPAb3pSK7qfEAd6DxX5+ULes3wR4SjVNQf76GEQjwhHE1Aok7BOlNoKWzaiIMShurijOEBO/9ANIRwCrYY40OvHlenMQquOGpcsU5kF+3aCNwsCR3PLQujBiWnVxziAAq0JwoGLoVrLdV8zzPithXGYwMcZXDcfJUmHN47nFhaIWoQDFhzR5ce2g5Vjd4nTOCrukyQ9uR7KLNivEXbPKZ+zYoIDKK4hO8DHL1cJAk5LW6PIdijnMrpOCXUbq3aIAxQI1aHwm0/Jrzk2pXw8pmoKB4eKY0MnEA7BrUQ4YMGqjnHAwkc1scMtpKCVatK/X6TYlFbgry2F9xS0CiEOQBGOgKsKqj2HQ4gmYQEa+pkjHF44OQS0P3loSuXzfIQDbtDHOADjmPA4Ew11DJyFEyi8l5DhxDehqoXz6EUHWqpEpSDlFgTTtAmuIITzk3Om7/sE4JBFiHbXON9Xyw4MN2UiSvgSnT+HhoN3BC56dQlWLz7qQI/sBHYPyLdUST3fJssBU0YBOY2ECwWWieuHiqzEb4AEBSCUDFTSsthWyDJycwfwq7bFcCcG+b3Lo2A2YKNKeIHF5xRYJXkplwWwnGbijIEPzVeMStrBsDvttNNOm5KQT6n/jkETH+00E2BDOdv0XLAxpZ7P9ycmSP8Li6dk4jCNfJrYpqrwhoRnrUinSnGjV7IVwjiMVC58aI3fpifHjQjj8Kk0KqA39n9zRVO8rJmlIhZnGNvr0ugtFOEQ6ymrH7Xfu/4R4ygCmU3jMk+rsL9zAZPgEAiv5KVRZXaI8++kMQ4NACZIIVllissNyN9foLlz/PGzSuPi56dxsFo5lURtaVXlRX4VZm7mjxecYiM40k6oVPLmX78LFXvdiP8Opt33TPjviQMW41jquGOBx44N4jD8NC6vNE1bMisn9thzdDQ66PRPDjqjk6OD/qiP3PLAz5OT0R4M73dGnYNRB/lj6Rz1DxbiODg5OYJ79I/gf+zX56RzdHIHF05GHfh1ALeiM5x0Oncwrs3hkNI2PEqLn+hCB0Ynn/vHJ5d3ozt0Tx9GveHe6EP/utO57PevkYOa0Yej0ejga3806izBMTq5hIIE8Xe/jz6O4IlGH4YXl0fwlJejzn1/dHk56qd18ZNK8zjYVOkDTcW0gAjG0Ye/WX8E/49QMoG/4WivMxr1RxDHSf9uDwZ/GMEU1IGbT5bg6Oyd7J0c9fswBfVhUujDjz5KWDDFnHRODuASTBlwWwd+bhaHyKTyuSkAe0F+mfPYs9gKrLcdK63HL7MdGEfaQ5fh+H1KltfiAH/8z0/rj9lz/HzNZTP1jjfAsU16wdPE74yjHvfdFiUDmn0J4ilVSuMa04Lrfzsc5Kum41g4RUx3zUHd1RfoueGgMrZl8EWgtJoAHOpq8sjlLfBp/XY4Xve68qIp37rr3o9vzPDI4xmCJ2ecxTzCPm9RdQRw6Mmx02WvtaDj/81wNBopD1uiBRNHrJ9LYmZ+tRo3N1EnzCDCOb5QJ0+zQKNND009rMCks2gYxNvheOVUBwsS/pq8AOZxmP7kHG56NKU9nsy16PK+BjSVQ4P2fLO+kMYaHAIr8hpNcI7DmbTKG6VJAtuIY2p6Pi8cXwOzhVELanzAnhcOSzVkOwR6yXCylThYl+bLnswE+XzAyF5Z0loT86JuPY56PMQElSxoVuJKUCoWUCEDhCV+MlbhYM7n2jUoYnyercfxglbuVTiIBe0fytiFz9bjeIFW4Fjo0QjoydTwkziEN8dR3DYc4kLbyyZTqE3ikEXrjXHw4pbhMENLJFDh1GlUmBUFN6bAT7R3MO7H6RbghkU2QJUEjarVABaJppshGxZOQt1wdQZfZqb5gHfFGAcZTUhC4n/WxDQk/5p2K61tEEfe9SpNjebGTnIcQrVFVo07aiV97MZRJ7jp/tvjs/ZF99gC3d7wzOoNspmr6v5146xXBWfZ7m13/6o6U4v9tzMtWKX8GG0a7Ld73eF9pkpeN27J2+rnJNn8x52sdnHE7Bzab4dDRDW8GS8cyDMCDNbDdCLNVACn3h+43h/cWGfWwNpvfwG319lM+zpz3OhlM+AYZNunmd71jA+0f3PczK2ZdFQ0DAZnvWz74hQA5D5tOLhKEtZ/3BmEm8KBp3BfIjPsuZbocWMhrKpN12vaoJvpfq0Cq5vJDLLdTLbb6F5ke0P4dHKWzcKAxkwV/F+lKXkap8Z7ZEG327UsmCayXbI7bFSTQ/9vaiZEamO2A3k04ui5xIECudgNx6QpZdzDV84rNGs3m7SwPaZUhnmiBJAXhBkaeaAg/y340MmSxX7rgtYQtqhkgTjQg/CchydU4ecJExfBkzgKv3c1DKWOYN6jEYHG3fsLcPzmtVLkZ8E09HkfPrRBE38VHPWoytAb9rLZXtsCgyzIIu+rxz3QrgLskHHCHywS70nLcBALLGkY+BfBET/gD64uqsPj+xtwOwCDa3B2k/kMbrrYHS2aY683Mbs+U9flBThY11khd2txJO4MkRKPhl+6YNi2crAyBFOGhV0t3J5hJ87W1WkvN1UDKnnCPA6BwUOfAmZGQRiMq+dbiGNh4yDG0b662g9xZD+hoNtvoYtv8uHTdH2QgZWo+WpYAblFNOactEwGT+N47XTpCxpG5zxNrNsjrxHT05ZGdUOUOs4+WeB4ANpfyRxq1T0d5DDt3qebL7M1pgU48mhGVGduHOlk8ExL+n6VfLmsRe3w1mDNUYPVKbIetwBedaE5HVyBzKf2N0gm17uCtqOLfN+0c13y6mrmOF8jZnEoqJLOzTlYy08Ez3Y7NbKv0ML7IdcctKYiXI+fG7oW8qGWQQ+UKKLssIuCunCZhEnEms+UYgAW4ZhPHRPBW98L9/IhjhVarU3jwO6/5loHw+Bw4u2tx/EKCdTv10f7Gglmxd7hGKtYNDxg7HAkYm1P2+FIVPDYHY4pGV6+ucORqGgY6g7HpHaZZUqlsbOC1SL+K14l3Wmn9bKgulmyYVnoWTBLZhob94e3zcre7mfOsoPTNkn2voKbxhn55b+ZRzZz1R2Cm+EZINv3meveMHt98d7X9I6yrGqjTWZJmCQG1SxATTTrGy93+h30/2dOlLU7EhAFAAAAAElFTkSuQmCC\" width = 400 height = 300 /></center>\n\n$\\;\\;\\;\\;\\;\\;$ \n\nNLPの場合、プロセスはより複雑です。なぜなら、NLPでは、異なるテキストデータには異なる文脈が含まれているからです。文脈言語モデリングとは、文の文脈を意味します（例えば、*abide by*と*abide in*は、どちらも主要な単語*abide*を使用しているにもかかわらず、全く異なる意味を持っています）。より良い文脈言語モデリングを定義できれば、伝達学習を用いてより良いモデルを構築することができます。多くの研究の結果、文脈的言語モデルは **ELMo** や **ULMFiT** のようにいくつか作られ、人気を博している。ELMo**（**E**mbeddings from **L**anguage **Mo**dels）と**ULMFiT**（**U**niversal **L**anguage **M**odel **Fi**ne-**T**uning）はどちらもLSTMベースである。ELMoでは2層の双方向LSTMが、ULMFitでは3層のLSTMが使われている。\n\n$\\;\\;\\;\\;\\;\\;$ \n\n<center><img src = \"https://5b0988e595225.cdn.sohucs.com/images/20180529/0b0036d9bba548bfab470d4ca3d750fe.jpg\" width = 500 height = 350 /></center>\n\n$\\;\\;\\;\\;\\;\\;$ \n\n\nHere $E_1$, $E_2$, ... $E_N$ is the word embedding and $T_1$, $T_2$, ... $T_N$ is the output of the model\n\n$\\;\\;$ \n\n<center><img src = \"https://miro.medium.com/max/2128/1*ko2Ut74J_oMxF4jSo1VnCg.png\" width = 400 height = 300 /></center>\n\n$\\;\\;\\;\\;\\;\\;$ \n\nしかし、LSTMの代わりにtransformerを使って言語モデリングを構築できたらどうでしょうか。トランスフォーマはLSTMよりもはるかに高速であるため、より多くのデータを学習することができ、それによってはるかに優れた言語モデルを定義することができます。基本的には、トランスフォーマーを用いた言語モデルが必要であり、それは伝達学習の事前学習モデルとしても利用できる。\n\nBERTの前に、OpenAIはGPT-2（**G**enerative **P**re-**T**raining）モデルを導入し、前節で述べた問題を解決することができます。GPT-2モデルはトランスフォーマーベースです。GPT-2のアーキテクチャを見てみると、GPT-2は12層のデコーダを積層しています（BERTとは異なり、デコーダのみを使用しています）。このモデルでは、トランスのエンコーダはキャンセルされています。このモデルではデコーダのみを使用しているため、デコーダ・アーキテクチャの**Encoder - Decoder Attention**ブロックもキャンセルされています。残りの部分は同じです。\n\n$\\;\\;\\;\\;\\;\\;$ \n\n<center><img src = \"http://jalammar.github.io/images/openai-transformer-language-modeling.png\" width = 500 height = 600 />\n    </center>\n\n$\\;\\;\\;\\;\\;\\;$\n\n変圧器の中のデコーダは、学習のために次の単語を予測するために**マスクされた自己注意**を使用することがすでにわかっています。そのため、デコーダは常にシフトした右の単語を予測語として与えます。これはフォワードLSTM（左から右へ）のように動作します。GPT-2では、トランスフォーマーを使って、任意のセンテンスの次の単語を自己回帰的に予測することができるので、トランスフォーマーを使った言語モデリングが可能です。 \n\n\n$\\;\\;\\;\\;\\;\\;$ \n\n\nHere $E_1$, $E_2$, ... $E_N$ is the word embedding, $T_1$, $T_2$, ... $T_N$ is the output of the model and **Trm** is Transformer Decoder\n\n$\\;\\;\\;\\;\\;\\;$ \n\n\n<center><img src = \"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQzqbw7d8rNA-FnXKcPPR0hiFC9RFJVi4FkiVSUiETmOIrtQqFo7Uk6cPx8_k1qZ-spuqI&usqp=CAU\" width = 300 height = 200 /> </center>\n\n$\\;\\;\\;\\;\\;\\;$\n\nGPT-2はtransformerを使った伝達学習の事前学習モデルとして使用されます。また、トランスフォーマーを様々なNLPタスクで使用できるようになります。GPT-2 ( Tansformer ) を様々なNLPタスクで使用する方法の全体像は以下の通りです。GPT-2の詳細については、以下をご覧ください [their blogs. ](https://openai.com/blog/tags/gpt-2/) \n\n\n$\\;\\;\\;\\;\\;\\;$ \n\n\n<center><img src = \"https://www.topbots.com/wp-content/uploads/2019/04/cover_GPT_web.jpg\" width = 550 height = 450 /></center>\n\n\n\n$\\;\\;\\;\\;\\;\\;$ \n","metadata":{}},{"cell_type":"markdown","source":"### 3.  Fully Replacement of LSTM <a class=\"anchor\" id=\"3.3\"></a>\n\n前節では、OpenAI GPT-2がトランスフォーマーを使って、多くのNLPタスクでLSTMを置き換えることができることを見てきました。では、実際にGPT-2はLSTMを完全に置き換えることができるのか、という重要な疑問が生じます。答えは **NO** です。なぜなら、LSTMを使用している間に、双方向性を利用して、よりロバストで文脈に沿った言語モデリングを構築することができるからです。**双方向性LSTM**は、言語モデリングにおいてより良い文脈を理解します。GPT-2は左から右への順方向のみを使用するので、場合によっては、 **双方向性LSTM** は言語の文脈をよりよく理解して、よりよく機能します。そのため、LSTMを完全に置き換えることはできませんでした。さて、ここで一つの疑問が出てきます。**トランスフォーマーを使って**双方向性**を追加したモデルを構築することは可能でしょうか？**もし可能であれば、LSTMはトランスフォーマーによって完全に置き換えられることになります。\n\nそこで、以下のようなモデルを構築する必要があります。\n\n   1. **Is capable to use tranformer in all kinds of NLP task ?**\n   2. **Can be used as a pre trained model for the downstream task while using transfer learning in NLP ?**\n   3. **Is bi-directional and understands the language form left to right and right to left ?**\n   4. **Understands deeper and better context of the language**\n     \n\n\n<h2><center>Then BERT said,</center></h2>  \n\n\n $\\;\\;\\;\\;\\;\\;$\n \n <center><img src = \"data:image/jpeg;base64,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\" width = 450 height = 450 /></center>\n \n $\\;\\;\\;\\;\\;\\;$ \n \n [Back to Table of Contents](#0.1)\n \n \n ","metadata":{}},{"cell_type":"markdown","source":"# 4. What is inside the BERT ? <a class=\"anchor\" id=\"4\"></a>\n\n**BERT**の基本的な概要はすでに見たとおりです。基本的に、BERTは**Encoders**の積み重ねです。さて、そろそろなぜエンコーダだけを使うのかを説明しましょう。それは、BERTをあらゆる種類のタスクに使用するためです。もう1つの理由は、OpenAI GPT-2がデコーダのスタッキングを使用していることを見たからです。また、OpenAI GPT-2では、デコーダを重ねて使用しているため、自動回帰モデル（次の単語の予測）でモデルを構築しています。そのため、一方向性（左から右）の変換アーキテクチャを定義することができました。双方向トランスのアーキテクチャを構築するために、BERT は、デコーダの代わりにトランスからエン コーダを使用する。そのため、BERTは、左から右だけでなく、右から左のモデルも構築しています。BERTの簡単な概要は以下の通りです :-\n\n\n $\\;\\;\\;\\;\\;\\;$\n \n<center> <img src = \"https://miro.medium.com/max/745/1*-oQKmzvHrzqeSQEnM9f_kQ.png\" width = 450 height = 450 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\nさて、BERTの中身はどうなっているのでしょうか？それは、単にエンコーダを積み重ねただけではなく、さらに多くの機能を備えています。BERTには、マスクド・ランゲージ・モデリングや次文予測も導入されています。BERTには大きく分けて4つの部分があります。\n\n \n          1. From Word to Vectors\n          2. The Encoders from the transformer\n          3. Masked Language Modeling (MLM)\n          4. Next Sentence Prediction (NSP)\n      \n \nそろそろ、これらの部分についての説明をしたいと思います。まず最初に、BERTは一度に2つの文を入力として受け取ることを知っておく必要があります。それらを文Aと文Bとします。","metadata":{}},{"cell_type":"markdown","source":"## 1. From Word to Vectors <a class=\"anchor\" id=\"4.1\"></a>\n\n $\\;\\;\\;\\;\\;\\;$\n \n<center><img src = \"https://miro.medium.com/max/1250/1*9DD12JPwj1pLY6yUEOv35A.png\" width = 900 height = 800 /> </center>\n<center><img src = \"https://miro.medium.com/max/1250/1*Y1MDr4WgzYp4eZaBOuJIYw.png\" width = 900 height = 800 /> </center>\n \n- **Tokenization** は、トークンと呼ばれる断片に切り刻む作業であり、同時に句読点などの特定の文字を捨てることになります。\n\n$\\;\\;\\;$\n\n- **Using wordpieces** (e.g. playing -> play + ##ing) を単語の代わりに使用しています。これは、語彙のサイズを小さくするのに有効で、各単語で利用可能なデータ量を増やすことができます。\n$\\;\\;\\;$\n\n\n- **Numericalization** は、各トークンを、コーパスの語彙の中の一意の整数にマッピングすることを目的としています。\n\n$\\;\\;\\;$\n\n\n- **Token embedding** は、シーケンスの各単語の埋め込み（すなわち、実数のベクトル）を取得するタスクである。シーケンスの各単語は、学習時にモデルが学習するemb_dim次元のベクトルにマッピングされます。これは、各トークンに対するベクトルのルックアップと考えることができます。これらのベクトルの要素は、モデルのパラメータとして扱われ、他の重みと同様にバックプロパゲーションによって最適化されます。\n\n$\\;\\;\\;$\n\n- **Padding** は、バッチ内の入力配列を同じ長さにするために使用されました。つまり、'<pad>' トークンを追加することで、いくつかのシーケンスの長さを増やします。\n\n$\\;\\;\\;$\n\n\n- **Positional encoding** 位置エンコーディングは、モデルがトークンの順序や相対的な位置関係を学習するのに役立つように設計されています。RNN、GRU、LSTMなどの伝統的なリカレントユニットを使用していないため、これは言語ベースのタスクには特に重要です。\n\n 直感的には、特定の単語の位置に応じて、表現された意味を変更できるようにすることが目的です。単語の完全な表現を変えるのではなく、トークンエンベッディングにあらかじめ決められた（学習されていない）正弦波関数を使って[-1,1]の間の数字を加えることで、その位置をエンコードするために少し修正したいのです。エンコーダーの残りの部分では、単語がどの位置にあるかによって（同じ単語であっても）単語の表現が少しずつ異なります。\n\nエンコーダは、ある単語が特定の位置にある一方で、同じ配列の中で他の単語が他の特定の位置にあるという事実を利用できなければなりません。つまり、絶対的な位置だけでなく、相対的な位置も理解できるようにしたいのです。\n \n Now, the function use for the positional encoding is given below:\n \n  $\\;\\;\\;\\;\\;\\;$\n<center> <img src = \"https://miro.medium.com/max/625/1*OsmkGAkon5IDTwZJ1ORwPA.png\" width = 550 height = 550 /> </center>\n  $\\;\\;\\;\\;\\;\\;$\n  \n  ここで、なぜこの関数は正弦関数を使っているのか、なぜこの関数は単一のsinまたはcos関数を使わないのか、そして最後に、なぜこのエンコーディングは連結ではなくエンコーディングで加算されているのか、といったいくつかの疑問が生じます。まず第一に、何かを符号化するときには、二値化が第一の選択肢です。しかし、NNモデルの重みやバイアスなどはすべて[-1, 1]の範囲であることがわかっています。ですから、もしバイナリエンコーディングを使用したいのであれば、浮動小数点の連続した値をエンコーディングする必要があります。 明らかに、浮動小数点値のバイナリエンコーディングは、はるかに複雑で、非常にスペースの無駄です。このような状況を解決するために、彼らは正弦波関数を使用しました。  \n  \n  また、この関数ではsinとcosの組み合わせを使用していますが、これはバイナリエンコーディングを使用した場合、代替ビットと同等の働きをするからです。単一のsinまたは単一のcosではこのようなことはできません。例えば、**pos = 0**と**index = 0,1**の場合、この関数はそれぞれ**0,1**を返します。最後に、この位置関係の符号化は、特徴の良いソースを提供し、より小さいdimベクトルを格納するために、連結ではなく、埋め込み表現でまとめられます。(連結すると、より高次元のベクトルを格納する必要があります)\n  \n   $\\;\\;\\;\\;\\;\\;$\n  \n- **Sentence embedding** の技術は、文章全体とその意味情報をベクトルとして表現します。これにより、機械は文章全体の文脈や意図、その他のニュアンスを理解することができます。機械は、どの単語がどの文に属しているかを単純に認識します。文章Aまたは文章Bを示すマーカーが各トークンに追加されます。これにより、モデルはセンテンスを区別することができます。\n  \n$\\;\\;\\;\\;\\;\\;$\n \n<h3><center>After the first step, we done our embedding and encoding step just like</center></h3>\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://www.researchgate.net/profile/Akbar-Karimi-4/publication/338934952/figure/fig2/AS:853247933808640@1580441568270/BERT-word-embedding-layer-Devlin-et-al-2018.ppm\" width = 550 height = 550 /></center>\n \n $\\;\\;\\;\\;\\;\\;$\n    \n    \n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"## 2. The Encoders from the transformer <a class=\"anchor\" id=\"4.2\"></a>\n\n変圧器のアーキテクチャは、エンコーダ-デコーダ形式に基づいています。エンコーダは、4つの部分（自己注目、マルチヘッド注目、残差接続と正規化、フィードフォワードネットワーク）で構成されています。変圧器アーキテクチャのエンコーダは次のようになります。\n\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://www.adityaagrawal.net/blog/assets/dnn/bert_encoder.png\" width = 200 height = 250 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\nトランスのエンコーダ部には、4つの測定部があることがエンコーダの構造からわかりました。トランスのエンコーダアーキテクチャの全体像を理解するには、以下の項目を理解する必要があります。\n\n        i.   Attention Score Measurement\n        ii.  Self Attention and its intuition\n        iii. Multi Head Attention/ Self Attention\n        iv.  Add & Norm\n         v.  Feed Forward Network\n        \n これらのトピックはすでにカバーされています。それらのトピックについて簡単に振り返ってみましょう。\n \n - **i. Attention Score Measurement**\n  \n $\\;\\;\\;\\;\\;$\n\n注意メカニズムは、入力データの関連する特徴を動的に強調することを可能にする神経アーキテクチャの一部であり、NLPでは通常、一連のテキスト要素である。これは、生の入力に直接適用することもできるし、その高レベルの表現に適用することもできる。アテンションスコアの測定にはいくつかの機能があります（例：加算アテンションスコア、ドットプロダクトアテンションスコア）。最も一般的なのは、クエリ、キー、値のベクトルを生成して、ドット積アテンションスコアを使用する方法です。このようなアテンションスコアの測定に使用される関数を以下に示します。\n\n\n<center><img src = \"https://miro.medium.com/max/3512/1*EphJAS1hwU9NNmUQMxv92w.png\" width = 500 height = 600 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\n- **ii.  Self Attention and its intuition**\n\n*自己言及（Self-attention）*は、*内言及（Intra-attention）*とも呼ばれ、同じ配列の表現を計算するために、1つの配列の異なる位置を関連付ける注目メカニズムです。\n\n   - エンコーダの各入力ベクトルから3つのベクトルを作成する\n   - 各単語に対して、Query ベクトル、Key ベクトル、Value ベクトルを作成します。\n   - これらのベクトルは、エンベッディングに、学習過程で学習した3つのマトリックスを掛け合わせて作成されます。\n   \n   $\\;\\;\\;$\n   \n <center><img src = \"https://lh5.googleusercontent.com/-PLfe9_p8Y4dySneLd-hNCtPkXiOK3oKh_TG_oZV-TMVEXXkfBe7_tX2DnFWAcVNQGpDlehwJJDlyH88F9-RMtCOszNYfj3ixhsuwcC1avfMDHS7yXTLgQaoYgRN5ak1K34qiz8lv78\" width = 500 height = 600 /></center>\n   \n  $\\;\\;\\;$\n  \n各単語の埋め込みに対して3つのベクトル（$Q$,$K$,$V$）を生成する必要があるのは、各単語の注目度スコアを、その単語が属する入力配列のすべての単語で求める必要があるからです。\n各単語の埋め込みに対して、3つの重みメトリック（$W_Q$,$W_K$,$W_V$）を掛けて、3つのベクトル（$Q$,$K$,$V$）を生成します。これらの指標はバックプロパゲーションによりモデルで学習されます。 \n \n $\\;\\;\\;$\n \n <center><img src = \"https://jalammar.github.io/images/t/self-attention-matrix-calculation.png\" width = 400 height = 400 /></center>\n \n $\\;\\;\\;$\n \n\nこれらの新しいベクトルは、エンベッディング・ベクトルよりも次元が小さいことに注意してください。エンベッディングとエンコーダーの入出力ベクトルの次元数が512であるのに対し、これらのベクトルの次元数は64です。\nエンコーダの各入力ベクトルから3つのベクトルを作成する\n \n**Why is dimensionality 64?**\n\nAs we must have :\n\n   - Output’s dimension is [length of input sequences] x [dimension of embeddings — 512]\n\n   - We use 8 heads during the Multi-head Self-Attention process. The output size of a given self-attention vector is [length of input sequences] x [64]. So the concatenated vector resulting from all Multi-head Self-Attention process would be [length of input sequences] x ([64] x [8]) = [length of input sequences] x ([512])\n\n\nSo, we will get a 64 dimension query, key, and value vector for each word. An example is given below:\n\n  \n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://miro.medium.com/max/3000/1*yw2PxgzsjNNKE-UaVoZESQ.png\" width = 1000 height = 1000 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\n  \n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://miro.medium.com/max/3000/1*R9NE3rNKGO1ThN2jhZYBRg.png\" width = 600 height = 600 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\n- **iii. Multi Head Attention**\n\nマルチヘッドアテンションとは、1つの単語に対して、複数の単語に連続して注意を払い続けることです。マルチヘッドアテンションは、アテンションメカニズムを複数回並行して実行するアテンションメカニズムのモジュールです。直感的には、複数の注意ヘッドは、シーケンスの部分に異なる方法で注意を払うことができます(例えば、長期的な依存関係と短期的な依存関係).\n\n**Why do we need multi head attention ?**\n\nセルフアテンションを行っていると、他の単語とのアテンションスコアよりも、その単語単体でのアテンションが非常に高くなることが観察されます。これは、モデルが文脈を理解する上で障害となる可能性があります。そこで、自己注目度を複数回測定することで、この問題を少しでも減らすことができます。\n\n  \n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://miro.medium.com/max/1270/1*LpDpZojgoKTPBBt8wdC4nQ.png\" width = 500 height = 500 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\n  \n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://jalammar.github.io/images/t/transformer_multi-headed_self-attention-recap.png\" width = 900 height = 900 /></center>\n\n$\\;\\;\\;\\;\\;\\;$","metadata":{}},{"cell_type":"markdown","source":"\n<h3><center>Till now the whole picture is like that</center></h3>.  \n\n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://miro.medium.com/max/3000/1*tbb9rywOeo3kBtJ85ZdPFA.png\" width = 900 height = 900 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\n\n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://miro.medium.com/max/3000/1*mllxBXok93AsQ_m43D3v_g.png\" width = 900 height = 900 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\n\n- **iv. Add and Norm** \n\nここでAddは残差接続を、normはレイヤーの正規化を意味します。また、この層ではオーバーフィッティングを抑えるためにドロップアウトを使用しています。\n\n$\\;\\;$\n\n$$\n\\text{ Layer Norm }(x+\\text{Dropout}(\\text{ Sublayer}(x)))\n$$\n\n$\\;\\;\\;\\;\\;\\;$\n\n次の例を見てみましょう。\n\n\n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"http://jalammar.github.io/images/t/encoder_with_tensors.png\" width = 500 height = 500 /> </center>\n\n$\\;\\;\\;\\;\\;\\;$\n\nHere, Self attention is the sublayer and X = [x1, x2] , Z = [z1, z2]\n\n\nLayernormでは、層ごと、学習点ごとに、平均0、分散1となるように入力を変更します（さらに2つのパラメータを追加します）。層の正規化の式は\n\n$$\n\\mu^{l}=\\frac{1}{H} \\sum_{i=1}^{H} a_{i}^{l}\n$$\n\n$$\\quad h_{i}=f\\left(\\frac{g_{i}}{\\sigma_{i}}\\left(a_{i}-\\mu_{i}\\right)+b_{i}\\right)$$\n\n$$\\quad \\sigma^{l}=\\sqrt{ \\frac{1}{H} \\sum_{i=1}^{H}\\left(a_{i}^{l}-\\mu^{l}\\right)^{2} }$$\n\n\nここで$l$は層、$mu$は平均、$sigma$は分散を表しています。\n\n$\\;\\;\\;\\;\\;\\;$\n\n- **v. Feed Forward Network**\n\n注意サブレイヤーに加えて、エンコーダとデコーダの各レイヤーには、完全に接続されたフィードフォワードネットワークが含まれており、このネットワークは各ポジションに別々に、かつ同一に適用されます。これは、ReLU活性化を挟んだ2つの線形変換で構成されており、次の式で簡略化できます。\n\n$\\;\\;$\n\n$$\n\\operatorname{FFN}(x)=\\max \\left(0, x W_{1}+b_{1}\\right) W_{2}+b_{2}\n$$\n\n\n$\\;\\;\\;\\;\\;\\;$\n\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"## 3. Masked Language Modeling (MLM) <a class=\"anchor\" id=\"4.3\"></a>\n\nBERT の最大の特徴の一つは、Masked Language Modeling（MLM）です。マスクド言語モデルは、入力からトークンの一部をランダムにマスクし、その目的は、その文脈のみに基づいて、マスクされた単語の元の語彙IDを予測することです。左から右への言語モデルの事前学習とは異なり、MLMの目的では、左と右の文脈を融合した表現が可能であり、これにより、深層の双方向トランスフォーマーを事前学習することができます。\n\n\n単語列を BERT に入力する前に、各列の単語の 15%が [MASK] トークンに置き換えられます。次に、モデルは、シーケンス内の他の（マスクされていない）単語によって提供される文脈に基づ いて、マスクされた単語の元の値を予測しようとします。技術的には、出力される単語の予測には以下が必要です。\n\n     1. エンコーダ出力の上に、分類層を追加する。\n     2. 出力ベクトルに埋め込み行列を掛けて、語彙次元に変換する。\n     3. softmaxを用いて、語彙に含まれる各単語の確率を計算する。\n \n$\\;\\;\\;\\;\\;\\;$\n\n\n\n<center><img src = \"https://miro.medium.com/max/3300/0*ViwaI3Vvbnd-CJSQ.png\" width = 600 height = 600 /></center>\n\n$\\;\\;\\;\\;\\;\\;$\n\nここで、$w_1$,...$w_5$は、単語の埋め込みであり、$O_1$,...$O_5$は、BERTの出力である。BERTは、GELU（Gaussian Error Linear Unit）活性化を使用します。\n\n$$\n\\operatorname{GELU}(x):=x \\mathbb{P}(X \\leq x)=x \\Phi(x)=0.5 x\\left(1+\\operatorname{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)\n$$\n\nBERT 損失関数は、マスキングされた値の予測のみを考慮し、マスキングされていない単語の予測を 無視します。その結果、このモデルは方向性のあるモデルよりも収束が遅くなりますが、この特性はコンテキスト認識の向上によって相殺されます。\n\nThe overview of MLM in BERT looks like\n\n$\\;\\;\\;$\n<center><img src = \"http://jalammar.github.io/images/BERT-language-modeling-masked-lm.png\" width = 600 height = 600 /></center>\n\n$\\;\\;\\;$\n\nSome important notes about are the following\n\n- **It is true bi-directional** \n  \n  BERTのMLM以前の双方向とは、単に左から右、右から左への単語表現を生成し、その2つの方向性の表現を単純に加算または連結することを意味していました。例えば、双方向のLSTMを使用する場合、1つのLSTMは左から右に向かって単語の表現を生成し、もう1つのLSTMは右から左に向かって単語の表現を生成します。その後、生成された単語の表現を連結します。しかし、LSTMは言語に関する文脈をあまり理解しません。しかし、MLMの場合は、テキスト内の単語をマスクするので、両側からモデルを学習する必要がありません。また、マスクされた単語はテキスト内にあるので、BERTは他の単語からマスクされた単語への方向を自動的に追跡します。\n  ","metadata":{}},{"cell_type":"code","source":"import os\nfrom IPython.display import Image\n#Image(filename=\"kaggle/input/bert-img/mlm_2.jpg\", width= 500, height=500)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-22T13:33:01.784595Z","iopub.execute_input":"2021-07-22T13:33:01.785014Z","iopub.status.idle":"2021-07-22T13:33:01.789411Z","shell.execute_reply.started":"2021-07-22T13:33:01.784977Z","shell.execute_reply":"2021-07-22T13:33:01.788381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- **Semi Supervised Training**\n\n  BERT は、入力テキストからランダムに単語をマスキングし、マスキングされた単語を予測して 学習するため、ラベル付きの教師付きデータを使用する必要はありません。したがって、BERT の学習には、教師なしデータと教師ありデータの両方を使用することができます。半教師付きデータは BERT の学習に使用できるため、学習用の膨大なデータを得ることができます。これにより、よりロバストでコンテクストなモデルを構築することができます。\n  \n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"## 4. Next Sentence Prediction (NSP) <a class=\"anchor\" id=\"4.4\"></a>\n\nOpenAIトランスフォーマーがさまざまなタスクを処理するために行っている入力変換を振り返ってみると、いくつかのタスクでは、モデルが2つの文章について何かインテリジェントなことを言う必要があることに気づくでしょう（例えば、それらは単にお互いの言い換えバージョンなのか？入力として wikipedia の項目があり、別の入力としてその項目に関する質問がある場合、その質問に答えることができますか？)\n\nBERT が複数の文の間の関係をより適切に処理できるようにするために、事前訓練プロセスには追加 の作業(2つの文（AおよびB）が与えられた場合、BはAに続く文である可能性が高いか、またはそうでないか)が含まれています。\n\n\nBERT の訓練過程において、モデルは、入力として文のペアを受け取り、ペアの 2 番目の文が元の 文書における後続の文であるかどうかを予測することを学習します。訓練中、入力の 50%は、2 番目の文が元の文書の後続文であるペアであり、残りの 50%は、コーパスからのランダムな文が 2 番目の文として選択される。ランダムな文は、最初の文から切り離されていることが前提です。\n\n学習時にモデルが2つの文を区別できるように、モデルに入力する前に入力を以下のように処理します。\n\n- 最初の文の最初に[CLS]トークンが挿入され、各文の最後に[SEP]トークンが挿入されます。\n- 各トークンには文節Aまたは文節Bを示す文の埋め込みが追加されます。センテンスエンベッディングは、トークンエンベッディングと同様の概念で、語彙数は2です。\n- 位置エンベッディングは、シーケンス内の位置を示すために、各トークンに追加されます。位置埋め込みの概念と実装については、Transformerの論文で紹介されています。\n\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://www.researchgate.net/profile/Akbar-Karimi-4/publication/338934952/figure/fig2/AS:853247933808640@1580441568270/BERT-word-embedding-layer-Devlin-et-al-2018.ppm\" width = 550 height = 550 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n \n 2つ目の文章が1つ目の文章と本当につながっているかどうかを予測するために、以下のステップが実行されます。\n- 入力シーケンス全体がTransformerモデルを通過します。(入力ベクトルのサイズは、BERT Baseでは各単語に対して768である）（**なぜ768なのか**以下に回答を示す\n- 各ポジションは、サイズhidden_size（BERT Baseでは768）のベクトルを出力します。\n- CLS]トークンの出力は、単純な分類層（重みとバイアスの学習済み行列）を使用して、2×1の形状のベクトルに変換されます。\n- ソフトマックスを用いて、IsNextSequence（IsNextラベルとNotNextラベル）の確率を計算します。\n\nFor example,\n\n            Input = [CLS] the man went to [MASK] store [SEP] he bought a gallon [MASK] milk [SEP]\n            Label = IsNext\n            Input = [CLS] the man [MASK] to the store [SEP] penguin [MASK] are flight ##less birds [SEP]\n            Label = NotNext\n\nBERT モデルを学習する際には、Masked LM と Next Sentence Prediction が一緒に学習され、2 つの戦略の複合損失関数を最小化することを目的としています。さて、この場合のBERTモデル全体は次のようになります。\n\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"http://jalammar.github.io/images/bert-next-sentence-prediction.png\" width = 750 height = 750 /></center>\n \n $\\;\\;\\;\\;\\;\\;$\n \n \n BERT_baseモデルでは、なぜ1つの単語の入力と出力が764次元のベクトルを持っているのでしょうか？\n \n BERT_baseモデルでは、マルチヘッドアテンションに12個のアテンションヘッドを使用しています。BERT_baseモデルでは、マルチヘッドアテンションに12個のアテンションヘッドを使用しています。各ヘッドには64次元のキー、クエリ、値のベクトルが含まれており、これにより1つの単語に対して自己アテンションスコアを持つ64個のダイムスベクトルを得ることができます。\n         \n         So, the input and output vector of a single token/word will be = 12 X 64 = 768  dimesion embedding  \n\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"# 5. BERT as Transfer Learning in NLP <a class=\"anchor\" id=\"5\"></a>\n\nBERT はラベルのない文のペアを取り、MLM は言語の文脈をよく理解するため、BERT は膨大な データセットに対して学習することができ、これを下層タスクの事前学習モデルとして使用することができます。事前学習の手順は、言語モデルの事前学習に関する既存の文献にほぼ従っている。BERT は、事前訓練用コーパスとして、BooksCorpus（8 億語）および英語版 Wikipedia（25 億語）を使用しています。長い連続した配列を抽出するためには、10 億語ベンチマークのようなシャッフルされた文レベルのコー パスではなく、文書レベルのコーパスを使用することが重要です。\n\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://miro.medium.com/max/875/1*-j96GYxnl4f44tD8dJTpng.png\" width = 650 height = 650 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n\n上の図は、BERT の全体的な事前トレーニングと微調整の手順を示しています。出力層を除いて、事前学習と微調整の両方で同じアーキテクチャが使用されています。また、異なるダウンストリーム・タスクのモデルを初期化するために、同じ事前トレーニング済みモデル・パラメータが使用されます。\n ファインチューニングでは、すべてのパラメータが微調整されます。\n [CLS]は、すべての入力例の前に追加される特別な記号であり、[SEP]は、特別なセパレータートーク ンです（例：質問／回答の分離）。 \nBERT は、教師なしデータに対して訓練されているが、BERT は、教師ありタスクで微調整することができます。\n\n下流の教師付きタスク（例えば、質問応答タスク）でBERTを事前学習モデルとして使用した場合、全体像は次のようになります。\n\n\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://www.determined.ai/assets/images/posts/nlp_transfer_learning.png\" width = 750 height = 750 /></center>\n \n $\\;\\;\\;\\;\\;\\;$\n\n画像分類にBERTを使用したい場合、BERTの伝達学習プロセスは次のようになります。\n\n\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"http://jalammar.github.io/images/BERT-classification-spam.png\" width = 750 height = 750 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n\n\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"# 6. BERT for Different NLP tasks <a class=\"anchor\" id=\"6\"></a>\n\n変形器を直接、異なるタスクに使用することはできないが、BERTは可能であるとすでに述べました。どのようにしてBERTを様々なNLPタスクに使うことができるのでしょうか。そのいくつかを以下に紹介します。\n\n\n- **a. Sentence Pair Classification task** <a class=\"anchor\" id=\"6.1\"></a>\n\n    文対分類では、データセットの各例には、適切なターゲット変数とともに2つの文があります。例：文の類似性、含意関係など。文章ペアはすべての分類サブタスクでサポートされています。MNLI、QQP、SWAGなど、文ペア分類タスクに関する多くのデータセットがあります。このタスクでBERTを微調整することができます。\n    \n    この課題を解決するために、BERT は、2 つの文（文 1 と文 2）を入力します。両方の文は [SEP] トークンで区切られており、これらの文の前に [CLS] トークンが挿入されています。ここで、これらの文を事前に訓練されたBERTに渡すと、[CLS]トークンは、これらの文を分類することで確率を与えます。入力に対してラベル出力が与えられているので、ラベル出力による損失を決定することで、BERTを使用して文ペア分類モデルを訓練することができます。\n    \n    \n\n$\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://media.geeksforgeeks.org/wp-content/uploads/20200422012400/Single-Sentence-Classification-Task.png\" width = 400 height = 400 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n \nまた、より正確な結果を得るために、今回の下流のタスクを解決するための[CLS]トークンの上部にあるラベルで損失を計算する前に、多層パーセプトロン（MLP）（別名：Dense Layers）を使用することができます。トップにMLPを使うと、次のようになります。:\n\n$\\;\\;\\;\\;\\;\\;$\n <center> <img src = \"https://d2l.ai/_images/bert-two-seqs.svg\" width = 400 height = 400 /> </center>\n $\\;\\;\\;\\;\\;\\;$\n \n \n [Back to Table of Contents](#0.1)\n \n \n \n - **b. Single Sentence Classification task** <a class=\"anchor\" id=\"6.2\"></a>\n \n     一文分類タスクでは、一文が与えられ、その一文を分類するように求められます。例えば、電子メールの本文が与えられた場合、その電子メールがスパムであるかどうかを予測する必要があります。SST-2やCoLAは、この種のタスクのためのデータセットです。\n     \n     さて、この種の課題に BERT を使用するために、BERT 入力に 1 つの文を渡します。入力の最初（文の前）には、[CLS]が挿入されています。ここで、文を事前に訓練されたBERTに渡すと、[CLS]トークンは、文を分類することで確率を与えます。入力に対するラベル出力が与えられているので、ラベル出力による損失を決定することで、BERTを使用して単文分類モデルを訓練することができます。\n     \n     \n$\\;\\;\\;\\;\\;\\;$\n\n<center> <img src = \"https://media.geeksforgeeks.org/wp-content/uploads/20200422012400/Single-Sentence-Classification-Task.png\" width = 400 height = 400 /> </center>\n\n$\\;\\;\\;\\;\\;\\;$\n\nまた、より正確な結果を得るために、[CLS]トークンの上部にあるラベルで損失を計算する前に、多層パーセプトロン(MLP)(別名Dense Layers)を使用することができます。トップにMLPを使用すると、次のようになります。\n\n$\\;\\;\\;\\;\\;\\;$\n <center> <img src = \"https://d2l.ai/_images/bert-one-seq.svg\" width = 400 height = 400 /> </center>\n $\\;\\;\\;\\;\\;\\;$\n \n \n [Back to Table of Contents](#0.1)\n \n \n \n","metadata":{}},{"cell_type":"markdown","source":" \n - **c.  Question Answering Task** <a class=\"anchor\" id=\"6.3\"></a>\n \n     質問応答タスクについて、BERT は、入力質問と通路を単一のパックされたシーケンスとして受け取る。入力エンベッディングは、トークンエンベッディングとセグメントエンベッディングの合計です。\n \n $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://miro.medium.com/max/680/1*gwu3JjZ3hM08dIUziSJ3yg.png\" width = 400 height = 400 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n \n \n 質問応答システム用に BERT を微調整するために、開始ベクトルおよび終了ベクトルを導入します。各単語が開始単語である確率は、通路シーケンスにおける単語の最終的な埋め込みと開始ベ クトルとの間のドット積を取り、その後、すべての単語に対するソフトマックスを行うことにより計算します。最も高い確率の値を持つ単語が考慮されます。同様のプロセスを経て、エンドワードを見つけます。\n   \n   \n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"http://www.mccormickml.com/assets/BERT/SQuAD/end_token_classification.png\" width = 500 height = 500 /></center>\n \n $\\;\\;\\;\\;\\;\\;$\n \n また、ソフトマックスを適用する前に、このダウンストラム・タスクのラベルを使って損失を計算する前に、多層パーセプトロン（MLP）（別名：密な層）を適用することもできます。しかし、MLPやsoftmaxは、文章中の全ての単語のトークンに適用されます。このタスクにMLPを適用した場合、全体像は次のようになります。\n    \n $\\;\\;\\;\\;\\;\\;$\n\n<center> <img src = \"https://d2l.ai/_images/bert-qa.svg\" width = 400 height = 400 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n \n [Back to Table of Contents](#0.1)\n \n \n    \n - **d. Single Sentence Tagging Task** <a class=\"anchor\" id=\"6.4\"></a>\n \n     名前付き実体認識などの単文タグ付けタスク（文が与えられ、その文から任意の人や物の名前を見つけたい場合）では、入力のすべての単語に対してタグを予測する必要があります。すべての入力トークンの最終的な隠れた状態（変換器の出力）は、分類層に与えられ、すべてのトークンの予測を得ます。WordPieceトークナイザーは、いくつかの単語をサブワードに分割するので、単語の最初のトークンのみの予測が考慮されます。\n \n $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://yashuseth.files.wordpress.com/2019/06/fig4.png\" width = 400 height = 400 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n \nまた、今回のダウンストラム課題では、ラベルによる損失を計算する前にMLP（別名Dense Layers）を使用することで、より良い結果を得ることができます。このタスクでは、[CLS]を除く各単語に対してMLPを適用します。このタスクにMLPを適用した場合、全体像は以下のようになります。\n \n  $\\;\\;\\;\\;\\;\\;$\n\n<center><img src = \"https://d2l.ai/_images/bert-tagging.svg\" width = 400 height = 400 /> </center>\n \n $\\;\\;\\;\\;\\;\\;$\n \n [Back to Table of Contents](#0.1)\n \n ","metadata":{}},{"cell_type":"markdown","source":"# 7. Applications <a class=\"anchor\" id=\"7\"></a>\n\n私たちは、BERTの魔法を見てきました。BERTは間違いなく、自然言語処理のための機械学習の使用における画期的なモデルです。BERTは、間違いなく自然言語処理のための機械学習の使用におけるブレイクスルーです。BERTが親しみやすく、迅速な微調整が可能であるという事実は、将来的に幅広い実用的なアプリケーションを可能にするでしょう。この要約では、過度な技術的詳細に溺れないようにしながら、論文の主旨を説明することを試みました。\n\nBERT の異なるバリエーションは、現在、さまざまな実生活のプロジェクトで使用されています。ドメイン／アプリケーション固有のコーパスで訓練されたモデルは、事前に訓練されたモデルである。ドメイン固有のコーパスで学習したモデルは、BERT の微調整と比較して、それらのドメ インの NER などの下流の NLP 作業で微調整する際に、より優れた性能を発揮することが示されている。以下に、異なる実世界の NLP 問題を使用したいくつかのバリエーションを示します。\n\nwww.DeepL.com/Translator（無料版）で翻訳しました。\n\n   - RoBERta (robustly optimized BERT for solving different tasks)\n   - BioBERT (use for biomedical text)\n   - SciBERT (use for scientific publications)\n   - ClinicalBERT (use for clinical notes)\n   - G-BERT (use for medical/diagnostic code representation and recommendation)\n   - M-BERT from 104 languages for zero-shot cross-lingual model transfer (task-specific annotations in one language is used to fine-tune a model for evaluation in another language)\n   - ERNIE (knowledge graph) + ERNIE (2) incorporates knowledge into pre-training but by masking entities and phrases using KG.\n   - TransBERT — unsupervised, followed by two supervised steps, for a story ending prediction task\n   - videoBERT (a model that jointly learns video and language representation learning) by representing video frames as special descriptor tokens along with text for pretraining. This is used for video captioning.\n   - DocBERT (use for Document classification)\n   - PatentBERT (Patent classification)\n   \n\n \n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"\n# 8. References  <a class=\"anchor\" id=\"8\"></a>\n\n- BERT Paper - https://arxiv.org/pdf/1810.04805.pdf\n- OpenAI GPT2 - https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf\n- ULMFit paper - https://arxiv.org/abs/1801.06146\n- ELMo    - https://arxiv.org/abs/1802.05365\n- Transformer - https://arxiv.org/abs/1706.03762\n- Bidreactional RNN/LSTM - https://ieeexplore.ieee.org/document/650093\n- WordPieces Embedding - https://arxiv.org/abs/1609.08144\n- More About Transfromer - https://jalammar.github.io/illustrated-transformer/\n- Bert Explanined - https://towardsdatascience.com/bert-explained-state-of-the-art-language-model-for-nlp-f8b21a9b6270\n- Bert with hugging face - https://towardsdatascience.com/fine-tuning-a-bert-model-with-transformers-c8e49c4e008b\n- Understanding Word Embedding - https://towardsdatascience.com/from-pre-trained-word-embeddings-to-pre-trained-language-models-focus-on-bert-343815627598\n- Illustred bert - http://jalammar.github.io/illustrated-bert/\n- Inside Bert - https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1\n- Deconstructing Bert  - https://towardsdatascience.com/deconstructing-bert-distilling-6-patterns-from-100-million-parameters-b49113672f77\n- BERT in question answering - https://medium.com/saarthi-ai/build-a-smart-question-answering-system-with-fine-tuned-bert-b586e4cfa5f5\n- Fine Tuning BERT - https://d2l.ai/chapter_natural-language-processing-applications/finetuning-bert.html\n  \n  \n  \n  \n  [Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"markdown","source":"# 感想\n本で転移学習付近を主に勉強したいと思いました(NLPもですが).","metadata":{}},{"cell_type":"markdown","source":"<h1><center>Thanks for reading</center></h1>\n<h3><center>Pls, upvote this kernel if you find it useful !</center></h3>","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}