{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path\n\nimport tensorflow as tf\nfrom tensorflow.python.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\ngpu_devices=tf.config.experimental.list_physical_devices(\"GPU\")\nfor device in gpu_devices:\n    tf.config.experimental.set_memory_growth(device,True)\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport os\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DATA_PATH = Path(\"../input/commonlitreadabilityprize/\")\n\ndf_train = pd.read_csv(BASE_DATA_PATH / \"train.csv\")\ndf_test = pd.read_csv(BASE_DATA_PATH / \"test.csv\")\ndf_sub = pd.read_csv(BASE_DATA_PATH / \"sample_submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"targets=np.array(df_train['target'])\nexcerpt_text=np.array(df_train['excerpt'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oov=\"<OOV>\"\ntotal_num_of_words=28651\npadding_type='pre'\ntrunc_type='post'\nembedding_output_dim=200","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=Tokenizer(oov_token=oov)\ntokenizer.fit_on_texts(excerpt_text)\nword_index=tokenizer.word_index\ntotal_num_of_words=len(tokenizer.word_index)+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seqs=tokenizer.texts_to_sequences(excerpt_text)\n#maxsentencelen=len(max(seqs, key = len))\nmaxsentencelen=200\npads=pad_sequences(seqs,maxlen=maxsentencelen,padding=padding_type,truncating=trunc_type)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split_point=int(2834*0.95)\n\nTRAIN_DATA=pads[:split_point]\nTRAIN_targets=targets[:split_point]\n\nVAL_DATA=pads[split_point:]\nVAL_targets=targets[split_point:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeddings_index = {}\nwith open(\"../input/glove6b200d/glove.6B.200d.txt\",'r',encoding='cp850') as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        coefs = np.asarray(values[1:], dtype='float32')\n        embeddings_index[word] = coefs\n\nembeddings_matrix = np.zeros((total_num_of_words, embedding_output_dim))\nfor word, i in word_index.items():\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None:\n        embeddings_matrix[i] = embedding_vector\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Model=tf.keras.models.Sequential([\n        tf.keras.layers.Embedding(input_dim=total_num_of_words,\n                              output_dim=embedding_output_dim,\n                              input_length=maxsentencelen,\n                              weights=[embeddings_matrix],\n                              trainable=False),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Conv1D(64, 5, activation='relu'),\n    tf.keras.layers.MaxPooling1D(pool_size=2),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100)),\n    tf.keras.layers.Dropout(0.2),\n    tf.keras.layers.Dense(16,activation='relu'),\n    tf.keras.layers.Dense(1,activation='linear'),\n])\nModel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"selected_optimizer=tf.keras.optimizers.Adam(learning_rate=1e-05)\nselected_loss=tf.keras.losses.MeanSquaredError()\n##selected_metrics=tf.keras.metrics.Accuracy()\nModel.compile(optimizer=selected_optimizer,loss=selected_loss)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"savedmodel_filepath='./SAVED_MODELs/Model.h5'\nearly_stopping=EarlyStopping(patience=10,monitor='val_loss')\nreduce_lr=ReduceLROnPlateau(monitor='val_loss',min_lr=0.00001,patience=3,mode='min',verbose=1)\nmodel_checkpoint=ModelCheckpoint(monitor='val_loss',filepath=savedmodel_filepath,\n                                 save_best_only=True)\n\n#lr_schedule = tf.keras.callbacks.LearningRateScheduler( lambda epoch: 0.00001 * 10**(epoch / 20),verbose=1)\n\nselected_callbacks=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=Model.fit(TRAIN_DATA,TRAIN_targets,epochs=200,verbose=1,callbacks=selected_callbacks,\n                         validation_data=(VAL_DATA,VAL_targets))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"excerpt_test=np.array(df_test['excerpt'])\ndf_test.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_seqs=tokenizer.texts_to_sequences(excerpt_test)\ntest_pads=pad_sequences(test_seqs,maxlen=maxsentencelen,padding=padding_type,truncating=trunc_type)\npedictions_testdata=Model.predict(test_pads)\ndf_test[\"target\"]=pedictions_testdata\ndf_test.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_sub[\"target\"]=pedictions_testdata\ndf_sub.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}