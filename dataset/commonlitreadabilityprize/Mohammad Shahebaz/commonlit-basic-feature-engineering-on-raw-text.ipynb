{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# What's In the Excerpt?\n\nThis notebook will explore various hypothesis I have on the problem, and in the go feature engineer and perform exploratory data analysis","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebr/a\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport plotly.offline as py\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objs as go\n\nimport string\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import TweetTokenizer\n\nfrom pandas.io.json import json_normalize\nfrom plotly import tools\npy.init_notebook_mode(connected=True)\npd.options.mode.chained_assignment = None\npd.options.display.max_columns = 999\ncolor = sns.color_palette()\nnp.random.seed(13)\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Exploration of text value : excerpt","metadata":{}},{"cell_type":"markdown","source":"Before we do anything lets begin by seeing few examples and trying to read it out loud. Yeah, I am doing a reading practise ðŸ˜…","metadata":{}},{"cell_type":"code","source":"sample_idx = [456, 784, 33]\n\nfor idx in sample_idx: \n    print(\"============================\")\n    print(f\">> Sample example #{idx}\")\n    print(\"============================\")\n    print(train_df.iloc[idx]['excerpt'],\"\\n\\n\", f\"=> Score {train_df.iloc[idx]['target']}\\n\\n\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['length'] = train_df['excerpt'].apply(len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm # I love this handy tool! \nprint(\">> Generating Count Based And Demographical Features\")\nfor df in ([train_df,test_df]):\n    df['length'] = df['excerpt'].apply(lambda x : len(x))\n    df['capitals'] = df['excerpt'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n    df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['length']),axis=1)\n    df['num_exclamation_marks'] = df['excerpt'].apply(lambda comment: comment.count('!'))\n    df['num_question_marks'] = df['excerpt'].apply(lambda comment: comment.count('?'))\n    df['num_punctuation'] = df['excerpt'].apply(lambda comment: sum(comment.count(w) for w in '.,;:'))\n    df['num_symbols'] = df['excerpt'].apply(lambda comment: sum(comment.count(w) for w in '*&$%'))\n    df['num_words'] = df['excerpt'].apply(lambda comment: len(comment.split()))\n    df['num_unique_words'] = df['excerpt'].apply(lambda comment: len(set(w for w in comment.split())))\n    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']\n \n\n\ndef tag_part_of_speech(text):\n    text_splited = text.split(' ')\n    text_splited = [''.join(c for c in s if c not in string.punctuation) for s in text_splited]\n    text_splited = [s for s in text_splited if s]\n    pos_list = pos_tag(text_splited)\n    noun_count = len([w for w in pos_list if w[1] in ('NN','NNP','NNPS','NNS')])\n    adjective_count = len([w for w in pos_list if w[1] in ('JJ','JJR','JJS')])\n    verb_count = len([w for w in pos_list if w[1] in ('VB','VBD','VBG','VBN','VBP','VBZ')])\n    return[noun_count, adjective_count, verb_count]\n\nprint(\">> Generating POS Features\")\nfor df in ([train_df,test_df]):\n    df['nouns'], df['adjectives'], df['verbs'] = zip(*df['excerpt'].apply(\n        lambda comment: tag_part_of_speech(comment)))\n    df['nouns_vs_length'] = df['nouns'] / df['length']\n    df['adjectives_vs_length'] = df['adjectives'] / df['length']\n    df['verbs_vs_length'] = df['verbs'] /df['length']\n    df['nouns_vs_words'] = df['nouns'] / df['num_words']\n    df['adjectives_vs_words'] = df['adjectives'] / df['num_words']\n    df['verbs_vs_words'] = df['verbs'] / df['num_words']\n    # More Handy Features\n    df[\"count_words_title\"] = df[\"excerpt\"].apply(lambda x: len([w for w in str(x).split() if w.istitle()]))\n    df[\"mean_word_len\"] = df[\"excerpt\"].apply(lambda x: np.mean([len(w) for w in str(x).split()]))\n    df['punct_percent']= df['num_punctuation']*100/df['num_words']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[['nouns','nouns_vs_length','adjectives_vs_length','verbs_vs_length','nouns_vs_words','adjectives_vs_words','verbs_vs_words']].head(8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize= [20,15])\nsns.heatmap(train_df.drop(['id','excerpt'], axis=1).corr(), annot=True, fmt=\".2f\", ax=ax, \n            cbar_kws={'label': 'Correlation Coefficient'}, cmap='viridis')\nax.set_title(\"Correlation Matrix for Target and New Features\", fontsize=20)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.to_csv(\"commonlit_feat_train.csv\", index=None)\ntest_df.to_csv(\"commonlit_feat_test.csv\", index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}