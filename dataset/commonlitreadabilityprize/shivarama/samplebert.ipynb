{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport transformers\nimport torch.nn as nn\nfrom sklearn import model_selection\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nimport time\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T07:21:36.230354Z","iopub.execute_input":"2021-06-14T07:21:36.230849Z","iopub.status.idle":"2021-06-14T07:21:43.317685Z","shell.execute_reply.started":"2021-06-14T07:21:36.230757Z","shell.execute_reply":"2021-06-14T07:21:43.316765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    MAX_LEN = 512\n    TRAIN_BATCH_SIZE = 8\n    VALID_BATCH_SIZE = 4\n    EPOCHS = 6\n    BERT_BASE_PATH = r'../input/bert-base-uncased'\n    MODEL_PATH = r'../working/final_model_.bin'\n    TRAINING_FILE = r'../input/commonlitreadabilityprize/train.csv'\n    TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_BASE_PATH, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.319037Z","iopub.execute_input":"2021-06-14T07:21:43.319351Z","iopub.status.idle":"2021-06-14T07:21:43.536153Z","shell.execute_reply.started":"2021-06-14T07:21:43.319317Z","shell.execute_reply":"2021-06-14T07:21:43.535247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTDAtaset:\n    def __init__(self, review, target):\n        self.review = review\n        self.target = target\n        self.tokenizer = CONFIG.TOKENIZER\n        self.max_len = CONFIG.MAX_LEN\n    \n    def __len__(self):\n        return len(self.review)\n    \n    def __getitem__(self, item_index):\n        review = str(self.review[item_index])\n        review = \" \".join(review.split())\n        inputs = self.tokenizer.encode_plus(\n            review,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len            \n        )\n        \n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        padding_len = self.max_len - len(ids)\n        \n        ids = ids + [0]*padding_len\n        mask = mask + [0]*padding_len\n        token_type_ids = token_type_ids + [0]*padding_len\n        \n        return {\n            \"ids\": torch.tensor(ids, dtype=torch.long),\n            \"mask\": torch.tensor(mask, dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n            \"target\": torch.tensor(self.target[item_index], dtype=torch.long)\n        }","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.537786Z","iopub.execute_input":"2021-06-14T07:21:43.5381Z","iopub.status.idle":"2021-06-14T07:21:43.548594Z","shell.execute_reply.started":"2021-06-14T07:21:43.538073Z","shell.execute_reply":"2021-06-14T07:21:43.546988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTBaseUncased(nn.Module):\n    def __init__(self):\n        super(BERTBaseUncased, self).__init__()\n        self.bert = transformers.BertModel.from_pretrained(CONFIG.BERT_BASE_PATH)\n#         self.bert_drop = nn.Dropout(0.3)\n#         self.out = nn.Linear(768, 1)\n        \n        # dropout layer\n        self.dropout = nn.Dropout(0.3)\n\n        # relu activation function\n        self.relu =  nn.ReLU()\n\n          # dense layer 1\n        self.fc1 = nn.Linear(768,512)\n\n          # dense layer 2 (Output layer)\n        self.fc2 = nn.Linear(512,1)\n        \n    def forward(self, ids, mask, token_type_ids):\n        o1, o2 = self.bert(ids, \n                     attention_mask=mask, \n                     token_type_ids=token_type_ids,\n                     return_dict=False\n                   )\n        bo = self.fc1(o2)\n        bo = self.relu(bo)\n        bo = self.dropout(bo)\n        output = self.fc2(bo)\n#         output = self.out(bo)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.550446Z","iopub.execute_input":"2021-06-14T07:21:43.55081Z","iopub.status.idle":"2021-06-14T07:21:43.559319Z","shell.execute_reply.started":"2021-06-14T07:21:43.550772Z","shell.execute_reply":"2021-06-14T07:21:43.55827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.560737Z","iopub.execute_input":"2021-06-14T07:21:43.561193Z","iopub.status.idle":"2021-06-14T07:21:43.571533Z","shell.execute_reply.started":"2021-06-14T07:21:43.561155Z","shell.execute_reply":"2021-06-14T07:21:43.570759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(outputs, targets):\n    criterion = nn.MSELoss()\n    loss = criterion(outputs, targets)\n    return loss","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.574474Z","iopub.execute_input":"2021-06-14T07:21:43.574756Z","iopub.status.idle":"2021-06-14T07:21:43.581124Z","shell.execute_reply.started":"2021-06-14T07:21:43.574729Z","shell.execute_reply":"2021-06-14T07:21:43.580351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, device, scheduler):\n    model.train() # Putting model in training mode\n    for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n        ids = d[\"ids\"]\n        mask = d[\"mask\"]\n        token_type_ids = d[\"token_type_ids\"]\n        targets = d[\"target\"]\n        \n        ids = ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n        \n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        \n        outputs = model(\n                    ids=ids,\n                    mask=mask,\n                    token_type_ids=token_type_ids)\n        \n        loss = loss_fn(outputs, targets)\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n        \ndef eval_fn(data_loader, model, device):\n    model.eval()\n    fin_loss = []\n    fin_outputs = []\n    with torch.no_grad():\n        for bi, d in tqdm(enumerate(data_loader), total=len(data_loader)):\n            ids = d[\"ids\"]\n            mask = d[\"mask\"]\n            token_type_ids = d[\"token_type_ids\"]\n            targets = d[\"target\"]\n\n            ids = ids.to(device, dtype=torch.long)\n            mask = mask.to(device, dtype=torch.long)\n            token_type_ids = token_type_ids.to(device, dtype=torch.long)\n\n            targets = targets.to(device, dtype=torch.float)\n\n            outputs = model(\n                        ids=ids,\n                        mask=mask,\n                        token_type_ids=token_type_ids)\n\n            eval_loss = loss_fn(outputs, targets)\n            \n    return eval_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.58341Z","iopub.execute_input":"2021-06-14T07:21:43.583723Z","iopub.status.idle":"2021-06-14T07:21:43.596915Z","shell.execute_reply.started":"2021-06-14T07:21:43.583697Z","shell.execute_reply":"2021-06-14T07:21:43.596123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run():\n    dfx = pd.read_csv(CONFIG.TRAINING_FILE).fillna(\"none\")\n    df_train, df_valid = model_selection.train_test_split(dfx, test_size=0.1, random_state=42)\n\n    df_train = df_train.reset_index(drop=True)\n    df_valid = df_valid.reset_index(drop=True)\n\n    train_dataset = BERTDAtaset(\n                review=df_train.excerpt.values,\n                target=df_train.target.values\n                )\n    valid_dataset = BERTDAtaset(\n                review=df_valid.excerpt.values,\n                target=df_valid.target.values\n                )\n\n    train_data_loader = torch.utils.data.DataLoader(\n                train_dataset,\n                batch_size=CONFIG.TRAIN_BATCH_SIZE,\n                num_workers=4\n                )\n\n    valid_data_loader = torch.utils.data.DataLoader(\n                valid_dataset,\n                batch_size=CONFIG.VALID_BATCH_SIZE,\n                num_workers=1\n                )\n\n    device = torch.device(\"cuda\")\n    model = BERTBaseUncased()\n    model.to(device)\n    param_optimizer = list(model.named_parameters())\n    no_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n    optimizer_parameters = [\n        {\"params\": [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], \"weight_decay\":0.001},\n        {\"params\": [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], \"weight_decay\":0.0}\n        ]\n\n    num_training_steps = int(len(df_train) / CONFIG.TRAIN_BATCH_SIZE * CONFIG.EPOCHS)\n    optimizer = AdamW(optimizer_parameters, lr=3e-5)\n    scheduler = get_linear_schedule_with_warmup(\n            optimizer,\n            num_warmup_steps=0,\n            num_training_steps=num_training_steps\n            )\n    best_loss = np.inf\n    for epoch in range(CONFIG.EPOCHS):\n        epoch_start_time = time.time()\n        train_fn(train_data_loader, model, optimizer, device, scheduler)\n        final_eval_loss = eval_fn(valid_data_loader, model, device)\n        print(f\"Validation loss = {final_eval_loss}\")\n        print('-' * 59)\n        print('| end of epoch {:3d} | time: {:5.2f}s | '\n              'valid accuracy {:8.3f} '.format(epoch,\n                                               time.time() - epoch_start_time,\n                                               final_eval_loss))\n        print('-' * 59)\n        try:\n            if final_eval_loss < best_loss:\n                torch.save(model.state_dict(), CONFIG.MODEL_PATH)\n                best_loss = final_eval_loss\n        except Exception as e:\n            print(e)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.599473Z","iopub.execute_input":"2021-06-14T07:21:43.59986Z","iopub.status.idle":"2021-06-14T07:21:43.614047Z","shell.execute_reply.started":"2021-06-14T07:21:43.599822Z","shell.execute_reply":"2021-06-14T07:21:43.613263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__==\"__main__\":\n    run()\n\n# torch.save(model.state_dict(), CONFIG.MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:21:43.615367Z","iopub.execute_input":"2021-06-14T07:21:43.615823Z","iopub.status.idle":"2021-06-14T07:37:22.781081Z","shell.execute_reply.started":"2021-06-14T07:21:43.615786Z","shell.execute_reply":"2021-06-14T07:37:22.7801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for bi, d in tqdm(enumerate(train_data_loader), total=len(train_data_loader)):\n#     print(d)\n#     break","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:37:22.783013Z","iopub.execute_input":"2021-06-14T07:37:22.783379Z","iopub.status.idle":"2021-06-14T07:37:22.78683Z","shell.execute_reply.started":"2021-06-14T07:37:22.78334Z","shell.execute_reply":"2021-06-14T07:37:22.786036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def final_prediction(sentence):\n#     predict_model = BERTBaseUncased()\n#     predict_model.load_state_dict(torch.load(CONFIG.MODEL_PATH))\n#     DEVICE = \"cpu\"\n#     predict_model.to(DEVICE)\n#     predict_model.eval()\n#     tokenizer = CONFIG.TOKENIZER\n#     max_len = CONFIG.MAX_LEN\n#     review = str(sentence)\n#     review = \" \".join(review.split())\n\n#     inputs = tokenizer.encode_plus(\n#         review, None, add_special_tokens=True, max_length=max_len\n#     )\n\n#     ids = inputs[\"input_ids\"]\n#     mask = inputs[\"attention_mask\"]\n#     token_type_ids = inputs[\"token_type_ids\"]\n\n#     padding_length = max_len - len(ids)\n#     ids = ids + ([0] * padding_length)\n#     mask = mask + ([0] * padding_length)\n#     token_type_ids = token_type_ids + ([0] * padding_length)\n\n#     ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n#     mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n#     token_type_ids = torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n\n#     ids = ids.to(DEVICE, dtype=torch.long)\n#     token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n#     mask = mask.to(DEVICE, dtype=torch.long)\n\n#     outputs = predict_model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n    \n#     print(outputs)\n#     return outputs\n    \n# final_prediction('THis is a sample sentence')","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-06-14T07:37:22.788107Z","iopub.execute_input":"2021-06-14T07:37:22.788651Z","iopub.status.idle":"2021-06-14T07:37:22.798626Z","shell.execute_reply.started":"2021-06-14T07:37:22.788612Z","shell.execute_reply":"2021-06-14T07:37:22.797788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n# final_predictions = []\n# for sentence in test_df.excerpt:\n#     pred_score = final_prediction(sentence)\n#     final_predictions.append(pred_score.tolist()[0][0])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:37:22.799648Z","iopub.execute_input":"2021-06-14T07:37:22.799892Z","iopub.status.idle":"2021-06-14T07:37:22.808689Z","shell.execute_reply.started":"2021-06-14T07:37:22.799868Z","shell.execute_reply":"2021-06-14T07:37:22.807943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\n# submission.target = final_predictions\n# submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:37:22.810196Z","iopub.execute_input":"2021-06-14T07:37:22.811103Z","iopub.status.idle":"2021-06-14T07:37:22.821712Z","shell.execute_reply.started":"2021-06-14T07:37:22.811076Z","shell.execute_reply":"2021-06-14T07:37:22.820912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nos.listdir('../working')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:37:22.822982Z","iopub.execute_input":"2021-06-14T07:37:22.823538Z","iopub.status.idle":"2021-06-14T07:37:22.834216Z","shell.execute_reply.started":"2021-06-14T07:37:22.823419Z","shell.execute_reply":"2021-06-14T07:37:22.833203Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_model = BERTBaseUncased()\n# test_model.load_state_dict(torch.load('./final_model.bin'))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:37:22.836567Z","iopub.execute_input":"2021-06-14T07:37:22.836964Z","iopub.status.idle":"2021-06-14T07:37:22.841668Z","shell.execute_reply.started":"2021-06-14T07:37:22.836926Z","shell.execute_reply":"2021-06-14T07:37:22.840816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nqq = np.inf","metadata":{"execution":{"iopub.status.busy":"2021-06-14T07:37:22.843778Z","iopub.execute_input":"2021-06-14T07:37:22.844097Z","iopub.status.idle":"2021-06-14T07:37:22.850352Z","shell.execute_reply.started":"2021-06-14T07:37:22.844072Z","shell.execute_reply":"2021-06-14T07:37:22.849541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}