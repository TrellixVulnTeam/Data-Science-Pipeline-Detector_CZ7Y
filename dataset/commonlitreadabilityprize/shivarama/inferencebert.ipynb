{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport transformers\nimport torch.nn as nn\nfrom sklearn import model_selection\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nimport time\nimport numpy as np","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T04:38:10.03836Z","iopub.execute_input":"2021-06-14T04:38:10.038689Z","iopub.status.idle":"2021-06-14T04:38:16.909019Z","shell.execute_reply.started":"2021-06-14T04:38:10.038613Z","shell.execute_reply":"2021-06-14T04:38:16.908216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG:\n    MAX_LEN = 512\n    TRAIN_BATCH_SIZE = 8\n    VALID_BATCH_SIZE = 4\n    EPOCHS = 6\n    BERT_BASE_PATH = r'../input/bert-base-uncased'\n    MODEL_PATH = r'../input/commonlitbert-basic/final_model.bin'\n    TRAINING_FILE = r'../input/commonlitreadabilityprize/train.csv'\n    TOKENIZER = transformers.BertTokenizer.from_pretrained(BERT_BASE_PATH, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T04:38:22.259886Z","iopub.execute_input":"2021-06-14T04:38:22.260196Z","iopub.status.idle":"2021-06-14T04:38:22.491565Z","shell.execute_reply.started":"2021-06-14T04:38:22.260166Z","shell.execute_reply":"2021-06-14T04:38:22.490752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTBaseUncased(nn.Module):\n    def __init__(self):\n        super(BERTBaseUncased, self).__init__()\n        self.bert = transformers.BertModel.from_pretrained(CONFIG.BERT_BASE_PATH)\n        self.bert_drop = nn.Dropout(0.3)\n        self.out = nn.Linear(768, 1)\n        \n    def forward(self, ids, mask, token_type_ids):\n        o1, o2 = self.bert(ids, \n                     attention_mask=mask, \n                     token_type_ids=token_type_ids,\n                     return_dict=False\n                   )\n        bo = self.bert_drop(o2)\n        output = self.out(bo)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-14T04:38:23.379079Z","iopub.execute_input":"2021-06-14T04:38:23.37942Z","iopub.status.idle":"2021-06-14T04:38:23.385085Z","shell.execute_reply.started":"2021-06-14T04:38:23.37939Z","shell.execute_reply":"2021-06-14T04:38:23.384278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_model = BERTBaseUncased()\npredict_model.load_state_dict(torch.load(CONFIG.MODEL_PATH))\ndef final_prediction(sentence):\n    DEVICE = \"cpu\"\n    predict_model.to(DEVICE)\n    predict_model.eval()\n    tokenizer = CONFIG.TOKENIZER\n    max_len = CONFIG.MAX_LEN\n    review = str(sentence)\n    review = \" \".join(review.split())\n\n    inputs = tokenizer.encode_plus(\n        review, None, add_special_tokens=True, max_length=max_len\n    )\n\n    ids = inputs[\"input_ids\"]\n    mask = inputs[\"attention_mask\"]\n    token_type_ids = inputs[\"token_type_ids\"]\n\n    padding_length = max_len - len(ids)\n    ids = ids + ([0] * padding_length)\n    mask = mask + ([0] * padding_length)\n    token_type_ids = token_type_ids + ([0] * padding_length)\n\n    ids = torch.tensor(ids, dtype=torch.long).unsqueeze(0)\n    mask = torch.tensor(mask, dtype=torch.long).unsqueeze(0)\n    token_type_ids = torch.tensor(token_type_ids, dtype=torch.long).unsqueeze(0)\n\n    ids = ids.to(DEVICE, dtype=torch.long)\n    token_type_ids = token_type_ids.to(DEVICE, dtype=torch.long)\n    mask = mask.to(DEVICE, dtype=torch.long)\n\n    outputs = predict_model(ids=ids, mask=mask, token_type_ids=token_type_ids)\n    \n    print(outputs)\n    return outputs\n    \n# final_prediction('THis is a sample sentence')","metadata":{"execution":{"iopub.status.busy":"2021-06-14T04:38:24.578926Z","iopub.execute_input":"2021-06-14T04:38:24.579247Z","iopub.status.idle":"2021-06-14T04:38:43.9384Z","shell.execute_reply.started":"2021-06-14T04:38:24.579216Z","shell.execute_reply":"2021-06-14T04:38:43.937535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\nfinal_predictions = []\nfor sentence in test_df.excerpt:\n    pred_score = final_prediction(sentence)\n    final_predictions.append(pred_score.tolist()[0][0])","metadata":{"execution":{"iopub.status.busy":"2021-06-14T04:38:43.939822Z","iopub.execute_input":"2021-06-14T04:38:43.940158Z","iopub.status.idle":"2021-06-14T04:38:51.434322Z","shell.execute_reply.started":"2021-06-14T04:38:43.940122Z","shell.execute_reply":"2021-06-14T04:38:51.433393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsubmission.target = final_predictions\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T04:38:53.629179Z","iopub.execute_input":"2021-06-14T04:38:53.629531Z","iopub.status.idle":"2021-06-14T04:38:53.851256Z","shell.execute_reply.started":"2021-06-14T04:38:53.629499Z","shell.execute_reply":"2021-06-14T04:38:53.850483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}