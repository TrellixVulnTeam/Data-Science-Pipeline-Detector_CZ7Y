{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Installing ktrain\n!pip install ktrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Modules","metadata":{}},{"cell_type":"code","source":"# Standard imports\nimport os\nimport pprint\nimport json\nimport pandas as pd\nimport numpy as np\nfrom IPython.display import display\n\n# For plotting\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# For Evaluation and model selection \nfrom sklearn.model_selection import *\nfrom sklearn.metrics import *\n\n# For model building\nimport tensorflow as tf\nimport ktrain\nfrom ktrain import text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config\n","metadata":{}},{"cell_type":"code","source":"params = {}\nparams['train_csv'] = \"../input/commonlitreadabilityprize/train.csv\"\nparams['test_csv'] = \"../input/commonlitreadabilityprize/test.csv\"\nparams['sample_sub'] = \"../input/commonlitreadabilityprize/sample_submission.csv\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading dataset","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(params['train_csv'])\ntest_df = pd.read_csv(params['test_csv'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether we have any duplicates in test and train\nprint(f\"Number of ids in train : {len(train_df)}\")\nprint(f\"Number of unique ids in train : {len(train_df['id'].unique())}\")\n\nprint(f\"Number of ids in test : {len(test_df)}\")\nprint(f\"Number of unique ids in test : {len(test_df['id'].unique())}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ids = set(train_df['id'].values)\ntest_ids = set(test_df['id'].values)\n\nif len(train_ids.intersection(test_ids)) > 0:\n    print(f\"Common ids in train and test : {train_ids.intersection(test_ids)}\")\nelse:\n    print(\"No intersection\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Distribution of labels","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(train_df, x = 'target')\nfig.update_layout(\n        title_text = \"Distribution of targets\",\n        title_x = 0.5,\n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Mean of my labels : {np.mean(train_df['target'])}\")\nprint(f\"Std of my labels : {np.std(train_df['target'])}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating training and validation datasets","metadata":{}},{"cell_type":"code","source":"max_ = 0; min_ = 1e9\nfor i in train_df.excerpt.values:\n    max_ = max(max_, len(i))\n    min_ = min(min_, len(i))\n\nmax_, min_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data, target=\"target\", num_splits = 5): \n    data[\"kfold\"] = -1 \n    data = data.sample(frac=1).reset_index(drop=True)\n    \n    # Applying Sturg's rule to calculate the no. of bins for target\n    num_bins = int(1 + np.log2(len(data))) \n\n    data.loc[:, \"bins\"] = pd.cut(data[target], bins=num_bins, labels=False) \n    kf = StratifiedKFold(n_splits=num_splits) \n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)): \n        data.loc[v_, 'kfold'] = f\n        \n    data = data.drop([\"bins\"], axis = 1)         \n    return data \n\ntrain_df = create_folds(train_df, target = 'target', num_splits = 4)\ntrain_df.kfold.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting into train and val\n\ntrain_set = train_df.loc[train_df.kfold != 3]\nval_set = train_df.loc[train_df.kfold == 3]\n\nlen(train_set), len(val_set)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting into features","metadata":{}},{"cell_type":"code","source":"X_train = train_set.excerpt.values\nX_val = val_set.excerpt.values\n\ny_train = train_set.target.values\ny_val = val_set.target.values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trn, val, preproc = text.texts_from_array(\n                        x_train=X_train, y_train=y_train,                                          \n                        x_test=X_val, y_test=y_val,                                          \n                        ngram_range=3,                                          \n                        maxlen=512,                                           \n                        max_features=35000,\n                        preprocess_mode='bert'\n                    )","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets see what all regression models we have !!","metadata":{}},{"cell_type":"code","source":"text.print_text_regression_models()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets start with the infamous BERT model","metadata":{}},{"cell_type":"code","source":"model = text.text_regression_model('bert',\n                                  train_data = trn,\n                                  preproc = preproc)\n# Setting our learner\nlearner = ktrain.get_learner(\n    model, \n    train_data = trn,\n    val_data = val,\n    batch_size = 6\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Estimating the optimizer Learning rate\n\nlearner.lr_find()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learner.lr_plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training and Inspecting Model","metadata":{}},{"cell_type":"code","source":"learner.fit_onecycle(1e-4, 10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learner.view_top_losses(n=3, preproc = preproc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing results","metadata":{}},{"cell_type":"code","source":"hist = learner.history.history\ntrain_loss = hist['loss']\nval_loss = hist['val_loss']\n\ntrain_mae = hist['mean_absolute_error']\nval_mae = hist['val_mean_absolute_error']\n\nepochs = [d for d in range(1, len(train_loss)+1)]\n\nlr = hist['lr']\niters = hist['iterations']\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=epochs, y=train_loss,\n                    mode='lines+markers',\n                    name='train_loss'))\nfig.add_trace(go.Scatter(x=epochs, y=val_loss,\n                    mode='lines+markers',\n                    name='val_loss'))\nfig.add_trace(go.Scatter(x=epochs, y=train_mae,\n                    mode='lines+markers', name='train_mae'))\nfig.add_trace(go.Scatter(x=epochs, y=val_mae,\n                    mode='lines+markers', name='val_mae'))\n\nfig.update_layout(\n    title_text = \"Training Results\",\n    title_x = .5,\n    xaxis_title = \"EPOCHS\",\n    yaxis_title = \"Values\"\n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = go.Figure()\nfig.add_trace(go.Scatter(x=iters, y=lr,\n                    mode='markers',\n                    name='Learning Rate'))\n\nfig.update_layout(\n    title_text = \"Learning rate\",\n    title_x = .5,\n    xaxis_title = \"Iterations\",\n    yaxis_title = \"Learning rates\"\n)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets Build our predictor and evaluate our model","metadata":{}},{"cell_type":"code","source":"predictor = ktrain.get_predictor(learner.model, preproc)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_preds = []\nfor txt in X_val:\n    val_preds.append(predictor.predict(txt))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model performance\nrmse = mean_squared_error(val_preds, y_val, squared = False)\nprint(f\"Model Score : {round(rmse,3)}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Saving model","metadata":{}},{"cell_type":"code","source":"!mkdir ./model_BERT_token_BERT_CLRP\npredictor.save(\"./model_BERT_token_BERT_CLRP/model\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install kaggle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp ../input/kaggle-token/kaggle_token.json ./\n!mv ./kaggle_token.json ./kaggle.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls -l ../../root\n!cp ./kaggle.json ../../root/\n!ls ../../root","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir ../../root/.kaggle\n!mv ../../root/kaggle.json ../../root/.kaggle/kaggle.json\n\n!chmod 600 /root/.kaggle/kaggle.json\n!kaggle datasets init -p ./model_BERT_token_BERT_CLRP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cat ./model_BERT_token_BERT_CLRP/dataset-metadata.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open(\"./model_BERT_token_BERT_CLRP/dataset-metadata.json\", 'r+') as file_:\n    meta_data = json.load(file_)\n    meta_data['title'] = 'model_BERT_token_BERT_CLRP'\n    meta_data['id'] = 'hotsonhonet/ModelsCLRP'\n    file_.seek(0)        \n    json.dump(meta_data, file_, indent=4)\n    file_.truncate()\n    \nprint(meta_data['title'], meta_data['id'])\n\n!cat ./model_BERT_token_BERT_CLRP/dataset-metadata.json","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mv ./model_BERT_token_BERT_CLRP/model/* ./model_BERT_token_BERT_CLRP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets create -p ./model_BERT_token_BERT_CLRP ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}