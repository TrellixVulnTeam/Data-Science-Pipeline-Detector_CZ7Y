{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport gc\nimport sys\nimport time\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport xgboost as xgb\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AutoModel, AutoTokenizer","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.085728,"end_time":"2021-05-13T21:44:51.03131","exception":false,"start_time":"2021-05-13T21:44:47.945582","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nfrom tensorflow.keras.models import load_model\nimport re\nimport pandas as pd\nimport string\nimport keras","metadata":{"papermill":{"duration":4.967334,"end_time":"2021-05-13T21:44:56.011365","exception":false,"start_time":"2021-05-13T21:44:51.044031","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/commonlitreadabilityprize/'\ntrain = pd.read_csv(data_dir + 'train.csv')\ntest = pd.read_csv(data_dir + 'test.csv')\nsample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n\ntarget = train['target'].to_numpy()","metadata":{"papermill":{"duration":0.122873,"end_time":"2021-05-13T21:44:56.146964","exception":false,"start_time":"2021-05-13T21:44:56.024091","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source: https://www.kaggle.com/maunish/clrp-roberta-lgbm\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n\nclass CLRPDataset(nn.Module):\n    def __init__(self, df, tokenizer, max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \n\ndef get_embeddings(df, path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    MODEL_PATH = path\n    model = AutoModel.from_pretrained(MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    model.eval()\n\n    ds = CLRPDataset(df, tokenizer, config['max_len'])\n    dl = DataLoader(ds,\n                    batch_size=config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0], -1).to(device) for key, val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:, 0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\nconfig = {\n    'batch_size': 128,\n    'max_len': 256,\n    'seed': 42,\n}\nseed_everything(seed=config['seed'])","metadata":{"papermill":{"duration":76.140176,"end_time":"2021-05-13T21:46:12.299898","exception":false,"start_time":"2021-05-13T21:44:56.159722","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 =  np.load('../input/commonlit-roberta-cnn/train_embeddings1.npy')\ntrain_embeddings2 =  np.load('../input/commonlit-roberta-cnn/train_embeddings2.npy')\ntrain_embeddings3 =  np.load('../input/commonlit-roberta-cnn/train_embeddings3.npy')\ntrain_embeddings4 =  np.load('../input/commonlit-roberta-cnn/train_embeddings4.npy')\ntrain_embeddings5 =  np.load('../input/commonlit-roberta-cnn/train_embeddings5.npy')\ntrain_embeddings6 =  np.load('../input/commonlit-roberta-cnn/train_embeddings6.npy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings1.shape","metadata":{"papermill":{"duration":0.038985,"end_time":"2021-05-13T21:46:12.368359","exception":false,"start_time":"2021-05-13T21:46:12.329374","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings_reshaped = train_embeddings1.reshape((1,)+train_embeddings1.shape) ","metadata":{"papermill":{"duration":0.035718,"end_time":"2021-05-13T21:46:12.433126","exception":false,"start_time":"2021-05-13T21:46:12.397408","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings_reshaped.shape","metadata":{"papermill":{"duration":0.036347,"end_time":"2021-05-13T21:46:12.498995","exception":false,"start_time":"2021-05-13T21:46:12.462648","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, LSTM,Dropout,concatenate\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense, Activation, Embedding, LSTM,Dropout,Bidirectional,GRU\nfrom keras.utils import plot_model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Flatten ,Embedding,Input,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Dropout,MaxPooling1D,Bidirectional,GRU,Concatenate\nfrom keras.models import Sequential,Model","metadata":{"papermill":{"duration":0.063653,"end_time":"2021-05-13T21:46:12.592387","exception":false,"start_time":"2021-05-13T21:46:12.528734","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","metadata":{"papermill":{"duration":0.037318,"end_time":"2021-05-13T21:46:12.659519","exception":false,"start_time":"2021-05-13T21:46:12.622201","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crt_model():\n    i=Input(shape=(768,1))\n    l1=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i)\n    l2 =MaxPooling1D(2) (l1)\n    l3=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l2)\n    l3 =MaxPooling1D(2) (l3)\n    l3=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(512,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(1024,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(2048,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(4098,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l3=Conv1D(8196,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l4=GlobalMaxPooling1D()(l3)\n    l5=Dense(120, kernel_initializer='normal',activation='relu')(l4)\n    l5=Dense(240, kernel_initializer='normal',activation='relu')(l5)\n    l5=Dense(480, kernel_initializer='normal',activation='relu')(l5)\n    l5=Dense(980, kernel_initializer='normal',activation='relu')(l5)\n    l5=Dense(1500, kernel_initializer='normal',activation='relu')(l5)\n    l7=Dense(1, kernel_initializer='normal')(l5)\n    model=Model(inputs=i, outputs=l7)\n    model.compile(loss='mean_squared_error', optimizer='adam',metrics=[keras.metrics.MeanSquaredError()])\n    return model","metadata":{"papermill":{"duration":0.04257,"end_time":"2021-05-13T21:46:12.731825","exception":false,"start_time":"2021-05-13T21:46:12.689255","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_models(i, train_embeddings):\n    model = crt_model()\n    nfolds = 3\n    kf = KFold(n_splits=nfolds, shuffle=True, random_state=config['seed'])\n    for k, (train_idx, valid_idx) in enumerate(kf.split(train)): \n        train_x,train_y,test_x,test_y=train_embeddings[train_idx], target[train_idx],train_embeddings[valid_idx], target[valid_idx]\n        model.fit(train_x.reshape(train_x.shape+(1,)),\n                  train_y,\n                  epochs=8,\n                  validation_data=(test_x,test_y),\n                  batch_size=64)\n    model.save(f'CNN_Model_{i}.pth')\n    del model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np.save('train_embeddings1.npy', train_embeddings1)\n# np.save('train_embeddings2.npy', train_embeddings2)\n# np.save('train_embeddings3.npy', train_embeddings3)\n# np.save('train_embeddings4.npy', train_embeddings4)\n# np.save('train_embeddings5.npy', train_embeddings5)\n# np.save('train_embeddings6.npy', train_embeddings6)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embeds = [train_embeddings1, train_embeddings2, train_embeddings3, train_embeddings4,\n         train_embeddings5, train_embeddings6]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import multiprocessing\n\nfor i, embs in enumerate(embeds):\n    process_eval = multiprocessing.Process(target=fit_models, args=(i, embs))\n    process_eval.start()\n    process_eval.join()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit_models(1, train_embeddings1)\n# fit_models(2, train_embeddings2)\n# fit_models(3, train_embeddings3)\n# fit_models(4, train_embeddings4)\n# fit_models(5, train_embeddings5)\n# fit_models(6, train_embeddings6)","metadata":{"papermill":{"duration":0.4291,"end_time":"2021-05-13T22:58:04.854491","exception":false,"start_time":"2021-05-13T22:58:04.425391","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}