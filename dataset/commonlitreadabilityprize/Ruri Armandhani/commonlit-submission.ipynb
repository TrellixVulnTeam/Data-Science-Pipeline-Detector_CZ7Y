{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport string\n\nfrom tensorflow.keras import Model, Input\nfrom tensorflow.keras.layers import Dense, LSTM, Dropout, Flatten\n\nfrom transformers import RobertaTokenizer, TFRobertaModel","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:32:01.321562Z","iopub.execute_input":"2021-07-17T06:32:01.322022Z","iopub.status.idle":"2021-07-17T06:32:05.72444Z","shell.execute_reply.started":"2021-07-17T06:32:01.321959Z","shell.execute_reply":"2021-07-17T06:32:05.723644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def custom_standardization(text):\n    text = text.lower() # if encoder is uncased\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    text = text.strip()\n    return text\n\ndef get_dataset(pandas_df, tokenizer, batch_size=32, seq_len=128):\n    \"\"\"\n        Return a Tensorflow dataset ready for training or inference.\n    \"\"\"\n    text = [custom_standardization(text) for text in pandas_df['excerpt']]\n    \n    # Tokenize inputs\n    tokenized_inputs = tokenizer(text, max_length=seq_len, truncation=True, \n                                 padding='max_length', return_tensors='tf')\n    \n    dataset = tf.data.Dataset.from_tensor_slices({'input_ids': tokenized_inputs['input_ids']}) \n#                                                   'attention_mask': tokenized_inputs['attention_mask']})\n        \n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n    \n    return dataset","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:32:05.72876Z","iopub.execute_input":"2021-07-17T06:32:05.729237Z","iopub.status.idle":"2021-07-17T06:32:05.73854Z","shell.execute_reply.started":"2021-07-17T06:32:05.729191Z","shell.execute_reply":"2021-07-17T06:32:05.737474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def base_model(encoder, seq_len=256):\n    input_ids = Input(shape=(seq_len,), dtype=tf.int32, name='input_ids')\n#     input_attention_mask = Input(shape=(seq_len,), dtype=tf.int32, name='attention_mask')\n    \n    transformer = encoder({'input_ids': input_ids})\n#                       'attention_mask': input_attention_mask})\n    \n    lstm = LSTM(32,return_sequences=True, name=\"lstm_layer\")(transformer.last_hidden_state)\n    \n    dropout1 = Dropout(0.3, name=\"dropout_layer1\")(lstm)\n    \n    dense = Dense(16, name=\"dense_layer\")(dropout1)\n    \n    dropout2 = Dropout(0.5, name=\"dropout_layer2\")(dense)\n    \n    flatten = Flatten(name=\"flatten_layer\")(dropout2)\n    \n    output = Dense(1, activation=\"linear\", name=\"output_layer\")(flatten)\n    \n    model = Model(inputs=[input_ids], outputs=output)\n    \n#     model = Model(inputs=[input_ids, input_attention_mask], outputs=output)\n    \n#     model.summary()\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:32:05.740006Z","iopub.execute_input":"2021-07-17T06:32:05.74052Z","iopub.status.idle":"2021-07-17T06:32:05.752158Z","shell.execute_reply.started":"2021-07-17T06:32:05.740473Z","shell.execute_reply":"2021-07-17T06:32:05.751088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nprint(df_test.shape)\ndf_test.head()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-17T06:32:05.753457Z","iopub.execute_input":"2021-07-17T06:32:05.753981Z","iopub.status.idle":"2021-07-17T06:32:05.791892Z","shell.execute_reply.started":"2021-07-17T06:32:05.753939Z","shell.execute_reply":"2021-07-17T06:32:05.790915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_MODEL = '../input/huggingface-roberta/roberta-base'","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:32:05.793055Z","iopub.execute_input":"2021-07-17T06:32:05.793346Z","iopub.status.idle":"2021-07-17T06:32:05.797185Z","shell.execute_reply.started":"2021-07-17T06:32:05.793319Z","shell.execute_reply":"2021-07-17T06:32:05.796188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEQ_LEN = 256\ntokenizer = RobertaTokenizer.from_pretrained(BASE_MODEL)\n\ndataset_test = get_dataset(df_test, tokenizer, batch_size=1, seq_len=SEQ_LEN)\n\npreds = np.zeros((df_test.shape[0],))\n\nfolds = 5\n\nfor x in range(folds):\n\n    model_path = f\"../input/clrp-roberta-lstm/model_fold{x+1}.h5\"\n\n    encoder = TFRobertaModel.from_pretrained(BASE_MODEL)\n    model = base_model(encoder, SEQ_LEN)\n\n    model.compile()\n\n    model.load_weights(model_path)\n\n    pred = model.predict(dataset_test)\n    preds += np.squeeze(pred, axis=-1) / folds\n#     print(pred.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:32:05.798733Z","iopub.execute_input":"2021-07-17T06:32:05.799178Z","iopub.status.idle":"2021-07-17T06:34:07.349194Z","shell.execute_reply.started":"2021-07-17T06:32:05.799136Z","shell.execute_reply":"2021-07-17T06:34:07.348117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred = df_test[['id']]\ndf_pred['target'] = pred\ndf_pred","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:34:07.350814Z","iopub.execute_input":"2021-07-17T06:34:07.351251Z","iopub.status.idle":"2021-07-17T06:34:07.366224Z","shell.execute_reply.started":"2021-07-17T06:34:07.351204Z","shell.execute_reply":"2021-07-17T06:34:07.365151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_pred.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:34:07.368341Z","iopub.execute_input":"2021-07-17T06:34:07.368622Z","iopub.status.idle":"2021-07-17T06:34:07.379552Z","shell.execute_reply.started":"2021-07-17T06:34:07.368595Z","shell.execute_reply":"2021-07-17T06:34:07.378511Z"},"trusted":true},"execution_count":null,"outputs":[]}]}