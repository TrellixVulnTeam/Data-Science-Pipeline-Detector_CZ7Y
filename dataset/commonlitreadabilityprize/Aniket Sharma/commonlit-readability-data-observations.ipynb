{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"In this notebook, I will be making observations regarding the data provided in the [CommonLit Readability Prize](https://www.kaggle.com/c/commonlitreadabilityprize/overview).\n\nI have made some submissions in the competitions.\n- [Decision Tree with score 0.941](https://www.kaggle.com/aniketsharma00411/commonlit-readability-decision-tree)\n- [Random Forest with score 0.780](https://www.kaggle.com/aniketsharma00411/commonlit-readability-random-forest)\n\nI will be using the observations I make in this notebook to improve these models and create further better models using other Regression techniques.\n\nAs in the other notebooks, I will be using the [readability](https://pypi.org/project/readability/) Python package to create features from excerpts.","metadata":{}},{"cell_type":"markdown","source":"# Initialization","metadata":{}},{"cell_type":"markdown","source":"I am using the [readability](https://pypi.org/project/readability/) and [syntok](https://pypi.org/project/syntok/) to evaluate readability of each excerpt and [textblob](https://pypi.org/project/textblob/) for sentiment analysis.","metadata":{}},{"cell_type":"code","source":"! pip install -q /kaggle/input/readability/readability-0.3.1-py3-none-any.whl\n! pip install -q /kaggle/input/syntok/syntok-1.3.1-py3-none-any.whl\nfrom textblob import TextBlob\nimport readability\nimport syntok.segmenter as segmenter\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-13T09:53:10.14911Z","iopub.execute_input":"2021-06-13T09:53:10.14951Z","iopub.status.idle":"2021-06-13T09:53:24.017755Z","shell.execute_reply.started":"2021-06-13T09:53:10.149427Z","shell.execute_reply":"2021-06-13T09:53:24.01673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:24.019482Z","iopub.execute_input":"2021-06-13T09:53:24.019851Z","iopub.status.idle":"2021-06-13T09:53:24.112887Z","shell.execute_reply.started":"2021-06-13T09:53:24.019807Z","shell.execute_reply":"2021-06-13T09:53:24.111963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:24.114527Z","iopub.execute_input":"2021-06-13T09:53:24.114772Z","iopub.status.idle":"2021-06-13T09:53:24.15537Z","shell.execute_reply.started":"2021-06-13T09:53:24.114747Z","shell.execute_reply":"2021-06-13T09:53:24.154364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.info()\ntest_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:24.157242Z","iopub.execute_input":"2021-06-13T09:53:24.157641Z","iopub.status.idle":"2021-06-13T09:53:24.177094Z","shell.execute_reply.started":"2021-06-13T09:53:24.157595Z","shell.execute_reply":"2021-06-13T09:53:24.175896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('/kaggle/input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:24.178639Z","iopub.execute_input":"2021-06-13T09:53:24.178961Z","iopub.status.idle":"2021-06-13T09:53:24.198883Z","shell.execute_reply.started":"2021-06-13T09:53:24.178932Z","shell.execute_reply":"2021-06-13T09:53:24.198101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Functions","metadata":{}},{"cell_type":"code","source":"def sentiment_analysis(text):\n    return TextBlob(text).sentiment.polarity","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:24.199716Z","iopub.execute_input":"2021-06-13T09:53:24.199967Z","iopub.status.idle":"2021-06-13T09:53:24.203227Z","shell.execute_reply.started":"2021-06-13T09:53:24.199942Z","shell.execute_reply":"2021-06-13T09:53:24.202385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize(text):\n    \"\"\"Tokenizing and creating excerpts in the format suggested in the README of readability project.\"\"\"\n    return '\\n\\n'.join(\n        '\\n'.join(\n            ' '.join(token.value for token in sentence)\n            for sentence in paragraph)\n        for paragraph in segmenter.analyze(text))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:24.204506Z","iopub.execute_input":"2021-06-13T09:53:24.204896Z","iopub.status.idle":"2021-06-13T09:53:24.215491Z","shell.execute_reply.started":"2021-06-13T09:53:24.204847Z","shell.execute_reply":"2021-06-13T09:53:24.214685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Features","metadata":{}},{"cell_type":"code","source":"train_data.loc[:,'readability_object'] = train_data.apply(lambda row: readability.getmeasures(tokenize(row.excerpt), lang='en'), axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:24.218054Z","iopub.execute_input":"2021-06-13T09:53:24.218401Z","iopub.status.idle":"2021-06-13T09:53:34.158278Z","shell.execute_reply.started":"2021-06-13T09:53:24.218367Z","shell.execute_reply":"2021-06-13T09:53:34.157377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.info()\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.159571Z","iopub.execute_input":"2021-06-13T09:53:34.159819Z","iopub.status.idle":"2021-06-13T09:53:34.191315Z","shell.execute_reply.started":"2021-06-13T09:53:34.159783Z","shell.execute_reply":"2021-06-13T09:53:34.190399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.loc[0, 'readability_object']['readability grades'].keys()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.192196Z","iopub.execute_input":"2021-06-13T09:53:34.192433Z","iopub.status.idle":"2021-06-13T09:53:34.200155Z","shell.execute_reply.started":"2021-06-13T09:53:34.192409Z","shell.execute_reply":"2021-06-13T09:53:34.19921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The readability module provides 9 readability grades. By definition none of these are better than other.\n\nSo, to decide which one to use we will calculate a correlation matrix of these with our target value and then take the grade with the higest correlation value.","metadata":{}},{"cell_type":"code","source":"readability_grades = pd.DataFrame(train_data['id'])\nreadability_grades.loc[:, 'Kincaid'] = train_data.apply(lambda row: row.readability_object['readability grades']['Kincaid'], axis=1)\nreadability_grades.loc[:, 'ARI'] = train_data.apply(lambda row: row.readability_object['readability grades']['ARI'], axis=1)\nreadability_grades.loc[:, 'Coleman-Liau'] = train_data.apply(lambda row: row.readability_object['readability grades']['Coleman-Liau'], axis=1)\nreadability_grades.loc[:, 'FleschReadingEase'] = train_data.apply(lambda row: row.readability_object['readability grades']['FleschReadingEase'], axis=1)\nreadability_grades.loc[:, 'GunningFogIndex'] = train_data.apply(lambda row: row.readability_object['readability grades']['GunningFogIndex'], axis=1)\nreadability_grades.loc[:, 'LIX'] = train_data.apply(lambda row: row.readability_object['readability grades']['LIX'], axis=1)\nreadability_grades.loc[:, 'SMOGIndex'] = train_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nreadability_grades.loc[:, 'RIX'] = train_data.apply(lambda row: row.readability_object['readability grades']['RIX'], axis=1)\nreadability_grades.loc[:, 'DaleChallIndex'] = train_data.apply(lambda row: row.readability_object['readability grades']['DaleChallIndex'], axis=1)\nreadability_grades.loc[:, 'target'] = train_data['target']","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.201591Z","iopub.execute_input":"2021-06-13T09:53:34.20199Z","iopub.status.idle":"2021-06-13T09:53:34.513517Z","shell.execute_reply.started":"2021-06-13T09:53:34.201947Z","shell.execute_reply":"2021-06-13T09:53:34.512661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"readability_grades.info()\nreadability_grades.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.514588Z","iopub.execute_input":"2021-06-13T09:53:34.514865Z","iopub.status.idle":"2021-06-13T09:53:34.539663Z","shell.execute_reply.started":"2021-06-13T09:53:34.514837Z","shell.execute_reply":"2021-06-13T09:53:34.539056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"read_corr = readability_grades.corr()\nread_corr.info()\nread_corr","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.540497Z","iopub.execute_input":"2021-06-13T09:53:34.540741Z","iopub.status.idle":"2021-06-13T09:53:34.56808Z","shell.execute_reply.started":"2021-06-13T09:53:34.540714Z","shell.execute_reply":"2021-06-13T09:53:34.567246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax =plt.subplots(figsize=(8, 6))\nplt.title(\"Correlation Plot\")\nsns.heatmap(read_corr,\n            mask=np.zeros_like(read_corr, dtype=np.bool),\n            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.56912Z","iopub.execute_input":"2021-06-13T09:53:34.569379Z","iopub.status.idle":"2021-06-13T09:53:34.925579Z","shell.execute_reply.started":"2021-06-13T09:53:34.569353Z","shell.execute_reply":"2021-06-13T09:53:34.924616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As expected, the readability grades are highly correlated with each other. So, using some or all of them will increase redundancy. Therefore, we will chose a single best readability grade, the one which is most correlated with target variable.","metadata":{}},{"cell_type":"code","source":"read_corr.target","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.926958Z","iopub.execute_input":"2021-06-13T09:53:34.92756Z","iopub.status.idle":"2021-06-13T09:53:34.934606Z","shell.execute_reply.started":"2021-06-13T09:53:34.92752Z","shell.execute_reply":"2021-06-13T09:53:34.933724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SMOGIndex** is the most correlated with the target variable. So, it is best to use it for training.","metadata":{}},{"cell_type":"markdown","source":"Now, we will take all the features readabiltiy module can give us and then remove them by calculating their correlation with each other and with the target variable.","metadata":{}},{"cell_type":"code","source":"X = pd.DataFrame(train_data['id'])\nX.loc[:,'readability'] = train_data.apply(lambda row: row.readability_object['readability grades']['SMOGIndex'], axis=1)\nX.loc[:,'sentiment'] = train_data.apply(lambda row: sentiment_analysis(row.excerpt), axis=1)\nX.loc[:,'characters_per_word'] = train_data.apply(lambda row: row.readability_object['sentence info']['characters_per_word'], axis=1)\nX.loc[:,'syll_per_word'] = train_data.apply(lambda row: row.readability_object['sentence info']['syll_per_word'], axis=1)\nX.loc[:,'words_per_sentence'] = train_data.apply(lambda row: row.readability_object['sentence info']['words_per_sentence'], axis=1)\nX.loc[:,'sentences_per_paragraph'] = train_data.apply(lambda row: row.readability_object['sentence info']['sentences_per_paragraph'], axis=1)\nX.loc[:,'type_token_ratio'] = train_data.apply(lambda row: row.readability_object['sentence info']['type_token_ratio'], axis=1)\nX.loc[:,'characters'] = train_data.apply(lambda row: row.readability_object['sentence info']['characters'], axis=1)\nX.loc[:,'syllables'] = train_data.apply(lambda row: row.readability_object['sentence info']['syllables'], axis=1)\nX.loc[:,'words'] = train_data.apply(lambda row: row.readability_object['sentence info']['words'], axis=1)\nX.loc[:,'wordtypes'] = train_data.apply(lambda row: row.readability_object['sentence info']['wordtypes'], axis=1)\nX.loc[:,'sentences'] = train_data.apply(lambda row: row.readability_object['sentence info']['sentences'], axis=1)\nX.loc[:,'long_words'] = train_data.apply(lambda row: row.readability_object['sentence info']['long_words'], axis=1)\nX.loc[:,'complex_words'] = train_data.apply(lambda row: row.readability_object['sentence info']['complex_words'], axis=1)\nX.loc[:,'complex_words_dc'] = train_data.apply(lambda row: row.readability_object['sentence info']['complex_words_dc'], axis=1)\nX.loc[:,'tobeverb'] = train_data.apply(lambda row: row.readability_object['word usage']['tobeverb'], axis=1)\nX.loc[:,'auxverb'] = train_data.apply(lambda row: row.readability_object['word usage']['auxverb'], axis=1)\nX.loc[:,'conjunction'] = train_data.apply(lambda row: row.readability_object['word usage']['conjunction'], axis=1)\nX.loc[:,'pronoun'] = train_data.apply(lambda row: row.readability_object['word usage']['pronoun'], axis=1)\nX.loc[:,'preposition'] = train_data.apply(lambda row: row.readability_object['word usage']['preposition'], axis=1)\nX.loc[:,'nominalization'] = train_data.apply(lambda row: row.readability_object['word usage']['nominalization'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:34.936259Z","iopub.execute_input":"2021-06-13T09:53:34.936681Z","iopub.status.idle":"2021-06-13T09:53:38.645181Z","shell.execute_reply.started":"2021-06-13T09:53:34.936639Z","shell.execute_reply":"2021-06-13T09:53:38.644451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.info()\nX.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:38.6461Z","iopub.execute_input":"2021-06-13T09:53:38.64647Z","iopub.status.idle":"2021-06-13T09:53:38.68519Z","shell.execute_reply.started":"2021-06-13T09:53:38.646435Z","shell.execute_reply":"2021-06-13T09:53:38.684243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"corr = X.corr()\ncorr.info()\ncorr","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:38.686511Z","iopub.execute_input":"2021-06-13T09:53:38.687062Z","iopub.status.idle":"2021-06-13T09:53:38.735435Z","shell.execute_reply.started":"2021-06-13T09:53:38.687018Z","shell.execute_reply":"2021-06-13T09:53:38.73465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax =plt.subplots(figsize=(8, 6))\nplt.title(\"Correlation Plot\")\nsns.heatmap(corr,\n            mask=np.zeros_like(corr, dtype=np.bool),\n            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:38.736453Z","iopub.execute_input":"2021-06-13T09:53:38.736694Z","iopub.status.idle":"2021-06-13T09:53:39.35982Z","shell.execute_reply.started":"2021-06-13T09:53:38.736668Z","shell.execute_reply":"2021-06-13T09:53:39.358635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that following groups of features has high correlation\n - characters_per_word and syll_per_word\n - characters and syllables\n - long_words, complex_words and complex_words_dc\n - sentences and sentences_per_paragraph\n \nSo, for all these three groups, we can only take one features.","metadata":{}},{"cell_type":"code","source":"tar_corr = pd.merge(X, train_data['target'], left_index=True, right_index=True).corr().loc['target']\ntar_corr","metadata":{"execution":{"iopub.status.busy":"2021-06-13T09:53:39.361192Z","iopub.execute_input":"2021-06-13T09:53:39.361564Z","iopub.status.idle":"2021-06-13T09:53:39.381321Z","shell.execute_reply.started":"2021-06-13T09:53:39.361521Z","shell.execute_reply":"2021-06-13T09:53:39.38024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Correlations of features with target are **not very high** but still reasonable.\n\nWe can still remove features with very less correlation values like sentiment.","metadata":{}}]}