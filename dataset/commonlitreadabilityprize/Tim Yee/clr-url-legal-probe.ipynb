{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import re\nimport os\nimport gc\ngc.enable()\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nimport math\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport logging\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import *\nfrom sklearn.linear_model import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import *\nfrom tensorflow_addons.optimizers import AdamW, RectifiedAdam\nfrom transformers import AutoTokenizer, AutoConfig, TFAutoModel, TFFunnelBaseModel\ntf.get_logger().setLevel(logging.ERROR)\nfrom glob import glob","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-14T05:10:45.476802Z","iopub.execute_input":"2021-07-14T05:10:45.477171Z","iopub.status.idle":"2021-07-14T05:10:55.337921Z","shell.execute_reply.started":"2021-07-14T05:10:45.477141Z","shell.execute_reply":"2021-07-14T05:10:55.336872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate RMSE using mixed means","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\nmean_no_url = train[train.url_legal.isnull()].target.mean()\nmean_url    = train[train.url_legal.notnull()].target.mean()\n\nprint(f'Mean w/o url_legal: {mean_no_url:.5f}')\nprint(f'Mean w/  url_legal: {mean_url:.5f}\\n')\n\ntrain['pred'] = train.url_legal.apply(lambda x: mean_no_url if type(x) == float else mean_url)\n\ntrain.iloc[train.url_legal.isnull().index].pred = mean_no_url\ntrain.iloc[train.url_legal.notnull().index].pred = mean_url\nhas_no_url = train[train.url_legal.isnull()]\nhas_url    = train[train.url_legal.notnull()]\nprint(f'RMSE w/ mixed means: {mean_squared_error(train.target, train.pred, squared=False):.5f}')\nprint(f'RMSE w/ simple mean: {mean_squared_error(train.target, np.full(len(train), train.target.mean()), squared=False):.5f}\\n')\nprint(f'RMSE w/o url_legal mean: {mean_squared_error(has_no_url.target, has_no_url.pred, squared=False):.5f}')\nprint(f'RMSE w/  url_legal mean: {mean_squared_error(has_url.target, has_url.pred, squared=False):.5f}')\nsns.displot(train[train.url_legal.isnull()].target);\nsns.displot(train[train.url_legal.notnull()].target);","metadata":{"execution":{"iopub.status.busy":"2021-07-14T05:15:44.801422Z","iopub.execute_input":"2021-07-14T05:15:44.801987Z","iopub.status.idle":"2021-07-14T05:15:45.5288Z","shell.execute_reply.started":"2021-07-14T05:15:44.801951Z","shell.execute_reply":"2021-07-14T05:15:45.527579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Configurations\nBATCH_SIZE = 4\nSEED = 1\nVERBOSE = 2\nFOLDS = 5\nMAX_LEN = 256\nAUTO = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2021-07-14T04:49:50.323845Z","iopub.execute_input":"2021-07-14T04:49:50.32435Z","iopub.status.idle":"2021-07-14T04:49:50.330303Z","shell.execute_reply.started":"2021-07-14T04:49:50.324311Z","shell.execute_reply":"2021-07-14T04:49:50.32874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get the trained model we want to use\nMODEL = '../input/download-distilbert-base-uncased'\nTOKENIZER = AutoTokenizer.from_pretrained(MODEL)\nmodel_paths = sorted(glob('../input/clr-exp387/*.h5'))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T04:49:50.641754Z","iopub.execute_input":"2021-07-14T04:49:50.642212Z","iopub.status.idle":"2021-07-14T04:49:50.760287Z","shell.execute_reply.started":"2021-07-14T04:49:50.642175Z","shell.execute_reply":"2021-07-14T04:49:50.75923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n\n# This function tokenize the text according to a transformers model tokenizer\ndef regular_encode(texts, tokenizer, maxlen = MAX_LEN):\n    enc_di = tokenizer.batch_encode_plus(\n        texts,\n        padding = 'max_length',\n        truncation = True,\n        max_length = maxlen,\n    )\n    \n    return np.array(enc_di['input_ids'])\n\n# This function encode our test sentences\ndef encode_test(x_test, MAX_LEN, tokenizer=None):\n    x_test = regular_encode(x_test.tolist(), tokenizer, maxlen = MAX_LEN)\n    return x_test\n\n# Function to build our model\ndef build_base_model(max_len, MODEL):\n    transformer = TFAutoModel.from_pretrained(MODEL)\n    input_word_ids = tf.keras.layers.Input(shape = (max_len, ), dtype = tf.int32, name = 'input_word_ids')\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    output = tf.keras.layers.Dense(1, activation = 'sigmoid', dtype = 'float32')(cls_token)\n    model = tf.keras.models.Model(inputs = [input_word_ids], outputs = [output])\n    return model\n\n# Function to train and evaluate our model\ndef evaluate(MODEL, MAX_LEN, TOKENIZER):\n    df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\n    test_df = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n    x_test = test_df['excerpt']\n    x_test = encode_test(x_test, MAX_LEN, tokenizer=TOKENIZER)\n    \n    seed_everything(SEED)\n    predictions = np.zeros(len(test_df))\n    \n    for fold, model_path in enumerate(model_paths):\n        print('\\n')\n        print('-'*50)\n        print(f'Training fold {fold + 1}')\n        K.clear_session()\n        model = build_base_model(MAX_LEN, MODEL)\n        model.load_weights(model_path)\n        predictions += model.predict(x_test)[:,0] / FOLDS\n        del model\n\n    sub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n    sub.target = predictions\n    sub.to_csv('has_url.csv', index=False)\n    return sub","metadata":{"execution":{"iopub.status.busy":"2021-07-14T04:49:53.197517Z","iopub.execute_input":"2021-07-14T04:49:53.197964Z","iopub.status.idle":"2021-07-14T04:49:53.214407Z","shell.execute_reply.started":"2021-07-14T04:49:53.197927Z","shell.execute_reply":"2021-07-14T04:49:53.212952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntest = evaluate(MODEL, MAX_LEN, TOKENIZER)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T04:49:54.966978Z","iopub.execute_input":"2021-07-14T04:49:54.967434Z","iopub.status.idle":"2021-07-14T04:51:08.850946Z","shell.execute_reply.started":"2021-07-14T04:49:54.967388Z","shell.execute_reply":"2021-07-14T04:51:08.849828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.merge(test, pd.read_csv('../input/commonlitreadabilityprize/test.csv'), on=['id'], how='left')\ntest.target = test.target.map(lambda x: mean_url if x > 0.5 else mean_no_url)\ntest[['id', 'target']].to_csv('submission.csv', index=False)\ntest.head(7)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T04:51:31.670044Z","iopub.execute_input":"2021-07-14T04:51:31.670531Z","iopub.status.idle":"2021-07-14T04:51:31.715429Z","shell.execute_reply.started":"2021-07-14T04:51:31.670484Z","shell.execute_reply":"2021-07-14T04:51:31.714278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}