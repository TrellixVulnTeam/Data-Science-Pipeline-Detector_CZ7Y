{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"######### IMPORT ########\nimport pickle\nfrom itertools import cycle\nfrom time import time\nfrom tqdm.auto import tqdm\nimport shutil\nfrom pathlib import Path\n\n# Pandas, Numpy\nimport pandas as pd\nimport numpy as np\nfrom numpy import interp\nfrom matplotlib import pyplot as plt\npd.set_option(\"display.max_columns\", None)\n\n# Model evaluation\nfrom sklearn.metrics import plot_confusion_matrix, roc_auc_score,  auc, \\\n    precision_recall_fscore_support, classification_report, roc_curve, plot_roc_curve\n\n# Sklearn pipeline\nfrom sklearn.base import TransformerMixin, BaseEstimator\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn import set_config\nfrom sklearn.pipeline import Pipeline\nset_config(display = 'diagram')\n\n\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import train_test_split\n\nfrom catboost import CatBoostClassifier, CatBoostRegressor\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ndata_test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ndata_sample_submission = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_sample_submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train.describe(percentiles=[0.01, 0.05, 0.25, 0.75, 0.95, 0.99])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['target'].hist(bins=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['standard_error'].hist(bins=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(data_train['target'] - data_train['standard_error']).hist(bins=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(data_train['target'] + data_train['standard_error']).hist(bins=30)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Explore","metadata":{}},{"cell_type":"code","source":"data_train['license'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['excerpt'][0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Build pipeline process","metadata":{}},{"cell_type":"code","source":"######## SUPPORTING CLASSES ########\nclass PipelineLogger(object):\n    def __init__(self):\n        pass\n        \n    def log_start(self):\n        self.start_time = time()\n        print(f'======== {self.__class__.__name__} - START ========')\n        return None\n        \n    def log_finish(self):\n        self.duration = time() - self.start_time\n        print(f'======== {self.__class__.__name__} - FINISH =======> Take: {self.duration:.6f}(s)')\n\nclass featureUnion(FeatureUnion):\n    def _hstack(self, Xs):\n        cols = [X.columns.tolist() for X in Xs]\n        dtypes = []\n        for X in Xs:\n            dtypes.append([str(X[col].dtype) for col in X])\n        cols = np.hstack(cols)\n        dtypes = np.hstack(dtypes)\n        data = pd.DataFrame(super()._hstack(Xs), columns = cols)\n        print('====Converting columns types====')\n        for col, dtype in tqdm(zip(cols, dtypes)):\n            data[col] = data[col].astype(dtype)\n        return data\n\nclass columnTransformer(ColumnTransformer):\n    def _hstack(self, Xs):\n        cols = [X.columns.tolist() for X in Xs]\n        dtypes = []\n        for X in Xs:\n            dtypes.append([str(X[col].dtype) for col in X])\n        cols = np.hstack(cols)\n        dtypes = np.hstack(dtypes)\n        data = pd.DataFrame(super()._hstack(Xs), columns = cols)\n        print('====Converting columns types====')\n        for col, dtype in tqdm(zip(cols, dtypes)):\n            data[col] = data[col].astype(dtype)\n        return data\n\nclass ExperimentBase(BaseEstimator):\n    def evaluate(self, X_test, y_test):\n        print('Evaluating model')\n        print(classification_report(y_true=y_test, y_pred=self.predict(X_test)))\n        metrics = self.auc_report(X_test, y_test)\n        metrics['precision'], metrics['recall'], metrics['f1_score'], metrics['support'] = precision_recall_fscore_support(y_test, self.predict(X_test))\n        return metrics\n    \n    def auc_report(self, X, y_true):\n        classes = self.classes_\n        y_pred_classes = self.predict_proba(X)\n        n_classes = len(classes)\n\n        lw = 2\n        for i in range(len(classes)):\n            print(f\"\"\"{classes[i]}: {roc_auc_score(y_true=(y_true==classes[i]).astype(int), y_score=y_pred_classes[:,i])}\"\"\")\n\n        # Compute ROC curve and ROC area for each class\n        fpr = dict()\n        tpr = dict()\n        roc_auc = dict()\n\n        for i in range(n_classes):\n            fpr[i], tpr[i], _ = roc_curve(y_true=(y_true==classes[i]).astype(int), y_score=y_pred_classes[:,i])\n            roc_auc[i] = auc(fpr[i], tpr[i])\n\n        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(len(classes))]))\n\n        # Then interpolate all ROC curves at this points\n        mean_tpr = np.zeros_like(all_fpr)\n        for i in range(len(classes)):\n            mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n\n        # Finally average it and compute AUC\n        mean_tpr /= n_classes\n\n        fpr[\"macro\"] = all_fpr\n        tpr[\"macro\"] = mean_tpr\n        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n\n        # Plot all ROC curves\n        plt.figure()\n\n        plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n                 label='macro-average ROC curve (area = {0:0.2f})'\n                       ''.format(roc_auc[\"macro\"]),\n                 color='navy', linestyle=':', linewidth=4)\n\n        colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n        for i, color in zip(range(n_classes), colors):\n            plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n                     label='ROC curve of class {0} (area = {1:0.2f})'\n                     ''.format(classes[i], roc_auc[i]))\n\n        plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n        plt.xlim([0.0, 1.0])\n        plt.ylim([0.0, 1.05])\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title('Some extension of Receiver operating characteristic to multi-class')\n        plt.legend(loc=\"lower right\")\n        plt.show()\n        metrics = {\n            'macro_auc': roc_auc[\"macro\"]\n        }\n        for i in range(n_classes):\n            metrics[f'auc_{classes[i]}'] = roc_auc[i]\n        return metrics\n    \nclass simpleImputer(SimpleImputer):\n    def fit(self, X, y=None):\n        self._cols = X.columns.tolist()\n        self._dtypes = [str(X[col].dtype) for col in X.columns]\n        super().fit(X, y)\n        return self\n        \n    def transform(self, X):\n        X_ = super().transform(X)\n        data = pd.DataFrame(X_, columns = self._cols)\n        for col, dtype in tqdm(zip(self._cols, self._dtypes)):\n            data[col] = data[col].astype(dtype)\n        return data\n######## DONE SUPPORTING CLASSES ########","metadata":{"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"('max_imputor', simpleImputer(strategy='constant', fill_value='unk'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextLowerer(BaseEstimator, TransformerMixin, PipelineLogger):\n    def __init__(self, columns):\n        super().__init__()\n        self.columns = columns\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X_ = X[self.columns].copy()\n        for c in X_.columns:\n            X_[c] = X_[c].apply(lambda x: x.lower())\n        return X_\n\nclass TextSpliter(BaseEstimator, TransformerMixin, PipelineLogger):\n    def __init__(self, columns, spliters):\n        super().__init__()\n        self.spliters = spliters\n        self.columns = columns\n        \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        X_ = X[self.columns].copy()\n        for col in self.columns:\n            X_[col] = X_[col].str.replace(pat='(:|/|_|-)',repl=' ', regex=True)\n        return X_\n    \nclass PassThroughExcept(BaseEstimator, TransformerMixin, PipelineLogger):\n    def __init__(self, col_except_func):\n        super().__init__()\n        self.col_except_func = col_except_func\n        \n    def fit(self, X, y=None):\n        self.except_cols = self.col_except_func(X)\n        return self\n    \n    def transform(self, X):\n        self.log_start()\n        X_ = X[[c for c in X.columns if c not in self.except_cols]]\n        self.log_finish()\n        return X_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train['url_legal'].str.replace(pat='(:|/|_|-)',repl=' ', regex=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series(dtype='object')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextCombinator(BaseEstimator, TransformerMixin, PipelineLogger):\n    def fit(self, X, y=None):\n        self.cols = X.columns.to_list()\n        return self\n    \n    def transform(self, X):\n        X_ = X.copy()\n        X_['comb_text'] = ''\n        for c in self.cols:\n            X_['comb_text'] += ' ' + X[c]\n        return X_['comb_text']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SVR()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl_preprocess = Pipeline(steps=[\n    ('unk_imputing', simpleImputer(strategy='constant', fill_value='unk')),\n    ('text_lowering', TextLowerer(columns=['url_legal', 'license', 'excerpt'])),\n    ('feature_processing', featureUnion(transformer_list=[\n        ('text_spliting', TextSpliter(columns=['url_legal', 'license'], spliters=[':', '/', '_', '-'])),\n        ('pass_through', PassThroughExcept(col_except_func=lambda X: [c for c in X.columns if c in ['url_legal', 'license']]))\n    ])),\n    ('combine_text', TextCombinator()),\n    ('vect', CountVectorizer(ngram_range=(1,1), max_df=0.9, max_features=None)), \n    ('tfidf', TfidfTransformer()),\n    ('clf', SVR(kernel= \"rbf\",gamma='scale',C=2))\n    \n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl_preprocess","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pl_preprocess.fit(data_train.drop(columns=['target', 'standard_error']), data_train.target)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test_copy = data_test.copy()\ndata_test_copy['target'] = pl_preprocess.predict(data_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test_copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_test_copy[['id', 'target']].to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_copy = data_train.copy()\ndata_train_copy['pred'] = pl_preprocess.predict(data_train.drop(columns=['target', 'standard_error']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata_train_copy","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_squared_error(data_train_copy['target'], data_train_copy['pred'], squared=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train's rmse ~ 0.269 is much much lower than submission score (~ 0.750)\n\n=> Could be overfitting","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}