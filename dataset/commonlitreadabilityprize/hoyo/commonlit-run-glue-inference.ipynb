{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**Training notebook** [here](https://www.kaggle.com/bumjunkoo/commonlit-run-glue/edit) will take around 40 minutes to run with GPU enabled   \n**Fitting notebook** [here](https://www.kaggle.com/bumjunkoo/commonlit-run-glue-fit) will take 1 hour and ~40 minutes to run with GPU enabled","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_text = test[['excerpt']].copy()\ntest_text.rename(columns={'excerpt':'text'}, inplace=True)\ntest_text.to_csv('test_data.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:06:05.087666Z","iopub.execute_input":"2021-06-19T15:06:05.088048Z","iopub.status.idle":"2021-06-19T15:06:05.355531Z","shell.execute_reply.started":"2021-06-19T15:06:05.087968Z","shell.execute_reply":"2021-06-19T15:06:05.354582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoModel, AutoTokenizer, AutoModelForSequenceClassification\ntokenizer = AutoTokenizer.from_pretrained(\"../input/huggingface-roberta/roberta-base\")\n\ntest_encodes = tokenizer([i for i in test_text.text], max_length=325, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:06:05.357108Z","iopub.execute_input":"2021-06-19T15:06:05.357482Z","iopub.status.idle":"2021-06-19T15:06:07.349108Z","shell.execute_reply.started":"2021-06-19T15:06:05.357443Z","shell.execute_reply":"2021-06-19T15:06:07.348275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset, DataLoader\n\nclass CommonLitDataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])\n\ntest_dataset = CommonLitDataset(test_encodes)","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:06:07.350763Z","iopub.execute_input":"2021-06-19T15:06:07.351085Z","iopub.status.idle":"2021-06-19T15:06:07.360823Z","shell.execute_reply.started":"2021-06-19T15:06:07.351046Z","shell.execute_reply":"2021-06-19T15:06:07.360029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer)\ntest_dataloader = DataLoader(\n    test_dataset, batch_size=16, collate_fn=data_collator\n)\n\n# for step, batch in enumerate(test_dataloader):\n#     print(batch[\"input_ids\"].shape)\n#     if step > 5:\n#         break","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:06:07.362324Z","iopub.execute_input":"2021-06-19T15:06:07.362678Z","iopub.status.idle":"2021-06-19T15:06:13.091288Z","shell.execute_reply.started":"2021-06-19T15:06:07.362636Z","shell.execute_reply":"2021-06-19T15:06:13.0904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer, TrainingArguments\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n\nmodel = AutoModelForSequenceClassification.from_pretrained('../input/commonlit-run-glue/output')\nmodel.load_state_dict(torch.load(\"../input/commonlit-run-glue-fit/model.pt\"))\nmodel.to(device)\npreds = []\nfor batch in test_dataloader:\n    batch = {k: v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n        prediction = outputs.logits\n        preds.extend(np.array(prediction.cpu().squeeze()))\n\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\nsample.target = preds\nsample.to_csv('submission.csv',index=False)\nsample","metadata":{"execution":{"iopub.status.busy":"2021-06-19T15:06:13.092711Z","iopub.execute_input":"2021-06-19T15:06:13.093054Z","iopub.status.idle":"2021-06-19T15:06:57.259467Z","shell.execute_reply.started":"2021-06-19T15:06:13.093016Z","shell.execute_reply":"2021-06-19T15:06:57.258553Z"},"trusted":true},"execution_count":null,"outputs":[]}]}