{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#DOWNLOAD NLP locally\n\nimport sys\nsys.path.append('../input/nlp-repo')\n!cp -r ../input/nlp-repo ./\n!mv nlp-repo NLP","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install --no-index fsspec==0.9.0 --find-links=file:///kaggle/input/fsspec-package/fsspec","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip3 install --no-index datasets --find-links=file:///kaggle/input/datasets-package/datasets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from NLP.dataset_utils import clean_datasets\nfrom datasets import Dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset, testset = clean_datasets()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainset.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\ntokenizer = transformers.RobertaTokenizer.from_pretrained(\"../input/roberta-transformers-pytorch/roberta-base\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = transformers.RobertaForSequenceClassification.from_pretrained(\"../input/roberta-transformers-pytorch/roberta-base\", num_labels=1)","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples, name=\"text\"):\n    return tokenizer(examples[name], padding=\"max_length\", truncation=True)\n\ntokenized_trainset = trainset.map(tokenize_function, batched=True)\ntokenized_testset = testset.map(tokenize_function, batched=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_trainset.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_trainset = tokenized_trainset.remove_columns(['text', 'id', 'index', 'standard_error'])\ntokenized_testset = tokenized_testset.remove_columns(['text', 'id', 'index', 'standard_error'])\n\ntokenized_trainset.set_format('torch')\ntokenized_testset.set_format('torch')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\n\ntrain_dataloader = DataLoader(tokenized_trainset, shuffle=True, batch_size=8)\ntest_dataloader = DataLoader(tokenized_testset, batch_size=8)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AdamW\n\noptimizer = AdamW(model.parameters(), lr=5e-5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_scheduler\n\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler(\n    \"linear\",\n    optimizer=optimizer,\n    num_warmup_steps=0,\n    num_training_steps=num_training_steps\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\nimport torch\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\nmodel.to(device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n\n#progress_bar = tqdm(range(num_training_steps))\n\nmodel.train()\nfor epoch in tqdm(range(num_epochs)):\n    for batch in train_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        #progress_bar.update(1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trying a submission\nimport pandas as pd\n\nsubmission_data = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\nsubmission_dataset = Dataset.from_pandas(submission_data)\n\n#submission_dataset.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tokenize_function(examples, name=\"excerpt\"):\n    return tokenizer(examples[name], padding=\"max_length\", truncation=True)\n\nsub_tokenized = submission_dataset.map(tokenize_function, batched=True)\nsub_tokenized.features","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#need this for the submission file\nids_sub = submission_data['id']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_tokenized = sub_tokenized.remove_columns(['excerpt', 'id', 'license', 'url_legal'])\n\nsub_tokenized.set_format('torch')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_dataloader = DataLoader(sub_tokenized, batch_size=7)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for b in sub_dataloader:\n    batch = {k: v.to(device) for k, v in b.items()}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = model(**batch)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(outputs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.Series([],dtype=pd.StringDtype())\nfor i in range(len(ids_sub)):\n        results.at[i] = float(outputs[0][i].item())\nprint(results)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = pd.Series({'id': ids_sub, 'target': results})\ns.to_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ids_new = pd.Series( (v for v in ids_sub))\n#data = [ids_new, results]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nheaders = [\"id\", \"target\"]\nsubmission = pd.concat(data, axis=1, keys = headers)\n\n#show submission\nprint(submission)\n\n#save submission\nsubmission.to_csv('submission.csv', index = False)\n\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r ./NLP","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}