{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# This note book is Modified for Haruki's learning. ","metadata":{}},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"This is inference notebooks that is trained using below notebooks.\n\nThis notebook uses the model created in pretrain any model notebook.\n\n1. Pretrain Roberta Model: https://www.kaggle.com/maunish/clrp-pytorch-roberta-pretrain\n2. Finetune Roberta Model: https://www.kaggle.com/maunish/clrp-pytorch-roberta-finetune <br/>\n   Finetune Roberta Model TPU: https://www.kaggle.com/maunish/clrp-pytorch-roberta-finetune-tpu\n3. Inference Notebook: this notebook\n4. Roberta + SVM: https://www.kaggle.com/maunish/clrp-roberta-svm\n","metadata":{}},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader,Sampler\n\nfrom transformers import (AutoModel, AutoTokenizer,\n                          AutoConfig ,AutoModelForSequenceClassification)\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-25T13:32:43.821065Z","iopub.execute_input":"2021-07-25T13:32:43.821682Z","iopub.status.idle":"2021-07-25T13:32:47.91239Z","shell.execute_reply.started":"2021-07-25T13:32:43.821587Z","shell.execute_reply":"2021-07-25T13:32:47.911324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:32:47.914232Z","iopub.execute_input":"2021-07-25T13:32:47.9147Z","iopub.status.idle":"2021-07-25T13:32:48.016451Z","shell.execute_reply.started":"2021-07-25T13:32:47.914621Z","shell.execute_reply":"2021-07-25T13:32:48.015411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'learning_rate':2e-5,\n    'batch_size':16,\n    'epochs':3,\n    'nfolds':5,\n    'seed':42,\n    'max_len':256,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:32:48.018959Z","iopub.execute_input":"2021-07-25T13:32:48.019396Z","iopub.status.idle":"2021-07-25T13:32:48.031953Z","shell.execute_reply.started":"2021-07-25T13:32:48.019351Z","shell.execute_reply":"2021-07-25T13:32:48.030805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:32:48.034433Z","iopub.execute_input":"2021-07-25T13:32:48.035028Z","iopub.status.idle":"2021-07-25T13:32:48.043112Z","shell.execute_reply.started":"2021-07-25T13:32:48.034984Z","shell.execute_reply":"2021-07-25T13:32:48.041789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:32:48.045107Z","iopub.execute_input":"2021-07-25T13:32:48.045959Z","iopub.status.idle":"2021-07-25T13:32:48.056615Z","shell.execute_reply.started":"2021-07-25T13:32:48.045817Z","shell.execute_reply":"2021-07-25T13:32:48.055438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,model_path):\n        super(Model,self).__init__()\n        self.roberta = AutoModel.from_pretrained(model_path) \n        self.config = AutoConfig.from_pretrained(model_path)\n        self.head = AttentionHead(self.config.hidden_size,self.config.hidden_size)\n        self.dropout = nn.Dropout(0.1)\n        self.linear = nn.Linear(self.config.hidden_size,1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n        x = self.dropout(x)\n        x = self.linear(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:32:48.058299Z","iopub.execute_input":"2021-07-25T13:32:48.05882Z","iopub.status.idle":"2021-07-25T13:32:48.072785Z","shell.execute_reply.started":"2021-07-25T13:32:48.058774Z","shell.execute_reply":"2021-07-25T13:32:48.071492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_prediction(df,path,model_path,device='cuda'):        \n    #モデルセットアップお作法...後でggる\n    model = Model(model_path)\n    model.load_state_dict(torch.load(path,map_location=device))\n    model.to(device)\n    model.eval()\n    \n    #tokenizerの読み込み\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n    \n    #読み込んだdfをtokenizerで処理してtest_dsにする\n    test_ds = CLRPDataset(df,tokenizer)\n    test_dl = DataLoader(test_ds,\n                        batch_size = config[\"batch_size\"],\n                        shuffle=False,\n                        num_workers = 4,\n                        pin_memory=True)\n    \n    predictions = list()\n    #tqdmでシークバーを出しながら、test_dlを処理していく\n    for i, (inputs) in tqdm(enumerate(test_dl)):\n        inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n        outputs = model(**inputs)\n        outputs = outputs.cpu().detach().numpy().ravel().tolist()\n        #各inputに対する予測結果をpredictionｓに追記していく\n        predictions.extend(outputs)\n        \n    torch.cuda.empty_cache()\n    \n    #predictionsを予測結果として返す\n    return np.array(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:32:48.074585Z","iopub.execute_input":"2021-07-25T13:32:48.075104Z","iopub.status.idle":"2021-07-25T13:32:48.087133Z","shell.execute_reply.started":"2021-07-25T13:32:48.075057Z","shell.execute_reply":"2021-07-25T13:32:48.085787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#modelを0-4までfoldで抽出したmodelを使って予測する\npred1 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-roberta-large/model0/model0.bin','../input/clrp-pytorch-roberta-pretrain-roberta-large/clrp_roberta_large')\npred2 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-roberta-large/model1/model1.bin','../input/clrp-pytorch-roberta-pretrain-roberta-large/clrp_roberta_large')\npred3 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-roberta-large/model2/model2.bin','../input/clrp-pytorch-roberta-pretrain-roberta-large/clrp_roberta_large')\npred4 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-roberta-large/model3/model3.bin','../input/clrp-pytorch-roberta-pretrain-roberta-large/clrp_roberta_large')\npred5 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-roberta-large/model4/model4.bin','../input/clrp-pytorch-roberta-pretrain-roberta-large/clrp_roberta_large')\n\npredictions1 = (pred1 + pred2 + pred3 + pred4 + pred5)/5","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:32:48.08917Z","iopub.execute_input":"2021-07-25T13:32:48.090067Z","iopub.status.idle":"2021-07-25T13:35:16.426608Z","shell.execute_reply.started":"2021-07-25T13:32:48.089841Z","shell.execute_reply":"2021-07-25T13:35:16.4253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#こっちはtpuモデル\npred1 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-tpu/model0/model0.bin','../input/clrp-pytorch-roberta-pretrain/clrp_roberta_base')\npred2 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-tpu/model1/model1.bin','../input/clrp-pytorch-roberta-pretrain/clrp_roberta_base')\npred3 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-tpu/model2/model2.bin','../input/clrp-pytorch-roberta-pretrain/clrp_roberta_base')\npred4 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-tpu/model3/model3.bin','../input/clrp-pytorch-roberta-pretrain/clrp_roberta_base')\npred5 = get_prediction(test_data,'../input/clrp-pytorch-roberta-finetune-tpu/model4/model4.bin','../input/clrp-pytorch-roberta-pretrain/clrp_roberta_base')\npredictions2 = (pred1 + pred2 + pred3 + pred4 + pred5)/5","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:35:16.430452Z","iopub.execute_input":"2021-07-25T13:35:16.430852Z","iopub.status.idle":"2021-07-25T13:35:16.435427Z","shell.execute_reply.started":"2021-07-25T13:35:16.430817Z","shell.execute_reply":"2021-07-25T13:35:16.433864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#CPUGPU and TPUモデルの平均を予測値とする\n\nsample['target'] = (predictions1 + predictions2)/2\nsample['target'] = predictions1\n\nsample.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:35:16.437578Z","iopub.execute_input":"2021-07-25T13:35:16.438488Z","iopub.status.idle":"2021-07-25T13:35:17.092732Z","shell.execute_reply.started":"2021-07-25T13:35:16.438399Z","shell.execute_reply":"2021-07-25T13:35:17.091529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample","metadata":{"execution":{"iopub.status.busy":"2021-07-25T13:35:57.832233Z","iopub.execute_input":"2021-07-25T13:35:57.832602Z","iopub.status.idle":"2021-07-25T13:35:57.843431Z","shell.execute_reply.started":"2021-07-25T13:35:57.832571Z","shell.execute_reply":"2021-07-25T13:35:57.842239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}