{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os \nimport re\n\n# for data cleaning\nimport string\n\n# for calculating Polarity and Subjectivity\nfrom textblob import TextBlob\n\n# import all the necessary libraries\nimport warnings\n\n#for Tokenization\nimport nltk\n\n#for Wordscloud\nfrom wordcloud import WordCloud\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom nltk.tokenize import sent_tokenize, word_tokenize\n\n#Ignoring unnecessory warnings\nwarnings.filterwarnings(\"ignore\")                   \n\n# for stopwords Removal\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\n\n# for removing accented and special chracters\nimport plotly.express as px\nimport unicodedata\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.ensemble import RandomForestClassifier              #for data manipulation and analysis \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler , LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix , accuracy_score , f1_score , classification_report , roc_curve , auc , roc_auc_score , zero_one_loss\nfrom sklearn.linear_model import LinearRegression","metadata":{"execution":{"iopub.status.busy":"2022-02-13T20:56:55.765791Z","iopub.execute_input":"2022-02-13T20:56:55.766581Z","iopub.status.idle":"2022-02-13T20:56:59.210088Z","shell.execute_reply.started":"2022-02-13T20:56:55.766539Z","shell.execute_reply":"2022-02-13T20:56:59.209265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing and Reading","metadata":{}},{"cell_type":"code","source":"paths = [ '../input/commonlitreadabilityprize/sample_submission.csv' ,\n          '../input/commonlitreadabilityprize/test.csv' , \n          '../input/commonlitreadabilityprize/train.csv'\n          ]\n\ntrain = pd.read_csv(paths[2])\ntest = pd.read_csv(paths[1])\nsubmission = pd.read_csv(paths[0])\n\ndisplay( train.head() )","metadata":{"execution":{"iopub.status.busy":"2022-02-13T20:56:59.211946Z","iopub.execute_input":"2022-02-13T20:56:59.212799Z","iopub.status.idle":"2022-02-13T20:56:59.378504Z","shell.execute_reply.started":"2022-02-13T20:56:59.212751Z","shell.execute_reply":"2022-02-13T20:56:59.377467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display( train.isnull().sum() )","metadata":{"execution":{"iopub.status.busy":"2022-02-13T20:57:02.496067Z","iopub.execute_input":"2022-02-13T20:57:02.49641Z","iopub.status.idle":"2022-02-13T20:57:02.508479Z","shell.execute_reply.started":"2022-02-13T20:57:02.496375Z","shell.execute_reply":"2022-02-13T20:57:02.507794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.drop(['url_legal' , 'license'] , axis=1 , inplace = True)\n\ndisplay( train.head() )","metadata":{"execution":{"iopub.status.busy":"2022-02-13T20:57:10.433525Z","iopub.execute_input":"2022-02-13T20:57:10.434278Z","iopub.status.idle":"2022-02-13T20:57:10.456341Z","shell.execute_reply.started":"2022-02-13T20:57:10.434241Z","shell.execute_reply":"2022-02-13T20:57:10.455329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt'][0]","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:25.173036Z","iopub.execute_input":"2022-01-21T15:18:25.173592Z","iopub.status.idle":"2022-01-21T15:18:25.181536Z","shell.execute_reply.started":"2022-01-21T15:18:25.173545Z","shell.execute_reply":"2022-01-21T15:18:25.180892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"stop_words = nltk.corpus.stopwords.words(\"english\")\n\ndef preprocess(text):\n    # removal of extra spaces\n    regex_pat = re.compile(r'\\s+')\n    text = text.str.replace(regex_pat, ' ')\n    \n    # removal of punctuations and numbers\n    punc_remove = text.str.replace(\"[^a-zA-Z]\", \" \")\n    \n    # remove whitespace with a single space\n    new_text=punc_remove.str.replace(r'\\s+', ' ')\n    \n    # remove leading and trailing whitespace\n    new_text=new_text.str.replace(r'^\\s+|\\s+?$','')\n    \n    # replace normal numbers with numbr\n    new_text=new_text.str.replace(r'\\d+(\\.\\d+)?','numbr')\n    \n    # removal of capitalization\n    text_lower = new_text.str.lower()\n    \n    # tokenizing\n    tokenized_text = text_lower.apply(lambda x: x.split())\n    \n    # removal of stopwords\n    tokenized_text=  tokenized_text.apply(lambda x: [item for item in x if item not in stop_words])\n    \n    for i in range(len(tokenized_text)):\n        tokenized_text[i] = ' '.join(tokenized_text[i])\n        texts_p= tokenized_text\n    \n    return texts_p\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:28.223964Z","iopub.execute_input":"2022-01-21T15:18:28.224834Z","iopub.status.idle":"2022-01-21T15:18:28.241861Z","shell.execute_reply.started":"2022-01-21T15:18:28.224776Z","shell.execute_reply":"2022-01-21T15:18:28.240674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train['excerpt'] = train['excerpt'].apply(preprocess)\ntext = train.excerpt\npreprocessed_text = preprocess(text)\n\ntrain['preprocessed_excerpt'] = preprocessed_text\n\nprint(train['excerpt'][0])\nprint('')\nprint(train['preprocessed_excerpt'][0])\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:30.207154Z","iopub.execute_input":"2022-01-21T15:18:30.208063Z","iopub.status.idle":"2022-01-21T15:18:32.301247Z","shell.execute_reply.started":"2022-01-21T15:18:30.208018Z","shell.execute_reply":"2022-01-21T15:18:32.30038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"**Help taken from https://www.kaggle.com/mohamedbakrey/eda-for-commonlit-rp-ml-predict**\n\nCheck for more fe (comparison on nouns , adj etc)","metadata":{}},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:35.755659Z","iopub.execute_input":"2022-01-21T15:18:35.75598Z","iopub.status.idle":"2022-01-21T15:18:35.779788Z","shell.execute_reply.started":"2022-01-21T15:18:35.755942Z","shell.execute_reply":"2022-01-21T15:18:35.778695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['length'] = train['preprocessed_excerpt'].apply(len)\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:37.12872Z","iopub.execute_input":"2022-01-21T15:18:37.129152Z","iopub.status.idle":"2022-01-21T15:18:37.144173Z","shell.execute_reply.started":"2022-01-21T15:18:37.129121Z","shell.execute_reply":"2022-01-21T15:18:37.143496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Text Polarity**\n\nIt is the expression that determines the sentimental aspect of an opinion. In textual data, the result of sentiment analysis can be determined for each entity in the sentence, document or sentence. The sentiment polarity can be determined as positive, negative and neutral.","metadata":{}},{"cell_type":"code","source":"def get_polarity(text):\n    textblob = TextBlob(str(text.encode('utf-8')))\n    pol = textblob.sentiment.polarity\n    return pol\n\ntrain['polarity'] = train['preprocessed_excerpt'].apply(get_polarity)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:39.441842Z","iopub.execute_input":"2022-01-21T15:18:39.44213Z","iopub.status.idle":"2022-01-21T15:18:41.741496Z","shell.execute_reply.started":"2022-01-21T15:18:39.442099Z","shell.execute_reply":"2022-01-21T15:18:41.740502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Text Subjectivity**\n\nIn natural language, subjectivity refers to expression of opinions, evaluations, feelings, and speculations and thus incorporates sentiment. Subjective text is further classified with sentiment or polarity.","metadata":{}},{"cell_type":"code","source":"# Lets calculate the Subjectvity of the Reviews\ndef get_subjectivity(text):\n    textblob = TextBlob(str(text.encode('utf-8')))\n    subj = textblob.sentiment.subjectivity\n    return subj\n\n# lets apply the Function\ntrain['subjectivity'] = train['preprocessed_excerpt'].apply(get_subjectivity)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:41.975708Z","iopub.execute_input":"2022-01-21T15:18:41.975994Z","iopub.status.idle":"2022-01-21T15:18:44.223348Z","shell.execute_reply.started":"2022-01-21T15:18:41.975962Z","shell.execute_reply":"2022-01-21T15:18:44.222404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[['length','polarity','subjectivity']].describe().style.background_gradient(cmap = 'copper')","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:44.225283Z","iopub.execute_input":"2022-01-21T15:18:44.225729Z","iopub.status.idle":"2022-01-21T15:18:44.319171Z","shell.execute_reply.started":"2022-01-21T15:18:44.225679Z","shell.execute_reply":"2022-01-21T15:18:44.318246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training (Feature Extraction)","metadata":{}},{"cell_type":"markdown","source":"**Bag of Words VS TFIDF**","metadata":{}},{"cell_type":"markdown","source":"**1) Bag of Words**\n\nThe bag-of-words model is a simplifying representation used in natural language processing and information retrieval (IR). In this model, a text (such as a sentence or a document) is represented as the bag (multiset) of its words, disregarding grammar and even word order but keeping multiplicity.","metadata":{}},{"cell_type":"code","source":"# Creating bag of words\nfrom sklearn.feature_extraction.text import CountVectorizer\n\ncv = CountVectorizer(max_features=30000)\n\nX = cv.fit_transform(train['preprocessed_excerpt']).toarray()\ny = train.target","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:48.507192Z","iopub.execute_input":"2022-01-21T15:18:48.507519Z","iopub.status.idle":"2022-01-21T15:18:49.141859Z","shell.execute_reply.started":"2022-01-21T15:18:48.507485Z","shell.execute_reply":"2022-01-21T15:18:49.141072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Feature Scaling\nsc = StandardScaler()\nX = sc.fit_transform(X)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:50.64924Z","iopub.execute_input":"2022-01-21T15:18:50.649575Z","iopub.status.idle":"2022-01-21T15:18:52.467211Z","shell.execute_reply.started":"2022-01-21T15:18:50.649542Z","shell.execute_reply":"2022-01-21T15:18:52.466218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting the dataset into the Training set and Test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)\n\nprint(X_train.shape , X_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:53.341191Z","iopub.execute_input":"2022-01-21T15:18:53.341515Z","iopub.status.idle":"2022-01-21T15:18:53.530143Z","shell.execute_reply.started":"2022-01-21T15:18:53.34148Z","shell.execute_reply":"2022-01-21T15:18:53.529218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport lightgbm as lgb\nimport xgboost as xgb","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:56.016067Z","iopub.execute_input":"2022-01-21T15:18:56.016359Z","iopub.status.idle":"2022-01-21T15:18:56.409299Z","shell.execute_reply.started":"2022-01-21T15:18:56.016328Z","shell.execute_reply":"2022-01-21T15:18:56.408644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dic_models = {#'RandomForestRegressor' : RandomForestRegressor(criterion='mse'), \n              #'GradientBoosting' : GradientBoostingRegressor() ,\n              'LightGBM' : lgb.LGBMRegressor(),\n              'XGradientBoosting' : xgb.XGBRegressor()    \n                }\n            #'CBR' : cb.CatBoostRegressor() \n    \nfor i in dic_models:\n    print('Training with ' + i + ' model. \\n')\n    \n    model = dic_models[i].fit(X_train , y_train)\n    \n    #Predicting\n    print('Predicting with ' + i + ' model. \\n')\n    pred = model.predict(X_test)\n    \n    # Using Accuracy Score for predicting models\n    print(\"Accuracy of \" + i + \" Model is \", model.score(X_test , y_test))\n    print(\"RMSE of \" + i + \" Model is \", np.sqrt(mean_squared_error(y_test , pred)))    \n    print(\"------------------------------------------------------------------\")\n    print()    ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:12:42.04244Z","iopub.execute_input":"2022-01-21T16:12:42.042708Z","iopub.status.idle":"2022-01-21T16:13:05.000416Z","shell.execute_reply.started":"2022-01-21T16:12:42.042679Z","shell.execute_reply":"2022-01-21T16:13:04.999052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting Linear Regression to the data set\nlin_reg = LinearRegression()\nlin_reg.fit(X_train,y_train)\n\n#Calculating Details\nprint('LogisticRegressionModel Train Score is : ' , lin_reg .score(X_train, y_train))\nprint('LogisticRegressionModel Test Score is : ' , lin_reg .score(X_test, y_test))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:18:58.926282Z","iopub.execute_input":"2022-01-21T15:18:58.927424Z","iopub.status.idle":"2022-01-21T15:19:13.333406Z","shell.execute_reply.started":"2022-01-21T15:18:58.927379Z","shell.execute_reply":"2022-01-21T15:19:13.332392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"rsquare no acc","metadata":{}},{"cell_type":"markdown","source":"**2) TFIDF**","metadata":{}},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\n\ntfidf_vectorizer = TfidfVectorizer()\n\n# TF-IDF feature matrix\ntfidf = tfidf_vectorizer.fit_transform(train['preprocessed_excerpt'] )","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:00:03.649107Z","iopub.execute_input":"2022-01-21T16:00:03.649425Z","iopub.status.idle":"2022-01-21T16:00:04.056249Z","shell.execute_reply.started":"2022-01-21T16:00:03.649392Z","shell.execute_reply":"2022-01-21T16:00:04.055409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"matrix = pd.DataFrame(tfidf.toarray())\nmatrix","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:23:43.900599Z","iopub.execute_input":"2022-01-21T15:23:43.900952Z","iopub.status.idle":"2022-01-21T15:23:44.474956Z","shell.execute_reply.started":"2022-01-21T15:23:43.900908Z","shell.execute_reply":"2022-01-21T15:23:44.47407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# If you don't specify the random_state in the code, \n# then every time you run(execute) your code a new random value is generated \n# and the train and test datasets would have different values each time.\nX = tfidf\ny = train.target\nX_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X, y,random_state=42, test_size=0.25)\n\nprint(\"Training split input- \", X_train_tfidf.shape)   # X FOR INPUT\nprint(\"Testing split input- \", X_test_tfidf.shape)\n\nprint(\"\\n\\nY : Training split input- \", y_train.shape) # Y FOR TARGET.\nprint(\"Y : Testing split input- \", y_test.shape)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:00:17.274234Z","iopub.execute_input":"2022-01-21T16:00:17.274577Z","iopub.status.idle":"2022-01-21T16:00:17.286462Z","shell.execute_reply.started":"2022-01-21T16:00:17.27454Z","shell.execute_reply":"2022-01-21T16:00:17.285462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_2 = {#'RandomForestRegressor' : RandomForestRegressor(), \n              'GradientBoosting' : GradientBoostingRegressor() ,    \n              'LightGBM' : lgb.LGBMRegressor(),\n              'XGradientBoosting' : xgb.XGBRegressor()        \n            }\n\nfor i in models_2:\n    print('Training with ' + i + ' model. \\n')\n    \n    model = models_2[i].fit(X_train_tfidf , y_train)\n    \n    #Predicting\n    print('Predicting with ' + i + ' model. \\n')\n    pred = model.predict(X_test_tfidf)\n    \n    # Using Accuracy Score for predicting models\n    print(\"R2 score of \" + i + \" Model is \", model.score(X_test_tfidf , y_test))\n    print(\"RMSE of \" + i + \" Model is \", np.sqrt(mean_squared_error(y_test , pred)))    \n    print(\"------------------------------------------------------------------\")\n    print()    ","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:12:39.616639Z","iopub.status.idle":"2022-01-21T16:12:39.616957Z","shell.execute_reply.started":"2022-01-21T16:12:39.616795Z","shell.execute_reply":"2022-01-21T16:12:39.616812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fitting Linear Regression to the data set\nlin_reg = LinearRegression()\nlin_reg.fit(X_train_tfidf,y_train)\n\npred = lin_reg.predict(X_test_tfidf)\n\n#Calculating Details\nprint('LogisticRegressionModel Train Score is : ' , lin_reg .score(X_train_tfidf, y_train))\nprint('LogisticRegressionModel Test Score is : ' , lin_reg .score(X_test_tfidf, y_test))\nprint(\"RMSE of LOGREGModel is \", np.sqrt(mean_squared_error(y_test , pred)))","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:37:56.991579Z","iopub.execute_input":"2022-01-21T15:37:56.992441Z","iopub.status.idle":"2022-01-21T15:37:57.129375Z","shell.execute_reply.started":"2022-01-21T15:37:56.992396Z","shell.execute_reply":"2022-01-21T15:37:57.128328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train with DLP Roberta https://www.kaggle.com/riadalmadani/finetune-roberta-5-fold**","metadata":{}},{"cell_type":"markdown","source":"# Data Visualization","metadata":{}},{"cell_type":"code","source":"# lets check relation between Polarity and Subjectivity\n\nplt.figure(figsize=(12,6))\nsns.scatterplot(train['polarity'], train['subjectivity'])\nplt.title('Polarity vs Subjectivity')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:44:06.394462Z","iopub.execute_input":"2022-01-21T15:44:06.394908Z","iopub.status.idle":"2022-01-21T15:44:06.623887Z","shell.execute_reply.started":"2022-01-21T15:44:06.394876Z","shell.execute_reply":"2022-01-21T15:44:06.62319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lets plot the Wordscloud\n\ncv = CountVectorizer(stop_words = 'english')\nwords = cv.fit_transform(train['preprocessed_excerpt'])\nsum_words = words.sum(axis=0)\n\nwords_freq = [(word, sum_words[0, idx]) for word, idx in cv.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse = True)\n\nwordcloud = WordCloud(background_color = 'lightcyan', width = 2000, height = 2000).generate_from_frequencies(dict(words_freq))\n\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(10, 10))\nplt.axis('off')\nplt.imshow(wordcloud)\nplt.title(\"Vocabulary from Reviews\", fontsize = 20)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T15:46:13.382381Z","iopub.execute_input":"2022-01-21T15:46:13.382919Z","iopub.status.idle":"2022-01-21T15:46:25.083588Z","shell.execute_reply.started":"2022-01-21T15:46:13.382883Z","shell.execute_reply":"2022-01-21T15:46:25.082618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing and Submission","metadata":{}},{"cell_type":"code","source":"#Training linear regression on complete Data\n\n#Fitting Linear Regression to the data set\nlin_reg = LinearRegression()\nlin_reg.fit(X ,y)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:00:24.661997Z","iopub.execute_input":"2022-01-21T16:00:24.662524Z","iopub.status.idle":"2022-01-21T16:00:24.829836Z","shell.execute_reply.started":"2022-01-21T16:00:24.662467Z","shell.execute_reply":"2022-01-21T16:00:24.828697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:00:26.111996Z","iopub.execute_input":"2022-01-21T16:00:26.112688Z","iopub.status.idle":"2022-01-21T16:00:26.119104Z","shell.execute_reply.started":"2022-01-21T16:00:26.112648Z","shell.execute_reply":"2022-01-21T16:00:26.118235Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:00:27.948965Z","iopub.execute_input":"2022-01-21T16:00:27.949266Z","iopub.status.idle":"2022-01-21T16:00:27.962609Z","shell.execute_reply.started":"2022-01-21T16:00:27.949233Z","shell.execute_reply":"2022-01-21T16:00:27.961816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Preprocessing test data**","metadata":{}},{"cell_type":"code","source":"#train['excerpt'] = train['excerpt'].apply(preprocess)\ntext = test.excerpt\npreprocessed_text = preprocess(text)\n\ntest['preprocessed_excerpt'] = preprocessed_text\n\nprint(test['excerpt'][0])\nprint('')\nprint(test['preprocessed_excerpt'][0])\n","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:00:30.361029Z","iopub.execute_input":"2022-01-21T16:00:30.361769Z","iopub.status.idle":"2022-01-21T16:00:30.376816Z","shell.execute_reply.started":"2022-01-21T16:00:30.361722Z","shell.execute_reply":"2022-01-21T16:00:30.375741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import collections\nimport copy\n\ncorpus_vocabulary = collections.defaultdict(None, copy.deepcopy(tfidf_vectorizer.vocabulary_))\ntfidf_transformer_query_sec = TfidfVectorizer(vocabulary=corpus_vocabulary)\nquery_tfidf_matrix = tfidf_transformer_query_sec.fit_transform(test['preprocessed_excerpt'])\n\n# # TF-IDF feature matrix\n# tfidf = tfidf_vectorizer.transform(test['preprocessed_excerpt'] )","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:01:40.481503Z","iopub.execute_input":"2022-01-21T16:01:40.481937Z","iopub.status.idle":"2022-01-21T16:01:40.552996Z","shell.execute_reply.started":"2022-01-21T16:01:40.481899Z","shell.execute_reply":"2022-01-21T16:01:40.552002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = lin_reg.predict(query_tfidf_matrix)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:01:53.397888Z","iopub.execute_input":"2022-01-21T16:01:53.39822Z","iopub.status.idle":"2022-01-21T16:01:53.402869Z","shell.execute_reply.started":"2022-01-21T16:01:53.398181Z","shell.execute_reply":"2022-01-21T16:01:53.401962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred[:5]","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:02:07.552153Z","iopub.execute_input":"2022-01-21T16:02:07.552492Z","iopub.status.idle":"2022-01-21T16:02:07.55813Z","shell.execute_reply.started":"2022-01-21T16:02:07.552454Z","shell.execute_reply":"2022-01-21T16:02:07.557512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target = pred\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-21T16:03:22.920275Z","iopub.execute_input":"2022-01-21T16:03:22.92115Z","iopub.status.idle":"2022-01-21T16:03:22.930716Z","shell.execute_reply.started":"2022-01-21T16:03:22.921097Z","shell.execute_reply":"2022-01-21T16:03:22.929997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Train using DLP as done in https://www.kaggle.com/riadalmadani/finetune-roberta-5-fold and https://www.kaggle.com/omkargangan/commonlit-readability-competition**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}