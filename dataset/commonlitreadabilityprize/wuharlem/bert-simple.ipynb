{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Package","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport tqdm\n\n## BERT\nimport transformers\nfrom transformers import BertTokenizer, BertModel, get_linear_schedule_with_warmup\n\nimport torch\nfrom torch.utils.data import DataLoader, Dataset, random_split\n\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-07-25T03:58:25.505897Z","iopub.execute_input":"2021-07-25T03:58:25.506259Z","iopub.status.idle":"2021-07-25T03:58:32.195665Z","shell.execute_reply.started":"2021-07-25T03:58:25.506174Z","shell.execute_reply":"2021-07-25T03:58:32.194827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_csv = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-25T03:58:37.38172Z","iopub.execute_input":"2021-07-25T03:58:37.382047Z","iopub.status.idle":"2021-07-25T03:58:37.477183Z","shell.execute_reply.started":"2021-07-25T03:58:37.382017Z","shell.execute_reply":"2021-07-25T03:58:37.476304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Module","metadata":{}},{"cell_type":"code","source":"def pad_to_len(seqs, to_len, padding=0):\n    paddeds = []\n    for seq in seqs:\n        paddeds.append(\n            seq[:to_len] + [padding] * max(0, to_len - len(seq))\n        )\n    return paddeds","metadata":{"execution":{"iopub.status.busy":"2021-07-25T03:58:40.54923Z","iopub.execute_input":"2021-07-25T03:58:40.549561Z","iopub.status.idle":"2021-07-25T03:58:40.55433Z","shell.execute_reply.started":"2021-07-25T03:58:40.549532Z","shell.execute_reply":"2021-07-25T03:58:40.553214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class dataset(Dataset):\n    def __init__(self, data):\n        self.data  = data\n        \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, index):\n        sample = self.data[index]\n        return sample\n    \n    def collate_fn(self, samples, target=True):\n\n        batch = {}\n        \n        for key in ['input_ids', 'token_type_ids', 'attention_mask']:\n            to_len = max([len(sample[key]) for sample in samples])\n            padded = pad_to_len(\n                [sample[key] for sample in samples], to_len, 0\n            )\n            batch[key] = torch.tensor(padded)\n        \n        if target:\n            batch['label'] = torch.tensor([sample['target'] for sample in samples])\n            \n        return batch","metadata":{"execution":{"iopub.status.busy":"2021-07-25T03:58:41.215568Z","iopub.execute_input":"2021-07-25T03:58:41.215902Z","iopub.status.idle":"2021-07-25T03:58:41.222954Z","shell.execute_reply.started":"2021-07-25T03:58:41.215872Z","shell.execute_reply":"2021-07-25T03:58:41.222011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERT(torch.nn.Module):\n    def __init__(self):\n        super().__init__()        \n        self.model = BertModel.from_pretrained( \"../input/huggingface-bert/bert-base-uncased\")\n        self.extractor = torch.nn.Linear(768, 768)\n        self.classifer = torch.nn.Linear(768, 1)\n        self.dropout   = torch.nn.Dropout(0.1)\n        self.tanh = torch.nn.Tanh() \n        \n    def forward(self, ids, mask):\n        output = self.model(ids, mask)\n        CLS    = output.last_hidden_state[:,0,:]\n        output = self.tanh(self.extractor(CLS))\n        output = self.dropout(output)\n        output = self.classifer(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:53:09.56182Z","iopub.execute_input":"2021-07-24T14:53:09.562167Z","iopub.status.idle":"2021-07-24T14:53:09.568944Z","shell.execute_reply.started":"2021-07-24T14:53:09.562133Z","shell.execute_reply":"2021-07-24T14:53:09.567976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Estimator():\n    def __init__(self, hyperparameters, device, model, optim = 'AdamW'):        \n        self.params = hyperparameters\n        self.model  = model\n        self.device = device\n        \n        no_decay = ['bias', 'LayerNorm.weight']\n        optimizer_grouped_parameters = [\n            {'params': [p for n, p in self.model.named_parameters() if not any(nd in n for nd in no_decay)], \n             'weight_decay': self.params['weight_decay']},\n            {'params': [p for n, p in self.model.named_parameters() if any(nd in n for nd in no_decay)], \n             'weight_decay': 0.0}\n        ]\n        \n        if optim == 'Adam':\n            self.optimizer = torch.optim.Adam(params=optimizer_grouped_parameters, \n                                              lr=self.params['learning_rate'])\n        if optim == 'AdamW':\n            self.optimizer = torch.optim.AdamW(params=optimizer_grouped_parameters, \n                                              lr=self.params['learning_rate'])\n        self.model.to(self.device)\n        \n    def load_weight(self, weight_path):\n        self.model.load_state_dict(torch.load(weight_path))\n\n    def fit(self, data, save_name):\n        \n        ## loss function\n        criterion = torch.nn.MSELoss()\n        criterion.to(self.device)\n\n        ## Meta\n        len_of_train = len(data['train'].dataset)\n        len_of_test  = len(data['test'].dataset)\n        best = 1000\n        \n        train_steps = int(len_of_train/self.params['batch_size']*self.params['epoch'])\n        num_steps   = int(train_steps*0.1)\n\n        scheduler = get_linear_schedule_with_warmup(self.optimizer, num_steps, train_steps)\n\n        for epoch in range(self.params['epoch']):\n            total_loss = 0\n            total_val_loss = 0\n            \n            self.model.train()\n            for batch in tqdm.tqdm(data['train']):\n                ## INPUT\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                target = batch['label'].to(self.device)\n\n                ## FOWARD\n                output = self.model(input_ids, attention_mask)\n                loss = criterion(output.squeeze(), target) ## LOSS and PREDICT\n                total_loss+=loss.item()*len(input_ids)\n\n                ## OPTIMIZE\n                self.optimizer.zero_grad()\n                loss.backward()\n                self.optimizer.step()\n                scheduler.step() # Update learning rate schedule\n\n            self.model.eval()\n            for batch in data['test']:\n                with torch.no_grad():\n                    ## INPUT\n                    input_ids = batch['input_ids'].to(self.device)\n                    attention_mask = batch['attention_mask'].to(self.device)\n                    target = batch['label'].to(self.device)\n\n                    ## FOWARD\n                    output = self.model(input_ids, attention_mask)\n                    loss = criterion(output.squeeze(), target) ## LOSS and PREDICT\n                    \n                    total_val_loss+=loss.item()*len(input_ids)\n                \n            print(f'Epoch: {epoch}, Train: {(total_loss/len_of_train)**(1/2)}, Test: {(total_val_loss/len_of_test)**(1/2)}')\n\n            if total_val_loss < best:\n                best = total_val_loss\n                torch.save(self.model.state_dict(), f\"{save_name}.pth\")\n                    \n    def inference(self, data, t = True):\n        \n        total_loss = 0\n        outputs = []\n        \n        ## loss function\n        criterion = torch.nn.MSELoss()\n        criterion.to(self.device)\n        \n        self.model.eval()\n        for batch in tqdm.tqdm(data):\n            with torch.no_grad():\n                ## INPUT\n                input_ids = batch['input_ids'].to(self.device)\n                attention_mask = batch['attention_mask'].to(self.device)\n                if t:\n                    target = batch['label'].to(self.device)\n                \n                ## FOWARD\n                output = self.model(input_ids, attention_mask)\n                \n                if t:\n                    loss = criterion(output.squeeze(), target) ## LOSS and PREDICT\n                    total_loss+=loss.item()*len(input_ids)\n                \n                outputs+=output.squeeze().tolist()\n        \n        if t:\n            return (total_loss/len(data.dataset))**(1/2)\n        else:\n            return outputs","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:51:10.959065Z","iopub.execute_input":"2021-07-24T14:51:10.959431Z","iopub.status.idle":"2021-07-24T14:51:10.980865Z","shell.execute_reply.started":"2021-07-24T14:51:10.9594Z","shell.execute_reply":"2021-07-24T14:51:10.979632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocess","metadata":{}},{"cell_type":"markdown","source":"### 1. Split Dataset","metadata":{}},{"cell_type":"code","source":"X_train, X_test, _, _ = train_test_split(train_csv, train_csv['target'], test_size=0.1, random_state=42)\n\n# X_train.to_csv('X_train.csv', index=False)\n# X_test.to_csv('X_test.csv', index=False)\n\n# X_train = pd.read_csv('X_train.csv')\n# X_test  = pd.read_csv('X_test.csv')\n\nX_train, X_valid, _, _ = train_test_split(X_train, X_train['target'], test_size=1/9, random_state=42)\n\nX_train = X_train.reset_index(drop=True)\nX_valid = X_valid.reset_index(drop=True)\nX_test  = X_test.reset_index(drop=True)\n\ndatasets = {\"train\": X_train, \"valid\": X_valid, \"test\": X_test, \"submit\": test_csv}","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:51:24.736966Z","iopub.execute_input":"2021-07-24T14:51:24.73733Z","iopub.status.idle":"2021-07-24T14:51:24.76089Z","shell.execute_reply.started":"2021-07-24T14:51:24.737291Z","shell.execute_reply":"2021-07-24T14:51:24.760138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pretrained_bert = \"../input/huggingface-bert/bert-base-uncased\"\ntokenizer = BertTokenizer.from_pretrained(pretrained_bert, do_lower_case=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:51:51.360725Z","iopub.execute_input":"2021-07-24T14:51:51.361096Z","iopub.status.idle":"2021-07-24T14:51:51.44153Z","shell.execute_reply.started":"2021-07-24T14:51:51.361062Z","shell.execute_reply":"2021-07-24T14:51:51.440499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor key in datasets.keys():\n    datasets[key]['input_ids'] = datasets[key]['excerpt'].apply(lambda x: tokenizer(x))\n    datasets[key]['token_type_ids'] = datasets[key]['input_ids'].apply(lambda x: x['token_type_ids'])\n    datasets[key]['attention_mask'] = datasets[key]['input_ids'].apply(lambda x: x['attention_mask'])\n    datasets[key]['input_ids']      = datasets[key]['input_ids'].apply(lambda x: x['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:51:52.753596Z","iopub.execute_input":"2021-07-24T14:51:52.753937Z","iopub.status.idle":"2021-07-24T14:52:08.897224Z","shell.execute_reply.started":"2021-07-24T14:51:52.753906Z","shell.execute_reply":"2021-07-24T14:52:08.896297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset  = dataset(X_train.transpose().to_dict())\nvalid_dataset  = dataset(X_valid.transpose().to_dict())\ntest_dataset   = dataset(X_test.transpose().to_dict())\nsubmit_dataset = dataset(test_csv.transpose().to_dict())","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:52:08.898628Z","iopub.execute_input":"2021-07-24T14:52:08.899142Z","iopub.status.idle":"2021-07-24T14:52:09.1333Z","shell.execute_reply.started":"2021-07-24T14:52:08.899087Z","shell.execute_reply":"2021-07-24T14:52:09.132468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 16","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:52:09.135267Z","iopub.execute_input":"2021-07-24T14:52:09.135592Z","iopub.status.idle":"2021-07-24T14:52:09.139641Z","shell.execute_reply.started":"2021-07-24T14:52:09.135565Z","shell.execute_reply":"2021-07-24T14:52:09.13852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader = DataLoader(\n    dataset = train_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = True,\n    num_workers=4,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(train_dataset, x)\n)\n\nvalid_loader = DataLoader(\n    dataset = valid_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = False,\n    num_workers=4,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(valid_dataset, x)\n)\n\ntest_loader = DataLoader(\n    dataset = test_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = False,\n    num_workers=4,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(test_dataset, x)\n)\n\nsubmit_loader = DataLoader(\n    dataset = submit_dataset,\n    batch_size = BATCH_SIZE,\n    shuffle = False,\n    num_workers=4,\n    pin_memory=True,\n    collate_fn = lambda x: dataset.collate_fn(submit_dataset, x, target=False)\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:52:09.141056Z","iopub.execute_input":"2021-07-24T14:52:09.141431Z","iopub.status.idle":"2021-07-24T14:52:09.15135Z","shell.execute_reply.started":"2021-07-24T14:52:09.141398Z","shell.execute_reply":"2021-07-24T14:52:09.150513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_dataset), len(valid_dataset), len(test_dataset), len(submit_dataset))","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:52:09.152756Z","iopub.execute_input":"2021-07-24T14:52:09.15451Z","iopub.status.idle":"2021-07-24T14:52:09.161741Z","shell.execute_reply.started":"2021-07-24T14:52:09.154478Z","shell.execute_reply":"2021-07-24T14:52:09.160783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:52:21.360416Z","iopub.execute_input":"2021-07-24T14:52:21.360744Z","iopub.status.idle":"2021-07-24T14:52:21.368806Z","shell.execute_reply.started":"2021-07-24T14:52:21.360713Z","shell.execute_reply":"2021-07-24T14:52:21.367899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator = Estimator(\n    hyperparameters = {\n        'learning_rate': 2e-5,\n        'epoch': 5,\n        'batch_size': BATCH_SIZE,\n        'weight_decay':1e-2,\n    }, \n    device = device,\n    model = BERT()\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:53:15.848377Z","iopub.execute_input":"2021-07-24T14:53:15.848693Z","iopub.status.idle":"2021-07-24T14:53:29.544914Z","shell.execute_reply.started":"2021-07-24T14:53:15.848663Z","shell.execute_reply":"2021-07-24T14:53:29.543969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator.fit({'train': train_loader, \n               'test': valid_loader},\n              save_name='best_model')","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:53:32.951787Z","iopub.execute_input":"2021-07-24T14:53:32.952334Z","iopub.status.idle":"2021-07-24T14:58:58.335558Z","shell.execute_reply.started":"2021-07-24T14:53:32.952281Z","shell.execute_reply":"2021-07-24T14:58:58.334621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"estimator.load_weight('best_model.pth')\nestimator.inference(test_loader)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:58:58.337739Z","iopub.execute_input":"2021-07-24T14:58:58.338166Z","iopub.status.idle":"2021-07-24T14:59:01.259667Z","shell.execute_reply.started":"2021-07-24T14:58:58.338118Z","shell.execute_reply":"2021-07-24T14:59:01.25866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid['predict'] = estimator.inference(valid_loader, False)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:59:01.26349Z","iopub.execute_input":"2021-07-24T14:59:01.263791Z","iopub.status.idle":"2021-07-24T14:59:03.946989Z","shell.execute_reply.started":"2021-07-24T14:59:01.263758Z","shell.execute_reply":"2021-07-24T14:59:03.945687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid[['excerpt', 'target', 'predict']].sample(5)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:59:03.948882Z","iopub.execute_input":"2021-07-24T14:59:03.949254Z","iopub.status.idle":"2021-07-24T14:59:03.970711Z","shell.execute_reply.started":"2021-07-24T14:59:03.949212Z","shell.execute_reply":"2021-07-24T14:59:03.969778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"submit = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\nsubmit['target'] = estimator.inference(submit_loader, False)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:59:09.939339Z","iopub.execute_input":"2021-07-24T14:59:09.939673Z","iopub.status.idle":"2021-07-24T14:59:10.214093Z","shell.execute_reply.started":"2021-07-24T14:59:09.939642Z","shell.execute_reply":"2021-07-24T14:59:10.213243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit","metadata":{"execution":{"iopub.status.busy":"2021-07-24T14:59:11.49979Z","iopub.execute_input":"2021-07-24T14:59:11.500166Z","iopub.status.idle":"2021-07-24T14:59:11.512178Z","shell.execute_reply.started":"2021-07-24T14:59:11.500125Z","shell.execute_reply":"2021-07-24T14:59:11.510338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-24T15:01:19.91073Z","iopub.execute_input":"2021-07-24T15:01:19.911078Z","iopub.status.idle":"2021-07-24T15:01:19.916122Z","shell.execute_reply.started":"2021-07-24T15:01:19.911047Z","shell.execute_reply":"2021-07-24T15:01:19.91531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}