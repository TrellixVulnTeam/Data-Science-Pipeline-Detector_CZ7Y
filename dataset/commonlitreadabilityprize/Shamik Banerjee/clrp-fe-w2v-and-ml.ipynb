{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"If you find this notebook helpful, please <b>UPVOTE</b>","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport re\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nimport numpy as np\nimport nltk\nfrom nltk.corpus import stopwords\nfrom sklearn.preprocessing import MinMaxScaler\nfrom gensim.models.keyedvectors import KeyedVectors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import make_scorer","metadata":{"id":"1tUZDd8LYL37","execution":{"iopub.status.busy":"2021-08-08T16:00:27.580849Z","iopub.execute_input":"2021-08-08T16:00:27.58127Z","iopub.status.idle":"2021-08-08T16:00:30.219277Z","shell.execute_reply.started":"2021-08-08T16:00:27.581179Z","shell.execute_reply":"2021-08-08T16:00:30.218016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')","metadata":{"id":"B9TtaX76YL4E","execution":{"iopub.status.busy":"2021-08-08T16:00:30.221023Z","iopub.execute_input":"2021-08-08T16:00:30.221328Z","iopub.status.idle":"2021-08-08T16:00:30.320641Z","shell.execute_reply.started":"2021-08-08T16:00:30.221299Z","shell.execute_reply":"2021-08-08T16:00:30.319219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The missing values are in url_legal and license columns, which we will drop anyways, so we can fill them with anything.","metadata":{}},{"cell_type":"code","source":"df = df.fillna('Missing')","metadata":{"id":"DNuHFzIUYL4M","execution":{"iopub.status.busy":"2021-08-08T16:00:30.322941Z","iopub.execute_input":"2021-08-08T16:00:30.323381Z","iopub.status.idle":"2021-08-08T16:00:30.333373Z","shell.execute_reply.started":"2021-08-08T16:00:30.323332Z","shell.execute_reply":"2021-08-08T16:00:30.332092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now we must try to get rid of anything which is not an alphabet, anything which is a stopword and then lemmatize the words.","metadata":{}},{"cell_type":"code","source":"%%time\nnltk.download('wordnet')\nnltk.download('punkt')\nnltk.download('stopwords')\n\ndef cleaner(excerpt):\n    clean = nltk.word_tokenize(re.sub(\"[^a-zA-Z]\", \" \", excerpt).lower())\n    clean = [word for word in clean if not word in set(stopwords.words(\"english\"))]\n\n    lem = nltk.WordNetLemmatizer()\n    clean = [lem.lemmatize(word) for word in clean]\n    return \" \".join(clean)\n\ndf.excerpt = df.excerpt.apply(cleaner)","metadata":{"id":"MDqPjXUdYL44","outputId":"eec6d2ca-089e-49a9-c664-5f6eacb981f7","execution":{"iopub.status.busy":"2021-08-08T16:00:30.336103Z","iopub.execute_input":"2021-08-08T16:00:30.336642Z","iopub.status.idle":"2021-08-08T16:01:46.102007Z","shell.execute_reply.started":"2021-08-08T16:00:30.336593Z","shell.execute_reply":"2021-08-08T16:01:46.100951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now I am going to create one extra feature by using another freely available dataset. The dataset gives us usage frequency of english words. \n\nSo if we sum up usage frequency of all words, we end up with a score of the paragraph. This score will be more if the words in the paragraph are used more in daily life and the score will be less if they are not used often. \n\nWhen words are not used often, they surely can be hard for people to understand. \n\nThere can be a better way to use this word frequency but I am going forward with this basic approach for now.","metadata":{}},{"cell_type":"code","source":"%%time\nwdf = pd.read_csv('../input/english-word-frequency/unigram_freq.csv')\n\nwdf['ncol'] = wdf.word.apply(lambda x: True if (x not in set(stopwords.words(\"english\"))) else False)\nnwdf = wdf[wdf.ncol==True]\n\nlem1 = nltk.WordNetLemmatizer()\nnwdf['lword'] = nwdf.word.apply(lambda x: lem1.lemmatize(str(x)))\nnwdf = nwdf.sort_values('count')\n\nnwdf['scaled_count'] = nwdf['count'] \nword_freq = dict(zip(nwdf.word, nwdf.scaled_count))\n\ndef get_score(excerpt):\n    score = 0\n\n    for i in excerpt.split(' '):\n        try:\n            score += word_freq[i]\n        except KeyError:\n            pass\n\n    return score","metadata":{"id":"gk3lsT0KYL45","outputId":"44be1fc3-91ba-4f68-ac15-7da612878a23","execution":{"iopub.status.busy":"2021-08-08T16:01:46.103603Z","iopub.execute_input":"2021-08-08T16:01:46.103959Z","iopub.status.idle":"2021-08-08T16:02:33.619025Z","shell.execute_reply.started":"2021-08-08T16:01:46.103928Z","shell.execute_reply":"2021-08-08T16:02:33.617883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We keep this score as excerpt_score and we will create another feature to take into account how long the paragraphs are, that feature is ex_len.","metadata":{}},{"cell_type":"code","source":"df['ex_len'] = df.excerpt.apply(lambda x: len(x))","metadata":{"id":"nXDYLO_bzKly","execution":{"iopub.status.busy":"2021-08-08T16:02:33.620291Z","iopub.execute_input":"2021-08-08T16:02:33.620581Z","iopub.status.idle":"2021-08-08T16:02:33.628348Z","shell.execute_reply.started":"2021-08-08T16:02:33.620552Z","shell.execute_reply":"2021-08-08T16:02:33.627348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.ex_len.min(), df.ex_len.median())\ndf.excerpt = df.excerpt.apply(lambda x: x[0:586])","metadata":{"execution":{"iopub.status.busy":"2021-08-08T16:02:33.629586Z","iopub.execute_input":"2021-08-08T16:02:33.630037Z","iopub.status.idle":"2021-08-08T16:02:33.649679Z","shell.execute_reply.started":"2021-08-08T16:02:33.630004Z","shell.execute_reply":"2021-08-08T16:02:33.648369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['excerpt_score'] = df.excerpt.apply(get_score)","metadata":{"id":"LB-Hh2fRNWdW","execution":{"iopub.status.busy":"2021-08-08T16:02:33.652665Z","iopub.execute_input":"2021-08-08T16:02:33.653153Z","iopub.status.idle":"2021-08-08T16:02:33.753807Z","shell.execute_reply.started":"2021-08-08T16:02:33.653031Z","shell.execute_reply":"2021-08-08T16:02:33.752766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop(['ex_len'], axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T16:02:33.755621Z","iopub.execute_input":"2021-08-08T16:02:33.755916Z","iopub.status.idle":"2021-08-08T16:02:33.76344Z","shell.execute_reply.started":"2021-08-08T16:02:33.755888Z","shell.execute_reply":"2021-08-08T16:02:33.762318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Scaling should help us get better results.","metadata":{}},{"cell_type":"code","source":"mms2 = MinMaxScaler()\n\ndf.excerpt_score = mms2.fit_transform(np.reshape(list(df.excerpt_score), (-1,1)))","metadata":{"id":"TttPH5wwZM0Z","execution":{"iopub.status.busy":"2021-08-08T16:02:33.764773Z","iopub.execute_input":"2021-08-08T16:02:33.765065Z","iopub.status.idle":"2021-08-08T16:02:33.779158Z","shell.execute_reply.started":"2021-08-08T16:02:33.765037Z","shell.execute_reply":"2021-08-08T16:02:33.778113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will be dropping some columns.","metadata":{}},{"cell_type":"code","source":"y = df['target']\ndf.drop(['id', 'url_legal', 'license', 'target', 'standard_error'], axis=1, inplace=True)","metadata":{"id":"Ivr40erVYL5N","execution":{"iopub.status.busy":"2021-08-08T16:02:33.780509Z","iopub.execute_input":"2021-08-08T16:02:33.781435Z","iopub.status.idle":"2021-08-08T16:02:33.798846Z","shell.execute_reply.started":"2021-08-08T16:02:33.781279Z","shell.execute_reply":"2021-08-08T16:02:33.797995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.excerpt_score = df.excerpt_score.apply(lambda x: np.round(x, 2))","metadata":{"execution":{"iopub.status.busy":"2021-08-08T16:02:33.799957Z","iopub.execute_input":"2021-08-08T16:02:33.800346Z","iopub.status.idle":"2021-08-08T16:02:33.852892Z","shell.execute_reply.started":"2021-08-08T16:02:33.800317Z","shell.execute_reply":"2021-08-08T16:02:33.85181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"hsbNgCkpYL5A","outputId":"d67aff11-fa77-4f89-9b95-568bdaa36aa6","execution":{"iopub.status.busy":"2021-08-08T16:02:33.854249Z","iopub.execute_input":"2021-08-08T16:02:33.854562Z","iopub.status.idle":"2021-08-08T16:02:33.880412Z","shell.execute_reply.started":"2021-08-08T16:02:33.854533Z","shell.execute_reply":"2021-08-08T16:02:33.879395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will use pre-trained Word2Vec.","metadata":{}},{"cell_type":"code","source":"# If you are running the notebook on Colab then uncomment the code below to get the Word2Vec model\n\n# !sudo apt install wget\n# !wget -c \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"\n# !gzip -d GoogleNews-vectors-negative300.bin.gz\n\npath = '../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin'\n\n\n\nword2vec_model = KeyedVectors.load_word2vec_format(path, binary=True)\nEMBEDDING_DIM=300\n\nprint(word2vec_model.vectors.shape)","metadata":{"id":"qt5VYPh41gz0","outputId":"3c23db92-d38c-4026-ef68-0557d9ca9e1d","execution":{"iopub.status.busy":"2021-08-08T16:02:33.881644Z","iopub.execute_input":"2021-08-08T16:02:33.881985Z","iopub.status.idle":"2021-08-08T16:03:49.999954Z","shell.execute_reply.started":"2021-08-08T16:02:33.881955Z","shell.execute_reply":"2021-08-08T16:03:49.998902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def avg_feature_vector(sentence, model, num_features):\n    words = sentence.split()\n    feature_vec = np.zeros((num_features,),dtype=\"float32\")\n    i=0\n    for word in words:\n        try:\n            feature_vec = np.add(feature_vec, model[word])\n        except KeyError as error:\n            feature_vec \n            i = i + 1\n    if len(words) > 0:\n        feature_vec = np.divide(feature_vec, len(words)- i)\n    return feature_vec\n\nword2vec_train = np.zeros((len(df.index),300),dtype=\"float32\")\n\nfor i in range(len(df.index)):\n    word2vec_train[i] = avg_feature_vector(df[\"excerpt\"][i],word2vec_model, 300)\n    \nprint(word2vec_train.shape)\nprint(y.shape)\n","metadata":{"id":"aNaf_tXb13k3","outputId":"ded87127-69bb-453b-f963-85d608d8d58e","execution":{"iopub.status.busy":"2021-08-08T16:03:50.002074Z","iopub.execute_input":"2021-08-08T16:03:50.002672Z","iopub.status.idle":"2021-08-08T16:03:51.169109Z","shell.execute_reply.started":"2021-08-08T16:03:50.002629Z","shell.execute_reply":"2021-08-08T16:03:51.168262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we will be using the word vectors to encode all paragraphs and will also keep two more columns we created.","metadata":{}},{"cell_type":"code","source":"names_df = pd.DataFrame(data=word2vec_train)\ndf = pd.concat([df, names_df], axis=1)","metadata":{"id":"p5f1g59y3109","execution":{"iopub.status.busy":"2021-08-08T16:03:51.170617Z","iopub.execute_input":"2021-08-08T16:03:51.17098Z","iopub.status.idle":"2021-08-08T16:03:51.184317Z","shell.execute_reply.started":"2021-08-08T16:03:51.170945Z","shell.execute_reply":"2021-08-08T16:03:51.183133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.shape","metadata":{"id":"U2b7uhQY4RW7","outputId":"cec6894c-58c8-42b1-a6c0-263b0963efdf","execution":{"iopub.status.busy":"2021-08-08T16:03:51.186011Z","iopub.execute_input":"2021-08-08T16:03:51.186471Z","iopub.status.idle":"2021-08-08T16:03:51.196063Z","shell.execute_reply.started":"2021-08-08T16:03:51.186398Z","shell.execute_reply":"2021-08-08T16:03:51.194898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now it is time to let go of the text column.","metadata":{}},{"cell_type":"code","source":"df.drop(['excerpt'], axis=1, inplace=True)","metadata":{"id":"35RSFPK-YL5Q","execution":{"iopub.status.busy":"2021-08-08T16:03:51.197607Z","iopub.execute_input":"2021-08-08T16:03:51.198074Z","iopub.status.idle":"2021-08-08T16:03:51.214987Z","shell.execute_reply.started":"2021-08-08T16:03:51.198028Z","shell.execute_reply":"2021-08-08T16:03:51.213643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"id":"F1dpuHg_bsRI","outputId":"e2f7fac2-f77a-403e-b087-f67ccf2eb4da","execution":{"iopub.status.busy":"2021-08-08T16:03:51.216489Z","iopub.execute_input":"2021-08-08T16:03:51.216897Z","iopub.status.idle":"2021-08-08T16:03:51.261352Z","shell.execute_reply.started":"2021-08-08T16:03:51.216862Z","shell.execute_reply":"2021-08-08T16:03:51.2602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df","metadata":{"id":"kC17jmBJYL5R","execution":{"iopub.status.busy":"2021-08-08T16:03:51.263021Z","iopub.execute_input":"2021-08-08T16:03:51.263465Z","iopub.status.idle":"2021-08-08T16:03:51.267953Z","shell.execute_reply.started":"2021-08-08T16:03:51.263395Z","shell.execute_reply":"2021-08-08T16:03:51.266675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)","metadata":{"id":"pJc6EoyzYL5U","execution":{"iopub.status.busy":"2021-08-08T16:03:51.269923Z","iopub.execute_input":"2021-08-08T16:03:51.270356Z","iopub.status.idle":"2021-08-08T16:03:51.290151Z","shell.execute_reply.started":"2021-08-08T16:03:51.270314Z","shell.execute_reply":"2021-08-08T16:03:51.289117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error as mse\nfrom sklearn.linear_model import LinearRegression\n\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nmse(y_test, y_pred)","metadata":{"execution":{"iopub.status.busy":"2021-08-08T16:03:51.291776Z","iopub.execute_input":"2021-08-08T16:03:51.29209Z","iopub.status.idle":"2021-08-08T16:03:51.452356Z","shell.execute_reply.started":"2021-08-08T16:03:51.292061Z","shell.execute_reply":"2021-08-08T16:03:51.451132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mse = make_scorer(mean_squared_error,greater_is_better=False)\n\n# model = RandomForestRegressor()\n\n# params = {\n#               \"max_features\": [1, 3, 10],\n#               \"min_samples_split\": [2, 3, 10],\n#               \"min_samples_leaf\": [1, 3, 10],\n#               \"n_estimators\" :[100, 300, 500, 1000, 1500]}\n\n\n# model = GridSearchCV(model,param_grid = params, cv=3, scoring=mse, n_jobs= -1, verbose = 1)\n\n# model.fit(X_train,y_train)\n\n# model = model.best_estimator_","metadata":{"execution":{"iopub.status.busy":"2021-08-08T16:03:51.457676Z","iopub.execute_input":"2021-08-08T16:03:51.458484Z","iopub.status.idle":"2021-08-08T16:03:51.468066Z","shell.execute_reply.started":"2021-08-08T16:03:51.458378Z","shell.execute_reply":"2021-08-08T16:03:51.466586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# y_pred = model.predict(X_test)\n\n# from sklearn.metrics import mean_squared_error as mse\n# mse(y_test, y_pred)","metadata":{"id":"svuSJjzgYL5X","outputId":"42ce9f18-dbcd-48a4-bf97-81c029bfe992","execution":{"iopub.status.busy":"2021-08-08T16:03:51.470377Z","iopub.execute_input":"2021-08-08T16:03:51.471134Z","iopub.status.idle":"2021-08-08T16:03:51.484047Z","shell.execute_reply.started":"2021-08-08T16:03:51.471081Z","shell.execute_reply":"2021-08-08T16:03:51.482741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Test Data - Creating Submission","metadata":{"id":"YNODJ57JgiH1"}},{"cell_type":"markdown","source":"We must do the same with test data, that is create two columns and use Word2Vec on the text data.","metadata":{}},{"cell_type":"code","source":"tdf = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n\ntdf = tdf.fillna('Missing')\n\n# tdf['ex_len'] = tdf.excerpt.apply(lambda x: len(x))\ntdf.excerpt = tdf.excerpt.apply(cleaner)\ntdf.excerpt = tdf.excerpt.apply(lambda x: x[:586])\ntdf['excerpt_score'] = tdf.excerpt.apply(get_score)\n\ntdf.drop(['id', 'url_legal', 'license'], axis=1, inplace=True)","metadata":{"id":"lyMBaNjzecQj","execution":{"iopub.status.busy":"2021-08-08T16:03:51.48565Z","iopub.execute_input":"2021-08-08T16:03:51.486465Z","iopub.status.idle":"2021-08-08T16:03:51.717076Z","shell.execute_reply.started":"2021-08-08T16:03:51.486397Z","shell.execute_reply":"2021-08-08T16:03:51.716049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf","metadata":{"id":"YQZYcFe8gbFJ","outputId":"6022f0e3-0716-47b0-a35c-4db8b2cc242a","execution":{"iopub.status.busy":"2021-08-08T16:03:51.718557Z","iopub.execute_input":"2021-08-08T16:03:51.718985Z","iopub.status.idle":"2021-08-08T16:03:51.729092Z","shell.execute_reply.started":"2021-08-08T16:03:51.718943Z","shell.execute_reply":"2021-08-08T16:03:51.727979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word2vec_test = np.zeros((len(tdf.index),300),dtype=\"float32\")\n\nfor i in range(len(tdf.index)):\n    word2vec_test[i] = avg_feature_vector(tdf[\"excerpt\"][i],word2vec_model, 300) \n\nprint(word2vec_test.shape)","metadata":{"id":"HR5vBVtv5cTr","outputId":"b01619cf-7895-4b13-dbb9-63bf920bd6b8","execution":{"iopub.status.busy":"2021-08-08T16:03:51.730784Z","iopub.execute_input":"2021-08-08T16:03:51.731212Z","iopub.status.idle":"2021-08-08T16:03:51.746304Z","shell.execute_reply.started":"2021-08-08T16:03:51.731168Z","shell.execute_reply":"2021-08-08T16:03:51.745137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf.drop(['excerpt'], axis=1, inplace=True)","metadata":{"id":"oiIH_WiXgerF","execution":{"iopub.status.busy":"2021-08-08T16:03:51.747817Z","iopub.execute_input":"2021-08-08T16:03:51.748262Z","iopub.status.idle":"2021-08-08T16:03:51.759267Z","shell.execute_reply.started":"2021-08-08T16:03:51.748197Z","shell.execute_reply":"2021-08-08T16:03:51.758323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tdf.excerpt_score = mms2.transform(np.reshape(list(tdf.excerpt_score), (-1,1)))\n# tdf.ex_len = mms3.transform(np.reshape(list(tdf.ex_len), (-1,1)))","metadata":{"id":"sfFDGkb7gezh","execution":{"iopub.status.busy":"2021-08-08T16:03:51.76055Z","iopub.execute_input":"2021-08-08T16:03:51.760977Z","iopub.status.idle":"2021-08-08T16:03:51.774478Z","shell.execute_reply.started":"2021-08-08T16:03:51.760936Z","shell.execute_reply":"2021-08-08T16:03:51.773018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"names_df = pd.DataFrame(data=word2vec_test)\ntdf = pd.concat([tdf, names_df], axis=1)\n\ntdf.shape","metadata":{"id":"udwbYehh5oJN","outputId":"9e393666-267a-4c8b-9409-c4a8fbf86702","execution":{"iopub.status.busy":"2021-08-08T16:03:51.775993Z","iopub.execute_input":"2021-08-08T16:03:51.776453Z","iopub.status.idle":"2021-08-08T16:03:51.791555Z","shell.execute_reply.started":"2021-08-08T16:03:51.776389Z","shell.execute_reply":"2021-08-08T16:03:51.790243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred = model.predict(tdf)","metadata":{"id":"vMI0WohJhfox","execution":{"iopub.status.busy":"2021-08-08T16:03:51.793243Z","iopub.execute_input":"2021-08-08T16:03:51.793703Z","iopub.status.idle":"2021-08-08T16:03:51.807988Z","shell.execute_reply.started":"2021-08-08T16:03:51.793656Z","shell.execute_reply":"2021-08-08T16:03:51.807114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ypred","metadata":{"id":"Kj7nCYeUlES8","outputId":"f4fa9555-a7a4-4e86-9ceb-d6bacb79b321","execution":{"iopub.status.busy":"2021-08-08T16:03:51.809279Z","iopub.execute_input":"2021-08-08T16:03:51.809708Z","iopub.status.idle":"2021-08-08T16:03:51.823019Z","shell.execute_reply.started":"2021-08-08T16:03:51.809675Z","shell.execute_reply":"2021-08-08T16:03:51.822201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({ 'id' : pd.read_csv('../input/commonlitreadabilityprize/test.csv')['id'], \n                           'target': list(ypred)})\n\nsubmission.to_csv('submission.csv', index=False)\n","metadata":{"id":"WI9PLy5IlGKa","execution":{"iopub.status.busy":"2021-08-08T16:03:51.824212Z","iopub.execute_input":"2021-08-08T16:03:51.824644Z","iopub.status.idle":"2021-08-08T16:03:51.844605Z","shell.execute_reply.started":"2021-08-08T16:03:51.8246Z","shell.execute_reply":"2021-08-08T16:03:51.843686Z"},"trusted":true},"execution_count":null,"outputs":[]}]}