{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Берт, усреднение по фолдам","metadata":{}},{"cell_type":"code","source":"from collections import Counter\nimport math\nfrom pathlib import Path\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_colwidth', None)\n\nimport sklearn\nfrom sklearn import metrics, model_selection\n\nfrom tqdm.auto import tqdm\ntqdm.pandas()\n\nimport tensorflow as tf\nprint(f'TF version: {tf.__version__}')\nprint(f'Eager mode: {tf.executing_eagerly()}')\nprint(f'GPU: {\"is available\" if tf.config.experimental.list_physical_devices(\"GPU\") else \"IS NOT AVAILABLE\"}')\n\nimport transformers\nprint(f'Hugging Face version: {transformers.__version__}')","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:46:20.253844Z","iopub.execute_input":"2021-07-04T11:46:20.254088Z","iopub.status.idle":"2021-07-04T11:46:25.961298Z","shell.execute_reply.started":"2021-07-04T11:46:20.254065Z","shell.execute_reply":"2021-07-04T11:46:25.95986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Прочитаю данные","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ndf.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:46:25.962699Z","iopub.execute_input":"2021-07-04T11:46:25.963045Z","iopub.status.idle":"2021-07-04T11:46:26.054162Z","shell.execute_reply.started":"2021-07-04T11:46:25.963009Z","shell.execute_reply":"2021-07-04T11:46:26.053239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Добавлю столбцы с бинами таргета и фолдами","metadata":{}},{"cell_type":"code","source":"def add_target_bin_and_fold_columns(df):\n    \"\"\"\n    https://www.kaggle.com/takiholadi/01-commonlit-linreg-4-features\n    \"\"\"\n\n    def add_column_with_target_bin(df):\n        assert 'target_bin' not in df\n\n        hist, bin_edges = np.histogram(\n            df['target'],\n            bins='doane',  # `sqrt`, `doane`, `sturges`, `rice`, `scott`, `fd`, `auto`\n        )\n        num_bins = len(hist)\n\n        out, bins = pd.cut(\n            df['target'],\n            bins=num_bins,\n            labels=[f'target_bin_{x}' for x in range(num_bins)],\n            retbins=True,\n        )\n\n        df.loc[:, 'target_bin'] = out.astype(str)\n\n        return df\n\n\n    def add_column_with_fold(df):\n        assert 'fold' not in df\n        assert 'target_bin' in df\n\n        df['fold'] = -1\n\n        train_size = 2_500\n\n        _, holdout_ids = sklearn.model_selection.train_test_split(\n            df['id'],\n            train_size=train_size,\n            random_state=567,\n            shuffle=True,\n            stratify=df['target_bin'],\n        )\n\n        holdout_ids = holdout_ids.values\n\n        df.loc[df['id'].isin(holdout_ids), 'fold'] = 'holdout'\n        assert sum(df['fold'] == -1) == train_size\n\n        #####\n        #####\n\n        df = df.reset_index()\n\n        crossvalidation_df = df[df['fold'] != 'holdout'].reset_index(drop=True)\n        holdout_df = df[df['fold'] == 'holdout'].reset_index(drop=True)\n\n        n_splits = 5\n        skf = sklearn.model_selection.StratifiedKFold(\n            n_splits=n_splits,\n            shuffle=True,\n            random_state=567,\n        )\n\n        for idx, (train_index, test_index) in enumerate(\n            skf.split(X=crossvalidation_df,\n                      y=crossvalidation_df['target_bin'])):\n            crossvalidation_df.loc[test_index, 'fold'] = f'fold_{idx}'\n\n        df = pd.concat([crossvalidation_df, holdout_df]).set_index('index').sort_index()\n\n        assert -1 not in df['fold']\n        for each in df['fold'].unique():\n            current, rest = df[df['fold'] == each], df[df['fold'] != each]\n            assert set(current.index).isdisjoint(rest.index)\n\n        return df\n    \n    df = add_column_with_target_bin(df)\n    df = add_column_with_fold(df)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:46:26.056087Z","iopub.execute_input":"2021-07-04T11:46:26.056458Z","iopub.status.idle":"2021-07-04T11:46:26.070634Z","shell.execute_reply.started":"2021-07-04T11:46:26.056421Z","shell.execute_reply":"2021-07-04T11:46:26.069645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = add_target_bin_and_fold_columns(df)\nprint(Counter(df['fold']))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:46:26.072316Z","iopub.execute_input":"2021-07-04T11:46:26.07268Z","iopub.status.idle":"2021-07-04T11:46:26.137389Z","shell.execute_reply.started":"2021-07-04T11:46:26.072644Z","shell.execute_reply":"2021-07-04T11:46:26.136489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head(1)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:46:26.138575Z","iopub.execute_input":"2021-07-04T11:46:26.138921Z","iopub.status.idle":"2021-07-04T11:46:26.155148Z","shell.execute_reply.started":"2021-07-04T11:46:26.138886Z","shell.execute_reply":"2021-07-04T11:46:26.154224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Выбираю сколько токенов взять","metadata":{}},{"cell_type":"code","source":"def prepare_texts_for_bert(texts, tokenizer, max_sequence_length):\n    assert all([isinstance(x, str) for x in texts])\n    res = tokenizer.batch_encode_plus(\n        texts,\n        max_length=max_sequence_length,\n        truncation=True,\n        padding='max_length',\n        add_special_tokens=True,\n        pad_to_max_length=True,\n        return_tensors='tf',\n    )\n    return res\n\n\ndef plot_tokens_heatmap(list_of_texts, tokenizer, max_sequence_length):\n    encoded = prepare_texts_for_bert(\n        texts=list_of_texts,\n        tokenizer=tokenizer,\n        max_sequence_length=max_sequence_length,\n    )\n    plt.figure(figsize=(12, 5))\n    plt.pcolormesh(encoded['input_ids'])\n    plt.show()\n    return None","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:46:26.156364Z","iopub.execute_input":"2021-07-04T11:46:26.156682Z","iopub.status.idle":"2021-07-04T11:46:26.162726Z","shell.execute_reply.started":"2021-07-04T11:46:26.156657Z","shell.execute_reply":"2021-07-04T11:46:26.161552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_tokens_heatmap(\n    list_of_texts=df['excerpt'].values.tolist(),\n    tokenizer=transformers.AutoTokenizer.from_pretrained('../input/huggingface-bert-variants/bert-base-cased/bert-base-cased'),\n    max_sequence_length=512,\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:46:26.164249Z","iopub.execute_input":"2021-07-04T11:46:26.164653Z","iopub.status.idle":"2021-07-04T11:46:35.370315Z","shell.execute_reply.started":"2021-07-04T11:46:26.16462Z","shell.execute_reply":"2021-07-04T11:46:35.369447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Параметры и оптимизатор","metadata":{}},{"cell_type":"code","source":"bert_model_name = '../input/huggingface-bert-variants/bert-base-cased/bert-base-cased'\n\nmax_sequence_length = 256\n\ntrain_data_size = 4 * 500  # это 4 фолда * 500 сэмплов, ещё один фолд уйдёт в валидацию\ninitial_learning_rate = 2e-5\nepochs = 3  # ещё шедулинг лёрнинг-рейта и ёрли-стоп\n\ntrain_batch_size = 16\nwarmup_ratio = 0.1","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:34.286286Z","iopub.execute_input":"2021-07-04T11:48:34.286617Z","iopub.status.idle":"2021-07-04T11:48:34.292743Z","shell.execute_reply.started":"2021-07-04T11:48:34.286587Z","shell.execute_reply":"2021-07-04T11:48:34.290247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_steps_per_epoch = math.ceil(train_data_size / train_batch_size)\nnum_train_steps = num_steps_per_epoch * epochs\nnum_warmup_steps = num_train_steps * warmup_ratio\nprint('num_steps_per_epoch:', num_steps_per_epoch)\nprint('num_train_steps:', num_train_steps)\nprint('num_warmup_steps:', num_warmup_steps)\n\ndef get_optimizer(initial_learning_rate, num_train_steps, num_warmup_steps, is_return_schedule=False):\n    \"\"\"\n    # https://huggingface.co/transformers/v4.4.2/_modules/transformers/optimization_tf.html#create_optimizer\n    \"\"\"\n    optimizer, lr_schedule = transformers.optimization_tf.create_optimizer(\n        init_lr=initial_learning_rate,  # The desired learning rate at the end of the warmup phase.\n        num_train_steps=num_train_steps,  # The total number of training steps.\n        num_warmup_steps=num_warmup_steps,  # The number of warmup steps.\n        min_lr_ratio=0.0,  # The final learning rate at the end of the linear decay will be. defaults to 0\n        adam_beta1=0.9,  # The beta1 to use in Adam. defaults to 0.9\n        adam_beta2=0.999,  # The beta2 to use in Adam. defaults to 0.999\n        adam_epsilon=1e-8,  # The epsilon to use in Adam. defaults to 1e-8\n        weight_decay_rate=0.01,  # The weight decay to use. defaults to 0\n        power=1.0,  # The power to use for PolynomialDecay. defaults to 1.0 (1.0 is a linear warmup)\n        include_in_weight_decay=None,  # if none is passed, weight decay is applied to all parameters except bias and layer norm parameters.\n    )\n    if is_return_schedule:\n        return optimizer, lr_schedule\n    return optimizer\n\n\noptimizer, lr_schedule = get_optimizer(initial_learning_rate, num_train_steps, num_warmup_steps, True)\nplt.figure(figsize=(12, 5))\nplt.plot([lr_schedule(n) for n in range(num_train_steps)])\nplt.xlabel(f'training steps, each step is batch of: {train_batch_size}')\nplt.ylabel('learning rate')\nplt.plot()\ndel optimizer, lr_schedule","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:35.101183Z","iopub.execute_input":"2021-07-04T11:48:35.1015Z","iopub.status.idle":"2021-07-04T11:48:35.521754Z","shell.execute_reply.started":"2021-07-04T11:48:35.10147Z","shell.execute_reply":"2021-07-04T11:48:35.520946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Лёрнинг-рейт будет линейно увеличиваться для первых 10% шагов, а потом линейно уменьшаться до нуля.","metadata":{}},{"cell_type":"markdown","source":"## Модель Берта","metadata":{}},{"cell_type":"code","source":"config = transformers.AutoConfig.from_pretrained(bert_model_name)\nprint(config.initializer_range)\n\ntokenizer = transformers.AutoTokenizer.from_pretrained(bert_model_name, fast=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:37.075887Z","iopub.execute_input":"2021-07-04T11:48:37.076246Z","iopub.status.idle":"2021-07-04T11:48:37.11747Z","shell.execute_reply.started":"2021-07-04T11:48:37.076214Z","shell.execute_reply":"2021-07-04T11:48:37.116724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model(bert_model_name, max_sequence_length):\n    \n    in_input_ids = tf.keras.Input(shape=(max_sequence_length, ), name='input_ids', dtype=tf.int32)\n    in_token_type_ids = tf.keras.Input(shape=(max_sequence_length, ), name='token_type_ids', dtype=tf.int32)\n    in_attention_mask = tf.keras.Input(shape=(max_sequence_length, ), name='attention_mask', dtype=tf.int32)  \n    bert_input = [in_input_ids, in_token_type_ids, in_attention_mask]\n    \n    bert = transformers.TFAutoModel.from_pretrained(bert_model_name)\n    output = bert(bert_input)\n    pooled_output = output.pooler_output\n    drop = tf.keras.layers.Dropout(0.1)(pooled_output)\n    scores = tf.keras.layers.Dense(\n        units=1,  # regression task\n        activation='linear',\n        #kernel_initializer=transformers.modeling_tf_utils.get_initializer(0.02),\n        #bias_initializer=tf.keras.initializers.Constant(-0.96),  # mean target\n    )(drop)\n    \n    model = tf.keras.models.Model(inputs=bert_input, outputs=scores)\n    return model\n\nmodel = get_model(bert_model_name, max_sequence_length)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:38.643348Z","iopub.execute_input":"2021-07-04T11:48:38.644009Z","iopub.status.idle":"2021-07-04T11:48:53.128754Z","shell.execute_reply.started":"2021-07-04T11:48:38.643969Z","shell.execute_reply":"2021-07-04T11:48:53.127936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:53.130101Z","iopub.execute_input":"2021-07-04T11:48:53.130426Z","iopub.status.idle":"2021-07-04T11:48:53.153582Z","shell.execute_reply.started":"2021-07-04T11:48:53.130391Z","shell.execute_reply":"2021-07-04T11:48:53.15156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Скоринг на кросс-валидации, для подбора параметров вручную","metadata":{}},{"cell_type":"code","source":"def get_cv_iterator(df):\n    \"\"\"\n    В тест по очереди фолды.\n    \"\"\"\n    cv_iterator = []\n    for each in sorted(df['fold'].unique()):\n        if each != 'holdout':\n            train_indices = df[~df['fold'].isin([each, 'holdout'])].index.values.astype(int)\n            test_indices =  df[df['fold'].isin([each])].index.values.astype(int)\n            cv_iterator.append( (train_indices, test_indices) )\n    return cv_iterator\n\ncv_iterator = get_cv_iterator(df)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:53.156195Z","iopub.execute_input":"2021-07-04T11:48:53.156678Z","iopub.status.idle":"2021-07-04T11:48:53.172623Z","shell.execute_reply.started":"2021-07-04T11:48:53.15658Z","shell.execute_reply":"2021-07-04T11:48:53.171895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = prepare_texts_for_bert(\n    texts=df['excerpt'].values.tolist(),\n    tokenizer=tokenizer,\n    max_sequence_length=max_sequence_length,\n)\n\ny = df['target'].values","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:53.173923Z","iopub.execute_input":"2021-07-04T11:48:53.174261Z","iopub.status.idle":"2021-07-04T11:48:54.629893Z","shell.execute_reply.started":"2021-07-04T11:48:53.174226Z","shell.execute_reply":"2021-07-04T11:48:54.621892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Path('checkpoints').mkdir(parents=True, exist_ok=True)\nfolds_history = []\nfor idx, (train_index, val_index) in enumerate(cv_iterator):\n\n    X_train = [\n        tf.gather(X['input_ids'], train_index),\n        tf.gather(X['token_type_ids'], train_index),\n        tf.gather(X['attention_mask'], train_index),\n    ]\n    y_train = y[train_index]\n    \n    X_validation = [\n        tf.gather(X['input_ids'], val_index),\n        tf.gather(X['token_type_ids'], val_index),\n        tf.gather(X['attention_mask'], val_index),\n    ]\n    y_validation = y[val_index]    \n    \n    model = get_model(bert_model_name, max_sequence_length)\n    model.compile(\n        optimizer=get_optimizer(initial_learning_rate, num_train_steps, num_warmup_steps),\n        loss=tf.keras.losses.MeanSquaredError(),\n        metrics=[tf.keras.metrics.RootMeanSquaredError()],\n    )\n    early_stopping = tf.keras.callbacks.EarlyStopping(\n        monitor='val_root_mean_squared_error',\n        patience=2,  # number of epochs with no improvement\n        mode='min',  # mode='auto'\n        restore_best_weights=True,\n        verbose=1,\n    )\n\n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        f'checkpoints/checkpoint_{idx}',\n        monitor='val_root_mean_squared_error',\n        mode='min',\n        save_best_only=True,\n        save_weights_only=True,\n        verbose=1,\n    )\n\n    history = model.fit(\n        x=X_train,\n        y=y_train,\n        validation_data=(X_validation, y_validation),\n        batch_size=train_batch_size,\n        validation_batch_size=train_batch_size,\n        epochs=epochs,\n        sample_weight=(1 - df['standard_error'].values[train_index]),\n        callbacks=[early_stopping, model_checkpoint],\n    )\n    \n    best_epoch_idx = np.argmin(history.history['val_root_mean_squared_error'])\n    print(f\"Fold {idx}, best score: {history.history['val_root_mean_squared_error'][best_epoch_idx]}, at epoch: {best_epoch_idx}\")\n    folds_history.append(history.history)\n    \n    del X_train, y_train, X_validation, y_validation\n    del model, early_stopping, model_checkpoint\n    del history, best_epoch_idx","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:48:54.63145Z","iopub.execute_input":"2021-07-04T11:48:54.631841Z","iopub.status.idle":"2021-07-04T12:07:33.420321Z","shell.execute_reply.started":"2021-07-04T11:48:54.631804Z","shell.execute_reply":"2021-07-04T12:07:33.419263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_cv_perfomance(folds_history):\n    fig, axes = plt.subplots(1, 5, sharey=True, figsize=(15, 5))\n    for ax, history in enumerate(folds_history):\n        axes[ax].plot(range(1, len(history['root_mean_squared_error']) + 1), history['root_mean_squared_error'], 'black', label='train')\n        axes[ax].plot(range(1, len(history['val_root_mean_squared_error']) + 1), history['val_root_mean_squared_error'], 'green', label='validation')\n        axes[ax].set_title(f'fold {ax}')\n        axes[ax].set_xlabel('Epoch')\n        axes[ax].legend()\n        if ax == 0:\n            axes[ax].set_ylabel('rmse')\n    plt.show()\n\nplot_cv_perfomance(folds_history)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:09:28.838075Z","iopub.execute_input":"2021-07-04T12:09:28.838418Z","iopub.status.idle":"2021-07-04T12:09:29.336844Z","shell.execute_reply.started":"2021-07-04T12:09:28.838386Z","shell.execute_reply":"2021-07-04T12:09:29.336007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Посмотрю на холдауте, блендинг чекпоинтов с фолдов","metadata":{}},{"cell_type":"code","source":"holdout_index = df[df['fold'] == 'holdout'].index.values\n\nX_holdout = [\n    tf.gather(X['input_ids'], holdout_index),\n    tf.gather(X['token_type_ids'], holdout_index),\n    tf.gather(X['attention_mask'], holdout_index),\n]\n\ny_holdout = y[holdout_index] ","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:09:52.104591Z","iopub.execute_input":"2021-07-04T12:09:52.104997Z","iopub.status.idle":"2021-07-04T12:09:52.113831Z","shell.execute_reply.started":"2021-07-04T12:09:52.104962Z","shell.execute_reply":"2021-07-04T12:09:52.112728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls checkpoints","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:09:56.918446Z","iopub.execute_input":"2021-07-04T12:09:56.918815Z","iopub.status.idle":"2021-07-04T12:09:57.702328Z","shell.execute_reply.started":"2021-07-04T12:09:56.918782Z","shell.execute_reply":"2021-07-04T12:09:57.701137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor idx, checkpoint_filepath in enumerate([\n    'checkpoints/checkpoint_0', 'checkpoints/checkpoint_1', 'checkpoints/checkpoint_2',\n    'checkpoints/checkpoint_3', 'checkpoints/checkpoint_4']):\n    \n    model = get_model(bert_model_name, max_sequence_length)\n    model.load_weights(checkpoint_filepath).expect_partial()\n    \n    y_pred = model.predict(X_holdout)\n    y_pred = y_pred.flatten()\n\n    score = sklearn.metrics.mean_squared_error(y_pred, y_holdout, squared=False)\n    print(f'Holdout score, from checkpoint {idx}:', score)\n    \n    predictions.append(y_pred)\n    del model\n\nassert [len(x) == len(y_holdout) for x in predictions]\nmean_prediction = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:10:02.459786Z","iopub.execute_input":"2021-07-04T12:10:02.46013Z","iopub.status.idle":"2021-07-04T12:11:18.469079Z","shell.execute_reply.started":"2021-07-04T12:10:02.460098Z","shell.execute_reply":"2021-07-04T12:11:18.468195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 5))\nplt.plot(range(len(y_pred)), mean_prediction, color='black')\nplt.plot(range(len(y_holdout)), y_holdout, color='red')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:11:18.470529Z","iopub.execute_input":"2021-07-04T12:11:18.470898Z","iopub.status.idle":"2021-07-04T12:11:18.611128Z","shell.execute_reply.started":"2021-07-04T12:11:18.470853Z","shell.execute_reply":"2021-07-04T12:11:18.610136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_score = sklearn.metrics.mean_squared_error(y_holdout, mean_prediction, squared=False)\nprint(f'Holdout, avg score:', mean_score)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:11:18.61282Z","iopub.execute_input":"2021-07-04T12:11:18.613159Z","iopub.status.idle":"2021-07-04T12:11:18.619236Z","shell.execute_reply.started":"2021-07-04T12:11:18.613121Z","shell.execute_reply":"2021-07-04T12:11:18.618285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holdout_error = np.abs(y_holdout - mean_prediction)\nprint('Holdout, mean_error:', np.mean(holdout_error))\nprint('Holdout, std_error:', np.std(holdout_error))\nprint('Holdout, min_error:', np.min(holdout_error))\nprint('Holdout, max_error:' ,np.max(holdout_error))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:11:38.574283Z","iopub.execute_input":"2021-07-04T12:11:38.574622Z","iopub.status.idle":"2021-07-04T12:11:38.58233Z","shell.execute_reply.started":"2021-07-04T12:11:38.57459Z","shell.execute_reply":"2021-07-04T12:11:38.581327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Сабмит, блендинг чепоинтов с фолдов","metadata":{}},{"cell_type":"code","source":"submit_df = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\nsubmit_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:13:51.764294Z","iopub.execute_input":"2021-07-04T12:13:51.764677Z","iopub.status.idle":"2021-07-04T12:13:51.776518Z","shell.execute_reply.started":"2021-07-04T12:13:51.764645Z","shell.execute_reply":"2021-07-04T12:13:51.775531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_submit = prepare_texts_for_bert(\n    texts=submit_df['excerpt'].values.tolist(),\n    tokenizer=tokenizer,\n    max_sequence_length=max_sequence_length,\n)\n\nX_submit = [X_submit['input_ids'], X_submit['token_type_ids'], X_submit['attention_mask']]","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:15:44.945057Z","iopub.execute_input":"2021-07-04T12:15:44.945378Z","iopub.status.idle":"2021-07-04T12:15:44.955284Z","shell.execute_reply.started":"2021-07-04T12:15:44.945348Z","shell.execute_reply":"2021-07-04T12:15:44.954406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor idx, checkpoint_filepath in enumerate([\n    'checkpoints/checkpoint_0', 'checkpoints/checkpoint_1', 'checkpoints/checkpoint_2',\n    'checkpoints/checkpoint_3', 'checkpoints/checkpoint_4']):\n    \n    model = get_model(bert_model_name, max_sequence_length)\n    model.load_weights(checkpoint_filepath).expect_partial()\n    \n    y_pred = model.predict(X_submit)\n    y_pred = y_pred.flatten()\n\n    predictions.append(y_pred)\n    del model\n\nassert [len(x) == len(X_submit) for x in predictions]\nmean_prediction = np.mean(predictions, axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:15:48.122042Z","iopub.execute_input":"2021-07-04T12:15:48.122383Z","iopub.status.idle":"2021-07-04T12:16:41.041122Z","shell.execute_reply.started":"2021-07-04T12:15:48.122351Z","shell.execute_reply":"2021-07-04T12:16:41.040242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = mean_prediction","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:16:41.04252Z","iopub.execute_input":"2021-07-04T12:16:41.042872Z","iopub.status.idle":"2021-07-04T12:16:41.04754Z","shell.execute_reply.started":"2021-07-04T12:16:41.042835Z","shell.execute_reply":"2021-07-04T12:16:41.04638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.DataFrame({'id': submit_df.id, 'target': 0})\nsubmission_df.target = result\n\nsubmission_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:18:21.570392Z","iopub.execute_input":"2021-07-04T12:18:21.570762Z","iopub.status.idle":"2021-07-04T12:18:21.846701Z","shell.execute_reply.started":"2021-07-04T12:18:21.570711Z","shell.execute_reply":"2021-07-04T12:18:21.845786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T12:18:21.848303Z","iopub.execute_input":"2021-07-04T12:18:21.848663Z","iopub.status.idle":"2021-07-04T12:18:21.859225Z","shell.execute_reply.started":"2021-07-04T12:18:21.848625Z","shell.execute_reply":"2021-07-04T12:18:21.857938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}