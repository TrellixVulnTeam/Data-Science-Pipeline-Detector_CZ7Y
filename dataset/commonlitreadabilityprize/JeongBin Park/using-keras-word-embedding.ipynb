{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest = test['excerpt']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text_token = []\nstemmer = PorterStemmer()\nfor text in train['excerpt']:\n    word_token = []\n    sentences = sent_tokenize(text)\n    for sentence in sentences:\n        words = word_tokenize(sentence)\n        for word in words:\n            if word not in stopwords.words('english'):\n                word = stemmer.stem(word)\n                word_token.append(word)\n    text_token.append(word_token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_text_token = []\nstemmer = PorterStemmer()\nfor text in test:\n    word_token = []\n    sentences = sent_tokenize(text)\n    for sentence in sentences:\n        words = word_tokenize(sentence)\n        for word in words:\n            if word not in stopwords.words('english'):\n                word = stemmer.stem(word)\n                word_token.append(word)\n    test_text_token.append(word_token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t = Tokenizer()\nt.fit_on_texts(text_token)\nvocab_size = len(t.word_index) + 1\nX_encoded = t.texts_to_sequences(text_token)\nmax_len=max(len(l) for l in X_encoded)\nX_test_encoded = t.texts_to_sequences(test_text_token)\n\nX_train=pad_sequences(X_encoded, maxlen=max_len, padding='post')\nX_test = pad_sequences(X_test_encoded, maxlen=max_len, padding='post')\ny_train=np.array(train['target'])\n\nX_train.shape, X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, Flatten\nfrom keras.layers import Dense, LSTM, InputLayer, Bidirectional,Dropout\n\nmodel = Sequential()\nmodel.add(Embedding(vocab_size, 4, input_length=max_len))\nmodel.add(Bidirectional(LSTM(256, return_sequences=False), input_shape=X_train.shape[1:]))\nmodel.add(Dense(1))\nmodel.compile(optimizer='adam', loss='mean_squared_error')\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, epochs=15, verbose=1,validation_split=0.4,batch_size=128)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(X_test)\nsubmit = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\nsubmit['target'] = predict\nsubmit.to_csv('submission.csv',index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}