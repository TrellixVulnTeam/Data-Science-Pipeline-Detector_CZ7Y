{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tqdm\nimport gensim\nimport nltk\nfrom nltk.tokenize import sent_tokenize\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\n\n# !wget \"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest = test['excerpt']\n\ntext_token = []\nstemmer = PorterStemmer()\nfor text in train['excerpt']:\n    word_token = []\n    sentences = sent_tokenize(text)\n    for sentence in sentences:\n        words = word_tokenize(sentence)\n        for word in words:\n            if word not in stopwords.words('english'):\n                word = stemmer.stem(word)\n                word_token.append(word)\n    text_token.append(word_token)\n    \ntest_text_token = []\nstemmer = PorterStemmer()\nfor text in test:\n    word_token = []\n    sentences = sent_tokenize(text)\n    for sentence in sentences:\n        words = word_tokenize(sentence)\n        for word in words:\n            if word not in stopwords.words('english'):\n                word = stemmer.stem(word)\n                word_token.append(word)\n    test_text_token.append(word_token)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word2vec_model = gensim.models.KeyedVectors.load_word2vec_format('../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin', binary=True)\nprint(word2vec_model.vectors.shape)\n# from gensim.models import KeyedVectors\n# model.wv.save_word2vec_format('eng_w2v')\n# !python -m gensim.scripts.word2vec2tensor --input eng_w2v --output eng_w2v\n\ndef get_vector(word):\n    if word in word2vec_model:\n        return word2vec_model[word]\n    else:\n        return None\n\nwords = list(word2vec_model.index_to_key)\nfor i in tqdm.tqdm(range(len(text_token))):\n    embedding_matrix = np.zeros((216, 300))\n    for j in range(len(text_token[i])):\n        temp = get_vector(text_token[i][j])\n        if temp is not None:\n            embedding_matrix[j] = temp\n    text_token[i] = embedding_matrix\n    \nwords = list(word2vec_model.index_to_key)\nfor i in tqdm.tqdm(range(len(test_text_token))):\n    embedding_matrix = np.zeros((216, 300))\n    for j in range(len(test_text_token[i])):\n        temp = get_vector(test_text_token[i][j])\n        if temp is not None:\n            embedding_matrix[j] = temp\n    test_text_token[i] = embedding_matrix","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = np.array(text_token)\ny = train['target']\nX_test =np.array(test_text_token)\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, InputLayer, Bidirectional,Dropout\nfrom keras.optimizers import Adam\n\nmodel = Sequential()\nmodel.add(Bidirectional(LSTM(256, return_sequences=False), input_shape=X.shape[1:]))\nmodel.add(Dense(100))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer=Adam(0.001))\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X,y,validation_split=0.4, epochs=10, batch_size=256,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(X_test)\nsubmit = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\nsubmit['target'] = predict\nsubmit.to_csv('submission.csv',index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}