{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# svm_preds 475","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/maunish/clrp-roberta-svm?scriptVersionId=64598846","metadata":{}},{"cell_type":"code","source":"W475 = [.2]*5","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:08:25.70591Z","iopub.execute_input":"2021-06-04T07:08:25.706264Z","iopub.status.idle":"2021-06-04T07:08:25.710496Z","shell.execute_reply.started":"2021-06-04T07:08:25.706216Z","shell.execute_reply":"2021-06-04T07:08:25.709633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification)\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-04T07:02:07.228425Z","iopub.execute_input":"2021-06-04T07:02:07.228901Z","iopub.status.idle":"2021-06-04T07:02:13.647499Z","shell.execute_reply.started":"2021-06-04T07:02:07.228817Z","shell.execute_reply":"2021-06-04T07:02:13.646545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\ntarget = train_data['target'].to_numpy()\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.649059Z","iopub.execute_input":"2021-06-04T07:02:13.649393Z","iopub.status.idle":"2021-06-04T07:02:13.750365Z","shell.execute_reply.started":"2021-06-04T07:02:13.649355Z","shell.execute_reply":"2021-06-04T07:02:13.749557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':128,\n    'max_len':256,\n    'nfolds':5,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.752975Z","iopub.execute_input":"2021-06-04T07:02:13.753318Z","iopub.status.idle":"2021-06-04T07:02:13.762326Z","shell.execute_reply.started":"2021-06-04T07:02:13.753291Z","shell.execute_reply":"2021-06-04T07:02:13.761514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.764136Z","iopub.execute_input":"2021-06-04T07:02:13.76455Z","iopub.status.idle":"2021-06-04T07:02:13.770582Z","shell.execute_reply.started":"2021-06-04T07:02:13.764476Z","shell.execute_reply":"2021-06-04T07:02:13.769762Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.771959Z","iopub.execute_input":"2021-06-04T07:02:13.77237Z","iopub.status.idle":"2021-06-04T07:02:13.783014Z","shell.execute_reply.started":"2021-06-04T07:02:13.772333Z","shell.execute_reply":"2021-06-04T07:02:13.782237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n        self.head = AttentionHead(768,768,1)\n        self.dropout = nn.Dropout(0.1)\n        self.linear = nn.Linear(self.head.out_features,1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.784219Z","iopub.execute_input":"2021-06-04T07:02:13.784621Z","iopub.status.idle":"2021-06-04T07:02:13.793263Z","shell.execute_reply.started":"2021-06-04T07:02:13.784586Z","shell.execute_reply":"2021-06-04T07:02:13.792478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    model = Model()\n    model.load_state_dict(torch.load(path))\n    model.to(device)\n    model.eval()\n    \n    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n    \n    ds = CLRPDataset(df,tokenizer)\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs.detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.794406Z","iopub.execute_input":"2021-06-04T07:02:13.7948Z","iopub.status.idle":"2021-06-04T07:02:13.804115Z","shell.execute_reply.started":"2021-06-04T07:02:13.794766Z","shell.execute_reply":"2021-06-04T07:02:13.80305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings1 =  get_embeddings(train_data,'../input/clrprobertamodels/model0/model0.bin')\n# test_embeddings1 = get_embeddings(test_data,'../input/clrprobertamodels/model0/model0.bin')\n\n# train_embeddings2 =  get_embeddings(train_data,'../input/clrprobertamodels/model1/model1.bin')\n# test_embeddings2 = get_embeddings(test_data,'../input/clrprobertamodels/model1/model1.bin')\n\n# train_embeddings3 =  get_embeddings(train_data,'../input/clrprobertamodels/model2/model2.bin')\n# test_embeddings3 = get_embeddings(test_data,'../input/clrprobertamodels/model2/model2.bin')\n\n# train_embeddings4 =  get_embeddings(train_data,'../input/clrprobertamodels/model3/model3.bin')\n# test_embeddings4 = get_embeddings(test_data,'../input/clrprobertamodels/model3/model3.bin')\n\n# train_embeddings5 =  get_embeddings(train_data,'../input/clrprobertamodels/model4/model4.bin')\n# test_embeddings5 = get_embeddings(test_data,'../input/clrprobertamodels/model4/model4.bin')","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.807298Z","iopub.execute_input":"2021-06-04T07:02:13.807649Z","iopub.status.idle":"2021-06-04T07:02:13.816767Z","shell.execute_reply.started":"2021-06-04T07:02:13.807615Z","shell.execute_reply":"2021-06-04T07:02:13.815944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## svm","metadata":{}},{"cell_type":"code","source":"def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    \n    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        model = SVR(C=C,kernel=kernel,gamma='auto')\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n        \n        model.fit(X_train,y_train)\n        prediction = model.predict(X_valid)\n        score = rmse_score(prediction,y_valid)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.818384Z","iopub.execute_input":"2021-06-04T07:02:13.818785Z","iopub.status.idle":"2021-06-04T07:02:13.828372Z","shell.execute_reply.started":"2021-06-04T07:02:13.81875Z","shell.execute_reply":"2021-06-04T07:02:13.827576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1).mean(axis=1)\n# svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2).mean(axis=1)\n# svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3).mean(axis=1)\n# svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4).mean(axis=1)\n# svm_preds5 = get_preds_svm(train_embeaddings5,target,test_embeddings5).mean(axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.830409Z","iopub.execute_input":"2021-06-04T07:02:13.830645Z","iopub.status.idle":"2021-06-04T07:02:13.839696Z","shell.execute_reply.started":"2021-06-04T07:02:13.830622Z","shell.execute_reply":"2021-06-04T07:02:13.839006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings1 =  get_embeddings(train_data,'../input/clrprobertamodels/model0/model0.bin')\n# test_embeddings1 = get_embeddings(test_data,'../input/clrprobertamodels/model0/model0.bin')\n# svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:13.841001Z","iopub.execute_input":"2021-06-04T07:02:13.841313Z","iopub.status.idle":"2021-06-04T07:02:13.849277Z","shell.execute_reply.started":"2021-06-04T07:02:13.841291Z","shell.execute_reply":"2021-06-04T07:02:13.84852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings1 =  get_embeddings(train_data,'../input/clrprobertamodels/model0/model0.bin')\ntest_embeddings1 = get_embeddings(test_data,'../input/clrprobertamodels/model0/model0.bin')\nsvm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\ndel train_embeddings1,test_embeddings1\ngc.collect()\n\ntrain_embeddings2 =  get_embeddings(train_data,'../input/clrprobertamodels/model1/model1.bin')\ntest_embeddings2 = get_embeddings(test_data,'../input/clrprobertamodels/model1/model1.bin')\nsvm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\ndel train_embeddings2,test_embeddings2\ngc.collect()\n\ntrain_embeddings3 =  get_embeddings(train_data,'../input/clrprobertamodels/model2/model2.bin')\ntest_embeddings3 = get_embeddings(test_data,'../input/clrprobertamodels/model2/model2.bin')\nsvm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\ndel train_embeddings3,test_embeddings3\ngc.collect()\n\ntrain_embeddings4 =  get_embeddings(train_data,'../input/clrprobertamodels/model3/model3.bin')\ntest_embeddings4 = get_embeddings(test_data,'../input/clrprobertamodels/model3/model3.bin')\nsvm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\ndel train_embeddings4,test_embeddings4\ngc.collect()\n\ntrain_embeddings5 =  get_embeddings(train_data,'../input/clrprobertamodels/model4/model4.bin')\ntest_embeddings5 = get_embeddings(test_data,'../input/clrprobertamodels/model4/model4.bin')\nsvm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)\ndel train_embeddings5,test_embeddings5\ndel train_data, test_data\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:02:30.212304Z","iopub.execute_input":"2021-06-04T07:02:30.212622Z","iopub.status.idle":"2021-06-04T07:06:20.381044Z","shell.execute_reply.started":"2021-06-04T07:02:30.212594Z","shell.execute_reply":"2021-06-04T07:06:20.380273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5\nsvm_preds475 = svm_preds1*W475[0] + svm_preds2*W475[1] + \\\n    svm_preds3*W475[2] + svm_preds4*W475[3] + svm_preds5*W475[4]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:08:36.823994Z","iopub.execute_input":"2021-06-04T07:08:36.824479Z","iopub.status.idle":"2021-06-04T07:08:36.831134Z","shell.execute_reply.started":"2021-06-04T07:08:36.824434Z","shell.execute_reply":"2021-06-04T07:08:36.830044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm_preds475 = svm_preds\nsvm_preds475[:10]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:08:49.911898Z","iopub.execute_input":"2021-06-04T07:08:49.912223Z","iopub.status.idle":"2021-06-04T07:08:49.918057Z","shell.execute_reply.started":"2021-06-04T07:08:49.912191Z","shell.execute_reply":"2021-06-04T07:08:49.917027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# svm_preds 476","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/maunish/clrp-roberta-svm?scriptVersionId=64600791","metadata":{}},{"cell_type":"code","source":"W476 = [.2]*5","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:37.703002Z","iopub.execute_input":"2021-06-04T07:16:37.703351Z","iopub.status.idle":"2021-06-04T07:16:37.710107Z","shell.execute_reply.started":"2021-06-04T07:16:37.703321Z","shell.execute_reply":"2021-06-04T07:16:37.709136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.svm import SVR\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification)\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:37.711784Z","iopub.execute_input":"2021-06-04T07:16:37.712434Z","iopub.status.idle":"2021-06-04T07:16:37.724166Z","shell.execute_reply.started":"2021-06-04T07:16:37.712391Z","shell.execute_reply":"2021-06-04T07:16:37.723369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\n\ntarget = train_data['target'].to_numpy()\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:37.944779Z","iopub.execute_input":"2021-06-04T07:16:37.945095Z","iopub.status.idle":"2021-06-04T07:16:37.989086Z","shell.execute_reply.started":"2021-06-04T07:16:37.945064Z","shell.execute_reply":"2021-06-04T07:16:37.988327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':128,\n    'max_len':256,\n    'nfolds':5,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:37.990536Z","iopub.execute_input":"2021-06-04T07:16:37.990882Z","iopub.status.idle":"2021-06-04T07:16:37.99748Z","shell.execute_reply.started":"2021-06-04T07:16:37.990848Z","shell.execute_reply":"2021-06-04T07:16:37.996404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(Dataset):\n    def __init__(self,df,tokenizer):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],return_tensors='pt',\n                                max_length=config['max_len'],\n                                padding='max_length',truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:37.999433Z","iopub.execute_input":"2021-06-04T07:16:37.999772Z","iopub.status.idle":"2021-06-04T07:16:38.011434Z","shell.execute_reply.started":"2021-06-04T07:16:37.999738Z","shell.execute_reply":"2021-06-04T07:16:38.010708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, in_features, hidden_dim, num_targets):\n        super().__init__()\n        self.in_features = in_features\n        self.middle_features = hidden_dim\n\n        self.W = nn.Linear(in_features, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n        self.out_features = hidden_dim\n\n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n\n        score = self.V(att)\n\n        attention_weights = torch.softmax(score, dim=1)\n\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:38.146691Z","iopub.execute_input":"2021-06-04T07:16:38.14697Z","iopub.status.idle":"2021-06-04T07:16:38.153337Z","shell.execute_reply.started":"2021-06-04T07:16:38.146944Z","shell.execute_reply":"2021-06-04T07:16:38.152279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self):\n        super(Model,self).__init__()\n        self.roberta = AutoModel.from_pretrained('../input/roberta-base')    \n        self.head = AttentionHead(768,768,1)\n        self.dropout = nn.Dropout(0.1)\n        self.linear = nn.Linear(self.head.out_features,1)\n\n    def forward(self,**xb):\n        x = self.roberta(**xb)[0]\n        x = self.head(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:38.154953Z","iopub.execute_input":"2021-06-04T07:16:38.155449Z","iopub.status.idle":"2021-06-04T07:16:38.16378Z","shell.execute_reply.started":"2021-06-04T07:16:38.155414Z","shell.execute_reply":"2021-06-04T07:16:38.16299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    model = Model()\n    model.load_state_dict(torch.load(path))\n    model.to(device)\n    model.eval()\n    \n    tokenizer = AutoTokenizer.from_pretrained('../input/roberta-base')\n    \n    ds = CLRPDataset(df,tokenizer)\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs.detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:38.16536Z","iopub.execute_input":"2021-06-04T07:16:38.165623Z","iopub.status.idle":"2021-06-04T07:16:38.17466Z","shell.execute_reply.started":"2021-06-04T07:16:38.1656Z","shell.execute_reply":"2021-06-04T07:16:38.173614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=20,kernel='rbf'):\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    \n    kfold = StratifiedKFold(n_splits=config['nfolds'],shuffle=True,random_state=config['seed'])\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        model = SVR(C=C,kernel=kernel,gamma='auto')\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n        \n        model.fit(X_train,y_train)\n        prediction = model.predict(X_valid)\n        score = rmse_score(prediction,y_valid)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:38.41565Z","iopub.execute_input":"2021-06-04T07:16:38.415925Z","iopub.status.idle":"2021-06-04T07:16:38.423839Z","shell.execute_reply.started":"2021-06-04T07:16:38.415899Z","shell.execute_reply":"2021-06-04T07:16:38.422995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings1 =  get_embeddings(train_data,'../input/clrprobertamodels/model0/model0.bin')\n# test_embeddings1 = get_embeddings(test_data,'../input/clrprobertamodels/model0/model0.bin')\n# svm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\n# del train_embeddings1,test_embeddings1\n# gc.collect()\n\n# train_embeddings2 =  get_embeddings(train_data,'../input/clrprobertamodels/model1/model1.bin')\n# test_embeddings2 = get_embeddings(test_data,'../input/clrprobertamodels/model1/model1.bin')\n# svm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\n# del train_embeddings2,test_embeddings2\n# gc.collect()\n\n# train_embeddings3 =  get_embeddings(train_data,'../input/clrprobertamodels/model2/model2.bin')\n# test_embeddings3 = get_embeddings(test_data,'../input/clrprobertamodels/model2/model2.bin')\n# svm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\n# del train_embeddings3,test_embeddings3\n# gc.collect()\n\n# train_embeddings4 =  get_embeddings(train_data,'../input/clrprobertamodels/model3/model3.bin')\n# test_embeddings4 = get_embeddings(test_data,'../input/clrprobertamodels/model3/model3.bin')\n# svm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\n# del train_embeddings4,test_embeddings4\n# gc.collect()\n\n# train_embeddings5 =  get_embeddings(train_data,'../input/clrprobertamodels/model4/model4.bin')\n# test_embeddings5 = get_embeddings(test_data,'../input/clrprobertamodels/model4/model4.bin')\n# svm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)\n# del train_embeddings5,test_embeddings5\n# del train_data, test_data\n# gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:16:38.425535Z","iopub.execute_input":"2021-06-04T07:16:38.42611Z","iopub.status.idle":"2021-06-04T07:19:47.040753Z","shell.execute_reply.started":"2021-06-04T07:16:38.426074Z","shell.execute_reply":"2021-06-04T07:19:47.039944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5\nsvm_preds476 = svm_preds1*W476[0] + svm_preds2*W476[1] + \\\n    svm_preds3*W476[2] + svm_preds4*W476[3] + svm_preds5*W476[4]","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:19:47.042544Z","iopub.execute_input":"2021-06-04T07:19:47.042868Z","iopub.status.idle":"2021-06-04T07:19:47.048081Z","shell.execute_reply.started":"2021-06-04T07:19:47.042829Z","shell.execute_reply":"2021-06-04T07:19:47.047107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM 4780\nhttps://www.kaggle.com/duttadebadri/eda-basline-modeling-commonlit-passages?scriptVersionId=64615496","metadata":{}},{"cell_type":"code","source":"W4780 = [.2]*5","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:36:52.4286Z","iopub.execute_input":"2021-06-04T07:36:52.428933Z","iopub.status.idle":"2021-06-04T07:36:52.433175Z","shell.execute_reply.started":"2021-06-04T07:36:52.428901Z","shell.execute_reply":"2021-06-04T07:36:52.432126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.offline as py\ncolor = sns.color_palette()\nimport plotly.graph_objs as go\npy.init_notebook_mode(connected=True)\nimport plotly.tools as tls\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\nos.listdir(\"../input/commonlitreadabilityprize\")\nfrom nltk.corpus import stopwords\nimport string\neng_stopwords = set(stopwords.words(\"english\"))\npd.options.mode.chained_assignment = None","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:36:52.777882Z","iopub.execute_input":"2021-06-04T07:36:52.778212Z","iopub.status.idle":"2021-06-04T07:36:52.789452Z","shell.execute_reply.started":"2021-06-04T07:36:52.778182Z","shell.execute_reply":"2021-06-04T07:36:52.788626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.svm import SVR\nimport random\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.optimizer import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import (CosineAnnealingWarmRestarts, CosineAnnealingLR, \n                                      ReduceLROnPlateau)\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup)\n\ntrain_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\ntarget = train_data['target'].to_numpy()\n\n#for kfold  \nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))\n\nconfig = {\n    'batch_size':32,\n    'max_len':512,\n    'seed':23,\n}\n\ndef seed_everything(seed=23):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])\n\nclass CLRPDataset(nn.Module):\n    def __init__(self,df,tokenizer,max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)  \n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \ndef get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    MODEL_PATH = path\n    model = AutoModel.from_pretrained(MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    model.eval()\n\n    ds = CLRPDataset(df,tokenizer,config['max_len'])\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:,0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\n\n\ndef get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n    kfold = StratifiedKFold(n_splits=nfolds)\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        model = SVR()\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n        \n        model.fit(X_train,y_train)\n        prediction = model.predict(X_valid)\n        score = rmse_score(prediction,y_valid)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds\n\ntrain_embeddings1 =  get_embeddings(train_data,'../input/modelf1')\ntest_embeddings1 = get_embeddings(test_data,'../input/modelf1')\n\ntrain_embeddings2 =  get_embeddings(train_data,'../input/modelf2')\ntest_embeddings2 = get_embeddings(test_data,'../input/modelf2')\n\ntrain_embeddings3 =  get_embeddings(train_data,'../input/modelf3')\ntest_embeddings3 = get_embeddings(test_data,'../input/modelf3')\n\ntrain_embeddings4 =  get_embeddings(train_data,'../input/modelf4')\ntest_embeddings4 = get_embeddings(test_data,'../input/modelf4')\n\ntrain_embeddings5 =  get_embeddings(train_data,'../input/modelf5')\ntest_embeddings5 = get_embeddings(test_data,'../input/modelf5')\n\nsvm_preds1 = get_preds_svm(train_embeddings1,target,test_embeddings1)\nsvm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\nsvm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\nsvm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\nsvm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)\n\n# svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5\n\n# sample.target = svm_preds\n# sample.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T07:36:53.105914Z","iopub.execute_input":"2021-06-04T07:36:53.106229Z","iopub.status.idle":"2021-06-04T07:42:46.689473Z","shell.execute_reply.started":"2021-06-04T07:36:53.106197Z","shell.execute_reply":"2021-06-04T07:42:46.688095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5\nsvm_preds4780 = svm_preds1*W4780[0] + svm_preds2*W4780[1] + \\\n    svm_preds3*W4780[2] + svm_preds4*W4780[3] + svm_preds5*W4780[4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM 4781","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/lars123/neural-tangent-kernel-2?scriptVersionId=63130079","metadata":{}},{"cell_type":"code","source":"W4781 = [.2]*5","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:00:12.013003Z","iopub.execute_input":"2021-06-04T08:00:12.013358Z","iopub.status.idle":"2021-06-04T08:00:12.017594Z","shell.execute_reply.started":"2021-06-04T08:00:12.013323Z","shell.execute_reply":"2021-06-04T08:00:12.016535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport sys\nimport cv2\nimport math\nimport time\nimport tqdm\nimport random\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport optuna\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.svm import SVR\nfrom catboost import CatBoostRegressor, Pool, CatBoost\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold,StratifiedKFold\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, lr_scheduler\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.optimizer import Optimizer\nfrom torch.optim.lr_scheduler import _LRScheduler\nfrom torch.optim.lr_scheduler import (CosineAnnealingWarmRestarts, CosineAnnealingLR, \n                                      ReduceLROnPlateau)\n\nfrom transformers import (AutoModel, AutoTokenizer, \n                          AutoModelForSequenceClassification,get_constant_schedule_with_warmup)\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\n\nfrom colorama import Fore, Back, Style\ny_ = Fore.YELLOW\nr_ = Fore.RED\ng_ = Fore.GREEN\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nsr_ = Style.RESET_ALL","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:00:12.024199Z","iopub.execute_input":"2021-06-04T08:00:12.024464Z","iopub.status.idle":"2021-06-04T08:00:12.446528Z","shell.execute_reply.started":"2021-06-04T08:00:12.02444Z","shell.execute_reply":"2021-06-04T08:00:12.445694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\nsample = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\ntarget = train_data['target'].to_numpy()\n\n#for kfold  \nnum_bins = int(np.floor(1 + np.log2(len(train_data))))\ntrain_data.loc[:,'bins'] = pd.cut(train_data['target'],bins=num_bins,labels=False)\nbins = train_data.bins.to_numpy()\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:00:12.448067Z","iopub.execute_input":"2021-06-04T08:00:12.448425Z","iopub.status.idle":"2021-06-04T08:00:12.494867Z","shell.execute_reply.started":"2021-06-04T08:00:12.44839Z","shell.execute_reply":"2021-06-04T08:00:12.494104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {\n    'batch_size':128,\n    'max_len':256,\n    'seed':42,\n}\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\nseed_everything(seed=config['seed'])","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:00:12.496649Z","iopub.execute_input":"2021-06-04T08:00:12.497005Z","iopub.status.idle":"2021-06-04T08:00:12.504198Z","shell.execute_reply.started":"2021-06-04T08:00:12.496969Z","shell.execute_reply":"2021-06-04T08:00:12.502342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CLRPDataset(nn.Module):\n    def __init__(self,df,tokenizer,max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)  \n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:00:12.50611Z","iopub.execute_input":"2021-06-04T08:00:12.506588Z","iopub.status.idle":"2021-06-04T08:00:12.517764Z","shell.execute_reply.started":"2021-06-04T08:00:12.506552Z","shell.execute_reply":"2021-06-04T08:00:12.516919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_embeddings(df,path,plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    MODEL_PATH = path\n    model = AutoModel.from_pretrained(MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    model.eval()\n\n    ds = CLRPDataset(df,tokenizer,config['max_len'])\n    dl = DataLoader(ds,\n                  batch_size = config[\"batch_size\"],\n                  shuffle=False,\n                  num_workers = 4,\n                  pin_memory=True,\n                  drop_last=False\n                 )\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0],-1).to(device) for key,val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:,0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:00:12.519048Z","iopub.execute_input":"2021-06-04T08:00:12.519673Z","iopub.status.idle":"2021-06-04T08:00:12.529743Z","shell.execute_reply.started":"2021-06-04T08:00:12.519637Z","shell.execute_reply":"2021-06-04T08:00:12.528957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:00:12.530931Z","iopub.execute_input":"2021-06-04T08:00:12.531355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from jax import random\nfrom neural_tangents import stax\nimport neural_tangents as nt\n\ndef get_preds_svm(X,y,X_test,bins=bins,nfolds=5,C=10,kernel='rbf'):\n    kfold = StratifiedKFold(n_splits=nfolds)\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    for k, (train_idx,valid_idx) in enumerate(kfold.split(X,bins)):\n        X_train,y_train = X[train_idx], y[train_idx]\n        X_valid,y_valid = X[valid_idx], y[valid_idx]\n\n        ResBlock = stax.serial(\n                        stax.FanOut(2),\n                        stax.parallel(\n                            stax.serial(\n                                stax.Erf(),\n                                stax.Dense(1, W_std=1.25, b_std=0.0),\n                                stax.Erf(),\n                                stax.Dense(1, W_std=1.25, b_std=0.0),\n                                stax.Erf(),\n                                stax.Dense(1, W_std=1.25, b_std=0.0),\n                            ),\n                            stax.Identity(),\n                        ),\n                        stax.FanInSum()\n                    )\n\n        init_fn, apply_fn, kernel_fn = stax.serial(\n                stax.Dense(1, W_std=1.0, b_std=0),\n                ResBlock, ResBlock, stax.Erf(),\n                stax.Dense(1, W_std=2.5, b_std=0.1)\n        )\n\n        key = random.PRNGKey(10)\n        _, params = init_fn(key, input_shape=X_train.shape)\n        predict_fn = nt.predict.gradient_descent_mse_ensemble(kernel_fn,\n                                                                  X_train,\n                                                                  y_train[:,np.newaxis],\n                                                                  diag_reg=1e-1,\n                                                                  lr=1)\n        prediction = predict_fn(x_test=X_valid, get='nngp', t=None)#model.predict(X_valid)\n        score = rmse_score(prediction,y_valid)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += predict_fn(x_test=X_test, get='nngp', t=None)#model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_embeddings1 =  get_embeddings(train_data,'../input/modelf1')\n# test_embeddings1 = get_embeddings(test_data,'../input/modelf1')\n# svm_p1 = get_preds_svm(train_embeddings1,target,test_embeddings1).mean(axis=1)\n# del train_embeddings1,test_embeddings1\n\n# train_embeddings2 =  get_embeddings(train_data,'../input/modelf2')\n# test_embeddings2 = get_embeddings(test_data,'../input/modelf2')\n# svm_p2 = get_preds_svm(train_embeddings2,target,test_embeddings2).mean(axis=1)\n# del train_embeddings2,test_embeddings2\n\n\n# train_embeddings3 =  get_embeddings(train_data,'../input/modelf3')\n# test_embeddings3 = get_embeddings(test_data,'../input/modelf3')\n# svm_p3 = get_preds_svm(train_embeddings3,target,test_embeddings3).mean(axis=1)\n# del train_embeddings3,test_embeddings3\n\n# train_embeddings4 =  get_embeddings(train_data,'../input/modelf4')\n# test_embeddings4 = get_embeddings(test_data,'../input/modelf4')\n# svm_p4 = get_preds_svm(train_embeddings4,target,test_embeddings4).mean(axis=1)\n# del train_embeddings4,test_embeddings4\n\n# train_embeddings5 =  get_embeddings(train_data,'../input/modelf5')\n# test_embeddings5 = get_embeddings(test_data,'../input/modelf5')\n# svm_p5 = get_preds_svm(train_embeddings5,target,test_embeddings5).mean(axis=1)\n# del train_embeddings5,test_embeddings5\n\n# del train_data, test_data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5\n# svm_preds4781 = svm_preds1*W4781[0] + svm_preds2*W4781[1] + \\\n#     svm_preds3*W4781[2] + svm_preds4*W4781[3] + svm_preds5*W4781[4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM 479","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/sourabhy/commonlit-roberta-ensemble-multichannel-cnn?scriptVersionId=63751318","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nimport gc\nimport sys\nimport time\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport xgboost as xgb\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom sklearn.metrics import mean_squared_error\n\nfrom transformers import AutoModel, AutoTokenizer\nimport json\nfrom tensorflow.keras.models import load_model\nimport re\nimport pandas as pd\nimport string\nimport keras\nfrom sklearn.svm import SVR","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '../input/commonlitreadabilityprize/'\ntrain = pd.read_csv(data_dir + 'train.csv')\ntest = pd.read_csv(data_dir + 'test.csv')\nsample_submission = pd.read_csv(data_dir + 'sample_submission.csv')\n\ntarget = train['target'].to_numpy()\n\n\ndef rmse_score(y_true,y_pred):\n    return np.sqrt(mean_squared_error(y_true,y_pred))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# source: https://www.kaggle.com/maunish/clrp-roberta-lgbm\n\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONASSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n\n\nclass CLRPDataset(nn.Module):\n    def __init__(self, df, tokenizer, max_len=128):\n        self.excerpt = df['excerpt'].to_numpy()\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n    \n    def __getitem__(self,idx):\n        encode = self.tokenizer(self.excerpt[idx],\n                                return_tensors='pt',\n                                max_length=self.max_len,\n                                padding='max_length',\n                                truncation=True)\n        return encode\n    \n    def __len__(self):\n        return len(self.excerpt)\n    \n\ndef get_embeddings(df, path, plot_losses=True, verbose=True):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"{device} is used\")\n            \n    MODEL_PATH = path\n    model = AutoModel.from_pretrained(MODEL_PATH)\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model.to(device)\n    model.eval()\n\n    ds = CLRPDataset(df, tokenizer, config['max_len'])\n    dl = DataLoader(ds,\n                    batch_size=config[\"batch_size\"],\n                    shuffle=False,\n                    num_workers = 4,\n                    pin_memory=True,\n                    drop_last=False)\n        \n    embeddings = list()\n    with torch.no_grad():\n        for i, inputs in tqdm(enumerate(dl)):\n            inputs = {key:val.reshape(val.shape[0], -1).to(device) for key, val in inputs.items()}\n            outputs = model(**inputs)\n            outputs = outputs[0][:, 0].detach().cpu().numpy()\n            embeddings.extend(outputs)\n    return np.array(embeddings)\n\nconfig = {\n    'batch_size': 128,\n    'max_len': 256,\n    'seed': 42,\n}\nseed_everything(seed=config['seed'])\n\n# train_embeddings =  get_embeddings(train,'../input/modelf1')\n# test_embeddings = get_embeddings(test,'../input/modelf1')\n\n# train_embeddings2 =  get_embeddings(train,'../input/modelf2')\n# test_embeddings2 = get_embeddings(test,'../input/modelf2')\n\n# train_embeddings3 =  get_embeddings(train,'../input/modelf3')\n# test_embeddings3 = get_embeddings(test,'../input/modelf3')\n\n# train_embeddings4 =  get_embeddings(train,'../input/modelf4')\n# test_embeddings4 = get_embeddings(test,'../input/modelf4')\n\n# train_embeddings5 =  get_embeddings(train,'../input/modelf5')\n# test_embeddings5 = get_embeddings(test,'../input/modelf5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split \nfrom keras.utils import to_categorical\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation, Embedding, LSTM,Dropout,concatenate\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport tensorflow as tf\nfrom tensorflow.python.keras.layers import Dense, Activation, Embedding, LSTM,Dropout,Bidirectional,GRU\nfrom keras.utils import plot_model\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Dense , Flatten ,Embedding,Input,Conv1D,GlobalAveragePooling1D,GlobalMaxPooling1D,Dropout,MaxPooling1D,Bidirectional,GRU,Concatenate\nfrom keras.models import Sequential,Model\nfrom keras.wrappers.scikit_learn import KerasRegressor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crt_model():\n    i1=Input(shape=(768,1))\n    l1=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i1)\n    l2 =MaxPooling1D(2) (l1)\n    l3=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l2)\n    l3 =MaxPooling1D(2) (l3)\n    l3=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l3)\n    l41=GlobalMaxPooling1D()(l3)\n    \n    \n    \n    i2=Input(shape=(768,1))\n    l12=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i2)\n    l22 =MaxPooling1D(2) (l12)\n    l32=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l22)\n    l32 =MaxPooling1D(2) (l32)\n    l32=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l32)\n    l42=GlobalMaxPooling1D()(l32)\n    \n    \n    \n    i3=Input(shape=(768,1))\n    l13=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i3)\n    l23 =MaxPooling1D(2) (l13)\n    l33=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l23)\n    l33 =MaxPooling1D(2) (l33)\n    l33=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l33)\n    l43=GlobalMaxPooling1D()(l33)\n    \n    \n    \n    \n    i4=Input(shape=(768,1))\n    l14=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i4)\n    l24 =MaxPooling1D(2) (l14)\n    l34=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l24)\n    l34 =MaxPooling1D(2) (l34)\n    l34=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l34)\n    l44=GlobalMaxPooling1D()(l34)\n    \n    \n    \n    \n    i5=Input(shape=(768,1))\n    l15=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i5)\n    l25 =MaxPooling1D(2) (l15)\n    l35=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l25)\n    l35 =MaxPooling1D(2) (l35)\n    l35=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l35)\n    l45=GlobalMaxPooling1D()(l35)\n    \n    \n    \n    \n    \n    i6=Input(shape=(768,1))\n    l16=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i6)\n    l26 =MaxPooling1D(2) (l16)\n    l36=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l26)\n    l36 =MaxPooling1D(2) (l36)\n    l36=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l36)\n    l46=GlobalMaxPooling1D()(l36)\n    \n    \n    \n    i7=Input(shape=(768,1))\n    l17=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i7)\n    l27 =MaxPooling1D(2) (l17)\n    l37=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l27)\n    l37 =MaxPooling1D(2) (l37)\n    l37=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l37)\n    l47=GlobalMaxPooling1D()(l37)\n    \n    \n    \n    i8=Input(shape=(768,1))\n    l18=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i8)\n    l28 =MaxPooling1D(2) (l18)\n    l38=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l28)\n    l38 =MaxPooling1D(2) (l38)\n    l38=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l38)\n    l48=GlobalMaxPooling1D()(l38)\n    \n    \n    \n    \n    i9=Input(shape=(768,1))\n    l19=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i9)\n    l29 =MaxPooling1D(2) (l19)\n    l39=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l29)\n    l39 =MaxPooling1D(2) (l39)\n    l39=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l39)\n    l49=GlobalMaxPooling1D()(l39)\n    \n    \n    \n    \n    i10=Input(shape=(768,1))\n    l110=Conv1D(64,5,padding='valid', kernel_initializer='normal',activation='relu')(i10)\n    l210=MaxPooling1D(2) (l110)\n    l310=Conv1D(128,5,padding='valid', kernel_initializer='normal',activation='relu')(l210)\n    l310 =MaxPooling1D(2) (l310)\n    l310=Conv1D(256,5,padding='valid', kernel_initializer='normal',activation='relu')(l310)\n    l410=GlobalMaxPooling1D()(l310)\n    \n    \n    \n    \n    \n    \n    \n    \n       \n    \n    l4 = concatenate([l41, l42, l43, l44, l45,l46,l47,l48,l49,l410])\n    \n    \n    l5=Dense(120, kernel_initializer='normal',activation='relu')(l4)\n    l5=Dense(240, kernel_initializer='normal',activation='relu')(l5)\n    l7=Dense(1, kernel_initializer='normal')(l5)\n    model=Model(inputs=[i1,i2,i3,i4,i5,i6,i7,i8,i9,i10], outputs=l7)\n    model.compile(loss='mean_squared_error', optimizer='adam',metrics=[keras.metrics.MeanSquaredError()])\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=crt_model()\nkeras.utils.plot_model(model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_res(train_embedd,target,test_embedd):\n    nfolds = 5\n    scores =[]\n    preds = np.zeros((test_embedd.shape[0]))\n    kf = KFold(n_splits=nfolds, shuffle=True, random_state=config['seed'])\n    for k, (train_idx, valid_idx) in enumerate(kf.split(train)): \n        model=crt_model()\n        train_x,train_y,test_x,test_y=train_embedd[train_idx], target[train_idx],train_embedd[valid_idx], target[valid_idx]\n        train_x=train_x.reshape(train_x.shape+(1,))\n        traindata=[train_x for i in range(10)]\n        val=[test_x for i in range(10)]\n        model.fit(traindata,train_y,epochs=7,validation_data=(val,test_y),batch_size=8)\n        y_pred=model.predict(val)\n        score = rmse_score(y_pred,test_y)\n        scores.append(score)\n        print(f'Fold {k} , rmse score: {score}')\n        test=[test_embedd for i in range(10)]\n        y_preds = model.predict(test)\n        y_preds=y_preds.reshape(-1)\n        preds+=y_preds\n   \n        \n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_preds_svm(X,y,X_test,nfolds=5,C=10,kernel='rbf'):\n    scores = list()\n    preds = np.zeros((X_test.shape[0]))\n    kf = KFold(n_splits=nfolds, shuffle=True, random_state=config['seed'])\n    for k, (train_idx, valid_idx) in enumerate(kf.split(train)): \n        model = SVR(C=C,kernel=kernel,gamma='auto')\n        train_x,train_y,val_x,val_y=X[train_idx], y[train_idx],X[valid_idx], y[valid_idx]\n        \n        \n        model.fit(train_x,train_y)\n        prediction = model.predict(val_x)\n        score = rmse_score(prediction,val_y)\n        print(f'Fold {k} , rmse score: {score}')\n        scores.append(score)\n        preds += model.predict(X_test)\n        \n    print(\"mean rmse\",np.mean(scores))\n    return np.array(preds)/nfolds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_embeddings =  get_embeddings(train,'../input/modelf1')\ntest_embeddings = get_embeddings(test,'../input/modelf1')\npred1=get_res(train_embeddings,target,test_embeddings)\nsvm_preds1 = get_preds_svm(train_embeddings,target,test_embeddings)\ndel train_embeddings,test_embeddings\ngc.collect()\n\ntrain_embeddings2 =  get_embeddings(train,'../input/modelf2')\ntest_embeddings2 = get_embeddings(test,'../input/modelf2')\npred2=get_res(train_embeddings2,target,test_embeddings2)\nsvm_preds2 = get_preds_svm(train_embeddings2,target,test_embeddings2)\ndel train_embeddings2,test_embeddings2\ngc.collect()\n\ntrain_embeddings3 =  get_embeddings(train,'../input/modelf3')\ntest_embeddings3 = get_embeddings(test,'../input/modelf3')\npred3=get_res(train_embeddings3,target,test_embeddings3)\nsvm_preds3 = get_preds_svm(train_embeddings3,target,test_embeddings3)\ndel train_embeddings3,test_embeddings3\ngc.collect()\n\ntrain_embeddings4 =  get_embeddings(train,'../input/modelf4')\ntest_embeddings4 = get_embeddings(test,'../input/modelf4')\npred4=get_res(train_embeddings4,target,test_embeddings4)\nsvm_preds4 = get_preds_svm(train_embeddings4,target,test_embeddings4)\ndel train_embeddings4,test_embeddings4\ngc.collect()\n\ntrain_embeddings5 =  get_embeddings(train,'../input/modelf5')\ntest_embeddings5 = get_embeddings(test,'../input/modelf5')\npred5=get_res(train_embeddings5,target,test_embeddings5)\nsvm_preds5 = get_preds_svm(train_embeddings5,target,test_embeddings5)\ndel train_embeddings5,test_embeddings5\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds=(pred1+pred2+pred3+pred4+pred5)/5\nsvm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"svm_preds479 = (preds+svm_preds)/2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# SVM 480","metadata":{}},{"cell_type":"code","source":"W480 = [.2]*5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pandas as pd\nimport numpy as np\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Dataset:\n    def __init__(self, excerpt, tokenizer, max_len):\n        self.excerpt = excerpt\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n\n    def __len__(self):\n        return len(self.excerpt)\n\n    def __getitem__(self, item):\n        text = str(self.excerpt[item])\n        inputs = self.tokenizer(\n            text, \n            max_length=self.max_len, \n            padding=\"max_length\", \n            truncation=True\n        )\n\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n\n        return {\n            \"input_ids\": torch.tensor(ids, dtype=torch.long),\n            \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n        }","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def generate_predictions(model_path, max_len):\n    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n    tokenizer = AutoTokenizer.from_pretrained(model_path)\n\n    model.to(\"cuda\")\n    model.eval()\n    \n    df = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n    \n    dataset = Dataset(excerpt=df.excerpt.values, tokenizer=tokenizer, max_len=max_len)\n    data_loader = torch.utils.data.DataLoader(\n        dataset, batch_size=32, num_workers=4, pin_memory=True, shuffle=False\n    )\n\n    final_output = []\n\n    for b_idx, data in enumerate(data_loader):\n        with torch.no_grad():\n            for key, value in data.items():\n                data[key] = value.to(\"cuda\")\n            output = model(**data)\n            output = output.logits.detach().cpu().numpy().ravel().tolist()\n            final_output.extend(output)\n    \n    torch.cuda.empty_cache()\n    return np.array(final_output)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# preds1 = generate_predictions(\"../input/a81653/\", max_len=256)\n# preds2 = generate_predictions(\"../input/a81656/\", max_len=256)\n# preds3 = generate_predictions(\"../input/a81657/\", max_len=256)\n# preds4 = generate_predictions(\"../input/a81660/\", max_len=256)\n# preds5 = generate_predictions(\"../input/a81675/\", max_len=192)\n# preds6 = generate_predictions(\"../input/a87832/\", max_len=256)\ngc.collect()\n\npreds480 = (preds1 + preds2 + preds3 + preds4 + preds5 + preds6) / 6","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # svm_preds = (svm_preds1 + svm_preds2 + svm_preds3 + svm_preds4 + svm_preds5)/5\n# svm_preds480 = svm_preds1*W480[0] + svm_preds2*W480[1] + \\\n#     svm_preds3*W480[2] + svm_preds4*W480[3] + svm_preds5*W480[4]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make sub","metadata":{}},{"cell_type":"code","source":"svm_preds475\nsvm_preds476\nsvm_preds4780\nsvm_preds4781\nsvm_preds479\npreds480","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n# sub['target'] = ((RBWRTbase_pred_df.mean(axis=1) + RBWRTlarge_pred_df.mean(axis=1))/2).values.tolist()\n# sub['target'] = pds1*W_M['RoBL'] + pds2*W_M['RoBB'] + pds3*W_M['SVM']\n# sub['target'] = (svm_preds475 + svm_preds476)/2\n# sub['target'] = (svm_preds475 + svm_preds476 + svm_preds4780 + svm_preds479)/4\n\n# sub['target'] = (svm_preds475 + svm_preds4780 + svm_preds479)/3\nsub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}