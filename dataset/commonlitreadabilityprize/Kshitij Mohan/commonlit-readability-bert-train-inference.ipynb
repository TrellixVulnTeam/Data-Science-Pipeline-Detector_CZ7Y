{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport sys\nimport seaborn as sns\nimport tensorflow as tf\nimport tensorflow_hub as hub\nfrom sklearn.model_selection import StratifiedKFold, KFold\nimport logging\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom wordcloud import WordCloud,STOPWORDS\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nimport re,string,unicodedata\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt\n\nsns.set_style(\"darkgrid\")\nlogging.basicConfig(level=logging.INFO)","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","papermill":{"duration":6.840927,"end_time":"2021-05-05T10:40:17.384963","exception":false,"start_time":"2021-05-05T10:40:10.544036","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. We will need bert `Tokenization` class","metadata":{"papermill":{"duration":0.012638,"end_time":"2021-05-05T10:40:17.410957","exception":false,"start_time":"2021-05-05T10:40:17.398319","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Step_1 load packages and data","metadata":{"papermill":{"duration":0.012489,"end_time":"2021-05-05T10:40:17.436168","exception":false,"start_time":"2021-05-05T10:40:17.423679","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\n\ntrain.head()","metadata":{"papermill":{"duration":0.112502,"end_time":"2021-05-05T10:40:17.561765","exception":false,"start_time":"2021-05-05T10:40:17.449263","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"debug = False\nif debug:\n    train = train.sample(1000)","metadata":{"papermill":{"duration":0.019811,"end_time":"2021-05-05T10:40:17.595732","exception":false,"start_time":"2021-05-05T10:40:17.575921","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step_2 data cleaning","metadata":{"papermill":{"duration":0.01331,"end_time":"2021-05-05T10:40:17.622788","exception":false,"start_time":"2021-05-05T10:40:17.609478","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Wordcloud for HIGH readability text**","metadata":{"papermill":{"duration":0.013181,"end_time":"2021-05-05T10:40:17.649553","exception":false,"start_time":"2021-05-05T10:40:17.636372","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize = (20,20))\nwc = WordCloud(max_words = 1000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(train[train.target > 0].excerpt))\nplt.imshow(wc , interpolation = 'bilinear')","metadata":{"papermill":{"duration":9.140484,"end_time":"2021-05-05T10:40:26.803401","exception":false,"start_time":"2021-05-05T10:40:17.662917","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Wordcloud for LOW readability text**","metadata":{"papermill":{"duration":0.034492,"end_time":"2021-05-05T10:40:26.872815","exception":false,"start_time":"2021-05-05T10:40:26.838323","status":"completed"},"tags":[]}},{"cell_type":"code","source":"plt.figure(figsize = (20,20))\nwc = WordCloud(max_words = 1000 , width = 1600 , height = 800 , stopwords = STOPWORDS).generate(\" \".join(train[train.target < 0].excerpt))\nplt.imshow(wc , interpolation = 'bilinear')","metadata":{"papermill":{"duration":10.547391,"end_time":"2021-05-05T10:40:37.454621","exception":false,"start_time":"2021-05-05T10:40:26.90723","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Number of characters in texts**","metadata":{"papermill":{"duration":0.05529,"end_time":"2021-05-05T10:40:37.566127","exception":false,"start_time":"2021-05-05T10:40:37.510837","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,8))\ntext_len=train[train.target < 0]['excerpt'].str.len()\nax1.hist(text_len,color='red')\nax1.set_title('Low Readability')\ntext_len=train[train.target > 0]['excerpt'].str.len()\nax2.hist(text_len,color='green')\nax2.set_title('High Readability')\nfig.suptitle('Characters in texts')\nplt.show()","metadata":{"papermill":{"duration":0.408029,"end_time":"2021-05-05T10:40:38.029637","exception":false,"start_time":"2021-05-05T10:40:37.621608","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Number of words in each text**","metadata":{"papermill":{"duration":0.055701,"end_time":"2021-05-05T10:40:38.141052","exception":false,"start_time":"2021-05-05T10:40:38.085351","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,8))\ntext_len=train[train.target < 0]['excerpt'].str.split().map(lambda x: len(x))\nax1.hist(text_len,color='red')\nax1.set_title('Low Readability')\ntext_len=train[train.target > 0]['excerpt'].str.split().map(lambda x: len(x))\nax2.hist(text_len,color='green')\nax2.set_title('High Readability')\nfig.suptitle('Words in texts')\nplt.show()","metadata":{"papermill":{"duration":0.45978,"end_time":"2021-05-05T10:40:38.658779","exception":false,"start_time":"2021-05-05T10:40:38.198999","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"papermill":{"duration":0.056632,"end_time":"2021-05-05T10:40:38.772178","exception":false,"start_time":"2021-05-05T10:40:38.715546","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"**Average word length in a text**","metadata":{"papermill":{"duration":0.058947,"end_time":"2021-05-05T10:40:38.889038","exception":false,"start_time":"2021-05-05T10:40:38.830091","status":"completed"},"tags":[]}},{"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(20,10))\nword=train[train.target < 0]['excerpt'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax1,color='red')\nax1.set_title('Low Readability')\nword=train[train.target > 0]['excerpt'].str.split().apply(lambda x : [len(i) for i in x])\nsns.distplot(word.map(lambda x: np.mean(x)),ax=ax2,color='green')\nax2.set_title('High Readability')\nfig.suptitle('Average word length in each text')","metadata":{"papermill":{"duration":0.819781,"end_time":"2021-05-05T10:40:39.769517","exception":false,"start_time":"2021-05-05T10:40:38.949736","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step_2: build bert_layer and model","metadata":{"papermill":{"duration":0.060266,"end_time":"2021-05-05T10:40:39.889017","exception":false,"start_time":"2021-05-05T10:40:39.828751","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%time\nsys.path.append('../input/tokenization')\nimport tensorflow_hub as hub \nimport tokenization\nmodule_url = '../input/bert-en-uncased-l12-h768-a122'\nbert_layer = hub.KerasLayer(module_url, trainable=True)","metadata":{"papermill":{"duration":15.689746,"end_time":"2021-05-05T10:40:55.638552","exception":false,"start_time":"2021-05-05T10:40:39.948806","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.gfile = tf.io.gfile\nvocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\ndo_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\ntokenizer = tokenization.FullTokenizer(vocab_file, do_lower_case)\n\ndef bert_encode(texts, tokenizer, max_len=512):\n    all_tokens = []\n    all_masks = []\n    all_segments = []\n    \n    for text in texts:\n        text = tokenizer.tokenize(text)\n            \n        text = text[:max_len-2]\n        input_sequence = [\"[CLS]\"] + text + [\"[SEP]\"]\n        pad_len = max_len - len(input_sequence)\n        \n        tokens = tokenizer.convert_tokens_to_ids(input_sequence) + [0] * pad_len\n        pad_masks = [1] * len(input_sequence) + [0] * pad_len\n        segment_ids = [0] * max_len\n        \n        all_tokens.append(tokens)\n        all_masks.append(pad_masks)\n        all_segments.append(segment_ids)\n    \n    return np.array(all_tokens), np.array(all_masks), np.array(all_segments)\n\ndef build_model(bert_layer, max_len=512):\n    input_word_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    input_mask = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"input_mask\")\n    segment_ids = tf.keras.Input(shape=(max_len,), dtype=tf.int32, name=\"segment_ids\")\n\n    pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n    clf_output = sequence_output[:, 0, :]\n    net = tf.keras.layers.Dense(64, activation='relu')(clf_output)\n    net = tf.keras.layers.Dropout(0.2)(net)\n    net = tf.keras.layers.Dense(16, activation='relu')(net)\n    net = tf.keras.layers.Dropout(0.2)(net)\n    out = tf.keras.layers.Dense(1, activation='linear')(net)\n    \n    model = tf.keras.models.Model(inputs=[input_word_ids, input_mask, segment_ids], outputs=out)\n    model.compile(tf.keras.optimizers.Adam(lr=1e-5), loss='mean_squared_error')\n    \n    return model","metadata":{"papermill":{"duration":0.199665,"end_time":"2021-05-05T10:40:55.898776","exception":false,"start_time":"2021-05-05T10:40:55.699111","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Step_3: Run model and export predictions","metadata":{"papermill":{"duration":0.059625,"end_time":"2021-05-05T10:40:56.019782","exception":false,"start_time":"2021-05-05T10:40:55.960157","status":"completed"},"tags":[]}},{"cell_type":"code","source":"preds = None\nkf = KFold(n_splits = 5 , shuffle = True , random_state = 42)\nfor fold , (train_index , val_index) in enumerate(kf.split(train[\"excerpt\"] , train['target'])):\n    print(\"Training Fold {}\".format(fold))\n    \n    x_train, x_val = train.excerpt.values[train_index], train.excerpt.values[val_index]\n    y_train, y_val = train.target.values[train_index], train.target.values[val_index]\n    \n    max_len = 300\n    train_input = bert_encode(x_train, tokenizer, max_len=max_len)\n    val_input = bert_encode(x_val, tokenizer, max_len=max_len)\n    test_input = bert_encode(test.excerpt.values, tokenizer, max_len=max_len)\n    \n    BATCH_SIZE = 16\n    \n    name = \"model_fold_{}\".format(fold) +\".h5\"\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(name, monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor = 0.5 , patience=2, mode='min', verbose=1)\n\n    load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n    bert_layer = hub.KerasLayer(module_url, trainable=True , load_options=load_locally)\n    model = build_model(bert_layer, max_len=max_len)\n    \n    train_history = model.fit(\n        train_input, y_train, \n        epochs=15,\n        callbacks=[checkpoint, reduce_lr],\n        batch_size=BATCH_SIZE,\n        validation_data = (val_input, y_val),\n        verbose=1)\n    \n    model.load_weights(name)\n    \n    if preds is None:\n        preds = model.predict(test_input)\n    else:\n        preds += model.predict(test_input)\n\npreds = preds/5","metadata":{"papermill":{"duration":4755.999006,"end_time":"2021-05-05T12:00:12.078304","exception":false,"start_time":"2021-05-05T10:40:56.079298","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds[:5]","metadata":{"papermill":{"duration":1.937284,"end_time":"2021-05-05T12:00:15.927385","exception":false,"start_time":"2021-05-05T12:00:13.990101","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nsub = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv')\n\nsub['target'] = preds\nsub.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":2.290349,"end_time":"2021-05-05T12:00:20.095721","exception":false,"start_time":"2021-05-05T12:00:17.805372","status":"completed"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":1.894263,"end_time":"2021-05-05T12:00:24.523383","exception":false,"start_time":"2021-05-05T12:00:22.62912","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}