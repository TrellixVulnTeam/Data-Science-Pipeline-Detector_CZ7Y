{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nfrom collections import Counter\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport nltk\nimport string\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import MinMaxScaler,Normalizer\nfrom sklearn.ensemble import  GradientBoostingRegressor,RandomForestRegressor\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom xgboost import XGBRegressor\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfiles = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        filename1 = '..'+dirname[7:]+'/'+filename\n        files.append(filename1)\nprint(files)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T15:15:17.885763Z","iopub.execute_input":"2021-06-11T15:15:17.886086Z","iopub.status.idle":"2021-06-11T15:15:17.896876Z","shell.execute_reply.started":"2021-06-11T15:15:17.886058Z","shell.execute_reply":"2021-06-11T15:15:17.895964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframes = []\nfor a in range(len(files)):\n    name = 'df{}'.format(a)\n    name = pd.read_csv(files[a])\n    dataframes.append(name)\n\nfor a in range(len(dataframes)):\n    print('FileName: ',files[a],'\\n',\"Shape:\",dataframes[a].shape,'\\n')\n    df = dataframes[a].head()\n    print(df)\n    if a != (len(dataframes) -1 ): \n        print('========================\\nNext DataFrame\\n========================')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:17.913415Z","iopub.execute_input":"2021-06-11T15:15:17.913833Z","iopub.status.idle":"2021-06-11T15:15:17.979586Z","shell.execute_reply.started":"2021-06-11T15:15:17.913788Z","shell.execute_reply":"2021-06-11T15:15:17.978523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframes[1]['excerpt'] = dataframes[1]['excerpt'].str.lower()\ndataframes[2]['excerpt'] = dataframes[2]['excerpt'].str.lower()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:17.981313Z","iopub.execute_input":"2021-06-11T15:15:17.981688Z","iopub.status.idle":"2021-06-11T15:15:17.994621Z","shell.execute_reply.started":"2021-06-11T15:15:17.98165Z","shell.execute_reply":"2021-06-11T15:15:17.993446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframes[1].head()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:17.996143Z","iopub.execute_input":"2021-06-11T15:15:17.99655Z","iopub.status.idle":"2021-06-11T15:15:18.021826Z","shell.execute_reply.started":"2021-06-11T15:15:17.996508Z","shell.execute_reply":"2021-06-11T15:15:18.020656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframes[1].info()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:18.022976Z","iopub.execute_input":"2021-06-11T15:15:18.023373Z","iopub.status.idle":"2021-06-11T15:15:18.043742Z","shell.execute_reply.started":"2021-06-11T15:15:18.023332Z","shell.execute_reply":"2021-06-11T15:15:18.042673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataframes[1].isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:18.044861Z","iopub.execute_input":"2021-06-11T15:15:18.045101Z","iopub.status.idle":"2021-06-11T15:15:18.053585Z","shell.execute_reply.started":"2021-06-11T15:15:18.045077Z","shell.execute_reply":"2021-06-11T15:15:18.052604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = dataframes[1][['id','excerpt','target','standard_error']]\ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:18.054953Z","iopub.execute_input":"2021-06-11T15:15:18.05523Z","iopub.status.idle":"2021-06-11T15:15:18.064927Z","shell.execute_reply.started":"2021-06-11T15:15:18.055206Z","shell.execute_reply":"2021-06-11T15:15:18.064128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df.columns)\nX = df['excerpt']\ny = df['target'].values","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:18.067389Z","iopub.execute_input":"2021-06-11T15:15:18.067739Z","iopub.status.idle":"2021-06-11T15:15:18.073989Z","shell.execute_reply.started":"2021-06-11T15:15:18.067677Z","shell.execute_reply":"2021-06-11T15:15:18.072953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.33)\n\ncount_vectorizer = CountVectorizer(stop_words = 'english')\ncount_train3 = count_vectorizer.fit_transform(X_train.values) \ncount_test3 = count_vectorizer.transform(X_test.values)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:18.075226Z","iopub.execute_input":"2021-06-11T15:15:18.075649Z","iopub.status.idle":"2021-06-11T15:15:18.445751Z","shell.execute_reply.started":"2021-06-11T15:15:18.075613Z","shell.execute_reply":"2021-06-11T15:15:18.444878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create and fit the model\nlinreg = LinearRegression()\nlinreg.fit(count_train3, y_train)\n# Predict on the test features, print the results\npred1 = linreg.predict(count_test3)\n\nmse = metrics.mean_squared_error(pred1,y_test) \nrmse = metrics.mean_squared_error(pred1,y_test, squared = False) \n# The mean squared error\nprint('Mean squared error: %.4f' % mse)\n# The Root mean squared error\nprint('Root mean squared error: %.4f' % rmse)\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.4f'\n      % metrics.r2_score(pred1, y_test))\nprint('R-Squared: %.4f'\n      %linreg.score(count_test3, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:18.44681Z","iopub.execute_input":"2021-06-11T15:15:18.447186Z","iopub.status.idle":"2021-06-11T15:15:18.588581Z","shell.execute_reply.started":"2021-06-11T15:15:18.447141Z","shell.execute_reply":"2021-06-11T15:15:18.58754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['Flesch Reading East Score'] = df['excerpt'].apply(textstat.flesch_reading_ease)\ndf['Flesch-Kincaid Grade'] = df['excerpt'].apply(textstat.flesch_kincaid_grade)\ndf['Dale-Chall Readability score'] = df['excerpt'].apply(textstat.dale_chall_readability_score)\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:18.589894Z","iopub.execute_input":"2021-06-11T15:15:18.590429Z","iopub.status.idle":"2021-06-11T15:15:21.218576Z","shell.execute_reply.started":"2021-06-11T15:15:18.590389Z","shell.execute_reply":"2021-06-11T15:15:21.217546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.33)\n\ncount_vectorizer = TfidfVectorizer(stop_words = 'english', ngram_range = (1,1))\ncount_train3 = count_vectorizer.fit_transform(X_train.values) \ncount_test3 = count_vectorizer.transform(X_test.values)\n\n# Create and fit the model\nlinreg = LinearRegression()\nlinreg.fit(count_train3, y_train)\n# Predict on the test features, print the results\npred1 = linreg.predict(count_test3)\n\nmse = metrics.mean_squared_error(pred1,y_test) \nrmse = metrics.mean_squared_error(pred1,y_test, squared = False) \n# The mean squared error\nprint('Mean squared error: %.4f' % mse)\n# The Root mean squared error\nprint('Root mean squared error: %.4f' % rmse)\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.4f'\n      % metrics.r2_score(pred1, y_test))\nprint('R-Squared: %.4f'\n      %linreg.score(count_test3, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:21.221124Z","iopub.execute_input":"2021-06-11T15:15:21.221435Z","iopub.status.idle":"2021-06-11T15:15:21.650411Z","shell.execute_reply.started":"2021-06-11T15:15:21.221407Z","shell.execute_reply":"2021-06-11T15:15:21.649337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.33)\n\ncount_vectorizer = CountVectorizer(stop_words = 'english', ngram_range = (1,4))\ncount_train3 = count_vectorizer.fit_transform(X_train.values) \ncount_test3 = count_vectorizer.transform(X_test.values)\n\n# Create and fit the model\nlinreg = GradientBoostingRegressor()\nlinreg.fit(count_train3, y_train)\n# Predict on the test features, print the results\npred1 = linreg.predict(count_test3)\n\nmse = metrics.mean_squared_error(pred1,y_test) \nrmse = metrics.mean_squared_error(pred1,y_test, squared = False) \n# The mean squared error\nprint('Mean squared error: %.4f' % mse)\n# The Root mean squared error\nprint('Root mean squared error: %.4f' % rmse)\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.4f'\n      % metrics.r2_score(pred1, y_test))\nprint('R-Squared: %.4f'\n      %linreg.score(count_test3, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:15:21.652031Z","iopub.execute_input":"2021-06-11T15:15:21.65244Z","iopub.status.idle":"2021-06-11T15:16:24.693598Z","shell.execute_reply.started":"2021-06-11T15:15:21.652397Z","shell.execute_reply":"2021-06-11T15:16:24.692631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into training and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size = 0.33)\n\ncount_vectorizer = CountVectorizer(stop_words = 'english', ngram_range = (1,2))\ncount_train3 = count_vectorizer.fit_transform(X_train.values) \ncount_test3 = count_vectorizer.transform(X_test.values)\n\n# Create and fit the model\nlinreg = LinearRegression()\nlinreg.fit(count_train3, y_train)\n# Predict on the test features, print the results\npred1 = linreg.predict(count_test3)\n\nmse = metrics.mean_squared_error(pred1,y_test) \nrmse = metrics.mean_squared_error(pred1,y_test, squared = False) \n# The mean squared error\nprint('Mean squared error: %.4f' % mse)\n# The Root mean squared error\nprint('Root mean squared error: %.4f' % rmse)\n# The coefficient of determination: 1 is perfect prediction\nprint('Coefficient of determination: %.4f'\n      % metrics.r2_score(pred1, y_test))\nprint('R-Squared: %.4f'\n      %linreg.score(count_test3, y_test))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:16:24.694866Z","iopub.execute_input":"2021-06-11T15:16:24.695222Z","iopub.status.idle":"2021-06-11T15:16:26.114486Z","shell.execute_reply.started":"2021-06-11T15:16:24.695184Z","shell.execute_reply":"2021-06-11T15:16:26.113521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = dataframes[2]\n\nx_test = df_test['excerpt']\ncount_test3 = count_vectorizer.transform(x_test.values)\npred2 = linreg.predict(count_test3)\na = pd.DataFrame(pred2)\nb = df_test['id']\ndf_s = pd.concat([b,a], axis = 1)\ndf_s = df_s.rename({0:'target'},axis = 1)\ndf_s","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:16:26.115816Z","iopub.execute_input":"2021-06-11T15:16:26.116383Z","iopub.status.idle":"2021-06-11T15:16:26.14038Z","shell.execute_reply.started":"2021-06-11T15:16:26.116342Z","shell.execute_reply":"2021-06-11T15:16:26.13938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_s.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T15:16:45.861306Z","iopub.execute_input":"2021-06-11T15:16:45.861855Z","iopub.status.idle":"2021-06-11T15:16:45.866875Z","shell.execute_reply.started":"2021-06-11T15:16:45.861821Z","shell.execute_reply":"2021-06-11T15:16:45.865869Z"},"trusted":true},"execution_count":null,"outputs":[]}]}