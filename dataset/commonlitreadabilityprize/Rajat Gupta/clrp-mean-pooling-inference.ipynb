{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport random\n\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup, logging\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, TensorDataset, SequentialSampler, RandomSampler, DataLoader\n\nfrom tqdm.notebook import tqdm\n\nimport gc; gc.enable()\nfrom IPython.display import clear_output\n\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nsns.set_style('whitegrid')\nlogging.set_verbosity_error()","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:49:20.733156Z","iopub.execute_input":"2021-07-25T08:49:20.73362Z","iopub.status.idle":"2021-07-25T08:49:26.277794Z","shell.execute_reply.started":"2021-07-25T08:49:20.733503Z","shell.execute_reply":"2021-07-25T08:49:26.276796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = '../input/commonlitreadabilityprize'\nMODEL_DIR = '../input/roberta-transformers-pytorch/roberta-large'\nCHECKPOINT_DIR = '../input/clrp-mean-pooling/'\n\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nMAX_LENGTH = 300\nTEST_BATCH_SIZE = 8\nHIDDEN_SIZE = 1024\n\nNUM_FOLDS = 5\nSEEDS = [113, 71]","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:49:26.279522Z","iopub.execute_input":"2021-07-25T08:49:26.279998Z","iopub.status.idle":"2021-07-25T08:49:26.318557Z","shell.execute_reply.started":"2021-07-25T08:49:26.279956Z","shell.execute_reply":"2021-07-25T08:49:26.317716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'))\ntest.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:49:26.320762Z","iopub.execute_input":"2021-07-25T08:49:26.321372Z","iopub.status.idle":"2021-07-25T08:49:26.354734Z","shell.execute_reply.started":"2021-07-25T08:49:26.321295Z","shell.execute_reply":"2021-07-25T08:49:26.353814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MeanPoolingModel(nn.Module):\n    \n    def __init__(self, model_name):\n        super().__init__()\n        \n        config = AutoConfig.from_pretrained(model_name)\n        self.model = AutoModel.from_pretrained(model_name, config=config)\n        self.linear = nn.Linear(HIDDEN_SIZE, 1)\n        self.loss = nn.MSELoss()\n        \n    def forward(self, input_ids, attention_mask, labels=None):\n        \n        outputs = self.model(input_ids, attention_mask)\n        last_hidden_state = outputs[0]\n        input_mask_expanded = attention_mask.unsqueeze(-1).expand(last_hidden_state.size()).float()\n        sum_embeddings = torch.sum(last_hidden_state * input_mask_expanded, 1)\n        sum_mask = input_mask_expanded.sum(1)\n        sum_mask = torch.clamp(sum_mask, min=1e-9)\n        mean_embeddings = sum_embeddings / sum_mask\n        logits = self.linear(mean_embeddings)\n        \n        preds = logits.squeeze(-1).squeeze(-1)\n        \n        if labels is not None:\n            loss = self.loss(preds.view(-1).float(), labels.view(-1).float())\n            return loss\n        else:\n            return preds","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:49:26.35638Z","iopub.execute_input":"2021-07-25T08:49:26.356755Z","iopub.status.idle":"2021-07-25T08:49:26.366164Z","shell.execute_reply.started":"2021-07-25T08:49:26.356706Z","shell.execute_reply":"2021-07-25T08:49:26.365131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_loader(data):\n\n    x_test = data.excerpt.tolist()\n    \n    tokenizer = AutoTokenizer.from_pretrained(MODEL_DIR)\n\n    encoded_test = tokenizer.batch_encode_plus(\n        x_test, \n        add_special_tokens=True, \n        return_attention_mask=True, \n        padding='max_length', \n        truncation=True,\n        max_length=MAX_LENGTH, \n        return_tensors='pt'\n    )\n\n    dataset_test = TensorDataset(\n        encoded_test['input_ids'],\n        encoded_test['attention_mask']\n    )\n\n    dataloader_test = DataLoader(\n        dataset_test,\n        sampler = SequentialSampler(dataset_test),\n        batch_size=TEST_BATCH_SIZE\n    )\n    \n    return dataloader_test\n\ntest_dataloader = get_test_loader(test)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:49:26.36768Z","iopub.execute_input":"2021-07-25T08:49:26.368376Z","iopub.status.idle":"2021-07-25T08:49:26.566186Z","shell.execute_reply.started":"2021-07-25T08:49:26.368341Z","shell.execute_reply":"2021-07-25T08:49:26.565249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_predictions = []\nfor seed in SEEDS:\n    \n    fold_predictions = []\n    \n    for fold in tqdm(range(NUM_FOLDS)):\n        model_path = f\"model_{seed + 1}_{fold + 1}.pth\"\n        \n        print(f\"\\nUsing {model_path}\")\n        \n        model_path = CHECKPOINT_DIR + f\"model_{seed + 1}_{fold + 1}.pth\"\n        model = MeanPoolingModel(MODEL_DIR)\n        model.load_state_dict(torch.load(model_path)) \n        model.to(DEVICE)\n        model.eval()\n\n        predictions = []\n        for batch in test_dataloader:\n\n            batch = tuple(b.to(DEVICE) for b in batch)\n\n            inputs = {'input_ids':      batch[0],\n                      'attention_mask': batch[1],\n                      'labels':         None,\n                     }\n\n     \n            predictions = model(**inputs).detach().cpu().numpy().tolist()\n            \n        del model \n        gc.collect()\n            \n        fold_predictions.append(predictions)\n    all_predictions.append(np.mean(fold_predictions, axis=0).tolist())\n    \nmodel_predictions = np.mean(all_predictions,axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:49:26.567536Z","iopub.execute_input":"2021-07-25T08:49:26.567917Z","iopub.status.idle":"2021-07-25T08:52:25.53651Z","shell.execute_reply.started":"2021-07-25T08:49:26.56788Z","shell.execute_reply":"2021-07-25T08:52:25.535645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv(os.path.join(INPUT_DIR, 'sample_submission.csv'))\nsubmit.target = model_predictions\nsubmit","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:52:25.539297Z","iopub.execute_input":"2021-07-25T08:52:25.539821Z","iopub.status.idle":"2021-07-25T08:52:25.569885Z","shell.execute_reply.started":"2021-07-25T08:52:25.53978Z","shell.execute_reply":"2021-07-25T08:52:25.569121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-25T08:52:25.571166Z","iopub.execute_input":"2021-07-25T08:52:25.571493Z","iopub.status.idle":"2021-07-25T08:52:25.582205Z","shell.execute_reply.started":"2021-07-25T08:52:25.571459Z","shell.execute_reply":"2021-07-25T08:52:25.581264Z"},"trusted":true},"execution_count":null,"outputs":[]}]}