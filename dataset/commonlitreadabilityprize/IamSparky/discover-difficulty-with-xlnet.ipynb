{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\n\nimport transformers\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nimport torch.nn as nn\nfrom sklearn import model_selection\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\n\nMAX_LEN = 128\nTRAIN_BATCH_SIZE = 8\nVALID_BATCH_SIZE = 4\nEPOCHS = 5\n\nTOKENIZER = transformers.XLNetTokenizer.from_pretrained('xlnet-base-cased', do_lower_case=True)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-31T13:57:05.232378Z","iopub.execute_input":"2021-05-31T13:57:05.232698Z","iopub.status.idle":"2021-05-31T13:57:07.505196Z","shell.execute_reply.started":"2021-05-31T13:57:05.23267Z","shell.execute_reply":"2021-05-31T13:57:07.504384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ../input/cpythonlibrary/cpython-master\nfrom Lib import copy\n%cd /kaggle/working","metadata":{"execution":{"iopub.status.busy":"2021-05-31T13:57:10.036977Z","iopub.execute_input":"2021-05-31T13:57:10.037313Z","iopub.status.idle":"2021-05-31T13:57:10.048319Z","shell.execute_reply.started":"2021-05-31T13:57:10.037282Z","shell.execute_reply":"2021-05-31T13:57:10.047391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport gc\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2021-05-31T13:57:10.380123Z","iopub.execute_input":"2021-05-31T13:57:10.380415Z","iopub.status.idle":"2021-05-31T13:57:10.384285Z","shell.execute_reply.started":"2021-05-31T13:57:10.380387Z","shell.execute_reply":"2021-05-31T13:57:10.383383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\", usecols = ['id','excerpt', 'target'])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T13:57:10.774541Z","iopub.execute_input":"2021-05-31T13:57:10.774835Z","iopub.status.idle":"2021-05-31T13:57:10.81338Z","shell.execute_reply.started":"2021-05-31T13:57:10.774807Z","shell.execute_reply":"2021-05-31T13:57:10.812448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"kfold\"] = -1    \ndf = df.sample(frac=1).reset_index(drop=True)\ny = df.target.values\nkf = model_selection.KFold(n_splits=5) # KFold for regression problems\n\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\ndf.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T13:57:11.14273Z","iopub.execute_input":"2021-05-31T13:57:11.142998Z","iopub.status.idle":"2021-05-31T13:57:11.16416Z","shell.execute_reply.started":"2021-05-31T13:57:11.142972Z","shell.execute_reply":"2021-05-31T13:57:11.163449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class XLNETDataset:\n    def __init__(self, excerpt, target):\n        self.excerpt = excerpt\n        self.target = target\n        self.tokenizer = TOKENIZER\n        self.max_len = MAX_LEN\n\n    def __len__(self):\n        return len(self.excerpt)\n\n    def __getitem__(self, item):\n        excerpt = str(self.excerpt[item])\n        excerpt = \" \".join(excerpt.split())\n\n        inputs = self.tokenizer.encode_plus(\n            excerpt,\n            None,\n            add_special_tokens=True,\n            max_length=self.max_len,\n            pad_to_max_length=True,\n        )\n\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        token_type_ids = inputs[\"token_type_ids\"]\n        \n        padding_length  =  self.max_len - len(ids)\n        ids = ids + ([0] * padding_length)\n        mask = mask + ([0] * padding_length)\n        token_type_ids = token_type_ids + ([0] * padding_length)\n\n        return {\n            \"ids\": torch.tensor(ids, dtype=torch.long),\n            \"mask\": torch.tensor(mask, dtype=torch.long),\n            \"token_type_ids\": torch.tensor(token_type_ids, dtype=torch.long),\n            \"targets\": torch.tensor(self.target[item], dtype=torch.float),\n        }","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-05-31T13:57:12.088019Z","iopub.execute_input":"2021-05-31T13:57:12.088375Z","iopub.status.idle":"2021-05-31T13:57:12.108632Z","shell.execute_reply.started":"2021-05-31T13:57:12.088343Z","shell.execute_reply":"2021-05-31T13:57:12.107671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 0\ndf_train = df[df.kfold != fold].reset_index(drop=True)\ndf_valid = df[df.kfold == fold].reset_index(drop=True)\n\ntrain_data = XLNETDataset(excerpt = df_train.excerpt.values, \n                         target = df_train.target.values)\n\nval_data = XLNETDataset(excerpt = df_valid.excerpt.values, \n                       target = df_valid.target.values)\n\nidx = 7\n\nprint(val_data[idx]['ids'])\nprint(val_data[idx]['mask'])\nprint(val_data[idx]['token_type_ids'])\nprint(val_data[idx]['targets'])","metadata":{"execution":{"iopub.status.busy":"2021-05-31T13:57:12.368873Z","iopub.execute_input":"2021-05-31T13:57:12.36919Z","iopub.status.idle":"2021-05-31T13:57:12.395594Z","shell.execute_reply.started":"2021-05-31T13:57:12.369162Z","shell.execute_reply":"2021-05-31T13:57:12.394663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_dataloader = DataLoader(train_data,\n                        num_workers= 4,\n                        batch_size= TRAIN_BATCH_SIZE,\n                        shuffle=True,\n                        drop_last=True\n                       )\n\nval_dataloader = DataLoader(val_data,\n                        num_workers= 4,\n                        batch_size= VALID_BATCH_SIZE,\n                        shuffle=False,\n                        drop_last=False\n                       )","metadata":{"execution":{"iopub.status.busy":"2021-05-31T13:57:12.866285Z","iopub.execute_input":"2021-05-31T13:57:12.866587Z","iopub.status.idle":"2021-05-31T13:57:12.875138Z","shell.execute_reply.started":"2021-05-31T13:57:12.86656Z","shell.execute_reply":"2021-05-31T13:57:12.873977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking if cuda is available\nfrom torch import device as device_\n\ndevice = device_(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T13:57:13.637413Z","iopub.execute_input":"2021-05-31T13:57:13.637728Z","iopub.status.idle":"2021-05-31T13:57:13.642869Z","shell.execute_reply.started":"2021-05-31T13:57:13.6377Z","shell.execute_reply":"2021-05-31T13:57:13.642048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class XLNETBERTBaseCased(nn.Module):\n    def __init__(self):\n        super(XLNETBERTBaseCased, self).__init__()\n        self.bert = transformers.XLNetModel.from_pretrained('xlnet-base-cased', return_dict=False)\n        self.bert_drop = nn.Dropout(0.5)\n        self.out = nn.Linear(768, 1)\n\n    def forward(self, ids, mask, token_type_ids):\n        x = self.bert(ids, attention_mask=mask, token_type_ids = token_type_ids)\n        \n        o1 = x[0]\n        \n        mean_pooling = torch.mean(o1, 1)\n        max_pooling, _ = torch.max(o1, 1) \n        avg_sum = torch.add(mean_pooling, max_pooling)/2\n        \n        output = self.out(avg_sum)\n        return output\n    \nmodel = XLNETBERTBaseCased()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:06:01.02089Z","iopub.execute_input":"2021-05-31T14:06:01.02127Z","iopub.status.idle":"2021-05-31T14:06:04.39776Z","shell.execute_reply.started":"2021-05-31T14:06:01.021239Z","shell.execute_reply":"2021-05-31T14:06:04.396918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_optimizer = list(model.named_parameters())\n\nno_decay = [\"bias\", \"LayerNorm.bias\", \"LayerNorm.weight\"]\n\noptimizer_parameters = [\n    {\n        \"params\": [\n            p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n        ],\n        \"weight_decay\": 0.01,\n    },\n    {\n        \"params\": [\n            p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n        ],\n        \"weight_decay\": 0.0,\n    },\n]\n\nnum_train_steps = int(len(df_train) / TRAIN_BATCH_SIZE * EPOCHS)\n\noptimizer = AdamW(optimizer_parameters, lr=2e-5)\n\nscheduler = get_linear_schedule_with_warmup(\n    optimizer, num_warmup_steps=0, num_training_steps=num_train_steps\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:06:09.315747Z","iopub.execute_input":"2021-05-31T14:06:09.316187Z","iopub.status.idle":"2021-05-31T14:06:09.334465Z","shell.execute_reply.started":"2021-05-31T14:06:09.31614Z","shell.execute_reply":"2021-05-31T14:06:09.333336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self,yhat,y):\n        return torch.sqrt(self.mse(yhat,y))\n\nloss_fn = RMSELoss()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:06:09.689357Z","iopub.execute_input":"2021-05-31T14:06:09.689646Z","iopub.status.idle":"2021-05-31T14:06:09.695344Z","shell.execute_reply.started":"2021-05-31T14:06:09.689613Z","shell.execute_reply":"2021-05-31T14:06:09.694307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# defining the training loop\ndef train_loop_fn(data_loader, model, optimizer, device, scheduler=None):\n    running_loss = 0.0\n    all_targets = 0\n    all_predictions = 0\n    \n    model.train()\n    \n    for batch_index,dataset in enumerate(data_loader):\n        ids = dataset['ids']\n        token_type_ids = dataset['token_type_ids']\n        mask = dataset['mask']\n        targets = dataset['targets']\n        \n        ids = ids.to(device, dtype=torch.long)\n        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n\n        outputs = model(ids = ids,\n                        mask = mask,\n                        token_type_ids = token_type_ids)\n        \n        loss = loss_fn(outputs, targets)\n\n        loss.backward()\n        optimizer.step()\n        scheduler.step()\n\n        running_loss += loss.item()\n        \n        del ids, token_type_ids, mask, targets\n        gc.collect()\n        torch.cuda.empty_cache()\n            \n    train_loss = running_loss / float(len(train_data))\n    \n    return train_loss\n\n\n\ndef eval_loop_fn(data_loader, model, device):\n    running_loss = 0.0\n    all_targets = 0\n    all_predictions = 0\n    \n    model.eval()\n    \n    for batch_index,dataset in enumerate(data_loader):\n        ids = dataset['ids']\n        token_type_ids = dataset['token_type_ids']\n        mask = dataset['mask']\n        targets = dataset['targets']\n        \n        ids = ids.to(device, dtype=torch.long)\n        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets = targets.to(device, dtype=torch.float)\n\n        outputs = model(ids = ids,\n                        mask = mask,\n                        token_type_ids = token_type_ids)\n        \n        loss = loss_fn(outputs, targets)\n        \n        running_loss += loss.item()\n        \n        del ids, token_type_ids, mask, targets\n        gc.collect()\n        torch.cuda.empty_cache()\n    \n    valid_loss = running_loss / float(len(val_data))\n    \n    return valid_loss","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:06:10.033784Z","iopub.execute_input":"2021-05-31T14:06:10.034078Z","iopub.status.idle":"2021-05-31T14:06:10.046416Z","shell.execute_reply.started":"2021-05-31T14:06:10.034047Z","shell.execute_reply":"2021-05-31T14:06:10.045363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _run():\n    no_of_folds = 5\n    for i in range(no_of_folds):\n        a_string = \"*\" * 20\n\n        print(a_string, \" FOLD NUMBER \", i, a_string)\n        \n        df_train = df[df.kfold != i].reset_index(drop=True)\n        df_valid = df[df.kfold == i].reset_index(drop=True)\n        \n        all_RMSE = []\n        \n        for epoch in range(EPOCHS):\n            print(f\"Epoch --> {epoch+1} / {EPOCHS}\")\n            print(f\"-------------------------------\")\n\n            train_loss = train_loop_fn(training_dataloader, model, optimizer, device, scheduler)\n            print('RMSE training Loss: {:.4f}'.format(train_loss))\n\n            valid_loss = eval_loop_fn(val_dataloader, model, device)\n            print('RMSE validation Loss: {:.4f}\\n'.format(valid_loss))\n            \n            all_RMSE.append(valid_loss)\n        print('\\n')\n        \n        if i < 1:\n            best_loss = min(all_RMSE)\n            best_model = copy.deepcopy(model)\n        else:\n            if best_loss < min(all_RMSE):\n                continue\n            else:\n                best_loss = min(all_RMSE)\n                best_model = copy.deepcopy(model)\n    \n    torch.save(best_model,'./bert_model2.bin')\n    print()\n    print(\"The least loss we got among all the folds is {:.4f}\".format(best_loss))\n        \nif __name__ == \"__main__\":\n    _run()","metadata":{"execution":{"iopub.status.busy":"2021-05-31T14:06:10.783248Z","iopub.execute_input":"2021-05-31T14:06:10.783565Z","iopub.status.idle":"2021-05-31T14:10:41.009726Z","shell.execute_reply.started":"2021-05-31T14:06:10.783536Z","shell.execute_reply":"2021-05-31T14:10:41.007479Z"},"trusted":true},"execution_count":null,"outputs":[]}]}