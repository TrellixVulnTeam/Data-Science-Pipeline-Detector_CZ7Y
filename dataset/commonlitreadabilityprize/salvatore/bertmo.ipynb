{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport random\nimport gc\nfrom pprint import pprint\nfrom tqdm import tqdm\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')\nfrom sklearn.model_selection import StratifiedKFold\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-05T09:08:47.190623Z","iopub.execute_input":"2021-06-05T09:08:47.191153Z","iopub.status.idle":"2021-06-05T09:08:47.271251Z","shell.execute_reply.started":"2021-06-05T09:08:47.191108Z","shell.execute_reply":"2021-06-05T09:08:47.270011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AutoModel\nfrom transformers import AutoTokenizer\nfrom transformers import AutoConfig","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:47.27909Z","iopub.execute_input":"2021-06-05T09:08:47.283138Z","iopub.status.idle":"2021-06-05T09:08:47.292845Z","shell.execute_reply.started":"2021-06-05T09:08:47.283087Z","shell.execute_reply":"2021-06-05T09:08:47.291923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = '../input/commonlitreadabilityprize/train.csv'\nTEST = '../input/commonlitreadabilityprize/test.csv'\n# BERT\nBERT = '../input/huggingface-bert-variants/bert-base-uncased/bert-base-uncased'\n# Distilbert\nDISTILBERT = '../input/huggingface-bert-variants/distilbert-base-uncased/distilbert-base-uncased'\n# Roberta\nROBERTA = '../input/huggingface-roberta-variants/roberta-base/roberta-base'\n\nARCH_PATH = DISTILBERT\n\ncfg={}\ncfg['train']={'n_folds':5}\n\nseed=28","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:47.297309Z","iopub.execute_input":"2021-06-05T09:08:47.301081Z","iopub.status.idle":"2021-06-05T09:08:47.316705Z","shell.execute_reply.started":"2021-06-05T09:08:47.300993Z","shell.execute_reply":"2021-06-05T09:08:47.315363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Device: ', device.type)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:47.319228Z","iopub.execute_input":"2021-06-05T09:08:47.32098Z","iopub.status.idle":"2021-06-05T09:08:47.337372Z","shell.execute_reply.started":"2021-06-05T09:08:47.320925Z","shell.execute_reply":"2021-06-05T09:08:47.336024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_data_stratified(df,n_bins=20,n_splits=5):\n    df['bin']=pd.cut(df.target,n_bins,labels=[i for i in range(n_bins)])\n    df['fold']=np.nan\n    skf=StratifiedKFold(n_splits=n_splits, random_state=seed, shuffle=True).split(df.id,y=df.bin)\n    for fold,(idx_train,idx_val) in enumerate(skf):\n        df.loc[idx_val,'fold']=fold\n    df['fold'] = df['fold'].astype('int8')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:47.339142Z","iopub.execute_input":"2021-06-05T09:08:47.339924Z","iopub.status.idle":"2021-06-05T09:08:47.348997Z","shell.execute_reply.started":"2021-06-05T09:08:47.339835Z","shell.execute_reply":"2021-06-05T09:08:47.347932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(TRAIN)\nget_data_stratified(df)\nfor fold in range(cfg['train']['n_folds']):\n    sns.histplot(data=df.loc[df.fold==fold],x='target',bins=10,hue='fold',label=f'fold{fold}')\nplt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:47.350586Z","iopub.execute_input":"2021-06-05T09:08:47.351246Z","iopub.status.idle":"2021-06-05T09:08:47.955146Z","shell.execute_reply.started":"2021-06-05T09:08:47.3512Z","shell.execute_reply":"2021-06-05T09:08:47.953919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.loc[106]['excerpt']","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:47.968999Z","iopub.execute_input":"2021-06-05T09:08:47.969508Z","iopub.status.idle":"2021-06-05T09:08:47.980642Z","shell.execute_reply.started":"2021-06-05T09:08:47.969458Z","shell.execute_reply":"2021-06-05T09:08:47.97912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sort_values('target',ascending=False).head(1)['excerpt'].values[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:47.984369Z","iopub.execute_input":"2021-06-05T09:08:47.985012Z","iopub.status.idle":"2021-06-05T09:08:47.997994Z","shell.execute_reply.started":"2021-06-05T09:08:47.984964Z","shell.execute_reply":"2021-06-05T09:08:47.996286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.sort_values('target').head(1)['excerpt'].values[0]","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.000013Z","iopub.execute_input":"2021-06-05T09:08:48.000724Z","iopub.status.idle":"2021-06-05T09:08:48.011969Z","shell.execute_reply.started":"2021-06-05T09:08:48.000677Z","shell.execute_reply":"2021-06-05T09:08:48.010268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 定义分词器Tokenizer，为蒸馏bert预训练模型","metadata":{}},{"cell_type":"code","source":"cfg['tokenizer'] ={'name': ARCH_PATH,'max_length': 210}\ntokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.014185Z","iopub.execute_input":"2021-06-05T09:08:48.014701Z","iopub.status.idle":"2021-06-05T09:08:48.06172Z","shell.execute_reply.started":"2021-06-05T09:08:48.01465Z","shell.execute_reply":"2021-06-05T09:08:48.060715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset+Dataloader","metadata":{}},{"cell_type":"code","source":"class cldataset(Dataset):\n    '''\n    call时，传入index，将该句分词，\n    返回第一部分{ids,mask,token_type_ids}，供bert使用\n    第二部分target，作为label\n    '''\n    def __init__(self,df,tokenizer,max_len):\n        self.df = df\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self):\n        return len(self.df)\n    def __getitem__(self,index):\n        text = self.df.loc[index, 'excerpt']\n        inputs = self.tokenizer.encode_plus(\n            text,                                 \n            add_special_tokens=True,\n            padding='max_length',\n            max_length=self.max_len,\n            truncation=True\n        )\n        ids=inputs['input_ids']\n        mask=inputs['attention_mask']\n        if cfg['tokenizer']['name']=='bert-base-uncased':\n            token_type_ids = inputs['token_type_ids'] \n        else:\n            token_type_ids = 1.\n        target=self.df.loc[index,['target']]\n        return {\n            'ids': torch.LongTensor(ids),#单词在词典中编码\n            'mask': torch.LongTensor(mask),#self-attention操作指定\n             'token_type_ids': torch.tensor(token_type_ids)#区分两个句子的编码\n            },{\n            'target': torch.Tensor(target)\n    }","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.076112Z","iopub.execute_input":"2021-06-05T09:08:48.076581Z","iopub.status.idle":"2021-06-05T09:08:48.089446Z","shell.execute_reply.started":"2021-06-05T09:08:48.076537Z","shell.execute_reply":"2021-06-05T09:08:48.087825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = cldataset(df=df,tokenizer=tokenizer,max_len=cfg['tokenizer']['max_length'])\nds = iter(ds)\ninputs, targets = next(ds)#例子","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.09141Z","iopub.execute_input":"2021-06-05T09:08:48.092155Z","iopub.status.idle":"2021-06-05T09:08:48.106421Z","shell.execute_reply.started":"2021-06-05T09:08:48.092108Z","shell.execute_reply":"2021-06-05T09:08:48.105208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg['dl_train'] = {\n    'batch_size': 8 if device.type=='cpu' else 16, \n    'shuffle': True, \n    'num_workers': os.cpu_count(), \n    'pin_memory': True\n}\ncfg['dl_val'] = {\n    'batch_size': 8 if device.type=='cpu' else 64, \n    'shuffle': False, \n    'num_workers': os.cpu_count(), \n    'pin_memory': True\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.108141Z","iopub.execute_input":"2021-06-05T09:08:48.108632Z","iopub.status.idle":"2021-06-05T09:08:48.118413Z","shell.execute_reply.started":"2021-06-05T09:08:48.108587Z","shell.execute_reply":"2021-06-05T09:08:48.117206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = cldataset(df=df,tokenizer=tokenizer, \n                max_len=cfg['tokenizer']['max_length'])\ndl = DataLoader(ds, **cfg['dl_train'])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.120291Z","iopub.execute_input":"2021-06-05T09:08:48.120914Z","iopub.status.idle":"2021-06-05T09:08:48.139422Z","shell.execute_reply.started":"2021-06-05T09:08:48.120842Z","shell.execute_reply":"2021-06-05T09:08:48.138206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class clbert(nn.Module):\n    def __init__(self,name,dropout=True):\n        super(clbert, self).__init__()\n        self.bert = AutoModel.from_pretrained(name)#导入预训练模型\n        self.name = name\n        \n        if name == BERT:\n            self.in_features = self.bert.pooler.dense.out_features\n        elif name == DISTILBERT:\n            self.in_features = self.bert.transformer.layer[5].output_layer_norm.normalized_shape[0]\n        elif name == ROBERTA:\n            self.in_features = self.bert.pooler.dense.out_features\n        else:\n            self.in_features = 768\n        \n        self.fc = nn.Linear(self.in_features, 1)\n        self.dense = nn.Linear(self.in_features, self.in_features)\n        self.activation = nn.Tanh()\n        self.dropout = nn.Dropout(p=0.2)\n        \n        torch.nn.init.kaiming_normal_(self.dense.weight)\n        torch.nn.init.kaiming_normal_(self.fc.weight)\n        \n    def forward(self, ids, mask, token_type_ids):\n        if self.name == BERT:\n            last_hidden_state, output = self.bert(ids,\n                                                  attention_mask=mask,\n                                                  token_type_ids=token_type_ids,\n                                                  return_dict=False)\n        elif self.name == DISTILBERT:\n            last_hidden_state = self.bert(ids, \n                                           attention_mask=mask, \n                                           return_dict=False)\n            first_token_tensor = last_hidden_state[0][:, 0]\n            output = self.dense(first_token_tensor)\n            output = self.activation(output)\n            \n        elif self.name == ROBERTA:\n            last_hidden_state, output = self.bert(ids,\n                                                  attention_mask=mask,\n#                                                   token_type_ids=token_type_ids,\n                                                  return_dict=False)\n        output = self.dropout(output)\n        output = self.fc(output)\n        return output","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.143387Z","iopub.execute_input":"2021-06-05T09:08:48.143761Z","iopub.status.idle":"2021-06-05T09:08:48.161132Z","shell.execute_reply.started":"2021-06-05T09:08:48.143718Z","shell.execute_reply":"2021-06-05T09:08:48.159935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install tensorwatch","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.164984Z","iopub.execute_input":"2021-06-05T09:08:48.165481Z","iopub.status.idle":"2021-06-05T09:08:48.176154Z","shell.execute_reply.started":"2021-06-05T09:08:48.165446Z","shell.execute_reply":"2021-06-05T09:08:48.174931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -i https://pypi.tuna.tsinghua.edu.cn/simple torch==1.2","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.177959Z","iopub.execute_input":"2021-06-05T09:08:48.178535Z","iopub.status.idle":"2021-06-05T09:08:48.187452Z","shell.execute_reply.started":"2021-06-05T09:08:48.178486Z","shell.execute_reply":"2021-06-05T09:08:48.18643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"!pip install graphviz  # 安装graphviz\n!pip install git+https://github.com/szagoruyko/pytorchviz  # 通过git安装torchviz","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:43:44.182523Z","iopub.execute_input":"2021-06-04T11:43:44.182876Z","iopub.status.idle":"2021-06-04T11:44:02.018185Z","shell.execute_reply.started":"2021-06-04T11:43:44.182822Z","shell.execute_reply":"2021-06-04T11:44:02.016669Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":"import torch\nfrom torchvision.models import AlexNet\nfrom torchviz import make_dot\n \nmodel = clbert(name=cfg['model']['name'])\ndata=next(iter(dl))\ninputs=data[0]\noutputs=model(**inputs)\n\n# 这三种方式都可以\ng = make_dot(outputs)\n g=make_dot(y, params=dict(model.named_parameters()))\n#g = make_dot(y, params=dict(list(model.named_parameters()) + [('x', x)]))\ng.render('bert', view=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-04T11:44:06.483619Z","iopub.execute_input":"2021-06-04T11:44:06.484004Z","iopub.status.idle":"2021-06-04T11:44:07.876965Z","shell.execute_reply.started":"2021-06-04T11:44:06.48397Z","shell.execute_reply":"2021-06-04T11:44:07.875818Z"}}},{"cell_type":"code","source":"cfg['model'] = {'name': ARCH_PATH}# roberta","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.190005Z","iopub.execute_input":"2021-06-05T09:08:48.191106Z","iopub.status.idle":"2021-06-05T09:08:48.199389Z","shell.execute_reply.started":"2021-06-05T09:08:48.191059Z","shell.execute_reply":"2021-06-05T09:08:48.198227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = clbert(name=cfg['model']['name'])\ndata=next(iter(dl))\ninputs=data[0]\noutputs=model(**inputs)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:08:48.201297Z","iopub.execute_input":"2021-06-05T09:08:48.201839Z","iopub.status.idle":"2021-06-05T09:09:05.067085Z","shell.execute_reply.started":"2021-06-05T09:08:48.201794Z","shell.execute_reply":"2021-06-05T09:09:05.063038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Criterion","metadata":{}},{"cell_type":"code","source":"def clmetric(y_pred, y_gt):\n    assert y_pred.size() == y_gt.size()\n    metric = nn.MSELoss()\n    metric = torch.sqrt(metric(y_pred, y_gt))\n    return metric","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.072452Z","iopub.execute_input":"2021-06-05T09:09:05.072904Z","iopub.status.idle":"2021-06-05T09:09:05.08047Z","shell.execute_reply.started":"2021-06-05T09:09:05.07285Z","shell.execute_reply":"2021-06-05T09:09:05.07908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optimizer","metadata":{"execution":{"iopub.status.busy":"2021-06-04T01:35:48.506704Z","iopub.execute_input":"2021-06-04T01:35:48.507126Z","iopub.status.idle":"2021-06-04T01:35:48.511325Z","shell.execute_reply.started":"2021-06-04T01:35:48.507094Z","shell.execute_reply":"2021-06-04T01:35:48.510277Z"}}},{"cell_type":"code","source":"from torch.optim import Adam\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom transformers import get_cosine_schedule_with_warmup\nfrom transformers import AdamW\n\ncfg['optim'] = {'lr': 3e-5}\ncfg['scheduler'] = {'num_warmup_steps':3, \n                    'num_training_steps':7, \n#                     'num_cycles': 1,\n                   }","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.087556Z","iopub.execute_input":"2021-06-05T09:09:05.08796Z","iopub.status.idle":"2021-06-05T09:09:05.094956Z","shell.execute_reply.started":"2021-06-05T09:09:05.087929Z","shell.execute_reply":"2021-06-05T09:09:05.093513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training/infer","metadata":{}},{"cell_type":"code","source":"from torch.cuda.amp import GradScaler\nfrom torch.cuda.amp import autocast\ncfg['train'] ={\n    'n_folds': 5,\n    'n_epochs': 100\n}","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.097481Z","iopub.execute_input":"2021-06-05T09:09:05.098044Z","iopub.status.idle":"2021-06-05T09:09:05.10563Z","shell.execute_reply.started":"2021-06-05T09:09:05.097978Z","shell.execute_reply":"2021-06-05T09:09:05.104194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class storeloss:    \n    def __init__(self, fold):\n        self.loss_train_mean = []\n        self.loss_train_std = []\n        self.loss_val_mean = []\n        self.loss_val_std = []\n        \n        self.fold = fold\n        \n    def get_loss(self, loss_train, loss_val):\n        self.loss_train_mean.append(loss_train[0])\n        self.loss_train_std.append(loss_train[1])\n        self.loss_val_mean.append(loss_val[0])\n        self.loss_val_std.append(loss_val[1])","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.107587Z","iopub.execute_input":"2021-06-05T09:09:05.10823Z","iopub.status.idle":"2021-06-05T09:09:05.117397Z","shell.execute_reply.started":"2021-06-05T09:09:05.10809Z","shell.execute_reply":"2021-06-05T09:09:05.116058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_fun(model,dl,cri,optim,scheduler):\n    scaler=GradScaler()\n    loss_train=[]\n    loss_total=0\n    model.train()\n    model.to(device)\n    progress_bar=tqdm(dl,desc='训练')\n    for i, data in enumerate(progress_bar):\n        optim.zero_grad()\n        inputs={key:value.to(device) for key,value in data[0].items()}\n        targets=data[1]['target'].to(device)\n        # Enables autocasting for the forward pass (model + loss)\n        with autocast():\n            output = model(**inputs)\n            loss = clmetric(output, targets)\n\n        # Exits the context manager before backward()\n        scaler.scale(loss).backward()\n        loss_train.append(loss.item())\n        loss_total+=loss.item()\n        scaler.step(optim)\n        scaler.update()\n    return np.mean(loss_train),np.std(loss_train)\n\ndef val_fun(model,dl):\n    scaler=GradScaler()\n    loss_val=[]\n    loss_total=0\n    model.eval()\n    model.to(device)\n    progress_bar=tqdm(dl,desc='测试')\n    with torch.no_grad():\n        for i, data in enumerate(progress_bar):\n\n            inputs={key:value.to(device) for key,value in data[0].items()}\n            targets=data[1]['target'].to(device)\n            # Enables autocasting for the forward pass (model + loss)\n            with autocast():\n                output = model(**inputs)\n                loss = clmetric(output, targets)\n            loss_val.append(loss.item())\n            loss_total += loss.item()\n\n    loss_val_2 = np.array(loss_val)**2 * cfg['dl_val']['batch_size'] / len(dl.dataset)\n    print('RMSE for validation set overall: ', np.sqrt(loss_val_2.sum()))\n    \n        \n    return np.sqrt(loss_val_2.sum()), np.std(loss_val)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.119396Z","iopub.execute_input":"2021-06-05T09:09:05.120418Z","iopub.status.idle":"2021-06-05T09:09:05.137793Z","shell.execute_reply.started":"2021-06-05T09:09:05.120372Z","shell.execute_reply":"2021-06-05T09:09:05.13663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run_one_epoch(model, train_dl, val_dl, criterion, optim, scheduler):\n    inputs_train = {\n        'model': model, \n        'dl': train_dl, \n        'cri': criterion, \n        'optim': optim, \n        'scheduler': scheduler\n    }\n\n    inputs_val = {'model': model, \n                  'dl': val_dl}\n\n    loss_train = train_fun(**inputs_train)\n    loss_val = val_fun(**inputs_val)\n    \n    return loss_train, loss_val","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.139693Z","iopub.execute_input":"2021-06-05T09:09:05.140312Z","iopub.status.idle":"2021-06-05T09:09:05.151339Z","shell.execute_reply.started":"2021-06-05T09:09:05.140265Z","shell.execute_reply":"2021-06-05T09:09:05.15017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dls_for_n_fold(df, fold, tokenizer):\n    train_df = df.loc[df.fold!=fold].reset_index(drop=True)\n    val_df = df.loc[df.fold==fold].reset_index(drop=True)\n    \n    train_ds = cldataset(\n        train_df, \n        tokenizer=tokenizer, \n        max_len=cfg['tokenizer']['max_length']\n    )\n    \n    val_ds = cldataset(\n        val_df, \n        tokenizer=tokenizer, \n        max_len=cfg['tokenizer']['max_length']\n    )\n    \n    train_dl = DataLoader(train_ds, **cfg['dl_train'])\n    val_dl = DataLoader(val_ds, **cfg['dl_val'])\n    \n    return train_dl, val_dl","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.153022Z","iopub.execute_input":"2021-06-05T09:09:05.153714Z","iopub.status.idle":"2021-06-05T09:09:05.165095Z","shell.execute_reply.started":"2021-06-05T09:09:05.153668Z","shell.execute_reply":"2021-06-05T09:09:05.163814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class earlystopping:\n    def __init__(self, patience=2, seq=False):\n        self.patience = patience\n        self.counter = 0\n        self.best_score = None\n        self.stop = False\n    def __call__(self, loss, model, optim, cfg, path):\n        if self.best_score is None:\n            self.best_score = loss\n            self.save_checkpoint(model, optim, cfg, path)\n        elif loss < self.best_score:\n            print(f'Loss decreased {self.best_score} -> {loss}.')\n            self.best_score = loss\n            self.counter = 0\n            self.save_checkpoint(model, optim, cfg, path)\n        else:\n            self.counter += 1\n            if self.counter > self.patience: self.stop = True\n            #两轮不更新，则停止\n    def save_checkpoint(self, model, optim, cfg, path):\n        save_list = {'model': model.state_dict(), \n#                      'optim': optim.state_dict(), \n                     'cfg': cfg}\n        SAVE_PATH = path\n        torch.save(save_list, SAVE_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.166775Z","iopub.execute_input":"2021-06-05T09:09:05.16726Z","iopub.status.idle":"2021-06-05T09:09:05.179698Z","shell.execute_reply.started":"2021-06-05T09:09:05.167216Z","shell.execute_reply":"2021-06-05T09:09:05.178494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=True","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.181457Z","iopub.execute_input":"2021-06-05T09:09:05.182215Z","iopub.status.idle":"2021-06-05T09:09:05.190148Z","shell.execute_reply.started":"2021-06-05T09:09:05.182153Z","shell.execute_reply":"2021-06-05T09:09:05.188977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if train:\n    def main():\n        df = pd.read_csv(TRAIN)\n        get_data_stratified(df, n_splits=cfg['train']['n_folds'])\n        tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])\n        for fold in range(cfg['train']['n_folds']):\n            store=storeloss(fold=fold)\n            es=earlystopping()\n            train_dl, val_dl = get_dls_for_n_fold(df, fold, tokenizer)\n\n            model=clbert(name=cfg['model']['name'])\n            criterion=clmetric\n            optim=AdamW(model.parameters(),**cfg['optim'])\n            scheduler=get_cosine_schedule_with_warmup(optim, **cfg['scheduler'])\n            if optim.param_groups[0]['lr']==0:\n                optim.step()\n                scheduler.step()\n            inputs = {'model': model,\n                      'train_dl': train_dl,\n                      'val_dl': val_dl,\n                      'criterion': criterion,\n                      'optim': optim,\n                      'scheduler': scheduler}\n            for epoch in range(cfg['train']['n_epochs']):\n                loss_train, loss_val = run_one_epoch(**inputs)\n                store.get_loss(loss_train, loss_val)\n                es(loss_val[0], model, optim, cfg, path=f'clbert_fold{fold}.tar')\n                if es.stop:\n                    print('Early Stop !')\n                    print()\n                    break\n\n                scheduler.step()\n\n            del model, optim\n            gc.collect()\n    main()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.191964Z","iopub.execute_input":"2021-06-05T09:09:05.192797Z","iopub.status.idle":"2021-06-05T09:09:05.207205Z","shell.execute_reply.started":"2021-06-05T09:09:05.192751Z","shell.execute_reply":"2021-06-05T09:09:05.206178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def val_fn_cv(model, dl):\n    '''\n    用model预测传入的dl数据\n    '''\n    scaler = GradScaler()\n    preds = []\n    \n    model.eval()\n    model.to(device)    \n    progress_bar = tqdm(dl, desc='cv')\n    \n    with torch.no_grad():\n        for i, data in enumerate(progress_bar):\n            inputs = {key: value.to(device) for key, value in data[0].items()}\n            targets = data[1]['target'].to(device)            \n            with autocast():\n                outputs = model(**inputs)\n            preds.append(outputs.detach().cpu().numpy())\n    \n    preds = np.concatenate(preds)    \n    return preds\n\nMODEL_NAME = 'clbert'\nif train==False:\n    MODEL_NAME='../input/clberttrainingoutputs/clbert'\ndef main_cv():\n    '''\n    交叉验证训练集\n    '''\n#     seed_everything(SEED)    \n    df = pd.read_csv(TRAIN)\n    get_data_stratified(df, n_splits=cfg['train']['n_folds'])\n    df['oof'] = np.nan\n\n    tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])\n    \n    for fold in range(cfg['train']['n_folds']):\n        train_dl, val_dl = get_dls_for_n_fold(df, fold, tokenizer)\n\n        model = clbert(name=cfg['model']['name'])\n        PATH = os.path.join(MODEL_NAME + f'_fold{fold}.tar')\n        saved_contents = torch.load(PATH, map_location=device)        \n        model.load_state_dict(saved_contents['model'])\n        \n        if fold==0:\n            cfg_for_train = saved_contents['cfg']\n            print('Configuration for training:')\n            print()\n            pprint(cfg_for_train)\n            print()\n        \n        print('Fold:', fold)\n        \n        inputs = {'model': model,\n                  'dl': val_dl}\n        preds = val_fn_cv(**inputs)\n        df.loc[df.fold==fold, 'oof'] = preds\n\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.210574Z","iopub.execute_input":"2021-06-05T09:09:05.212087Z","iopub.status.idle":"2021-06-05T09:09:05.228743Z","shell.execute_reply.started":"2021-06-05T09:09:05.212003Z","shell.execute_reply":"2021-06-05T09:09:05.227387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\ndf = main_cv()\ndf.to_csv('oof_df.csv', index=False)\n\nmse = mean_squared_error(df['target'], df['oof'])\nrmse = np.sqrt(mse)\nprint('CV score: ', rmse)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:05.231025Z","iopub.execute_input":"2021-06-05T09:09:05.231804Z","iopub.status.idle":"2021-06-05T09:09:39.158531Z","shell.execute_reply.started":"2021-06-05T09:09:05.231755Z","shell.execute_reply":"2021-06-05T09:09:39.157375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main_infer(): \n    '''\n    预测test数据\n    '''\n    df = pd.read_csv(TEST)\n    df['target'] = 0.\n    \n    tokenizer = AutoTokenizer.from_pretrained(cfg['tokenizer']['name'])\n    \n    for fold in range(cfg['train']['n_folds']):\n        print('Fold:', fold)\n        test_ds =cldataset(df, tokenizer=tokenizer,max_len=cfg['tokenizer']['max_length'])\n    \n        test_dl = DataLoader(test_ds, **cfg['dl_val'])\n        #加载训练好的模型\n        model = clbert(name=cfg['model']['name'])\n        PATH = os.path.join( MODEL_NAME +f'_fold{fold}.tar')\n        state_dict = torch.load(PATH, map_location=device)['model']\n        model.load_state_dict(state_dict)\n        #定义测试集的输入\n        inputs = {'model': model,\n                  'dl': test_dl}\n        #引用了另一个函数\n        preds = val_fn_cv(**inputs)\n        df['target'] = df['target'] + np.concatenate(preds)\n    \n    df['target'] = df['target'] / cfg['train']['n_folds']\n    return df\nMODEL_NAME = 'clbert'\nif train==False:\n    MODEL_NAME='../input/clberttrainingoutputs/clbert'\ndf = main_infer()\ndf[['id', 'target']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:39.160593Z","iopub.execute_input":"2021-06-05T09:09:39.161072Z","iopub.status.idle":"2021-06-05T09:09:51.333291Z","shell.execute_reply.started":"2021-06-05T09:09:39.161023Z","shell.execute_reply":"2021-06-05T09:09:51.332097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv('submission.csv')\npd.read_csv('oof_df.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:09:51.337134Z","iopub.execute_input":"2021-06-05T09:09:51.337451Z","iopub.status.idle":"2021-06-05T09:09:51.398332Z","shell.execute_reply.started":"2021-06-05T09:09:51.337416Z","shell.execute_reply":"2021-06-05T09:09:51.396954Z"},"trusted":true},"execution_count":null,"outputs":[]}]}