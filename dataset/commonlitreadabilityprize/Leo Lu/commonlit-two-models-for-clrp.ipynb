{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Model 1","metadata":{}},{"cell_type":"code","source":"import os\nimport math\nimport random\nimport time\n\nimport numpy as np\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\n\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import AutoConfig\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.svm import SVR\n\nimport gc\ngc.enable()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-26T05:53:28.971827Z","iopub.execute_input":"2021-07-26T05:53:28.972182Z","iopub.status.idle":"2021-07-26T05:53:31.570847Z","shell.execute_reply.started":"2021-07-26T05:53:28.972104Z","shell.execute_reply":"2021-07-26T05:53:31.569894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nMAX_LEN = 248\nEVAL_SCHEDULE = [(0.50, 16), (0.49, 8), (0.48, 4), (0.47, 2), (-1., 1)]\nROBERTA_PATH = \"../input/huggingface-roberta/roberta-base\"\nTOKENIZER_PATH = \"../input/huggingface-roberta/roberta-base\"\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.572297Z","iopub.execute_input":"2021-07-26T05:53:31.572734Z","iopub.status.idle":"2021-07-26T05:53:31.637109Z","shell.execute_reply.started":"2021-07-26T05:53:31.572671Z","shell.execute_reply":"2021-07-26T05:53:31.635983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\nsubmission_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.63991Z","iopub.execute_input":"2021-07-26T05:53:31.640825Z","iopub.status.idle":"2021-07-26T05:53:31.668708Z","shell.execute_reply.started":"2021-07-26T05:53:31.64078Z","shell.execute_reply":"2021-07-26T05:53:31.667429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(TOKENIZER_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.670822Z","iopub.execute_input":"2021-07-26T05:53:31.671369Z","iopub.status.idle":"2021-07-26T05:53:31.805193Z","shell.execute_reply.started":"2021-07-26T05:53:31.671327Z","shell.execute_reply":"2021-07-26T05:53:31.804371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class LitDataset(Dataset):\n    def __init__(self, df, inference_only=False):\n        super().__init__()\n\n        self.df = df        \n        self.inference_only = inference_only\n        self.text = df.excerpt.tolist()\n        #self.text = [text.replace(\"\\n\", \" \") for text in self.text]\n        \n        if not self.inference_only:\n            self.target = torch.tensor(df.target.values, dtype=torch.float32)        \n    \n        self.encoded = tokenizer.batch_encode_plus(\n            self.text,\n            padding = 'max_length',            \n            max_length = MAX_LEN,\n            truncation = True,\n            return_attention_mask=True\n        )        \n \n\n    def __len__(self):\n        return len(self.df)\n\n    \n    def __getitem__(self, index):        \n        input_ids = torch.tensor(self.encoded['input_ids'][index])\n        attention_mask = torch.tensor(self.encoded['attention_mask'][index])\n        \n        if self.inference_only:\n            return (input_ids, attention_mask)            \n        else:\n            target = self.target[index]\n            return (input_ids, attention_mask, target)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.806662Z","iopub.execute_input":"2021-07-26T05:53:31.807054Z","iopub.status.idle":"2021-07-26T05:53:31.816849Z","shell.execute_reply.started":"2021-07-26T05:53:31.807018Z","shell.execute_reply":"2021-07-26T05:53:31.815718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model\nThe model is inspired by the one from [Maunish](https://www.kaggle.com/maunish/clrp-roberta-svm).","metadata":{}},{"cell_type":"code","source":"class LitModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        config = AutoConfig.from_pretrained(ROBERTA_PATH)\n        config.update({\"output_hidden_states\":True, \n                       \"hidden_dropout_prob\": 0.0,\n                       \"layer_norm_eps\": 1e-7})                       \n        \n        self.roberta = AutoModel.from_pretrained(ROBERTA_PATH, config=config)  \n            \n        self.attention = nn.Sequential(            \n            nn.Linear(768, 512),            \n            nn.Tanh(),                       \n            nn.Linear(512, 1),\n            nn.Softmax(dim=1)\n        )        \n\n        self.regressor = nn.Sequential(                        \n            nn.Linear(768, 1)                        \n        )\n        \n\n    def forward(self, input_ids, attention_mask):\n        roberta_output = self.roberta(input_ids=input_ids,\n                                      attention_mask=attention_mask)        \n\n        # There are a total of 13 layers of hidden states.\n        # 1 for the embedding layer, and 12 for the 12 Roberta layers.\n        # We take the hidden states from the last Roberta layer.\n        last_layer_hidden_states = roberta_output.hidden_states[-1]\n\n        # The number of cells is MAX_LEN.\n        # The size of the hidden state of each cell is 768 (for roberta-base).\n        # In order to condense hidden states of all cells to a context vector,\n        # we compute a weighted average of the hidden states of all cells.\n        # We compute the weight of each cell, using the attention neural network.\n        weights = self.attention(last_layer_hidden_states)\n                \n        # weights.shape is BATCH_SIZE x MAX_LEN x 1\n        # last_layer_hidden_states.shape is BATCH_SIZE x MAX_LEN x 768        \n        # Now we compute context_vector as the weighted average.\n        # context_vector.shape is BATCH_SIZE x 768\n        context_vector = torch.sum(weights * last_layer_hidden_states, dim=1)        \n        \n        # Now we reduce the context vector to the prediction score.\n        return self.regressor(context_vector)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.818625Z","iopub.execute_input":"2021-07-26T05:53:31.819047Z","iopub.status.idle":"2021-07-26T05:53:31.83102Z","shell.execute_reply.started":"2021-07-26T05:53:31.819004Z","shell.execute_reply":"2021-07-26T05:53:31.829845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, data_loader):\n    \"\"\"Returns an np.array with predictions of the |model| on |data_loader|\"\"\"\n    model.eval()\n\n    result = np.zeros(len(data_loader.dataset))    \n    index = 0\n    \n    with torch.no_grad():\n        for batch_num, (input_ids, attention_mask) in enumerate(data_loader):\n            input_ids = input_ids.to(DEVICE)\n            attention_mask = attention_mask.to(DEVICE)\n                        \n            pred = model(input_ids, attention_mask)                        \n\n            result[index : index + pred.shape[0]] = pred.flatten().to(\"cpu\")\n            index += pred.shape[0]\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.832555Z","iopub.execute_input":"2021-07-26T05:53:31.833081Z","iopub.status.idle":"2021-07-26T05:53:31.842669Z","shell.execute_reply.started":"2021-07-26T05:53:31.833038Z","shell.execute_reply":"2021-07-26T05:53:31.841528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"test_dataset = LitDataset(test_df, inference_only=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.846171Z","iopub.execute_input":"2021-07-26T05:53:31.84663Z","iopub.status.idle":"2021-07-26T05:53:31.867637Z","shell.execute_reply.started":"2021-07-26T05:53:31.846592Z","shell.execute_reply":"2021-07-26T05:53:31.866723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_MODELS = 5\n\nall_predictions = np.zeros((NUM_MODELS, len(test_df)))\n\n\n\ntest_dataset = LitDataset(test_df, inference_only=True)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE,\n                         drop_last=False, shuffle=False, num_workers=2)\n\nfor model_index in range(NUM_MODELS):            \n    model_path = f\"../input/commonlit-roberta-0467/model_{model_index + 1}.pth\"\n    print(f\"\\nUsing {model_path}\")\n                        \n    model = LitModel()\n    model.load_state_dict(torch.load(model_path, map_location=DEVICE))    \n    model.to(DEVICE)\n        \n    all_predictions[model_index] = predict(model, test_loader)\n            \n    del model\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:53:31.86938Z","iopub.execute_input":"2021-07-26T05:53:31.869971Z","iopub.status.idle":"2021-07-26T05:54:22.738824Z","shell.execute_reply.started":"2021-07-26T05:53:31.869934Z","shell.execute_reply":"2021-07-26T05:54:22.737912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model1_predictions = all_predictions.mean(axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:54:22.740339Z","iopub.execute_input":"2021-07-26T05:54:22.740765Z","iopub.status.idle":"2021-07-26T05:54:22.746576Z","shell.execute_reply.started":"2021-07-26T05:54:22.740721Z","shell.execute_reply":"2021-07-26T05:54:22.745352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model 2\nImported from [https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3](https://www.kaggle.com/rhtsingh/commonlit-readability-prize-roberta-torch-infer-3)","metadata":{}},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nin_folder_path = Path('../input/clrp-finetune-roberta-large')\nscripts_dir = Path(in_folder_path / 'scripts')\nos.chdir(scripts_dir)\nexec(Path(\"imports.py\").read_text())\nexec(Path(\"config.py\").read_text())\nexec(Path(\"dataset.py\").read_text())\nexec(Path(\"model.py\").read_text())\nos.chdir('/kaggle/working')\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\ntokenizer = torch.load('../input/mytokenizers/roberta-tokenizer.pt')\nmodels_folder_path = Path(in_folder_path / 'models')\nmodels_preds = []\nn_models = 10\n\nfor model_num in range(n_models):\n    print(f'Inference#{model_num+1}/{n_models}')\n    test_ds = CLRPDataset(data=test_df, tokenizer=tokenizer, max_len=Config.max_len, is_test=True)\n    test_sampler = SequentialSampler(test_ds)\n    test_dataloader = DataLoader(test_ds, sampler = test_sampler, batch_size=Config.batch_size)\n    model = torch.load(models_folder_path / f'best_model_{model_num}.pt').to(Config.device)\n\n    all_preds = []\n    \n    model.eval()\n\n    for step,batch in enumerate(test_dataloader):\n        sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n        with torch.no_grad():\n            preds = model(sent_id, mask)\n            all_preds += preds.flatten().cpu().tolist()\n            \n    models_preds.append(all_preds)\ndel model, tokenizer, test_dataloader, test_sampler\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:54:22.748315Z","iopub.execute_input":"2021-07-26T05:54:22.748813Z","iopub.status.idle":"2021-07-26T05:56:28.519511Z","shell.execute_reply.started":"2021-07-26T05:54:22.748768Z","shell.execute_reply":"2021-07-26T05:56:28.518482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nin_folder_path2 = Path('../input/mymodelrobertabase')\nscripts_dir2 = Path(in_folder_path2 / 'scripts')\n\nos.chdir(scripts_dir2)\nexec(Path(\"imports.py\").read_text())\nexec(Path(\"config.py\").read_text())\nexec(Path(\"dataset.py\").read_text())\nexec(Path(\"model.py\").read_text())\nos.chdir('/kaggle/working')\n\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\ntokenizer = torch.load('../input/mytokenizers/roberta-tokenizer.pt')\nmodels_folder_path2 = Path(in_folder_path2 / 'models')\nmodels_preds2 = []\nn_models = 5\n\nfor model_num in range(n_models):\n    print(f'Inference#{model_num+1}/{n_models}')\n    test_ds = CLRPDataset(data=test_df, tokenizer=tokenizer, max_len=Config.max_len, is_test=True)\n    test_sampler = SequentialSampler(test_ds)\n    test_dataloader = DataLoader(test_ds, sampler = test_sampler, batch_size=Config.batch_size)\n    model2 = torch.load(models_folder_path2 / f'best_model_{model_num}.pt').to(Config.device)\n\n    all_preds2 = []\n    \n    model2.eval()\n\n    for step,batch in enumerate(test_dataloader):\n        sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n        with torch.no_grad():\n            preds2 = model2(sent_id, mask)\n            all_preds2 += preds2.flatten().cpu().tolist()\n            \n    models_preds2.append(all_preds2)\ndel model2, tokenizer, test_dataloader, test_sampler\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:56:28.522476Z","iopub.execute_input":"2021-07-26T05:56:28.523239Z","iopub.status.idle":"2021-07-26T05:56:49.205953Z","shell.execute_reply.started":"2021-07-26T05:56:28.523184Z","shell.execute_reply":"2021-07-26T05:56:49.204991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom pathlib import Path\nin_folder_path3 = Path('../input/clrprobertalarge463-lb')\nscripts_dir3 = Path(in_folder_path3 / 'scripts')\n\nos.chdir(scripts_dir3)\nexec(Path(\"imports.py\").read_text())\nexec(Path(\"config.py\").read_text())\nexec(Path(\"dataset.py\").read_text())\nexec(Path(\"model.py\").read_text())\nos.chdir('/kaggle/working')\n\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\ntokenizer = torch.load('../input/mytokenizers/roberta-tokenizer.pt')\nmodels_folder_path3 = Path(in_folder_path3 / 'models')\nmodels_preds3 = []\nn_models = 5\n\nfor model_num in range(n_models):\n    print(f'Inference#{model_num+1}/{n_models}')\n    test_ds = CLRPDataset(data=test_df, tokenizer=tokenizer, max_len=Config.max_len, is_test=True)\n    test_sampler = SequentialSampler(test_ds)\n    test_dataloader = DataLoader(test_ds, sampler = test_sampler, batch_size=Config.batch_size)\n    model3 = torch.load(models_folder_path3 / f'best_model_{model_num}.pt').to(Config.device)\n\n    all_preds3 = []\n    \n    model3.eval()\n\n    for step,batch in enumerate(test_dataloader):\n        sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n        with torch.no_grad():\n            preds3 = model3(sent_id, mask)\n            all_preds3 += preds3.flatten().cpu().tolist()\n            \n    models_preds3.append(all_preds3)","metadata":{"execution":{"iopub.status.busy":"2021-07-26T05:56:49.207312Z","iopub.execute_input":"2021-07-26T05:56:49.207686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_preds_ens = np.array(models_preds).mean(axis=0)*0.5+np.array(models_preds2).mean(axis=0)*0.3+np.array(models_preds3).mean(axis=0)*0.2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = model1_predictions * 0.222 + models_preds_ens* 0.778","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.target = predictions\nprint(submission_df)\nsubmission_df.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}