{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%config Completer.use_jedi = False","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:09.741471Z","iopub.execute_input":"2021-05-22T08:15:09.741874Z","iopub.status.idle":"2021-05-22T08:15:09.759329Z","shell.execute_reply.started":"2021-05-22T08:15:09.741793Z","shell.execute_reply":"2021-05-22T08:15:09.758587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-22T08:15:09.760913Z","iopub.execute_input":"2021-05-22T08:15:09.761263Z","iopub.status.idle":"2021-05-22T08:15:10.553984Z","shell.execute_reply.started":"2021-05-22T08:15:09.761226Z","shell.execute_reply":"2021-05-22T08:15:10.553094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport transformers\nimport random\n\nimport warnings\nwarnings.simplefilter('ignore')\n\nscaler = torch.cuda.amp.GradScaler()\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:10.555651Z","iopub.execute_input":"2021-05-22T08:15:10.556048Z","iopub.status.idle":"2021-05-22T08:15:12.100198Z","shell.execute_reply.started":"2021-05-22T08:15:10.556009Z","shell.execute_reply":"2021-05-22T08:15:12.099419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEED = 20210520\n\ndef random_seed():\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    np.random.seed(SEED)\n    torch.manual_seed(SEED)\n    torch.cuda.manual_seed(SEED)\n    torch.cuda.manual_seed_all(SEED)\n    torch.backends.cudnn.deterministic = True","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:12.101682Z","iopub.execute_input":"2021-05-22T08:15:12.102025Z","iopub.status.idle":"2021-05-22T08:15:12.10695Z","shell.execute_reply.started":"2021-05-22T08:15:12.10199Z","shell.execute_reply":"2021-05-22T08:15:12.106012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntest = pd.read_csv('../input/commonlitreadabilityprize/test.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:12.108351Z","iopub.execute_input":"2021-05-22T08:15:12.109098Z","iopub.status.idle":"2021-05-22T08:15:12.185923Z","shell.execute_reply.started":"2021-05-22T08:15:12.109059Z","shell.execute_reply":"2021-05-22T08:15:12.185146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(7)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:12.18772Z","iopub.execute_input":"2021-05-22T08:15:12.187974Z","iopub.status.idle":"2021-05-22T08:15:12.211927Z","shell.execute_reply.started":"2021-05-22T08:15:12.18795Z","shell.execute_reply":"2021-05-22T08:15:12.210972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:12.215124Z","iopub.execute_input":"2021-05-22T08:15:12.215365Z","iopub.status.idle":"2021-05-22T08:15:12.229348Z","shell.execute_reply.started":"2021-05-22T08:15:12.215341Z","shell.execute_reply":"2021-05-22T08:15:12.228575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = transformers.BertTokenizer.from_pretrained('../input/huggingface-bert/bert-base-uncased/')","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:12.231049Z","iopub.execute_input":"2021-05-22T08:15:12.231287Z","iopub.status.idle":"2021-05-22T08:15:12.437584Z","shell.execute_reply.started":"2021-05-22T08:15:12.231264Z","shell.execute_reply":"2021-05-22T08:15:12.436811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['excerpt'].iloc[0]","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:12.438818Z","iopub.execute_input":"2021-05-22T08:15:12.439144Z","iopub.status.idle":"2021-05-22T08:15:12.447839Z","shell.execute_reply.started":"2021-05-22T08:15:12.439109Z","shell.execute_reply":"2021-05-22T08:15:12.446844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sentence_length = []\n\nfor sentence in tqdm(train['excerpt']):\n    token_words = tokenizer.encode_plus(sentence)['input_ids']\n    sentence_length.append(len(token_words))\n    \nprint('maxlength:', max(sentence_length))","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:12.449405Z","iopub.execute_input":"2021-05-22T08:15:12.44984Z","iopub.status.idle":"2021-05-22T08:15:26.928747Z","shell.execute_reply.started":"2021-05-22T08:15:12.449804Z","shell.execute_reply":"2021-05-22T08:15:26.925612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_tokenize = tokenizer.encode_plus(train['excerpt'][0])\nsample_tokenize","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:26.930441Z","iopub.execute_input":"2021-05-22T08:15:26.93099Z","iopub.status.idle":"2021-05-22T08:15:26.946136Z","shell.execute_reply.started":"2021-05-22T08:15:26.93092Z","shell.execute_reply":"2021-05-22T08:15:26.945127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(sample_tokenize['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:26.947365Z","iopub.execute_input":"2021-05-22T08:15:26.947875Z","iopub.status.idle":"2021-05-22T08:15:31.56609Z","shell.execute_reply.started":"2021-05-22T08:15:26.947839Z","shell.execute_reply":"2021-05-22T08:15:31.565241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pad_sentence = tokenizer.encode_plus(\n    train['excerpt'][0],\n    add_special_tokens = True,\n    max_length = 314,\n    pad_to_max_length = True,\n    truncation = True\n)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.567325Z","iopub.execute_input":"2021-05-22T08:15:31.567699Z","iopub.status.idle":"2021-05-22T08:15:31.580496Z","shell.execute_reply.started":"2021-05-22T08:15:31.567659Z","shell.execute_reply":"2021-05-22T08:15:31.579492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.decode(pad_sentence['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.583673Z","iopub.execute_input":"2021-05-22T08:15:31.584004Z","iopub.status.idle":"2021-05-22T08:15:31.59441Z","shell.execute_reply.started":"2021-05-22T08:15:31.583974Z","shell.execute_reply":"2021-05-22T08:15:31.593379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# preprocess","metadata":{}},{"cell_type":"code","source":"train_data = train.sort_values('target').reset_index(drop=True)\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.596977Z","iopub.execute_input":"2021-05-22T08:15:31.597308Z","iopub.status.idle":"2021-05-22T08:15:31.622173Z","shell.execute_reply.started":"2021-05-22T08:15:31.597255Z","shell.execute_reply":"2021-05-22T08:15:31.621393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['kfold'] = train_data.index % 5\ntrain_data","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.62337Z","iopub.execute_input":"2021-05-22T08:15:31.623693Z","iopub.status.idle":"2021-05-22T08:15:31.652306Z","shell.execute_reply.started":"2021-05-22T08:15:31.623658Z","shell.execute_reply":"2021-05-22T08:15:31.651605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_train_data = train_data[train_data['kfold']!=0].reset_index(drop=True)\np_val_data = train_data[train_data['kfold']==0].reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.653828Z","iopub.execute_input":"2021-05-22T08:15:31.654062Z","iopub.status.idle":"2021-05-22T08:15:31.663295Z","shell.execute_reply.started":"2021-05-22T08:15:31.654033Z","shell.execute_reply":"2021-05-22T08:15:31.662471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTDataset(Dataset):\n    def __init__(self, sentences, targets):\n        self.sentences = sentences\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.sentences)\n\n    def __getitem__(self, idx):\n        sentence = self.sentences[idx]\n        \n        encode_sentence = tokenizer.encode_plus(\n                                sentence,\n                                add_special_tokens = True,\n                                max_length = 314,\n                                pad_to_max_length = True,\n                                truncation = True,\n                                return_attention_mask = True\n                        )\n        \n        ids = torch.tensor(encode_sentence['input_ids'], dtype=torch.long)\n        mask = torch.tensor(encode_sentence['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(encode_sentence['token_type_ids'], dtype=torch.long)\n        \n        target = torch.tensor(self.targets[idx], dtype=torch.float)\n        \n        return {\n            'ids': ids,\n            'mask': mask,\n            'token_type_ids': token_type_ids,\n            'targets': target\n        }","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.666238Z","iopub.execute_input":"2021-05-22T08:15:31.666473Z","iopub.status.idle":"2021-05-22T08:15:31.675991Z","shell.execute_reply.started":"2021-05-22T08:15:31.66645Z","shell.execute_reply":"2021-05-22T08:15:31.675161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = BERTDataset(p_train_data['excerpt'], p_train_data['target'])\nval_dataset = BERTDataset(p_val_data['excerpt'], p_val_data['target'])","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.67975Z","iopub.execute_input":"2021-05-22T08:15:31.68005Z","iopub.status.idle":"2021-05-22T08:15:31.687401Z","shell.execute_reply.started":"2021-05-22T08:15:31.680025Z","shell.execute_reply":"2021-05-22T08:15:31.686632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.689296Z","iopub.execute_input":"2021-05-22T08:15:31.689896Z","iopub.status.idle":"2021-05-22T08:15:31.774022Z","shell.execute_reply.started":"2021-05-22T08:15:31.68986Z","shell.execute_reply":"2021-05-22T08:15:31.773295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_batch = 8\nval_batch = 32","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.776433Z","iopub.execute_input":"2021-05-22T08:15:31.776691Z","iopub.status.idle":"2021-05-22T08:15:31.782001Z","shell.execute_reply.started":"2021-05-22T08:15:31.776666Z","shell.execute_reply":"2021-05-22T08:15:31.781243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = DataLoader(train_dataset, batch_size=train_batch, shuffle=True, num_workers=8, pin_memory=True)\nval_dataloader = DataLoader(val_dataset, batch_size=val_batch, shuffle=False, num_workers=8, pin_memory=True)\n\nfor a in train_dataloader:\n    print(a)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:31.783169Z","iopub.execute_input":"2021-05-22T08:15:31.783609Z","iopub.status.idle":"2021-05-22T08:15:38.032286Z","shell.execute_reply.started":"2021-05-22T08:15:31.783582Z","shell.execute_reply":"2021-05-22T08:15:38.031098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = transformers.BertForSequenceClassification.from_pretrained('../input/huggingface-bert/bert-base-uncased/', num_labels=1)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:38.033986Z","iopub.execute_input":"2021-05-22T08:15:38.034528Z","iopub.status.idle":"2021-05-22T08:15:47.375838Z","shell.execute_reply.started":"2021-05-22T08:15:38.034485Z","shell.execute_reply":"2021-05-22T08:15:47.374848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for train_encode in train_dataloader:\n    ids = train_encode['ids'].to(device)\n    mask = train_encode['mask'].to(device)\n    \n    output = model(ids, mask)\n    break\noutput","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:47.377284Z","iopub.execute_input":"2021-05-22T08:15:47.377634Z","iopub.status.idle":"2021-05-22T08:15:49.2693Z","shell.execute_reply.started":"2021-05-22T08:15:47.377598Z","shell.execute_reply":"2021-05-22T08:15:49.268309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(output['logits'].squeeze(-1))\nprint(output['logits'].squeeze(-1).shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:49.273367Z","iopub.execute_input":"2021-05-22T08:15:49.275433Z","iopub.status.idle":"2021-05-22T08:15:49.288152Z","shell.execute_reply.started":"2021-05-22T08:15:49.275367Z","shell.execute_reply":"2021-05-22T08:15:49.286964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Training","metadata":{}},{"cell_type":"code","source":"from transformers import AdamW\nLR = 2e-5\noptimizer = AdamW(model.parameters(), LR, betas=(0.9, 0.999), weight_decay=1e-2)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:49.292919Z","iopub.execute_input":"2021-05-22T08:15:49.294915Z","iopub.status.idle":"2021-05-22T08:15:49.313077Z","shell.execute_reply.started":"2021-05-22T08:15:49.294873Z","shell.execute_reply":"2021-05-22T08:15:49.312316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import get_linear_schedule_with_warmup\n\nepochs = 20\n\ntrain_steps = int(len(p_train_data)/train_batch*epochs)\nprint(train_steps)\n\nnum_steps = int(train_steps*0.1)\n\nscheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:49.316661Z","iopub.execute_input":"2021-05-22T08:15:49.3187Z","iopub.status.idle":"2021-05-22T08:15:49.327813Z","shell.execute_reply.started":"2021-05-22T08:15:49.31864Z","shell.execute_reply":"2021-05-22T08:15:49.327019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 学習率の推移\n# le = []\n# train_dataloader = DataLoader(train_dataset,\n#                               batch_size = train_batch,\n#                               shuffle = True,\n#                               num_workers = 8,\n#                               pin_memory = True\n#                              )\n\n# for epoch in tqdm(range(epochs)):\n#     for train_dl in train_dataloader:\n#         le.append(scheduler.get_last_lr())\n#         scheduler.step()\n# x = np.arange(len(le))\n# plt.plot(x, le)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:49.331974Z","iopub.execute_input":"2021-05-22T08:15:49.334099Z","iopub.status.idle":"2021-05-22T08:15:49.339203Z","shell.execute_reply.started":"2021-05-22T08:15:49.334062Z","shell.execute_reply":"2021-05-22T08:15:49.338375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loss_fn(output, target):\n    loss = nn.MSELoss()\n    return torch.sqrt(loss(output, target))","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:49.343489Z","iopub.execute_input":"2021-05-22T08:15:49.34627Z","iopub.status.idle":"2021-05-22T08:15:49.352555Z","shell.execute_reply.started":"2021-05-22T08:15:49.346234Z","shell.execute_reply":"2021-05-22T08:15:49.351515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training(train_dataloader, model, optimizer, scheluder):\n    model.train()\n    torch.backends.cudnn.benchmark = True\n    \n    all_preds = []\n    all_targets = []\n    losses = []\n\n    for train_dl in train_dataloader:\n\n        optimizer.zero_grad()\n        \n        with torch.cuda.amp.autocast():\n            ids = train_dl['ids'].to(device, non_blocking=True)\n            mask = train_dl['mask'].to(device, non_blocking=True)\n            \n            output = model(ids, mask)\n            output = output['logits'].squeeze(-1)\n            \n            target = train_dl['targets'].to(device, non_blocking=True)\n            \n            loss = loss_fn(output, target)\n            pred = output.detach().cpu().numpy()\n\n            losses.append(loss.item())\n            all_preds.append(pred)\n            all_targets.append(target.detach().squeeze(-1).cpu().numpy())\n            \n        scaler.scale(loss).backward()\n        scaler.step(optimizer)\n        scaler.update()\n\n        scheduler.step()\n\n        del loss, ids, mask\n    \n    all_preds = np.concatenate(all_preds)\n    all_targets = np.concatenate(all_targets)\n    \n    losses = np.mean(losses)\n    train_rme_loss = np.sqrt(mean_squared_error(all_targets, all_preds))\n    \n    return losses, train_rme_loss\n    ","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:49.356213Z","iopub.execute_input":"2021-05-22T08:15:49.357568Z","iopub.status.idle":"2021-05-22T08:15:49.373908Z","shell.execute_reply.started":"2021-05-22T08:15:49.357514Z","shell.execute_reply":"2021-05-22T08:15:49.373086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validating(val_dataloader, model):\n    model.eval()\n    \n    all_preds = []\n    all_targets = []\n    losses = []\n    \n    for val_dl in val_dataloader:\n        with torch.no_grad():\n            ids = val_dl['ids'].to(device)\n            mask = val_dl['mask'].to(device)\n            \n            output = model(ids, mask)\n            output = output['logits'].squeeze(-1)\n            \n            target = val_dl['targets'].to(device)\n            \n            loss = loss_fn(output, target)\n            \n            losses.append(loss.item())\n            all_preds.append(output.detach().cpu().numpy())\n            all_targets.append(target.detach().squeeze(-1).cpu().numpy())\n            \n            del loss, ids, mask\n            \n    all_preds = np.concatenate(all_preds)\n    all_targets = np.concatenate(all_targets)\n    \n    losses = np.mean(losses)\n    \n    val_rme_loss = np.sqrt(mean_squared_error(all_targets, all_preds))\n    \n    return all_preds, losses, val_rme_loss","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:18:20.399652Z","iopub.execute_input":"2021-05-22T08:18:20.400027Z","iopub.status.idle":"2021-05-22T08:18:20.408245Z","shell.execute_reply.started":"2021-05-22T08:18:20.39999Z","shell.execute_reply":"2021-05-22T08:18:20.407112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:15:49.397389Z","iopub.execute_input":"2021-05-22T08:15:49.400117Z","iopub.status.idle":"2021-05-22T08:15:49.426725Z","shell.execute_reply.started":"2021-05-22T08:15:49.40008Z","shell.execute_reply":"2021-05-22T08:15:49.425855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"p_train = train_data[train_data['kfold']!=0].reset_index(drop=True)\np_val = train_data[train_data['kfold']==0].reset_index(drop=True)\n\ntrain_batch = 16\nval_batch = 32\n\ntrain_dataset = BERTDataset(p_train['excerpt'], p_train['target'])\nval_dataset = BERTDataset(p_val['excerpt'], p_val['target'])\n\ntrain_dataloader = DataLoader(train_dataset,\n                               batch_size = train_batch,\n                               shuffle = True,\n                               num_workers = 4,\n                               pin_memory = True)\n\nval_dataloader = DataLoader(val_dataset,\n                           batch_size = val_batch,\n                           shuffle = False,\n                           num_workers = 4,\n                           pin_memory = True)\n\nmodel = transformers.BertForSequenceClassification.from_pretrained('../input/huggingface-bert/bert-base-uncased/', num_labels=1)\nmodel.to(device)\n\nlearning_rate = 2e-5\noptimizer = AdamW(model.parameters(), learning_rate, betas=(0.9, 0.999), weight_decay=1e-2)\n\ntrain_steps = int(len(p_train)/train_batch*epochs)\nnum_steps = int(train_steps*0.1)\n\nscheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:18:28.644283Z","iopub.execute_input":"2021-05-22T08:18:28.644611Z","iopub.status.idle":"2021-05-22T08:18:32.188424Z","shell.execute_reply.started":"2021-05-22T08:18:28.644579Z","shell.execute_reply":"2021-05-22T08:18:32.187567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_losses = []\nval_losses = []\nbest_score = None\n\ntrain_scores = []\nval_scores = []\n\nfor epoch in range(epochs):\n    print(f'Epochs: {epoch+1}/{epochs}')\n\n    train_loss, train_score = training(train_dataloader, model, optimizer, scheduler)\n    train_losses.append(train_loss)\n    train_scores.append(train_score)\n    \n    preds, val_loss, val_score = validating(val_dataloader, model)\n    val_losses.append(val_loss)\n    val_scores.append(val_score)\n    \n    print(f'train loss {train_loss}, train RME {train_score}')\n    print(f'validation loss {val_loss}, validation RME {val_score}')\n    \n    if best_score is None:\n        best_score = val_score\n        \n        print('Save first model')\n        \n        state = {\n            'state_dict': model.state_dict(),\n            'optimizer_dict': optimizer.state_dict(),\n            'best_score': best_score\n        }\n        torch.save(state, 'model0.pth')\n        \n    elif best_score > val_score:\n        best_score = val_score\n        \n        print('found better point')\n        \n        state = {\n            'state_dict': model.state_dict(),\n            'optimizer_dict': optimizer.state_dict(),\n            'best_score': best_score\n        }\n        torch.save(state, 'model0.pth')\n    \n    else:\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:23:00.696071Z","iopub.execute_input":"2021-05-22T08:23:00.696407Z","iopub.status.idle":"2021-05-22T08:51:47.311338Z","shell.execute_reply.started":"2021-05-22T08:23:00.696373Z","shell.execute_reply":"2021-05-22T08:51:47.310288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(p_val['target'], preds)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:52:08.65923Z","iopub.execute_input":"2021-05-22T08:52:08.659582Z","iopub.status.idle":"2021-05-22T08:52:08.815139Z","shell.execute_reply.started":"2021-05-22T08:52:08.65955Z","shell.execute_reply":"2021-05-22T08:52:08.814057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(epochs)\nplt.plot(x, train_losses)\nplt.plot(x, val_losses)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:52:12.478961Z","iopub.execute_input":"2021-05-22T08:52:12.479296Z","iopub.status.idle":"2021-05-22T08:52:12.602118Z","shell.execute_reply.started":"2021-05-22T08:52:12.479268Z","shell.execute_reply":"2021-05-22T08:52:12.601181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = np.arange(epochs)\nplt.plot(x, train_scores)\nplt.plot(x, val_scores)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:52:17.67825Z","iopub.execute_input":"2021-05-22T08:52:17.678569Z","iopub.status.idle":"2021-05-22T08:52:17.803469Z","shell.execute_reply.started":"2021-05-22T08:52:17.678536Z","shell.execute_reply":"2021-05-22T08:52:17.802747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_scores = []\nbest_scores.append(best_score)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:52:21.398897Z","iopub.execute_input":"2021-05-22T08:52:21.399219Z","iopub.status.idle":"2021-05-22T08:52:21.405573Z","shell.execute_reply.started":"2021-05-22T08:52:21.399187Z","shell.execute_reply":"2021-05-22T08:52:21.404696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(1, 5):\n    p_train = train_data[train_data['kfold']!=k].reset_index(drop=True)\n    p_val = train_data[train_data['kfold']==k].reset_index(drop=True)\n    \n    train_dataset = BERTDataset(p_train['excerpt'], p_train['target'])\n    val_dataset = BERTDataset(p_val['excerpt'], p_val['target'])\n\n    train_dataloader = DataLoader(train_dataset,\n                                   batch_size = train_batch,\n                                   shuffle = True,\n                                   num_workers = 4,\n                                   pin_memory = True)\n\n    val_dataloader = DataLoader(val_dataset,\n                               batch_size = val_batch,\n                               shuffle = False,\n                               num_workers = 4,\n                               pin_memory = True)\n\n    model = transformers.BertForSequenceClassification.from_pretrained('../input/huggingface-bert/bert-base-uncased/', num_labels=1)\n    model.to(device)\n\n    learning_rate = 2e-5\n    optimizer = AdamW(model.parameters(), learning_rate, betas=(0.9, 0.999), weight_decay=1e-2)\n\n    train_steps = int(len(p_train)/train_batch*epochs)\n    num_steps = int(train_steps*0.1)\n\n    scheduler = get_linear_schedule_with_warmup(optimizer, num_steps, train_steps)\n    \n    train_losses = []\n    val_losses = []\n    best_score = None\n\n    train_scores = []\n    val_scores = []\n\n    for epoch in range(epochs):\n        print(f'Epochs: {epoch+1}/{epochs}')\n\n        train_loss, train_score = training(train_dataloader, model, optimizer, scheduler)\n        train_losses.append(train_loss)\n        train_scores.append(train_score)\n\n        preds, val_loss, val_score = validating(val_dataloader, model)\n        val_losses.append(val_loss)\n        val_scores.append(val_score)\n\n        print(f'train loss {train_loss}, train RME {train_score}')\n        print(f'validation loss {val_loss}, validation RME {val_score}')\n\n        if best_score is None:\n            best_score = val_score\n\n            print('Save first model')\n\n            state = {\n                'state_dict': model.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n                'best_score': best_score\n            }\n            torch.save(state, f'model{k}.pth')\n\n        elif best_score > val_score:\n            best_score = val_score\n\n            print('found better point')\n\n            state = {\n                'state_dict': model.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n                'best_score': best_score\n            }\n            torch.save(state, f'model{k}.pth')\n\n        else:\n            pass\n    \n    best_scores.append(best_score)","metadata":{"execution":{"iopub.status.busy":"2021-05-22T08:52:24.110182Z","iopub.execute_input":"2021-05-22T08:52:24.110497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_scores","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'score: {np.mean(best_scores)}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# inference","metadata":{}},{"cell_type":"code","source":"import gc\ndel train_dataset, val_dataset, train_dataloader, val_dataloader, model, optimizer, scheduler\n_ = gc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BERTinfDataset(Dataset):\n    def __init__(self, sentences):\n        self.sentences = sentences\n\n        \n    def __len__(self):\n        return len(self.sentences)\n    \n    \n    def __getitem__(self, idx):\n        sentence = self.sentences[idx]\n        \n        encode_sentence = tokenizer.encode_plus(\n                                sentence,\n                                add_special_tokens = True,\n                                max_length = 314,\n                                pad_to_max_length = True,\n                                truncation = True\n                        )\n        \n        ids = torch.tensor(encode_sentence['input_ids'], dtype=torch.long)\n        mask = torch.tensor(encode_sentence['attention_mask'], dtype=torch.long)\n        token_type_ids = torch.tensor(encode_sentence['token_type_ids'], dtype=torch.long)\n\n        return {\n            'ids': ids,\n            'mask': mask,\n            'token_type_ids': token_type_ids\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = BERTinfDataset(test['excerpt'])\ntest_batch = 32\n\ntest_dataloader = DataLoader(test_dataset,\n                            batch_size = test_batch,\n                            shuffle = False,\n                            num_workers = 4,\n                            pin_memory = True)\n\nmodel = transformers.BertForSequenceClassification.from_pretrained('../input/huggingface-bert/bert-base-uncased/', num_labels=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pthes = [os.path.join('./', s) for s in os.listdir('./') if '.pth' in s]\npthes","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predicting(test_dataloader, model, pthes):\n    all_preds = []\n    \n    for pth in pthes:\n        state = torch.load(pth)\n        model.load_state_dict(state['state_dict'])\n        model.to(device)\n        model.eval()\n        \n        preds = []\n        all_val_loss = 0\n        \n        with torch.no_grad():\n            for test_dl in test_dataloader:\n                ids = test_dl['ids'].to(device)\n                mask = test_dl['mask'].to(device)\n                token_type = test_dl['token_type_ids'].to(device)\n                \n                output = model(ids, mask)\n                output = output['logits'].squeeze(-1)\n                \n                preds.append(output.cpu().numpy())\n\n        preds = np.concatenate(preds)\n        all_preds.append(preds)\n        \n    return all_preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = predicting(test_dataloader, model, pthes)\ndf = pd.DataFrame(all_preds).T\ndf","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_submission = df.mean(axis=1)\nmean_submission","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df = pd.read_csv(\"../input/commonlitreadabilityprize/sample_submission.csv\")\nsubmit_df['target'] = mean_submission\nsubmit_df","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit_df.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}