{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center><h1> CommonLit Readability Prize </h1>\n    <h2>ðŸ“– EDA + NaÃ¯ve Submission ðŸ“–</h2>\n\n<img src=\"https://www.commonsense.org/education/sites/default/files/tlr-blog/commonlit-logo-1.png\" width=\"500\"/>\n    <p style=\"text-align:center;\">Image <a href=\"https://www.commonsense.org/education/website/commonlit\">source</a>.</p>\n</center>","metadata":{}},{"cell_type":"markdown","source":"# Overview\n\nCiting the competition's hosts:\n> In this competition, youâ€™ll build algorithms to rate the complexity of reading passages for grade 3-12 classroom use.\n\nThus, given a set of text excerpts, we'll have to predict their relative *textual complexity*. Such work would prove to be extremely beneficial in the context of knowledge sharing and availability. One would be able to quickly search text excerpts of interest while consequently getting a match that perfectly fits the person's reading capabilities. Consequently, knowledge sharing could be automated and education speed greatly accelerated.\n\nIn this notebook, we'll take a look at an Exploratory Data Analysis of the training data provided for this competition, as well as building and running a naÃ¯ve solution that basically performs string matching frequencies to predict whether a given text excerpt has a higher or lower textual complexity.\n\n\n### Outline:\n\n1. [Setup and Basic EDA](#head-1)\n2. [Understanding Excerpts and their Associated Targets](#head-2) \n3. [A NaÃ¯ve String Matching Submission](#head-3)","metadata":{}},{"cell_type":"markdown","source":"# 1. Setup and Basic EDA <a class=\"anchor\" id=\"head-1\"></a>","metadata":{}},{"cell_type":"code","source":"import os\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\n\nfrom wordcloud import WordCloud, STOPWORDS\n\n%matplotlib inline\n\nos.listdir('/kaggle/input/commonlitreadabilityprize')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We are provided with 3 main pieces of data:\n\n* `train.csv`: The CSV file containing all the training reading passages as well as their corresponding metadata, such as their ID and their target complexities (ground truths).\n* `test.csv`: The CSV file containing (a small subset of) the actual reading passages that will be used for testing purposes (thus, with no ground truth column available).\n* `sample_submission.csv`: The CSV file containing all the publications IDs in the test set, for which we'll have to populate the prediction column.","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/commonlitreadabilityprize/train.csv')\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The training data contains 2,834 rows, with 6 columns describing each row.","metadata":{}},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"That's great! There are no missing values (except for legal and license information), and the dataset looks complete.","metadata":{}},{"cell_type":"code","source":"for col in train.columns:\n    print(f\"{col}: {len(train[col].unique())}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like **all targets and standard errors** are unique in the dataset. This comes with no surprise as the problem at hand is a regression problem and not a classification problem.\n\nAlso, all 830 excerpts having a license share a pool of only 16 unique licenses.","metadata":{}},{"cell_type":"markdown","source":"# 2. Understanding Excerpts and their Associated Targets <a class=\"anchor\" id=\"head-2\"></a>","metadata":{}},{"cell_type":"markdown","source":"Let's first take a look at the distribution of the targets in the training set.","metadata":{}},{"cell_type":"code","source":"fig = ff.create_distplot([train['target']], ['target'])\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Targets follow a normal distribution centered at **-1**. It is apparent that negative targets are more common than positive ones, with the training range going **from -3.67 up to 1.71**.\n\nBut what do those numbers actualy mean? Which direction is the \"easier\" complexity of text excerpts? To answer this, let's take a look at the 5 excerpts with the highest and lowest target scores.","metadata":{}},{"cell_type":"code","source":"# Top 5 excerpts with lowest scores\n\nmin_5_targets = sorted(train['target'])[:5]\nfor min_target in min_5_targets:\n    print(\"Target:\", train[train['target'] == min_target].iloc[0,4])\n    print(train[train['target'] == min_target].iloc[0,3])\n    print(\"*\" * 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Top 5 excerpts with highest scores\n\nmax_5_targets = sorted(train['target'])[-5:]\nfor max_target in max_5_targets:\n    print(\"Target:\", train[train['target'] == max_target].iloc[0,4])\n    print(train[train['target'] == max_target].iloc[0,3])\n    print(\"*\" * 50)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like higher scoring excerpts tend to have a lower reading complexity than excerpts with lower scores.\n\nSentences and simpler, and context is easily caught in higher scoring excerpts, whereas the opposite can be observed in lower scoring excerpts.\n\nFor a deeper grasp of the differences in text excerpts, let's take a look at the world cloud of the top 100 excerpts with the highest and lowest target scores.","metadata":{}},{"cell_type":"code","source":"# Defining our word cloud drawing function\ndef wordcloud_draw(data, color = 'white'):\n    wordcloud = WordCloud(stopwords = STOPWORDS,\n                          background_color = color,\n                          width = 3000,\n                          height = 2000\n                         ).generate(' '.join(data))\n    plt.figure(1, figsize = (12, 8))\n    plt.imshow(wordcloud)\n    plt.axis('off')\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_in_lower_scoring_excerpts = []\n\nfor _, row in train.sort_values('target').head(100).iterrows():\n    words_in_lower_scoring_excerpts.extend(row['excerpt'].split())\n\nprint(\"Wordcloud for excerpts with lowest targets:\")\nwordcloud_draw(words_in_lower_scoring_excerpts, color='black')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Words present in lower scoring excerpts seems to be more precise or *scientific*. Words such as **system**, **light**, **matter** and **surface** stand out the most.","metadata":{}},{"cell_type":"code","source":"words_in_higher_scoring_excerpts = []\n\nfor _, row in train.sort_values('target').tail(100).iterrows():\n    words_in_higher_scoring_excerpts.extend(row['excerpt'].split())\n\nprint(\"Wordcloud for excerpts with highest targets:\")\nwordcloud_draw(words_in_higher_scoring_excerpts)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Words present in higher scoring excerpts seems to be more relaxed and geared towards *story-telling*. Words such as **said**, **went**, **little** and **mother** stand out the most.","metadata":{}},{"cell_type":"markdown","source":"# 3. A NaÃ¯ve String Matching Submission <a class=\"anchor\" id=\"head-3\"></a>","metadata":{}},{"cell_type":"markdown","source":"Obviously, the end goal of such a competition is not simply do string matching of known text excerpts in order to predict textual complecity, however, it is to build a strong enough NLP model that can infer from context whether or not a piece of text contains cohesion and semantics of high or low textual complexity.\n\nThat being said, below we will implement a very simple string matching technique as a POC and template for building a submission.","metadata":{}},{"cell_type":"code","source":"test = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv('../input/commonlitreadabilityprize/sample_submission.csv', index_col=0)\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"range_len = 100\nrange_counter = 0\nlower_bound = 0\nupper_bound = 0\ntarget_ranges = []\nfor _, row in train.sort_values('target').iterrows():\n    if range_counter >= range_len - 1:\n        range_counter = 0\n        upper_bound = row['target']\n        target_ranges.append((lower_bound, upper_bound))\n    elif range_counter == 0:\n        lower_bound = row['target']\n        range_counter += 1\n    else:\n        range_counter += 1\n\nif range_counter > 0:\n    target_ranges.append((lower_bound, train.sort_values('target').iloc[-1,4]))\n        \ntarget_ranges","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_ranges_prediction = {}\nmargin = 0.1\nfor target_range in target_ranges:\n    prediction = sum(target_range)/2\n    if prediction < -2: prediction += margin\n    if prediction > 0: prediction -= margin\n    target_ranges_prediction[target_range] = prediction\n\ntarget_ranges_prediction","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words_in_target_ranges = defaultdict(set)\n\nfor target_range in target_ranges:\n    lower_bound, upper_bound = target_range\n    for _, row in train[(train['target'] > lower_bound) & (train['target'] < upper_bound)].iterrows():\n        words_in_target_ranges[target_range] |= set(row['excerpt'].lower().split())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\nfor index in submission_df.index:\n    excerpt_words = test[test['id'] == index].iloc[0,3].lower().split()\n    max_intersection = sum([1 if word in words_in_target_ranges[target_ranges[0]] else 0 for word in excerpt_words])\n    max_target_range = target_ranges[0]\n    for target_range in target_ranges[1:]:\n        intersection = sum([1 if word in words_in_target_ranges[target_range] else 0 for word in excerpt_words])\n        if intersection > max_intersection:\n            max_intersection = intersection\n            max_target_range = target_range\n    predictions.append(target_ranges_prediction[max_target_range])\n\nsubmission_df['target'] = predictions\n\nsubmission_df.to_csv('submission.csv')\n\nsubmission_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This notebook is under development ðŸš§\n\n---\n\n## Please upvote if you found it useful ðŸ˜Š","metadata":{}}]}