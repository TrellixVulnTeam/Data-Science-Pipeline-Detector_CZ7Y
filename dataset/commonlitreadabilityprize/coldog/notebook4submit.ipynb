{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"```\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n```","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-04T08:16:25.683309Z","iopub.execute_input":"2021-06-04T08:16:25.683726Z","iopub.status.idle":"2021-06-04T08:16:25.690958Z","shell.execute_reply.started":"2021-06-04T08:16:25.683642Z","shell.execute_reply":"2021-06-04T08:16:25.690029Z"}}},{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom torch.nn.utils.rnn import pad_sequence\nfrom transformers import BertModel, BertTokenizer\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.300932Z","iopub.execute_input":"2021-06-12T15:00:59.301322Z","iopub.status.idle":"2021-06-12T15:00:59.306223Z","shell.execute_reply.started":"2021-06-12T15:00:59.301288Z","shell.execute_reply":"2021-06-12T15:00:59.305359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define DataLoader","metadata":{}},{"cell_type":"code","source":"def load_data(data_filename, mode='train', type='numpy'):\n    pd_table = pd.read_csv(data_filename)\n    ids, urls, licenses, excerpts, = pd_table['id'], pd_table['url_legal'], pd_table['license'], pd_table['excerpt']\n\n    targets, standard_errors = [pd_table['target'], pd_table['standard_error']] if mode == 'train' else [None, None]\n\n\n    if type == 'pandas':\n        return ids, urls, licenses, excerpts, targets, standard_errors\n    elif type == 'numpy':\n        return map(np.array, [ids, urls, licenses, excerpts, targets, standard_errors])\n    else:\n        raise AssertionError('Unknown type [%s]' % type)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.308022Z","iopub.execute_input":"2021-06-12T15:00:59.30861Z","iopub.status.idle":"2021-06-12T15:00:59.318704Z","shell.execute_reply.started":"2021-06-12T15:00:59.308574Z","shell.execute_reply":"2021-06-12T15:00:59.317988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CRPDataset(torch.utils.data.Dataset):\n    def __init__(self, mode, tokenizer=lambda x: x):\n        ids, urls, licenses, excerpts, targets, standard_errors = load_data(os.path.join(DATA_ROOT_DIR, \"%s.csv\" % mode), mode=mode)\n        self.ids = ids\n        self.excerpts, self.targets, self.standard_errors = excerpts, targets, standard_errors\n        self.mode = mode\n        self.tokenizer = tokenizer\n\n    def __getitem__(self, index):\n        if self.mode == 'train':\n            return {'excerpt': self.tokenizer(self.excerpts[index],\n                                              padding=\"max_length\", \n                                              truncation=True, \n                                              max_length=512)['input_ids'], # only take 'input_ids', discarding 'token_type_ids'\n                    'target': self.targets[index],\n                    'standard_error': self.standard_errors[index]}\n        else:\n            return {'id': self.ids[index],\n                    'excerpt': self.tokenizer(self.excerpts[index])['input_ids']}\n        \n    def __len__(self):\n        return len(self.ids)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.320714Z","iopub.execute_input":"2021-06-12T15:00:59.32229Z","iopub.status.idle":"2021-06-12T15:00:59.341939Z","shell.execute_reply.started":"2021-06-12T15:00:59.320945Z","shell.execute_reply":"2021-06-12T15:00:59.3411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def collate_fn(batch):\n    # tokens = [tokenizer(data['excerpt'], padding=True) for data in datas]\n    ids = [data['id'] for data in batch]\n    tokens = pad_sequence([torch.tensor(data['excerpt'], dtype=torch.long) for data in batch], batch_first=True)\n    # targets = torch.tensor([torch.tensor(data['target'], dtype=torch.float32) for data in batch])\n    # stds = torch.tensor([torch.tensor(data['standard_error'], dtype=torch.float32) for data in batch])\n    # tokens = truncate_or_pad(tensor=tokens, max_length=MAX_SEQ_LEN)\n    return ids, tokens","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.343693Z","iopub.execute_input":"2021-06-12T15:00:59.344063Z","iopub.status.idle":"2021-06-12T15:00:59.35001Z","shell.execute_reply.started":"2021-06-12T15:00:59.344029Z","shell.execute_reply":"2021-06-12T15:00:59.349228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define Network","metadata":{}},{"cell_type":"code","source":"class Baseline_BERT(nn.Module):\n    def __init__(self, freeze_bert=True):\n        super(Baseline_BERT, self).__init__()\n        self.bert = BertModel.from_pretrained(BERT_DIR)\n        if freeze_bert:\n            self.bert.requires_grad_(False)\n        self.regressor = nn.Linear(768, 1)\n\n    def forward(self, tokens):\n        bert_output = self.bert(input_ids=tokens, return_dict=True)\n        cls = bert_output['pooler_output']\n        out = self.regressor(cls)\n        return out","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.351526Z","iopub.execute_input":"2021-06-12T15:00:59.352224Z","iopub.status.idle":"2021-06-12T15:00:59.359485Z","shell.execute_reply.started":"2021-06-12T15:00:59.352151Z","shell.execute_reply":"2021-06-12T15:00:59.358714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pipeline","metadata":{}},{"cell_type":"code","source":"DATA_ROOT_DIR = '/kaggle/input/commonlitreadabilityprize'\nBERT_DIR = '/kaggle/input/huggingface-bert/bert-base-chinese'\nDEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\nBATCH_SIZE = 1","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.360781Z","iopub.execute_input":"2021-06-12T15:00:59.361347Z","iopub.status.idle":"2021-06-12T15:00:59.371404Z","shell.execute_reply.started":"2021-06-12T15:00:59.361309Z","shell.execute_reply":"2021-06-12T15:00:59.370592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Input\ntokenizer = BertTokenizer.from_pretrained(BERT_DIR)\ntest_dataset = CRPDataset('test', tokenizer=tokenizer)\ntest_dataloader = torch.utils.data.DataLoader(dataset=test_dataset,\n                                               batch_size=BATCH_SIZE,\n                                               shuffle=False,\n                                               collate_fn=collate_fn)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.374407Z","iopub.execute_input":"2021-06-12T15:00:59.374645Z","iopub.status.idle":"2021-06-12T15:00:59.413542Z","shell.execute_reply.started":"2021-06-12T15:00:59.374623Z","shell.execute_reply":"2021-06-12T15:00:59.412822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Baseline_BERT(freeze_bert=True)\nmodel.load_state_dict(torch.load('/kaggle/input/models/baseline_bert.pt'))\nmodel.to(DEVICE)\nmodel.eval()\nprint('model loaded.')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:00:59.414753Z","iopub.execute_input":"2021-06-12T15:00:59.415077Z","iopub.status.idle":"2021-06-12T15:01:02.226228Z","shell.execute_reply.started":"2021-06-12T15:00:59.415044Z","shell.execute_reply":"2021-06-12T15:01:02.225352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# writer = open(os.path.join('/kaggle/working', 'submission.csv'), 'w', encoding='utf-8')\n# writer.write('id,target\\n')\ntotal_ids, total_outs = [], []\nwith torch.no_grad():\n    for step, (ids, inputs) in tqdm(enumerate(test_dataloader)):\n        inputs = inputs.to(DEVICE)\n        output = model(tokens=inputs)\n        \n        outs = output.squeeze().cpu().numpy().tolist()\n        \n#         for (id, out) in zip(ids, outs):\n#             writer.write('%s,%s\\n' % (id, out))\n        total_ids.append(ids)\n        total_outs.append(outs)\n# writer.close()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:01:02.228987Z","iopub.execute_input":"2021-06-12T15:01:02.229271Z","iopub.status.idle":"2021-06-12T15:01:02.422609Z","shell.execute_reply.started":"2021-06-12T15:01:02.229232Z","shell.execute_reply":"2021-06-12T15:01:02.421661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dump prediction","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ntest = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\n# test = np.array(test)\n\ntest['target'] = np.array(total_outs)\ns = pd.DataFrame({'id': test['id'], 'target': test['target']})\ns.to_csv(\"./submission.csv\", encoding='utf-8', index=False)\n\n# total_ids, total_outs = np.array(total_ids), np.array(total_outs)\n# total_ids = total_ids[:, np.newaxis]\n# total_outs = total_outs[:, np.newaxis]\n# prediction = np.concatenate((total_ids, total_outs), axis = 1)\n# colname = ['id', 'target']\n# prediction = pd.DataFrame(data=prediction, columns = colname)\n# prediction.to_csv(\"./submission.csv\", encoding='utf-8', index=False, float_format='%.20f')","metadata":{"execution":{"iopub.status.busy":"2021-06-12T15:01:02.424125Z","iopub.execute_input":"2021-06-12T15:01:02.42449Z","iopub.status.idle":"2021-06-12T15:01:02.649893Z","shell.execute_reply.started":"2021-06-12T15:01:02.424453Z","shell.execute_reply":"2021-06-12T15:01:02.649095Z"},"trusted":true},"execution_count":null,"outputs":[]}]}