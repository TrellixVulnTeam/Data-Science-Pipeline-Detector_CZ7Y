{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nfrom transformers import RobertaModel, AutoTokenizer, get_linear_schedule_with_warmup\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport re\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport torch\nfrom torch import nn\nimport sklearn\nfrom tqdm.notebook import tqdm\n\nfrom nltk.corpus import stopwords\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-27T06:16:01.815486Z","iopub.execute_input":"2021-06-27T06:16:01.816013Z","iopub.status.idle":"2021-06-27T06:16:04.474131Z","shell.execute_reply.started":"2021-06-27T06:16:01.815933Z","shell.execute_reply":"2021-06-27T06:16:04.473247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(2021)\ntorch.cuda.manual_seed(2021)\ntorch.cuda.manual_seed_all(2021)\nnp.random.seed(2021)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.480826Z","iopub.execute_input":"2021-06-27T06:16:04.48135Z","iopub.status.idle":"2021-06-27T06:16:04.487806Z","shell.execute_reply.started":"2021-06-27T06:16:04.481313Z","shell.execute_reply":"2021-06-27T06:16:04.487034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/commonlitreadabilityprize/test.csv')\ntest","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.489396Z","iopub.execute_input":"2021-06-27T06:16:04.489762Z","iopub.status.idle":"2021-06-27T06:16:04.514634Z","shell.execute_reply.started":"2021-06-27T06:16:04.489724Z","shell.execute_reply":"2021-06-27T06:16:04.513878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/commonlitreadabilityprize/sample_submission.csv')\nsample","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.517617Z","iopub.execute_input":"2021-06-27T06:16:04.5179Z","iopub.status.idle":"2021-06-27T06:16:04.533629Z","shell.execute_reply.started":"2021-06-27T06:16:04.517874Z","shell.execute_reply":"2021-06-27T06:16:04.532737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/commonlitreadabilityprize/train.csv')\ntrain['excerpt'][1]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.535028Z","iopub.execute_input":"2021-06-27T06:16:04.535604Z","iopub.status.idle":"2021-06-27T06:16:04.572333Z","shell.execute_reply.started":"2021-06-27T06:16:04.535563Z","shell.execute_reply":"2021-06-27T06:16:04.571381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.573663Z","iopub.execute_input":"2021-06-27T06:16:04.574035Z","iopub.status.idle":"2021-06-27T06:16:04.595306Z","shell.execute_reply.started":"2021-06-27T06:16:04.573999Z","shell.execute_reply":"2021-06-27T06:16:04.5943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Before stopword removal\\n\\n')\nprint(train['excerpt'][0])\nstop_words = set(stopwords.words('english'))\nprint('After stopword removal\\n\\n')\nprint(\" \".join([x for x in train['excerpt'][0].split(\" \") if x not in stop_words]))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.596633Z","iopub.execute_input":"2021-06-27T06:16:04.597018Z","iopub.status.idle":"2021-06-27T06:16:04.606136Z","shell.execute_reply.started":"2021-06-27T06:16:04.596983Z","shell.execute_reply":"2021-06-27T06:16:04.60508Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Before special characters removed\\n')\nprint(train['excerpt'][0])\n\nprint('After special characters removed\\n')\nprint(\" \".join(re.findall(r\"\\w+\", train['excerpt'][0])))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.610159Z","iopub.execute_input":"2021-06-27T06:16:04.610779Z","iopub.status.idle":"2021-06-27T06:16:04.617068Z","shell.execute_reply.started":"2021-06-27T06:16:04.610592Z","shell.execute_reply":"2021-06-27T06:16:04.616038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt'][5]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.619493Z","iopub.execute_input":"2021-06-27T06:16:04.620322Z","iopub.status.idle":"2021-06-27T06:16:04.627651Z","shell.execute_reply.started":"2021-06-27T06:16:04.620281Z","shell.execute_reply":"2021-06-27T06:16:04.626737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # Stop words\ntrain['excerpt'] = train['excerpt'].apply(lambda x : \n             \" \".join([k for k in x.split(\" \") if k not in stop_words]))\n# Special characters\ntrain['excerpt'] = train['excerpt'].apply(lambda x: \" \".join(re.findall(r\"\\w+\", x)))\n\n# # Stop words\ntest['excerpt'] = test['excerpt'].apply(lambda x : \n             \" \".join([k for k in x.split(\" \") if k not in stop_words]))\n# Special characters\ntest['excerpt'] = test['excerpt'].apply(lambda x: \" \".join(re.findall(r\"\\w+\", x)))","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.629214Z","iopub.execute_input":"2021-06-27T06:16:04.629578Z","iopub.status.idle":"2021-06-27T06:16:04.832675Z","shell.execute_reply.started":"2021-06-27T06:16:04.629541Z","shell.execute_reply":"2021-06-27T06:16:04.831872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['excerpt'][5]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.834663Z","iopub.execute_input":"2021-06-27T06:16:04.835171Z","iopub.status.idle":"2021-06-27T06:16:04.840613Z","shell.execute_reply.started":"2021-06-27T06:16:04.835133Z","shell.execute_reply":"2021-06-27T06:16:04.839626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['target'].hist()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.841933Z","iopub.execute_input":"2021-06-27T06:16:04.842286Z","iopub.status.idle":"2021-06-27T06:16:04.984339Z","shell.execute_reply.started":"2021-06-27T06:16:04.84225Z","shell.execute_reply":"2021-06-27T06:16:04.983331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['length'] = train['excerpt'].apply(lambda x: len(x.split(' ')))\ntrain['length'].hist()\nprint('Value Counts:',train['length'].value_counts())\ntrain.drop(columns=['length'], inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:04.985753Z","iopub.execute_input":"2021-06-27T06:16:04.986141Z","iopub.status.idle":"2021-06-27T06:16:05.134819Z","shell.execute_reply.started":"2021-06-27T06:16:04.986102Z","shell.execute_reply":"2021-06-27T06:16:05.133866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.heatmap(train[['target', 'standard_error']].corr(), vmin=-1, vmax=1, cmap=\"RdYlGn\", annot=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:05.136305Z","iopub.execute_input":"2021-06-27T06:16:05.13666Z","iopub.status.idle":"2021-06-27T06:16:05.358382Z","shell.execute_reply.started":"2021-06-27T06:16:05.136619Z","shell.execute_reply":"2021-06-27T06:16:05.357586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:05.359629Z","iopub.execute_input":"2021-06-27T06:16:05.359992Z","iopub.status.idle":"2021-06-27T06:16:05.388803Z","shell.execute_reply.started":"2021-06-27T06:16:05.359956Z","shell.execute_reply":"2021-06-27T06:16:05.388007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train[['excerpt', 'standard_error', 'target']]","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:05.390863Z","iopub.execute_input":"2021-06-27T06:16:05.391431Z","iopub.status.idle":"2021-06-27T06:16:05.397817Z","shell.execute_reply.started":"2021-06-27T06:16:05.391392Z","shell.execute_reply":"2021-06-27T06:16:05.397039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n\n    def __init__(\n        self,\n#         n_classes = CFG.classes,\n        model_name = '../input/bert-base-uncased',\n        fc_dim = 768,\n#         margin = CFG.margin,\n#         scale = CFG.scale,\n        use_fc = True\n    ):\n\n        super(Model,self).__init__()\n        print('Building Model Backbone for {} model'.format(model_name))\n\n        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n#         self.backbone = RobertaModel.from_pretrained(model_name).to(device)\n        self.backbone = transformers.BertForSequenceClassification.from_pretrained(model_name,num_labels=1)\n        self.backbone.cuda()\n\n        in_features = 768\n        self.use_fc = use_fc\n        \n        if use_fc:\n#             self.dropout = nn.Dropout(p=0.0)\n#             self.classifier = nn.Linear(in_features, fc_dim)\n#             self.bn = nn.BatchNorm1d(fc_dim)\n            self.dropout = nn.Dropout(0.3)\n            self.final = nn.Linear(768, 1)\n#             self.layer_norm = nn.LayerNorm(in_features, elementwise_affine=False)\n#             print(self.layer_norm)\n#             self.relu = nn.ReLU()\n#             self._init_params()\n            \n            \n#             self._init_params()\n#             in_features = fc_dim\n            \n\n#     def forward(self, texts, labels=torch.tensor([0])):\n#         features = self.extract_features(texts)\n#         if self.training:\n#             logits = self.final(features, labels.to(device))\n#             return logits\n#         else:\n#             return features\n        \n    def _init_params(self):\n        nn.init.xavier_normal_(self.classifier.weight)\n        nn.init.xavier_normal_(self.final.weight)\n#         self.layer_norm.bias.data.zero_()\n#         self.layer_norm.weight.data.fill_(1.0)\n    \n    def forward(self, texts):\n        encoding = self.tokenizer(texts, padding=True, truncation=True,\n                             max_length=150, return_tensors='pt').to(device)\n        input_ids = encoding['input_ids']\n        attention_mask = encoding['attention_mask']\n        embedding = self.backbone(input_ids, attention_mask=attention_mask)\n        return embedding","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:05.398869Z","iopub.execute_input":"2021-06-27T06:16:05.399118Z","iopub.status.idle":"2021-06-27T06:16:05.411108Z","shell.execute_reply.started":"2021-06-27T06:16:05.399093Z","shell.execute_reply":"2021-06-27T06:16:05.410239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import transformers\nmodel = Model()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:05.412286Z","iopub.execute_input":"2021-06-27T06:16:05.412831Z","iopub.status.idle":"2021-06-27T06:16:12.202486Z","shell.execute_reply.started":"2021-06-27T06:16:05.412781Z","shell.execute_reply":"2021-06-27T06:16:12.201632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ExcerptDataset(torch.utils.data.Dataset):\n    def __init__(self, df, text_column, label_column=None, submission=False):\n        texts = df[text_column]\n        self.submission=submission\n        if not submission:\n            self.labels = df[label_column].values\n        \n        self.titles = []\n        for title in texts:\n#             title = title.encode('utf-8').decode(\"unicode_escape\")\n#             title = title.encode('ascii', 'ignore').decode(\"unicode_escape\")\n#             title = title.lower()\n            self.titles.append(title)\n\n    def __len__(self):\n        return len(self.titles)\n\n    def __getitem__(self, idx):\n        text = self.titles[idx]\n        if not self.submission:\n            label = torch.tensor(self.labels[idx], dtype=torch.float32)\n            label = label.reshape(1)\n            return text, label\n        else:\n            return text","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.203781Z","iopub.execute_input":"2021-06-27T06:16:12.204154Z","iopub.status.idle":"2021-06-27T06:16:12.212049Z","shell.execute_reply.started":"2021-06-27T06:16:12.204117Z","shell.execute_reply":"2021-06-27T06:16:12.211139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Naive train test split","metadata":{}},{"cell_type":"code","source":"# train, val = sklearn.model_selection.train_test_split(train)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.213262Z","iopub.execute_input":"2021-06-27T06:16:12.21359Z","iopub.status.idle":"2021-06-27T06:16:12.225465Z","shell.execute_reply.started":"2021-06-27T06:16:12.213553Z","shell.execute_reply":"2021-06-27T06:16:12.224644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"StratifyKFold","metadata":{}},{"cell_type":"code","source":"data = train.copy()\nnum_bins = int(np.floor(1 + np.log2(len(data)))) # Sturge's Rule\ndata[\"bins\"] = pd.cut(data['target'], bins=num_bins, labels=False)\n\nkf = sklearn.model_selection.StratifiedKFold(3)\n\nfor i, (train_index, test_index) in enumerate(kf.split(data, data['bins'])):\n    data.loc[test_index, 'kfold'] = i\n\ndata = data.drop(columns=['bins'])\n\nfor i, group in enumerate(data.groupby('kfold')):\n#     print(group[1]['target'])\n    plt.subplot(3, 1, i+1)\n    plt.hist(group[1]['target'])\n#     break\nprint(\"K-Fold Histogram of Target\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.226698Z","iopub.execute_input":"2021-06-27T06:16:12.227117Z","iopub.status.idle":"2021-06-27T06:16:12.50267Z","shell.execute_reply.started":"2021-06-27T06:16:12.227079Z","shell.execute_reply":"2021-06-27T06:16:12.501706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['kfold'] = data['kfold'].astype(int)\ndata","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.504053Z","iopub.execute_input":"2021-06-27T06:16:12.504422Z","iopub.status.idle":"2021-06-27T06:16:12.519233Z","shell.execute_reply.started":"2021-06-27T06:16:12.504384Z","shell.execute_reply":"2021-06-27T06:16:12.518109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_dataset = ExcerptDataset(train, 'excerpt', 'target')\n# train_dataloader = torch.utils.data.DataLoader(\n#     train_dataset,\n#     batch_size = 32,\n#     num_workers = 4,\n#     pin_memory = True,\n#     shuffle = True,\n#     drop_last = False\n# )\n# val_dataset = ExcerptDataset(val, 'excerpt', 'target')\n# val_dataloader = torch.utils.data.DataLoader(\n#     val_dataset,\n#     batch_size = 32,\n#     num_workers = 4,\n#     pin_memory = True,\n#     shuffle = True,\n#     drop_last = False\n# )","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.520849Z","iopub.execute_input":"2021-06-27T06:16:12.521254Z","iopub.status.idle":"2021-06-27T06:16:12.529335Z","shell.execute_reply.started":"2021-06-27T06:16:12.521212Z","shell.execute_reply":"2021-06-27T06:16:12.528479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model(next(iter(train_dataloader))[0]).logits","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.530543Z","iopub.execute_input":"2021-06-27T06:16:12.530998Z","iopub.status.idle":"2021-06-27T06:16:12.543563Z","shell.execute_reply.started":"2021-06-27T06:16:12.530955Z","shell.execute_reply":"2021-06-27T06:16:12.542655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def validate(model, val_dataloader, loss_fn):\n    with torch.no_grad():\n        average_loss=0\n        for (texts,labels) in val_dataloader:\n            texts = list(texts)\n            labels = labels.to(device)\n\n            outputs = model(texts).logits\n            loss = loss_fn(outputs, labels)\n            average_loss += loss.item()\n        average_loss = average_loss/len(val_dataloader)\n        del model\n        gc.collect()\n        return average_loss","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.544896Z","iopub.execute_input":"2021-06-27T06:16:12.54532Z","iopub.status.idle":"2021-06-27T06:16:12.553185Z","shell.execute_reply.started":"2021-06-27T06:16:12.545284Z","shell.execute_reply":"2021-06-27T06:16:12.552206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# epocs=10\n# optimizer=torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n# loss_fn=nn.MSELoss()\n# total_steps = len(train_dataloader)*epocs\n# scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=3, num_training_steps=total_steps)\n# train_loss_history=[]\n# val_loss_history=[]\n# best_val=None\n# progress = tqdm(range(epocs))\n# for i in progress:\n#     tk=tqdm(train_dataloader, desc=\"Training epoch: \"+str(i+1))\n#     epoch_loss=0\n#     for j, (texts, labels) in enumerate(tk):\n#         texts = list(texts)\n#         labels = labels.to(device)\n        \n#         outputs = model(texts).logits\n# #         print(outputs.detach().cpu().numpy())\n# #         break\n#         loss = loss_fn(outputs, labels)\n#         epoch_loss += loss.item()\n        \n#         optimizer.zero_grad()\n#         loss.backward()\n#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n#         optimizer.step()\n#         scheduler.step()\n# #         break\n#     epoch_loss = epoch_loss/len(train_dataloader)\n#     val_loss = validate(model, val_dataloader, loss_fn)\n#     val_loss_history.append(val_loss)\n#     train_loss_history.append(epoch_loss)\n#     progress.set_postfix({'Epoch Loss': epoch_loss, 'Val Loss':val_loss})\n#     if (best_val==None or val_loss<best_val) and (i>=3):\n#         print(f\"Saving model at epoch {i+1}\")\n#         torch.save(model.state_dict(), f'model_epoch{i+1}')\n#     print(f'Epoch Loss {epoch_loss}, Val Loss {val_loss}')\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.558659Z","iopub.execute_input":"2021-06-27T06:16:12.559024Z","iopub.status.idle":"2021-06-27T06:16:12.564536Z","shell.execute_reply.started":"2021-06-27T06:16:12.558993Z","shell.execute_reply":"2021-06-27T06:16:12.5637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = ExcerptDataset(data[data['kfold']!=0], 'excerpt', 'target')\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset,\n    batch_size = 32,\n    num_workers = 4,\n    pin_memory = True,\n    shuffle = True,\n    drop_last = False\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.567237Z","iopub.execute_input":"2021-06-27T06:16:12.567645Z","iopub.status.idle":"2021-06-27T06:16:12.583547Z","shell.execute_reply.started":"2021-06-27T06:16:12.567618Z","shell.execute_reply":"2021-06-27T06:16:12.582803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Uncomment to do training","metadata":{}},{"cell_type":"code","source":"# from transformers import AdamW\n# epocs=6\n# train_loss_history=[]\n# val_loss_history=[]\n# best_val=None\n# progress = tqdm(range(epocs))\n# for fold in range(3):\n#     model=Model()\n#     train = data[data['kfold']!=fold]\n#     val = data[data['kfold']==fold]\n#     train_dataset = ExcerptDataset(train, 'excerpt', 'target')\n#     train_dataloader = torch.utils.data.DataLoader(\n#         train_dataset,\n#         batch_size = 32,\n#         num_workers = 4,\n#         pin_memory = True,\n#         shuffle = True,\n#         drop_last = False\n#     )\n#     val_dataset = ExcerptDataset(val, 'excerpt', 'target')\n#     val_dataloader = torch.utils.data.DataLoader(\n#         val_dataset,\n#         batch_size = 32,\n#         num_workers = 4,\n#         pin_memory = True,\n#         shuffle = True,\n#         drop_last = False\n#     )\n#     optimizer=AdamW(model.parameters(),\n#                   lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n#                   eps = 1e-8, # args.adam_epsilon  - default is 1e-8.\n#                   weight_decay= 1e-1\n#                 )\n#     loss_fn=nn.MSELoss()\n#     total_steps = len(train_dataloader)*epocs\n#     scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=1, num_training_steps=total_steps)\n#     print(\"Training Fold:\",(fold+1))\n#     best_val=999\n#     for i in progress:\n#         tk=tqdm(train_dataloader, desc=\"Training epoch: \"+str(i+1))\n#         epoch_loss=0\n#         for j, (texts, labels) in enumerate(tk):\n#             texts = list(texts)\n#             labels = labels.to(device)\n\n#             outputs = model(texts).logits\n#     #         print(outputs.detach().cpu().numpy())\n#     #         break\n#             loss = loss_fn(outputs, labels)\n#             epoch_loss += loss.item()\n\n#             optimizer.zero_grad()\n#             loss.backward()\n#             torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n#             optimizer.step()\n#             scheduler.step()\n#     #         break\n#         epoch_loss = epoch_loss/len(train_dataloader)\n#         val_loss = validate(model, val_dataloader, loss_fn)\n#         val_loss_history.append(val_loss)\n#         train_loss_history.append(epoch_loss)\n#         progress.set_postfix({'Epoch Loss': epoch_loss, 'Val Loss':val_loss})\n#         if (best_val==999 or val_loss<best_val):\n#             print(f\"Saving model at epoch {i+1}\")\n#             torch.save(model.state_dict(), f'model_fold{fold+1}')\n#             best_val=val_loss\n#         print(f'Epoch Loss {epoch_loss}, Val Loss {val_loss}')","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.58572Z","iopub.execute_input":"2021-06-27T06:16:12.586314Z","iopub.status.idle":"2021-06-27T06:16:12.591761Z","shell.execute_reply.started":"2021-06-27T06:16:12.58627Z","shell.execute_reply":"2021-06-27T06:16:12.590992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.plot(train_loss_history)\n# plt.plot(val_loss_history)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.592988Z","iopub.execute_input":"2021-06-27T06:16:12.593532Z","iopub.status.idle":"2021-06-27T06:16:12.604349Z","shell.execute_reply.started":"2021-06-27T06:16:12.593494Z","shell.execute_reply":"2021-06-27T06:16:12.603432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = ExcerptDataset(test, 'excerpt', submission=True)\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size = 2,\n    num_workers = 4,\n    pin_memory = True,\n    shuffle = False,\n    drop_last = False\n)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:12.605731Z","iopub.execute_input":"2021-06-27T06:16:12.606157Z","iopub.status.idle":"2021-06-27T06:16:12.613582Z","shell.execute_reply.started":"2021-06-27T06:16:12.606117Z","shell.execute_reply":"2021-06-27T06:16:12.612754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labels = []\nmodels = []\nfor fold in range(3):\n    model=Model()\n    model.eval()\n    model.load_state_dict(torch.load(f'../input/pretrained-readability/model_fold{fold+1}'))\n    models.append(model)\nfor fold in range(3):\n    labels=[]\n    for texts in test_dataloader:\n        with torch.no_grad():\n            output = models[fold](texts).logits\n            labels.extend(output.cpu().numpy())\n            \n    all_labels.append(labels)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:17:14.357498Z","iopub.execute_input":"2021-06-27T06:17:14.357971Z","iopub.status.idle":"2021-06-27T06:17:26.914205Z","shell.execute_reply.started":"2021-06-27T06:17:14.357928Z","shell.execute_reply":"2021-06-27T06:17:26.913126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_labels = np.array(all_labels, dtype=object)\n# print(all_labels)\nprint(\"All outputs\")\nall_labels = all_labels.reshape(3, -1).transpose()\nprint(all_labels)\nprint(\"Aggregated outputs\")\nmean_labels = np.mean(all_labels, axis=1)\nprint(mean_labels)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:17:26.917822Z","iopub.execute_input":"2021-06-27T06:17:26.918107Z","iopub.status.idle":"2021-06-27T06:17:26.927781Z","shell.execute_reply.started":"2021-06-27T06:17:26.918075Z","shell.execute_reply":"2021-06-27T06:17:26.926475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['target']=-1\ntest['target']=mean_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:25.917473Z","iopub.execute_input":"2021-06-27T06:16:25.918075Z","iopub.status.idle":"2021-06-27T06:16:25.925726Z","shell.execute_reply.started":"2021-06-27T06:16:25.918034Z","shell.execute_reply":"2021-06-27T06:16:25.924715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=test[['id', 'target']]\ntest","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:25.928358Z","iopub.execute_input":"2021-06-27T06:16:25.928654Z","iopub.status.idle":"2021-06-27T06:16:25.942634Z","shell.execute_reply.started":"2021-06-27T06:16:25.928628Z","shell.execute_reply":"2021-06-27T06:16:25.941745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:25.943821Z","iopub.execute_input":"2021-06-27T06:16:25.944265Z","iopub.status.idle":"2021-06-27T06:16:26.081906Z","shell.execute_reply.started":"2021-06-27T06:16:25.944143Z","shell.execute_reply":"2021-06-27T06:16:26.081066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2021-06-27T06:16:26.083221Z","iopub.execute_input":"2021-06-27T06:16:26.083547Z","iopub.status.idle":"2021-06-27T06:16:26.094168Z","shell.execute_reply.started":"2021-06-27T06:16:26.083511Z","shell.execute_reply":"2021-06-27T06:16:26.093271Z"},"trusted":true},"execution_count":null,"outputs":[]}]}