{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Augmentation and Excerpt-Target Correlation Analysis ðŸ”¥ðŸ”¥","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom pathlib import Path\nimport plotly.express as px\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install packages\n!pip install plotly statsmodels pandas numpy tokenizers nltk mosestokenizer transformers\n!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt -P data\n\nimport nltk\nnltk.download('perluniprops')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATADIR = Path(\"/kaggle/working/data\")\nFILEPATH = Path(\"/kaggle/input/commonlitreadabilityprize/train.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(FILEPATH)\ndf.tail(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.excerpt.apply(lambda x: len(x))\nY = df.target\nfig = px.scatter(x=X, y=Y, labels={'x': \"Length of sentence\", 'y': \"Target Value\"})\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see below, there is slight downslope. i.e. as the length of sentence increases the target is more negative. This is weird because as the length of sentence increses, it should be more difficult to read.","metadata":{}},{"cell_type":"code","source":"fig = px.scatter(x=X, y=Y, opacity=0.65, trendline='ols', trendline_color_override='red')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's also see the correlation between these two. Ah! as expected. A -ve correlation.","metadata":{}},{"cell_type":"code","source":"X.corr(Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Trying different tokenizers","metadata":{}},{"cell_type":"markdown","source":"### Levenshtein distance\n\nIn information theory, linguistics, and computer science, the Levenshtein distance is a string metric for measuring the difference between two sequences. Informally, the Levenshtein distance between two words is the minimum number of single-character edits required to change one word into the other. - *Wikipedia*","metadata":{}},{"cell_type":"code","source":"from Levenshtein import distance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = df.excerpt[2].replace('\\n', '').lower()\nprint(sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize words with BertWordPieceTokenizer","metadata":{}},{"cell_type":"code","source":"from tokenizers import BertWordPieceTokenizer\ntokenizer = BertWordPieceTokenizer('/kaggle/working/data/bert-base-uncased-vocab.txt', lowercase=True)\nprint(tokenizer)\nprint()\noutput = tokenizer.encode(sample)\ndecoded = tokenizer.decode(output.ids).replace('\" ', '\"').replace('? \"', '?\"').replace(' \"', '\"')\nprint(decoded)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The tokenizer seem to not recreate the exact same sentence from encoding and decoding. Is there a bug in tokenizer?\n\nThe distance will be zero if the two sentences exactly matches to each other.\n\nBut, here it is not zero =(","metadata":{}},{"cell_type":"code","source":"distance(decoded, sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Tokenize words with NLTK word_tokenize","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import word_tokenize\nfrom mosestokenizer import MosesDetokenizer\ntokens = word_tokenize(sample)\nprint(tokens)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"decoded = ' '.join(tokens)\nprint(decoded)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Worse results than BertWordPieceTokenizer","metadata":{}},{"cell_type":"code","source":"distance(decoded, sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Trying a decoder. But still not better than BertWordPieceTokenizer","metadata":{}},{"cell_type":"code","source":"detokenizer = MosesDetokenizer()\ndecoded2 = detokenizer(tokens)\ndistance(decoded2, sample)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation\n\n## Split the data into sentences and create new samples with target +- standard_error\n\n1. Convert sample paragraphs to single sentences.\n\n2. Suppose target = -0.340259 and standard_error = 0.464009. create *N* samples in the range  [(-0.340259 - 0.464009), (-0.340259 + 0.464009)] while leaving the excerpt same.\n","metadata":{}},{"cell_type":"code","source":"from nltk.tokenize import sent_tokenize\nfrom fastprogress import progress_bar\nimport random\n\nN = 10 # Number of new samples to generated from `target +- standard_error`","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, I'm splitting the paragraph to sentences but you can also use the whole paragraph.","metadata":{}},{"cell_type":"code","source":"newdf = {\"id\": [], \"excerpt\": [], \"target\":[], \"standard_error\": []}\nfor idx in progress_bar(range(len(df))):\n    row = df.iloc[idx]\n    sample_id, excerpt, target, standard_error = row.id, row.excerpt, row.target, row.standard_error\n    for i, sentence in enumerate(sent_tokenize(excerpt)): # Break paragraph into sentences\n        frac_error = standard_error * .10 # Taking only 10% of the original error to keep the target range narrow\n        _from, _to = target + frac_error, target - frac_error\n        for _ in range(N): # target +- standard_error random N values\n            new_target = random.uniform(_from, _to)\n            newdf[\"id\"].append(sample_id)\n            newdf[\"excerpt\"].append(sentence)\n            newdf[\"target\"].append(new_target)\n            newdf[\"standard_error\"].append(standard_error)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"newdf = pd.DataFrame.from_dict(newdf)\nnewdf.to_csv(f\"{DATADIR}/generated_data.csv\")\nprint(\"Number of training examples after augmentation =\", newdf.shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the each sample has one sentence (not paragraph).","metadata":{}},{"cell_type":"code","source":"newdf.sample(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"let's look at the correlation of new data","metadata":{}},{"cell_type":"code","source":"X = newdf.excerpt.apply(lambda x: len(x))\nY = newdf.target\nX.corr(Y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.scatter(x=X, y=Y, opacity=0.65, trendline='ols', trendline_color_override='red')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Please let me know in the comments if this information was helpful and the augmentation is useful!**\n\n*If you find this information useful, please <span style=\"color:green\">upvote</span> this notebook.*\n\n**That's all =)**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}