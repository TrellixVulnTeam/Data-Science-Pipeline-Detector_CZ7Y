{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\nfrom sklearn.metrics import classification_report\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModel\nfrom transformers import AutoConfig\nfrom sklearn.preprocessing import KBinsDiscretizer\nimport transformers\nfrom transformers import AutoModel, BertTokenizerFast\nfrom torch.utils.data import TensorDataset\nfrom torch.utils.tensorboard import SummaryWriter\nfrom torch.utils.data import Dataset\nimport random","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, hidden_dim=512):\n        super().__init__()\n        self.W = nn.Linear(768, 512)\n        self.V = nn.Linear(512, 1)\n        \n    def forward(self, features):\n        att = torch.tanh(self.W(features))\n        score = self.V(att)\n        attention_weights = torch.softmax(score, dim=1)\n        context_vector = attention_weights * features\n        context_vector = torch.sum(context_vector, dim=1)\n\n        return context_vector\n\nclass CLRPModel(nn.Module):\n    def __init__(self,transformer,config):\n        super(CLRPModel,self).__init__()\n        self.h_size = config.hidden_size\n        self.transformer = transformer\n        self.head = AttentionHead(self.h_size)\n        self.linear = nn.Linear(self.h_size, 1)\n              \n    def forward(self, input_ids, attention_mask):\n        transformer_out = self.transformer(input_ids, attention_mask)\n        x = self.head(transformer_out.last_hidden_state)\n        x = self.linear(x)\n        return x\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef convert_examples_to_features(text, tokenizer):\n\n    tok = tokenizer.encode_plus(\n        text, \n        max_length=Config.max_len, \n        truncation=True,\n        padding='max_length',\n    )\n    return tok\n\n\nclass CLRPDataset(Dataset):\n    def __init__(self, data, tokenizer, is_test=False):\n        self.data = data\n        self.excerpts = self.data.excerpt.tolist()\n        if not is_test:\n            self.targets = self.data.target.tolist()\n            \n        self.tokenizer = tokenizer\n        self.is_test = is_test\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, item):\n        if not self.is_test:\n            excerpt = self.excerpts[item]\n            label = self.targets[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n                'label':torch.tensor(label, dtype=torch.float),\n            }\n        else:\n            excerpt = self.excerpts[item]\n            features = convert_examples_to_features(\n                excerpt, self.tokenizer\n            )\n            return {\n                'input_ids':torch.tensor(features['input_ids'], dtype=torch.long),\n                'attention_mask':torch.tensor(features['attention_mask'], dtype=torch.long),\n            }\n        \n        \n        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass Config:\n    model_name = 'roberta-base'\n    pretrained_model_path = '../input/clrp-roberta-base/clrp_roberta_base'\n    output_hidden_states = True\n    epochs = 3\n    batch_size = 16\n    device = 'cuda'\n    seed = 42\n    max_len = 256\n\n\ntest_df = pd.read_csv(\"/kaggle/input/commonlitreadabilityprize/test.csv\")\ntest_df.head()\ntokenizer = torch.load('../input/tokenizers/roberta-tokenizer.pt')\n\nmodels_preds = []\nn_models = 5\n\n# config = AutoConfig.from_pretrained(Config.pretrained_model_path)\n# config.update({\n#     \"hidden_dropout_prob\": 0.0,\n#     \"layer_norm_eps\": 1e-7\n# }) \n    \n    \n# for model_num in range(n_models):\nfor model_num in [0]:\n    print(f'Inference#{model_num+1}/{n_models}')\n    test_ds = CLRPDataset(data=test_df, tokenizer=tokenizer, is_test=True)\n    test_sampler = SequentialSampler(test_ds)\n    test_dataloader = DataLoader(test_ds, sampler = test_sampler, batch_size=Config.batch_size)\n    \n    model = torch.load(f'../input/clrp-finetune/best_model_{model_num}.pt').to(Config.device)\n\n    all_preds = []\n    model.eval()\n\n    for step,batch in enumerate(test_dataloader):\n        sent_id, mask = batch['input_ids'].to(Config.device), batch['attention_mask'].to(Config.device)\n        with torch.no_grad():\n            preds = model(sent_id, mask)\n            all_preds += preds.flatten().cpu().tolist()\n    \n    models_preds.append(all_preds)\n    \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_preds = np.array(models_preds)\nprint(models_preds.shape)\nprint(models_preds)\nall_preds = models_preds.mean(axis=0)*1.2000005\nprint(all_preds.shape)\nresult_df = pd.DataFrame(\n    {\n        'id': test_df.id,\n        'target': all_preds\n    })\n\n\nresult_df.to_csv('/kaggle/working/submission.csv', index=False)\nresult_df.to_csv('submission.csv', index=False)\nresult_df.head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}