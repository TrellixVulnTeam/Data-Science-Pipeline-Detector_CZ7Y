{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch\nimport transformers\n\n!pip install textstat\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\ntorch.manual_seed(42)\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-03T07:03:48.668444Z","iopub.execute_input":"2021-08-03T07:03:48.668769Z","iopub.status.idle":"2021-08-03T07:03:55.992018Z","shell.execute_reply.started":"2021-08-03T07:03:48.66874Z","shell.execute_reply":"2021-08-03T07:03:55.991137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ntest = pd.read_csv(\"../input/commonlitreadabilityprize/test.csv\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:03:55.993849Z","iopub.execute_input":"2021-08-03T07:03:55.994225Z","iopub.status.idle":"2021-08-03T07:03:56.11283Z","shell.execute_reply.started":"2021-08-03T07:03:55.994182Z","shell.execute_reply":"2021-08-03T07:03:56.111869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nfig = plt.figure(figsize=(20,4))\n\nplt.subplot(221)\ntrain['target'].hist()\nplt.subplot(222)\nplt.scatter(train['target'],train['standard_error'])\nplt.subplot(223)\nplt.plot(train['target'])\nplt.show()\n\n#train['target'].hist(),train['target'].hist()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:03:56.115013Z","iopub.execute_input":"2021-08-03T07:03:56.115402Z","iopub.status.idle":"2021-08-03T07:03:56.504137Z","shell.execute_reply.started":"2021-08-03T07:03:56.115361Z","shell.execute_reply":"2021-08-03T07:03:56.503173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import textstat\n\nri=[textstat.textstat.automated_readability_index(i) for i in train['excerpt'].values ]\nrf=[textstat.textstat.flesch_reading_ease(i) for i in train['excerpt'].values ]\nrd=[textstat.textstat.dale_chall_readability_score_v2(i) for i in train['excerpt'].values ]\n\n\nfig = plt.figure(figsize=(20,4))\nplt.subplot(131)\nplt.scatter(ri,train['target'])\nplt.subplot(132)\nplt.scatter(rf,train['target'])\nplt.subplot(133)\nplt.scatter(rd,train['target'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:03:56.505777Z","iopub.execute_input":"2021-08-03T07:03:56.506136Z","iopub.status.idle":"2021-08-03T07:04:00.355664Z","shell.execute_reply.started":"2021-08-03T07:03:56.506097Z","shell.execute_reply":"2021-08-03T07:04:00.354737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenization","metadata":{}},{"cell_type":"code","source":"from transformers import AutoTokenizer\n\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:00.357Z","iopub.execute_input":"2021-08-03T07:04:00.357331Z","iopub.status.idle":"2021-08-03T07:04:06.776727Z","shell.execute_reply.started":"2021-08-03T07:04:00.357295Z","shell.execute_reply":"2021-08-03T07:04:06.775714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\n\nclass TextData(Dataset):\n    def __init__(self, text, labels, max_len=250):\n        self.text = text\n        self.labels = labels\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        \n    def __len__(self):\n        return len(self.text)\n    \n    def __getitem__(self, item):\n        tokenized_text = tokenizer(\n            self.text[item].replace('\\n', ''), max_length=self.max_len, truncation=True, \n            return_attention_mask=True, return_token_type_ids=True)\n        \n        padding_length = self.max_len - len(tokenized_text['input_ids'])\n        \n        return {\n            'input_ids':torch.tensor(tokenized_text['input_ids'] + ([0] * padding_length), dtype=torch.long),\n            #'token_type_ids':torch.tensor(tokenized_text['token_type_ids'] + ([0] * padding_length), dtype=torch.long),\n            'attention_mask':torch.tensor(tokenized_text['attention_mask'] + ([0] * padding_length), dtype=torch.long),\n            'label':torch.tensor(self.labels[item], dtype=torch.double),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:06.778225Z","iopub.execute_input":"2021-08-03T07:04:06.778636Z","iopub.status.idle":"2021-08-03T07:04:06.789891Z","shell.execute_reply.started":"2021-08-03T07:04:06.778594Z","shell.execute_reply":"2021-08-03T07:04:06.788742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.initial_seed()","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:06.791343Z","iopub.execute_input":"2021-08-03T07:04:06.792051Z","iopub.status.idle":"2021-08-03T07:04:06.802684Z","shell.execute_reply.started":"2021-08-03T07:04:06.792Z","shell.execute_reply":"2021-08-03T07:04:06.801681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data.dataset import random_split\n\ntorch.manual_seed(42)\n\ndataset = TextData(train['excerpt'].values, train['target'].values)\n\ntrain_dataset, valid_dataset = random_split(dataset, [2000,834])\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:06.805528Z","iopub.execute_input":"2021-08-03T07:04:06.805894Z","iopub.status.idle":"2021-08-03T07:04:06.811784Z","shell.execute_reply.started":"2021-08-03T07:04:06.805858Z","shell.execute_reply":"2021-08-03T07:04:06.810785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loaders = {\n    \"train\": DataLoader(train_dataset,shuffle=True, batch_size=16),\n    \"valid\": DataLoader(valid_dataset, batch_size=16)\n}","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:06.813645Z","iopub.execute_input":"2021-08-03T07:04:06.814116Z","iopub.status.idle":"2021-08-03T07:04:06.820736Z","shell.execute_reply.started":"2021-08-03T07:04:06.81404Z","shell.execute_reply":"2021-08-03T07:04:06.819597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from transformers import AutoModel\n\nclass ReadModel(torch.nn.Module): \n    def __init__(self):\n        super(ReadModel, self).__init__()\n        self.bert = AutoModel.from_pretrained('roberta-base', output_hidden_states=False)\n        self.dropout = torch.nn.Dropout(0.2)\n        self.hidden = net = torch.nn.Sequential(\n            torch.nn.Linear(768, 384),\n            torch.nn.LeakyReLU(),\n            torch.nn.Dropout(0.1),\n            torch.nn.Linear(384, 128),\n            torch.nn.LeakyReLU(),\n        )\n        self.regressor = torch.nn.Linear(128, 1)\n        \n    def forward(self, input_ids, attention_mask):\n        output = self.bert(input_ids,attention_mask)\n        output = output.last_hidden_state[:, 0]\n        output = self.dropout(output)\n        output = self.hidden(output)\n        logits = self.regressor(output)  \n        return logits ","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:06.822308Z","iopub.execute_input":"2021-08-03T07:04:06.822846Z","iopub.status.idle":"2021-08-03T07:04:06.831883Z","shell.execute_reply.started":"2021-08-03T07:04:06.822793Z","shell.execute_reply":"2021-08-03T07:04:06.831066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ReadModel()\n\nfor param in model.bert.embeddings.parameters():\n    param.requires_grad = False\n\nfor i in range(0,10):\n    for param in model.bert.encoder.layer[i].parameters():\n        param.requires_grad = False \n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:06.833209Z","iopub.execute_input":"2021-08-03T07:04:06.8336Z","iopub.status.idle":"2021-08-03T07:04:11.834454Z","shell.execute_reply.started":"2021-08-03T07:04:06.833563Z","shell.execute_reply":"2021-08-03T07:04:11.833654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Runner","metadata":{}},{"cell_type":"code","source":"import catalyst\nfrom catalyst import dl, metrics, utils\ncatalyst.__version__","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:11.835664Z","iopub.execute_input":"2021-08-03T07:04:11.836005Z","iopub.status.idle":"2021-08-03T07:04:11.841661Z","shell.execute_reply.started":"2021-08-03T07:04:11.835956Z","shell.execute_reply":"2021-08-03T07:04:11.8407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.nn import functional as F\n\nclass CustomRunner(dl.Runner):\n    \n    def predict_batch(self, batch):       \n        input_ids = batch['input_ids'].T.to(self.device)\n        #token_type_ids = batch['token_type_ids'].to(self.device)\n        attention_mask = batch['attention_mask'].T.to(self.device)\n        return self.model(input_ids, attention_mask)  #, token_type_ids\n    \n    def on_loader_start(self, runner):\n        super().on_loader_start(runner)\n        self.meters = {\n            key: metrics.AdditiveValueMetric(compute_on_call=False)\n            for key in [\"loss\", \"mae\"]\n        }\n\n    def handle_batch(self, batch):\n        \n        input_ids = batch['input_ids']\n        #token_type_ids = batch['token_type_ids']\n        attention_mask = batch['attention_mask']\n        \n        y = batch['label'].view(-1, 1).float()\n\n        y_pred = self.model(input_ids, attention_mask).view(-1, 1).float() #, token_type_ids\n        \n        self.batch = {'logits': y_pred, 'target': y}\n        \n        loss = F.mse_loss(y_pred.view(-1), y.view(-1))\n\n        self.batch_metrics.update({\"loss\": loss**0.5, \"mae\": F.l1_loss(y_pred, y)})\n        for key in [\"loss\", \"mae\"]:\n            self.meters[key].update(self.batch_metrics[key].item(), self.batch_size)\n\n        if self.is_train_loader:\n            loss.backward(retain_graph=True)\n            self.optimizer.step()\n            self.optimizer.zero_grad()\n    \n    def on_loader_end(self, runner):\n        for key in [\"loss\", \"mae\"]:\n            self.loader_metrics[key] = self.meters[key].compute()[0]\n        super().on_loader_end(runner)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:11.843201Z","iopub.execute_input":"2021-08-03T07:04:11.843921Z","iopub.status.idle":"2021-08-03T07:04:11.873615Z","shell.execute_reply.started":"2021-08-03T07:04:11.843853Z","shell.execute_reply":"2021-08-03T07:04:11.872723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"criterion = torch.nn.MSELoss()\n#optimizer = torch.optim.AdamW(model.parameters(), lr=0.00001)\n\noptimizer = torch.optim.AdamW([\n    {'params': model.bert.parameters(), 'lr': 0.00001},\n    {'params': model.hidden.parameters(), 'lr': 0.0001},\n    {'params': model.regressor.parameters(), 'lr': 0.0001}\n])\n\nrunner = CustomRunner()\n\nrunner.train(\n  model=model, \n  optimizer=optimizer, \n  loaders=loaders, \n  logdir=\"logs\",\n  valid_loader=\"valid\",\n  valid_metric=\"loss\",\n  num_epochs=10,\n  minimize_valid_metric=True,\n  verbose=True,\n  timeit=False,\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:04:11.87542Z","iopub.execute_input":"2021-08-03T07:04:11.875866Z","iopub.status.idle":"2021-08-03T07:14:23.527232Z","shell.execute_reply.started":"2021-08-03T07:04:11.875823Z","shell.execute_reply":"2021-08-03T07:14:23.526338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(runner.model.state_dict(), \"n2_model.pth\")\n#qmodel = utils.quantize_model(model=runner.model)\n#torch.save(qmodel.state_dict(), \"q1_model.pth\")","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:14:23.528573Z","iopub.execute_input":"2021-08-03T07:14:23.528924Z","iopub.status.idle":"2021-08-03T07:14:36.903241Z","shell.execute_reply.started":"2021-08-03T07:14:23.528876Z","shell.execute_reply":"2021-08-03T07:14:36.902173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluate","metadata":{}},{"cell_type":"code","source":"test_params = {\"batch_size\": 128*4,\n               \"shuffle\": False,\n               \"drop_last\": False}\n\n\nf = TextData(test['excerpt'].values,np.zeros(len(test)))\n\nf_generator = DataLoader(f, **test_params)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:14:36.908505Z","iopub.execute_input":"2021-08-03T07:14:36.910934Z","iopub.status.idle":"2021-08-03T07:14:36.928384Z","shell.execute_reply.started":"2021-08-03T07:14:36.910896Z","shell.execute_reply":"2021-08-03T07:14:36.927426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(model, data_loader):\n    model.eval()\n\n    result = np.zeros(len(data_loader.dataset))    \n    index = 0\n    \n    with torch.no_grad():\n        for item in data_loader:\n            input_ids = item['input_ids'].cuda()\n            attention_mask = item['attention_mask'].cuda()\n                        \n            pred = model(input_ids, attention_mask)                        \n\n            result[index : index + pred.shape[0]] = pred.flatten().cpu()\n            index += pred.shape[0]\n\n    return result","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:14:36.929799Z","iopub.execute_input":"2021-08-03T07:14:36.930326Z","iopub.status.idle":"2021-08-03T07:14:36.940181Z","shell.execute_reply.started":"2021-08-03T07:14:36.930276Z","shell.execute_reply":"2021-08-03T07:14:36.939327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict(runner.model,f_generator)","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:14:36.941465Z","iopub.execute_input":"2021-08-03T07:14:36.941868Z","iopub.status.idle":"2021-08-03T07:14:37.026841Z","shell.execute_reply.started":"2021-08-03T07:14:36.941833Z","shell.execute_reply":"2021-08-03T07:14:37.025943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre = pd.DataFrame({\n    'id': test.loc[:, 'id'].values,\n    'target': predict(runner.model,f_generator)\n})\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:14:37.028255Z","iopub.execute_input":"2021-08-03T07:14:37.02859Z","iopub.status.idle":"2021-08-03T07:14:37.10955Z","shell.execute_reply.started":"2021-08-03T07:14:37.028556Z","shell.execute_reply":"2021-08-03T07:14:37.108816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pre.to_csv('submission.csv', index=False)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-03T07:14:37.110779Z","iopub.execute_input":"2021-08-03T07:14:37.111117Z","iopub.status.idle":"2021-08-03T07:14:37.116271Z","shell.execute_reply.started":"2021-08-03T07:14:37.111083Z","shell.execute_reply":"2021-08-03T07:14:37.115446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}