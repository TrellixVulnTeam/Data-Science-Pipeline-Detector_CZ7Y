{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#========================================\n# library\n# ========================================\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import StratifiedKFold, KFold,GroupKFold\nfrom sklearn.metrics import mean_squared_error\n%matplotlib inline\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader, Subset\nfrom transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\nimport transformers\nfrom transformers import RobertaModel,RobertaTokenizer\nfrom transformers import AlbertModel,AlbertTokenizer\nfrom transformers import XLNetModel,XLNetTokenizer,XLNetConfig\nfrom transformers import DebertaModel, DebertaTokenizer\nfrom transformers import ElectraModel, ElectraTokenizer, ElectraForSequenceClassification\nfrom transformers import BartModel\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom transformers import MPNetModel,MPNetTokenizer\nfrom transformers import FunnelModel,FunnelTokenizer,FunnelBaseModel\nfrom transformers import LongformerModel, LongformerTokenizer,LongformerForSequenceClassification\nimport logging\nimport sys\nfrom contextlib import contextmanager\nimport time\nimport random\nfrom tqdm import tqdm\nimport os\nimport pickle\nimport gc","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:33:21.585073Z","iopub.execute_input":"2021-07-20T06:33:21.585405Z","iopub.status.idle":"2021-07-20T06:33:28.867242Z","shell.execute_reply.started":"2021-07-20T06:33:21.585331Z","shell.execute_reply":"2021-07-20T06:33:28.866382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ==================\n# Constant\n# ==================\nex = \"216\"\nTRAIN_PATH = \"../input/commonlitreadabilityprize/train.csvv\"\nLOGGER_PATH = f\"ex{ex}.txt\"\nFOLD_PATH = \"../input/fe001-step-1-create-folds/fe001_train_folds.csv\"\nMODEL_PATH_BASE = f\"ex{ex}\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:33:28.868699Z","iopub.execute_input":"2021-07-20T06:33:28.869035Z","iopub.status.idle":"2021-07-20T06:33:28.915034Z","shell.execute_reply.started":"2021-07-20T06:33:28.869001Z","shell.execute_reply":"2021-07-20T06:33:28.913925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ===============\n# Settings\n# ===============\nBATCH_SIZE = 4\nmax_len = 256\nMODEL_PATH_BASE = f\"ex{ex}\"\n\ndeberta_v2_xxlarge_MODEL_PATH = \"../input/deberta/v2-xxlarge\"\ndeberta_v2_xxlarge_tokenizer = AutoTokenizer.from_pretrained(deberta_v2_xxlarge_MODEL_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:35:03.738415Z","iopub.execute_input":"2021-07-20T06:35:03.738747Z","iopub.status.idle":"2021-07-20T06:35:03.970698Z","shell.execute_reply.started":"2021-07-20T06:35:03.738715Z","shell.execute_reply":"2021-07-20T06:35:03.966262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CommonLitDataset(Dataset):\n    def __init__(self, excerpt, tokenizer, max_len, target=None):\n        self.excerpt = excerpt\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n        self.target = target\n\n    def __len__(self):\n        return len(self.excerpt)\n\n    def __getitem__(self, item):\n        text = str(self.excerpt[item])\n        inputs = self.tokenizer(\n            text, \n            max_length=self.max_len, \n            padding=\"max_length\", \n            truncation=True,\n            return_attention_mask=True,\n            return_token_type_ids=True\n        )\n        ids = inputs[\"input_ids\"]\n        mask = inputs[\"attention_mask\"]\n        token_type_ids = inputs[\"token_type_ids\"]\n        if self.target is not None:\n            return {\n                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n                \"token_type_ids\" : torch.tensor(token_type_ids, dtype=torch.long),\n                \"target\" : torch.tensor(self.target[item], dtype=torch.float32)\n            }\n        else:\n            return {\n                \"input_ids\": torch.tensor(ids, dtype=torch.long),\n                \"attention_mask\": torch.tensor(mask, dtype=torch.long),\n                \"token_type_ids\" : torch.tensor(token_type_ids, dtype=torch.long)\n            }\n\nclass deberta_v2_xxlarge_model(nn.Module):\n    def __init__(self):\n        super(deberta_v2_xxlarge_model, self).__init__()\n        self.deberta_model =  AutoModel.from_pretrained(deberta_v2_xxlarge_MODEL_PATH, \n                                                        hidden_dropout_prob = 0,\n                                                        attention_probs_dropout_prob = 0)\n        \n        #self.dropout = nn.Dropout(p=0.2)\n        #self.ln = nn.LayerNorm(1536)\n        self.out = nn.Linear(1536, 1)\n    \n    def forward(self, ids, mask, token_type_ids):\n        # pooler\n        emb = self.deberta_model(ids, attention_mask=mask,token_type_ids=token_type_ids)['last_hidden_state'][:,0,:]\n        #output = self.ln(emb)\n        #output = self.dropout(output)\n        output = self.out(emb)\n        return output\n    \n    \ndef calc_loss(y_true, y_pred):\n    return  np.sqrt(mean_squared_error(y_true, y_pred))\n    \ndef set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\n\ndef setup_logger(out_file=None, stderr=True, stderr_level=logging.INFO, file_level=logging.DEBUG):\n    LOGGER.handlers = []\n    LOGGER.setLevel(min(stderr_level, file_level))\n\n    if stderr:\n        handler = logging.StreamHandler(sys.stderr)\n        handler.setFormatter(FORMATTER)\n        handler.setLevel(stderr_level)\n        LOGGER.addHandler(handler)\n\n    if out_file is not None:\n        handler = logging.FileHandler(out_file)\n        handler.setFormatter(FORMATTER)\n        handler.setLevel(file_level)\n        LOGGER.addHandler(handler)\n\n    LOGGER.info(\"logger set up\")\n    return LOGGER\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    yield \n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s')\n    \n    \nLOGGER = logging.getLogger()\nFORMATTER = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\nsetup_logger(out_file=LOGGER_PATH)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:35:03.973683Z","iopub.execute_input":"2021-07-20T06:35:03.97439Z","iopub.status.idle":"2021-07-20T06:35:04.026253Z","shell.execute_reply.started":"2021-07-20T06:35:03.974341Z","shell.execute_reply":"2021-07-20T06:35:04.025389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================\n# Main\n# ================================\ntrain = pd.read_csv(\"../input/commonlitreadabilityprize/train.csv\")\ny = train[\"target\"]\nfold_df = pd.read_csv(\"../input/fe001-step-1-create-folds/fe001_train_folds.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:35:04.061908Z","iopub.execute_input":"2021-07-20T06:35:04.062715Z","iopub.status.idle":"2021-07-20T06:35:04.166735Z","shell.execute_reply.started":"2021-07-20T06:35:04.062647Z","shell.execute_reply":"2021-07-20T06:35:04.165659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_array = fold_df[\"kfold\"].values","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:35:04.734732Z","iopub.execute_input":"2021-07-20T06:35:04.735105Z","iopub.status.idle":"2021-07-20T06:35:04.741668Z","shell.execute_reply.started":"2021-07-20T06:35:04.735074Z","shell.execute_reply":"2021-07-20T06:35:04.7385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ================================\n# train\n# ================================\nwith timer(\"roberta_large_model2\"):\n    #set_seed(SEED)\n    oof = np.zeros([len(train)])\n    #kf = KFold(n_splits=N_SPLITS, shuffle=SHUFFLE, random_state=SEED)\n    for fold in range(3):\n        x_val, y_val =train.iloc[fold_array == fold], y.iloc[fold_array == fold]\n        \n        # dataset\n        val_ = CommonLitDataset(x_val[\"excerpt\"].values, deberta_v2_xxlarge_tokenizer , max_len, y_val.values.reshape(-1,1))\n        \n        # loader\n        val_loader = DataLoader(dataset=val_, batch_size=BATCH_SIZE, shuffle = False , num_workers=4)\n        \n        # model\n        model =  deberta_v2_xxlarge_model()\n        model.load_state_dict(torch.load(f\"../input/commonlit-ex216/ex216_{fold}.pth\"))\n        model = model.to(device)\n        val_losses_batch = []\n        model.eval()  # switch model to the evaluation mode\n        val_preds = np.ndarray((0,1))\n        with torch.no_grad():  \n            # Predicting on validation set\n            for d in tqdm(val_loader):\n                # =========================\n                # data loader\n                # =========================\n                input_ids = d['input_ids']\n                mask = d['attention_mask']\n                token_type_ids = d[\"token_type_ids\"]\n                target = d[\"target\"]\n\n                input_ids = input_ids.to(device)\n                mask = mask.to(device)\n                token_type_ids = token_type_ids.to(device)\n                target = target.to(device)\n                output = model(input_ids, mask,token_type_ids )\n                val_preds = np.concatenate([val_preds, output.detach().cpu().numpy()], axis=0)\n\n\n\n        #val_loss = np.mean(val_losses_batch)\n        val_rmse = calc_loss(y_val, val_preds)\n        print(fold, val_rmse)\n\n        oof[fold_array == fold] = val_preds.reshape(-1)\n        torch.save(model.state_dict(), MODEL_PATH_BASE + f\"_{fold}.pth\")\n        del model\n        gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:35:06.461459Z","iopub.execute_input":"2021-07-20T06:35:06.46189Z","iopub.status.idle":"2021-07-20T06:45:19.456004Z","shell.execute_reply.started":"2021-07-20T06:35:06.461849Z","shell.execute_reply":"2021-07-20T06:45:19.454973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"calc_loss(y, oof)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T06:45:19.457644Z","iopub.execute_input":"2021-07-20T06:45:19.458032Z","iopub.status.idle":"2021-07-20T06:45:19.46589Z","shell.execute_reply.started":"2021-07-20T06:45:19.457985Z","shell.execute_reply":"2021-07-20T06:45:19.464945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}