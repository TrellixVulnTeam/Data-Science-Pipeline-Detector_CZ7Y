{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Context:\nThe extra-ordinary power of Transformer models comes from the fact that they can be used a feature extractor. Therefore I wanted to figure out what are the possible features one could extract from a transformer model and on top of it figure out what are all the additional features one could derive from it. To illustrate this, from a simple pretrained BERT base model I do the following:\n* Extract the following features\n    1. Pooler output\n    2. Hidden states of the transformer. (In the case of BERT base there are 12 hidden states)  \n    \n    \n    \n* Derive the following features from the hidden states:\n    1. Mean of the last hidden state (from n<sup>th</sup> layer)\n    2. Mean of the last but one hidden state (from n-1<sup>st</sup> layer)\n    3. Mean of the last but two hidden state (from n-2<sup>nd</sup> layer)\n    4. Hidden state corresponding to the CLS token of last hidden state (from n<sup>th</sup> layer)\n    5. Hidden state corresponding to the CLS token of last but one hidden state (from n-1<sup>st</sup> layer)\n    6. Hidden state corresponding to the CLS token of last but two hidden state (from n-2<sup>nd</sup> layer)\n    \n  \n# Objectives:\n1. To extract various features from a transformer model\n2. To derive many more features from the extracted features\n3. Evaluate the performance of the features on the given task\n\nA pre-trained BERT model is used to demonstrate this pipeline\n\n# Steps:\n1. Read train and test data\n2. Define Dataset and DataLoader\n3. Define the model\n4. Make sure the entire notebook can execute on CPU or CUDA\n5. Iterate through the train_dataloader and extract features\n6. Derive additional features from the extracted features\n7. Build a regressor and evaluate the various features","metadata":{}},{"cell_type":"code","source":"import json\nimport torch\nimport itertools\nimport numpy as np\nimport pandas as pd\nimport numpy.ma as ma\n\nfrom pathlib import Path\nfrom sklearn.svm import SVR\nfrom sklearn.linear_model import Ridge\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import BertTokenizer, BertModel\nfrom sklearn.model_selection import cross_val_score","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:47:48.724119Z","iopub.execute_input":"2021-06-03T13:47:48.724575Z","iopub.status.idle":"2021-06-03T13:47:51.476092Z","shell.execute_reply.started":"2021-06-03T13:47:48.724471Z","shell.execute_reply":"2021-06-03T13:47:51.475221Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_DATA_PATH = Path('../input/commonlitreadabilityprize')\nTRAIN_DATA_PATH = COMPETITION_DATA_PATH / 'train.csv'\nTEST_DATA_PATH = COMPETITION_DATA_PATH / 'test.csv'","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:47:51.477612Z","iopub.execute_input":"2021-06-03T13:47:51.478231Z","iopub.status.idle":"2021-06-03T13:47:51.483736Z","shell.execute_reply.started":"2021-06-03T13:47:51.478185Z","shell.execute_reply":"2021-06-03T13:47:51.482362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 32\nRANDOM_STATE = 41","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:47:54.960607Z","iopub.execute_input":"2021-06-03T13:47:54.961194Z","iopub.status.idle":"2021-06-03T13:47:54.966108Z","shell.execute_reply.started":"2021-06-03T13:47:54.961138Z","shell.execute_reply":"2021-06-03T13:47:54.96501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(TRAIN_DATA_PATH)\ntest_data = pd.read_csv(TEST_DATA_PATH)\n# Remove these lines before submission\n# train_data = train_data.sample(n=40, random_state=RANDOM_STATE)\ntrain_data = train_data.sort_values(by='excerpt', key=lambda x: x.str.len())\nprint(f'Length of train data: {len(train_data)}')\nprint(f'Length of test data: {len(test_data)}')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:47:56.584238Z","iopub.execute_input":"2021-06-03T13:47:56.584893Z","iopub.status.idle":"2021-06-03T13:47:56.740929Z","shell.execute_reply.started":"2021-06-03T13:47:56.584853Z","shell.execute_reply":"2021-06-03T13:47:56.739881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset and DataLoader creation","metadata":{}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, text_excerpts, targets):\n        self.text_excerpts = text_excerpts\n        self.targets = targets\n    \n    def __len__(self):\n        return len(self.text_excerpts)\n    \n    def __getitem__(self, idx):\n        return {'text_excerpt': self.text_excerpts[idx], 'target': self.targets[idx]}\n    \nclass PredictionDataset(Dataset):\n    def __init__(self, text_excerpts):\n        self.text_excerpts = text_excerpts\n    \n    def __len__(self):\n        return len(self.text_excerpts)\n    \n    def __getitem__(self, idx):\n        return {'text_excerpt': self.text_excerpts[idx]}","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:47:59.056639Z","iopub.execute_input":"2021-06-03T13:47:59.057036Z","iopub.status.idle":"2021-06-03T13:47:59.064235Z","shell.execute_reply.started":"2021-06-03T13:47:59.057004Z","shell.execute_reply":"2021-06-03T13:47:59.063266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = TrainDataset(text_excerpts=train_data['excerpt'].tolist(),\n                             targets=train_data['target'].tolist())\ntest_dataset = PredictionDataset(text_excerpts=test_data['excerpt'].tolist())\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:48:00.336408Z","iopub.execute_input":"2021-06-03T13:48:00.337156Z","iopub.status.idle":"2021-06-03T13:48:00.345282Z","shell.execute_reply.started":"2021-06-03T13:48:00.337094Z","shell.execute_reply":"2021-06-03T13:48:00.344075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model definition","metadata":{}},{"cell_type":"code","source":"%%capture\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertModel.from_pretrained('bert-base-uncased')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:48:07.618292Z","iopub.execute_input":"2021-06-03T13:48:07.618671Z","iopub.status.idle":"2021-06-03T13:48:16.461575Z","shell.execute_reply.started":"2021-06-03T13:48:07.618638Z","shell.execute_reply":"2021-06-03T13:48:16.460548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nmodel.eval()\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:48:16.464393Z","iopub.execute_input":"2021-06-03T13:48:16.464894Z","iopub.status.idle":"2021-06-03T13:48:16.482138Z","shell.execute_reply.started":"2021-06-03T13:48:16.46484Z","shell.execute_reply":"2021-06-03T13:48:16.480849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extract and Derive features\nThe mean of the hidden state has to be calculated carefully after masking the hidden states corresponding to the PAD token","metadata":{}},{"cell_type":"code","source":"def derive_cls_hidden_state(hidden_state):\n    return np.asarray(hidden_state)[:,0,:]\n\ndef mask_and_compute_mean_hidden_state(hidden_state, attention_mask):\n    vector_size = hidden_state.shape[-1]\n    attention_mask = np.expand_dims(attention_mask, axis=2)\n    attention_mask = attention_mask == 0\n    tiled_attention_mask = np.tile(attention_mask, reps=[1, 1, vector_size])\n    masked_hidden_state = ma.array(hidden_state, mask=tiled_attention_mask)\n    mean_masked_hidden_state = masked_hidden_state.mean(axis=1).data\n    return mean_masked_hidden_state\n\ndef extract_and_derive_features(dataloader):\n    features = {'pooler_output': [],\n                'mean_last_hidden_state': [],\n                'mean_last_but_one_hidden_state': [],\n                'mean_last_but_two_hidden_state': [],\n                'cls_last_hidden_state': [],\n                'cls_last_but_one_hidden_state': [],\n                'cls_last_but_two_hidden_state': []}\n    \n    for batch_num, batch in enumerate(dataloader):\n        text_excerpts_batch = batch['text_excerpt']\n        with torch.no_grad():\n            inputs = tokenizer(text_excerpts_batch, return_tensors='pt', padding=True, truncation=True)\n            inputs = inputs.to(device)\n            outputs = model(**inputs, output_attentions=False, output_hidden_states=True)\n            attention_mask = inputs['attention_mask'].detach().cpu().numpy()\n            # Extract features\n            pooler_output = outputs['pooler_output'].detach().cpu().numpy()\n            last_but_two_hidden_state, last_but_one_hidden_state,  last_hidden_state = [hidden_state.detach().cpu().numpy() for hidden_state in outputs['hidden_states'][-3:]]\n            # Derive features\n            mean_last_hidden_state = mask_and_compute_mean_hidden_state(last_hidden_state, attention_mask)\n            mean_last_but_one_hidden_state = mask_and_compute_mean_hidden_state(last_but_one_hidden_state, attention_mask)\n            mean_last_but_two_hidden_state = mask_and_compute_mean_hidden_state(last_but_two_hidden_state, attention_mask)\n            cls_last_hidden_state = derive_cls_hidden_state(last_hidden_state)\n            cls_last_but_one_hidden_state = derive_cls_hidden_state(last_but_one_hidden_state)\n            cls_last_but_two_hidden_state = derive_cls_hidden_state(last_but_two_hidden_state)\n            # Append features\n            features['pooler_output'].extend(pooler_output.tolist())\n            features['mean_last_hidden_state'].extend(mean_last_hidden_state.tolist())\n            features['mean_last_but_one_hidden_state'].extend(mean_last_but_one_hidden_state.tolist())\n            features['mean_last_but_two_hidden_state'].extend(mean_last_but_two_hidden_state.tolist())\n            features['cls_last_hidden_state'].extend(cls_last_hidden_state.tolist())\n            features['cls_last_but_one_hidden_state'].extend(cls_last_but_one_hidden_state.tolist())\n            features['cls_last_but_two_hidden_state'].extend(cls_last_but_two_hidden_state.tolist())       \n    features = {key: np.asarray(value) for key, value in features.items()}\n    return features","metadata":{"execution":{"iopub.status.busy":"2021-06-03T13:48:49.574711Z","iopub.execute_input":"2021-06-03T13:48:49.575309Z","iopub.status.idle":"2021-06-03T13:48:49.590763Z","shell.execute_reply.started":"2021-06-03T13:48:49.57527Z","shell.execute_reply":"2021-06-03T13:48:49.58989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ntrain_features = extract_and_derive_features(train_dataloader)\ntest_features = extract_and_derive_features(test_dataloader)\n\ntrain_targets = [batch['target'].detach().cpu().tolist() for batch in train_dataloader]\ntrain_targets = list(itertools.chain(*train_targets))","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:13:36.332439Z","iopub.execute_input":"2021-06-02T16:13:36.332937Z","iopub.status.idle":"2021-06-02T16:14:32.348376Z","shell.execute_reply.started":"2021-06-02T16:13:36.3329Z","shell.execute_reply":"2021-06-02T16:14:32.34749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Fit regressor","metadata":{}},{"cell_type":"code","source":"for key in train_features.keys():\n    regressor = SVR(C=10, kernel='rbf', gamma='auto')\n#     regressor = Ridge(fit_intercept=True, normalize=False)\n    scores = cross_val_score(regressor, train_features[key], train_targets, cv=5, scoring='neg_root_mean_squared_error')\n    print(f'{key}: Average Root mean squared error: {np.abs(np.mean(scores))}')","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:14:32.352101Z","iopub.execute_input":"2021-06-02T16:14:32.354195Z","iopub.status.idle":"2021-06-02T16:14:34.661325Z","shell.execute_reply.started":"2021-06-02T16:14:32.354154Z","shell.execute_reply":"2021-06-02T16:14:34.660195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_feature = 'mean_last_hidden_state'\nregressor = regressor.fit(train_features[best_feature], train_targets)\n\ntest_data = pd.read_csv(TEST_DATA_PATH)\ntest_data['target'] = regressor.predict(test_features[best_feature])\ntest_data[['id','target']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T16:14:34.662972Z","iopub.execute_input":"2021-06-02T16:14:34.663665Z","iopub.status.idle":"2021-06-02T16:14:34.992866Z","shell.execute_reply.started":"2021-06-02T16:14:34.66362Z","shell.execute_reply":"2021-06-02T16:14:34.992058Z"},"trusted":true},"execution_count":null,"outputs":[]}]}