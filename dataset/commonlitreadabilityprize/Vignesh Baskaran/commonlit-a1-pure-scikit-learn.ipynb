{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Objectives\n1. Develop a strong baseline using nothing more than **Scikit-learn**\n2. Inspect into the top features of the regression model\n3. Search for the best pipelines and the corresponding hyper-parameters using GridSearch\n4. Discuss the interesting observations\n\n# Pipelines to be evaluated\n1. TFIDF vectorizer -> Linear Regression\n2. TFIDF vectorizer -> Ridge Regression\n3. TFIDF vectorizer -> TruncatedSVD -> Linear Regression\n4. TFIDF vectorizer -> TruncatedSVD -> Ridge Regression\n\n# Spolier alert of interesting observations\n1. One peculiar observation is that the **top negative features of the regression model contain a lot of stop words** \n2. Removing the stop words results in an inferior performance which I guess is because, well structured sentences consists predominantly of conjunctions, articles etc. which are in fact in the list of stop words\n3. The performance of the model with dimensionality reduction is superior to the model without dimensionality reduction\n4. Normalizing the data before passing on to the regressors achieves superior performance\n5. Best model **Without** SVD -> **Ridge regression**\n6. Best model **With** SVD -> **Linear Regression**. So this implies that SVD does reduce noise and substitutes regularization","metadata":{}},{"cell_type":"code","source":"import string\nimport pandas as pd\n\nfrom pathlib import Path\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.feature_extraction.text import TfidfVectorizer","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_DATA_PATH = Path('../input/commonlitreadabilityprize')\nTRAIN_DATA_PATH = COMPETITION_DATA_PATH / 'train.csv'\nTEST_DATA_PATH = COMPETITION_DATA_PATH / 'test.csv'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(TRAIN_DATA_PATH)\ntrain_data = train_data[['excerpt', 'target']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_text(text):\n    # Strip punctuations\n    text = text.translate(str.maketrans('', '', string.punctuation))\n    return text","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline without Dimensionality reduction\n\nTo inspect word features","metadata":{}},{"cell_type":"code","source":"pipeline_without_svd = Pipeline([('vectorizer', 'passthrough'),\n                                 ('regressor', 'passthrough')])\n\nparam_grid = {'vectorizer': [TfidfVectorizer(preprocessor=preprocess_text)],\n              'regressor':  [LinearRegression(), Ridge()],\n              \n              'vectorizer__stop_words': [None, 'english'],\n              'vectorizer__min_df': [5, 7, 9],\n              'vectorizer__ngram_range': [(1, 2), (1, 3)],\n              \n              'regressor__fit_intercept': [True, False],\n              'regressor__normalize': [True, False]}\n\nsearch_without_svd = GridSearchCV(pipeline_without_svd, param_grid, cv=3,\n                                  n_jobs=-1, scoring='neg_root_mean_squared_error')\nsearch_without_svd.fit(X=train_data['excerpt'], y=train_data['target'])\n\nprint(\"Best parameter (CV score=%0.3f):\" % search_without_svd.best_score_)\nprint(search_without_svd.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Top features","metadata":{}},{"cell_type":"code","source":"best_pipeline_without_svd = search_without_svd.best_estimator_\n\nvectorizer_features = best_pipeline_without_svd['vectorizer'].get_feature_names()\nmodel_weights = best_pipeline_without_svd['regressor'].coef_\n\nprint('Top positive features')\nfor weight, feature in sorted(zip(model_weights, vectorizer_features))[::-1][:10]:\n    print(f'Feature: {feature}: {weight:.2f}')\n    \nprint(5*'--------------------')\n\nprint('Top negative features')\nfor weight, feature in sorted(zip(model_weights, vectorizer_features))[:10]:\n    print(f'Feature: {feature}: {weight:.2f}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline with Dimensionality reduction","metadata":{}},{"cell_type":"code","source":"pipeline_with_svd = Pipeline([('vectorizer', 'passthrough'),\n                              ('svd', 'passthrough'),\n                              ('regressor', 'passthrough')])\n\nparam_grid = {'vectorizer': [TfidfVectorizer(preprocessor=preprocess_text)],\n              'svd': [TruncatedSVD()],\n              'regressor':  [LinearRegression(), Ridge()],\n              \n              'vectorizer__stop_words': [None, 'english'],\n              'vectorizer__min_df': [3, 5, 7],\n              'vectorizer__ngram_range': [(1, 2), (1, 3)],\n              \n              'svd__n_components': [700, 800],\n              \n              'regressor__fit_intercept': [True, False],\n              'regressor__normalize': [True, False]}\n\nsearch_with_svd = GridSearchCV(pipeline_with_svd, param_grid, cv=3,\n                                  n_jobs=-1, scoring='neg_root_mean_squared_error')\nsearch_with_svd.fit(X=train_data['excerpt'], y=train_data['target'])\n\nprint(\"Best parameter (CV score=%0.3f):\" % search_with_svd.best_score_)\nprint(search_with_svd.best_params_)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Repeating the Interesting observations\n1. One peculiar observation is that the top features of the regression model contain a lot of stop words \n2. Removing the stop words results in an inferior performance which I guess is because well structured sentences consists predominantly of conjunctions, articles etc. which are in fact in the list of stop words\n3. The performance of the model with dimensionality reduction is superior to the model without dimensionality reduction\n4. Normalizing the data before passing on to the regressors achieves superior performance\n5. Best model **Without** SVD -> Ridge regression where Best model **with** SVD -> Linear Regression. So this implies that SVD does reduce noise and substitutes regularization","metadata":{}},{"cell_type":"markdown","source":"# Predicting with the best pipeline","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(TEST_DATA_PATH)\ntest_data['target'] = search_with_svd.predict(test_data['excerpt'])\ntest_data[['id','target']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}