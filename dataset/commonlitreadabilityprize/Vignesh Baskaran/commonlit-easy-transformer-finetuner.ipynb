{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Objective\nThe objective of this notebook is to set up the easiest and fastest notebook to quickly finetune a transformer model and make a submission. This notebook contains only the bare minimum transparent code necessary with no external trainer functions. Although the notebook is simple, it includes all the components to train a model such as :\n1. Early stopping\n2. Model Saver\n3. Kfold Cross-validation\n\nInference notebook: https://www.kaggle.com/vigneshbaskaran/commonlit-easy-finetuner-inference\n\n# Plan\n1. Define model\n2. Define Dataset and DataLoader\n3. Define training and evaluation loop\n4. Create cross-validation folds\n5. For each fold: Train -> Save best model\n6. Make predictions and submit","metadata":{"_uuid":"6d4efe8c-84a5-44c4-82e1-39daca6f0c54","_cell_guid":"182d14e1-810d-493d-94d7-3ffbc4a56d7f","trusted":true}},{"cell_type":"code","source":"import gc\nimport torch\nimport numpy as np\nimport pandas as pd\nfrom torch import nn\n\nfrom pathlib import Path\nfrom sklearn.model_selection import KFold\nfrom transformers.file_utils import ModelOutput\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AdamW, AutoTokenizer, AutoModel\nfrom transformers import BertModel, BertPreTrainedModel, RobertaModel\nfrom transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel","metadata":{"_uuid":"dffb8ebd-33e6-4cc3-b0c4-3f6a4275ad24","_cell_guid":"f137055a-d64c-47ce-94d3-231c0c5a539a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:10.579268Z","iopub.execute_input":"2021-06-10T15:16:10.579681Z","iopub.status.idle":"2021-06-10T15:16:13.446584Z","shell.execute_reply.started":"2021-06-10T15:16:10.579595Z","shell.execute_reply":"2021-06-10T15:16:13.445712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_DATA_PATH = Path('../input/commonlitreadabilityprize')\nTRAIN_DATA_PATH = COMPETITION_DATA_PATH / 'train.csv'\nTEST_DATA_PATH = COMPETITION_DATA_PATH / 'test.csv'","metadata":{"_uuid":"618fe0d4-c3ec-4a90-accf-08436497e92f","_cell_guid":"a9a96d5a-0180-4bc8-9d04-fd85ca0f4f0d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.448459Z","iopub.execute_input":"2021-06-10T15:16:13.448787Z","iopub.status.idle":"2021-06-10T15:16:13.45401Z","shell.execute_reply.started":"2021-06-10T15:16:13.448759Z","shell.execute_reply":"2021-06-10T15:16:13.453089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Dataset and DataLoader","metadata":{}},{"cell_type":"code","source":"class TrainingDataset(Dataset):\n    def __init__(self, text_excerpts, targets):\n        self.text_excerpts = text_excerpts\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.text_excerpts)\n    \n    def __getitem__(self, idx):\n        sample = {'text_excerpt': self.text_excerpts[idx],\n                  'target': self.targets[idx]}\n        return sample\n    \nclass PredictionDataset(Dataset):\n    def __init__(self, text_excerpts):\n        self.text_excerpts = text_excerpts\n        \n    def __len__(self):\n        return len(self.text_excerpts)\n    \n    def __getitem__(self, idx):\n        sample = {'text_excerpt': self.text_excerpts[idx]}\n        return sample","metadata":{"_uuid":"e195eb71-a0f4-4dd5-89b0-0c1963e7276b","_cell_guid":"82fbbf0c-b2fd-4c70-8d48-e31e48dae4c4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.455943Z","iopub.execute_input":"2021-06-10T15:16:13.456576Z","iopub.status.idle":"2021-06-10T15:16:13.465545Z","shell.execute_reply.started":"2021-06-10T15:16:13.456537Z","shell.execute_reply":"2021-06-10T15:16:13.464599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def transform_targets(targets):\n    targets = targets.astype(np.float32).reshape(-1, 1)\n    return targets","metadata":{"_uuid":"3d9d91d2-3204-4c31-8314-3769c9939c7e","_cell_guid":"483a120c-3339-4177-bf62-afe5a21e1dc4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.466646Z","iopub.execute_input":"2021-06-10T15:16:13.466896Z","iopub.status.idle":"2021-06-10T15:16:13.476978Z","shell.execute_reply.started":"2021-06-10T15:16:13.466872Z","shell.execute_reply":"2021-06-10T15:16:13.475962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_training_dataloader(data, batch_size, shuffle):\n    text_excerpts = data['excerpt'].tolist()\n    targets = transform_targets(data['target'].to_numpy())\n    dataset = TrainingDataset(text_excerpts=text_excerpts, targets=targets)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n    return dataloader","metadata":{"_uuid":"b0317ac2-732b-4d9a-941a-900c5fee9b25","_cell_guid":"31208be4-ae7a-407d-9a08-5966f8a73af4","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.479412Z","iopub.execute_input":"2021-06-10T15:16:13.480038Z","iopub.status.idle":"2021-06-10T15:16:13.488115Z","shell.execute_reply.started":"2021-06-10T15:16:13.47999Z","shell.execute_reply":"2021-06-10T15:16:13.487194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_prediction_dataloader(data, batch_size):\n    text_excerpts = data['excerpt'].tolist()\n    dataset = PredictionDataset(text_excerpts=text_excerpts)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    return dataloader","metadata":{"_uuid":"aa9498c0-a441-45d7-b369-232a8a76587d","_cell_guid":"6df0bbae-488a-4771-8190-1b80359935ec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.48929Z","iopub.execute_input":"2021-06-10T15:16:13.489625Z","iopub.status.idle":"2021-06-10T15:16:13.503772Z","shell.execute_reply.started":"2021-06-10T15:16:13.489597Z","shell.execute_reply":"2021-06-10T15:16:13.502763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_into_kfolds(data, n_splits, shuffle, random_state):\n    kf = KFold(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n    for train_indices, valid_indices in kf.split(data):\n        yield data.iloc[train_indices], data.iloc[valid_indices]","metadata":{"_uuid":"7bc37336-0007-4b6c-b853-0436f1bf2e50","_cell_guid":"104f7966-da76-44a3-bee3-0736a6935b8e","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.50657Z","iopub.execute_input":"2021-06-10T15:16:13.507222Z","iopub.status.idle":"2021-06-10T15:16:13.514047Z","shell.execute_reply.started":"2021-06-10T15:16:13.507181Z","shell.execute_reply":"2021-06-10T15:16:13.513052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Metric, EarlyStopping, Saver, Monitor","metadata":{"_uuid":"3aef81b0-ddee-4cbf-8bd4-81eaf0398277","_cell_guid":"2f757234-985d-456d-b48e-ca22da1498d4","trusted":true}},{"cell_type":"code","source":"class Metric:\n    def __init__(self):\n        self.sse = 0\n        self.num_samples = 0\n    \n    def update(self, targets, predictions):\n        self.sse += np.sum(np.square(targets - predictions))\n        self.num_samples += len(targets)\n    \n    def get_rmse(self):\n        rmse = np.sqrt(self.sse / self.num_samples)\n        return rmse","metadata":{"_uuid":"275d13d1-54ae-4d75-8b0f-3eccbe9fc78d","_cell_guid":"256e58be-7adf-42f0-9909-d8e47b74f518","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.51883Z","iopub.execute_input":"2021-06-10T15:16:13.519135Z","iopub.status.idle":"2021-06-10T15:16:13.525889Z","shell.execute_reply.started":"2021-06-10T15:16:13.519096Z","shell.execute_reply":"2021-06-10T15:16:13.524852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Monitor:\n    def __init__(self, num_patient_epochs):\n        self.num_patient_epochs = num_patient_epochs\n        self.best_epoch_num = None\n        self.best_score = np.inf\n        self.best_model = None\n        \n    def early_stopping(self, current_epoch_num):\n        return True if current_epoch_num > self.best_epoch_num + self.num_patient_epochs else False\n        \n    def update_best_model(self, current_epoch_num, score, model, tokenizer, save_name):\n        if score < self.best_score:\n            self.best_epoch_num = current_epoch_num\n            self.best_score = score\n            self.best_model = model\n            model.save_pretrained(save_name)\n            tokenizer.save_pretrained(save_name)","metadata":{"_uuid":"e456db15-d05a-4e84-a9ba-ee8b09e33454","_cell_guid":"46479a73-d379-4f25-a5cd-ad3b5ada71f5","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.528654Z","iopub.execute_input":"2021-06-10T15:16:13.529017Z","iopub.status.idle":"2021-06-10T15:16:13.537608Z","shell.execute_reply.started":"2021-06-10T15:16:13.52898Z","shell.execute_reply":"2021-06-10T15:16:13.536689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class KfoldMonitor:\n    def __init__(self):\n        self.fold_monitor = {}\n        \n    def update(self, fold, monitor):\n        self.fold_monitor[fold] = monitor","metadata":{"_uuid":"5f14c018-4f9a-4a8a-92c1-6e2e0e5fdc7b","_cell_guid":"1a689e3d-d358-4dac-955c-9f1b37cbc7a9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.539108Z","iopub.execute_input":"2021-06-10T15:16:13.539694Z","iopub.status.idle":"2021-06-10T15:16:13.546447Z","shell.execute_reply.started":"2021-06-10T15:16:13.539655Z","shell.execute_reply":"2021-06-10T15:16:13.545672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define training, validation and testing loops","metadata":{"_uuid":"1b9513c7-0e99-4f8c-a8fd-73f4da6e398e","_cell_guid":"94800bbc-831c-4069-bb0d-fdd2c99e29dd","trusted":true}},{"cell_type":"code","source":"def train(dataloader, model, tokenizer, optimizer, device):\n    model.train()\n    epoch_loss = 0\n    for batch_num, batch in enumerate(dataloader):\n        # Forward prop\n        inputs = tokenizer(batch['text_excerpt'], padding=True, truncation=True, return_tensors=\"pt\")\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n        targets = batch['target'].to(device)\n        outputs = model(**inputs, labels=targets)\n        epoch_loss += outputs.loss.item()\n        # Backprop\n        outputs.loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n    average_epoch_loss = epoch_loss / len(dataloader)\n    return model, average_epoch_loss","metadata":{"_uuid":"1485983d-40ac-4e3e-a071-9c4c31159a2c","_cell_guid":"2b68f503-f42e-4229-87ed-07403a738af0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.548816Z","iopub.execute_input":"2021-06-10T15:16:13.549816Z","iopub.status.idle":"2021-06-10T15:16:13.560826Z","shell.execute_reply.started":"2021-06-10T15:16:13.549784Z","shell.execute_reply":"2021-06-10T15:16:13.559788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(dataloader, model, tokenizer, device):\n    model.eval()\n    epoch_loss = 0\n    metric = Metric()\n    for batch_num, batch in enumerate(dataloader):\n        inputs = tokenizer(batch['text_excerpt'], padding=True, truncation=True, return_tensors=\"pt\")\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n        targets = batch['target'].to(device)\n        with torch.no_grad():\n            outputs = model(**inputs, labels=targets)\n        epoch_loss += outputs.loss.item()\n        targets = targets.detach().cpu().numpy()\n        predictions = outputs.logits.detach().cpu().numpy()\n        metric.update(targets=targets, predictions=predictions)\n    average_epoch_loss = epoch_loss / len(dataloader)\n    return average_epoch_loss, metric","metadata":{"_uuid":"9d89ee01-97d7-4aeb-b174-5bf91eed35e7","_cell_guid":"3c1213af-3920-45a6-afd9-a4776fe8e8ae","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.562342Z","iopub.execute_input":"2021-06-10T15:16:13.56276Z","iopub.status.idle":"2021-06-10T15:16:13.571802Z","shell.execute_reply.started":"2021-06-10T15:16:13.56272Z","shell.execute_reply":"2021-06-10T15:16:13.570883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(dataloader, model, tokenizer, device):\n    model.eval()\n    predictions = []\n    for batch_num, batch in enumerate(dataloader):\n        inputs = tokenizer(batch['text_excerpt'], padding=True, truncation=True, return_tensors=\"pt\")\n        inputs = {key: value.to(device) for key, value in inputs.items()}\n        with torch.no_grad():\n            outputs = model(**inputs)\n        batch_predictions = outputs.logits.detach().cpu().numpy()\n        predictions.append(batch_predictions)\n    predictions = np.vstack(predictions)\n    return predictions","metadata":{"_uuid":"92ef7281-3dbe-4ff0-892a-a3e388cf836a","_cell_guid":"2107311e-d407-41ad-9263-b2cd4a97b30b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.573215Z","iopub.execute_input":"2021-06-10T15:16:13.573854Z","iopub.status.idle":"2021-06-10T15:16:13.581954Z","shell.execute_reply.started":"2021-06-10T15:16:13.57381Z","shell.execute_reply":"2021-06-10T15:16:13.581053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{"_uuid":"e075e4e2-0fda-4619-a630-c33c3d7ebfd5","_cell_guid":"2537e644-f2e8-406e-9eb6-768fc914e781","trusted":true}},{"cell_type":"code","source":"class RegressorOutput(ModelOutput):\n    loss = None\n    logits = None\n    hidden_states = None\n    attentions = None","metadata":{"_uuid":"76057597-7df2-41e7-9e68-ca6cedd7c9e7","_cell_guid":"81ca7213-a9c5-4584-9875-a3d226673420","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.5833Z","iopub.execute_input":"2021-06-10T15:16:13.583702Z","iopub.status.idle":"2021-06-10T15:16:13.594536Z","shell.execute_reply.started":"2021-06-10T15:16:13.583662Z","shell.execute_reply":"2021-06-10T15:16:13.593433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BertPoolerRegressor(BertPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        \n        self.bert = BertModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.regressor = nn.Linear(config.hidden_size, 1)\n        self.loss_fct = nn.MSELoss()\n        self.init_weights()\n        \n    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None):\n        bert_outputs = self.bert(input_ids=input_ids,\n                                 attention_mask=attention_mask,\n                                 token_type_ids=token_type_ids)\n        pooler_output = bert_outputs['pooler_output']\n        pooler_output = self.dropout(pooler_output)\n        logits = self.regressor(pooler_output)\n        loss = self.loss_fct(labels, logits) if labels is not None else None\n        return RegressorOutput(loss=loss, logits=logits)","metadata":{"_uuid":"eb1ce4b3-209c-4913-8205-13ea551c4f30","_cell_guid":"44516b36-e725-4bac-9671-09c7ff98ed06","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.596551Z","iopub.execute_input":"2021-06-10T15:16:13.596832Z","iopub.status.idle":"2021-06-10T15:16:13.608288Z","shell.execute_reply.started":"2021-06-10T15:16:13.596777Z","shell.execute_reply":"2021-06-10T15:16:13.607438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaPoolerRegressor(RobertaPreTrainedModel):\n    def __init__(self, config):\n        super().__init__(config)\n        \n        self.roberta = RobertaModel(config)\n        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n        self.regressor = nn.Linear(config.hidden_size, 1)\n        self.loss_fct = nn.MSELoss()\n        self.init_weights()\n        \n    def forward(self, input_ids=None, attention_mask=None, labels=None):\n        bert_outputs = self.roberta(input_ids=input_ids,\n                                    attention_mask=attention_mask)\n        pooler_output = bert_outputs['pooler_output']\n        pooler_output = self.dropout(pooler_output)\n        logits = self.regressor(pooler_output)\n        loss = self.loss_fct(labels, logits) if labels is not None else None\n        return RegressorOutput(loss=loss, logits=logits)","metadata":{"_uuid":"6c737362-28c3-4407-b3ba-17a1a1d15525","_cell_guid":"10cd31e7-703e-4928-812b-01f658fd95da","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.611683Z","iopub.execute_input":"2021-06-10T15:16:13.611959Z","iopub.status.idle":"2021-06-10T15:16:13.621134Z","shell.execute_reply.started":"2021-06-10T15:16:13.611934Z","shell.execute_reply":"2021-06-10T15:16:13.620386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Experiments","metadata":{"_uuid":"64d536f2-ac4c-4098-b6df-576c3da8642f","_cell_guid":"5088c9e6-aed9-4e71-8e7a-ddfea773e2f3","trusted":true}},{"cell_type":"code","source":"BATCH_SIZE = 16\nRANDOM_STATE = 41\nSAVE_NAME = Path('roberta-base-pooler-regressor')","metadata":{"_uuid":"78021f81-b62a-44b6-9b1d-5e3c2668aefc","_cell_guid":"abce2c2e-24a3-4b8e-86e5-9954c533e89b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.622567Z","iopub.execute_input":"2021-06-10T15:16:13.623285Z","iopub.status.idle":"2021-06-10T15:16:13.632936Z","shell.execute_reply.started":"2021-06-10T15:16:13.623247Z","shell.execute_reply":"2021-06-10T15:16:13.631973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = pd.read_csv(TRAIN_DATA_PATH)\n#### Remove before submission #####\n# train_data = train_data.sort_values(by='excerpt', key=lambda x: x.str.len())[:len(train_data)//4]\n# train_data = train_data[:20]\n###################################\nkfolf_monitor = KfoldMonitor()\nfor fold, (train_data, valid_data) in enumerate(split_into_kfolds(train_data, n_splits=5, shuffle=True, random_state=RANDOM_STATE)):\n    gc.collect()\n    torch.cuda.empty_cache()\n    print(f'Length of train data: {len(train_data)}, valid data: {len(valid_data)}')\n    train_dataloader = create_training_dataloader(data=train_data, batch_size=BATCH_SIZE, shuffle=True)\n    valid_dataloader = create_training_dataloader(data=valid_data, batch_size=BATCH_SIZE * 4, shuffle=False)\n    monitor = Monitor(num_patient_epochs=3)\n    MODEL_PATH = '../input/commonlit-data-download/roberta-base'\n    num_epochs = 20\n    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n    model = RobertaPoolerRegressor.from_pretrained(MODEL_PATH)\n    model.to(device)\n    optimizer = AdamW(params=model.parameters(), lr=2e-5)\n    for epoch_num in range(num_epochs):\n        model, train_loss = train(train_dataloader, model, tokenizer, optimizer, device)\n        valid_loss, valid_metric = evaluate(valid_dataloader, model, tokenizer, device)\n        monitor.update_best_model(current_epoch_num=epoch_num, score=valid_metric.get_rmse(), model=model,\n                                  tokenizer=tokenizer, save_name=SAVE_NAME/str(fold))\n        print(f'Epoch num: {epoch_num} Train epoch loss: {train_loss}')\n        print(f'Epoch num: {epoch_num} Valid epoch loss: {valid_loss}, RMSE: {valid_metric.get_rmse()}')\n        if monitor.early_stopping(current_epoch_num=epoch_num):\n            print(f'Exiting at epoch_num {epoch_num} due to early stopping')\n            break\n    kfolf_monitor.update(fold=fold, monitor=monitor)\n    print(2*'--------------------------------------')\n\nmean_cross_validation_score = np.mean([fold_monitor.best_score for fold_monitor in kfolf_monitor.fold_monitor.values()])\nprint(f'Mean cross validation score: {mean_cross_validation_score}')","metadata":{"_uuid":"802c2750-9e52-49ba-bcda-7ad5bb2f6f48","_cell_guid":"4f1ed006-d303-4e35-8005-497c479a96ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:16:13.634563Z","iopub.execute_input":"2021-06-10T15:16:13.634974Z","iopub.status.idle":"2021-06-10T15:17:28.256058Z","shell.execute_reply.started":"2021-06-10T15:16:13.634937Z","shell.execute_reply":"2021-06-10T15:17:28.253417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make submission","metadata":{}},{"cell_type":"code","source":"test_data = pd.read_csv(TEST_DATA_PATH)\ntest_dataloader = create_prediction_dataloader(test_data, batch_size=4)\nMODEL_PATH = '../input/commonlit-data-download/roberta-base'\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ntokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n\npredictions = []\nfor monitor in kfolf_monitor.fold_monitor.values():\n    gc.collect()\n    torch.cuda.empty_cache()\n    model = monitor.best_model\n    model.to(device)\n    fold_predictions = predict(test_dataloader, model, tokenizer, device)\n    predictions.append(fold_predictions)\n    \nmean_predictions = np.mean(np.hstack(predictions), axis=1)\ntest_data['target'] = mean_predictions\ntest_data[['id','target']].to_csv('submission.csv', index=False)","metadata":{"_uuid":"725f9339-47ca-4d57-9224-2a45ff92661f","_cell_guid":"d9bdb64d-b480-4852-95be-8ba678a3c2e6","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2021-06-10T15:17:28.256936Z","iopub.status.idle":"2021-06-10T15:17:28.257322Z"},"trusted":true},"execution_count":null,"outputs":[]}]}