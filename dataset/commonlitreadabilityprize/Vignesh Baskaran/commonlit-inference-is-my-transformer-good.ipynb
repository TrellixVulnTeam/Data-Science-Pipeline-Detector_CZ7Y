{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Context:\nIn the previous notebook we investigated which components improve the performance of my transformer using cross validation score. In this notebook we verify if the LB score increases.\n\nTrainer notebook: https://www.kaggle.com/vigneshbaskaran/commonlit-making-my-transformer-good-enough  \nStory of how I improved my transformer: https://www.kaggle.com/vigneshbaskaran/commonlit-halftime-recap-of-my-transformer-journey  ","metadata":{}},{"cell_type":"code","source":"import gc\nimport torch\nimport numpy as np\nimport pandas as pd\n\nfrom torch import nn\nfrom transformers.file_utils import ModelOutput\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoModel, AutoTokenizer","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:48.606241Z","iopub.execute_input":"2021-06-15T12:23:48.606721Z","iopub.status.idle":"2021-06-15T12:23:50.595291Z","shell.execute_reply.started":"2021-06-15T12:23:48.606691Z","shell.execute_reply":"2021-06-15T12:23:50.594263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction Dataset and Dataloader","metadata":{}},{"cell_type":"code","source":"class PredictionDataset(Dataset):\n    def __init__(self, text_excerpts):\n        self.text_excerpts = text_excerpts\n    \n    def __len__(self):\n        return len(self.text_excerpts)\n    \n    def __getitem__(self, idx):\n        sample = {'text_excerpt': self.text_excerpts[idx]}\n        return sample","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:50.596725Z","iopub.execute_input":"2021-06-15T12:23:50.597053Z","iopub.status.idle":"2021-06-15T12:23:50.602478Z","shell.execute_reply.started":"2021-06-15T12:23:50.59702Z","shell.execute_reply":"2021-06-15T12:23:50.60148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_prediction_dataloader(data, batch_size, num_workers=4):\n    text_excerpts = data['excerpt'].tolist()\n    dataset = PredictionDataset(text_excerpts=text_excerpts)\n    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True, drop_last=False)\n    return dataloader","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:50.604289Z","iopub.execute_input":"2021-06-15T12:23:50.604778Z","iopub.status.idle":"2021-06-15T12:23:50.617139Z","shell.execute_reply.started":"2021-06-15T12:23:50.604745Z","shell.execute_reply":"2021-06-15T12:23:50.616005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clear_cuda():\n    gc.collect()\n    torch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:50.618704Z","iopub.execute_input":"2021-06-15T12:23:50.619045Z","iopub.status.idle":"2021-06-15T12:23:50.628142Z","shell.execute_reply.started":"2021-06-15T12:23:50.619017Z","shell.execute_reply":"2021-06-15T12:23:50.627343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(dataloader, model, tokenizer, padding, max_length, device):\n    clear_cuda()\n    model.eval()\n    model.to(device)\n    predictions = []\n    for batch_num, batch in enumerate(dataloader):\n        # Forward Propagation\n        inputs = tokenizer(batch['text_excerpt'], padding=padding, truncation=True, max_length=max_length,return_tensors=\"pt\")\n        inputs = {key:value.to(device) for key, value in inputs.items()}\n        with torch.no_grad():\n            outputs = model(**inputs)\n        batch_predictions = outputs.logits.detach().cpu().numpy()\n        predictions.append(batch_predictions)\n    predictions = np.vstack(predictions)\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:50.629342Z","iopub.execute_input":"2021-06-15T12:23:50.629784Z","iopub.status.idle":"2021-06-15T12:23:50.747725Z","shell.execute_reply.started":"2021-06-15T12:23:50.629754Z","shell.execute_reply":"2021-06-15T12:23:50.746633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class RegressorOutput(ModelOutput):\n    loss = None\n    logits = None\n    hidden_states = None\n    attentions = None","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:51.01537Z","iopub.execute_input":"2021-06-15T12:23:51.015948Z","iopub.status.idle":"2021-06-15T12:23:51.021304Z","shell.execute_reply.started":"2021-06-15T12:23:51.015895Z","shell.execute_reply":"2021-06-15T12:23:51.020258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaPoolerRegressor(nn.Module):\n    def __init__(self, model_path, apply_sqrt_to_loss):\n        super(RobertaPoolerRegressor, self).__init__()\n        self.roberta = AutoModel.from_pretrained(model_path)\n        self.dropout = nn.Dropout(self.roberta.config.hidden_dropout_prob)\n        self.regressor = nn.Linear(self.roberta.config.hidden_size, 1)\n        self.loss_fn = nn.MSELoss()\n        self.apply_sqrt_to_loss = apply_sqrt_to_loss\n    \n    def forward(self, input_ids=None, attention_mask=None, labels=None):\n        roberta_outputs = self.roberta(input_ids=input_ids, \n                                       attention_mask=attention_mask)\n        pooler_output = roberta_outputs['pooler_output']\n        pooler_output = self.dropout(pooler_output)\n        logits = self.regressor(pooler_output)\n        if self.apply_sqrt_to_loss:\n            loss = torch.sqrt(self.loss_fn(labels, logits)) if labels is not None else None\n        else:\n            loss = self.loss_fn(labels, logits) if labels is not None else None\n        return RegressorOutput(loss=loss, logits=logits)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:51.385556Z","iopub.execute_input":"2021-06-15T12:23:51.385919Z","iopub.status.idle":"2021-06-15T12:23:51.395132Z","shell.execute_reply.started":"2021-06-15T12:23:51.385886Z","shell.execute_reply":"2021-06-15T12:23:51.394243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AttentionHead(nn.Module):\n    def __init__(self, hidden_dim):\n        super(AttentionHead, self).__init__()\n        self.W = nn.Linear(hidden_dim, hidden_dim)\n        self.V = nn.Linear(hidden_dim, 1)\n    \n    def forward(self, x):\n        attention_scores = self.V(torch.tanh(self.W(x)))\n        attention_scores = torch.softmax(attention_scores, dim=1)\n        attentive_x = attention_scores * x\n        attentive_x = attentive_x.sum(axis=1)\n        return attentive_x","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:51.800502Z","iopub.execute_input":"2021-06-15T12:23:51.801056Z","iopub.status.idle":"2021-06-15T12:23:51.807684Z","shell.execute_reply.started":"2021-06-15T12:23:51.801004Z","shell.execute_reply":"2021-06-15T12:23:51.806711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaPoolerRegressor(nn.Module):\n    def __init__(self, model_path, apply_sqrt_to_loss):\n        super(RobertaPoolerRegressor, self).__init__()\n        self.roberta = AutoModel.from_pretrained(model_path)\n        self.dropout = nn.Dropout(self.roberta.config.hidden_dropout_prob)\n        self.regressor = nn.Linear(self.roberta.config.hidden_size, 1)\n        self.loss_fn = nn.MSELoss()\n        self.apply_sqrt_to_loss = apply_sqrt_to_loss\n    \n    def forward(self, input_ids=None, attention_mask=None, labels=None):\n        roberta_outputs = self.roberta(input_ids=input_ids, \n                                       attention_mask=attention_mask)\n        pooler_output = roberta_outputs['pooler_output']\n        pooler_output = self.dropout(pooler_output)\n        logits = self.regressor(pooler_output)\n        if self.apply_sqrt_to_loss:\n            loss = torch.sqrt(self.loss_fn(labels, logits)) if labels is not None else None\n        else:\n            loss = self.loss_fn(labels, logits) if labels is not None else None\n        return RegressorOutput(loss=loss, logits=logits)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:52.208103Z","iopub.execute_input":"2021-06-15T12:23:52.208675Z","iopub.status.idle":"2021-06-15T12:23:52.221831Z","shell.execute_reply.started":"2021-06-15T12:23:52.208623Z","shell.execute_reply":"2021-06-15T12:23:52.220367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RobertaLastHiddenStateRegressor(nn.Module):\n    def __init__(self, model_path):\n        super(RobertaLastHiddenStateRegressor, self).__init__()\n        self.roberta = AutoModel.from_pretrained(model_path)\n        self.head = AttentionHead(self.roberta.config.hidden_size)\n        self.dropout = nn.Dropout(self.roberta.config.hidden_dropout_prob)\n        self.regressor = nn.Linear(self.roberta.config.hidden_size, 1)\n        self.loss_fn = nn.MSELoss()\n    \n    def forward(self, input_ids=None, attention_mask=None, labels=None):\n        roberta_outputs = self.roberta(input_ids=input_ids,\n                                       attention_mask=attention_mask)\n        last_hidden_state = roberta_outputs['last_hidden_state']\n        attentive_vector = self.head(last_hidden_state)\n        attentive_vector = self.dropout(attentive_vector)\n        logits = self.regressor(attentive_vector)\n        loss = torch.sqrt(self.loss_fn(labels, logits)) if labels is not None else None\n        return RegressorOutput(loss=loss, logits=logits)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:52.593808Z","iopub.execute_input":"2021-06-15T12:23:52.594169Z","iopub.status.idle":"2021-06-15T12:23:52.602825Z","shell.execute_reply.started":"2021-06-15T12:23:52.594124Z","shell.execute_reply":"2021-06-15T12:23:52.601994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ntest_data = pd.read_csv('../input/commonlitreadabilityprize/test.csv')\ntest_dataloader = create_prediction_dataloader(data=test_data, batch_size=8)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:53.128075Z","iopub.execute_input":"2021-06-15T12:23:53.128477Z","iopub.status.idle":"2021-06-15T12:23:53.151062Z","shell.execute_reply.started":"2021-06-15T12:23:53.128445Z","shell.execute_reply":"2021-06-15T12:23:53.150041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EXPERIMENT_NAME = 'experiment_7'","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:53.448061Z","iopub.execute_input":"2021-06-15T12:23:53.448527Z","iopub.status.idle":"2021-06-15T12:23:53.453062Z","shell.execute_reply.started":"2021-06-15T12:23:53.44849Z","shell.execute_reply":"2021-06-15T12:23:53.451909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiment_1_fold_predictions = []\nfor fold in range(5):\n    print(f'Inferring fold: {fold}')\n    pretrained_model_path = '../input/maunish-clrp-model/clrp_roberta_base'\n    tokenizer_path = '../input/commonlit-data-download/roberta-base'\n    model = RobertaLastHiddenStateRegressor(model_path=pretrained_model_path)\n    finetuned_model_path = f'../input/commonlit-making-my-transformer-good-enough/experiment_1/fold_{fold}/model.pth'\n    model.load_state_dict(torch.load(finetuned_model_path, map_location=torch.device('cpu')))\n    model.to(device)\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n    padding = 'max_length'\n    max_length = 256\n    experiment_1_fold_predictions.append(predict(test_dataloader, model, tokenizer, padding, max_length, device))\nexperiment_1_fold_predictions = np.hstack(experiment_1_fold_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:23:54.184036Z","iopub.execute_input":"2021-06-15T12:23:54.18443Z","iopub.status.idle":"2021-06-15T12:24:55.275334Z","shell.execute_reply.started":"2021-06-15T12:23:54.184393Z","shell.execute_reply":"2021-06-15T12:24:55.27414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"experiment_7_fold_predictions = []\nfor fold in range(5):\n    print(f'Inferring fold: {fold}')\n    pretrained_model_path = '../input/commonlit-data-download/roberta-base'\n    tokenizer_path = '../input/commonlit-data-download/roberta-base'\n    model = RobertaPoolerRegressor(model_path=pretrained_model_path, apply_sqrt_to_loss=False)\n    finetuned_model_path = f'../input/commonlit-making-my-transformer-good-enough/experiment_7/fold_{fold}/model.pth'\n    model.load_state_dict(torch.load(finetuned_model_path, map_location=torch.device('cpu')))\n    model.to(device)\n    tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n    padding = True\n    max_length = None\n    experiment_7_fold_predictions.append(predict(test_dataloader, model, tokenizer, padding, max_length, device))\nexperiment_7_fold_predictions = np.hstack(experiment_7_fold_predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:24:55.277048Z","iopub.execute_input":"2021-06-15T12:24:55.277378Z","iopub.status.idle":"2021-06-15T12:25:53.654961Z","shell.execute_reply.started":"2021-06-15T12:24:55.277343Z","shell.execute_reply":"2021-06-15T12:25:53.653973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold_predictions = np.hstack((experiment_1_fold_predictions, experiment_7_fold_predictions))\nmean_predictions = np.mean(fold_predictions, axis=1)\ntest_data['target'] = mean_predictions\ntest_data[['id','target']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:26:42.947804Z","iopub.execute_input":"2021-06-15T12:26:42.948284Z","iopub.status.idle":"2021-06-15T12:26:42.962291Z","shell.execute_reply.started":"2021-06-15T12:26:42.948241Z","shell.execute_reply":"2021-06-15T12:26:42.961209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data[['id','target']]","metadata":{"execution":{"iopub.status.busy":"2021-06-15T12:26:49.510253Z","iopub.execute_input":"2021-06-15T12:26:49.51058Z","iopub.status.idle":"2021-06-15T12:26:49.528661Z","shell.execute_reply.started":"2021-06-15T12:26:49.51055Z","shell.execute_reply":"2021-06-15T12:26:49.527795Z"},"trusted":true},"execution_count":null,"outputs":[]}]}