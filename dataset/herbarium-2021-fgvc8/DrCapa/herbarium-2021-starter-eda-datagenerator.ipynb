{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Intro\nWelcome to the [Herbarium 2021 - Half-Earth Challenge - FGVC8](https://www.kaggle.com/c/herbarium-2021-fgvc8) compedition.\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/25558/logos/header.png)\n\n<span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. </span>"},{"metadata":{},"cell_type":"markdown","source":"# Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport json\nfrom collections import Counter\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import to_categorical, Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, Activation\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.applications import ResNet50\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Path"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '/kaggle/input/herbarium-2021-fgvc8/'\nos.listdir(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"samp_subm = pd.read_csv(path+'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(path+'train/'+'metadata.json') as f:\n    train_data = json.load(f)\nwith open(path+'test/'+'metadata.json') as f:\n    test_data = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_examples():\n    fig, axs = plt.subplots(4, 4, figsize=(20, 20))\n    fig.subplots_adjust(hspace = .1, wspace=.1)\n    \n    axs = axs.ravel()\n    for i in range(16):\n        img = cv2.imread(path+'train/'+train_data['images'][i]['file_name'])\n        axs[i].imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n        axs[i].set_title(train_data['categories'][i]['family'])\n        axs[i].set_xticklabels([])\n        axs[i].set_yticklabels([])\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of train images:', len(train_data['images']))\nprint('Number of test images:', len(test_data['images']))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{},"cell_type":"markdown","source":"## Focus Train Data Structure\nThere are some metadata: \"annotations\", \"categories\", \"images\", \"info\", \"licenses\" \"institutions\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['annotations'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['categories'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['images'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['info']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['licenses'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['institutions'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Focus Test Data Structure\nThere are some metadata: \"images\", \"info\", \"licenses\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['images'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['info']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['licenses'][0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Plot Some Examples"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plot_examples()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prepare Data For Data Generator\nTrain Data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_image = pd.json_normalize(train_data['images'])\ndf_annot = pd.json_normalize(train_data['annotations'])\ndf_train_data = pd.DataFrame()\ndf_train_data['file_name'] = df_image['file_name']\ndf_train_data['category_id'] = df_annot['category_id']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Split Train And Validation Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_data, df_val_data = train_test_split(df_train_data, test_size=0.3)\ndf_train_data.index = range(len(df_train_data.index))\ndf_val_data.index = range(len(df_val_data.index))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_image = pd.json_normalize(test_data['images'])\ndf_test_data = pd.DataFrame()\ndf_test_data['file_name'] = df_image['file_name']\ndf_test_data['category_id'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Summary"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Number of train samples:', len(df_train_data))\nprint('Number of val samples:', len(df_val_data))\nprint('Number of test samples:', len(df_test_data))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Distribution Of Categories"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of categories:', len(df_train_data['category_id'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_data['category_id'].value_counts()[0:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Generator"},{"metadata":{},"cell_type":"markdown","source":"Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"q_size = 64\nimg_channel = 3\nnum_classes = 64500\nbatch_size = 32\nepochs = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, labels, batch_size, img_size, img_channel, num_classes):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_size = img_size\n        self.img_channel = img_channel\n        self.num_classes = num_classes\n        self.indexes = np.arange(len(self.list_IDs))\n\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        return X, y\n            \n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, self.img_size, self.img_size, self.img_channel))\n        y = np.zeros((self.batch_size, self.num_classes), dtype=int)\n        for i, ID in enumerate(list_IDs_temp):\n            img = cv2.imread(self.path+ID)\n            img = cv2.resize(img, (self.img_size, self.img_size))\n            X[i, ] = img/255\n            y[i, ] = to_categorical(self.labels[i], num_classes=self.num_classes)\n        return X, y","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test On Subset\nBoth train and test data sets are big. To test the algorithms we work on a small subset."},{"metadata":{"trusted":true},"cell_type":"code","source":"number_samples = 10000\ndf_train_data = df_train_data[0:number_samples]\ndf_val_data = df_val_data[0:number_samples]\ndf_test_data = df_test_data[0:number_samples]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Train, Val And Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = DataGenerator(path+'train/', df_train_data['file_name'], df_train_data['category_id'],\n                                batch_size, q_size, img_channel, num_classes)\nval_generator = DataGenerator(path+'train/',df_val_data['file_name'], df_val_data['category_id'],\n                                batch_size, q_size, img_channel, num_classes)\ntest_generator = DataGenerator(path+'test/',df_test_data['file_name'], df_test_data['category_id'],\n                                batch_size, q_size, img_channel, num_classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Pretrained Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"weights='../input/models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nconv_base = ResNet50(weights=weights,\n                     include_top=False,\n                     input_shape=(q_size, q_size, img_channel))\nconv_base.trainable = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\nmodel.add(conv_base)\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(num_classes, activation='sigmoid'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer = RMSprop(lr=1e-5),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(generator=train_generator,\n                              validation_data=val_generator,\n                              epochs = epochs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analyse Training"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(20, 6))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = history.history['binary_accuracy']\nacc_val = history.history['val_binary_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"predict = model.predict_generator(test_generator, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict.argmax(axis=1)\nsamp_subm.loc[0:len(df_test_data.index)-1, 'Predicted'] = predict.argmax(axis=1)[0:len(df_test_data.index)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Export"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = samp_subm.copy()\noutput.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}