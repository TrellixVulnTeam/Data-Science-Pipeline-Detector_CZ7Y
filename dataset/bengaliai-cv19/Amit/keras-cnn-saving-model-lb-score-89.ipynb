{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport pandas as pd\nfrom keras.models import Sequential\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense\nfrom keras.layers import Convolution2D,BatchNormalization\nimport gc\nfrom keras.models import clone_model\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.auto import tqdm\nimport cv2\nimport numpy as np\nfrom keras.models import model_from_json\nfrom keras.preprocessing.image import ImageDataGenerator\n\nstringpath = '/kaggle/input/bengaliai-cv19'\nfeaturepath = \"/kaggle/input/bengaliaicv19feather\"\n\nmodelpath = \"/kaggle/input/my-trained-model\"\n\ntraincsv =  pd.read_csv(stringpath  + r'/train.csv')\nOutputCols = ['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']\n\nBS = 100\nHEIGHT = 137\nWIDTH = 236\nIMG_SIZE = 96\n\ndef resize(df, size=IMG_SIZE, need_progress_bar=True):\n    resized = {}\n    if need_progress_bar:\n        for i in tqdm(range(df.shape[0])):\n            resized[df.index[i]] = (cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size, size), interpolation = cv2.INTER_AREA)).reshape(-1)\n    else:\n        for i in range(df.shape[0]):\n            resized[df.index[i]] = (cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size, size), interpolation = cv2.INTER_AREA)).reshape(-1)\n    resized = pd.DataFrame(resized).T\n    del df\n    gc.collect()\n    return resized\n\naug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n\thorizontal_flip=True, fill_mode=\"nearest\")\n\n\n############# Model prepartion #############################\nmodel = Sequential()\nmodel.add(Convolution2D(32,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(Convolution2D(32,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(Convolution2D(32,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(Convolution2D(32,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1, momentum=0.2))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Convolution2D(64,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(64,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(64,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(Convolution2D(64,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1, momentum=0.2))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Convolution2D(128,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(128,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(128,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(Convolution2D(128,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1, momentum=0.2))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Convolution2D(256,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(256,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(256,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(Convolution2D(256,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1, momentum=0.2))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Convolution2D(512,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(512,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same',activation = 'relu'))\nmodel.add(Convolution2D(512,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(Convolution2D(512,(3,3),input_shape=(IMG_SIZE, IMG_SIZE,1), padding='same', activation = 'relu'))\nmodel.add(BatchNormalization(axis=-1, momentum=0.2))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(activation=\"relu\", units=1024))\nmodel.add(Dense(activation=\"relu\", units=512))\n\nmodel_root = clone_model(model)\nmodel_vowel = clone_model(model)\nmodel_consonant = clone_model(model)\n\nmodel_root.add(Dense(activation = 'softmax', units = 168))\nmodel_vowel.add(Dense(activation = 'softmax', units = 11))\nmodel_consonant.add(Dense( activation = 'softmax', units = 7))\n\n\n\nmodel_root.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\nmodel_vowel.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\nmodel_consonant.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n\nprint(\"Done  Model prepartion  \")\n############# Model prepartion #############################\n\n\n\n\n############ Creating Input #################################\nfor i in range(4):\n    print(i)\n    featherdir = featurepath + r'/train_image_data_{}.feather'.format(i)\n    trainData = pd.merge(traincsv,  pd.read_feather(featherdir), how='inner', on=['image_id']).drop(['image_id','grapheme'], axis = 1)\n   \n    alltrainY = trainData[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']]\n    trainX = trainData.drop(OutputCols, axis=1)\n    \n    trainX = resize(trainX)\n    trainX_df = trainX.values.reshape(-1, IMG_SIZE, IMG_SIZE, 1).astype('uint8')\n    \n    del trainX,trainData  \n    gc.collect()\n    \n    print(\"Start model Training \")\n    \n    trainrootY = pd.get_dummies(alltrainY['grapheme_root']).values \n    trainvowelY = pd.get_dummies(alltrainY['vowel_diacritic']).values\n    trainconsonantY = pd.get_dummies(alltrainY['consonant_diacritic']).values\n    trainX, ValX,trainrootY,valrootY, trainvowelY, valvowelY, trainconsonantY, valconsonantY = train_test_split(trainX_df, trainrootY, trainvowelY, trainconsonantY, test_size=0.2, random_state=400)\n            \n    model_root.fit_generator(aug.flow(trainX, trainrootY, batch_size=BS), steps_per_epoch = trainX.shape[0] / BS,  epochs=15, validation_data = (ValX, valrootY))\n    model_vowel.fit_generator(aug.flow(trainX, trainvowelY, batch_size=BS),steps_per_epoch = trainX.shape[0] / BS, epochs=12, validation_data = (ValX, valvowelY))\n    model_consonant.fit_generator(aug.flow(trainX, trainconsonantY, batch_size=BS), steps_per_epoch = trainX.shape[0] / BS, epochs=12, validation_data = (ValX, valconsonantY))\n    del trainX,ValX,trainrootY,trainvowelY,trainconsonantY,valrootY,valvowelY,valconsonantY,trainX_df,alltrainY\n    gc.collect()\n    print(\"Done model Training \")\n############ Creating Input #################################\n\n\n############ Saving Model ##################################\nmodel_rootjson = model_root.to_json()\nmodel_voweljson = model_vowel.to_json()\nmodel_consonantjson = model_consonant.to_json()\n\nwith open(\"model_root.json\", \"w\") as json_file:\n    json_file.write(model_rootjson)\n    \nwith open(\"model_vowel.json\", \"w\") as json_file:\n    json_file.write(model_voweljson)\n    \nwith open(\"model_consonant.json\", \"w\") as json_file:\n    json_file.write(model_consonantjson)\n# serialize weights to HDF5\nmodel_root.save_weights(\"model_root.h5\")\nmodel_vowel.save_weights(\"model_vowel.h5\")\nmodel_consonant.save_weights(\"model_consonant.h5\")\nprint(\"Saved model to disk\")\n############ End Saving Model #################################\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}