{"cells":[{"metadata":{},"cell_type":"markdown","source":"### In this competition, we have three targets for each sample, thus I think using iterative stratifications (https://github.com/trent-b/iterative-stratification) is helpful according to previous competition:\nimet top 1 solution https://www.kaggle.com/c/imet-2019-fgvc6/discussion/94687"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n!pip install iterative-stratification","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#get data\nnfold = 5\nseed = 12\n\ntrain_df = pd.read_csv('/kaggle/input/bengaliai-cv19/train.csv')\ntrain_df['id'] = train_df['image_id'].apply(lambda x: int(x.split('_')[1]))\n\nX, y = train_df[['id', 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic']]\\\n.values[:,0], train_df.values[:,1:]\n\ntrain_df['fold'] = np.nan\n\n#split data\nfrom iterstrat.ml_stratifiers import MultilabelStratifiedKFold\nmskf = MultilabelStratifiedKFold(n_splits=nfold, random_state=seed)\nfor i, (_, test_index) in enumerate(mskf.split(X, y)):\n    train_df.iloc[test_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#output\ntrain_df.to_csv('train_with_fold.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}