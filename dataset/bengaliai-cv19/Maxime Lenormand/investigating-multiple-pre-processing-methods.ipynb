{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Investigating multiple pre-processing effects\n\nThe aim of this notebook is mostly for visual aid, seeing what different types of pre-processing look like. I've seen multiple people use different blurrings, filters, noise reduction methods, etc. whithout really knowing what they look like mot of the time, even if I understand the theory behind them.\n\nThis notebook is based on my previous [Resizing and cropping kernel](https://www.kaggle.com/maxlenormand/cropping-to-character-resizing-images) and adds components taken from the pre-processing done by @shawon10 in his [notebook](https://www.kaggle.com/shawon10/noise-removing-cropping-and-roi-of-images).\n\nThis helped me get a visual understanding, hope it helps others too! Ideally, I'd like to see how different pre-processing affect training results, I'll see if I have time for that!"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\n\nimport time\nimport os\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"start_time = time.time()\ndf_0 = pd.read_parquet('/kaggle/input/bengaliai-cv19/train_image_data_0.parquet')\nprint(f\"Shape of df_0: {df_0.shape} (took {time.time() - start_time}sec to load)\")\ncurrent_time = time.time()\n\ndf_1 = pd.read_parquet('/kaggle/input/bengaliai-cv19/train_image_data_1.parquet')\nprint(f\"Shape of df_1: {df_1.shape} (took {time.time() - current_time}sec to load)\")\ncurrent_time = time.time()\n\ndf_2 = pd.read_parquet('/kaggle/input/bengaliai-cv19/train_image_data_2.parquet')\nprint(f\"Shape of df_2: {df_2.shape} (took {time.time() - current_time}sec to load)\")\ncurrent_time = time.time()\n\ndf_3 = pd.read_parquet('/kaggle/input/bengaliai-cv19/train_image_data_3.parquet')\n\nprint(f\"It took: {time.time() - start_time} to load all 4 datasets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HEIGHT = 137\nWIDTH = 236\nCROP_SIZE = 75","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"original_img_size = HEIGHT * WIDTH\ncropped_img_size = CROP_SIZE * CROP_SIZE\n\nprint(f\"Original shape of images: {original_img_size}\\nCropped & resized shape of images: {cropped_img_size}\")\nprint(f\"Reduction fatio: {np.round(original_img_size/cropped_img_size, 3)}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reducing image size to 75x75 reduced the number of pixels in the image by ~5.75, which is nice to keep in mind for training time."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"resized = df_0.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"DEFAULT_PADDING_SIZE = int((CROP_SIZE)*.05)\nprint(f'Default padding size: {DEFAULT_PADDING_SIZE}')\n\ndef crop_and_resize_with_interpolation_and_correction_images(df,\n                                                             resized_df, \n                                                             resize_size = CROP_SIZE,\n                                                             padding_size = DEFAULT_PADDING_SIZE, \n                                                             remove_noise = False,\n                                                             blur=False, \n                                                             Laplace_filter=False):\n    cropped_imgs = {}\n    for img_id in tqdm(range(df.shape[0])):\n        img = resized_df[img_id]\n        _, thresh = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n        contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n        \n        idx = 0 \n        ls_xmin = []\n        ls_ymin = []\n        ls_xmax = []\n        ls_ymax = []\n        for cnt in contours:\n            idx += 1\n            x,y,w,h = cv2.boundingRect(cnt)\n            ls_xmin.append(x)\n            ls_ymin.append(y)\n            ls_xmax.append(x + w)\n            ls_ymax.append(y + h)\n        xmin = min(ls_xmin)\n        ymin = min(ls_ymin)\n        xmax = max(ls_xmax)\n        ymax = max(ls_ymax)\n        \n        roi = img[ymin:ymax,xmin:xmax]\n        # Padding:\n        padded_roi = cv2.copyMakeBorder(roi, padding_size, padding_size, padding_size, padding_size, cv2.BORDER_CONSTANT, value=[255])\n\n        resized_roi = cv2.resize(padded_roi, (resize_size, resize_size), interpolation = cv2.INTER_AREA)\n        \n        #Noise Removing\n        if remove_noise:\n            resized_roi=cv2.fastNlMeansDenoising(resized_roi)\n        \n        #Gaussian Blur\n        if blur:\n            gaussian = cv2.GaussianBlur(resized_roi, (9,9), 10.0)\n            resized_roi = cv2.addWeighted(resized_roi, 1.5, gaussian, -0.5, 0, resized_roi)\n            \n        #Laplacian Filter\n        if Laplace_filter:\n            kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n            resized_roi = cv2.filter2D(resized_roi, -1, kernel)\n        \n        cropped_imgs[df.image_id[img_id]] = resized_roi.reshape(-1)\n        \n    resized = pd.DataFrame(cropped_imgs).T.reset_index()\n    resized.columns = resized.columns.astype(str)\n    resized.rename(columns={'index':'image_id'},inplace=True)\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"IMGS_TO_TEST = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"test_df_no_blur_no_filter = crop_and_resize_with_interpolation_and_correction_images(df_0.head(IMGS_TO_TEST), resized, CROP_SIZE, \n                                                                                     blur=False, \n                                                                                     Laplace_filter=False)\nresized_test = test_df_no_blur_no_filter.iloc[:, 1:].values.reshape(-1, CROP_SIZE, CROP_SIZE)\n\n\n\ntest_df_with_blur_no_filter = crop_and_resize_with_interpolation_and_correction_images(df_0.head(IMGS_TO_TEST), resized, CROP_SIZE, \n                                                                                       blur=True, \n                                                                                       Laplace_filter=False)\nresized_test_blur = test_df_with_blur_no_filter.iloc[:, 1:].values.reshape(-1, CROP_SIZE, CROP_SIZE)\n\n\n\ntest_df_with_blur_with_filter = crop_and_resize_with_interpolation_and_correction_images(df_0.head(IMGS_TO_TEST), resized, CROP_SIZE, \n                                                                                         blur=True, \n                                                                                         Laplace_filter=True)\nresized_test_blur_filter = test_df_with_blur_with_filter.iloc[:, 1:].values.reshape(-1, CROP_SIZE, CROP_SIZE)\n\n\n\ntest_df_with_blur_with_filter_with_noise_removal = crop_and_resize_with_interpolation_and_correction_images(df_0.head(IMGS_TO_TEST), resized, CROP_SIZE,\n                                                                                                            remove_noise=True, \n                                                                                                            blur=True,\n                                                                                                            Laplace_filter=True)\nresized_test_blur_filter_noise_removed = test_df_with_blur_with_filter_with_noise_removal.iloc[:, 1:].values.reshape(-1, CROP_SIZE, CROP_SIZE)\n\nfor img in range(5):\n    fig, (ax0, ax1, ax2, ax3, ax4) = plt.subplots(1, 5, figsize=(30, 15))\n    ax0.imshow(resized[img], cmap='Greys')\n    ax0.set_title('Original image')\n    ax1.imshow(resized_test[img], cmap='Greys')\n    ax1.set_title('Resized & cropped image')\n    ax2.imshow(resized_test_blur[img], cmap='Greys')\n    ax2.set_title('Resized, cropped and blurred image')\n    ax3.imshow(resized_test_blur_filter[img], cmap='Greys')\n    ax3.set_title('Resized & cropped, blurred, filter')\n    ax4.imshow(resized_test_blur_filter_noise_removed[img], cmap='Greys')\n    ax4.set_title('Resized & cropped, blurred, filter & noise removed')\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"And finally saving the images in new `.feather` datasets, with all the different pre-processing steps done."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# start = time.time()\n\n# # dataset 1\n# resized_0 = df_0.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n# cropped_df_0 = crop_and_resize_with_interpolation_and_correction_images(df_0, resized_0, CROP_SIZE,remove_noise=True,blur=True,Laplace_filter=True)\n# cropped_df_0.to_feather(\"train_data_0.feather\")\n# del resized_0\n# del cropped_df_0\n# print(f\"Saved cropped & resized df_0 to feather in {time.time() - start}sec\")\n# current = time.time()\n\n# # dataset 1\n# resized_1 = df_1.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n# cropped_df_1 = crop_and_resize_with_interpolation_and_correction_images(df_1, resized_1, CROP_SIZE,remove_noise=True,blur=True,Laplace_filter=True)\n# cropped_df_1.to_feather(\"train_data_1.feather\")\n# del resized_1\n# del cropped_df_1\n# print(f\"Saved cropped & resized df_1 to feather in {time.time() - start}sec\")\n# current = time.time()\n\n# # dataset 2\n# resized_2 = df_2.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n# cropped_df_2 = crop_and_resize_with_interpolation_and_correction_images(df_2, resized_2, CROP_SIZE,remove_noise=True,blur=True,Laplace_filter=True)\n# cropped_df_2.to_feather(\"train_data_2.feather\")\n# del resized_2\n# del cropped_df_2\n# print(f\"Saved cropped & resized df_2 to feather in {time.time() - current}sec\")\n# current = time.time()\n\n# # dataset 3\n# resized_3 = df_3.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)\n# cropped_df_3 = crop_and_resize_with_interpolation_and_correction_images(df_3, resized_3, CROP_SIZE,remove_noise=True,blur=True,Laplace_filter=True)\n# cropped_df_3.to_feather(\"train_data_3.feather\")\n# del resized_3\n# del cropped_df_3\n# print(f\"Saved cropped & resized df_3 to feather in {time.time() - current}sec\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}