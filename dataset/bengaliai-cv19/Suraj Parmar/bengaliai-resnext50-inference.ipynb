{"cells":[{"metadata":{},"cell_type":"markdown","source":"## This kernel is from [@Abhishek Thakur](https://www.kaggle.com/abhishek) youtube channel\n\n### [Bengali.AI: Handwritten Grapheme Classification Using PyTorch (Part-1)](https://www.youtube.com/watch?v=8J5Q4mEzRtY) \n\n### [Bengali.AI: Handwritten Grapheme Classification Using PyTorch (Part-2)](https://www.youtube.com/watch?v=uZalt-weQMM&t=3478s)"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport joblib\nimport glob\nfrom tqdm import tqdm\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport albumentations\nimport joblib\nimport numpy as np\nimport torch\n\nfrom PIL import Image\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nfrom torch.nn import functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%writefile train.py\n\nimport os\nimport ast\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport sklearn.metrics\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import sys\nfrom torchvision import models","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import glob\nimport torch\nimport albumentations\nimport pandas as pd\nimport numpy as np\n\nfrom tqdm import tqdm\nfrom PIL import Image\nimport joblib\nimport torch.nn as nn\nfrom torch.nn import functional as F","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_dir =  \"../input/bengalifold6/fold6.pth\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BengaliModel(nn.Module):\n    def __init__(self, pretrained=False):\n        super(BengaliModel, self).__init__()\n        self.basemodel = models.resnext50_32x4d(pretrained=pretrained)\n        \n        self.Linr = nn.Linear(2048, 168)\n        self.Linv = nn.Linear(2048, 11)\n        self.Linc = nn.Linear(2048, 7)\n\n    def forward(self, x):\n        bs, _, _ , _ = x.shape\n\n        x = self.basemodel.conv1(x)\n        x = self.basemodel.bn1(x)\n        x = self.basemodel.relu(x)\n        x = self.basemodel.maxpool(x)\n        x = self.basemodel.layer1(x)\n        x = self.basemodel.layer2(x)\n        x = self.basemodel.layer3(x)\n        x = self.basemodel.layer4(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(bs, -1)\n\n        roots = self.Linr(x)\n        vowels = self.Linv(x)\n        consonents = self.Linc(x)\n\n\n        return roots, vowels, consonents\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nMODEL_MEAN = (0.485, 0.456, 0.406)\nMODEL_STD = (0.229, 0.224, 0.225)\nIMG_HEIGHT = 137\nIMG_WIDTH = 236\nDEVICE=\"cuda\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BengaliDatasetTest:\n    def __init__(self, df, img_height, img_width, mean, std):\n        \n        self.image_ids = df.image_id.values\n        self.img_arr = df.iloc[:, 1:].values\n\n        self.aug = albumentations.Compose([\n            albumentations.Resize(img_height, img_width, always_apply=True),\n            albumentations.Normalize(mean, std, always_apply=True)\n        ])\n\n\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, item):\n        image = self.img_arr[item, :]\n        img_id = self.image_ids[item]\n        \n        image = image.reshape(137, 236).astype(float)\n        image = Image.fromarray(image).convert(\"RGB\")\n        image = self.aug(image=np.array(image))[\"image\"]\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n\n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"image_id\": img_id\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_predict():\n    g_pred, v_pred, c_pred = [], [], []\n    img_ids_list = [] \n    \n    for file_idx in range(4):\n        print('loading Parquet'+str(file_idx))\n        df = pd.read_parquet(f\"../input/bengaliai-cv19/test_image_data_{file_idx}.parquet\")\n\n        dataset = BengaliDatasetTest(df=df,\n                                    img_height=IMG_HEIGHT,\n                                    img_width=IMG_WIDTH,\n                                    mean=MODEL_MEAN,\n                                    std=MODEL_STD)\n\n        data_loader = torch.utils.data.DataLoader(\n            dataset=dataset,\n            batch_size= TEST_BATCH_SIZE,\n            shuffle=False,\n            num_workers=4\n        )\n\n        for bi, d in enumerate(data_loader):\n            image = d[\"image\"]\n            img_id = d[\"image_id\"]\n            image = image.to(DEVICE, dtype=torch.float)\n\n            g, v, c = model(image)\n            #g = np.argmax(g.cpu().detach().numpy(), axis=1)\n            #v = np.argmax(v.cpu().detach().numpy(), axis=1)\n            #c = np.argmax(c.cpu().detach().numpy(), axis=1)\n\n            for ii, imid in enumerate(img_id):\n                g_pred.append(g[ii].cpu().detach().numpy())\n                v_pred.append(v[ii].cpu().detach().numpy())\n                c_pred.append(c[ii].cpu().detach().numpy())\n                img_ids_list.append(imid)\n        \n    return g_pred, v_pred, c_pred, img_ids_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = BengaliModel(pretrained=False)\nmodel.load_state_dict(torch.load(model_dir))\n\nTEST_BATCH_SIZE = 32\n\nfinal_g_pred = []\nfinal_v_pred = []\nfinal_c_pred = []\nfinal_img_ids = []\n\nmodel.to(DEVICE)\nmodel.eval()\ng_pred, v_pred, c_pred, img_ids_list = model_predict()\n\nfinal_g_pred.append(g_pred)\nfinal_v_pred.append(v_pred)\nfinal_c_pred.append(c_pred)\nfinal_img_ids.extend(img_ids_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_ids_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.argmax(torch.softmax(torch.tensor(final_g_pred[0]), 0), 1).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_g = np.argmax(np.array(final_g_pred[0]), axis=1)\nfinal_v = np.argmax(np.array(final_v_pred[0]), axis=1)\nfinal_c = np.argmax(np.array(final_c_pred[0]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_img_ids","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_g.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nfor ii, imid in enumerate(final_img_ids):\n    predictions.append((f\"{imid}_consonant_diacritic\", final_c[ii]))\n    predictions.append((f\"{imid}_grapheme_root\", final_g[ii]))\n    predictions.append((f\"{imid}_vowel_diacritic\", final_v[ii]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(predictions, columns=[\"row_id\", \"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}