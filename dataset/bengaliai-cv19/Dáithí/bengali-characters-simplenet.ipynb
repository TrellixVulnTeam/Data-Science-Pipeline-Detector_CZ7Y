{"cells":[{"metadata":{"_uuid":"cc0e9695-ad2a-444a-b410-7d467c0949f4","_cell_guid":"eb161a34-9577-48df-b813-70a95aee3410","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(os.getcwd()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"03914930-b225-4202-8d60-e7bf30d629ec","_cell_guid":"3e78b1a4-bdcd-4a2c-8920-b05633aced1d","trusted":true},"cell_type":"code","source":"#Ad majorem dei gloriam\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input, Activation, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.callbacks import ReduceLROnPlateau,TensorBoard,ModelCheckpoint,EarlyStopping \nimport sys\nimport time\nfrom keras.applications import densenet\nimport os\n#import numpy as np\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nimport gc\n\n\n###--- FUNCTIONS\nclass MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n    \n    def flow(self,x,y=None,batch_size=32,shuffle=True,sample_weight=None,seed=None,save_to_dir=None,save_prefix='',save_format='png',subset=None):\n\n        targets = None\n        target_lengths = {}\n        ordered_outputs = []\n        for output, target in y.items():\n            if targets is None:\n                targets = target\n            else:\n                targets = np.concatenate((targets, target), axis=1)\n            target_lengths[output] = target.shape[1]\n            ordered_outputs.append(output)\n\n\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n                                         shuffle=shuffle):\n            target_dict = {}\n            i = 0\n            for output in ordered_outputs:\n                target_length = target_lengths[output]\n                target_dict[output] = flowy[:, i: i + target_length]\n                i += target_length\n\n            yield flowx, target_dict\n\ndef SimpleNet(inp):\n    \n    #Model 1\n    #L1\n    x=Conv2D(32, (3,3),activation=\"relu\", padding='SAME')(inp)\n    x=Conv2D(32, (3,3),activation=\"relu\", padding=\"SAME\")(x)\n    x=Conv2D(32, (3,3),activation=\"relu\", padding=\"SAME\")(x)\n    x=MaxPool2D(pool_size=(2,2))(x)\n\n    #L2\n    x=Conv2D(64,(3,3),activation=\"relu\", padding=\"SAME\")(x)\n    x=Conv2D(64,(3,3),activation=\"relu\", padding=\"SAME\")(x)\n    x=Conv2D(64,(3,3),activation=\"relu\", padding=\"SAME\")(x)\n    x=MaxPool2D(pool_size=(2,2))(x)\n    x=Dropout(0.10)(x)\n\n    #L3\n    x=Conv2D(128,(3,3),padding=\"SAME\",activation=\"relu\")(x)\n    x=Conv2D(128,(3,3),padding=\"SAME\",activation=\"relu\")(x)\n    x=Conv2D(128,(3,3),padding=\"SAME\",activation=\"relu\")(x)\n    x=MaxPool2D(pool_size=(2,2))(x)\n    x=Dropout(0.20)(x)\n    \n    #L4\n    x=Conv2D(256,(3,3),padding=\"SAME\",activation=\"relu\")(x)\n    x=Conv2D(256,(3,3),padding=\"SAME\",activation=\"relu\")(x)\n    x=Conv2D(256,(3,3),padding=\"SAME\",activation=\"relu\")(x)\n    x=MaxPool2D(pool_size=(2,2))(x)\n    x=Dropout(0.20)(x)\n    \n\n    #flatten\n    x=Flatten()(x)\n    x=Dense(1152, activation = \"relu\")(x)\n    x=Dropout(rate=0.25)(x)\n    dense=Dense(324, activation = \"relu\")(x)\n    dense=Dropout(rate=0.3)(dense)\n\n    #out\n    head_root = Dense(168, activation = 'softmax',name=\"roots\")(dense)\n    head_vowel = Dense(11, activation = 'softmax',name=\"vowels\")(dense)\n    head_consonant = Dense(7, activation = 'softmax',name=\"consonants\")(dense)\n\n    model = Model(inputs=inp, outputs=[head_root, head_vowel, head_consonant])\n    \n    return model\n\n\n\ndef load_img_data(path,img_size):\n    \n    df=pd.read_parquet(path,engine=\"pyarrow\")\n    df=df.drop([\"image_id\"],axis=1)\n    a=df.values\n    a.astype(\"float16\")\n    a=np.reshape( a,(a.shape[0],)+(137,236))\n    s=a.shape[0]\n    \n    \n    A=[]\n    for i in a:\n        A.append(list(cv2.resize(i,(img_size,img_size))))\n    A=np.array(A)/255\n    \n    X_train=A.reshape(-1,img_size,img_size,1)\n    \n    print(\"IMG Data Created, Shape:\", A.shape)\n    \n    del df\n    del a\n    gc.collect()\n    \n    return X_train,s\n\n\n###----train-----\n\n\n\n#variables\nimg_size=74\nBATCH_SIZE=84\nlepochs=[10,30,30,80]\n\n#NAME=\"WTFWTF{}\".format(int(time.time()))\n#tensorboard= TensorBoard(log_dir='logs/{}'.format(NAME))\n\n\ninp=Input(shape=(img_size,img_size,1))\nmodel=SimpleNet(inp)\n\n\nadamm=keras.optimizers.Adam(learning_rate=0.0003, beta_1=0.9, beta_2=0.999, amsgrad=False)\n\n#lrr_root = ReduceLROnPlateau(monitor='roots_accuracy',patience=2,verbose=1,factor=0.5,cooldown=3,min_lr=0.000005)\n#callbacks= [lrr_root]\n\n#model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\nmodel.compile(optimizer=adamm, loss='categorical_crossentropy', metrics=['accuracy'])\n    \n\nmodel.summary()\n\n\n\nt1=time.time()\nsp=0\nhistories=[]\nfor i in [0,1,2,3]:\n    \n    epochs=lepochs[i]\n    print(\"Begin Loading Data Set:\",i)\n    \n    #GET DATA\n    path=\"/kaggle/input/bengaliai-cv19/train_image_data_\"+str(i)+\".parquet\"\n    X_train, L = load_img_data(path,img_size=img_size)\n    \n    train_df=pd.read_csv(\"/kaggle/input/bengaliai-cv19/train.csv\")\n    root = pd.get_dummies(train_df['grapheme_root']).values[sp:sp+L]\n    vowel = pd.get_dummies(train_df['vowel_diacritic']).values[sp:sp+L]\n    consonant = pd.get_dummies(train_df['consonant_diacritic']).values[sp:sp+L]\n    \n    print(\"Label Data Created, Shape:\", root.shape, consonant.shape, vowel.shape)\n    \n    \n    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, root, vowel, consonant, test_size=0.08, random_state=666)\n    sp=sp+L\n    \n    \n    if i==3:\n        model.optimizer.optimizer.lr = 0.0002\n        \n#     if i==2:\n#         model.optimizer.optimizer.lr = 0.0000125\n    \n#     if i==3:\n#         model.optimizer.optimizer.lr = 0.0000075\n\n#     print(model.optimizer.optimizer.lr)\n    \n    #SETUP\n    datagen = MultiOutputDataGenerator(featurewise_center=False,samplewise_center=False,featurewise_std_normalization=False,samplewise_std_normalization=False,zca_whitening=False,rotation_range=8,zoom_range = 0.15,width_shift_range=0.15,height_shift_range=0.15,horizontal_flip=False,vertical_flip=False)\n    datagen.fit(x_train)\n\n    #RUN\n    \n    print(\"Start Training Iter:\",i)\n    history = model.fit_generator(datagen.flow(x_train, {'roots': y_train_root, 'vowels': y_train_vowel, 'consonants': y_train_consonant}, batch_size=BATCH_SIZE),epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]),steps_per_epoch=x_train.shape[0] // BATCH_SIZE)\n    \n    print(history)\n    \n    del train_df\n    del root\n    del vowel\n    del consonant\n    del x_train\n    del x_test\n    del y_test_root\n    del y_train_vowel\n    del y_test_vowel\n    del y_train_consonant\n    del y_test_consonant\n    gc.collect()\n    \n    h1=history.history[\"roots_accuracy\"]\n    v1=history.history[\"roots_loss\"]\n    histories.append(h1)\n    plt.plot(h1)\n    plt.show()\n    \n    plt.plot(v1)\n    plt.show()\n    \n#     plt.plot(list(range(len(histories))),histories)\n#     plt.show()\n    \nprint(\"Done!\")\nprint(time.time() - t1)\n\n\n\n# histories=history.history[\"roots_accuracy\"]\n# h0,h1,h2,h3 = histories[0:epochs], histories[epochs:epochs*2], histories[epochs*2:epochs*3], histories[epochs*3:epochs*4]\n\n# plt.plot(list(range(0,epochs)), h0, color=\"b\") \n# plt.plot(list(range(epochs,epochs*2)), h1, color=\"r\")\n# plt.plot(list(range(epochs*2,epochs*3)), h2, color=\"b\")\n# plt.plot(list(range(epochs*3,epochs*4)), h3, color=\"g\")\n\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h1=history.history[\"roots_accuracy\"]\nv1=history.history[\"roots_loss\"]\n\nprint(\"Max\", h1[-1])\nprint(\" \")\nplt.plot(h1)\nplt.show()\n\nplt.plot(v1)\nplt.show()\n    \n\npreds_dict = {'grapheme_root': [], 'vowel_diacritic': [], 'consonant_diacritic': []}\n    \ncomponents = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntarget,row_id=[],[]\n\nimg_size=74\nfor i in range(4):\n    \n    path='/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i)\n    X_test,L = load_img_data(path,img_size)\n    \n    preds = model.predict(X_test)\n    #print(preds)\n    print(\"Getting df again...\")\n    df_test_img = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i))\n    df_test_img.set_index('image_id', inplace=True)\n    \n    print(df_test_img.head())\n    \n    for i, p in enumerate(preds_dict):\n        preds_dict[p] = np.argmax(preds[i], axis=1)\n\n    for k,id in enumerate(df_test_img.index.values):  \n        for i,comp in enumerate(components):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n\n    del df_test_img\n    del X_test\n    gc.collect()\n\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\ndf_sample.to_csv('submission.csv',index=False)\nprint(df_sample.head())\n\nprint(\"Time\", time.time() - t1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}