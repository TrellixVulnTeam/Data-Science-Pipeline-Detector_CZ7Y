{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Here is my experiments on SqueezeNet.\n\n[SqueezeNet](https://arxiv.org/pdf/1602.07360.pdf)\n\n[training code](https://github.com/meyson/bengaliai-cv19)\n\nSome ideas form [@abhishek](https://www.kaggle.com/abhishek)'s youtube channel."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import sys\nimport glob\nimport os\n\nimport albumentations as A\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm.notebook import tqdm_notebook as tqdm \nfrom PIL import Image\n\nsys.path.insert(0, '../input/pretrained-models/pretrained-models.pytorch-master/')\nimport pretrainedmodels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_HEIGHT = 137\nIMG_WEIGHT = 236\nTEST_BATCH_SIZE = 32\nDEVICE = 'cuda'\n\nUSE_RGB = False\n\nImageNetStat = {\n    'mean': [0.485, 0.456, 0.406],\n    'std': [0.229, 0.224, 0.225]\n}\n\nBengaliAIStat = {\n    'mean': [0.06922848809290576],\n    'std': [0.20515700083327537]\n}\n\nSTAT = ImageNetStat if USE_RGB else BengaliAIStat\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class SqueezeNet(nn.Module):\n    def __init__(self, pretrained=True, use_rgb=True):\n        super(SqueezeNet, self).__init__()\n\n        if pretrained:\n            self.model = pretrainedmodels.models.squeezenet1_1(pretrained='imagenet')\n        else:\n            self.model = pretrainedmodels.models.squeezenet1_1(pretrained=None)\n\n        if not use_rgb:\n            # modify first layer\n            first_conv = nn.Conv2d(1, 64, kernel_size=3, stride=2)\n            init.kaiming_uniform_(first_conv.weight)\n            self.model.features[0] = first_conv\n\n        self.l0 = nn.Linear(512, 168)\n        self.l1 = nn.Linear(512, 11)\n        self.l2 = nn.Linear(512, 7)\n\n    def forward(self, x):\n        N = x.shape[0]\n\n        x = self.model.features(x)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(N, -1)\n        s0 = self.l0(x)\n        s1 = self.l1(x)\n        s2 = self.l2(x)\n        return s0, s1, s2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\n\nclass BengaliDatasetTest(Dataset):\n    def __init__(self, df, aug=None, use_rgb=USE_RGB):\n        self.img_arr = df.iloc[:, 1:].values\n        self.image_id = df.image_id.values\n\n        del df\n        gc.collect()\n    \n        self.img_arr = self.img_arr.reshape(-1, 137, 236)\n        self.aug = aug\n        self.use_rgb = use_rgb\n\n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        image = Image.fromarray(self.img_arr[index])\n        image_id = self.image_id[index]\n        \n        if self.use_rgb:\n            image = image.convert('RGB')\n\n        image = np.array(image)\n\n        if self.aug is not None:\n            image = self.aug(image=image)['image']\n\n        image = image.astype(np.float32)\n\n        if self.use_rgb:\n            image = image.transpose((2, 0, 1))\n        else:\n            image = image[np.newaxis, :]\n\n        return {\n            'image': torch.tensor(image, dtype=torch.float32),\n            'image_id': image_id\n        }\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return len(self.image_id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(loader, model, fold):\n    model.eval()\n    model.load_state_dict(torch.load(fold))\n\n    scores = {'g': [], 'v': [], 'c': []}\n    with torch.no_grad():\n        for i, d in tqdm(enumerate(loader), total=len(loader)):\n            image = d['image'].to(DEVICE)\n            g, v, c = model(image)\n            g = g.cpu().numpy()\n            v = v.cpu().numpy()\n            c = c.cpu().numpy()\n            for i in range(len(d['image'])):\n                scores['g'].append(g[i])\n                scores['v'].append(v[i])\n                scores['c'].append(c[i])\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\n\ntest_files = glob.glob('../input/bengaliai-cv19/test_image_data_*.parquet')\nfor f in tqdm(test_files, total=len(test_files)):\n    df = pd.read_parquet(f)\n    \n    dataset = BengaliDatasetTest(\n        df=df,\n        aug=A.Compose([\n            A.Resize(IMG_HEIGHT, IMG_WEIGHT, always_apply=True),\n            A.Normalize(**STAT)\n        ]),\n        use_rgb=USE_RGB\n    )\n    \n    loader = DataLoader(\n        dataset=dataset,\n        batch_size=TEST_BATCH_SIZE,\n        num_workers=4,\n        pin_memory=True\n    )\n    \n    model = SqueezeNet(pretrained=False, use_rgb=USE_RGB)\n    model.to(DEVICE)\n\n    folds = glob.glob('../input/bengaliaicv19-squeezenet-pretrained/pretrained_models/squeezenet_train_folds_*.h5')\n    gvc_scores = [predict(loader, model, fold) for fold in folds]\n\n    \n    g = np.mean([p['g'] for p in gvc_scores], axis=0)\n    v = np.mean([p['v'] for p in gvc_scores], axis=0)\n    c = np.mean([p['c'] for p in gvc_scores], axis=0)\n    image_id = dataset.image_id\n    \n    g_preds = np.argmax(g, axis=1)\n    v_preds = np.argmax(v, axis=1)\n    c_preds = np.argmax(c, axis=1)\n\n    for j, img_id in enumerate(image_id):\n        predictions.append((f'{img_id}_consonant_diacritic', (c_preds[j])))\n        predictions.append((f'{img_id}_grapheme_root', (g_preds[j])))\n        predictions.append((f'{img_id}_vowel_diacritic', (v_preds[j])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(predictions, columns=['row_id', 'target'])\nsub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}