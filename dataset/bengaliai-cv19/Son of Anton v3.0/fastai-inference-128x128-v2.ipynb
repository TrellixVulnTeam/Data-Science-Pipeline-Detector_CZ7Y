{"cells":[{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"%%time\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport matplotlib.pyplot as  py\nimport cv2\nimport pandas as pd\nfrom fastai.vision import *\nimport os\nimport glob\nimport imageio\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" <h1>Preprocessing to obtain 128x128 images</h1>"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nHEIGHT = 137\nWIDTH = 236\nSIZE = 128\nstats = (0.0692, 0.2051)\n#check https://www.kaggle.com/iafoss/image-preprocessing-128x128\nTEST = ['/kaggle/input/bengaliai-cv19/train_image_data_0.parquet',\n        '/kaggle/input/bengaliai-cv19/train_image_data_1.parquet',\n        '/kaggle/input/bengaliai-cv19/train_image_data_2.parquet',\n        '/kaggle/input/bengaliai-cv19/train_image_data_3.parquet']\ndef bbox(img):\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    return rmin, rmax, cmin, cmax\n\ndef crop_resize(img0, size=SIZE, pad=16):\n    #crop a box around pixels large than the threshold \n    #some images contain line at the sides\n    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n    #cropping may cut too much, so we need to add it back\n    xmin = xmin - 13 if (xmin > 13) else 0\n    ymin = ymin - 10 if (ymin > 10) else 0\n    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n    img = img0[ymin:ymax,xmin:xmax]\n    #remove lo intensity pixels as noise\n    img[img < 28] = 0\n    lx, ly = xmax-xmin,ymax-ymin\n    l = max(lx,ly) + pad\n    #make sure that the aspect ratio is kept in rescaling\n    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n    return cv2.resize(img,(size,size))\nima=[]\nfor fname in TEST:\n    df = pd.read_parquet(fname)\n        #the input is inverted\n    data = 255 - df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n    for idx in range(len(df)):\n        #name = df.iloc[idx,0]\n        #normalize each image by its max val\n        img = (data[idx]*(255.0/data[idx].max())).astype(np.uint8)\n        img = crop_resize(img)\n        ima.append(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del TEST\ndel HEIGHT\ndel WIDTH\ndel SIZE\ndel img\ndel data\ndel df\n       ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Saving the images in a directory\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nim128=np.array(ima)\ndef save_imgs(path:Path, data):\n    path.mkdir(parents=True,exist_ok=True)\n    for i in range(len(data)):\n        imageio.imsave(path/'{}.png'.format(i),data[i])\n        \nsave_imgs(Path('/data/test'),im128)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!cp /kaggle/input/grapheme-imgs-128x128 -r /data/train\ndel ima\ndel im128","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Databunch creation for test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nptrain = pd.read_csv('/kaggle/input/bengaliai-cv19/train.csv')\nptrain['Image_path'] = ptrain.apply(lambda row: '/kaggle/input/grapheme-imgs-128x128/' + row.image_id + '.png', axis = 1)\nptrain['grapheme_root'] = ptrain.apply(lambda row: str(row.grapheme_root), axis = 1)\nptrain['vowel_diacritic'] = ptrain.apply(lambda row: str(row.vowel_diacritic), axis = 1)\nptrain['consonant_diacritic'] = ptrain.apply(lambda row: str(row.consonant_diacritic), axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\nptra=glob.glob('/kaggle/input/grapheme-imgs-128x128/*')\np1=pd.DataFrame(ptra,columns=['Image_path'])\ndef process(s):\n    return str(s).split('/')[4]\np1['Image_path']=p1['Image_path'].apply(process)\nptrain['Image_path']=ptrain['Image_path'].apply(process)\np3=p1.merge(ptrain,on='Image_path',)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del ptrain\ndel p1\ndel ptra","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time\ntfms = get_transforms(do_flip=False,)\ndata = ImageDataBunch.from_folder('../input', \n                                  train=\"grapheme-imgs-128x128\",\n                                  size=128,bs=128).normalize(stats)\ntest=ImageList.from_folder('/data/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.add_test(test,tfm_y=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Databunch creation for training images"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndata_cd = ImageDataBunch.from_df(path='/kaggle/input/',folder='grapheme-imgs-128x128',df=p3,bs=128,size=128,label_col='consonant_diacritic',tfm_y=False).normalize(imagenet_stats)\ndata_gr = ImageDataBunch.from_df(path='/kaggle/input/',folder='grapheme-imgs-128x128',df=p3,bs=128,size=128,label_col='grapheme_root',tfm_y=False).normalize(imagenet_stats)\ndata_vd = ImageDataBunch.from_df(path='/kaggle/input/',folder='grapheme-imgs-128x128',df=p3,bs=128,size=128,label_col='vowel_diacritic',tfm_y=False).normalize(imagenet_stats)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model loading "},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif not os.path.exists('/root/.cache/torch/checkpoints'):\n        os.makedirs('/root/.cache/torch/checkpoints')\n!cp /kaggle/input/fastai-pretrained-models/densenet121-a639ec97.pth /root/.cache/torch/checkpoints/densenet121-a639ec97.pth\n\nlearn_cd = cnn_learner(data_cd, models.densenet121, metrics=[error_rate, accuracy],model_dir = Path('../kaggle/working'),).to_fp16()\nlearn_vd = cnn_learner(data_vd, models.densenet121, metrics=[error_rate, accuracy],model_dir = Path('../kaggle/working'),).to_fp16()\nlearn_gr = cnn_learner(data_gr, models.densenet121, metrics=[error_rate, accuracy], model_dir = Path('../kaggle/working'),).to_fp16()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del data_cd\ndel data_vd\ndel data_gr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"%%capture\nlearn_gr.load('/kaggle/input/modelgr/best_gr_model')\nlearn_cd.load('/kaggle/input/models/best_cd_model',)\nlearn_vd.load('/kaggle/input/models/best_vd_model',)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%capture\nm1_pred1=[]\nm2_pred2=[]\nm3_pred3=[]\nfor i in data.test_ds:\n    y1=learn_cd.predict(i[0])\n    y2=learn_vd.predict(i[0])\n    y3=learn_gr.predict(i[0])\n    m2_pred2.append(y1[1].item())\n    m3_pred3.append(y2[1].item())\n    m1_pred1.append(y3[1].item())\n    del y1\n    del y2\n    del y3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del learn_gr\ndel learn_vd\ndel learn_cd","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting data to submission format\n\n# m1 CD\n# m2 VD\nsample_sub = pd.read_csv('/kaggle/input/bengaliai-cv19/sample_submission.csv')\ncd = 0 \ncd_itr = 0\ngr = 1\ngr_itr = 0\nvd = 2 \nvd_itr = 0\nlength = sample_sub['target'].shape[0]\nfor i in range(length):\n    if(i==gr):\n        sample_sub.at[i,'target'] = m1_pred1[gr_itr]\n        gr_itr+=1\n        gr+=3\n    if(i==cd):\n        sample_sub.at[i,'target'] = m2_pred2[cd_itr]\n        cd_itr+=1\n        cd+=3\n    elif(i==vd):\n        sample_sub.at[i,'target'] = m3_pred3[vd_itr]\n        vd_itr+=1\n        vd+=3\n#print(sample_sub.head())\ndel cd\ndel cd_itr\ndel gr\ndel gr_itr\ndel vd\ndel vd_itr\ndel length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Writing to submission csv file\nsample_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del sample_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}