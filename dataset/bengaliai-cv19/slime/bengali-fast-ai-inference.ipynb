{"cells":[{"metadata":{},"cell_type":"markdown","source":"This entire notebook is modified from lafoss notebook. Thank you so much for creating helpful kernels."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import *\nfrom tqdm import tqdm_notebook as tqdm\nimport gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# original size of images\nHEIGHT = 137\nWIDTH = 236","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ComponentMetric(Callback):\n    def __init__(self, start, end):\n        super().__init__()\n        self.start = start\n        self.end = end\n        self.tp = 0\n        self.total = 0\n        self.batch_num = 0\n    def on_epoch_begin(self, **kwargs):\n        self.tp = 0\n        self.total = 0\n\n    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n        assert last_output.shape == last_target.shape # sanity check\n        last_output = last_output[:, self.start: self.end]\n        last_target = last_target[:, self.start: self.end]\n        preds = last_output.argmax(1).cpu()\n        targs = last_target.argmax(1).cpu()\n        self.tp += (preds == targs).sum()\n#         print('batch num: {}, sum: {}, tp: {}, total: {}'.format(self.batch_num, (preds == targs).sum(), self.tp, self.total))\n        self.total += last_output.shape[0]\n        self.batch_num += 1\n#         return (preds == targs).sum().item() # return value for testing only\n    \n    def on_epoch_end(self, last_metrics, **kwargs):     \n        print('{}, tp: {}, total: {}'.format(last_metrics, self.tp, self.total))\n        return add_metrics(last_metrics, float(self.tp)/self.total) # integer divide yields zero\n    \n    \nclass TotalMetric(Callback):\n    def __init__(self):\n        super().__init__()\n        self.grapheme = ComponentMetric(0, 168)\n        self.vowel = ComponentMetric(168, 179)\n        self.consonant = ComponentMetric(179, 187)\n        \n    def on_epoch_begin(self, **kwargs):\n        self.grapheme.on_epoch_begin(**kwargs)\n        self.vowel.on_epoch_begin(**kwargs)\n        self.consonant.on_epoch_begin(**kwargs)\n    \n    def on_batch_end(self, last_output:Tensor, last_target:Tensor, **kwargs):\n        self.grapheme.on_batch_end(last_output, last_target, **kwargs)\n        self.vowel.on_batch_end(last_output, last_target, **kwargs)\n        self.consonant.on_batch_end(last_output, last_target, **kwargs)\n        \n    def on_epoch_end(self, last_metrics, **kwargs): \n        return add_metrics(last_metrics, 0.5*self.grapheme._recall() +\n                0.25*self.vowel._recall() + 0.25*self.consonant._recall())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = load_learner('/kaggle/input/bengali-fast-ai-training/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def parse_prediction(pred_string):\n    pred_string = pred_string.split(';')\n    pred_dict = {'g': None, 'v': None, 'c': None} # ensure that we only get at most one value per field\n    for p in pred_string:\n        p = p.split('_')\n        if pred_dict[p[0]] is None:\n            pred_dict[p[0]] = p[1]\n    return [int(x) if x is not None else 0 for x in pred_dict.values()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# unit test\nparse_prediction('g_15;v_0;c_3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count = 0\nrow_id = []\ntarget= []\n\nfor i in range(4):\n    test = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i))\n    data = test.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n    # hacky way of converting a numpy array img into a fastai Image object.\n    for img in data:\n        img = np.stack((img,)*3, axis=-1)\n        img = pil2tensor(img,np.float32).div_(255)\n        # gets the Multicategory portion of the prediction and converts to string\n        # format looks something like: g_3;v_0;c_0\n        pred_string = str(learn.predict(Image(img))[0])\n        prediction = parse_prediction(pred_string)\n        row_id += ['Test_{}_grapheme_root'.format(count), \n                   'Test_{}_vowel_diacritic'.format(count), \n                   'Test_{}_consonant_diacritic'.format(count)]\n        target += prediction\n        count += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame({'row_id': row_id, 'target': target})\nsub_df.to_csv('submission.csv', index=False)\nsub_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}