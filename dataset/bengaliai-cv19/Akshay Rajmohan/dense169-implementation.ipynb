{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfrom tqdm.auto import tqdm\nfrom keras import layers,optimizers\nimport numpy as np\nimport pandas as pd\nimport gc\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport cv2\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, Input, load_model\nfrom keras.layers import Dense, Conv2D, Flatten, Activation, Concatenate\nfrom keras.layers import MaxPool2D, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom keras.initializers import RandomNormal\nfrom keras.applications import DenseNet169\nfrom sklearn.model_selection import train_test_split\nfrom keras.layers import LeakyReLU\nfrom skimage import exposure","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DIR = '../input/bengaliai-cv19'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(os.path.join(DIR,'train.csv'))\ntest_df = pd.read_csv(os.path.join(DIR,'test.csv'))\nclass_map_df = pd.read_csv(os.path.join(DIR,'class_map.csv'))\nsample_sub_df = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\n                            \nimg_df = pd.read_parquet(os.path.join(DIR,'train_image_data_0.parquet'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc_df = train_df[tgt_cols].astype('str').describe()\ndesc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"desc_df = train_df[tgt_cols].astype('str').describe()\ndesc_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"types = desc_df.loc['unique',:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SIZE = 64    \nN_ch = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_densenet():\n    \n    \n    densenet = DenseNet169(weights='imagenet', include_top=False)\n\n    input = Input(shape=(SIZE, SIZE, N_ch))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = densenet(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256)(x)\n    x= LeakyReLU(alpha=0.1)(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    grapheme_root = Dense(types['grapheme_root'],\n                          activation = 'softmax', name='root')(x)\n    vowel_diacritic = Dense(types['vowel_diacritic'],\n                            activation = 'softmax', name='vowel')(x)\n    consonant_diacritic = Dense(types['consonant_diacritic'],\n                                activation = 'softmax', name='consonant')(x)\n\n    # model\n    model = Model(input,\n                  [grapheme_root, vowel_diacritic, consonant_diacritic])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_densenet()\n    \n    \nmodel.compile(Adam(lr=0.002),\n              loss={'root': 'categorical_crossentropy',\n                    'vowel': 'categorical_crossentropy',\n                    'consonant': 'categorical_crossentropy'},\n              metrics={'root': 'accuracy',\n                       'vowel': 'accuracy',\n                       'consonant': 'accuracy'}\n             )\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def AHE(img):\n    img_adapteq = exposure.equalize_adapthist(img, clip_limit=0.03)\n    return img_adapteq","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def resize(df, size=64):\n    resized = {}\n    for i in range(df.shape[0]):\n        img = AHE(df.loc[df.index[i]].values.reshape(137,236))\n        image = cv2.resize(img,(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized_df = pd.DataFrame(resized).T\n    return resized_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_df = img_df.drop(['image_id'], axis = 1)\nX_df = (resize(img_df, SIZE) / 255.).astype('float32')\ndel img_df\ngc.collect()\nfor i in tqdm(range(1,4)):\n    img_df = pd.read_parquet(os.path.join(\n    DIR, 'train_image_data_'+str(i)+'.parquet'))\n    img_df = img_df.drop(['image_id'], axis = 1)\n    img_df = (resize(img_df, SIZE) / 255.).astype('float32')\n    X_df = pd.concat([X_df, img_df], axis = 0)\n    del img_df\n    gc.collect()\n    \nX_train = X_df.values.reshape(-1, SIZE, SIZE, N_ch)\ndel X_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = train_df[tgt_cols].astype('uint8')\nfor col in tgt_cols:\n    train_df[col] = train_df[col].map('{:03}'.format)\nY_train = pd.get_dummies(train_df)\n\ndel train_df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X_train, Y_train,\n                                                test_size=0.1, random_state=42)\ny_train_root = y_train.iloc[:,0:types['grapheme_root']]\ny_train_vowel = y_train.iloc[:,types['grapheme_root']:types['grapheme_root']+types['vowel_diacritic']]\ny_train_consonant = y_train.iloc[:,types['grapheme_root']+types['vowel_diacritic']:]\ny_test_root = y_test.iloc[:,0:types['grapheme_root']]\ny_test_vowel = y_test.iloc[:,types['grapheme_root']:types['grapheme_root']+types['vowel_diacritic']]\ny_test_consonant = y_test.iloc[:,types['grapheme_root']+types['vowel_diacritic']:]\n    \ndel X_train, Y_train\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 25","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reduceLR = ReduceLROnPlateau(monitor = 'val_root_loss',\n                             patience = 2,\n                             factor = 0.5,\n                             min_lr = 1e-5,\n                             verbose = 1)\n\nchkPoint = ModelCheckpoint('dense169.h5',\n                           monitor = 'val_root_accuracy',\n                           save_best_only = True,\n                           save_weights_only = False,\n                           mode = 'auto',\n                           period = 1,\n                           verbose = 0)\n\nearlyStop = EarlyStopping(monitor='val_root_accuracy',\n                          mode = 'auto',\n                          patience = 3,\n                          min_delta = 0,\n                          verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"H = model.fit(x_train,\n                    {'root': y_train_root,\n                     'vowel': y_train_vowel,\n                     'consonant': y_train_consonant},\n                    batch_size=batch_size,\n                    epochs =epochs,\n                    shuffle = True,\n                    validation_data = (x_test,\n                                       {'root': y_test_root,\n                                        'vowel': y_test_vowel,\n                                        'consonant': y_test_consonant}),\n                    callbacks = [reduceLR, chkPoint, earlyStop],\n                    verbose = 1)\n\ndel x_train, x_test, y_train, y_test\ngc.collect()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"row_ids = []\ntargets = []      # prediction result\nid = 0\nfor i in range(4):\n    img_df = pd.read_parquet(os.path.join(\n                            DIR, 'test_image_data_'+str(i)+'.parquet'))\n    img_df = img_df.drop('image_id', axis = 1)\n    img_df = resize(img_df, SIZE) / 255.\n    X_test = img_df.values.reshape(-1, SIZE, SIZE, N_ch)\n\n    preds = model.predict(X_test)\n    for j in range(len(X_test)):\n        for k in range(3):\n            row_ids.append('Test_'+str(id)+'_'+tgt_cols[k])\n            targets.append(np.argmax(preds[k][j]))\n        id += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df = pd.DataFrame({'row_id':row_ids,'target':targets},\n                         columns = ['row_id','target'])\nsubmit_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}