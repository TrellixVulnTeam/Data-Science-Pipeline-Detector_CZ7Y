{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom keras.models import Model\nfrom keras.layers import *\n\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\nimport zipfile\nimport io\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n!pip install '/kaggle/input/kerasefficientnetb3/efficientnet-1.0.0-py3-none-any.whl'\nimport efficientnet.keras as efn\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.xception import Xception\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_v3 import InceptionV3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data=pd.read_csv('/kaggle/input/bengaliai-cv19/train.csv')\ntrain_data=train_data.drop(['image_id','grapheme'],axis=1)\n\nimage_data=['/kaggle/input/bengaliai-cv19/train_image_data_0.parquet',\n         '/kaggle/input/bengaliai-cv19/train_image_data_1.parquet',\n         '/kaggle/input/bengaliai-cv19/train_image_data_2.parquet',\n         '/kaggle/input/bengaliai-cv19/train_image_data_3.parquet']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_data.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from matplotlib import pyplot\n# def show_image(idd,batch=0):\n#     data=np.matrix(test_image_data_0.iloc[idd][1:].values,dtype=np.int32).reshape(137,236)\n#     pyplot.imshow(data,cmap='gray')\n# show_image(idd=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SIZE=75","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport cv2\nimport albumentations as A\n\ndef resize(df, size=SIZE, need_progress_bar=True):\n    resized = {}\n    resize_size=SIZE\n    if True:\n        for i in tqdm(range(df.shape[0])):\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            augBright=A.RandomBrightnessContrast(p=1.0)\n            image = augBright(image=image)['image']\n            _, thresh = cv2.threshold(image, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(image,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            idx = 0 \n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                idx += 1\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)/255\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef get_model():\n\n     \n#     model = InceptionV3(input_shape=(SIZE,SIZE,3),weights=\"/kaggle/input/keras-pretrained-models/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top=False,)\n#     model = Xception(input_shape=(SIZE,SIZE,3),weights=\"/kaggle/input/keras-pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top=False,)\n#     model = InceptionResNetV2(input_shape=(SIZE,SIZE,3),weights=\"/kaggle/input/keras-pretrained-models/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top=False,)\n#     model = ResNet50(input_shape=(SIZE,SIZE,3),weights=\"/kaggle/input/keras-pretrained-models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top=False,)\n#     model = VGG16(input_shape=(SIZE,SIZE,3),weights=\"/kaggle/input/keras-pretrained-models/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\",include_top=False,)\n    model=efn.EfficientNetB7(input_shape=(SIZE,SIZE,3),include_top=False,weights='/kaggle/input/effi-net-b7-weights/efficientnet-b7_weights_tf_dim_ordering_tf_kernels_autoaugment_notop.h5')\n\n\n\n    X=GlobalAveragePooling2D()(model.output)\n    x = BatchNormalization()(X)\n    x = Dropout(0.3)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.3)(x)\n\n    \n    X_vowel = Dense(11, activation='softmax',name='vowel')(x)\n    X_const=Dense(7, activation='softmax',name='const')(x)\n    X_root = Dense(168, activation='softmax',name='root')(x)\n\n    model=Model(inputs=model.inputs,outputs=[X_root,X_vowel,X_const])\n\n\n    return model\nmodel=get_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layer in model.layers:\n    layer.trainable=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nfrom tensorflow.keras.metrics import categorical_accuracy, top_k_categorical_accuracy\nmodel.compile(optimizer = Adam(lr=0.01), loss={'root': 'categorical_crossentropy',\n                    'vowel': 'categorical_crossentropy',\n                    'const': 'categorical_crossentropy'},metrics=[categorical_accuracy])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import *\nTRAIN=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load Data 1\nfrom sklearn.model_selection import train_test_split\nif not TRAIN:\n    rlrp = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, min_delta=1E-30,verbose=1)\n    i=0\n    print(\"Reading data for \",i)\n    train_image_data=pd.read_parquet(image_data[i])\n    train_image_data=train_image_data.drop('image_id',axis=1)\n    b_size=train_image_data.shape[0]\n    fac=10\n    half_b_size=b_size//fac\n    \n    print(\"Data Read.\")\n        \n    \n    for part in range(fac):\n        \n        print(\"Resizing for \",i,part)\n    \n\n        X1=resize(train_image_data[part*half_b_size:(part+1)*half_b_size])\n        print(\"Resized \",i,part)\n    \n        print(\"Input Shape Before : \",X1.shape)\n        X1_stacked=(X1.values.reshape(X1.shape[0],SIZE,SIZE,1))\n        X1_stacked=np.stack((X1_stacked,X1_stacked,X1_stacked),axis=3).reshape(X1.shape[0],SIZE,SIZE,3,)\n        print(\"Input Shape After : \",X1_stacked.shape)\n    \n    \n        Y1=train_data.loc[i*part*half_b_size:(i+1)*(part+1)*half_b_size-1,:]\n\n        X1_train,X1_test,Y1_train_root,Y1_test_root,Y1_train_vowel,Y1_test_vowel,Y1_train_const,Y1_test_const=train_test_split(X1_stacked,pd.get_dummies(Y1['grapheme_root']).values, pd.get_dummies(Y1['vowel_diacritic']).values,pd.get_dummies(Y1['consonant_diacritic']).values,test_size=0.1)\n    \n        model.fit( X1_train,[Y1_train_root,Y1_train_vowel,Y1_train_const,],validation_data=(X1_test,[Y1_test_root,Y1_test_vowel,Y1_test_const]),batch_size=32,epochs=10,callbacks=[rlrp])\n    \n        del X1,Y1   \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ACTUAL TRAINING\nfrom keras.callbacks.callbacks import ModelCheckpoint\n\nif TRAIN:\n    rlrp = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=2, min_delta=1E-30,verbose=1)\n    vlbk = ModelCheckpoint(filepath='/kaggle/working/weights.hdf5', verbose=1, save_best_only=True)\n\n    for i in range(4):\n        gc.collect()\n        print(\"Reading data for \",i)\n        train_image_data=pd.read_parquet(image_data[i])\n        \n        train_image_data=train_image_data.drop('image_id',axis=1)\n        \n        b_size=train_image_data.shape[0]\n        fac=10\n        half_b_size=b_size//fac\n    \n        print(\"Data Read.\")\n        \n    \n        for part in range(fac):\n            gc.collect()\n        \n            print(\"Resizing for \",i,part)\n            X1=resize(train_image_data[part*half_b_size:(part+1)*half_b_size])\n            print(\"Resized \",i,part)\n    \n            X1_stacked=(X1.values.reshape(X1.shape[0],SIZE,SIZE,1))\n            X1_stacked=np.stack((X1_stacked,X1_stacked,X1_stacked),axis=3).reshape(X1.shape[0],SIZE,SIZE,3,)\n            print(\"Input Shape After : \",X1_stacked.shape)\n    \n    \n            Y1=train_data.loc[i*b_size+(part*half_b_size):(i*b_size)+((part+1)*half_b_size)]\n\n            X1_train,X1_test,Y1_train_root,Y1_test_root,Y1_train_vowel,Y1_test_vowel,Y1_train_const,Y1_test_const=train_test_split(X1_stacked,pd.get_dummies(Y1['grapheme_root']).values, pd.get_dummies(Y1['vowel_diacritic']).values,pd.get_dummies(Y1['consonant_diacritic']).values,test_size=0.05)\n    \n            model.fit( X1_train,[Y1_train_root,Y1_train_vowel,Y1_train_const,],validation_data=(X1_test,[Y1_test_root,Y1_test_vowel,Y1_test_const]),batch_size=64,epochs=10,callbacks=[rlrp])\n    \n            del X1,Y1,X1_train,X1_test,Y1_train_root,Y1_test_root,Y1_train_vowel,Y1_test_vowel,Y1_train_const,Y1_test_const,X1_stacked\n        del train_image_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save(\"/kaggle/working/model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\npreds_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}\n\ncomponents = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntarget=[] # model predictions placeholder\nrow_id=[] # row_id place holder\nfor i in range(4):\n    df_test_img = pd.read_parquet(f'/kaggle/input/bengaliai-cv19/test_image_data_{i}.parquet') \n    df_test_img.set_index('image_id', inplace=True)\n\n    X_test = resize(df_test_img, need_progress_bar=False)\n    \n    X1_stacked=(X_test.values.reshape(X_test.shape[0],SIZE,SIZE,1))\n    X1_stacked=np.stack((X1_stacked,X1_stacked,X1_stacked),axis=2).reshape(X_test.shape[0],SIZE,SIZE,3,)\n    \n    preds = model.predict(X1_stacked)\n\n    for i, p in enumerate(preds_dict):\n        preds_dict[p] = np.argmax(preds[i], axis=1)\n\n    for k,id in enumerate(df_test_img.index.values):  \n        for i,comp in enumerate(components):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n    del df_test_img\n    del X_test,X1_stacked\n    gc.collect()\n\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\ndf_sample.to_csv('submission.csv',index=False)\ndf_sample.head()\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}