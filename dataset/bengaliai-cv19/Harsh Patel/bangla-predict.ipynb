{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport os\nimport sys\nimport subprocess\nimport gc\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport keras\nimport tensorflow as tf\n\nimport math\nimport heapq\nfrom functools import partial, reduce\nimport functools\nimport random\nfrom kaggle_datasets import KaggleDatasets\nfrom tqdm.notebook import tqdm as tqdm\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!cp -r /kaggle/input/model-package/* /kaggle/working","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from classification_models.tfkeras import Classifiers\n\nSEResNext50, preprocess_input = Classifiers.get('seresnext50')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"tf.keras.backend.clear_session()\nHEIGHT = 137\nWIDTH = 236\nSIZE = 128\nBATCH_SIZE = 512\nGLOBAL_PIXEL_STATS = (np.array([0.06922849]),np.array([0.20515700]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bbox(img):\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    return rmin, rmax, cmin, cmax\n\ndef crop_resize(img0, size=SIZE, pad=16):\n    #crop a box around pixels large than the threshold \n    #some images contain line at the sides\n    ymin,ymax,xmin,xmax = bbox(img0[5:-5,5:-5] > 80)\n    #cropping may cut too much, so we need to add it back\n    xmin = xmin - 13 if (xmin > 13) else 0\n    ymin = ymin - 10 if (ymin > 10) else 0\n    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n    img = img0[ymin:ymax,xmin:xmax]\n    #remove lo intensity pixels as noise\n    img[img < 28] = 0\n    lx, ly = xmax-xmin,ymax-ymin\n    l = max(lx,ly) + pad\n    #make sure that the aspect ratio is kept in rescaling\n    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n    img = cv2.resize(img,(size,size))\n    \n    mean, std = GLOBAL_PIXEL_STATS\n    img = (img.astype(np.float32)- mean) / std\n    return cv2.resize(img,(size,size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if tf.test.is_gpu_available(cuda_only=True):\n    config = tf.compat.v1.ConfigProto( device_count = {'GPU': 1 , 'CPU': 1} ) \n    sess = tf.compat.v1.Session(config=config) \n    tf.compat.v1.keras.backend.set_session(sess)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# pred_resnet_model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_shape = (128,128,1), classes=168)\n# pred_model = tf.keras.layers.Dropout(rate=0.3)(pred_resnet_model.output)\n# pred_model = tf.keras.layers.Flatten()(pred_model)\n# pred_model = tf.keras.layers.Dense(1024, activation = \"relu\")(pred_model)\n# pred_model = tf.keras.layers.Dropout(rate=0.3)(pred_model)\n# pred_dense = tf.keras.layers.Dense(512, activation = \"relu\")(pred_model)\n\n# pred_head_root = tf.keras.layers.Dense(168, activation = 'softmax', name='grapheme_out')(pred_dense)\n# pred_head_vowel = tf.keras.layers.Dense(11, activation = 'softmax', name='vowel_out')(pred_dense)\n# pred_head_consonant = tf.keras.layers.Dense(7, activation = 'softmax', name='consonant_out')(pred_dense)\n\n# pred_model = tf.keras.Model(inputs=pred_resnet_model.input, outputs=[pred_head_root, pred_head_vowel, pred_head_consonant])\n\n# pred_model.compile(\n#         optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n#         loss={\n#               #\"fc1000\": categorical_focal_loss(gamma=2.0, alpha=0.25), #\"categorical_crossentropy\",\n#               \"grapheme_out\":  \"sparse_categorical_crossentropy\",\n#             \"vowel_out\":  \"sparse_categorical_crossentropy\",\n#             \"consonant_out\":  \"sparse_categorical_crossentropy\",\n#         },\n#         metrics=['top_k_categorical_accuracy', 'accuracy'])\n\n# pred_model.load_weights('/kaggle/input/bangla-keras-models/weights.10.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seresnext_model = SEResNext50(input_shape=(128,128,1), include_top=False)\nintermediate_layer = tf.keras.layers.GlobalAveragePooling2D()(seresnext_model.layers[-1].output)\nintermediate_layer = tf.keras.layers.BatchNormalization()(intermediate_layer)#(seresnext_model.layers[-3].output) #GLOBAL AVG POOLED LAYER\nintermediate_layer = tf.keras.layers.Dropout(0.5)(intermediate_layer)\n\nhead_root = tf.keras.layers.Dense(168, activation = 'softmax', name='grapheme')(intermediate_layer)\nhead_vowel = tf.keras.layers.Dense(11, activation = 'softmax', name='vowel')(intermediate_layer)\nhead_consonant = tf.keras.layers.Dense(7, activation = 'softmax', name='consonant')(intermediate_layer)\n\npred_model = tf.keras.Model(inputs=[seresnext_model.input], outputs=[head_root, head_vowel, head_consonant])\n\npred_model.compile(\n  optimizer=tf.keras.optimizers.Adam(lr=1e-4),\n  loss={\n      \"grapheme\":  \"sparse_categorical_crossentropy\",\n      \"vowel\":  \"sparse_categorical_crossentropy\",\n      \"consonant\":  \"sparse_categorical_crossentropy\",\n  },\n  loss_weights={\n      'grapheme': 0.5,\n      'vowel': 0.25,\n      'consonant': 0.25\n  },\n  metrics=['sparse_top_k_categorical_accuracy', 'accuracy'])\n\npred_model.load_weights('/kaggle/input/bangla-keras-models/SeResNext50_Balanced_Mix_TPU.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_files = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.startswith('test_image_data'):\n            pred_files.append(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_batch_generator(df, batch_size):\n    num_imgs = len(df)\n\n    for batch_start in range(0, num_imgs, batch_size):\n        curr_batch_size = min(num_imgs, batch_start + batch_size) - batch_start\n        idx = np.arange(batch_start, batch_start + curr_batch_size)\n\n        names_batch = df.iloc[idx, 0].values\n        imgs_batch = 255 - df.iloc[idx, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n        X_batch = np.zeros((curr_batch_size, SIZE, SIZE, 1))\n        \n        for j in range(curr_batch_size):\n            img = (imgs_batch[j,]*(255.0/imgs_batch[j,].max())).astype(np.uint8)\n            img = crop_resize(img, size=SIZE)\n            img = img[:, :, np.newaxis]\n            X_batch[j,] = img\n\n        yield X_batch, names_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"row_id = []\ntarget = []\n# iterative over the test sets\nfor fname in pred_files:\n    test_ = pd.read_parquet(fname)\n    test_gen = test_batch_generator(test_, batch_size=BATCH_SIZE)\n\n    for batch_x, batch_name in test_gen:\n        # prediction\n        batch_predict = pred_model.predict(batch_x)\n        for idx, name in enumerate(batch_name):\n            row_id += [\n                f\"{name}_grapheme_root\",\n                f\"{name}_vowel_diacritic\",\n                f\"{name}_consonant_diacritic\"\n                \n            ]\n            target += [\n                np.argmax(batch_predict[0], axis=1)[idx],\n                np.argmax(batch_predict[1], axis=1)[idx],\n                np.argmax(batch_predict[2], axis=1)[idx],\n            ]\n\n    del test_\n    gc.collect()\n    \n    \ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\n\ndf_sample.to_csv('submission.csv',index=False)\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir junk\n!mv ./* ./junk\n!mv ./junk/submission.csv ./\n!rm -rf junk","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}