{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport os\nimport joblib\nimport tensorflow as tf\nimport keras\nimport cv2\nfrom tqdm import tqdm\nfrom PIL import Image\nimport gc\nfrom math import ceil\n\nfrom keras.layers import Input\nfrom keras import backend as K \nfrom keras.preprocessing.image import ImageDataGenerator \nfrom keras import layers, models, optimizers \nfrom keras.models import Sequential, Model\nfrom keras.utils.vis_utils import plot_model\nfrom albumentations.augmentations import functional as F\nfrom keras.models import load_model\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n# !mkdir '../working/test_data'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HEIGHT = 137\nWIDTH = 236\n\ndata_dir = '../input/bengaliai-cv19/'\nfiles_test = [f'test_image_data_{fid}.parquet' for fid in range(4)]\nfiles_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.load_model('../input/bengal-model/baseline_v5.h5')\n# model.load_weights('../input/bengal-model/baseline_v5_weights.hdf5')\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bbox(img):\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    return rmin, rmax, cmin, cmax\n\n# Image Prep\ndef crop_image(img, WIDTH_NEW, HEIGHT_NEW):\n    # Invert\n    pad = 16\n    size = 128\n#     img = 255 - img.reshape(137, 236)\n#     print(img0.shape)\n#     plt.imshow(img0)\n#     plt.show()\n    \n    ymin,ymax,xmin,xmax = bbox(img[5:-5,5:-5] > 80)\n    #cropping may cut too much, so we need to add it back\n    xmin = xmin - 13 if (xmin > 13) else 0\n    ymin = ymin - 10 if (ymin > 10) else 0\n    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n    img = img[ymin:ymax,xmin:xmax]\n    #remove lo intensity pixels as noise\n    img[img < 28] = 0\n    lx, ly = xmax-xmin,ymax-ymin\n    l = max(lx,ly) + pad\n    #make sure that the aspect ratio is kept in rescaling\n    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode='constant')\n    img = cv2.resize(img,(WIDTH_NEW,HEIGHT_NEW))\n    img = img / 255\n    return img\n\ndef resize(df, size=64):\n    resized = {}\n    \n    for i in tqdm(range(df.shape[0])):\n        image= df.loc[df.index[i]].values\n        image = crop_image(image, 128, 128)\n        image = image.reshape(128*128)\n        resized[df.index[i]] = image\n        \n    del df\n    df = 0\n    image = 0\n    gc.collect()\n    print('collect df')\n    resized = np.array(list(resized.values()))\n#     resized = pd.DataFrame(index=resized.keys(), data=resized.values())\n    print('return')\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_batch_generator(df, batch_size):\n    num_imgs = len(df)\n\n    for batch_start in tqdm(range(0, num_imgs, batch_size)):\n        curr_batch_size = min(num_imgs, batch_start + batch_size) - batch_start\n        idx = np.arange(batch_start, batch_start + curr_batch_size)\n\n        names_batch = df.iloc[idx, 0].values\n        imgs_batch = 255 - df.iloc[idx, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n        X_batch = np.zeros((curr_batch_size, 128, 128, 1))\n        \n        for j in range(curr_batch_size):\n#             img = (imgs_batch[j,]*(255.0/imgs_batch[j,].max())).astype(np.uint8)\n#             img = resize_image(img, 128, 128)\n#             img = (img.astype(np.float32)/255.0 - stats[0])/stats[1]\n#             img = img[:, :, np.newaxis]\n#             img = resize_img(imgs_batch[j,], 128, 128)\n            img = imgs_batch[j,] #shape 137,236\n            img = crop_image(img, 128, 128) # shape 128, 128\n            img = np.expand_dims(img, axis=2) #shape 128, 128, 1\n#             print(img.shape)\n            X_batch[j,] = img\n\n        yield X_batch, names_batch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_df = pd.read_csv('../input/bengaliai-cv19/test.csv')\n# test_df['name'] = test_df['image_id'] +'_' + test_df['component']\n# test_df['name'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/bengaliai-cv19/test.csv')\ntest_df['name'] = test_df['image_id'] +'_' + test_df['component']\n\ncomponent = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[test_df['image_id'] == 'Test_1'].iloc[0]['component'] # 0, 1, 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load the parquet files \n# TEST = [\n#     \"../input/bengaliai-cv19/test_image_data_0.parquet\",\n#     \"../input/bengaliai-cv19/test_image_data_1.parquet\",\n#     \"../input/bengaliai-cv19/test_image_data_2.parquet\",\n#     \"../input/bengaliai-cv19/test_image_data_3.parquet\",\n# ]\n\n# placeholders \nrow_id = []\ntarget = []\ntest_df = pd.read_csv('../input/bengaliai-cv19/test.csv')\ntest_df['name'] = test_df['image_id'] +'_' + test_df['component']\n\ncomponent = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n\n\n# iterative over the test sets\nfor i in range(4):\n    test_ = pd.read_parquet('../input/bengaliai-cv19/'+files_test[i])\n    test_gen = test_batch_generator(test_, batch_size=64)\n\n    for batch_x, batch_name in test_gen:\n        # prediction\n        batch_predict0 = model.predict(batch_x, batch_size = 64)\n\n        for idx, name in enumerate(batch_name):\n#             print(name)\n            for i in range(len(test_df[test_df['image_id'] == name])):\n                if test_df[test_df['image_id'] == name].iloc[i]['component'] == 'consonant_diacritic':\n                    target.append(np.argmax(batch_predict0[2], axis=1)[idx])\n                elif test_df[test_df['image_id'] == name].iloc[i]['component'] == 'grapheme_root':\n                    target.append(np.argmax(batch_predict0[0], axis=1)[idx])\n                elif test_df[test_df['image_id'] == name].iloc[i]['component'] == 'vowel_diacritic':\n                    target.append(np.argmax(batch_predict0[1], axis=1)[idx])\n#             target += [\n#                 np.argmax(batch_predict0[2], axis=1)[idx],\n#                 np.argmax(batch_predict0[0], axis=1)[idx],\n#                 np.argmax(batch_predict0[1], axis=1)[idx],\n#             ]\n\n    del test_\n    gc.collect()\n    \nrow_id = test_df['name'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\n# df_sample.fillna(0)\ndf_sample.to_csv('submission.csv',index=False)\n# print(type(df_sample['target'].values[0]))\n# print(type(df_sample['row_id'].values[0]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class TestDataGenerator(keras.utils.Sequence):\n#     def __init__(self, X, batch_size = 16, img_size = (128, 128, 1), *args, **kwargs):\n#         self.X = X\n#         self.indices = np.arange(len(self.X))\n#         self.batch_size = batch_size\n#         self.img_size = img_size\n                    \n#     def __len__(self):\n#         return int(ceil(len(self.X) / self.batch_size))\n\n#     def __getitem__(self, index):\n#         indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n#         X = self.__data_generation(indices)\n#         return X\n    \n#     def __data_generation(self, indices):\n#         X = np.empty((self.batch_size, *self.img_size))\n        \n#         for i, index in enumerate(indices):\n#             image = self.X[index]\n#             crop_X = resize_image(image, 128, 128)\n# #             plt.imshow(crop_X)\n# #             plt.show()\n#             crop_X = np.expand_dims(crop_X, axis=2)\n#             X[i,] = crop_X\n#         return X","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pred_dict = {\n#     'grapheme_root': [],\n#     'vowel_diacritic': [],\n#     'consonant_diacritic': []\n# }\n\n# components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n# target=[] # model predictions placeholder\n# row_id=[] # row_id place holder\n# for i in range(4):\n#     df_test_img = pd.read_parquet('../input/bengaliai-cv19/'+files_test[i])\n#     df_test_img.set_index('image_id',inplace=True)\n#     df_test_img_index = df_test_img.index\n    \n#     df_test_img = resize(df_test_img)\n# #     resized = pd.DataFrame(index=resized.keys(), data=resized.values())\n#     gc.collect()\n#     print('reshape')\n#     df_test_img = df_test_img.reshape(-1, 128, 128, 1)\n#     print('preds start')\n#     preds = model.predict(df_test_img, batch_size=16)\n#     del df_test_img\n#     gc.collect()\n    \n#     print('gc collect finished')\n    \n#     for i, p in enumerate(pred_dict):\n#         pred_dict[p] = np.argmax(preds[i], axis=1)\n\n#     for k,id in enumerate(df_test_img_index):  \n#         for i,comp in enumerate(components):\n#             id_sample=id+'_'+comp\n#             row_id.append(id_sample)\n#             target.append(pred_dict[comp][k])\n            \n\n\n# df_sample = pd.DataFrame(\n#     {\n#         'row_id': row_id,\n#         'target':target\n#     },\n#     columns = ['row_id','target'] \n# )\n\n# df_sample.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n# row_ids, targets = [], []\n\n\n# df = pd.read_parquet('../input/bengaliai-cv19/'+files_test[0])\n# test_files = list(df['image_id'].values)\n# df = df.drop(['image_id'], axis=1)\n# df = df.values\n# data_generator_test = TestDataGenerator(df, batch_size = 1, img_size = (128, 128, 1))\n\n# # Predict with all 3 models\n# preds1 = model.predict_generator(data_generator_test, verbose = 1)\n# print(preds1[0].shape)\n# print(preds1[1].shape)\n# print(preds1[2].shape)\n\n\n# for i, image_id in zip(range(len(test_files)), test_files):\n#     print('i', i)\n#     print('image_id',image_id)\n#     for subi, col in zip(range(len(preds1)), tgt_cols):\n# #         print('subi', subi)\n# #         print('col', col)\n#         sub_preds1 = preds1[subi]\n        \n#         row_ids.append(str(image_id)+'_'+col)\n#         sub_pred_value = np.argmax(sub_preds1[i])\n#         targets.append(sub_pred_value)\n# del df \n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']\n# row_ids, targets = [], []\n\n# for i in range(0, 4):\n#     df = pd.read_parquet('../input/bengaliai-cv19/'+files_test[i])\n#     test_files = list(df['image_id'].values)\n#     df = df.drop(['image_id'], axis=1)\n#     df = df.values\n#     data_generator_test = TestDataGenerator(df, batch_size = 16, img_size = (128, 128, 1))\n\n#     # Predict with all 3 models\n#     preds1 = model.predict_generator(data_generator_test, verbose = 1)\n# #     print(len(preds1))\n#     for i, image_id in zip(range(len(test_files)), test_files):\n#         for subi, col in zip(range(len(preds1)), tgt_cols):\n#             print('subi', subi)\n#             sub_preds1 = preds1[subi]\n#             row_ids.append(str(image_id)+'_'+col)\n#             print(sub_preds1[i][np.argmax(sub_preds1[i])])\n#             sub_pred_value = np.argmax(sub_preds1[i])\n#             targets.append(sub_pred_value)\n#     del df \n#     gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_sub = pd.read_csv('../input/bengaliai-cv19/sample_submission.csv')\n# print(type(sample_sub['target'].values[0]))\n# print(type(sample_sub['row_id'].values[0]))\n# print(sample_sub.info())\n# sample_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# submit_df = pd.DataFrame({'row_id':row_ids,'target':targets}, columns = ['row_id','target'])\n# submit_df.to_csv('submission.csv', index = False)\n# print(type(submit_df['target'].values[0]))\n# print(type(submit_df['row_id'].values[0]))\n# print(submit_df.info())\n# submit_df.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # sort by test\n# test_csv = pd.read_csv('../input/bengaliai-cv19/test.csv')\n# sorter = list(test_csv['row_id'].values)\n# submit_df_sort = pd.DataFrame({'row_id':row_ids,'target':targets}, columns = ['row_id','target'])\n# submit_df_sort.row_id = submit_df_sort.row_id.astype('category')\n# submit_df_sort.row_id.cat.set_categories(sorter,inplace=True)\n# submit_df_sort = submit_df_sort.sort_values(['row_id'])\n# submit_df_sort.row_id = submit_df_sort.row_id.astype('str')\n# submit_df_sort = submit_df_sort.reset_index(drop=True)\n# # submit_df.to_csv('submission.csv', index = False)\n# print(type(submit_df['target'].values[0]))\n# print(type(submit_df['row_id'].values[0]))\n# print(submit_df.info())\n# submit_df_sort.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Create and Save Submission File\n# submit_df = pd.DataFrame({'row_id':row_ids,'target':targets}, columns = ['row_id','target'])\n# submit_df.row_id = submit_df.row_id.astype('category')\n# submit_df.row_id.cat.set_categories(sorter,inplace=True)\n# submit_df = submit_df.sort_values(['row_id'])\n# submit_df.row_id = submit_df.row_id.astype('str')\n# submit_df = submit_df.reset_index(drop=True)\n# submit_df.to_csv('submission.csv', index = False)\n# print(submit_df.head())\n# print(type(submit_df['target'].values[0]))\n# print(type(submit_df['row_id'].values[0]))\n# print(submit_df.info())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample_sub = pd.read_csv('../input/bengaliai-cv19/sample_submission.csv')\n# print(type(sample_sub['target'].values[0]))\n# print(type(sample_sub['row_id'].values[0]))\n# print(sample_sub.head())\n# print(sample_sub.info())","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}