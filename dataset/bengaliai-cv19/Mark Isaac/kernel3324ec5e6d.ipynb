{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\n\nimport gc\nfrom tqdm import tqdm_notebook, tnrange\n\nimport tensorflow as tf\nimport time\nfrom numpy import expand_dims\nfrom tensorflow.keras.models import load_model\nmodel = load_model(\"/kaggle/input/modbenai2/modcombo2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TEST = [\"test_image_data_0.parquet\", \"test_image_data_1.parquet\", \n         \"test_image_data_2.parquet\",\n         \"test_image_data_3.parquet\"]\ninpath = \"/kaggle/input/bengaliai-cv19/\"\nHEIGHT = 137\nWIDTH = 236\noutpath = \"/kaggle/working/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testimages = [\"Test_0\",\"Test_1\",\"Test_2\",\"Test_3\",\"Test_4\",\"Test_5\",\"Test_6\",\"Test_7\",\"Test_8\",\"Test_9\",\"Test_10\",\"Test_11\"]\nresize_size=64 \ndef resizeimg(img):\n   \n    _, thresh = cv2.threshold(img, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n    contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n    idx = 0 \n    ls_xmin = []\n    ls_ymin = []\n    ls_xmax = []\n    ls_ymax = []\n    for cnt in contours:\n        idx += 1\n        x,y,w,h = cv2.boundingRect(cnt)\n        ls_xmin.append(x)\n        ls_ymin.append(y)\n        ls_xmax.append(x + w)\n        ls_ymax.append(y + h)\n    xmin = min(ls_xmin)\n    ymin = min(ls_ymin)\n    xmax = max(ls_xmax)\n    ymax = max(ls_ymax)\n\n    roi = img[ymin:ymax,xmin:xmax]\n    resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n    return resized_roi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfor p in TEST:\n        \n     print(\"processing \", p)\n     df = pd.read_parquet(inpath+p)\n     #df = pd.read_parquet(inpath+\"test_image_data_0.parquet\")   \n     data = df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8) \n     for idx in tqdm_notebook(range(len(df)), desc =\"zipping\", leave=False):\n        #name = df.iloc[idx,0]\n        \n        #normalize each image by its max val\n        #img = (data[idx]*(255.0/data[idx].max())).astype(np.uint8)\n        img = (data[idx].astype(np.uint8))\n        #print('resizing')\n        img = resizeimg(img)\n        testimages[i] = img\n        i+=1\n        print(i)\n        #gc.collect()\n        #img = da.from_array(img)\n        #np.append(x_tot,((img/255.0).mean()))\n        #np.append(x2_tot,((img/255.0)**2).mean())\n        #print('nearly there') \n        #img = cv2.imencode('.png',img)[1]\n        #test = np.append(test, img)\n        #cv2.imwrite(outpath+name + '.png', img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = np.array([f for f in testimages])\nX_test = expand_dims(X_test, axis=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntestdf = pd.read_csv(\"/kaggle/input/bengaliai-cv19/test.csv\")\ntestdf['target'] = 0\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combres = model.predict(X_test)\ngraphpred = np.array(combres[0])\nvowelpred = np.array(combres[1])\nconspred = np.array(combres[2])\nresroot = graphpred.argmax(axis=-1)\nresconst = vowelpred.argmax(axis=-1)\nresvowel = conspred.argmax(axis=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = testdf.query('component==\"grapheme_root\"').index\ntestdf.target.iloc[i] = resroot\nj = testdf.query('component==\"consonant_diacritic\"').index\ntestdf.target.iloc[j] = resconst\nk = testdf.query('component==\"vowel_diacritic\"').index\ntestdf.target.iloc[k] = resvowel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"row_id = testdf['row_id']\ntarget = testdf['target']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del testdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission['row_id'] = row_id\nsubmission['target'] = target\nsubmission.head()\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}