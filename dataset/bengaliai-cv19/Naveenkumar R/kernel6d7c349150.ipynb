{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nfrom matplotlib import pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\nimport random \nimport os\nimport cv2\nimport gc\nfrom tqdm.auto import tqdm\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import load_model\nmodel_root = load_model('/kaggle/input/pretrained/model_root.h5')\nmodel_vowel = load_model('/kaggle/input/pretrained/model_vowel.h5')\nmodel_consonant = load_model('/kaggle/input/pretrained/model_consonant.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Single data inference\n\nfrom tensorflow.keras.models import load_model\nimport numpy as np\nimport pandas as pd\n\n# model_root = load_model('model_root.h5')\n# model_vowel = load_model('model_vowel.h5')\n# model_consonant = load_model('model_consonant.h5')\n\n# model_root.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n# model_vowel.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n# model_consonant.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n\ndef resize(df, size=64, need_progress_bar=True):\n    resized = {}\n    for i in range(df.shape[0]):\n        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized\n\nmodel_dict = {\n    'grapheme_root': model_root,\n    'vowel_diacritic': model_vowel,\n    'consonant_diacritic': model_consonant\n}\n\n# preds_dict = {\n#     'grapheme_root': [],\n#     'vowel_diacritic': [],\n#     'consonant_diacritic': []\n# }\n\ntest_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}\n\ncomponents = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntarget=[] # model predictions placeholder\nrow_id=[] # row_id place holder\ntop_5_scores=[] # top 5 target:confidence scores\n\n# test_img = df_train_img_0.iloc[0]\n\ndf_test_img_0 = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_0.parquet') \ndf_test_img_0.set_index('image_id', inplace=True)\n\ntest_img = df_test_img_0[df_test_img_0.index == 'Test_2']\n\nX_test = resize(test_img)/255\nX_test = X_test.values.reshape(-1, 64, 64, 1)\n\n# for pred in preds_dict:\n#     preds_dict[pred]=np.argmax(model_dict[pred].predict(X_test), axis=1)\n    \nfor pred in test_dict:\n    np.set_printoptions(suppress=True)\n#     preds_dict[pred]=np.argmax(model_dict[pred].predict(X_test), axis=1)\n    predictions = model_dict[pred].predict(X_test)\n    top5scores = predictions.flatten()[np.argsort(-predictions.flatten())[:5]]\n    top5targets = np.argsort(-predictions.flatten())[:5]\n    result = dict(zip(top5targets,top5scores))\n    resList = [(k,v) for k,v in result.items()]\n    test_dict[pred] = resList\n    \n\nfor k,id in enumerate(test_img.index.values):  \n    for i,comp in enumerate(components):\n        id_sample=id+'_'+comp\n        row_id.append(id_sample)\n        target.append(test_dict[comp][0])\n        top_5_scores.append(test_dict[comp])\n        \ndel test_img\ndel X_test\ngc.collect()\n\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target,\n        'top_5_scores':top_5_scores\n    },\n    columns = ['row_id','target','top_5_scores'] \n)\n# df_sample.to_csv('submission_root.csv',index=False)\ndf_sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load saved model and infer on test data to get submission file\n\nimport numpy as np\nimport pandas as pd\n\n# model_root = load_model('model_root.h5')\n# model_vowel = load_model('model_vowel.h5')\n# model_consonant = load_model('model_consonant.h5')\n\n# model_root.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n# model_vowel.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n# model_consonant.compile(optimizer=\"adam\", loss=['categorical_crossentropy'], metrics=['accuracy'])\n\ndef resize(df, size=64, need_progress_bar=True):\n    resized = {}\n    for i in range(df.shape[0]):\n        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized\n\nmodel_dict = {\n    'grapheme_root': model_root,\n    'vowel_diacritic': model_vowel,\n    'consonant_diacritic': model_consonant\n}\n\npreds_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}\n\ncomponents = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntarget=[] # model predictions placeholder\nrow_id=[] # row_id place holder\nfor i in range(4):\n    test_img = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i)) \n    test_img.set_index('image_id', inplace=True)\n\n    X_test = resize(test_img)/255\n    X_test = X_test.values.reshape(-1, 64, 64, 1)\n\n    for pred in preds_dict:\n        preds_dict[pred]=np.argmax(model_dict[pred].predict(X_test), axis=1)\n\n    for k,id in enumerate(test_img.index.values):  \n        for i,comp in enumerate(components):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n    del test_img\n    del X_test\n    gc.collect()\n\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\ndf_sample.to_csv('submission.csv',index=False)\ndf_sample.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}