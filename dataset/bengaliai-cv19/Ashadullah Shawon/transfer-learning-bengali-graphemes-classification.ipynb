{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","id":"q_oga2KUnmwe","colab_type":"code","outputId":"eacf7c99-a723-4a5e-cd89-bb46064f1967","colab":{"base_uri":"https://localhost:8080/","height":80},"trusted":true},"cell_type":"code","source":"import os\nfrom tqdm.auto import tqdm\nimport time, gc\n\nimport numpy as np\nimport pandas as pd\n# pd.set_option('display.max_columns', None)\n\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport cv2\nimport albumentations as A\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model, Input, load_model\nfrom keras.layers import Dense, Conv2D, Flatten, Activation, Concatenate\nfrom keras.layers import MaxPool2D, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.layers import Dropout, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras import backend as K\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\nfrom keras.initializers import RandomNormal\nfrom keras.applications import DenseNet121\n\nfrom sklearn.model_selection import train_test_split\n\nstart_time = time.time()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Resource path setting "},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","id":"37gVDbtCnmw3","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"dataset = '/kaggle/input/bengaliai-cv19'\npretrained = '../input/bangla-graphemes-pretrained-weights'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Checking Model"},{"metadata":{"id":"IVMfmstInmxE","colab_type":"code","outputId":"c3d481b8-546f-4aba-e7c8-e4b9a690bdb6","colab":{"base_uri":"https://localhost:8080/","height":51},"trusted":true},"cell_type":"code","source":"if os.path.isfile(os.path.join(pretrained,\"GraphemeDenseNet121.h5\")) \\\n        and os.path.isfile(os.path.join(pretrained,\"hist.csv\")):\n    print('Model is present')\nelse:\n    print(\"Error. No Model Found\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Size and Channel of images"},{"metadata":{"id":"D6pyqi_dnm0k","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"SIZE = 100   # input image size\nN_ch = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Loading Pretrained Densenet121 Model\n### Batch Size: 256\n### Epochs: 30 (Early Stopped in 20)"},{"metadata":{"id":"2-UnNN_zQ8A3","colab_type":"code","outputId":"911beadf-e629-46f2-ee8d-8fae156b8de5","colab":{"base_uri":"https://localhost:8080/","height":632},"trusted":true},"cell_type":"code","source":"model = load_model(os.path.join(pretrained, 'GraphemeDenseNet121.h5'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## DenseNet121 Model Summary"},{"metadata":{"id":"yCCKi97lRaI9","colab_type":"code","outputId":"56342c9c-dd8c-4802-8807-dad5e1e9a888","colab":{"base_uri":"https://localhost:8080/","height":561},"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Loading Images and Pre-processing"},{"metadata":{"id":"fx7mUmwlnm0u","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# Resize image size\ndef resize(df, size=100):\n    resized = {}\n    resize_size=100\n    angle=0\n    for i in range(df.shape[0]):\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            #Centering\n            image_center = tuple(np.array(image.shape[1::-1]) / 2)\n            matrix = cv2.getRotationMatrix2D(image_center, angle, 1.0)\n            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_AREA,\n                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n            #Scaling\n            matrix = cv2.getRotationMatrix2D(image_center, 0, 1.0)\n            image = cv2.warpAffine(image, matrix, image.shape[1::-1], flags=cv2.INTER_AREA,\n                            borderMode=cv2.BORDER_CONSTANT, borderValue=(0, 0, 0))\n            #Removing Blur\n            #aug = A.GaussianBlur(p=1.0)\n            #image = aug(image=image)['image']\n            #Noise Removing\n            #augNoise=A.MultiplicativeNoise(p=1.0)\n            #image = augNoise(image=image)['image']\n            #Removing Distortion\n            #augDist=A.ElasticTransform(sigma=50, alpha=1, alpha_affine=10, p=1.0)\n            #image = augDist(image=image)['image']\n            #Brightness\n            augBright=A.RandomBrightnessContrast(p=1.0)\n            image = augBright(image=image)['image']\n            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            idx = 0 \n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                idx += 1\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            #image=affine_image(image)\n            #image= crop_resize(image)\n            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n            #image=resize_image(image,(64,64))\n            #image = cv2.resize(image,(size,size),interpolation=cv2.INTER_AREA)\n            #gaussian_3 = cv2.GaussianBlur(image, (5,5), cv2.BORDER_DEFAULT) #unblur\n            #image = cv2.addWeighted(image, 1.5, gaussian_3, -0.5, 0, image)\n            #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]]) #filter\n            #image = cv2.filter2D(image, -1, kernel)\n            #ret,image = cv2.threshold(image, 128, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    resized_df = pd.DataFrame(resized).T\n    return resized_df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Accuracy and Loss Curve"},{"metadata":{"id":"Nk2StqnYnm1c","colab_type":"code","outputId":"6a8a937b-6b1f-4b44-dda3-5d6b4b5a6f17","colab":{"base_uri":"https://localhost:8080/","height":281},"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(pretrained,'hist.csv'))\n    \n# Plot the loss and accuracy curves for training and validation \nfig, ax = plt.subplots(1, 2, figsize = (12, 4))\n\nax[0].plot(df[['root_loss','vowel_loss','consonant_loss',\n               'val_root_loss','val_vowel_loss','val_consonant_loss']])\nax[0].set_ylim(0, 2)\nax[0].set_title('Loss')\nax[0].legend(['train_root_loss','train_vowel_loss','train_conso_loss',\n              'val_root_loss','val_vowel_loss','val_conso_loss'],\n             loc='upper right')\nax[0].grid()\nax[1].plot(df[['root_acc','vowel_acc','consonant_acc',\n               'val_root_acc','val_vowel_acc','val_consonant_acc']])\nax[1].set_ylim(0.5, 1)\nax[1].set_title('Accuracy')\nax[1].legend(['train_root_acc','train_vowel_acc','train_conso_acc',\n              'val_root_acc','val_vowel_acc','val_conso_acc'],\n             loc='lower right')\nax[1].grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Target Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"tgt_cols = ['grapheme_root','vowel_diacritic','consonant_diacritic']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction on Test Images"},{"metadata":{"id":"PUtCrKjUnm1k","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"row_ids = []\ntargets = []      \nid = 0\nfor i in range(4):\n    img_df = pd.read_parquet(os.path.join(\n                            dataset, 'test_image_data_'+str(i)+'.parquet'))\n    img_df = img_df.drop('image_id', axis = 1)\n    img_df = resize(img_df, SIZE) / 255\n    X_test = img_df.values.reshape(-1, SIZE, SIZE, N_ch)\n\n    preds = model.predict(X_test)\n    for j in range(len(X_test)):\n        for k in range(3):\n            row_ids.append('Test_'+str(id)+'_'+tgt_cols[k])\n            targets.append(np.argmax(preds[k][j]))\n        id += 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Creating Submission CSV File"},{"metadata":{"id":"JuEdvGu4So6U","colab_type":"code","outputId":"256ad766-0940-406a-9ec6-8dc3e7651975","colab":{"base_uri":"https://localhost:8080/","height":359},"trusted":true},"cell_type":"code","source":"df_submit = pd.DataFrame({'row_id':row_ids,'target':targets},\n                         columns = ['row_id','target'])\ndf_submit.to_csv('submission.csv',index=False)\ndf_submit.head(10)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"},"colab":{"name":"bangla-graphemes-image-processing-deep-cnn.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":1}