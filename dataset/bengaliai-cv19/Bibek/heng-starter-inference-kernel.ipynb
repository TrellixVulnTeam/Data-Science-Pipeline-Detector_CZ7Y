{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.sampler import *\nprint('torch version:', torch.__version__)\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input/hengmodels')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA_DIR = '../input/bengaliai-cv19'\nSUBMISSION_CSV_FILE = 'submission.csv'\nMYFILE_DIR = '../input/myfile'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sys.path.append(MYFILE_DIR)\nfrom etc import *\nfrom densenet_model import Net as DenseNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef do_predict(net, input):\n\n    def logit_to_probability(logit):\n        probability=[]\n        for l in logit:\n            p = F.softmax(l,1)\n            probability.append(p)\n        return probability\n\n    #-----\n    num_ensemble = len(net)\n    for i in range(num_ensemble):\n        net[i].eval()\n\n\n    probability=[0,0,0]\n    #----\n    for i in range(num_ensemble):\n        logit = net[i](input)\n        prob  = logit_to_probability(logit)\n        probability = [p+q for p,q in zip(probability,prob)]\n\n    #----\n    probability = [p/num_ensemble for p in probability]\n    predict = [torch.argmax(p,-1) for p in probability]\n    predict = [p.data.cpu().numpy() for p in predict]\n    predict = np.array(predict).T\n    predict = predict.reshape(-1)\n\n    return predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DESENET_CHECKPOINT_FILE = [\n        '../input/hengmodels/swa_fold1_no_bn_model.pth',\n    ]\nTASK_NAME = [ 'grapheme_root', 'vowel_diacritic', 'consonant_diacritic' ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n## load net -----------------------------------\nnet = []\nfor checkpoint_file in DESENET_CHECKPOINT_FILE:\n    n = DenseNet().cuda()\n    n.load_state_dict(torch.load(checkpoint_file, map_location=lambda storage, loc: storage),strict=True)\n    net.append(n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef run_make_submission_csv():\n\n    row_id=[]\n    target=[]\n    batch_size= 32\n\n    print('\\nstart here !!!!')\n    for i in range(4):\n        start_timer = timer()\n        df  = pd.read_parquet(DATA_DIR+'/test_image_data_%d.parquet'%i, engine='pyarrow')\n        #df  = pd.read_parquet(DATA_DIR+'/train_image_data_%d.parquet'%i, engine='pyarrow') #use this to test timing\n        print('pd.read_parquet() = %s'%(time_to_str((timer() - start_timer),'sec')))\n\n        start_timer = timer()\n        num_test = len(df)\n        for b in range(0,num_test,batch_size):\n            if b%1000==0:\n                print('test_image_data_%d.parquet @%06d, %s'%(i,b,time_to_str((timer() - start_timer),'sec')))\n            #----\n            B = min(num_test,b+batch_size)-b\n            image = df.iloc[b:b+B, range(1,32332+1)].values\n            image_id = df.iloc[b:b+B, 0].values\n\n            image = image.reshape(B,1,137, 236)\n            image = np.tile(image, (1,3,1,1))\n            image = image.astype(np.float32)/255\n\n            #----\n            input = torch.from_numpy(image).float().cuda()\n            predict = do_predict(net, input)\n            #----\n\n            image_id = np.tile(image_id.reshape(B,1), (1,3,)) + ['_']  + TASK_NAME\n            image_id = image_id.reshape(-1)\n            row_id.append(image_id)\n            target.append(predict)\n        print('')\n\n    row_id = np.concatenate(row_id)\n    target = np.concatenate(target)\n    #---------\n\n    df = pd.DataFrame(zip(row_id, target), columns=['row_id', 'target'])\n    df.to_csv(SUBMISSION_CSV_FILE, index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"run_make_submission_csv()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}