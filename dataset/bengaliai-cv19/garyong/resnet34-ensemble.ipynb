{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = [\"test_image_data_0.parquet\",\"test_image_data_1.parquet\",\"test_image_data_2.parquet\",\"test_image_data_3.parquet\"]\n#inputs = [\"train_image_data_0.parquet\",\"train_image_data_1.parquet\",\"train_image_data_2.parquet\",\"train_image_data_3.parquet\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DIR = \"../input/bengaliai-cv19/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset, DataLoader\nimport torchvision.transforms as transforms\nimport pandas as pd\nimport torch\nimport numpy as np\nimport cv2\nfrom PIL import Image\nclass EvalDataset(Dataset):\n    def __init__(self,df,transform=None,aug=None,norm=None):\n        self.norm = norm\n        self.df = df\n        self.data = 255 - self.df.iloc[:, 1:].values.reshape(-1, 137, 236).astype(np.uint8)\n        self.transform = transform\n        self.aug = aug\n        \n    def __getitem__(self, idx):\n        name = self.df.iloc[idx,0]\n        image_arr = cv2.resize(self.data[idx],(128,128))\n        image_arr = image_arr/255.0\n        if self.norm != None:\n            mean = self.norm['mean']\n            std = self.norm['std']\n            image_arr = (image_arr -  mean)/std\n        image_arr = torch.from_numpy(image_arr.astype(np.float32))\n        return image_arr.unsqueeze(0).repeat(3,1,1),name\n\n\n    def __len__(self):\n        return len(self.data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import models\nimport torch.nn as nn\n# Easier to split stuff up and backpropagate\nclass MyModel(nn.Module):\n  def __init__(self):\n    super().__init__()\n    model = models.resnet34()\n    self.model = nn.Sequential(*list(model.children())[:-1])#chop off last layer\n    self.fc_g = nn.Sequential(nn.Linear(512,200), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(200,168))\n    self.fc_v = nn.Sequential(nn.Linear(512,200), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(200,11))\n    self.fc_c = nn.Sequential(nn.Linear(512,200), nn.ReLU(), nn.Dropout(p=0.2), nn.Linear(200,7))\n  def forward(self,x):\n    x = self.model(x)\n    # print(x.shape)\n    x = torch.flatten(x,1)\n    g = self.fc_g(x)\n    v = self.fc_v(x)\n    c = self.fc_c(x)\n    return g,v,c","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kaggle_out(model1,model2,model3,dataloader,device):\n    model1.eval()\n    model2.eval()\n    model3.eval()\n    grapheme_output = []\n    vowel_output = []\n    consonant_output = []\n    img_id_ls = []\n    for data in dataloader:\n        inputs = data[0]\n        image_id = data[1]\n        inputs = inputs.to(device)\n        with torch.no_grad():\n            g1,v1,c1 = model1(inputs)\n            g2,v2,c2 = model2(inputs)\n            g3,v3,c3 = model3(inputs)\n            g = g1+g2+g3\n            v = v1+v2+v3\n            c = c1+c2+c3\n            grapheme_preds = g.argmax(dim=1)\n            vowel_preds = v.argmax(dim=1)\n            consonant_preds = c.argmax(dim=1)\n        for i in range(len(image_id)):\n            img_id_ls.append(image_id[i])\n            grapheme_output.append(grapheme_preds[i].cpu().detach().item())\n            vowel_output.append(vowel_preds[i].cpu().detach().item())\n            consonant_output.append(consonant_preds[i].cpu().detach().item())\n    return img_id_ls,grapheme_output,vowel_output,consonant_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = []\nmean = 13.4/255\nstd = 40.8/255\nmodel1 = MyModel()\nmodel1.load_state_dict(torch.load('../input/cv-resnets/model_epoch34.pt'))\nmodel1.to(device)\n\nmodel2 = MyModel()\nmodel2.load_state_dict(torch.load('../input/cv-resnets/model_epoch69.pt'))\nmodel2.to(device)\n\nmodel3 = MyModel()\nmodel3.load_state_dict(torch.load('../input/cv-resnets/model_epoch104.pt'))\nmodel3.to(device)\nfor inp in inputs:\n    df = pd.read_parquet(DIR+inp)\n    kaggle_dataset = EvalDataset(df,norm={'mean':mean,'std':std})\n    dl = DataLoader(kaggle_dataset,batch_size=128,num_workers=4)\n    img,gra,vow,con = kaggle_out(model1,model2,model3,dl,device)\n    for i in range(len(img)):\n        results.append((f\"{img[i]}_grapheme_root\",gra[i]))\n        results.append((f\"{img[i]}_vowel_diacritic\",vow[i]))\n        results.append((f\"{img[i]}_consonant_diacritic\",con[i]))\ndf2 = pd.DataFrame(results, columns=[\"row_id\", \"target\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = df2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}