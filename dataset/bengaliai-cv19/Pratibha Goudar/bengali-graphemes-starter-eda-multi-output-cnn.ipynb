{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm.auto import tqdm\nfrom glob import glob\nimport time, gc\nimport cv2\n\nfrom tensorflow import keras\nimport matplotlib.image as mpimg\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.models import clone_model\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization, Input\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-09-09T04:24:31.72062Z","iopub.execute_input":"2021-09-09T04:24:31.720937Z","iopub.status.idle":"2021-09-09T04:24:38.156065Z","shell.execute_reply.started":"2021-09-09T04:24:31.72088Z","shell.execute_reply":"2021-09-09T04:24:38.154629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_ = pd.read_csv('/kaggle/input/bengaliai-cv19/train.csv')\ntest_df_ = pd.read_csv('/kaggle/input/bengaliai-cv19/test.csv')\nclass_map_df = pd.read_csv('/kaggle/input/bengaliai-cv19/class_map_corrected.csv')\nsample_sub_df = pd.read_csv('/kaggle/input/bengaliai-cv19/sample_submission.csv')","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.status.busy":"2021-09-09T04:24:42.429729Z","iopub.execute_input":"2021-09-09T04:24:42.430066Z","iopub.status.idle":"2021-09-09T04:24:42.682426Z","shell.execute_reply.started":"2021-09-09T04:24:42.430011Z","shell.execute_reply":"2021-09-09T04:24:42.681613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:24:45.198618Z","iopub.execute_input":"2021-09-09T04:24:45.198951Z","iopub.status.idle":"2021-09-09T04:24:45.226546Z","shell.execute_reply.started":"2021-09-09T04:24:45.198895Z","shell.execute_reply":"2021-09-09T04:24:45.225913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df_.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:24:47.978691Z","iopub.execute_input":"2021-09-09T04:24:47.979021Z","iopub.status.idle":"2021-09-09T04:24:47.989154Z","shell.execute_reply.started":"2021-09-09T04:24:47.978967Z","shell.execute_reply":"2021-09-09T04:24:47.988184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_sub_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:24:50.799944Z","iopub.execute_input":"2021-09-09T04:24:50.800251Z","iopub.status.idle":"2021-09-09T04:24:50.808818Z","shell.execute_reply.started":"2021-09-09T04:24:50.800193Z","shell.execute_reply":"2021-09-09T04:24:50.808034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_map_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:24:53.698867Z","iopub.execute_input":"2021-09-09T04:24:53.699184Z","iopub.status.idle":"2021-09-09T04:24:53.708254Z","shell.execute_reply.started":"2021-09-09T04:24:53.699131Z","shell.execute_reply":"2021-09-09T04:24:53.707446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Size of training data: {train_df_.shape}')\nprint(f'Size of test data: {test_df_.shape}')\nprint(f'Size of class map: {class_map_df.shape}') # 186 ký tự và một phụ âm rỗng","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:24:58.14972Z","iopub.execute_input":"2021-09-09T04:24:58.150026Z","iopub.status.idle":"2021-09-09T04:24:58.158559Z","shell.execute_reply.started":"2021-09-09T04:24:58.149972Z","shell.execute_reply":"2021-09-09T04:24:58.157887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Phân tích dữ liệu","metadata":{}},{"cell_type":"code","source":"HEIGHT = 236\nWIDTH = 236\n\n# Trả về 'top' 'n' phần tử xuất hiện 'field' nhiều nhất trong tập 'df' với trường component và count\ndef get_n(df, field, n, top=True):\n    top_graphemes = df.groupby([field]).size().reset_index(name='counts')['counts'].sort_values(ascending=not top)[:n]\n    top_grapheme_roots = top_graphemes.index\n    top_grapheme_counts = top_graphemes.values\n    top_graphemes = class_map_df[class_map_df['component_type'] == field].reset_index().iloc[top_grapheme_roots]\n    top_graphemes.drop(['component_type', 'label'], axis=1, inplace=True)\n    top_graphemes.loc[:, 'count'] = top_grapheme_counts\n    return top_graphemes\n\n# Hiển thị hình ảnh chữ từ ký tự component\ndef image_from_char(char):\n    image = Image.new('RGB', (WIDTH, HEIGHT))\n    draw = ImageDraw.Draw(image)\n    myfont = ImageFont.truetype('/kaggle/input/kalpurush-fonts/kalpurush-2.ttf', 120)\n    w, h = draw.textsize(char, font=myfont)\n    draw.text(((WIDTH - w) / 2,(HEIGHT - h) / 3), char, font=myfont)\n    return image","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:00.517408Z","iopub.execute_input":"2021-09-09T04:25:00.517693Z","iopub.status.idle":"2021-09-09T04:25:00.527267Z","shell.execute_reply.started":"2021-09-09T04:25:00.517645Z","shell.execute_reply":"2021-09-09T04:25:00.526534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Số lượng giá trị của các lớp","metadata":{}},{"cell_type":"code","source":"print(f'Number of unique grapheme roots: {train_df_[\"grapheme_root\"].nunique()}')\nprint(f'Number of unique vowel diacritic: {train_df_[\"vowel_diacritic\"].nunique()}')\nprint(f'Number of unique consonant diacritic: {train_df_[\"consonant_diacritic\"].nunique()}')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:03.549329Z","iopub.execute_input":"2021-09-09T04:25:03.549651Z","iopub.status.idle":"2021-09-09T04:25:03.563148Z","shell.execute_reply.started":"2021-09-09T04:25:03.549598Z","shell.execute_reply":"2021-09-09T04:25:03.562156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 10 gốc grapheme có trong train nhiều nhất","metadata":{}},{"cell_type":"code","source":"top_10_roots = get_n(train_df_, 'grapheme_root', 10)\ntop_10_roots","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-09T04:25:07.26842Z","iopub.execute_input":"2021-09-09T04:25:07.268736Z","iopub.status.idle":"2021-09-09T04:25:07.295462Z","shell.execute_reply.started":"2021-09-09T04:25:07.268677Z","shell.execute_reply":"2021-09-09T04:25:07.294361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hiện các ảnh top 10 gốc grapheme\nf, ax = plt.subplots(2, 5, figsize=(16, 8))\nax = ax.flatten()\n\nfor i in range(10):\n    ax[i].imshow(image_from_char(top_10_roots['component'].iloc[i]), cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:12.869569Z","iopub.execute_input":"2021-09-09T04:25:12.869902Z","iopub.status.idle":"2021-09-09T04:25:14.417581Z","shell.execute_reply.started":"2021-09-09T04:25:12.869846Z","shell.execute_reply":"2021-09-09T04:25:14.416709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 10 gốc Grapheme có trong train ít nhất","metadata":{}},{"cell_type":"code","source":"bottom_10_roots = get_n(train_df_, 'grapheme_root', 10, False)\nbottom_10_roots","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:18.088523Z","iopub.execute_input":"2021-09-09T04:25:18.088868Z","iopub.status.idle":"2021-09-09T04:25:18.114924Z","shell.execute_reply.started":"2021-09-09T04:25:18.088771Z","shell.execute_reply":"2021-09-09T04:25:18.113848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(2, 5, figsize=(16, 8))\nax = ax.flatten()\n\nfor i in range(10):\n    ax[i].imshow(image_from_char(bottom_10_roots['component'].iloc[i]), cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:20.864488Z","iopub.execute_input":"2021-09-09T04:25:20.864792Z","iopub.status.idle":"2021-09-09T04:25:22.316546Z","shell.execute_reply.started":"2021-09-09T04:25:20.86474Z","shell.execute_reply":"2021-09-09T04:25:22.315553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 5 nguyên âm có trong train nhiều nhất","metadata":{}},{"cell_type":"code","source":"top_5_vowels = get_n(train_df_, 'vowel_diacritic', 5)\ntop_5_vowels","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:25.318813Z","iopub.execute_input":"2021-09-09T04:25:25.319365Z","iopub.status.idle":"2021-09-09T04:25:25.356038Z","shell.execute_reply.started":"2021-09-09T04:25:25.319143Z","shell.execute_reply":"2021-09-09T04:25:25.355211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1, 5, figsize=(16, 8))\nax = ax.flatten()\n\nfor i in range(5):\n    ax[i].imshow(image_from_char(top_5_vowels['component'].iloc[i]), cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:28.168427Z","iopub.execute_input":"2021-09-09T04:25:28.168755Z","iopub.status.idle":"2021-09-09T04:25:29.050558Z","shell.execute_reply.started":"2021-09-09T04:25:28.168691Z","shell.execute_reply":"2021-09-09T04:25:29.04974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Top 5 phụ âm có trong train nhiều nhất","metadata":{}},{"cell_type":"code","source":"top_5_consonants = get_n(train_df_, 'consonant_diacritic', 5)\ntop_5_consonants","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:32.148483Z","iopub.execute_input":"2021-09-09T04:25:32.148796Z","iopub.status.idle":"2021-09-09T04:25:32.171267Z","shell.execute_reply.started":"2021-09-09T04:25:32.148744Z","shell.execute_reply":"2021-09-09T04:25:32.170483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(1, 5, figsize=(16, 8))\nax = ax.flatten()\n\nfor i in range(5):\n    ax[i].imshow(image_from_char(top_5_consonants['component'].iloc[i]), cmap='Greys')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:35.8686Z","iopub.execute_input":"2021-09-09T04:25:35.868916Z","iopub.status.idle":"2021-09-09T04:25:36.8445Z","shell.execute_reply.started":"2021-09-09T04:25:35.868853Z","shell.execute_reply":"2021-09-09T04:25:36.843672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_ = train_df_.drop(['grapheme'], axis=1, inplace=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:39.768727Z","iopub.execute_input":"2021-09-09T04:25:39.769052Z","iopub.status.idle":"2021-09-09T04:25:39.778664Z","shell.execute_reply.started":"2021-09-09T04:25:39.768999Z","shell.execute_reply":"2021-09-09T04:25:39.777879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']] = train_df_[['grapheme_root', 'vowel_diacritic', 'consonant_diacritic']].astype('uint8')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:42.338784Z","iopub.execute_input":"2021-09-09T04:25:42.339108Z","iopub.status.idle":"2021-09-09T04:25:42.351602Z","shell.execute_reply.started":"2021-09-09T04:25:42.339059Z","shell.execute_reply":"2021-09-09T04:25:42.350474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE=64\nN_CHANNELS=1","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:44.578624Z","iopub.execute_input":"2021-09-09T04:25:44.578947Z","iopub.status.idle":"2021-09-09T04:25:44.585287Z","shell.execute_reply.started":"2021-09-09T04:25:44.578895Z","shell.execute_reply":"2021-09-09T04:25:44.584435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's apply some image processing (credits: [this kernel](https://www.kaggle.com/shawon10/bangla-graphemes-image-processing-deep-cnn)) while resizing the images, which will center crop the region of interest from the original images.","metadata":{}},{"cell_type":"code","source":"# resize lại kích thước ảnh\ndef resize(df, size=64, need_progress_bar=True):\n    resized = {}\n    resize_size=64\n    if need_progress_bar:\n        for i in tqdm(range(df.shape[0])):\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            idx = 0 \n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                idx += 1\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    else:\n        for i in range(df.shape[0]):\n            #image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size),None,fx=0.5,fy=0.5,interpolation=cv2.INTER_AREA)\n            image=df.loc[df.index[i]].values.reshape(137,236)\n            _, thresh = cv2.threshold(image, 30, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n            contours, _ = cv2.findContours(thresh,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)[-2:]\n\n            idx = 0 \n            ls_xmin = []\n            ls_ymin = []\n            ls_xmax = []\n            ls_ymax = []\n            for cnt in contours:\n                idx += 1\n                x,y,w,h = cv2.boundingRect(cnt)\n                ls_xmin.append(x)\n                ls_ymin.append(y)\n                ls_xmax.append(x + w)\n                ls_ymax.append(y + h)\n            xmin = min(ls_xmin)\n            ymin = min(ls_ymin)\n            xmax = max(ls_xmax)\n            ymax = max(ls_ymax)\n\n            roi = image[ymin:ymax,xmin:xmax]\n            resized_roi = cv2.resize(roi, (resize_size, resize_size),interpolation=cv2.INTER_AREA)\n            resized[df.index[i]] = resized_roi.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:47.104582Z","iopub.execute_input":"2021-09-09T04:25:47.104933Z","iopub.status.idle":"2021-09-09T04:25:47.137256Z","shell.execute_reply.started":"2021-09-09T04:25:47.104874Z","shell.execute_reply":"2021-09-09T04:25:47.135813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tạo ma trận dựa trên các giá trị của df và số bản ghi\ndef get_dummies(df):\n    cols = []\n    for col in df:\n        cols.append(pd.get_dummies(df[col].astype(str)))\n    return pd.concat(cols, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:50.579497Z","iopub.execute_input":"2021-09-09T04:25:50.579848Z","iopub.status.idle":"2021-09-09T04:25:50.586307Z","shell.execute_reply.started":"2021-09-09T04:25:50.579776Z","shell.execute_reply":"2021-09-09T04:25:50.585276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Xây dụng Model training","metadata":{}},{"cell_type":"code","source":"# input shape = 64 x 64 x 1\ninputs = Input(shape = (IMG_SIZE, IMG_SIZE, 1))\n\n# filter shape = 3 x 3 x 32 (4 layer)\n# output shape = 64 x 64 x 32\nmodel = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 1))(inputs)\nmodel = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = BatchNormalization(momentum=0.15)(model)\n\n# max pooling 2 x 2\n# shape = 32 x 32 x 32\nmodel = MaxPool2D(pool_size=(2, 2))(model)\n\n# filter shape = 5 x 5 x 32\n# output shape = 32 x 32 x 32\nmodel = Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\nmodel = Dropout(rate=0.3)(model) # Dropout 1 phần tham số để giảm overfitting\n\n# filter shape = 3 x 3 x 64 (4 layer)\n# output shape = 32 x 32 x 64\nmodel = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = BatchNormalization(momentum=0.15)(model)\n\n# max pooling 2 x 2\n# shape = 16 x 16 x 64\nmodel = MaxPool2D(pool_size=(2, 2))(model)\n\n# filter shape = 5 x 5 x 64\n# output shape = 16 x 16 x 64\nmodel = Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\nmodel = BatchNormalization(momentum=0.15)(model)\nmodel = Dropout(rate=0.3)(model)\n\n# filter shape = 3 x 3 x 128 (4 layer)\n# output shape = 16 x 16 x 128\nmodel = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=128, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = BatchNormalization(momentum=0.15)(model)\n\n# max pooling 2 x 2\n# shape = 8 x 8 x 128\nmodel = MaxPool2D(pool_size=(2, 2))(model)\n\n# filter shape = 5 x 5 x 128\n# output shape = 8 x 8 x 128\nmodel = Conv2D(filters=128, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\nmodel = BatchNormalization(momentum=0.15)(model)\nmodel = Dropout(rate=0.3)(model)\n\n# filter shape = 3 x 3 x 256 (4 layer)\n# output shape = 8 x 8 x 256\nmodel = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = Conv2D(filters=256, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = BatchNormalization(momentum=0.15)(model)\n\n# max pooling 2 x 2\n# shape = 4 x 4 x 256\nmodel = MaxPool2D(pool_size=(2, 2))(model)\n\n# filter shape = 5 x 5 x 256\n# output shape = 4 x 4 x 256\nmodel = Conv2D(filters=256, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\nmodel = BatchNormalization(momentum=0.15)(model)\nmodel = Dropout(rate=0.3)(model)\n\n# Làm phẳng tham số\nmodel = Flatten()(model) # output shape = 1024 x 1 x 1\n# Tâng Fully Connected\nmodel = Dense(1024, activation = \"relu\")(model) # output shape = 1024 x 1 x 1\nmodel = Dropout(rate=0.3)(model)\n\ndense = Dense(512, activation = \"relu\")(model) # output shape = 512 x 1 x 1\n\nhead_root = Dense(168, activation = 'softmax')(dense)\nhead_vowel = Dense(11, activation = 'softmax')(dense)\nhead_consonant = Dense(7, activation = 'softmax')(dense)\n\nmodel = Model(inputs=inputs, outputs=[head_root, head_vowel, head_consonant])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:25:53.710386Z","iopub.execute_input":"2021-09-09T04:25:53.710681Z","iopub.status.idle":"2021-09-09T04:25:56.702559Z","shell.execute_reply.started":"2021-09-09T04:25:53.710632Z","shell.execute_reply":"2021-09-09T04:25:56.701573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:26:00.59874Z","iopub.execute_input":"2021-09-09T04:26:00.599087Z","iopub.status.idle":"2021-09-09T04:26:00.613579Z","shell.execute_reply.started":"2021-09-09T04:26:00.599032Z","shell.execute_reply":"2021-09-09T04:26:00.612381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's visualize the 3-tailed (3 output) CNN by plotting it.","metadata":{}},{"cell_type":"code","source":"from keras.utils import plot_model\nplot_model(model, to_file='model.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:26:05.64846Z","iopub.execute_input":"2021-09-09T04:26:05.648758Z","iopub.status.idle":"2021-09-09T04:26:05.769313Z","shell.execute_reply.started":"2021-09-09T04:26:05.6487Z","shell.execute_reply":"2021-09-09T04:26:05.768455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set a learning rate annealer. Learning rate will be half after 3 epochs if accuracy is not increased\nlearning_rate_reduction_root = ReduceLROnPlateau(monitor='dense_3_accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)\nlearning_rate_reduction_vowel = ReduceLROnPlateau(monitor='dense_4_accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)\nlearning_rate_reduction_consonant = ReduceLROnPlateau(monitor='dense_5_accuracy', \n                                            patience=3, \n                                            verbose=1,\n                                            factor=0.5, \n                                            min_lr=0.00001)","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:26:08.92978Z","iopub.execute_input":"2021-09-09T04:26:08.930102Z","iopub.status.idle":"2021-09-09T04:26:08.935731Z","shell.execute_reply.started":"2021-09-09T04:26:08.930052Z","shell.execute_reply":"2021-09-09T04:26:08.935008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size =32\nepochs = 10","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:26:18.039359Z","iopub.execute_input":"2021-09-09T04:26:18.039664Z","iopub.status.idle":"2021-09-09T04:26:18.043443Z","shell.execute_reply.started":"2021-09-09T04:26:18.039609Z","shell.execute_reply":"2021-09-09T04:26:18.042619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n\n    def flow(self,\n             x,\n             y=None,\n             batch_size=32,\n             shuffle=True,\n             sample_weight=None,\n             seed=None,\n             save_to_dir=None,\n             save_prefix='',\n             save_format='png',\n             subset=None):\n\n        targets = None\n        target_lengths = {}\n        ordered_outputs = []\n        for output, target in y.items():\n            if targets is None:\n                targets = target\n            else:\n                targets = np.concatenate((targets, target), axis=1)\n            target_lengths[output] = target.shape[1]\n            ordered_outputs.append(output)\n\n\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,\n                                         shuffle=shuffle):\n            target_dict = {}\n            i = 0\n            for output in ordered_outputs:\n                target_length = target_lengths[output]\n                target_dict[output] = flowy[:, i: i + target_length]\n                i += target_length\n\n            yield flowx, target_dict","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:26:20.30165Z","iopub.execute_input":"2021-09-09T04:26:20.302014Z","iopub.status.idle":"2021-09-09T04:26:20.319557Z","shell.execute_reply.started":"2021-09-09T04:26:20.301967Z","shell.execute_reply":"2021-09-09T04:26:20.318632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HEIGHT = 137\nWIDTH = 236","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:26:24.108501Z","iopub.execute_input":"2021-09-09T04:26:24.108809Z","iopub.status.idle":"2021-09-09T04:26:24.113029Z","shell.execute_reply.started":"2021-09-09T04:26:24.108755Z","shell.execute_reply":"2021-09-09T04:26:24.111975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Training loop","metadata":{}},{"cell_type":"code","source":"# Bắt đầu traing các file parquet\nhistories = []\nfor i in range(4):\n    train_df = pd.merge(pd.read_parquet(f'/kaggle/input/bengaliai-cv19/train_image_data_{i}.parquet'), train_df_, on='image_id').drop(['image_id'], axis=1)\n    \n    # Visualize few samples of current training dataset\n    fig, ax = plt.subplots(nrows=3, ncols=4, figsize=(16, 8))\n    count=0\n    for row in ax:\n        for col in row:\n            col.imshow(resize(train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1).iloc[[count]], need_progress_bar=False).values.reshape(-1).reshape(IMG_SIZE, IMG_SIZE).astype(np.float64))\n            count += 1\n    plt.show()\n    \n    X_train = train_df.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic'], axis=1)\n    X_train = resize(X_train)/255\n    \n    # CNN takes images in shape `(batch_size, h, w, channels)`, so reshape the images\n    X_train = X_train.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n    \n    Y_train_root = pd.get_dummies(train_df['grapheme_root']).values\n    Y_train_vowel = pd.get_dummies(train_df['vowel_diacritic']).values\n    Y_train_consonant = pd.get_dummies(train_df['consonant_diacritic']).values\n\n    print(f'Training images: {X_train.shape}')\n    print(f'Training labels root: {Y_train_root.shape}')\n    print(f'Training labels vowel: {Y_train_vowel.shape}')\n    print(f'Training labels consonants: {Y_train_consonant.shape}')\n\n    # Divide the data into training and validation set\n    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split(X_train, Y_train_root, Y_train_vowel, Y_train_consonant, test_size=0.08, random_state=666)\n    del train_df\n    del X_train\n    del Y_train_root, Y_train_vowel, Y_train_consonant\n\n    # Data augmentation for creating more training data\n    datagen = MultiOutputDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=8,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.15, # Randomly zoom image \n        width_shift_range=0.15,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.15,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\n    # This will just calculate parameters required to augment the given data. This won't perform any augmentations\n    datagen.fit(x_train)\n\n    # Fit the model\n    history = model.fit_generator(datagen.flow(x_train, {'dense_3': y_train_root, 'dense_4': y_train_vowel, 'dense_5': y_train_consonant}, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]), \n                              steps_per_epoch=x_train.shape[0] // batch_size, \n                              callbacks=[learning_rate_reduction_root, learning_rate_reduction_vowel, learning_rate_reduction_consonant])\n\n    histories.append(history)\n    \n    # Xóa để giảm bộ nhớ sử dụng\n    del x_train\n    del x_test\n    del y_train_root\n    del y_test_root\n    del y_train_vowel\n    del y_test_vowel\n    del y_train_consonant\n    del y_test_consonant\n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:26:27.237105Z","iopub.execute_input":"2021-09-09T04:26:27.237397Z","iopub.status.idle":"2021-09-09T04:41:59.123501Z","shell.execute_reply.started":"2021-09-09T04:26:27.237348Z","shell.execute_reply":"2021-09-09T04:41:59.121353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\ndef plot_loss(his, epoch, title):\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\n    plt.plot(np.arange(0, epoch), his.history['dense_3_loss'], label='train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['dense_4_loss'], label='train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['dense_5_loss'], label='train_consonant_loss')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_dense_3_loss'], label='val_train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_4_loss'], label='val_train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_5_loss'], label='val_train_consonant_loss')\n    \n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.show()\n\ndef plot_acc(his, epoch, title):\n    plt.style.use('ggplot')\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['dense_3_accuracy'], label='train_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['dense_4_accuracy'], label='train_vowel_accuracy')\n    plt.plot(np.arange(0, epoch), his.history['dense_5_accuracy'], label='train_consonant_accuracy')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_dense_3_accuracy'], label='val_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_4_accuracy'], label='val_vowel_accuracy')\n    plt.plot(np.arange(0, epoch), his.history['val_dense_5_accuracy'], label='val_consonant_accuracy')\n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='upper right')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:42:07.065094Z","iopub.execute_input":"2021-09-09T04:42:07.065404Z","iopub.status.idle":"2021-09-09T04:42:07.092118Z","shell.execute_reply.started":"2021-09-09T04:42:07.065352Z","shell.execute_reply":"2021-09-09T04:42:07.091136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for dataset in range(4):\n    plot_loss(histories[dataset], epochs, f'Training Dataset: {dataset}')\n    plot_acc(histories[dataset], epochs, f'Training Dataset: {dataset}')","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:42:10.272088Z","iopub.execute_input":"2021-09-09T04:42:10.272394Z","iopub.status.idle":"2021-09-09T04:42:10.820067Z","shell.execute_reply.started":"2021-09-09T04:42:10.272343Z","shell.execute_reply":"2021-09-09T04:42:10.818978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del histories\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:42:30.155197Z","iopub.execute_input":"2021-09-09T04:42:30.155497Z","iopub.status.idle":"2021-09-09T04:42:30.411079Z","shell.execute_reply.started":"2021-09-09T04:42:30.155446Z","shell.execute_reply":"2021-09-09T04:42:30.410156Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:42:32.516141Z","iopub.execute_input":"2021-09-09T04:42:32.516452Z","iopub.status.idle":"2021-09-09T04:42:32.520201Z","shell.execute_reply.started":"2021-09-09T04:42:32.516398Z","shell.execute_reply":"2021-09-09T04:42:32.519413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntarget=[] # model predictions placeholder\nrow_id=[] # row_id place holder\nfor i in range(4):\n    df_test_img = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_{}.parquet'.format(i)) \n    df_test_img.set_index('image_id', inplace=True)\n\n    X_test = resize(df_test_img, need_progress_bar=False)/255\n    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n    \n    preds = model.predict(X_test)\n\n    for i, p in enumerate(preds_dict):\n        preds_dict[p] = np.argmax(preds[i], axis=1)\n\n    for k,id in enumerate(df_test_img.index.values):  \n        for i,comp in enumerate(components):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n    del df_test_img\n    del X_test\n    gc.collect()\n\ndf_sample = pd.DataFrame(\n    {\n        'row_id': row_id,\n        'target':target\n    },\n    columns = ['row_id','target'] \n)\ndf_sample.to_csv('submission.csv',index=False)\ndf_sample.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:42:51.075354Z","iopub.execute_input":"2021-09-09T04:42:51.075658Z","iopub.status.idle":"2021-09-09T04:49:07.662741Z","shell.execute_reply.started":"2021-09-09T04:42:51.075608Z","shell.execute_reply":"2021-09-09T04:49:07.661931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testParquet = pd.read_parquet('/kaggle/input/bengaliai-cv19/test_image_data_0.parquet')\ntestParquet.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-09T04:49:07.664353Z","iopub.execute_input":"2021-09-09T04:49:07.664643Z","iopub.status.idle":"2021-09-09T04:50:42.229047Z","shell.execute_reply.started":"2021-09-09T04:49:07.664597Z","shell.execute_reply":"2021-09-09T04:50:42.22826Z"},"trusted":true},"execution_count":null,"outputs":[]}]}