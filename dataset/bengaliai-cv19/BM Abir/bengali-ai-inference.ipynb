{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is from [@Abhishek Thakur](https://www.youtube.com/channel/UCBPRJjIWfyNG4X-CRbnv78A) youtube channel\n\n[Bengali.AI: Handwritten Grapheme Classification Using PyTorch (Part-1)](https://www.youtube.com/watch?v=8J5Q4mEzRtY)\n\n[Bengali.AI: Handwritten Grapheme Classification Using PyTorch (Part-2)](https://www.youtube.com/watch?v=uZalt-weQMM&t=3970s)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## Ref https://youtu.be/uZalt-weQMM\nimport sys\npt_models = \"../input/pretrained-models/pretrained-models.pytorch-master/\"\nsys.path.insert(0,pt_models)\nimport pretrainedmodels\n\nimport glob\nimport torch\nimport albumentations\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nfrom tqdm import tqdm\nfrom PIL import Image\nimport joblib\nimport torch.nn as nn\nfrom torch.nn import functional as F","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TEST_BATCH_SIZE = 32\nMODEL_MEAN=(0.485,0.465,0.406)\nMODEL_STD=(0.229,0.224,0.225)\nIMG_HEIGHT=137\nIMG_WIDTH=236\nDEVICE=\"cuda\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ResNet34(nn.Module):\n    def __init__(self ,pretrained):\n        super(ResNet34,self).__init__()\n        if pretrained is True:\n            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=\"imagenet\")\n        else:\n            self.model = pretrainedmodels.__dict__[\"resnet34\"](pretrained=None)\n\n        # To replace the last layer of the model with these\n        self.layer0 = nn.Linear(512,168) # 168 grapheme_root\n        self.layer1 = nn.Linear(512,11) # 11 vowel_diacritic\n        self.layer2 = nn.Linear(512,7) # 7 consonant_diacritic\n\n    def forward(self,x):\n#         print(x.shape)\n        batch_size ,_,_,_ = x.shape\n        x = self.model.features(x)\n        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size, -1)\n        layer0 = self.layer0(x)\n        layer1 = self.layer1(x)\n        layer2 = self.layer2(x)\n        return layer0, layer1, layer2 # grapheme_root, vowel_diacritic, consonant_diacritic\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class BengaliDatasetTest:\n    def __init__(self, df, img_height, img_width, mean, std):\n        \n        self.image_ids = df.image_id.values\n        self.img_arr = df.iloc[:, 1:].values\n\n        self.aug = albumentations.Compose([\n            albumentations.Resize(img_height, img_width, always_apply=True),\n            albumentations.Normalize(mean, std, always_apply=True)\n        ])\n\n\n    def __len__(self):\n        return len(self.image_ids)\n    \n    def __getitem__(self, item):\n        image = self.img_arr[item, :]\n        img_id = self.image_ids[item]\n        \n        image = image.reshape(137, 236).astype(float)\n        image = Image.fromarray(image).convert(\"RGB\")\n        image = self.aug(image=np.array(image))[\"image\"]\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n\n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"image_id\": img_id\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def model_predict():\n    g_pred, v_pred, c_pred = [], [], []\n    img_ids_list = [] \n    \n    for file_idx in range(4):\n        df = pd.read_parquet(f\"../input/bengaliai-cv19/test_image_data_{file_idx}.parquet\")\n\n        dataset = BengaliDatasetTest(df=df,\n                                    img_height=IMG_HEIGHT,\n                                    img_width=IMG_WIDTH,\n                                    mean=MODEL_MEAN,\n                                    std=MODEL_STD)\n\n        data_loader = torch.utils.data.DataLoader(\n            dataset=dataset,\n            batch_size= TEST_BATCH_SIZE,\n            shuffle=False,\n            num_workers=4\n        )\n\n        for bi, d in enumerate(data_loader):\n            image = d[\"image\"]\n            img_id = d[\"image_id\"]\n            image = image.to(DEVICE, dtype=torch.float)\n\n            g, v, c = model(image)\n            #g = np.argmax(g.cpu().detach().numpy(), axis=1)\n            #v = np.argmax(v.cpu().detach().numpy(), axis=1)\n            #c = np.argmax(c.cpu().detach().numpy(), axis=1)\n\n            for ii, imid in enumerate(img_id):\n                g_pred.append(g[ii].cpu().detach().numpy())\n                v_pred.append(v[ii].cpu().detach().numpy())\n                c_pred.append(c[ii].cpu().detach().numpy())\n                img_ids_list.append(imid)\n        \n    return g_pred, v_pred, c_pred, img_ids_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = ResNet34(pretrained=False)\nTEST_BATCH_SIZE = 32\nStart_fold=3\nfinal_g_pred = []\nfinal_v_pred = []\nfinal_c_pred = []\nfinal_img_ids = []\n\nfor i in range(Start_fold,5):\n    model.load_state_dict(torch.load(f\"../input/bengali-models/50 Epoch/resnet34_fold{i}.bin\"))\n#     print(model)\n    model.to(DEVICE)\n    model.eval()\n    g_pred, v_pred, c_pred, img_ids_list = model_predict()\n#     print(img_ids_list)\n    final_g_pred.append(g_pred)\n    final_v_pred.append(v_pred)\n    final_c_pred.append(c_pred)\n#     print(final_c_pred)\n    if i == Start_fold:\n        final_img_ids.extend(img_ids_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_g = np.argmax(np.mean(np.array(final_g_pred), axis=0), axis=1)\nfinal_v = np.argmax(np.mean(np.array(final_v_pred), axis=0), axis=1)\nfinal_c = np.argmax(np.mean(np.array(final_c_pred), axis=0), axis=1)\n# print(final_g)\n# print(final_img_ids)\npredictions = []\nfor ii, imid in enumerate(final_img_ids):\n\n    predictions.append((f\"{imid}_grapheme_root\", final_g[ii]))\n    predictions.append((f\"{imid}_vowel_diacritic\", final_v[ii]))\n    predictions.append((f\"{imid}_consonant_diacritic\", final_c[ii]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame(predictions,columns=[\"row_id\",\"target\"])\nprint(sub)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}