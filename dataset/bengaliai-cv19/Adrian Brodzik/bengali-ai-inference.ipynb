{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/efficientnet-pytorch\n!pip install /kaggle/input/pytorchcv/pytorchcv-0.0.57-py2.py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport os\nimport zipfile\n\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import EfficientNet\nfrom pytorchcv.model_provider import get_model\nfrom torch.utils.data import DataLoader, Dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_FILES = [\"/kaggle/input/bengaliai-cv19/test_image_data_0.parquet\",\n               \"/kaggle/input/bengaliai-cv19/test_image_data_1.parquet\",\n               \"/kaggle/input/bengaliai-cv19/test_image_data_2.parquet\",\n               \"/kaggle/input/bengaliai-cv19/test_image_data_3.parquet\"]\n\nHEIGHT = 137\nWIDTH = 236\n\nBATCH_SIZE = 50\n\nDEVICE = torch.device(\"cuda\")\nDTYPE = torch.float","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def bbox(img):\n    rows = np.any(img, axis=1)\n    cols = np.any(img, axis=0)\n    rmin, rmax = np.where(rows)[0][[0, -1]]\n    cmin, cmax = np.where(cols)[0][[0, -1]]\n    return rmin, rmax, cmin, cmax","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_resize(img0, size, pad=16):\n    ymin, ymax, xmin, xmax = bbox(img0[5:-5, 5:-5] > 80)\n    xmin = xmin - 13 if (xmin > 13) else 0\n    ymin = ymin - 10 if (ymin > 10) else 0\n    xmax = xmax + 13 if (xmax < WIDTH - 13) else WIDTH\n    ymax = ymax + 10 if (ymax < HEIGHT - 10) else HEIGHT\n    img = img0[ymin:ymax, xmin:xmax]\n    img[img < 28] = 0\n    lx, ly = xmax-xmin, ymax-ymin\n    l = max(lx, ly) + pad\n    img = np.pad(img, [((l-ly)//2,), ((l-lx)//2,)], mode=\"constant\")\n    return cv2.resize(img, (size, size))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_images(input_files, output_file, size):\n    x_tot, x2_tot = [], []\n\n    with zipfile.ZipFile(output_file, \"w\") as img_out:\n        for fname in input_files:\n            df = pd.read_parquet(fname)\n            data = 255 - df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH).astype(np.uint8)\n            for idx in range(len(df)):\n                name = df.iloc[idx, 0]\n\n                img = (data[idx]*(255.0/data[idx].max())).astype(np.uint8)\n                img = crop_resize(img, size)\n\n                x_tot.append((img/255.0).mean())\n                x2_tot.append(((img/255.0)**2).mean())\n                img = cv2.imencode(\".png\", img)[1]\n                img_out.writestr(name + \".png\", img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, img_dir, img_files):\n        self.img_dir = img_dir\n        self.img_files = img_files\n\n    def __len__(self):\n        return len(self.img_files)\n\n    def __getitem__(self, idx):\n        img = cv2.imread(self.img_files[idx])\n        img = img.transpose((2, 0, 1))[0]\n        img = img / 255\n        return int(self.img_files[idx].replace(self.img_dir, \"\").replace(\".png\", \"\").replace(\"Test_\", \"\")), np.array([img])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = {}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.isfile(\"test_images_128.zip\"):\n    preprocess_images(INPUT_FILES, \"test_images_128.zip\", 128)\n\nwith zipfile.ZipFile(\"test_images_128.zip\") as img_zip:\n    img_zip.extractall(\"test_images_128\")\n\ntest_set = MyDataset(\"test_images_128/\", glob.glob(\"test_images_128/*.png\"))\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################################\n# EfficientNet B5 Epoch 28 (Public score: 0.9638)\n##################################################\nmodel = EfficientNet.from_name_2(\"efficientnet-b5\", num_classes=186, in_channels=1)\nmodel.load_state_dict(torch.load(\"/kaggle/input/bengaliai-trained-models/model_b5_28.pth\"))\nmodel = model.to(device=DEVICE, dtype=DTYPE)\nmodel = model.eval()\n\nwith torch.no_grad():\n    for test_id, X in test_loader:\n        test_id = test_id.numpy()\n        X = X.to(device=DEVICE, dtype=DTYPE)\n\n        y_pred = model(X)\n        y_pred = torch.sigmoid(y_pred).cpu().detach().numpy() * 0.9638\n\n        for i, pred in list(zip(test_id, y_pred)):\n            if i in preds:\n                preds[i] += pred\n            else:\n                preds[i] = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################################\n# EfficientNet B2 epoch 20 (Public score: 0.9629)\n##################################################\nmodel = EfficientNet.from_name_2(\"efficientnet-b2\", num_classes=186, in_channels=1)\nmodel.load_state_dict(torch.load(\"/kaggle/input/bengaliai-trained-models/model_b2_20.pth\"))\nmodel = model.to(device=DEVICE, dtype=DTYPE)\nmodel = model.eval()\n\nwith torch.no_grad():\n    for test_id, X in test_loader:\n        test_id = test_id.numpy()\n        X = X.to(device=DEVICE, dtype=DTYPE)\n\n        y_pred = model(X)\n        y_pred = torch.sigmoid(y_pred).cpu().detach().numpy() * 0.9629\n\n        for i, pred in list(zip(test_id, y_pred)):\n            if i in preds:\n                preds[i] += pred\n            else:\n                preds[i] = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf test_images_128 test_images_128.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if not os.path.isfile(\"test_images_224.zip\"):\n    preprocess_images(INPUT_FILES, \"test_images_224.zip\", 224)\n\nwith zipfile.ZipFile(\"test_images_224.zip\") as img_zip:\n    img_zip.extractall(\"test_images_224\")\n\ntest_set = MyDataset(\"test_images_224/\", glob.glob(\"test_images_224/*.png\"))\ntest_loader = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##################################################\n# seresnext50_32x4d epoch 16 (Public score: 0.9630)\n##################################################\nmodel = get_model(\"seresnext50_32x4d\", pretrained=False)\nmodel.features.init_block.conv.conv = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.output = nn.Linear(in_features=2048, out_features=186, bias=True)\nmodel.load_state_dict(torch.load(\"/kaggle/input/bengaliai-trained-models/model_seresnext50_32x4d_16.pth\"))\nmodel = model.to(device=DEVICE, dtype=DTYPE)\nmodel = model.eval()\n\nwith torch.no_grad():\n    for test_id, X in test_loader:\n        test_id = test_id.numpy()\n        X = X.to(device=DEVICE, dtype=DTYPE)\n\n        y_pred = model(X)\n        y_pred = torch.sigmoid(y_pred).cpu().detach().numpy() * 0.9630\n\n        for i, pred in list(zip(test_id, y_pred)):\n            if i in preds:\n                preds[i] += pred\n            else:\n                preds[i] = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf test_images_224 test_images_224.zip","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = []","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"for i, pred in preds.items():\n    y1 = np.argmax(pred[:168]) # grapheme_root\n    y2 = np.argmax(pred[168:179]) # vowel_diacritic\n    y3 = np.argmax(pred[179:]) # consonant_diacritic\n\n    submission.append((i, \"Test_\" + str(i) + \"_grapheme_root\", y1))\n    submission.append((i, \"Test_\" + str(i) + \"_vowel_diacritic\", y2))\n    submission.append((i, \"Test_\" + str(i) + \"_consonant_diacritic\", y3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(submission, columns=[\"id\", \"row_id\", \"target\"]).sort_values(by=[\"id\", \"row_id\"]).reset_index()[[\"row_id\", \"target\"]]\nsubmission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}