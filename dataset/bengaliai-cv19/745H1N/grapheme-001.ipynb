{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from matplotlib import pyplot as plt\nimport numpy as np \nimport pandas as pd \nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\nimport random \nimport os\nimport cv2\nimport gc\nfrom tqdm.auto import tqdm\n\n\nimport numpy as np\nimport keras\nfrom tensorflow.keras.models import Sequential, clone_model\nfrom tensorflow.keras.layers import BatchNormalization, LeakyReLU, Dense, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import SGD\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport numpy as np\nimport datetime as dt\n\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\n# for dirname, _, filenames in os.walk('../input/bengaliai-cv19/'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/bengaliai-cv19/train.csv')\n\ndef resize(df, size=64, need_progress_bar=True):\n    resized = {}\n    for i in range(df.shape[0]):\n        image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n        resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = keras.Input(shape = (64, 64, 1))\n#CONV 1A STARTS\nmodel = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(inputs)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.BatchNormalization(momentum=0.15)(model)\nmodel = layers.MaxPool2D(pool_size=(2, 2))(model)\nmodel = layers.Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.Dropout(rate=0.3)(model)\n#CONV 1B STARTS\nmodel = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(inputs)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.Conv2D(filters=32, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.BatchNormalization(momentum=0.15)(model)\nmodel = layers.MaxPool2D(pool_size=(2, 2))(model)\nmodel = layers.Conv2D(filters=32, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.Dropout(rate=0.3)(model)\n\n#CONV 2A STARTS\nmodel = layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.BatchNormalization(momentum=0.15)(model)\nmodel = layers.Dropout(rate=0.3)(model)\n#CONV 2B STARTS\nmodel = layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.BatchNormalization(momentum=0.15)(model)\nmodel = layers.Dropout(rate=0.3)(model)\n#CONV 3A STARTS\nmodel = layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.Conv2D(filters=64, kernel_size=(3, 3), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.BatchNormalization(momentum=0.15)(model)\nmodel = layers.MaxPool2D(pool_size=(2, 2))(model)\n#CONV 3B STARTS\nmodel = layers.Conv2D(filters=64, kernel_size=(5, 5), padding='SAME', activation='relu')(model)\nmodel = tf.nn.leaky_relu(model, alpha=0.01, name='Leaky_ReLU') \nmodel = layers.BatchNormalization(momentum=0.15)(model)\nmodel = layers.Dropout(rate=0.3)(model)\n#FLATTEN STARTS\nmodel = layers.Flatten()(model)\nmodel = layers.Dense(1024, activation = \"relu\")(model)\nmodel = layers.Dropout(rate=0.3)(model)\ndense = layers.Dense(512, activation = \"relu\")(model)\n#CLASS DECSISION STARTS    \nout_root = layers.Dense(168, activation='softmax', name='root_out')(dense) \nout_vowel = layers.Dense(11, activation='softmax', name='vowel_out')(dense) \nout_consonant = layers.Dense(7, activation='softmax', name='consonant_out')(dense)\n#FINAL MODEL    \ncnn1model = keras.Model(inputs=inputs, outputs=[out_root, out_vowel, out_consonant])\n\nplot_model(cnn1model, to_file='mode4.png')\n# print(cnn1model.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cnn1model.compile(optimizer=\"adam\", loss=['categorical_crossentropy','categorical_crossentropy','categorical_crossentropy'], metrics=['accuracy']) \nmc = keras.callbacks.ModelCheckpoint('weights{epoch:08d}.h5', save_weights_only=True, period=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 128\nepochs = 40\nhistory_list = []\nparaquets_used = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultiOutputDataGenerator(keras.preprocessing.image.ImageDataGenerator):\n    def flow(self,x,y=None,batch_size=32,shuffle=True,sample_weight=None,seed=None,save_to_dir=None,save_prefix='',save_format='png',subset=None):\n        targets = None\n        target_lengths = {}\n        ordered_outputs = []\n        for output, target in y.items():\n            if targets is None:\n                targets = target\n            else:\n                targets = np.concatenate((targets, target), axis=1)\n            target_lengths[output] = target.shape[1]\n            ordered_outputs.append(output)\n\n        for flowx, flowy in super().flow(x, targets, batch_size=batch_size,shuffle=shuffle):\n            target_dict = {}\n            i = 0\n            for output in ordered_outputs:\n                target_length = target_lengths[output]\n                target_dict[output] = flowy[:, i: i + target_length]\n                i += target_length\n\n            yield flowx, target_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(paraquets_used):\n    b_train_data =  pd.merge(pd.read_parquet(f'../input/bengaliai-cv19/train_image_data_{i}.parquet'), train_data, on='image_id').drop(['image_id'], axis =1)\n    print(\"Data Loaded\")\n    x_train, x_test, y_train_root, y_test_root, y_train_vowel, y_test_vowel, y_train_consonant, y_test_consonant = train_test_split((resize(\n        b_train_data.drop(['grapheme_root', 'vowel_diacritic', 'consonant_diacritic','grapheme'], axis=1))/255).values.reshape(-1, 64, 64, 1), pd.get_dummies(\n        b_train_data['grapheme_root']).values, pd.get_dummies(b_train_data['vowel_diacritic']).values, pd.get_dummies(b_train_data['consonant_diacritic']).values, \n                                                                                                                                    test_size=0.08, random_state=666)\n    print(\"b train data : \")\n    print(b_train_data)\n    print(\"x train : \")\n    print(x_train)\n    del b_train_data\n    gc.collect()\n    \n    #del Y_train_root, Y_train_vowel, Y_train_consonant\n    indeX = str(i)\n    print(\"Run \" + indeX + \" starts\")\n    datagen = MultiOutputDataGenerator(\n        featurewise_center=False,            # set input mean to 0 over the dataset\n        samplewise_center=False,             # set each sample mean to 0\n        featurewise_std_normalization=False, # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,                 # apply ZCA whitening\n        rotation_range=8,                    # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.20,                   # Randomly zoom image \n        width_shift_range=0.20,              # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.20,             # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,               # randomly flip images\n        vertical_flip=False)                 # randomly flip images\n\n\n        # This will just calculate parameters required to augment the given data. This won't perform any augmentations\n    datagen.fit(x_train)\n    history = cnn1model.fit_generator(datagen.flow(x_train, {'root_out': y_train_root, 'vowel_out': y_train_vowel, 'consonant_out': y_train_consonant}, batch_size=batch_size),\n            epochs = epochs, validation_data = (x_test, [y_test_root, y_test_vowel, y_test_consonant]), \n            steps_per_epoch=x_train.shape[0] // batch_size,\n            callbacks=[mc])\n                                  \n    history_list.append(history)\n    del datagen\n    del x_train\n    del x_test\n    del y_train_root\n    del y_test_root\n    del y_train_vowel\n    del y_test_vowel\n    del y_train_consonant\n    del y_test_consonant    \n    print(\"Run \" + indeX + \" ends\")\n    gc.collect()\ndel train_data\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\ndef plot_loss(his, epoch, title):\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['loss'], label='train_loss')\n    plt.plot(np.arange(0, epoch), his.history['root_out_loss'], label='train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['vowel_out_loss'], label='train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['consonant_out_loss'], label='train_consonant_loss')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_root_out_loss'], label='val_train_root_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_vowel_out_loss'], label='val_train_vowel_loss')\n    plt.plot(np.arange(0, epoch), his.history['val_consonant_out_loss'], label='val_train_consonant_loss')\n    \n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Loss')\n    plt.legend(loc='upper right')\n    plt.show()\n\ndef plot_acc(his, epoch, title):\n    plt.figure()\n    plt.plot(np.arange(0, epoch), his.history['root_out_acc'], label='train_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['vowel_out_acc'], label='train_vowel_acc')\n    plt.plot(np.arange(0, epoch), his.history['consonant_out_acc'], label='train_consonant_acc')\n    \n    plt.plot(np.arange(0, epoch), his.history['val_root_out_acc'], label='val_root_acc')\n    plt.plot(np.arange(0, epoch), his.history['val_vowel_out_acc'], label='val_vowel_acc')\n    plt.plot(np.arange(0, epoch), his.history['val_consonant_out_acc'], label='val_consonant_acc')\n    plt.title(title)\n    plt.xlabel('Epoch #')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='upper right')\n    plt.show()\n    \nfor dataset in range(paraquets_used):\n    plot_loss(history_list[dataset], epochs, f'Training Dataset: {dataset}')\n    plot_acc(history_list[dataset], epochs, f'Training Dataset: {dataset}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_dict = {\n    'grapheme_root': [],\n    'vowel_diacritic': [],\n    'consonant_diacritic': []\n}\n\ncomponents = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\ntarget=[] # model predictions placeholder\nrow_id=[] # row_id place holder\nfor i in range(4):\n    df_test_img = pd.read_parquet('../input/bengaliai-cv19/test_image_data_{}.parquet'.format(i)) \n    df_test_img.set_index('image_id', inplace=True)\n    X_test = resize(df_test_img, need_progress_bar=False)/255\n    X_test = X_test.values.reshape(-1, 64, 64, 1)\n    preds = cnn1model.predict(X_test)\n    for i, p in enumerate(preds_dict):\n        preds_dict[p] = np.argmax(preds[i], axis=1)\n\n    for k,id in enumerate(df_test_img.index.values):  \n        for i,comp in enumerate(components):\n            id_sample=id+'_'+comp\n            row_id.append(id_sample)\n            target.append(preds_dict[comp][k])\n    del df_test_img\n    del X_test\n    gc.collect()\n\ndf_sample = pd.DataFrame({'row_id': row_id, 'target':target}, columns = ['row_id','target'])\ndf_sample.to_csv('submission.csv',index=False)\ndf_sample.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}