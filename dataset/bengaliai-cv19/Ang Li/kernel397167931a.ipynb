{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pwd","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!pip install /kaggle/input/pretrained/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4/","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import os\nimport shutil\nif not os.path.exists('/tmp/.cache/torch/checkpoints/'):\n    os.makedirs('/tmp/.cache/torch/checkpoints/')\nshutil.copy('/kaggle/input/pretrained/densenet121-fbdb23505.pth','/tmp/.cache/torch/checkpoints/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"model_name = 'densenet121'\nchannels = 1024\nloss_weight1 = 0.8\nloss_weight2 = 0.1\nloss_weight3 = 0.1\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# -*- coding: utf-8 -*-\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport torch.nn.functional as F\nfrom torch.nn import Sequential\nimport pretrainedmodels\nimport torchvision.models as models\n\nIMAGE_RGB_MEAN = [0.485, 0.456, 0.406]\nIMAGE_RGB_STD  = [0.229, 0.224, 0.225]\n\n\nclass LinearBlock(nn.Module):\n\n    def __init__(self, in_features, out_features, bias=True,\n                 use_bn=True, activation=F.relu, dropout_ratio=-1, residual=False,):\n        super(LinearBlock, self).__init__()\n        if in_features is None:\n            self.linear = LazyLinear(in_features, out_features, bias=bias)\n        else:\n            self.linear = nn.Linear(in_features, out_features, bias=bias)\n        if use_bn:\n            self.bn = nn.BatchNorm1d(out_features)\n        if dropout_ratio > 0.:\n            self.dropout = nn.Dropout(p=dropout_ratio)\n        else:\n            self.dropout = None\n        self.activation = activation\n        self.use_bn = use_bn\n        self.dropout_ratio = dropout_ratio\n        self.residual = residual\n    def __call__(self, x):\n        h = self.linear(x)\n        if self.use_bn:\n            h = self.bn(h)\n        if self.activation is not None:\n            h = self.activation(h)\n        if self.residual:\n            h = residual_add(h, x)\n        if self.dropout_ratio > 0:\n            h = self.dropout(h)\n        return h\n\nclass RGB(nn.Module):\n    def __init__(self,):\n        super(RGB, self).__init__()\n        self.register_buffer('mean', torch.zeros(1,3,1,1))\n        self.register_buffer('std', torch.ones(1,3,1,1))\n        self.mean.data = torch.FloatTensor(IMAGE_RGB_MEAN).view(self.mean.shape)\n        self.std.data = torch.FloatTensor(IMAGE_RGB_STD).view(self.std.shape)\n\n    def forward(self, x):\n        print(self.mean,self.std)\n        x = (x-self.mean)/self.std\n        return x\n\n\n\nclass classifier(nn.Module):\n    def __init__(self,n_classes=[168,11,7],use_bn=True):\n        super(classifier, self).__init__()\n        #self.conv0 = nn.Conv2d(1,3,kernel_size=3,stride=1,padding=1)\n        self.base_model = pretrainedmodels.__dict__[model_name](pretrained='imagenet')\n        #print(*list(self.base_model.children()))\n        #exit()\n        \n        self.backbone = nn.Sequential(*list(self.base_model.children())[:-1]) \n\n        inch = channels\n\n\n        self.lin1 = LinearBlock(inch, 512, use_bn=use_bn, activation=F.leaky_relu, dropout_ratio = 0.5, residual=False)\n        \n        self.head1 = LinearBlock(512, 168, use_bn=False, activation=None, residual=False)\n\n        self.head2 = LinearBlock(512, 11, use_bn=False, activation=None, residual=False)\n\n        self.head3 = LinearBlock(512, 7, use_bn=False, activation=None, residual=False)\n\n\n    def forward(self,x):\n        x_ = x\n        feat = self.backbone(x_)\n        h = torch.mean(feat, dim=(-1,-2))\n        h = self.lin1(h)\n        \n        x1 = self.head1(h)\n\n        x2 = self.head2(h)\n\n        x3 = self.head3(h)\n\n        return x1,x2,x3\n\n        \n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = classifier().cuda()\n\nif os.path.exists('/kaggle/input/densenet/densenet121_86.pth'):\n    model.load_state_dict(torch.load('/kaggle/input/densenet/densenet121_86.pth'))\n    print(\"load model success\")\nelse:\n    print('load model fail')\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset,DataLoader\nimport pandas as pd\nimport numpy as np\nimport cv2\nH=137\nW=236\n\nclass GraphemeDataset(Dataset):#测试dataset\n    def __init__(self, fname):\n        print(fname)\n        self.df = pd.read_parquet(fname)\n        self.data = 255 - self.df.iloc[:, 1:].values.reshape(-1, H, W).astype(np.uint8)\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        name = self.df.iloc[idx,0]\n        img = np.reshape(self.data[idx],(H,W))\n        img = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)\n        img = img.astype(np.float32)/255.0\n        img = np.transpose(img,(2,0,1))\n        mean = np.array([0.485, 0.456, 0.406]).reshape(3,1,1)\n        std = np.array([0.229, 0.224, 0.225]).reshape(3,1,1)\n        img = (img-mean)/std\n        img = torch.FloatTensor(img)\n        return img, name\n\ntest_data = ['/kaggle/input/bengaliai-cv19/test_image_data_0.parquet','/kaggle/input/bengaliai-cv19/test_image_data_1.parquet','/kaggle/input/bengaliai-cv19/test_image_data_2.parquet',\n             '/kaggle/input/bengaliai-cv19/test_image_data_3.parquet']","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"from tqdm import tqdm_notebook as tqdm\nrow_id,target = [],[]\nfor fname in test_data:\n    #data = pd.read_parquet(f'/kaggle/input/bengaliai-cv19/{fname}')\n    test_image = GraphemeDataset(fname)\n    dl = torch.utils.data.DataLoader(test_image,batch_size=128,num_workers=12,shuffle=False)\n    with torch.no_grad():\n        for x, y in tqdm(dl):\n            x = x.float().cuda()\n            p1,p2,p3 = model(x)\n            p1 = p1.argmax(-1).view(-1).cpu()\n            p2 = p2.argmax(-1).view(-1).cpu()\n            p3 = p3.argmax(-1).view(-1).cpu()\n            for idx,name in enumerate(y):\n                row_id += [f'{name}_grapheme_root',f'{name}_vowel_diacritic',\n                           f'{name}_consonant_diacritic']\n                target += [p1[idx].item(),p2[idx].item(),p3[idx].item()]\n                \nsub_df = pd.DataFrame({'row_id': row_id, 'target': target})\nsub_df.to_csv('submission.csv', index=False)\nsub_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}