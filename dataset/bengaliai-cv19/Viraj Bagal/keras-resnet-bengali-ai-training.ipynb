{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom numpy.random import shuffle\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.models import Sequential\nimport keras\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping\nfrom keras.utils import to_categorical\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport gc\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAINDF_PATH = '/kaggle/input/bengaliai-cv19'\nIMG_PATH = '/kaggle/input/bengaliai/256_train/256'\ndf_train = pd.read_csv(TRAINDF_PATH + '/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 64\nDIM = (256,256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nclass BengaliGenerator(keras.utils.Sequence):\n    def __init__(self,data,batch_size,dim, shuffle):\n        self.data = data\n        self.labels1 = pd.get_dummies(data['grapheme_root'], columns = ['grapheme_root'])\n        self.labels2 = pd.get_dummies(data['vowel_diacritic'], columns = ['vowel_diacritic'])\n        self.labels3 = pd.get_dummies(data['consonant_diacritic'], columns = ['consonant_diacritic'])\n        self.list_ids = data.index.values\n        self.batch_size = batch_size\n        self.dim = dim\n        self.shuffle = shuffle\n        self.on_epoch_end()\n        \n    def __len__(self):\n        return int(np.floor(len(self.data)/self.batch_size))\n    \n    def __getitem__(self,index):\n        batch_ids = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        \n        valid_ids = [self.list_ids[k] for k in batch_ids]\n        X = np.empty((self.batch_size, *self.dim, 3))\n        Y1 = np.empty((self.batch_size, 168), dtype = int)\n        Y2 = np.empty((self.batch_size, 11), dtype = int)\n        Y3 = np.empty((self.batch_size, 7), dtype = int)\n        \n        for i, k in enumerate(valid_ids):\n            X[i,:, :, :] = cv2.imread(IMG_PATH + self.data['image_id'][k] + '.png') \n            Y1[i,:] = self.labels1.loc[k, :].values\n            Y2[i,:] = self.labels2.loc[k, :].values\n            Y3[i,:] = self.labels3.loc[k, :].values\n            \n        return X, [Y1, Y2, Y3]\n    \n    def on_epoch_end(self):\n        self.indexes = np.arange(len(self.list_ids))\n        if self.shuffle:\n            shuffle(self.indexes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_X, val_X = train_test_split(df_train, test_size = 0.2, random_state = 2019)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = BengaliGenerator(train_X, BATCH_SIZE, DIM, True)\nval_generator = BengaliGenerator(val_X, BATCH_SIZE, DIM, True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x,y = train_generator.next()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# x,y = next(train_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resnet=ResNet50(weights='../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5',\n#                include_top=False,input_shape=(*DIM,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet=ResNet50(weights=None,\n               include_top=False,input_shape=(*DIM,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Conv2D\n\nresnet.layers[2] = Conv2D(64, (2, 2),\n                      strides=(2, 2),\n                      padding='valid',\n                      kernel_initializer='he_normal',\n                      name='conv1')\n\nresnet.layers[2].build((None,262,262,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, GlobalAveragePooling2D, Dropout, Dense\nfrom keras.models import Model\n\ndef build_model(nclasses1, nclasses2, nclasses3):\n    \n    res_output = resnet.output\n    x = GlobalAveragePooling2D()(res_output)\n    x = Dropout(0.5)(x)\n    out1 = Dense(nclasses1, activation = 'softmax')(x)\n    out2 = Dense(nclasses2, activation = 'softmax')(x)\n    out3 = Dense(nclasses3, activation = 'softmax')(x)\n    \n    model = Model(inputs = resnet.input, outputs = [out1,out2,out3])\n    \n#     for layer in model.layers:\n#         layer.trainable=True\n    \n    model.compile(\n        loss='categorical_crossentropy',\n        optimizer=Adam(lr=4e-4),\n        metrics=['accuracy']\n    )\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model(168, 11, 7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"est=EarlyStopping(monitor='val_loss',patience=5, min_delta=0.005)\ncheck_point = ModelCheckpoint('resnet50_1.pth', monitor = 'val_loss', verbose = 1, save_best_only = True, mode = 'min')\ncall_backs=[est, check_point]\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=int(len(train_X)/BATCH_SIZE),\n    validation_data=val_generator,\n    validation_steps = int(len(val_X))/BATCH_SIZE,\n     epochs=5,\n   callbacks=call_backs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}