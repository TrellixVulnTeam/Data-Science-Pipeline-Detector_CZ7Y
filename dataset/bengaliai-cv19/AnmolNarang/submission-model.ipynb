{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load in \n\nimport os\n# import gc\n# os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\";\n# !pip uninstall tensorflow --yes\n# !pip install tensorflow-gpu \n# The GPU id to use, usually either \"0\" or \"1\";\n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"; \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport glob\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Prediction Code**"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_files = glob.glob('/kaggle/input/bengaliai-cv19/test_image_data_*')\ntest_files.sort()\n# model = load_model('/kaggle/input/resnet50/ResNet50.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dict_={\"row_id\":[],\"target\":[]}\n# testX = []\n# image_ids = []\n# batch_size=256\n# for file in test_files:\n    \n#     df = pd.read_parquet(file, engine='pyarrow')\n    \n#     for idx in range(len(df)):\n        \n#         img_name = df.iloc[idx]['image_id']\n#         image_ids.append(img_name)\n#         image = df.loc[df.index[idx]].values[1:].reshape(137,236)\n#         image = np.uint8(image)\n#         testX.append(np.repeat(image[..., np.newaxis], 3, -1))\n        \n#         if len(testX) >= batch_size:\n            \n#             grayscale_batch = np.array(testX)\n# #             rgb_batch = np.repeat(grayscale_batch[..., np.newaxis], 3, -1)\n\n#             predictions = model.predict(grayscale_batch)\n\n#             for idx in range(len(image_ids)):\n#                 img_name = image_ids[idx]\n#                 for key,value in {0:\"grapheme_root\",1:\"vowel_diacritic\",2:\"consonant_diacritic\"}.items():\n#                     name  = img_name+'_'+value\n#                     val = np.argmax(predictions[key][idx])\n#                     dict_['row_id'].append(name)\n#                     dict_['target'].append(val)\n#             testX = []\n#             image_ids = []\n            \n            \n            \n            \n        \n        \n        \n#     if len(testX)>0:     \n#         grayscale_batch = np.array(testX)\n#     #     rgb_batch = np.repeat(grayscale_batch[..., np.newaxis], 3, -1)\n\n#         predictions = model.predict(grayscale_batch)\n\n#         for idx in range(len(image_ids)):\n#             img_name = image_ids[idx]\n#             for key,value in {0:\"grapheme_root\",1:\"vowel_diacritic\",2:\"consonant_diacritic\"}.items():\n#                 name  = img_name+'_'+value\n#                 val = np.argmax(predictions[key][idx])\n#                 dict_['row_id'].append(name)\n#                 dict_['target'].append(val)\n#         testX = []\n#         image_ids = []\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dict_={\"row_id\":[],\"target\":[]}\ntestX = []\nfor file in test_files:\n    df = pd.read_parquet(file, engine='pyarrow')\n    for idx in range(len(df)):\n        img_name = df.iloc[idx]['image_id']\n        for key,value in {0:\"grapheme_root\",1:\"vowel_diacritic\",2:\"consonant_diacritic\"}.items():\n            name  = img_name+'_'+value\n            val = 0\n            dict_['row_id'].append(name)\n            dict_['target'].append(val)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Read Csv From Input**"},{"metadata":{"trusted":true},"cell_type":"code","source":"# dict_={\"row_id\":[],\"target\":[]}\n# df = pd.read_csv('../input/submission/submission.csv')\n# for index in range(len(df)):\n#     dict_['row_id'].append(df.iloc[index]['row_id'])\n#     dict_['target'].append(df.iloc[index]['target'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(dict_)\nsubmission.to_csv('submission.csv',index=False)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(submission)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}