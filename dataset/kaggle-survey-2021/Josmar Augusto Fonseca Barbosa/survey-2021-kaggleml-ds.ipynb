{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n# How can I plot separate Pandas DataFrames as subplots?\n# https://stackoverflow.com/questions/22483588/how-can-i-plot-separate-pandas-dataframes-as-subplots\n# Creating multiple subplots using plt.subplots\n# https://matplotlib.org/stable/gallery/subplots_axes_and_figures/subplots_demo.html\nimport re\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib\nimport operator as op\nmatplotlib.style.use('ggplot')\n#\nregex = re.compile('[^a-zA-Z]')\n# Loading the dataset\ndf = pd.read_csv('../input/kaggle-survey-2021/kaggle_survey_2021_responses.csv', low_memory=False)\ndescriptions = df.iloc[0,:] # The first row contains the description of the columns, keep it sepearetely\ndf = df.iloc[1:,:]          # Eliminate the descriptions from the dataframe to ease of use\n#Total from dataframe\nprint('Total people:',df.shape[0])\n# drop participants under the following restrictions:\n# we excluded respondents that were flagged by our survey system as “Spam” or \"Duplicate. \n# I choose these key columns to narrowing the dataframe and considering all of these columns \n# as not merely coincidence but duplication or spam\ndf=df.drop_duplicates(subset=['Q1', 'Q2', 'Q3','Q4','Q5','Q6','Q8','Q11','Q13','Q15','Q20','Q21'],keep='last')\nprint('Total people: without SPAM and DUP ... ',df.shape[0])\n# We also dropped responses from respondents that spent less than 2 minutes completing the survey, \ndf=df[ df.iloc[:, 0].astype('int')>120]      \nprint('Total people spent more than 2 minutes:',df.shape[0])\n# as well as responses from respondents that selected fewer than 15 answer choices in total.\nheader = df.head().iloc[0:0]   \n\n# clusters of stacked bars with python (Pandas) \ndef plot_clustered_stacked(dfall, labels=None, title=\"/\",  H=\"/\", **kwargs):\n    \"\"\"Given a list of dataframes, with identical columns and index, create a clustered stacked bar plot. \nlabels is a list of the names of the dataframe, used for the legend\ntitle is a string for the title of the plot\nH is the hatch used for identification of the different dataframe\"\"\"\n\n    n_df = len(dfall)\n    n_col = len(dfall[0].columns) \n    n_ind = len(dfall[0].index)\n    axe = plt.subplot(111)\n\n    for df in dfall : # for each data frame\n        axe = df.plot(kind=\"bar\",\n                      linewidth=0,\n                      stacked=True,\n                      ax=axe,\n                      legend=False,\n                      grid=False,\n                      **kwargs)  # make bar plots\n\n    h,l = axe.get_legend_handles_labels() # get the handles we want to modify\n    for i in range(0, n_df * n_col, n_col): # len(h) = n_col * n_df\n        for j, pa in enumerate(h[i:i+n_col]):\n            for rect in pa.patches: # for each index\n                rect.set_x(rect.get_x() + 1 / float(n_df + 1) * i / float(n_col))\n                rect.set_hatch(H * int(i / n_col)) #edited part     \n                rect.set_width(1 / float(n_df + 1))\n\n    axe.set_xticks((np.arange(0, 2 * n_ind, 2) + 1 / float(n_df + 1)) / 2.)\n    axe.set_xticklabels(df.index, rotation = 75)\n    axe.set_title(title)\n\n    # Add invisible data to add another legend\n    n=[]        \n    for i in range(n_df):\n        n.append(axe.bar(0, 0, color=\"lightgray\", hatch=H * i))\n\n    l1 = axe.legend(h[:n_col], l[:n_col], loc=[1.01, 0.5])\n    if labels is not None:\n        l2 = plt.legend(n, labels, loc=[1.01, 0.1]) \n    axe.add_artist(l1)\n    return axe\n#\ndef _clustered_stacked_by_country_gender(country, gender,title=\"/\"):\n    Ages =[]\n    Genders=[]\n    Countries=[]\n    Formal_Grade=[]\n    Current_Rule_Title=[]\n    How_Many_YeasCode=[]\n    #\n    What_Programming_Python=[]\n    What_Programming_R=[]\n    What_Programming_SQL=[]\n    What_Programming_C=[]\n    What_Programming_CPP=[]\n    What_Programming_Java=[]\n    What_Programming_JS=[]\n    What_Programming_Julia=[]\n    What_Programming_Swift=[]\n    What_Programming_Bash=[]\n    What_Programming_MATLAB=[]\n    What_Programming_None=[]\n    What_Programming_Other=[]\n    #\n    Programming_Lang_Recomend=[]\n    # Q9_Part_1 - Q9_Part_12 - Q9_OTHER\n    IDE_Jupyter=[]\n    IDE_RStudio=[]\n    IDE_VidualStudio=[]\n    IDE_VSCode=[]\n    IDE_PyCharm=[]\n    IDE_Spyder=[]\n    IDE_Npp=[]\n    IDE_SublimeText=[]\n    IDE_Vim_Emacs=[]\n    IDE_MATLAB=[]\n    IDE_None=[]\n    IDE_Other=[]    \n    # Q10_Part_1 - Q10_Part_13 - Q10_OTHER\n    Notebook_Kaggle=[]\n    Notebook_Colab=[]\n    Notebook_Azure=[]\n    Notebook_Paperspace=[]\n    Notebook_Binder=[]\n    Notebook_CodeOcean=[]\n    Notebook_IBM_WhatsonStudio=[]\n    Notebook_SageMakerAMS=[]\n    Notebook_EMR_AWS=[]\n    Notebook_GCAI_Google=[]\n    Notebook_GCD_Google=[]\n    Notebook_Databricks=[]\n    Notebook_None=[]\n    Notebook_OTHER=[]\n    # Q10_Part_1 - Q10_Part_13 - Q10_OTHER\n    Type_of_Comp_Platfrm=[]\n    # Q12_Part_1 - Q12_Part_3 - Q12_OTHER    \n    Type_Special_Hrdwr_GPUs=[]\n    Type_Special_Hrdwr_TPUs=[]\n    Type_Special_Hrdwr_None=[]\n    Type_Special_Hrdwr_OTHER=[]\n    #\n    #\n    TPU_How_Many_Times=[]\n    #What_Data_Visualztion_Libs=[]\n    #\n    Countries.append(country)\n    # Iterate over each row \n    # Hierarchy -> Country - Formal Grade - Age - Gender\n    # this way of organization will bring more similarity \n    # for grouping data\n    lstAgesRange = list(set(df['Q1'] ))\n    lstFormalGrade = list(set(df['Q4'] ))\n    \n    countAgeRanges = len(lstAgesRange)\n    countFormalGrade = len(lstFormalGrade)\n    #Filtered by gender and country\n    print('Ages range',lstAgesRange)\n    dfaux = df.loc[df['Q2'] == gender]\n    dfaux2 = dfaux.loc[dfaux['Q3'] == country]\n    for index, rows in dfaux2.iterrows(): \n        # Create list for the current row \n        #print(index,') - Age: ',rows.Q1,' Gender: ',rows.Q2,' Country: ',rows.Q3,' Formal grade: ',rows.Q4,' Job Title: ',rows.Q5,' Years of expert: ',rows.Q6,' Coding lang: ',rows.Q7_OTHER)\n        Ages.append(rows.Q1)\n        Genders.append(rows.Q2)\n        Formal_Grade.append(rows.Q4)\n        Current_Rule_Title.append(rows.Q5)\n        How_Many_YeasCode.append(rows.Q6)\n        # Q7_Part_1 - Q7_Part_12 - Q7_OTHER\n        What_Programming_Python.append(rows.Q7_Part_1)\n        What_Programming_R.append(rows.Q7_Part_2)\n        What_Programming_SQL.append(rows.Q7_Part_3)\n        What_Programming_C.append(rows.Q7_Part_4)\n        What_Programming_CPP.append(rows.Q7_Part_5)\n        What_Programming_Java.append(rows.Q7_Part_6)\n        What_Programming_JS.append(rows.Q7_Part_7)\n        What_Programming_Julia.append(rows.Q7_Part_8)\n        What_Programming_Swift.append(rows.Q7_Part_9)\n        What_Programming_Bash.append(rows.Q7_Part_10)\n        What_Programming_MATLAB.append(rows.Q7_Part_11)\n        What_Programming_None.append(rows.Q7_Part_12)\n        What_Programming_Other.append(rows.Q7_OTHER)\n        # Q8 - programming language recomendation\n        Programming_Lang_Recomend.append(rows.Q8)\n        # Q9_Part_1 - Q9_Part_11 - Q9_OTHER\n        IDE_Jupyter.append(rows.Q9_Part_1)\n        IDE_RStudio.append(rows.Q9_Part_2)\n        IDE_VidualStudio.append(rows.Q9_Part_3)\n        IDE_VSCode.append(rows.Q9_Part_4)\n        IDE_PyCharm.append(rows.Q9_Part_5)\n        IDE_Spyder.append(rows.Q9_Part_6)\n        IDE_Npp.append(rows.Q9_Part_7)\n        IDE_SublimeText.append(rows.Q9_Part_8)\n        IDE_Vim_Emacs.append(rows.Q9_Part_9)\n        IDE_MATLAB.append(rows.Q9_Part_10)\n        IDE_None.append(rows.Q9_Part_11)\n        IDE_Other.append(rows.Q9_OTHER)         \n        # Q10_Part_1 - Q10_Part_13 - Q10_OTHER\n        Notebook_Kaggle.append(rows.Q10_Part_1)\n        Notebook_Colab.append(rows.Q10_Part_2)\n        Notebook_Azure.append(rows.Q10_Part_3)\n        Notebook_Paperspace.append(rows.Q10_Part_4)\n        Notebook_Binder.append(rows.Q10_Part_5)\n        Notebook_CodeOcean.append(rows.Q10_Part_6)\n        Notebook_IBM_WhatsonStudio.append(rows.Q10_Part_7)\n        Notebook_SageMakerAMS.append(rows.Q10_Part_8)\n        Notebook_EMR_AWS.append(rows.Q10_Part_9)\n        Notebook_GCAI_Google.append(rows.Q10_Part_10)\n        Notebook_GCD_Google.append(rows.Q10_Part_11)\n        Notebook_Databricks.append(rows.Q10_Part_12)\n        Notebook_None.append(rows.Q10_Part_13)\n        Notebook_OTHER.append(rows.Q10_OTHER)\n        #\n        Type_of_Comp_Platfrm.append(rows.Q11)\n        # Q12_Part_1 - Q12_Part_3 - Q12_OTHER\n        Type_Special_Hrdwr_GPUs.append(rows.Q12_Part_1)\n        Type_Special_Hrdwr_TPUs.append(rows.Q12_Part_2)\n        Type_Special_Hrdwr_None.append(rows.Q12_Part_3)\n        Type_Special_Hrdwr_OTHER.append(rows.Q12_OTHER)                            \n        #\n        TPU_How_Many_Times.append(rows.Q13)\n        #What_Data_Visualztion_Libs.append(rows.Q14)\n    #   \n    AgesOccurs=[]\n    #print(Genders)\n    #print(Countries)\n    Formal_GradeOccurs=[]\n    #\n    lstAgesRange.sort()\n    #For item in Ages\n    for item in lstAgesRange:\n        AgesOccurs.append(op.countOf(Ages,item))\n    #\n    AgesOccurs.sort()\n    #For item in Grades\n    for item in lstFormalGrade:\n        Formal_GradeOccurs.append(op.countOf(Formal_Grade,item))\n    #\n    #_lstFormalGrade = [regex.sub('', FormalGrade) for FormalGrade in lstFormalGrade]\n    \n    _lstFormalGrade = ['Master Degree', 'No Formal', 'Preffer Not Answer', 'Prof Doctorate', 'Some College', 'Doctoral Degree', 'Bachelors Degree']\n    ##  \n    #if (len(lstAgesRange) > len(_lstFormalGrade)):\n    #    lower = len(_lstFormalGrade)-1\n    #    upper = len(lstAgesRange)-1\n    #    while lower<upper:\n    #        _lstFormalGrade.append('')\n    #        Formal_GradeOccurs.append('0')\n    #        lower+=1\n    #        \n    #elif (len(_lstFormalGrade) >len(lstAgesRange)):\n    #    lower = len(lstAgesRange)-1\n    #    upper = len(_lstFormalGrade)-1\n    #    while lower<upper:\n    #        lstAgesRange.append('')\n    #        AgesOccurs.append(0)\n    #        lower+=1\n    ##\n    # don't use the series but it's metrics\n\n    print('Ages ranges: ',len(lstAgesRange),' ',lstAgesRange)\n    print('Ages Occurences: ',len(AgesOccurs),' ',AgesOccurs)\n    print('Education ranges: ',len(_lstFormalGrade),' ',_lstFormalGrade)\n    print('Education Occurences: ',len(Formal_GradeOccurs),' ',Formal_GradeOccurs)\n    \n    print('Maximum elements: ',max(len(lstAgesRange), len(_lstFormalGrade)),' - ', (' Ages ' if len(lstAgesRange) == max(len(lstAgesRange), len(_lstFormalGrade)) else ' Formal education'))\n    # create fake dataframes\n    df1 = pd.DataFrame(np.random.rand(len(lstAgesRange), len(AgesOccurs)),\n                       AgesOccurs,\n                       lstAgesRange)\n    #\n    df2 = pd.DataFrame(np.random.rand(len(_lstFormalGrade), len(Formal_GradeOccurs)),\n                       Formal_GradeOccurs,\n                       _lstFormalGrade)\n    #\n    df3 = pd.DataFrame(np.random.rand(len(_lstFormalGrade), len(lstAgesRange)),\n                       _lstFormalGrade,\n                       lstAgesRange)\n\n    # Then, just call :\n    print('Plotting for: ',country,' ',gender)\n    #plot_clustered_stacked([df1, df2],[\"Ages\", \"Formal Grade\"])\n    #plot_clustered_stacked([df1],[\"Ages\"])\n    plot_clustered_stacked([df3],[\"Age vs Formal Grade\"],title)\n    #\n #\nprint('1')\n_clustered_stacked_by_country_gender('India', 'Woman',\"India women statistics: Age & Formal Education\")\nprint('2')\n_clustered_stacked_by_country_gender('India', 'Man',\"India men statistics: Age & Formal Education\")\nprint('3')\n_clustered_stacked_by_country_gender('Brazil', 'Woman',\"Brazil women statistics: Age & Formal Education\")\nprint('4')\n_clustered_stacked_by_country_gender('Brazil', 'Man',\"Brazil men statistics: Age & Formal Education\")\n\n# People participated to the survey\nnumber_of_people = df.shape[0]\nnumber_of_questions_answered = df.shape[1]\nprint('Number of people participated to the survey:', df.shape[0])\nprint('Number of questions answered:', df.shape[1])\n\n# Turkish people participated to the survey\nmy_country = 'Brazil'\nGCP_familiar = ' Google Cloud Platform (GCP) '\nAZURE_Familiar = ' Microsoft Azure '\nmy_folks = 'Brazilian'\ndf_Brazil = df[df.Q3 == my_country]\ndf_GCloud_Familiar = df.loc[df['Q28'] == GCP_familiar]\ndf_AZURE_Familiar = df.loc[df['Q28'] == AZURE_Familiar]\ndf_NotCloud_Familiar = df.loc[(df['Q28'].empty) or (pd.isna(df['Q28']))]\n\n\nnumber_of_br_people = df_Brazil.shape[0]\nnumber_of_cloud_familiar_people = df_GCloud_Familiar.shape[0]\nnumber_of_azure_familiar_people = df_AZURE_Familiar.shape[0]\nnumber_of_cloud_non_familiar_people = df_NotCloud_Familiar.shape[0]\nprint(f'Number of {my_folks} people participated to the survey:', number_of_br_people)\nprint(f'Number of people participated to the survey who are familiar with Google Cloud Platform:', number_of_cloud_familiar_people)\nprint(f'Number of people participated to the survey who are familiar with AZURE Cloud Platform:', number_of_azure_familiar_people)\nprint(f'Number of people participated to the survey who are not familiar with any Cloud Platform:', number_of_cloud_non_familiar_people)\n\nquestion = descriptions.iloc[3]    # Question\ncountry = df.Q3\nx = country.value_counts().values\ny = country.value_counts().index\n\n# Only explode the slice of my country.\nexplode = (y == my_country) * 0.15\n\n# Only show labels above 1 percent, to avoid overlapping\npercent = 100.*x/x.sum()\nlabels = ['{0} - {1:1.2f}%'.format(i,j) if j > 1.0 else '' for i, j in zip(y, percent)]\n\nplt.subplots(figsize=[24,14])\npatches, texts = plt.pie(x, labels=labels, explode=explode, startangle=90, labeldistance=1.05, textprops={'fontsize': 14})\n\n# More labels can be shown in the legend without any overlapping\nlegend_labels = ['{0} - {1:1.2f}%'.format(i,j) for i, j in zip(y, percent) if j > 0.5]\nplt.legend(patches, legend_labels, loc=\"upper left\")\n\n# Set aspect ratio to be equal so that pie is drawn as a circle.\nplt.axis('equal')\nplt.tight_layout()\n\npercent_of_my_country = 100.*x[y.get_loc(my_country)]/x.sum()\nplt.title('{0}\\n{1:1.2f}% of Kagglers are from {2}'.format(question, percent_of_my_country, my_country), fontsize=24);\nplt.show()\n# Countries which are not matching with geopandas map\ncountries = df[df.columns[3]].copy()\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\ncountries_not_matching = []\nfor name in y:\n    if sum(world['name'] == name) == 0:\n        countries_not_matching.insert(len(countries_not_matching), name)\nprint(countries_not_matching)\n# Replace and remove countries\ncountries.replace({'United Kingdom of Great Britain and Northern Ireland':'United Kingdom',\n                   'Iran, Islamic Republic of...':'Iran',\n                   'Czech Republic':'Czechia',\n                   'Viet Nam':'Vietnam'}, inplace=True)\nx = countries.value_counts().values\ny = countries.value_counts().index\n\ncountries_not_matching = ['Other', 'Singapore', 'Hong Kong (S.A.R.)', 'I do not wish to disclose my location']\nfor country in countries_not_matching:\n    index = y.get_loc(country)\n    y = y.delete(index)\n    x = np.delete(x, index)\n# Reading the geopandas data \nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\n# Next we need to create a dataframe with lis_countries and lis_pop\ncolumn = 'kaggle_population'\ncountry_data = pd.DataFrame(y, columns=['Country'])\ncountry_data[column] = x\n\n# Next, we are going to visualize this...\nworld = world.set_index('name').join(country_data.set_index('Country')).reset_index()\nfig, ax = plt.subplots(figsize=(24,16))\n\nworld.plot(column=column, ax=ax, legend=True, legend_kwds={'label': \"Kaggle population by country\", 'orientation': \"horizontal\", 'shrink': 0.3})\nax.set_axis_off();\n# AGE\nmy_age = 53\n\nquestion = descriptions.iloc[1]    # Question\nage = df.Q1\nx = age.value_counts().values\ny = age.value_counts().index\n\n# Only explode the slice of my age\nages = [age.replace('+', '').split('-') for age in y]\nages[-1] = [ages[-1][0], 'inf'] # 70+ age doesn't have a max value\nexplode = [0.1 if float(age[0]) <= my_age and float(age[1]) >= my_age else 0 for age in ages]\n\n# Only show labels above 1 percent, to avoid overlapping\npercent = 100.*x/x.sum()\nlabels = ['{0} - {1:1.2f} %'.format(i,j) if j > 1.0 else '' for i, j in zip(y, percent)]\n\nplt.subplots(figsize=[24,14])\npatches, texts = plt.pie(x, labels=labels, explode=explode, labeldistance=1.03, textprops={'fontsize': 14})\n\n# Add a legend\nlegend_labels = ['{0} - {1:1.2f} %'.format(i,j) for i, j in zip(y, percent) if j > 0.5]\nplt.legend(patches, legend_labels, loc=\"upper left\", prop={'size': 16})\n\n# Set aspect ratio to be equal so that pie is drawn as a circle.\nplt.axis('equal')\nplt.tight_layout()\n\nmy_age_range = [float(age[0]) <= my_age and float(age[1]) >= my_age for age in ages].index(True)\npercent_of_my_age = 100.*x[my_age_range]/x.sum()\nplt.title('{0}\\n{1:1.2f} % of Kagglers are in your age.'.format(question, percent_of_my_age), fontsize=24);\nplt.show()\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-28T18:43:14.212305Z","iopub.execute_input":"2021-11-28T18:43:14.213017Z","iopub.status.idle":"2021-11-28T18:43:24.008886Z","shell.execute_reply.started":"2021-11-28T18:43:14.212865Z","shell.execute_reply":"2021-11-28T18:43:24.007895Z"},"trusted":true},"execution_count":null,"outputs":[]}]}