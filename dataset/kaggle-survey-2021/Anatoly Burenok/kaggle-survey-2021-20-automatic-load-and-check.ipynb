{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 1. Importing Libraries & Datasets","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-07T16:08:47.458671Z","iopub.execute_input":"2021-11-07T16:08:47.459286Z","iopub.status.idle":"2021-11-07T16:08:47.467449Z","shell.execute_reply.started":"2021-11-07T16:08:47.459236Z","shell.execute_reply":"2021-11-07T16:08:47.466209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_data(df):\n    replace_values = {}\n    replace_values['Q2'] = {'Male': 'Man', 'Female': 'Woman'}\n\n    replace_values['Q4'] = {'Professional doctorate': 'Professional degree',\n                            np.nan: 'I prefer not to answer'}\n\n    replace_values['Q5'] = {'Program/Project Manager': 'Product/Project Manager',\n                                    'Product Manager': 'Product/Project Manager'}\n\n    replace_values['Q8'] = {'Julia': 'Other', 'Bash': 'Other', 'Swift': 'Other',\n                            'TypeScript': 'Other'}\n    \n    replace_values['Q15'] = {'< 1 years': 'Under 1 year',\n                             '10-15 years': '10-20 years',\n                             '20+ years': '20 or more years',\n                             np.nan: 'I do not use machine learning methods'}\n\n    replace_values['Q21'] = {'> 10,000 employees': '10,000 or more employees'}\n    \n    for column_name, replace_dict in replace_values.items():\n        if column_name in df.columns:\n            df[column_name] = df[column_name].replace(replace_dict)\n        \n    return df\n\ndef get_data(data_list, is_clean_data=True):\n    downloaded_data = [(load_data[0], pd.read_csv(load_data[1], low_memory=False))\n                       for load_data in data_list]\n\n    questions_list = [set(check_data[1].loc[0, :].values)\n                      for check_data in downloaded_data]\n    questions_intersection = questions_list[0].intersection(*questions_list[1:])\n    \n    columns_description = dict()\n    columns_intersection = {name_data: []\n                            for name_data, _ in downloaded_data}\n\n    base_name, base_data = downloaded_data[0]\n    for column_name in base_data.columns:\n        question = base_data.loc[0, column_name]\n        if question in questions_intersection:\n            columns_description[column_name] = question\n\n            for name_data, current_data in downloaded_data:\n                for column in current_data.columns:\n                    if current_data.loc[0, column] == question:\n                        columns_intersection[name_data].append(column)\n\n    concat_data = []\n    concat_keys = []\n    for data_name, df in downloaded_data:\n        columns_list = columns_intersection[data_name]\n        data_values = pd.DataFrame(df.loc[1:, columns_list].values)\n        concat_data.append(data_values)\n        concat_keys.append(data_name)\n\n    data = pd.concat(concat_data, keys=concat_keys)\n    data.columns = columns_intersection[base_name]\n    data = data.reset_index(level=0).reset_index(drop=True) \\\n                .rename(columns={'level_0': 'Year'})\n       \n    columns_description['Year'] = \"Year\"\n    columns_description = {key: value.replace('- Selected Choice', '').strip()\n                             for key, value in columns_description.items()}\n\n    data = data.apply(lambda x: x.str.strip())\n    \n    if is_clean_data == True:\n        data = clean_data(data)\n    \n    return columns_description, data\n\n\ndef get_columns_data(df):\n    multiple_columns = df.filter(like='_').columns.tolist()\n\n    multiple_groups = []\n    for x in multiple_columns:\n        x = x.split('_')[0]\n        if x not in multiple_groups:\n            multiple_groups.append(x)\n\n    single_columns = [col for col in df.columns\n                      if col not in multiple_columns]\n    \n    return single_columns, multiple_groups, multiple_columns","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-07T16:08:47.469676Z","iopub.execute_input":"2021-11-07T16:08:47.469981Z","iopub.status.idle":"2021-11-07T16:08:47.490102Z","shell.execute_reply.started":"2021-11-07T16:08:47.469944Z","shell.execute_reply":"2021-11-07T16:08:47.489404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_list = [(\"2021\", \"/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv\"),\n             (\"2020\", \"/kaggle/input/kaggle-survey-2020/kaggle_survey_2020_responses.csv\"),\n             (\"2019\", \"/kaggle/input/kaggle-survey-2019/multiple_choice_responses.csv\")]\n\ndata_description, data = get_data(data_list)\nprint(data.shape)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:08:47.491509Z","iopub.execute_input":"2021-11-07T16:08:47.492049Z","iopub.status.idle":"2021-11-07T16:08:54.602668Z","shell.execute_reply.started":"2021-11-07T16:08:47.492005Z","shell.execute_reply":"2021-11-07T16:08:54.601911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> I take a list of data with names (by year), load the first row from each dataset, look for common questions (column names may not match) and, based on this list of questions, form a list of columns for each dataset.\n> \n> Then I load the required columns from each dataset into one dataset.","metadata":{}},{"cell_type":"code","source":"data.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:08:54.604488Z","iopub.execute_input":"2021-11-07T16:08:54.604947Z","iopub.status.idle":"2021-11-07T16:08:54.631193Z","shell.execute_reply.started":"2021-11-07T16:08:54.604909Z","shell.execute_reply":"2021-11-07T16:08:54.630308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data['Year'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:08:54.632334Z","iopub.execute_input":"2021-11-07T16:08:54.632585Z","iopub.status.idle":"2021-11-07T16:08:54.64914Z","shell.execute_reply.started":"2021-11-07T16:08:54.632534Z","shell.execute_reply":"2021-11-07T16:08:54.648358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"single_cols, multiple_groups, multiple_cols = get_columns_data(data)\n\nprint(\"Single columns:\", len(single_cols))\nprint(\"Multiple groups:\", len(multiple_groups))\nprint(\"Multiple columns:\", len(multiple_cols))","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:08:54.650396Z","iopub.execute_input":"2021-11-07T16:08:54.650656Z","iopub.status.idle":"2021-11-07T16:08:54.748584Z","shell.execute_reply.started":"2021-11-07T16:08:54.65062Z","shell.execute_reply":"2021-11-07T16:08:54.7478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> There are single columns and group columns in the dataset, I form three lists - with single columns, group names and group columns.\n> \n> This is necessary to automatically check each column type in the loop.","metadata":{}},{"cell_type":"markdown","source":"# 2. Automatic check single columns","metadata":{}},{"cell_type":"code","source":"def make_table_by(column_name, groupby_column=None):\n    cleaned_data = data[column_name]\n    cleaned_data = cleaned_data.fillna('--- None ---')\n\n    result = pd.DataFrame()\n\n    answers_counted = cleaned_data.value_counts(dropna=False)\n    \n    result['ALL %'] = (answers_counted / answers_counted.sum()) \\\n                                    .mul(100).round(1).map(\"{} %\".format)\n    result['Count'] = answers_counted\n\n    if groupby_column and groupby_column in data.columns:\n        result[' | '] = \" | \"\n        for g_name, g_value in data.groupby(groupby_column):\n            g_value_stats = g_value[column_name].fillna('--- None ---').value_counts()\n            g_value_stats.name = g_name\n            \n            result = result.join(g_value_stats)\n            result[g_name] = result[g_name].fillna(0).astype(int)\n\n    max_len = 30\n    result.index = [index_name[:max_len] + \" [...]\" if len(index_name) > max_len\n                    else index_name \n                    for index_name in result.index.tolist()]\n    result.index.name = 'Answers:'\n    \n    return result\n    \n\ndef make_plot_by_age(column_name, age='Q1', size=(12,6), perc_other=None, is_notna=True, is_norm=True):\n    plot_data = data.copy()\n\n    if is_notna == True:\n        plot_data = plot_data.fillna('--- None ---')\n    else:\n        plot_data = data\n    \n    if is_norm == True:\n        multiple = 'fill'\n    else:\n        multiple = 'layer'\n\n    # replacing values less than X percent with '--- Other ---'\n    if perc_other:\n        top_values = (plot_data[column_name].value_counts() /\n                      plot_data[column_name].count()\n                     ).mul(100)\n        more_than = (top_values < perc_other).values\n        replace_to = top_values[more_than].index.tolist()\n        plot_data[column_name] = plot_data[column_name].replace(replace_to, '--- Other ---')\n    \n    plt.figure(figsize=size)\n    sns.histplot(x=age, hue=column_name, data=plot_data.sort_values(by=age),\n                 multiple=multiple, shrink=.75)\n    plt.title(\"Distribution by Age\")\n    plt.xlabel(\"\")\n    plt.show()\n\n\ndef make_plot_by_year(column_name, size=(12,6), perc_other=None, is_notna=True, is_norm=True):\n    column_year = \"Year\"\n    plot_data = data.copy()\n\n    if is_notna == True:\n        plot_data = plot_data.fillna('--- None ---')\n    else:\n        plot_data = data\n    \n    if is_norm == True:\n        multiple = 'fill'\n    else:\n        multiple = 'layer'\n\n    # replacing values less than X percent with '--- Other ---'\n    if perc_other:\n        top_values = (plot_data[column_name].value_counts() /\n                      plot_data[column_name].count()\n                     ).mul(100)\n        more_than = (top_values < perc_other).values\n        replace_to = top_values[more_than].index.tolist()\n        plot_data[column_name] = plot_data[column_name].replace(replace_to, '--- Other ---')\n    \n    plt.figure(figsize=size)\n    sns.histplot(y=column_year, hue=column_name, data=plot_data.sort_values(by=column_year),\n                 multiple=multiple, shrink=.75)\n    plt.title(\"Distribution by Year\")\n    plt.ylabel(\"\")\n    plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-07T16:08:54.74986Z","iopub.execute_input":"2021-11-07T16:08:54.750127Z","iopub.status.idle":"2021-11-07T16:08:54.78342Z","shell.execute_reply.started":"2021-11-07T16:08:54.7501Z","shell.execute_reply":"2021-11-07T16:08:54.782562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.1 Distribution by Age","metadata":{}},{"cell_type":"code","source":"for col_name in single_cols[2:]:\n    result = make_table_by(col_name, \"Year\")\n    print()\n    print(\">>> ({}) {}\\n\".format(col_name, data_description.get(col_name)))\n    print(result)\n    print()\n    col_age = \"Q1\"\n    if col_name != col_age:\n        make_plot_by_age(col_name, age=col_age, size=(12,6), perc_other=5)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:08:54.784829Z","iopub.execute_input":"2021-11-07T16:08:54.785142Z","iopub.status.idle":"2021-11-07T16:09:11.203427Z","shell.execute_reply.started":"2021-11-07T16:08:54.785111Z","shell.execute_reply":"2021-11-07T16:09:11.202779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2.2 Distribution by Year","metadata":{}},{"cell_type":"code","source":"for col_name in single_cols[2:]:\n    result = make_table_by(col_name, \"Year\")\n    print()\n    print(\">>> ({}) {}\\n\".format(col_name, data_description.get(col_name)))\n    print(result)\n    print()\n    make_plot_by_year(col_name, is_norm=True, perc_other=2)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:09:11.204671Z","iopub.execute_input":"2021-11-07T16:09:11.205052Z","iopub.status.idle":"2021-11-07T16:09:27.586665Z","shell.execute_reply.started":"2021-11-07T16:09:11.205021Z","shell.execute_reply":"2021-11-07T16:09:27.585564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Automatic check multiple columns","metadata":{}},{"cell_type":"code","source":"def make_multiple_table_by(group_name, is_years=False, is_sort=False):\n    group_data = data.filter(like=group_name)\n\n    result = pd.DataFrame(group_data.describe().T)\n    result = result.reset_index()\n    result = result.fillna('--- None ---')\n    result = result.set_index('top')\n    result = result.rename(columns={\"index\": \"code\"})\n    result = result.drop(['freq', 'unique'], axis=1)\n    \n    result[' % '] = (result['count'] / result['count'].sum()) \\\n                            .mul(100).round(2).map(\" {} %\".format)\n    \n    if is_years == True:\n        result[' | '] = \" | \"\n        years_column = \"Year\"\n        \n        for select_year in sorted(data[years_column].unique()):\n            mask_select_year = (data[years_column] == select_year)\n            result[select_year] = data.loc[mask_select_year].filter(like=group_name) \\\n                                                    .describe().T \\\n                                                    .set_index('top')['count']\n    max_len = 15\n    result.index = result.index.str.strip()\n    result.index = [index_name[:max_len] + \" [...]\" if len(index_name) > max_len\n                    else index_name \n                    for index_name in result.index.tolist()]\n    result.index.name = 'Answers:'    \n\n    if is_sort == True:\n        result = result.sort_values(by='count', ascending=False)\n        \n    return result\n\n\ndef make_plot_multiple(group_name, column_name='Year', size=(12,6), perc_other=None, is_norm=True):\n    column_by = column_name\n    group_data = data.filter(like=group_name)\n    plot_data = group_data.join(data[column_by]).melt(id_vars=[column_by],\n                                                        value_vars=group_data.columns,\n                                                        ignore_index=False) \\\n                                                            .drop('variable', axis=1) \\\n                                                            .dropna()\n    \n    if is_norm == True:\n        multiple = 'fill'\n    else:\n        multiple = 'layer'\n\n    value_name = 'value'\n    # replacing values less than X percent with '--- Other ---'\n    if perc_other:\n        top_values = (plot_data[value_name].value_counts() /\n                      plot_data[value_name].count()\n                     ).mul(100)\n        more_than = (top_values < perc_other).values\n        replace_to = top_values[more_than].index.tolist()\n        plot_data[value_name] = plot_data[value_name].replace(replace_to, '--- Other ---')\n    \n    plot_data = plot_data.reset_index(drop=True)  # to fix Kaggle's trouble\n    \n    plt.figure(figsize=size)\n    sns.histplot(y=column_by, hue=value_name, data=plot_data.sort_values(by=column_by),\n                 multiple=multiple, shrink=.75)\n    plt.title(\"Distribution group '{}' by column '{}'\".format(group_name, column_name))\n    plt.ylabel(\"\")\n    plt.show()\n    \n    \ndef show_multiple_result(column_name, size=(12,6), perc_other=None, is_norm=True):\n    for check_group in multiple_groups:\n        if check_group in list_of_incomplete_groups:\n            continue\n\n        result = make_multiple_table_by(check_group, is_years=True, is_sort=True)\n        first_question = result.iloc[0, 0]\n        group_title = data_description.get(first_question)\n\n        group_select = '(Select all that apply)'\n        group_title = group_title.split(group_select)[0]\n\n        print()\n        print(\">>> Group question: ({}) {}- {}\\n\".format(check_group, group_title, group_select))\n        print(result)\n        print()\n        make_plot_multiple(check_group, column_name, size, perc_other, is_norm)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-07T16:17:37.938486Z","iopub.execute_input":"2021-11-07T16:17:37.939025Z","iopub.status.idle":"2021-11-07T16:17:37.955128Z","shell.execute_reply.started":"2021-11-07T16:17:37.938969Z","shell.execute_reply":"2021-11-07T16:17:37.954033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for datasets: 2021 + 2020 + 2019\nlist_of_incomplete_groups = ['Q9', 'Q10', 'Q12', 'Q19', 'Q40', 'Q42']","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:09:27.607874Z","iopub.execute_input":"2021-11-07T16:09:27.608085Z","iopub.status.idle":"2021-11-07T16:09:27.62098Z","shell.execute_reply.started":"2021-11-07T16:09:27.608048Z","shell.execute_reply":"2021-11-07T16:09:27.620211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.1 Distribution by Year","metadata":{}},{"cell_type":"code","source":"show_multiple_result('Year', perc_other=6)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:18:23.968462Z","iopub.execute_input":"2021-11-07T16:18:23.968795Z","iopub.status.idle":"2021-11-07T16:18:30.655339Z","shell.execute_reply.started":"2021-11-07T16:18:23.968758Z","shell.execute_reply":"2021-11-07T16:18:30.654297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2 Distribution by Age","metadata":{}},{"cell_type":"code","source":"show_multiple_result('Q1', size=(12,8), perc_other=6)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:19:37.189808Z","iopub.execute_input":"2021-11-07T16:19:37.190107Z","iopub.status.idle":"2021-11-07T16:19:45.357742Z","shell.execute_reply.started":"2021-11-07T16:19:37.190073Z","shell.execute_reply":"2021-11-07T16:19:45.356558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.3 Distribution by Gender","metadata":{}},{"cell_type":"code","source":"show_multiple_result('Q2', perc_other=6)","metadata":{"execution":{"iopub.status.busy":"2021-11-07T16:20:33.705018Z","iopub.execute_input":"2021-11-07T16:20:33.705297Z","iopub.status.idle":"2021-11-07T16:20:40.609288Z","shell.execute_reply.started":"2021-11-07T16:20:33.705265Z","shell.execute_reply":"2021-11-07T16:20:40.608363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}