{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"üîë **Key words of the project**\n\n#Python #EDA\n\nüéØ **Objective of this analysis**\n\nWe want to have a good understanding of the professional environment linked to datas. \nWith insights coming from people using differents languages and coming from different backgrounds. \nThe purpose of EDA is to launch the stories of the data. In this notebook, we will <mark>focus on the diversity (visualization)</mark> more than the story. I want to use this notebook as a general guide - template for my students for their next eda analysis.\n\n‚ÑπÔ∏è  **Origin of the data**\n\nKaggle competition based on the annual survey about the data professionals. [Click here](https://www.kaggle.com/c/kaggle-survey-2021/overview) to access the overview page of the competition.\n\nThe data provided are splited in 3 documents : \n- Main data = Results of the survey = kaggle_survey_2021_responses.csv: 42+ questions and 25,973 responses\n- Supplementary Data = kaggle_survey_2021_answer_choices.pdf: list of answer choices for every question\n- Supplementary Data = kaggle_survey_2021_methodology.pdf: a description of how the survey was conducted  \n  \nWe will <mark>focus on the data of 2021.</mark> We won't compare data from previous years in order to analyze their evolution.  \n\nüîó **Inspirations**  \n  \nFor any analysis, it is always inspiring to open our mind to other ideas and other ways to approach a problematic. Inspiration is the best way to improve. \nI would like to thanks [Indian AI Production](https://indianaiproduction.com/seaborn-histogram-using-seaborn-distplot/),  [datafan07](https://www.kaggle.com/datafan07/what-takes-to-be-a-data-scientist-story-of-robert), [vivek](https://www.kaggle.com/vivek468/what-s-up-kaggle-kaggle-survey-2021/notebook),  [aditidutta](https://www.kaggle.com/aditidutta/learning-about-my-fellow-kagglers), [Kenjee](https://youtu.be/r-DR9HBaipU), [amiraabdallahi](https://www.kaggle.com/amiraabdallahi/2021-survey-amira). I have upvoted their notebook, in addition to this reference, and I wrote a comment on their notebook in order to inform them that they have been an inspiration for me.\n\nüí™ **How to improve?**\n\nAnalysis can always be better. It usually depends on the time spent on the project. Here are some example of improvements that could have been done : \n\n   - Include the survey of previous years in order to compare the results and built evolutive visualization (example with [dwin183287](https://www.kaggle.com/dwin183287/kagglers-seen-by-continents) and [patelris](https://www.kaggle.com/patelris/exploring-kaggle-survey-2021)). \n   - Create API with W&B for amazing artistics visualization (example with [ruchi798](https://www.kaggle.com/ruchi798/kaggle-ml-ds-survey-analysis) or [andradaolteanu](https://www.kaggle.com/andradaolteanu/how-are-the-ladies-and-the-gents-doing)\n   - We could have changed the name of columns titles. But it was shorter to write the number of question than the question itself (example : shorter to write Q4 than \"What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\"). We could also have rename the question with shorter keyword.  \n   \n---------\n# <font color=\"#1d479b\">PLAN</font>\n\nWe don't have a specific problematic to solve. \nWe won't answer a specific problematic = we remain quit wide in our EDA. This is the reason why i decided to start with a \"question per question\" analysis. And then, a combo of variables in order to give a general overview of the conclusions we can built. \nWith this introduction, different direction can be taken, according to the problematic we decide to dig. \n\n1. [Dataset preparation](#section_1)  \n    1.1. [Details of the survey (pdf)](#section_1_1)  \n    1.2. [Settings of the work environment](#section_1_2)  \n    1.3. [Data discovery (csv), preparation & cleaning - NaN management](#section_1_3)  \n2. [Question per Question analysis](#section_2)  \n    2.1. [Q0 - Time from Start to Finish (seconds)](#section_2_1)  \n    2.2. [Q1 - What is your age (# years)?](#section_2_2)  \n    2.3. [Q2 - What is your gender?](#section_2_3)  \n    2.4. [Q3 -  In which country do you currently reside? And mix with gender](#section_2_4)  \n    2.5. [Q4 -  What is the highest level of formal education that you have attained or plan to attain within the next 2 years?](#section_2_5)  \n    2.6. [Q5 -  Select the title most similar to your current role (or most recent title if retired)? And position by gender](#section_2_6)  \n    2.7. [Q6 - For how many years have you been writing code and/or programming?](#section_2_7)  \n    2.8. [Q7 - What programming languages do you use on a regular basis?](#section_2_8)  \n    2.9. [Q8 - What programming language would you recommend an aspiring data scientist to learn first?](#section_2_9)  \n    2.10. [Q9 - Which of the following integrated development environments (IDE's) do you use on a regular basis? AND VS Hardware VS TPU](#section_2_10)  \n    2.11. [Q10 - Which of the following hosted notebook products do you use on a regular basis?](#section_2_11)  \n    2.12. [Q11 - What type of computing platform do you use most often for your data science projects?](#section_2_12)  \n    2.13. [Q12 - Which types of specialized hardware do you use on a regular basis?](#section_2_13)  \n    2.14. [Q13 - Approximately how many times have you used a TPU (tensor processing unit)?](#section_2_14)  \n    2.15. [Q14 - What data visualization libraries or tools do you use on a regular basis?](#section_2_15)  \n    2.16. [Q15 - For how many years have you used machine learning methods?](#section_2_16)  \n    2.17. [Q16 - Which of the following machine learning frameworks do you use on a regular basis?](#section_2_17)  \n    2.18. [Q17 - Which of the following ML algorithms do you use on a regular basis?](#section_2_18)  \n    2.19. [Q18 - Which categories of computer vision methods do you use on a regular basis?](#section_2_19)  \n    2.20. [Q19 - Which of the following natural language processing (NLP) methods do you use on a regular basis?](#section_2_20)  \n    2.21. [Q20 - In what industry is your current employer/contract (or your most recent employer if retired)?](#section_2_21)  \n    2.22. [Q21 - What is the size of the company where you are employed?](#section_2_22)  \n    2.23. [Q22 - Approximately how many individuals are responsible for data science workloads at your place of business?](#section_2_23)  \n    2.24. [Q23 - Does your current employer incorporate machine learning methods into their business?](#section_2_24)  \n    2.25. [Q24 - Select any activities that make up an important part of your role at work](#section_2_25)  \n    2.26. [Q25 - What is your current yearly compensation?](#section_2_26)  \n    2.27. [Q26 - Approximately how much money have you (or your team) spent on machine learning and/or cloud computing services at home (or at work) in the past 5 years?](#section_2_27)  \n    2.28. [Q27 - Which of the following cloud computing platforms do you use on a regular basis?](#section_2_28)  \n    2.29. [Q28 - Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)?](#section_2_29)  \n    2.30. [Q29 - Do you use any of the following cloud computing products on a regular basis?](#section_2_30)  \n    2.31. [Q30 -  Do you use any of the following data storage products on a regular basis?](#section_2_31)  \n    2.32. [Q31 -  Do you use any of the following managed machine learning products on a regular basis?](#section_2_32)  \n    2.33. [Q32 -  Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?](#section_2_33)  \n    2.34. [Q33 -  Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?](#section_2_34)  \n    2.35. [Q34 -  Which of the following business intelligence tools do you use on a regular basis?](#section_2_35)  \n    2.36. [Q35 -  Which of the following business intelligence tools do you use most often?](#section_2_36)  \n    2.37. [Q36 -  Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?](#section_2_37)  \n    2.38. [Q37 -  Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?](#section_2_38)  \n    2.39. [Q38 - Do you use any tools to help manage machine learning experiments?](#section_2_39)  \n    2.40. [Q39 - Where do you publicly share or deploy your data analysis or machine learning applications?](#section_2_40)  \n    2.41. [Q40 - On which platforms have you begun or completed data science courses?](#section_2_41)  \n    2.42. [Q41 - What is the primary tool that you use at work or school to analyze data?](#section_2_42)  \n    2.43. [Q42 - Who/what are your favorite media sources that report on data science topics?](#section_2_43)  \n3. [Multivariate analysis](#section_3)  \n    3.0. [Survey duration VS Age](#section_3_0)  \n    3.1. [Gender VS Age ](#section_3_1)  \n    3.2. [Gender VS Country ](#section_3_2)  \n    3.3. [Age distribution per country ](#section_3_3)  \n    3.4. [Degree / job / experience ](#section_3_4)  \n    3.5. [Gender & experience](#section_3_5)  \n    3.6. [Language used & recommended](#section_3_6)  \n    3.7. [Language used & IDE](#section_3_7)  \n    3.8. [Gender / General Exp. / ML Exp.](#section_3_8)  \n    3.9. [Visu / ML Exp. / ML framework](#section_3_9)  \n    3.10. [job VS industry](#section_3_10)  \n    3.11. [Salary VS Industry VS experience in Machine Learning](#section_3_11)  \n    3.12. [Company size VS number of data science human workforce](#section_3_12)  \n    3.13. [Companies incorporating Machine Learning and their people to workload ratio](#section_3_13)  \n    3.14. [Compare popular programming language with various demographic information](#section_3_14)  \n    3.15. [Participants who work on Machine Learning methods and their spendings on computing plateform](#section_3_15)  \n    3.16. [Participants who works on one cloud platform and their respective preferences](#section_3_16)  \n    3.17. [Big data products VS business tools usage & preference comparison](#section_3_17)  \n    3.18. [Relation between developer experience VS big data product & BI tools prefered by developers.](#section_3_18)  \n    3.19. [Platforms which are popular among participants for DS courses VS popular DS media sources](#section_3_19)  \n    3.20. [Media sources usages based on age, education and job](#section_3_20)  \n    3.21. [Correlation experience & Age](#section_3_21)  \n    3.22. [Comparison of jobs position per age](#section_3_22)  \n    3.23. [Comparison of jobs position per hardware](#section_3_23)  \n    3.24. [Comparison of coding language by position](#section_3_24)  \n    3.25. [Education VS Age](#section_3_25)  \n    3.26. [Salary VS Experience VS Country](#section_3_26)  \n    3.27. [Radar chart](#section_3_27)  \n\n\n\n------------\n## <font color=\"#337da4\" id=\"section_1\">1. Dataset preparation</font>\n### <font color=\"#2cb7b0\" id=\"section_1_1\">1.1. Details of the survey (pdf)</font>\nBelow, we have included the list of questions included in the survey.\n\n**General informations**\n- 'Q1' : What is your age (# years)?\n- 'Q2' : What is your gender?\n- 'Q3' : In which country do you currently reside?\n- 'Q4' : What is the highest level of formal education that you have attained or plan to attain within the next 2 years?\n- 'Q5' : Select the title most similar to your current role (or most recent title if retired)?\n- 'Q6' : For how many years have you been writing code and/or programming?\n\n**Technical questions**\n- 'Q7' : What programming languages do you use on a regular basis? \n- 'Q8' : What programming language would you recommend an aspiring data scientist to learn first?\n- 'Q9' : Which of the following integrated development environments (IDE's) do you use on a regular basis?\n- 'Q10' : Which of the following hosted notebook products do you use on a regular basis?\n- 'Q11' : What type of computing platform do you use most often for your data science projects?\n- 'Q12' : Which types of specialized hardware do you use on a regular basis?\n- 'Q13' : Approximately how many times have you used a TPU (tensor processing unit)?\n\n**Machine Learning questions**\n- 'Q14' : What data visualization libraries or tools do you use on a regular basis?\n- 'Q15' : For how many years have you used machine learning methods?\n- 'Q16' : Which of the following machine learning frameworks do you use on a regular basis?\n- 'Q17' : Which of the following ML algorithms do you use on a regular basis?\n- 'Q18' : Which categories of computer vision methods do you use on a regular basis?\n- 'Q19' : Which of the following natural language processing (NLP) methods do you use on a regular basis?\n\n**Employement questions**\n- 'Q20' : In what industry is your current employer/contract (or your most recent employer if retired)?\n- 'Q21' : What is the size of the company where you are employed?\n- 'Q22' : Approximately how many individuals are responsible for data science workloads at your place of business?\n- 'Q23' : Does your current employer incorporate machine learning methods into their business?\n- 'Q24' : Select any activities that make up an important part of your role at work\n- 'Q25' : What is your current yearly compensation?\n- 'Q26' : Approximately how much money have you (or your team) spent on machine learning and/or cloud computing services at home (or at work) in the past 5 years?\n\n**Personal preferences**\n- 'Q27' : Which of the following cloud computing platforms do you use on a regular basis?\n- 'Q28' : Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)?\n- 'Q29' : Do you use any of the following cloud computing products on a regular basis?\n- 'Q30' : Do you use any of the following data storage products on a regular basis?\n- 'Q31' : Do you use any of the following managed machine learning products on a regular basis?\n- 'Q32' : Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?\n- 'Q33' : Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?\n- 'Q34' : Which of the following business intelligence tools do you use on a regular basis?\n- 'Q35' : Which of the following business intelligence tools do you use most often?\n- 'Q36' : Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?\n- 'Q37' : Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?\n- 'Q38' : Do you use any tools to help manage machine learning experiments?\n- 'Q39' : Where do you publicly share or deploy your data analysis or machine learning applications?\n- 'Q40' : On which platforms have you begun or completed data science courses?\n- 'Q41' : What is the primary tool that you use at work or school to analyze data?\n- 'Q42' : Who/what are your favorite media sources that report on data science topics?\n\n\n*Question 28 (which specific product) was only asked to respondents that selected more than one\nchoice for Question 27-A (which of the following products).*\n\n*Question 29-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected\nthe relevant answer choices for Question 27-A (which of the following companies).*\n\n*Question 30-A (which specific AWS/Azure/GCP products) was only asked to respondents that selected\nthe relevant answer choices for Question 27-A (which of the following companies).*\n\n*Question 33 (which specific product) was only asked to respondents that selected more than one choice for Question 32-A (which of the following products).*\n\n*Question 35 (which specific product) was only asked to respondents that selected more than one\nchoice for Question 34-A (which of the following products).*\n\n*Question 37-A (which specific product) was only asked to respondents that answered affirmatively to\nQuestion 36-A (which of the following categories of products).*\n\n### <font color=\"#2cb7b0\" id=\"section_1_2\">1.2. Settings of the work environment</font>\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"!pip install circlify","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:39:57.709549Z","iopub.execute_input":"2022-04-04T08:39:57.710525Z","iopub.status.idle":"2022-04-04T08:40:07.996975Z","shell.execute_reply.started":"2022-04-04T08:39:57.710374Z","shell.execute_reply":"2022-04-04T08:40:07.996209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install venn","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:07.99868Z","iopub.execute_input":"2022-04-04T08:40:07.998908Z","iopub.status.idle":"2022-04-04T08:40:18.245702Z","shell.execute_reply.started":"2022-04-04T08:40:07.998883Z","shell.execute_reply":"2022-04-04T08:40:18.244726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Traditional \nimport pandas as pd\nimport numpy as np\n\n#visualization\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as mpatches\nimport matplotlib.gridspec as gridspec\nfrom matplotlib.ticker import MaxNLocator\n\nimport plotly \nimport plotly.graph_objects as go\nimport plotly.express as px               \nimport plotly.offline as pyo\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import iplot\nimport seaborn as sns\n%matplotlib inline\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport circlify\nfrom venn import venn\nimport gc\n\n#statistics\nfrom scipy.stats import norm\nfrom scipy import stats\n\n#we want to display more rows and columns than just the first lines/rows preview.\npd.set_option('display.max_rows',500)\npd.set_option('display.max_columns',500)\n\n#warnings\nimport warnings\nwarnings.filterwarnings('ignore')\nplotly.offline.init_notebook_mode(connected=True)\n\n#date & timing\nimport datetime\nimport time\nfrom datetime import datetime\n\n#to save machine efforts  \n%load_ext autoreload\n%autoreload 2\n\n# setting - visuals' homogenization \nplt.style.use('fivethirtyeight')\ncust_color = ['#000000',\n'#000066',\n'#0000CC',\n'#0033FF',\n'#0066FF',\n'#0099FF',\n'#00CCFF',\n'#00FFFF',\n'#00FFCC',\n'#00CCCC',\n'#0099CC',\n'#009999',\n'#00CC99',\n]\nplt.rcParams['figure.figsize'] = (18,14)\nplt.rcParams['figure.dpi'] = 300\nplt.rcParams[\"axes.grid\"] = True\nplt.rcParams[\"grid.color\"] = cust_color[3]\nplt.rcParams[\"grid.alpha\"] = 0.5\nplt.rcParams[\"grid.linestyle\"] = '--'\nplt.rcParams[\"font.family\"] = \"monospace\"\n\nplt.rcParams['axes.edgecolor'] = 'black'\nplt.rcParams['figure.frameon'] = True\nplt.rcParams['axes.spines.left'] = True\nplt.rcParams['axes.spines.bottom'] = True\nplt.rcParams['axes.spines.top'] = False\nplt.rcParams['axes.spines.right'] = False\nplt.rcParams['axes.linewidth'] = 1.5\n\n#informations about packages versions\nimport sys\n \nprint(\"Current version of Python is \", sys.version)\nprint('Current version of NumPy is : ' + np.version.full_version)\nprint('Current version of Pandas is : ' + pd.__version__)\nnow = datetime.now().isoformat()\nprint('Lanched on : ' + now)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:18.247756Z","iopub.execute_input":"2022-04-04T08:40:18.248095Z","iopub.status.idle":"2022-04-04T08:40:21.470376Z","shell.execute_reply.started":"2022-04-04T08:40:18.248054Z","shell.execute_reply":"2022-04-04T08:40:21.469773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import the main dataset\nprint('------------Main datasets------------')\ndf = pd.read_csv('/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')\nprint('The main dataset presenting the survey results (called df) has a shape of :', df.shape[0], \"rows and\", df.shape[1],'columns')\n\n\n#vanessa . int√©grer les supplementary dataset ? \nprint('------------Complementary datasets------------')\nprint('The supplementary dataset include a pdf with the general answers received in 2021, called \"kaggle_survey_2021_answers\"') \nprint('The supplementary dataset include a pdf with the methodology of the survey in 2021, called \"kaggle_survey_2021_methodology\"') ","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:21.471796Z","iopub.execute_input":"2022-04-04T08:40:21.472304Z","iopub.status.idle":"2022-04-04T08:40:22.825434Z","shell.execute_reply.started":"2022-04-04T08:40:21.472269Z","shell.execute_reply":"2022-04-04T08:40:22.824596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> We will focus this EDA only on the main dataset. ","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_1_1\">1.3. Data discovery (csv), preparation and cleaning  - NaN management</font>","metadata":{}},{"cell_type":"code","source":"#Let's have an overview of the 5 FIRST rows\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:22.826595Z","iopub.execute_input":"2022-04-04T08:40:22.826818Z","iopub.status.idle":"2022-04-04T08:40:23.106137Z","shell.execute_reply.started":"2022-04-04T08:40:22.82679Z","shell.execute_reply":"2022-04-04T08:40:23.105513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We can also have an overview of the 5 LAST rows\ndf.tail()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:23.10719Z","iopub.execute_input":"2022-04-04T08:40:23.107508Z","iopub.status.idle":"2022-04-04T08:40:23.353923Z","shell.execute_reply.started":"2022-04-04T08:40:23.107466Z","shell.execute_reply":"2022-04-04T08:40:23.352721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data discovery with a basic statistical analysis\ndf.describe(include=\"all\")","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:23.355512Z","iopub.execute_input":"2022-04-04T08:40:23.355893Z","iopub.status.idle":"2022-04-04T08:40:24.634968Z","shell.execute_reply.started":"2022-04-04T08:40:23.355849Z","shell.execute_reply":"2022-04-04T08:40:24.634379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• The first row is dedicated to the question. It should be removed in order to avoid any confusion between the content/answers and the question itself. ","metadata":{}},{"cell_type":"code","source":"#remove top row \ndf_fin = df.iloc[1:,:]\n#verification\ndf_fin.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:24.635863Z","iopub.execute_input":"2022-04-04T08:40:24.636211Z","iopub.status.idle":"2022-04-04T08:40:24.892417Z","shell.execute_reply.started":"2022-04-04T08:40:24.636177Z","shell.execute_reply":"2022-04-04T08:40:24.889576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#replace empty string with nan...\ndf_fin = df_fin.replace(r'^\\s*$', np.NaN, regex=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:24.893896Z","iopub.execute_input":"2022-04-04T08:40:24.894692Z","iopub.status.idle":"2022-04-04T08:40:35.107619Z","shell.execute_reply.started":"2022-04-04T08:40:24.894649Z","shell.execute_reply":"2022-04-04T08:40:35.106925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Do we have any NaN (missing values) in the dataset ? True or False = Boolean logic\nprint(df_fin.isnull().values.any())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:35.111204Z","iopub.execute_input":"2022-04-04T08:40:35.111727Z","iopub.status.idle":"2022-04-04T08:40:35.449399Z","shell.execute_reply.started":"2022-04-04T08:40:35.11168Z","shell.execute_reply":"2022-04-04T08:40:35.448075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• We have missing values => We want to know the distribution and quantity of missing values in order to set our strategy","metadata":{}},{"cell_type":"code","source":"#We define the distribution of missing values\ndf_missing = df_fin.isnull().sum().sort_values(ascending=False) / df_fin.shape[0] * 100\n\n#distribution visualisation\nplt.figure(figsize=(10,5))\nsns.displot(df_missing, bins=100, kde=False)\nplt.xlabel(\"Missing values in %\")\nplt.ylabel(\"Number of columns\") \nplt.title(\"Distribution of missing values per column (in %) \")","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:35.450569Z","iopub.execute_input":"2022-04-04T08:40:35.451366Z","iopub.status.idle":"2022-04-04T08:40:36.646222Z","shell.execute_reply.started":"2022-04-04T08:40:35.451314Z","shell.execute_reply":"2022-04-04T08:40:36.645389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Reminder, the dataset has a total of :', df_fin.shape[1],'columns')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:36.647546Z","iopub.execute_input":"2022-04-04T08:40:36.647814Z","iopub.status.idle":"2022-04-04T08:40:36.690875Z","shell.execute_reply.started":"2022-04-04T08:40:36.647782Z","shell.execute_reply":"2022-04-04T08:40:36.689544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• Around half of the data with 80(or more)% NaN. Why so many missing values ?? We can't delete all missing values (fillna) => we would lose too many informations and the dataset would not be usefull anymore. ","metadata":{}},{"cell_type":"markdown","source":"üë©üèª‚Äçüíª **reflexion:** \nWe need to define the strategy we want to follow. We have **quantitatives columns = numerical values** and **qualitative columns = categorical variables**. Should we use similar or different strategy ? For this decision, we also want to know the split of types.","metadata":{}},{"cell_type":"code","source":"df_fin.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:36.692869Z","iopub.execute_input":"2022-04-04T08:40:36.693081Z","iopub.status.idle":"2022-04-04T08:40:36.740825Z","shell.execute_reply.started":"2022-04-04T08:40:36.693055Z","shell.execute_reply":"2022-04-04T08:40:36.739896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" > üî• Object dtype","metadata":{}},{"cell_type":"markdown","source":"üë©üèª‚Äçüíª **reflexion:** Replacing the NaN with the most represented values (=mode) of each columns would be a good strategy.  \nWhat are the mode values of our dataset ?","metadata":{}},{"cell_type":"code","source":"#What is the most represented value of each columns ?\ndf_fin.mode(axis=1, numeric_only=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:36.74192Z","iopub.execute_input":"2022-04-04T08:40:36.743411Z","iopub.status.idle":"2022-04-04T08:40:47.710885Z","shell.execute_reply.started":"2022-04-04T08:40:36.743376Z","shell.execute_reply":"2022-04-04T08:40:47.710101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• **Problem** ! We see that the most represented value is very often \"NaN\". Which means that we can not use the mode-replacement technic for NaN management because we will have even more NaN values in our dataset. ","metadata":{}},{"cell_type":"markdown","source":"**Option for quantitative values**\nIf we wanted to fill every column with its own most frequent value we would have used :\n>df = df.fillna(df.mode().iloc[0])\n\n**Option for quantitative values**\nOr we also could have used this technic : \nMost of the time, you wouldn't want the same imputing strategy for all the columns. For example, you may want column mode for categorical variables and column mean or median for numeric columns.  \n\nnumeric columns  \n>df.fillna(df.select_dtypes(include='number').mean().iloc[0], inplace=True)  \n\ncategorical columns  \n>df.fillna(df.select_dtypes(include='object').mode().iloc[0], inplace=True)  \n\n\n**Option for qualitative values**  \nWe can convert the columns to a generic object type or string type. Then we can fill the NaN with a value.  \n>df['categorical_column'] = df['categorical_column'].astype(object)  \n>df['categorical_column'].fillna('Null', inplace=True)  \n\nBut it is not really \"natural\".\n\n\n**Option for mix qualitative & quantitative values**  \n\ncategory_columns=df_fin.select_dtypes(include=['object']).columns.tolist()  \ninteger_columns=df_fin.select_dtypes(include=['int64','float64']).columns.tolist()  \n\nfor column in df_fin:  \n    if df_fin[column].isnull().any():  \n        if(column in category_columns):  \n            df_fin[column]=df_fin[column].fillna(df_fin[column].mode())  \n        else:  \n            df_fin[column]=df_fin[colum].fillna(df_fin[column].mode)  ","metadata":{"execution":{"iopub.status.busy":"2022-03-19T14:51:30.387927Z","iopub.execute_input":"2022-03-19T14:51:30.388328Z","iopub.status.idle":"2022-03-19T14:51:30.45449Z","shell.execute_reply.started":"2022-03-19T14:51:30.388277Z","shell.execute_reply":"2022-03-19T14:51:30.453482Z"}}},{"cell_type":"markdown","source":"üë©üèª‚Äçüíª **decision:**  \nWe decide to avoid the above options and, instead, follow the strategy as:  \n- quantitative values : replace NaN with median values \n- qualitative values : replace NaN with the value \"NotAvailable\" ","metadata":{}},{"cell_type":"code","source":"#we replace quantitative missing values with the median values of the column = variable\n#df_fin.fillna(df_fin.median().iloc[0])\ndf_fin = df_fin.fillna(df_fin.median())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:47.711977Z","iopub.execute_input":"2022-04-04T08:40:47.712198Z","iopub.status.idle":"2022-04-04T08:40:49.456945Z","shell.execute_reply.started":"2022-04-04T08:40:47.71217Z","shell.execute_reply":"2022-04-04T08:40:49.455997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Confirmation : we have remaining missing values (the qualitative values, which, by definition, don't have \"median values\")\nprint(df_fin.isnull().values.any())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:49.457998Z","iopub.execute_input":"2022-04-04T08:40:49.458315Z","iopub.status.idle":"2022-04-04T08:40:49.792922Z","shell.execute_reply.started":"2022-04-04T08:40:49.458283Z","shell.execute_reply":"2022-04-04T08:40:49.792202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#As the remaining NAN values are only in the categorical variables, \n#we can decide to replace all remaining NaN values with 0 (=for the entire dataframe)\ndf_fin = df_fin.fillna(\"NotAvailable\")\n#other technics : https://theprogrammingexpert.com/pandas-fillna/\n\n#Confirmation : We don't have any remaining missing values = False / boolean \nprint(df_fin.isnull().values.any())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:49.793862Z","iopub.execute_input":"2022-04-04T08:40:49.794438Z","iopub.status.idle":"2022-04-04T08:40:50.816689Z","shell.execute_reply.started":"2022-04-04T08:40:49.794404Z","shell.execute_reply":"2022-04-04T08:40:50.815624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" > üî• No NA/Null values anymore in the dataset ","metadata":{}},{"cell_type":"code","source":"#check for duplicated values in the dataframe\ndf_fin.duplicated().any()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:50.817993Z","iopub.execute_input":"2022-04-04T08:40:50.818567Z","iopub.status.idle":"2022-04-04T08:40:51.557298Z","shell.execute_reply.started":"2022-04-04T08:40:50.818521Z","shell.execute_reply":"2022-04-04T08:40:51.556408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" > üî• We don't have any duplicated values","metadata":{}},{"cell_type":"markdown","source":"--------","metadata":{}},{"cell_type":"markdown","source":"üë©üèª‚Äçüíª **info to keep in mind:** \n\nThe strategy we decided to follow is to analyze question per question.  \n\n- we will built a dictionary => avoid the filters for each questions). Efficient for questions with multiple answers.  \n- key = number of the question  \n- values = dataframe with parts of the question  ","metadata":{}},{"cell_type":"code","source":"#We create the dictionary for questions\nQuestions = {}\n\n#Now we create the list of questions :\n#We use the split coming from \"_\" => underscore is our splitting criteria\nqnums = list(dict.fromkeys([i.split('_')[0] for i in  df_fin.columns]))\nqnums","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:51.558578Z","iopub.execute_input":"2022-04-04T08:40:51.55887Z","iopub.status.idle":"2022-04-04T08:40:51.602939Z","shell.execute_reply.started":"2022-04-04T08:40:51.558828Z","shell.execute_reply":"2022-04-04T08:40:51.602343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we want to consider the questions => We take all columns starting with \"Q\" (= all columns ...) (=>\"startswith\")\n#and we load them into the dictionnary \n\n#add data for each question to key value pairs in dictionary\nfor i in qnums:\n    if i in ['Q1','Q2','Q3']:     \n        Questions[i] = df_fin[i]\n    else:\n        Questions[i] = df_fin[[q for q in df_fin.columns if q.startswith(i)]]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:51.604016Z","iopub.execute_input":"2022-04-04T08:40:51.604782Z","iopub.status.idle":"2022-04-04T08:40:52.018512Z","shell.execute_reply.started":"2022-04-04T08:40:51.604738Z","shell.execute_reply":"2022-04-04T08:40:52.017774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Similar to previous steps, we will create a dictionary. \n# key = roles\n# value pairs = fataframes filtered by role\n\n\n#Reminder : \nRoles = {}\nfor i in df_fin.Q5.unique():\n    Roles[i] = df_fin[df_fin.Q5 == i]","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:52.019592Z","iopub.execute_input":"2022-04-04T08:40:52.019809Z","iopub.status.idle":"2022-04-04T08:40:52.299627Z","shell.execute_reply.started":"2022-04-04T08:40:52.019783Z","shell.execute_reply":"2022-04-04T08:40:52.298904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Let's list the different possibles values of Q5\nRoles.keys()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:52.300996Z","iopub.execute_input":"2022-04-04T08:40:52.301235Z","iopub.status.idle":"2022-04-04T08:40:52.343306Z","shell.execute_reply.started":"2022-04-04T08:40:52.301199Z","shell.execute_reply":"2022-04-04T08:40:52.342381Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color=\"#337da4\" id=\"section_2\">2. Question per question - analysis</font>\n\n### <font color=\"#2cb7b0\" id=\"section_2_1\">2.1. Q0 - Time from Start to finish (seconds) </font>","metadata":{}},{"cell_type":"markdown","source":"We analyze the time required to complete the survey","metadata":{}},{"cell_type":"code","source":"# We change the dtype for numerical aggregations\ndf_fin['Time from Start to Finish (seconds)']=df_fin['Time from Start to Finish (seconds)'].astype(int)\n\n\nmx=df_fin['Time from Start to Finish (seconds)'].max()\nprint(f'Maximum Survey Time: {mx} seconds.')\nprint(f'equal to : {mx/3600} hours.')\n\nprint('----')\n\nmin=df_fin['Time from Start to Finish (seconds)'].min()\nprint(f'Minimum Survey Time: {min} seconds.')\nprint(f'equal to : {min/3600} hours.')\n\nprint('----')\n\nmed=df_fin['Time from Start to Finish (seconds)'].median()\nprint(f'Median Survey Time: {med} seconds.')\nprint(f'equal to : {med/3600} hours.')\n\nprint('----')\n\nmean=df_fin['Time from Start to Finish (seconds)'].mean()\nprint(f'Mean Survey Time: {mean} seconds.')\nprint(f'equal to : {mean/3600} hours.')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:52.345259Z","iopub.execute_input":"2022-04-04T08:40:52.345503Z","iopub.status.idle":"2022-04-04T08:40:52.509879Z","shell.execute_reply.started":"2022-04-04T08:40:52.345454Z","shell.execute_reply":"2022-04-04T08:40:52.508867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• Outlier ? 691 hours to complete the survey --- looks like a little bit too much","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_2\">2.2. Q1 - What is your age? </font>","metadata":{}},{"cell_type":"code","source":"df_fin.Q1.value_counts()   ","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:56.971282Z","iopub.execute_input":"2022-04-04T08:40:56.971521Z","iopub.status.idle":"2022-04-04T08:40:57.015887Z","shell.execute_reply.started":"2022-04-04T08:40:56.971486Z","shell.execute_reply":"2022-04-04T08:40:57.01517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Settings for both graphics\n\n\n#Position of the graphs : 2 on the same line \nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n#We are looking for the information of Question 1 => reset index\nn_ages = df_fin['Q1'].value_counts().reset_index(name='total')\n\n\n#Setting of the first graph \nfig.add_trace(go.Bar(\n     x=n_ages['index'], y=n_ages['total'], showlegend=False,\n    text =n_ages['total'],\n     name=\"Age-groups\"), \n     row=1, col=1)\nfig.update_yaxes(range=[0,5500])\n#fig.update_layout(uniformtext_minsize=8)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\nfig.update_layout(\n    shapes=[\n        dict(type=\"rect\", xref=\"x\", yref=\"y\",\n            x0=-0.5, y0=4000, x1=2.5, y1=5500, line_width=3)\n    ])\n\n\n\n#figure 1 : annotation about the top 3 informations \nfig.add_annotation(\n        x=2.5,\n        y=5000,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"category 18-29 represent more than 50% of the respondants\",\n        showarrow=True,\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"#222A2A\"\n            ),\n        align=\"right\",\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax=120,\n        ay=-20,\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\nn_agegroup  = n_ages['index'].values\n\n\n\n#Graph number 2 :\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=n_ages['total'],\n     labels=n_agegroup, pull=[0.15, 0.15, 0.15, 0.15, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10, 0.10], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Age-groups\"),\n    row=1, col=2)\n\n\n\n\n#general  information - titre\n\nfig.update_layout(title_text='Age distribution - international people who answered the survey in 2021', title_x=0.5,\n#                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n                 )\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:57.016807Z","iopub.execute_input":"2022-04-04T08:40:57.017621Z","iopub.status.idle":"2022-04-04T08:40:57.330368Z","shell.execute_reply.started":"2022-04-04T08:40:57.017585Z","shell.execute_reply":"2022-04-04T08:40:57.329626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• insights : Majority of the persons who answered the survey are \"young\". 50% of them are between 18-29. least represented category is 70y+ which make sens as at this age, in majority of the countries, this is retirement. \n\nWe can wonder : \n- Is it representative of the international population or just representative of the fact that yonger people took the time to answer the survey?\n- Or maybe the older persons who could have answered the survey did not had access to it / received the survey.\n- Or it is a direct consequence of the media publication the last 5 years mentionning that \"data science\" will be the best job in the future (= most required and well paid). \n- we can also wonder if the covid crisis had an impact on the general size of people who answered the survey (much more than the previous years (link to be included)","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_3\">2.3. Q2 - What is your gender ? </font>","metadata":{}},{"cell_type":"code","source":"df_fin.Q2.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:57.331856Z","iopub.execute_input":"2022-04-04T08:40:57.332296Z","iopub.status.idle":"2022-04-04T08:40:57.404328Z","shell.execute_reply.started":"2022-04-04T08:40:57.332257Z","shell.execute_reply":"2022-04-04T08:40:57.403538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#general settings for the graph\n\ndf_q1_q2 = df_fin.copy()\ndf_q1_q2 = pd.crosstab(df_q1_q2['Q1'], df_q1_q2['Q2']).reset_index()\n\n#settings for Men informations\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df_q1_q2['Q1'], y=df_q1_q2['Man'], name = \"Men\",\n                 marker_color = '#0033FF', text = df_q1_q2['Man'], textposition = \"outside\",\n))\n\n#settings for Women informations\nfig.add_trace(go.Bar(x=df_q1_q2['Q1'], y=-df_q1_q2['Woman'], name = \"Women\",\n            marker_color = '#00CCFF', text = df_q1_q2['Woman'], textposition = \"outside\"))\n\n#settings for non binary informations\nfig.add_trace(go.Bar(x=df_q1_q2['Q1'], y=-df_q1_q2['Nonbinary'], name = \"Nonbinary\",\n            marker_color = '#00CCCC', text = df_q1_q2['Nonbinary'], textposition = \"outside\"))\n\n#settings for people who prefered not to answer this question\nfig.add_trace(go.Bar(x=df_q1_q2['Q1'], y=-df_q1_q2['Prefer not to say'], name = \"Prefer not to say\",\n            marker_color = '#0099CC', text = df_q1_q2['Prefer not to say'], textposition = \"outside\"))\n\n#settings for people who prefered to self describe\nfig.add_trace(go.Bar(x=df_q1_q2['Q1'], y=-df_q1_q2['Prefer to self-describe'], name = \"Prefer to self-describe\",\n            marker_color = '#00CC99', text = df_q1_q2['Prefer to self-describe'], textposition = \"outside\"))\n\n\n\n#general informations about the comments\nfig.add_annotation(\n        x=5.5,\n        y=3598,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Imbalanced data : survey represents mainly male participants\",\n        showarrow=False,\n            yshift=10,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\nfig.add_shape(type='line',\n                x0=-0.5,\n                y0=0.31,\n                x1=11,\n                y1=0.31,\n                line=dict(color='black', dash='dot'),\n                xref='x',\n                yref='paper'\n)\n\nfig.update_layout(barmode='relative',\n    title_text='Gender distribution - international population who answered the survey in 2021',\n    height=500, title_x = 0.5, yaxis_title=\" \", \n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n)\n\nfig.update_xaxes(visible=True, categoryorder='total descending')\nfig.update_yaxes(visible=False, range=[-2000,4500])\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:57.410209Z","iopub.execute_input":"2022-04-04T08:40:57.410484Z","iopub.status.idle":"2022-04-04T08:40:57.683135Z","shell.execute_reply.started":"2022-04-04T08:40:57.41044Z","shell.execute_reply":"2022-04-04T08:40:57.682332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• insights : we have a imbalanced dataset between men/women. Representative of the current disproportion of women in the tech field.\n\nWe could wonder : \n- how to dig the answers \"prefer not to say / prefer to self describe / non binary\"\n- We could calculate the ratio men/women through the generation (we have an increase of women with younger generation, but in % ?)","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_4\">2.4. Q3 - In which country do you currently reside ? And mix with gender distribution </font>   ","metadata":{}},{"cell_type":"code","source":"print(\"In 2021, we have a representation of \\033[1m{} countries\\033[0m which took part in this survey\".format(len(df_fin['Q3'].value_counts().to_list())))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:57.684559Z","iopub.execute_input":"2022-04-04T08:40:57.684831Z","iopub.status.idle":"2022-04-04T08:40:57.731666Z","shell.execute_reply.started":"2022-04-04T08:40:57.684781Z","shell.execute_reply":"2022-04-04T08:40:57.730781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_fin.Q3.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:57.733116Z","iopub.execute_input":"2022-04-04T08:40:57.733882Z","iopub.status.idle":"2022-04-04T08:40:57.789072Z","shell.execute_reply.started":"2022-04-04T08:40:57.733837Z","shell.execute_reply":"2022-04-04T08:40:57.787929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• insights : TOP COUNTRY : INDIA (the most represented country in this survey). LAST COUNTRY : IRAQ (the least represented country in this survey). \nThe question now is to know if the survey is representative of the general trend or if the dataset is not representative (and for which reasons). \n\n> üî• insights : 69 person did not wanted to share the information.","metadata":{}},{"cell_type":"code","source":"#Selection of question 3\nn_country = df_fin['Q3'].value_counts().reset_index(name='total')\n\n#General settings\n\n#Settings of the map\ndf_fin['Q3'] = np.where((df_fin['Q3'] == 'United States of America'),'USA',df_fin['Q3'])\ndf_fin['Q3'] = np.where((df_fin['Q3'] == 'United Kingdom of Great Britain and Northern Ireland'),'UK & North Ireland',df_fin['Q3'])\n\n#information about the person who did not wish to share this information\nn_undisclosed_loc= df_fin.loc[df_fin.Q3 == 'I do not wish to disclose my location', 'Q3'].count()\nn_other_loc= df_fin.loc[df_fin.Q3 == 'Other', 'Q3'].count()\n\ndf_234 = df_fin[['Q2','Q3','Q4']]\ndf_234=df_234.rename(columns={'Some college/university study without earning a bachelor‚Äôs degree':'Without Bachelor‚Äôs degree'})\ndf_m = df_234[df_234['Q2']=='Man']\ndf_w = df_234[df_234['Q2']=='Woman']\ndf_o = df_234[(df_234['Q2'] != 'Man') & (df_234['Q2'] != 'Woman')]\n\nblue_colors = {'Bachelor‚Äôs degree':'#0099C6', 'Master‚Äôs degree':'#17BECF',\n              'Doctoral degree':'#19D3F3', 'I prefer not to answer':'#2ED9FF',\n              'High school passout':'#1CFFCE', 'Professional doctorate':'rgb(204, 235, 197)',\n              'Higher study w/o bachelor‚Äôs': 'rgb(102, 102, 102)'}\n\n\n# For better reading, we will change some countries names \ndf_m['Q3'] = np.where((df_m['Q3'] == 'United States of America'),'USA',df_m['Q3'])\ndf_m['Q3'] = np.where((df_m['Q3'] == 'United Kingdom of Great Britain and Northern Ireland'),'UK',df_m['Q3'])\n\ndf_m['Q4'] = np.where((df_m['Q4'] == 'No formal education past high school'),'High school passout',df_m['Q4'])\ndf_m['Q4'] = np.where((df_m['Q4'] == 'Some college/university study without earning a bachelor‚Äôs degree'),'Higher study w/o bachelor‚Äôs',df_m['Q4'])\n\n\ndf_w['Q3'] = np.where((df_w['Q3'] == 'United States of America'),'USA',df_w['Q3'])\ndf_w['Q3'] = np.where((df_w['Q3'] == 'United Kingdom of Great Britain and Northern Ireland'),'UK',df_w['Q3'])\n\ndf_w['Q4'] = np.where((df_w['Q4'] == 'No formal education past high school'),'High school passout',df_w['Q4'])\ndf_w['Q4'] = np.where((df_w['Q4'] == 'Some college/university study without earning a bachelor‚Äôs degree'),'Higher study w/o bachelor‚Äôs',df_w['Q4'])\n\ndf_o['Q3'] = np.where((df_o['Q3'] == 'United States of America'),'USA',df_o['Q3'])\ndf_o['Q3'] = np.where((df_o['Q3'] == 'United Kingdom of Great Britain and Northern Ireland'),'UK',df_o['Q3'])\n\ndf_o['Q4'] = np.where((df_o['Q4'] == 'No formal education past high school'),'High school passout',df_o['Q4'])\ndf_o['Q4'] = np.where((df_o['Q4'] == 'Some college/university study without earning a bachelor‚Äôs degree'),'Higher study w/o bachelor‚Äôs',df_o['Q4'])\n\ndf_o.drop(df_o.index[df_o['Q3'] == 'Other'], inplace = True)\ndf_o.drop(df_o.index[df_o['Q3'] == 'I do not wish to disclose my location'], inplace = True)\n\nn_country_gen = df_o['Q3'].value_counts().reset_index(name='total')\n\ndf_w.drop(df_w.index[df_w['Q3'] == 'Other'], inplace = True)\n\nn_country_female = df_w['Q3'].value_counts().reset_index(name='total')\n\ndf_m.drop(df_m.index[df_m['Q3'] == 'Other'], inplace = True)\n\nn_country_male = df_m['Q3'].value_counts().reset_index(name='total')\n\n\nfig1 = go.Figure(data=[go.Choropleth(locations = n_country['index'],\n                                            z = n_country['total'],\n                                            zmid = 4000,\n                                            locationmode = 'country names',\n                                            colorscale = cust_color, name='All',\n                                            colorbar_title = \"No. of respondants\"),   \n                    go.Choropleth(locations = n_country_male['index'],\n                                            z = n_country_male['total'],\n                                            zmid = 3000,\n                                            locationmode = 'country names',\n                                            colorscale = cust_color, name='Men',\n                                            colorbar_title = \"No. of male respondants\"),\n                    go.Choropleth(locations = n_country_female['index'],\n                                            z = n_country_female['total'],\n                                            zmid = 3000,\n                                            locationmode = 'country names',\n                                            colorscale = cust_color, name='Women',\n                                            colorbar_title = \"No. of female respondants\"),\n                    go.Choropleth(locations = n_country_gen['index'],\n                                            z = n_country_gen['total'],\n                                            zmid = 3000,\n                                            locationmode = 'country names',\n                                            colorscale = cust_color, name='Other Genders',\n                                            colorbar_title = \"No. of other respondants\")\n                ])\n\n\nfig1.update_layout(\n    title_text = 'Participations from each countries for all genders', title_x=0.5, title_y=0.94,\n                         geo = dict(showframe = False,\n                                    showcoastlines = False,\n                                    projection_type = 'equirectangular'),\n    annotations = [dict(\n        x=0.5,\n        y=0,    #Trying a negative number makes the caption disappear - I'd like the caption to be below the map\n        xref='paper',\n        yref='paper',\n        text=\" No. of respondants who did not wish to disclose <br> their location: \" + str(n_undisclosed_loc) +\n           \"<br> and who are from other (unlisted) countries: \" + str(n_other_loc),\n        showarrow = False,\n        font=dict(\n                family=\"Muli, sans-serif\",\n                size=14,\n                color=\"#ffffff\"\n                ),\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#222A2A\",\n        opacity=0.8\n    )], \n    updatemenus=[\n        dict(\n            active=0,\n            buttons=list([\n                dict(label=\"All\",\n                     method=\"update\",\n                     args=[{\"visible\": [True, False, False, False]}]),\n                dict(label=\"Men\",\n                     method=\"update\",\n                     args=[{\"visible\": [False, True, False, False]}]),\n                dict(label=\"Women\",\n                     method=\"update\",\n                     args=[{\"visible\": [False, False, True, False]}]),\n                dict(label=\"Other/Undisclosed Genders\",\n                     method=\"update\",\n                     args=[{\"visible\": [False, False, False, True]}])\n                            ]\n                         ))])\nfig1.update_layout(\n    margin=dict(l=10, r=10, t=10, b=10))  \n\nfig1.show()\n\n\n\ndf_m_sort = pd.crosstab( index=df_m['Q3'], columns=df_m['Q4'], margins=True, margins_name='Total')\ndf_m_sort = df_m_sort.sort_values(by='Total', ascending=False).head(11)\ndf_m_sort = df_m_sort.iloc[1:,:-1]\n\ndf_w_sort = pd.crosstab( index=df_w['Q3'], columns=df_w['Q4'], margins=True, margins_name='Total')\ndf_w_sort = df_w_sort.sort_values(by='Total', ascending=False).head(11)\ndf_w_sort = df_w_sort.iloc[1:,:-1]\n\ndf_o_sort = pd.crosstab( index=df_o['Q3'], columns=df_o['Q4'], margins=True, margins_name='Total')\ndf_o_sort = df_o_sort.sort_values(by='Total', ascending=False).head(11)\ndf_o_sort = df_o_sort.iloc[1:,:-1]\n\nfig2 = make_subplots(rows=1, cols=3, specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}, {\"type\": \"bar\"}]], subplot_titles=('Gender type 1', 'Gender type 2','Gender type 3'))\n\nfor col in df_m_sort.columns:\n    fig2.add_trace(go.Bar(x=df_m_sort.index, y=df_m_sort[col], name = col, text=df_m_sort[col], marker_color=blue_colors[col], textposition = 'outside', showlegend=False), row=1, col=1)\n    fig2.add_trace(go.Scatter(x=df_m_sort.index, y=df_m_sort[col], name = col, line = dict(\n        color = blue_colors[col],\n        width = 0.5), showlegend=False),\n              row = 1, col = 1)\n\nfor col in df_w_sort.columns:\n    fig2.add_trace(go.Bar(x=df_w_sort.index, y=df_w_sort[col], name = col, text=df_w_sort[col], marker_color=blue_colors[col], textposition = 'outside', showlegend=False), row=1, col=2)\n    fig2.add_trace(go.Scatter(x=df_w_sort.index, y=df_w_sort[col], name = col, line = dict(\n        color = blue_colors[col],\n        width = 0.5), showlegend=False),\n              row = 1, col = 2)\n    \nfor col in df_o_sort.columns:\n    fig2.add_trace(go.Bar(x=df_o_sort.index, y=df_o_sort[col], name = col, text=df_o_sort[col],\n                          marker_color=blue_colors[col], textposition = 'outside'), row=1, col=3)\n    fig2.add_trace(go.Scatter(x=df_o_sort.index, y=df_o_sort[col], name = col, line = dict(\n        color = blue_colors[col],\n        width = 0.5),showlegend=False),\n              row = 1, col = 3)\n\nnames = {'Gender type 1':'Man', 'Gender type 2':'Woman', 'Gender type 3':'Other/Undisclosed gender'}\nfig2.for_each_annotation(lambda a: a.update(text = names[a.text]))\n\nfig2.update_layout(\n    title_text = 'Top 10 countries with participations from each gender based on their qualifications', title_x=0.5, title_y=0.98,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.097, xanchor=\"center\", x=0.5))\nfig2.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:57.790748Z","iopub.execute_input":"2022-04-04T08:40:57.791373Z","iopub.status.idle":"2022-04-04T08:40:58.228685Z","shell.execute_reply.started":"2022-04-04T08:40:57.791325Z","shell.execute_reply":"2022-04-04T08:40:58.22775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_5\">2.5. Q4 - What is the highest level of formal education that you have attained or plan to attain within the next 2 years? </font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q4.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:58.23Z","iopub.execute_input":"2022-04-04T08:40:58.230287Z","iopub.status.idle":"2022-04-04T08:40:58.28281Z","shell.execute_reply.started":"2022-04-04T08:40:58.23025Z","shell.execute_reply":"2022-04-04T08:40:58.281003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nn_roles = df_fin['Q4'].value_counts().reset_index(name='total')\nn_roles= n_roles.replace({'Some college/university study without earning a bachelor‚Äôs degree': 'Without Bachelor‚Äôs degree'})\n\nfig.add_trace(go.Bar(\n     x=n_roles['index'], y=n_roles['total'], showlegend=False, \n    text =n_roles['total'],\n     name=\"Jobs roles\"), \n     row=1, col=1)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\nfig.update_yaxes(range=[0,11000])\n\nn_jobcategory  = n_roles['index'].values\n\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=n_roles['total'],\n     labels=n_jobcategory, pull=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Job Role\"),\n    row=1, col=2)\n\nfig.add_annotation(\n        x=4,\n        y=9000,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Most of the participants <br> pursued/are pursuing <br> higher studies\",\n        showarrow=False,\n            yshift=10,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\n\nfig.update_layout(title_text='Highest level of education', title_x=0.5,title_y=0.97,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5), height=450)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:58.284069Z","iopub.execute_input":"2022-04-04T08:40:58.284284Z","iopub.status.idle":"2022-04-04T08:40:58.377099Z","shell.execute_reply.started":"2022-04-04T08:40:58.284255Z","shell.execute_reply":"2022-04-04T08:40:58.376318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• insights : majority have master/ bachelor degrees. As the majority of people who answered the survey were between 18 - 29 years old = the young generation is mainly diplomated. ","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_6\">2.6. Q5 - Select the title most similar to your current role (or most recent title if retired)? And position by gender </font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q5.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:58.378338Z","iopub.execute_input":"2022-04-04T08:40:58.378555Z","iopub.status.idle":"2022-04-04T08:40:58.425329Z","shell.execute_reply.started":"2022-04-04T08:40:58.378529Z","shell.execute_reply":"2022-04-04T08:40:58.424744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nn_roles = df_fin['Q5'].value_counts().reset_index(name='total')\n\nfig.add_trace(go.Bar(\n     x=n_roles['index'], y=n_roles['total'], showlegend=False,\n    text =n_roles['total'],\n     name=\"Jobs roles\"), \n     row=1, col=1)\n#fig.update_layout(uniformtext_minsize=8)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\nfig.add_annotation(\n        x=0.6,\n        y=6804,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Students participated the most in this survey, <br> more than a quarter of the respondants\",\n        showarrow=True,\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"#222A2A\"\n            ),\n        align=\"center\",\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax=120,\n        ay=-30,\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\n\n\nn_jobcategory  = n_roles['index'].values\n\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=n_roles['total'],\n     labels=n_jobcategory, pull=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Job Role\"),\n    row=1, col=2)\n\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Job roles of the participants', title_x=0.5, title_y=0.996,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()\n\ndf_profession_male = df_fin[df_fin['Q2'] == 'Man'][['Q2', 'Q5']]\ndf_profession_male = df_profession_male['Q5'].value_counts().rename_axis('Profession').reset_index(name='Counts').sort_values(by=['Counts'], ascending=False)\ndf_profession_male['Gender'] = 'Man'\n\ndf_profession_female = df_fin[df_fin['Q2'] == 'Woman'][['Q2', 'Q5']]\ndf_profession_female = df_profession_female['Q5'].value_counts().rename_axis('Profession').reset_index(name='Counts').sort_values(by=['Counts'], ascending=False)\ndf_profession_female['Gender'] = 'Woman'\n\ndf_profession_other = df_fin[(df_fin['Q2'] != 'Man') & (df_fin['Q2'] != 'Woman')][['Q2', 'Q5']]\ndf_profession_other = df_profession_other['Q5'].value_counts().rename_axis('Profession').reset_index(name='Counts').sort_values(by=['Counts'], ascending=False)\ndf_profession_other['Gender'] = 'Others'\n\ndf_gen_prof = pd.concat([df_profession_male, df_profession_female, df_profession_other], axis=0)\nfig1 = px.funnel(df_gen_prof, x='Counts', y='Profession', color='Gender',\n                       height=500, title='Profession by gender',\n                       category_orders={'Gender': ['Man', 'Woman', 'Others']},\n                       color_discrete_sequence=['darkblue', 'blue', 'royalblue'],\n                       )\nfig1.update_traces(textposition='inside')\nfig1.update_layout(autosize=True,\n                         margin=dict(t=110, b=50, l=70, r=40), title_x=0.5, title_y=0.92,\n                         plot_bgcolor='white', paper_bgcolor='white', \n                         title_font=dict(size=21, color='#636363', family=\"Muli, sans-serif\"),\n                         font=dict(color='#636363'),\n                         legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig1.update_layout(\n                 margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                        ))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:58.426819Z","iopub.execute_input":"2022-04-04T08:40:58.427029Z","iopub.status.idle":"2022-04-04T08:40:59.280882Z","shell.execute_reply.started":"2022-04-04T08:40:58.427004Z","shell.execute_reply":"2022-04-04T08:40:59.280233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> üî• We have a confirmation that we have a majority of students who answered the survey. This explain the reason why 50% of the participants have 18-29 years old. On the contrary, the least represented professions are : Developer relations/Advocacy and DBA/Database engineer. Why ? Either they have not enough free time to answer, either they are mainly working with confidential data and are not allowed / do not have the habits to complete surveys or it's because these profession do not often use Kaggle which could explain that they are not even aware of this study. ","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_7\">2.7. Q6 - For how many years have you been writing code and/or programming? </font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q6.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:59.281805Z","iopub.execute_input":"2022-04-04T08:40:59.281994Z","iopub.status.idle":"2022-04-04T08:40:59.3351Z","shell.execute_reply.started":"2022-04-04T08:40:59.281969Z","shell.execute_reply":"2022-04-04T08:40:59.334174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nn_coding = df['Q6'].value_counts().reset_index(name='total')\n\nfig.add_trace(go.Bar(\n     x=n_coding['index'], y=n_coding['total'], showlegend=False,\n    text =n_coding['total'],\n     name=\"Coding experience\"), \n     row=1, col=1)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n#fig.update_layout(\n#    shapes=[\n#        dict(type=\"rect\", xref=\"x\", yref=\"y\",\n#            x0=-0.5, y0=5000, x1=1.5, y1=8500, line_width=3),\n#        dict(type=\"rect\", xref=\"x\", yref=\"y\",\n#            x0=5.5, y0=900, x1=6.5, y1=1500, line_width=3)\n#    ])\n\nfig.add_annotation(\n        x=3,\n        y=7874,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Most are beginners and/or amateurs\",\n        showarrow=False,\n            yshift=10,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\n\nn_codgroup  = n_coding['index'].values\n\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=n_coding['total'],\n     labels=n_codgroup, pull=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Coding Exp\"),\n    row=1, col=2)\n\n\nfig.update_layout(title_text='Coding experiences of the participants', title_x=0.5,\n#                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5),\n                 height=450)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:59.336377Z","iopub.execute_input":"2022-04-04T08:40:59.337071Z","iopub.status.idle":"2022-04-04T08:40:59.415184Z","shell.execute_reply.started":"2022-04-04T08:40:59.337024Z","shell.execute_reply":"2022-04-04T08:40:59.414498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_8\">2.8. Q7 - What programming languages do you use on a regular basis?</font>   ","metadata":{}},{"cell_type":"code","source":"Q7_values = df_fin.loc[:,['Q7_Part_1', 'Q7_Part_2', 'Q7_Part_3', 'Q7_Part_4',\n       'Q7_Part_5', 'Q7_Part_6', 'Q7_Part_7', 'Q7_Part_8', 'Q7_Part_9',\n       'Q7_Part_10', 'Q7_Part_11', 'Q7_Part_12', 'Q7_OTHER']]\n\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q7_values.stack().unique(), y=Q7_values.stack().value_counts().values, showlegend=False,\n    text =Q7_values.stack().value_counts().values,\n     name=\"Programming language\"), \n     row=1, col=1)\n#fig.update_layout(uniformtext_minsize=8)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q7_values.stack().value_counts().values,\n     labels=Q7_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Programming language\"),\n    row=1, col=2)\n\n\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Preferred programming language by participants', title_x=0.5, title_y=0.95,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5), height= 350)\nfig.show()\n\n\nfig1 = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nn_recom_coding = df['Q8'].value_counts().reset_index(name='total')\n\nfig1.add_trace(go.Bar(\n     x=n_recom_coding['index'], y=n_recom_coding['total'], showlegend=False,\n    text =n_recom_coding['total'],\n     name=\"Coding experience\"), \n     row=1, col=1)\n\nfig1.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\nfig1.add_trace(go.Scatter(x=n_recom_coding['index'], y=n_recom_coding['total'], showlegend=False, line = dict(\n        color = 'red',\n        width = 1.5)), row=1, col=1)\n\nfig1.add_annotation(\n        x=0.6,\n        y=12000,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"A huge gap in <br> between Python and <br> other coding language <br> suggestions\",\n        showarrow=True,\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"#222A2A\"\n            ),\n        align=\"center\",\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax=120,\n        ay=-30,\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\nfig1.add_shape(type='line',\n                x0=0.5,\n                y0=0,\n                x1=0.5,\n                y1=1,\n                line=dict(color='black', dash='dot'),\n                xref='x',\n                yref='paper'\n)\n\nn_reccodgroup  = n_recom_coding['index'].values\n\n# pull is given as a fraction of the pie radius\nfig1.add_trace(go.Pie(\n     values=n_recom_coding['total'],\n     labels=n_reccodgroup, pull=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Coding Recom\"),\n    row=1, col=2)\n\n\nfig1.update_layout(title_text='Coding recommendations of the participants', title_x=0.5, title_y=0.96,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.07, xanchor=\"center\", x=0.5),\n                 height=350)\nfig1.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:59.416182Z","iopub.execute_input":"2022-04-04T08:40:59.416371Z","iopub.status.idle":"2022-04-04T08:40:59.724144Z","shell.execute_reply.started":"2022-04-04T08:40:59.416348Z","shell.execute_reply":"2022-04-04T08:40:59.723211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_9\">2.9. Q8 - What programming language would you recommend ?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q8.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:59.725419Z","iopub.execute_input":"2022-04-04T08:40:59.72571Z","iopub.status.idle":"2022-04-04T08:40:59.778106Z","shell.execute_reply.started":"2022-04-04T08:40:59.725676Z","shell.execute_reply":"2022-04-04T08:40:59.777524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.ecdf(df_fin, x = 'Q8')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:40:59.779228Z","iopub.execute_input":"2022-04-04T08:40:59.779697Z","iopub.status.idle":"2022-04-04T08:41:00.119243Z","shell.execute_reply.started":"2022-04-04T08:40:59.779661Z","shell.execute_reply":"2022-04-04T08:41:00.118388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"edu2 = df_fin.Q8.value_counts()\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Recommended Coding Languages by Position\")))\n\n#changed from role selection to selection 1\nfig.add_trace(go.Bar(name= 'Selection 1', x= edu2.index, y=(edu2.values/ edu2.values.sum())))\nfig.update_traces(marker=dict(color=cust_color))\nbuttons = []\n\n#added button for all data comparison\nbuttons.append(dict(method='restyle',\n                        label= 'All Samples',\n                        visible=True,\n                        args=[{'y':[df_fin.Q8.value_counts().values/df_fin.Q8.value_counts().values.sum()],\n                               'x':[df_fin.Q8.value_counts().index],\n                               'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfor i in list(Roles.keys())[1:]:\n    buttons.append(dict(method='restyle',\n                        label= i,\n                        visible=True,\n                        args=[{'y':[Roles[i].Q8.value_counts().values/Roles[i].Q8.value_counts().values.sum()],\n                               'x':[Roles[i].Q8.value_counts().index],\n                               'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfig.add_trace(go.Bar(name= 'Selection 2',x= edu2.index, y=(edu2.values/ edu2.values.sum())))\nfig.update_traces(marker=dict(color=cust_color))\n\nbuttons2 = []\n#added button for all data comparison\nbuttons2.append(dict(method='restyle',\n                        label= 'All Samples',\n                        visible=True,\n                        args=[{'y':[df_fin.Q8.value_counts().values/df_fin.Q8.value_counts().values.sum()],\n                               'x':[df_fin.Q8.value_counts().index],\n                               'type':'bar'}, [1]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfor i in list(Roles.keys())[1:]:\n    buttons2.append(dict(method='restyle',\n                        label= i,\n                        visible=True,\n                        args=[{'y':[Roles[i].Q8.value_counts().values/Roles[i].Q8.value_counts().values.sum()],\n                               'x':[Roles[i].Q8.value_counts().index],\n                               'type':'bar'}, [1]], # the [1] at the end lets us know they are for the first trace\n                        )                        #literally figured that out by just experimenting \n                  )\n# adjusted dropdown placement \n#found out updatemenus take a dictionary of buttons and allow you to format how the dropdowns look etc.\n# https://plotly.com/python/dropdowns/\nbutton_layer_1_height = 1.15\nupdatemenus = list([\n    dict(buttons=buttons,\n            direction=\"down\",\n            pad={\"b\": 10, \"b\": 10},\n            showactive=True,\n            x=0.1,\n            xanchor=\"left\",\n            y=button_layer_1_height,\n            yanchor=\"top\"),\n    dict(buttons=buttons2,\n            direction=\"down\",\n            pad={\"b\": 10, \"b\": 10},\n            showactive=True,\n            x=0.50,\n            xanchor=\"left\",\n            y=button_layer_1_height,\n            yanchor=\"top\")])\n    \nfig.update_layout( updatemenus=updatemenus)\n#added annotations next to dropdowns \nfig.update_layout(\n    annotations=[\n        dict(text=\"Selection 1\", x=0, xref=\"paper\", y=1.1, yref=\"paper\",\n                             align=\"left\", showarrow=False),\n        dict(text=\"Selection 2\", x=0.45, xref=\"paper\", y=1.1,\n                             yref=\"paper\", showarrow=False)\n    ])\n#fig.update_xaxes(categoryorder= 'array', categoryarray= [\"Doctoral degree\",'Master‚Äôs degree','Bachelor‚Äôs degree','Some college/university study without earning a bachelor‚Äôs degree',\"Professional degree\",\"No formal education past high school\",\"I prefer not to answer\"])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:00.120692Z","iopub.execute_input":"2022-04-04T08:41:00.121085Z","iopub.status.idle":"2022-04-04T08:41:00.273153Z","shell.execute_reply.started":"2022-04-04T08:41:00.121049Z","shell.execute_reply":"2022-04-04T08:41:00.272405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_10\">2.10. Q9 - which IDE's do you use on a regular basis ?</font>   ","metadata":{}},{"cell_type":"code","source":"def filter_bars(role, data):\n    df = data[data['Roles'] == role]\n    q = df.drop('Roles', axis= 1).count().reset_index()\n    q.columns = ['language','Count']\n    return (q.language, q.Count/q.Count.sum())","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:00.274671Z","iopub.execute_input":"2022-04-04T08:41:00.275167Z","iopub.status.idle":"2022-04-04T08:41:00.32284Z","shell.execute_reply.started":"2022-04-04T08:41:00.275124Z","shell.execute_reply":"2022-04-04T08:41:00.322126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q9_values = df_fin.loc[:,['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4',\n       'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9',\n       'Q9_Part_10', 'Q9_Part_11', 'Q9_Part_12', 'Q9_OTHER']]\n\nQ9_df = pd.DataFrame(list(Q9_values.stack().value_counts().items()), columns = ['IDE', 'Count'])\nQ9_df.iloc[0] = Q9_df.iloc[0] + Q9_df.iloc[3]\nQ9_df = Q9_df.drop(3).reset_index(drop=True)\nQ9_df['IDE'] = np.where((Q9_df.IDE == ' Jupyter NotebookJupyter (JupyterLab, Jupyter Notebooks, etc) '),'Jupyter',Q9_df.IDE)\nQ9_df['IDE'] = np.where((Q9_df.IDE == ' Visual Studio Code (VSCode) '),'VSCode',Q9_df.IDE)\n\n\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q9_df['IDE'], y=Q9_df['Count'], showlegend=False,\n    text =Q9_df['Count'],\n     name=\"Programming language\"), \n     row=1, col=1)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\nfig.add_shape(type=\"line\",\n    x0=-0.3, y0=22700, x1=-0.3, y1=23400,\n    line=dict(color=\"rgb(102,102,102)\",width=2)\n)\nfig.add_shape(type=\"line\",\n    x0=-0.3, y0=23400, x1=2.3, y1=23400,\n    line=dict(color=\"rgb(102,102,102)\",width=2)\n)\nfig.add_shape(type=\"line\",\n    x0=2.3, y0=8700, x1=2.3, y1=23400,\n    line=dict(color=\"rgb(102,102,102)\",width=2)\n)\n\nfig.add_annotation(\n        x=2.3,\n        y=16000,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"It explains why most <br> of the regularly used IDEs <br> are Python-based editors. <br> Covers more than <br> 50% of the IDEs\",\n        showarrow=True,\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"#222A2A\"\n            ),\n        align=\"center\",\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax=120,\n        ay=-30,\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q9_df['Count'],\n     labels=Q9_df['IDE'], pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Programming language\"),\n    row=1, col=2)\n\nfig.update_yaxes(range=[0,24000])\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Regularly used integrated development environments (IDEs)', title_x=0.5, title_y=0.94,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5), height=450)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:00.324286Z","iopub.execute_input":"2022-04-04T08:41:00.324564Z","iopub.status.idle":"2022-04-04T08:41:00.458457Z","shell.execute_reply.started":"2022-04-04T08:41:00.324533Z","shell.execute_reply":"2022-04-04T08:41:00.457542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Questions['Q9'].columns = list(Questions['Q9'].mode().iloc[0,:])\nq9 = Questions['Q9'].count().reset_index()\nq9.columns = ['language','Count']\nq9 = q9.sort_values('Count', ascending = False)\n\nQuestions['Q9']['Roles'] = df_fin.Q5\n\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Comparing IDE's by Position\")))\n#changed from role selection to selection 1\nfig.add_trace(go.Bar(name= 'Selection 1', x= q9.language, y=(q9.Count/ q9.Count.sum())))\nfig.update_traces(marker=dict(color=cust_color))\nbuttons = []\n\n#added button for all data comparison\nbuttons.append(dict(method='restyle',\n                        label= 'All Samples',\n                        visible=True,\n                        args=[{'y':[(q9.Count/ q9.Count.sum())],\n                               'x':[q9.language],\n                               'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfor i in list(Roles.keys())[1:]:\n    buttons.append(dict(method='restyle',\n                        label= i,\n                        visible=True,\n                        args=[{'y':[filter_bars(i,Questions['Q9'])[1].values],\n                               'x':[filter_bars(i,Questions['Q9'])[0].values],\n                               'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfig.add_trace(go.Bar(name= 'Selection 2', x= q9.language, y=(q9.Count/ q9.Count.sum())))\nfig.update_traces(marker=dict(color=cust_color))\nbuttons2 = []\n#added button for all data comparison\nbuttons2.append(dict(method='restyle',\n                        label= 'All Samples',\n                        visible=True,\n                        args=[{'y':[(q9.Count/ q9.Count.sum())],\n                               'x':[q9.language],\n                               'type':'bar'}, [1]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfor j in list(Roles.keys())[1:]:\n    buttons2.append(dict(method='restyle',\n                        label= j,\n                        visible=True,\n                        args=[{'y':[filter_bars(j,Questions['Q9'])[1].values],\n                               'x':[filter_bars(j,Questions['Q9'])[0].values],\n                               'type':'bar'}, [1]], # the [1] at the end lets us know they are for the first trace\n                        )                        #literally figured that out by just experimenting \n                  )\n# adjusted dropdown placement \n#found out updatemenus take a dictionary of buttons and allow you to format how the dropdowns look etc.\n# https://plotly.com/python/dropdowns/\nbutton_layer_1_height = 1.15\nupdatemenus = list([\n    dict(buttons=buttons,\n            direction=\"down\",\n            pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.1,\n            xanchor=\"left\",\n            y=button_layer_1_height,\n            yanchor=\"top\"),\n    dict(buttons=buttons2,\n            direction=\"down\",\n            pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.50,\n            xanchor=\"left\",\n            y=button_layer_1_height,\n            yanchor=\"top\")])\n    \nfig.update_layout( updatemenus=updatemenus)\n#added annotations next to dropdowns \nfig.update_layout(\n    annotations=[\n        dict(text=\"Selection 1\", x=0, xref=\"paper\", y=1.1, yref=\"paper\",\n                             align=\"left\", showarrow=False),\n        dict(text=\"Selection 2\", x=0.45, xref=\"paper\", y=1.1,\n                             yref=\"paper\", showarrow=False)\n    ])\nfig.update_xaxes(categoryorder= 'array', categoryarray= q9.language)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:00.460074Z","iopub.execute_input":"2022-04-04T08:41:00.46037Z","iopub.status.idle":"2022-04-04T08:41:00.967214Z","shell.execute_reply.started":"2022-04-04T08:41:00.46033Z","shell.execute_reply":"2022-04-04T08:41:00.966389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_11\">2.11. Q10 - Which of the following hosted notebook products do you use on a regular basis ? AND VS Hardware VS TPU</font>   ","metadata":{}},{"cell_type":"code","source":"df_q12_q13 = df_fin.copy()\ndf_q12_q13 = df_q12_q13.groupby(['Q13'])[['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4', 'Q12_Part_5', 'Q12_OTHER']\n                                 ].count().unstack().fillna(0).reset_index(name='counts')\n\ndf_q12_q13 = df_q12_q13.replace({'level_0' : \n                                 { 'Q12_Part_1' : 'NVIDIA GPUs', 'Q12_Part_2' : 'Google Cloud TPUs',\n                                 \"Q12_Part_3\" : 'AWS Trainium Chips' ,  \"Q12_Part_4\" : 'AWS Inferentia Chips',     \n                                  \"Q12_Part_5\" : 'None',  \"Q12_OTHER\": 'Other'\n                                 }}) \ndf_q12_q13 = df_q12_q13[df_q12_q13['level_0'] != 'None']\n#df_q12_q13 = df_q12_q13[df_q12_q13['Q13'] != 'Never']\n\ndf_q12_q13 = df_q12_q13.sort_values(by='counts', ascending = False)\n\ndf_q12_q13_0 = df_q12_q13[df_q12_q13['Q13'] == 'Never'].drop('Q13', axis='columns').rename(columns = {'counts': 'Never'}, inplace = False)\ndf_q12_q13_1 = df_q12_q13[df_q12_q13['Q13'] == 'Once'].drop('Q13', axis='columns').rename(columns = {'counts': 'Once'}, inplace = False)\ndf_q12_q13_2 = df_q12_q13[df_q12_q13['Q13'] == '2-5 times'].drop('Q13', axis='columns').rename(columns = {'counts': '2-5 times'}, inplace = False)\ndf_q12_q13_3 = df_q12_q13[df_q12_q13['Q13'] == '6-25 times'].drop('Q13', axis='columns').rename(columns = {'counts': '6-25 times'}, inplace = False)\ndf_q12_q13_4 = df_q12_q13[df_q12_q13['Q13'] == 'More than 25 times'].drop('Q13', axis='columns').rename(columns = {'counts': 'More than 25 times'}, inplace = False)\n\ndf_q12_q13= pd.merge(df_q12_q13_0, df_q12_q13_1, on='level_0')\ndf_q12_q13= pd.merge(df_q12_q13, df_q12_q13_2, on='level_0')\ndf_q12_q13= pd.merge(df_q12_q13, df_q12_q13_3, on='level_0')\ndf_q12_q13= pd.merge(df_q12_q13, df_q12_q13_4, on='level_0')\n\n\nQ13_values = df_fin['Q13'].value_counts().reset_index(name='total')\n\nfig = make_subplots(rows=1, cols=2, shared_yaxes=True, horizontal_spacing=0, vertical_spacing=0, \n                    specs=[[{\"type\": \"bar\"},{\"type\": \"pie\"}]],\n                    column_widths=[0.6, 0.4])\n\ncolors = ['#0026ff', '#0055ff', '#0095ff', '#00d5ff', '#00ffea']\n\n#fig.add_trace(go.Bar(x=df_q12_q13['level_0'], y=df_q12_q13['Never'], marker_color='#0026ff', name= 'Never',\n#                     text=df_q12_q13['Never'], showlegend=False,  opacity=0.6),\n#                     row=1, col=2)\nfig.add_trace(go.Bar(x=df_q12_q13['level_0'], y=df_q12_q13['Once'], marker_color='#0055ff', name= 'Once',\n                     text=df_q12_q13['Once'], showlegend=False, opacity=0.6),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q12_q13['level_0'], y=df_q12_q13['2-5 times'], marker_color='#0095ff', name= '2-5 times',\n                      text=df_q12_q13['2-5 times'], showlegend=False, opacity=0.6), #, legendgroup = '1'\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q12_q13['level_0'], y=df_q12_q13['6-25 times'], marker_color='#00d5ff', name= '6-25 times',\n                    text=df_q12_q13['6-25 times'], showlegend=False, opacity=0.6), #, legendgroup = '1'\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q12_q13['level_0'], y=df_q12_q13['More than 25 times'], marker_color='#00ffea', name= 'More than 25 times',\n                     text=df_q12_q13['More than 25 times'], showlegend=False, opacity=0.6), \n                     row=1, col=1)\nfig.update_traces(textposition='outside', marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n\nfig.add_trace(go.Pie(\n     values=Q13_values['total'],\n     labels=Q13_values['index'].values, pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=colors, opacity=0.5,\n     name=\"Coding Platform\"),\n    row=1, col=2)\n\nfig.update_layout(\n    title_text=\"Usage of specialized hardware and their usage frequencies by participants\", title_x=0.5, title_y=0.9,\n    xaxis1_title = 'Specialized Hardware',\n    yaxis1_title = 'Usage frequency of TPU types',\n    #legend_tracegroupgap = 180,\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n)\nfig.show()\ndf_q10_q13 = df_fin.copy()\ndf_q10_q13 = df_q10_q13.groupby(['Q13'])[['Q10_Part_1', 'Q10_Part_2', 'Q10_Part_3', 'Q10_Part_4',\n       'Q10_Part_5', 'Q10_Part_6', 'Q10_Part_7', 'Q10_Part_8', 'Q10_Part_9',\n       'Q10_Part_10', 'Q10_Part_11', 'Q10_Part_12', 'Q10_Part_13',\n       'Q10_Part_14', 'Q10_Part_15', 'Q10_Part_16', 'Q10_OTHER']\n                                 ].count().unstack().fillna(0).reset_index(name='counts')\n\ndf_q10_q13_0 = df_q10_q13[df_q10_q13['Q13'] == 'Never'].drop('Q13', axis='columns').rename(columns = {'counts': 'Never'}, inplace = False)\ndf_q10_q13_1 = df_q10_q13[df_q10_q13['Q13'] == 'Once'].drop('Q13', axis='columns').rename(columns = {'counts': 'Once'}, inplace = False)\ndf_q10_q13_2 = df_q10_q13[df_q10_q13['Q13'] == '2-5 times'].drop('Q13', axis='columns').rename(columns = {'counts': '2-5 times'}, inplace = False)\ndf_q10_q13_3 = df_q10_q13[df_q10_q13['Q13'] == '6-25 times'].drop('Q13', axis='columns').rename(columns = {'counts': '6-25 times'}, inplace = False)\ndf_q10_q13_4 = df_q10_q13[df_q10_q13['Q13'] == 'More than 25 times'].drop('Q13', axis='columns').rename(columns = {'counts': 'More than 25 times'}, inplace = False)\n\n\ndf_q10_q13= pd.merge(df_q10_q13_0, df_q10_q13_1, on='level_0')\ndf_q10_q13= pd.merge(df_q10_q13, df_q10_q13_2, on='level_0')\ndf_q10_q13= pd.merge(df_q10_q13, df_q10_q13_3, on='level_0')\ndf_q10_q13= pd.merge(df_q10_q13, df_q10_q13_4, on='level_0')\n\n\ndf_q10_q13 = df_q10_q13.replace({'level_0' : \n                                 { 'Q10_Part_1' : 'Kaggle Notebooks', 'Q10_Part_2' : 'Colab Notebooks',\n                                 \"Q10_Part_3\" : 'Azure Notebooks' ,  \"Q10_Part_4\" : 'Paperspace / Gradient',     \n                                \"Q10_Part_5\" : 'Binder / JupyterHub', \"Q10_Part_6\" : 'Code Ocean',\n                                \"Q10_Part_7\" : ' IBM Watson Studio', \"Q10_Part_8\" : 'Amazon Sagemaker Studio Notebooks', \n                                \"Q10_Part_9\" : ' Amazon EMR Notebooks',  \"Q10_Part_10\" : 'Google Cloud Notebooks (AI Platform / Vertex AI)', \n                                \"Q10_Part_11\" : 'Google Cloud Datalab', \"Q10_Part_12\" : ' Databricks Collaborative Notebooks',  \n                                  \"Q10_Part_13\" : 'Zeppelin / Zepl Notebooks', \"Q10_Part_14\" : ' Deepnote Notebooks', \n                                  \"Q10_Part_15\" : 'Observable Notebooks', \"Q10_Part_16\" : 'None', \"Q10_OTHER\": 'Other'\n                                 }})\n\n\nplot = go.Figure(data=[go.Bar(\n    name = 'Never',\n    y = df_q10_q13['level_0'],\n    x = df_q10_q13['Never'], \n    orientation = 'h', text=df_q10_q13['Never'], marker_color='#02252e' , opacity = 0.7\n   ),\n                       go.Bar(\n    name = 'Once',\n    y = df_q10_q13['level_0'],\n    x = df_q10_q13['Once'],\n    orientation = 'h', text=df_q10_q13['Once'], marker_color='#124739' , opacity = 0.7\n   ),\n                       go.Bar(\n    name = '2-5 times',\n    y = df_q10_q13['level_0'],\n    x = df_q10_q13['2-5 times'],\n    orientation = 'h', text=df_q10_q13['2-5 times'], marker_color = '#0ba179', opacity = 0.7\n   ),\n                       go.Bar(\n    name = '6-25 times',\n    y = df_q10_q13['level_0'],\n    x = df_q10_q13['6-25 times'],\n    orientation = 'h', text=df_q10_q13['6-25 times'], marker_color = '#84d4e8', opacity = 0.7\n   ),\n                       go.Bar(\n    name = 'More than 25 times',\n    y = df_q10_q13['level_0'],\n    x = df_q10_q13['More than 25 times'],\n    orientation = 'h', text=df_q10_q13['More than 25 times'], marker_color = '#bcdbe3', opacity = 0.7\n   )                       \n])\n\nplot.update_yaxes(categoryorder='total ascending')\nplot.update_traces(textposition=\"outside\")\n \nplot.update_layout(barmode='stack', title_text = \"Notebook products and corresponding TPU usage by participants\",\n                  title_x = 0.5, title_y = 0.93,\n                  legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5),\n                  margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=80,\n                        ),)\n                  \nplot.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:00.968575Z","iopub.execute_input":"2022-04-04T08:41:00.968769Z","iopub.status.idle":"2022-04-04T08:41:01.453386Z","shell.execute_reply.started":"2022-04-04T08:41:00.968745Z","shell.execute_reply":"2022-04-04T08:41:01.452503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_12\">2.12. Q11 - What type of computing platform do you use most often for your data science projects ? </font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q11.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:01.454651Z","iopub.execute_input":"2022-04-04T08:41:01.455229Z","iopub.status.idle":"2022-04-04T08:41:01.508425Z","shell.execute_reply.started":"2022-04-04T08:41:01.455195Z","shell.execute_reply":"2022-04-04T08:41:01.507566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.violin(df_fin, x = 'Q11')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:01.509851Z","iopub.execute_input":"2022-04-04T08:41:01.510714Z","iopub.status.idle":"2022-04-04T08:41:01.786159Z","shell.execute_reply.started":"2022-04-04T08:41:01.510668Z","shell.execute_reply":"2022-04-04T08:41:01.785351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (10, 10))\n# Create a word cloud of the current jobs\nfrom wordcloud import WordCloud\n#Creating the text variable\ntext = \" \".join(job for job in df_fin['Q11'])\n# Creating word_cloud with text as argument in .generate() method\n#word_cloud = WordCloud(collocations = True, background_color = 'white').generate(text)\nwordcloud = WordCloud(width = 3000, height = 2000, random_state=1, background_color='black', colormap='Set1', collocations=False, stopwords = STOPWORDS).generate(text)\n#collocation argument is set to FALSE to ensure that the word cloud doesn‚Äôt contain any bigrams or duplicate words.\n# Display the generated Word Cloud\nplt.imshow(word_cloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\n\n#https://www.analyticsvidhya.com/blog/2021/08/creating-customized-word-cloud-in-python/","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:01.787504Z","iopub.execute_input":"2022-04-04T08:41:01.787732Z","iopub.status.idle":"2022-04-04T08:41:04.49448Z","shell.execute_reply.started":"2022-04-04T08:41:01.787705Z","shell.execute_reply":"2022-04-04T08:41:04.492111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_13\">2.13. Q12 - Which types of specialized hardware do you use on a regular basis</font>   ","metadata":{}},{"cell_type":"code","source":"Q12_values = df_fin.loc[:,['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4', 'Q12_Part_5', 'Q12_OTHER']]\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q12_values.stack().unique(), y=Q12_values.stack().value_counts().values, showlegend=False,\n    text =Q12_values.stack().value_counts().values,\n     name=\"ML framework\"), \n     row=1, col=1,)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q12_values.stack().value_counts().values,\n     labels=Q12_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"ML framework\"),\n    row=1, col=2)\n\n\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Machine learning frameworks regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.495354Z","iopub.status.idle":"2022-04-04T08:41:04.495982Z","shell.execute_reply.started":"2022-04-04T08:41:04.495808Z","shell.execute_reply":"2022-04-04T08:41:04.495829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_14\">2.14. Q13 - Approx how many times have you used a TPu ?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q13.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.497203Z","iopub.status.idle":"2022-04-04T08:41:04.49768Z","shell.execute_reply.started":"2022-04-04T08:41:04.497507Z","shell.execute_reply":"2022-04-04T08:41:04.497535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(df_fin['Q13'].value_counts().index)\nvalues = list(df_fin['Q13'].value_counts())\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.3, textinfo='label+percent',\n                             insidetextorientation='radial',\n                             marker=dict(colors=cust_color, line=dict(color='#000000', width=2))\n                            )])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.498634Z","iopub.status.idle":"2022-04-04T08:41:04.498897Z","shell.execute_reply.started":"2022-04-04T08:41:04.498759Z","shell.execute_reply":"2022-04-04T08:41:04.498774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_15\">2.15. Q14 - What data visualization libraries or tools do you ise on a regular basis ? </font>   ","metadata":{}},{"cell_type":"code","source":"data_q14 = df_fin[[i for i in df_fin.columns if 'Q14' in i]]\ndata_q14_count = pd.Series(dtype='int')\nfor i in data_q14.columns:\n    data_q14_count[data_q14[i].value_counts().index[0]] = data_q14[i].count()\n    \n# Q14\n\ncolor=cust_color\n\n#colors = ['lightgray'] * 14 \n#colors[0] = colors[1] = colors[3] = '#02080F'\n#colors[2] = colors[4] = colors[6] = colors[7] = '#522e75'\n#colors[8] = colors[9] = '#714e3d'\n\nfig, ax = plt.subplots(1,1, figsize=(15, 6))\nax.bar(data_q14_count.index, data_q14_count, width=0.55, \n       edgecolor='darkgray', color=cust_color,\n       linewidth=0.7)\n\nfor i in data_q14_count.index:\n    ax.annotate(f\"{data_q14_count[i]}\", \n                   xy=(i, data_q14_count[i] + 500),\n                   va = 'center', ha='center',fontweight='light', fontfamily='serif',\n                   color='#4a4a4a')\n\n\nfor s in ['top', 'left', 'right']:\n    ax.spines[s].set_visible(False)\n\nax.set_xticklabels(data_q14_count.index, fontfamily='serif', rotation=40)\nfig.text(0.13, 0.95, 'Visualization Library', fontsize=15, fontweight='bold', fontfamily='serif')    \nax.grid(axis='y', linestyle='-', alpha=0.4)    \n\nstatic = mpatches.Patch(color='#02080F', label='static')\ninteractive = mpatches.Patch(color='#522e75', label='interactive')\ngeo = mpatches.Patch(color='#714e3d', label='geospatial')\n\nplt.legend(handles=[static, interactive, geo], fontsize=13)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.499963Z","iopub.status.idle":"2022-04-04T08:41:04.500248Z","shell.execute_reply.started":"2022-04-04T08:41:04.500093Z","shell.execute_reply":"2022-04-04T08:41:04.500109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_16\">2.16. Q15 - For how many years have you used machine learning methods ?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q15.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.501093Z","iopub.status.idle":"2022-04-04T08:41:04.501383Z","shell.execute_reply.started":"2022-04-04T08:41:04.501222Z","shell.execute_reply":"2022-04-04T08:41:04.501248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nn_code_methods = df_fin['Q15'].value_counts().reset_index(name='total')\n\nfig.add_trace(go.Bar(\n     x=n_code_methods['index'], y=n_code_methods['total'], showlegend=False,\n    text =n_code_methods['total'],\n     name=\"Coding methods\"), \n     row=1, col=1)\n\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\nn_codemethod  = n_code_methods['index'].values\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=n_code_methods['total'],\n     labels=n_codemethod, pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05,0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Coding method\"),\n    row=1, col=2)\n\n\nfig.update_layout(title_text='Coding method experiences by the participants', title_x=0.5,title_y=0.97,\n                  legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.502462Z","iopub.status.idle":"2022-04-04T08:41:04.503141Z","shell.execute_reply.started":"2022-04-04T08:41:04.502944Z","shell.execute_reply":"2022-04-04T08:41:04.50297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_17\">2.17. Q16 - Which of the following machine learning frameworks do you use on a regular basis ?</font>   ","metadata":{}},{"cell_type":"code","source":"Q16_values = df_fin.loc[:,['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4',\n       'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9',\n       'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12', 'Q16_Part_13',\n       'Q16_Part_14', 'Q16_Part_15', 'Q16_Part_16', 'Q16_Part_17',\n                       'Q16_OTHER']]\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q16_values.stack().unique(), y=Q16_values.stack().value_counts().values, showlegend=False,\n    text =Q16_values.stack().value_counts().values,\n     name=\"ML framework\"), \n     row=1, col=1,)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n'''\ndf_q15_q16 = df.copy()\ndf_q15_q16 = df_q15_q16.groupby(['Q15'])[\n                                 ['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4',\n                                   'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9',\n                                   'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12', 'Q16_Part_13',\n                                   'Q16_Part_14', 'Q16_Part_15', 'Q16_Part_16', 'Q16_Part_17',\n                                                   'Q16_OTHER']\n                                 ].count().unstack().fillna(0).reset_index(name='16_counts')\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['I do not use machine learning methods', 'Under 1 year', '1-2 years'],'Beginner'))\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['2-3 years', '3-4 years', '4-5 years'],'Intermediate'))\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['5-10 years', '10-20 years', '20 or more years'],'Advanced'))\n\ndf_q15_q16 = df_q15_q16.replace({'level_0' : \n                                 { 'Q16_Part_1' : 'Scikit-learn', 'Q16_Part_2' : 'TensorFlow',\n                                 \"Q16_Part_3\" : 'Keras' ,  \"Q16_Part_4\" : 'PyTorch',     \n                                \"Q16_Part_5\" : 'Fast.ai', \"Q16_Part_6\" : 'MXNet',\n                                \"Q16_Part_7\" : ' Xgboost', \"Q16_Part_8\" :' LightGBM', \n                                \"Q16_Part_9\" : ' CatBoost',  \"Q16_Part_10\" : 'Prophet', \n                                \"Q16_Part_11\" : ' H2O 3',  \"Q16_Part_12\" : 'Caret', \n                                  \"Q16_Part_13\" : ' Tidymodels', \"Q16_Part_14\" :' JAX', \n                                  \"Q16_Part_15\" : ' PyTorch Lightning', \"Q16_Part_16\" :' Huggingface',\n                                \"Q16_Part_17\" : 'None', \"Q16_OTHER\": 'Other'\n                                 }})\n'''\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q16_values.stack().value_counts().values,\n     labels=Q16_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"ML framework\"),\n    row=1, col=2)\n\n\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Machine learning frameworks regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.504803Z","iopub.status.idle":"2022-04-04T08:41:04.505142Z","shell.execute_reply.started":"2022-04-04T08:41:04.504981Z","shell.execute_reply":"2022-04-04T08:41:04.505004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_18\">2.18. Q17 - Which of the following ML algorithms do you use on a regular basis</font>   ","metadata":{}},{"cell_type":"code","source":"Q17_values = df_fin.loc[:,['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4', 'Q12_Part_5', 'Q12_OTHER']]\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q12_values.stack().unique(), y=Q12_values.stack().value_counts().values, showlegend=False,\n    text =Q12_values.stack().value_counts().values,\n     name=\"ML framework\"), \n     row=1, col=1,)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q12_values.stack().value_counts().values,\n     labels=Q12_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"ML framework\"),\n    row=1, col=2)\n\n\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Machine learning frameworks regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.506313Z","iopub.status.idle":"2022-04-04T08:41:04.506636Z","shell.execute_reply.started":"2022-04-04T08:41:04.506451Z","shell.execute_reply":"2022-04-04T08:41:04.50649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_19\">2.19. Q18 - Which categories of computer vision methods do you use on a regular basis ? </font>   ","metadata":{}},{"cell_type":"code","source":"Q18_values = df_fin.loc[:,['Q18_Part_1', 'Q18_Part_2', 'Q18_Part_3', 'Q18_Part_4',\n       'Q18_Part_5', 'Q18_Part_6', 'Q18_OTHER']]\n\ndf_q18 = Q18_values.stack().value_counts().rename_axis('Computer Vision methods').reset_index(name='counts')\ndf_q18['Computer Vision methods'] = np.where((df_q18['Computer Vision methods'] == 'Generative Networks (GAN, VAE, etc)'),'Generative Networks',df_q18['Computer Vision methods'])\ndf_q18['Computer Vision methods'] = np.where((df_q18['Computer Vision methods'] == 'Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)'),\n                                             'Image classification methods',df_q18['Computer Vision methods'])\ndf_q18['Computer Vision methods'] = np.where((df_q18['Computer Vision methods'] == 'Image segmentation methods (U-Net, Mask R-CNN, etc)'),\n                                             'Image segmentation methods',df_q18['Computer Vision methods'])\ndf_q18['Computer Vision methods'] = np.where((df_q18['Computer Vision methods'] == 'Object detection methods (YOLOv3, RetinaNet, etc)'),\n                                             'Object detection methods',df_q18['Computer Vision methods'])\ndf_q18['Computer Vision methods'] = np.where((df_q18['Computer Vision methods'] == 'General purpose image/video tools (PIL, cv2, skimage, etc)'),\n                                             'General purpose image/video tools',df_q18['Computer Vision methods'])\n\nQ19_values = df_fin.loc[:,['Q19_Part_1', 'Q19_Part_2', 'Q19_Part_3', 'Q19_Part_4',\n       'Q19_Part_5',  'Q19_OTHER']]\n\ndf_q19 = Q19_values.stack().value_counts().rename_axis('NLP methods').reset_index(name='counts')\n\ndf_q19['NLP methods'] = np.where((df_q19['NLP methods'] == 'Word embeddings/vectors (GLoVe, fastText, word2vec)'),\n                                             'Word embeddings/vectors',df_q19['NLP methods'])\ndf_q19['NLP methods'] = np.where((df_q19['NLP methods'] == 'Transformer language models (GPT-3, BERT, XLnet, etc)'),\n                                             'Transformer language models',df_q19['NLP methods'])\ndf_q19['NLP methods'] = np.where((df_q19['NLP methods'] == 'Encoder-decorder models (seq2seq, vanilla transformers)'),\n                                             'Encoder-decorder models',df_q19['NLP methods'])\ndf_q19['NLP methods'] = np.where((df_q19['NLP methods'] == 'Contextualized embeddings (ELMo, CoVe)'),\n                                             'Contextualized embeddings',df_q19['NLP methods'])\n\ndf_q18_q19 = pd.concat([df_q18, df_q19], axis=1)\ncolumn_names =['CV methods', 'CV counts', 'NLP methods', 'NLP counts']\ndf_q18_q19.columns = column_names\n\n#blue_colors = ['#045669', '#1b7a8f', '#429eb3', '#69bed1', '#91d4e3', '#caf1fa']\n#orange_colors = ['#ad7309','#c28d2d','#d4ac63','#e6cc9c','#FFA500']\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df_q18_q19['CV methods'], y=df_q18_q19['CV counts'], name = \"CV methods\",\n                 marker_color = cust_color, text = df_q18_q19['CV counts'], textposition = \"outside\",\n))\nfig.add_trace(go.Bar(x=df_q18_q19['NLP methods'], y=-df_q18_q19['NLP counts'], name = \"NLP methods\",\n            marker_color = cust_color, text = df_q18_q19['NLP counts'], textposition = \"outside\"))\n\n\nfig.update_layout(barmode='relative',                  \n    title_text='Participants using the two of the major areas of deep learning',\n    height=500, title_x = 0.5, yaxis_title=\" \", xaxis_title=\"Methods\", \n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n)\n\nfig.update_xaxes(visible=True, categoryorder='total descending')\nfig.update_yaxes(visible=False, range=[-3500,5000])\nfig.show()\n\n\nd1 = df_fin[~df_fin['Q19_Part_1'].isnull()].index.tolist() \nd2 = df_fin[~df_fin['Q19_Part_2'].isnull()].index.tolist() \nd3 = df_fin[~df_fin['Q19_Part_3'].isnull()].index.tolist() \nd4 = df_fin[~df_fin['Q19_Part_5'].isnull()].index.tolist()\nd5 = df_fin[~df_fin['Q18_Part_1'].isnull()].index.tolist() \nd6 = df_fin[~df_fin['Q18_Part_2'].isnull()].index.tolist() \nd7 = df_fin[~df_fin['Q18_Part_3'].isnull()].index.tolist() \nd8 = df_fin[~df_fin['Q18_Part_4'].isnull()].index.tolist()\nd9 = df_fin[~df_fin['Q18_Part_5'].isnull()].index.tolist() \n\n_, (ax1, ax2) = plt.subplots(ncols=2, nrows=1, figsize=(18, 8))\nlabels = ['Word embeddings/vectors',\n 'Transformer language models',\n 'Encoder-decorder models',\n 'Contextualized embeddings',\n 'Image classification methods',\n 'Image segmentation methods',\n 'Object detection methods',\n 'General purpose image/video tools',\n 'Generative Networks']\nletters = iter(labels)\n\n\nfor n_sets, ax in zip(range(1,2), (ax1, ax2)):\n    dataset_dict1 = {\n        labels[4]: set(d5),\n    labels[5]: set(d6),\n    labels[6]: set(d7),\n    labels[7]: set(d8),\n    labels[8]: set(d9)\n    }\n    venn(dataset_dict1, fmt=\"{percentage:.1f}%\", fontsize=8, legend_loc=\"upper left\", ax=ax1)\n    ax1.title.set_text('Computer Vision methods')\n    dataset_dict2 = {\n        labels[0]: set(d1),\n    labels[1]: set(d2),\n    labels[2]: set(d3),\n    labels[3]: set(d4),\n    }\n    venn(dataset_dict2, fmt=\"{percentage:.1f}%\", fontsize=8, legend_loc=\"upper right\", ax=ax2)\n    ax2.title.set_text('Natural Language Processing methods')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.507735Z","iopub.status.idle":"2022-04-04T08:41:04.508032Z","shell.execute_reply.started":"2022-04-04T08:41:04.507875Z","shell.execute_reply":"2022-04-04T08:41:04.507897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_20\">2.20. Q19 - Which of the following Natural Language Processing (NLP) methods do you use on a regular basis ? </font>   ","metadata":{}},{"cell_type":"code","source":"# Creating subplots this time: (Hidden Input)\nfig, axis = plt.subplots(6, 1, figsize=(20, 50))\n\n# Declaring all the values and their counts:\n# For Q14:\nname14 = ['Matplotlib','Seaborn','Plotly','GGplot','None','Shiny','Geoplotlib','Bokeh','D3 js','Other','Folium','Altair',]\nval14 = [17595,12586,5778,5100,3479,1322,1148,1050,978,776,716,309]\n\n# For Q15:\nname15 = ['<1 year','1-2 years','No ML usage','2-3 years','3-4 years','5-10 years','4-5 years','10-20 years','20+ years']\nval15 = [9163,4675,3889,2305,1171,1033,945,362,211]\n\n# For Q16:\nname16 = ['Scikit-Learn','TensorFlow','Keras','PyTorch','XGBoost','LightGBM','None','CatBoost','Higgingface','Pytorch Lightning','Caret',\n          'Fast.ai','Prophet','Tidymodels','H20 3','Other','MXNet','JAX']\nval16 = [13987,9371,7975,6088,5974,2635,1916,1512,1122,1060,1009,824,800,678,488,439,252,190]\n\n# For Q17:\nname17 = ['Linear Models','Tree Models','CNN','Dense Neural Net','Bayesian Approch','RNN','Transformer Networks','None','GAN','Evolutionary Approaches']\nval17 = [13952,11863,7410,4468,4392,4228,2273,1470,1353,963]\n\n# For Q18:\nname18 = ['VGG/Inception/ResNet','Image Segmentation Method','Object Detection Method','General Purpose Img/Vid Tools','GAN','None','Other']\nval18 = [4373,2740,2716,2662,1492,1439,119]\n\n# For Q19:\nname19 = ['Word Embeddings/Vectors','Transformer Lang Tools','Encoder-Decoder Models','None','Contextualized Embeddings']\nval19 = [2643,2351,2023,1331,748]\n\n##### Visualization Begins Here #####\n\n# Visualizing using a barh Q14:\n\naxis[0].barh(width=val14, y=name14, height=0.7, color = cust_color, alpha=0.8)\n\n##################### For the Visualization Tool ###################################\ns1 = name14\nx1 = [18695,13586,6578,6000,4279,2122,2248,1850,1578,1376,1416,909]\ny1 = [0,1,2,3,4,5,6,7,8,9,10,11]\n\n\nfor i in range(12):\n    axis[0].text(s = s1[i], x=x1[i], y=y1[i] ,font = 'Comic Sans MS', fontsize=12,va='center',ha='right',alpha=0.8)\n\naxis[0].title.set_text(\"Favourite Visualization Module\")\naxis[0].title.set_color(\"#189AB4\")\naxis[0].axis('off')\naxis[0].invert_yaxis()\n\n#################################################################################################################################\n# Visualizing using a barh Q15:\n\naxis[1].barh(width=val15, y=name15, height=0.7, color = cust_color, alpha=0.8)\n\n##################### For the ML Experience ###################################\ns2 = name15\nx2 = [9663,5275,4689,2905,1771,1633,1490,1062,811]\ny2 = [0,1,2,3,4,5,6,7,8]\n\n\nfor i in range(9):\n    axis[1].text(s = s2[i], x=x2[i], y=y2[i] ,font = 'Comic Sans MS', fontsize=12,va='center',ha='right',alpha=0.8)\n\n\naxis[1].title.set_text(\"Machine Learning Usage\")\naxis[1].title.set_color(\"#189AB4\")\naxis[1].axis('off')\naxis[1].invert_yaxis()\n\n#################################################################################################################################\n# Visualizing using a barh Q16:\n\naxis[2].barh(width=val16, y=name16, height=0.7, color = cust_color, alpha=0.8)\n\n##################### For the Fav SKLearn Tool ###################################\ns3 = name16\nx3 = [14987,10271,8475,6788,6674,3435,2416,2312,2122,2480,1509,1424,1450,1648,988,939,852,490]\ny3 = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17]\n\n\nfor i in range(18):\n    axis[2].text(s = s3[i], x=x3[i], y=y3[i] ,font = 'Comic Sans MS', fontsize=12,va='center',ha='right',alpha=0.8)\n\n\naxis[2].title.set_text(\"Popular ML Frameworks\")\naxis[2].title.set_color(\"#189AB4\")\naxis[2].axis('off')\naxis[2].invert_yaxis()\n\n#################################################################################################################################\n# Visualizing using a barh Q17:\n\naxis[3].barh(width=val17, y=name17, height=0.7, color = cust_color, alpha=0.8)\n\n##################### For the ML Algorithms ###################################\ns3 = name17\nx3 = [15152,12863,7810,5868,5902,4628,4073,1970,1753,2963]\ny3 = [0,1,2,3,4,5,6,7,8,9]\n\n\nfor i in range(10):\n    axis[3].text(s = s3[i], x=x3[i], y=y3[i] ,font = 'Comic Sans MS', fontsize=12,va='center',ha='right',alpha=0.8)\n\n\naxis[3].title.set_text(\"Most Popular ML Algorithms\")\naxis[3].title.set_color(\"#189AB4\")\naxis[3].axis('off')\naxis[3].invert_yaxis()\n\n#################################################################################################################################\n# Visualizing using a barh Q18:\n\naxis[4].barh(width=val18, y=name18, height=0.7, color = cust_color, alpha=0.8)\n\n##################### For the Computer Vision ###################################\ns4 = name18\nx4 = [4973,3490,3346,3450,1632,1579,269]\ny4 = [0,1,2,3,4,5,6]\n\n\nfor i in range(7):\n    axis[4].text(s = s4[i], x=x4[i], y=y4[i] ,font = 'Comic Sans MS', fontsize=12,va='center',ha='right',alpha=0.8)\n\n\naxis[4].title.set_text(\"Popular Computer Vision Tools\")\naxis[4].title.set_color(\"#189AB4\")\naxis[4].axis('off')\naxis[4].invert_yaxis()\n\n#################################################################################################################################\n# Visualizing using a barh Q19:\n\naxis[5].barh(width=val19, y=name19, height=0.7, color = cust_color, alpha=0.8)\n\n##################### For the NLP Methods ###################################\ns5 = name19\nx5 = [3043,2721,2423,1431,1188]\ny5 = [0,1,2,3,4]\n\n\nfor i in range(5):\n    axis[5].text(s = s5[i], x=x5[i], y=y5[i] ,font = 'Comic Sans MS', fontsize=12,va='center',ha='right',alpha=0.8)\n\n\naxis[5].title.set_text(\"Popular NLP Methods\")\naxis[5].title.set_color(\"#189AB4\")\naxis[5].axis('off')\naxis[5].invert_yaxis()\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.509191Z","iopub.status.idle":"2022-04-04T08:41:04.509544Z","shell.execute_reply.started":"2022-04-04T08:41:04.509347Z","shell.execute_reply":"2022-04-04T08:41:04.509369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_21\">2.21. Q20 - In what industry is your current enployer/contract ?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q20.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.510801Z","iopub.status.idle":"2022-04-04T08:41:04.511354Z","shell.execute_reply.started":"2022-04-04T08:41:04.511151Z","shell.execute_reply":"2022-04-04T08:41:04.511178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_q2_q20 = df_fin.copy()\ndf_q2_q20['Q2'] = np.where(((df_q2_q20['Q2'] != 'Man') & (df_q2_q20['Q2'] != 'Woman')),'Other/Undisclosed genders',df_q2_q20['Q2'])\ndf_q2_q20 = pd.crosstab(df_q2_q20['Q20'], df_q2_q20['Q2']).reset_index()\n\nfig = go.Figure()\nfig.add_trace(go.Bar(x=df_q2_q20['Q20'], y=df_q2_q20['Man'], name = \"Man\",\n                 marker_color = '#0033FF', text = df_q2_q20['Man'], textposition = \"outside\",\n))\nfig.add_trace(go.Bar(x=df_q2_q20['Q20'], y=-df_q2_q20['Woman'], name = \"Woman\",\n            marker_color = '#0099FF', text = df_q2_q20['Woman'], textposition = \"outside\"))\nfig.add_trace(go.Bar(x=df_q2_q20['Q20'], y=-df_q2_q20['Other/Undisclosed genders'], name = \"Other/Undisclosed genders\",\n            marker_color = '#00CCCC', text = df_q2_q20['Other/Undisclosed genders'], textposition = \"outside\"))\n\nfig.update_layout(\n    shapes=[\n        dict(type=\"rect\", xref=\"x\", yref=\"y\",\n            x0=-0.5, y0=-1200, x1=2.5, y1=3800, line_width=3),\n    ])\n\nfig.add_annotation(\n        x=2.5,\n        y=2600,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"These top three industries cover more than 50% of the participants. <br> Consequently,these sectors seem to use data science more in their fields.\",\n        showarrow=True,\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=11,\n            color=\"#222A2A\"\n            ),\n        align=\"center\",\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax=120,\n        ay=-30,\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\n\nfig.update_layout(barmode='relative',                  \n    title_text='Gender Ratio based on their current industry',\n    height=500, title_x = 0.45, yaxis_title=\" \", xaxis_title=\"Industries\", \n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5),\n                  margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=70,\n                        ),\n                  \n)\n\nfig.update_xaxes(visible=True, categoryorder='total descending')\nfig.update_yaxes(visible=False, range=[-1500,4000])\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.51255Z","iopub.status.idle":"2022-04-04T08:41:04.51305Z","shell.execute_reply.started":"2022-04-04T08:41:04.512863Z","shell.execute_reply":"2022-04-04T08:41:04.512887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q20 = df_fin['Q20'].value_counts().tolist()\n\n\nQ20_labels = ['Hospitality/\\nEntertainment/\\nSports','Military/\\nSecurity/\\nDefense','Online Business/\\nInternet-based\\n Sales','Non-profit/Service','Shipping/\\nTransportation','Broadcasting/\\nCommunications',\n'Marketing/CRM','Insurance/\\nRisk Assessment','Retail/Sales','Energy/Mining','Online Service/\\nInternet-based\\n Services','Government/Public Service','Medical/Pharmaceutical',\n'Manufacturing/Fabrication','Other','Accounting/Finance','Academics/Education','Computers/Technology']\n\n# compute circle positions:\ncircles = circlify.circlify(\n    Q20, \n    show_enclosure=False, \n    target_enclosure=circlify.Circle(x=0, y=0, r=4)\n)\n\n# Create just a figure and only one subplot\nfig, ax = plt.subplots(figsize=(30,30))\n\n# Remove axes\nax.axis('off')\n\n# Find axis boundaries\nlim = max(\n    max(\n        abs(circle.x) + circle.r,\n        abs(circle.y) + circle.r,\n    )\n    for circle in circles\n)\nplt.xlim(-lim, lim)\nplt.ylim(-lim, lim)\n\n# list of labels\nlabels = Q20_labels\n\n# print circles\nfor circle, label in zip(circles, labels):\n    x, y, r = circle\n    if label in ['Computers/Technology','Academics/Education','Accounting/Finance']:\n        ax.add_patch(plt.Circle((x, y), r*0.95, alpha=0.6, facecolor=\"#0000CC\", edgecolor=\"#009999\"))\n        plt.annotate(label, (x,y ) ,va='center', ha='center',  fontsize=30)\n    else:\n        ax.add_patch(plt.Circle((x, y), r*0.95, alpha=0.5, facecolor='#0066FF', edgecolor='#000066'))\n        plt.annotate(label, (x,y ) ,va='center', ha='center',  fontsize=15)\n\nplt.title(\"Type of Industry\",font='Comic Sans MS', fontsize=80, color='#0000CC')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.51424Z","iopub.status.idle":"2022-04-04T08:41:04.514997Z","shell.execute_reply.started":"2022-04-04T08:41:04.514799Z","shell.execute_reply":"2022-04-04T08:41:04.514826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_22\">2.22. Q21 - What is the size of the company where you are employed ?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q21.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.516459Z","iopub.status.idle":"2022-04-04T08:41:04.516783Z","shell.execute_reply.started":"2022-04-04T08:41:04.516626Z","shell.execute_reply":"2022-04-04T08:41:04.516648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig,ax1 = plt.subplots(1,1,figsize=(24,8))\nsns.barplot(x=df_fin[\"Q21\"].value_counts().index,y=df_fin[\"Q21\"].value_counts().values,color=\"blue\",label=\"Number of employees\")\nfor index,value in enumerate (df_fin[\"Q21\"].value_counts().values):\n    ax1.annotate(value,xy=(index,value+100),ha=\"center\",va=\"center\",fontsize=20)\nsns.lineplot(x=df_fin[\"Q21\"].value_counts().index,y=df_fin[\"Q1\"].value_counts().values.mean(),label=\"Number of employees_mean\")\nplt.legend(fontsize=26)\nplt.xlabel(\"Number of employees_category\",color=\"blue\",fontsize=20)\nplt.ylabel(\"Number of employees_count\",color=\"blue\",fontsize=20)\nplt.title(\"Number of employees in 2021\",color=\"blue\",fontsize=30)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.517748Z","iopub.status.idle":"2022-04-04T08:41:04.518225Z","shell.execute_reply.started":"2022-04-04T08:41:04.518041Z","shell.execute_reply":"2022-04-04T08:41:04.518063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_23\">2.23. Q22 - Approximately how many individuals are responsible for data science workloads at your place of business?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q22.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.51939Z","iopub.status.idle":"2022-04-04T08:41:04.519698Z","shell.execute_reply.started":"2022-04-04T08:41:04.519554Z","shell.execute_reply":"2022-04-04T08:41:04.51957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.histogram(df_fin, x = 'Q22', title='Number of employees responsible for data science workloads at your company')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.520249Z","iopub.status.idle":"2022-04-04T08:41:04.520917Z","shell.execute_reply.started":"2022-04-04T08:41:04.520693Z","shell.execute_reply":"2022-04-04T08:41:04.520718Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_2_24\">2.24. Q23 - Does your current employer incorporate machine learning methods into their business?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q23.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.522171Z","iopub.status.idle":"2022-04-04T08:41:04.522464Z","shell.execute_reply.started":"2022-04-04T08:41:04.522306Z","shell.execute_reply":"2022-04-04T08:41:04.522323Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_fin_education = df_fin.Q23.value_counts()\nplt.style.use('seaborn-darkgrid')\nplt.figure(figsize=(7,5),edgecolor='#FFFFFF')\ndf_fin_education.plot(kind='pie', colors=cust_color)\nplt.title(\"ML methods used by employers of the world in 2021\",fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.52421Z","iopub.status.idle":"2022-04-04T08:41:04.524558Z","shell.execute_reply.started":"2022-04-04T08:41:04.524368Z","shell.execute_reply":"2022-04-04T08:41:04.524389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_25\">2.25. Q24 - Select any activities that make up an important part of your role at work</font>   ","metadata":{}},{"cell_type":"code","source":"Q17_values = df_fin.loc[:,['Q17_Part_1', 'Q17_Part_2', 'Q17_Part_3', 'Q17_Part_4',\n       'Q17_Part_5', 'Q17_Part_6', 'Q17_Part_7', 'Q17_OTHER']]\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q17_values.stack().unique(), y=Q17_values.stack().value_counts().values, showlegend=False,\n    text =Q17_values.stack().value_counts().values,\n     name=\"Important part of your role\"), \n     row=1, col=1,)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n'''\ndf_q15_q16 = df.copy()\ndf_q15_q16 = df_q15_q16.groupby(['Q15'])[\n                                 ['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4',\n                                   'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9',\n                                   'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12', 'Q16_Part_13',\n                                   'Q16_Part_14', 'Q16_Part_15', 'Q16_Part_16', 'Q16_Part_17',\n                                                   'Q16_OTHER']\n                                 ].count().unstack().fillna(0).reset_index(name='16_counts')\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['I do not use machine learning methods', 'Under 1 year', '1-2 years'],'Beginner'))\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['2-3 years', '3-4 years', '4-5 years'],'Intermediate'))\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['5-10 years', '10-20 years', '20 or more years'],'Advanced'))\n\ndf_q15_q16 = df_q15_q16.replace({'level_0' : \n                                 { 'Q16_Part_1' : 'Scikit-learn', 'Q16_Part_2' : 'TensorFlow',\n                                 \"Q16_Part_3\" : 'Keras' ,  \"Q16_Part_4\" : 'PyTorch',     \n                                \"Q16_Part_5\" : 'Fast.ai', \"Q16_Part_6\" : 'MXNet',\n                                \"Q16_Part_7\" : ' Xgboost', \"Q16_Part_8\" :' LightGBM', \n                                \"Q16_Part_9\" : ' CatBoost',  \"Q16_Part_10\" : 'Prophet', \n                                \"Q16_Part_11\" : ' H2O 3',  \"Q16_Part_12\" : 'Caret', \n                                  \"Q16_Part_13\" : ' Tidymodels', \"Q16_Part_14\" :' JAX', \n                                  \"Q16_Part_15\" : ' PyTorch Lightning', \"Q16_Part_16\" :' Huggingface',\n                                \"Q16_Part_17\" : 'None', \"Q16_OTHER\": 'Other'\n                                 }})\n'''\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q17_values.stack().value_counts().values,\n     labels=Q17_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"ML framework\"),\n    row=1, col=2)\n\n\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Activities that make up an important part of your role at work', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.525596Z","iopub.status.idle":"2022-04-04T08:41:04.525902Z","shell.execute_reply.started":"2022-04-04T08:41:04.525737Z","shell.execute_reply":"2022-04-04T08:41:04.525766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_26\">2.26. Q25 - What is your current yearly compensation?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q25.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.526839Z","iopub.status.idle":"2022-04-04T08:41:04.527113Z","shell.execute_reply.started":"2022-04-04T08:41:04.526969Z","shell.execute_reply":"2022-04-04T08:41:04.526985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize= (10, 10))\n# Create a word cloud \n\n#Creating the text variable\ntext = \" \".join(job for job in df_fin['Q25'])\n# Creating word_cloud with text as argument in .generate() method\nword_cloud = WordCloud(collocations = True, background_color = 'white').generate(text)\n# Display the generated Word Cloud\nplt.imshow(word_cloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.528911Z","iopub.status.idle":"2022-04-04T08:41:04.52935Z","shell.execute_reply.started":"2022-04-04T08:41:04.529114Z","shell.execute_reply":"2022-04-04T08:41:04.529139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> \"funny\" to see that this question is not answered in a very high number of cases !  The wordcloud can't even represent the other answers. I think that this caption is very expressive, even if we don't see the other alternatives.","metadata":{}},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_27\">2.27. Q26 - Approximately how much money have you (or your team) spent on machine learning and/or cloud computing services at home (or at work) in the past 5 years?</font>   ","metadata":{}},{"cell_type":"code","source":"df_fin.Q26.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.530763Z","iopub.status.idle":"2022-04-04T08:41:04.531214Z","shell.execute_reply.started":"2022-04-04T08:41:04.530975Z","shell.execute_reply":"2022-04-04T08:41:04.531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Order by alphabetical rules\nf1=df_fin['Q26'].value_counts().reset_index()\nf1=f1.sort_values(by='index')\n\n#Create % ratio for the values\nY=(f1['Q26']/f1['Q26'].sum())*100\n\n#cheese slices out of the circle\nmyexplode=(0.25,0.25,0.25,0.15,0.10,0.5,0.2)\n\n#colors={'#9b2226','#ae2012','#bb3e03','#ca6702','#ee9b00','#e9d8a6','#94d2bd',\n#'#0a9396','#005f73','#001219','#99d98c'}\nplt.style.use(\"fivethirtyeight\")\nmylabel=f1['index']\nplt.pie(Y,labels=mylabel,autopct=\"%1.1f%%\",startangle=15,explode=myexplode,shadow=True,colors=cust_color)\nplt.axis(\"equal\")\n\nplt.title(\"Money spent on ML / cloud computing services in the last 5 years (in%) ?\")\nplt.legend(mylabel)\nplt.gcf().set_size_inches(15,8)\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.532509Z","iopub.status.idle":"2022-04-04T08:41:04.532945Z","shell.execute_reply.started":"2022-04-04T08:41:04.532709Z","shell.execute_reply":"2022-04-04T08:41:04.532734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_28\">2.28. Q27 - Which of the following cloud computing platforms do you use on a regular basis?</font>   ","metadata":{}},{"cell_type":"markdown","source":"> small change here. Instead of the \"traditional\" 'Q27_Part_2', we have 'Q27_A_Part_2'","metadata":{}},{"cell_type":"code","source":"Q27_values = df_fin.loc[:,['Q27_A_Part_1', 'Q27_A_Part_2', 'Q27_A_Part_3', 'Q27_A_Part_4',\n       'Q27_A_Part_5', 'Q27_A_Part_6', 'Q27_A_Part_7', 'Q27_A_Part_8', 'Q27_A_Part_9',\n       'Q27_A_Part_10', 'Q27_A_Part_11', 'Q27_A_OTHER']]\n\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q27_values.stack().unique(), y=Q27_values.stack().value_counts().values, showlegend=False,\n    text =Q27_values.stack().value_counts().values,\n     name=\"Cloud computing platforms\"), \n     row=1, col=1)\n#fig.update_layout(uniformtext_minsize=8)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q27_values.stack().value_counts().values,\n     labels=Q27_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Cloud computing platforms\"),\n    row=1, col=2)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.53426Z","iopub.status.idle":"2022-04-04T08:41:04.534723Z","shell.execute_reply.started":"2022-04-04T08:41:04.534463Z","shell.execute_reply":"2022-04-04T08:41:04.534507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_29\">2.29. Q28 - Of the cloud platforms that you are familiar with, which has the best developer experience (most enjoyable to use)?</font> ","metadata":{}},{"cell_type":"code","source":"df_fin.Q28.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.53646Z","iopub.status.idle":"2022-04-04T08:41:04.536776Z","shell.execute_reply.started":"2022-04-04T08:41:04.53663Z","shell.execute_reply":"2022-04-04T08:41:04.536647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.treemap(df_fin, path=['Q28'], color='Q28')\nfig.update_layout(margin = dict(t=60, l=15, r=15, b=15),\n                  title_text=\"<b>Cloud platforms providing the best user experience</b>\",\n                  title_x=0.5,\n                  font=dict(family=\"serif\", size=20))\nfig.show()\n\n#NOTE : additional info when we the mouse pass over each category\n\n\n\n#NOTE : cust_color can t be used as we should include too many colors in the list. We prefer to use the values by default. ","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.537731Z","iopub.status.idle":"2022-04-04T08:41:04.538271Z","shell.execute_reply.started":"2022-04-04T08:41:04.538092Z","shell.execute_reply":"2022-04-04T08:41:04.538113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_30\">2.30. Q29 - Do you use any of the following cloud computing products on a regular basis?</font> ","metadata":{}},{"cell_type":"code","source":"Q29_values = df_fin.loc[:,['Q29_A_Part_1', 'Q29_A_Part_2', 'Q29_A_Part_3', 'Q29_A_Part_4', 'Q29_A_OTHER']]\n\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q27_values.stack().unique(), y=Q27_values.stack().value_counts().values, showlegend=False,\n    text =Q27_values.stack().value_counts().values,\n     name=\"Cloud computing products used on a regular basis\"), \n     row=1, col=1)\n#fig.update_layout(uniformtext_minsize=8)\nfig.update_traces(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q27_values.stack().value_counts().values,\n     labels=Q27_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Cloud computing products used on a regular basis\"),\n    row=1, col=2)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.539191Z","iopub.status.idle":"2022-04-04T08:41:04.53981Z","shell.execute_reply.started":"2022-04-04T08:41:04.539574Z","shell.execute_reply":"2022-04-04T08:41:04.539602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_31\">2.31. Q30 - Do you use any of the following data storage products on a regular basis?</font> ","metadata":{}},{"cell_type":"code","source":"Q30_values = df_fin.loc[:,['Q30_A_Part_1', 'Q30_A_Part_2', 'Q30_A_Part_3', 'Q30_A_Part_4', 'Q30_A_Part_5','Q30_A_Part_6','Q30_A_Part_7', 'Q30_A_OTHER']]\n\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\n\nfig.add_trace(go.Bar(\n     x=Q30_values.stack().unique(), y=Q30_values.stack().value_counts().values, showlegend=False,\n    text =Q30_values.stack().value_counts().values,\n     name=\"Data storage product used on a regular basis\"), \n     row=1, col=1)\n#fig.update_layout(uniformtext_minsize=8)\nfig.update_traces(marker_color=cust_color, marker_line_color=cust_color,  marker_line_width=1.5, opacity=0.6)\n\n# pull is given as a fraction of the pie radius\nfig.add_trace(go.Pie(\n     values=Q27_values.stack().value_counts().values,\n     labels=Q27_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n    marker_colors=cust_color, opacity=0.6,\n     name=\"Data storage product used on a regular basis\"),\n    #row=1, col=2\n             )","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.540996Z","iopub.status.idle":"2022-04-04T08:41:04.54129Z","shell.execute_reply.started":"2022-04-04T08:41:04.54114Z","shell.execute_reply":"2022-04-04T08:41:04.541155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_32\">2.32. Q31 - Do you use any of the following managed machine learning products on a regular basis?</font> ","metadata":{}},{"cell_type":"code","source":"#df_fin['Q31_A_Part_1'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.542151Z","iopub.status.idle":"2022-04-04T08:41:04.542464Z","shell.execute_reply.started":"2022-04-04T08:41:04.542294Z","shell.execute_reply":"2022-04-04T08:41:04.542315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Q31_values = df_fin.loc[:,['Q31_A_Part_1', 'Q31_A_Part_2', 'Q31_A_Part_3', 'Q31_A_Part_4', 'Q31_A_Part_5', 'Q31_A_Part_6', 'Q31_A_Part_7', 'Q31_A_Part_8', 'Q31_A_Part_9', 'Q31_A_OTHER']]\n\n#fig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"pie\"}]])\nfig = px.bar(\n    x=Q31_values.stack().unique(),\n    y=Q31_values.stack().value_counts().values,\n#    showlegend=False,\n    text =Q31_values.stack().value_counts().values,\n#    name=\"Q31\"\n)\n\n#fig(textposition='outside', marker_color=cust_color, marker_line_color='rgb(8,48,107)',  marker_line_width=1.5, opacity=0.6)\n\n'''\ndf_q15_q16 = df.copy()\ndf_q15_q16 = df_q15_q16.groupby(['Q15'])[\n                                 ['Q16_Part_1', 'Q16_Part_2', 'Q16_Part_3', 'Q16_Part_4',\n                                   'Q16_Part_5', 'Q16_Part_6', 'Q16_Part_7', 'Q16_Part_8', 'Q16_Part_9',\n                                   'Q16_Part_10', 'Q16_Part_11', 'Q16_Part_12', 'Q16_Part_13',\n                                   'Q16_Part_14', 'Q16_Part_15', 'Q16_Part_16', 'Q16_Part_17',\n                                                   'Q16_OTHER']\n                                 ].count().unstack().fillna(0).reset_index(name='16_counts')\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['I do not use machine learning methods', 'Under 1 year', '1-2 years'],'Beginner'))\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['2-3 years', '3-4 years', '4-5 years'],'Intermediate'))\ndf_q15_q16['Q15'] = df_q15_q16['Q15'].replace(dict.fromkeys(['5-10 years', '10-20 years', '20 or more years'],'Advanced'))\n\ndf_q15_q16 = df_q15_q16.replace({'level_0' : \n                                 { 'Q16_Part_1' : 'Scikit-learn', 'Q16_Part_2' : 'TensorFlow',\n                                 \"Q16_Part_3\" : 'Keras' ,  \"Q16_Part_4\" : 'PyTorch',     \n                                \"Q16_Part_5\" : 'Fast.ai', \"Q16_Part_6\" : 'MXNet',\n                                \"Q16_Part_7\" : ' Xgboost', \"Q16_Part_8\" :' LightGBM', \n                                \"Q16_Part_9\" : ' CatBoost',  \"Q16_Part_10\" : 'Prophet', \n                                \"Q16_Part_11\" : ' H2O 3',  \"Q16_Part_12\" : 'Caret', \n                                  \"Q16_Part_13\" : ' Tidymodels', \"Q16_Part_14\" :' JAX', \n                                  \"Q16_Part_15\" : ' PyTorch Lightning', \"Q16_Part_16\" :' Huggingface',\n                                \"Q16_Part_17\" : 'None', \"Q16_OTHER\": 'Other'\n                                 }})\n'''\n\n# pull is given as a fraction of the pie radius\n#fig.add_trace(go.Pie(\n#     values=Q16_values.stack().value_counts().values,\n#     labels=Q16_values.stack().unique(), pull=[0.08, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.05], hole=.3, \n#    marker_colors=cust_color, opacity=0.6,\n#     name=\"ML framework\"),\n#    row=1, col=2)\n\n\n#fig.update_traces(opacity=0.6)\n\nfig.update_layout(title_text='Machine learning frameworks regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.544059Z","iopub.status.idle":"2022-04-04T08:41:04.544343Z","shell.execute_reply.started":"2022-04-04T08:41:04.544194Z","shell.execute_reply":"2022-04-04T08:41:04.544209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_33\">2.33. Q32 - Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?</font> ","metadata":{}},{"cell_type":"code","source":"Q32_values = df_fin.loc[:,['Q32_A_Part_1', 'Q32_A_Part_2', 'Q32_A_Part_3', 'Q32_A_Part_4', 'Q32_A_Part_5', 'Q32_A_Part_6', 'Q32_A_Part_7', 'Q32_A_Part_8', 'Q32_A_Part_9','Q32_A_Part_10','Q32_A_Part_11','Q32_A_Part_12','Q32_A_Part_13','Q32_A_Part_14','Q32_A_Part_15','Q32_A_Part_16','Q32_A_Part_17','Q32_A_Part_18','Q32_A_Part_19','Q32_A_Part_20', 'Q32_A_OTHER']]\n\nfig = px.bar(\n    x=Q32_values.stack().unique(),\n    y=Q32_values.stack().value_counts().values,\n    text =Q32_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Big data products regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.545412Z","iopub.status.idle":"2022-04-04T08:41:04.545784Z","shell.execute_reply.started":"2022-04-04T08:41:04.545622Z","shell.execute_reply":"2022-04-04T08:41:04.54564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_34\">2.34. Q33 - Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?</font> ","metadata":{}},{"cell_type":"code","source":"df_fin.Q33.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.546749Z","iopub.status.idle":"2022-04-04T08:41:04.547267Z","shell.execute_reply.started":"2022-04-04T08:41:04.547088Z","shell.execute_reply":"2022-04-04T08:41:04.547108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_q33 = df_fin['Q33'].value_counts()\n\nfig, ax = plt.subplots(1,1, figsize=(12, 6))\nax.bar(data_q33.index, data_q33, width=0.55, \n       edgecolor='darkgray', color=sns.color_palette(\"crest\", 7),\n       linewidth=0.7)\n\nfor i in data_q33.index:\n    ax.annotate(f\"{data_q33[i]}\", \n                   xy=(i, data_q33[i] + 300),\n                   va = 'center', ha='center',fontweight='light', fontfamily='serif',\n                   color='#4a4a4a')\n\n\nfor s in ['top', 'left', 'right']:\n    ax.spines[s].set_visible(False)\n\nax.set_xticklabels(data_q33.index, fontfamily='serif', rotation=90)\nfig.text(0.09, 0.95, 'Education Distribution', fontsize=15, fontweight='bold', fontfamily='serif')    \nax.grid(axis='y', linestyle='-', alpha=0.4)    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.548125Z","iopub.status.idle":"2022-04-04T08:41:04.548677Z","shell.execute_reply.started":"2022-04-04T08:41:04.548497Z","shell.execute_reply":"2022-04-04T08:41:04.548523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_35\">2.35. Q34 - Which of the following business intelligence tools do you use on a regular basis?</font> ","metadata":{}},{"cell_type":"code","source":"Q34_values = df_fin.loc[:,['Q34_A_Part_1', 'Q34_A_Part_2', 'Q34_A_Part_3', 'Q34_A_Part_4', 'Q34_A_Part_5', 'Q34_A_Part_6', 'Q34_A_Part_7', 'Q34_A_Part_8', 'Q34_A_Part_9','Q34_A_Part_10','Q34_A_Part_11','Q34_A_Part_12','Q34_A_Part_13','Q34_A_Part_14','Q34_A_Part_15','Q34_A_Part_16', 'Q34_A_OTHER']]\n\nfig = px.bar(\n    x=Q34_values.stack().unique(),\n    y=Q34_values.stack().value_counts().values,\n    text =Q34_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Business Intelligence tools regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.54963Z","iopub.status.idle":"2022-04-04T08:41:04.5499Z","shell.execute_reply.started":"2022-04-04T08:41:04.54976Z","shell.execute_reply":"2022-04-04T08:41:04.549776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_36\">2.36. Q35 - Which of the following business intelligence tools do you use most often? </font> ","metadata":{}},{"cell_type":"code","source":"df_fin.Q35.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.550799Z","iopub.status.idle":"2022-04-04T08:41:04.55108Z","shell.execute_reply.started":"2022-04-04T08:41:04.550934Z","shell.execute_reply":"2022-04-04T08:41:04.55095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Simple bar\ndf_fin_35 = df_fin.Q35.value_counts()\nplt.style.use('seaborn-darkgrid')\nplt.figure(figsize=(7,5),edgecolor='#FFFFFF')\ndf_fin_35.plot(kind='bar')\nplt.title(\"Gender\",fontweight='bold')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.551808Z","iopub.status.idle":"2022-04-04T08:41:04.552085Z","shell.execute_reply.started":"2022-04-04T08:41:04.551941Z","shell.execute_reply":"2022-04-04T08:41:04.551956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_37\">2.37. Q36 - Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis? </font> ","metadata":{}},{"cell_type":"code","source":"Q36_values = df_fin.loc[:,['Q36_A_Part_1', 'Q36_A_Part_2', 'Q36_A_Part_3', 'Q36_A_Part_4', 'Q36_A_Part_5', 'Q36_A_Part_6', 'Q36_A_Part_7', 'Q36_A_OTHER']]\n\nfig = px.bar(\n    x=Q36_values.stack().unique(),\n    y=Q36_values.stack().value_counts().values,\n    text =Q36_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Automated machine learning tools regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.553301Z","iopub.status.idle":"2022-04-04T08:41:04.553629Z","shell.execute_reply.started":"2022-04-04T08:41:04.553439Z","shell.execute_reply":"2022-04-04T08:41:04.55346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_38\">2.38. Q37 - Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis? </font> ","metadata":{}},{"cell_type":"code","source":"Q37_values = df_fin.loc[:,['Q37_A_Part_1', 'Q37_A_Part_2', 'Q37_A_Part_3', 'Q37_A_Part_4', 'Q37_A_Part_5', 'Q37_A_Part_6', 'Q37_A_Part_7', 'Q37_A_OTHER']]\n\nfig = px.bar(\n    x=Q37_values.stack().unique(),\n    y=Q37_values.stack().value_counts().values,\n    text =Q37_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Automated machine learning tools regularly used by participants', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.555148Z","iopub.status.idle":"2022-04-04T08:41:04.555494Z","shell.execute_reply.started":"2022-04-04T08:41:04.555314Z","shell.execute_reply":"2022-04-04T08:41:04.555335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_39\">2.39. Q38 - Do you use any tools to help manage machine learning experiments?</font> ","metadata":{}},{"cell_type":"code","source":"Q38_values = df_fin.loc[:,['Q38_A_Part_1', 'Q38_A_Part_2', 'Q38_A_Part_3', 'Q38_A_Part_4', 'Q38_A_Part_5', 'Q38_A_Part_6', 'Q38_A_Part_7','Q38_A_Part_8','Q38_A_Part_9','Q38_A_Part_10','Q38_A_Part_11', 'Q38_A_OTHER']]\n\nfig = px.bar(\n    x=Q38_values.stack().unique(),\n    y=Q38_values.stack().value_counts().values,\n    text =Q38_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Which tools are mainly used to help manage machine learning experiment ?', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.55639Z","iopub.status.idle":"2022-04-04T08:41:04.556752Z","shell.execute_reply.started":"2022-04-04T08:41:04.556574Z","shell.execute_reply":"2022-04-04T08:41:04.556604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_40\">2.40. Q39 - Where do you publicly share or deploy your data analysis or machine learning applications?</font> ","metadata":{}},{"cell_type":"code","source":"Q39_values = df_fin.loc[:,['Q39_Part_1', 'Q39_Part_2', 'Q39_Part_3', 'Q39_Part_4', 'Q39_Part_5', 'Q39_Part_6', 'Q39_Part_7','Q39_Part_8','Q39_Part_9','Q39_OTHER']]\n\nfig = px.bar(\n    x=Q39_values.stack().unique(),\n    y=Q39_values.stack().value_counts().values,\n    text =Q39_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Where do you deploy your data analysis / ML application ?', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.55786Z","iopub.status.idle":"2022-04-04T08:41:04.55814Z","shell.execute_reply.started":"2022-04-04T08:41:04.557994Z","shell.execute_reply":"2022-04-04T08:41:04.558011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_41\">2.41. Q40 - On which platforms have you begun or completed data science courses?</font> ","metadata":{}},{"cell_type":"code","source":"Q40_values = df_fin.loc[:,['Q40_Part_1', 'Q40_Part_2', 'Q40_Part_3', 'Q40_Part_4', 'Q40_Part_5', 'Q40_Part_6', 'Q40_Part_7','Q40_Part_8','Q40_Part_9','Q40_Part_10','Q40_Part_11','Q40_OTHER']]\n\nfig = px.bar(\n    x=Q39_values.stack().unique(),\n    y=Q39_values.stack().value_counts().values,\n    text =Q39_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Where did you start your data science courses ?', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.559435Z","iopub.status.idle":"2022-04-04T08:41:04.559753Z","shell.execute_reply.started":"2022-04-04T08:41:04.559604Z","shell.execute_reply":"2022-04-04T08:41:04.559621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_42\">2.42. Q41 - What is the primary tool that you use at work or school to analyze data?</font> ","metadata":{}},{"cell_type":"code","source":"df_fin.Q41.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.560564Z","iopub.status.idle":"2022-04-04T08:41:04.560845Z","shell.execute_reply.started":"2022-04-04T08:41:04.5607Z","shell.execute_reply":"2022-04-04T08:41:04.560715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_q41 = df_fin['Q41'].value_counts()\n\nfig, ax = plt.subplots(1,1, figsize=(12, 6))\nax.bar(data_q41.index, data_q41, width=0.55, \n       edgecolor='darkgray', color=sns.color_palette(\"crest\", 7),\n       linewidth=0.7)\n\nfor i in data_q41.index:\n    ax.annotate(f\"{data_q41[i]}\", \n                   xy=(i, data_q41[i] + 300),\n                   va = 'center', ha='center',fontweight='light', fontfamily='serif',\n                   color='#4a4a4a')\n\n\nfor s in ['top', 'left', 'right']:\n    ax.spines[s].set_visible(False)\n\nax.set_xticklabels(data_q41.index, fontfamily='serif', rotation=90)\nfig.text(0.09, 0.95, 'First tool used for data analyze', fontsize=15, fontweight='bold', fontfamily='serif')    \nax.grid(axis='y', linestyle='-', alpha=0.4)    \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.561606Z","iopub.status.idle":"2022-04-04T08:41:04.562141Z","shell.execute_reply.started":"2022-04-04T08:41:04.561951Z","shell.execute_reply":"2022-04-04T08:41:04.561973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color=\"#2cb7b0\" id=\"section_2_43\">2.43. Q42 - Who/what are your favorite media sources that report on data science topics?</font> ","metadata":{}},{"cell_type":"code","source":"Q42_values = df_fin.loc[:,['Q42_Part_1', 'Q42_Part_2', 'Q42_Part_3', 'Q42_Part_4', 'Q42_Part_5', 'Q42_Part_6', 'Q42_Part_7','Q42_Part_8','Q42_Part_9','Q42_Part_10','Q42_Part_11','Q42_OTHER']]\n\nfig = px.bar(\n    x=Q42_values.stack().unique(),\n    y=Q42_values.stack().value_counts().values,\n    text =Q42_values.stack().value_counts().values\n)\n\n\n\nfig.update_layout(title_text='Favorite medias sources about data science topics ?', title_x=0.5, title_y=0.99,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.564726Z","iopub.status.idle":"2022-04-04T08:41:04.565019Z","shell.execute_reply.started":"2022-04-04T08:41:04.564866Z","shell.execute_reply":"2022-04-04T08:41:04.564882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## <font color=\"#337da4\" id=\"section_3\">3. Multivariate analysis </font>  \n### <font color=\"#2cb7b0\" id=\"section_3_0\">3.0. Survey duration VS Age </font>","metadata":{}},{"cell_type":"code","source":"# eliminating outliers => We will delete values over (10000 seconds)\nz=df_fin[df_fin['Time from Start to Finish (seconds)']<10000].groupby('Q1')['Time from Start to Finish (seconds)'].mean().sort_values(ascending=False)\n# plotting and styling\nfig, ax = plt.subplots(figsize=(12,4))\nsns.barplot(x=z.index, y=z.values, palette=cust_color, edgecolor='black', linewidth=1.5, saturation=1.5)\n\nplt.xlabel(\"Age Group\", fontname = 'monospace', weight='semibold')\nplt.ylabel(\"Mean Time to Finish Survey\", fontname = 'monospace', weight='semibold')\nplt.title('Average Time to Finish Survey by Age', fontname = 'monospace', weight='bold')\nplt.xticks(fontsize=12)\nplt.yticks(np.arange(0, z.values.max()+1, 100))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.566139Z","iopub.status.idle":"2022-04-04T08:41:04.566425Z","shell.execute_reply.started":"2022-04-04T08:41:04.566282Z","shell.execute_reply":"2022-04-04T08:41:04.566298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_1\">3.1. Gender VS Age </font>","metadata":{}},{"cell_type":"code","source":"# Plotting interactive sunburst:\n\nfig = px.sunburst(data_frame=df_fin,\n                  path=['Q2', 'Q1'],\n                  color='Q1',\n                  color_discrete_sequence=cust_color[::-4],\n                  title='Gender and Age'\n                 )\n\nfig.update_traces(textinfo='label+percent parent')\nfig.update_layout(margin=dict(t=40, l=0, r=0, b=0))\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.567375Z","iopub.status.idle":"2022-04-04T08:41:04.56783Z","shell.execute_reply.started":"2022-04-04T08:41:04.567677Z","shell.execute_reply":"2022-04-04T08:41:04.567695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_2\">3.2. Gender VS Country </font>","metadata":{}},{"cell_type":"code","source":"# percentages \nz=df_fin.groupby([ 'Q3', 'Q2']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(14, 24))\n\n#plot in heatmap\nsns.heatmap(z.apply(lambda x: x/x.sum(), axis=1), xticklabels=True, yticklabels=True, cmap=cust_color, annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":12}, fmt='.4f', cbar=False)\nplt.title('Gender Distribution by Country', fontname = 'monospace', weight='bold')\nplt.yticks(fontsize=9)\nplt.xticks(fontsize=10)\nplt.show()\ndel z","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.568719Z","iopub.status.idle":"2022-04-04T08:41:04.569283Z","shell.execute_reply.started":"2022-04-04T08:41:04.569062Z","shell.execute_reply":"2022-04-04T08:41:04.569081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_3\">3.3. Age distribution per Country </font>","metadata":{}},{"cell_type":"code","source":"# getting percentages and plotting them in heatmap\nz=df_fin.groupby([ 'Q3', 'Q1']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(14, 24))\nsns.heatmap(z.apply(lambda x: x/x.sum(), axis=1), xticklabels=True, yticklabels=True, cmap=cust_color, annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":12}, fmt='.3f', cbar=False)\nplt.title('Age Distribution by Country', fontname = 'monospace', weight='bold')\nplt.yticks(fontsize=9)\nplt.show()\ndel z","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.570436Z","iopub.status.idle":"2022-04-04T08:41:04.571055Z","shell.execute_reply.started":"2022-04-04T08:41:04.570879Z","shell.execute_reply":"2022-04-04T08:41:04.570898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_4\">3.4. Degree / job / Experience </font>","metadata":{}},{"cell_type":"code","source":"df_456 = df_fin[['Q4', 'Q5', 'Q6']]\ndf_456['Q6'] = df_456['Q6'].replace(dict.fromkeys(['I have never written code', '< 1 years', '1-3 years'],'Beginner'))\ndf_456['Q6'] = df_456['Q6'].replace(dict.fromkeys(['3-5 years', '5-10 years'],'Intermediate'))\ndf_456['Q6'] = df_456['Q6'].replace(dict.fromkeys(['10-20 years', '20+ years'],'Expert'))\ndf_456['Q4'] = df_456['Q4'].replace({'Some college/university study without earning a bachelor‚Äôs degree': 'Without Bachelor‚Äôs degree'})\n\ndf_456 = round(pd.crosstab(df_456['Q4'], [df_456['Q5'],df_456['Q6']], normalize='index'), 2).T.reset_index()\n\ndf_456_beginner = df_456[df_456['Q6']=='Beginner'].sort_values(by=[\"Q5\"]).reset_index().drop('index', axis=1)\ndf_456_intermediate = df_456[df_456['Q6']=='Intermediate'].sort_values(by=[\"Q5\"]).reset_index().drop('index', axis=1)\ndf_456_expert = df_456[df_456['Q6']=='Expert'].sort_values(by=[\"Q5\"]).reset_index().drop('index', axis=1)\n\nfig = make_subplots(rows=1, cols=7, shared_yaxes=True, horizontal_spacing=0, vertical_spacing=0)                    \nfig.add_trace(go.Bar(y=df_456_beginner['Q5'], x=df_456_beginner['Bachelor‚Äôs degree'], marker_color=cust_color, name='Beginner-level coding experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=1)\nfig.add_trace(go.Bar(y=df_456_intermediate['Q5'], x=df_456_intermediate['Bachelor‚Äôs degree'], marker_color='#00FFFF', name='Intermediate-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=1)\nfig.add_trace(go.Bar(y=df_456_expert['Q5'], x=df_456_expert['Bachelor‚Äôs degree'], marker_color='#0033FF', name='Expert-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=1)\n\n\n\nfig.add_trace(go.Bar(y=df_456_beginner['Q5'], x=df_456_beginner['Master‚Äôs degree'], marker_color=cust_color, name='Beginner-level coding experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=2)\nfig.add_trace(go.Bar(y=df_456_intermediate['Q5'], x=df_456_intermediate['Master‚Äôs degree'], marker_color='#00FFFF', name='Intermediate-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=2)\nfig.add_trace(go.Bar(y=df_456_expert['Q5'], x=df_456_expert['Master‚Äôs degree'], marker_color='#0033FF', name='Expert-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=2)\n\n\nfig.add_trace(go.Bar(y=df_456_beginner['Q5'], x=df_456_beginner['Doctoral degree'], marker_color=cust_color, name='Beginner-level coding experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=3)\nfig.add_trace(go.Bar(y=df_456_intermediate['Q5'], x=df_456_intermediate['Doctoral degree'], marker_color='#00FFFF', name='Intermediate-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=3)\nfig.add_trace(go.Bar(y=df_456_expert['Q5'], x=df_456_expert['Doctoral degree'], marker_color='#0033FF', name='Expert-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=3)\n\n\nfig.add_trace(go.Bar(y=df_456_beginner['Q5'], x=df_456_beginner['Professional doctorate'], marker_color=cust_color, name='Beginner-level coding experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=4)\nfig.add_trace(go.Bar(y=df_456_intermediate['Q5'], x=df_456_intermediate['Professional doctorate'], marker_color='#00FFFF', name='Intermediate-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=4)\nfig.add_trace(go.Bar(y=df_456_expert['Q5'], x=df_456_expert['Professional doctorate'], marker_color='#0033FF', name='Expert-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=4)\n\n\nfig.add_trace(go.Bar(y=df_456_beginner['Q5'], x=df_456_beginner['I prefer not to answer'], marker_color=cust_color, name='Beginner-level coding experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=5)\nfig.add_trace(go.Bar(y=df_456_intermediate['Q5'], x=df_456_intermediate['I prefer not to answer'], marker_color='#00FFFF', name='Intermediate-level coding experience', \n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=5)\nfig.add_trace(go.Bar(y=df_456_expert['Q5'], x=df_456_expert['I prefer not to answer'], marker_color='#0033FF', name='Expert-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=5)\n\n\nfig.add_trace(go.Bar(y=df_456_beginner['Q5'], x=df_456_beginner['Without Bachelor‚Äôs degree'],  marker_color=cust_color, name='Beginner-level coding experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=6)\nfig.add_trace(go.Bar(y=df_456_intermediate['Q5'], x=df_456_intermediate['Without Bachelor‚Äôs degree'], marker_color='#00FFFF', name='Intermediate-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=6)\nfig.add_trace(go.Bar(y=df_456_expert['Q5'], x=df_456_expert['Without Bachelor‚Äôs degree'], marker_color='#0033FF', name='Expert-level coding experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=6)\n\nfig.add_trace(go.Bar(y=df_456_beginner['Q5'], x=df_456_beginner['No formal education past high school'],  marker_color=cust_color, name='Beginner-level coding experience',\n                     orientation='h', opacity=0.8),\n                     row=1, col=7)\nfig.add_trace(go.Bar(y=df_456_intermediate['Q5'], x=df_456_intermediate['No formal education past high school'], marker_color='#00FFFF', name='Intermediate-level coding experience',\n                     orientation='h', opacity=0.8),\n                     row=1, col=7)\nfig.add_trace(go.Bar(y=df_456_expert['Q5'], x=df_456_expert['No formal education past high school'], marker_color='#0033FF', name='Expert-level coding experience',\n                     orientation='h', opacity=0.8),\n                     row=1, col=7)\n\nfig.update_xaxes(zeroline=False,showticklabels=False, ticks=\"\")\nfig.update_traces(hovertemplate=None, marker=dict(line=dict(width=0)))\nfig.update_yaxes(tickmode='array', showline=False, showgrid=False,\n                 tickvals=['Business Analyst', 'Currently not employed',\n                       'DBA/Database Engineer', 'Data Analyst', 'Data Engineer',\n                       'Data Scientist', 'Developer Relations/Advocacy',\n                       'Machine Learning Engineer', 'Other', 'Product Manager',\n                       'Program/Project Manager', 'Research Scientist',\n                       'Software Engineer', 'Statistician', 'Student'],\n                 ticktext=['Business Analyst', 'Currently not employed',\n                       'DBA/Database Engineer', 'Data Analyst', 'Data Engineer',\n                       'Data Scientist', 'Developer Relations/Advocacy',\n                       'Machine Learning Engineer', 'Other', 'Product Manager',\n                       'Program/Project Manager', 'Research Scientist',\n                       'Software Engineer', 'Statistician', 'Student'])\nfig.update_layout(height=550, \n                  title_text=\"Degree and Job title based on Coding Experience\", title_x =0.5, title_y = 0.96,\n                  template=\"plotly_white\", barmode='stack',\n                  autosize=True,\n                  margin=dict(t=80, b=50, l=70, r=40),\n                 plot_bgcolor='white', paper_bgcolor='white', \n                title_font=dict(size=21, color='#222A2A', family=\"Muli, sans-serif\"),\n                         font=dict(color='#222A2A'),\n                         legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n                 )\n\n\nfig['layout']['xaxis'].update(title_text='Bachelor\\'s<br> degree', title_font=dict(size=12))\nfig['layout']['xaxis2'].update(title_text='Master\\'s<br> degree', title_font=dict(size=12))\nfig['layout']['xaxis3'].update(title_text='Doctoral\\'s<br> degree', title_font=dict(size=12))\nfig['layout']['xaxis4'].update(title_text='Professional<br> doctorate', title_font=dict(size=12))\nfig['layout']['xaxis5'].update(title_text='Prefer<br> not to<br> answer', title_font=dict(size=12))\nfig['layout']['xaxis6'].update(title_text='Without<br> Bachelor\\'s<br> degree', title_font=dict(size=12))\nfig['layout']['xaxis7'].update(title_text='No formal<br> education<br> past high<br>school', title_font=dict(size=12))\n\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.572148Z","iopub.status.idle":"2022-04-04T08:41:04.57271Z","shell.execute_reply.started":"2022-04-04T08:41:04.572543Z","shell.execute_reply":"2022-04-04T08:41:04.572563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_5\">3.5. Gender & Experience </font>","metadata":{}},{"cell_type":"code","source":"dfb = df_fin[df_fin['Q2']=='Man']\ndfb = pd.crosstab(dfb['Q3'], dfb['Q6'], margins=True, margins_name=\"Total\").sort_values(by='Total', ascending=False).reset_index()\ndfb = dfb.iloc[1:, :-1]\ndfb = dfb.loc(axis=0)[1,2,3,16,7,10,8,6,11,5].reset_index(drop=True)\ncm1 = sns.light_palette(\"#0033FF\", as_cmap=True)\ndfb.style.background_gradient(axis=1, cmap=cm1)\n\n\ndfg = df_fin[df_fin['Q2']=='Woman']\ndfg = pd.crosstab(dfg['Q3'], dfg['Q6'], margins=True, margins_name=\"Total\").sort_values(by='Total', ascending=False).reset_index()\ndfg = dfg.iloc[1:, :-1]\ndfg = dfg.loc(axis=0)[1,2,3,16,7,10,8,6,11,5].reset_index(drop=True)\ncm2 = sns.light_palette(\"#00FFFF\", as_cmap=True)\ndfg.style.background_gradient(axis=1, cmap=cm2)\n\n\ndfo = df_fin[(df_fin['Q2'] != 'Man') & (df_fin['Q2'] != 'Woman')]\ndfo = pd.crosstab(dfo['Q3'], dfo['Q6'], margins=True, margins_name=\"Total\").sort_values(by='Total', ascending=False).reset_index()\ndfo = dfo.iloc[1:, :-1]\ndfo = dfo.loc(axis=0)[1,2,3,16,7,10,8,6,11,5].reset_index(drop=True)\n\n\ndf_gender_wise = pd.merge(dfb, dfg, left_index=True, right_index=True)\ndf_gender_wise = pd.merge(df_gender_wise, dfo, left_index=True, right_index=True)\ndf_gender_wise.drop(['Q3', 'Q3_y'], axis='columns', inplace=True)\n\ndf_gender_wise.rename(columns={\"1-3 years_x\": \"1-3 years\", \n                               '10-20 years_x': \"1-3 years\", '20+ years_x': \"20+ years\", \n                               '3-5 years_x': \"3-5 years\", '5-10 years_x': \"5-10 years\", \n                               '< 1 years_x': \"< 1 years\",  'I have never written code_x': \"I have never written code\",                             \n                               \"1-3 years_y\": \"1-3 years\",\n                               '10-20 years_y': \"1-3 years\", '20+ years_y': \"20+ years\", \n                               '3-5 years_y': \"3-5 years\", '5-10 years_y': \"5-10 years\", \n                               '< 1 years_y': \"< 1 years\", 'I have never written code_y': \"I have never written code\"\n                              }, inplace = True)\n\ndf_gender_wise_1 = df_gender_wise.iloc[:, 0]\ndf_gender_wise_2 = df_gender_wise.iloc[:, 1:]\n\ndf_gender_wise_2.columns = pd.MultiIndex.from_product([['Men', 'Women', 'Other Genders'],['1-3 years', '10-20 years', '20+ years', '3-5 years', '5-10 years',\n       '< 1 years', 'I have never written code']])\n\ndf_gender_wise = pd.concat([df_gender_wise_1, df_gender_wise_2], axis=1)\ndf_gender_wise = df_gender_wise.rename({'Q3_x' : 'Country'}, axis=1)\n\ncm1 = sns.light_palette(\"#0033FF\", as_cmap=True)\ncm2 = sns.light_palette(\"#00FFFF\", as_cmap=True)\ncm3 = sns.light_palette(\"#009999\", as_cmap=True)\n\n\ndf_gender_wise.style.background_gradient(cmap=cm1, subset=[('Men', '1-3 years'),\n                               ('Men', '10-20 years'),\n                                 ('Men', '20+ years'),\n                                 ('Men', '3-5 years'),\n                                ('Men', '5-10 years'),\n                                 ('Men', '< 1 years'),\n                 ('Men', 'I have never written code')])\\\n    .background_gradient(cmap=cm2, subset=[('Women', '1-3 years'),\n                             ('Women', '10-20 years'),\n                               ('Women', '20+ years'),\n                               ('Women', '3-5 years'),\n                              ('Women', '5-10 years'),\n                               ('Women', '< 1 years'),\n               ('Women', 'I have never written code')])\\\n    .background_gradient(cmap=cm3, subset=[('Other Genders', '1-3 years'),\n                     ('Other Genders', '10-20 years'),\n                       ('Other Genders', '20+ years'),\n                       ('Other Genders', '3-5 years'),\n                      ('Other Genders', '5-10 years'),\n                       ('Other Genders', '< 1 years'),\n       ('Other Genders', 'I have never written code')])\\\n    .set_caption(\"Genders and their years of experience in the top 10 countries of participation\")\\\n    .format(precision=2).set_properties(**{\n        'width': '20px',\n        'max-width': '20px',\n        'font-size': '8pt'\n    })","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.573605Z","iopub.status.idle":"2022-04-04T08:41:04.574211Z","shell.execute_reply.started":"2022-04-04T08:41:04.574036Z","shell.execute_reply":"2022-04-04T08:41:04.574056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_6\">3.6. Comparison Experience and language used + lien avec language recommended  </font>","metadata":{}},{"cell_type":"code","source":"df_q6_q7 = df_fin[['Q6',\"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_3\",\n                                 \"Q7_Part_4\", \"Q7_Part_5\", \"Q7_Part_6\",\n                                 \"Q7_Part_7\", \"Q7_Part_8\", \"Q7_Part_9\",\n                                 \"Q7_Part_10\", \"Q7_Part_11\", \"Q7_Part_12\", \"Q14_OTHER\"]]\n\ndf_q6_q7['Q6'] = df_q6_q7['Q6'].replace(dict.fromkeys(['I have never written code', '< 1 years', '1-3 years'],'Beginner'))\ndf_q6_q7['Q6'] = df_q6_q7['Q6'].replace(dict.fromkeys(['3-5 years', '5-10 years'],'Intermediate'))\ndf_q6_q7['Q6'] = df_q6_q7['Q6'].replace(dict.fromkeys(['10-20 years', '20+ years'],'Expert'))\n\ndf_q6_q7 = df_q6_q7.groupby(['Q6'])[[\"Q7_Part_1\", \"Q7_Part_2\", \"Q7_Part_3\",\n                                 \"Q7_Part_4\", \"Q7_Part_5\", \"Q7_Part_6\",\n                                 \"Q7_Part_7\", \"Q7_Part_8\", \"Q7_Part_9\",\n                                 \"Q7_Part_10\", \"Q7_Part_11\", \"Q7_Part_12\", \"Q14_OTHER\"] \n                                 ].count().unstack().fillna(0).reset_index(name='counts')\n\n\ndf_q6_q7_beginner = df_q6_q7[df_q6_q7['Q6'] == 'Beginner'].drop(columns='Q6').sort_values(by='counts', axis=0, ascending=False)\ndf_q6_q7_intermediate = df_q6_q7[df_q6_q7['Q6'] == 'Intermediate'].drop(columns='Q6').sort_values(by='counts', axis=0, ascending=False)\ndf_q6_q7_expert = df_q6_q7[df_q6_q7['Q6'] == 'Expert'].drop(columns='Q6').sort_values(by='counts', axis=0, ascending=False)\n\n#df_q6_q7 = df_q6_q7.sort_values(by='counts', ascending = True).tail()\ndf_q6_q7 = pd.merge(df_q6_q7_beginner, df_q6_q7_intermediate, on='level_0')\ndf_q6_q7 = pd.merge(df_q6_q7, df_q6_q7_expert, on='level_0')\nnames = ['Q7', 'Beginner', 'Intermediate', 'Expert']\ndf_q6_q7.columns = names\ndf_q6_q7[\"All\"] = df_q6_q7.sum(axis=1)\ndf_q6_q7 = df_q6_q7.head()\n\ndf_q6_q7 = df_q6_q7.replace({'Q7' : \n                                 { 'Q7_Part_1' : 'Python', \"Q7_Part_2\" : 'R' ,     \n                                \"Q7_Part_3\" : 'SQL', \"Q7_Part_4\" : 'C',\n                                \"Q7_Part_5\" : 'C++'\n                                 }})\n\n\ndata1 = [{'id': 'World', 'datum': df_q6_q7.value_counts().sum(), 'children' : [\n              {'id' : df_q6_q7['Q7'].iloc[0], 'datum' : df_q6_q7['All'].iloc[0],  \n                   'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q7['Beginner'].iloc[0]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q7['Intermediate'].iloc[0]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q7['Expert'].iloc[0]}\n                   ]},\n              {'id' : df_q6_q7['Q7'].iloc[1], 'datum' : df_q6_q7['All'].iloc[1],  \n                   'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q7['Beginner'].iloc[1]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q7['Intermediate'].iloc[1]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q7['Expert'].iloc[1]}\n                   ]},\n              {'id' : df_q6_q7['Q7'].iloc[2], 'datum' : df_q6_q7['All'].iloc[2],  \n                   'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q7['Beginner'].iloc[2]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q7['Intermediate'].iloc[2]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q7['Expert'].iloc[2]}\n                   ]},\n              {'id' : df_q6_q7['Q7'].iloc[3], 'datum' : df_q6_q7['All'].iloc[3],  \n                               'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q7['Beginner'].iloc[3]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q7['Intermediate'].iloc[3]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q7['Expert'].iloc[3]}\n                               ]},\n              {'id' : df_q6_q7['Q7'].iloc[4], 'datum' : df_q6_q7['All'].iloc[4],  \n                               'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q7['Beginner'].iloc[4]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q7['Intermediate'].iloc[4]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q7['Expert'].iloc[4]}\n                               ]}\n    ]}]\n\n\ncircles = circlify.circlify(\n    data1, \n    show_enclosure=False, \n    target_enclosure=circlify.Circle(x=0, y=0, r=1)\n)\n\n\nchild_circle_groups = []\nfor i in range(len(data1)):\n    child_circle_groups.append(circlify.circlify(\n        data1, \n        show_enclosure=False, \n        target_enclosure=circlify.Circle(x=circles[i].x, y=circles[i].y, r=circles[i].r)\n    ))\n\n    \nfig1 = go.Figure()\n\nfig1.update_xaxes(\n    range=[-1.05, 1.05], # making slightly wider axes than -1 to 1 so no edge of circles cut-off\n    showticklabels=False,\n    showgrid=False,\n    zeroline=False\n)\n\nfig1.update_yaxes(\n    range=[-1.05, 1.05],\n    showticklabels=False,\n    showgrid=False,\n    zeroline=False,\n)\n\nfor circle in circles:\n    if circle.level != 2:\n        continue\n    x, y, r = circle    \n    label = circle.ex[\"id\"]\n    value = circle.ex['datum']\n    fig1.add_shape(type=\"circle\",\n        xref=\"x\", yref=\"y\",\n        x0=x-r, y0=y-r, x1=x+r, y1=y+r,\n        line_color=\"LightSeaGreen\",\n        line_width=2,\n        fillcolor=\"#0099CC\", \n    )\n    fig1.add_annotation(\n        x=x,\n        y=y,\n        xref=\"x\",\n        yref=\"y\",showarrow=False, xshift=50, yshift=70,\n        text= str(label) + \": \" + str(value),\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"black\"\n            ),\n        align=\"center\",\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=1\n        )\n    fig1.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n    \n    \nfor circle in circles:\n    if circle.level != 3:\n        continue\n    x, y, r = circle\n    label = circle.ex[\"id\"]\n    value = circle.ex['datum']\n    fig1.add_shape(type=\"circle\",\n        xref=\"x\", yref=\"y\",\n        x0=x-r, y0=y-r, x1=x+r, y1=y+r,\n        line_color=\"LightSeaGreen\",\n        line_width=2,\n        fillcolor=\"rgb(82, 188, 163)\",\n    )\n    fig1.add_annotation(\n        x=x,\n        y=y, \n        xref=\"x\", yref=\"y\",showarrow=False,\n        text= str(label) + \": \" + str(value),\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"black\"\n            ),\n        align=\"center\",\n        opacity=0.8,\n        )\n    fig1.update_layout(uniformtext_minsize=8, uniformtext_mode='hide', width=500, height=500, plot_bgcolor=\"white\",\n                      margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=0, #top margin\n                        ), title_text='Top 5 programming languages used regularly', title_x=0.5, title_y=0.998,\n                      )\nfig1.show()\n\n\ndf_q6_q8 = df[['Q6','Q8']]\ndf_q6_q8 = df_q6_q8[df_q6_q8.Q8 != 'None']\n\ndf_q6_q8['Q6'] = df_q6_q8['Q6'].replace(dict.fromkeys(['I have never written code', '< 1 years', '1-3 years'],'Beginner'))\ndf_q6_q8['Q6'] = df_q6_q8['Q6'].replace(dict.fromkeys(['3-5 years', '5-10 years'],'Intermediate'))\ndf_q6_q8['Q6'] = df_q6_q8['Q6'].replace(dict.fromkeys(['10-20 years', '20+ years'],'Expert'))\n\ndf_q6_q8 = pd.crosstab(df_q6_q8['Q8'], df_q6_q8['Q6'], margins=True).reset_index()[:-1].sort_values(by='All', ascending=False).head(5)\n\ndata2 = [{'id': 'World', 'datum': df_q6_q8.value_counts().sum(), 'children' : [\n              {'id' : df_q6_q8['Q8'].iloc[0], 'datum' : df_q6_q8['All'].iloc[0],  \n                   'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q8['Beginner'].iloc[0]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q8['Intermediate'].iloc[0]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q8['Expert'].iloc[0]}\n                   ]},\n              {'id' : df_q6_q8['Q8'].iloc[1], 'datum' : df_q6_q8['All'].iloc[1],  \n                   'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q8['Beginner'].iloc[1]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q8['Intermediate'].iloc[1]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q8['Expert'].iloc[1]}\n                   ]},\n              {'id' : df_q6_q8['Q8'].iloc[2], 'datum' : df_q6_q8['All'].iloc[2],  \n                   'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q8['Beginner'].iloc[2]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q8['Intermediate'].iloc[2]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q8['Expert'].iloc[2]}\n                   ]},\n              {'id' : df_q6_q8['Q8'].iloc[3], 'datum' : df_q6_q8['All'].iloc[3],  \n                               'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q8['Beginner'].iloc[3]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q8['Intermediate'].iloc[3]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q8['Expert'].iloc[3]}\n                               ]},\n              {'id' : df_q6_q8['Q8'].iloc[4], 'datum' : df_q6_q8['All'].iloc[4],  \n                               'children' : [ \n                     {'id' : \"Beginner\", 'datum' : df_q6_q8['Beginner'].iloc[4]},\n                     {'id' : \"Intermediate\", 'datum' : df_q6_q8['Intermediate'].iloc[4]},\n                     {'id' : \"Expert\", 'datum' : df_q6_q8['Expert'].iloc[4]}\n                               ]}\n    ]}]\n\n\ncircles = circlify.circlify(\n    data2, \n    show_enclosure=False, \n    target_enclosure=circlify.Circle(x=0, y=0, r=1)\n)\n\n\nchild_circle_groups = []\nfor i in range(len(data2)):\n    child_circle_groups.append(circlify.circlify(\n        data2, \n        show_enclosure=False, \n        target_enclosure=circlify.Circle(x=circles[i].x, y=circles[i].y, r=circles[i].r)\n    ))\n\n    \nfig2 = go.Figure()\n\nfig2.update_xaxes(\n    range=[-1.05, 1.05], # making slightly wider axes than -1 to 1 so no edge of circles cut-off\n    showticklabels=False,\n    showgrid=False,\n    zeroline=False\n)\n\nfig2.update_yaxes(\n    range=[-1.05, 1.05],\n    showticklabels=False,\n    showgrid=False,\n    zeroline=False,\n)\n\nfor circle in circles:\n    if circle.level != 2:\n        continue\n    x, y, r = circle    \n    label = circle.ex[\"id\"]\n    value = circle.ex['datum']\n    fig2.add_shape(type=\"circle\",\n        xref=\"x\", yref=\"y\",\n        x0=x-r, y0=y-r, x1=x+r, y1=y+r,\n        line_color=\"#d48b06\",\n        line_width=2,\n        fillcolor=\"#f2cc85\", \n    )\n    fig2.add_annotation(\n        x=x,\n        y=y,\n        xref=\"x\",\n        yref=\"y\",showarrow=False, xshift=-30, yshift=40,\n        text= str(label) + \": \" + str(value),\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"black\"\n            ),\n        align=\"center\",\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=1\n        )\n    fig2.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\n    \n    \nfor circle in circles:\n    if circle.level != 3:\n        continue\n    x, y, r = circle\n    label = circle.ex[\"id\"]\n    value = circle.ex['datum']\n    fig2.add_shape(type=\"circle\",\n        xref=\"x\", yref=\"y\",\n        x0=x-r, y0=y-r, x1=x+r, y1=y+r,\n        line_color='#00CCFF',\n        line_width=2,\n        fillcolor='#00CCCC',\n    )\n    fig2.add_annotation(\n        x=x,\n        y=y, \n        xref=\"x\", yref=\"y\",showarrow=False,\n        text= str(label) + \": \" + str(value) + \"\\n\",\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=10,\n            color=\"black\"\n            ),\n        align=\"center\",\n        opacity=0.8,\n        )\n    fig2.update_layout(uniformtext_minsize=8, uniformtext_mode='hide', width=500, height=500, plot_bgcolor=\"white\",\n                      margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=0, #top margin\n                        ), title_text='Top 5 programming languages recommended', title_x=0.5, title_y=0.91)\nfig2.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.57533Z","iopub.status.idle":"2022-04-04T08:41:04.575926Z","shell.execute_reply.started":"2022-04-04T08:41:04.575738Z","shell.execute_reply":"2022-04-04T08:41:04.575759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_7\">3.7. Language used and IDE  </font>","metadata":{}},{"cell_type":"code","source":"df_q7_q9 = df_fin.copy()\ndf_q7_q9_1 = df_q7_q9.groupby(['Q7_Part_1'])[['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4',\n       'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9',\n       'Q9_Part_10', 'Q9_Part_11', 'Q9_Part_12', 'Q9_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='Python').drop('Q7_Part_1', axis='columns')\ndf_q7_q9_2 = df_q7_q9.groupby(['Q7_Part_2'])[['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4',\n       'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9',\n       'Q9_Part_10', 'Q9_Part_11', 'Q9_Part_12', 'Q9_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='R').drop('Q7_Part_2', axis='columns')\ndf_q7_q9_3 = df_q7_q9.groupby(['Q7_Part_3'])[['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4',\n       'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9',\n       'Q9_Part_10', 'Q9_Part_11', 'Q9_Part_12', 'Q9_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='SQL').drop('Q7_Part_3', axis='columns')\ndf_q7_q9_4 = df_q7_q9.groupby(['Q7_Part_4'])[['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4',\n       'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9',\n       'Q9_Part_10', 'Q9_Part_11', 'Q9_Part_12', 'Q9_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='C').drop('Q7_Part_4', axis='columns')\ndf_q7_q9_5 = df_q7_q9.groupby(['Q7_Part_5'])[['Q9_Part_1', 'Q9_Part_2', 'Q9_Part_3', 'Q9_Part_4',\n       'Q9_Part_5', 'Q9_Part_6', 'Q9_Part_7', 'Q9_Part_8', 'Q9_Part_9',\n       'Q9_Part_10', 'Q9_Part_11', 'Q9_Part_12', 'Q9_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='C++').drop('Q7_Part_5', axis='columns')\ndf_q7_q9 = df_q7_q9_1.merge(df_q7_q9_2, how='left', on='level_0')\ndf_q7_q9 = df_q7_q9.merge(df_q7_q9_3, how='left', on='level_0')\ndf_q7_q9 = df_q7_q9.merge(df_q7_q9_4, how='left', on='level_0')\ndf_q7_q9 = df_q7_q9.merge(df_q7_q9_5, how='left', on='level_0')\n\ndf_q7_q9 = df_q7_q9.replace({'level_0' : \n                                 { 'Q9_Part_1' : 'JupyterLab', 'Q9_Part_2' : 'RStudio',\n                                 \"Q9_Part_3\" : 'Visual Studio' ,  \"Q9_Part_4\" : 'VSCode',  \n                                  \"Q9_Part_5\" : 'PyCharm' ,  \"Q9_Part_6\" : 'Spyder',\n                                  'Q9_Part_7' : 'Notepad++', 'Q9_Part_8' : 'Sublime Text',\n                                 \"Q9_Part_9\" : 'Vim, Emacs, or similar' ,  \"Q9_Part_10\" : 'MATLAB',  \n                                  \"Q9_Part_11\" : 'Jupyter Notebook' ,  \"Q9_Part_12\" : 'None',\n                                    \"Q9_OTHER\": 'Other'\n                                 }}) \n\ndf_q7_q9 = df_q7_q9[(df_q7_q9['level_0'] != 'None')]\ndf_q7_q9['total'] = df_q7_q9.sum(axis=1)\ndf_q7_q9 = df_q7_q9.sort_values(by='total', ascending=False)\n\n\n\ndf_q7_q12 = df_fin.copy()\ndf_q7_q12_1 = df_q7_q12.groupby(['Q7_Part_1'])[['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4',\n       'Q12_Part_5', 'Q12_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='Python').drop('Q7_Part_1', axis='columns')\ndf_q7_q12_2 = df_q7_q12.groupby(['Q7_Part_2'])[['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4',\n       'Q12_Part_5', 'Q12_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='R').drop('Q7_Part_2', axis='columns')\ndf_q7_q12_3 = df_q7_q12.groupby(['Q7_Part_3'])[['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4',\n       'Q12_Part_5', 'Q12_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='SQL').drop('Q7_Part_3', axis='columns')\ndf_q7_q12_4 = df_q7_q12.groupby(['Q7_Part_4'])[['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4',\n       'Q12_Part_5', 'Q12_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='C').drop('Q7_Part_4', axis='columns')\ndf_q7_q12_5 = df_q7_q12.groupby(['Q7_Part_5'])[['Q12_Part_1', 'Q12_Part_2', 'Q12_Part_3', 'Q12_Part_4',\n       'Q12_Part_5', 'Q12_OTHER'] \n                                 ].count().unstack().fillna(0).reset_index(name='C++').drop('Q7_Part_5', axis='columns')\ndf_q7_q12 = df_q7_q12_1.merge(df_q7_q12_2, how='left', on='level_0')\ndf_q7_q12 = df_q7_q12.merge(df_q7_q12_3, how='left', on='level_0')\ndf_q7_q12 = df_q7_q12.merge(df_q7_q12_4, how='left', on='level_0')\ndf_q7_q12 = df_q7_q12.merge(df_q7_q12_5, how='left', on='level_0')\n\ndf_q7_q12 = df_q7_q12.replace({'level_0' : \n                                 { 'Q12_Part_1' : 'NVIDIA GPUs', 'Q12_Part_2' : 'Google Cloud TPUs',\n                                 \"Q12_Part_3\" : 'AWS Trainium Chips' ,  \"Q12_Part_4\" : 'AWS Inferentia Chips',  \n                                  \"Q12_Part_5\" : 'None' , \"Q12_OTHER\": 'Other'\n                                 }}) \ndf_q7_q12 = df_q7_q12[(df_q7_q12['level_0'] != 'None')]\n\ndf_q7_q12['total'] = df_q7_q12.sum(axis=1)\ndf_q7_q12 = df_q7_q12.sort_values(by='total', ascending=False)\n\nfig = make_subplots(rows=1, cols=2, shared_yaxes=True, specs=[[{\"type\": \"bar\"},{\"type\": \"bar\"}]], horizontal_spacing=0.01, vertical_spacing=0)\n\nfig.add_trace(go.Bar(x=df_q7_q9['level_0'], y=df_q7_q9['Python'], marker_color='#011338', name= 'Python',\n                     text=df_q7_q9['Python'], showlegend=False, opacity=0.6),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q7_q9['level_0'], y=df_q7_q9['R'], marker_color='#0b484a', name= 'R',\n                      text=df_q7_q9['R'], showlegend=False, opacity=0.6), \n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q7_q9['level_0'], y=df_q7_q9['SQL'], marker_color='#0978bd', name= 'SQL',\n                     text=df_q7_q9['SQL'], showlegend=False, opacity=0.6),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q7_q9['level_0'], y=df_q7_q9['C'], marker_color='#4dc3eb', name= 'C',\n                      text=df_q7_q9['C'], showlegend=False, opacity=0.6), \n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q7_q9['level_0'], y=df_q7_q9['C++'], marker_color='#72f3f7', name= 'C++',\n                     text=df_q7_q9['C++'], showlegend=False, opacity=0.6),\n                     row=1, col=1)\n\nfig.add_trace(go.Bar(x=df_q7_q12['level_0'], y=df_q7_q12['Python'], marker_color='#011338', name= 'Python',\n                     text=df_q7_q12['Python'], opacity=0.6),\n                     row=1, col=2)\nfig.add_trace(go.Bar(x=df_q7_q12['level_0'], y=df_q7_q12['R'], marker_color='#0b484a', name= 'R',\n                      text=df_q7_q12['R'], opacity=0.6), \n                     row=1, col=2)\nfig.add_trace(go.Bar(x=df_q7_q12['level_0'], y=df_q7_q12['SQL'], marker_color='#0978bd', name= 'SQL',\n                     text=df_q7_q12['SQL'], opacity=0.6),\n                     row=1, col=2)\nfig.add_trace(go.Bar(x=df_q7_q12['level_0'], y=df_q7_q12['C'], marker_color='#4dc3eb', name= 'C', \n                      text=df_q7_q12['C'], opacity=0.6), \n                     row=1, col=2)\nfig.add_trace(go.Bar(x=df_q7_q12['level_0'], y=df_q7_q12['C++'], marker_color='#72f3f7', name= 'C++',\n                     text=df_q7_q12['C++'], opacity=0.6),\n                     row=1, col=2)\n\nfig.update_layout(\n    title_text = 'Usage of IDEs for each of the 5 most popular languages and their corresponding usage of specialized hardware', title_x=0.5, title_y=0.95,\n                         geo = dict(showframe = False,\n                                    showcoastlines = False,\n                                    projection_type = 'equirectangular'),\n    margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=70,\n                        ),\n    updatemenus=[\n        dict(\n            active=0,\n            buttons=list([\n                dict(label=\"Python\",\n                     method=\"update\",\n                     args=[{\"visible\": [True, False,False,False,False, True, False, False,False,False,]}]),\n                dict(label=\"R\",\n                     method=\"update\",\n                     args=[{\"visible\": [False, True,False,False,False, False, True, False,False,False,]}]),\n                dict(label=\"SQL\",\n                     method=\"update\",\n                     args=[{\"visible\": [False, False,True,False,False, False, False, True,False,False,]}]),\n                dict(label=\"C\",\n                     method=\"update\",\n                     args=[{\"visible\": [False, False,False,True, False, False, False, False, True,False,]}]),\n                dict(label=\"C++\",\n                     method=\"update\",\n                     args=[{\"visible\": [False, False,False,False, True, False, False,False,False,True]}]),\n                            ]\n                         ))],\nlegend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5))\nfig.update_traces(textposition=\"outside\")\nfig.update_yaxes(range=[0,16000])\nfig['layout']['xaxis'].update(title_text='IDEs')\nfig['layout']['xaxis2'].update(title_text='Specialized hardwares')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.576976Z","iopub.status.idle":"2022-04-04T08:41:04.577552Z","shell.execute_reply.started":"2022-04-04T08:41:04.577357Z","shell.execute_reply":"2022-04-04T08:41:04.577377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_8\">3.8. Gender / General experience / ML experience  </font>","metadata":{}},{"cell_type":"code","source":"fig = make_subplots(rows=2, cols=1, specs=[[{\"type\": \"scatter\"}], [{\"type\": \"scatter\"}]],\n                   subplot_titles=('Experience 1', 'Experience 2'))\n\ndf_q26 = df_fin[['Q2','Q6']]\ndf_q26['Q2'] = np.where(((df_q26['Q2'] != 'Man') & (df_q26['Q2'] != 'Woman')),'Other/Undisclosed genders',df_q26['Q2'])\ndf_q26 = pd.crosstab(df_q26.Q2, df_q26.Q6).T.reset_index() \ndf_q26 = df_q26.loc(axis=0)[6,5,0,3,4,1,2].reset_index(drop=True)\ndf_q26['Q6'] = np.where((df_q26.Q6 == 'I have never written code'),'No experience',df_q26.Q6)\n\nfig.add_trace(go.Scatter(x=df_q26['Man'], y=df_q26['Q6'], mode = 'markers', name='Man',\n                          marker=dict(color='teal', size = 10), showlegend=False\n             ), row=1, col=1)\nfig.add_trace(go.Scatter(x=df_q26['Woman'], y=df_q26['Q6'], mode = 'markers', name='Woman', showlegend=False,\n                         marker=dict(color='orange', size = 10)\n            ), row=1, col=1)\nfig.add_trace(go.Scatter(x=df_q26['Other/Undisclosed genders'], y=df_q26['Q6'], mode = 'markers', name='Other/Undisclosed genders',showlegend=False,\n                         marker=dict(color='lightblue', size = 10)\n            ), row=1, col=1)\nfor i in range(0, len(df_q26)):\n    fig.add_shape(type='line',\n                              x0 = df_q26['Man'][i],\n                              y0 = i,\n                              x1 = df_q26['Woman'][i],\n                              y1 = i,\n                              line=dict(color='#c6ccd8', width = 2), row=1, col=1)\n    fig.add_shape(type='line',\n                              x0 = df_q26['Woman'][i],\n                              y0 = i,\n                              x1 = df_q26['Other/Undisclosed genders'][i],\n                              y1 = i,\n                              line=dict(color='#647087', width = 2), row=1, col=1)\n\nfig.update_xaxes(\n    showgrid=True,\n    ticks=\"outside\",\n    tickson=\"boundaries\",\n)\nfig.update_yaxes(tickmode='linear')\n\n\ndf_q215 = df_fin[['Q2','Q15']]\ndf_q215['Q2'] = np.where(((df_q215['Q2'] != 'Man') & (df_q215['Q2'] != 'Woman')),'Other/Undisclosed genders',df_q215['Q2'])\ndf_q215 = pd.crosstab(df_q215.Q2, df_q215.Q15).T.reset_index() \ndf_q215.iloc[0] = df_q215.iloc[0] + df_q215.iloc[2]\ndf_q215 = df_q215.drop(2).reset_index(drop=True)\ndf_q215.iloc[3] = df_q215.iloc[3] + df_q215.iloc[4]\ndf_q215 = df_q215.drop(4).reset_index(drop=True)\ndf_q215['Q15'] = np.where((df_q215.Q15 == '1-2 years2-3 years'),'1-3 years',df_q215.Q15)\ndf_q215['Q15'] = np.where((df_q215.Q15 == '3-4 years4-5 years'),'3-5 years',df_q215.Q15)\ndf_q215['Q15'] = np.where((df_q215.Q15 == 'Under 1 year'),'< 1 years',df_q215.Q15)\ndf_q215['Q15'] = np.where((df_q215.Q15 == '20 or more years'),'20+ years',df_q215.Q15)\ndf_q215['Q15'] = np.where((df_q215.Q15 == 'I do not use machine learning methods'),'No experience',df_q215.Q15)\ndf_q215 = df_q215.loc(axis=0)[5,6,0,3,4,1,2].reset_index(drop=True)\n\nfig.add_trace(go.Scatter(x=df_q215['Man'], y=df_q215['Q15'], mode = 'markers', name='Man',\n                          marker=dict(color='teal', size = 10),\n             ), row=2, col=1)\nfig.add_trace(go.Scatter(x=df_q215['Woman'], y=df_q215['Q15'], mode = 'markers', name='Woman',\n                         marker=dict(color='orange', size = 10),\n            ), row=2, col=1)\nfig.add_trace(go.Scatter(x=df_q215['Other/Undisclosed genders'], y=df_q215['Q15'], mode = 'markers', name='Other/Undisclosed genders',\n                         marker=dict(color='lightblue', size = 10),\n            ), row=2, col=1)\nfor i in range(0, len(df_q215)):\n    fig.add_shape(type='line',\n                              x0 = df_q215['Man'][i],\n                              y0 = i,\n                              x1 = df_q215['Woman'][i],\n                              y1 = i,\n                              line=dict(color='#c6ccd8', width = 2), row=2, col=1)\n    fig.add_shape(type='line',\n                              x0 = df_q215['Woman'][i],\n                              y0 = i,\n                              x1 = df_q215['Other/Undisclosed genders'][i],\n                              y1 = i,\n                              line=dict(color='#647087', width = 2), row=2, col=1)\nfig.update_xaxes(matches='x')\nfig.update_yaxes(tickmode='linear')\n\nnames = {'Experience 1':'Coding Experience', 'Experience 2':'Machine Learning Experience'}\nfig.for_each_annotation(lambda a: a.update(text = names[a.text]))\n\nfig.update_layout(height=500, \n                  margin=dict(b=0,r=20,l=20), \n                  title_text=\"Coding and ML Experience Comparison by Gender\", title_x=0.5, title_y=0.96,\n                  template=\"plotly_white\",\n                  title_font=dict(size=25, color='#444', family=\"Muli, sans-serif\"),\n                  font=dict(color='#8a8d93'),\n                  hoverlabel=dict(bgcolor=\"#f2f2f2\", font_size=13, font_family=\"Lato, sans-serif\"),\n                  legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.05, xanchor=\"center\", x=0.5))\nfig.update_traces(mode = \"markers+lines\")\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.578564Z","iopub.status.idle":"2022-04-04T08:41:04.579101Z","shell.execute_reply.started":"2022-04-04T08:41:04.578924Z","shell.execute_reply":"2022-04-04T08:41:04.578944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_9\">3.9. Visu / ML exp / ML framework  </font>","metadata":{}},{"cell_type":"markdown","source":"intercategory : Data Visualization tools vs Machine Learning algorithms","metadata":{}},{"cell_type":"code","source":"df_q14_q15_q17 = df_fin.copy()\n\ndf_q14_q15_q17['Q15'] = df_q14_q15_q17['Q15'].replace(dict.fromkeys(['I do not use machine learning methods', 'Under 1 year', '1-2 years'],'Beginner'))\ndf_q14_q15_q17['Q15'] = df_q14_q15_q17['Q15'].replace(dict.fromkeys(['2-3 years', '3-4 years', '4-5 years'],'Intermediate'))\ndf_q14_q15_q17['Q15'] = df_q14_q15_q17['Q15'].replace(dict.fromkeys(['5-10 years', '10-20 years', '20 or more years'],'Advanced'))\n\ndf_q14_q15 = df_q14_q15_q17.groupby(['Q15'])[[\"Q14_Part_1\", \"Q14_Part_2\", \"Q14_Part_3\",\n                                 \"Q14_Part_4\", \"Q14_Part_5\", \"Q14_Part_6\",\n                                 \"Q14_Part_7\", \"Q14_Part_8\", \"Q14_Part_9\",\n                                 \"Q14_Part_10\", \"Q14_Part_11\", \"Q14_OTHER\",] \n                                 ].count().unstack().fillna(0).reset_index(name='15_counts')\ndf_q14_q15 = df_q14_q15.sort_values(by='15_counts', ascending = True)\n\ndf_q15_q17 = df_q14_q15_q17.groupby(['Q15'])[[\n                                 \"Q17_Part_1\", \"Q17_Part_2\", \"Q17_Part_3\",\n                                 \"Q17_Part_4\", \"Q17_Part_5\", \"Q17_Part_6\",\n                                 \"Q17_Part_7\", \"Q17_Part_8\", \"Q17_Part_9\",\n                                 \"Q17_Part_10\", \"Q17_Part_11\", \"Q17_OTHER\"] \n                                 ].count().unstack().fillna(0).reset_index(name='17_counts')\ndf_q15_q17 = df_q15_q17.sort_values(by='17_counts', ascending = True)\n\ndf_q14_q15 = df_q14_q15.replace({'level_0' : \n                                 { 'Q14_Part_1' : 'Matplotlib', 'Q14_Part_2' : 'Seaborn',\n                                 \"Q14_Part_3\" : ' Plotly / Plotly Express' ,  \"Q14_Part_4\" : 'Ggplot / ggplot2',     \n                                \"Q14_Part_5\" : 'Shiny', \"Q14_Part_6\" : 'D3 js',\n                                \"Q14_Part_7\" : ' Altair', \"Q14_Part_8\" :' Bokeh', \n                                \"Q14_Part_9\" : ' Geoplotlib',  \"Q14_Part_10\" : 'Leaflet / Folium', \n                                \"Q14_Part_11\" : 'None', \"Q14_OTHER\": 'Other'\n                                 }})\n\n\n\ndf_q15_q17 = df_q15_q17.replace({'level_0' : \n                                 { 'Q17_Part_1' : 'Linear or Logistic Regression', 'Q17_Part_2' : 'Decision Trees or Random Forests',\n                                 \"Q17_Part_3\" : 'Gradient Boosting Machines' ,  \"Q17_Part_4\" : 'Bayesian Approaches',     \n                                \"Q17_Part_5\" : 'Evolutionary Approaches', \"Q17_Part_6\" : 'Dense Neural Networks',\n                                \"Q17_Part_7\" : 'Convolutional Neural Networks', \"Q17_Part_8\" :'Generative Adversarial Networks', \n                                \"Q17_Part_9\" : 'Recurrent Neural Networks',  \"Q17_Part_10\" : 'Transformer Networks', \n                                \"Q17_Part_11\" : 'None', \"Q17_OTHER\": 'Other'\n                                 }})\n\ndf_q14_q15_beginner = df_q14_q15[df_q14_q15['Q15']=='Beginner']\ndf_q14_q15_intermediate = df_q14_q15[df_q14_q15['Q15']=='Intermediate']\ndf_q14_q15_advanced = df_q14_q15[df_q14_q15['Q15']=='Advanced']\n\ndf_q15_q17_beginner = df_q15_q17[df_q15_q17['Q15']=='Beginner']\ndf_q15_q17_intermediate = df_q15_q17[df_q15_q17['Q15']=='Intermediate']\ndf_q15_q17_advanced = df_q15_q17[df_q15_q17['Q15']=='Advanced']\n\nfig = make_subplots(rows=1, cols=2, specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}]], horizontal_spacing = 0.005)\nfig.add_trace(go.Bar(y=df_q14_q15_beginner['level_0'], x=df_q14_q15_beginner['15_counts'], marker_color='#009999', name='Beginner (0-2 years)',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=1)\nfig.add_trace(go.Bar(y=df_q14_q15_intermediate['level_0'], x=df_q14_q15_intermediate['15_counts'], marker_color='#00FFCC', name='Intermediate (2-5 years)',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=1)\nfig.add_trace(go.Bar(y=df_q14_q15_advanced['level_0'], x=df_q14_q15_advanced['15_counts'], marker_color='#0033FF', name='Advanced (More than 5 years)',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=1)\nfig['layout']['xaxis'].update(autorange='reversed', title_text='DV tools')\n\n'''\nfig['layout']['xaxis'].update(\n    annotations=[\n    dict(\n        x=2, y=2, # annotation point\n        xref='x1', \n        yref='y1',\n        text='dict Text',\n        showarrow=True,\n        arrowhead=7,\n        ax=10,\n        ay=70\n    ),\n    dict(\n        ...\n        # if have multiple annotations\n    )\n])\n'''\n\n\nfig.add_trace(go.Bar(y=df_q15_q17_beginner['level_0'], x=df_q15_q17_beginner['17_counts'], marker_color='#009999', name='Beginner (0-2 years)',\n                      orientation='h', opacity=0.8), \n                     row=1, col=2)\nfig.add_trace(go.Bar(y=df_q15_q17_intermediate['level_0'], x=df_q15_q17_intermediate['17_counts'], marker_color='#00FFCC', name='Intermediate (2-5 years)',\n                     orientation='h', opacity=0.8 ),\n                     row=1, col=2)\nfig.add_trace(go.Bar(y=df_q15_q17_advanced['level_0'], x=df_q15_q17_advanced['17_counts'], marker_color='#0033FF', name='Advanced (More than 5 years)',\n                     orientation='h', opacity=0.8),\n                     row=1, col=2)\nfig['layout']['xaxis2'].update(title_text='ML algorithms')\n#fig.update_yaxes(visible=False, categoryorder='total ascending')\nfig.update_layout(title_text='Participants using data visualization (DV) tools and machine learning (ML) <br> algorithms as per participant\\'s experience in ML', title_x=0.5, title_y=0.92,\n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5),\n                    yaxis=dict(side='left') , yaxis2=dict(side='right'))","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.580061Z","iopub.status.idle":"2022-04-04T08:41:04.580673Z","shell.execute_reply.started":"2022-04-04T08:41:04.580497Z","shell.execute_reply":"2022-04-04T08:41:04.580522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_10\">3.10. Job vs Industry </font>","metadata":{}},{"cell_type":"code","source":"df_q5_q20 = df_fin[['Q5', 'Q20']]\nnames = ['Job role', 'Industry']\ndf_q5_q20.columns = names\n\ndf_q5_q20 = df_q5_q20[(df_q5_q20['Job role'] != \"Student\") & (df_q5_q20['Job role'] != \"Currently not employed\")] # Since they cannot be working in any industry right now\nfig = px.box(df_q5_q20, x=\"Job role\", y=\"Industry\", notched=True)\nfig.update_layout(title_text =\"Job vs Industry\", title_x = 0.5, title_y = 0.93)\nfig.update_xaxes( categoryorder='total ascending')\n \nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.581563Z","iopub.status.idle":"2022-04-04T08:41:04.582151Z","shell.execute_reply.started":"2022-04-04T08:41:04.581976Z","shell.execute_reply":"2022-04-04T08:41:04.581995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_11\">3.11. Salary VS Industry VS experience in ML </font>","metadata":{}},{"cell_type":"code","source":"df_q15_q20_q25 = df_fin[['Q20', 'Q25', 'Q15']].dropna() \n\ndf_q15_q20_q25 ['Q15'] = df_q15_q20_q25['Q15'].replace(dict.fromkeys(['I do not use machine learning methods', 'Under 1 year', '1-2 years'],'Beginner'))\ndf_q15_q20_q25 ['Q15'] = df_q15_q20_q25['Q15'].replace(dict.fromkeys(['2-3 years', '3-4 years', '4-5 years'],'Intermediate'))\ndf_q15_q20_q25 ['Q15'] = df_q15_q20_q25['Q15'].replace(dict.fromkeys(['5-10 years', '10-20 years', '20 or more years'],'Advanced'))\n\ndf_q15_q20_q25 ['Q25'] = df_q15_q20_q25['Q25'].replace(dict.fromkeys([ '$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999',\n                                                                       '4,000-4,999', '5,000-7,499', '7,500-9,999'],'Lower-income bracket'))\ndf_q15_q20_q25 ['Q25'] = df_q15_q20_q25['Q25'].replace(dict.fromkeys([ '10,000-14,999', '15,000-19,999', \n                                                                      '20,000-24,999', '25,000-29,999', '30,000-39,999',\n                                                                       '40,000-49,999'],'Lower-middle-income bracket'))\ndf_q15_q20_q25 ['Q25'] = df_q15_q20_q25['Q25'].replace(dict.fromkeys([ '50,000-59,999', '60,000-69,999', '70,000-79,999',\n                                                                      '80,000-89,999', '90,000-99,999', '100,000-124,999',\n                                                                       '125,000-149,999'],'Upper-middle income bracket'))\ndf_q15_q20_q25 ['Q25'] = df_q15_q20_q25['Q25'].replace(dict.fromkeys(['150,000-199,999','200,000-249,999',\n                                                                       '250,000-299,999', '300,000-499,999',\n                                                                       '$500,000-999,999', '>$1,000,000'],'Upper-income bracket'))\n\n\n\ndf_q15_q20_q25 = round(pd.crosstab(df_q15_q20_q25['Q25'], [df_q15_q20_q25['Q20'],df_q15_q20_q25['Q15']], normalize='index'), 2).T.reset_index()\n\ndf_q15_q20_q25_beginner = df_q15_q20_q25[df_q15_q20_q25['Q15']=='Beginner']\ndf_q15_q20_q25_intermediate = df_q15_q20_q25[df_q15_q20_q25['Q15']=='Intermediate']\ndf_q15_q20_q25_expert = df_q15_q20_q25[df_q15_q20_q25['Q15']=='Advanced']\n\n\nfig = make_subplots(rows=1, cols=4, shared_yaxes=True, horizontal_spacing=0, vertical_spacing=0)      \n\nfig.add_trace(go.Bar(y=df_q15_q20_q25_beginner['Q20'], x=df_q15_q20_q25_beginner['Lower-income bracket'], marker_color='#0033FF', name='Beginner-level experience',\n                     showlegend=False, orientation='h', opacity=0.8,),\n                     row=1, col=1)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_intermediate['Q20'], x=df_q15_q20_q25_intermediate['Lower-income bracket'], marker_color='#00CCFF', name='Intermediate-level experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=1)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_expert['Q20'], x=df_q15_q20_q25_expert['Lower-income bracket'], marker_color='#009999', name='Expert-level experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=1)\n\nfig.add_trace(go.Bar(y=df_q15_q20_q25_beginner['Q20'], x=df_q15_q20_q25_beginner['Lower-middle-income bracket'], marker_color='#0033FF', name='Beginner-level experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=2)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_intermediate['Q20'], x=df_q15_q20_q25_intermediate['Lower-middle-income bracket'], marker_color='#00CCFF', name='Intermediate-level experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=2)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_expert['Q20'], x=df_q15_q20_q25_expert['Lower-middle-income bracket'], marker_color='#009999', name='Expert-level experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=2)\n\nfig.add_trace(go.Bar(y=df_q15_q20_q25_beginner['Q20'], x=df_q15_q20_q25_beginner['Upper-middle income bracket'], marker_color='#0033FF', name='Beginner-level experience',\n                     showlegend=False, orientation='h', opacity=0.8),\n                     row=1, col=3)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_intermediate['Q20'], x=df_q15_q20_q25_intermediate['Upper-middle income bracket'], marker_color='#00CCFF', name='Intermediate-level experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=3)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_expert['Q20'], x=df_q15_q20_q25_expert['Upper-middle income bracket'], marker_color='#009999', name='Expert-level experience',\n                     orientation='h', showlegend=False, opacity=0.8),\n                     row=1, col=3)\n\nfig.add_trace(go.Bar(y=df_q15_q20_q25_beginner['Q20'], x=df_q15_q20_q25_beginner['Upper-income bracket'], marker_color='#0033FF', name='Beginner-level experience',\n                    orientation='h', opacity=0.8),\n                     row=1, col=4)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_intermediate['Q20'], x=df_q15_q20_q25_intermediate['Upper-income bracket'], marker_color='#00CCFF', name='Intermediate-level experience',\n                     orientation='h', opacity=0.8),\n                     row=1, col=4)\nfig.add_trace(go.Bar(y=df_q15_q20_q25_expert['Q20'], x=df_q15_q20_q25_expert['Upper-income bracket'], marker_color='#009999', name='Expert-level experience',\n                     orientation='h', opacity=0.8),\n                     row=1, col=4)\n\nfig.update_layout(height=550, \n                  title_text=\"Yearly compensation of participants based on the industrial sector <br> they work in and their experience in using ML methods\", title_x =0.5, title_y = 0.96,\n                  template=\"plotly_white\", barmode='stack',\n                  autosize=True,\n                 # margin=dict(t=80, b=50, l=70, r=40),\n                 plot_bgcolor='white', paper_bgcolor='white', \n                title_font=dict(size=21, color='#222A2A', family=\"Muli, sans-serif\"),\n                         font=dict(color='#222A2A'),\n                         legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5),\n                  margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=80,\n                        ),\n                 )\n\nfig['layout']['xaxis'].update(title_text='Lower-income bracket', title_font=dict(size=12))\nfig['layout']['xaxis2'].update(title_text='Lower-middle income bracket', title_font=dict(size=12))\nfig['layout']['xaxis3'].update(title_text='Upper-middle income bracket', title_font=dict(size=12))\nfig['layout']['xaxis4'].update(title_text='Upper-income bracket', title_font=dict(size=12))\n\nfig.update_xaxes(zeroline=False,showticklabels=False, ticks=\"\")\nfig.update_traces(hovertemplate=None, marker=dict(line=dict(width=0)))\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.583186Z","iopub.status.idle":"2022-04-04T08:41:04.583818Z","shell.execute_reply.started":"2022-04-04T08:41:04.583654Z","shell.execute_reply":"2022-04-04T08:41:04.583674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_11\">3.11. XX  </font>","metadata":{}},{"cell_type":"code","source":"df_q21_q22 = pd.crosstab(df_fin['Q21'], df_fin['Q22']).reset_index()\ndf_q21_q22 = df_q21_q22.loc(axis=0)[0,4,3,2,1].reset_index(drop=True)\n\nfig = go.Figure()\n\nfig = go.Figure(data=[\n    go.Bar(x=df_q21_q22[\"Q21\"], y=df_q21_q22['0'], marker_color = '#065769', name='People responsible: 0',textposition = 'outside', text = df_q21_q22['0']),\n    go.Bar(x=df_q21_q22[\"Q21\"], y=df_q21_q22['1-2'], marker_color = '#15778c', name='People responsible: 1-2',textposition = 'outside', text = df_q21_q22['1-2']),\n    go.Bar(x=df_q21_q22[\"Q21\"], y=df_q21_q22['3-4'], marker_color = '#2d9cb5', name='People responsible: 3-4',textposition = 'outside', text = df_q21_q22['3-4']),\n    go.Bar(x=df_q21_q22[\"Q21\"], y=df_q21_q22['5-9'], marker_color = '#41b7d1', name='People responsible: 5-9', textposition = 'outside',text = df_q21_q22['5-9']),\n    go.Bar(x=df_q21_q22[\"Q21\"], y=df_q21_q22['10-14'], marker_color = '#55cbe6', name='People responsible: 10-14', textposition = 'outside',text = df_q21_q22['10-14']),\n    go.Bar(x=df_q21_q22[\"Q21\"], y=df_q21_q22['15-19'], marker_color = '#6ddaf2', name='People responsible: 15-19',textposition = 'outside', text = df_q21_q22['15-19']),\n    go.Bar(x=df_q21_q22[\"Q21\"], y=df_q21_q22['20+'], marker_color = '#92e9fc', name='People responsible: 20+',textposition = 'outside', text = df_q21_q22['20+']),\n    go.Line(x=df_q21_q22[\"Q21\"], y=df_q21_q22['0'], marker_color = '#065769', showlegend=False),\n    go.Line(x=df_q21_q22[\"Q21\"], y=df_q21_q22['1-2'], marker_color = '#15778c', showlegend=False),\n    go.Line(x=df_q21_q22[\"Q21\"], y=df_q21_q22['3-4'], marker_color = '#2d9cb5', showlegend=False),\n    go.Line(x=df_q21_q22[\"Q21\"], y=df_q21_q22['5-9'], marker_color = '#41b7d1', showlegend=False),\n    go.Line(x=df_q21_q22[\"Q21\"], y=df_q21_q22['10-14'], marker_color = '#55cbe6', showlegend=False),\n    go.Line(x=df_q21_q22[\"Q21\"], y=df_q21_q22['15-19'], marker_color = '#6ddaf2', showlegend=False),\n    go.Line(x=df_q21_q22[\"Q21\"], y=df_q21_q22['20+'], marker_color = '#92e9fc', showlegend=False)\n])\n\n\n\nfig.add_annotation(\n        x=2.0,\n        y=1800,\n        xref=\"x\",\n        yref=\"y\",\n        text=\"Following the lines within this circle, normally each line should decrease as we move up <br> to companies with more employess. But even after steady decline, <br> some companies still seem to have very less people in <br> data science team as per their company size.\",\n        showarrow=False,\n        font=dict(\n            family=\"Muli, sans-serif\",\n            size=11,\n            color=\"#222A2A\"\n            ),\n        align=\"center\",\n        bordercolor=\"#c7c7c7\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"#ffffff\",\n        opacity=0.8\n        )\n\n\n\nfig.update_layout(\n    shapes=[\n        dict(type=\"circle\", xref=\"x\", yref=\"y\",\n            x0=0.2, y0=300, x1=0.7, y1=1400, line_width=3, line=dict(color='red')),\n        dict(type=\"circle\", xref=\"x\", yref=\"y\",\n            x0=3.8, y0=150, x1=4.1, y1=500, line_width=3, line=dict(color='red')),\n    ])\n\n\nfig.update_layout(                \n    title_text='Company size VS number of data science human workforce',\n    height=500, title_x = 0.5, yaxis_title=\" \", xaxis_title=\"Companies\", title_y = 0.93,\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n)\nfig.update_xaxes(visible=True, matches='x')\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.584727Z","iopub.status.idle":"2022-04-04T08:41:04.585249Z","shell.execute_reply.started":"2022-04-04T08:41:04.585095Z","shell.execute_reply":"2022-04-04T08:41:04.585112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_13\">3.13. Companies incorporating ML and their people to workload ratio</font>","metadata":{}},{"cell_type":"code","source":"df_q22_q23_q24 = df_fin.copy()\n\ndf_q22_q23_q24 = df_q22_q23_q24.groupby(['Q22','Q23'])[[\"Q24_Part_1\", \"Q24_Part_2\", \"Q24_Part_3\",\n                                 \"Q24_Part_4\", \"Q24_Part_5\", \"Q24_Part_6\",\n                                 \"Q24_Part_7\", \"Q24_OTHER\",] \n                                 ].count().unstack().fillna(0).reset_index()\ndf_q22_q23_q24 = df_q22_q23_q24.loc(axis=0)[0,1,5,6,2,3,4].reset_index(drop=True)\n#df_q22_q23_q24 = df_q22_q23_q24.sort_values(by='24_counts', ascending = True)\ndf_q22_q23_q24 = df_q22_q23_q24.T.reset_index()[1:]\ncolumn_names = ['Q22', 'Q23', '0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+']\ndf_q22_q23_q24.columns = column_names\n\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_Part_1': 'Analyzing and understanding data to influence product/business decisions'})\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_Part_2': 'Building and/or running data infrastructure for storing, analyzing, and operationalizing data'})\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_Part_3': 'Building prototypes to explore applying machine learning to new areas'})\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_Part_4': 'Building and/or running machine learning service that operationally improve product/workflows'})\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_Part_5': 'Experimentation and iteration for improving existing ML models'})\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_Part_6': 'Researching for advancing the state of the art of machine learning'})\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_Part_7': 'None'})\ndf_q22_q23_q24['Q22'] = df_q22_q23_q24['Q22'].replace({'Q24_OTHER': 'Other'})\n\ndf_q22_q23_q24_1_1 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'Analyzing and understanding data to influence product/business decisions'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_1_2 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'Building and/or running data infrastructure for storing, analyzing, and operationalizing data'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_1_3 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'Building prototypes to explore applying machine learning to new areas'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_1_4 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'Building and/or running machine learning service that operationally improve product/workflows'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_1_5 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'Experimentation and iteration for improving existing ML models'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_1_6 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'Researching for advancing the state of the art of machine learning'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_1_7 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'None'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_1_8 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'I do not know'][df_q22_q23_q24.Q22 == 'Other'].drop(['Q22', 'Q23'], axis=1)\n\ndf_q22_q23_q24_1 = np.concatenate((df_q22_q23_q24_1_1, df_q22_q23_q24_1_2, df_q22_q23_q24_1_3, df_q22_q23_q24_1_4, df_q22_q23_q24_1_5, df_q22_q23_q24_1_6, df_q22_q23_q24_1_7, df_q22_q23_q24_1_8))\n\ndf_q22_q23_q24_2_1 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'Analyzing and understanding data to influence product/business decisions'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_2_2 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'Building and/or running data infrastructure for storing, analyzing, and operationalizing data'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_2_3 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'Building prototypes to explore applying machine learning to new areas'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_2_4 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'Building and/or running machine learning service that operationally improve product/workflows'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_2_5 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'Experimentation and iteration for improving existing ML models'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_2_6 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'Researching for advancing the state of the art of machine learning'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_2_7 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'None'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_2_8 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'No (we do not use ML methods)'][df_q22_q23_q24.Q22 == 'Other'].drop(['Q22', 'Q23'], axis=1)\n\ndf_q22_q23_q24_2 = np.concatenate((df_q22_q23_q24_2_1, df_q22_q23_q24_2_2, df_q22_q23_q24_2_3, df_q22_q23_q24_2_4, df_q22_q23_q24_2_5, df_q22_q23_q24_2_6, df_q22_q23_q24_2_7, df_q22_q23_q24_2_8))\n\ndf_q22_q23_q24_3_1 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'Analyzing and understanding data to influence product/business decisions'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_3_2 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'Building and/or running data infrastructure for storing, analyzing, and operationalizing data'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_3_3 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'Building prototypes to explore applying machine learning to new areas'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_3_4 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'Building and/or running machine learning service that operationally improve product/workflows'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_3_5 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'Experimentation and iteration for improving existing ML models'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_3_6 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'Researching for advancing the state of the art of machine learning'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_3_7 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'None'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_3_8 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We are exploring ML methods (and may one day put a model into production)'][df_q22_q23_q24.Q22 == 'Other'].drop(['Q22', 'Q23'], axis=1)\n\ndf_q22_q23_q24_3 = np.concatenate((df_q22_q23_q24_3_1, df_q22_q23_q24_3_2, df_q22_q23_q24_3_3, df_q22_q23_q24_3_4, df_q22_q23_q24_3_5, df_q22_q23_q24_3_6, df_q22_q23_q24_3_7, df_q22_q23_q24_3_8))\n\ndf_q22_q23_q24_4_1 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'Analyzing and understanding data to influence product/business decisions'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_4_2 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'Building and/or running data infrastructure for storing, analyzing, and operationalizing data'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_4_3 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'Building prototypes to explore applying machine learning to new areas'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_4_4 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'Building and/or running machine learning service that operationally improve product/workflows'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_4_5 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'Experimentation and iteration for improving existing ML models'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_4_6 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'Researching for advancing the state of the art of machine learning'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_4_7 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'None'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_4_8 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We have well established ML methods (i.e., models in production for more than 2 years)'][df_q22_q23_q24.Q22 == 'Other'].drop(['Q22', 'Q23'], axis=1)\n\ndf_q22_q23_q24_4 = np.concatenate((df_q22_q23_q24_4_1, df_q22_q23_q24_4_2, df_q22_q23_q24_4_3, df_q22_q23_q24_4_4, df_q22_q23_q24_4_5, df_q22_q23_q24_4_6, df_q22_q23_q24_4_7, df_q22_q23_q24_4_8))\n\n\ndf_q22_q23_q24_5_1 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'Analyzing and understanding data to influence product/business decisions'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_5_2 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'Building and/or running data infrastructure for storing, analyzing, and operationalizing data'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_5_3 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'Building prototypes to explore applying machine learning to new areas'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_5_4 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'Building and/or running machine learning service that operationally improve product/workflows'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_5_5 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'Experimentation and iteration for improving existing ML models'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_5_6 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'Researching for advancing the state of the art of machine learning'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_5_7 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'None'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_5_8 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We recently started using ML methods (i.e., models in production for less than 2 years)'][df_q22_q23_q24.Q22 == 'Other'].drop(['Q22', 'Q23'], axis=1)\n\ndf_q22_q23_q24_5 = np.concatenate((df_q22_q23_q24_5_1, df_q22_q23_q24_5_2, df_q22_q23_q24_5_3, df_q22_q23_q24_5_4, df_q22_q23_q24_5_5, df_q22_q23_q24_5_6, df_q22_q23_q24_5_7, df_q22_q23_q24_5_8))\n\n\ndf_q22_q23_q24_6_1 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'Analyzing and understanding data to influence product/business decisions'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_6_2 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'Building and/or running data infrastructure for storing, analyzing, and operationalizing data'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_6_3 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'Building prototypes to explore applying machine learning to new areas'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_6_4 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'Building and/or running machine learning service that operationally improve product/workflows'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_6_5 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'Experimentation and iteration for improving existing ML models'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_6_6 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'Researching for advancing the state of the art of machine learning'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_6_7 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'None'].drop(['Q22', 'Q23'], axis=1)\ndf_q22_q23_q24_6_8 = df_q22_q23_q24[df_q22_q23_q24.Q23 == 'We use ML methods for generating insights (but do not put working models into production)'][df_q22_q23_q24.Q22 == 'Other'].drop(['Q22', 'Q23'], axis=1)\n\ndf_q22_q23_q24_6 = np.concatenate((df_q22_q23_q24_6_1, df_q22_q23_q24_6_2, df_q22_q23_q24_6_3, df_q22_q23_q24_6_4, df_q22_q23_q24_6_5, df_q22_q23_q24_6_6, df_q22_q23_q24_6_7, df_q22_q23_q24_6_8))\n\n\nfig = go.Figure(data=[go.Heatmap(\n                   z=df_q22_q23_q24_1, zmid = 450, text=df_q22_q23_q24_1,\n                   x=['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+'], name='Not sure',\n                   y=['Analyzing and understanding data to influence product/business decisions',\n                                       'Building and/or running data infrastructure for storing, analyzing, and operationalizing data',\n                                       'Building prototypes to explore applying machine learning to new areas',\n                                       'Building and/or running machine learning service that operationally improve product/workflows',\n                                       'Experimentation and iteration for improving existing ML models',\n                                       'Researching for advancing the state of the art of machine learning',\n                                       'None', 'Other'], colorscale=px.colors.diverging.BrBG, \n                                       hoverongaps = False),\n                      go.Heatmap(\n                   z=df_q22_q23_q24_2, zmid = 450,\n                   x=['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+'], name='Do not use ML methods',\n                   y=['Analyzing and understanding data to influence product/business decisions',\n                                       'Building and/or running data infrastructure for storing, analyzing, and operationalizing data',\n                                       'Building prototypes to explore applying machine learning to new areas',\n                                       'Building and/or running machine learning service that operationally improve product/workflows',\n                                       'Experimentation and iteration for improving existing ML models',\n                                       'Researching for advancing the state of the art of machine learning',\n                                       'None', 'Other'], colorscale=px.colors.diverging.BrBG,\n                                       hoverongaps = False),\n                      go.Heatmap(\n                   z=df_q22_q23_q24_3, zmid = 450,\n                   x=['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+'], name='May one day put a model into production',\n                   y=['Analyzing and understanding data to influence product/business decisions',\n                                       'Building and/or running data infrastructure for storing, analyzing, and operationalizing data',\n                                       'Building prototypes to explore applying machine learning to new areas',\n                                       'Building and/or running machine learning service that operationally improve product/workflows',\n                                       'Experimentation and iteration for improving existing ML models',\n                                       'Researching for advancing the state of the art of machine learning',\n                                       'None', 'Other'], colorscale=px.colors.diverging.BrBG,\n                                       hoverongaps = False),\n                      go.Heatmap(\n                   z=df_q22_q23_q24_4, zmid = 450,\n                   x=['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+'], name='Models in production for more than 2 years',\n                   y=['Analyzing and understanding data to influence product/business decisions',\n                                       'Building and/or running data infrastructure for storing, analyzing, and operationalizing data',\n                                       'Building prototypes to explore applying machine learning to new areas',\n                                       'Building and/or running machine learning service that operationally improve product/workflows',\n                                       'Experimentation and iteration for improving existing ML models',\n                                       'Researching for advancing the state of the art of machine learning',\n                                       'None', 'Other'], colorscale=px.colors.diverging.BrBG,\n                                       hoverongaps = False),\n                      go.Heatmap(\n                   z=df_q22_q23_q24_5, zmid = 450,\n                   x=['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+'], name='Models in production for less than 2 years',\n                   y=['Analyzing and understanding data to influence product/business decisions',\n                                       'Building and/or running data infrastructure for storing, analyzing, and operationalizing data',\n                                       'Building prototypes to explore applying machine learning to new areas',\n                                       'Building and/or running machine learning service that operationally improve product/workflows',\n                                       'Experimentation and iteration for improving existing ML models',\n                                       'Researching for advancing the state of the art of machine learning',\n                                       'None', 'Other'], colorscale=px.colors.diverging.BrBG, #px.colors.sequential.Tealgrn,\n                                       hoverongaps = False),\n                      go.Heatmap(\n                   z=df_q22_q23_q24_6, zmid = 450,\n                   x=['0', '1-2', '3-4', '5-9', '10-14', '15-19', '20+'], name='Do not put working models into production',\n                   y=['Analyzing and understanding data to influence product/business decisions',\n                                       'Building and/or running data infrastructure for storing, analyzing, and operationalizing data',\n                                       'Building prototypes to explore applying machine learning to new areas',\n                                       'Building and/or running machine learning service that operationally improve product/workflows',\n                                       'Experimentation and iteration for improving existing ML models',\n                                       'Researching for advancing the state of the art of machine learning',\n                                       'None', 'Other'], \n                          colorscale=px.colors.diverging.BrBG,\n                                       hoverongaps = False),\n                     ])\n\n    \nfig.update_xaxes(side=\"top\", title_text = \"Individuals responsible for data science\")\nfig.update_yaxes(title_text = \"Purpose of the respective workers\")\n\nfig.update_layout( \n     title_text = 'Companies incorporating Machine Learning and their people to workload ratio',\n     title_x = 0.5, title_y = 0.96,\n     margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b = 0\n                        ),\n     updatemenus=[\n        dict(\n            active=0,\n            x=-0.5,\n            y=1,\n            buttons=list(\n                [\n                    dict(\n                        label=\"Not sure\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [True, False, False, False, False, False]},\n                        ],\n                    ),\n                    dict(\n                        label=\"ML methods not used\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [False, True, False, False, False, False]},\n                        ],\n                    ),\n                    dict(\n                        label=\"Exploring ML methods\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [False, False, True, False, False, False]},\n                        ],\n                    ),\n                    dict(\n                        label=\"Well established in ML methods\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [False, False, False, True, False, False]},\n                        ],\n                    ),\n                    dict(\n                        label=\"Recently started using ML methods\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [False, False, False, False, True, False]},\n                        ],\n                    ),\n                    dict(\n                        label=\"Use ML methods for generating insights\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [False, False, False, False, False, True]},\n                        ],\n                    ),\n                ]\n            ),\n        )\n    ]\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.586423Z","iopub.status.idle":"2022-04-04T08:41:04.586912Z","shell.execute_reply.started":"2022-04-04T08:41:04.586736Z","shell.execute_reply":"2022-04-04T08:41:04.586756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_14\">3.14. Compare popular programming language with various demographic informations </font>","metadata":{}},{"cell_type":"code","source":"#Python R/SQL demographic plot\ndf_copy = df_fin.copy()\ndf_copy = df_copy[['Q1', 'Q2', 'Q4', 'Q5', 'Q6', 'Q25', 'Q8']]\ndf_copy['Q2'] = np.where(((df_copy['Q2'] != 'Man') & (df_copy['Q2'] != 'Woman')),'Other/Undisclosed',df_copy['Q2'])\ndf_copy['Q6'] = df_copy['Q6'].replace(dict.fromkeys(['I have never written code', '< 1 years', '1-3 years'],'Beginner'))\ndf_copy['Q6'] = df_copy['Q6'].replace(dict.fromkeys(['3-5 years', '5-10 years'],'Intermediate'))\ndf_copy['Q6'] = df_copy['Q6'].replace(dict.fromkeys(['10-20 years', '20+ years'],'Advanced'))\ndf_copy['Q4'] = np.where((df_copy['Q4'] == 'No formal education past high school'),'High school passout',df_copy['Q4'])\ndf_copy['Q4'] = np.where((df_copy['Q4'] == 'Some college/university study without earning a bachelor‚Äôs degree'),'Higher study w/o bachelor‚Äôs',df_copy['Q4'])\ndf_copy['Q5'] = np.where((df_copy['Q5'] == 'Machine Learning Engineer'),'ML Engineer',df_copy['Q5'])\ndf_copy['Q5'] = np.where((df_copy['Q5'] == 'Developer Relations/Advocacy'),'Dev Relations/Advocacy',df_copy['Q5'])\ndf_copy ['Q25'] = df_copy['Q25'].replace(dict.fromkeys([ '$0-999', '1,000-1,999', '2,000-2,999', '3,000-3,999',\n                                                                       '4,000-4,999', '5,000-7,499', '7,500-9,999'],'Lower-income'))\ndf_copy ['Q25'] = df_copy['Q25'].replace(dict.fromkeys([ '10,000-14,999', '15,000-19,999', \n                                                                      '20,000-24,999', '25,000-29,999', '30,000-39,999',\n                                                                       '40,000-49,999'],'Lower-middle-income'))\ndf_copy ['Q25'] = df_copy['Q25'].replace(dict.fromkeys([ '50,000-59,999', '60,000-69,999', '70,000-79,999',\n                                                                      '80,000-89,999', '90,000-99,999', '100,000-124,999',\n                                                                       '125,000-149,999'],'Upper-middle income'))\ndf_copy ['Q25'] = df_copy['Q25'].replace(dict.fromkeys(['150,000-199,999','200,000-249,999',\n                                                                       '250,000-299,999', '300,000-499,999',\n                                                                       '$500,000-999,999', '>$1,000,000'],'Upper-income'))\n\n\n\ndf_py = df_copy.copy()\ndf_py = df_py[df_py['Q8'] == 'Python']\n\ndf_rsql =df_copy.copy()\ndf_rsql = df_rsql[(df_rsql['Q8'] == 'R') | (df_rsql['Q8'] == 'SQL')]\n\ndf_py_age = df_py.groupby(['Q1']).size().reset_index().rename(columns={0:'age count'})\ndf_py_gen = df_py.groupby(['Q2']).size().reset_index().rename(columns={0:'gen count'})\ndf_py_edu = df_py.groupby(['Q4']).size().reset_index().rename(columns={0:'edu count'})\ndf_py_ocp = df_py.groupby(['Q5']).size().reset_index().rename(columns={0:'ocp count'})\ndf_py_cod = df_py.groupby(['Q6']).size().reset_index().rename(columns={0:'cod count'})\ndf_py_sal = df_py.groupby(['Q25']).size().reset_index().rename(columns={0:'sal count'})\n\ndf_rsql_age = df_rsql.groupby(['Q1']).size().reset_index().rename(columns={0:'age count'})\ndf_rsql_gen = df_rsql.groupby(['Q2']).size().reset_index().rename(columns={0:'gen count'})\ndf_rsql_edu = df_rsql.groupby(['Q4']).size().reset_index().rename(columns={0:'edu count'})\ndf_rsql_ocp = df_rsql.groupby(['Q5']).size().reset_index().rename(columns={0:'ocp count'})\ndf_rsql_cod = df_rsql.groupby(['Q6']).size().reset_index().rename(columns={0:'cod count'})\ndf_rsql_sal = df_rsql.groupby(['Q25']).size().reset_index().rename(columns={0:'sal count'})\n\nfig = make_subplots(rows=2, cols=3, horizontal_spacing=0.035, vertical_spacing=0.1)                    \nfig.add_trace(go.Bar(x=df_py_age['Q1'], y=df_py_age['age count'], marker_color='teal', name='Python',textposition='outside',\n                     text=df_py_age['age count'], opacity=0.8, showlegend=False),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_rsql_age['Q1'], y=df_rsql_age['age count'], marker_color='orange', name='R/SQL',textposition='outside',\n                      text=df_rsql_age['age count'], opacity=0.8, showlegend=False),\n                     row=1, col=1)\n\nfig.add_trace(go.Bar(x=df_py_gen['Q2'], y=df_py_gen['gen count'], marker_color='teal', name='Python',textposition='outside',\n                     text=df_py_gen['gen count'], opacity=0.8, showlegend=False),\n                     row=1, col=2)\nfig.add_trace(go.Bar(x=df_rsql_gen['Q2'], y=df_rsql_gen['gen count'], marker_color='orange', name='R/SQL',textposition='outside',\n                      text=df_rsql_gen['gen count'], opacity=0.8, showlegend=False),\n                     row=1, col=2)\n\nfig.add_trace(go.Bar(x=df_py_edu['Q4'], y=df_py_edu['edu count'], marker_color='teal', name='Python',textposition='outside',\n                     text=df_py_edu['edu count'], opacity=0.8, showlegend=False),\n                     row=2, col=2)\nfig.add_trace(go.Bar(x=df_rsql_edu['Q4'], y=df_rsql_edu['edu count'], marker_color='orange', name='R/SQL',textposition='outside',\n                      text=df_rsql_edu['edu count'], opacity=0.8, showlegend=False),\n                     row=2, col=2)\n\nfig.add_trace(go.Bar(x=df_py_ocp['Q5'], y=df_py_ocp['ocp count'], marker_color='teal', name='Python',textposition='outside',\n                     text=df_py_ocp['ocp count'], opacity=0.8, showlegend=False),\n                     row=2, col=1)\nfig.add_trace(go.Bar(x=df_rsql_ocp['Q5'], y=df_rsql_ocp['ocp count'], marker_color='orange', name='R/SQL',textposition='outside',\n                      text=df_rsql_ocp['ocp count'], opacity=0.8, showlegend=False),\n                     row=2, col=1)\n\nfig.add_trace(go.Bar(x=df_py_cod['Q6'], y=df_py_cod['cod count'], marker_color='teal', name='Python',textposition='outside',\n                     text=df_py_cod['cod count'], opacity=0.8, showlegend=False),\n                     row=1, col=3)\nfig.add_trace(go.Bar(x=df_rsql_cod['Q6'], y=df_rsql_cod['cod count'], marker_color='orange', name='R/SQL',textposition='outside',\n                      text=df_rsql_cod['cod count'], opacity=0.8, showlegend=False),\n                     row=1, col=3)\n\nfig.add_trace(go.Bar(x=df_py_sal['Q25'], y=df_py_sal['sal count'], marker_color='teal', name='Python',textposition='outside',\n                     text=df_py_sal['sal count'], opacity=0.8),\n                     row=2, col=3)\nfig.add_trace(go.Bar(x=df_rsql_sal['Q25'], y=df_rsql_sal['sal count'], marker_color='orange', name='R/SQL',textposition='outside',\n                      text=df_rsql_sal['sal count'], opacity=0.8),\n                     row=2, col=3)\n\nfig['layout']['xaxis5'].update(tickangle=90)\nfig['layout']['xaxis6'].update(tickangle=90)\nfig.update_layout(yaxis2 = dict(range=[0, 18000]), yaxis3 = dict(range=[0, 12500]),  yaxis6 = dict(range=[0, 6000]))\n\nfig.update_layout(height=750,\n                 title_text='Demographic plot of the most popular programming languages', title_x=0.5, \n                 legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1.05, xanchor=\"center\", x=0.5),\n                 hoverlabel=dict(font=dict(family='sans-serif', size=14)),\n                 \n                 annotations = [dict(\n                    x=0.93,\n                    y=1.06,    \n                    xref='paper',\n                    yref='paper',\n                    text=\"Coding experience\",\n                    showarrow = False,\n                    font=dict(\n                            family=\"Muli, sans-serif\",\n                            size=14,\n                            color=\"black\"\n                            ),\n                    bordercolor=\"white\"\n                ),\n                              dict(\n                    x=0.12,\n                    y=1.06,    \n                    xref='paper',\n                    yref='paper',\n                    text=\"Age\",\n                    showarrow = False,\n                    font=dict(\n                            family=\"Muli, sans-serif\",\n                            size=14,\n                            color=\"black\"\n                            ),\n                    bordercolor=\"white\"\n                ),\n                 dict(\n                    x=0.5,\n                    y=1.06,    \n                    xref='paper',\n                    yref='paper',\n                    text=\"Gender\",\n                    showarrow = False,\n                    font=dict(\n                            family=\"Muli, sans-serif\",\n                            size=14,\n                            color=\"black\"\n                            ),\n                    bordercolor=\"white\"\n                ),\n                 dict(\n                    x=0.10,\n                    y=-0.395,    \n                    xref='paper',\n                    yref='paper',\n                    text=\"Occupation\",\n                    showarrow = False,\n                    font=dict(\n                            family=\"Muli, sans-serif\",\n                            size=14,\n                            color=\"black\"\n                            ),\n                    bordercolor=\"white\"\n                ),  \n                  dict(\n                    x=0.5,\n                    y=-0.395,    \n                    xref='paper',\n                    yref='paper',\n                    text=\"Education level\",\n                    showarrow = False,\n                    font=dict(\n                            family=\"Muli, sans-serif\",\n                            size=14,\n                            color=\"black\"\n                            ),\n                    bordercolor=\"white\"\n                ),  \n                  dict(\n                    x=0.93,\n                    y=-0.395,    \n                    xref='paper',\n                    yref='paper',\n                    text=\"Yearly compensation\",\n                    showarrow = False,\n                    font=dict(\n                            family=\"Muli, sans-serif\",\n                            size=14,\n                            color=\"black\"\n                            ),\n                    bordercolor=\"white\"\n                )\n                               ]\n                 \n                 )\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.58797Z","iopub.status.idle":"2022-04-04T08:41:04.588583Z","shell.execute_reply.started":"2022-04-04T08:41:04.588383Z","shell.execute_reply":"2022-04-04T08:41:04.588407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_15\">3.15. Participants who work on ML methods and their spendings on computing platforms </font>","metadata":{}},{"cell_type":"code","source":"df_q26_q25_q15 = df_fin.copy()\ndf_q26_q25_q15_1 = df_q26_q25_q15[(df_q26_q25_q15['Q15'] == 'I do not use machine learning methods') | (df_q26_q25_q15['Q15'] == '1-2 years') | (df_q26_q25_q15['Q15'] == 'Under 1 year')]\ndf_q26_q25_q15_2 = df_q26_q25_q15[(df_q26_q25_q15['Q15'] == '4-5 years') | (df_q26_q25_q15['Q15'] == '3-4 years') | (df_q26_q25_q15['Q15'] == '2-3 years')]\ndf_q26_q25_q15_3 = df_q26_q25_q15[(df_q26_q25_q15['Q15'] == '5-10 years') | (df_q26_q25_q15['Q15'] == '10-20 years') | (df_q26_q25_q15['Q15'] == '20 or more years')]\n\n\nfig = go.Figure()\n\ndf_q26_q25_q15_1 = pd.crosstab(df_q26_q25_q15_1['Q25'], df_q26_q25_q15_1['Q26'], rownames=['Q25'], colnames=['Q26'])\ndf_q26_q25_q15_1 = df_q26_q25_q15_1.reset_index()\n\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_1['Q25'],\n        y=df_q26_q25_q15_1['$0 ($USD)'], \n        name=\"0\", mode='lines+markers',\n        marker_color=\"#023040\",\n    ),\n)\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_1['Q25'],\n        y=df_q26_q25_q15_1['$1-$99'], \n        name=\"1-99\",mode='lines+markers',\n        marker_color=\"#19647d\",\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_1['Q25'],\n        y=df_q26_q25_q15_1['$10,000-$99,999'], \n        name=\"10,000-99,999\",mode='lines+markers',\n        marker_color=\"#cc9e21\",\n    ),\n)\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_1['Q25'],\n        y=df_q26_q25_q15_1['$100,000 or more ($USD)'], \n        name=\"100,000+\",mode='lines+markers',\n        marker_color=\"#13b7ed\",\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_1['Q25'],\n        y=df_q26_q25_q15_1['$1000-$9,999'], \n        name=\"1000-9,999\",mode='lines+markers',\n        marker_color=\"#943d0a\",\n    ),\n)\n\n\n\ndf_q26_q25_q15_2 = pd.crosstab(df_q26_q25_q15_2['Q25'], df_q26_q25_q15_2['Q26'], rownames=['Q25'], colnames=['Q26'])\ndf_q26_q25_q15_2 = df_q26_q25_q15_2.reset_index()\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_2['Q25'],\n        y=df_q26_q25_q15_2['$0 ($USD)'], \n        name=\"0\",mode='lines+markers',\n        marker_color=\"#023040\",\n    ),\n)\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_2['Q25'],\n        y=df_q26_q25_q15_2['$1-$99'], \n        name=\"1-99\",mode='lines+markers',\n        marker_color=\"#19647d\",\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_2['Q25'],\n        y=df_q26_q25_q15_2['$10,000-$99,999'], \n        name=\"10,000-99,999\", mode='lines+markers',\n        marker_color=\"#cc9e21\",\n    ),\n)\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_2['Q25'],\n        y=df_q26_q25_q15_2['$100,000 or more ($USD)'],\n        name=\"100,000+\",mode='lines+markers',\n        marker_color=\"#13b7ed\",\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_2['Q25'],\n        y=df_q26_q25_q15_2['$1000-$9,999'], \n        name=\"1000-9,999\",mode='lines+markers',\n        marker_color=\"#943d0a\",\n    ),\n)\n\n\ndf_q26_q25_q15_3 = pd.crosstab(df_q26_q25_q15_3['Q25'], df_q26_q25_q15_3['Q26'], rownames=['Q25'], colnames=['Q26'])\ndf_q26_q25_q15_3 = df_q26_q25_q15_3.reset_index()\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_3['Q25'],\n        y=df_q26_q25_q15_3['$0 ($USD)'],\n        name=\"0\",mode='lines+markers',\n        marker_color=\"#023040\",\n    ),\n)\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_3['Q25'],\n        y=df_q26_q25_q15_3['$1-$99'],\n        name=\"1-99\",mode='lines+markers',\n        marker_color=\"#19647d\",\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_3['Q25'],\n        y=df_q26_q25_q15_3['$10,000-$99,999'],\n        name=\"10,000-99,999\",mode='lines+markers',\n        marker_color=\"#cc9e21\",\n    ),\n)\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_3['Q25'],\n        y=df_q26_q25_q15_3['$100,000 or more ($USD)'],\n        name=\"100,000+\",mode='lines+markers',\n        marker_color=\"#13b7ed\",\n    )\n)\n\nfig.add_trace(\n    go.Scatter(\n        x=df_q26_q25_q15_3['Q25'],\n        y=df_q26_q25_q15_3['$1000-$9,999'],\n        name=\"1000-9,999\",mode='lines+markers',\n        marker_color=\"#943d0a\",\n    ),\n)\n\n\n\nfig.update_layout(\n    template=\"simple_white\", title_text = 'Participants who work on ML methods and their spendings on computing platforms', \n    title_x = 0.5, title_y = 0.95, showlegend= True,\n    xaxis=dict(title_text=\"Current yearly compensation (approximate $USD)\"),\n    yaxis=dict(title_text=\"Number of people spending an amount <br> on computing services at home <br>(or at work) in the past 5 years <br> (approximate $USD)\"),\n    legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5),\n    #legend_title=\"Money spent\",\n)\n\nfig.update_layout(\n    updatemenus=[\n        dict(\n            type=\"buttons\",\n            direction=\"right\",\n            x=0.65,\n            y=0.95,\n            showactive=True,\n            buttons=list(\n                [\n                    dict(\n                        label=\"Beginners\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [True, True,True,True,True, False,False,False,False,False,False,False,False,False,False]},\n                        ],\n                    ),\n                    dict(\n                        label=\"Intermediates\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [False,False,False,False,False, True, True,True,True,True, False,False,False,False,False]},\n                        ],\n                    ),\n                    dict(\n                        label=\"Experts\",\n                        method=\"update\",\n                        args=[\n                            {\"visible\": [False,False,False,False,False,False,False,False,False,False,True, True,True,True,True]},\n                        ],\n                    ),\n                ]\n            ),\n        )\n    ]\n)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.589617Z","iopub.status.idle":"2022-04-04T08:41:04.590153Z","shell.execute_reply.started":"2022-04-04T08:41:04.589987Z","shell.execute_reply":"2022-04-04T08:41:04.590007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_16\">3.16. Participants who work on one cloud platform and their respective preferences</font>","metadata":{}},{"cell_type":"code","source":"df_q27a_q28 = df_fin.copy()\n\ndf_q27a_q28 = df_q27a_q28.groupby(['Q28'])[[\"Q27_A_Part_1\", \"Q27_A_Part_2\", \"Q27_A_Part_3\",\n                                 \"Q27_A_Part_4\", \"Q27_A_Part_5\", \"Q27_A_Part_6\",\n                                 \"Q27_A_Part_7\", \"Q27_A_Part_8\", \"Q27_A_Part_9\",\n                                 \"Q27_A_Part_10\", \"Q27_A_Part_11\", \"Q27_A_OTHER\",] \n                                 ].count().unstack().fillna(0).reset_index(name='counts').sort_values(['counts'], ascending=[False])\ndf_q27a_q28 = df_q27a_q28.loc[~(df_q27a_q28['counts'] == 0)]\n\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_1'),\n                                             'Amazon Web Services (AWS)',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_2'),\n                                             'Microsoft Azure',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_3'),\n                                             'Google Cloud Platform (GCP)',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_4'),\n                                             'IBM Cloud / Red Hat',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_5'),\n                                             'Oracle Cloud',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_6'),\n                                             'SAP Cloud',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_7'),\n                                             'Salesforce Cloud',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_8'),\n                                             'VMware Cloud',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_9'),\n                                             'Alibaba Cloud',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_10'),\n                                             'Tencent Cloud',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_Part_11'),\n                                             'None',df_q27a_q28['level_0'])\ndf_q27a_q28['level_0'] = np.where((df_q27a_q28['level_0'] == 'Q27_A_OTHER'),\n                                             'Other',df_q27a_q28['level_0'])\ncolumn_names = ['Q27a', 'Q28', 'counts']\ndf_q27a_q28.columns = column_names\n\ndf_q27a_q28= df_q27a_q28.replace({'They all had a similarly enjoyable developer experience': 'Similar experience for all'})\ndf_q27a_q28 = df_q27a_q28.loc[~((df_q27a_q28['Q27a'] == 'Other') | (df_q27a_q28['Q28'] == 'Other'))]\n\ndef genSankey(df,cat_cols=[],value_cols='',title=''):\n    # maximum of 6 value cols -> 6 colors\n    colorPalette = ['#0a4963', 'orange', 'lightblue']\n    labelList = []\n    colorNumList = []\n    for catCol in cat_cols:\n        labelListTemp =  list(set(df[catCol].values))\n        colorNumList.append(len(labelListTemp))\n        labelList = labelList + labelListTemp\n        \n    # remove duplicates from labelList\n    labelList = list(dict.fromkeys(labelList))\n    \n    # define colors based on number of levels\n    colorList = []\n    for idx, colorNum in enumerate(colorNumList):\n        colorList = colorList + [colorPalette[idx]]*colorNum\n        \n    # transform df into a source-target pair\n    for i in range(len(cat_cols)-1):\n        if i==0:\n            sourceTargetDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n            sourceTargetDf.columns = ['source','target','count']\n        else:\n            tempDf = df[[cat_cols[i],cat_cols[i+1],value_cols]]\n            tempDf.columns = ['source','target','count']\n            sourceTargetDf = pd.concat([sourceTargetDf,tempDf])\n        sourceTargetDf = sourceTargetDf.groupby(['source','target']).agg({'count':'sum'}).reset_index()\n        \n    # add index for source-target pair\n    sourceTargetDf['sourceID'] = sourceTargetDf['source'].apply(lambda x: labelList.index(x))\n    sourceTargetDf['targetID'] = sourceTargetDf['target'].apply(lambda x: labelList.index(x))\n    \n    # creating the sankey diagram\n    data = dict(\n        type='sankey',\n        node = dict(\n          pad = 15,\n          thickness = 20,\n          line = dict(\n            color = \"black\",\n            width = 0.5\n          ),\n          label = labelList,\n          color = colorList\n        ),\n        link = dict(\n          source = sourceTargetDf['sourceID'],\n          target = sourceTargetDf['targetID'],\n          value = sourceTargetDf['count']\n        )\n      )\n    \n    layout =  dict(\n        title = title,\n        font = dict(\n          size = 10\n        )\n    )\n       \n    fig = dict(data=[data], layout=layout)\n    return fig\n\nsank = genSankey(df_q27a_q28,cat_cols=['Q27a', 'Q28'],value_cols='counts')\n\nfig = go.Figure(sank)\n\nfig.update_layout(height = 400, width = 800,\n    template=\"simple_white\", title_text = 'Participants who work on one cloud platform and their respective preferences', \n    title_x = 0.5, title_y = 0.95, \n    margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=70,\n                        ),\n    annotations = [dict(\n        x=1,\n        y=1.1,    \n        xref='paper',\n        yref='paper',\n        text=\"Platform with the best developer experience\",\n        showarrow = False,\n        font=dict(\n                family=\"Muli, sans-serif\",\n                size=12,\n                color=\"black\"\n                ),\n        bordercolor=\"white\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"white\",\n        opacity=0.8\n    ),\n                  dict(\n        x=0,\n        y=1.1,    \n        xref='paper',\n        yref='paper',\n        text=\"Cloud computing platforms used on a regular basis\",\n        showarrow = False,\n        font=dict(\n                family=\"Muli, sans-serif\",\n                size=12,\n                color=\"black\"\n                ),\n        bordercolor=\"white\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"white\",\n        opacity=0.8\n    )]\n)\nfig.update_yaxes(visible = False)\nfig.update_xaxes(visible = False)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.591056Z","iopub.status.idle":"2022-04-04T08:41:04.59186Z","shell.execute_reply.started":"2022-04-04T08:41:04.591667Z","shell.execute_reply":"2022-04-04T08:41:04.591689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_17\">3.17. Big data products vs business tools usage and preference comparison</font>","metadata":{}},{"cell_type":"code","source":"fig = tools.make_subplots(rows=1, cols=2, specs=[[{}, {}]], shared_xaxes=True,\n                          shared_yaxes=False, vertical_spacing=0.001)\n\nQ32a_values = df_fin.loc[:,[\"Q32_A_Part_1\", \"Q32_A_Part_2\", \"Q32_A_Part_3\",\n                                 \"Q32_A_Part_4\", \"Q32_A_Part_5\", \"Q32_A_Part_6\",\n                                 \"Q32_A_Part_7\", \"Q32_A_Part_8\", \"Q32_A_Part_9\",\n                                 \"Q32_A_Part_10\", \"Q32_A_Part_11\",\"Q32_A_Part_12\", \"Q32_A_Part_13\",\n                                 \"Q32_A_Part_14\", \"Q32_A_Part_15\", \"Q32_A_Part_16\",\n                                 \"Q32_A_Part_17\", \"Q32_A_Part_18\", \"Q32_A_Part_19\",\n                                 \"Q32_A_OTHER\"]]\n\nbig_data_products = df_fin['Q33'].value_counts().reset_index(name='total')\ntrace0 = go.Scatter(\n                x=big_data_products['index'],\n                y=big_data_products['total'],\n                mode='lines+markers',\n                line=dict(color='teal'),showlegend=False,\n                name='big data products',\n)\n\ntrace1 = go.Bar(\n                x=Q32a_values.stack().unique(), y=Q32a_values.stack().value_counts().values, showlegend=False,\n    text =Q32a_values.stack().value_counts().values,\n                marker=dict(color='lightblue',line=dict(color='teal',width=1)), textposition='outside',\n                name='big data products',\n                \n)\nfig.append_trace(trace0, 1, 1)\nfig.append_trace(trace1, 1, 1)\n\nQ34a_values = df_fin.loc[:,[\"Q34_A_Part_1\", \"Q34_A_Part_2\", \"Q34_A_Part_3\",\n                                 \"Q34_A_Part_4\", \"Q34_A_Part_5\", \"Q34_A_Part_6\",\n                                 \"Q34_A_Part_7\", \"Q34_A_Part_8\", \"Q34_A_Part_9\",\n                                 \"Q34_A_Part_10\", \"Q34_A_Part_11\",\"Q34_A_Part_12\", \"Q34_A_Part_13\",\n                                 \"Q34_A_Part_14\", \"Q34_A_Part_15\", \"Q34_A_OTHER\"]]\n\nbusiness_products = df_fin['Q35'].value_counts().reset_index(name='total')\ntrace3 = go.Scatter(\n                x=business_products['index'],\n                y=business_products['total'],\n                mode='lines+markers',\n                line=dict(color='teal'),showlegend=False,\n                name='business tools products',\n)\n\ntrace4 = go.Bar(\n                x=Q34a_values.stack().unique(), y=Q34a_values.stack().value_counts().values, showlegend=False,\n    text =Q34a_values.stack().value_counts().values,\n                marker=dict(color='lightblue',line=dict(color='teal',width=1)), textposition='outside',\n                name='business tools products',\n                \n)\nfig.append_trace(trace3, 1, 2)\nfig.append_trace(trace4, 1, 2)\n\n\nfig.update_layout(title_text='Big data products vs business tools usage and preference comparison', title_x=0.5,\n                 \n                 annotations = [dict(\n                    x=0.5,\n                    y=1.2,   \n                    xref='paper',\n                    yref='paper',\n                    text=\"In both the diagrams, the lines show the preferences of the participants, and the bar graphs show what they regularly use\",\n                    showarrow = False,\n                    font=dict(\n                            family=\"Muli, sans-serif\",\n                            size=14,\n                            color=\"#ffffff\"\n                            ),\n                    bordercolor=\"#c7c7c7\",\n                    borderwidth=2,\n                    borderpad=4,\n                    bgcolor=\"#222A2A\",\n                    opacity=0.8\n                )])\n\nfig['layout']['xaxis'].update(title_text='Big data products', title_font=dict(size=12))\nfig['layout']['xaxis2'].update(title_text='Business tools', title_font=dict(size=12))\n\n\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.592816Z","iopub.status.idle":"2022-04-04T08:41:04.593371Z","shell.execute_reply.started":"2022-04-04T08:41:04.593204Z","shell.execute_reply":"2022-04-04T08:41:04.593224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_18\">3.18. Relation between developer experience vs big data product and business intelligent tools preferred by developers </font>","metadata":{}},{"cell_type":"code","source":"df_q28_q33_q35 = df_fin.copy()\n\ndf_q28_q33_q35 = df_q28_q33_q35.groupby(['Q28', 'Q33', 'Q35']).size().reset_index(name='count').sort_values(by=['count'], ascending = False)\ndf_q28_q33_q35 = df_q28_q33_q35.loc[~(df_q28_q33_q35['count'] == 0)]\ndf_q28_q33_q35 = df_q28_q33_q35.loc[~((df_q28_q33_q35['Q28'] == 'Other') | (df_q28_q33_q35['Q33'] == 'Other') | (df_q28_q33_q35['Q35'] == 'Other'))]\n\nsank = genSankey(df_q28_q33_q35,cat_cols=['Q28', 'Q33', 'Q35'],value_cols='count')\nfig = go.Figure(sank)\nfig.update_layout(template=\"simple_white\", \n                  title_text = 'Relation between developer experience vs big data product and business intelligent tools preferred by developers', \n                  title_x = 0.5, title_y = 0.95,\n                  margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=10, #bottom margin\n                        ),\n                  annotations = [dict(\n                            x=1,\n                            y=1.1,    \n                            xref='paper',\n                            yref='paper',\n                            text=\"Business tools\",\n                            showarrow = False,\n                            font=dict(\n                                    family=\"Muli, sans-serif\",\n                                    size=14,\n                                    color=\"black\"\n                                    ),\n                            bordercolor=\"white\",\n                            borderwidth=2,\n                            borderpad=4,\n                            bgcolor=\"white\",\n                            opacity=0.8\n                        ),\n                                 dict(\n                            x=0.5,\n                            y=1.1,    \n                            xref='paper',\n                            yref='paper',\n                            text=\"Big data products\",\n                            showarrow = False,\n                            font=dict(\n                                    family=\"Muli, sans-serif\",\n                                    size=14,\n                                    color=\"black\"\n                                    ),\n                            bordercolor=\"white\",\n                            borderwidth=2,\n                            borderpad=4,\n                            bgcolor=\"white\",\n                            opacity=0.8\n                        ),\n                                      dict(\n                            x=0,\n                            y=1.1,    \n                            xref='paper',\n                            yref='paper',\n                            text=\"Cloud computing platforms\",\n                            showarrow = False,\n                            font=dict(\n                                    family=\"Muli, sans-serif\",\n                                    size=14,\n                                    color=\"black\"\n                                    ),\n                            bordercolor=\"white\",\n                            borderwidth=2,\n                            borderpad=4,\n                            bgcolor=\"white\",\n                            opacity=0.8\n                        )]\n                 )\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.594521Z","iopub.status.idle":"2022-04-04T08:41:04.595131Z","shell.execute_reply.started":"2022-04-04T08:41:04.594944Z","shell.execute_reply":"2022-04-04T08:41:04.594966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_19\">3.19. Platforms which are popular among participants for data science courses <br>vs the popular data science media sources </font>","metadata":{}},{"cell_type":"code","source":"Q40_values = df_fin.loc[:,[\"Q40_Part_1\", \"Q40_Part_2\", \"Q40_Part_3\",\n                                 \"Q40_Part_4\", \"Q40_Part_5\", \"Q40_Part_6\",\n                                 \"Q40_Part_7\", \"Q40_Part_8\", \"Q40_Part_9\",\n                                 \"Q40_Part_10\", \"Q40_OTHER\"]].stack().reset_index(name='Q40').drop('level_1', axis=1)\n\nQ42_values = df_fin.loc[:,[\"Q42_Part_1\", \"Q42_Part_2\", \"Q42_Part_3\",\n                                 \"Q42_Part_4\", \"Q42_Part_5\", \"Q42_Part_6\",\n                                 \"Q42_Part_7\", \"Q42_Part_8\", \"Q42_Part_9\",\n                                 \"Q42_Part_10\", \"Q42_OTHER\"]].stack().reset_index(name='Q42').drop('level_1', axis=1)\n\ndf_q40_q42 = pd.merge(Q40_values, Q42_values, on='level_0')\n\ndf_q40_q42 = df_q40_q42.groupby(['Q40','Q42']).size().reset_index().rename(columns={0:'counts'})\n\n\nsank = genSankey(df_q40_q42,cat_cols=['Q40','Q42'],value_cols='counts')\n\nfig = go.Figure(sank)\nfig.update_layout(height = 400, width = 800,\n    template=\"simple_white\", title_text = 'Platforms which are popular among participants for data science courses <br>vs the popular data science media sources', \n    title_x = 0.5, title_y = 0.95, \n    margin=go.layout.Margin(\n                            l=0, #left margin\n                            r=0, #right margin\n                            b=0, #bottom margin\n                            t=70,\n                        ),\n    annotations = [dict(\n        x=1,\n        y=1.1,    \n        xref='paper',\n        yref='paper',\n        text=\"Media sources for data science topic\",\n        showarrow = False,\n        font=dict(\n                family=\"Muli, sans-serif\",\n                size=12,\n                color=\"black\"\n                ),\n        bordercolor=\"white\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"white\",\n        opacity=0.8\n    ),\n                  dict(\n        x=0,\n        y=1.1,    \n        xref='paper',\n        yref='paper',\n        text=\"Platforms providing data science courses\",\n        showarrow = False,\n        font=dict(\n                family=\"Muli, sans-serif\",\n                size=12,\n                color=\"black\"\n                ),\n        bordercolor=\"white\",\n        borderwidth=2,\n        borderpad=4,\n        bgcolor=\"white\",\n        opacity=0.8\n    )]\n)\n\nfig.update_yaxes(visible = False)\nfig.update_xaxes(visible = False)\niplot(fig)","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.59623Z","iopub.status.idle":"2022-04-04T08:41:04.596817Z","shell.execute_reply.started":"2022-04-04T08:41:04.596628Z","shell.execute_reply":"2022-04-04T08:41:04.596649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_20\">3.20. Media sources usage based on age, education-level and occupation</font>","metadata":{}},{"cell_type":"code","source":"df_q1_q42 = df_fin.copy()\ndf_q1_q42 = df_q1_q42.groupby(['Q1'])[[\"Q42_Part_1\", \"Q42_Part_2\", \"Q42_Part_3\",\n                                 \"Q42_Part_4\", \"Q42_Part_5\", \"Q42_Part_6\",\n                                 \"Q42_Part_7\", \"Q42_Part_8\", \"Q42_Part_9\",\n                                 \"Q42_Part_10\", \"Q42_OTHER\"]\n                                 ].count().unstack().fillna(0).reset_index(name='counts')\n\ndf_q1_q42 = df_q1_q42.replace({'level_0' : \n                                 { 'Q42_Part_1' : 'Twitter', 'Q42_Part_2' : 'Email newsletters',\n                                 \"Q42_Part_3\" : 'Reddit' ,  \"Q42_Part_4\" : 'Kaggle',     \n                                \"Q42_Part_5\" : 'Course Forums', \"Q42_Part_6\" : 'YouTube',\n                                \"Q42_Part_7\" : 'Podcasts', \"Q42_Part_8\" : 'Blogs', \n                                \"Q42_Part_9\" : 'Journal Publications',  \"Q42_Part_10\" : 'Slack Communities', \n                                 \"Q42_OTHER\": 'Other'\n                                 }})\n\n\ndf_q1_q42_1 = df_q1_q42[df_q1_q42['Q1'] == '18-21'].drop(['Q1'], axis=1).rename(columns = {'counts': '18-21'})\ndf_q1_q42_2 = df_q1_q42[df_q1_q42['Q1'] == '22-24'].drop(['Q1'], axis=1).rename(columns = {'counts': '22-24'})\ndf_q1_q42_3 = df_q1_q42[df_q1_q42['Q1'] == '25-29'].drop(['Q1'], axis=1).rename(columns = {'counts': '25-29'})\ndf_q1_q42_4 = df_q1_q42[df_q1_q42['Q1'] == '30-34'].drop(['Q1'], axis=1).rename(columns = {'counts': '30-34'})\ndf_q1_q42_5 = df_q1_q42[df_q1_q42['Q1'] == '35-39'].drop(['Q1'], axis=1).rename(columns = {'counts': '35-39'})\ndf_q1_q42_6 = df_q1_q42[df_q1_q42['Q1'] == '40-44'].drop(['Q1'], axis=1).rename(columns = {'counts': '40-44'})\ndf_q1_q42_7 = df_q1_q42[df_q1_q42['Q1'] == '45-49'].drop(['Q1'], axis=1).rename(columns = {'counts': '45-49'})\ndf_q1_q42_8 = df_q1_q42[df_q1_q42['Q1'] == '50-54'].drop(['Q1'], axis=1).rename(columns = {'counts': '50-54'})\ndf_q1_q42_9 = df_q1_q42[df_q1_q42['Q1'] == '55-59'].drop(['Q1'], axis=1).rename(columns = {'counts': '55-59'})\ndf_q1_q42_10 = df_q1_q42[df_q1_q42['Q1'] == '60-69'].drop(['Q1'], axis=1).rename(columns = {'counts': '60-69'})\ndf_q1_q42_11 = df_q1_q42[df_q1_q42['Q1'] == '70+'].drop(['Q1'], axis=1).rename(columns = {'counts': '70+'})\n\n\ndf_q1_q42 = pd.merge(df_q1_q42_1, df_q1_q42_2, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_3, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_4, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_5, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_6, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_7, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_8, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_9, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_10, on='level_0')\ndf_q1_q42 = pd.merge(df_q1_q42, df_q1_q42_11, on='level_0')\n\ndf_q4_q42 = df_fin.copy()\ndf_q4_q42 = df_q4_q42.groupby(['Q4'])[[\"Q42_Part_1\", \"Q42_Part_2\", \"Q42_Part_3\",\n                                 \"Q42_Part_4\", \"Q42_Part_5\", \"Q42_Part_6\",\n                                 \"Q42_Part_7\", \"Q42_Part_8\", \"Q42_Part_9\",\n                                 \"Q42_Part_10\", \"Q42_OTHER\"]\n                                 ].count().unstack().fillna(0).reset_index(name='counts')\n\ndf_q4_q42 = df_q4_q42.replace({'level_0' : \n                                 { 'Q42_Part_1' : 'Twitter', 'Q42_Part_2' : 'Email newsletters',\n                                 \"Q42_Part_3\" : 'Reddit' ,  \"Q42_Part_4\" : 'Kaggle',     \n                                \"Q42_Part_5\" : 'Course Forums', \"Q42_Part_6\" : 'YouTube',\n                                \"Q42_Part_7\" : 'Podcasts', \"Q42_Part_8\" : 'Blogs', \n                                \"Q42_Part_9\" : 'Journal Publications',  \"Q42_Part_10\" : 'Slack Communities', \n                                 \"Q42_OTHER\": 'Other'\n                                 }})\n\n\ndf_q4_q42_1 = df_q4_q42[df_q4_q42['Q4'] == 'Bachelor‚Äôs degree'].drop(['Q4'], axis=1).rename(columns = {'counts': 'Bachelor‚Äôs degree'})\ndf_q4_q42_2 = df_q4_q42[df_q4_q42['Q4'] == 'Master‚Äôs degree'].drop(['Q4'], axis=1).rename(columns = {'counts': 'Master‚Äôs degree'})\ndf_q4_q42_3 = df_q4_q42[df_q4_q42['Q4'] == 'Doctoral degree'].drop(['Q4'], axis=1).rename(columns = {'counts': 'Doctoral degree'})\ndf_q4_q42_4 = df_q4_q42[df_q4_q42['Q4'] == 'I prefer not to answer'].drop(['Q4'], axis=1).rename(columns = {'counts': 'Prefer not to answer'})\ndf_q4_q42_5 = df_q4_q42[df_q4_q42['Q4'] == 'Some college/university study without earning a bachelor‚Äôs degree'].drop(['Q4'], axis=1).rename(columns = {'counts': 'Without Bachelor‚Äôs degree'})\ndf_q4_q42_6 = df_q4_q42[df_q4_q42['Q4'] == 'No formal education past high school'].drop(['Q4'], axis=1).rename(columns = {'counts': 'No formal education past high school'})\ndf_q4_q42_7 = df_q4_q42[df_q4_q42['Q4'] == 'Professional doctorate'].drop(['Q4'], axis=1).rename(columns = {'counts': 'Professional doctorate'})\n\n\ndf_q4_q42 = pd.merge(df_q4_q42_1, df_q4_q42_2, on='level_0')\ndf_q4_q42 = pd.merge(df_q4_q42, df_q4_q42_3, on='level_0')\ndf_q4_q42 = pd.merge(df_q4_q42, df_q4_q42_4, on='level_0')\ndf_q4_q42 = pd.merge(df_q4_q42, df_q4_q42_5, on='level_0')\ndf_q4_q42 = pd.merge(df_q4_q42, df_q4_q42_6, on='level_0')\ndf_q4_q42 = pd.merge(df_q4_q42, df_q4_q42_7, on='level_0')\n\ndf_q5_q42 = df_fin.copy()\ndf_q5_q42 = df_q5_q42.groupby(['Q5'])[[\"Q42_Part_1\", \"Q42_Part_2\", \"Q42_Part_3\",\n                                 \"Q42_Part_4\", \"Q42_Part_5\", \"Q42_Part_6\",\n                                 \"Q42_Part_7\", \"Q42_Part_8\", \"Q42_Part_9\",\n                                 \"Q42_Part_10\", \"Q42_OTHER\"]\n                                 ].count().unstack().fillna(0).reset_index(name='counts')\n\ndf_q5_q42 = df_q5_q42.replace({'level_0' : \n                                 { 'Q42_Part_1' : 'Twitter', 'Q42_Part_2' : 'Email newsletters',\n                                 \"Q42_Part_3\" : 'Reddit' ,  \"Q42_Part_4\" : 'Kaggle',     \n                                \"Q42_Part_5\" : 'Course Forums', \"Q42_Part_6\" : 'YouTube',\n                                \"Q42_Part_7\" : 'Podcasts', \"Q42_Part_8\" : 'Blogs', \n                                \"Q42_Part_9\" : 'Journal Publications',  \"Q42_Part_10\" : 'Slack Communities', \n                                 \"Q42_OTHER\": 'Other'\n                                 }})\n\n\ndf_q5_q42_1 = df_q5_q42[df_q5_q42['Q5'] == 'Other'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Other'})\ndf_q5_q42_2 = df_q5_q42[df_q5_q42['Q5'] == 'Program/Project Manager'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Program/Project Manager'})\ndf_q5_q42_3 = df_q5_q42[df_q5_q42['Q5'] == 'Software Engineer'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Software Engineer'})\ndf_q5_q42_4 = df_q5_q42[df_q5_q42['Q5'] == 'Research Scientist'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Research Scientist'})\ndf_q5_q42_5 = df_q5_q42[df_q5_q42['Q5'] == 'Currently not employed'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Currently not employed'})\ndf_q5_q42_6 = df_q5_q42[df_q5_q42['Q5'] == 'Student'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Student'})\ndf_q5_q42_7 = df_q5_q42[df_q5_q42['Q5'] == 'Data Scientist'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Data Scientist'})\ndf_q5_q42_8 = df_q5_q42[df_q5_q42['Q5'] == 'Data Analyst'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Data Analyst'})\ndf_q5_q42_9 = df_q5_q42[df_q5_q42['Q5'] == 'Machine Learning Engineer'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Machine Learning Engineer'})\ndf_q5_q42_10 = df_q5_q42[df_q5_q42['Q5'] == 'Business Analyst'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Business Analyst'})\ndf_q5_q42_11 = df_q5_q42[df_q5_q42['Q5'] == 'Data Engineer'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Data Engineer'})\ndf_q5_q42_12 = df_q5_q42[df_q5_q42['Q5'] == 'Product Manager'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Product Manager'})\ndf_q5_q42_13 = df_q5_q42[df_q5_q42['Q5'] == 'Statistician'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Statistician'})\ndf_q5_q42_14 = df_q5_q42[df_q5_q42['Q5'] == 'Developer Relations/Advocacy'].drop(['Q5'], axis=1).rename(columns = {'counts': 'Developer Relations/Advocacy'})\ndf_q5_q42_15 = df_q5_q42[df_q5_q42['Q5'] == 'DBA/Database Engineer'].drop(['Q5'], axis=1).rename(columns = {'counts': 'DBA/Database Engineer'})\n\n\ndf_q5_q42 = pd.merge(df_q5_q42_1, df_q5_q42_2, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_3, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_4, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_5, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_6, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_7, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_8, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_9, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_10, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_11, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_12, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_13, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_14, on='level_0')\ndf_q5_q42 = pd.merge(df_q5_q42, df_q5_q42_15, on='level_0')\n\nfig = make_subplots(rows=3, cols=1, horizontal_spacing=0, vertical_spacing=0, shared_xaxes=True)                    \nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['18-21'], marker_color='#022f52', name='18-21',\n                     text=df_q1_q42['18-21'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['22-24'], marker_color='#104670', name='22-24',\n                      text=df_q1_q42['22-24'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['25-29'], marker_color='#095e9e', name='25-29',\n                     text=df_q1_q42['25-29'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\n\n\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['30-34'], marker_color='#1f74b5', name='30-34',\n                     text=df_q1_q42['30-34'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['35-39'], marker_color='#228fe3', name='35-39',\n                     text=df_q1_q42['35-39'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['40-44'], marker_color='#4aa8f0', name='40-44',\n                     text=df_q1_q42['40-44'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\n\n\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['45-49'], marker_color='#61b3f2', name='45-49',\n                     text=df_q1_q42['45-49'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['50-54'], marker_color='#6db0e3', name='50-54',\n                     text=df_q1_q42['50-54'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\n\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['55-59'], marker_color='#89c3f0', name='55-59',\n                     text=df_q1_q42['55-59'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['60-69'], marker_color='#abd5f5', name='60-69',\n                     text=df_q1_q42['60-69'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\nfig.add_trace(go.Bar(x=df_q1_q42['level_0'], y=df_q1_q42['70+'], marker_color='#cbe3f5', name='70+',\n                     text=df_q1_q42['70+'], opacity=0.8, legendgroup = '1'),\n                     row=1, col=1)\n\nfig.add_trace(go.Bar(x=df_q4_q42['level_0'], y=df_q4_q42['Bachelor‚Äôs degree'], marker_color='#c47002', name='Bachelor‚Äôs degree',\n                    text=df_q4_q42['Bachelor‚Äôs degree'],  opacity=0.8, legendgroup = '2'),\n                     row=2, col=1)\nfig.add_trace(go.Bar(x=df_q4_q42['level_0'], y=df_q4_q42['Master‚Äôs degree'], marker_color='#de8004', name='Master‚Äôs degree',\n                    text=df_q4_q42['Master‚Äôs degree'],  opacity=0.8, legendgroup = '2'),\n                     row=2, col=1)\nfig.add_trace(go.Bar(x=df_q4_q42['level_0'], y=df_q4_q42['Doctoral degree'], marker_color='#fc9105', name='Doctoral degree',\n                    text=df_q4_q42['Doctoral degree'], opacity=0.8, legendgroup = '2'),\n                     row=2, col=1)\n\n\nfig.add_trace(go.Bar(x=df_q4_q42['level_0'], y=df_q4_q42['Prefer not to answer'], marker_color='#ffaf47', name='Prefer not to answer',\n                   text=df_q4_q42['Prefer not to answer'], opacity=0.8, legendgroup = '2'),\n                     row=2, col=1)\nfig.add_trace(go.Bar(x=df_q4_q42['level_0'], y=df_q4_q42['Without Bachelor‚Äôs degree'], marker_color='#fab45c', name='Without Bachelor‚Äôs degree',\n                    text=df_q4_q42['Without Bachelor‚Äôs degree'], opacity=0.8, legendgroup = '2'),\n                     row=2, col=1)\nfig.add_trace(go.Bar(x=df_q4_q42['level_0'], y=df_q4_q42['No formal education past high school'], marker_color='#e8c290', name='No formal education past high school',\n                    text = df_q4_q42['No formal education past high school'], opacity=0.8, legendgroup = '2'),\n                     row=2, col=1)\n\n\nfig.add_trace(go.Bar(x=df_q4_q42['level_0'], y=df_q4_q42['Professional doctorate'], marker_color='#f5ddbf', name='Professional doctorate',\n                    text=df_q4_q42['Professional doctorate'], opacity=0.8, legendgroup = '2'),\n                     row=2, col=1)\n\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Other'], marker_color='#243804', name='Other',\n                      text=df_q5_q42['Other'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Program/Project Manager'], marker_color='#406308', name='Program/Project Manager',\n                     text=df_q5_q42['Program/Project Manager'],  opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Software Engineer'], marker_color='#588a08', name='Software Engineer',\n                     text=df_q5_q42['Software Engineer'],  opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\n\n\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Research Scientist'], marker_color='#71b00c', name='Research Scientist',\n                    text=df_q5_q42['Research Scientist'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Currently not employed'], marker_color='#88d40f', name='Currently not employed',\n                    text=df_q5_q42['Currently not employed'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Student'], marker_color='#9ef511', name='Student',\n                      text=df_q5_q42['Student'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\n\n\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Data Scientist'], marker_color='#78f8fa', name='Data Scientist',\n                    text=df_q5_q42['Data Scientist'],  opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Data Analyst'], marker_color='#5ee8eb', name='Data Analyst',\n                     text=df_q5_q42['Data Analyst'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\n\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Machine Learning Engineer'], marker_color='#47e3e6', name='Machine Learning Engineer',\n                     text=df_q5_q42['Machine Learning Engineer'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Business Analyst'], marker_color='#27d3d6', name='Business Analyst',\n                     text=df_q5_q42['Business Analyst'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Data Engineer'], marker_color='#15bcbf', name='Data Engineer',\n                     text=df_q5_q42['Data Engineer'],  opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Product Manager'], marker_color='#05adb0', name='Product Manager',\n                    text=df_q5_q42['Product Manager'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Statistician'], marker_color='#048a8c', name='Statistician',\n                   text=df_q5_q42['Statistician'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['Developer Relations/Advocacy'], marker_color='#046466', name='Developer Relations/Advocacy',\n                     text=df_q5_q42['Developer Relations/Advocacy'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\nfig.add_trace(go.Bar(x=df_q5_q42['level_0'], y=df_q5_q42['DBA/Database Engineer'], marker_color='#023233', name='DBA/Database Engineer',\n                     text=df_q5_q42['DBA/Database Engineer'], opacity=0.8, legendgroup = '3'),\n                     row=3, col=1)\n\n\nfig.update_yaxes(showline=False, showgrid=False)\nfig.update_traces(textfont_size=8, textangle=0, textposition=\"inside\", cliponaxis=False)\nfig.update_xaxes(categoryorder='array', \n                 categoryarray= ['Kaggle','YouTube','Blogs','Twitter', 'Email newsletters', 'Journal Publications', \n                                 'Course Forums', 'Reddit', 'Slack Communities', 'Podcasts', 'Other'],\n                showgrid=True)\nfig.update_layout(height=1100, title='Media sources usage based on age, education-level and occupation', title_x=0.5, title_y=0.94,\n                  template=\"plotly_white\", barmode='stack',\n                  xaxis3_title = 'Media Sources',\n                  yaxis1_title = 'Age count by media sources',\n                  yaxis2_title = 'Education-level count by media sources',\n                  yaxis3_title = 'Occupation count by media sources',\n                  legend_tracegroupgap = 126)\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.598108Z","iopub.status.idle":"2022-04-04T08:41:04.598837Z","shell.execute_reply.started":"2022-04-04T08:41:04.598639Z","shell.execute_reply":"2022-04-04T08:41:04.598662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_21\">3.21. Correlation experience & age </font>","metadata":{}},{"cell_type":"code","source":"cmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(pd.crosstab(df_fin['Q6'], df_fin['Q1'], normalize='columns'),vmin=0.01,cmap=cust_color)\nplt.title('Correlation between experience and Age')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.599922Z","iopub.status.idle":"2022-04-04T08:41:04.600436Z","shell.execute_reply.started":"2022-04-04T08:41:04.600245Z","shell.execute_reply":"2022-04-04T08:41:04.600266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_22\">3.22. Comparison of jobs positions per Age</font>","metadata":{}},{"cell_type":"code","source":"\ndef build_graph(q_number, Roles, Title):\n    \"\"\"Create dropdown visual with question data\"\"\"\n    if isinstance(q_number, pd.DataFrame):\n        qnumber = q_number.copy()\n        qnumber.columns = list(qnumber.mode().iloc[0,:])\n        qcnt = qnumber.count().reset_index()\n        qcnt.columns = ['feature','cnt']\n        qcnt = qcnt.sort_values('cnt', ascending = False)\n        qnumber['Roles'] = df_fin.Q5\n        \n\n        fig = go.Figure(layout=go.Layout(title= go.layout.Title(text=Title)))\n        #changed from role selection to selection 1\n        fig.add_trace(go.Bar(name= 'Selection 1', x= qcnt.feature, y=(qcnt.cnt/ qcnt.cnt.sum())))\n\n        buttons = []\n\n        #added button for all data comparison\n        buttons.append(dict(method='restyle',\n                                label= 'All Samples',\n                                visible=True,\n                                args=[{'y':[(qcnt.cnt/ qcnt.cnt.sum())],\n                                       'x':[qcnt.feature],\n                                       'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                                )\n                          )\n\n        for i in list(Roles.keys())[1:]:\n            buttons.append(dict(method='restyle',\n                                label= i,\n                                visible=True,\n                                args=[{'y':[filter_bars(i,qnumber)[1].values],\n                                       'x':[filter_bars(i,qnumber)[0].values],\n                                       'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                                )\n                          )\n\n        fig.add_trace(go.Bar(name= 'Selection 2', x= qcnt.feature, y=(qcnt.cnt/ qcnt.cnt.sum())))\n\n        buttons2 = []\n        #added button for all data comparison\n        buttons2.append(dict(method='restyle',\n                                label= 'All Samples',\n                                visible=True,\n                                args=[{'y':[(qcnt.cnt/ qcnt.cnt.sum())],\n                                       'x':[qcnt.feature],\n                                       'type':'bar'}, [1]], \n                                )\n                          )\n\n        for i in list(Roles.keys())[1:]:\n            buttons2.append(dict(method='restyle',\n                                label= i,\n                                visible=True,\n                                args=[{'y':[filter_bars(i,qnumber)[1].values],\n                                       'x':[filter_bars(i,qnumber)[0].values],\n                                       'type':'bar'}, [1]],\n                                )\n                          )\n\n        # adjusted dropdown placement \n        #found out updatemenus take a dictionary of buttons and allow you to format how the dropdowns look etc.\n        # https://plotly.com/python/dropdowns/\n        button_layer_1_height = 1.15\n        updatemenus = list([\n            dict(buttons=buttons,\n                    direction=\"down\",\n                    pad={\"r\": 10, \"t\": 10},\n                    showactive=True,\n                    x=0.1,\n                    xanchor=\"left\",\n                    y=button_layer_1_height,\n                    yanchor=\"top\"),\n            dict(buttons=buttons2,\n                    direction=\"down\",\n                    pad={\"r\": 10, \"t\": 10},\n                    showactive=True,\n                    x=0.50,\n                    xanchor=\"left\",\n                    y=button_layer_1_height,\n                    yanchor=\"top\")])\n\n        fig.update_layout( updatemenus=updatemenus)\n        #added annotations next to dropdowns \n        fig.update_layout(\n            annotations=[\n                dict(text=\"Selection 1\", x=0, xref=\"paper\", y=1.1, yref=\"paper\",\n                                     align=\"left\", showarrow=False),\n                dict(text=\"Selection 2\", x=0.45, xref=\"paper\", y=1.1,\n                                     yref=\"paper\", showarrow=False)\n            ])\n        fig.update_xaxes(categoryorder= 'array', categoryarray= qcnt.feature)\n        fig.show()\n        \n        \n    else:\n        qnumber= q_number.copy()\n        vcnts = qnumber.value_counts()\n        qnumber = pd.concat([qnumber,df_fin.Q5], axis =1)\n        qnumber.columns = ['feature','Roles']\n\n        fig = go.Figure(layout=go.Layout(title= go.layout.Title(text=Title)))\n        #changed from role selection to selection 1\n        fig.add_trace(go.Bar(name= 'Selection 1', x= vcnts.index, y=(vcnts.values/ vcnts.values.sum())))\n\n        buttons = []\n\n        #added button for all data comparison\n        buttons.append(dict(method='restyle',\n                                label= 'All Samples',\n                                visible=True,\n                                args=[{'y':[vcnts.values/ vcnts.values.sum()],\n                                       'x':[vcnts.index],\n                                       'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                                )\n                          )\n\n        for i in list(Roles.keys())[1:]:\n            qrole = qnumber[qnumber['Roles']==i].feature.value_counts()\n            buttons.append(dict(method='restyle',\n                                label= i,\n                                visible=True,\n                                args=[{'y':[qrole.values/qrole.values.sum()],\n                                       'x':[qrole.index],\n                                       'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                                )\n                          )\n\n        fig.add_trace(go.Bar(name= 'Selection 2',x= vcnts.index, y=(vcnts.values/ vcnts.values.sum())))\n\n        buttons2 = []\n                #added button for all data comparison\n        buttons2.append(dict(method='restyle',\n                                label= 'All Samples',\n                                visible=True,\n                                args=[{'y':[(vcnts.values/ vcnts.values.sum())],\n                                       'x':[vcnts.index],\n                                       'type':'bar'}, [1]], # the [0] at the end lets us know they are for the first trace\n                                )\n                          )\n\n        for i in list(Roles.keys())[1:]:\n            qrole = qnumber[qnumber['Roles']==i].feature.value_counts()\n            buttons2.append(dict(method='restyle',\n                                label= i,\n                                visible=True,\n                                args=[{'y':[qrole.values/qrole.values.sum()],\n                                       'x':[qrole.index],\n                                       'type':'bar'}, [1]], # the [0] at the end lets us know they are for the first trace\n                                )\n                          )\n        # adjusted dropdown placement \n        #found out updatemenus take a dictionary of buttons and allow you to format how the dropdowns look etc.\n        # https://plotly.com/python/dropdowns/\n        button_layer_1_height = 1.15\n        updatemenus = list([\n            dict(buttons=buttons,\n                    direction=\"down\",\n                    pad={\"r\": 10, \"t\": 10},\n                    showactive=True,\n                    x=0.1,\n                    xanchor=\"left\",\n                    y=button_layer_1_height,\n                    yanchor=\"top\"),\n            dict(buttons=buttons2,\n                    direction=\"down\",\n                    pad={\"r\": 10, \"t\": 10},\n                    showactive=True,\n                    x=0.50,\n                    xanchor=\"left\",\n                    y=button_layer_1_height,\n                    yanchor=\"top\")])\n\n        fig.update_layout( updatemenus=updatemenus)\n        #added annotations next to dropdowns \n        fig.update_layout(\n            annotations=[\n                dict(text=\"Selection 1\", x=0, xref=\"paper\", y=1.1, yref=\"paper\",\n                                     align=\"left\", showarrow=False),\n                dict(text=\"Selection 2\", x=0.45, xref=\"paper\", y=1.1,\n                                     yref=\"paper\", showarrow=False)\n            ])\n        fig.update_xaxes(categoryorder= 'array', categoryarray= vcnts.index)\n        fig.show()\n        \n    return","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.601631Z","iopub.status.idle":"2022-04-04T08:41:04.601918Z","shell.execute_reply.started":"2022-04-04T08:41:04.601774Z","shell.execute_reply":"2022-04-04T08:41:04.60179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"build_graph(Questions['Q1'],Roles,'Age by Position')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.602761Z","iopub.status.idle":"2022-04-04T08:41:04.603027Z","shell.execute_reply.started":"2022-04-04T08:41:04.602888Z","shell.execute_reply":"2022-04-04T08:41:04.602903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_23\">3.23. Comparison of jobs positions per Hardware</font>","metadata":{}},{"cell_type":"code","source":"build_graph(Questions['Q12'],Roles,'Hardware by position')","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.603811Z","iopub.status.idle":"2022-04-04T08:41:04.604075Z","shell.execute_reply.started":"2022-04-04T08:41:04.603938Z","shell.execute_reply":"2022-04-04T08:41:04.603953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_24\">3.24. Comparison of coding language by positions</font>","metadata":{}},{"cell_type":"code","source":"q7 = Questions['Q7'].count().reset_index()\n\n\nq7.columns = ['language', 'Count']\n\n\n\n#we follow the same process \nQuestions['Q7']['Roles'] = df_fin.Q5\nfig = go.Figure(layout=go.Layout(title= go.layout.Title(text=\"Comparing Coding Languages by Position\")))\n#changed from role selection to selection 1\nfig.add_trace(go.Bar(name= 'Selection 1', x= q7.language, y=(q7.Count/ q7.Count.sum())))\n\ndef filter_bars(role, data):\n    df = data[data['Roles'] == role]\n    q7 = df.drop('Roles', axis= 1).count().reset_index()\n    q7.columns = ['language','Count']\n    return (q7.language, q7.Count/q7.Count.sum())\n\nbuttons = []\n\n#added button for all data comparison\nbuttons.append(dict(method='restyle',\n                        label= 'All Samples',\n                        visible=True,\n                        args=[{'y':[(q7.Count/ q7.Count.sum())],\n                               'x':[q7.language],\n                               'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfor i in list(Roles.keys())[1:]:\n    buttons.append(dict(method='restyle',\n                        label= i,\n                        visible=True,\n                        args=[{'y':[filter_bars(i,Questions['Q7'])[1].values],\n                               'x':[filter_bars(i,Questions['Q7'])[0].values],\n                               'type':'bar'}, [0]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfig.add_trace(go.Bar(name= 'Selection 2', x= q7.language, y=(q7.Count/ q7.Count.sum())))\n\nbuttons2 = []\n#added button for all data comparison\nbuttons2.append(dict(method='restyle',\n                        label= 'All Samples',\n                        visible=True,\n                        args=[{'y':[(q7.Count/ q7.Count.sum())],\n                               'x':[q7.language],\n                               'type':'bar'}, [1]], # the [0] at the end lets us know they are for the first trace\n                        )\n                  )\n\nfor j in list(Roles.keys())[1:]:\n    buttons2.append(dict(method='restyle',\n                        label= j,\n                        visible=True,\n                        args=[{'y':[filter_bars(j,Questions['Q7'])[1].values],\n                               'x':[filter_bars(j,Questions['Q7'])[0].values],\n                               'type':'bar'}, [1]], # the [1] at the end lets us know they are for the first trace\n                        )                        #literally figured that out by just experimenting \n                  )\n# adjusted dropdown placement \n#found out updatemenus take a dictionary of buttons and allow you to format how the dropdowns look etc.\n# https://plotly.com/python/dropdowns/\nbutton_layer_1_height = 1.15\nupdatemenus = list([\n    dict(buttons=buttons,\n            direction=\"down\",\n            pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.1,\n            xanchor=\"left\",\n            y=button_layer_1_height,\n            yanchor=\"top\"),\n    dict(buttons=buttons2,\n            direction=\"down\",\n            pad={\"r\": 10, \"t\": 10},\n            showactive=True,\n            x=0.50,\n            xanchor=\"left\",\n            y=button_layer_1_height,\n            yanchor=\"top\")])\n    \nfig.update_layout( updatemenus=updatemenus)\n#added annotations next to dropdowns \nfig.update_layout(\n    annotations=[\n        dict(text=\"Selection 1\", x=0, xref=\"paper\", y=1.1, yref=\"paper\",\n                             align=\"left\", showarrow=False),\n        dict(text=\"Selection 2\", x=0.45, xref=\"paper\", y=1.1,\n                             yref=\"paper\", showarrow=False)\n    ])\nfig.update_xaxes(categoryorder= 'array', categoryarray= q7.language)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.605911Z","iopub.status.idle":"2022-04-04T08:41:04.606228Z","shell.execute_reply.started":"2022-04-04T08:41:04.606059Z","shell.execute_reply":"2022-04-04T08:41:04.606081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_25\">3.25. Education VS Age </font>","metadata":{}},{"cell_type":"code","source":"z=df_fin.groupby(['Q1','Q4']).size().unstack().fillna(0).astype('int16')\nfig, ax = plt.subplots(figsize=(14, 12))\nsns.heatmap(z.apply(lambda x: x/x.sum(), axis=1), xticklabels=True, yticklabels=True, annot=True, linewidths=0.005, linecolor='black', annot_kws={\"fontsize\":12}, fmt='.4f', cbar=False)\nplt.title('Education VS Age (in%)', fontname = 'monospace', weight='bold')\nlabels = [item.get_text() for item in ax.get_xticklabels()]\nlabels[-1] = 'Some College/Uni Study'\nax.set_xticklabels(labels)\nplt.xticks(fontsize=12, rotation=60)\nplt.yticks(fontsize=12)\nplt.xlabel(\"Education\", fontname = 'monospace', weight='semibold')\nplt.ylabel(\"Age\", fontname = 'monospace', weight='semibold')\nplt.show()\n#To avoid unnecessary data storage, let's delete z\ndel z","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.607458Z","iopub.status.idle":"2022-04-04T08:41:04.608194Z","shell.execute_reply.started":"2022-04-04T08:41:04.608009Z","shell.execute_reply":"2022-04-04T08:41:04.60803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Dark colors : no strong relation. Light colors : important relation","metadata":{}},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_26\">3.26. Salary VS Experience VS Country </font>","metadata":{}},{"cell_type":"code","source":"df_456 = df_fin[['Q3', 'Q6', 'Q25']]\ndf_456['Q6'] = df_456['Q6'].replace(dict.fromkeys(['I have never written code', '< 1 years', '1-3 years'],'Beginner'))\ndf_456['Q6'] = df_456['Q6'].replace(dict.fromkeys(['3-5 years', '5-10 years'],'Intermediate'))\ndf_456['Q6'] = df_456['Q6'].replace(dict.fromkeys(['10-20 years', '20+ years'],'Expert'))\ndf_456 = df_456[df_456['Q3'].isin(['India','United States of America'])]\ndf_456 = df_456[df_456['Q25'].isin(['$0-999','1,000-1,999','10,000-14,999','30,000-39,999','100,000-124,999'])]\n\ndf_456 = round(pd.crosstab(df_456['Q25'], [df_456['Q6'],df_456['Q3']], normalize='index'), 2).T.reset_index()\n\ndf_456_India = df_456[df_456['Q3']=='India'].sort_values(by=[\"Q6\"]).reset_index().drop('index', axis=1)\ndf_456_USA = df_456[df_456['Q3']=='United States of America'].sort_values(by=[\"Q6\"]).reset_index().drop('index', axis=1)\n\n\nfig = make_subplots(rows=1, cols=5, shared_yaxes=True, horizontal_spacing=0, vertical_spacing=0)                    \nfig.add_trace(go.Bar(y=df_456_India['Q6'], x=df_456_India['$0-999'], marker_color='magenta', name='Extrem Low Salary',\n                     showlegend=True, orientation='h', opacity=0.8),\n                     row=1, col=1)\nfig.add_trace(go.Bar(y=df_456_USA['Q6'], x=df_456_USA['$0-999'], marker_color='gold', name='Extrem Low Salary',\n                     orientation='h', showlegend=True, opacity=0.8),\n                     row=1, col=1)\n\n\nfig.add_trace(go.Bar(y=df_456_India['Q6'], x=df_456_India['1,000-1,999'], marker_color='chartreuse', name='Low Salary',\n                     showlegend=True, orientation='h', opacity=0.8),\n                     row=1, col=2)\nfig.add_trace(go.Bar(y=df_456_USA['Q6'], x=df_456_USA['1,000-1,999'], marker_color='chocolate', name='Low Salary',\n                     orientation='h', showlegend=True, opacity=0.8),\n                     row=1, col=2)\n\n\nfig.add_trace(go.Bar(y=df_456_India['Q6'], x=df_456_India['10,000-14,999'], marker_color='sea green', name='Medium Salary',\n                     showlegend=True, orientation='h', opacity=0.8),\n                     row=1, col=3)\nfig.add_trace(go.Bar(y=df_456_USA['Q6'], x=df_456_USA['10,000-14,999'], marker_color='pink', name='Medium Salary',\n                     orientation='h', showlegend=True, opacity=0.8),\n                     row=1, col=3)\n\n\nfig.add_trace(go.Bar(y=df_456_India['Q6'], x=df_456_India['30,000-39,999'], marker_color='red', name='High Salary',\n                     showlegend=True, orientation='h', opacity=0.8),\n                     row=1, col=4)\nfig.add_trace(go.Bar(y=df_456_USA['Q6'], x=df_456_USA['30,000-39,999'], marker_color='green', name='High Salary',\n                     orientation='h', showlegend=True, opacity=0.8),\n                     row=1, col=4)\n\n\n\nfig.add_trace(go.Bar(y=df_456_India['Q6'], x=df_456_India['100,000-124,999'], marker_color='teal', name='Very High Salary',\n                     showlegend=True, orientation='h', opacity=0.8),\n                     row=1, col=5)\nfig.add_trace(go.Bar(y=df_456_USA['Q6'], x=df_456_USA['100,000-124,999'], marker_color='orange', name='Very High Salary', \n                     orientation='h', showlegend=True, opacity=0.8),\n                     row=1, col=5)\n\n\n\n\nfig.update_xaxes(zeroline=False,showticklabels=True, ticks=\"\")\nfig.update_traces(hovertemplate=None, marker=dict(line=dict(width=0)))\nfig.update_yaxes(tickmode='array', showline=False, showgrid=False,\n                 tickvals=['Beginner', 'Intermediate',\n                       'Expert'],\n                 ticktext=['Beginner', 'Intermediate',\n                       'Expert'])\nfig.update_layout(height=550, \n                  title_text=\"Salary distribution according to the level of experience (India vs USA)\", title_x =0.5, title_y = 0.96,\n                  template=\"plotly_white\", barmode='stack',\n                  autosize=True,\n                  margin=dict(t=80, b=50, l=70, r=40),\n                 plot_bgcolor='white', paper_bgcolor='white', \n                title_font=dict(size=21, color='#222A2A', family=\"Muli, sans-serif\"),\n                         font=dict(color='#222A2A'),\n                         legend=dict(orientation=\"h\", yanchor=\"bottom\", y=1, xanchor=\"center\", x=0.5)\n                 )\n\n\nfig['layout']['xaxis'].update(title_text='0-999', title_font=dict(size=12))\nfig['layout']['xaxis2'].update(title_text='1,000-1,999', title_font=dict(size=12))\nfig['layout']['xaxis3'].update(title_text='10,000-14,999', title_font=dict(size=12))\nfig['layout']['xaxis4'].update(title_text='30,000-39,999', title_font=dict(size=12))\nfig['layout']['xaxis5'].update(title_text='100,000-124,999', title_font=dict(size=12))\n\n\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.609405Z","iopub.status.idle":"2022-04-04T08:41:04.610172Z","shell.execute_reply.started":"2022-04-04T08:41:04.609999Z","shell.execute_reply":"2022-04-04T08:41:04.610019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color=\"#2cb7b0\" id=\"section_3_27\">3.27. radar chart. </font>","metadata":{}},{"cell_type":"code","source":"fig = px.line_polar(df_fin, r=df_fin['Q2'], theta=df_fin['Q26'], line_close=True, title='xxx')\nfig.update_traces(fill='toself')\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.611109Z","iopub.status.idle":"2022-04-04T08:41:04.611403Z","shell.execute_reply.started":"2022-04-04T08:41:04.611242Z","shell.execute_reply":"2022-04-04T08:41:04.61127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#7. Save the chart as a picture\n\n\n#filename = 'sns-boxplot'\n#plt.savefig(filename+'.png', facecolor=facecolor)\n\n\n#You might need to repeat facecolor in savefig(). Otherwise, plt.savefig might ignore it.\n#facecolor = '#eaeaf2'\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-04T08:41:04.612357Z","iopub.status.idle":"2022-04-04T08:41:04.612669Z","shell.execute_reply.started":"2022-04-04T08:41:04.612492Z","shell.execute_reply":"2022-04-04T08:41:04.612514Z"},"trusted":true},"execution_count":null,"outputs":[]}]}