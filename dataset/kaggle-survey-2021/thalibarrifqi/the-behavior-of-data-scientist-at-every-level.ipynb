{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import ConnectionPatch\nimport seaborn as sns\nimport sys\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2021-11-30T02:05:44.407545Z","iopub.execute_input":"2021-11-30T02:05:44.408149Z","iopub.status.idle":"2021-11-30T02:05:44.419373Z","shell.execute_reply.started":"2021-11-30T02:05:44.408116Z","shell.execute_reply":"2021-11-30T02:05:44.41848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<div style=\"text-align: center\">The Challenge Objective</div>**","metadata":{}},{"cell_type":"markdown","source":"**Tell a data story about a subset of the data science community represented in this survey, through a combination of both narrative text and data exploration. The challenge is to deeply explore (through data) the impact, priorities, or concerns of a specific group of data science and machine learning practitioners.**","metadata":{}},{"cell_type":"markdown","source":"# **<div style=\"text-align: center\">What We Observe?</div>**","metadata":{}},{"cell_type":"markdown","source":"**We will explore the data of Data Scientist practitioners, get information about their job role, experience, their favorite tools and other information related to being an expert in Data Science.**","metadata":{}},{"cell_type":"markdown","source":"# **<div style=\"text-align: center\">Read The Dataset</div>**","metadata":{}},{"cell_type":"markdown","source":"**We read the data given by Kaggle, the Kaggle Survey 2021 data. The warning occurs because the data frame has a different data type on the first index or in index 0. Now we will remove the 0 index and use the rest as our main data frame.**","metadata":{}},{"cell_type":"code","source":"dataframe = pd.read_csv('/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')\ndataframe.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:44.421074Z","iopub.execute_input":"2021-11-30T02:05:44.421572Z","iopub.status.idle":"2021-11-30T02:05:45.421193Z","shell.execute_reply.started":"2021-11-30T02:05:44.42154Z","shell.execute_reply":"2021-11-30T02:05:45.420261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<div style=\"text-align: center\">Main Dataframe</div>**","metadata":{}},{"cell_type":"code","source":"df = dataframe.copy()\ndf = df[1:]\ndf = df.reset_index(drop=True) #Reset index\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:45.422388Z","iopub.execute_input":"2021-11-30T02:05:45.422756Z","iopub.status.idle":"2021-11-30T02:05:45.76051Z","shell.execute_reply.started":"2021-11-30T02:05:45.422723Z","shell.execute_reply":"2021-11-30T02:05:45.759604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **<div style=\"text-align: center\">Exploratory Data Analysis</div>**","metadata":{}},{"cell_type":"markdown","source":"**At this step, we'll try to understand and find out who is our subject of observation.**","metadata":{}},{"cell_type":"markdown","source":"# **A. Respondent's Profile**","metadata":{}},{"cell_type":"code","source":"def ds_explore(column):\n    plt.figure(figsize=(12,6))\n    count = sns.countplot(data=df, y=column, order=column.value_counts().iloc[:16].index)\n    for i in count.patches:\n        count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()), \n                                xytext=(30,-8),fontsize=9, color='#000000', \n                                textcoords='offset points', \n                                horizontalalignment='right')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:45.762606Z","iopub.execute_input":"2021-11-30T02:05:45.76284Z","iopub.status.idle":"2021-11-30T02:05:45.769328Z","shell.execute_reply.started":"2021-11-30T02:05:45.762811Z","shell.execute_reply":"2021-11-30T02:05:45.768506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1. Age**","metadata":{}},{"cell_type":"code","source":"ds_explore(df['Q1'])\nplt.title('Age Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Age', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:45.770664Z","iopub.execute_input":"2021-11-30T02:05:45.771062Z","iopub.status.idle":"2021-11-30T02:05:46.103995Z","shell.execute_reply.started":"2021-11-30T02:05:45.77101Z","shell.execute_reply":"2021-11-30T02:05:46.103409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Gender**","metadata":{}},{"cell_type":"code","source":"ds_explore(df['Q2'])\nplt.title('Gender Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Gender', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:46.105021Z","iopub.execute_input":"2021-11-30T02:05:46.105642Z","iopub.status.idle":"2021-11-30T02:05:46.392694Z","shell.execute_reply.started":"2021-11-30T02:05:46.105607Z","shell.execute_reply":"2021-11-30T02:05:46.391931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Country**","metadata":{}},{"cell_type":"code","source":"df['Q3'] = df['Q3'].replace({\n    'United States of America':'USA',\n    'United Kingdom of Great Britain and Northern Ireland':'UK'\n})\nds_explore(df['Q3'])\nplt.title('Country Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Country', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:46.393852Z","iopub.execute_input":"2021-11-30T02:05:46.394089Z","iopub.status.idle":"2021-11-30T02:05:46.794208Z","shell.execute_reply.started":"2021-11-30T02:05:46.39406Z","shell.execute_reply":"2021-11-30T02:05:46.79334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Education**","metadata":{}},{"cell_type":"code","source":"df['Q4'] = df['Q4'].replace({\n    'Some college/university study without earning a bachelor’s degree':'Without bachelor’s degree',\n    'No formal education past high school':'High school'\n})\nds_explore(df['Q4'])\nplt.title('Formal Education Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Education', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:46.795771Z","iopub.execute_input":"2021-11-30T02:05:46.796709Z","iopub.status.idle":"2021-11-30T02:05:47.101626Z","shell.execute_reply.started":"2021-11-30T02:05:46.796658Z","shell.execute_reply":"2021-11-30T02:05:47.100729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5. Job Title**","metadata":{}},{"cell_type":"code","source":"ds_explore(df['Q5'])\nplt.title('Job Distribution', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Job', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:47.104697Z","iopub.execute_input":"2021-11-30T02:05:47.10553Z","iopub.status.idle":"2021-11-30T02:05:47.712479Z","shell.execute_reply.started":"2021-11-30T02:05:47.105476Z","shell.execute_reply":"2021-11-30T02:05:47.711562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**According to the information provided, the majority of poll respondents are men aged 18 to 29. India has the most data science responders, followed by the United States in second place. In their education, the majority of our responders have a master's degree. Some of them don't refer to themselves as data scientists-practitioners, but they have used data science in various capacities.**","metadata":{}},{"cell_type":"markdown","source":"# **B. Data Science Experience**","metadata":{}},{"cell_type":"markdown","source":"**Analyze the respondent's experience data, this information is significant since it will be used as one of the clustering technique's features, along with other data that supports the method.**","metadata":{}},{"cell_type":"markdown","source":"**1. Programming Experience**","metadata":{}},{"cell_type":"code","source":"df['Q6'] = df['Q6'].replace({\n    'I have never written code':'0',\n    '20+ years':'> 20'\n})\ndf['Q6'] = df['Q6'].str.replace('years,?','', regex=True)\nds_explore(df['Q6'])\nplt.title('Programming Experience', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Years', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:47.714209Z","iopub.execute_input":"2021-11-30T02:05:47.714533Z","iopub.status.idle":"2021-11-30T02:05:48.045954Z","shell.execute_reply.started":"2021-11-30T02:05:47.714491Z","shell.execute_reply":"2021-11-30T02:05:48.044995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Machine Learning Experience**","metadata":{}},{"cell_type":"code","source":"df['Q15'] = df['Q15'].replace({\n    'Under 1 year':'< 1',\n    'I do not use machine learning methods':'0',\n    '20 or more years':'> 20'\n})\ndf['Q15'] = df['Q15'].str.replace('years,?','', regex=True)\nds_explore(df['Q15'])\nplt.title('Machine Learning Experience', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Years', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:48.04733Z","iopub.execute_input":"2021-11-30T02:05:48.047596Z","iopub.status.idle":"2021-11-30T02:05:48.371299Z","shell.execute_reply.started":"2021-11-30T02:05:48.047566Z","shell.execute_reply":"2021-11-30T02:05:48.370289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **C. Work as Data Scientist**","metadata":{}},{"cell_type":"markdown","source":"**Some of our respondents have worked in the data field and they are paid for it, they also spend money on computing services. This information can be used as a data feature.**","metadata":{}},{"cell_type":"markdown","source":"**1. Yearly Compensation**","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\ncount = sns.countplot(data=df, y='Q25', order=df['Q25'].value_counts().index)\nfor i in count.patches:\n    count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()),\n                   xytext=(30,-8),fontsize=9, color='#000000', textcoords='offset points',\n                   horizontalalignment='right')\nplt.title('Yearly Compensation', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('Compensation (USD)', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:48.372881Z","iopub.execute_input":"2021-11-30T02:05:48.373172Z","iopub.status.idle":"2021-11-30T02:05:49.017408Z","shell.execute_reply.started":"2021-11-30T02:05:48.373133Z","shell.execute_reply":"2021-11-30T02:05:49.016493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Money Spent on Machine Learning/Cloud Computing Services**","metadata":{}},{"cell_type":"code","source":"df['Q26'] = df['Q26'].replace({\n    '$0 ($USD)':'0',\n    '$100,000 or more ($USD)':'> 100,000'\n})\nplt.figure(figsize=(12,6))\ncount = sns.countplot(data=df, y='Q26', order=df['Q26'].value_counts().index)\nfor i in count.patches:\n    count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()),\n                   xytext=(30,-8),fontsize=9, color='#000000', textcoords='offset points',\n                   horizontalalignment='right')\nplt.title('Money Spend on Cloud Services', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")\nplt.ylabel('(USD)', fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:49.018845Z","iopub.execute_input":"2021-11-30T02:05:49.019155Z","iopub.status.idle":"2021-11-30T02:05:49.325127Z","shell.execute_reply.started":"2021-11-30T02:05:49.019113Z","shell.execute_reply":"2021-11-30T02:05:49.324214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **D. Identifying The Data Scientist**","metadata":{}},{"cell_type":"markdown","source":"**Now, We know the profile, experience, and salary of our respondents. Next, we will identify our respondents into some categories. We can use the data of profile, experience, salary and etc. The categories will split our respondents by their capabilities or level.**","metadata":{}},{"cell_type":"markdown","source":"**1. Convert from string to numeric variable**","metadata":{}},{"cell_type":"code","source":"def to_float(column):\n    for i in range(len(column)):\n        if pd.isnull(column[i]) == False:\n            if column[i].find('-') != -1:\n                number0 = float(column[i].split('-')[0])\n                number1 = float(column[i].split('-')[1])\n                column[i] = np.random.uniform(number0, number1)\n            elif column[i] == 0:\n                column[i] = 0\n            else:\n                number2 = float(column[i].split()[0])\n                number3 = number2+2.0\n                column[i] = np.random.uniform(number2, number3)\n    return column\n\ndef to_int(column):\n    for i in range(len(column)):\n        if pd.isnull(column[i]) == False:\n            if column[i].find('-') != -1:\n                number0 = int(column[i].split('-')[0])\n                number1 = int(column[i].split('-')[1])\n                column[i] = np.random.randint(number0, number1)\n            elif column[i] == 0:\n                column[i] = 0\n            else:\n                number2 = int(column[i].split()[0])\n                number3 = number2+2\n                column[i] = np.random.randint(number2, number3)\n    return column","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:49.326599Z","iopub.execute_input":"2021-11-30T02:05:49.326949Z","iopub.status.idle":"2021-11-30T02:05:49.338401Z","shell.execute_reply.started":"2021-11-30T02:05:49.326893Z","shell.execute_reply":"2021-11-30T02:05:49.337492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Change salary column from string into float, we fill the value using random value with range\ndf['yearly_comp'] = df['Q25']\ndf['yearly_comp'] = df['yearly_comp'].str.replace('\\$|,|<|>','', regex=True)\ndf['yearly_comp'] = to_float(df['yearly_comp'])\n\n# 2. Change salary column from string into float, we fill the value using random value with range\ndf['money_spend'] = df['Q26']\ndf['money_spend'] = df['money_spend'].str.replace('\\$|,|<|>','', regex=True)\ndf['money_spend'] = to_float(df['money_spend'])\n\n# 3. Change experience column from string into int, we fill the value using random value with range\ndf['prog_exp'] = df['Q6']\ndf['prog_exp'] = df['prog_exp'].str.replace(' |,|<|>','', regex=True)\ndf['prog_exp'] = to_int(df['prog_exp'])\n\n# 4. Change experience column from string into int, we fill the value using random value with range\ndf['ml_exp'] = df['Q15']\ndf['ml_exp'] = df['ml_exp'].str.replace(' |,|<|>','', regex=True)\ndf['ml_exp'] = to_int(df['ml_exp'])\n\n# 5. Change age column from string into int, we fill the value using random value with range\ndf['age_y'] = df['Q1']\ndf['age_y'] = df['age_y'].str.replace('+','', regex=True)\ndf['age_y'] = to_int(df['age_y'])","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:05:49.339843Z","iopub.execute_input":"2021-11-30T02:05:49.340179Z","iopub.status.idle":"2021-11-30T02:06:29.243551Z","shell.execute_reply.started":"2021-11-30T02:05:49.340138Z","shell.execute_reply":"2021-11-30T02:06:29.242503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Create a new dataframe for clustering**","metadata":{}},{"cell_type":"code","source":"newdf = df[['ml_exp', 'prog_exp', 'age_y', 'money_spend', 'yearly_comp']].copy()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:29.245087Z","iopub.execute_input":"2021-11-30T02:06:29.24534Z","iopub.status.idle":"2021-11-30T02:06:29.523459Z","shell.execute_reply.started":"2021-11-30T02:06:29.24531Z","shell.execute_reply":"2021-11-30T02:06:29.522611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Handle the missing value**","metadata":{}},{"cell_type":"code","source":"# We don't remove the nan value, but we will fill the missing value\n# Sort the dataframe by age\nnewdf = newdf.sort_values(by='age_y')\n# Fill the missing value using  ffill method\n# ffill method : propagates the last observed non-null value forward until another non-null value is encountered\n# That's why we sort the dataframe by age\nnewdf = newdf.fillna(axis=0, method='ffill')\n\n# Fill with mean value\nnewdf['prog_exp'] = newdf['prog_exp'].fillna(newdf['prog_exp'].mean())\nnewdf['age_y'] = newdf['age_y'].fillna(newdf['age_y'].mean())\nnewdf['ml_exp'] = newdf['ml_exp'].fillna(newdf['ml_exp'].mean())\nnewdf['money_spend'] = newdf['money_spend'].fillna(newdf['money_spend'].mean())\nnewdf['yearly_comp'] = newdf['yearly_comp'].fillna(newdf['yearly_comp'].mean())\nnewdf = newdf.sort_index()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:29.524595Z","iopub.execute_input":"2021-11-30T02:06:29.524828Z","iopub.status.idle":"2021-11-30T02:06:29.580456Z","shell.execute_reply.started":"2021-11-30T02:06:29.5248Z","shell.execute_reply":"2021-11-30T02:06:29.579696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Clustering with KMeans method**","metadata":{}},{"cell_type":"code","source":"# CLustering library\nfrom sklearn.cluster import KMeans","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:29.581393Z","iopub.execute_input":"2021-11-30T02:06:29.582154Z","iopub.status.idle":"2021-11-30T02:06:29.586153Z","shell.execute_reply.started":"2021-11-30T02:06:29.582116Z","shell.execute_reply":"2021-11-30T02:06:29.585293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = newdf[['ml_exp', 'prog_exp', 'age_y', 'money_spend', 'yearly_comp']].copy()\n\n# Using elbow method to find the best K value\nsse = []\nk_rng = range(1, 10)\nfor k in k_rng:\n    km = KMeans(n_clusters=k)\n    km.fit(dataset)\n    sse.append(km.inertia_)\n\nplt.plot(k_rng, sse)\nplt.xlabel('K')\nplt.ylabel('Sum of Squared Error', fontsize=16)\nplt.title('Elbow Method', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:29.58755Z","iopub.execute_input":"2021-11-30T02:06:29.5878Z","iopub.status.idle":"2021-11-30T02:06:44.834747Z","shell.execute_reply.started":"2021-11-30T02:06:29.587772Z","shell.execute_reply":"2021-11-30T02:06:44.828754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The use of 3 clusters makes acceptable. The level of a data scientist is commonly divided into an entry-level data scientist, a mid-level data scientist, and an expert data scientist, depending on the data science job opening.**","metadata":{}},{"cell_type":"code","source":"# Modeling\nmodel = KMeans(n_clusters=3)\ny_pred = model.fit_predict(dataset)\n\n# add cluster to new column\nnewdf['cluster'] = y_pred\nnewdf.corr()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:44.836698Z","iopub.execute_input":"2021-11-30T02:06:44.837787Z","iopub.status.idle":"2021-11-30T02:06:46.509209Z","shell.execute_reply.started":"2021-11-30T02:06:44.837729Z","shell.execute_reply":"2021-11-30T02:06:46.508345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**It is not easy to visualize all features of data in clustering, we will use one feature with the highest correlation value.**","metadata":{}},{"cell_type":"code","source":"df1 = newdf[newdf.cluster==0]\ndf2 = newdf[newdf.cluster==1]\ndf3 = newdf[newdf.cluster==2]\nplt.figure(figsize=(8, 6))\nplt.scatter(df1.age_y, df1['yearly_comp'], color='green')\nplt.scatter(df2.age_y, df2['yearly_comp'], color='red')\nplt.scatter(df3.age_y, df3['yearly_comp'], color='blue')\nplt.xlabel('Age')\nplt.ylabel('Yearly Compensation')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:46.510854Z","iopub.execute_input":"2021-11-30T02:06:46.515817Z","iopub.status.idle":"2021-11-30T02:06:46.933132Z","shell.execute_reply.started":"2021-11-30T02:06:46.515773Z","shell.execute_reply":"2021-11-30T02:06:46.932293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5. Give a name to the cluster**","metadata":{}},{"cell_type":"markdown","source":"**We can give name labels to the highest yearly compensation as Expert, and the middle as Mid, and the least yearly compensation as Entry.**","metadata":{}},{"cell_type":"code","source":"newdf['exp_level'] = newdf['cluster']\nnewdf['exp_level'] = newdf['exp_level'].replace({\n    0:'Entry',\n    1:'Expert',\n    2:'Mid'\n})\n\n# concatinating df with newdf\ndf = pd.concat([df, newdf['exp_level']], axis=1)\ndf['exp_level'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:46.934664Z","iopub.execute_input":"2021-11-30T02:06:46.9353Z","iopub.status.idle":"2021-11-30T02:06:47.192137Z","shell.execute_reply.started":"2021-11-30T02:06:46.935253Z","shell.execute_reply":"2021-11-30T02:06:47.191219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6. Who are they?**","metadata":{}},{"cell_type":"markdown","source":"**We can use the experience level data to see their profile broken down by experience level.**","metadata":{}},{"cell_type":"code","source":"def profile_level(col, level, explode, explode_n):\n    # Entry\n    # make figure and assign axis objects\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n    fig.subplots_adjust(wspace=0)\n\n    # pie chart parameters\n    ratios = df['exp_level'].value_counts()\n    labels = df['exp_level'].unique()\n    explode = explode\n\n    # rotate so that first wedge is split by the x-axis\n    angle = 0 * ratios[0]\n    ax1.pie(ratios, autopct='%1.1f%%', startangle=angle, labels=labels, explode=explode)\n\n    # bar chart parameters\n    xpos = 0\n    bottom = 0\n    ratios = df.loc[df['exp_level'] == level, col].value_counts()\n    width = .2\n\n    for j in range(len(ratios)):\n        height = ratios[j]\n        ax2.bar(xpos, height, width, bottom=bottom)\n        ypos = bottom + ax2.patches[j].get_height() / 2\n        bottom += height\n        ax2.text(xpos, ypos, (ax2.patches[j].get_height()), ha='center')\n\n    ax2.set_title('Count')\n    ax2.legend(df.loc[df['exp_level'] == level, col].unique(), loc='upper right')\n    ax2.axis('off')\n    ax2.set_xlim(- 2.5 * width, 2.5 * width)\n\n    # use ConnectionPatch to draw lines between the two plots\n    # get the wedge data\n    theta1, theta2 = ax1.patches[explode_n].theta1, ax1.patches[explode_n].theta2\n    center, r = ax1.patches[explode_n].center, ax1.patches[explode_n].r\n    bar_height = sum([item.get_height() for item in ax2.patches])\n\n    # draw top connecting line\n    x = r * np.cos(np.pi / 180 * theta2) + center[0]\n    y = r * np.sin(np.pi / 180 * theta2) + center[1]\n    con = ConnectionPatch(xyA=(-width / 2, bar_height), coordsA=ax2.transData, xyB=(x, y), coordsB=ax1.transData)\n    con.set_color([0, 0, 0])\n    con.set_linewidth(4)\n    ax2.add_artist(con)\n\n    # draw bottom connecting line\n    x = r * np.cos(np.pi / 180 * theta1) + center[0]\n    y = r * np.sin(np.pi / 180 * theta1) + center[1]\n    con = ConnectionPatch(xyA=(-width / 2, 0), coordsA=ax2.transData, xyB=(x, y), coordsB=ax1.transData)\n    con.set_color([0, 0, 0])\n    ax2.add_artist(con)\n    con.set_linewidth(4)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:47.193559Z","iopub.execute_input":"2021-11-30T02:06:47.194257Z","iopub.status.idle":"2021-11-30T02:06:47.208337Z","shell.execute_reply.started":"2021-11-30T02:06:47.194223Z","shell.execute_reply":"2021-11-30T02:06:47.207253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**By Respondent's Age**","metadata":{}},{"cell_type":"markdown","source":"**Entry Level by Age**","metadata":{}},{"cell_type":"code","source":"sns.set_palette('CMRmap_r')\n# col, level, explode, explode_n\nprofile_level('Q1', 'Entry', [0.1, 0.0, 0.0], 0)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:47.212748Z","iopub.execute_input":"2021-11-30T02:06:47.213076Z","iopub.status.idle":"2021-11-30T02:06:47.500358Z","shell.execute_reply.started":"2021-11-30T02:06:47.213033Z","shell.execute_reply":"2021-11-30T02:06:47.499484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Middle Level by Age****","metadata":{}},{"cell_type":"code","source":"# col, level, explode, explode_n\nprofile_level('Q1', 'Mid', [0.0, 0.1, 0.0], 1)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:47.501668Z","iopub.execute_input":"2021-11-30T02:06:47.502364Z","iopub.status.idle":"2021-11-30T02:06:47.772313Z","shell.execute_reply.started":"2021-11-30T02:06:47.502322Z","shell.execute_reply":"2021-11-30T02:06:47.771511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Expert Level by Age**","metadata":{}},{"cell_type":"code","source":"# col, level, explode, explode_n\nprofile_level('Q1', 'Expert', [0.0, 0.0, 0.1], 2)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:47.773846Z","iopub.execute_input":"2021-11-30T02:06:47.774285Z","iopub.status.idle":"2021-11-30T02:06:48.042861Z","shell.execute_reply.started":"2021-11-30T02:06:47.774244Z","shell.execute_reply":"2021-11-30T02:06:48.041999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**By Respondent's Education**","metadata":{}},{"cell_type":"markdown","source":"**Entry Level by Education**","metadata":{}},{"cell_type":"code","source":"# col, level, explode, explode_n\nprofile_level('Q4', 'Entry', [0.1, 0.0, 0.0], 0)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:48.044397Z","iopub.execute_input":"2021-11-30T02:06:48.044881Z","iopub.status.idle":"2021-11-30T02:06:48.297185Z","shell.execute_reply.started":"2021-11-30T02:06:48.044839Z","shell.execute_reply":"2021-11-30T02:06:48.296352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Middle Level by Education**","metadata":{}},{"cell_type":"code","source":"# col, level, explode, explode_n\nprofile_level('Q4', 'Mid', [0.0, 0.1, 0.0], 1)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:48.298653Z","iopub.execute_input":"2021-11-30T02:06:48.299079Z","iopub.status.idle":"2021-11-30T02:06:48.648356Z","shell.execute_reply.started":"2021-11-30T02:06:48.299039Z","shell.execute_reply":"2021-11-30T02:06:48.647467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Expert Level by Education**","metadata":{}},{"cell_type":"code","source":"# col, level, explode, explode_n\nprofile_level('Q4', 'Expert', [0.0, 0.0, 0.1], 2)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:48.649557Z","iopub.execute_input":"2021-11-30T02:06:48.649794Z","iopub.status.idle":"2021-11-30T02:06:49.001741Z","shell.execute_reply.started":"2021-11-30T02:06:48.649764Z","shell.execute_reply":"2021-11-30T02:06:49.001099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **E. The Behavior of Data Scientist**","metadata":{}},{"cell_type":"markdown","source":"**We'll learn about data scientists' behaviors when working in the field, such as \"What programming language do they use?\" \"What cloud computing services do they use?\" \"What are their preferred tools?\" and so on. We'll use their actions as a blueprint for becoming data scientists.**","metadata":{}},{"cell_type":"code","source":"def behavior_ds(cols):\n    list_Q = [col for col in df.columns if cols in col]\n    Q = df[list_Q].copy()\n    exp = pd.concat([Q, df['exp_level']], axis=1)\n    new_exp = (exp.melt(\n        id_vars='exp_level', \n        value_vars = list_Q, \n        value_name=cols).drop('variable', axis=1))\n    plt.figure(figsize=(12,10))\n    count = sns.countplot(data=new_exp, y=cols, hue='exp_level', order=new_exp[cols].value_counts().iloc[:10].index)\n    for i in count.patches:\n        count.annotate(int(i.get_width()),((i.get_x() + i.get_width()), i.get_y()), \n                       xytext=(26,-9),fontsize=9, color='#000000', textcoords='offset points', horizontalalignment='right')\n        \ndef behavior_ds_one(col):\n    plt.figure(figsize=(12,10))\n    count = sns.countplot(data=df, y=col, hue='exp_level', order=df[col].value_counts().iloc[:10].index)\n    for i in count.patches:\n        count.annotate(format(i.get_width()),((i.get_x() + i.get_width()), i.get_y()), \n                       xytext=(30,-8),fontsize=9, color='#000000', textcoords='offset points', horizontalalignment='right')","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:49.002686Z","iopub.execute_input":"2021-11-30T02:06:49.003244Z","iopub.status.idle":"2021-11-30T02:06:49.013742Z","shell.execute_reply.started":"2021-11-30T02:06:49.003209Z","shell.execute_reply":"2021-11-30T02:06:49.012716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**1. Programming Language**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite programming language?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q7')\nplt.ylabel('Programming Language', fontsize=16)\nplt.title('Most used programming language on reguler basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:49.015237Z","iopub.execute_input":"2021-11-30T02:06:49.016291Z","iopub.status.idle":"2021-11-30T02:06:50.311967Z","shell.execute_reply.started":"2021-11-30T02:06:49.016245Z","shell.execute_reply":"2021-11-30T02:06:50.310909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**They also give you a recommendation about what programming language you should learn to work in the data field**","metadata":{}},{"cell_type":"code","source":"behavior_ds_one('Q8')\nplt.ylabel('Programming Language', fontsize=16)\nplt.title('Programming language to learn data science recommend by data scientist', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:50.313317Z","iopub.execute_input":"2021-11-30T02:06:50.314215Z","iopub.status.idle":"2021-11-30T02:06:50.887753Z","shell.execute_reply.started":"2021-11-30T02:06:50.314158Z","shell.execute_reply":"2021-11-30T02:06:50.886394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**2. Integrated Development Environments (IDE)**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite IDE?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q9')\nplt.ylabel('IDE', fontsize=16)\nplt.title('Most used IDE on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:50.889251Z","iopub.execute_input":"2021-11-30T02:06:50.88967Z","iopub.status.idle":"2021-11-30T02:06:51.729304Z","shell.execute_reply.started":"2021-11-30T02:06:50.889624Z","shell.execute_reply":"2021-11-30T02:06:51.728456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is their favorite Hosted Notebook?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q10')\nplt.ylabel('Hosted Notebook', fontsize=16)\nplt.title('Most used hosted notebook products on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:51.730573Z","iopub.execute_input":"2021-11-30T02:06:51.730784Z","iopub.status.idle":"2021-11-30T02:06:52.654206Z","shell.execute_reply.started":"2021-11-30T02:06:51.730758Z","shell.execute_reply":"2021-11-30T02:06:52.653252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**3. Specialized Hardware**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite specialized hardware?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q12')\nplt.ylabel('Hardware', fontsize=16)\nplt.title('Most used specialized hardware on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:52.656034Z","iopub.execute_input":"2021-11-30T02:06:52.656355Z","iopub.status.idle":"2021-11-30T02:06:53.157567Z","shell.execute_reply.started":"2021-11-30T02:06:52.656314Z","shell.execute_reply":"2021-11-30T02:06:53.156456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**4. Data Visualization Libraries**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite visualization library?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q14')\nplt.ylabel('Data Visualization Libraries', fontsize=16)\nplt.title('Most used data visualization libraries on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:53.159083Z","iopub.execute_input":"2021-11-30T02:06:53.159334Z","iopub.status.idle":"2021-11-30T02:06:54.16269Z","shell.execute_reply.started":"2021-11-30T02:06:53.159297Z","shell.execute_reply":"2021-11-30T02:06:54.161813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**5. Machine Learning**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite machine learning framewok?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q16')\nplt.ylabel('Machine Learning Framework', fontsize=16)\nplt.title('Most used machine learning framework on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:54.163927Z","iopub.execute_input":"2021-11-30T02:06:54.164137Z","iopub.status.idle":"2021-11-30T02:06:55.083721Z","shell.execute_reply.started":"2021-11-30T02:06:54.164113Z","shell.execute_reply":"2021-11-30T02:06:55.08284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is their favorite machine learning algorithm?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q17')\nplt.ylabel('Machine Learning Algorithms', fontsize=16)\nplt.title('Most used machine learning algorithms on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:55.08501Z","iopub.execute_input":"2021-11-30T02:06:55.085215Z","iopub.status.idle":"2021-11-30T02:06:55.962267Z","shell.execute_reply.started":"2021-11-30T02:06:55.085191Z","shell.execute_reply":"2021-11-30T02:06:55.961241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is their favorite machine learning product?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q31_A')\nplt.ylabel('Machine Learning Products', fontsize=16)\nplt.title('Most used managed machine learning products', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:55.963721Z","iopub.execute_input":"2021-11-30T02:06:55.964041Z","iopub.status.idle":"2021-11-30T02:06:56.677243Z","shell.execute_reply.started":"2021-11-30T02:06:55.963997Z","shell.execute_reply":"2021-11-30T02:06:56.676373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is their favorite automated machine learning tool?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q37_A')\nplt.ylabel('Automated Machine Learning Tools', fontsize=16)\nplt.title('Most used automated machine learning tools on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:56.678395Z","iopub.execute_input":"2021-11-30T02:06:56.678633Z","iopub.status.idle":"2021-11-30T02:06:57.261718Z","shell.execute_reply.started":"2021-11-30T02:06:56.678607Z","shell.execute_reply":"2021-11-30T02:06:57.260737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**6. Computer Vision**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite computer vision method?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q18')\nplt.ylabel('Computer Vision Methods', fontsize=16)\nplt.title('Most used computer vision methods on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:57.262863Z","iopub.execute_input":"2021-11-30T02:06:57.263094Z","iopub.status.idle":"2021-11-30T02:06:57.870259Z","shell.execute_reply.started":"2021-11-30T02:06:57.263067Z","shell.execute_reply":"2021-11-30T02:06:57.869266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**7. Cloud Computing Platforms**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite cloud computing platforms?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q27_A')\nplt.ylabel('Cloud Computing Platforms', fontsize=16)\nplt.title('Most used cloud computing platforms on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:57.871386Z","iopub.execute_input":"2021-11-30T02:06:57.871641Z","iopub.status.idle":"2021-11-30T02:06:58.675901Z","shell.execute_reply.started":"2021-11-30T02:06:57.871612Z","shell.execute_reply":"2021-11-30T02:06:58.675025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**8. Data Storage Products**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite data storage product?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q30_A')\nplt.ylabel('Data Storage Products', fontsize=16)\nplt.title('Most used data storage products on regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:58.677123Z","iopub.execute_input":"2021-11-30T02:06:58.677475Z","iopub.status.idle":"2021-11-30T02:06:59.339286Z","shell.execute_reply.started":"2021-11-30T02:06:58.677435Z","shell.execute_reply":"2021-11-30T02:06:59.338439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is their favorite big data product?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q32_A')\nplt.ylabel('Big Data Products', fontsize=16)\nplt.title('Most used big data products one regular basis', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:06:59.34103Z","iopub.execute_input":"2021-11-30T02:06:59.341343Z","iopub.status.idle":"2021-11-30T02:07:00.294705Z","shell.execute_reply.started":"2021-11-30T02:06:59.341302Z","shell.execute_reply":"2021-11-30T02:07:00.293746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**9. Business Intelligence Tools**","metadata":{}},{"cell_type":"markdown","source":"**What is their favorite business intelligence tool?**","metadata":{}},{"cell_type":"code","source":"behavior_ds_one('Q35')\nplt.ylabel('Business Intelligence Tools', fontsize=16)\nplt.title('Most used business intelligence tools for data science', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:07:00.295885Z","iopub.execute_input":"2021-11-30T02:07:00.296117Z","iopub.status.idle":"2021-11-30T02:07:00.808014Z","shell.execute_reply.started":"2021-11-30T02:07:00.296088Z","shell.execute_reply":"2021-11-30T02:07:00.80713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**10. Data Science Platform**","metadata":{}},{"cell_type":"markdown","source":"**Favorite platform to learn data science**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q40')\nplt.ylabel('Learning Platform', fontsize=16)\nplt.title('A platform to learn data science', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:07:00.8092Z","iopub.execute_input":"2021-11-30T02:07:00.809481Z","iopub.status.idle":"2021-11-30T02:07:01.668513Z","shell.execute_reply.started":"2021-11-30T02:07:00.809445Z","shell.execute_reply":"2021-11-30T02:07:01.667674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Keep up-to-date with data science topics**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q42')\nplt.ylabel('Media Sources', fontsize=16)\nplt.title('Favorite media sources that report on data science topics', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:07:01.669774Z","iopub.execute_input":"2021-11-30T02:07:01.670205Z","iopub.status.idle":"2021-11-30T02:07:02.577577Z","shell.execute_reply.started":"2021-11-30T02:07:01.670164Z","shell.execute_reply":"2021-11-30T02:07:02.576686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**What is their favorite platform to share their machine learning application?**","metadata":{}},{"cell_type":"code","source":"behavior_ds('Q39')\nplt.ylabel('Publicy Platform', fontsize=16)\nplt.title('A platform for publish data analysis or machine learning applications', fontfamily='sans-serif', fontsize=16, fontweight=\"bold\")","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:07:02.579319Z","iopub.execute_input":"2021-11-30T02:07:02.580025Z","iopub.status.idle":"2021-11-30T02:07:03.338888Z","shell.execute_reply.started":"2021-11-30T02:07:02.579952Z","shell.execute_reply":"2021-11-30T02:07:03.338014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **F. Conclusion**","metadata":{}},{"cell_type":"markdown","source":"**When using data science tools, the majority of our respondents behaved in a similar way, whether they were beginners, intermediates, or experts.** \n1. Python is the most popular programming language among our respondents, and they advise learning it if you want to work as a data scientist.\n2. Their favorite IDEs are Jupyter Notebook and VSCode. Their favorite hosted notebooks are Colab, and Kaggle.\n3. Although the majority of our respondents do not employ specialized hardware, NVIDIA GPU and Google Cloud TPU are the most popular.\n4. Their favorite data visualization libraries are Matplotlib and Seaborn.\n5. The most popular machine learning frameworks are Scikit-Learn and TensorFlow, and the most popular machine learning algorithms are Linear Regression and Decision Trees or Random Forest. However, most of them do not use machine learning products or automated machine learning tools.\n6. Their primary computer vision method is image classification.\n7. Amazon's cloud computing and data storage capabilities remain at the top\n8. MySQL as their big data solution.\n9. The most popular business intelligence tool is Microsoft Power BI, however other experts prefer Tableau.\n10. Our respondents' preferred learning sites are Coursera,Kaggle Learn and Udemy, they used Kaggle to gain information about data science topics. They use GitHub to share their machine learning apps.","metadata":{}},{"cell_type":"markdown","source":"**We can draw some conclusions based on the information we've gathered.**","metadata":{"execution":{"iopub.status.busy":"2021-11-26T17:50:17.75736Z","iopub.execute_input":"2021-11-26T17:50:17.757755Z","iopub.status.idle":"2021-11-26T17:50:17.764671Z","shell.execute_reply.started":"2021-11-26T17:50:17.757706Z","shell.execute_reply":"2021-11-26T17:50:17.763333Z"}}},{"cell_type":"markdown","source":"**Data Science Roadmap**","metadata":{}},{"cell_type":"code","source":"from datetime import date\n\ndates = [date(2022, 1, 1), date(2022, 1, 15), date(2022, 2, 15), date(2022, 3, 15), \n         date(2022, 4, 15), date(2022, 6, 15), date(2022, 7, 1)]\n \nlabels = [\n    'Statistics and Mathematics\\nStd, Mean, Median, Mode, etc',\n    'Programming\\nPython, R, SQL', \n    'Data Extraction\\nPython Libraries (e.g. Pandas, Numpy)', \n    'Exploratory Data Analysis\\nSeaborn, Matplotlib, Plotly, etc',\n    'Machine Learning\\nMachine Learning Frameworks and Algorithms',\n    'Data Engineering\\nCloud Services, Deploying Machine Learning Model, ETL, etc',\n    'Keep Practicing ~'\n]\n\n# Add label to dates\nlabels = ['{0:%d %b %Y}\\n{1}'.format(d, l) for l, d in zip (labels, dates)]\n\nfig, ax = plt.subplots(figsize=(16, 4), constrained_layout=True)\nax.set_ylim(-1, 1)\n\nax.scatter(dates, np.zeros(len(dates)), s=120, zorder=2)\nax.scatter(dates, np.zeros(len(dates)), s=30, zorder=3)\n\nlabel_offsets = np.zeros(len(dates))\nlabel_offsets[::2] = 0.4 # top label\nlabel_offsets[1::2] = -0.7 # bottom label\nfor i, (l, d) in enumerate(zip(labels, dates)):\n    ax.text(d, label_offsets[i], l, ha='center', fontsize=12)\n\nstems = np.zeros(len(dates))\nstems[::2] = 0.35 # top marker\nstems[1::2] = -0.35 # bottom marker\nmarkerline, stemline, baseline = ax.stem(dates, stems, use_line_collection=True)\nplt.setp(markerline, color='black')\nplt.setp(stemline, color='black')\n\n# hide chart border\nfor spine in [\"left\", \"top\", \"right\", \"bottom\"]:\n    ax.spines[spine].set_visible(False)\n\nax.set_xticks([])\nax.set_yticks([])    \nax.set_title('Data Science Roadmap', fontweight=\"bold\", fontsize=16)","metadata":{"execution":{"iopub.status.busy":"2021-11-30T02:07:03.340248Z","iopub.execute_input":"2021-11-30T02:07:03.340509Z","iopub.status.idle":"2021-11-30T02:07:03.616115Z","shell.execute_reply.started":"2021-11-30T02:07:03.340479Z","shell.execute_reply":"2021-11-30T02:07:03.615312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We might assume that the respondent's lowest level of education is high school. I believe we all studied basic statistics and mathematics in high school, and with only those fundamentals, we can begin our journey to become data scientists. Basic statistics lectures are mostly given by some Data Science learning platforms as a refresher.**","metadata":{}},{"cell_type":"markdown","source":"**Although Data Science is a high-demand job, there are still few experts in the field. You can become a Data Science regardless of your background. After reading some of the data presented above and reading the Data Science Roadmap, I hope you have a better understanding of how to begin as a Data Science until you become an expert. This is only a small portion of what data science has to provide, you may learn more from experts by visiting data science forums or platforms like Kaggle and others.**","metadata":{}},{"cell_type":"markdown","source":"**I hope that everyone who reads this data visualization finds it to be useful. Since I'm also an entry-level person, you can give me advice if you see any inaccurate or misleading information.**","metadata":{}},{"cell_type":"markdown","source":"# **<div style=\"text-align: center\">Thank You!</div>**","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}