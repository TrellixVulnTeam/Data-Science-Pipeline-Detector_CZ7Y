{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.options.mode.chained_assignment = None  # default='warn'\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":2.328035,"end_time":"2021-11-19T05:18:24.553722","exception":false,"start_time":"2021-11-19T05:18:22.225687","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:28:52.848238Z","iopub.execute_input":"2021-11-19T05:28:52.849039Z","iopub.status.idle":"2021-11-19T05:28:55.117547Z","shell.execute_reply.started":"2021-11-19T05:28:52.848896Z","shell.execute_reply":"2021-11-19T05:28:55.116584Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_response=pd.read_csv('/kaggle/input/kaggle-survey-2021/kaggle_survey_2021_responses.csv')\ndf_response = df_response[~df_response.Q2.str.contains(\"Selected Choice\")]\ndf_response['Q25'] = df_response['Q25'].replace(['$0-999'],'Level 1: $0-9,999')\ndf_response['Q25'] = df_response['Q25'].replace(['1,000-1,999'],'Level 1: $0-9,999')\ndf_response['Q25'] = df_response['Q25'].replace(['2,000-2,999'],'Level 1: $0-9,999')\ndf_response['Q25'] = df_response['Q25'].replace(['3,000-3,999'],'Level 1: $0-9,999')\ndf_response['Q25'] = df_response['Q25'].replace(['4,000-4,999'],'Level 1: $0-9,999')\ndf_response['Q25'] = df_response['Q25'].replace(['5,000-7,499'],'Level 1: $0-9,999')\ndf_response['Q25'] = df_response['Q25'].replace(['7,500-9,999'],'Level 1: $0-9,999')\n\ndf_response['Q25'] = df_response['Q25'].replace(['10,000-14,999'],'Level 2: $10,000-39,999')\ndf_response['Q25'] = df_response['Q25'].replace(['15,000-19,999'],'Level 2: $10,000-39,999')\ndf_response['Q25'] = df_response['Q25'].replace(['20,000-24,999'],'Level 2: $10,000-39,999')\ndf_response['Q25'] = df_response['Q25'].replace(['25,000-29,999'],'Level 2: $10,000-39,999')\ndf_response['Q25'] = df_response['Q25'].replace(['30,000-39,999'],'Level 2: $10,000-39,999')\n\ndf_response['Q25'] = df_response['Q25'].replace(['40,000-49,999'],'Level 3: $40,000-79,999')\ndf_response['Q25'] = df_response['Q25'].replace(['50,000-59,999'],'Level 3: $40,000-79,999')\ndf_response['Q25'] = df_response['Q25'].replace(['60,000-69,999'],'Level 3: $40,000-79,999')\ndf_response['Q25'] = df_response['Q25'].replace(['70,000-79,999'],'Level 3: $40,000-79,999')\n\ndf_response['Q25'] = df_response['Q25'].replace(['80,000-89,999'],'Level 4: $80,000-149,999')\ndf_response['Q25'] = df_response['Q25'].replace(['90,000-99,999'],'Level 4: $80,000-149,999')\ndf_response['Q25'] = df_response['Q25'].replace(['100,000-124,999'],'Level 4: $80,000-149,999')\ndf_response['Q25'] = df_response['Q25'].replace(['125,000-149,999'],'Level 4: $80,000-149,999')\n\ndf_response['Q25'] = df_response['Q25'].replace(['150,000-199,999'],'Level 5: $150,000-499,999')\ndf_response['Q25'] = df_response['Q25'].replace(['200,000-249,999'],'Level 5: $150,000-499,999')\ndf_response['Q25'] = df_response['Q25'].replace(['250,000-299,999'],'Level 5: $150,000-499,999')\ndf_response['Q25'] = df_response['Q25'].replace(['300,000-499,999'],'Level 5: $150,000-499,999')\n\ndf_response['Q25'] = df_response['Q25'].replace(['$500,000-999,999'],'Level 6: > $500,000')\ndf_response['Q25'] = df_response['Q25'].replace(['>$1,000,000'],'Level 6: > $500,000')\n\ndf_response['Q4'] = df_response['Q4'].replace(['No formal education past high school'],'Upto HS')\ndf_response['Q4'] = df_response['Q4'].replace(['Some college/university study without earning a bachelor’s degree'],'College/no degree')\n\ndf_response['Q23'] = df_response['Q23'].replace(['We are exploring ML methods (and may one day put a model into production)'],'Level 1 -Exploring ML')\ndf_response['Q23'] = df_response['Q23'].replace(['We use ML methods for generating insights (but do not put working models into production)'],'Level 2- ML insights')\n\ndf_response['Q23'] = df_response['Q23'].replace(['We recently started using ML methods (i.e., models in production for less than 2 years)'],'Level 3 - ML recent users')\ndf_response['Q23'] = df_response['Q23'].replace(['We have well established ML methods (i.e., models in production for more than 2 years)'],'Level 4 - ML established users')\n\ndf_response['Q23'] = df_response['Q23'].replace(['No (we do not use ML methods)'],'No ML')\ndf_response['Q23'] = df_response['Q23'].replace(['I do not know'],'Not Aware')\n\ndf_response['Q15'] = df_response['Q15'].replace(['Under 1 year'],' 1 year or less')\ndf_response['Q15'] = df_response['Q15'].replace(['1-2 years'],'1-2 years')\n\ndf_response['Q15'] = df_response['Q15'].replace(['2-3 years'],'2-5 years')\ndf_response['Q15'] = df_response['Q15'].replace(['3-4 years'],'2-5 years')\n\ndf_response['Q15'] = df_response['Q15'].replace(['4-5 years'],'2-5 years')\ndf_response['Q15'] = df_response['Q15'].replace(['5-10 years'],'5-10 years')\n\ndf_response['Q15'] = df_response['Q15'].replace(['10-20 years'],'>10 years')\ndf_response['Q15'] = df_response['Q15'].replace(['20 or more years'],'>10 years')\ndf_response['Q15'] = df_response['Q15'].replace(['I do not use machine learning methods'],'No Exp with ML')\n\ndf_response['Q3'] = df_response['Q3'].replace(['United States of America'],'USA')\n\n\n\n","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.878814,"end_time":"2021-11-19T05:18:26.460517","exception":false,"start_time":"2021-11-19T05:18:24.581703","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:28:55.119846Z","iopub.execute_input":"2021-11-19T05:28:55.120638Z","iopub.status.idle":"2021-11-19T05:28:56.949173Z","shell.execute_reply.started":"2021-11-19T05:28:55.120592Z","shell.execute_reply":"2021-11-19T05:28:56.948297Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# “Earn Nicely, spend wisely and you will live happily.” ― Auliq Ice\n#### As kagglers we all know a job is the field of data science is one of the highest paid jobs in today’s market. But does everyone working in this field get paid high salaries? What are the key factors that affect income? Let's find out who is earning the highest salary in this field and how! \n\n#### We will perform two kinds of analysis. First we will analyze respondent's **background* - their age, where they live and education levels. Secondly, we will analyze their **job roles** - the size of the company, years of experience, ML focus.. \n\n#### In The given data set, the salary levels are grouped and ordered as below. \n* Level 1: \\\\$0-9,999 \n* Level 2: \\\\$10,000-39,999\n* Level 3: \\\\$40,000-79,999\n* Level 4: \\\\$80,000-149,999\n* Level 5: \\\\$150,000-499,999\n* Level 6: > \\\\$500,000\n\n* We can see that majority of respondents earn less than 10,000 USD a year! \n* The second highest percent are in the Level 2 salary range of 10,000 - 40,000. 30% of the respondents are in the mid-level salary range. \n* However, there are around 5% of respondents who earn more than 150,000 a year. \n\n### Who earns a Level 5 or 6 salary range and what makes them different?\n","metadata":{"papermill":{"duration":0.025886,"end_time":"2021-11-19T05:18:26.512645","exception":false,"start_time":"2021-11-19T05:18:26.486759","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_exp = df_response['Q25'].value_counts(normalize=True).to_frame('Percent')\ndf_exp['Percent'] = round(df_exp['Percent'].mul(100),1)\n\ndf_exp = df_exp.sort_index(ascending=True)\nax = df_exp.plot.bar(color='#8f5dc3', alpha=0.7,figsize=(8, 6), title =\"Percent of income levels in the dataset\", legend=None )\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\nplt.grid(color='#b196ba', linestyle='--', linewidth=2, axis='y', alpha=0.7)\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.323721,"end_time":"2021-11-19T05:18:26.862614","exception":false,"start_time":"2021-11-19T05:18:26.538893","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:28:56.950584Z","iopub.execute_input":"2021-11-19T05:28:56.95084Z","iopub.status.idle":"2021-11-19T05:28:57.30637Z","shell.execute_reply.started":"2021-11-19T05:28:56.950798Z","shell.execute_reply":"2021-11-19T05:28:57.305577Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Does Location matter? \n#### First, let's see where most of the people who responded to the survey live. We will then analyze the top 5 countries that took part in the survey. \n#### We see the top 5 countries that responded to the survey were India, United States of America, Japan, China, Brazil.\n","metadata":{"papermill":{"duration":0.027272,"end_time":"2021-11-19T05:18:26.917383","exception":false,"start_time":"2021-11-19T05:18:26.890111","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#Creating Dataframes for each income level\ndf_temp = df_response[df_response['Q3'] != 'Other']\ndf_top5=df_temp['Q3'].value_counts()\ndf_top5=df_top5.sort_values(ascending= False).head(5)\n\n\ntop5C = ['India',\"USA\",'Japan','China','Brazil']\ndf_countries = df_response[df_response.Q3.isin(top5C)]\n\nLevel1 = ['Level 1: $0-9,999']\ndf_l1 = df_countries[df_countries.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_countries[df_countries.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_countries[df_countries.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_countries[df_countries.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_countries[df_countries.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_countries[df_countries.Q25.isin(Level6)]","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.236467,"end_time":"2021-11-19T05:18:27.181955","exception":false,"start_time":"2021-11-19T05:18:26.945488","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:28:57.308372Z","iopub.execute_input":"2021-11-19T05:28:57.308884Z","iopub.status.idle":"2021-11-19T05:28:57.512281Z","shell.execute_reply.started":"2021-11-19T05:28:57.308845Z","shell.execute_reply":"2021-11-19T05:28:57.511381Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Now let's look at each salary band and see the distribution of countries in it. \n* In the Level 1 and Level 2 bands, we see most respondents are from India.  \n* Level 3 Salary has an almost equal distribution of countries. \n* In higher salary levels of Level 4,5 and 6, almost 80% are from the United States of America.\n* In the small number of people who earn higher than 500,000. 26% of them live in India.\n","metadata":{"papermill":{"duration":0.027461,"end_time":"2021-11-19T05:18:27.236844","exception":false,"start_time":"2021-11-19T05:18:27.209383","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_exp1 = df_l1['Q3'].value_counts(normalize=True).to_frame('Percent')\ndf_exp1['Percent'] = round(df_exp1['Percent'].mul(100),1)\ndf_exp1 = df_exp1.sort_index(ascending=True)\n\ndf_exp2 = df_l2['Q3'].value_counts(normalize=True).to_frame('Percent')\ndf_exp2['Percent'] = round(df_exp2['Percent'].mul(100),1)\ndf_exp2 = df_exp2.sort_index(ascending=True)\n\n\ndf_exp3 = df_l3['Q3'].value_counts(normalize=True).to_frame('Percent')\ndf_exp3['Percent'] = round(df_exp3['Percent'].mul(100),1)\ndf_exp3 = df_exp3.sort_index(ascending=True)\n\n\ndf_exp4 = df_l4['Q3'].value_counts(normalize=True).to_frame('Percent')\ndf_exp4['Percent'] = round(df_exp4['Percent'].mul(100),1)\ndf_exp4 = df_exp4.sort_index(ascending=True)\n\ndf_exp5 = df_l5['Q3'].value_counts(normalize=True).to_frame('Percent')\ndf_exp5['Percent'] = round(df_exp5['Percent'].mul(100),1)\ndf_exp5 = df_exp5.sort_index(ascending=True)\n\n\ndf_exp6 = df_l6['Q3'].value_counts(normalize=True).to_frame('Percent')\ndf_exp6['Percent'] = round(df_exp6['Percent'].mul(100),1)\ndf_exp6 = df_exp6.sort_index(ascending=True)\n\n\ndf_list = [df_exp1 ,df_exp2, df_exp3, df_exp4,df_exp5,df_exp6]\n\nfig, axes = plt.subplots(2, 3,sharey=True,constrained_layout = True)\ncolors =['#a8e6cf', '#dcedc1', '#ffd3b6', '#ffaaa5', '#ff8b94', '#66373B']\ntitles =['Percent of country - Level 1', 'Percent of country - Level 2', 'Percent of country - Level 2', 'Percent of country - Level 4', 'Percent of country - Level 5', 'Percent of country - Level 6']\n# plot counter\ncount=0\nfor r in range(2):\n    for c in range(3):\n        ax = df_list[count].plot.bar(color=colors[count],alpha=0.7,ax=axes[r,c],figsize=(15, 13), title =titles[count], legend=None )\n        for p in ax.patches:\n            width = p.get_width()\n            height = p.get_height()\n            x, y = p.get_xy() \n            ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\n\n        #df_list[count].plot.bar(color='royalblue', alpha=0.7,ax=axes[r,c],figsize=(18, 16))\n        count+=1\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.200572,"end_time":"2021-11-19T05:18:28.464952","exception":false,"start_time":"2021-11-19T05:18:27.26438","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:28:57.513859Z","iopub.execute_input":"2021-11-19T05:28:57.514084Z","iopub.status.idle":"2021-11-19T05:28:58.720459Z","shell.execute_reply.started":"2021-11-19T05:28:57.514057Z","shell.execute_reply":"2021-11-19T05:28:58.719596Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Does age matter?\n### As we analyze our dataset we can see the majority of the respondents are between 18 to 30 years.\n","metadata":{"papermill":{"duration":0.028928,"end_time":"2021-11-19T05:18:28.522805","exception":false,"start_time":"2021-11-19T05:18:28.493877","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_exp = df_response['Q1'].value_counts(normalize=True).to_frame('Percent')\ndf_exp['Percent'] = round(df_exp['Percent'].mul(100),1)\n\ndf_exp = df_exp.sort_index(ascending=True)\nax = df_exp.plot.bar(color='#8f5dc3', alpha=0.7,figsize=(8, 6), title =\"Percent of age in dataset\", legend=None)\nfor p in ax.patches:\n    width = p.get_width()\n    height = p.get_height()\n    x, y = p.get_xy() \n    ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\nplt.grid(color='#b196ba', linestyle='--', linewidth=2, axis='y', alpha=0.7)\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.335413,"end_time":"2021-11-19T05:18:28.887009","exception":false,"start_time":"2021-11-19T05:18:28.551596","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:28:58.72178Z","iopub.execute_input":"2021-11-19T05:28:58.722592Z","iopub.status.idle":"2021-11-19T05:28:59.029247Z","shell.execute_reply.started":"2021-11-19T05:28:58.722547Z","shell.execute_reply":"2021-11-19T05:28:59.028474Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## We see a clear change in the salary trend as age increases. \n* The number of people between the ages 22-30 is highest in the Level 1 salary range. \n* People between 25-35 increases in the Level 2 and 3.\n* Level 4 sees an increase in ages 30 to 40. \n* Surprisingly, there is a dip in the ages 40-45 in the Level 5 range. But ages 35-50 still are the most likely to earn a level 5 salary. \n* Level 6 has a very varied range of ages, perhaps due to the low number of responses in this range.\n","metadata":{"papermill":{"duration":0.029551,"end_time":"2021-11-19T05:18:28.946585","exception":false,"start_time":"2021-11-19T05:18:28.917034","status":"completed"},"tags":[]}},{"cell_type":"code","source":"Level1 = ['Level 1: $0-9,999']\ndf_l1 = df_response[df_response.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_response[df_response.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_response[df_response.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_response[df_response.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_response[df_response.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_response[df_response.Q25.isin(Level6)]\n\ndf_exp1 = df_l1['Q1'].value_counts(normalize=True).to_frame('Percent')\ndf_exp1['Percent'] = round(df_exp1['Percent'].mul(100),1)\ndf_exp1 = df_exp1.sort_index(ascending=True)\n\ndf_exp2 = df_l2['Q1'].value_counts(normalize=True).to_frame('Percent')\ndf_exp2['Percent'] = round(df_exp2['Percent'].mul(100),1)\ndf_exp2 = df_exp2.sort_index(ascending=True)\n\n\ndf_exp3 = df_l3['Q1'].value_counts(normalize=True).to_frame('Percent')\ndf_exp3['Percent'] = round(df_exp3['Percent'].mul(100),1)\ndf_exp3 = df_exp3.sort_index(ascending=True)\n\n\ndf_exp4 = df_l4['Q1'].value_counts(normalize=True).to_frame('Percent')\ndf_exp4['Percent'] = round(df_exp4['Percent'].mul(100),1)\ndf_exp4 = df_exp4.sort_index(ascending=True)\n\ndf_exp5 = df_l5['Q1'].value_counts(normalize=True).to_frame('Percent')\ndf_exp5['Percent'] = round(df_exp5['Percent'].mul(100),1)\ndf_exp5 = df_exp5.sort_index(ascending=True)\n\n\ndf_exp6 = df_l6['Q1'].value_counts(normalize=True).to_frame('Percent')\ndf_exp6['Percent'] = round(df_exp6['Percent'].mul(100),1)\ndf_exp6 = df_exp6.sort_index(ascending=True)\n\n\ndf_list = [df_exp1 ,df_exp2, df_exp3, df_exp4,df_exp5,df_exp6]\n\nfig, axes = plt.subplots(2, 3,sharey=True,constrained_layout = True)\ncolors =['#a8e6cf', '#dcedc1', '#ffd3b6', '#ffaaa5', '#ff8b94', '#66373B']\ntitles =['Percent of age - Level 1', 'Percent of age - Level 2', 'Percent of age - Level 2', 'Percent of age - Level 4', 'Percent of age - Level 5', 'Percent of age - Level 6']\n\n# plot counter\ncount=0\nfor r in range(2):\n    for c in range(3):\n        ax = df_list[count].plot.bar(color=colors[count],alpha=0.7,ax=axes[r,c],figsize=(15, 13), title =titles[count], legend=None)\n        for p in ax.patches:\n            width = p.get_width()\n            height = p.get_height()\n            x, y = p.get_xy() \n            ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\n\n        #df_list[count].plot.bar(color='royalblue', alpha=0.7,ax=axes[r,c],figsize=(18, 16))\n        count+=1\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":2.242177,"end_time":"2021-11-19T05:18:31.219961","exception":false,"start_time":"2021-11-19T05:18:28.977784","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:28:59.03036Z","iopub.execute_input":"2021-11-19T05:28:59.030682Z","iopub.status.idle":"2021-11-19T05:29:01.179115Z","shell.execute_reply.started":"2021-11-19T05:28:59.030651Z","shell.execute_reply":"2021-11-19T05:29:01.178482Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Do degrees matter?\n### How does education level affect income?\n* When we analyze the dataset, we can see that every pay scale has a combination of various degree holders. \n* But we can clearly see the percent of Master's and Doctorate degree holders increase with pay level. \n* The percent of respondents with a Bachelor's degree is highest in Level 1 and slowly reduces as the salary range increases, \n* At least 50% of Level 4 and 5 have masters and 20-30% of Level 4 and 5 respondents are doctorates. \n* In fact, 20% of Level 6 Salary are doctorates. But Level 6 once again has a very varied range of Education levels. This may be because of the number of respondents in that category or at the end of the day salary range may just come down to pure talent. :)\n","metadata":{"papermill":{"duration":0.031921,"end_time":"2021-11-19T05:18:31.284467","exception":false,"start_time":"2021-11-19T05:18:31.252546","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_temp = df_response[df_response['Q4'] != 'I prefer not to answer']\ndf_temp.loc[:,'Q4'] = pd.Categorical(df_temp.loc[:,'Q4'], ['Upto HS','College/no degree','Bachelor’s degree','Master’s degree','Doctoral degree','Professional doctorate'])\ndf_temp.sort_values(\"Q4\")\n\nLevel1 = ['Level 1: $0-9,999']\ndf_l1 = df_temp[df_temp.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_temp[df_temp.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_temp[df_temp.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_temp[df_temp.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_temp[df_temp.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_temp[df_temp.Q25.isin(Level6)]\n\ndf_exp1 = df_l1['Q4'].value_counts(normalize=True).to_frame('Percent')\ndf_exp1['Percent'] = round(df_exp1['Percent'].mul(100),1)\ndf_exp1 = df_exp1.sort_index(ascending=True)\n\ndf_exp2 = df_l2['Q4'].value_counts(normalize=True).to_frame('Percent')\ndf_exp2['Percent'] = round(df_exp2['Percent'].mul(100),1)\ndf_exp2 = df_exp2.sort_index(ascending=True)\n\n\ndf_exp3 = df_l3['Q4'].value_counts(normalize=True).to_frame('Percent')\ndf_exp3['Percent'] = round(df_exp3['Percent'].mul(100),1)\ndf_exp3 = df_exp3.sort_index(ascending=True)\n\n\ndf_exp4 = df_l4['Q4'].value_counts(normalize=True).to_frame('Percent')\ndf_exp4['Percent'] = round(df_exp4['Percent'].mul(100),1)\ndf_exp4 = df_exp4.sort_index(ascending=True)\n\ndf_exp5 = df_l5['Q4'].value_counts(normalize=True).to_frame('Percent')\ndf_exp5['Percent'] = round(df_exp5['Percent'].mul(100),1)\ndf_exp5 = df_exp5.sort_index(ascending=True)\n\n\ndf_exp6 = df_l6['Q4'].value_counts(normalize=True).to_frame('Percent')\ndf_exp6['Percent'] = round(df_exp6['Percent'].mul(100),1)\ndf_exp6 = df_exp6.sort_index(ascending=True)\n\n\ndf_list = [df_exp1 ,df_exp2, df_exp3, df_exp4,df_exp5,df_exp6]\n\nfig, axes = plt.subplots(2, 3,sharey=True,constrained_layout = True)\ncolors =['#a8e6cf', '#dcedc1', '#ffd3b6', '#ffaaa5', '#ff8b94', '#66373B']\ntitles =['Percent of education - Level 1', 'Percent of education - Level 2', 'Percent of education - Level 2', 'Percent of education - Level 4', 'Percent of education - Level 5', 'Percent of education - Level 6']\n\n# plot counter\ncount=0\nfor r in range(2):\n    for c in range(3):\n        ax = df_list[count].plot.bar(color=colors[count],alpha=0.7,ax=axes[r,c],figsize=(15, 13), title =titles[count], legend=None)\n        for p in ax.patches:\n            width = p.get_width()\n            height = p.get_height()\n            x, y = p.get_xy() \n            ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\n\n        #df_list[count].plot.bar(color='royalblue', alpha=0.7,ax=axes[r,c],figsize=(18, 16))\n        count+=1\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":2.117338,"end_time":"2021-11-19T05:18:33.433758","exception":false,"start_time":"2021-11-19T05:18:31.31642","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:01.180495Z","iopub.execute_input":"2021-11-19T05:29:01.180922Z","iopub.status.idle":"2021-11-19T05:29:03.240372Z","shell.execute_reply.started":"2021-11-19T05:29:01.18089Z","shell.execute_reply":"2021-11-19T05:29:03.239467Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Does the Job Role matter?\n#### Now that we understand the background of people, where they live, their ages, education levels. Let's analyze their jobs and see what kind of jobs earn the highest salaries. \nWe consider the top 6 job roles selected by the respondents. The top job roles are Student,Data Scientist,Software Engineer,Data Analyst,Research Scientist and Machine Learning Engineer.\n* Not all job roles are the same even though thy may sound similar and have overlapping responsibilities. Data analyst is not the same as Data scientist. \n* 20% of people earning Level 1 -level 3 salary ranges are data analysists, but only 1-5% of level 4-6 are data analysts. \n* The number of Data scientists and Software engineers increase as the Salary range increases. \n* Machine Learning Engineers and Research scientists increase in the Level 3-5 range. \n","metadata":{"papermill":{"duration":0.034273,"end_time":"2021-11-19T05:18:33.502654","exception":false,"start_time":"2021-11-19T05:18:33.468381","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\ndf_top7roles = df_response['Q5'].value_counts().sort_values(ascending = False)\ntop7 =['Student','Data Scientist','Software Engineer','Data Analyst','Research Scientist','Machine Learning Engineer']\ndf_temp = df_response[df_response.Q5.isin(top7)]\nLevel1 = ['Level 1: $0-9,999']\ndf_l1 = df_temp[df_temp.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_temp[df_temp.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_temp[df_temp.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_temp[df_temp.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_temp[df_temp.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_temp[df_temp.Q25.isin(Level6)]\n\ndf_exp1 = df_l1['Q5'].value_counts(normalize=True).to_frame('Percent')\ndf_exp1['Percent'] = round(df_exp1['Percent'].mul(100),1)\ndf_exp1 = df_exp1.sort_index(ascending=True)\n\ndf_exp2 = df_l2['Q5'].value_counts(normalize=True).to_frame('Percent')\ndf_exp2['Percent'] = round(df_exp2['Percent'].mul(100),1)\ndf_exp2 = df_exp2.sort_index(ascending=True)\n\n\ndf_exp3 = df_l3['Q5'].value_counts(normalize=True).to_frame('Percent')\ndf_exp3['Percent'] = round(df_exp3['Percent'].mul(100),1)\ndf_exp3 = df_exp3.sort_index(ascending=True)\n\n\ndf_exp4 = df_l4['Q5'].value_counts(normalize=True).to_frame('Percent')\ndf_exp4['Percent'] = round(df_exp4['Percent'].mul(100),1)\ndf_exp4 = df_exp4.sort_index(ascending=True)\n\ndf_exp5 = df_l5['Q5'].value_counts(normalize=True).to_frame('Percent')\ndf_exp5['Percent'] = round(df_exp5['Percent'].mul(100),1)\ndf_exp5 = df_exp5.sort_index(ascending=True)\n\n\ndf_exp6 = df_l6['Q5'].value_counts(normalize=True).to_frame('Percent')\ndf_exp6['Percent'] = round(df_exp6['Percent'].mul(100),1)\ndf_exp6 = df_exp6.sort_index(ascending=True)\n\n\ndf_list = [df_exp1 ,df_exp2, df_exp3, df_exp4,df_exp5,df_exp6]\n\nfig, axes = plt.subplots(2, 3,sharey=True,constrained_layout = True)\ncolors =['#a8e6cf', '#dcedc1', '#ffd3b6', '#ffaaa5', '#ff8b94', '#66373B']\ntitles =['Percent of job role - Level 1', 'Percent of job role - Level 2', 'Percent of job role - Level 2', 'Percent of job role - Level 4', 'Percent of job role - Level 5', 'Percent of job role - Level 6']\n\n# plot counter\ncount=0\nfor r in range(2):\n    for c in range(3):\n        ax = df_list[count].plot.bar(color=colors[count],alpha=0.7,ax=axes[r,c],figsize=(15, 13), title =titles[count], legend=None)\n        for p in ax.patches:\n            width = p.get_width()\n            height = p.get_height()\n            x, y = p.get_xy() \n            ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\n\n        #df_list[count].plot.bar(color='royalblue', alpha=0.7,ax=axes[r,c],figsize=(18, 16))\n        count+=1\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.527648,"end_time":"2021-11-19T05:18:35.06479","exception":false,"start_time":"2021-11-19T05:18:33.537142","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:03.242048Z","iopub.execute_input":"2021-11-19T05:29:03.242325Z","iopub.status.idle":"2021-11-19T05:29:04.734198Z","shell.execute_reply.started":"2021-11-19T05:29:03.242292Z","shell.execute_reply":"2021-11-19T05:29:04.733355Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Does Experience count?\n* We can see a clear trend of increasing salaries as the number of years of experience increases. \n* Level 1 has most people writing code for less than 1 year or 1-3 years. \n* Most of the people earning high salaries in Level 5 and 6 have been writing code for more than 10 years at least! \n* If you are just starting out in the field of data science- take heart, every year of experience you gain is valuable!","metadata":{"papermill":{"duration":0.036641,"end_time":"2021-11-19T05:18:35.138145","exception":false,"start_time":"2021-11-19T05:18:35.101504","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_temp = df_response[df_response['Q6'] != 'I have never written code']\ndf_temp.loc[:,'Q6'] = pd.Categorical(df_temp.loc[:,'Q6'], ['< 1 years', '1-3 years', '3-5 years','5-10 years', '10-20 years', '20+ years'])\ndf_temp.sort_values(\"Q6\")\nLevel1 = ['Level 1: $0-9,999']\ndf_l1 = df_temp[df_temp.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_temp[df_temp.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_temp[df_temp.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_temp[df_temp.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_temp[df_temp.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_temp[df_temp.Q25.isin(Level6)]\n\ndf_exp1 = df_l1['Q6'].value_counts(normalize=True).to_frame('Percent')\ndf_exp1['Percent'] = round(df_exp1['Percent'].mul(100),1)\ndf_exp1 = df_exp1.sort_index(ascending=True)\n\ndf_exp2 = df_l2['Q6'].value_counts(normalize=True).to_frame('Percent')\ndf_exp2['Percent'] = round(df_exp2['Percent'].mul(100),1)\ndf_exp2 = df_exp2.sort_index(ascending=True)\n\n\ndf_exp3 = df_l3['Q6'].value_counts(normalize=True).to_frame('Percent')\ndf_exp3['Percent'] = round(df_exp3['Percent'].mul(100),1)\ndf_exp3 = df_exp3.sort_index(ascending=True)\n\n\ndf_exp4 = df_l4['Q6'].value_counts(normalize=True).to_frame('Percent')\ndf_exp4['Percent'] = round(df_exp4['Percent'].mul(100),1)\ndf_exp4 = df_exp4.sort_index(ascending=True)\n\ndf_exp5 = df_l5['Q6'].value_counts(normalize=True).to_frame('Percent')\ndf_exp5['Percent'] = round(df_exp5['Percent'].mul(100),1)\ndf_exp5 = df_exp5.sort_index(ascending=True)\n\n\ndf_exp6 = df_l6['Q6'].value_counts(normalize=True).to_frame('Percent')\ndf_exp6['Percent'] = round(df_exp6['Percent'].mul(100),1)\ndf_exp6 = df_exp6.sort_index(ascending=True)\n\n\ndf_list = [df_exp1 ,df_exp2, df_exp3, df_exp4,df_exp5,df_exp6]\n\nfig, axes = plt.subplots(2, 3,sharey=True,constrained_layout = True)\ncolors =['#a8e6cf', '#dcedc1', '#ffd3b6', '#ffaaa5', '#ff8b94', '#66373B']\ntitles =['Percent of experience - Level 1', 'Percent of experience - Level 2', 'Percent of experience - Level 2', 'Percent of experience - Level 4', 'Percent of experience - Level 5', 'Percent of experience - Level 6']\n\n# plot counter\ncount=0\nfor r in range(2):\n    for c in range(3):\n        ax = df_list[count].plot.bar(color=colors[count],alpha=0.7,ax=axes[r,c],figsize=(15, 13), title =titles[count], legend=None)\n        for p in ax.patches:\n            width = p.get_width()\n            height = p.get_height()\n            x, y = p.get_xy() \n            ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\n\n        #df_list[count].plot.bar(color='royalblue', alpha=0.7,ax=axes[r,c],figsize=(18, 16))\n        count+=1\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":2.213983,"end_time":"2021-11-19T05:18:37.388556","exception":false,"start_time":"2021-11-19T05:18:35.174573","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:04.738327Z","iopub.execute_input":"2021-11-19T05:29:04.738582Z","iopub.status.idle":"2021-11-19T05:29:06.7074Z","shell.execute_reply.started":"2021-11-19T05:29:04.738552Z","shell.execute_reply":"2021-11-19T05:29:06.706575Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Do large companies pay more? \n* As expected, salaries increase with the size of the company. \n* Level 1 salary range has majority of the people working for a company with less than 250 employees.\n* Level 2 salaries have a equal distribution of all company sizes. \n* Level 3 and 4 salaries have a majority of people working for a medium sized company 1000 to 10,000 employees. \n* Level 5 and 6 are clearly dominated by companies with 10,000 or more employees","metadata":{"papermill":{"duration":0.038559,"end_time":"2021-11-19T05:18:37.465306","exception":false,"start_time":"2021-11-19T05:18:37.426747","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_temp.loc[:,'Q21'] = pd.Categorical(df_temp.loc[:,'Q21'], ['0-49 employees', '50-249 employees', '250-999 employees','1000-9,999 employees', '10,000 or more employees'])\ndf_temp.sort_values(\"Q21\")\nLevel1 = ['Level 1: $0-9,999']\ndf_l1 = df_temp[df_temp.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_temp[df_temp.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_temp[df_temp.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_temp[df_temp.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_temp[df_temp.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_temp[df_temp.Q25.isin(Level6)]\n\ndf_exp1 = df_l1['Q21'].value_counts(normalize=True).to_frame('Percent')\ndf_exp1['Percent'] = round(df_exp1['Percent'].mul(100),1)\ndf_exp1 = df_exp1.sort_index(ascending=True)\n\ndf_exp2 = df_l2['Q21'].value_counts(normalize=True).to_frame('Percent')\ndf_exp2['Percent'] = round(df_exp2['Percent'].mul(100),1)\ndf_exp2 = df_exp2.sort_index(ascending=True)\n\n\ndf_exp3 = df_l3['Q21'].value_counts(normalize=True).to_frame('Percent')\ndf_exp3['Percent'] = round(df_exp3['Percent'].mul(100),1)\ndf_exp3 = df_exp3.sort_index(ascending=True)\n\n\ndf_exp4 = df_l4['Q21'].value_counts(normalize=True).to_frame('Percent')\ndf_exp4['Percent'] = round(df_exp4['Percent'].mul(100),1)\ndf_exp4 = df_exp4.sort_index(ascending=True)\n\ndf_exp5 = df_l5['Q21'].value_counts(normalize=True).to_frame('Percent')\ndf_exp5['Percent'] = round(df_exp5['Percent'].mul(100),1)\ndf_exp5 = df_exp5.sort_index(ascending=True)\n\n\ndf_exp6 = df_l6['Q21'].value_counts(normalize=True).to_frame('Percent')\ndf_exp6['Percent'] = round(df_exp6['Percent'].mul(100),1)\ndf_exp6 = df_exp6.sort_index(ascending=True)\n\n\ndf_list = [df_exp1 ,df_exp2, df_exp3, df_exp4,df_exp5,df_exp6]\n\nfig, axes = plt.subplots(2, 3,sharey=True,constrained_layout = True)\ncolors =['#a8e6cf', '#dcedc1', '#ffd3b6', '#ffaaa5', '#ff8b94', '#66373B']\ntitles =['Percent of company size - Level 1', 'Percent of company size - Level 2', 'Percent of company size - Level 2', 'Percent of company size - Level 4', 'Percent of company size - Level 5', 'Percent of company size - Level 6']\n\n# plot counter\ncount=0\nfor r in range(2):\n    for c in range(3):\n        ax = df_list[count].plot.bar(color=colors[count],alpha=0.7,ax=axes[r,c],figsize=(15, 13), title =titles[count], legend=None)\n        for p in ax.patches:\n            width = p.get_width()\n            height = p.get_height()\n            x, y = p.get_xy() \n            ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\n\n        #df_list[count].plot.bar(color='royalblue', alpha=0.7,ax=axes[r,c],figsize=(18, 16))\n        count+=1\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.675528,"end_time":"2021-11-19T05:18:39.179334","exception":false,"start_time":"2021-11-19T05:18:37.503806","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:06.708798Z","iopub.execute_input":"2021-11-19T05:29:06.709276Z","iopub.status.idle":"2021-11-19T05:29:08.484335Z","shell.execute_reply.started":"2021-11-19T05:29:06.709229Z","shell.execute_reply":"2021-11-19T05:29:08.483254Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Does a company with more ML focus pay more?\n### If we analyze companies that incorporate machine learning methods into their businesses, we see a clear trend of companies with established ML users tend to have the highest salaries. \nIn this analysis we renamed the below categories for readability purposes. \n* We are exploring ML methods (and may one day put a model into production) : **Level 1- Exploring ML**\n* We use ML methods for generating insights (but do not put working models into production) : **Level 2 - ML insights**\n* We recently started using ML methods (i.e., models in production for less than 2 years): **Level 3 - ML recent users** \n* We have well established ML methods (i.e., models in production for more than 2 years) : **Level 4 - ML established users**\n* No (we do not use ML methods) : **No ML**\n* I do not know: **Not Aware**\n\nAs per the analysis, we can see that \n* Level 1 and 2 salary ranges have a majority of users that do not use ML or have just started exploring ML. \n* Level 3 and 4 we see the businesses with no  ML decreasing and businesses exploring or recent ML users increasing. \n* Level 5 and 6 have clear majority of established ML users.\n","metadata":{"papermill":{"duration":0.041676,"end_time":"2021-11-19T05:18:39.262723","exception":false,"start_time":"2021-11-19T05:18:39.221047","status":"completed"},"tags":[]}},{"cell_type":"code","source":"\nLevel1 = ['Level 1: $0-9,999']\ndf_l1 = df_response[df_response.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_response[df_response.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_response[df_response.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_response[df_response.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_response[df_response.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_response[df_response.Q25.isin(Level6)]\n\ndf_exp1 = df_l1['Q23'].value_counts(normalize=True).to_frame('Percent')\ndf_exp1['Percent'] = round(df_exp1['Percent'].mul(100),1)\ndf_exp1 = df_exp1.sort_index(ascending=True)\n\ndf_exp2 = df_l2['Q23'].value_counts(normalize=True).to_frame('Percent')\ndf_exp2['Percent'] = round(df_exp2['Percent'].mul(100),1)\ndf_exp2 = df_exp2.sort_index(ascending=True)\n\n\ndf_exp3 = df_l3['Q23'].value_counts(normalize=True).to_frame('Percent')\ndf_exp3['Percent'] = round(df_exp3['Percent'].mul(100),1)\ndf_exp3 = df_exp3.sort_index(ascending=True)\n\n\ndf_exp4 = df_l4['Q23'].value_counts(normalize=True).to_frame('Percent')\ndf_exp4['Percent'] = round(df_exp4['Percent'].mul(100),1)\ndf_exp4 = df_exp4.sort_index(ascending=True)\n\ndf_exp5 = df_l5['Q23'].value_counts(normalize=True).to_frame('Percent')\ndf_exp5['Percent'] = round(df_exp5['Percent'].mul(100),1)\ndf_exp5 = df_exp5.sort_index(ascending=True)\n\n\ndf_exp6 = df_l6['Q23'].value_counts(normalize=True).to_frame('Percent')\ndf_exp6['Percent'] = round(df_exp6['Percent'].mul(100),1)\ndf_exp6 = df_exp6.sort_index(ascending=True)\n\n\ndf_list = [df_exp1 ,df_exp2, df_exp3, df_exp4,df_exp5,df_exp6]\n\nfig, axes = plt.subplots(2, 3,sharey=True,constrained_layout = True)\ncolors =['#a8e6cf', '#dcedc1', '#ffd3b6', '#ffaaa5', '#ff8b94', '#66373B']\ntitles =['Percent of ML focus - Level 1', 'Percent of ML focus - Level 2', 'Percent of ML focus - Level 2', 'Percent of ML focus - Level 4', 'Percent of ML focus - Level 5', 'Percent of ML focus - Level 6']\n\n# plot counter\ncount=0\nfor r in range(2):\n    for c in range(3):\n        ax = df_list[count].plot.bar(color=colors[count],alpha=0.7,ax=axes[r,c],figsize=(15, 13), title =titles[count], legend=None)\n        for p in ax.patches:\n            width = p.get_width()\n            height = p.get_height()\n            x, y = p.get_xy() \n            ax.annotate(f'{height}%', (x + width/2, y + height*1.02), ha='center')\n\n        #df_list[count].plot.bar(color='royalblue', alpha=0.7,ax=axes[r,c],figsize=(18, 16))\n        count+=1\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.703919,"end_time":"2021-11-19T05:18:41.007903","exception":false,"start_time":"2021-11-19T05:18:39.303984","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:08.48596Z","iopub.execute_input":"2021-11-19T05:29:08.486371Z","iopub.status.idle":"2021-11-19T05:29:10.139068Z","shell.execute_reply.started":"2021-11-19T05:29:08.486339Z","shell.execute_reply":"2021-11-19T05:29:10.138241Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML Frameworks usage\n### Let us see what are the top 5 ML frameworks that people use and if their usage changes with salary levels. \n#### We see that Scikit-learn, TensorFlow, Keras, PyTorch and Xgboost are the top 5 ML frameworks used.\n","metadata":{"papermill":{"duration":0.042931,"end_time":"2021-11-19T05:18:41.094549","exception":false,"start_time":"2021-11-19T05:18:41.051618","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#finding the top 5\ndf_top5=pd.DataFrame(columns = ['Scikit-learn' ,'TensorFlow' ,'Keras' ,'PyTorch' ,'Fast.ai', 'MXNet', 'Xgboost', 'LightGBM', 'CatBoost', 'Prophet', 'H2O 3', 'Caret', 'Tidymodels', 'JAX', 'PyTorch Lightning', 'Huggingface', 'None'], index = [0])\n\ndf_top5.loc[0]['Scikit-learn'] = df_response['Q16_Part_1'].count()*100 / len(df_response)\ndf_top5.loc[0]['TensorFlow']=df_response['Q16_Part_2'].count()*100 / len(df_response)\ndf_top5.loc[0]['Keras']=df_response['Q16_Part_3'].count()*100 / len(df_response)\ndf_top5.loc[0]['PyTorch']=df_response['Q16_Part_4'].count() *100/ len(df_response)\ndf_top5.loc[0]['Fast.ai']=df_response['Q16_Part_5'].count()*100 / len(df_response)\ndf_top5.loc[0]['MXNet']=df_response['Q16_Part_6'].count()*100 / len(df_response)\ndf_top5.loc[0]['Xgboost']=df_response['Q16_Part_7'].count()*100 / len(df_response)\ndf_top5.loc[0]['LightGBM']=df_response['Q16_Part_8'].count()*100 / len(df_response)\ndf_top5.loc[0]['CatBoost']=df_response['Q16_Part_9'].count()*100 / len(df_response)\ndf_top5.loc[0]['Prophet']=df_response['Q16_Part_10'].count() *100/ len(df_response)\ndf_top5.loc[0]['H2O 3']=df_response['Q16_Part_11'].count() *100/ len(df_response)\ndf_top5.loc[0]['Caret']=df_response['Q16_Part_12'].count()*100 / len(df_response)\ndf_top5.loc[0]['Tidymodels']=df_response['Q16_Part_13'].count() *100/ len(df_response)\ndf_top5.loc[0]['JAX']=df_response['Q16_Part_14'].count() *100/ len(df_response)\ndf_top5.loc[0]['PyTorch Lightning']=df_response['Q16_Part_15'].count()*100 / len(df_response)\ndf_top5.loc[0]['Huggingface']=df_response['Q16_Part_16'].count()*100 / len(df_response)\ndf_top5.loc[0]['None']=df_response['Q16_Part_17'].count() *100/ len(df_response)\ndf_top5 = df_top5.T\ndf_top5.columns = ['maxval']\ndf_top5['maxval']=df_top5['maxval'].apply(np.floor)\ndf_top5=df_top5.sort_values(by=['maxval'],ascending= False).head(5)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.097439,"end_time":"2021-11-19T05:18:41.235009","exception":false,"start_time":"2021-11-19T05:18:41.13757","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:10.140304Z","iopub.execute_input":"2021-11-19T05:29:10.140978Z","iopub.status.idle":"2021-11-19T05:29:10.192579Z","shell.execute_reply.started":"2021-11-19T05:29:10.140943Z","shell.execute_reply":"2021-11-19T05:29:10.191965Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The ML Frameworks usage trend is almost the same for all Salary levels. \n* Scikit-learn is #1 preferred ML framework across all levels, although the percent of users decreases with the salary level. \n* TensorFlow, Keras and PyTorch usage is consistent across all salary bands \n* The use of Xgboost increases with the salary level, signifying that users with a higher salary are using more complex frameworks and algorithms.\n","metadata":{"papermill":{"duration":0.042914,"end_time":"2021-11-19T05:18:41.321731","exception":false,"start_time":"2021-11-19T05:18:41.278817","status":"completed"},"tags":[]}},{"cell_type":"code","source":"Level1 = ['Level 1: $0-9,999']\ndf_l1 = df_response[df_response.Q25.isin(Level1)]\nLevel2 = ['Level 2: $10,000-39,999']\ndf_l2 = df_response[df_response.Q25.isin(Level2)]\n\nLevel3 = ['Level 3: $40,000-79,999']\ndf_l3 = df_response[df_response.Q25.isin(Level3)]\n\nLevel4 = ['Level 4: $80,000-149,999']\ndf_l4 = df_response[df_response.Q25.isin(Level4)]\n\nLevel5 = ['Level 5: $150,000-499,999']\ndf_l5 = df_response[df_response.Q25.isin(Level5)]\n\nLevel6 = ['Level 6: > $500,000']\ndf_l6 = df_response[df_response.Q25.isin(Level6)]\n\ndf_coding=pd.DataFrame(columns = ['Scikit-learn' ,'TensorFlow' ,'Keras' ,'PyTorch' ,'Xgboost'], index = [0,1, 2, 3,4,5])\ndf_coding.loc[0]['Scikit-learn']=df_l1['Q16_Part_1'].notnull().sum()\ndf_coding.loc[0]['TensorFlow']=df_l1['Q16_Part_2'].notnull().sum()\ndf_coding.loc[0]['Keras']=df_l1['Q16_Part_3'].notnull().sum()\ndf_coding.loc[0]['PyTorch']=df_l1['Q16_Part_4'].notnull().sum()\ndf_coding.loc[0]['Xgboost']=df_l1['Q16_Part_7'].notnull().sum()\n\n\ndf_coding.loc[1]['Scikit-learn']=df_l2['Q16_Part_1'].notnull().sum()\ndf_coding.loc[1]['TensorFlow']=df_l2['Q16_Part_2'].notnull().sum()\ndf_coding.loc[1]['Keras']=df_l2['Q16_Part_3'].notnull().sum()\ndf_coding.loc[1]['PyTorch']=df_l2['Q16_Part_4'].notnull().sum()\ndf_coding.loc[1]['Xgboost']=df_l2['Q16_Part_7'].notnull().sum()\n\n\ndf_coding.loc[2]['Scikit-learn']=df_l3['Q16_Part_1'].notnull().sum()\ndf_coding.loc[2]['TensorFlow']=df_l3['Q16_Part_2'].notnull().sum()\ndf_coding.loc[2]['Keras']=df_l3['Q16_Part_3'].notnull().sum()\ndf_coding.loc[2]['PyTorch']=df_l3['Q16_Part_4'].notnull().sum()\ndf_coding.loc[2]['Xgboost']=df_l3['Q16_Part_7'].notnull().sum()\n\n\ndf_coding.loc[3]['Scikit-learn']=df_l4['Q16_Part_1'].notnull().sum()\ndf_coding.loc[3]['TensorFlow']=df_l4['Q16_Part_2'].notnull().sum()\ndf_coding.loc[3]['Keras']=df_l4['Q16_Part_3'].notnull().sum()\ndf_coding.loc[3]['PyTorch']=df_l4['Q16_Part_4'].notnull().sum()\ndf_coding.loc[3]['Xgboost']=df_l4['Q16_Part_7'].notnull().sum()\n\n\ndf_coding.loc[4]['Scikit-learn']=df_l5['Q16_Part_1'].notnull().sum()\ndf_coding.loc[4]['TensorFlow']=df_l5['Q16_Part_2'].notnull().sum()\ndf_coding.loc[4]['Keras']=df_l5['Q16_Part_3'].notnull().sum()\ndf_coding.loc[4]['PyTorch']=df_l5['Q16_Part_4'].notnull().sum()\ndf_coding.loc[4]['Xgboost']=df_l5['Q16_Part_7'].notnull().sum()\n\n\ndf_coding.loc[5]['Scikit-learn']=df_l6['Q16_Part_1'].notnull().sum()\ndf_coding.loc[5]['TensorFlow']=df_l6['Q16_Part_2'].notnull().sum()\ndf_coding.loc[5]['Keras']=df_l6['Q16_Part_3'].notnull().sum()\ndf_coding.loc[5]['PyTorch']=df_l6['Q16_Part_4'].notnull().sum()\ndf_coding.loc[5]['Xgboost']=df_l6['Q16_Part_7'].notnull().sum()\n\n\ndf_coding = round(df_coding.apply(lambda x: x*100/x.sum(), axis=1),1)\n\ndf_coding.loc[:,'Name'] = 'value'\ndf_coding.loc[0,'Name']=\"Level 1\"\ndf_coding.loc[1,'Name']=\"Level 2\"\ndf_coding.loc[2,'Name']=\"Level 3\"\ndf_coding.loc[3,'Name']=\"Level 4\"\ndf_coding.loc[4,'Name']=\"Level 5\"\ndf_coding.loc[5,'Name']=\"Level 6\"\n\n\n\n\ng = sns.catplot(kind='bar', height=3, aspect=3,data=df_coding,row='Name',palette=\"Set2\")\ng.fig.set_size_inches(15, 13)\ng.fig.subplots_adjust(top=0.9)\n\ng.fig.suptitle('Machine learning frameworks used on a regular basis')\n\n# iterate through axes\nfor ax in g.axes.ravel():\n    \n    # add annotations\n    for c in ax.containers:\n        labels = [f'{(v.get_height()):.1f}%' for v in c]\n        ax.bar_label(c, labels=labels, label_type='edge')\n    ax.margins(y=0.2)\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.495017,"end_time":"2021-11-19T05:18:42.859678","exception":false,"start_time":"2021-11-19T05:18:41.364661","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:10.193561Z","iopub.execute_input":"2021-11-19T05:29:10.194217Z","iopub.status.idle":"2021-11-19T05:29:11.582542Z","shell.execute_reply.started":"2021-11-19T05:29:10.19418Z","shell.execute_reply":"2021-11-19T05:29:11.581643Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ML algorithms usage\n### Let us see what are the top 5 ML algorithms that people use and if their usage chages with salary levels. \n#### We see that Linear or Logistic Regression, Decision Trees or Random Forests, Gradient Boosting Machines (xgboost, lightgbm, etc),Dense Neural Networks (MLPs, etc) and Convolutional Neural Networks are the top 5 ML algortithms used. ","metadata":{"papermill":{"duration":0.045032,"end_time":"2021-11-19T05:18:42.950592","exception":false,"start_time":"2021-11-19T05:18:42.90556","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#finding the top 5\ndf_top5=pd.DataFrame(columns = ['Linear or Logistic Regression', 'Decision Trees or Random Forests', 'Gradient Boosting Machines (xgboost, lightgbm, etc)', 'Bayesian Approaches', 'Evolutionary Approaches', 'Dense Neural Networks (MLPs, etc)', 'Convolutional Neural Networks', 'Generative Adversarial Networks', 'Recurrent Neural Networks', 'Transformer Networks (BERT, gpt-3, etc)', 'None'], index = [0])\n\ndf_top5.loc[0]['Linear or Logistic Regression']=df_response['Q17_Part_1'].count()*100 / len(df_response)\ndf_top5.loc[0]['Decision Trees or Random Forests']=df_response['Q17_Part_2'].count()*100 / len(df_response)\ndf_top5.loc[0]['Gradient Boosting Machines (xgboost, lightgbm, etc)']=df_response['Q17_Part_3'].count()*100 / len(df_response)\ndf_top5.loc[0]['Bayesian Approaches']=df_response['Q17_Part_4'].count()*100 / len(df_response)\ndf_top5.loc[0]['Evolutionary Approaches']=df_response['Q17_Part_5'].count()*100 / len(df_response)\ndf_top5.loc[0]['Dense Neural Networks (MLPs, etc)']=df_response['Q17_Part_6'].count()*100 / len(df_response)\ndf_top5.loc[0]['Convolutional Neural Networks']=df_response['Q17_Part_7'].count()*100 / len(df_response)\ndf_top5.loc[0]['Generative Adversarial Networks']=df_response['Q17_Part_8'].count()*100 / len(df_response)\ndf_top5.loc[0]['Recurrent Neural Networks']=df_response['Q17_Part_9'].count()*100 / len(df_response)\ndf_top5.loc[0]['Transformer Networks (BERT, gpt-3, etc)']=df_response['Q17_Part_10'].count()*100 / len(df_response)\ndf_top5.loc[0]['None']=df_response['Q17_Part_11'].count()*100 / len(df_response)\n\ndf_top5 = df_top5.T\ndf_top5.columns = ['maxval']\ndf_top5['maxval']=df_top5['maxval'].apply(np.floor)\ndf_top5=df_top5.sort_values(by=['maxval'],ascending= False).head(5)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.092732,"end_time":"2021-11-19T05:18:43.088664","exception":false,"start_time":"2021-11-19T05:18:42.995932","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:11.583927Z","iopub.execute_input":"2021-11-19T05:29:11.584359Z","iopub.status.idle":"2021-11-19T05:29:11.62245Z","shell.execute_reply.started":"2021-11-19T05:29:11.584315Z","shell.execute_reply":"2021-11-19T05:29:11.621694Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### The ML algorithms usage trend is almost the same for all Salary levels. \n* Linear or Logistic Regression is the most common  ML algorithm across all levels, although the percent of users decreases with the salary level. \n* Decision Trees and CNN usage is consistent with small variations across all salary bands. \n* More complex algorithms like the Gradient Boosting Machines, Dense Neural Networks show an increase as the salary increases.\n","metadata":{"papermill":{"duration":0.045078,"end_time":"2021-11-19T05:18:43.179691","exception":false,"start_time":"2021-11-19T05:18:43.134613","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_coding=pd.DataFrame(columns = ['Linear or Logistic Regression', 'Decision Trees or Random Forests', 'Gradient Boosting Machines', 'Dense Neural Networks', 'Convolutional Neural Networks'], index = [0,1, 2, 3,4,5])\n\n\n\ndf_coding.loc[0]['Linear or Logistic Regression']=df_l1['Q17_Part_1'].notnull().sum()\ndf_coding.loc[0]['Decision Trees or Random Forests']=df_l1['Q17_Part_2'].notnull().sum()\ndf_coding.loc[0]['Gradient Boosting Machines']=df_l1['Q17_Part_3'].notnull().sum()\ndf_coding.loc[0]['Dense Neural Networks']=df_l1['Q17_Part_6'].notnull().sum()\ndf_coding.loc[0]['Convolutional Neural Networks']=df_l1['Q17_Part_7'].notnull().sum()\n\ndf_coding.loc[1]['Linear or Logistic Regression']=df_l2['Q17_Part_1'].notnull().sum()\ndf_coding.loc[1]['Decision Trees or Random Forests']=df_l2['Q17_Part_2'].notnull().sum()\ndf_coding.loc[1]['Gradient Boosting Machines']=df_l2['Q17_Part_3'].notnull().sum()\ndf_coding.loc[1]['Dense Neural Networks']=df_l2['Q17_Part_6'].notnull().sum()\ndf_coding.loc[1]['Convolutional Neural Networks']=df_l2['Q17_Part_7'].notnull().sum()\n\ndf_coding.loc[2]['Linear or Logistic Regression']=df_l3['Q17_Part_1'].notnull().sum()\ndf_coding.loc[2]['Decision Trees or Random Forests']=df_l3['Q17_Part_2'].notnull().sum()\ndf_coding.loc[2]['Gradient Boosting Machines']=df_l3['Q17_Part_3'].notnull().sum()\ndf_coding.loc[2]['Dense Neural Networks']=df_l3['Q17_Part_6'].notnull().sum()\ndf_coding.loc[2]['Convolutional Neural Networks']=df_l3['Q17_Part_7'].notnull().sum()\n\ndf_coding.loc[3]['Linear or Logistic Regression']=df_l4['Q17_Part_1'].notnull().sum()\ndf_coding.loc[3]['Decision Trees or Random Forests']=df_l4['Q17_Part_2'].notnull().sum()\ndf_coding.loc[3]['Gradient Boosting Machines']=df_l4['Q17_Part_3'].notnull().sum()\ndf_coding.loc[3]['Dense Neural Networks']=df_l4['Q17_Part_6'].notnull().sum()\ndf_coding.loc[3]['Convolutional Neural Networks']=df_l4['Q17_Part_7'].notnull().sum()\n\ndf_coding.loc[4]['Linear or Logistic Regression']=df_l5['Q17_Part_1'].notnull().sum()\ndf_coding.loc[4]['Decision Trees or Random Forests']=df_l5['Q17_Part_2'].notnull().sum()\ndf_coding.loc[4]['Gradient Boosting Machines']=df_l5['Q17_Part_3'].notnull().sum()\ndf_coding.loc[4]['Dense Neural Networks']=df_l5['Q17_Part_6'].notnull().sum()\ndf_coding.loc[4]['Convolutional Neural Networks']=df_l5['Q17_Part_7'].notnull().sum()\n\ndf_coding.loc[5]['Linear or Logistic Regression']=df_l6['Q17_Part_1'].notnull().sum()\ndf_coding.loc[5]['Decision Trees or Random Forests']=df_l6['Q17_Part_2'].notnull().sum()\ndf_coding.loc[5]['Gradient Boosting Machines']=df_l6['Q17_Part_3'].notnull().sum()\ndf_coding.loc[5]['Dense Neural Networks']=df_l6['Q17_Part_6'].notnull().sum()\ndf_coding.loc[5]['Convolutional Neural Networks']=df_l6['Q17_Part_7'].notnull().sum()\n\ndf_coding = round(df_coding.apply(lambda x: x*100/x.sum(), axis=1),1)\n\ndf_coding.loc[:,'Name'] = 'value'\ndf_coding.loc[0,'Name']=\"Level 1\"\ndf_coding.loc[1,'Name']=\"Level 2\"\ndf_coding.loc[2,'Name']=\"Level 3\"\ndf_coding.loc[3,'Name']=\"Level 4\"\ndf_coding.loc[4,'Name']=\"Level 5\"\ndf_coding.loc[5,'Name']=\"Level 6\"\n\ng = sns.catplot(kind='bar', height=3, aspect=3,data=df_coding,row='Name',palette=\"Set2\")\ng.fig.set_size_inches(15, 13)\ng.fig.subplots_adjust(top=0.9)\n\ng.fig.suptitle('Machine learning algorithms used on a regular basis')\n\n# iterate through axes\nfor ax in g.axes.ravel():\n    \n    # add annotations\n    for c in ax.containers:\n        labels = [f'{(v.get_height()):.1f}%' for v in c]\n        ax.bar_label(c, labels=labels, label_type='edge')\n    ax.margins(y=0.2)\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.657086,"end_time":"2021-11-19T05:18:44.882153","exception":false,"start_time":"2021-11-19T05:18:43.225067","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:11.623787Z","iopub.execute_input":"2021-11-19T05:29:11.623998Z","iopub.status.idle":"2021-11-19T05:29:13.094468Z","shell.execute_reply.started":"2021-11-19T05:29:11.623972Z","shell.execute_reply":"2021-11-19T05:29:13.093644Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cloud computing platforms usage\n### Let us see what are the top cloud computing platforms that people use and if their usage changes with salary levels. \n#### We see that Amazon Web Services (AWS), Google Cloud Platform (GCP), Microsoft Azure are the top 3 cloud platforms used. In this survey 10% of the respondents do not even use cloud platforms. But based on the participants that do use cloud services, we can make the following observations.\n \n","metadata":{"papermill":{"duration":0.04628,"end_time":"2021-11-19T05:18:44.976494","exception":false,"start_time":"2021-11-19T05:18:44.930214","status":"completed"},"tags":[]}},{"cell_type":"code","source":"#finding the top 5\ndf_top5=pd.DataFrame(columns = ['Amazon Web Services (AWS)','Microsoft Azure','Google Cloud Platform (GCP)','IBM Cloud / Red Hat','Oracle Cloud','SAP Cloud','Salesforce Cloud','VMware Cloud','Alibaba Cloud','Tencent Cloud','None'], index = [0])\n\ndf_top5.loc[0]['Amazon Web Services (AWS)']=df_response['Q27_A_Part_1'].count()*100 / len(df_response)\ndf_top5.loc[0]['Microsoft Azure']=df_response['Q27_A_Part_2'].count()*100 / len(df_response)\ndf_top5.loc[0]['Google Cloud Platform (GCP)']=df_response['Q27_A_Part_3'].count()*100 / len(df_response)\ndf_top5.loc[0]['IBM Cloud / Red Hat']=df_response['Q27_A_Part_4'].count()*100 / len(df_response)\ndf_top5.loc[0]['Oracle Cloud']=df_response['Q27_A_Part_5'].count()*100 / len(df_response)\ndf_top5.loc[0]['SAP Cloud']=df_response['Q27_A_Part_6'].count()*100 / len(df_response)\ndf_top5.loc[0]['Salesforce Cloud']=df_response['Q27_A_Part_7'].count()*100 / len(df_response)\ndf_top5.loc[0]['VMware Cloud']=df_response['Q27_A_Part_8'].count()*100 / len(df_response)\ndf_top5.loc[0]['Alibaba Cloud']=df_response['Q27_A_Part_9'].count()*100 / len(df_response)\ndf_top5.loc[0]['Tencent Cloud']=df_response['Q27_A_Part_10'].count()*100 / len(df_response)\ndf_top5.loc[0]['None']=df_response['Q27_A_Part_11'].count()*100 / len(df_response)\n\n\ndf_top5 = df_top5.T\ndf_top5.columns = ['maxval']\ndf_top5['maxval']=df_top5['maxval'].apply(np.floor)\ndf_top5=df_top5.sort_values(by=['maxval'],ascending= False).head(8)\n","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.086445,"end_time":"2021-11-19T05:18:45.109887","exception":false,"start_time":"2021-11-19T05:18:45.023442","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:13.095777Z","iopub.execute_input":"2021-11-19T05:29:13.096011Z","iopub.status.idle":"2021-11-19T05:29:13.132117Z","shell.execute_reply.started":"2021-11-19T05:29:13.095981Z","shell.execute_reply":"2021-11-19T05:29:13.131235Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cloud computing platforms usage preferences changes for each salary level. \n* Google Cloud Platform (GCP) is heavily used in the Level 1 Salary range. perhaps this is because it is the most affordable but the usage decreases as Salary level increases\n* AWS use increases with rise in the salary level. \n* Azure usage is consistent with small variations across all salary bands.\n","metadata":{"papermill":{"duration":0.046984,"end_time":"2021-11-19T05:18:45.204466","exception":false,"start_time":"2021-11-19T05:18:45.157482","status":"completed"},"tags":[]}},{"cell_type":"code","source":"df_coding=pd.DataFrame(columns =['Amazon Web Services (AWS)','Microsoft Azure','Google Cloud Platform (GCP)'], index = [0,1, 2, 3,4,5])\n\n\n\ndf_coding.loc[0]['Amazon Web Services (AWS)']=df_l1['Q27_A_Part_1'].notnull().sum()\ndf_coding.loc[0]['Microsoft Azure']=df_l1['Q27_A_Part_2'].notnull().sum()\ndf_coding.loc[0]['Google Cloud Platform (GCP)']=df_l1['Q27_A_Part_3'].notnull().sum()\n\ndf_coding.loc[1]['Amazon Web Services (AWS)']=df_l2['Q27_A_Part_1'].notnull().sum()\ndf_coding.loc[1]['Microsoft Azure']=df_l2['Q27_A_Part_2'].notnull().sum()\ndf_coding.loc[1]['Google Cloud Platform (GCP)']=df_l2['Q27_A_Part_3'].notnull().sum()\n\ndf_coding.loc[2]['Amazon Web Services (AWS)']=df_l3['Q27_A_Part_1'].notnull().sum()\ndf_coding.loc[2]['Microsoft Azure']=df_l3['Q27_A_Part_2'].notnull().sum()\ndf_coding.loc[2]['Google Cloud Platform (GCP)']=df_l3['Q27_A_Part_3'].notnull().sum()\n\n\ndf_coding.loc[3]['Amazon Web Services (AWS)']=df_l4['Q27_A_Part_1'].notnull().sum()\ndf_coding.loc[3]['Microsoft Azure']=df_l4['Q27_A_Part_2'].notnull().sum()\ndf_coding.loc[3]['Google Cloud Platform (GCP)']=df_l4['Q27_A_Part_3'].notnull().sum()\n\ndf_coding.loc[4]['Amazon Web Services (AWS)']=df_l5['Q27_A_Part_1'].notnull().sum()\ndf_coding.loc[4]['Microsoft Azure']=df_l5['Q27_A_Part_2'].notnull().sum()\ndf_coding.loc[4]['Google Cloud Platform (GCP)']=df_l5['Q27_A_Part_3'].notnull().sum()\n\n\ndf_coding.loc[5]['Amazon Web Services (AWS)']=df_l6['Q27_A_Part_1'].notnull().sum()\ndf_coding.loc[5]['Microsoft Azure']=df_l6['Q27_A_Part_2'].notnull().sum()\ndf_coding.loc[5]['Google Cloud Platform (GCP)']=df_l6['Q27_A_Part_3'].notnull().sum()\n\ndf_coding = round(df_coding.apply(lambda x: x*100/x.sum(), axis=1),1)\n\ndf_coding.loc[:,'Name'] = 'value'\ndf_coding.loc[0,'Name']=\"Level 1\"\ndf_coding.loc[1,'Name']=\"Level 2\"\ndf_coding.loc[2,'Name']=\"Level 3\"\ndf_coding.loc[3,'Name']=\"Level 4\"\ndf_coding.loc[4,'Name']=\"Level 5\"\ndf_coding.loc[5,'Name']=\"Level 6\"\n\ng = sns.catplot(kind='bar', height=3, aspect=3,data=df_coding,row='Name',palette=\"Set2\")\ng.fig.set_size_inches(8, 13)\ng.fig.subplots_adjust(top=0.9)\n\ng.fig.suptitle('Cloud computing platforms usage')\n\n# iterate through axes\nfor ax in g.axes.ravel():\n    \n    # add annotations\n    for c in ax.containers:\n        labels = [f'{(v.get_height()):.1f}%' for v in c]\n        ax.bar_label(c, labels=labels, label_type='edge')\n    ax.margins(y=0.2)\n\nplt.show()","metadata":{"_kg_hide-input":true,"papermill":{"duration":1.151687,"end_time":"2021-11-19T05:18:46.402288","exception":false,"start_time":"2021-11-19T05:18:45.250601","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-19T05:29:13.134Z","iopub.execute_input":"2021-11-19T05:29:13.134268Z","iopub.status.idle":"2021-11-19T05:29:14.246328Z","shell.execute_reply.started":"2021-11-19T05:29:13.134238Z","shell.execute_reply":"2021-11-19T05:29:14.245511Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CONCLUSION\n## This analysis confirms a well known trend. Data scientists with a Master's degree, working in a large company with more than 10,000 employees and a focus on ML approaches have the highest probability of earning a salary higher than 150,000 USD.  ","metadata":{"papermill":{"duration":0.048466,"end_time":"2021-11-19T05:18:46.49923","exception":false,"start_time":"2021-11-19T05:18:46.450764","status":"completed"},"tags":[]}}]}