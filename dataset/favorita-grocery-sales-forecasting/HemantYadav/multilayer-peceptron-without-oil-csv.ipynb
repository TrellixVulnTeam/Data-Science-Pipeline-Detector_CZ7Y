{"nbformat_minor":1,"nbformat":4,"cells":[{"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\nimport matplotlib.pyplot as plt\n\n# Any results you write to the current directory are saved as output.","outputs":[],"metadata":{"_cell_guid":"bd526fb1-6242-4b43-a030-744662cf2ff3","_uuid":"ca74ddacb04cc363742b6cb2420c74d7c16a5b36"},"execution_count":null,"cell_type":"code"},{"source":"train = pd.read_csv(\"../input/train.csv\",parse_dates=[\"date\"],index_col='date')\ntrain[\"onpromotion\"].fillna(0, inplace=True)\ntrain['id'] = train['id'].astype(np.uint32)\ntrain['store_nbr'] = train['store_nbr'].astype(np.uint8)\ntrain['item_nbr'] = train['item_nbr'].astype(np.uint32)\ntrain['unit_sales'] = train['unit_sales'].astype(np.uint32)\ntrain[\"onpromotion\"]=train[\"onpromotion\"].astype(np.int8)","outputs":[],"metadata":{"_cell_guid":"8ea5dc53-b0ee-4ad1-a6d4-34e432e408d4","_uuid":"b6a965848c098405616129605bba94d3bf74cd36"},"execution_count":null,"cell_type":"code"},{"source":"test = pd.read_csv(\"../input/test.csv\",parse_dates=[\"date\"],index_col='date')\ntest[\"onpromotion\"].fillna(0, inplace=True)\ntest['id'] = test['id'].astype(np.uint32)\ntest['store_nbr'] = test['store_nbr'].astype(np.uint8)\ntest['item_nbr'] = test['item_nbr'].astype(np.uint32)\ntest[\"onpromotion\"]=test[\"onpromotion\"].astype(np.int8)","outputs":[],"metadata":{"_cell_guid":"94574838-1850-46b1-bb43-f177dc015e17","collapsed":true,"_uuid":"03f89b40096abd645132c50f634737a9cbd3319f"},"execution_count":null,"cell_type":"code"},{"source":"items = pd.read_csv('../input/items.csv')\ntransaction = pd.read_csv('../input/transactions.csv')\nstores = pd.read_csv('../input/stores.csv')","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"print(\"Total Obsevations before sampling\",len(train))\nstrain = train.sample(frac=0.01,replace=True)\n#print(\"Total Obsevations after sampling\",len(test))\nprint(\"Total Obsevations after sampling\",len(strain))","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"df = strain.merge(right = items, on='item_nbr', right_index  = True)\ndf = df.merge(right=stores,on='store_nbr', right_index  = True)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"dft = test.merge(right = items, on='item_nbr', right_index  = True)\ndft = dft.merge(right=stores,on='store_nbr', right_index  = True)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from sklearn.model_selection import GridSearchCV\ndf.drop(['city','state','id'], axis=1,inplace=True)\ndft.drop(['city','state','id'], axis=1,inplace=True)\nohe_df = pd.get_dummies(df, columns=['onpromotion','family','type'])    \nohe_dft = pd.get_dummies(dft, columns=['onpromotion','family','type'])  ","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"from sklearn.model_selection   import train_test_split\n\nunitSales = ohe_df['unit_sales']\nfeatures = ohe_df.drop('unit_sales', axis = 1)\n\nX_train, X_test, y_train, y_test = train_test_split(features, unitSales, test_size=0.2, random_state=42)\nprint(X_test.shape[0], X_train.shape[0],ohe_df.shape[0])","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"import time\nfrom sklearn.neural_network import MLPRegressor\n\nstime=time.time()\nmlpc = MLPRegressor(hidden_layer_sizes=(100, 300, 100), activation='relu', \n                         solver='adam', alpha=0.005, learning_rate_init = 0.001, shuffle=False)\n\nmlpc.fit(X_train, y_train)\netime=time.time()","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"print(etime-stime)\nprediction = mlpc.predict(X_test)\n","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"prediction = pd.DataFrame(prediction, index=X_test.index,columns=['PedictedSale'])\nsub =  pd.concat([prediction, y_test.to_frame()], axis=1)\nsub =  pd.concat([sub, X_test['perishable'].to_frame()], axis=1)","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"sub['newPS'] = sub.apply(lambda row: 0 if(row['PedictedSale']<0) else row['PedictedSale'] , axis=1)\nsub['newUS'] = sub.apply(lambda row: 0 if(row['unit_sales']<0) else row['unit_sales'] , axis=1)","outputs":[],"metadata":{"collapsed":true},"execution_count":null,"cell_type":"code"},{"source":"sub['newPS'] = np.log(sub.newPS + 1 )\nsub['newUS'] = np.log(sub.newPS + 1 )\nsub['yhatminusy'] = (sub['newPS']-sub['newUS'])**2\nsub['perishable'] = sub.perishable>0\nsub['perishableW'] = sub.apply(lambda row: 1.5 if(row['perishable']) else 1, axis=1)\nsub['comp1'] = sub.yhatminusy*sub.perishableW\n\nsub.head()","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"ax = sub['PedictedSale'].resample('m').mean().plot(figsize = (15, 6), color='red')\nfig = sub['unit_sales'].resample('m').mean().plot(ax=ax).get_figure()\nplt.legend(['Predicted Sale', 'actual'], loc='upper right')\nplt.show()","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"(sub.comp1.sum()/sub.perishableW.sum())**0.5","outputs":[],"metadata":{},"execution_count":null,"cell_type":"code"},{"source":"Following are results **without considering** 'city','state','id' while training model\n\n**Test Dataset** | **Train Dataset Size**  | **NWRMSLE **\n\nX_test  | 0.0001 | 0.68249025011606335\n\nX_test  | 0.001  | 1.094370399919558\n\nX_test  | 0.01    | 1.1043093902342433 \n\n____________________________________________\n\nFollowing are results **with considering** 'city','state','id' while training model\n\n**Test Dataset** | **Train Dataset Size**  | **NWRMSLE **\n\nX_test  | 0.0001 | 1.0789754618301821\n\nX_test  | 0.001  | 1.0688842227424471\n\nX_test  | 0.01    | 1.1023627733144485 \n\n\n\ntest  | 0.001 | \n\nX_test  | 0.01 | 1.094370399919558\n\n","metadata":{},"cell_type":"markdown"}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"name":"python","mimetype":"text/x-python","pygments_lexer":"ipython3","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3"}}}