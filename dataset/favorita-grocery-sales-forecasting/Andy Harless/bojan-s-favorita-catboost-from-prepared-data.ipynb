{"metadata":{"language_info":{"nbconvert_exporter":"python","mimetype":"text/x-python","name":"python","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.3","file_extension":".py"},"kernelspec":{"language":"python","name":"python3","display_name":"Python 3"}},"nbformat":4,"cells":[{"metadata":{"_cell_guid":"2bd7824d-4501-4724-8b2e-0c2844460353","_uuid":"146117f38cde91077f74723fc3d11babc5bc69b8"},"source":"\nData were prepared by [this script](https://www.kaggle.com/aharless/preparing-data-for-lgbm-or-something-else/output) (originally designed for LightGBM, hence the title, but it turns out to work just as well for other methods).\n\nThis notebook implements [Bojan's Catboost kernel](https://www.kaggle.com/tunguz/catboost-starter-lb-0-518) using the previously prepared data.  This goes into a little bit more detail about validation results.   (Since this is a notebook, the output is also easier to read than for the original script, because you can start a new code block after it runs out of log space.)  The results are slightly different, maybe because of lost precision (since I only use 6 decimal places in the prepared data) or maybe just because gradient boosting algorithms can be ticklish.\n\nThe data arrangement comes originally from  [Lingzhi's upgraded version](https://www.kaggle.com/vrtjso/lgbm-one-step-ahead) of Ceshine's [LGBM starter](https://www.kaggle.com/ceshine/lgbm-starter) script.","cell_type":"markdown"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"acc4a2ab-8249-48b9-9208-0318827e0e31","collapsed":true,"_uuid":"9fbf4db969b3035cde640c651aa4031b8d8440c3"},"source":"MAX_PRED = 1000\nMAX_ROUNDS = 330","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"1e632d4a-2fe8-4a4e-bc96-5b7c985ad3a5","collapsed":true,"_uuid":"8ec47e6264e7a62a2f555101331b5ef20545bb95"},"source":"from datetime import date, timedelta\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"6ddda393-3bf0-4427-8090-4afd29fed0ae","collapsed":true,"_uuid":"d87c09bff2d91506fb431c64864c2ca85a1d345c"},"source":"indir = '../input/preparing-data-for-lgbm-or-something-else/'\nindir2 = '../input/favorita-grocery-sales-forecasting/'","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"e0a3cdab-1e83-4eac-8a65-9087b1c7bcf1","collapsed":true,"_uuid":"12b8b208eea67cc7d63b812f7f74ea859c970cb2"},"source":"X_test = pd.read_csv(indir + 'X_test.csv')\nX_val = pd.read_csv(indir + 'X_val.csv')\nX_train = pd.read_csv(indir + 'X_train.csv')\ny_train = np.array(pd.read_csv(indir + 'y_train.csv'))\ny_val = np.array(pd.read_csv(indir + 'y_val.csv'))\nstores_items = pd.read_csv(indir + 'stores_items.csv', index_col=['store_nbr','item_nbr'])\ntest_ids = pd.read_csv( indir + 'test_ids.csv',  parse_dates=['date']).set_index(\n                        ['store_nbr', 'item_nbr', 'date'] )","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"18fc56fb-2cd4-4a8f-b674-ac69a9be785b","collapsed":true,"_uuid":"eab98ff74166b8c95d051affc17ff0add8ed5c21"},"source":"items = pd.read_csv( indir2 + 'items.csv' ).set_index(\"item_nbr\")\nitems = items.reindex( stores_items.index.get_level_values(1) )","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"d8d0fedb-c005-4c84-821d-38594af832cf","collapsed":true,"_uuid":"c94a579ef3229e57fe8d01fd066e0ae29f0c1bea"},"source":"val_pred = []\ntest_pred = []\ncate_vars = []\nfor i in range(16):\n    print(\"=\" * 50)\n    print(\"Step %d\" % (i+1))\n    print(\"=\" * 50)\n    model = CatBoostRegressor(\n        iterations=MAX_ROUNDS, learning_rate=0.4,\n        depth=4  )\n        \n    model.fit(\n        X_train, y_train[:, i],\n        cat_features=cate_vars,\n        logging_level='Silent'\n             )\n    \n    val_pred.append(model.predict(X_val))\n    test_pred.append(model.predict(X_test))","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"f36e22b1-cfff-42be-814e-73aaec710506","collapsed":true,"_uuid":"09220ec904335735d5d135c7e08ccc9b6bfce664"},"source":"n_public = 5 # Number of days in public test set\nweights=pd.concat([items[\"perishable\"]]) * 0.25 + 1\nprint(\"Unweighted validation mse: \", mean_squared_error(\n    y_val, np.minimum( np.array(val_pred).transpose(), np.log1p(MAX_PRED) ) )   )\nmse = mean_squared_error(\n    y_val, np.minimum( np.array(val_pred).transpose(), np.log1p(MAX_PRED) ), \n    sample_weight=weights)\nprint(\"Full validation mse:       \", mse )\nmsepub = mean_squared_error(\n    y_val[:,:n_public], \n    np.minimum( np.array(val_pred).transpose()[:,:n_public], np.log1p(MAX_PRED) ),\n    sample_weight=weights)\nprint(\"'Public' validation mse:   \",  msepub )\nmsepriv = mean_squared_error(\n    y_val[:,n_public:], \n    np.minimum( np.array(val_pred).transpose()[:,n_public:], np.log1p(MAX_PRED) ),\n    sample_weight=weights)\nprint(\"'Private' validation mse:  \",  msepriv )\nprint('Validation NRMSWLE')\nprint( \"  Full:    \", np.sqrt(mse) )\nprint( \"  Public:  \", np.sqrt(msepub) )\nprint( \"  Private: \", np.sqrt(msepriv) )","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"6725af78-42d4-4979-96ac-72250fa682cb","collapsed":true,"_uuid":"0e02cd63f6efb3e889fb9e3ba6e2bad3be40c2da"},"source":"y_test = np.array(test_pred).transpose()\ndf_preds = pd.DataFrame(\n    y_test, index=stores_items.index,\n    columns=pd.date_range(\"2017-08-16\", periods=16)\n).stack().to_frame(\"unit_sales\")\ndf_preds.index.set_names([\"store_nbr\", \"item_nbr\", \"date\"], inplace=True)","cell_type":"code"},{"execution_count":null,"outputs":[],"metadata":{"_cell_guid":"3c7be7e9-df8c-404e-b0f3-e6f0fd7e0719","collapsed":true,"_uuid":"c4f4dadcd3b7588bb8bb62256ca10d1297efb793"},"source":"submission = test_ids.join(df_preds, how=\"left\").fillna(0)\nsubmission[\"unit_sales\"] = np.clip(np.expm1(submission[\"unit_sales\"]), 0, MAX_PRED)\nsubmission.to_csv('cat_whatever.csv', float_format='%.4f', index=None)","cell_type":"code"}],"nbformat_minor":1}