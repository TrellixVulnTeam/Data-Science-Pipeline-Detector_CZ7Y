{"nbformat":4,"cells":[{"outputs":[],"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"_uuid":"c6c2b20aee7eb5fcc40f065a8aaf490530cb3388","_cell_guid":"1520ddda-0051-4873-b65c-657614ecb27b"},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom math import sqrt\nfrom sklearn.metrics import mean_squared_error\nfrom matplotlib import pyplot\n\n# transform series into train and test sets for supervised learning\ndef series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = pd.DataFrame(data)\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    for i in range(0, n_out):\n        cols.append(df.shift(-i))\n        if i == 0:\n            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n        else:\n            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n    return agg\n    \n\ndef prepare_data(series, n_test, n_lag, n_seq):\n    # extract raw values\n    raw_values = series.values\n    raw_values = raw_values.reshape(len(raw_values), 1)\n    # transform into supervised learning problem X, y\n    supervised = series_to_supervised(raw_values, n_lag, n_seq)\n    supervised_values = supervised.values\n    # split into train and test sets\n    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n    return train, test\n\n\n# make a persistence forecast\ndef persistence(last_ob, n_seq):\n    return [last_ob for i in range(n_seq)]\n\n\n# evaluate the persistence model\ndef make_forecasts(test, n_lag, n_seq):\n    \"\"\"\n    Takes the last observation and the number of forecast steps to persist and takes the train, test, and \n    configuration for the dataset as arguments and returns a list of forecasts.\n    \"\"\"    \n    forecasts = []\n    for i in range(len(test)):\n        X, y = test[i, 0:n_lag], test[i, n_lag:]\n        # make forecast\n        forecast = persistence(X[-1], n_seq)\n        # store the forecast\n        forecasts.append(forecast)\n    return forecasts\n\n\n# evaluate the RMSE for each forecast time step\ndef evaluate_forecasts(test, forecasts, n_lag, n_seq):\n    for i in range(n_seq):\n        actual = test[:, (n_lag+i)]\n        predicted = [forecast[i] for forecast in forecasts]\n        rmse = sqrt(mean_squared_error(actual, predicted))\n        print('t+%d RMSE: %f' % ((i+1), rmse))\n\n\n# plot the forecasts in the context of the original dataset\ndef plot_forecasts(series, forecasts, n_test):\n    # plot the entire dataset in blue\n    pyplot.plot(series.values)\n    # plot the forecasts in red\n    for i in range(len(forecasts)):\n        off_s = len(series) - n_test + i - 1\n        off_e = off_s + len(forecasts[i]) + 1\n        xaxis = [x for x in range(off_s, off_e)]\n        yaxis = [series.values[off_s]] + forecasts[i]\n        pyplot.plot(xaxis, yaxis, color='red')\n    # show the plot\n    pyplot.show()\n\n# Any results you write to the current directory are saved as output.\ndtypes = {'store_nbr': np.dtype('int64'),\n          'item_nbr': np.dtype('int64'),\n          'unit_sales': np.dtype('float64'),\n          'onpromotion': np.dtype('O')}\n\ndf = pd.read_csv('../input/train.csv', index_col='id', parse_dates=['date'], dtype=dtypes)\n# If done on all train data, results in 367m rows. So, we're taking a small sample:\nitem_mask = (df['item_nbr'] == 103665) & (df['store_nbr'] == 9)\nprint(df.shape)\ndf = df[item_mask]\nprint(df.shape)\n\nfrom IPython.display import display, HTML\ndisplay(HTML('<h1>Persistence Forecast</h1>'))\ndisplay(HTML('Simple item-store combination for univariate persistence forecast. This could be used as a baseline level of performance when comparing with more sophisticated models'))\n\n\"\"\"\nCode adapted from https://machinelearningmastery.com/ examples.\n\"\"\"\nsample = pd.concat([df['unit_sales']], axis=1)\n# configure\nn_lag = 1\nn_seq = 17\nn_test = 16\ntrain, test = prepare_data(sample, n_test, n_lag, n_seq)\nprint('Train: %s, Test: %s' % (train.shape, test.shape))\nforecasts = make_forecasts(test, n_lag, n_seq)\nevaluate_forecasts(test, forecasts, n_lag, n_seq)\n# plot forecasts\nplot_forecasts(sample, forecasts, n_test+2)","execution_count":1}],"nbformat_minor":1,"metadata":{"language_info":{"pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","name":"python","version":"3.6.3"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}}}