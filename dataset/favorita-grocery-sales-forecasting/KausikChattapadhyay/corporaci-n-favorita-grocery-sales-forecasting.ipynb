{"nbformat":4,"nbformat_minor":1,"cells":[{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport gc"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#importing all input data to Dataframe"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_holevents = pd.read_csv('input_data/holidays_events.csv')\ndf_items     = pd.read_csv('input_data/items.csv')\ndf_oil       = pd.read_csv('input_data/oil.csv')\ndf_stores    = pd.read_csv('input_data/stores.csv')\ndf_test      = pd.read_csv('input_data/test.csv')\ndf_train     = pd.read_csv('input_data/train.csv')\ndf_trans     = pd.read_csv('input_data/transactions.csv')"},{"cell_type":"markdown","metadata":{},"source":"# Exploring data"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"print(df_train.shape)\ndf_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"print(df_test.shape)\ndf_test.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"print(df_stores.shape)\ndf_stores.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"print(df_items.shape)\ndf_items.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"print(df_oil.shape)\ndf_oil.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"print(df_trans.shape)\ndf_trans.head()"},{"cell_type":"markdown","metadata":{},"source":"# Train Data"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.info()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#Now, let's get a sense of the time range for which the data was collected."},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# convert date to datetime\ndf_train[\"date\"] =  pd.to_datetime(df_train[\"date\"])"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train[\"date\"].dt.year.value_counts(sort = False).plot.bar()\nplt.xlabel('Year')\nplt.ylabel(\"Collected Data\")\n"},{"cell_type":"markdown","metadata":{"collapsed":true},"source":"They have collected data from 2013 to 2017. There is an increase in the number of observations for each year except 2017 but this is probably because it is not yet over. Note that the training set is quite large."},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train_2016 = df_train[df_train[\"date\"].dt.year == 2016]"},{"cell_type":"markdown","metadata":{"collapsed":true},"source":"Let's take a look at how the data is distributed by month."},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train_2016[\"date\"].dt.month.value_counts(sort = False).plot.bar()"},{"cell_type":"markdown","metadata":{"collapsed":true},"source":"The observations are almost uniformly distributed by month. The maximum occurs in December and the minimum in February. How about by day of the month?"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train_2016[\"date\"].dt.day.value_counts(sort = False).plot.bar()"},{"cell_type":"markdown","metadata":{},"source":"Again, the observations are almost uniformly distributed by day."},{"cell_type":"markdown","metadata":{},"source":"# Stores"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# How many stores?"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_stores.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_stores['store_nbr'].unique()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_stores['state'].unique()"},{"cell_type":"markdown","metadata":{},"source":"# Items"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train_2016[\"item_nbr\"].unique().shape[0]"},{"cell_type":"markdown","metadata":{},"source":"There were 3886 different types of items either sold or returned during 2016."},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"stores = np.arange(1, 55)\nitems_store = np.zeros((54, ))\nfor i, store in enumerate(stores) :\n    items_store[i] = df_train_2016[\"item_nbr\"][df_train_2016[\"store_nbr\"] \\\n                                               == store].unique().shape[0]\nsns.barplot(stores, items_store)"},{"cell_type":"markdown","metadata":{},"source":"As expected, this is very similar to the last bar plot because it measures the variety of items in each store. Interestingly, store 52 has 0 unique items. This is because there is no store number 52."},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"#Item sales is our target variable\ndf_train_2016[\"unit_sales\"].describe()"},{"cell_type":"markdown","metadata":{"collapsed":true},"source":"It is probably a good thing that the mean and median for unit sales is positive, otherwise the company would be losing money. Suprisingly, on one day, 4673 items were returned. I wonder if this corresponds to some sort of outbreak or health concern for a particular product. On the other hand, on another day, 89440 items were purchased. Perhaps this was before some sort of natural disaster (e.g. a hurricane)."},{"cell_type":"markdown","metadata":{},"source":"Now, let's find out how many items were purchased by coupon clippers."},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train_2016[\"onpromotion\"].value_counts()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"3514584/31715287 * 100"},{"cell_type":"markdown","metadata":{"collapsed":true},"source":"About 11% of items are purchased on promotion."},{"cell_type":"markdown","metadata":{},"source":"Missing data and Outliers"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train_2016.isnull().sum()"},{"cell_type":"markdown","metadata":{},"source":"Yay! There is no missing data in the training set. How about outliers in the target variable?"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"unit_sales = df_train_2016[\"unit_sales\"].values\ngc.collect()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"plt.scatter(x = range(unit_sales.shape[0]), y = np.sort(unit_sales))"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train = df_train.set_index('date')"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train = df_train[['unit_sales']]"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train = df_train.to_period(freq='M')\ndf_train.head()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train = df_train.groupby(['date']).sum()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"#Plotting the time Series for the training dataset\ndf_train.plot()"},{"cell_type":"markdown","metadata":{},"source":"Problem description:\n    In this competition, we will be predicting the unit sales for thousands of items sold at different Favorita stores located in Ecuador. The training data includes dates, store and item information, whether that item was being promoted, as well as the unit sales. Additional files include supplementary information that may be useful in building your models."},{"cell_type":"markdown","metadata":{},"source":"The dataset provides the number of monthly sales of items from January 2013 to August 2017.\n\nThe values are a count of millions of sales and there are 56 monthly observations."},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind = \"hist\", bins = 30)"},{"cell_type":"markdown","metadata":{},"source":"Transformation - Log\nTransformations such as logarithms can help to stabilize the variance of a time series."},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train['sales_unit_Log'] = np.log(df_train.unit_sales)\ndf_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train['sales_unit_Log'].plot(kind = \"hist\", bins = 30)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train['sales_unit_Log'].plot()"},{"cell_type":"markdown","metadata":{},"source":"Basic Time Series Model\nWe will build a time-series forecasting model to get a forecast for Onion prices. Let us start with the three most basic models -\nMean Constant Model\nLinear Trend Model\nRandom Walk Model"},{"cell_type":"markdown","metadata":{},"source":"Mean Model\nThis very simple forecasting model will be called the \"mean model\""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"model_mean_pred = df_train.sales_unit_Log.mean()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Let us store this as our Mean Predication Value\ndf_train[\"salesMean\"] = np.exp(model_mean_pred)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind=\"line\", y = [\"unit_sales\", \"salesMean\"])"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"def RMSE(predicted, actual):\n    mse = (predicted - actual)**2\n    rmse = np.sqrt(mse.sum()/mse.count())\n    return rmse"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"model_mean_RMSE = RMSE(df_train.salesMean, df_train.unit_sales)\nmodel_mean_RMSE"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Save this in a dataframe\ndfBangResults = pd.DataFrame(columns = [\"Model\", \"Forecast\", \"RMSE\"])\ndfBangResults.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"dfBangResults.loc[0,\"Model\"] = \"Mean\"\ndfBangResults.loc[0,\"Forecast\"] = np.exp(model_mean_pred)\ndfBangResults.loc[0,\"RMSE\"] = model_mean_RMSE\ndfBangResults.head()"},{"cell_type":"markdown","metadata":{},"source":"\nLinear Trend Model\nLet us start by plotting a linear trend model between priceModLog and time.\nHowever to do linear regression, we need a numeric indicator for time period - Let us create that."},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train['date'] = df_train.index.to_timestamp()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Convert date in datetimedelta figure starting from zero\ndf_train[\"timeIndex\"] = df_train.date - df_train.date.min()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.dtypes"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Convert to months using the timedelta function\ndf_train[\"timeIndex\"] =  df_train[\"timeIndex\"]/np.timedelta64(1, 'M')"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.timeIndex.head()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Round the number to 0\ndf_train[\"timeIndex\"] = df_train[\"timeIndex\"].round(0).astype(int)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.tail()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"## Now plot linear regression\n# Import statsmodel\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\nfrom statsmodels.tsa.stattools import adfuller\n\nmodel_linear = smf.ols('sales_unit_Log ~ timeIndex', data = df_train).fit()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"model_linear.summary()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"## Parameters for y = mx + c equation\nmodel_linear.params"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"c = model_linear.params[0]\nc"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"m = model_linear.params[1]\nm"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"model_linear_pred = model_linear.predict()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"model_linear_pred"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Plot the prediction line\ndf_train.plot(kind=\"line\", x=\"timeIndex\", y = \"sales_unit_Log\")\nplt.plot(df_train.timeIndex,model_linear_pred, '-')"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"model_linear.resid.plot(kind = \"bar\")"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train[\"salesLinear\"] = np.exp(model_linear_pred)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Root Mean Squared Error (RMSE)\nmodel_linear_RMSE = RMSE(df_train.salesLinear, df_train.unit_sales)\nmodel_linear_RMSE"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Manual Calculation\nmodel_linear_forecast_manual = m * 146 + c\nmodel_linear_forecast_manual"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"dfBangResults.loc[1,\"Model\"] = \"Linear\"\ndfBangResults.loc[1,\"Forecast\"] = np.exp(model_linear_forecast_manual)\ndfBangResults.loc[1,\"RMSE\"] = model_linear_RMSE\ndfBangResults.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind=\"line\", x=\"timeIndex\", y = [\"unit_sales\", \"salesMean\", \"salesLinear\"])"},{"cell_type":"markdown","metadata":{},"source":"Random Walk Model\nWhen faced with a time series that shows irregular growth, the best strategy may not be to try to directly predict the level of the series at each period (i.e., the quantity Yt). Instead, it may be better to try to predict the change that occurs from one period to the next (i.e., the quantity Yt - Yt-1). That is, it may be better to look at the first difference of the series, to see if a predictable pattern can be found there. For purposes of one-period-ahead forecasting, it is just as good to predict the next change as to predict the next level of the series, since the predicted change can be added to the current level to yield a predicted level. The simplest case of such a model is one that always predicts that the next change will be zero, as if the series is equally likely to go up or down in the next period regardless of what it has done in the past.\nRandom Walk Model $$ \\hat{Y_t} = Y_{t-1} + \\epsilon \\\\$$\nRandom Walk Model with drift $$ \\hat{Y_t} = Y_{t-1} + c + \\epsilon \\\\$$"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train[\"priceModLogShift1\"] = df_train.sales_unit_Log.shift()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind= \"scatter\", y = \"sales_unit_Log\", x = \"priceModLogShift1\", s = 50)"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Lets plot the one-month difference curve\ndf_train[\"priceModLogDiff\"] = df_train.sales_unit_Log - df_train.priceModLogShift1"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.priceModLogDiff.plot()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train[\"priceRandom\"] = np.exp(df_train.priceModLogShift1)\ndf_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind=\"line\", x=\"timeIndex\", y = [\"unit_sales\",\"priceRandom\"])"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Root Mean Squared Error (RMSE)\nmodel_random_RMSE = RMSE(df_train.priceRandom, df_train.unit_sales)\nmodel_random_RMSE"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"dfBangResults.loc[2,\"Model\"] = \"Random\"\ndfBangResults.loc[2,\"Forecast\"] = np.exp(df_train.priceModLogShift1[-1])\ndfBangResults.loc[2,\"RMSE\"] = model_random_RMSE\ndfBangResults.head()"},{"cell_type":"markdown","metadata":{},"source":"Advanced Model\nMost of the time series models work on the assumption that the time series is stationary. Intuitively, we can see that if a time series has a particular behaviour over time, there is a very high probability that it will follow the same in the future. Also, the theories related to stationary series are more mature and easier to implement as compared to non-stationary series\nStatistical stationarity: A stationary time series is one whose statistical properties such as mean, variance, autocorrelation, etc. are all constant over time. Most statistical forecasting methods are based on the assumption that the time series can be rendered approximately stationary (i.e., \"stationarized\") through the use of mathematical transformations. A stationarized series is relatively easy to predict: you simply predict that its statistical properties will be the same in the future as they have been in the past!\nThere are three basic criterion for a series to be classified as stationary series :\nThe mean of the series should not be a function of time rather should be a constant.\nThe variance of the series should not a be a function of time. This property is known as homoscedasticity.\nThe covariance of the i th term and the (i + m) th term should not be a function of time."},{"cell_type":"markdown","metadata":{},"source":"How do we check for Stationarity in a series?\nPlotting Rolling Statistics: We can plot the moving average or moving variance and see if it varies with time. By moving average/variance I mean that at any instant ‘t’, we’ll take the average/variance of the last year, i.e. last 12 months. But again this is more of a visual technique.\nDickey-Fuller Test: This is one of the statistical tests for checking stationarity. Here the null hypothesis is that the time series is non-stationary. The test results comprise of a Test Statistic and some Critical Values for difference confidence levels. If the ‘Test Statistic’ is less than the ‘Critical Value’, we can reject the null hypothesis and say that the series is stationary."},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"def adf(ts):\n    \n    # Determing rolling statistics\n    rolmean = pd.rolling_mean(ts, window=12)\n    rolstd = pd.rolling_std(ts, window=12)\n\n    #Plot rolling statistics:\n    orig = plt.plot(ts, color='blue',label='Original')\n    mean = plt.plot(rolmean, color='red', label='Rolling Mean')\n    std = plt.plot(rolstd, color='black', label = 'Rolling Std')\n    plt.legend(loc='best')\n    plt.title('Rolling Mean & Standard Deviation')\n    plt.show(block=False)\n    \n    # Calculate ADF factors\n    adftest = adfuller(ts, autolag='AIC')\n    adfoutput = pd.Series(adftest[0:4], index=['Test Statistic','p-value','# of Lags Used',\n                                              'Number of Observations Used'])\n    for key,value in adftest[4].items():\n        adfoutput['Critical Value (%s)'%key] = value\n    return adfoutput"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# For smoothing the values we can use 12 month Moving Averages \ndf_train['priceModLogMA12'] = pd.rolling_mean(df_train.sales_unit_Log, window = 12)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind =\"line\", y=[\"priceModLogMA12\", \"sales_unit_Log\"])"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train[\"priceMA12\"] = np.exp(df_train.priceModLogMA12)\ndf_train.tail()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"model_MA12_forecast = df_train.sales_unit_Log.tail(12).mean()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Root Mean Squared Error (RMSE)\nmodel_MA12_RMSE = RMSE(df_train.priceMA12, df_train.unit_sales)\nmodel_MA12_RMSE"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"dfBangResults.loc[3,\"Model\"] = \"Moving Average 12\"\ndfBangResults.loc[3,\"Forecast\"] = np.exp(model_MA12_forecast)\ndfBangResults.loc[3,\"RMSE\"] = model_MA12_RMSE\ndfBangResults.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind=\"line\", x=\"timeIndex\", y = [\"unit_sales\", \"salesMean\", \"salesLinear\",\n                                             \"priceRandom\", \"priceMA12\"])"},{"cell_type":"markdown","metadata":{},"source":"\nEliminating Trend and Seasonality\nDifferencing – taking the differece with a particular time lag\nDecomposition – modeling both trend and seasonality and removing them from the model.\nDifferencing\nOne of the most common methods of dealing with both trend and seasonality is differencing. In this technique, we take the difference of the observation at a particular instant with that at the previous instant. This mostly works well in improving stationarity. We have already done first order difference earlier"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.priceModLogDiff.plot()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Test remaining part for Stationary\nts = df_train.priceModLogDiff\nts.dropna(inplace = True)\nadfuller(ts)"},{"cell_type":"markdown","metadata":{},"source":"\nTime Series Decomposition\nWe can also decompose the time series into trend and seasonality"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"from statsmodels.tsa.seasonal import seasonal_decompose\ndf_train.index = df_train.index.to_datetime()\ndf_train.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"decomposition = seasonal_decompose(df_train.sales_unit_Log, model = \"additive\")\ndecomposition.plot()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"trend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train[\"priceDecomp\"] = np.exp(trend + seasonal)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Root Mean Squared Error (RMSE)\nmodel_Decomp_RMSE = RMSE(df_train.priceDecomp, df_train.unit_sales)\nmodel_Decomp_RMSE"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind=\"line\", x=\"timeIndex\", y = [\"unit_sales\", \"salesMean\", \"salesLinear\", \"priceRandom\",\n                                             \"priceMA12\",  \"priceDecomp\"])"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind=\"line\", x=\"timeIndex\", y = [\"unit_sales\",\n                                              \"priceDecomp\"])"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Test remaining part for Stationary\nts = decomposition.resid\nts.dropna(inplace = True)\nadfuller(ts)"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"ts = df_train.sales_unit_Log\nts_diff = df_train.priceModLogDiff\nts_diff.dropna(inplace = True)"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"#ACF and PACF plots:\nfrom statsmodels.tsa.stattools import acf, pacf"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"lag_acf = acf(ts_diff, nlags=20)\nlag_acf"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"ACF = pd.Series(lag_acf)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"ACF.plot(kind = \"bar\")"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"lag_pacf = pacf(ts_diff, nlags=20, method='ols')"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"PACF = pd.Series(lag_pacf)\nPACF.plot(kind = \"bar\")"},{"cell_type":"markdown","metadata":{},"source":"Running the ARIMA Model"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"from statsmodels.tsa.arima_model import ARIMA"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"ts_diff.head()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"# Running the ARIMA Model(1,0,1)\nmodel_AR1MA = ARIMA(ts_diff, order=(1,0,1))"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"results_ARIMA = model_AR1MA.fit(disp = -1)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"results_ARIMA.fittedvalues.head()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"ts_diff.plot()\nresults_ARIMA.fittedvalues.plot()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"ts_diff.sum()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"predictions_ARIMA_diff = pd.Series(results_ARIMA.fittedvalues, copy=True)\npredictions_ARIMA_diff.tail()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"predictions_ARIMA_diff.sum()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"predictions_ARIMA_diff_cumsum = predictions_ARIMA_diff.cumsum()\npredictions_ARIMA_diff_cumsum.tail()"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"ts.ix[0]"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"predictions_ARIMA_log = pd.Series(ts.ix[0], index=ts.index)\npredictions_ARIMA_log = predictions_ARIMA_log.add(predictions_ARIMA_diff_cumsum,fill_value=0)\npredictions_ARIMA_log.tail()"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train['priceARIMA'] = np.exp(predictions_ARIMA_log)"},{"metadata":{},"outputs":[],"cell_type":"code","execution_count":null,"source":"df_train.plot(kind=\"line\", x=\"timeIndex\", y = [\"unit_sales\", \"priceARIMA\"])"},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""},{"metadata":{"collapsed":true},"outputs":[],"cell_type":"code","execution_count":null,"source":""}],"metadata":{"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"},"language_info":{"file_extension":".py","mimetype":"text/x-python","pygments_lexer":"ipython3","name":"python","nbconvert_exporter":"python","codemirror_mode":{"name":"ipython","version":3},"version":"3.6.2"}}}