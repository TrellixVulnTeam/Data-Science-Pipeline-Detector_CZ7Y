{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# AMEX-Default-Prediction\n\nIn this version we try a baseline approach using LightGBM\nAlso the data currently employs only the last row corresponding to a user","metadata":{}},{"cell_type":"code","source":"# -i --- input file location\n# -o --- output file location\n# Uncomment the below line and convert the test and train dataset\n# Although I'll advise to separately convert the datasets because it can give OOM (Out of Memory Error)\n# !python /kaggle/usr/lib/amex_dataset_prep/amex_dataset_prep.py -i ../input/amex-default-prediction/test_data.csv -o test.csv ","metadata":{"execution":{"iopub.status.busy":"2022-06-25T21:19:35.921487Z","iopub.execute_input":"2022-06-25T21:19:35.921939Z","iopub.status.idle":"2022-06-25T21:41:44.933146Z","shell.execute_reply.started":"2022-06-25T21:19:35.92181Z","shell.execute_reply":"2022-06-25T21:41:44.931427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A cell to clear off variables in case you continue to make predictions within the same notebook\n%reset -sf\nimport gc\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:48:16.578137Z","iopub.execute_input":"2022-06-25T22:48:16.578556Z","iopub.status.idle":"2022-06-25T22:48:16.752787Z","shell.execute_reply.started":"2022-06-25T22:48:16.578448Z","shell.execute_reply":"2022-06-25T22:48:16.751928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Importing the necessary libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm \nimport os\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nfrom catboost import CatBoostClassifier\nimport lightgbm as lgb\nimport xgboost as xgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-25T23:29:10.004277Z","iopub.execute_input":"2022-06-25T23:29:10.00468Z","iopub.status.idle":"2022-06-25T23:29:10.823368Z","shell.execute_reply.started":"2022-06-25T23:29:10.004648Z","shell.execute_reply":"2022-06-25T23:29:10.822428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Preprocessing the dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv(\"../input/d/datasets/bhavesjain/amex-default-prediction/train-last-rows.csv\")\ndf1 = pd.read_csv(\"../input/amex-default-prediction/train_labels.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:49:31.479862Z","iopub.execute_input":"2022-06-25T22:49:31.480453Z","iopub.status.idle":"2022-06-25T22:50:01.673517Z","shell.execute_reply.started":"2022-06-25T22:49:31.480422Z","shell.execute_reply":"2022-06-25T22:50:01.672336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.merge(df,df1,how=\"inner\")\ndf.fillna(df.mode().iloc[0],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:50:01.680804Z","iopub.execute_input":"2022-06-25T22:50:01.681176Z","iopub.status.idle":"2022-06-25T22:50:20.685142Z","shell.execute_reply.started":"2022-06-25T22:50:01.681144Z","shell.execute_reply":"2022-06-25T22:50:20.684073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_val= train_test_split(df,test_size=0.1, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:50:20.686532Z","iopub.execute_input":"2022-06-25T22:50:20.687155Z","iopub.status.idle":"2022-06-25T22:50:21.391822Z","shell.execute_reply.started":"2022-06-25T22:50:20.687117Z","shell.execute_reply":"2022-06-25T22:50:21.390851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_cols = [col for col in X_val.columns[2:-1] if col not in ['D_63','D_64']]\ny_col = \"target\"","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:52:46.40618Z","iopub.execute_input":"2022-06-25T22:52:46.406656Z","iopub.status.idle":"2022-06-25T22:52:46.416734Z","shell.execute_reply.started":"2022-06-25T22:52:46.406613Z","shell.execute_reply":"2022-06-25T22:52:46.415882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = MinMaxScaler()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:52:47.03324Z","iopub.execute_input":"2022-06-25T22:52:47.033723Z","iopub.status.idle":"2022-06-25T22:52:47.039177Z","shell.execute_reply.started":"2022-06-25T22:52:47.033679Z","shell.execute_reply":"2022-06-25T22:52:47.038114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train[x_cols] = scaler.fit_transform(X_train[x_cols])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:52:47.824059Z","iopub.execute_input":"2022-06-25T22:52:47.824567Z","iopub.status.idle":"2022-06-25T22:52:49.439198Z","shell.execute_reply.started":"2022-06-25T22:52:47.824524Z","shell.execute_reply":"2022-06-25T22:52:49.438197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Metrics and Model Configuration","metadata":{}},{"cell_type":"code","source":"def amex_metric(y_true, y_pred):\n    labels     = np.transpose(np.array([y_true, y_pred]))\n    labels     = labels[labels[:, 1].argsort()[::-1]]\n    weights    = np.where(labels[:,0]==0, 20, 1)\n    cut_vals   = labels[np.cumsum(weights) <= int(0.04 * np.sum(weights))]\n    top_four   = np.sum(cut_vals[:,0]) / np.sum(labels[:,0])\n\n    gini = [0,0]\n    for i in [1,0]:\n        labels         = np.transpose(np.array([y_true, y_pred]))\n        labels         = labels[labels[:, i].argsort()[::-1]]\n        weight         = np.where(labels[:,0]==0, 20, 1)\n        weight_random  = np.cumsum(weight / np.sum(weight))\n        total_pos      = np.sum(labels[:, 0] *  weight)\n        cum_pos_found  = np.cumsum(labels[:, 0] * weight)\n        lorentz        = cum_pos_found / total_pos\n        gini[i]        = np.sum((lorentz - weight_random) * weight)\n\n    return 0.5 * (gini[1]/gini[0] + top_four)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T22:52:50.172641Z","iopub.execute_input":"2022-06-25T22:52:50.173718Z","iopub.status.idle":"2022-06-25T22:52:50.184272Z","shell.execute_reply.started":"2022-06-25T22:52:50.17367Z","shell.execute_reply":"2022-06-25T22:52:50.18293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lgb_amex_metric(y_pred, y_true):\n    y_true = y_true.get_label()\n    return 'amex_metric', amex_metric(y_true, y_pred), True\n\nparams = {\n        'objective': 'binary',\n        'metric': \"binary_logloss\",\n        'boosting': 'dart',\n        'seed': 42,\n        'num_leaves': 100,\n        'learning_rate': 0.01,\n        'feature_fraction': 0.20,\n        'bagging_freq': 10,\n        'bagging_fraction': 0.50,\n        'n_jobs': -1,\n        'lambda_l2': 2,\n        'min_data_in_leaf': 40\n        }\n    \nlgb_train = lgb.Dataset(X_train[x_cols], X_train[y_col])#, categorical_feature = cat_features)\nlgb_valid = lgb.Dataset(X_val[x_cols], X_val[y_col])#, categorical_feature = cat_features)\nmodel = lgb.train(\n    params=params,\n    train_set = lgb_train,\n    num_boost_round = 2500,\n    valid_sets = [ lgb_valid],\n    early_stopping_rounds = 100,\n    verbose_eval = 500,\n    feval = lgb_amex_metric\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-26T00:15:16.106917Z","iopub.execute_input":"2022-06-26T00:15:16.107256Z","iopub.status.idle":"2022-06-26T00:53:41.074953Z","shell.execute_reply.started":"2022-06-26T00:15:16.107226Z","shell.execute_reply":"2022-06-26T00:53:41.073932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inferring on test set or validation set","metadata":{}},{"cell_type":"code","source":"pred = model.predict(X_val[x_cols])\ny = X_val[y_col]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T00:57:34.911447Z","iopub.execute_input":"2022-06-26T00:57:34.912074Z","iopub.status.idle":"2022-06-26T00:57:42.205704Z","shell.execute_reply.started":"2022-06-26T00:57:34.912038Z","shell.execute_reply":"2022-06-26T00:57:42.204917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Current CV","metadata":{}},{"cell_type":"code","source":"amex_metric(y,pred)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T00:57:42.207565Z","iopub.execute_input":"2022-06-26T00:57:42.208187Z","iopub.status.idle":"2022-06-26T00:57:42.234239Z","shell.execute_reply.started":"2022-06-26T00:57:42.20815Z","shell.execute_reply":"2022-06-26T00:57:42.233423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save the model for future use","metadata":{}},{"cell_type":"code","source":"model.save_model(\"lgb_model.json\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Prediction Notebook\n\nI've separately prepared the inferring notebook at: https://www.kaggle.com/bhavesjain/amex-default-pred-infer","metadata":{}}]}