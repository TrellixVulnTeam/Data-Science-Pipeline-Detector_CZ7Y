{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This notebook based on my previous notebook [here](https://www.kaggle.com/code/pavelvod/amex-eda-revealing-time-patterns-of-features)\n\nI asked to split feature time series between positive and negative cases, but failed to add this research into the old one due to lack of RAM.I do not feel like it worth to spend time to append into old one instead of starting a new one.\n\nHowever, results are absolutely insane!\n","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-18T08:00:00.655839Z","iopub.execute_input":"2022-06-18T08:00:00.656619Z","iopub.status.idle":"2022-06-18T08:00:01.757277Z","shell.execute_reply.started":"2022-06-18T08:00:00.656514Z","shell.execute_reply":"2022-06-18T08:00:01.755786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = pd.read_csv('../input/amex-default-prediction/train_labels.csv')\ntrain_df = pd.read_parquet('../input/amex-data-integer-dtypes-parquet-format/train.parquet').assign(S_2=lambda dx: pd.to_datetime(dx.S_2))\n\navg_with_target = train_df.merge(labels, on='customer_ID').groupby(['S_2', 'target']).mean().unstack()\n\nfeature_names = list(set([col[0] for col in avg_with_target.columns]))","metadata":{"execution":{"iopub.status.busy":"2022-06-18T08:00:01.759766Z","iopub.execute_input":"2022-06-18T08:00:01.760684Z","iopub.status.idle":"2022-06-18T08:02:49.711056Z","shell.execute_reply.started":"2022-06-18T08:00:01.760636Z","shell.execute_reply":"2022-06-18T08:02:49.710038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import ks_2samp","metadata":{"execution":{"iopub.status.busy":"2022-06-18T08:11:20.980908Z","iopub.execute_input":"2022-06-18T08:11:20.981408Z","iopub.status.idle":"2022-06-18T08:11:20.986663Z","shell.execute_reply.started":"2022-06-18T08:11:20.981365Z","shell.execute_reply":"2022-06-18T08:11:20.985589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(plt.style.available[4])\nfor feature_name in feature_names:\n    print(feature_name)\n    dt = avg_with_target[feature_name].rename(columns={0: 'Negative', 1: 'Positive'})\n    ks_statistics = np.round(ks_2samp(dt.Positive, dt.Negative).statistic,3)\n    dt.plot(title=f'{feature_name}, KS Test: {ks_statistics}', figsize=(12,6))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-18T08:15:50.28811Z","iopub.execute_input":"2022-06-18T08:15:50.28908Z","iopub.status.idle":"2022-06-18T08:17:05.393095Z","shell.execute_reply.started":"2022-06-18T08:15:50.289029Z","shell.execute_reply":"2022-06-18T08:17:05.391391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}