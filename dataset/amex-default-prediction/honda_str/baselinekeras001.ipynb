{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 作成中。。。","metadata":{"id":"82GWIx3pEGoY"}},{"cell_type":"markdown","source":"# 引用元: https://www.kaggle.com/code/tgwstr/baselinelgbm001","metadata":{}},{"cell_type":"markdown","source":"# Pipeline","metadata":{"id":"XAed8tBOEzyO"}},{"cell_type":"markdown","source":"## Library","metadata":{"id":"iDON_httEjM0"}},{"cell_type":"code","source":"import os\nimport json\nimport warnings\nimport shutil\nimport logging\nimport joblib\nimport random\nimport datetime\nimport pytz\nimport sys\nimport re\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom tqdm.notebook import tqdm\nfrom tqdm.auto import tqdm\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score, mean_squared_error\n\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom tensorflow.keras import backend as K\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom tensorflow.keras.utils import plot_model\n\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n\nimport pickle\nimport glob\n\n# import shap\nimport xgboost\nfrom scipy.stats import spearmanr\nfrom sklearn.ensemble import (\n    ExtraTreesRegressor,\n    GradientBoostingRegressor,\n    RandomForestRegressor,\n)\n\nimport lightgbm as lgb\n# from lightgbm import log_evaluation\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\nwarnings.filterwarnings(\"ignore\")","metadata":{"executionInfo":{"elapsed":422,"status":"error","timestamp":1655216801015,"user":{"displayName":"津川聡","userId":"17621678834685835832"},"user_tz":-540},"id":"WA-bmarGgH2b","outputId":"9e9a17c9-17bb-4ec6-e723-608d60ecb64e","execution":{"iopub.status.busy":"2022-06-29T03:32:17.989891Z","iopub.execute_input":"2022-06-29T03:32:17.990549Z","iopub.status.idle":"2022-06-29T03:32:25.998739Z","shell.execute_reply.started":"2022-06-29T03:32:17.990455Z","shell.execute_reply":"2022-06-29T03:32:25.997944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Config","metadata":{"id":"ySSZB4IzELyJ"}},{"cell_type":"markdown","source":"## 作成・編集途中です。","metadata":{}},{"cell_type":"code","source":"COLAB = \"google.colab\" in sys.modules","metadata":{"execution":{"iopub.status.busy":"2022-06-29T03:32:26.000553Z","iopub.execute_input":"2022-06-29T03:32:26.000912Z","iopub.status.idle":"2022-06-29T03:32:26.006018Z","shell.execute_reply.started":"2022-06-29T03:32:26.000876Z","shell.execute_reply":"2022-06-29T03:32:26.00458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Config:\n    # notebookのタイトル取得\n    if COLAB:\n        from requests import get\n        name = get('http://172.28.0.2:9000/api/sessions').json()[0]['name'].split('.')[0]  \n    else:\n        name = \"baseline_lgbm001\"  # kaggle環境ならば自分で記入\n\n    # 予測のみ/学習+予測の選択\n    only_inference = False\n    if only_inference:\n        task = 'infer'\n    else:\n        task = 'train'\n\n    # クロスバリデーション設定\n    n_fold = 5\n    trn_fold = list(range(n_fold))\n\n    seed = 42\n    \n    target_col = \"target\"  # ⚠️コンペごとに更新\n    categ_feats = ['B_30', 'B_38', 'D_114', 'D_116', 'D_117', 'D_120', 'D_126', 'D_63', 'D_64', 'D_66', 'D_68']\n    # debug = False\n\n    # lgb params\n    def get_lgb_params() -> dict:\n        lgb_params = {\n            'objective': 'binary',\n            'metric': 'binary_logloss',\n            'learning_rate': 0.05,\n            'num_leaves': 64,\n            'force_col_wise': True,\n            'bagging_freq': 1,\n            'seed': 2112,\n            'verbosity': 0,\n            'first_metric_only': True,\n            'bin_construct_sample_cnt': 100000000,\n            'feature_pre_filter': False,\n            'bagging_fraction': 0.9,\n            'feature_fraction': 0.2,\n            'lambda_l1': 0.1,\n            'lambda_l2': 0.1,\n            'min_data_in_leaf': 1000,\n            'path_smooth': 10,\n            'max_bin': 255,\n            }\n        return lgb_params\n\n    # 解凍ファイル\n    # zip_file = 'foursquare-location-matching.zip'  # ⚠️コンペごとに更新\n\n    # Colab Env\n    upload_from_colab = True\n    api_path = \"/content/drive/MyDrive/kaggle/kaggle.json\"\n    drive_path = \"/content/drive/MyDrive/kaggle/AmericanExpress\"  # ⚠️コンペごとに更新\n    \n    # Kaggle Env\n    kaggle_input_path = \"../input/expression-chinchilla\"  # ⚠️コンペごとに更新\n    kaggle_dataset_path = None","metadata":{"id":"jB5W0vW9fsLz","executionInfo":{"status":"ok","timestamp":1655216631944,"user_tz":-540,"elapsed":60,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-29T03:32:26.007988Z","iopub.execute_input":"2022-06-29T03:32:26.00843Z","iopub.status.idle":"2022-06-29T03:32:26.022146Z","shell.execute_reply.started":"2022-06-29T03:32:26.008385Z","shell.execute_reply":"2022-06-29T03:32:26.021319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{"id":"rTotr8nyEYld"}},{"cell_type":"code","source":"# log を txtファイルに出力させるためのクラス\nclass Logger:\n    # 参考) https://github.com/ghmagazine/kagglebook/blob/master/ch04-model-interface/code/util.py\n    def __init__(self, path, log_title='Experiment'):\n        self.general_logger = logging.getLogger(path)\n        stream_handler = logging.StreamHandler()\n        file_general_handler = logging.FileHandler(os.path.join(path, f'{log_title}.log'))\n        if len(self.general_logger.handlers) == 0:\n            self.general_logger.addHandler(stream_handler)\n            self.general_logger.addHandler(file_general_handler)\n            self.general_logger.setLevel(logging.INFO)\n\n    def info(self, message):\n        # display time\n        self.general_logger.info(f'[{self.now_string()}] - {message}')\n\n    @staticmethod\n    def now_string():\n        return str(datetime.datetime.now(pytz.timezone('Asia/Tokyo')).strftime('%Y-%m-%d %H:%M:%S'))","metadata":{"id":"t4FkO6Cpg5zP","executionInfo":{"status":"ok","timestamp":1655216631944,"user_tz":-540,"elapsed":59,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-29T03:32:26.025273Z","iopub.execute_input":"2022-06-29T03:32:26.025605Z","iopub.status.idle":"2022-06-29T03:32:26.034323Z","shell.execute_reply.started":"2022-06-29T03:32:26.025581Z","shell.execute_reply":"2022-06-29T03:32:26.03354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# シード固定用関数\ndef seed_everything(seed=42):\n#  参考) https://qiita.com/kaggle_grandmaster-arai-san/items/d59b2fb7142ec7e270a5\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)","metadata":{"id":"2fRR9p6A2LQD","executionInfo":{"status":"ok","timestamp":1655216631944,"user_tz":-540,"elapsed":59,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-29T03:32:26.035582Z","iopub.execute_input":"2022-06-29T03:32:26.03598Z","iopub.status.idle":"2022-06-29T03:32:26.045105Z","shell.execute_reply.started":"2022-06-29T03:32:26.035942Z","shell.execute_reply":"2022-06-29T03:32:26.044084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_feats_cols(train_df: pd.DataFrame, *drop_cols) -> list:\n    return list(train_df.drop(labels=list(drop_cols), axis=1).columns)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T03:32:26.046773Z","iopub.execute_input":"2022-06-29T03:32:26.047236Z","iopub.status.idle":"2022-06-29T03:32:26.053958Z","shell.execute_reply.started":"2022-06-29T03:32:26.047199Z","shell.execute_reply":"2022-06-29T03:32:26.053175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## SetUp","metadata":{"id":"gUeiMunXEv8i"}},{"cell_type":"markdown","source":"### 環境ごとのセットアップ","metadata":{"id":"hY7xPwMVhJce"}},{"cell_type":"code","source":"# -------------------------------colab 環境の場合-------------------------------\nif COLAB:\n    print(\"-------------------------------This environment is Google Colab-------------------------------\")\n    \n    # mount\n    from google.colab import drive\n    if not os.path.isdir(\"/content/drive\"):\n        drive.mount('/content/drive') \n\n    # my-modules のPath設定\n    import sys\n    sys.path.append('/content/drive/MyDrive/Colab Notebooks/my-modules')\n\n    # use kaggle api (need kaggle token)\n    f = open(Config.api_path, 'r')\n    json_data = json.load(f) \n    os.environ[\"KAGGLE_USERNAME\"] = json_data[\"username\"]\n    os.environ[\"KAGGLE_KEY\"] = json_data[\"key\"]\n    \n    # set dirs\n    DRIVE = Config.drive_path\n    EXP = (Config.name if Config.name is not None \n           else get(\"http://172.28.0.2:9000/api/sessions\").json()[0][\"name\"][:-6])\n    INPUT = os.path.join(DRIVE, \"INPUT\")\n    FEATURES = os.path.join(INPUT, \"FEATURES\")\n    OUTPUT = os.path.join(DRIVE, \"OUTPUT\")\n    SUBMISSION = os.path.join(DRIVE, \"SUBMISSION\")\n    OUTPUT_EXP = os.path.join(OUTPUT, EXP) \n    EXP_MODEL = os.path.join(OUTPUT_EXP, \"MODEL\")\n    EXP_FIG = os.path.join(OUTPUT_EXP, \"FIG\")\n    EXP_PREDS = os.path.join(OUTPUT_EXP, \"PREDS\")\n\n    # make dirs\n    for d in [INPUT, FEATURES, SUBMISSION, EXP_MODEL, EXP_FIG, EXP_PREDS]:\n        os.makedirs(d, exist_ok=True)\n\n    # if not os.path.isfile(os.path.join(INPUT, Config.zip_file)):\n    #     # download dataset\n    #     # kaggle をインストール\n    #     # アクセスパーミッションのため、以下を打ち込みます。\n    #     ! chmod 600 /root/.kaggle/kaggle.json\n    #     ! pip install kaggle\n    #     ! kaggle competitions download -c foursquare-location-matching -p $INPUT  # ⚠️コンペごとに更新\n    #     # 上記でdownloadしてきたZIPファイルを解凍\n    #     ! apt-get install p7zip-full -y\n    #     ! 7za x os.path.join(INPUT, Config.zip_file)\n    # else:\n    #     print('DS for competition has been already installed.') \n    \n    # utils\n    logger = Logger(OUTPUT_EXP)\n    \n    sys.path.append('/content/drive/MyDrive/Colab Notebooks/my-modules')\n\n\n# -------------------------------kaggle 環境の場合-------------------------------\nelse:\n    print(\"-------------------------------This environment is Kaggle Kernel-------------------------------\")\n    \n    # set dirs\n    INPUT = Config.kaggle_input_path  # ⚠️コンペごとに更新\n    EXP, OUTPUT, SUBMISSION = \"./\", \"./\", \"./\"\n    EXP_MODEL = os.path.join(EXP, \"model\")\n    EXP_FIG = os.path.join(EXP, \"fig\")\n    EXP_PREDS = os.path.join(EXP, \"preds\")\n    \n    # copy dirs\n    if Config.kaggle_dataset_path is not None:\n        KD_MODEL = os.path.join(Config.kaggle_dataset_path, \"model\")\n        KD_EXP_PREDS = os.path.join(Config.kaggle_dataset_path, \"preds\")\n        shutil.copytree(KD_MODEL, EXP_MODEL)\n        shutil.copytree(KD_EXP_PREDS, EXP_PREDS)\n\n    # make dirs\n    for d in [EXP_MODEL, EXP_FIG, EXP_PREDS]:\n        os.makedirs(d, exist_ok=True)\n        \n    # utils\n    logger = Logger(EXP)\n\n# utils\nwarnings.filterwarnings(\"ignore\")\nsns.set(style='whitegrid')\nseed_everything(seed=Config.seed)","metadata":{"executionInfo":{"elapsed":59,"status":"ok","timestamp":1655216631944,"user":{"displayName":"津川聡","userId":"17621678834685835832"},"user_tz":-540},"id":"ay6hwrE3hTFM","outputId":"4238ae1f-e620-4be7-a8cf-e0d663dacfa5","execution":{"iopub.status.busy":"2022-06-29T03:32:26.055436Z","iopub.execute_input":"2022-06-29T03:32:26.055949Z","iopub.status.idle":"2022-06-29T03:32:26.07688Z","shell.execute_reply.started":"2022-06-29T03:32:26.055914Z","shell.execute_reply":"2022-06-29T03:32:26.07531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## コンペ説明","metadata":{"id":"CVGI0JLYZrBz"}},{"cell_type":"markdown","source":"レストランでの食事やコンサートのチケット購入など、現代の生活では日々の買い物にクレジットカードの利便性が欠かせません。\nクレジットカードがあれば、多額の現金を持ち歩く必要がなく、また、買い物の全額を前払いして、長期にわたって支払うことができます。\nしかし、カード発行会社は、私たちが請求した金額をきちんと返済してくれることをどうやって確認するのでしょうか？\nこの問題は複雑で、多くの解決策がありますが、このコンペティションでは、さらに多くの改善策が検討されています。\n\n貸し倒れ予測は、消費者金融ビジネスのリスク管理の中心的存在です。\n貸し倒れを予測することで、貸し出しの決定を最適化し、より良い顧客体験と健全なビジネス経済を実現することができます。\n現在のモデルは、リスク管理を支援するために存在しています。\nしかし、現在使用されているモデルを凌駕する、より優れたモデルを作成することは可能です。\n\nアメリカン・エキスプレスは、世界的に統合された決済企業です。\n世界最大の決済カード発行会社である同社は、生活を豊かにし、ビジネスの成功をもたらす商品、洞察、体験へのアクセスを顧客に提供しています。\n\nこのコンペティションでは、機械学習のスキルを応用して、クレジット・デフォルトを予測します。\n具体的には、産業界規模のデータセットを活用し、現在の生産モデルに挑戦する機械学習モデルを構築していただきます。\nトレーニング、検証、テストの各データセットには、時系列行動データおよび匿名化された顧客プロファイル情報が含まれます。\n特徴量の作成から、モデル内でのデータの有機的な利用まで、最も強力なモデルを作るためのあらゆる手法を自由に探求することができます。\n\n成功すれば、クレジットカードの審査が通りやすくなり、カード会員にとってより良い顧客体験の創造に貢献できます。\n優れたソリューションは、世界最大のクレジットカード発行会社が使用しているクレジットデフォルト予測モデルに挑戦し、\n賞金やアメリカン・エキスプレスとの面接の機会、そしてやりがいのある新しいキャリアを獲得する可能性があります。","metadata":{"id":"zfG4HQptZj_A"}},{"cell_type":"markdown","source":"## Load Data","metadata":{"id":"-2RFUO1Qk0Wr"}},{"cell_type":"code","source":"train = pd.read_parquet(os.path.join(INPUT, 'train_agg.parquet'))\ntest = pd.read_parquet(os.path.join(INPUT, 'test_agg.parquet'))\nsample_submission = pd.read_csv(os.path.join(INPUT, 'sample_submission.csv'))  # parquetにすべき？\n\ncustomer_ID = train['customer_ID']","metadata":{"id":"OvOoQCrji4uk","executionInfo":{"status":"ok","timestamp":1655216641982,"user_tz":-540,"elapsed":10040,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-29T03:32:26.07805Z","iopub.execute_input":"2022-06-29T03:32:26.078364Z","iopub.status.idle":"2022-06-29T03:33:10.607557Z","shell.execute_reply.started":"2022-06-29T03:32:26.07834Z","shell.execute_reply":"2022-06-29T03:33:10.606662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"id":"V4iL47SCzyUC","executionInfo":{"status":"ok","timestamp":1655216641982,"user_tz":-540,"elapsed":24,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"outputId":"6bed1e9d-9621-459e-9ca4-de3a30e8a5ed","execution":{"iopub.status.busy":"2022-06-29T03:33:10.609243Z","iopub.execute_input":"2022-06-29T03:33:10.609849Z","iopub.status.idle":"2022-06-29T03:33:10.654319Z","shell.execute_reply.started":"2022-06-29T03:33:10.609811Z","shell.execute_reply":"2022-06-29T03:33:10.653597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_cols = ['customer_ID', 'target']\nfeats_cols = get_feats_cols(train, *drop_cols)","metadata":{"execution":{"iopub.status.busy":"2022-06-29T03:36:47.742665Z","iopub.execute_input":"2022-06-29T03:36:47.743321Z","iopub.status.idle":"2022-06-29T03:36:48.681434Z","shell.execute_reply.started":"2022-06-29T03:36:47.743281Z","shell.execute_reply":"2022-06-29T03:36:48.680313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train Models","metadata":{"id":"zSZdiLGpWBxB"}},{"cell_type":"markdown","source":"### CV split","metadata":{"id":"phEpMOEodj6e"}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\ntrain[\"fold\"] = -1\n\nskf = StratifiedKFold(n_splits=Config.n_fold,\n                      shuffle=True,\n                      random_state=Config.seed)\nskf_split = list(skf.split(X=train,\n                        y=train[Config.target_col]))\n\nfor i_fold, lst in enumerate(skf_split):\n    if i_fold in Config.trn_fold:\n        train.loc[lst[1].tolist(), \"fold\"] = i_fold","metadata":{"id":"mbfY_ipOgHME","executionInfo":{"status":"ok","timestamp":1655216641983,"user_tz":-540,"elapsed":21,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-29T03:34:59.343502Z","iopub.execute_input":"2022-06-29T03:34:59.344498Z","iopub.status.idle":"2022-06-29T03:34:59.537878Z","shell.execute_reply.started":"2022-06-29T03:34:59.344456Z","shell.execute_reply":"2022-06-29T03:34:59.536992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Calculate functions","metadata":{"id":"N4N2xY28iO6T"}},{"cell_type":"code","source":"def compute_recall_at4(y_true: np.array, y_pred: np.array) -> float:\n    \n    # count of positives and negatives\n    n_pos = y_true.sum()\n    n_neg = y_true.shape[0] - n_pos\n    \n    # desc sorting by prediction values\n    indices = np.argsort(y_pred)[::-1]\n    target = y_true[indices]\n    \n    # filter the top 4% by cumulative row weights\n    weight = 20.0 - target * 19.0\n    cum_norm_weight = (weight / weight.sum()).cumsum()\n    four_pct_mask = cum_norm_weight <= 0.04\n    \n    # default rate captured at 4%\n    d = target[four_pct_mask].sum() / n_pos\n    \n    return d\n\ndef compute_normalized_gini(y_true: np.array, y_pred: np.array) -> float:\n    \n    # count of positives and negatives\n    n_pos = y_true.sum()\n    n_neg = y_true.shape[0] - n_pos\n\n    # sorting desc by prediction values\n    indices = np.argsort(y_pred)[::-1]\n    target = y_true[indices]\n\n    # weighted gini coefficient\n    weight = 20.0 - target * 19.0\n    cum_norm_weight = (weight / weight.sum()).cumsum()\n\n    lorentz = (target / n_pos).cumsum()\n    gini = ((lorentz - cum_norm_weight) * weight).sum()\n\n    # max weighted gini coefficient\n    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n\n    # normalized weighted gini coefficient\n    g = gini / gini_max\n    \n    return g\n    \ndef compute_amex_metric(y_true: np.array, y_pred: np.array) -> float:\n\n    # count of positives and negatives\n    n_pos = y_true.sum()\n    n_neg = y_true.shape[0] - n_pos\n\n    # sorting desc by prediction values\n    indices = np.argsort(y_pred)[::-1]\n    target = y_true[indices]\n\n    # filter the top 4% by cumulative row weights\n    weight = 20.0 - target * 19.0\n    cum_norm_weight = (weight / weight.sum()).cumsum()\n    four_pct_filter = cum_norm_weight <= 0.04\n\n    # default rate captured at 4%\n    d = target[four_pct_filter].sum() / n_pos\n\n    # weighted gini coefficient\n    lorentz = (target / n_pos).cumsum()\n    gini = ((lorentz - cum_norm_weight) * weight).sum()\n\n    # max weighted gini coefficient\n    gini_max = 10 * n_neg * (1 - 19 / (n_pos + 20 * n_neg))\n\n    # normalized weighted gini coefficient\n    g = gini / gini_max\n\n    return 0.5 * (g + d)","metadata":{"id":"VWSKaUyAiMZO","executionInfo":{"status":"ok","timestamp":1655216642681,"user_tz":-540,"elapsed":719,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-29T03:35:02.958955Z","iopub.execute_input":"2022-06-29T03:35:02.95975Z","iopub.status.idle":"2022-06-29T03:35:02.972932Z","shell.execute_reply.started":"2022-06-29T03:35:02.959708Z","shell.execute_reply":"2022-06-29T03:35:02.972131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics in lgbm format\n\ndef metric_recall_at4(y_pred: np.ndarray, data: lgb.Dataset):\n    y_true = data.get_label()\n    # name, result, is_higher_better\n    return 'recall_at4', compute_recall_at4(y_true, y_pred), True\n\ndef metric_normalized_gini(y_pred: np.ndarray, data: lgb.Dataset):\n    y_true = data.get_label()\n    # name, result, is_higher_better\n    return 'norm_gini', compute_normalized_gini(y_true, y_pred), True\n\ndef metric_amex(y_pred: np.ndarray, data: lgb.Dataset):\n    y_true = data.get_label()\n    # name, result, is_higher_better\n    return 'amex_metric', compute_amex_metric(y_true, y_pred), True","metadata":{"id":"S9SBHD-55Hmk","executionInfo":{"status":"ok","timestamp":1655216642682,"user_tz":-540,"elapsed":8,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-29T03:35:07.643828Z","iopub.execute_input":"2022-06-29T03:35:07.644656Z","iopub.status.idle":"2022-06-29T03:35:07.651442Z","shell.execute_reply.started":"2022-06-29T03:35:07.644616Z","shell.execute_reply":"2022-06-29T03:35:07.649931Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LGBM","metadata":{"id":"MqNcM7A4WBxB"}},{"cell_type":"code","source":"def make_lgb_ds(X, y):\n    return lgb.Dataset(data=X, \n                       label=y, \n                       feature_name='auto',  # 列名を自動で認識\n#                        categorical_feature=Config.categ_feats,\n                       free_raw_data=False)","metadata":{"id":"EWdTznZPtciw","executionInfo":{"status":"ok","timestamp":1655216642682,"user_tz":-540,"elapsed":6,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-16T03:42:26.863204Z","iopub.execute_input":"2022-06-16T03:42:26.863944Z","iopub.status.idle":"2022-06-16T03:42:26.873601Z","shell.execute_reply.started":"2022-06-16T03:42:26.863875Z","shell.execute_reply":"2022-06-16T03:42:26.872308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_lgbm(df, folds=Config.n_fold, params=Config.get_lgb_params()):\n    models = []\n    \n    for fold in tqdm(range(folds)):\n        model_path = os.path.join(EXP_MODEL, f\"{Config.name}-seed{Config.seed}-fold{fold}\")\n        # modelが保存されていない場合はtrainning\n        if not os.path.isfile(model_path):\n            # train, valid毎の入出力を用意\n            X_train = df[df.fold != fold][feats_cols]\n            y_train = df[df.fold != fold][Config.target_col]\n            X_valid = df[df.fold == fold][feats_cols]\n            y_valid = df[df.fold == fold][Config.target_col]\n            # train, valid毎にdsへ格納\n            train_ds = make_lgb_ds(X_train, y_train)\n            valid_ds = make_lgb_ds(X_valid, y_valid)\n            # modelの用意\n            model = lgb.train(params=params,\n                              train_set=train_ds,\n                              valid_sets=[train_ds, valid_ds],\n                              feval=[metric_amex, \n                                     metric_recall_at4, \n                                     metric_normalized_gini],\n                              early_stopping_rounds=20,\n                              num_boost_round=3000,  # 最大の分岐回数\n                              callbacks=[lgb.log_evaluation(period=50), \n                                         lgb.early_stopping(50)]\n                              )\n            # fold毎のmodelをpklファイルとして保存\n            pickle.dump(model, open(model_path, 'wb'))\n            print(f\"{Config.name}-seed{Config.seed}-fold{fold} has been saved.\")\n            \n            # modelsへmodelを追加\n            models.append(model)\n            \n            # validモードの予測とAmexMetricを計算\n            oof_preds = model.predict(X_valid)\n            oof_score = compute_amex_metric(y_valid, oof_preds)\n\n            # fold毎にモデル名とスコア(AmexMetric)を表示\n            logger.info(f\"model_name:{Config.name}-seed:{Config.seed}-fold:{fold}\\\n                        \\n-X_cols:{X_train.columns.values}-y:{y_train.columns.values} >>>>> Score(AmexMetric)={oof_score}\")\n            print(f'fold_{fold} has finished.')\n            print('-----------------------------')\n        # 既に保存済みの場合は保存しない\n        else:\n            print(f'fold_{fold}: No model trained.')\n        \n    return models","metadata":{"id":"XP-mMZvMtciw","executionInfo":{"status":"ok","timestamp":1655216654866,"user_tz":-540,"elapsed":624,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"execution":{"iopub.status.busy":"2022-06-16T03:42:26.875522Z","iopub.execute_input":"2022-06-16T03:42:26.876007Z","iopub.status.idle":"2022-06-16T03:42:26.892147Z","shell.execute_reply.started":"2022-06-16T03:42:26.875963Z","shell.execute_reply":"2022-06-16T03:42:26.890858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nlgbm_models = train_lgbm(train, \n                         folds=Config.n_fold, \n                         params=Config.get_lgb_params())","metadata":{"executionInfo":{"status":"error","timestamp":1655216671911,"user_tz":-540,"elapsed":4869,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"outputId":"233e383e-08a1-41c2-fc8d-006f677e455c","id":"Blu7GZyvtnxi","execution":{"iopub.status.busy":"2022-06-16T03:42:26.895121Z","iopub.execute_input":"2022-06-16T03:42:26.895848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgbm\n\ndef fit_lgbm(X, y, params=None, es_rounds=20, seed=42, N_SPLITS=5, \n             n_class=None, model_dir=None, folds=None):\n    models = []\n    oof = np.zeros((len(y), n_class), dtype=np.float64)\n    \n    for i in tqdm(range(Config.n_fold)):\n        print(f\"== fold {i} ==\")\n        trn_idx = (folds!=i)\n        val_idx = (folds==i)\n        X_train, y_train = X[trn_idx], y.iloc[trn_idx]\n        X_valid, y_valid = X.iloc[val_idx], y.iloc[val_idx]\n\n        if model_dir is None:\n            model = lgbm.LGBMClassifier(**params)\n            model.fit(\n                X_train, y_train, \n                eval_set=[(X_valid, y_valid)],  \n                early_stopping_rounds=es_rounds, \n                eval_metric='logloss',  \n    #             verbose=-1)\n                verbose=50)\n        else:\n            with open(f'{model_dir}/lgbm_fold{i}.pkl', 'rb') as f:\n                model = pickle.load(f)\n            \n        pred = model.predict_proba(X_valid)\n        oof[val_idx] = pred\n        models.append(model)\n        \n        file = f'lgbm_fold{i}.pkl'\n        pickle.dump(model, open(file, 'wb'))\n        print()\n\n    cv = (oof.argmax(axis=-1) == y).mean()\n    print(f\"CV-accuracy: {cv}\")\n\n    return oof, models","metadata":{"id":"Vm9iBPY3eghK","executionInfo":{"status":"ok","timestamp":1654697297824,"user_tz":-540,"elapsed":236,"user":{"displayName":"津川聡","userId":"17621678834685835832"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def inference_lgbm(models, feat_df):\n    pred = np.array([model.predict_proba(feat_df) for model in models])\n    pred = np.mean(pred, axis=0)\n    return pred","metadata":{"id":"QjFss-syeimn","executionInfo":{"status":"ok","timestamp":1654697313391,"user_tz":-540,"elapsed":337,"user":{"displayName":"津川聡","userId":"17621678834685835832"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {\n    'objective': \"logloss\",\n    'learning_rate': 0.2,\n    'reg_alpha': 0.1,\n    'reg_lambda': 0.1,\n    'random_state': 42,\n\n    'max_depth': 7,   \n    'num_leaves': 35, \n    'n_estimators': 1000000, \n    \"colsample_bytree\": 0.9,\n}\n\noof, models = fit_lgbm(train.drop(Config.target_col, axis=1), train[Config.target_col], \n                       params=params, n_class=, \n                       N_SPLITS=Config.n_fold, folds=y_train.values)","metadata":{"id":"60wcNnbGvCcw","executionInfo":{"status":"error","timestamp":1652685684950,"user_tz":-540,"elapsed":490,"user":{"displayName":"津川聡","userId":"17621678834685835832"}},"outputId":"e56ddbd5-ed6f-44d8-96a4-6bd5744dcece"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Run - prints rmse for each fold","metadata":{"id":"yzRo8c2jWBxC"}},{"cell_type":"code","source":"%%time\nlgb_params = Config.get_lgb_params()\nlgbm_models = train_lgbm(prices, folds=Config.n_fold, params=lgb_params)","metadata":{"executionInfo":{"elapsed":17122,"status":"ok","timestamp":1650553540358,"user":{"displayName":"津川聡","userId":"17621678834685835832"},"user_tz":-540},"id":"R3OhKponWBxC","outputId":"0ec3fec3-8290-41e7-d5a8-8d873ff36944","jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make Predictions & Submit","metadata":{"id":"tBWWrbijWBxC"}},{"cell_type":"code","source":"def pred_to_submission(pred):\n    pred = pred.sort_values(by = \"Prediction\", ascending=False)\n    pred.Rank = np.arange(0,2000)\n    pred = pred.sort_values(by = \"SecuritiesCode\", ascending=True)\n    pred.drop([\"Prediction\"],axis=1)\n    submission = pred[[\"Date\",\"SecuritiesCode\",\"Rank\"]]\n    return submission","metadata":{"id":"lOGVX1z0nTn-","jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not COLAB:\n    import jpx_tokyo_market_prediction as JTMP\n    env = JTMP.make_env()\n    iter_test = env.iter_test()\n\n    for (prices, options, financials, trades, secondary_prices, sample_prediction) in iter_test:\n        prices[\"SecuritiesCode\"] = enc.fit_transform(prices[[\"SecuritiesCode\"]])\n\n        X_test = prices[[\"SecuritiesCode\", \"Open\", \"High\", \"Low\", \"Close\"]]\n        lgbm_preds = list()\n        for model in lgbm_models:\n            lgbm_preds.append( model.predict(X_test) )\n        lgbm_preds = np.mean(lgbm_preds, axis=0)\n\n        sample_prediction[\"Prediction\"] = lgbm_preds\n        submission = pred_to_submission(sample_prediction)\n\n        env.predict(submission)","metadata":{"id":"jy9AWBV1WBxC","jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = prices[[\"SecuritiesCode\", \"Open\", \"High\", \"Low\", \"Close\"]]\ny_pred = \nfor model in lgbm_models:\n    display(model.predict(X_test))","metadata":{"executionInfo":{"elapsed":6329,"status":"ok","timestamp":1650555484098,"user":{"displayName":"津川聡","userId":"17621678834685835832"},"user_tz":-540},"id":"t5_nLjHNw3Jq","outputId":"299c2c77-24d3-41c0-8a47-7eec25ff5c7b","jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Others","metadata":{"id":"pIxLBypaED0h"}},{"cell_type":"code","source":"# folderのディレクトリ構造可視化ツール\nimport pathlib\nimport glob\nimport os\n\ndef tree(path, layer=0, is_last=False, indent_current='　'):\n    if not pathlib.Path(path).is_absolute():\n        path = str(pathlib.Path(path).resolve())\n\n    # カレントディレクトリの表示\n    current = path.split('/')[::-1][0]\n    if layer == 0:\n        print('<'+current+'>')\n    else:\n        branch = '└' if is_last else '├'\n        print('{indent}{branch}<{dirname}>'.format(indent=indent_current, branch=branch, dirname=current))\n\n    # 下の階層のパスを取得\n    paths = [p for p in glob.glob(path+'/*') if os.path.isdir(p) or os.path.isfile(p)]\n    def is_last_path(i):\n        return i == len(paths)-1\n\n    # 再帰的に表示\n    for i, p in enumerate(paths):\n\n        indent_lower = indent_current\n        if layer != 0:\n            indent_lower += '　　' if is_last else '│　'\n\n        if os.path.isfile(p):\n            branch = '└' if is_last_path(i) else '├'\n            print('{indent}{branch}{filename}'.format(indent=indent_lower, branch=branch, filename=p.split('/')[::-1][0]))\n        if os.path.isdir(p):\n            tree(p, layer=layer+1, is_last=is_last_path(i), indent_current=indent_lower)","metadata":{"id":"H2PA3JjCx4nw","jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree('/content/drive/MyDrive/kaggle/JPXTokyoStock')","metadata":{"executionInfo":{"elapsed":17,"status":"ok","timestamp":1650553540926,"user":{"displayName":"津川聡","userId":"17621678834685835832"},"user_tz":-540},"id":"pvjGkkw77uLp","outputId":"1f085457-7ab3-43e5-f538-6f535afa20a9","jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]}]}