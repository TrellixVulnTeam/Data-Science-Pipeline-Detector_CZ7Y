{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# <b><span style='color:#016FD0;font-size:200%'>1 |</span><span style='color:#016FD0;font-size:200%'> Introduction</span></b>","metadata":{}},{"cell_type":"markdown","source":"Dataset for [\"American Express - Default Prediction\"][1] competition was splitted to approximately equal-sized chunks in the kernel for processing it more efficiently (The dataset cannot be loaded to a kernel at once!!). The code for processing the dataset with [Pandas][2] in the kernel is simple and easy to understand. So it can be helpful for kaggle/machine learning/data science beginners to learn how to process large dataset.\n\n[1]: https://www.kaggle.com/competitions/amex-default-prediction\n[2]: https://pandas.pydata.org/docs/","metadata":{}},{"cell_type":"markdown","source":"\n\n<b><div style='color:#9BD4F5;font-size:120%'>NOTE : When you want to save time to read, please check hidden \"Table of Contents\" (in the right side of notebook) first. All of topics are summarized in it, and you can jump to the item you want to check.</div></b>","metadata":{}},{"cell_type":"markdown","source":"The kernel may have several bugs/wrongs. I am happy to get your comments. Thank you in advance for your kind advice to make the kernel so NICE! and to make me NICE deep learning guy!!","metadata":{}},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>List of files that created in the kernel</div></b>","metadata":{}},{"cell_type":"markdown","source":"The following files will be created in the kernel, if configurations are not changed,\n- Chunked train metadata : \"/kaggle/working/train_data_chunk_#.parquet\",\n- Chunked test metadata : \"/kaggle/working/test_data_chunk_#.parquet\",\n- Compressed train labels : \"/kaggle/working/train_labels.parquet\",\n- Grouped names of features : \"/kaggle/working/features.json\",\n- Customer IDs decoding map for train metadata : \"/kaggle/working/customer_id_decoding_map_train.json\",\n- Customer IDs decoding map for test metadata : \"/kaggle/working/customer_id_decoding_map_test.json\".","metadata":{}},{"cell_type":"markdown","source":"# <b><span style='color:#016FD0;font-size:200%'>2 |</span><span style='color:#016FD0;font-size:200%'> Load Competition Dataset to the Kernel</span></b>","metadata":{}},{"cell_type":"markdown","source":"Load [\"American Express - Default Prediction\"][1] competition dataset to the kernel and check its contents. If you are beginner and don't know how to add competition data set to your kernel (notebook), the other kernels [\"Preview of Whale and Dolphin Dataset with Plotly/Matplotlib\"][2], [\"Plotly/Matplotlib による Whale&Dolphin データセットのプレビュー\"][3] can be useful (See Chapter 2 \"Preparation of dataset\".).\n\n[1]: https://www.kaggle.com/competitions/amex-default-prediction\n[2]: https://www.kaggle.com/code/acchiko/preview-of-whale-dolphin-dataset-with-plotly-matpl\n[3]: https://www.kaggle.com/code/acchiko/plotly-matplotlib-whale-dolphin","metadata":{}},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>List of files</div></b>","metadata":{}},{"cell_type":"code","source":"# Show list of files.\npath_to_dir_input = \"/kaggle/input/amex-default-prediction\"\n!ls {path_to_dir_input}","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:00:32.042974Z","iopub.execute_input":"2022-06-28T13:00:32.043358Z","iopub.status.idle":"2022-06-28T13:00:32.806939Z","shell.execute_reply.started":"2022-06-28T13:00:32.043327Z","shell.execute_reply":"2022-06-28T13:00:32.805838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Train metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Show contents of train metadata and number of lines.\npath_to_train_metadata = f\"{path_to_dir_input}/train_data.csv\"\n!echo \"Contents : \"\n!head -3 {path_to_train_metadata}\n!echo \"\"\n!echo \"Number of lines : \"\n!cat -n {path_to_train_metadata} | tail -1 | cut -f1","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:20:03.99416Z","iopub.execute_input":"2022-06-27T17:20:03.994687Z","iopub.status.idle":"2022-06-27T17:20:07.055222Z","shell.execute_reply.started":"2022-06-27T17:20:03.994638Z","shell.execute_reply":"2022-06-27T17:20:07.053626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Train labels</div></b>","metadata":{}},{"cell_type":"code","source":"# Show contents of train labels and number of lines.\npath_to_train_labels = f\"{path_to_dir_input}/train_labels.csv\"\n!echo \"Contents : \"\n!head -3 {path_to_train_labels}\n!echo \"\"\n!echo \"Number of lines : \"\n!cat -n {path_to_train_labels} | tail -1 | cut -f1","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:00:36.345621Z","iopub.execute_input":"2022-06-28T13:00:36.346751Z","iopub.status.idle":"2022-06-28T13:00:40.562788Z","shell.execute_reply.started":"2022-06-28T13:00:36.346693Z","shell.execute_reply":"2022-06-28T13:00:40.561715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Test metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Show contents of test metadata and number of lines.\npath_to_test_metadata = f\"{path_to_dir_input}/test_data.csv\"\n!echo \"Contents : \"\n!head -3 {path_to_test_metadata}\n!echo \"\"\n!echo \"Number of lines : \"\n!cat -n {path_to_test_metadata} | tail -1 | cut -f1","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:20:10.121208Z","iopub.execute_input":"2022-06-27T17:20:10.121591Z","iopub.status.idle":"2022-06-27T17:20:13.122531Z","shell.execute_reply.started":"2022-06-27T17:20:10.121554Z","shell.execute_reply":"2022-06-27T17:20:13.120942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Sample submission</div></b>","metadata":{}},{"cell_type":"code","source":"# Show contents of sample submission and number of lines.\npath_to_sample_submission = f\"{path_to_dir_input}/sample_submission.csv\"\n!echo \"Contents : \"\n!head -3 {path_to_sample_submission}\n!echo \"\"\n!echo \"Number of lines : \"\n!cat -n {path_to_sample_submission} | tail -1 | cut -f1","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:20:13.12476Z","iopub.execute_input":"2022-06-27T17:20:13.1284Z","iopub.status.idle":"2022-06-27T17:20:16.150884Z","shell.execute_reply.started":"2022-06-27T17:20:13.128333Z","shell.execute_reply":"2022-06-27T17:20:16.149476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#016FD0;font-size:200%'>3 |</span><span style='color:#016FD0;font-size:200%'> Split Train Metadata</span></b>","metadata":{}},{"cell_type":"markdown","source":"Load train metadata and split it to approximately equal-sized chunks. Configurations for splitting, such as number of chunks, path to chunks of metadata, type of data, etc., can be changed in the class \"Config\", if it is required.","metadata":{}},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Configuration for splitting train metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Set configuration for splitting train metadata.\nclass Config():\n    num_chunks = 10\n    encode_customer_ID = True\n    dtype_numerical = \"float32\" # \"float16\" is more appropriate for reducing memory usage, but it cannot be available for parquet file.\n    dtype_categorical = \"category\"\n    categorical_features = [\"B_30\", \"B_38\", \"D_114\", \"D_116\", \"D_117\", \"D_120\", \"D_126\", \"D_63\", \"D_64\", \"D_66\", \"D_68\"]\n    path_to_metadata = path_to_train_metadata # Path to original csv format metadata.\n    path_to_chunked_metadata = \"/kaggle/working/train_data_chunk_#.parquet\" # Basename of path to chunks of metadata. \"#\" will be replaced with id of chunk.","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:20:16.153687Z","iopub.execute_input":"2022-06-27T17:20:16.154239Z","iopub.status.idle":"2022-06-27T17:20:16.162764Z","shell.execute_reply.started":"2022-06-27T17:20:16.154187Z","shell.execute_reply":"2022-06-27T17:20:16.161505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Required libraries for splitting metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Import libs.\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport gc\nimport json","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:20:16.165083Z","iopub.execute_input":"2022-06-27T17:20:16.165594Z","iopub.status.idle":"2022-06-27T17:20:16.175934Z","shell.execute_reply.started":"2022-06-27T17:20:16.16554Z","shell.execute_reply":"2022-06-27T17:20:16.174432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Number of rows of train metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Define utility functions for getting number of rows of train metadata.\ndef getNumRows(path_to_metadata_csv):\n    \"\"\"Load first column of csv format metadata and extract total number of rows.\"\"\"\n    df = pd.read_csv(path_to_metadata_csv, usecols=[0])\n    return len(df)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:20:16.177695Z","iopub.execute_input":"2022-06-27T17:20:16.178964Z","iopub.status.idle":"2022-06-27T17:20:16.191267Z","shell.execute_reply.started":"2022-06-27T17:20:16.178907Z","shell.execute_reply":"2022-06-27T17:20:16.19018Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show number of rows of train metadata.\ngetNumRows(path_to_metadata_csv=Config.path_to_metadata)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:20:16.193291Z","iopub.execute_input":"2022-06-27T17:20:16.193771Z","iopub.status.idle":"2022-06-27T17:22:58.736208Z","shell.execute_reply.started":"2022-06-27T17:20:16.193723Z","shell.execute_reply":"2022-06-27T17:22:58.734268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Name of features</div></b>","metadata":{}},{"cell_type":"code","source":"# Define utility functions for getting name of features.\ndef getFeatures(path_to_metadata_csv):\n    \"\"\"Load first line of csv format metadata and extract names of features.\"\"\"\n    \n    # Load first line of metadata for getting names of features.\n    df = pd.read_csv(path_to_metadata_csv, nrows=1)\n    \n    # Define group of features.\n    features = {}\n    features[\"index\"] = [\"customer_ID\", \"S_2\"]\n    features[\"all\"] = [feature for feature in df.columns if feature not in features[\"index\"]]\n    \n    features[\"categorical\"] = Config.categorical_features\n    features[\"categorical_delinquency\"] = [feature for feature in features[\"categorical\"] if feature.startswith(\"D_\")]\n    features[\"categorical_balance\"] = [feature for feature in features[\"categorical\"] if feature.startswith(\"B_\")]\n    \n    features[\"numerical\"] = [feature for feature in features[\"all\"] if feature not in features[\"categorical\"]]\n    features[\"numerical_delinquency\"] = [feature for feature in features[\"numerical\"] if feature.startswith(\"D_\")]\n    features[\"numerical_spend\"] = [feature for feature in features[\"numerical\"] if feature.startswith(\"S_\")]\n    features[\"numerical_payment\"] = [feature for feature in features[\"numerical\"] if feature.startswith(\"P_\")]\n    features[\"numerical_balance\"] = [feature for feature in features[\"numerical\"] if feature.startswith(\"B_\")]\n    features[\"numerical_risk\"] = [feature for feature in features[\"numerical\"] if feature.startswith(\"R_\")]\n    \n    return features","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:22:58.740674Z","iopub.execute_input":"2022-06-27T17:22:58.742761Z","iopub.status.idle":"2022-06-27T17:22:58.758869Z","shell.execute_reply.started":"2022-06-27T17:22:58.742654Z","shell.execute_reply":"2022-06-27T17:22:58.757761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show grouped name of features.\nfeatures = getFeatures(path_to_metadata_csv=Config.path_to_metadata)\nfor group in features.keys():\n    print(f\"features[\\\"{group}\\\"] ({len(features[group])} features total) :\")\n    print(f\"  {features[group]}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:22:58.760559Z","iopub.execute_input":"2022-06-27T17:22:58.761798Z","iopub.status.idle":"2022-06-27T17:22:58.802589Z","shell.execute_reply.started":"2022-06-27T17:22:58.761758Z","shell.execute_reply":"2022-06-27T17:22:58.801292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Save grouped name of features as json for future use.\npath_to_features_json = \"/kaggle/working/features.json\"\nwith open(path_to_features_json, \"w\") as fout:\n    json.dump(features, fout)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:22:58.804405Z","iopub.execute_input":"2022-06-27T17:22:58.805388Z","iopub.status.idle":"2022-06-27T17:22:58.816875Z","shell.execute_reply.started":"2022-06-27T17:22:58.805342Z","shell.execute_reply":"2022-06-27T17:22:58.815483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Customer IDs in train metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Define utility functions for loading metadata.\ndef loadMetadata(path_to_metadata_csv, cols=None, index_range=None, encode_customer_ID=False):\n    \"\"\"Load specified row range and columns of csv format metadata with data type conversion.\"\"\"\n    \n    # Load first line of metadata (csv) and extract names of features.\n    features = getFeatures(path_to_metadata_csv)\n    \n    # Define dictionaries for data type conversion.\n    categorical_features_dtypes = dict.fromkeys(features[\"categorical\"], Config.dtype_categorical)\n    numerical_features_dtypes = dict.fromkeys(features[\"numerical\"], Config.dtype_numerical)\n    dtypes = dict(**categorical_features_dtypes, **numerical_features_dtypes)\n    \n    # Prepare args for read_csv().\n    kwargs = dict(parse_dates=[\"S_2\"], dtype=dtypes)\n    \n    if cols is not None:\n        cols.extend(features[\"index\"])\n        kwargs[\"usecols\"] = cols\n        \n    if index_range is not None:\n        skiprows, nrows = _toReadCsvArgs(index_range)\n        kwargs[\"skiprows\"] = skiprows\n        kwargs[\"nrows\"] = nrows\n        \n    if encode_customer_ID:\n        kwargs[\"converters\"] = {\"customer_ID\": encodeCustomerID}\n    \n    # Reload metadata from second line with data type conversion.\n    df = pd.read_csv(path_to_metadata_csv, **kwargs)\n    \n    return df\n\ndef _isValidRange(index_range, valid_range):\n    first_index, last_index = index_range\n    lower_limit, upper_limit = valid_range\n    \n    if first_index >= last_index:\n        return False\n    \n    if first_index < lower_limit or upper_limit < last_index:\n        return False\n    \n    return True\n    \ndef _toReadCsvArgs(index_range):\n    # Convert index range of dataframe to line numbers to skip (skiprows) and line number of rows to load (nrows).\n    # skiprows starts from 1 for keeping name of columns.\n    first_index, end_index = index_range\n    skiprows = range(1, first_index + 1)\n    nrows = (end_index - first_index) + 1\n    \n    return skiprows, nrows\n\ndef encodeCustomerID(customer_id):\n    return int(customer_id[-16:], 16)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T17:22:58.818767Z","iopub.execute_input":"2022-06-27T17:22:58.820152Z","iopub.status.idle":"2022-06-27T17:22:58.835414Z","shell.execute_reply.started":"2022-06-27T17:22:58.82011Z","shell.execute_reply":"2022-06-27T17:22:58.833408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Show customer IDs (If cols=[] is specified for loadMetadata(), only features[\"index\"] are loaded.).\nindices_df = loadMetadata(path_to_metadata_csv=Config.path_to_metadata, cols=[])\ncustomer_ids = indices_df[\"customer_ID\"].unique() # Uniques are returned in order of appearance. This does NOT sort.\ncustomer_ids","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:43:06.901101Z","iopub.execute_input":"2022-06-24T04:43:06.901817Z","iopub.status.idle":"2022-06-24T04:46:13.646364Z","shell.execute_reply.started":"2022-06-24T04:43:06.901779Z","shell.execute_reply":"2022-06-24T04:46:13.644504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b><div style='color:#9BD4F5;font-size:120%'>Tips : All customer IDs in train metadata are same as the ones in train labels? And is its order same?</div></b>","metadata":{}},{"cell_type":"code","source":"# Load train labels and compare it with customer IDs in train metadata for answering the question.\ntrain_labels = pd.read_csv(path_to_train_labels, usecols=[\"customer_ID\"])\n\"Yes\" if customer_ids.tolist() == train_labels[\"customer_ID\"].tolist() else \"No\"","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:46:13.649692Z","iopub.execute_input":"2022-06-24T04:46:13.650101Z","iopub.status.idle":"2022-06-24T04:46:14.535529Z","shell.execute_reply.started":"2022-06-24T04:46:13.650062Z","shell.execute_reply":"2022-06-24T04:46:14.534507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Encoded customer IDs in train metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Show first 3 encoded customer IDs as example.\nencoded_customer_ids = [encodeCustomerID(customer_id) for customer_id in customer_ids]\nencoded_customer_ids[:3]","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:46:14.536866Z","iopub.execute_input":"2022-06-24T04:46:14.537214Z","iopub.status.idle":"2022-06-24T04:46:14.779916Z","shell.execute_reply.started":"2022-06-24T04:46:14.537175Z","shell.execute_reply":"2022-06-24T04:46:14.778695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create map for decoding customer IDs and save it as json for future use.\ndecoding_map = dict(zip(encoded_customer_ids, customer_ids))\n\npath_to_decoding_map_json = \"/kaggle/working/customer_id_decoding_map_train.json\"\nwith open(path_to_decoding_map_json, \"w\") as fout:\n    json.dump(decoding_map, fout)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Memory cleaning</div></b>","metadata":{}},{"cell_type":"code","source":"# Clean memory, if it is required.\ndel indices_df, customer_ids, train_labels, encoded_customer_ids, decoding_map\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T04:46:14.781432Z","iopub.execute_input":"2022-06-24T04:46:14.781888Z","iopub.status.idle":"2022-06-24T04:46:15.051296Z","shell.execute_reply.started":"2022-06-24T04:46:14.781828Z","shell.execute_reply":"2022-06-24T04:46:15.050046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Chunk of train metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Define utility functions for splitting metadata.\ndef splitMetadata(path_to_metadata_csv, num_chunks, path_to_chunked_metadata_basename):\n    \"\"\"Load metadata and split it to approximately equal-sized chunks.\"\"\"\n    \n    # Load metadata and extract unique customer IDs.\n    indices_df = loadMetadata(path_to_metadata_csv=path_to_metadata_csv, cols=[], encode_customer_ID=Config.encode_customer_ID)\n    customer_ids = indices_df[\"customer_ID\"].unique()\n    \n    # Split customer IDs.\n    chunked_customer_ids = np.array_split(ary=customer_ids, indices_or_sections=num_chunks)\n    \n    # Split metadata.\n    for chunk_id, chunked_customer_ids_ in enumerate(tqdm(chunked_customer_ids, desc=\"Splitting metadata ...\")):\n        # Load metadata for chunked customers ids.\n        start_index = _getFirstRowIndex(df=indices_df, customer_id=chunked_customer_ids_[0])\n        end_index = _getLastRowIndex(df=indices_df, customer_id=chunked_customer_ids_[-1])\n        index_range = (start_index, end_index)\n        chunked_metadata = loadMetadata(path_to_metadata_csv=path_to_metadata_csv, index_range=index_range, encode_customer_ID=Config.encode_customer_ID)\n        \n        # Save chunked metadata.\n        path_to_chunked_metadata = path_to_chunked_metadata_basename.replace(\"#\", f\"{chunk_id:03d}\")\n        chunked_metadata.to_parquet(path_to_chunked_metadata)\n        \ndef _getFirstRowIndex(df, customer_id):\n    #return df.query(f\"customer_ID == '{customer_id}'\").index[0]  # NOT works for encoded customer ID.\n    return df[df[\"customer_ID\"] == customer_id].index[0]\n\ndef _getLastRowIndex(df, customer_id):\n    #return df.query(f\"customer_ID == '{customer_id}'\").index[-1]  # NOT works for encoded customer ID.\n    return df[df[\"customer_ID\"] == customer_id].index[-1]","metadata":{"execution":{"iopub.status.busy":"2022-06-24T05:03:19.410923Z","iopub.execute_input":"2022-06-24T05:03:19.411383Z","iopub.status.idle":"2022-06-24T05:03:19.423106Z","shell.execute_reply.started":"2022-06-24T05:03:19.411348Z","shell.execute_reply":"2022-06-24T05:03:19.421908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load metadata and split it to approximately equal-sized chunks.\nsplitMetadata(path_to_metadata_csv=Config.path_to_metadata, num_chunks=Config.num_chunks, path_to_chunked_metadata_basename=Config.path_to_chunked_metadata)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T05:03:22.923648Z","iopub.execute_input":"2022-06-24T05:03:22.924597Z","iopub.status.idle":"2022-06-24T05:22:43.459881Z","shell.execute_reply.started":"2022-06-24T05:03:22.924553Z","shell.execute_reply":"2022-06-24T05:22:43.456989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#016FD0;font-size:200%'>4 |</span><span style='color:#016FD0;font-size:200%'> Split Test Metadata</span></b>","metadata":{}},{"cell_type":"markdown","source":"Load test metadata and split it to approximately equal-sized chunks. Configurations for splitting, such as number of chunks, path to chunks of metadata, type of data, etc., can be changed in the class \"Config\", if it is required.","metadata":{}},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Configuration for splitting test metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Set configuration for splitting test metadata.\nclass Config():\n    num_chunks = 20\n    encode_customer_ID = True\n    dtype_numerical = \"float32\" # \"float16\" is more appropriate for reducing memory usage, but it cannot be available for parquet file.\n    dtype_categorical = \"category\"\n    categorical_features = [\"B_30\", \"B_38\", \"D_114\", \"D_116\", \"D_117\", \"D_120\", \"D_126\", \"D_63\", \"D_64\", \"D_66\", \"D_68\"]\n    path_to_metadata = path_to_test_metadata # Path to original csv format metadata.\n    path_to_chunked_metadata = \"/kaggle/working/test_data_chunk_#.parquet\" # Basename of path to chunks of metadata. \"#\" will be replaced with id of chunk.","metadata":{"execution":{"iopub.execute_input":"2022-06-22T12:26:47.809409Z","iopub.status.busy":"2022-06-22T12:26:47.809064Z","iopub.status.idle":"2022-06-22T12:26:47.818163Z","shell.execute_reply":"2022-06-22T12:26:47.817Z","shell.execute_reply.started":"2022-06-22T12:26:47.809375Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Number of rows of test metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Show number of rows of test metadata.\ngetNumRows(path_to_metadata_csv=Config.path_to_metadata)","metadata":{"execution":{"iopub.execute_input":"2022-06-22T12:26:47.848366Z","iopub.status.busy":"2022-06-22T12:26:47.847651Z","iopub.status.idle":"2022-06-22T12:30:49.216466Z","shell.execute_reply":"2022-06-22T12:30:49.21524Z","shell.execute_reply.started":"2022-06-22T12:26:47.848324Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Customer IDs in test metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Show customer IDs (If cols=[] is specified for loadMetadata(), only features[\"index\"] are loaded.).\nindices_df = loadMetadata(path_to_metadata_csv=Config.path_to_metadata, cols=[])\ncustomer_ids = indices_df[\"customer_ID\"].unique()\ncustomer_ids","metadata":{"execution":{"iopub.execute_input":"2022-06-22T12:30:49.291579Z","iopub.status.busy":"2022-06-22T12:30:49.291205Z","iopub.status.idle":"2022-06-22T12:34:05.91594Z","shell.execute_reply":"2022-06-22T12:34:05.914942Z","shell.execute_reply.started":"2022-06-22T12:30:49.291549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Number of customer IDs in test metadata</div></b>","metadata":{}},{"cell_type":"code","source":"len(customer_ids)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Encoded customer IDs in test metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Show first 3 encoded customer IDs as example.\nencoded_customer_ids = [encodeCustomerID(customer_id) for customer_id in customer_ids]\nencoded_customer_ids[:3]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create map for decoding customer IDs and save it as json for future use.\ndecoding_map = dict(zip(encoded_customer_ids, customer_ids))\n\npath_to_decoding_map_json = \"/kaggle/working/customer_id_decoding_map_test.json\"\nwith open(path_to_decoding_map_json, \"w\") as fout:\n    json.dump(decoding_map, fout)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Memory cleaning</div></b>","metadata":{}},{"cell_type":"code","source":"# Clean memory, if it is required.\ndel indices_df, customer_ids, encoded_customer_ids, decoding_map\ngc.collect()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Chunk of test metadata</div></b>","metadata":{}},{"cell_type":"code","source":"# Load test metadata and split it to approximately equal-sized chunks.\nsplitMetadata(path_to_metadata_csv=Config.path_to_metadata, num_chunks=Config.num_chunks, path_to_chunked_metadata_basename=Config.path_to_chunked_metadata)","metadata":{"execution":{"iopub.execute_input":"2022-06-22T12:44:51.266278Z","iopub.status.busy":"2022-06-22T12:44:51.264185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><span style='color:#016FD0;font-size:200%'>4 |</span><span style='color:#016FD0;font-size:200%'> Compress Train Labels</span></b>","metadata":{}},{"cell_type":"markdown","source":"Load train labels and compress it. Configurations for compressing, such as path to compressed labels, type of data, etc., can be changed in the class \"Config\", if it is required.","metadata":{}},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Configuration for compressing train labels</div></b>","metadata":{}},{"cell_type":"code","source":"# Set configuration for compressing train metadata.\nclass Config():\n    encode_customer_ID = True\n    dtype_target = \"category\"\n    path_to_labels = path_to_train_labels # Path to original csv format labels.\n    path_to_labels_parquet = \"/kaggle/working/train_labels.parquet\" # Path to parquet format labels.","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:00:56.166888Z","iopub.execute_input":"2022-06-28T13:00:56.167337Z","iopub.status.idle":"2022-06-28T13:00:56.173726Z","shell.execute_reply.started":"2022-06-28T13:00:56.167295Z","shell.execute_reply":"2022-06-28T13:00:56.172379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <b><div style='padding:20px;background-color:#636364;color:white;border-radius:5px;font-size:80%'>Compressed train labels</div></b>","metadata":{}},{"cell_type":"code","source":"# Define utility functions for loading metadata.\ndef loadLabels(path_to_labels_csv, encode_customer_ID=False):\n    \"\"\"Load csv format labels with data type conversion.\"\"\"\n    \n    # Define dictionaries for data type conversion.\n    dtypes = {\"target\": Config.dtype_target}\n    \n    # Prepare args for read_csv().\n    kwargs = dict(dtype=dtypes)\n    \n    if encode_customer_ID:\n        kwargs[\"converters\"] = {\"customer_ID\": encodeCustomerID}\n    \n    # Load lables with data type conversion.\n    df = pd.read_csv(path_to_labels_csv, **kwargs)\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2022-06-28T13:01:13.794129Z","iopub.execute_input":"2022-06-28T13:01:13.794517Z","iopub.status.idle":"2022-06-28T13:01:13.801824Z","shell.execute_reply.started":"2022-06-28T13:01:13.794486Z","shell.execute_reply":"2022-06-28T13:01:13.800407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load train labels with data type conversion.\ntrain_labels = loadLabels(Config.path_to_labels, encode_customer_ID=Config.encode_customer_ID)\ntrain_labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Saves train labels.\ntrain_labels.to_parquet(Config.path_to_labels_parquet)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<b><div style='padding:20px;background-color:#016FD0;color:white;border-radius:5px;font-size:700%'>Thank you for reading!!</div></b>","metadata":{}}]}