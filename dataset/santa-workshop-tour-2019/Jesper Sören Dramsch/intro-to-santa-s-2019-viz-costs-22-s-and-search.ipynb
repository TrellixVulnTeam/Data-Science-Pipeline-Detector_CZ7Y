{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, we'll go through some exploratory data analysis, visualize these data points to gain deeper insights, and then build the cost function according to the problem formulation and do a bit of a search for the optimum.\n\n# The Problem\n![Santa](https://i.imgur.com/reXzZWf.jpg)\n\nSanta's worhshop runs like a well-oiled machine and the accountants run a tight ship. Let's have a look at how we can accommodate as many families as possible without breaking the bank entirely.\n\n## The Deets:\n- 5,000 families\n-   100 days\n- 125 to 300 per day (hard limit)\n\n## The Costs:\n### Consolation Gifts:\n\nThis should be interesting to look at. Every choice has a cost and the lower we go in priority, the more gratuitous we get with the families. Look at `9` and `++` getting helicopter rides for each person. Ooph!\n\n| `choice` | Gift Card  | Buffet  | Helicopter |\n|----------|------------|---------|------------|\n|          | (fixed)    | (per P) | (per P)    |\n| 0        | 0          | 0       | 0          |\n| 1        | 50         | 0       | 0          |\n| 2        | 50         | 9       | 0          |\n| 3        | 100        | 9       | 0          |\n| 4        | 200        | 9       | 0          |\n| 5        | 200        | 18      | 0          |\n| 6        | 300        | 18      | 0          |\n| 7        | 300        | 36      | 0          |\n| 8        | 400        | 36      | 0          |\n| 9        | 500        | 36      | 199        |\n| ++       | 500        | 36      | 398        |\n\n### Accounting:\nAccounting runs a tight, recursive ship. $N_d$ is the number of occupants on the day $d$. Starting 100 days before, working your way towards Christmas.\n\n$$\\text{accounting penalty} = \\sum\\limits_{d=100}^1 \\frac{N_d - 125}{400} \\cdot N_d^{\\left(0.5 + \\frac{\\left|N_d - N_{d+1}\\right|}{50}\\right)}$$\n\n## Sources:\n\nBlatantly copying stuff from these notebooks. Give them an upvote!\n\n- https://www.kaggle.com/inversion/santa-s-2019-starter-notebook (Get a good initial idea)\n- https://www.kaggle.com/chewzy/santa-finances-a-closer-look-at-the-costs (Nice EDA)\n- https://www.kaggle.com/nickel/santa-s-2019-fast-pythonic-cost-23-s (Really fast Pythonic cost, which I adapted)\n- https://www.kaggle.com/xhlulu/santa-s-2019-stochastic-product-search (Great impementation of random search, which I adapted)\n- https://www.kaggle.com/ilu000/greedy-dual-and-tripple-shuffle-with-fast-scoring (Better data, which I'm using in the newer kernels.)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom numba import njit\nfrom itertools import product\nfrom time import time\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nstart_time = time()\nend_time = start_time + (7.5 *60 *60)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"fpath = '/kaggle/input/santa-workshop-tour-2019/family_data.csv'\ndata = pd.read_csv(fpath, index_col='family_id')\n\nfpath = '/kaggle/input/santa-workshop-tour-2019/sample_submission.csv'\nsubmission = pd.read_csv(fpath, index_col='family_id')\n\nfpath = '/kaggle/input/santa-s-2019-stochastic-product-search/submission_76177.csv'\nprediction = pd.read_csv(fpath, index_col='family_id').assigned_day.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"family_sizes = data.n_people.values.astype(np.int8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Families Visualized\nQuick look at the data and the distribution of family sizes and all that jazz. The families seem to be be mostly smaller than 5 families, and most would like to go right before Christmas, let's dive in:"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Average number of people per day:\", sum(data['n_people'])//100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"family_size = data['n_people'].value_counts().sort_index()\nfamily_size /= 50\n\nplt.figure(figsize=(14,6))\nax = sns.barplot(x=family_size.index, y=family_size.values)\n\nax.set_ylim(0, 1.1*max(family_size))\nplt.xlabel('Family Size', fontsize=14)\nplt.ylabel('Percentage', fontsize=14)\nplt.title('Members in Family', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No surprises there. Most families between 2 and 5 with 4 being the highest. Some families in the long tail, sadly lacking information whether they're catholic."},{"metadata":{"trusted":true},"cell_type":"code","source":"fave_day = data['choice_0'].value_counts().sort_index()\n\nplt.figure(figsize=(14,6))\nax = sns.barplot(x=fave_day.index, y=fave_day.values)\n\n\nplt.xlabel('$\\Leftarrow$ Christmas this way!', fontsize=14)\nplt.ylabel('Wishes', fontsize=14)\nplt.title('Primary Choice', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ninthfave_day = data['choice_9'].value_counts().sort_index()\n\nplt.figure(figsize=(14,6))\nax = sns.barplot(x=ninthfave_day.index, y=ninthfave_day.values)\n\n\nplt.xlabel('$\\Leftarrow$ Christmas this way!', fontsize=14)\nplt.ylabel('Wishes', fontsize=14)\nplt.title('Last Choice', fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, Christmas day is the most wished for clearly. In between there are the weekends pretty steady. The weekday wishes decrease towards the farther days. This holds for the first as much as the last.\n\nLet's look at some costs:"},{"metadata":{},"cell_type":"markdown","source":"# Costs Visualized\nSet up a dict, because they're cheap and we only need two values accessible. We can use this one for later hopefully. Array would probably be fine though. I'm no software engineer."},{"metadata":{"trusted":true},"cell_type":"code","source":"cost_dict = {0:  [  0,  0],\n             1:  [ 50,  0],\n             2:  [ 50,  9],\n             3:  [100,  9],\n             4:  [200,  9],\n             5:  [200, 18],\n             6:  [300, 18],\n             7:  [300, 36],\n             8:  [400, 36],\n             9:  [500, 36 + 199],\n             10: [500, 36 + 398],\n            }\n\ndef cost(choice, members, cost_dict):\n    x = cost_dict[choice]\n    return x[0] + members * x[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at all the costs for each choice for each family. In the image, I'm dropping the choices `0` and `1`, because they're boring (constant for any number of members). \n\nIt's really clear there is a big cliff for `choice_9` and `otherwise`, helicopters gonna helicopter."},{"metadata":{"trusted":true},"cell_type":"code","source":"all_costs = {k: pd.Series([cost(k, x, cost_dict) for x in range(2,9)], index=range(2,9)) for k in cost_dict.keys()}\ndf_all_costs = pd.DataFrame(all_costs)\nplt.figure(figsize=(14,11))\nsns.heatmap(df_all_costs.drop([0, 1],axis=1), annot=True, fmt=\"g\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(14,11))\nsns.heatmap(df_all_costs.drop([0, 1, 9, 10],axis=1), annot=True, fmt=\"g\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We need this one to get a quick cost calculation and to be quite honest, we don't need to look at it technically, but the barcode is kinda cool:"},{"metadata":{"trusted":true},"cell_type":"code","source":"family_cost_matrix = np.zeros((100,len(family_sizes))) # Cost for each family for each day.\n\nfor i, el in enumerate(family_sizes):\n    family_cost_matrix[:, i] += all_costs[10][el] # populate each day with the max cost\n    for j, choice in enumerate(data.drop(\"n_people\",axis=1).values[i,:]):\n        family_cost_matrix[choice-1, i] = all_costs[j][el] # fill wishes into cost matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(40,10))\nsns.heatmap(family_cost_matrix)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Accounting Visualized\nIt seems accounting can throw us off a bit. I cliped it to 4k similar to the gift-cards to make a point. But if you go to the maximum in the corner, the cost easily outpaces paying off every family to stay home.\n\nThat's why you always take care off accounting."},{"metadata":{"trusted":true},"cell_type":"code","source":"def accounting(today, previous):\n    return ((today - 125) / 400 ) * today ** (.5 + (abs(today - previous) / 50))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc_costs = np.zeros([176,176])\n\nfor i, x in enumerate(range(125,300+1)):\n    for j, y in enumerate(range(125,300+1)):\n        acc_costs[i,j] = accounting(x,y)\n\nplt.figure(figsize=(10,10))\nplt.imshow(np.clip(acc_costs, 0, 4000))\nplt.title('Accounting Cost')\nplt.colorbar()\n\nprint(\"The maximum cost is a ridiculous:\", acc_costs.max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Optimized Cost Function [22μs]\nThis means we can now look up all of the costs for the actual optimization.\n\nEveryone would love to come on the weekend and of course on the day before Christmas, but ideally we should smooth it out somehow, so accounting doesn't bite us."},{"metadata":{"trusted":true},"cell_type":"code","source":"@njit(fastmath=True)\ndef cost_function(prediction, family_size, family_cost_matrix, accounting_cost_matrix):\n    N_DAYS = 100\n    MAX_OCCUPANCY = 300\n    MIN_OCCUPANCY = 125\n    penalty = 0\n    accounting_cost = 0\n    max_occ = False\n    \n    daily_occupancy = np.zeros(N_DAYS + 1, dtype=np.int16)\n    for i, (pred, n) in enumerate(zip(prediction, family_size)):\n        daily_occupancy[pred - 1] += n\n        penalty += family_cost_matrix[pred - 1, i]\n        \n    daily_occupancy[-1] = daily_occupancy[-2]\n    for day in range(N_DAYS):\n        n_next = daily_occupancy[day + 1]\n        n = daily_occupancy[day]\n        max_occ += MIN_OCCUPANCY > n\n        max_occ += MAX_OCCUPANCY < n\n        accounting_cost += accounting_cost_matrix[n-MIN_OCCUPANCY, n_next-MIN_OCCUPANCY]\n    if max_occ: \n        return 1e11\n    return penalty + accounting_cost","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cost_function(prediction, family_sizes, family_cost_matrix, acc_costs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit cost_function(prediction, family_sizes, family_cost_matrix, acc_costs)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aw yiss. Thanks Crescenzi. I did choose not to return an array, but just a single cost, which apparently shaves off another $\\mu s$, not sure if that matters. Let's use the [stochastic product search](https://www.kaggle.com/xhlulu/santa-s-2019-stochastic-product-search/data), because it seems really cool. Let's do two long rounds as well, this is a slight modification not using tqdm, I think more modifications would be great to make it work even better.\n\n# Versatile Stochastic Search"},{"metadata":{"trusted":true},"cell_type":"code","source":"def stochastic_product_search(original, choice_matrix, top_k=2, num_fam=8, \n                              n_time=None, n_iter=None, early_stop=np.inf,\n                              decrease=np.inf, random_state=42, verbose=1e4):\n    \"\"\"Randomly sample families, reassign and evaluate.\n    \n    At every iterations, randomly sample num_fam families. Then, given their top_k\n    choices, compute the Cartesian product of the families' choices, and compute the\n    score for each of those top_k^num_fam products.\n    \n    Both n_time and n_iter can be set, optimization stops when first one is reached.\n    \n    Arguments:\n        original {1d Array} -- Initial assignment of families\n        choice_matrix {2d Array} -- Choices of each family\n    \n    Keyword Arguments:\n        top_k {int} -- Number of choices to include (default: {2})\n        num_fam {int} -- Number of families to sample (default: {8})\n        n_time {int} -- Maximum execution time (default: {None})\n        n_iter {int} -- Maximum number of executions (default: {None})\n        early_stop {int} -- Stop after number of stagnant iterations (default: {np.inf})\n        decrease {int} -- Decrease num_fam after number of stagnant iterations (default: {np.inf})\n        random_state {int} -- Set NumPy random state for reproducibility (default: {42})\n        verbose {int} -- Return current best after number of iterations (default: {1e4})\n    \n    Example:\n        best = stochastic_product_search(\n        choice_matrix=data.drop(\"n_people\", axis=1).values, \n        top_k=3,\n        num_fam=16, \n        original=prediction,\n        n_time=int(3600),\n        n_iter=int(1e5),\n        early_stop=5e6,\n        decrease=5e4,\n        verbose=int(5e3),\n        )\n    \n    Returns:\n        [1d Array] -- Best assignment of families\n    \"\"\"\n    np.random.seed(random_state)\n    \n    i = 0\n    early_i = 0\n    opt_time = time()  \n    \n    if n_time:\n        max_time = opt_time + n_time\n    else:\n        max_time = opt_time\n    \n    if n_iter:\n        max_iter = n_iter\n    else:\n        max_iter = 0\n    \n    best = original.copy()\n    best_score = cost_function(best, family_sizes, family_cost_matrix, acc_costs)\n    \n    while ((max_time - time() > 0) or (not n_time)) and ((i < max_iter) or (not n_iter)) and (early_i < early_stop):\n        fam_indices = np.random.choice(choice_matrix.shape[0], size=num_fam)\n        \n        for change in np.array(np.meshgrid(*choice_matrix[fam_indices, :top_k])).T.reshape(-1,num_fam):\n            new = best.copy()\n            new[fam_indices] = change\n\n            new_score = cost_function(new, family_sizes, family_cost_matrix, acc_costs)\n\n            if new_score < best_score:\n                best_score = new_score\n                best = new\n                early_i = 0\n            else:\n                early_i += 1/num_fam\n        \n        if (early_i > decrease) and (num_fam > 2):\n            num_fam -= 1\n            early_i = 0\n            if verbose:\n                print(f\"Decreasing sampling size to {num_fam}.\")\n                \n            \n        if verbose and i % verbose == 0:\n            print(f\"Iteration {i:05d}:\\t Best score is {best_score:.2f}\\t after {(time()-opt_time)//60:.0f} minutues {(time()-opt_time)%60:.0f} seconds.\")\n        i += 1\n    \n    print(f\"Final best score is {best_score:.2f} after {(time()-opt_time)//60:.0f} minutues {(time()-opt_time)%60:.0f} seconds.\")\n    print(f\"Each loop took {1000*(time()-opt_time)/i:.2f} ms.\")\n    return best","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is just a quick demonstration for the kernel:"},{"metadata":{"trusted":true},"cell_type":"code","source":"best = stochastic_product_search(\n    prediction,\n    choice_matrix=data.drop(\"n_people\", axis=1).values, \n    top_k=1,\n    num_fam=32, \n    n_time=int(60),\n    early_stop=5e6,\n    decrease=5e4,\n    verbose=int(5e3),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's just bundle this up and send it off to the elves."},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['assigned_day'] = best\nfinal_score = cost_function(best, family_sizes, family_cost_matrix, acc_costs)\nsubmission.to_csv(f'submission_{int(final_score)}.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Happy Kaggling\nI think we can clearly improve this further, large families seem quite costly and there's a trade-off between caching solutions and simply calculating them, considering the optimization of the cost function. Nevertheless, random search seems to be a pretty good fit for this problem. Maybe Genetic algorithms would also work. Either way, this is a small overview over the data analysis. \n\nDon't forget to upvote the other kernels, they did amazing work."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}