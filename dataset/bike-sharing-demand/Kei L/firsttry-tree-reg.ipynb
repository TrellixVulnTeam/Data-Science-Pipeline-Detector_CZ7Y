{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib as mpl\nmpl.rcParams['agg.path.chunksize'] = 10000\nimport matplotlib.pyplot as plt\n\nimport datetime\n\nfrom IPython.display import display\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 200)\npd.set_option(\"display.max_colwidth\", 10000)\npd.set_option(\"display.float_format\", lambda x: \"%.2f\" % x)\n    \nplt.rcParams['font.size'] = 15","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load csv Data","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")\ndf_test = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(df_train.shape)\nprint(df_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 前処理","metadata":{}},{"cell_type":"markdown","source":"## datetimeについて","metadata":{}},{"cell_type":"code","source":"df_train['datetime'] = pd.to_datetime(df_train['datetime'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['year'] = df_train['datetime'].apply(lambda x: x.strftime('%Y'))\ndf_train['month']= df_train['datetime'].apply(lambda x: x.strftime('%m'))\ndf_train['day'] = df_train['datetime'].apply(lambda x: x.strftime('%d'))\ndf_train['hour'] = df_train['datetime'].apply(lambda x: x.strftime('%H'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 不要な列削除","metadata":{}},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = df_train.drop(['atemp', 'casual', 'registered'], axis=1)\n#df_train = df_train.drop(['datetime', 'month', 'day'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 学習準備","metadata":{}},{"cell_type":"code","source":"y_train = df_train['count'].copy()       # Target\nX_train = df_train.drop('count', axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nnum_pipeline = Pipeline([\n        #('imputer', SimpleImputer(strategy='constant', fill_value=0)), //今回欠損値がない\n        #('attribs_adder', CombinedAttributesAdder()) // これを追加することでFeatureの重要性を示す\n        ('std_scaler', StandardScaler()), \n    ])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.compose import ColumnTransformer\n\nnum_feats = ['temp', 'humidity', 'windspeed']\ncat_feats = ['season','workingday', 'holiday', 'weather','year','hour'] \n\nfull_pipeline = ColumnTransformer([\n    ('num', num_pipeline, num_feats),\n    ('cat', OneHotEncoder(), cat_feats)\n])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train_prepared = full_pipeline.fit_transform(X_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_cols = full_pipeline.named_transformers_.cat.get_feature_names().tolist()\ncols_prepared = num_feats + encoded_cols","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modeling ","metadata":{}},{"cell_type":"markdown","source":"## DecisionTreeRegressor","metadata":{}},{"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\n\ntree_reg = DecisionTreeRegressor()\ntree_reg.fit(X_train_prepared, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n\ncount_predictions = tree_reg.predict(X_train_prepared)\ntree_msle = np.sqrt(mean_squared_log_error(y_train, count_predictions))\ntree_msle","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissions","metadata":{}},{"cell_type":"code","source":"df_test['datetime'] = pd.to_datetime(df_test['datetime'])\ndf_test['year'] = df_test['datetime'].apply(lambda x: x.strftime('%Y'))\ndf_test['month']= df_test['datetime'].apply(lambda x: x.strftime('%m'))\ndf_test['day'] = df_test['datetime'].apply(lambda x: x.strftime('%d'))\ndf_test['hour'] = df_test['datetime'].apply(lambda x: x.strftime('%H'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = df_test.drop(['atemp'], axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test_prepared = full_pipeline.fit_transform(df_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"final_preds = tree_reg.predict(X_test_prepared)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_dt = df_test.loc[:, 'datetime']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({\"datetime\":submission_dt, \"count\":final_preds})\nsubmission.to_csv(\"tree_reg_v1.csv\", index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}