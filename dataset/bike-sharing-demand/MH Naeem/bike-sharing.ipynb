{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv(\"../input/bike-sharing-demand/train.csv\")\ntest = pd.read_csv(\"../input/bike-sharing-demand/test.csv\")\nsubmission = pd.read_csv(\"../input/bike-sharing-demand/sampleSubmission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:34.875475Z","iopub.execute_input":"2021-09-03T06:21:34.8761Z","iopub.status.idle":"2021-09-03T06:21:35.103617Z","shell.execute_reply.started":"2021-09-03T06:21:34.875952Z","shell.execute_reply":"2021-09-03T06:21:35.102074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data_temp = pd.concat([train, test])\nall_data_temp","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.108173Z","iopub.execute_input":"2021-09-03T06:21:35.108854Z","iopub.status.idle":"2021-09-03T06:21:35.167188Z","shell.execute_reply.started":"2021-09-03T06:21:35.108794Z","shell.execute_reply":"2021-09-03T06:21:35.165865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.169651Z","iopub.execute_input":"2021-09-03T06:21:35.170203Z","iopub.status.idle":"2021-09-03T06:21:35.21175Z","shell.execute_reply.started":"2021-09-03T06:21:35.170148Z","shell.execute_reply":"2021-09-03T06:21:35.210237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Feature Engineering","metadata":{}},{"cell_type":"code","source":"from datetime import datetime\n\nall_data['date'] = all_data['datetime'].apply(lambda x: x.split()[0]) # Create date feature\nall_data['year'] = all_data['datetime'].apply(lambda x: x.split()[0].split('-')[0]) # Create year feature\nall_data['month'] = all_data['datetime'].apply(lambda x: x.split()[0].split('-')[1]) # Create month feature\nall_data['hour'] = all_data['datetime'].apply(lambda x: x.split()[1].split(':')[0]) # Create hour feature\nall_data[\"weekday\"] = all_data['date'].apply(lambda dateString : datetime.strptime(dateString,\"%Y-%m-%d\").weekday()) # Create weekday feature","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.214089Z","iopub.execute_input":"2021-09-03T06:21:35.214568Z","iopub.status.idle":"2021-09-03T06:21:35.504048Z","shell.execute_reply.started":"2021-09-03T06:21:35.214528Z","shell.execute_reply":"2021-09-03T06:21:35.50253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Change categorical data type for memory reduction","metadata":{}},{"cell_type":"code","source":"categorical_features = ['season', 'holiday', 'workingday', 'weather', 'weekday', 'month', 'year', 'hour']\n\nfor feature in categorical_features:\n    all_data[feature] = all_data[feature].astype(\"category\")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.505693Z","iopub.execute_input":"2021-09-03T06:21:35.506058Z","iopub.status.idle":"2021-09-03T06:21:35.534626Z","shell.execute_reply.started":"2021-09-03T06:21:35.506024Z","shell.execute_reply":"2021-09-03T06:21:35.533729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = all_data[pd.notnull(all_data['count'])]\ntest = all_data[~pd.notnull(all_data['count'])]\ny = train['count']","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.535799Z","iopub.execute_input":"2021-09-03T06:21:35.536272Z","iopub.status.idle":"2021-09-03T06:21:35.553607Z","shell.execute_reply.started":"2021-09-03T06:21:35.536239Z","shell.execute_reply":"2021-09-03T06:21:35.552634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Drop useless features","metadata":{}},{"cell_type":"code","source":"drop_features = ['count', 'casual', 'registered', 'datetime', 'date', 'datetime', 'windspeed', 'month']\n\nX_train = train.drop(drop_features, axis=1)\nX_test = test.drop(drop_features, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.554785Z","iopub.execute_input":"2021-09-03T06:21:35.555292Z","iopub.status.idle":"2021-09-03T06:21:35.56324Z","shell.execute_reply.started":"2021-09-03T06:21:35.555257Z","shell.execute_reply":"2021-09-03T06:21:35.562269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check final features and types","metadata":{}},{"cell_type":"code","source":"X_train.info()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.565632Z","iopub.execute_input":"2021-09-03T06:21:35.566134Z","iopub.status.idle":"2021-09-03T06:21:35.603591Z","shell.execute_reply.started":"2021-09-03T06:21:35.566083Z","shell.execute_reply":"2021-09-03T06:21:35.602319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Evaluation score(RMSLE) function","metadata":{}},{"cell_type":"code","source":"def rmsle(y_true, y_pred, convertExp=True):\n    # Apply exponential transformation function\n    if convertExp:\n        y_true = np.exp(y_true)\n        y_pred = np.exp(y_pred)\n        \n    # Convert missing value to zero after log transformation\n    log_true = np.nan_to_num(np.array([np.log(y+1) for y in y_true]))\n    log_pred = np.nan_to_num(np.array([np.log(y+1) for y in y_pred]))\n    \n    # Compute RMSLE\n    output = np.sqrt(np.mean((log_true - log_pred)**2))\n    return output","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.605628Z","iopub.execute_input":"2021-09-03T06:21:35.606044Z","iopub.status.idle":"2021-09-03T06:21:35.613541Z","shell.execute_reply.started":"2021-09-03T06:21:35.605996Z","shell.execute_reply":"2021-09-03T06:21:35.612562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear regression model","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\n# Step 1: Create Model\nlinear_reg_model = LinearRegression()\n\n# Step 2: Train Model\nlog_y = np.log1p(y)  # Log Transformation of Target Value y\nlinear_reg_model.fit(X_train, log_y) \n\n# Step 3 : Predict\npreds = linear_reg_model.predict(X_train)\n\n# Step 4 : Evaluate\nprint ('Linear Regression RMSLE:', rmsle(log_y, preds, True))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:35.615146Z","iopub.execute_input":"2021-09-03T06:21:35.615671Z","iopub.status.idle":"2021-09-03T06:21:37.165738Z","shell.execute_reply.started":"2021-09-03T06:21:35.615623Z","shell.execute_reply":"2021-09-03T06:21:37.164442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ridge Model (Apply Gridsearch)","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Ridge\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\n\n# Step 1: Create Model\nridge_model = Ridge()\n\n# Step 2-1 : Create GridSearchCV Object\n# Hyper-parameter List\nridge_params = {'max_iter':[3000], 'alpha':[0.1, 1, 2, 3, 4, 10, 30, 100, 200, 300, 400, 800, 900, 1000]}\n# Evaluate Function for Cross-Validation (RMSLE score)\nrmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False) \n# Create GridSearchCV Object (with Ridge)\ngridsearch_ridge_model = GridSearchCV(estimator=ridge_model,\n                                      param_grid=ridge_params,\n                                      scoring=rmsle_scorer,\n                                      cv=5)\n\n# Step 2-2 : Perform Grid Search\nlog_y = np.log1p(y) # Log Transformation of Target Value y\ngridsearch_ridge_model.fit(X_train, log_y) # Train (Grid Search)\n\nprint('Best Parameter:', gridsearch_ridge_model.best_params_)\n# Step 3 : Predict\npreds = gridsearch_ridge_model.best_estimator_.predict(X_train)\n\n# Step 4 : Evaluate\nprint('Ridge Regression RMSLE:', rmsle(log_y, preds, True))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:37.16739Z","iopub.execute_input":"2021-09-03T06:21:37.168129Z","iopub.status.idle":"2021-09-03T06:21:42.018091Z","shell.execute_reply.started":"2021-09-03T06:21:37.168076Z","shell.execute_reply":"2021-09-03T06:21:42.016848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lasso Model (Apply Gridsearch)","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import Lasso\n\n# Step 1: Create Model\nlasso_model = Lasso()\n\n# Step 2-1 : Create GridSearchCV Object\n# Hyper-parameter List\nlasso_alpha = 1/np.array([0.1, 1, 2, 3, 4, 10, 30, 100, 200, 300, 400, 800, 900, 1000])\nlasso_params = {'max_iter':[3000], 'alpha':lasso_alpha}\n# Create GridSearchCV Object (with Lasso)\ngridsearch_lasso_model = GridSearchCV(estimator=lasso_model,\n                                      param_grid=lasso_params,\n                                      scoring=rmsle_scorer,\n                                      cv=5)\n\n\n# Step 2-2 : Perform Grid Search\nlog_y = np.log1p(y)\ngridsearch_lasso_model.fit(X_train, log_y) # Train (Grid Search)\n\nprint('Best Parameter:', gridsearch_lasso_model.best_params_)\n# Step 3 : Predict\npreds = gridsearch_lasso_model.best_estimator_.predict(X_train)\n\n# Step 4 : Evaluate\nprint('Lasso Regression RMSLE:', rmsle(log_y, preds, True))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:42.019954Z","iopub.execute_input":"2021-09-03T06:21:42.020729Z","iopub.status.idle":"2021-09-03T06:21:48.444207Z","shell.execute_reply.started":"2021-09-03T06:21:42.020674Z","shell.execute_reply":"2021-09-03T06:21:48.439536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest Regression Model (Apply Grid Search)","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\n# Step 1: Create Model\nrandomforest_model = RandomForestRegressor()\n\n# Step 2-1 : Create GridSearchCV Object\n# Hyper-parameter List\nrf_params = {'random_state':[42], 'n_estimators':[100, 120, 140]}\n# Create GridSearchCV Object (with Random Forest Regression)\ngridsearch_random_forest_model = GridSearchCV(estimator=randomforest_model,\n                                              param_grid=rf_params,\n                                              scoring=rmsle_scorer,\n                                              cv=5)\n\n# Step 2-2 : Perform Grid Search\nlog_y = np.log1p(y)\ngridsearch_random_forest_model.fit(X_train, log_y)\n\nprint('Best Parameter:', gridsearch_random_forest_model.best_params_)\n\n# 스텝 3 : 예측\npreds = gridsearch_random_forest_model.best_estimator_.predict(X_train)\n\n# 스텝 4 : 평가\nprint('Random Forest Regression RMSLE:', rmsle(log_y, preds, True))","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:21:48.446015Z","iopub.execute_input":"2021-09-03T06:21:48.446346Z","iopub.status.idle":"2021-09-03T06:22:45.98951Z","shell.execute_reply.started":"2021-09-03T06:21:48.446316Z","shell.execute_reply":"2021-09-03T06:22:45.987903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Compare train data vs predicted test data distribution","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nrandomforest_preds = gridsearch_random_forest_model.best_estimator_.predict(X_test)\n\nfigure, axes = plt.subplots(ncols=2)\nfigure.set_size_inches(10, 4)\n\nsns.distplot(y, ax=axes[0], bins=50)\naxes[0].set_title('Train Data Distribution')\nsns.distplot(np.exp(randomforest_preds), ax=axes[1], bins=50)\naxes[1].set_title('Predicted Test Data Distribution');","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:22:45.991482Z","iopub.execute_input":"2021-09-03T06:22:45.992262Z","iopub.status.idle":"2021-09-03T06:22:47.132347Z","shell.execute_reply.started":"2021-09-03T06:22:45.992205Z","shell.execute_reply":"2021-09-03T06:22:47.131527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['count'] = np.exp(randomforest_preds)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T06:22:47.133477Z","iopub.execute_input":"2021-09-03T06:22:47.133913Z","iopub.status.idle":"2021-09-03T06:22:47.172561Z","shell.execute_reply.started":"2021-09-03T06:22:47.13388Z","shell.execute_reply":"2021-09-03T06:22:47.17165Z"},"trusted":true},"execution_count":null,"outputs":[]}]}