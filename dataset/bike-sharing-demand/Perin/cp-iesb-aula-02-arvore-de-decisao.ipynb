{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Aluguel de Biciletas em WDC\n    Prever quantas bicicletas serão alugadas por hora\n        Base de treino - 01 a 19 de cada mês (02 anos-com respostas)\n        Base teste - 20 ao final de cada mês (sem repostas)\n    Métrica = Raiz quadrada de RMSE LOG\n    \nPassos\n 1) Transformação da Base\n 2) Dividir treino em treino + Validação\n 3) Instalar o algoritmo modelo -> Base Treino\n 4) Realizar as predições -> Base Validação\n 5) Apurar a métrica\n 6) Prever usando a base de teste\n 7) Submeter ao Kaggle\n \n - Valores Contínuos -> Regressão\n - Valores Categóricos -> Classificação\n - Aprendizado Supervisionado\n - Overfitting (modelo viciado nos dados existentes e que é um \"Vitinho\" em novos dados)\n - Underfitting (modelo já é ruim no treino e nem chega a ser \"Vitinho' nos novos dados)\n \n Olhar com carinho os códigos de python constantes do link abaixo:\n - https://www.kaggle.com/clperin/k20190916-1\n    \n Nome alternativo para criar coluna -> feature engineering (\"impressionar o chefe\")\n     fit - treinar o modelo - as árvores são preenchidas ficando em memória no modelo treinado de forma a ficar pronta para ser utilizado.\n predict - predizer o modelo\n \n https://valor.globo.com/brasil/noticia/2019/11/11/infraestrutura-estuda-fusao-entre-tres-estatais-da-area-de-transporte.ghtml\n \n How do you Interpret RMSLE (Root Mean Squared Logarithmic Error)?\n \n I've been doing a machine learning competition where they use RMSLE (Root Mean Squared Logarithmic Error) to evaluate the performance predicting the sale price of a category of equipment. The problem is I'm not sure how to interpret the success of my final result.\n\nFor example if I achieved a RMSLE of 1.052\ncould I raise it the the exponential power e and interpret it like rmse? (ie. e1.052=2.863=RMSE\n\n)?\n\nCould I then say that my predictions were ±$2.863\non average from the the actual prices? Or is there a better way to interpret the metric? Or can the metric even be interpreted at all with the exception of comparing to the other RMSLEs of other models? \n\n\n\nI haven't seen RMSLE before, but I'm assuming it's 1N∑Ni=1(log(xi)−log(yi))2−−−−−−−−−−−−−−−−−−−−−√\n\n.\n\nThus exponentiating it won't give you RMSE, it'll give you\n\ne1N∑Ni=1(log(xi)−log(yi))2√≠1N∑Ni=1(xi−yi)2−−−−−−−−−−−−−−√\n\n.\n\nIf we take the log of both sides, we get the RMSLE versus 12log(1N∑Ni=1(xi−yi)2)\n\n, which is clearly not the same thing.\n\nUnfortunately, there isn't a good easy relationship in general (though someone smarter than me / thinking about it harder than me could probably use Jensen's inequality to figure out some relationship between the two).\n\nIt is, of course, the RMSE of the log-transformed variable, for what that's worth. If you want a rough sense of the spread of the distribution, you can instead get a rough sense of the spread of their logarithm, so that a RMSLE of 1.052 means that the \"average\" is 2.86\ntimes as big as the true value, or 1/2.86. Of course that's not quite what RMSE means....\n\nhttps://stats.stackexchange.com/questions/56658/how-do-you-interpret-rmsle-root-mean-squared-logarithmic-error"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\ntest = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando os dataframes\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"datetime, season, holiday, workingday, weather, temp, atemp, humidity, windspeed"},{"metadata":{"trusted":true},"cell_type":"code","source":"# REalizando as trasnformações nos dados","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplicar log na variável de resposta\ndf['count'] = np.log(df['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Juntando os dataframente\ndf = df.append(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converter a coluna datetime\ndf['datetime'] = pd.to_datetime(df['datetime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Criar Future Engineering(criar colunas) para o datetime\ndf['year'] = df['datetime'].dt.year\ndf['month'] = df['datetime'].dt.month\ndf['day'] = df['datetime'].dt.day\ndf['dayofweek'] = df['datetime'].dt.dayofweek\ndf['hour'] = df['datetime'].dt.hour","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Separando os dataframes\ntest = df[df['count'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Excluindo os nulos do dataframe df\ndf = df[~df['count'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dividindo o dataframe de treino\n# Importando o método scikitlearn para divisão\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dividir a base de treino\ntrain, valid = train_test_split(df, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verificando tamanhos\ntrain.shape, valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Selecionando as colunas que iremos usar como entrada\n# lista das colunas não usadas\nremoved_cols = ['casual', 'registered', 'count', 'datetime']\n\n# Criar a lista das colunas de entrada\nfeats = [c for c in train.columns if c not in removed_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Usando o modelo random forest\n# Importando o modelo\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Instanciar o modelo\nrf = RandomForestRegressor(random_state=42, n_jobs=-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Treinar o modelo. Romário não gostaria disso.\nrf.fit(train[feats], train['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fazendo predições em cima dos dados de validação\npreds = rf.predict(valid[feats])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# verificando as previsões\npreds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Verificando o real\nvalid['count'].head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos verificar o modelo com relação à métrica\n\n# Importar a métrica\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Aplicando a métrica\nmean_squared_error(valid['count'], preds)**(1/2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Vamos prever com base nos dados de treino\n# Como o modelo se comporta prevendo em cima de dados desconhecidos?\ntrain_preds = rf.predict(train[feats])\n\nmean_squared_error(train['count'], train_preds)**(1/2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Gerando as previsões para envio ao Kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vamos fazer previsões para a base de teste\ntest['count'] = np.exp(rf.predict(test[feats]))\n\n#mean_squared_error(test['count'], test_preds)**(1/2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Gerando o arquivo para submeter ao kaggle\ntest[['datetime', 'count']].head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['datetime', 'count']].to_csv('rf.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}