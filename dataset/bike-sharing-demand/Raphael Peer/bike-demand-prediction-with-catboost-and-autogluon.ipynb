{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Project for the [AWS Machine Learning Engineer Nanodegree](https://www.udacity.com/course/aws-machine-learning-engineer-nanodegree--nd189)\n\nIn this project, I experiment with the auto-ML framework Autogluon as well as a regular CatBoost model.\n\nFirst, some simple baseline models are trained. After that, the score was improved by creating some new features from the raw timestamp as well as hyperparamter tuning. As so often in machine learning, providing better features to the model lead to a rather big improvement. Hyperparameter tuning has much less impact but still improves the error by a considerable margin.","metadata":{}},{"cell_type":"markdown","source":"# Prerequisites","metadata":{}},{"cell_type":"code","source":"!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n!pip install autogluon --no-cache-dir","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-02-18T15:30:24.027499Z","iopub.execute_input":"2022-02-18T15:30:24.02787Z","iopub.status.idle":"2022-02-18T15:31:45.932814Z","shell.execute_reply.started":"2022-02-18T15:30:24.027769Z","shell.execute_reply":"2022-02-18T15:31:45.931946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom os.path import join\nimport json\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.metrics import mean_squared_log_error, make_scorer, mean_squared_error\nfrom sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split\nfrom sklearn.linear_model import Ridge\nfrom sklearn.inspection import permutation_importance\n\nfrom skopt import BayesSearchCV\nfrom skopt.space import Real, Integer\n\nfrom catboost import CatBoostRegressor\nfrom autogluon.tabular import TabularPredictor\nimport autogluon.core as ag","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:31:45.934865Z","iopub.execute_input":"2022-02-18T15:31:45.935121Z","iopub.status.idle":"2022-02-18T15:31:48.409322Z","shell.execute_reply.started":"2022-02-18T15:31:45.935092Z","shell.execute_reply":"2022-02-18T15:31:48.408344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_dir = '/kaggle/input/bike-sharing-demand'\n\ntrain = pd.read_csv(join(input_dir, 'train.csv')).drop(['casual', 'registered'], axis=1)\ny_train = train['count']\nx_train = train.drop('count', axis=1)\n\nx_test = pd.read_csv(join(input_dir, 'test.csv'))\n\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:31:48.412234Z","iopub.execute_input":"2022-02-18T15:31:48.412486Z","iopub.status.idle":"2022-02-18T15:31:48.525607Z","shell.execute_reply.started":"2022-02-18T15:31:48.412456Z","shell.execute_reply":"2022-02-18T15:31:48.52447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cap_at_zero(predictions):\n    predictions[predictions < 0] = 0\n    return predictions\n\n\nclass RidgeNonNegative(Ridge):\n    \n    def predict(self, *args, **kwargs):\n        predictions = super().predict(*args, **kwargs)\n        return cap_at_zero(predictions)\n\n\nclass CatBoostRegressorNonNegative(CatBoostRegressor):\n    \n    def predict(self, *args, **kwargs):\n        predictions = super().predict(*args, **kwargs)\n        return cap_at_zero(predictions)\n\n\nclass TabularPredictorNonNegative(TabularPredictor):\n    \n    def predict(self, *args, **kwargs):\n        predictions = super().predict(*args, **kwargs)\n        return cap_at_zero(predictions)\n\n\ndef root_mean_squared_log_error(*args, **kwargs):\n    return np.sqrt(mean_squared_log_error(*args, **kwargs))\n\n\ndef root_mean_squared_error(*args, **kwargs):\n    return np.sqrt(mean_squared_error(*args, **kwargs))\n\n\nrmsle_scorer = make_scorer(score_func=root_mean_squared_log_error, greater_is_better=False)\n\n\ndef save_submission(y_pred, file_name='submission.csv'):\n    dirname = 'submission_files'\n    if not os.path.exists(dirname):\n        os.makedirs(dirname)\n    \n    submission = pd.read_csv(join(input_dir,'sampleSubmission.csv'))\n    submission['count'] = y_pred\n    assert (submission['count'] >= 0).all()\n    submission.to_csv(os.path.join(dirname, file_name), index=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:31:48.527729Z","iopub.execute_input":"2022-02-18T15:31:48.528151Z","iopub.status.idle":"2022-02-18T15:31:50.889958Z","shell.execute_reply.started":"2022-02-18T15:31:48.528111Z","shell.execute_reply":"2022-02-18T15:31:50.889132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Quick EDA\n\nThere 8 ready-to-use featues and 1 target variable.  \nIn addition, there's one more column `datetime` which can be used for feature engineering later.","metadata":{}},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (20, 20)\ntrain.hist();","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:31:50.891368Z","iopub.execute_input":"2022-02-18T15:31:50.891851Z","iopub.status.idle":"2022-02-18T15:31:53.187702Z","shell.execute_reply.started":"2022-02-18T15:31:50.891807Z","shell.execute_reply":"2022-02-18T15:31:53.186593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline models","metadata":{}},{"cell_type":"code","source":"x_train_raw = x_train.drop('datetime', axis=1)\nx_test_raw = x_test.drop('datetime', axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:31:53.189185Z","iopub.execute_input":"2022-02-18T15:31:53.189519Z","iopub.status.idle":"2022-02-18T15:31:53.198841Z","shell.execute_reply.started":"2022-02-18T15:31:53.189472Z","shell.execute_reply":"2022-02-18T15:31:53.197661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ridge = RidgeNonNegative()\ncv_pred_ridge = cross_val_predict(estimator=ridge,\n                                  X=x_train_raw,\n                                  y=y_train)\nridge_baseline_rmse = round(root_mean_squared_error(y_train, cv_pred_ridge), 2)\nprint('Baseline ridge-regression:\\n'\n      f'RMSE = {ridge_baseline_rmse}\\n'\n      f'RMSLE = {round(root_mean_squared_log_error(y_train, cv_pred_ridge), 2)}')\n\nridge.fit(x_train_raw, y_train)\ny_pred_ridge = ridge.predict(x_test_raw)\nsave_submission(y_pred_ridge, 'ridge_regression_baseline.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:31:53.200718Z","iopub.execute_input":"2022-02-18T15:31:53.203207Z","iopub.status.idle":"2022-02-18T15:31:53.382042Z","shell.execute_reply.started":"2022-02-18T15:31:53.203149Z","shell.execute_reply":"2022-02-18T15:31:53.381071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Note that the metric used to train and evaluate the autogluon model is not the same as the one used in the competition. Thus, the leaderboard only shows the relative performance of the autogluaon models and cannot be used to for comparison with the regression model or the CatBoost. See the last section of this notebook for a comprehensive comparision between of all scores on the competition test set.","metadata":{}},{"cell_type":"code","source":"auto_model = TabularPredictorNonNegative(label='count',\n                                         problem_type='regression',\n                                         eval_metric='root_mean_squared_error',\n                                         verbosity=0)\nauto_model.fit(train_data=train,\n               time_limit=300,\n               presets='best_quality')\ny_pred_auto = auto_model.predict(x_test)\nsave_submission(y_pred_auto, 'autogluon_baseline.csv')\nautogluon_baseline_rmse = -auto_model.leaderboard(silent=True).score_val.iloc[0]\nauto_model.leaderboard(silent=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:31:53.383763Z","iopub.execute_input":"2022-02-18T15:31:53.384425Z","iopub.status.idle":"2022-02-18T15:37:09.906546Z","shell.execute_reply.started":"2022-02-18T15:31:53.384351Z","shell.execute_reply":"2022-02-18T15:37:09.90562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for comparison: no time limit\nauto_model = TabularPredictorNonNegative(label='count',\n                                         problem_type='regression',\n                                         eval_metric='root_mean_squared_error',\n                                         verbosity=0)\nauto_model.fit(train_data=train,\n               time_limit=None,\n               presets='best_quality')\nauto_model.leaderboard(silent=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:37:09.908072Z","iopub.execute_input":"2022-02-18T15:37:09.908366Z","iopub.status.idle":"2022-02-18T15:40:59.100958Z","shell.execute_reply.started":"2022-02-18T15:37:09.908333Z","shell.execute_reply":"2022-02-18T15:40:59.097534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_model = CatBoostRegressorNonNegative(verbose=0)\ncv_pred_cb = cross_val_predict(estimator=cb_model,\n                               X=x_train_raw,\n                               y=y_train)\ncb_baseline_rmse = round(root_mean_squared_error(y_train, cv_pred_cb), 2)\nprint('Baseline catboost:\\n'\n      f'RMSE = {cb_baseline_rmse}\\n'\n      f'RMSLE = {round(root_mean_squared_log_error(y_train, cv_pred_cb), 2)}')\n\ncb_model.fit(x_train_raw, y_train)\ny_pred_cb = cb_model.predict(x_test_raw)\nsave_submission(y_pred_cb, 'catboost_baseline.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:40:59.102747Z","iopub.status.idle":"2022-02-18T15:40:59.103227Z","shell.execute_reply.started":"2022-02-18T15:40:59.10297Z","shell.execute_reply":"2022-02-18T15:40:59.102993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering and further EDA","metadata":{}},{"cell_type":"code","source":"def engineer_features(df: pd.DataFrame) -> pd.DataFrame:\n\n    df = df.copy()\n    df['datetime'] = pd.to_datetime(df.datetime)\n    \n    df['year'] = df.datetime.dt.year\n    df['week'] = df.datetime.dt.week\n    df['hour'] = df.datetime.dt.hour\n    df['weekday'] = df.datetime.dt.day_name()\n    \n    df.season = df.season\n    df.weather = df.weather\n    \n    return df\n\ndef make_categorical(df: pd.DataFrame, cat_features: list):\n    for f in cat_features:\n        df[f] = df[f].astype('category')\n    return df\n    \nx_train_eng = engineer_features(x_train)\nx_test_eng = engineer_features(x_test)\nx_train_eng.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:00.664432Z","iopub.execute_input":"2022-02-08T15:33:00.664717Z","iopub.status.idle":"2022-02-08T15:33:00.729223Z","shell.execute_reply.started":"2022-02-08T15:33:00.664686Z","shell.execute_reply":"2022-02-08T15:33:00.728212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_eng.year.value_counts().to_frame(name='num_datapoints').rename_axis('year', axis='columns')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:00.730793Z","iopub.execute_input":"2022-02-08T15:33:00.731484Z","iopub.status.idle":"2022-02-08T15:33:00.743812Z","shell.execute_reply.started":"2022-02-08T15:33:00.731433Z","shell.execute_reply":"2022-02-08T15:33:00.742868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (10, 5)\nx_train_eng[['week', 'hour']].hist()\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:00.745039Z","iopub.execute_input":"2022-02-08T15:33:00.745302Z","iopub.status.idle":"2022-02-08T15:33:01.208917Z","shell.execute_reply.started":"2022-02-08T15:33:00.745253Z","shell.execute_reply":"2022-02-08T15:33:01.207866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weekday_counts = x_train_eng.weekday.value_counts()[['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']]\n\nplt.bar(weekday_counts.index, weekday_counts.values)\nplt.title('weekday');","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:01.210438Z","iopub.execute_input":"2022-02-08T15:33:01.210794Z","iopub.status.idle":"2022-02-08T15:33:01.490957Z","shell.execute_reply.started":"2022-02-08T15:33:01.21075Z","shell.execute_reply":"2022-02-08T15:33:01.489985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"categorical_features = ['year', 'weekday', 'season', 'weather']\nx_train_eng = make_categorical(x_train_eng, categorical_features)\nx_test_eng = make_categorical(x_test_eng, categorical_features)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:01.492317Z","iopub.execute_input":"2022-02-08T15:33:01.492554Z","iopub.status.idle":"2022-02-08T15:33:01.507977Z","shell.execute_reply.started":"2022-02-08T15:33:01.492525Z","shell.execute_reply":"2022-02-08T15:33:01.506925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Selection","metadata":{}},{"cell_type":"markdown","source":"#### redundant features\n\nDatetime could now be dropped because we used it to create the four features `year`, `week`, `weekday` and `hour`.\n\nThe feature `workingday` is redundant because the features `holiday` and `weekday` already contain the same information.\nIf holiday is 1 or `weekday` is 'Saturday' or 'Sunday', then workingday is 0 otherwise, it's 1 (see below).\n\nFinally, the feature `week` refering to the calendar-week contains the information of `season` just much more granular.\n\nIn the experiments below, a model is fitted after dropping redundant features while another one uses all the features.","metadata":{}},{"cell_type":"code","source":"day_stats = x_train_eng.groupby(['holiday', 'weekday']).apply(lambda d: d.workingday.value_counts())\nday_stats.to_frame(name='count').rename_axis('workinday', axis='columns')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:01.509622Z","iopub.execute_input":"2022-02-08T15:33:01.510004Z","iopub.status.idle":"2022-02-08T15:33:01.538227Z","shell.execute_reply.started":"2022-02-08T15:33:01.509965Z","shell.execute_reply":"2022-02-08T15:33:01.537369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_model = CatBoostRegressorNonNegative(verbose=0, cat_features=['year', 'weekday', 'weather'])\ncv_pred_cb = cross_val_predict(estimator=cb_model,\n                               X=x_train_eng.drop(['datetime', 'workingday', 'season'], axis=1),\n                               y=y_train)\nprint('Catboost with non-redundant features:\\n'\n      f'RMSE = {round(root_mean_squared_error(y_train, cv_pred_cb), 2)}\\n'\n      f'RMSLE = {round(root_mean_squared_log_error(y_train, cv_pred_cb), 2)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:01.539531Z","iopub.execute_input":"2022-02-08T15:33:01.539789Z","iopub.status.idle":"2022-02-08T15:33:23.406989Z","shell.execute_reply.started":"2022-02-08T15:33:01.539757Z","shell.execute_reply":"2022-02-08T15:33:23.406074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_model = CatBoostRegressorNonNegative(verbose=0, \n                                        cat_features=categorical_features)\ncv_pred_cb = cross_val_predict(estimator=cb_model,\n                               X=x_train_eng,\n                               y=y_train)\nprint('Catboost with all features:\\n'\n      f'RMSE = {round(root_mean_squared_error(y_train, cv_pred_cb), 2)}\\n'\n      f'RMSLE = {round(root_mean_squared_log_error(y_train, cv_pred_cb), 2)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:23.408228Z","iopub.execute_input":"2022-02-08T15:33:23.408467Z","iopub.status.idle":"2022-02-08T15:33:50.246698Z","shell.execute_reply.started":"2022-02-08T15:33:23.408438Z","shell.execute_reply":"2022-02-08T15:33:50.245267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for feature importance:\nx_tr, x_val, y_tr, y_val = train_test_split(x_train_eng, y_train)\ncb_model = CatBoostRegressorNonNegative(verbose=0, cat_features=categorical_features)\ncb_model.fit(x_tr, y_tr);","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:50.248751Z","iopub.execute_input":"2022-02-08T15:33:50.249091Z","iopub.status.idle":"2022-02-08T15:33:55.361548Z","shell.execute_reply.started":"2022-02-08T15:33:50.249013Z","shell.execute_reply":"2022-02-08T15:33:55.360504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, the model with all (including redundant features) performs better. Therefore, it is not a good idea to just drop the features that seem redundant. However, it is still likely that not all those features are required for optimal performance.\n\nTo find the smallest subset of features with optimal performence, the plot below shows the permutation feature importance of all features. By dropping those, whose importance is close to zero in the plot, we can have the same performance as the model with all features but using only a subset of the features. All other things equal, a model with fewer features is preferable.","metadata":{}},{"cell_type":"code","source":"feature_importances = permutation_importance(cb_model, x_val, y_val, n_repeats=50)\n\nmean_imp = sorted(zip(cb_model.feature_names_, feature_importances['importances_mean']), key=lambda x: x[1], reverse=True)\nsorted_features, sorted_mean_importance = zip(*mean_imp)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:33:55.364555Z","iopub.execute_input":"2022-02-08T15:33:55.364908Z","iopub.status.idle":"2022-02-08T15:34:03.633977Z","shell.execute_reply.started":"2022-02-08T15:33:55.364866Z","shell.execute_reply":"2022-02-08T15:34:03.632959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(sorted_features, sorted_mean_importance)\nplt.xticks(rotation=70)\nplt.ylabel('importance')\nplt.title('feature importance');","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:34:03.635297Z","iopub.execute_input":"2022-02-08T15:34:03.635551Z","iopub.status.idle":"2022-02-08T15:34:03.981326Z","shell.execute_reply.started":"2022-02-08T15:34:03.635518Z","shell.execute_reply":"2022-02-08T15:34:03.980396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train_final = x_train_eng.drop(['season', 'holiday', 'windspeed', 'year'], axis=1)\nx_test_final = x_test_eng.drop(['season', 'holiday', 'windspeed', 'year'], axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:34:03.982377Z","iopub.execute_input":"2022-02-08T15:34:03.982597Z","iopub.status.idle":"2022-02-08T15:34:03.990434Z","shell.execute_reply.started":"2022-02-08T15:34:03.982557Z","shell.execute_reply":"2022-02-08T15:34:03.98959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_model = CatBoostRegressorNonNegative(verbose=0, cat_features=['weekday', 'weather'])\ncv_pred_cb = cross_val_predict(estimator=cb_model,\n                               X=x_train_final,\n                               y=y_train)\ncb_features_rmse = round(root_mean_squared_error(y_train, cv_pred_cb), 2)\nprint('Catboost with final features:\\n'\n      f'RMSE = {cb_features_rmse}\\n'\n      f'RMSLE = {round(root_mean_squared_log_error(y_train, cv_pred_cb), 2)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:34:03.99196Z","iopub.execute_input":"2022-02-08T15:34:03.992212Z","iopub.status.idle":"2022-02-08T15:34:26.095076Z","shell.execute_reply.started":"2022-02-08T15:34:03.992182Z","shell.execute_reply":"2022-02-08T15:34:26.094177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_model.fit(x_train_final, y_train)\ny_pred_feature_eng = cb_model.predict(x_test_final)\n\nsave_submission(y_pred_feature_eng, 'catboost_with_engineered_features.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:34:26.096403Z","iopub.execute_input":"2022-02-08T15:34:26.096722Z","iopub.status.idle":"2022-02-08T15:34:31.519787Z","shell.execute_reply.started":"2022-02-08T15:34:26.096674Z","shell.execute_reply":"2022-02-08T15:34:31.518794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nauto_model_feature_eng = TabularPredictorNonNegative(label='count',\n                                                     problem_type='regression',\n                                                     eval_metric='root_mean_squared_error',\n                                                     verbosity=0)\nauto_model_feature_eng.fit(train_data=pd.concat([x_train_final, y_train], axis=1),\n                           time_limit=None,\n                           presets='best_quality')\nsave_submission(auto_model_feature_eng.predict(x_test_final), 'autogluon_feature_engineering.csv')\nautogluon_features_rmse = -auto_model_feature_eng.leaderboard(silent=True).score_val.iloc[0]\nauto_model_feature_eng.leaderboard(silent=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:34:31.521238Z","iopub.execute_input":"2022-02-08T15:34:31.521549Z","iopub.status.idle":"2022-02-08T15:37:36.939244Z","shell.execute_reply.started":"2022-02-08T15:34:31.521508Z","shell.execute_reply":"2022-02-08T15:37:36.93838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning","metadata":{}},{"cell_type":"code","source":"%%time\n\ncb_hyperparams = {'iterations': (100, 1000),\n                   'learning_rate': (0.01, 0.03),\n                   'depth': (4, 10),\n                   'l2_leaf_reg': (0, 100),\n                   'random_strength': (1, 10),\n                   'colsample_bylevel': (0.5, 1),\n                   'subsample': (0.5, 1)}\n\nbayesian_search = BayesSearchCV(\n    estimator=CatBoostRegressorNonNegative(verbose=0, cat_features=['weekday', 'weather']),\n    search_spaces=cb_hyperparams,\n    scoring=rmsle_scorer,\n    cv=5,\n    n_iter=100,\n    refit=False,\n    n_jobs=-1,\n    error_score=0,\n    verbose=0,\n)\nbayesian_search.fit(x_train_final, y_train)\nbayesian_search.best_params_","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:37:36.940722Z","iopub.execute_input":"2022-02-08T15:37:36.941113Z","iopub.status.idle":"2022-02-08T15:38:06.274341Z","shell.execute_reply.started":"2022-02-08T15:37:36.941061Z","shell.execute_reply":"2022-02-08T15:38:06.273435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_model_hyper = CatBoostRegressorNonNegative(verbose=0, cat_features=['weekday', 'weather'], **bayesian_search.best_params_)\ncv_pred_cb = cross_val_predict(estimator=cb_model_hyper,\n                               X=x_train_final,\n                               y=y_train)\ncb_hyper_rmse = round(root_mean_squared_error(y_train, cv_pred_cb), 2)\nprint('Catboost after hyperparameter-tuning:\\n'\n      f'RMSE = {cb_hyper_rmse}\\n'\n      f'RMSLE = {round(root_mean_squared_log_error(y_train, cv_pred_cb), 2)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:38:06.275885Z","iopub.execute_input":"2022-02-08T15:38:06.276103Z","iopub.status.idle":"2022-02-08T15:38:06.305404Z","shell.execute_reply.started":"2022-02-08T15:38:06.276076Z","shell.execute_reply":"2022-02-08T15:38:06.303861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cb_model_hyper.fit(x_train_final, y_train)\ny_pred_hyper = cb_model_hyper.predict(x_test_final)\n\nsave_submission(y_pred_hyper, 'catboost_with_hyperparam_tuning.csv')","metadata":{"execution":{"iopub.status.busy":"2022-02-08T15:38:06.306474Z","iopub.status.idle":"2022-02-08T15:38:06.307137Z","shell.execute_reply.started":"2022-02-08T15:38:06.30693Z","shell.execute_reply":"2022-02-08T15:38:06.306953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\nauto_model_hyper = TabularPredictorNonNegative(label='count',\n                                               problem_type='regression',\n                                               eval_metric='root_mean_squared_error',\n                                               verbosity=0)\nauto_model_hyper.fit(train_data=pd.concat([x_train_final, y_train], axis=1),\n                     time_limit=None,\n                     presets='best_quality',\n                     hyperparameter_tune_kwargs='bayesopt')\nsave_submission(auto_model_hyper.predict(x_test_final), 'autogluon_hyper.csv')\nautogluon_hyper_rmse = -auto_model_hyper.leaderboard(silent=True).score_val.iloc[0]\nauto_model_hyper.leaderboard(silent=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T16:07:21.713513Z","iopub.execute_input":"2022-02-08T16:07:21.713839Z","iopub.status.idle":"2022-02-08T16:17:32.067296Z","shell.execute_reply.started":"2022-02-08T16:07:21.713807Z","shell.execute_reply":"2022-02-08T16:17:32.066411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model comparison","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame([\n    ['baseline', 'ridge_regression', ridge_baseline_rmse ,1.43],\n    ['baseline', 'catboost', cb_baseline_rmse , 1.32],\n    ['baseline', 'autogluon', autogluon_baseline_rmse ,1.40],\n    ['add_features', 'catboost', cb_features_rmse ,0.63],\n    ['hyperparam', 'catboost', cb_hyper_rmse , 0.53],\n    ['add_features', 'autogluon', autogluon_features_rmse ,0.45],\n    ['hyperparam', 'autogluon', autogluon_hyper_rmse ,0.45]\n],\n    columns=['iteration', 'model', 'cv_rmse', 'submission_rmsle'])\ndf","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:40:49.802628Z","iopub.execute_input":"2022-02-09T13:40:49.802889Z","iopub.status.idle":"2022-02-09T13:40:49.83391Z","shell.execute_reply.started":"2022-02-09T13:40:49.802858Z","shell.execute_reply":"2022-02-09T13:40:49.833306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsns.pointplot(data=df, x='iteration', y='cv_rmse', hue='model')\nplt.ylim(0, df.cv_rmse.max() + df.cv_rmse.max() / 10)\nplt.xlabel('')\nplt.ylabel('cross-validated RMSE')\nplt.title('Model comparison: cross-validation')\n\nplt.savefig('model_comparison_cv.png', dpi=300)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:42:17.089618Z","iopub.execute_input":"2022-02-09T13:42:17.089883Z","iopub.status.idle":"2022-02-09T13:42:17.687983Z","shell.execute_reply.started":"2022-02-09T13:42:17.089856Z","shell.execute_reply":"2022-02-09T13:42:17.687044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pointplot(data=df, x='iteration', y='submission_rmsle', hue='model')\nplt.ylim(0, 1.5)\nplt.xlabel('')\nplt.ylabel('leaderboard RMSLE')\nplt.title('Model comparison: leaderboard')\n\nplt.savefig('model_comparison_leaderboard.png', dpi=300)","metadata":{"execution":{"iopub.status.busy":"2022-02-09T13:42:43.652272Z","iopub.execute_input":"2022-02-09T13:42:43.652532Z","iopub.status.idle":"2022-02-09T13:42:44.250301Z","shell.execute_reply.started":"2022-02-09T13:42:43.652507Z","shell.execute_reply":"2022-02-09T13:42:44.249457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Summary\n\nEven with the fairly small dataset at hand, the score improved substantially with some simple feature engineering und hyperparameter tuning.\n\nThe results also show that it is not trivial to beat autoML models and demonstrate the usefulness of autoML for quickly creating baseline and exploratory models.","metadata":{}}]}