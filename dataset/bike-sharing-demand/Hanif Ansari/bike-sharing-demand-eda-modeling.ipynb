{"cells":[{"metadata":{},"cell_type":"markdown","source":"![](http://storage.googleapis.com/kaggle-competitions/kaggle/3948/media/bikes.png)\n\nI am super excited to share my first kernel with the Kaggle community. This kernel is for all the aspiring data scientists who wants to learn and review their knowledge. As I go on in this journey and learn new topics, I will incorporate them with each new updates. Going back to the topics of this kernel, I will do visualizations to explain the data, and machine learning algorithms to forecast bike rental demand  in the Capital Bikeshare program in Washington, D.C."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Let's import the usual suspects\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Importing the dataset\ntrain = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\ntest = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')\ndata = train.append(test, sort = False)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Types of variables:\n* Categorical - Season, Holiday, Working day, Weather\n* Timeseries - Datetime\n* Numerical - Temp, aTemp, Humidity, Windspeed, Casual, Registered, Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Exploratory Data Analysis**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Histogram for count\nsns.set_style('darkgrid')\nsns.distplot(train['count'], bins = 100, color = 'green')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Q-Q Plot\nfrom scipy import stats\nplt = stats.probplot(train['count'], plot=sns.mpl.pyplot)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Boxplot for count\nimport matplotlib.pyplot as plt\nsns.boxplot(x = 'count', data = train, color = 'mediumpurple')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These three charts above can tell us a lot about our target variable.\n\n* Our target variable, count is not normally distributed.\n* Our target variable is right-skewed.\n* There are multiple outliers in the variable."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating the number of outliers\nQ1 = train['count'].quantile(0.25)\nQ3 = train['count'].quantile(0.75)\nIQR = Q3 - Q1\noutliers = train[(train['count'] < (Q1 - 1.5 * IQR)) | (train['count'] > (Q3 + 1.5 * IQR))]\nprint((len(outliers)/len(data))*100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1.72% of the target values are above Q3 + 1.5IQR. Let's get rid of this."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Data without the outliers in count\ndata = data[~data.isin(outliers)]\ndata = data[data['datetime'].notnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = 'season', y = 'count', data = train, estimator = np.average, palette='coolwarm')\nplt.ylabel('Average Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = 'holiday', y = 'count', data = train, estimator = np.average, palette='deep')\nplt.ylabel('Average Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = 'workingday', y = 'count', data = train, estimator = np.average, palette='colorblind')\nplt.ylabel('Average Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x = 'weather', y = 'count', data = train, estimator = np.average, palette='deep')\nplt.ylabel('Average Count')\nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,7))\ntc = train.corr()\nsns.heatmap(tc, annot = True, cmap = 'coolwarm', linecolor = 'white', linewidths=0.1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Count is hightly correlated with Casual and Registered. It's because Count is derived from Casual and Registered. We'll have to omit these variables. Temp and atemp are highly correlated."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert to integer variables\ncolumns=['season', 'holiday', 'workingday', 'weather']\nfor i in columns:\n    data[i] = data[i].apply(lambda x : int(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Convert string to datatime and create Hour, Month and Day of week\ndata['datetime'] = pd.to_datetime(data['datetime'])\ndata['Hour'] = data['datetime'].apply(lambda x:x.hour)\ndata['Month'] = data['datetime'].apply(lambda x:x.month)\ndata['Day of Week'] = data['datetime'].apply(lambda x:x.dayofweek)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,4))\nsns.lineplot(x = 'Month', y = 'count', data = data, estimator = np.average, hue = 'weather', palette = 'coolwarm')\nplt.ylabel('Average Count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['weather'] == 4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no line plot for weather = 4, because there is only three data point for weather = 4"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(ncols = 2, figsize = (15,5), sharey = True)\nsns.pointplot(x = 'Hour', y = 'count', data = data, estimator = np.average, hue = 'workingday', ax = axes[0], palette = 'muted')\nsns.pointplot(x = 'Hour', y = 'count', data = data, estimator = np.average, hue = 'holiday', ax = axes[1], palette = 'muted')\nax = [0,1]\nfor i in ax:\n    axes[i].set(ylabel='Average Count')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* During working days there is a high demand around the 7th hour and 17th hour. There is a lower demand during 0 to 5th hour and 10 to 14th hour.\n* During non workin days there is a high demand during 10 to 14th hour. There is a lower demand around the 7th hour."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (10,4))\nsns.pointplot(x = 'Hour', y = 'count', data = data, estimator=np.average, hue = 'Day of Week', palette='coolwarm')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly, weekend and weekdays follows a different pattern."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.jointplot(x = 'atemp', y = 'count', data = data, kind = 'kde', cmap = 'plasma')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,4))\nsns.pointplot(x = 'Hour', y = 'casual', data = data, estimator = np.average, color = 'blue')\nsns.pointplot(x = 'Hour', y = 'registered', data = data, estimator = np.average, color = 'red')\nplt.ylabel('Registered')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Histogram for Windspeed\nsns.set_style('darkgrid')\nsns.distplot(data['windspeed'], bins = 100, color = 'purple') #Windspeed cannot be 0.\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replacing 0s in windspeed with the mean value grouped by season\ndata['windspeed'] = data['windspeed'].replace(0, np.nan)\ndata['windspeed'] = data['windspeed'].fillna(data.groupby('weather')['season'].transform('mean'))\nsns.distplot(data['windspeed'], bins = 100, color = 'red')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Encoding cyclical features\ndata['Month_sin'] = data['Month'].apply(lambda x: np.sin((2*np.pi*x)/12))\ndata['Month_cos'] = data['Month'].apply(lambda x: np.cos((2*np.pi*x)/12))\ndata['Hour_sin'] = data['Hour'].apply(lambda x: np.sin((2*np.pi*(x+1))/24))\ndata['Hour_cos'] = data['Hour'].apply(lambda x: np.cos((2*np.pi*(x+1))/24))\ndata['DayOfWeek_sin'] = data['Day of Week'].apply(lambda x: np.sin((2*np.pi*(x+1))/7))\ndata['DayOfWeek_cos'] = data['Day of Week'].apply(lambda x: np.cos((2*np.pi*(x+1))/7))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the target variable is a highly skewed data, we will try to transform this data using either log, square-root or box-cox transformation. After trying out all three, log square gives the best result. Also as the evaluation metric is RMSLE, using log would help as it would allow to less penalize the large difference in final variable values."},{"metadata":{"trusted":true},"cell_type":"code","source":"#trainsforming target variable using log transformation\ndata['count'] = np.log(data['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Converting Categorical to numerical - Removing Co-Linearity\ndata_ = pd.get_dummies(data=data, columns=['season', 'holiday', 'workingday', 'weather'])\ntrain_ = data_[pd.notnull(data_['count'])].sort_values(by=[\"datetime\"])\ntest_ = data_[~pd.notnull(data_['count'])].sort_values(by=[\"datetime\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Standardizing numerical variables\nfrom sklearn.preprocessing import StandardScaler\ncols = ['temp','atemp','humidity', 'windspeed', 'Month_sin', 'Month_cos', 'Hour_sin', 'Hour_cos', 'DayOfWeek_sin','DayOfWeek_cos']\nfeatures = data[cols]\n\n#Standard Scaler\nscaler = StandardScaler().fit(features.values)\ndata[cols] = scaler.transform(features.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Predictor columns names\ncols = ['temp','atemp','humidity', 'windspeed', 'Month_sin', 'Month_cos', 'Hour_sin', 'Hour_cos', 'DayOfWeek_sin','DayOfWeek_cos', 'season_1','season_2', 'season_3',\n        'holiday_0', 'workingday_0', 'weather_1', 'weather_2', 'weather_3']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Linear Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train test split\nX = train_[cols]\ny = train_['count']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(X_train, y_train)\nprint(lm.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (18,4))\ncoeff = pd.DataFrame(lm.coef_, index = X.columns, columns = ['Coefficient'])\nsns.barplot(x = coeff.index, y = 'Coefficient', data = coeff, color = 'red')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,4))\npred = lm.predict(X_test)\nsns.scatterplot(x = y_test, y = pred)\nplt.xlabel('Count')\nplt.ylabel('Predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variability between the actual values and the predicted values is higher."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot((y_test-pred),bins=100, color = 'gray')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The residual distribution is normal."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSLE:', np.sqrt(metrics.mean_squared_log_error(np.exp(y_test), np.exp(pred))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ridge Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n#Assiging different sets of alpha values to explore which can be the best fit for the model. \ntemp_msle = {}\nfor i in np.linspace(0, 40, 20):\n    ridge = Ridge(alpha= i, normalize=True)\n    #fit the model. \n    ridge.fit(X_train, y_train)\n    ## Predicting the target value based on \"Test_x\"\n    pred = ridge.predict(X_test)\n\n    msle = np.sqrt(metrics.mean_squared_log_error(np.exp(y_test), np.exp(pred)))\n    temp_msle[i] = msle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_msle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Lasso Regression**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\n## Assiging different sets of alpha values to explore which can be the best fit for the model. \ntemp_msle = {}\nfor i in np.logspace(-10, -1, 20):\n    ## Assigin each model. \n    lasso = Lasso(alpha= i, normalize=True, tol = 0.1)\n    ## fit the model. \n    lasso.fit(X_train, y_train)\n    ## Predicting the target value based on \"Test_x\"\n    pred = lasso.predict(X_test)\n\n    msle = np.sqrt(metrics.mean_squared_log_error(np.exp(y_test), np.exp(pred)))\n    temp_msle[i] = msle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_msle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfr = RandomForestRegressor(n_estimators = 500)\nrfr.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (8,4))\npred = rfr.predict(X_test)\nsns.scatterplot(x = y_test, y = pred)\nplt.xlabel('Count')\nplt.ylabel('Predictions')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The variability between the actual values and the predicted values is lesser than the linear regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot((y_test-pred),bins=100, color = 'gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RMSLE\nprint('RMSLE:', np.sqrt(metrics.mean_squared_log_error(np.exp(y_test), np.exp(pred))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#submission\nnew = test_[cols]\npred = rfr.predict(new)\nsubmission = pd.DataFrame({'datetime':test['datetime'],'count':np.exp(pred)})\nsubmission['count'] = submission['count'].astype(int)\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}