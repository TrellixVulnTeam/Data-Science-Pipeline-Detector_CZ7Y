{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div class=\"alert alert-block \">\n    <h1 align=\"center\">Six Algorithm in Machine Learning</h1>\n    <h1 align=\"center\">Multiple Linear Regression</h1>\n    <h4 align=\"center\"><a href=\"https://www.kaggle.com/competitions/bike-sharing-demand/overview\">Original Competition</a> | <a href=\"https://www.kaggle.com/competitions/bike-sharing-demand/data\">Dataset</a> | <a href=\"https://rfebrians.github.io\"> Writer</a></h5>\n</div>","metadata":{}},{"cell_type":"markdown","source":"> This notebook is inspired by [Bike Sharing Demand Competition](https://www.kaggle.com/competitions/bike-sharing-demand/code) using the same Dataset ,\n\n> On this notebook we'll explore further more about how multiple linear regression , the algorithm and other model works.","metadata":{}},{"cell_type":"markdown","source":"## Subject\nYou are an owner of a bike shop. You rent bicycles to customers. \n\nNow you want to predict the the number of requsets for bicycles by customers based on some information you have. \n\nSo We'll analyze this to a kind of linear regression with multiple features.\n\n![alt text](https://www.sefiles.net/merchant/5432/images/site/rental-ebike-2-slimC.jpg?t=1572206062455 \"Title\")\n\n","metadata":{}},{"cell_type":"markdown","source":"# The Algorithm\n\n> Algorithm is just a workflow , it contain a procedur that can be read on human being .\n\n![img](https://raw.githubusercontent.com/RFebrians/object-detection-playground/main/Six-Algorithm-ML.png)\n\n1. Import All Libraries that we'll needed\n2. Load Dataset and Begin EDA\n3. Recognize Missing Values\n4. Visualize Data\n5. Train Various Model\n6. Result","metadata":{}},{"cell_type":"markdown","source":"# Model that will be tested\n\n* Linear Regression\n* Multiple Linear Regression\n* K Nearest Neighbour\n* Decision Tree\n* Random Forest","metadata":{}},{"cell_type":"markdown","source":"## Object\n\nLet's get started with some information related to columns existed in the dataset.\n\n##### datetime:\nhourly date + timestamp  \n##### season:\n1 = spring, 2 = summer, 3 = fall, 4 = winter \n##### holiday:\nwhether the day is considered a holiday\n##### workingday:\nwhether the day is neither a weekend nor holiday\n##### weather:\n* 1 = Clear, Few clouds, Partly cloudy, Partly cloudy\n* 2 =  Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n* 3 = Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n* 4 = Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\n##### temp:\ntemperature in Celsius\n##### atemp:\n\"feels like\" temperature in Celsius\n##### humidity:\nrelative humidity\n##### windspeed:\nwind speed\n##### casual:\nnumber of non-registered user rentals initiated\n##### registered:\nnumber of registered user rentals initiated\n##### count:\nnumber of total rentals\n","metadata":{}},{"cell_type":"markdown","source":"\n<div class=\"alert alert-block\">\n    <h1 align=\"center\">Let's get started</h1>\n    <h2 align=\"center\">Step1: Import libraries</h2>\n</div> ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nimport time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block\">\n    <h2 align=\"center\">Step2: Load dataset and Begin Exploratory Data Analysis (EDA) </h2>\n</div> ","metadata":{}},{"cell_type":"code","source":"# Load dataset \ndata_unseen =  pd.read_csv('../input/bike-sharing-demand/test.csv')\ndata = pd.read_csv('../input/bike-sharing-demand/train.csv')\ndata.head()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# As we understood, there is no null value in our data. Great !\n# No we must change the type of columns to suitable value to use less memory\n# Here we have a column called datetime with datetime64 type. So I change the type of it\ndata['datetime'] = data['datetime'].astype('datetime64')\n#To machine learning we need numerical values so we must split this column to numerical values\ndata['datetime_year'] = data['datetime'].dt.year\ndata['datetime_month'] = data['datetime'].dt.month\ndata['datetime_day'] = data['datetime'].dt.day\ndata['datetime_hour'] = data['datetime'].dt.hour\n\ndata.drop(['datetime'], axis=1, inplace=True)\nfor i in data.columns:        \n    if i in ['temp','atemp', 'windspeed']:\n        data[f'{i}'] = data[f'{i}'].astype('float16')\n    else:\n        data[f'{i}'] = data[f'{i}'].astype('int16')\n        \n\n# Change the order of columns in the table\ndata = data[['datetime_year', 'datetime_month', 'datetime_day', 'datetime_hour',\n            'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n            'humidity', 'windspeed', 'casual', 'registered', 'count']]\n\n# Similarly, we do these actions on data_unseen.\ndata_unseen['datetime'] = data_unseen['datetime'].astype('datetime64')\ndata_unseen['datetime_year'] = data_unseen['datetime'].dt.year\ndata_unseen['datetime_month'] = data_unseen['datetime'].dt.month\ndata_unseen['datetime_day'] = data_unseen['datetime'].dt.day\ndata_unseen['datetime_hour'] = data_unseen['datetime'].dt.hour\n# Change the order of columns in the table\ndata_unseen = data_unseen[['datetime_year', 'datetime_month', 'datetime_day', 'datetime_hour',\n            'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',\n            'humidity', 'windspeed']]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We could optimize the useage of memory.Let's take a look a data again\ndata.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summary Statistics\ndata.describe()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block\">\n    <h2 align=\"center\">Step3: Recognize missing values</h2>\n</div> ","metadata":{}},{"cell_type":"code","source":"# To check the number of missing values\ndata.isnull().sum()","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block\">\n    <h2 align=\"center\">Step4: Visualize data for better understand</h2>\n</div> ","metadata":{}},{"cell_type":"code","source":"# See some useful graphs\nfig , axes = plt.subplots(2,2,figsize=(20,15))\n\n# Axes[0,0]: Here We want to compare the number of total rentals based on each season\nnumber_of_total_rentals = []\nfor i in (data.season.unique()):\n    number_of_total_rentals.append(data[data.season==i]['count'].sum())\n    \nsns.barplot(ax=axes[0,0],x=['spring','summer','fall','winter'], y=number_of_total_rentals, label='number of total rentals based on each season',\n            )\naxes[0,0].legend(loc=2, fontsize=15)\naxes[0,0].tick_params(axis='both', which='major', labelsize=15)\n# Axes[0,1]: Here I want to compare the number of total rentals based on holidays\nnumber_of_total_rentals = []\nfor i in (data.holiday.unique()):\n    number_of_total_rentals.append(data[data.holiday==i]['count'].sum())\n\nsns.barplot(ax= axes[0,1],x=['Not holiday(0)','holiday(1)'], y=number_of_total_rentals, label='number of total rentals based on holidays')\naxes[0,1].legend(loc=1, fontsize=15)\naxes[0,1].tick_params(axis='both', which='major', labelsize=15)\n# Axes[1,0]: Here I want to compare the number of total rentals based on workingdays\nnumber_of_total_rentals = []\nfor i in (data.workingday.unique()):\n    number_of_total_rentals.append(data[data.workingday==i]['count'].sum())\n    \nsns.barplot(ax=axes[1,0],x=['Not workingday(0)','workingday(1)'], y=number_of_total_rentals, label='number of total rentals based on workingdays')\naxes[1,0].legend(loc=2, fontsize=15)\naxes[1,0].tick_params(axis='both', which='major', labelsize=15)\n# Axes[1,1]: Here I want to compare the number of total rentals based on weather\nnumber_of_total_rentals= []\nfor i in (data.weather.unique()):\n    number_of_total_rentals.append(data[data.weather==i]['count'].sum())\n\nsns.barplot(ax=axes[1,1],x=['1','2','3','4'], y=number_of_total_rentals, label='the number of total rentals based on weather')\naxes[1,1].legend(loc=1, fontsize=15)\naxes[1,1].tick_params(axis='both', which='major', labelsize=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the correlation between parameters\nmy_correlation = data.corr()\nplt.figure(figsize=(15,15))\nsns.heatmap(my_correlation,cbar=True, square= True, fmt='.2f', annot=True,annot_kws={'size':15}, cmap='Greens')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"my_correlation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block\">\n    <h2 align=\"center\">Step5: Train the model with different models</h2>\n</div> ","metadata":{}},{"cell_type":"markdown","source":"## 1st model - Linear Regression\n\n### What is Linear Regression ?\n\n> Linear regression analysis is used to predict the value of a variable based on the value of another variable.\n\n* The variable you want to predict is called the dependent variable. \n* The variable you are using to predict the other variable's value is called the independent variable.","metadata":{}},{"cell_type":"code","source":"# Define feature and target: According to the determined correlation, I chose the column temp as our feature and count as our target\nx= data[['temp']]\ny= data[['count']]\n\n# Splitting data to training and testing data\nx_train, x_test , y_train , y_test = train_test_split(x,y,test_size=.2,random_state=4)\n\n# Set the model and find coefficient and intercept\nregressor = LinearRegression()\nregressor.fit(x_train, y_train)\ncoefficient = regressor.coef_\nintercept = regressor.intercept_\nprint('coefficient = ',coefficient)\nprint('intercept = ',intercept)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict with our model on x_test\ny_predicted = regressor.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot data with fitline\nfig, axs = plt.subplots(1, 2, figsize=(20, 10))\nfig.suptitle('Our Graphs', fontweight='bold', fontsize=20)\naxs[0].scatter(x=x, y=y, c='blue', marker='*', linewidths=1, label='Data')\naxs[0].grid()\naxs[0].set(xlabel='weather', ylabel='count')\naxs[0].legend()\naxs[1].scatter(x=x_test, y=y_test, c='red', marker='*', linewidths=1, label='data_test')\naxs[1].scatter(x=x_train, y=y_train, c='blue', marker='*', linewidths=1, label='data_train')\naxs[1].legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create score table and a function to store all scores obtained from different models\nform = {'Model':[],'MAE':[],'MSE':[],'sqrt MSE':[]}\nscore_table = pd.DataFrame(data=form)\ndef store_scores(name_of_model,position_of_it_in_tabel, y_test, y_predicted):\n    score_table.loc[position_of_it_in_tabel,['Model','MAE','MSE','sqrt MSE']] =[name_of_model,\n                                                                int(metrics.mean_absolute_error(y_test, y_predicted))\n                                                                ,int(metrics.mean_squared_error(y_test, y_predicted))\n                                                                ,int(np.sqrt(metrics.mean_squared_error(y_test, y_predicted)))] \n    return score_table\n\nstore_scores('Linear Regression',0,y_test,y_predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2nd model: Linear Regression with multiple features\n\n### What is Multiple Linear Regression ?\n\n> Multiple linear regression is a regression model that estimates the relationship between a quantitative dependent variable and two or more independent variables using a straight line.","metadata":{}},{"cell_type":"code","source":"# Define features and target:\nx = data.iloc[:,:-3].values\ny = data.iloc[:,-1].values\n\n#Splitting the dataset into the Training set and Test set\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2, random_state=2)\n\n# Feature scaling (standardized)\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\n# Set the model\nregressor1 = LinearRegression()\nregressor1.fit(X=x_train, y=y_train)\ncoefficient = regressor1.coef_\nintercept = regressor1.intercept_\nprint('coefficient = ',coefficient)\nprint('intercept = ',intercept)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict with our model on x_test\ny_predicted = regressor1.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store scores of this model in table\nstore_scores('Mutiple Lienar Regression',1,y_test,y_predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3rd model: K nearest neighbours (KNN)\n\n### What is KNN ?\n> The KNN is a data classification method for estimating the likelihood that a data point will become a member of one group or another based on what group the data points nearest to it belong to.","metadata":{}},{"cell_type":"code","source":"# Define features and target:\nx = data.iloc[:,:-3].values\ny = data.iloc[:,-1].values\n\n#Splitting the dataset into the Training set and Test set\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2, random_state=2)\n\n# Feature scaling (standardized)\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we must find the optimal value for k with plotting MAE, so we have:\nMAE_list = []\nfor i in range(1,10):\n    \n    knn = KNeighborsRegressor(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    y_predicted = knn.predict(x_test)\n    MAE_list.append(metrics.mean_absolute_error(y_test,y_predicted))\n\n#Plot the values in MAE_list\nplt.figure(figsize=(10,6))\nplt.plot(range(1,10),MAE_list,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('MAE vs. K Value')\nplt.xlabel('K')\nplt.ylabel('MAE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# So the best k is equal to 2 for us\n# Set the model and train it\nknn = KNeighborsRegressor(n_neighbors=2)\nknn.fit(x_train,y_train)\ny_predicted = knn.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store scores of this model in score_table\nstore_scores('K_Nearest neighbour',2,y_test,y_predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4th model: Decision tree\n\n> Decision tree is a a tree-like model of decisions and their possible consequences, including chance event outcomes, resource costs, and utility. ","metadata":{}},{"cell_type":"code","source":"# Define features and target:\nx = data.iloc[:,:-3].values\ny = data.iloc[:,-1].values\n\n#Splitting the dataset into the Training set and Test set\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2, random_state=2)\n\n# Feature scaling (standardized)\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)\n\n# Set the model and train it\nregressor = DecisionTreeRegressor(random_state = 0)\nregressor.fit(x_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store scores of this model in score_table\nstore_scores('Decision tree',3,y_test,y_predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5th model: Random forest\n\n> Random forests or random decision forests is an ensemble learning method for classification, regression and other tasks that operates by constructing a multitude of decision trees at training time","metadata":{}},{"cell_type":"code","source":"# Define features and target:\nx = data.iloc[:,:-3].values\ny = data.iloc[:,-1].values\n\n#Splitting the dataset into the Training set and Test set\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2, random_state=2)\n\n# Feature scaling (standardized)\nsc = StandardScaler()\nx_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we must find the optimal value for estimators ot trees with plotting MAE, so we have:\nMAE_list =[]\nprint('The program is finding the best number for trees in the model. Please wait.')\nfor i in range(50,550,50):\n    regressor = RandomForestRegressor(n_estimators = i, random_state = 0)\n    regressor.fit(x_train,y_train)\n    y_predicted = regressor.predict(x_test)\n    MAE_list.append(metrics.mean_absolute_error(y_test,y_predicted))\n    print(\"({}% of the program completed)\".format(100*i//500))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the values in MAE_list\nplt.figure(figsize=(10,6))\nplt.plot(range(50,550,50),MAE_list,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('MAE vs. number of estimators(trees)')\nplt.xlabel('Trees')\nplt.ylabel('MAE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# So the best value for trees is equal to 250 for us\n# Set the model and train it\nregressor = RandomForestRegressor(n_estimators = 250, random_state = 0)\nregressor.fit(x_train,y_train)\ny_predicted = regressor.predict(x_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Store scores of this model in score_table\nstore_scores('Random Forest',4,y_test,y_predicted)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div class=\"alert alert-block \">\n    <h2 align=\"center\">Step 6: Find the Results</h2>\n</div> ","metadata":{}},{"cell_type":"code","source":"# Find the results for real data, which here is called test.csv file\n# Now it's time to run the best model \"Random forest\" with good results on test.csv file(real data) to predict Count values\nx_unseed = data_unseen.iloc[:,:].values # Set features of the dataset(test.csv, called data_unseen) to run prediction  on them\ny_unseen = regressor.predict(x_unseed)\n\n# Turn y_unseen to a data frame \ny_unseen = pd.DataFrame(data= y_unseen, columns=['Count'])\n\n# Concatenate y_unseen to data_unseen and name it sampleSubmission , cause it's from Competition Notebook\nsampleSubmission = pd.concat([data_unseen, y_unseen], axis=1)\n# Save this results as sampleSubmission.csv\nsampleSubmission.to_csv(path_or_buf='result.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Congratulations \n\n- Congratulations. We have done it together.Take a look at scores and results in the real data !\n- Also you can find the result on right sidebar on output section , called result.csv","metadata":{}},{"cell_type":"code","source":"score_table","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reference\n\n\n* [Competition Playground ](https://www.kaggle.com/competitions/bike-sharing-demand/overview)\n* [Unknown Author from GitHub/TDS on Linear / Multiple Linear Regression Section(?)]()\n* [Bike Sharing Demand](https://www.kaggle.com/code/werooring/bike-sharing-demand-top-6-6-solution)\n* [EDA , Linear Regression , KNN , Decision Tree](https://www.kaggle.com/code/ramasalahat/eda-linear-regression-ridge-k-nn-decision-tree)","metadata":{}}]}