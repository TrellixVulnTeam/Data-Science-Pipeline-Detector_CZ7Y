{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 1. Data Loading & Checking\n\n> #### 1.1 Data Loading\n> #### 1.2 Train, Test Data 정보 확인\n> #### 1.3 결측치 확인\n> #### 1.4 Feature 타입 확인 "},{"metadata":{},"cell_type":"markdown","source":"## 1.1 Data Loading"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 초기 설정\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom pathlib import Path\nfrom IPython.display import display\nfrom datetime import datetime\nfrom pandas import DataFrame\nfrom typing import List, NamedTuple, Tuple\n\n# allow plots to appear directly in the notebook\n%matplotlib \n\n# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\npd.set_option('display.max_rows', 100)\npd.set_option('display.max_columns', 50)\npd.set_option('display.width', 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 필요 함수 선언\ndef load(path: Path) -> DataFrame:\n#     return pd.read_csv(path)\n    return pd.read_csv(path, parse_dates=True, index_col=\"datetime\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ROOT_DIR = Path(\"/kaggle/input/bike-sharing-demand\")\nTRAIN_DATA_PATH = ROOT_DIR / \"train.csv\"\nTEST_DATA_PATH = ROOT_DIR / \"test.csv\"\nTARGET_NAME = 'count'\n\noriginal_train: DataFrame = load(TRAIN_DATA_PATH)\noriginal_test: DataFrame = load(TEST_DATA_PATH)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Train, Test 정보 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"only_train_columns = [c1 for c1 in original_train.columns if not c1 in original_test.columns and c1 != TARGET_NAME]\nprint('Only Train Columns')\nprint(only_train_columns)\nonly_test_columns = [c1 for c1 in original_test.columns if not c1 in original_train.columns]\nprint('Only Test Columns')\nprint(only_test_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 결측치 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.4 feature 타입 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"original_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. EDA\n\n> #### 2.1 Target 분포 확인 및 정규화\n> #### 2.2 Feature 분포 확인 및 정규화\n> #### 2.3 Feature간 관계 확인 및 정규화\n> #### 2.4 Feature와 Target의 관계 확인 및 정규화"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = [c1 for c1 in original_train.columns if c1 in original_test.columns and c1 != TARGET_NAME]\nfeature_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_feature_columns=['season', 'holiday', 'workingday', 'weather',]\nnumeric_feature_columns=['temp', 'atemp', 'humidity', 'windspeed']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.1 Target 분포 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(original_train[TARGET_NAME])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Feature 분포 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_distplot(df, name, fig, m, n, idx):\n    ax = fig.add_subplot(m, n, idx)\n    ax = sns.distplot(df[name])\n\ndef draw_distplots(df, columns):\n    M = round(len(columns)/2)\n    N = 2\n    fig = plt.figure(figsize=[N*10, M*6])\n    for idx, name in enumerate(columns):\n        draw_distplot(df=df, name=name, fig=fig, m=M, n=N, idx=idx+1)\n        \ndraw_distplots(df=original_train, columns=feature_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Feature간 관계 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(original_train[feature_columns])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(original_train[feature_columns].corr(), annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.4 Target&Feature 관계 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_boxplot(df, x_name, y_name, fig, m, n, idx): \n    ax = fig.add_subplot(m, n, idx)\n    ax = sns.boxplot(data=df, x=x_name, y=y_name)\n\ndef draw_boxplots(df, x_columns, y_name):\n    M = round(len(x_columns)/2)\n    N = 2\n    fig = plt.figure(figsize=[N*10, M*6])\n    for idx, name in enumerate(x_columns):\n        draw_boxplot(df=df, x_name=name,y_name=y_name, fig=fig, m=M, n=N, idx=idx+1)\n        \ndraw_boxplots(df=original_train, x_columns=categorical_feature_columns, y_name=TARGET_NAME)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_scatterplot(df, x_name, y_name, fig, m, n, idx): \n    ax = fig.add_subplot(m, n, idx)\n    ax = sns.scatterplot(data=df, x=x_name, y=y_name)\n\ndef draw_scatterplots(df, x_columns, y_name):\n    M = round(len(x_columns)/2)\n    N = 2\n    fig = plt.figure(figsize=[N*10, M*6])\n    for idx, name in enumerate(x_columns):\n        draw_scatterplot(df=df, x_name=name,y_name=y_name, fig=fig, m=M, n=N, idx=idx+1)\n        \ndraw_scatterplots(df=original_train, x_columns=numeric_feature_columns, y_name=TARGET_NAME)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Data Preprocessing\n\n> #### 3.1 결측치 확인 및 처리\n> #### 3.2 Feature 타입 변환\n> #### 3.3 Column 값 표준화(대소문자, 같은 의미 데이터 통합)\n\n"},{"metadata":{},"cell_type":"markdown","source":"## 3.1 결측치 확인 및 처리"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = original_train.copy()\ntest_data = original_test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"original_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3.2 Feature 타입 변환"},{"metadata":{"trusted":true},"cell_type":"code","source":"#categorical columns change to one-hot encoding data\n\ndef replaced_with_onehot_cols(data: DataFrame, col_names: List[str]) -> DataFrame:\n    data = data.copy()\n    \n    for col_name in col_names:\n        one_hot = pd.get_dummies(data[col_name], prefix=col_name)\n        data = data.join(one_hot)\n        \n        # Original column is not needed anymore\n        del data[col_name]\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = replaced_with_onehot_cols(data=train_data, col_names=categorical_feature_columns)\ntest_data = replaced_with_onehot_cols(data=test_data, col_names=categorical_feature_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 4. Feature Engineering\n\n> #### 4.1 Feature 생성/추출/변환\n> #### 4.2 Target/Feature 정규화\n> #### 4.3 Feature importances 확인"},{"metadata":{},"cell_type":"markdown","source":"## 4.1 Feature 생성/추출/변환"},{"metadata":{"trusted":true},"cell_type":"code","source":"#remove only_train_columns\ntrain_data = train_data.drop(only_train_columns, axis=1)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#seperate datetime index\ndef expanded_index_datetime_col(data: DataFrame) -> DataFrame:\n    data = data.copy()\n    data[\"hour\"] = data.index.hour\n    data[\"weekday\"] = data.index.weekday\n    data[\"month\"] = data.index.month\n    data[\"year\"] = data.index.year\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = expanded_index_datetime_col(data=train_data)\ntest_data = expanded_index_datetime_col(data=test_data)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#change datetime data to one-hot data\ndatetime_cols = ['hour', 'weekday','month','year']\ntrain_data = replaced_with_onehot_cols(data=train_data, col_names=datetime_cols)\ntest_data = replaced_with_onehot_cols(data=test_data, col_names=datetime_cols)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.2 Target/Feature 정규화"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\ndef normalize_cols(df: DataFrame, scaler) -> DataFrame:\n    df = df.copy()\n    return DataFrame(scaler.fit_transform(df.values), columns=df.columns, index=df.index)\n\nx_scaler = MinMaxScaler()\nx = train_data.drop(TARGET_NAME, axis=1)\nx = normalize_cols(df=x, scaler=x_scaler)\n\ny_scaler = MinMaxScaler()\ny = train_data[[TARGET_NAME]]\ny = normalize_cols(df=y, scaler=y_scaler)\n\ntest_data =  normalize_cols(df=test_data, scaler=x_scaler)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4.3 Feature Importance 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor()\n\nresult = model.fit(x.values, y.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features = pd.DataFrame()\nfeatures[\"features\"] = x.columns\nfeatures[\"coefficient\"] = model.feature_importances_\n\nfeatures.sort_values(by=[\"coefficient\"], ascending=False, inplace=True)\nfig,ax= plt.subplots()\nfig.set_size_inches(20,20)\nsns.barplot(data=features, x=\"coefficient\", y=\"features\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 5. Modeling\n\n> #### 5.1 학습\n> #### 5.2 모델 선택 및 튜닝"},{"metadata":{},"cell_type":"markdown","source":"## 5.1 학습"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install livelossplot tensorflow-gpu\nimport tensorflow.keras.backend as K\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Split train, test data\nfrom sklearn.model_selection import train_test_split\nrandom_seed = 5\n\nx_train, x_validation, y_train, y_validation = train_test_split(x, y, test_size=0.3, shuffle=True, random_state=random_seed)\n\nprint('train data count : ' + str(len(x_train)))\nprint('test data count : ' + str(len(x_validation)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make cost function\nfrom sklearn import metrics\ndef rmsle_K(y, pred):\n    return K.sqrt(K.mean(K.square(tf.math.log1p(y) - tf.math.log1p(pred))))\ndef rmsle(y, pred):\n    return np.sqrt(metrics.mean_squared_error(y, pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make result\nclass ModelResult():\n    def __init__(self, name, cost, model):\n        self.name = name\n        self.cost = cost\n        self.model = model\n    def __str__(self):\n        return self.name+\"\\tcost:\"+str(self.cost)\nresults = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make DL Models\nfrom tensorflow.keras.layers import Input, Dense, Dropout\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n\n_, NUM_FEATURES = x_train.shape\n\ndef make_dl_model()-> Model:\n    input = Input(shape=(NUM_FEATURES, ))\n    _ = Dense(32, activation='relu')(input)\n    _ = Dropout(0.4)(_)\n    _ = Dense(32, activation='relu')(_)\n    _ = Dropout(0.4)(_)\n    _ = Dense(16, activation='relu')(_)\n    output = Dense(1, activation='relu')(_)\n    model = Model(inputs=input, outputs=output)\n    model.compile(optimizer='adam', loss=rmsle_K, metrics=['mse'])\n    return model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = make_dl_model()\nmodel.fit(x_train,y_train, validation_data=(x_validation,y_validation),\n         epochs=200, batch_size=128, verbose=1,\n         callbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.4, patience=5, min_lr=0.000001, verbose=1),\n                    EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0),\n                    ]\n         )\nresults.append(ModelResult(name='DL',cost=rmsle(y_validation, model.predict(x_validation)), model=model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Make ML Models\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\n\nml_models = {\n    'LinearRegression': LinearRegression(),\n    'LassoRegression': Lasso(),\n    'RidgeRegression': Ridge(),\n    'ElasticNet': ElasticNet(),\n    'RandomForestRegressor': RandomForestRegressor(),\n    'XGBRegressor': XGBRegressor()\n}\n\n#train ML Models\nfor name, model in ml_models.items():\n    model.fit(x_train, y_train)\n    results.append(ModelResult(name=name,cost=rmsle(y_validation, model.predict(x_validation)), model=model))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for r in results:\n    print(r)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 5.2 모델 선택 및 튜닝"},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted_result= sorted(results, key=lambda result: result.cost)   \nfor r in sorted_result:\n    print(r)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 6. Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"best_model = sorted_result[0].model\ny_pred = best_model.predict(test_data)\ny_pred = y_scaler.inverse_transform(y_pred.reshape(-1, 1)).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Save Submission\nsubmission = test_data.copy()\nsubmission[\"datetime\"] = test_data.index\nsubmission[\"count\"] = y_pred.astype(int)\nsubmission = submission[[\"datetime\", \"count\"]]\nsubmission.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}