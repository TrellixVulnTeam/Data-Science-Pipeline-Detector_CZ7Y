{"cells":[{"metadata":{},"cell_type":"markdown","source":"\nTeam Name - Notebook\n\nTeam Members -\nDaksha Pareek (2019mc21080)\nRanjan Mathur (2018mc21571)\n    \nThe notebook covers below models\n- Regularization Model - Ridge\n- Regularization Model - Lasso\n- Regression Tree with Pruning\n- Ensemble Model - Gradient Boost\n- Ensemble Models - Random Forest\n1. \n**About Dataset**"},{"metadata":{},"cell_type":"markdown","source":"**Overview**\nBike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.\n\n**Data Fields**\ndatetime - hourly date + timestamp\nseason - 1 = spring, 2 = summer, 3 = fall, 4 = winter\nholiday - whether the day is considered a holiday\nworkingday - whether the day is neither a weekend nor holiday\nweather -\n\n* Clear, Few clouds, Partly cloudy, Partly cloudy\n* Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n* Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n* Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\n* temp - temperature in Celsius\n* atemp - \"feels like\" temperature in Celsius\n* humidity - relative humidity\n* windspeed - wind speed\n* casual - number of non-registered user rentals initiated\n* registered - number of registered user rentals initiated\n* count - number of total rentals (Dependent Variable)"},{"metadata":{"trusted":true},"cell_type":"code","source":"import IPython\ndisplay(\"IPython version: {}\". format(IPython.__version__)) \n\nfrom IPython.display import display \n\nimport sys\ndisplay(\"Python version: {}\". format(sys.version))\n\nimport sklearn\ndisplay(\"scikit-learn version: {}\". format(sklearn.__version__))\n\nimport pylab\nimport calendar\nimport numpy as np\ndisplay(\"NumPy version: {}\". format(np.__version__))\nimport pandas as pd\ndisplay(\"pandas version: {}\". format(pd.__version__))\n\nimport seaborn as sn\nfrom scipy import stats\nimport missingno as msno\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport warnings\n\n\npd.options.mode.chained_assignment = None\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n%matplotlib inline\n\n\n\nfrom sklearn import svm, tree, linear_model, neighbors, naive_bayes, ensemble, discriminant_analysis, gaussian_process\nfrom xgboost import XGBClassifier\n\n#Common Model Helpers\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder\nfrom sklearn import feature_selection\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.model_selection import cross_val_score\npd.set_option(\"max_colwidth\", None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dailyData = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Summary**\n\nAs a first step lets do three simple steps on the dataset\n\n* Size of the dataset\n* Get a glimpse of data by printing few rows of it.\n* What type of variables contribute our data"},{"metadata":{},"cell_type":"markdown","source":"Shape of Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"dailyData.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Sample Of First Few Rows"},{"metadata":{"trusted":true},"cell_type":"code","source":"dailyData.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Variables Data Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"dailyData.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering**\n\nAs we see from the above results, the columns \"season\",\"holiday\",\"workingday\" and \"weather\" should be of \"categorical\" data type.But the current data type is \"int\" for those columns. Let us transform the dataset in the following ways so that we can get started up with our EDA\n\n* Create new columns \"date,\"hour\",\"weekDay\",\"month\" from \"datetime\" column.\n* Coerce the datatype of \"season\",\"holiday\",\"workingday\" and weather to category.\n* Drop the datetime column as we already extracted useful features from it."},{"metadata":{},"cell_type":"markdown","source":"Creating New Columns From \"Datetime\" Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"dailyData[\"date\"] = dailyData.datetime.apply(lambda x : x.split()[0])\ndailyData[\"hour\"] = dailyData.datetime.apply(lambda x : x.split()[1].split(\":\")[0])\ndailyData[\"weekday\"] = dailyData.date.apply(lambda dateString : calendar.day_name[datetime.strptime(dateString,\"%Y-%m-%d\").weekday()])\ndailyData[\"month\"] = dailyData.date.apply(lambda dateString : calendar.month_name[datetime.strptime(dateString,\"%Y-%m-%d\").month])\ndailyData[\"season\"] = dailyData.season.map({1: \"Spring\", 2 : \"Summer\", 3 : \"Fall\", 4 :\"Winter\" })\ndailyData[\"weather\"] = dailyData.weather.map({1: \" Clear + Few clouds + Partly cloudy + Partly cloudy\",\\\n                                        2 : \" Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \", \\\n                                        3 : \" Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\", \\\n                                        4 :\" Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \" })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coercing To Category Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"categoryVariableList = [\"hour\",\"weekday\",\"month\",\"season\",\"weather\",\"holiday\",\"workingday\"]\nfor var in categoryVariableList:\n    dailyData[var] = dailyData[var].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping Unncessary Columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"dailyData  = dailyData.drop([\"datetime\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets Start With Very Simple Visualization Of Variables DataType Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataTypeDf = pd.DataFrame(dailyData.dtypes.value_counts()).reset_index().rename(columns={\"index\":\"variableType\",0:\"count\"})\nfig,ax = plt.subplots()\nfig.set_size_inches(12,5)\ndataTypeDf['variableType'] = dataTypeDf['variableType'].astype('str')\nsn.barplot(data=dataTypeDf,x=\"variableType\",y=\"count\",ax=ax)\nax.set(xlabel='variableTypeariable Type', ylabel='Count',title=\"Variables DataType Count\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Missing Values Analysis**\nOnce we get hang of the data and columns, next step we geneally is to find out whether we have any missing values in our data. Luckily we dont have any missing value in the dataset. One way which I generally prefer to visualize missing value in the dataset is through \"missingno\".\n\nIts a quiet handy library to quickly visualize variables for missing values. As I mentioned earlier we got lucky this time as there no missing value in the dataset.\n\n**Skewness In Distribution**\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(dailyData,figsize=(12,5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Outliers Analysis**\nAt first look, \"count\" variable contains lot of outlier data points which skews the distribution towards right (as there are more data points beyond Outer Quartile Limit).But in addition to that, following inferences can also been made from the simple boxplots given below.\n\n* Spring season has got relatively lower count.The dip in median value in boxplot gives evidence for it.\n* The boxplot with \"Hour Of The Day\" is quiet interesting.The median value are relatively higher at 7AM - 8AM and 5PM - 6PM. It can be attributed to regular school and office users at that time.\n* Most of the outlier points are mainly contributed from \"Working Day\" than \"Non Working Day\". It is quiet visible from from figure 4."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=2)\nfig.set_size_inches(15, 15)\nsn.boxplot(data=dailyData,y=\"count\",orient=\"v\",ax=axes[0][0])\nsn.boxplot(data=dailyData,y=\"count\",x=\"season\",orient=\"v\",ax=axes[0][1])\nsn.boxplot(data=dailyData,y=\"count\",x=\"hour\",orient=\"v\",ax=axes[1][0])\nsn.boxplot(data=dailyData,y=\"count\",x=\"workingday\",orient=\"v\",ax=axes[1][1])\n\naxes[0][0].set(ylabel='Count',title=\"Box Plot On Count\")\naxes[0][1].set(xlabel='Season', ylabel='Count',title=\"Box Plot On Count Across Season\")\naxes[1][0].set(xlabel='Hour Of The Day', ylabel='Count',title=\"Box Plot On Count Across Hour Of The Day\")\naxes[1][1].set(xlabel='Working Day', ylabel='Count',title=\"Box Plot On Count Across Working Day\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remove Outliers In The Count Column"},{"metadata":{"trusted":true},"cell_type":"code","source":"dailyDataWithoutOutliers = dailyData[np.abs(dailyData[\"count\"]-dailyData[\"count\"].mean())<=(3*dailyData[\"count\"].std())] \ndisplay(\"Shape Of the dataframe before Ouliers: \",dailyData.shape)\ndisplay(\"Shape Of the dataframe after Ouliers: \",dailyDataWithoutOutliers.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Correlation Analysis**\nOne common to understand how a dependent variable is influenced by features (numerical) is to fibd a correlation matrix between them. Lets plot a correlation plot between \"count\" and [\"temp\",\"atemp\",\"humidity\",\"windspeed\"].\n\n* temp and humidity features has got positive and negative correlation with count respectively.Although the correlation between them are not very prominent still the count variable has got little dependency on \"temp\" and \"humidity\".\n* windspeed is not gonna be really useful numerical feature and it is visible from it correlation value with \"count\"\n* \"atemp\" is variable is not taken into since \"atemp\" and \"temp\" has got strong correlation with each other. During model building any one of the variable has to be dropped since they will exhibit multicollinearity in the data.\n* \"Casual\" and \"Registered\" are also not taken into account since they are leakage variables in nature and need to dropped during model building.\nRegression plot in seaborn is one useful way to depict the relationship between two features. Here we consider \"count\" vs \"temp\", \"humidity\", \"windspeed\"."},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatt = dailyData[[\"temp\",\"atemp\",\"casual\",\"registered\",\"humidity\",\"windspeed\",\"count\"]].corr()\nmask = np.array(corrMatt)\nmask[np.tril_indices_from(mask)] = False\nfig,ax= plt.subplots()\nfig.set_size_inches(20,10)\nsn.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #correlation heatmap of dataset\n# def correlation_heatmap(df):\n#     _ , ax = plt.subplots(figsize =(14, 12))\n#     colormap = sn.diverging_palette(220, 10, as_cmap = True)\n    \n#     _ = sn.heatmap(\n#         df.corr(), \n#         cmap = colormap,\n#         square=True, \n#         cbar_kws={'shrink':.9 }, \n#         ax=ax,\n#         annot=True, \n#         linewidths=0.1,vmax=1.0, linecolor='white',\n#         annot_kws={'fontsize':12 }\n#     )\n    \n#     plt.title('Pearson Correlation of Features', y=1.05, size=15)\n\n# correlation_heatmap(dailyData)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2,ax3) = plt.subplots(ncols=3)\nfig.set_size_inches(12, 5)\nsn.regplot(x=\"temp\", y=\"count\", data=dailyData,ax=ax1)\nsn.regplot(x=\"windspeed\", y=\"count\", data=dailyData,ax=ax2)\nsn.regplot(x=\"humidity\", y=\"count\", data=dailyData,ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing Distribution Of Data**\nAs it is visible from the below figures that \"count\" variable is skewed towards right. It is desirable to have Normal distribution as most of the machine learning techniques require dependent variable to be Normal. One possible solution is to take log transformation on \"count\" variable after removing outlier data points. After the transformation the data looks lot better but still not ideally following normal distribution."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(ncols=2,nrows=2)\nfig.set_size_inches(12, 10)\nsn.distplot(dailyData[\"count\"],ax=axes[0][0])\nstats.probplot(dailyData[\"count\"], dist='norm', fit=True, plot=axes[0][1])\nsn.distplot(np.log(dailyDataWithoutOutliers[\"count\"]),ax=axes[1][0])\nstats.probplot(np.log1p(dailyDataWithoutOutliers[\"count\"]), dist='norm', fit=True, plot=axes[1][1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing Count Vs (Month,Season,Hour,Weekday,Usertype)**\n* It is quiet obvious that people tend to rent bike during summer season since it is really conducive to ride bike at that season.Therefore June, July and August has got relatively higher demand for bicycle.\n* On weekdays more people tend to rent bicycle around 7AM-8AM and 5PM-6PM. As we mentioned earlier this can be attributed to regular school and office commuters.\n* Above pattern is not observed on \"Saturday\" and \"Sunday\".More people tend to rent bicycle between 10AM and 4PM.\n* The peak user count around 7AM-8AM and 5PM-6PM is purely contributed by registered user."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2,ax3,ax4)= plt.subplots(nrows=4)\nfig.set_size_inches(12,20)\nsortOrder = [\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"]\nhueOrder = [\"Sunday\",\"Monday\",\"Tuesday\",\"Wednesday\",\"Thursday\",\"Friday\",\"Saturday\"]\n\nmonthAggregated = pd.DataFrame(dailyData.groupby(\"month\")[\"count\"].mean()).reset_index()\nmonthSorted = monthAggregated.sort_values(by=\"count\",ascending=False)\nsn.barplot(data=monthSorted,x=\"month\",y=\"count\",ax=ax1,order=sortOrder)\nax1.set(xlabel='Month', ylabel='Avearage Count',title=\"Average Count By Month\")\n\nhourAggregated = pd.DataFrame(dailyData.groupby([\"hour\",\"season\"],sort=True)[\"count\"].mean()).reset_index()\nsn.pointplot(x=hourAggregated[\"hour\"], y=hourAggregated[\"count\"],hue=hourAggregated[\"season\"], data=hourAggregated, join=True,ax=ax2)\nax2.set(xlabel='Hour Of The Day', ylabel='Users Count',title=\"Average Users Count By Hour Of The Day Across Season\",label='big')\n\nhourAggregated = pd.DataFrame(dailyData.groupby([\"hour\",\"weekday\"],sort=True)[\"count\"].mean()).reset_index()\nsn.pointplot(x=hourAggregated[\"hour\"], y=hourAggregated[\"count\"],hue=hourAggregated[\"weekday\"],hue_order=hueOrder, data=hourAggregated, join=True,ax=ax3)\nax3.set(xlabel='Hour Of The Day', ylabel='Users Count',title=\"Average Users Count By Hour Of The Day Across Weekdays\",label='big')\n\nhourTransformed = pd.melt(dailyData[[\"hour\",\"casual\",\"registered\"]], id_vars=['hour'], value_vars=['casual', 'registered'])\nhourAggregated = pd.DataFrame(hourTransformed.groupby([\"hour\",\"variable\"],sort=True)[\"value\"].mean()).reset_index()\nsn.pointplot(x=hourAggregated[\"hour\"], y=hourAggregated[\"value\"],hue=hourAggregated[\"variable\"],hue_order=[\"casual\",\"registered\"], data=hourAggregated, join=True,ax=ax4)\nax4.set(xlabel='Hour Of The Day', ylabel='Users Count',title=\"Average Users Count By Hour Of The Day Across User Type\",label='big')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So we have visualized the data to a greater extent.So lets go and build some models and see how close we can predict the results.\n\n**Filling 0's In windspeed Using Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import stats\n\ndataTrain = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")\n#dataTrain = dataTrain5[np.abs(dataTrain5[\"count\"]-dataTrain5[\"count\"].mean())<=(3*dataTrain5[\"count\"].std())] \n\n\n#dataTrain = dailyDataWithoutOutliers.copy(deep=True)\ndataTest = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\")\n\ndisplay(dataTrain.info()) \ndisplay(dataTrain.sample(10))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display('Train columns with null values:\\n', dataTrain.isnull().sum())\ndisplay(\"-\"*10)\n\ndisplay('Test/Validation columns with null values:\\n', dataTest.isnull().sum())\ndisplay(\"-\"*10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(dataTrain.describe(include = 'all'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(dataTest.describe(include = 'all'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Combine Train And Test"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = dataTrain.append(dataTest)\ndata.reset_index(inplace=True)\ndata.drop('index',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"date\"] = data.datetime.apply(lambda x : x.split()[0])\ndata[\"hour\"] = data.datetime.apply(lambda x : x.split()[1].split(\":\")[0]).astype(\"int\")\ndata[\"year\"] = data.datetime.apply(lambda x : x.split()[0].split(\"-\")[0])\ndata[\"weekday\"] = data.date.apply(lambda dateString : datetime.strptime(dateString,\"%Y-%m-%d\").weekday())\ndata[\"month\"] = data.date.apply(lambda dateString : datetime.strptime(dateString,\"%Y-%m-%d\").month)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest Model To Predict 0's In Windspeed"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\ndataWind0 = data[data[\"windspeed\"]==0]\ndataWindNot0 = data[data[\"windspeed\"]!=0]\nrfModel_wind = RandomForestRegressor()\nwindColumns = [\"season\",\"weather\",\"humidity\",\"month\",\"temp\",\"year\",\"atemp\"]\nrfModel_wind.fit(dataWindNot0[windColumns], dataWindNot0[\"windspeed\"])\n\nwind0Values = rfModel_wind.predict(X= dataWind0[windColumns])\ndataWind0[\"windspeed\"] = wind0Values\ndata = dataWindNot0.append(dataWind0)\ndata.reset_index(inplace=True)\ndata.drop('index',inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Coercing To Categorical Type"},{"metadata":{"trusted":true},"cell_type":"code","source":"categoricalFeatureNames = [\"season\",\"holiday\",\"workingday\",\"weather\",\"weekday\",\"month\",\"year\",\"hour\"]\nnumericalFeatureNames = [\"temp\",\"humidity\",\"windspeed\",\"atemp\"]\ndropFeatures = ['casual',\"count\",\"datetime\",\"date\",\"registered\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for var in categoricalFeatureNames:\n    data[var] = data[var].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting Train And Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataTrain1 = data[pd.notnull(data['count'])].sort_values(by=[\"datetime\"])\ndataTest1 = data[~pd.notnull(data['count'])].sort_values(by=[\"datetime\"])\ndatetimecol = dataTest[\"datetime\"]\nyLablesRegistered = dataTrain1[\"registered\"]\nyLablesCasual = dataTrain1[\"casual\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping Unncessary Variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import asarray\nfrom sklearn.preprocessing import MinMaxScaler\n\nfeatures = [\"temp\",\"atemp\",\"humidity\",\"windspeed\"]\ndataTrain2  = dataTrain1[dataTrain1[features].apply(lambda x: np.abs(x - x.mean()) / x.std() < 3).all(axis=1)]\n\nyLabels = dataTrain2[\"count\"]\n\ndisplay(dataTrain2)\ndisplay(dataTrain2)\n\ndataTrain3  = dataTrain2.drop(dropFeatures,axis=1)\ndataTest2  = dataTest1.drop(dropFeatures,axis=1)\n\n\n\n\n\n# define min max scaler\nscaler = MinMaxScaler()\n# transform data\ndataTrain = scaler.fit_transform(dataTrain3)\ndisplay(dataTrain)\ndataTest = scaler.fit_transform(dataTest2)\ndisplay(dataTrain)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y, y_,convertExp=True):\n    if convertExp:\n        y = np.exp(y),\n        y_ = np.exp(y_)\n    log1 = np.nan_to_num(np.array([np.log(v + 1) for v in y]))\n    log2 = np.nan_to_num(np.array([np.log(v + 1) for v in y_]))\n    calc = (log1 - log2) ** 2\n    return np.sqrt(np.mean(calc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"summary_data = {'ModelName':[],\n\t'RootMeanSquaredError':[],\n\t'RSquare':[],\n\t'RMSLE':[], \n\t'TrainingScore': [],\n\t'TestingScore': [], \n    'IdealCondition':[]\n    }\n\ndf_summary = pd.DataFrame(summary_data)\ndf_summary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mean_squared_error(actual, pred): \n    actual, pred = np.array(actual), np.array(pred)\n    return np.square(np.subtract(actual,pred)).mean() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(actual, pred): \n    actual, pred = np.array(actual), np.array(pred)\n    return np.sqrt(np.square(np.subtract(actual,pred)).mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Regression Tree with Pruning**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score\n\n\nyLabelsLog = np.log1p(yLabels)\n\n\nreg = DecisionTreeRegressor()\nparameters = {'max_depth':[5,6,7,8,9,10]}\n\nreg = RandomizedSearchCV(reg,parameters, cv = 10,refit = True)\nreg.fit(dataTrain, yLabelsLog)     \n\npreds = reg.predict(X= dataTrain)\n\n\nrmsle_1 =rmsle(np.exp(yLabelsLog),np.exp(preds),False)\ndisplay (\"RMSLE Value: \",rmsle_1)\n\nrmse_1 = rmse(yLabelsLog,preds)\n\ndisplay( \"Root Mean squared Error\", rmse_1)\nr2 = r2_score(yLabelsLog, preds)\ndisplay(\"R Square Value\", r2)\n\ntrain_score = reg.score(dataTrain, yLabelsLog)\n\ndisplay(\"Training Score\", train_score ) \npredsTest = reg.predict(X= dataTest)\ntest_score =reg.score(dataTest, np.exp(predsTest))\ndisplay(\"Testing Score\", test_score ) \n\nnew_row = {'ModelName':'Regression Tree with Pruning', 'RootMeanSquaredError':rmse_1, 'RSquare':r2, 'RMSLE':rmsle_1,'TrainingScore':train_score, 'TestingScore': test_score   ,'IdealCondition': 'The most ideal result would be an RMSE value of zero and R-squared value of 1'}\n\ndf_summary = df_summary.append([new_row], ignore_index=True)\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsn.distplot(yLabels,ax=ax1,bins=50)\nsn.distplot(np.exp(predsTest),ax=ax2,bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Regularization Model - Ridge**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\n\nridge_m_ = Ridge()\nridge_params_ = { 'max_iter':[3000],'alpha':[0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000]}\nrmsle_scorer = metrics.make_scorer(rmsle, greater_is_better=False)\ngrid_ridge_m = GridSearchCV( ridge_m_,\n                          ridge_params_,\n                          scoring = rmsle_scorer,\n                          cv=10)\nyLabelsLog = np.log1p(yLabels)\n\ngrid_ridge_m.fit( dataTrain, yLabelsLog )\npreds = grid_ridge_m.predict(X= dataTrain)\n\n\nrmse_1 = np.sqrt(mean_squared_error(yLabelsLog,preds))\n\ndisplay (grid_ridge_m.best_params_)\nr2= r2_score(yLabelsLog, preds)\nrmsle_1 = rmsle(np.exp(yLabelsLog),np.exp(preds),False)\n\ndisplay( \"Root Mean squared Error\", rmse_1)\ndisplay(\"R Square Value\", r2)\n\ndisplay (\"RMSLE Value: \",rmsle_1)\ntrain_score = grid_ridge_m.score(dataTrain, yLabelsLog)\ndisplay(\"Training Score\", train_score ) \npredsTest = grid_ridge_m.predict(X= dataTest)\n\ntest_score =grid_ridge_m.score(dataTest, np.exp(predsTest))\n\ndisplay(\"Testing Score\", test_score ) \n\n\nnew_row = {'ModelName':'Regularization Model - Ridge', 'RootMeanSquaredError':rmse_1, 'RSquare':r2, 'RMSLE':rmsle_1,'TrainingScore':train_score, 'TestingScore': test_score, 'IdealCondition': 'The most ideal result would be an RMSE value of zero and R-squared value of 1'}\ndf_summary = df_summary.append([new_row], ignore_index=True)\n\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsn.distplot(yLabels,ax=ax1,bins=50)\nsn.distplot(np.exp(predsTest),ax=ax2,bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"![](http://)**Regularization Model - Lasso**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\n\nlasso_m_ = Lasso()\n\nalpha  = 1/np.array([0.1, 1, 2, 3, 4, 10, 30,100,200,300,400,800,900,1000])\nlasso_params_ = { 'max_iter':[3000],'alpha':alpha}\n\ngrid_lasso_m = GridSearchCV( lasso_m_,lasso_params_,scoring = rmsle_scorer,cv=10)\nyLabelsLog = np.log1p(yLabels)\ngrid_lasso_m.fit( dataTrain, yLabelsLog )\npreds = grid_lasso_m.predict(X= dataTrain)\ndisplay (grid_lasso_m.best_params_)\n\n\nrmse_1 = np.sqrt(mean_squared_error(yLabelsLog,preds))\n\ndisplay (grid_lasso_m.best_params_)\nr2= r2_score(yLabelsLog, preds)\nrmsle_1 = rmsle(np.exp(yLabelsLog),np.exp(preds),False)\n\ndisplay( \"Root Mean squared Error\", rmse_1)\ndisplay(\"R Square Value\", r2)\n\ndisplay (\"RMSLE value: \",rmsle_1)\ntrain_score = grid_lasso_m.score(dataTrain, yLabelsLog)\ndisplay(\"Training Score\", train_score ) \npredsTest = grid_lasso_m.predict(X= dataTest)\ntest_score =grid_lasso_m.score(dataTest, np.exp(predsTest))\ndisplay(\"Testing Score\", test_score ) \n\nnew_row = {'ModelName':'Regularization Model - Lasso', 'RootMeanSquaredError':rmse_1, 'RSquare':r2, 'RMSLE':rmsle_1, 'TrainingScore':train_score, 'TestingScore': test_score, 'IdealCondition': 'The most ideal result would be an RMSE value of zero and R-squared value of 1'}\ndf_summary = df_summary.append([new_row], ignore_index=True)\n\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsn.distplot(yLabels,ax=ax1,bins=50)\nsn.distplot(np.exp(predsTest),ax=ax2,bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ensemble Models - Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfModel = RandomForestRegressor(n_estimators=100)\nyLabelsLog = np.log1p(yLabels)\nrfModel.fit(dataTrain,yLabelsLog)\npreds = rfModel.predict(X= dataTrain)\n\n\nrmse_1 = np.sqrt(mean_squared_error(yLabelsLog,preds))\n\nr2= r2_score(yLabelsLog, preds)\nrmsle_1 = rmsle(np.exp(yLabelsLog),np.exp(preds),False)\n\ndisplay( \"Root Mean squared Error\", rmse_1)\ndisplay(\"R Square Value\", r2)\n\ndisplay (\"RMSLE Value: \",rmsle_1)\ntrain_score = rfModel.score(dataTrain, yLabelsLog)\ndisplay(\"Training Score\", train_score ) \npredsTest = rfModel.predict(X= dataTest)\n\noutput =predsTest\n\ntest_score =rfModel.score(dataTest, np.exp(predsTest))\ndisplay(\"Testing Score\", test_score ) \n\nnew_row = {'ModelName':'Ensemble Models - Random Forest', 'RootMeanSquaredError':rmse_1, 'RSquare':r2, 'RMSLE':rmsle_1, 'TrainingScore':train_score, 'TestingScore': test_score, 'IdealCondition': 'The most ideal result would be an RMSE value of zero and R-squared value of 1'}\ndf_summary = df_summary.append([new_row], ignore_index=True)\n\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsn.distplot(yLabels,ax=ax1,bins=50)\nsn.distplot(np.exp(predsTest),ax=ax2,bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Ensemble Model - Gradient Boost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbm = GradientBoostingRegressor(n_estimators=4000,alpha=0.01); ### Test 0.41\nyLabelsLog = np.log1p(yLabels)\ngbm.fit(dataTrain,yLabelsLog)\npreds = gbm.predict(X= dataTrain)\n\nrmse_1 = np.sqrt(mean_squared_error(yLabelsLog,preds))\n\nr2= r2_score(yLabelsLog, preds)\nrmsle_1 = rmsle(np.exp(yLabelsLog),np.exp(preds),False)\n\ndisplay( \"Root Mean squared Error\", rmse_1)\ndisplay(\"R Square Value\", r2)\ndisplay (\"RMSLE value: \",rmsle_1)\ntrain_score = gbm.score(dataTrain, yLabelsLog)\ndisplay(\"Training Score\", train_score ) \npredsTest = gbm.predict(X= dataTest)\ntest_score =gbm.score(dataTest, np.exp(predsTest))\ndisplay(\"Testing Score\", test_score ) \n\nnew_row = {'ModelName':'Ensemble Model - Gradient Boost', 'RootMeanSquaredError':rmse_1, 'RSquare':r2, 'RMSLE':rmsle_1, 'TrainingScore':train_score, 'TestingScore': test_score, 'IdealCondition': 'The most ideal result would be an RMSE value of zero and R-squared value of 1'}\ndf_summary = df_summary.append([new_row], ignore_index=True)\n\n\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsn.distplot(yLabels,ax=ax1,bins=50)\nsn.distplot(np.exp(predsTest),ax=ax2,bins=50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets compare the distribution of train and test results. More or less the distribution of train and test looks identical. It confirms visually that our model has not predicted really bad and not suffering from major overfitting problem."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}