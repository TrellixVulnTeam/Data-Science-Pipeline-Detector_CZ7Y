{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-16T17:14:39.526039Z","iopub.execute_input":"2021-08-16T17:14:39.526626Z","iopub.status.idle":"2021-08-16T17:14:39.819381Z","shell.execute_reply.started":"2021-08-16T17:14:39.526535Z","shell.execute_reply":"2021-08-16T17:14:39.818319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install dataprep\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:39.821044Z","iopub.execute_input":"2021-08-16T17:14:39.821463Z","iopub.status.idle":"2021-08-16T17:14:46.561418Z","shell.execute_reply.started":"2021-08-16T17:14:39.82142Z","shell.execute_reply":"2021-08-16T17:14:46.560454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#reading csv files of train and test data \ntrain_data = pd.read_csv(\"../input/bike-sharing-demand/train.csv\")\ntest_data = pd.read_csv(\"../input/bike-sharing-demand/test.csv\")\nsubmission = pd.read_csv(\"../input/bike-sharing-demand/sampleSubmission.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:46.563883Z","iopub.execute_input":"2021-08-16T17:14:46.564277Z","iopub.status.idle":"2021-08-16T17:14:46.609222Z","shell.execute_reply.started":"2021-08-16T17:14:46.564226Z","shell.execute_reply":"2021-08-16T17:14:46.60832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:46.610707Z","iopub.execute_input":"2021-08-16T17:14:46.610961Z","iopub.status.idle":"2021-08-16T17:14:46.635091Z","shell.execute_reply.started":"2021-08-16T17:14:46.610936Z","shell.execute_reply":"2021-08-16T17:14:46.634288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:46.63628Z","iopub.execute_input":"2021-08-16T17:14:46.636619Z","iopub.status.idle":"2021-08-16T17:14:46.649658Z","shell.execute_reply.started":"2021-08-16T17:14:46.636584Z","shell.execute_reply":"2021-08-16T17:14:46.648868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#checking if there is null values in train and test data\ndisplay(train_data.isnull().any())\nprint('*'*20)\ndisplay(test_data.isnull().any())","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:46.651377Z","iopub.execute_input":"2021-08-16T17:14:46.65198Z","iopub.status.idle":"2021-08-16T17:14:46.674099Z","shell.execute_reply.started":"2021-08-16T17:14:46.651944Z","shell.execute_reply":"2021-08-16T17:14:46.6734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(train_data.describe().T)\ndisplay(test_data.describe().T)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:46.675253Z","iopub.execute_input":"2021-08-16T17:14:46.675587Z","iopub.status.idle":"2021-08-16T17:14:46.746731Z","shell.execute_reply.started":"2021-08-16T17:14:46.675554Z","shell.execute_reply":"2021-08-16T17:14:46.745745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#displaying Data type of each column\nprint(train_data.dtypes)\nprint('*'*21)\nprint(test_data.dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:46.748054Z","iopub.execute_input":"2021-08-16T17:14:46.748423Z","iopub.status.idle":"2021-08-16T17:14:46.755706Z","shell.execute_reply.started":"2021-08-16T17:14:46.748387Z","shell.execute_reply":"2021-08-16T17:14:46.754421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"sns.pairplot(train_data, diag_kind=\"kde\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:14:46.759305Z","iopub.execute_input":"2021-08-16T17:14:46.759708Z","iopub.status.idle":"2021-08-16T17:15:11.35733Z","shell.execute_reply.started":"2021-08-16T17:14:46.759671Z","shell.execute_reply":"2021-08-16T17:15:11.356329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting train (datetime column)to (year,month, day, hour, weekday )\n\ntrain_data[\"datetimenew\"] = pd.to_datetime(train_data[\"datetime\"])\n\n# train_data['year'] = train_data['datetimenew'].apply(lambda x: x.strftime('%Y'))\n# train_data['month']= train_data['datetimenew'].apply(lambda x: x.strftime('%-m'))\n# train_data['day']  = train_data['datetimenew'].apply(lambda x: x.strftime('%-d'))\n# train_data['hour'] = train_data['datetimenew'].apply(lambda x: x.strftime('%-H'))\n# train_data['weekday'] = train_data['datetimenew'].apply(lambda x: x.strftime('%w'))\n\n\n\ntrain_data['Day']=train_data['datetimenew'].dt.day\ntrain_data['month']=train_data['datetimenew'].dt.month\ntrain_data['year']=train_data['datetimenew'].dt.year\ntrain_data['hour']=train_data['datetimenew'].dt.hour\ntrain_data['weekday']=train_data['datetimenew'].dt.weekday\n\ntrain_data=train_data.drop(['datetime','datetimenew'],axis=1)\ndisplay(train_data)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:11.359532Z","iopub.execute_input":"2021-08-16T17:15:11.359835Z","iopub.status.idle":"2021-08-16T17:15:11.418131Z","shell.execute_reply.started":"2021-08-16T17:15:11.359804Z","shell.execute_reply":"2021-08-16T17:15:11.416965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting test (datetime column)to (year,month, day, hour, weekday )\n\ntest_data[\"datetimenew\"] = pd.to_datetime(test_data[\"datetime\"])\n# test_data['year'] = test_data['datetimenew'].apply(lambda x: x.strftime('%Y'))\n# test_data['month']= test_data['datetimenew'].apply(lambda x: x.strftime('%-m'))\n# test_data['day']  = test_data['datetimenew'].apply(lambda x: x.strftime('%-d'))\n# test_data['hour'] = test_data['datetimenew'].apply(lambda x: x.strftime('%-H'))\n# test_data['weekday'] = test_data['datetimenew'].apply(lambda x: x.strftime('%w'))\n\n\ntest_data['Day']=test_data['datetimenew'].dt.day\ntest_data['month']=test_data['datetimenew'].dt.month\ntest_data['year']=test_data['datetimenew'].dt.year\ntest_data['hour']=test_data['datetimenew'].dt.hour\ntest_data['weekday']=test_data['datetimenew'].dt.weekday\ntest_date = test_data[['datetime']]\ntest_data=test_data.drop(['datetime','datetimenew'],axis=1)\n\ndisplay(test_data)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:11.419941Z","iopub.execute_input":"2021-08-16T17:15:11.420384Z","iopub.status.idle":"2021-08-16T17:15:11.462303Z","shell.execute_reply.started":"2021-08-16T17:15:11.420324Z","shell.execute_reply":"2021-08-16T17:15:11.461331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:11.463763Z","iopub.execute_input":"2021-08-16T17:15:11.46415Z","iopub.status.idle":"2021-08-16T17:15:11.471707Z","shell.execute_reply.started":"2021-08-16T17:15:11.46411Z","shell.execute_reply":"2021-08-16T17:15:11.470726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_data.dtypes","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:11.473329Z","iopub.execute_input":"2021-08-16T17:15:11.474071Z","iopub.status.idle":"2021-08-16T17:15:11.48503Z","shell.execute_reply.started":"2021-08-16T17:15:11.474026Z","shell.execute_reply":"2021-08-16T17:15:11.483856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# using LabelEncoder to transform categorical data to numerical\n# from sklearn.preprocessing import LabelEncoder\n# le = LabelEncoder()\n# train_data['year'] = le.fit_transform(train_data['year'])\n# train_data['month'] = le.fit_transform(train_data['month'])\n# train_data['day']= le.fit_transform(train_data['day'])\n# train_data ['hour'] = le.fit_transform(train_data ['hour'])\n# train_data ['weekday'] = le.fit_transform(train_data ['weekday'])\n\n\n# test_data['year'] = le.fit_transform(test_data['year'])\n# test_data['month'] = le.fit_transform(test_data['month'])\n# test_data['day']= le.fit_transform(test_data['day'])\n# test_data ['hour'] = le.fit_transform(test_data ['hour'])\n# test_data ['weekday'] = le.fit_transform(test_data ['weekday'])\n\n# train_data \n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:11.486891Z","iopub.execute_input":"2021-08-16T17:15:11.487358Z","iopub.status.idle":"2021-08-16T17:15:11.493873Z","shell.execute_reply.started":"2021-08-16T17:15:11.487298Z","shell.execute_reply":"2021-08-16T17:15:11.493019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataprep import eda\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:11.495258Z","iopub.execute_input":"2021-08-16T17:15:11.495715Z","iopub.status.idle":"2021-08-16T17:15:13.181241Z","shell.execute_reply.started":"2021-08-16T17:15:11.495676Z","shell.execute_reply":"2021-08-16T17:15:13.180332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eda.create_report(train_data, title=\"train data report\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:13.182524Z","iopub.execute_input":"2021-08-16T17:15:13.182893Z","iopub.status.idle":"2021-08-16T17:15:20.469092Z","shell.execute_reply.started":"2021-08-16T17:15:13.182857Z","shell.execute_reply":"2021-08-16T17:15:20.467892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"eda.create_report(test_data, title=\"test data report\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:20.47075Z","iopub.execute_input":"2021-08-16T17:15:20.471509Z","iopub.status.idle":"2021-08-16T17:15:27.10094Z","shell.execute_reply.started":"2021-08-16T17:15:20.471439Z","shell.execute_reply":"2021-08-16T17:15:27.09951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.agg(['skew', 'kurtosis']).transpose()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:27.102957Z","iopub.execute_input":"2021-08-16T17:15:27.103709Z","iopub.status.idle":"2021-08-16T17:15:27.146537Z","shell.execute_reply.started":"2021-08-16T17:15:27.103659Z","shell.execute_reply":"2021-08-16T17:15:27.145791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#dealing with skewness of data \"some columns\"\n\n# from sklearn.datasets import load_boston\n\n# from skew_autotransform import skew_autotransform\n\n# exampleDF = pd.DataFrame(load_boston()['train_data'], columns = load_boston()['casual','registered','count'].tolist())\n\n# transformedDF = skew_autotransform(exampleDF.copy(deep=True), plot = True, exp = False, threshold = 0.5)\n\n# print('Original average skewness value was %2.2f' %(np.mean(abs(exampleDF.skew()))))\n# print('Average skewness after transformation is %2.2f' %(np.mean(abs(transformedDF.skew()))))","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:27.147879Z","iopub.execute_input":"2021-08-16T17:15:27.148411Z","iopub.status.idle":"2021-08-16T17:15:27.151783Z","shell.execute_reply.started":"2021-08-16T17:15:27.14837Z","shell.execute_reply":"2021-08-16T17:15:27.151063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## it works with +ve data only ##\n# from scipy.stats import boxcox \n# train_data_transformed = boxcox (train_data['count'])","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:27.152935Z","iopub.execute_input":"2021-08-16T17:15:27.153395Z","iopub.status.idle":"2021-08-16T17:15:27.160919Z","shell.execute_reply.started":"2021-08-16T17:15:27.153358Z","shell.execute_reply":"2021-08-16T17:15:27.160244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #dealing with skewness of data\n# train_data_final= train_data.apply(lambda x: np.log1p(x+1))\n\n# test_data_final = test_data.apply(lambda x: np.log1p(x+1))\n# train_data_finall = np.log1p(train_data+1)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:27.162042Z","iopub.execute_input":"2021-08-16T17:15:27.16254Z","iopub.status.idle":"2021-08-16T17:15:27.170489Z","shell.execute_reply.started":"2021-08-16T17:15:27.162505Z","shell.execute_reply":"2021-08-16T17:15:27.169717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#display 'windspeed ' column \n\n# plt.hist(train_data_final['windspeed'] )\n# use a gray background\n# ax = plt.axes(facecolor='#E6E6E6')\n# ax.set_axisbelow(True)\n\n# # draw solid white grid lines\n# plt.grid(color='w', linestyle='solid')\n\n# # hide axis spines\n# for spine in ax.spines.values():\n#     spine.set_visible(False)\n    \n# # hide top and right ticks\n# ax.xaxis.tick_bottom()\n# ax.yaxis.tick_left()\n\n# # lighten ticks and labels\n# ax.tick_params(colors='gray', direction='out')\n# for tick in ax.get_xticklabels():\n#     tick.set_color('gray')\n# for tick in ax.get_yticklabels():\n#     tick.set_color('gray')\n    \n# # control face and edge color of histogram\n# ax.hist(train_data_final[['count']], edgecolor='#E6E6E6', color='#EE6666');\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:18:45.809611Z","iopub.execute_input":"2021-08-16T17:18:45.809954Z","iopub.status.idle":"2021-08-16T17:18:45.81415Z","shell.execute_reply.started":"2021-08-16T17:18:45.809922Z","shell.execute_reply":"2021-08-16T17:18:45.813111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data ( feature , target) :\nY= train_data[['count']]\nX = train_data.drop(['count','atemp','casual', 'registered'], axis = 1)\ntest =test_data.drop(['atemp'],axis =1)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:18:52.159181Z","iopub.execute_input":"2021-08-16T17:18:52.159566Z","iopub.status.idle":"2021-08-16T17:18:52.167617Z","shell.execute_reply.started":"2021-08-16T17:18:52.159532Z","shell.execute_reply":"2021-08-16T17:18:52.166433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# #using RobustScaler :\n# from sklearn.preprocessing import RobustScaler\n# r = RobustScaler()\n# x = r.fit_transform(X)\n# test = r.fit_transform(test)\n# x= pd.DataFrame(x).astype(float)\n# testt = pd.DataFrame(test).astype(float)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:18:54.320205Z","iopub.execute_input":"2021-08-16T17:18:54.322618Z","iopub.status.idle":"2021-08-16T17:18:54.327915Z","shell.execute_reply.started":"2021-08-16T17:18:54.322569Z","shell.execute_reply":"2021-08-16T17:18:54.326953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(test.dtypes)\nprint(X.dtypes)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:18:55.958403Z","iopub.execute_input":"2021-08-16T17:18:55.958745Z","iopub.status.idle":"2021-08-16T17:18:55.968527Z","shell.execute_reply.started":"2021-08-16T17:18:55.958714Z","shell.execute_reply":"2021-08-16T17:18:55.967431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create training and test sets\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y,  test_size=0.25 , random_state=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:19:04.93977Z","iopub.execute_input":"2021-08-16T17:19:04.940089Z","iopub.status.idle":"2021-08-16T17:19:04.949475Z","shell.execute_reply.started":"2021-08-16T17:19:04.94006Z","shell.execute_reply":"2021-08-16T17:19:04.948634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Intiate the modelfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators = 500, max_depth = 50 ,random_state = 0)\nrf.fit(x_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:20:10.394075Z","iopub.execute_input":"2021-08-16T17:20:10.394437Z","iopub.status.idle":"2021-08-16T17:20:24.309205Z","shell.execute_reply.started":"2021-08-16T17:20:10.3944Z","shell.execute_reply":"2021-08-16T17:20:24.308319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\nprint(\"model score: %.3f\" % rf.score(x_train, y_train))\ny_pred1 = rf.predict(x_test)\ny_pred = rf.predict(test)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:20:29.921685Z","iopub.execute_input":"2021-08-16T17:20:29.922028Z","iopub.status.idle":"2021-08-16T17:20:31.584653Z","shell.execute_reply.started":"2021-08-16T17:20:29.921995Z","shell.execute_reply":"2021-08-16T17:20:31.583755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import BaggingRegressor\nmodell=BaggingRegressor()\nmodell.fit(x_train,y_train)\nprint(\"model score: %.3f\" % modell.score(x_train, y_train))\ny_pred1 = modell.predict(x_test)\n# y_pred2 = modell.predict(test)\ny_pred2 =np.round(np.expm1(modell.predict(test))).astype(int)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:28:44.610675Z","iopub.execute_input":"2021-08-16T17:28:44.611034Z","iopub.status.idle":"2021-08-16T17:28:44.940223Z","shell.execute_reply.started":"2021-08-16T17:28:44.611001Z","shell.execute_reply":"2021-08-16T17:28:44.939288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# from sklearn.tree import DecisionTreeClassifier\n\n\n# dtree = DecisionTreeClassifier()\n# dtree.fit(x_train, y_train)\n# dtree_predict = dtree.predict(_test)\n# print('Decision Tree accuracy: ', metrics.accuracy_score(y_test, dtree_predict))\n# parameters={\"splitter\":[\"best\",\"random\"],\n#             \"max_depth\" : [1,3,5,7,9,11,12],\n#            \"min_samples_leaf\":[1,2,3,4,5,6,7,8,9,10],\n#            \"min_weight_fraction_leaf\":[0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9],\n#            \"max_features\":[\"auto\",\"log2\",\"sqrt\",None],\n#            \"max_leaf_nodes\":[None,10,20,30,40,50,60,70,80,90] }\n# dtree_gs = GridSearchCV(dtree, parameters, cv=5, return_train_score=True)\n\n# # Fit the grid search object\n# dtree_gs.fit(X, y)\n\n# # Print the tuned parameters and score\n# print(\"Tuned Decision Tree Parameters: {}\".format(dtree_gs.best_params_))\n# print(\"Best score is {}\".format(dtree_gs.best_score_))","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:15:27.465243Z","iopub.status.idle":"2021-08-16T17:15:27.466009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = np.squeeze(y_pred2)\ny_pred.shape\noutput = pd.DataFrame({'datetime': test_date.datetime,\n                     'count': y_pred})\noutput.to_csv('submission3.csv', index=False)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T17:28:51.438776Z","iopub.execute_input":"2021-08-16T17:28:51.439093Z","iopub.status.idle":"2021-08-16T17:28:51.466012Z","shell.execute_reply.started":"2021-08-16T17:28:51.439062Z","shell.execute_reply":"2021-08-16T17:28:51.465112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}