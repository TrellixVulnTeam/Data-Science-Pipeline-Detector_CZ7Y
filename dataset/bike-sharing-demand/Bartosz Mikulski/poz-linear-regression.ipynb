{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\n\nRANDOM_STATE = 31415","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdf8070db21a168fd9f21e3c20aef330a12d747b"},"cell_type":"code","source":"# metric to optimize\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import make_scorer\n\nscorer = make_scorer(lambda y_test, predictions: np.sqrt(mean_squared_error(y_test, predictions)))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"training_set = pd.read_csv('../input/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d2a254e33f2aac6ae636d343278e21f21146ef2"},"cell_type":"code","source":"training_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b8e2228143cc1ef3a86189e3b30448d85e01bfb"},"cell_type":"code","source":"training_set.plot(x = 'datetime', y = 'casual')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f74546bdaec87ff18d5f0a2dbfea0c9108f400af"},"cell_type":"code","source":"training_set.plot(x = 'datetime', y = 'registered')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ad06a7687f51ccfb085074a9d31f4395920b35a5"},"cell_type":"markdown","source":"What do we see? The number of registed users grows over time. My first idea is that I may need to do some time series analisys in case of this variable. The number of casual users is completly different. There must be something that affects the number of casual users but it does not grow over time. There are spikes but it goes back to the normal value.\n\nlet's look at a correlation plot"},{"metadata":{"trusted":true,"_uuid":"945201dc503746c116f81c52ea33e284305bdfda"},"cell_type":"code","source":"corr = training_set.corr()\nfig, ax = plt.subplots(figsize=(30, 30))\nax.matshow(corr)\n\nfor (i, j), z in np.ndenumerate(corr):\n    ax.text(j, i, '{:0.1f}'.format(z), ha='center', va='center',\n            bbox=dict(boxstyle='round', facecolor='white', edgecolor='0.3'))\n\nplt.xticks(range(len(corr.columns)), corr.columns);\nplt.yticks(range(len(corr.columns)), corr.columns);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0c909be4003818f1036132fe30f294a8d9621401"},"cell_type":"markdown","source":"Looks like I may try to use 'workday', 'temp', 'atemp', and 'humidity' to predict the number of casual users. The problem is 'temp' and 'atemp' are correlated with each other, so I must decide which one is redundant an duse only one of them."},{"metadata":{"_uuid":"017e27c11b1841b3ddd2cd778a8656b222275f00"},"cell_type":"markdown","source":"In the first attempt I am going to normalize all values, remove datetime and atemp + registered and count columns. Then I am going to use linear regression to predict the value of the 'casual' variable. I will use regularization so hopefully it will sort out the problem of uncorrelated variables which I did not remove yet. Anyone that is the starting point just to set the baseline.\n\nThere is one more thing I have to do. Despite being numeric columns, some of the columns are in fact categorical variables. I must encode them using one-hot encoding instead of pretending that for example weather is a number ;)\n\nIt may be tempting to leave workday and holiday unencoded because they aready contain only 0 and 1. It will not end up well in case of linear regression. If x = 0 means \"not a holiday\" there is no value of the weight that may produce something not equal to 0 ;)"},{"metadata":{"trusted":true,"_uuid":"bc88ca492416a556df72c8df4ff14d45d9732759"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Basic preprocessing which applies to all regression techniques (dependent variable: casual)\ndata = training_set.drop(columns = ['datetime', 'atemp', 'registered', 'count'])\n\nX_train, X_test, y_train, y_test = train_test_split(data, data.casual, test_size=0.2, random_state = RANDOM_STATE)\nX_train = X_train.drop(columns = ['casual'])\nX_test = X_test.drop(columns = ['casual'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c1813d083df04b17097c94daa15db0a06852e57"},"cell_type":"code","source":"# Preprocessing for linear regression\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_norm = scaler.fit_transform(X_train)\nX_test_norm = scaler.transform(X_test)\n\none_hot = OneHotEncoder(categorical_features = [0, 1, 2, 3]) #season, holiday, workingday and weather\nX_train_norm = one_hot.fit_transform(X_train_norm)\nX_test_norm = one_hot.transform(X_test_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d229ce6343c65a5b8284b71cc0fa3e49744e7499"},"cell_type":"code","source":"from sklearn.linear_model import Lasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fafe5d85ad0aafe647c599b57410820b245ac550"},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\ncasual_model = Lasso()\nscores = cross_val_score(casual_model, X_train_norm, y_train, cv=5, scoring = scorer)\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ebdcd27a6dff49814b6a3d89baadacf4a84dd5d3"},"cell_type":"code","source":"casual_model.fit(X_train_norm, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e45452516530fb24a08d720f36cb9e4f6b9b3e4e"},"cell_type":"code","source":"# Same thing for the second variable\n# Basic preprocessing which applies to all regression techniques (dependent variable: casual)\ndata = training_set.drop(columns = ['datetime', 'atemp', 'casual', 'count'])\n\nX_train, X_test, y_train, y_test = train_test_split(data, data.registered, test_size=0.2, random_state = RANDOM_STATE)\nX_train = X_train.drop(columns = ['registered'])\nX_test = X_test.drop(columns = ['registered'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fc2f2a7f8f243575033fc39b9d5a1f86eedfaf55"},"cell_type":"code","source":"# Preprocessing for linear regression\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()\nX_train_norm = scaler.fit_transform(X_train)\nX_test_norm = scaler.transform(X_test)\n\none_hot = OneHotEncoder(categorical_features = [0, 1, 2, 3]) #season, holiday, workingday and weather\nX_train_norm = one_hot.fit_transform(X_train_norm)\nX_test_norm = one_hot.transform(X_test_norm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"28b07f48da7913b0a6d7d489e546219029d76ed2"},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nfrom sklearn.model_selection import cross_val_score\nregistered_model = Lasso()\nscores = cross_val_score(registered_model, X_train_norm, y_train, cv=5, scoring = scorer)\nscores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"81c13a2ad964e11f33d6e4d09d24da249f8ad2e2"},"cell_type":"code","source":"registered_model.fit(X_train_norm, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3a57df3c091c66d03f3dddf83ad09db4c677c84f"},"cell_type":"code","source":"# Final prediction of the baseline models, as I am not going to tweak them, I will move directly to the test data\n\ntest_dataset = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d2f46b16ed1480c7007466daf6d71a95d034b4cf"},"cell_type":"code","source":"test_data = test_dataset.drop(columns = ['datetime', 'atemp'])\ntest_data = scaler.transform(test_data)\ntest_data = one_hot.transform(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77b4a0fded6e3d48025f9d901735743b0d85cc5d"},"cell_type":"code","source":"casual = casual_model.predict(test_data)\nregistered = registered_model.predict(test_data)\ntotal = casual + registered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"abcd23744444c6a079a0f69a2b2409aee6a050d6"},"cell_type":"code","source":"test_dataset['count'] = pd.Series(total)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6d198bcd6beaf2c580c0a53aea908145021da604"},"cell_type":"code","source":"test_dataset[test_dataset['count'] < 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a047124ac7479173670f1c784ddead7df09c66f"},"cell_type":"code","source":"test_dataset.loc[test_dataset['count'] < 0, 'count'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d3576291ee98872f58ad3ee74e255478e5ae9fc"},"cell_type":"code","source":"test_dataset[test_dataset['count'] <= 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ed3909c2b8517e352e3c5150f7b7033e06cdb8d"},"cell_type":"code","source":"test_dataset[['datetime', 'count']].to_csv('result.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8906913111be3e13406cbc5c34770782024eb01f"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}