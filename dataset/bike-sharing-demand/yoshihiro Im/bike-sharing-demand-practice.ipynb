{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##  Regression  - Bike Sharing Demand Practice\n###","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ntrain = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\")\n\n                   \nbike_df=train.copy()\n#test_df=test.copy()\n\n#bike_df = pd.read_csv('./bike_train.csv')\n#print(bike_df.shape)\nbike_df.head(3)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:23:55.12599Z","iopub.execute_input":"2021-11-17T08:23:55.126955Z","iopub.status.idle":"2021-11-17T08:23:55.188963Z","shell.execute_reply.started":"2021-11-17T08:23:55.126908Z","shell.execute_reply":"2021-11-17T08:23:55.187965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:23:55.191126Z","iopub.execute_input":"2021-11-17T08:23:55.191527Z","iopub.status.idle":"2021-11-17T08:23:55.208178Z","shell.execute_reply.started":"2021-11-17T08:23:55.191481Z","shell.execute_reply":"2021-11-17T08:23:55.207578Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****시각화****","metadata":{}},{"cell_type":"code","source":"# Boxplot between count & each categorical features\nfig, axes = plt.subplots(nrows=2,ncols=2)\nfig.set_size_inches(20, 10)\nsns.boxplot(data=train, y=\"count\", x=\"season\", ax=axes[0][0])\nsns.boxplot(data=train, y=\"count\", x=\"holiday\", ax=axes[0][1])\nsns.boxplot(data=train, y=\"count\", x=\"workingday\", ax=axes[1][0])\nsns.boxplot(data=train, y=\"count\", x=\"weather\", ax=axes[1][1])\n\naxes[0][0].set(xlabel='Season', ylabel=\"Count\")\naxes[0][1].set(xlabel='Holiday', ylabel='Count')\naxes[1][0].set(xlabel='Workingday', ylabel='Count')\naxes[1][1].set(xlabel='Weather', ylabel='Count')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:43:18.64305Z","iopub.execute_input":"2021-11-17T08:43:18.643375Z","iopub.status.idle":"2021-11-17T08:43:19.307212Z","shell.execute_reply.started":"2021-11-17T08:43:18.643339Z","shell.execute_reply":"2021-11-17T08:43:19.306301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Correlation between each features\nplt.figure(figsize=(10,10))\nsns.heatmap(train.corr(\"pearson\"),\n            vmin=-1, vmax=1,\n            cmap='coolwarm',\n            annot=True, \n            square=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:44:44.060212Z","iopub.execute_input":"2021-11-17T08:44:44.060816Z","iopub.status.idle":"2021-11-17T08:44:45.172778Z","shell.execute_reply.started":"2021-11-17T08:44:44.060763Z","shell.execute_reply":"2021-11-17T08:44:45.169748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****Data preprocessing****","metadata":{}},{"cell_type":"code","source":"# 문자열을 datetime 타입으로 변경. \nbike_df['datetime'] = bike_df.datetime.apply(pd.to_datetime)\n\n# datetime 타입에서 년, 월, 일, 시간 추출\nbike_df['year'] = bike_df.datetime.apply(lambda x : x.year)\nbike_df['month'] = bike_df.datetime.apply(lambda x : x.month)\nbike_df['day'] = bike_df.datetime.apply(lambda x : x.day)\nbike_df['dayofweek'] = bike_df.datetime.apply(lambda x: x.dayofweek)\nbike_df['hour'] = bike_df.datetime.apply(lambda x: x.hour)\nbike_df.head(3)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:23:55.209327Z","iopub.execute_input":"2021-11-17T08:23:55.209753Z","iopub.status.idle":"2021-11-17T08:23:56.516146Z","shell.execute_reply.started":"2021-11-17T08:23:55.209706Z","shell.execute_reply":"2021-11-17T08:23:56.515325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_columns = ['datetime','casual','registered']\nbike_df.drop(drop_columns, axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:23:56.518412Z","iopub.execute_input":"2021-11-17T08:23:56.519427Z","iopub.status.idle":"2021-11-17T08:23:56.525182Z","shell.execute_reply.started":"2021-11-17T08:23:56.51939Z","shell.execute_reply":"2021-11-17T08:23:56.524609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Boxplot between count & each categorical features\nfig, axes = plt.subplots(nrows=1,ncols=3)\nfig.set_size_inches(25, 5)\nsns.barplot(data=bike_df, x='year', y=train['count'], ax=axes[0])\nsns.barplot(data=bike_df, x='month', y=train['count'], ax=axes[1])\nsns.pointplot(data=bike_df, x='hour', y=train['count'], ax=axes[2], hue='dayofweek')","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:23:56.526081Z","iopub.execute_input":"2021-11-17T08:23:56.526714Z","iopub.status.idle":"2021-11-17T08:24:03.891926Z","shell.execute_reply.started":"2021-11-17T08:23:56.52668Z","shell.execute_reply":"2021-11-17T08:24:03.891017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count column looks skew.\nsns.distplot(bike_df['count'])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:03.893022Z","iopub.execute_input":"2021-11-17T08:24:03.893235Z","iopub.status.idle":"2021-11-17T08:24:04.335113Z","shell.execute_reply.started":"2021-11-17T08:24:03.893208Z","shell.execute_reply":"2021-11-17T08:24:04.334546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Take a log for count column\nbike_df['count'] = np.log1p(bike_df['count'])\nsns.distplot(bike_df['count'])","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:04.336217Z","iopub.execute_input":"2021-11-17T08:24:04.337Z","iopub.status.idle":"2021-11-17T08:24:04.778027Z","shell.execute_reply.started":"2021-11-17T08:24:04.336968Z","shell.execute_reply":"2021-11-17T08:24:04.777423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****평가지표(rmsle)****","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# log 값 변환 시 NaN등의 이슈로 log() 가 아닌 log1p() 를 이용하여 RMSLE 계산\ndef rmsle(y, pred):\n    log_y = np.log1p(y)\n    log_pred = np.log1p(pred)\n    squared_error = (log_y - log_pred) ** 2\n    rmsle = np.sqrt(np.mean(squared_error))\n    return rmsle\n\n# 사이킷런의 mean_square_error() 를 이용하여 RMSE 계산\ndef rmse(y,pred):\n    return np.sqrt(mean_squared_error(y,pred))\n\n# MSE, RMSE, RMSLE 를 모두 계산 \ndef evaluate_regr(y,pred):\n    rmsle_val = rmsle(y,pred)\n    rmse_val = rmse(y,pred)\n    # MAE 는 scikit learn의 mean_absolute_error() 로 계산\n    mae_val = mean_absolute_error(y,pred)\n    print('RMSLE: {0:.3f}, RMSE: {1:.3F}, MAE: {2:.3F}'.format(rmsle_val, rmse_val, mae_val))","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:04.77916Z","iopub.execute_input":"2021-11-17T08:24:04.779738Z","iopub.status.idle":"2021-11-17T08:24:04.787053Z","shell.execute_reply.started":"2021-11-17T08:24:04.779703Z","shell.execute_reply":"2021-11-17T08:24:04.78648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 로그 변환, 피처 인코딩, 모델 학습/예측/평가 ","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split , GridSearchCV\nfrom sklearn.linear_model import LinearRegression , Ridge , Lasso\n\ny_target = bike_df['count']\nX_features = bike_df.drop(['count'],axis=1,inplace=False)\n\nX_train, X_test, y_train, y_test = train_test_split(X_features, y_target, test_size=0.3, random_state=0)\n\nlr_reg = LinearRegression()\nlr_reg.fit(X_train, y_train)\npred = lr_reg.predict(X_test)\n\nevaluate_regr(y_test ,pred)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:04.78812Z","iopub.execute_input":"2021-11-17T08:24:04.788484Z","iopub.status.idle":"2021-11-17T08:24:04.818503Z","shell.execute_reply.started":"2021-11-17T08:24:04.788454Z","shell.execute_reply":"2021-11-17T08:24:04.817606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****LinearRegression()이 가장 좋음****","metadata":{}},{"cell_type":"code","source":"def get_top_error_data(y_test, pred, n_tops = 5):\n    # DataFrame에 컬럼들로 실제 대여횟수(count)와 예측 값을 서로 비교 할 수 있도록 생성. \n    result_df = pd.DataFrame(y_test.values, columns=['real_count'])\n    result_df['predicted_count']= np.round(pred)\n    result_df['diff'] = np.abs(result_df['real_count'] - result_df['predicted_count'])\n    # 예측값과 실제값이 가장 큰 데이터 순으로 출력. \n    print(result_df.sort_values('diff', ascending=False)[:n_tops])\n    \nget_top_error_data(y_test,pred,n_tops=5)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:04.822347Z","iopub.execute_input":"2021-11-17T08:24:04.823702Z","iopub.status.idle":"2021-11-17T08:24:04.842397Z","shell.execute_reply.started":"2021-11-17T08:24:04.823651Z","shell.execute_reply":"2021-11-17T08:24:04.841512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_target.hist()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:04.844019Z","iopub.execute_input":"2021-11-17T08:24:04.844563Z","iopub.status.idle":"2021-11-17T08:24:05.105381Z","shell.execute_reply.started":"2021-11-17T08:24:04.844516Z","shell.execute_reply":"2021-11-17T08:24:05.104813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_log_transform = np.log1p(y_target)\ny_log_transform.hist()","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:05.106402Z","iopub.execute_input":"2021-11-17T08:24:05.106704Z","iopub.status.idle":"2021-11-17T08:24:05.362354Z","shell.execute_reply.started":"2021-11-17T08:24:05.106677Z","shell.execute_reply":"2021-11-17T08:24:05.361755Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 타겟 컬럼인 count 값을 log1p 로 Log 변환\ny_target_log = np.log1p(y_target)\n\n# 로그 변환된 y_target_log를 반영하여 학습/테스트 데이터 셋 분할\nX_train, X_test, y_train, y_test = train_test_split(X_features, y_target_log, test_size=0.3, random_state=0)\nlr_reg = LinearRegression()\nlr_reg.fit(X_train, y_train)\npred = lr_reg.predict(X_test)\n\n# 테스트 데이터 셋의 Target 값은 Log 변환되었으므로 다시 expm1를 이용하여 원래 scale로 변환\ny_test_exp = np.expm1(y_test)\n\n# 예측 값 역시 Log 변환된 타겟 기반으로 학습되어 예측되었으므로 다시 exmpl으로 scale변환\npred_exp = np.expm1(pred)\n\nevaluate_regr(y_test_exp ,pred_exp)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:05.363639Z","iopub.execute_input":"2021-11-17T08:24:05.364044Z","iopub.status.idle":"2021-11-17T08:24:05.387535Z","shell.execute_reply.started":"2021-11-17T08:24:05.364012Z","shell.execute_reply":"2021-11-17T08:24:05.386615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"****RMSLE값 좋아졌음****","metadata":{}},{"cell_type":"code","source":"coef = pd.Series(lr_reg.coef_, index=X_features.columns)\ncoef_sort = coef.sort_values(ascending=False)\nsns.barplot(x=coef_sort.values, y=coef_sort.index)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-17T08:24:05.389478Z","iopub.execute_input":"2021-11-17T08:24:05.390138Z","iopub.status.idle":"2021-11-17T08:24:05.870301Z","shell.execute_reply.started":"2021-11-17T08:24:05.390086Z","shell.execute_reply":"2021-11-17T08:24:05.869382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 'year', month', 'day', hour'등의 피처들을 One Hot Encoding\nX_features_ohe = pd.get_dummies(X_features, columns=['year', 'month','day', 'hour', 'holiday',\n                                              'workingday','season','weather'])\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:05.871457Z","iopub.execute_input":"2021-11-17T08:24:05.871675Z","iopub.status.idle":"2021-11-17T08:24:05.888153Z","shell.execute_reply.started":"2021-11-17T08:24:05.871648Z","shell.execute_reply":"2021-11-17T08:24:05.887509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 원-핫 인코딩이 적용된 feature 데이터 세트 기반으로 학습/예측 데이터 분할. \nX_train, X_test, y_train, y_test = train_test_split(X_features_ohe, y_target_log,\n                                                    test_size=0.3, random_state=0)\n\n# 모델과 학습/테스트 데이터 셋을 입력하면 성능 평가 수치를 반환\ndef get_model_predict(model, X_train, X_test, y_train, y_test, is_expm1=False):\n    model.fit(X_train, y_train)\n    pred = model.predict(X_test)\n    if is_expm1 :\n        y_test = np.expm1(y_test)\n        pred = np.expm1(pred)\n    print('###',model.__class__.__name__,'###')\n    evaluate_regr(y_test, pred)\n# end of function get_model_predict    \n\n# model 별로 평가 수행\nlr_reg = LinearRegression()\nridge_reg = Ridge(alpha=10)\nlasso_reg = Lasso(alpha=0.01)\n\nfor model in [lr_reg, ridge_reg, lasso_reg]:\n    get_model_predict(model,X_train, X_test, y_train, y_test,is_expm1=True)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-17T08:24:05.889153Z","iopub.execute_input":"2021-11-17T08:24:05.88981Z","iopub.status.idle":"2021-11-17T08:24:06.005478Z","shell.execute_reply.started":"2021-11-17T08:24:05.889776Z","shell.execute_reply":"2021-11-17T08:24:06.004526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LinearRegression이 가장 우수 ###","metadata":{}},{"cell_type":"code","source":"coef = pd.Series(lr_reg.coef_ , index=X_features_ohe.columns)\ncoef_sort = coef.sort_values(ascending=False)[:20]\nsns.barplot(x=coef_sort.values , y=coef_sort.index)\n","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-11-17T08:24:06.007147Z","iopub.execute_input":"2021-11-17T08:24:06.007766Z","iopub.status.idle":"2021-11-17T08:24:06.373363Z","shell.execute_reply.started":"2021-11-17T08:24:06.007718Z","shell.execute_reply":"2021-11-17T08:24:06.372447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\n# 랜덤 포레스트, GBM, XGBoost, LightGBM model 별로 평가 수행\nrf_reg = RandomForestRegressor(n_estimators=500)\ngbm_reg = GradientBoostingRegressor(n_estimators=500)\nxgb_reg = XGBRegressor(n_estimators=500)\nlgbm_reg = LGBMRegressor(n_estimators=500)\n\nfor model in [rf_reg, gbm_reg, xgb_reg, lgbm_reg]:\n    # XGBoost의 경우 DataFrame이 입력 될 경우 버전에 따라 오류 발생 가능. ndarray로 변환.\n    get_model_predict(model,X_train.values, X_test.values, y_train.values, y_test.values,is_expm1=True)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:06.374514Z","iopub.execute_input":"2021-11-17T08:24:06.374722Z","iopub.status.idle":"2021-11-17T08:24:56.932392Z","shell.execute_reply.started":"2021-11-17T08:24:06.374696Z","shell.execute_reply":"2021-11-17T08:24:56.931547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***LGBMRegressor이 가장 우수  ###","metadata":{}},{"cell_type":"code","source":"def evaluate(reg_cls, params=None):\n    reg = reg_cls()\n    if params:\n        reg = GridSearchCV(reg, param_grid=params, refit=True)\n    reg.fit(X_train, y_train)\n    pred = reg.predict(X_test)\n    \n    y_test_exp = np.expm1(y_test)\n    pred_exp = np.expm1(pred)\n    print('\\n', reg_cls)\n    if params:\n        print(reg.best_params_)\n        reg = reg.best_estimator_\n    print(rmsle(y_test_exp, pred_exp))\n    return reg, pred_exp","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:56.936719Z","iopub.execute_input":"2021-11-17T08:24:56.937081Z","iopub.status.idle":"2021-11-17T08:24:56.94514Z","shell.execute_reply.started":"2021-11-17T08:24:56.937045Z","shell.execute_reply":"2021-11-17T08:24:56.944142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# lr_reg, pred_lr = evaluate(LinearRegression)\n# rg_reg, pred_rg = evaluate(Ridge)\n# ls_reg, pred_ls = evaluate(Lasso)\n# rf_reg, pred_rf = evaluate(RandomForestRegressor)\n# gb_reg, pred_gb = evaluate(GradientBoostingRegressor)\n\nparams = {'n_estimators': [100*i for i in range(1, 6)]}\nxg_reg, pred_xg = evaluate(XGBRegressor, params)\nlg_reg, pred_lg = evaluate(LGBMRegressor, params)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:24:56.946554Z","iopub.execute_input":"2021-11-17T08:24:56.946919Z","iopub.status.idle":"2021-11-17T08:26:16.354905Z","shell.execute_reply.started":"2021-11-17T08:24:56.946858Z","shell.execute_reply":"2021-11-17T08:26:16.354306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_importances(reg):\n    plt.figure(figsize=(20, 10))\n    print(type(reg))\n    df = pd.DataFrame(sorted(zip(X_train.columns, reg.feature_importances_)), columns=['Feature', 'Value'])\n    sns.barplot(x=\"Value\", y=\"Feature\", data=df.sort_values(by=\"Value\", ascending=False))\n    plt.show()\nfeature_importances(xg_reg)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:26:16.356298Z","iopub.execute_input":"2021-11-17T08:26:16.35676Z","iopub.status.idle":"2021-11-17T08:26:17.660979Z","shell.execute_reply.started":"2021-11-17T08:26:16.356727Z","shell.execute_reply":"2021-11-17T08:26:17.660054Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_importances(xg_reg)","metadata":{"execution":{"iopub.status.busy":"2021-11-17T08:26:17.662483Z","iopub.execute_input":"2021-11-17T08:26:17.663201Z","iopub.status.idle":"2021-11-17T08:26:18.968813Z","shell.execute_reply.started":"2021-11-17T08:26:17.663154Z","shell.execute_reply":"2021-11-17T08:26:18.967915Z"},"trusted":true},"execution_count":null,"outputs":[]}]}