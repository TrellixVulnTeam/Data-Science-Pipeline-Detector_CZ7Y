{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Importing the libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Loading the dataset**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\ndf_test = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## **Checking for the null values**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.isnull().sum(axis = 0))\nprint(df_test.isnull().sum(axis = 0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Luckily we do not have to deal with null values"},{"metadata":{},"cell_type":"markdown","source":"## **Lets first explore the output value (Count)**"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train['count'].plot(kind = 'hist', bins=100, ax =ax[0])\ndf_train['count'].plot(kind = 'box', ax =ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we can see that it contains the outliers. It happens when we have more rented bikes than ususal. So we need to remove the outliers as they can affect our models for predictions."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before removing the outliers ', df_train.shape)\ndf_train = df_train[abs(df_train['count'] - df_train['count'].mean()) < 3*df_train['count'].std()]\nprint('After removing the outliers ', df_train.shape)\ndf_train.reset_index(drop = True, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lets visualize the distribution of the output variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 3)\nfig.set_size_inches(20, 10)\nsns.distplot(df_train[\"count\"], ax = ax[0])\nsns.distplot(df_train[\"casual\"], ax = ax[1])\nsns.distplot(df_train[\"registered\"], ax = ax[2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As most of the machine learning models work best when the output variable is normally distributed, we will apply the log transformation to \"Count\" and \"Registered\" to make it more normally distributed"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['count'] = np.log(df_train['count'] + 1)\ndf_train['registered'] = np.log(df_train['registered'] + 1)\nfig, ax = plt.subplots(1, 3)\nfig.set_size_inches(20, 10)\nsns.distplot(df_train[\"count\"], ax = ax[0])\nsns.distplot(df_train[\"casual\"], ax = ax[1])\nsns.distplot(df_train[\"registered\"], ax = ax[2])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Now the distribution is more normally distributed but remember we have added 1 before taking the log as np.log(0) will give infinity"},{"metadata":{},"cell_type":"markdown","source":"### Extract the month, hour, year from the datetime column. I am not considering the day as the training set contains only dates from 1 to 19 and test data is of 20th day of each month."},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_month(dataframe):\n    month = pd.DatetimeIndex(dataframe['datetime']).month\n    return month\n\ndef add_time(dataframe):\n    time = pd.DatetimeIndex(dataframe['datetime']).hour\n    return time\n\ndef add_year(dataframe):\n    year = pd.DatetimeIndex(dataframe['datetime']).year\n    return year\n\ndef add_day(dataframe):\n    day = pd.DatetimeIndex(dataframe['datetime']).dayofweek\n    return day","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['month'] = add_month(df_train)\ndf_train['time'] = add_time(df_train)\ndf_train['year'] = add_year(df_train)\ndf_train['day'] = add_day(df_train)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### To find the dependence of independent variable on dependent variable we will calculate the correlation between them"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = df_train.corr()\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can draw the following obsevations from it:\n#### 1. The correlation between temp and atemp is very high so we can discard any of the variable\n#### 2. The correlation between count and time is highest and the correlation of count with year, month, temp,humidity is also significant"},{"metadata":{},"cell_type":"markdown","source":"## Lets explore how the count is varying with different features"},{"metadata":{},"cell_type":"markdown","source":"### 1. Time "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.groupby('time')['count'].mean().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see that the maximum is around 7-9 am and 5-6 pm "},{"metadata":{},"cell_type":"markdown","source":"### 2. Month and Season"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train.groupby('month')['count'].mean().plot('bar', ax = ax[0])\ndf_train.groupby('season')['count'].mean().plot('bar', ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can observe from the above graphs that the number of rented bikes are less in season 1 as compared to others"},{"metadata":{},"cell_type":"markdown","source":"### 3. Temperature and Humidity"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train.groupby('temp')['count'].mean().plot('bar', ax = ax[0])\ndf_train.groupby('humidity')['count'].mean().plot('bar', ax = ax[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We can see that there is a positive relation of temperature with count and a negative relation of humidity with the count, this verifies the correlation values that we got above "},{"metadata":{},"cell_type":"markdown","source":"### 4. Holiday amd Workingday"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 2)\nfig.set_size_inches(20,5)\ndf_train.groupby('holiday')['count'].mean().plot('bar', ax = ax[0])\ndf_train.groupby('workingday')['count'].mean().plot('bar', ax = ax[1])\nprint(\"mean of count according to holidays \", df_train.groupby('holiday')['count'].mean())\nprint(\"No of holiday = 1 and holdays = 0 \", df_train.groupby('holiday')['count'].count())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nThree reasons to discard holiday and working day: \n1. Correlation value is low\n2. Examples where holiday = 1 is less than 3 percent\n3. The mean is almost similar\nBut we will make different models one with holiday and workingday and one without these features"},{"metadata":{},"cell_type":"markdown","source":"### 5. Windspeed"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['windspeed'] == 0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As a lot of values are 0 in windspeed we can consider the following scenerios:\n1.  It can actually be 0 at these points.\n2.  It is too low to be measured, for example varying from 0 to 5.\n3.  All zeros or part of them are nothing but NAs.\n\n\n## So we will be estimating the missing values using the random forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.groupby('windspeed')['count'].count().plot(kind='bar')\ndf_train.groupby('windspeed')['count'].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_windspeed_0 = df_train[df_train['windspeed'] == 0]\ndf_train_windspeed_not_0 = df_train[df_train['windspeed'] != 0]\nprint(df_train_windspeed_0.head())\nprint(df_train_windspeed_not_0.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train_windspeed_0.shape)\nprint(df_train_windspeed_not_0.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns_for_windspeed = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf_windspeed = RandomForestRegressor().fit(df_train_windspeed_not_0[columns_for_windspeed], df_train_windspeed_not_0['windspeed'])\ndf_train_windspeed_0['windspeed'] = rf_windspeed.predict(df_train_windspeed_0[columns_for_windspeed])\n\ndf_train = df_train_windspeed_0.append(df_train_windspeed_not_0, sort = 'datetime')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train[df_train['windspeed'] == 0])\ndf_train.groupby('windspeed')['count'].count()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we can see now that the windspeed is not 0 for any example"},{"metadata":{},"cell_type":"markdown","source":"### As we can not use the categorical values as input for models like linear regression we will convert it to one hot vector using pd.get_dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['holiday', 'season', 'workingday', 'weather', 'month', 'time', 'year', 'day']\nfor category in categorical_columns:\n    df_train = df_train.join(pd.get_dummies(df_train[category], prefix = category))\n    \ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Below function is equaivalent to pd.get_dummies"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\ndef one_hot_encode(dataframe, column):\n    for i in dataframe.groupby(column).count().index:\n        s = column + \"_\" + str(i)\n        a = []\n        for element in dataframe[column]:\n            if element == i:\n                a.append(1)\n            else:\n                a.append(0)\n        dataframe[s] = a\n    return dataframe\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Some algorithms performed better when the input data is normalized so we will normalize temp, humidity and windspeed"},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(dataframe, columns):\n    for column in columns:\n        dataframe[column]=((dataframe[column]-dataframe[column].min())/(dataframe[column].max()-dataframe[column].min()))\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = normalize(df_train, columns=['temp', 'humidity', 'windspeed'])\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### As we have taken all the information from the datetime column we can remove that"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_columns(dataframe, columns):\n    dataframe = dataframe.drop(columns, axis = 1)\n    return dataframe","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = remove_columns(df_train, ['datetime', 'atemp']) \nprint(df_train.columns)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split the dataset into input and output"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_y = df_train[['count', 'casual', 'registered']]\ndf_train_x = remove_columns(df_train, ['casual', 'registered', 'count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Split the dataset into training and testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(df_train_x, df_train_y, test_size=0.15, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### We will make 2 models in the first one we directly estimate the variable \"Count\" and in the 2nd one we will estimate \"Casual\" and \"Registered\" and \"Count\" will be equal to their summition"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train_casual = y_train['casual']\ny_train_registered = y_train['registered']\ny_train_total = y_train['count']\ny_test_casual = y_test['casual']\ny_test_registered = y_test['registered']\ny_test_total = y_test['count']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Importing the Machine Learning Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_log_error","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Using Linear Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_predictions = []\n\n#as we have the one hot vector we will remove this categorical data\ncategorical_data = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day']\nlr_train_x = remove_columns(x_train, categorical_data)\nlr_test_x = remove_columns(x_test, categorical_data)\n\nlr = LinearRegression().fit(lr_train_x, y_train_total)\nlr_predictions_on_test_data = np.exp(lr.predict(lr_test_x)) - 1\n\nlr_predictions_on_train_data = np.exp(lr.predict(lr_train_x))\n\nall_predictions.append(lr_predictions_on_train_data)\nall_predictions.append(lr_predictions_on_test_data)\n\nfor i, prediction in enumerate(all_predictions):\n    pre = []\n    for p in prediction:\n        if p < 0:\n            pre.append(0)\n        else:\n            pre.append(p)\n    if i == 0:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_train_total)-1, pre )))\n    else:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_test_total)-1, pre )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### For the Random Forest we do not need the one hot encoding for the categorical variables"},{"metadata":{"trusted":true},"cell_type":"code","source":"all_predictions = []\n\ntraining_columns = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity', 'windspeed']\ntrain_x = x_train[training_columns]\ntest_x = x_test[training_columns]\n\nrf = RandomForestRegressor(n_estimators=100, max_depth = 10, min_samples_split=5).fit(train_x, y_train_total)\npredictions_on_test_data = np.exp(rf.predict(test_x)) - 1\n\npredictions_on_train_data = np.exp(rf.predict(train_x))\n\nall_predictions.append(predictions_on_train_data)\nall_predictions.append(predictions_on_test_data)\n\nfor i, prediction in enumerate(all_predictions):\n    pre = []\n    for p in prediction:\n        if p < 0:\n            pre.append(0)\n        else:\n            pre.append(p)\n    if i == 0:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_train_total)-1, pre )))\n    else:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_test_total)-1, pre )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest with different model for \"Casual\" and \"Registered\""},{"metadata":{"trusted":true},"cell_type":"code","source":"all_predictions = []\n\ntraining_columns = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity', 'windspeed']\ntrain_x = x_train[training_columns]\ntest_x = x_test[training_columns]\n\nrf_casual = RandomForestRegressor(n_estimators=300, max_depth = 10, min_samples_split=8).fit(train_x, y_train_casual)\npredictions_casual = rf_casual.predict(test_x)\n\n\nrf_registered = RandomForestRegressor().fit(train_x, y_train_registered)\npredictions_registered = np.exp(rf_registered.predict(test_x))-1\n\npredictions = predictions_casual + predictions_registered\n\npredictions_casual_train = rf_casual.predict(train_x)\npredictions_registered_train = np.exp(rf_registered.predict(train_x))-1\n\npredictions_train = predictions_casual_train + predictions_registered_train\n\nall_predictions.append(predictions_train)\nall_predictions.append(predictions)\n\nfor i, prediction in enumerate(all_predictions):\n    pre = []\n    for p in prediction:\n        if p < 0:\n            pre.append(0)\n        else:\n            pre.append(p)\n    if i == 0:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_train_total)-1, pre )))\n    else:\n        print(np.sqrt(mean_squared_log_error( np.exp(y_test_total)-1, pre )))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Processing of the test data\n### 1. Addition of the day, month, time, year\n### 2. Removing the zero in the windspeed\n### 3. Sorting the data according to datetime\n### 4. Adding the one hot vector in case you want to predict the count using Linear Regression\n### 5. Normalisation\n### 6. Prediction\n### 7. Storing"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['month'] = add_month(df_test)\ndf_test['time'] = add_time(df_test)\ndf_test['year'] = add_year(df_test)\ndf_test['day'] = add_day(df_test)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_windspeed_0 = df_test[df_test['windspeed'] == 0]\ndf_test_windspeed_not_0 = df_test[df_test['windspeed'] != 0]\ncolumns_for_windspeed = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity']\n\ndf_test_windspeed_0['windspeed'] = rf_windspeed.predict(df_test_windspeed_0[columns_for_windspeed])\n\ndf_test = df_test_windspeed_0.append(df_test_windspeed_not_0, sort = 'datetime')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df_test.sort_values(by='datetime')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categorical_columns = ['holiday', 'season', 'workingday', 'weather', 'month', 'time', 'year', 'day']\nfor category in categorical_columns:\n    df_test = df_test.join(pd.get_dummies(df_test[category], prefix = category))\n    \nprint(df_test.head())\nprint(df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = normalize(df_test, columns=['temp', 'humidity', 'windspeed'])\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_datetime = df_test['datetime']\ndf_test = remove_columns(df_test, ['datetime', 'atemp']) \nprint(df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.columns.shape == df_train_x.columns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_columns = ['holiday', 'season', 'workingday', 'month', 'time', 'year', 'day', 'temp', 'humidity', 'windspeed']\ndf_test_final = df_test[training_columns]\npredictions = np.exp(rf.predict(df_test_final))-1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### If you want to predict using 2 models"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\npredictions_casual = rf_casual.predict(df_test_final)\n\npredictions_registered = np.exp(rf_registered.predict(df_test_final))-1\n\npredictions = predictions_casual + predictions_registered\n\nprint(predictions[:5])\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'datetime': df_datetime, 'count': predictions}\ndf = pd.DataFrame(data)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ** While training for submitting use the entire dataset to train **"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}