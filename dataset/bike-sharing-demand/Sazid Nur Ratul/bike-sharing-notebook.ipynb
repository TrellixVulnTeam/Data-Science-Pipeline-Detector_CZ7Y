{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:52.217046Z","iopub.execute_input":"2021-09-03T10:00:52.217393Z","iopub.status.idle":"2021-09-03T10:00:52.227123Z","shell.execute_reply.started":"2021-09-03T10:00:52.217365Z","shell.execute_reply":"2021-09-03T10:00:52.225765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom matplotlib.gridspec import GridSpec\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import make_scorer\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:52.228832Z","iopub.execute_input":"2021-09-03T10:00:52.22934Z","iopub.status.idle":"2021-09-03T10:00:52.239753Z","shell.execute_reply.started":"2021-09-03T10:00:52.229305Z","shell.execute_reply":"2021-09-03T10:00:52.238648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:52.241779Z","iopub.execute_input":"2021-09-03T10:00:52.242117Z","iopub.status.idle":"2021-09-03T10:00:52.292718Z","shell.execute_reply.started":"2021-09-03T10:00:52.242087Z","shell.execute_reply":"2021-09-03T10:00:52.291257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[:5]","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:52.294304Z","iopub.execute_input":"2021-09-03T10:00:52.294784Z","iopub.status.idle":"2021-09-03T10:00:52.314199Z","shell.execute_reply.started":"2021-09-03T10:00:52.294749Z","shell.execute_reply":"2021-09-03T10:00:52.312917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[:5]","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:52.316052Z","iopub.execute_input":"2021-09-03T10:00:52.316565Z","iopub.status.idle":"2021-09-03T10:00:52.336408Z","shell.execute_reply.started":"2021-09-03T10:00:52.316518Z","shell.execute_reply":"2021-09-03T10:00:52.335306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transfer the target from x to log(x + 1)\nfor col in ['casual', 'registered', 'count']:\n    train['%s_log' % col] = np.log(train[col] + 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:52.338166Z","iopub.execute_input":"2021-09-03T10:00:52.338546Z","iopub.status.idle":"2021-09-03T10:00:52.355973Z","shell.execute_reply.started":"2021-09-03T10:00:52.338459Z","shell.execute_reply":"2021-09-03T10:00:52.35472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nplt.subplot(221)\nsns.distplot(train['casual'])\nplt.xlabel(\"casual (before transformation)\")\nplt.subplot(222)\nsns.distplot(np.log(train['casual'] + 1))\nplt.xlabel(\"casual (after transformation)\")\nplt.subplot(223)\nsns.distplot(train['registered'])\nplt.xlabel(\"registered (before transformation)\")\nplt.subplot(224)\nsns.distplot(np.log(train['registered'] + 1))\nplt.xlabel(\"registered (after transformation)\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:52.357803Z","iopub.execute_input":"2021-09-03T10:00:52.35829Z","iopub.status.idle":"2021-09-03T10:00:53.924809Z","shell.execute_reply.started":"2021-09-03T10:00:52.358237Z","shell.execute_reply":"2021-09-03T10:00:53.922067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# extract information from the timestamp\ntrain_date = pd.DatetimeIndex(train['datetime'])\ntrain['year'] = train_date.year\ntrain['month'] = train_date.month\ntrain['hour'] = train_date.hour\ntrain['dayofweek'] = train_date.dayofweek\ntest_date = pd.DatetimeIndex(test['datetime'])\ntest['year'] = test_date.year\ntest['month'] = test_date.month\ntest['hour'] = test_date.hour\ntest['dayofweek'] = test_date.dayofweek","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:53.926403Z","iopub.execute_input":"2021-09-03T10:00:53.926879Z","iopub.status.idle":"2021-09-03T10:00:53.954787Z","shell.execute_reply.started":"2021-09-03T10:00:53.926833Z","shell.execute_reply":"2021-09-03T10:00:53.953703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new feature\n# non-registered user: more rentals during daytime\n# registered user: more rentals when going to work / going off work\nfig = plt.figure(figsize=(15, 10))\ngs1 = GridSpec(4, 4, fig, wspace=0.5, hspace=0.5)\nplt.subplot(gs1[:2, 1:3])\nsns.boxplot(x='hour', y='count', hue='workingday', data=train)\nplt.subplot(gs1[2:, :2])\nsns.boxplot(x='hour', y='casual', hue='workingday', data=train)\nplt.subplot(gs1[2:, 2:])\nsns.boxplot(x='hour', y='registered', hue='workingday', data=train)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:53.957257Z","iopub.execute_input":"2021-09-03T10:00:53.957921Z","iopub.status.idle":"2021-09-03T10:00:57.26952Z","shell.execute_reply.started":"2021-09-03T10:00:53.95788Z","shell.execute_reply":"2021-09-03T10:00:57.268389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new feature\n# combine year and season\ntrain['year_season'] = train_date.year + train.season / 10\nfig = plt.figure(figsize=(12, 10))\ngs1 = GridSpec(4, 4, fig, wspace=0.5, hspace=0.5)\nplt.subplot(gs1[:2, 1:3])\nsns.boxplot(x='year_season', y='count', data=train)\nplt.subplot(gs1[2:, :2])\nsns.boxplot(x='year_season', y='casual', data=train)\nplt.subplot(gs1[2:, 2:])\nsns.boxplot(x='year_season', y='registered', data=train)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:57.27201Z","iopub.execute_input":"2021-09-03T10:00:57.27245Z","iopub.status.idle":"2021-09-03T10:00:58.014841Z","shell.execute_reply.started":"2021-09-03T10:00:57.272406Z","shell.execute_reply":"2021-09-03T10:00:58.013609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# new feature\nfor df in [train, test]:\n    df['year_season'] = df['year'] + df['season'] / 10\n    df['hour_workingday_casual'] = df[['hour', 'workingday']].apply(\n        lambda x: int(10 <= x['hour'] <= 19), axis=1)\n    df['hour_workingday_registered'] = df[['hour', 'workingday']].apply(\n      lambda x: int(\n        (x['workingday'] == 1 and (x['hour'] == 8 or 17 <= x['hour'] <= 18))\n        or (x['workingday'] == 0 and 10 <= x['hour'] <= 19)), axis=1)\n\nby_season = train.groupby('year_season')[['count']].median()\nby_season.columns = ['count_season']\ntrain = train.join(by_season, on='year_season')\ntest = test.join(by_season, on='year_season')","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:58.016923Z","iopub.execute_input":"2021-09-03T10:00:58.017357Z","iopub.status.idle":"2021-09-03T10:00:58.823123Z","shell.execute_reply.started":"2021-09-03T10:00:58.017312Z","shell.execute_reply":"2021-09-03T10:00:58.821869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GradientBoostingRegressor\n# features used to train the model\n# removing month improves the performance\nfeatures = ['season', 'holiday', 'workingday', 'weather',\n            'temp', 'atemp', 'humidity', 'windspeed',\n            'year', 'hour', 'dayofweek', 'hour_workingday_casual', 'count_season']\nreg = GradientBoostingRegressor(n_estimators=1000, min_samples_leaf=6, random_state=0)\nreg.fit(train[features], train['casual_log'])\npred_casual = reg.predict(test[features])\npred_casual = np.exp(pred_casual) - 1\npred_casual[pred_casual < 0] = 0\nfeatures = ['season', 'holiday', 'workingday', 'weather',\n            'temp', 'atemp', 'humidity', 'windspeed',\n            'year', 'hour', 'dayofweek', 'hour_workingday_registered', 'count_season']\nreg = GradientBoostingRegressor(n_estimators=1000, min_samples_leaf=6, random_state=0)\nreg.fit(train[features], train['registered_log'])\npred_registered = reg.predict(test[features])\npred_registered = np.exp(pred_registered) - 1\npred_registered[pred_registered < 0] = 0\npred1 = pred_casual + pred_registered","metadata":{"execution":{"iopub.status.busy":"2021-09-03T10:00:58.824715Z","iopub.execute_input":"2021-09-03T10:00:58.825154Z","iopub.status.idle":"2021-09-03T10:01:20.767453Z","shell.execute_reply.started":"2021-09-03T10:00:58.825108Z","shell.execute_reply":"2021-09-03T10:01:20.766422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GradientBoostingRegressor\n# rank 4７/3251 public score 0.36904\nsubmission = pd.DataFrame({'datetime':test.datetime, 'count':pred1},\n                          columns = ['datetime', 'count'])\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}}]}