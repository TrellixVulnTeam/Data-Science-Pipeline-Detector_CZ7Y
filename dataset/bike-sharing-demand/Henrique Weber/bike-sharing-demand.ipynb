{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-20T00:36:20.306039Z","iopub.execute_input":"2022-01-20T00:36:20.306368Z","iopub.status.idle":"2022-01-20T00:36:20.318419Z","shell.execute_reply.started":"2022-01-20T00:36:20.306328Z","shell.execute_reply":"2022-01-20T00:36:20.31761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"original_df = pd.read_csv(r'/kaggle/input/bike-sharing-demand/train.csv')\ntest_df = pd.read_csv(r'/kaggle/input/bike-sharing-demand/test.csv')\noriginal_df['datetime'] = pd.to_datetime(original_df['datetime'])\ntest_df['datetime'] = pd.to_datetime(test_df['datetime'])\ntotal_df = pd.concat([original_df,test_df],axis=0).reset_index().drop(columns=['index'])","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:02:22.263825Z","iopub.execute_input":"2022-01-20T02:02:22.264165Z","iopub.status.idle":"2022-01-20T02:02:22.333282Z","shell.execute_reply.started":"2022-01-20T02:02:22.264129Z","shell.execute_reply":"2022-01-20T02:02:22.332267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', None)\n#pd.set_option('display.max_rows', None)\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno as msno\nfrom sklearn.preprocessing import StandardScaler\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:02:24.15676Z","iopub.execute_input":"2022-01-20T02:02:24.157096Z","iopub.status.idle":"2022-01-20T02:02:24.162977Z","shell.execute_reply.started":"2022-01-20T02:02:24.157061Z","shell.execute_reply":"2022-01-20T02:02:24.162316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T22:33:17.73582Z","iopub.execute_input":"2022-01-19T22:33:17.736102Z","iopub.status.idle":"2022-01-19T22:33:17.755002Z","shell.execute_reply.started":"2022-01-19T22:33:17.736074Z","shell.execute_reply":"2022-01-19T22:33:17.754223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T22:33:44.834755Z","iopub.execute_input":"2022-01-19T22:33:44.835069Z","iopub.status.idle":"2022-01-19T22:33:44.880555Z","shell.execute_reply.started":"2022-01-19T22:33:44.83503Z","shell.execute_reply":"2022-01-19T22:33:44.879774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_df.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-01-19T22:34:23.439485Z","iopub.execute_input":"2022-01-19T22:34:23.439737Z","iopub.status.idle":"2022-01-19T22:34:23.452833Z","shell.execute_reply.started":"2022-01-19T22:34:23.43971Z","shell.execute_reply":"2022-01-19T22:34:23.452107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_df['year'] = total_df['datetime'].dt.year\ntotal_df['month'] = total_df['datetime'].dt.month\ntotal_df['hour'] = total_df['datetime'].dt.hour\ntotal_df['dayofweek'] = total_df['datetime'].dt.dayofweek","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:02:27.222226Z","iopub.execute_input":"2022-01-20T02:02:27.222674Z","iopub.status.idle":"2022-01-20T02:02:27.238583Z","shell.execute_reply.started":"2022-01-20T02:02:27.222621Z","shell.execute_reply":"2022-01-20T02:02:27.237819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-20T00:36:39.834555Z","iopub.execute_input":"2022-01-20T00:36:39.83566Z","iopub.status.idle":"2022-01-20T00:36:39.866313Z","shell.execute_reply.started":"2022-01-20T00:36:39.835594Z","shell.execute_reply":"2022-01-20T00:36:39.865334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arrumando outliers que não tem sentido.\n# Existem valores de humidade igual a zero (todos registrados no mesmo dia)\n    # Vamos substituir esse valores pelo valor mediano de humidade por tempo\ntotal_df['humidity'][total_df['humidity']==0] = np.nan\ntotal_df['humidity'] = total_df['humidity'].fillna(total_df.groupby(['weather'])['humidity'].transform('median'))\n\n# removendo coluna atemp (alta correlcao com temp)\ntotal_df.drop(columns=['atemp','casual','registered'],inplace=True)\n\n# criando variaveis\ntotal_df['humidity_temp'] = total_df['humidity']/total_df['temp']\ntotal_df['windspeed_temp'] = total_df['windspeed']/total_df['temp']\ntotal_df['windspeed_humidity'] = total_df['windspeed']/total_df['humidity']\ntotal_df['clima'] = total_df['humidity']+total_df['temp']+total_df['windspeed']","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:02:29.465499Z","iopub.execute_input":"2022-01-20T02:02:29.466261Z","iopub.status.idle":"2022-01-20T02:02:29.48782Z","shell.execute_reply.started":"2022-01-20T02:02:29.466222Z","shell.execute_reply":"2022-01-20T02:02:29.486877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = total_df[total_df['datetime'].isin(original_df['datetime'])]\ntrain.drop(columns=['datetime'],inplace=True)\ntest = total_df[total_df['datetime'].isin(test_df['datetime'])]\ntest_dat = test.copy()\ntest.drop(columns=['datetime','count'],inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:02:30.843983Z","iopub.execute_input":"2022-01-20T02:02:30.844577Z","iopub.status.idle":"2022-01-20T02:02:30.859037Z","shell.execute_reply.started":"2022-01-20T02:02:30.844524Z","shell.execute_reply":"2022-01-20T02:02:30.857912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = train.drop(columns=['count'])\nscaler = StandardScaler()\nx = pd.DataFrame(scaler.fit_transform(x),columns=x.columns)\ny = pd.DataFrame(train['count'],columns=['count'])","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:02:32.756523Z","iopub.execute_input":"2022-01-20T02:02:32.756834Z","iopub.status.idle":"2022-01-20T02:02:32.776097Z","shell.execute_reply.started":"2022-01-20T02:02:32.756802Z","shell.execute_reply":"2022-01-20T02:02:32.775276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modelos de Regressão\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso, BayesianRidge, LogisticRegression, TweedieRegressor, SGDRegressor, PassiveAggressiveRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import cross_val_score\n\ndef model_test(x,y):\n    mlp = MLPRegressor()\n    LiRegr = LinearRegression()\n    ridge = Ridge()\n    lasso = Lasso()\n    bayesian = BayesianRidge()\n    LogRegr = LogisticRegression()\n    tweedie = TweedieRegressor()\n    sgd = SGDRegressor()\n    passiveaggr = PassiveAggressiveRegressor()\n    svr = SVR()\n    knearest = KNeighborsRegressor()\n    gaussian = GaussianProcessRegressor()\n    pls = PLSRegression()\n    decisiontree = DecisionTreeRegressor()\n    rdmforest = RandomForestRegressor()\n    extratree = ExtraTreesRegressor()\n    adaboost = AdaBoostRegressor()\n    gradientboost = GradientBoostingRegressor()\n    xgb = XGBRegressor()\n\n    models_dict = {'MLP':mlp,\"Linear Regression\":LiRegr,\"Ridge Regression\":ridge,\n                   'Lasso Regression':lasso,\"Bayesian Ridge\":bayesian,\n                   'Logistic Regression':LogRegr,'Tweedie Regressor':tweedie,\n                  'SGD Regressor':sgd,\"Passive Aggressive\":passiveaggr,\n                  'SVR':svr,'K Nearest':knearest,'Gaussian Process':gaussian,\n                  'PLS Regression':pls,'Decision Tree':decisiontree,'Random Forest':rdmforest,\n                  'Extra Trees':extratree, 'Ada Boost':adaboost,'Gradient Boosting':gradientboost,\n                  'XGB Regressor':xgb}\n    \n    values_dict = {}\n    for model in models_dict:\n        print(model)\n        values_dict[model] =cross_val_score(models_dict[model],x,y,cv=5,scoring='neg_root_mean_squared_error')\n    \n    return values_dict","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:02:34.82531Z","iopub.execute_input":"2022-01-20T02:02:34.825639Z","iopub.status.idle":"2022-01-20T02:02:34.840272Z","shell.execute_reply.started":"2022-01-20T02:02:34.825605Z","shell.execute_reply":"2022-01-20T02:02:34.839064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\n\nparams = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\ngbm_model = GradientBoostingRegressor(**params)\ngbm_model.fit(x,y)\n\npredict = gbm_model.predict(pd.DataFrame(scaler.transform(test),columns=test.columns))\npredictions = pd.concat([pd.DataFrame(test_dat.loc[:,'datetime'],columns=['datetime']).reset_index(),pd.DataFrame(predict,columns=['count'])],axis=1).set_index('datetime')\npredictions.drop(columns=['index'],inplace=True)\npredictions['count'][predictions['count']<0]=0\npredictions=predictions.round(0)\npredictions.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:12:05.705144Z","iopub.execute_input":"2022-01-20T02:12:05.705462Z","iopub.status.idle":"2022-01-20T02:12:06.81408Z","shell.execute_reply.started":"2022-01-20T02:12:05.705426Z","shell.execute_reply":"2022-01-20T02:12:06.813051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:12:10.231688Z","iopub.execute_input":"2022-01-20T02:12:10.232024Z","iopub.status.idle":"2022-01-20T02:12:10.248046Z","shell.execute_reply.started":"2022-01-20T02:12:10.231993Z","shell.execute_reply":"2022-01-20T02:12:10.246776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-20T02:05:31.980024Z","iopub.execute_input":"2022-01-20T02:05:31.980965Z","iopub.status.idle":"2022-01-20T02:05:31.994735Z","shell.execute_reply.started":"2022-01-20T02:05:31.980905Z","shell.execute_reply":"2022-01-20T02:05:31.993618Z"},"trusted":true},"execution_count":null,"outputs":[]}]}