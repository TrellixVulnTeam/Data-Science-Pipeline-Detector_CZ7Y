{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\n\n#Import libraries\n\n#Import libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport math\nimport seaborn as sns \nfrom sklearn.metrics import mean_squared_error, mean_squared_log_error\nfrom datetime import datetime\nimport statsmodels.formula.api as sm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Read Training and Test Data**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data=pd.read_csv(r'../input/bike-sharing-demand/train.csv')\ntest_data=pd.read_csv(r'../input/bike-sharing-demand/test.csv')\ndf=train_data.copy()\ntest_df=test_data.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Describe dataset\ntrain_data.describe() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # B. Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#check Null values\ntrain_data.isnull().values.any()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data Exploration\nsns.barplot(x='season', y='count', data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(x='weather', y='count', data=train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[['count', 'holiday']].groupby(['holiday'], as_index = True).mean().sort_values(by = 'count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data[['count', 'season']].groupby(['season'], as_index = True).mean().sort_values(by = 'count')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we have a datetime object here, so it's better to break them into hour, day, month, year and make them a separate column.\ntrain_data[\"hour\"] = [t.hour for t in pd.DatetimeIndex(train_data.datetime)]\ntrain_data[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(train_data.datetime)]\ntrain_data[\"month\"] = [t.month for t in pd.DatetimeIndex(train_data.datetime)]\ntrain_data['year'] = [t.year for t in pd.DatetimeIndex(train_data.datetime)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Box plot\nfig, axes = plt.subplots(nrows=3,ncols=2)\nfig.set_size_inches(15, 15)\nsns.boxplot(data=train_data,y=\"count\",orient=\"v\",ax=axes[0][0])\nsns.boxplot(data=train_data,y=\"count\",x=\"month\",orient=\"v\",ax=axes[0][1])\nsns.boxplot(data=train_data,y=\"count\",x=\"weather\",orient=\"v\",ax=axes[1][0])\nsns.boxplot(data=train_data,y=\"count\",x=\"workingday\",orient=\"v\",ax=axes[1][1])\nsns.boxplot(data=train_data,y=\"count\",x=\"hour\",orient=\"v\",ax=axes[2][0])\nsns.boxplot(data=train_data,y=\"count\",x=\"temp\",orient=\"v\",ax=axes[2][1])\n\naxes[0][0].set(ylabel='Count',title=\"Box Plot On Count\")\naxes[0][1].set(xlabel='Month', ylabel='Count',title=\"Box Plot On Count Across Months\")\naxes[1][0].set(xlabel='Weather Situation', ylabel='Count',title=\"Box Plot On Count Across Weather Situations\")\naxes[1][1].set(xlabel='Working Day', ylabel='Count',title=\"Box Plot On Count Across Working Day\")\naxes[2][0].set(xlabel='Hour Of The Day', ylabel='Count',title=\"Box Plot On Count Across Hour Of The Day\")\naxes[2][1].set(xlabel='Temperature', ylabel='Count',title=\"Box Plot On Count Across Temperature\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping datetime column becuase we already break them and created new columns\ntrain_data.drop('datetime',axis=1,inplace=True) \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# correlation by pairplot\nsns.pairplot(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping holiday column as it is highly correlated to‘workingday’ column\ntrain_data.drop('holiday',axis=1,inplace=True) \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping atemp column as it is highly correlated to ‘temp’ column\ntrain_data.drop('atemp',axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# there are just 2 different years 2011,2012 so using map(), I converted 2011 and 2012 to 0 and 1 respectively.\ntrain_data['year'] = train_data['year'].map({2011:0, 2012:1})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding the correlation between the columns 'casual','registred','count'\n\nplt.scatter(x = train_data['casual'] + train_data['registered'], y = train_data['count'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Dropping the column registred and casual\ntrain_data = train_data.drop(['registered', 'casual'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# #B. Applying Machine Learning Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = train_data.iloc[:, :], train_data['count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.drop('count',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize the train set\n#def norm_func(i):\n    #x = (i-i.min())\t/ (i.max()-i.min())\n    #return (x)\nfrom sklearn.preprocessing import StandardScaler\nscl= StandardScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X = scl.fit_transform(X)\n#y = scl.fit_transform(y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import  train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nX_train = scl.fit_transform(X_train)\nX_test = scl.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # C. Ridge Regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\nreg5 = Ridge(alpha=0.05, normalize=True)\nreg5.fit(X_train,y_train)\nreg5.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ridge = reg5.predict(X_test)\nRidge","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reg5.intercept_)\nprint(reg5.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(y_test,Ridge)\nplt.title('Residual Analysis - Ridge_Regression')\nplt.xlabel('Observed')\nplt.ylabel('Residual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint(\"MAE:\", metrics.mean_absolute_error(y_test,Ridge))\nprint('MSE:', metrics.mean_squared_error(y_test, Ridge))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, Ridge)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# grid search hyperparameters for ridge regression\nfrom numpy import arange\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RepeatedKFold\nfrom sklearn.linear_model import Ridge\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define model\nmodel = Ridge()\n# define model evaluation method\ncv = RepeatedKFold(n_splits=10, random_state=1)\n# define grid\ngrid = dict()\ngrid['alpha'] = arange(0, 1, 0.01)\n# define search\nsearch = GridSearchCV(model, grid, scoring='neg_mean_squared_error', cv=cv)\n# perform the search\nresults = search.fit(X_train, y_train)\n# summarize\nprint('MSE: %.3f' % results.best_score_)\nprint('Config: %s' % results.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # D. Lasso Regression\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nreg6 = Lasso(alpha=0.3, normalize=True)\nreg6.fit(X_train,y_train)\nreg6.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Lasso = reg6.predict(X_test)\nLasso","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(reg6.intercept_)\nprint(reg6.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(y_test,Lasso)\nplt.title('Residual Analysis - Lasso Regression')\nplt.xlabel('Observed')\nplt.ylabel('Residual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE:\", metrics.mean_absolute_error(y_test,Lasso))\nprint('MSE:', metrics.mean_squared_error(y_test, Lasso))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, Lasso)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10 fold CV\nfrom sklearn.linear_model import LassoCV\n## define model evaluation method\ncv = RepeatedKFold(n_splits=10, random_state=1)\n# define model\nmodel = LassoCV(alphas=arange(0, 1, 0.01), cv=cv)\n# fit model\nmodel.fit(X_train, y_train)\n# summarize chosen configuration\nprint('alpha: %f' % model.alpha_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # E. Regression Tree"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nreg4 = DecisionTreeRegressor()\nreg4.fit(X_train,y_train)\nreg4.score(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Dec_Tree = reg4.predict(X_test)\nDec_Tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(y_test,Dec_Tree)\nplt.title('Residual Analysis - Decision Tree Regression')\nplt.xlabel('Observed')\nplt.ylabel('Residual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"MAE:\", metrics.mean_absolute_error(y_test,Dec_Tree ))\nprint('MSE:', metrics.mean_squared_error(y_test, Dec_Tree))\nprint('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, Dec_Tree)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10 Fold\nparameters = {'max_depth':range(3,20)}\nclf = GridSearchCV(reg4, parameters,scoring='neg_mean_squared_error', cv=10)\nclf.fit(X=X_train, y=y_train)\ntree_model = clf.best_estimator_\nprint (clf.best_score_, clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# F.Decision Tree with Pruning"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pruning the Tree\nfrom sklearn.metrics import mean_squared_error, r2_score\n# Minimum observations at the internal node approach\nregtree2 = DecisionTreeRegressor(min_samples_split = 3)\nregtree2.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prediction\ntest_pred2 = regtree2.predict(X_test)\ntrain_pred2 = regtree2.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error on test dataset\nmean_squared_error(y_test, test_pred2)\nr2_score(y_test, test_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Error on train dataset\nmean_squared_error(y_train, train_pred2)\nr2_score(y_train, train_pred2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Minimum observations at the leaf node approach\nregtree3 = DecisionTreeRegressor(min_samples_leaf = 3)\nregtree3.fit(X_train, y_train)\n\n# Prediction\ntest_pred3 = regtree3.predict(X_test)\ntrain_pred3 = regtree3.predict(X_train)\n\n# measure of error on test dataset\nmean_squared_error(y_test, test_pred3)\nr2_score(y_test, test_pred3)\n\n# measure of error on train dataset\nmean_squared_error(y_train, train_pred3)\nr2_score(y_train, train_pred3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10 Fold DT pruning with leaf node apporoach\nparameters = {'max_depth':range(3,20)}\nclf = GridSearchCV(regtree3, parameters,scoring='neg_mean_squared_error' ,cv=10)\nclf.fit(X=X_train, y=y_train)\ntree_model = clf.best_estimator_\nprint (clf.best_score_, clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 10 Fold DT pruning internal node approach\nparameters = {'max_depth':range(3,20)}\nclf = GridSearchCV(regtree2, parameters,scoring='neg_mean_squared_error', cv=10)\nclf.fit(X=X_train, y=y_train)\ntree_model = clf.best_estimator_\nprint (clf.best_score_, clf.best_params_)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # G. Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor(n_estimators = 400, criterion='mse',random_state=1, n_jobs=-1)\nforest.fit(X_train, y_train)\ny_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, r2_score\n#Root_Mean_Square_Log_Error(RMSE) is accuracy criteria for this problem\nprint('RMSLE train: %.3f' % np.sqrt(mean_squared_error(np.log(y_train + 1), np.log(y_train_pred + 1))))\nprint('RMSLE test: %.3f' % np.sqrt(mean_squared_error(np.log(y_test + 1), np.log(y_test_pred + 1))))\nprint('R2 train: %.3f' % r2_score(y_train, y_train_pred))\nprint('R2 test: %.3f' % r2_score(y_test, y_test_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model = RandomForestClassifier()\nfrom sklearn.datasets import make_classification\nfrom sklearn.model_selection import cross_val_score\nfrom numpy import mean\nfrom numpy import std\n# evaluate the model\nmodel = RandomForestRegressor()\n# evaluate the model\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(forest, X_train, y_train, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1, error_score='raise')\n# report performance\nprint('MSE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.regplot(y_test,y_test_pred)\nplt.title('Residual Analysis - Random Forest Regression')\nplt.xlabel('Observed')\nplt.ylabel('Residual')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The best result given by Random Forest across A-H."},{"metadata":{},"cell_type":"markdown","source":"# # H. Gradient Boosting"},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.metrics import accuracy_score, confusion_matrix\nfrom sklearn.ensemble import GradientBoostingRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = GradientBoostingRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model on the whole dataset\nmodel1.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define the evaluation procedure\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n# evaluate the model\nn_scores = cross_val_score(model1, X, y, scoring='neg_mean_squared_error', cv=cv, n_jobs=-1)\n# report performance\nprint('MSE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# # I. Optimal Model"},{"metadata":{},"cell_type":"markdown","source":"*Random Forest with 10 fold cross validation was giving the least error and high accuracy across all the models from A-H\n\nSimilar apporach within train and validation can be apply to the given test data*"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isnull().values.any()  # checking missing entries","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"similarly converting datetime to hour , month and year "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data[\"hour\"] = [t.hour for t in pd.DatetimeIndex(test_data.datetime)]\ntest_data[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(test_data.datetime)]\ntest_data[\"month\"] = [t.month for t in pd.DatetimeIndex(test_data.datetime)]\ntest_data['year'] = [t.year for t in pd.DatetimeIndex(test_data.datetime)]\ntest_data['year'] = test_data['year'].map({2011:0, 2012:1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data =test_data.drop('atemp',axis=1) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=test_data.iloc[:,1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test = scl.transform(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test=forest.predict(X_test) # Random Forest ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = pd.DataFrame(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = test_data\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final['count'] = np.round(y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final = df_final.drop(['season', 'workingday','weather', 'holiday',\n                            'temp', 'humidity', 'windspeed', 'hour', 'day', 'month', 'year'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_final.to_csv('submission.csv', index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}