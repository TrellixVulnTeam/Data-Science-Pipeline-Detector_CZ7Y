{"cells":[{"metadata":{},"cell_type":"markdown","source":"**DATA ANALYSIS AND PREDICTION OF BIKE SHARING DEMAND DATASET**","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#importing all the required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import figure\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn import model_selection\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nimport xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom mlxtend.regressor import StackingRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Loading the dataset\ntrain = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Nulls in training dataset:\",train.isnull().sum().sum())\nprint(\"Nulls in testing dataset:\",test.isnull().sum().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Shape of the training dataset: \",train.shape)\nprint(\"Shape of the testing dataset : \",test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sale Price distribution\nplt.figure(figsize=(10,5))\nax=sns.distplot(train[\"count\"], hist=True , color='skyblue')\nax.text(x=0.97, y=0.97,transform=ax.transAxes, s=\"Skewness: %f\" % train[\"count\"].skew(),\\\n        fontweight='demibold', fontsize=16, verticalalignment='top', horizontalalignment='right',\\\n         color='teal')\nax.text(x=0.97, y=0.91, transform=ax.transAxes, s=\"Kurtosis: %f\" % train[\"count\"].kurt(),\\\n        fontweight='demibold', fontsize=16, verticalalignment='top', horizontalalignment='right',\\\n       color='teal')\nplt.ylabel('Frequency')\nplt.title('No. of total rentals')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The count distribution is highly skewed and platykurtic.We do the transformation by log1p.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sale Price distribution\nplt.figure(figsize=(10,5))\nax=sns.distplot(np.log1p(train[\"count\"]), hist=True , color='skyblue')\nax.text(x=0.97, y=0.97,transform=ax.transAxes, s=\"Skewness: %f\" % np.log1p(train[\"count\"]).skew(),\\\n        fontweight='demibold', fontsize=16, verticalalignment='top', horizontalalignment='right',\\\n         color='teal')\nax.text(x=0.97, y=0.91, transform=ax.transAxes, s=\"Kurtosis: %f\" % np.log1p(train[\"count\"]).kurt(),\\\n        fontweight='demibold', fontsize=16, verticalalignment='top', horizontalalignment='right',\\\n       color='teal')\nplt.ylabel('Frequency')\nplt.title('No. of total rentals')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#removing the outliars\nQ1 =np.log1p(train['count']).quantile(0.25)\nQ3 =np.log1p(train['count']).quantile(0.75)\nIQR = Q3 - Q1\nfilter=(np.log1p(train['count']) >= Q1 - 1.5 * IQR) & (np.log1p(train['count'])<= Q3 + 1.5 *IQR)\ntrain=train.loc[filter]\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding the additional columns required\ntrain['hour'] = pd.DatetimeIndex(train['datetime']).hour\ntrain['day'] = pd.DatetimeIndex(train['datetime']).day\ntrain['month'] = pd.DatetimeIndex(train['datetime']).month\ntrain['year'] = pd.DatetimeIndex(train['datetime']).year\ntrain[\"weekday\"]=pd.DatetimeIndex(train['datetime']).weekday\ntest[\"weekday\"]=pd.DatetimeIndex(test['datetime']).weekday\ntest['hour'] = pd.DatetimeIndex(test['datetime']).hour\ntest['day'] = pd.DatetimeIndex(test['datetime']).day\ntest['month'] = pd.DatetimeIndex(test['datetime']).month\ntest['year'] = pd.DatetimeIndex(test['datetime']).year\nd=test[\"datetime\"]\ntest[\"weekend\"]=0\ntest.loc[(train[\"holiday\"]==0) & (test[\"workingday\"]==0),\"weekend\"]=1\ntrain[\"weekend\"]=0\ntrain.loc[(train[\"holiday\"]==0) & (train[\"workingday\"]==0),\"weekend\"]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation of columns with the count column\ncorr=train[train.columns[1:]].corr()['count'][:]\ncorr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nColumns such as casual , registered and temp have good correlation with the counts column. We also see that temperature and feels like temperature has similar correlation and as they mean the same thing so we can drop either of the one column.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of rentals according to day time\nsns.barplot(y='count', x=\"hour\", data=train, palette=\"bright\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The bike demands are high at around 8 a.m. and 5-6 p.m.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#peak timings according to weather condition\nsns.catplot(x=\"hour\",y=\"count\",col=\"weather\",data=train,kind='bar')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Weather conditions have no influence on peak timings as those are generally the arrival and departure timings of offices. Only the amount of rentals changes as per the weather but the peak timings remains the same.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Counts due to weather conditions\nsns.barplot(x=\"weather\", y=\"count\",data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"from the above graph we conclude that most of the rentals are in clear weather","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#influence of working day on counts as per timings \nplt.figure(figsize=(15,10))\nsns.boxplot(y='count', x=\"workingday\", data=train, palette=\"colorblind\",hue='hour')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"this tells us that only on working days we have peaks around 8 a.m and 5-6 p.m on other days that is weekends and holidays peaks are in evening as people go out to roam","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#number of rentals over the years\nsns.lineplot(x=\"month\", y=\"count\",hue=\"year\", markers=True, dashes=False, data=train)  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"over the years the number of rentals have increased","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#one hot encoding season and weather column\ncolumns=[\"season\",\"weather\"]\nfor col in columns:\n    for i in train.groupby(col).count().index:\n        c=col+str(i)\n        train[c]=0\n        for j in train[col]:\n            if (j==i):\n                train[c].replace({0:1}, inplace=True)\n            else:\n                train[c]=0\ntrain=train.drop(columns=[\"season\",\"weather\"],axis=1)\ntrain.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"columns=[\"season\",\"weather\"]\nfor col in columns:\n    for i in test.groupby(col).count().index:\n        c=col+str(i)\n        test[c]=0\n        for j in test[col]:\n            if (j==i):\n                train[c].replace({0:1}, inplace=True)\n            else:\n                test[c]=0\ntest=test.drop(columns=[\"season\",\"weather\"],axis=1)\ntest.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#mean encoding the hour column as seems to be an important factor \ncolumns=[\"hour\"]\nfor x in columns: \n    mean_encode=train.groupby(x)[\"count\"].mean()\n    train.loc[:,x]=train[x].map(mean_encode)\n    test.loc[:,x]=test[x].map(mean_encode)\n    test[x]=test[x] / test[x].max()\n    train[x]=train[x] / train[x].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.drop(columns=[\"registered\",\"casual\",\"atemp\",\"datetime\",\"weekday\"],axis=1)\nd=test[\"datetime\"]\ntest=test.drop(columns=[\"atemp\",\"datetime\",\"weekday\"],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here we will predict our data using stacking regressor.Stacking is an ensemble machine learning algorithm that combines various classification or regression models to compute the final prediction. We stack all our base estimators i.e, decision tree,random forest,gradient boosting and adaboosting models. These base estimators are then combined using our final estimator i.e, xgboost.\nSo se first look over different regressor models accuacy using  to show why are we using stacking regressor to test the model.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection\nkfold = model_selection.KFold(n_splits=10, random_state=100)\nfrom sklearn.tree import DecisionTreeRegressor\nreg = DecisionTreeRegressor(criterion = 'mse')\nparameters = {\"max_depth\": [5,10,15,20],\n             \"min_samples_split\": [2,4,6,8],\n             \"min_samples_leaf\": [2,4,6,8,10]}\nm1= GridSearchCV(reg, parameters, cv=5, verbose=2,n_jobs=-1)\nm1.fit(train.drop([\"count\"], axis=1), train[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"decision_tree = model_selection.cross_val_score(m1,train.drop([\"count\"], axis=1), train[\"count\"], cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy using decision tree: %.2f%%\" % (decision_tree.mean()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf=RandomForestRegressor(criterion = 'mse')\nparameters = {\"max_depth\": [5,10,15,20],\n             \"min_samples_split\": [2,4,6,8],\n             \"min_samples_leaf\": [2,4,6,8,10]}\nm2=GridSearchCV(rf, parameters, cv=5, verbose=2,n_jobs=-1)\nm2.fit(train.drop([\"count\"], axis=1), train[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_forest = model_selection.cross_val_score(m2,train.drop([\"count\"], axis=1), train[\"count\"], cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy using random forest: %.2f%%\" % (random_forest.mean()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gb=GradientBoostingRegressor(criterion = 'mse')\nparameters = {\"max_depth\": [5,10,15,20],\n             \"min_samples_split\": [2,4,6,8],\n             \"min_samples_leaf\": [2,4,6,8,10]}\nm3=GridSearchCV(rf, parameters, cv=5, verbose=2,n_jobs=-1)\nm3.fit(train.drop([\"count\"], axis=1), train[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gradient_boost= model_selection.cross_val_score(m3,train.drop([\"count\"], axis=1), train[\"count\"], cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy using gradient boost: %.2f%%\" % (gradient_boost.mean()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xg = xgb.XGBRegressor(criterion = 'mse')\nparameters = {\"max_depth\": [5,10,15,20],\n             \"learning rate\": [0.1,0.01,0.001,0.9],\n             \"alpha\":[0,1,10],}\nm4 = GridSearchCV(xg, parameters, cv=5, verbose=2)\nm4.fit(train.drop([\"count\"], axis=1), train[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"extreme_gradient_boost = model_selection.cross_val_score(m4,train.drop([\"count\"], axis=1), train[\"count\"], cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy using extreme gradient boost: %.2f%%\" % (extreme_gradient_boost.mean()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"st= StackingRegressor(regressors=(m1,m2,m3), \n                               meta_regressor=m4,\n                               use_features_in_secondary=True)\nst.fit(train.drop([\"count\"], axis=1), train[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stacked = model_selection.cross_val_score(st,train.drop([\"count\"], axis=1), train[\"count\"], cv=kfold)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Accuracy using stacking: %.2f%%\" % (stacked.mean()*100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans=st.predict(test)\nans[ans<0] = min(train[\"count\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ans=np.round(ans)\nans","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = pd.DataFrame(data = {\"datetime\":d,\"count\":ans})\nresult.to_csv(\"stacked\",index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}