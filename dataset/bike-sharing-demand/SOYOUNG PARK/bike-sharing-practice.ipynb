{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-09T07:43:23.036169Z","iopub.execute_input":"2022-03-09T07:43:23.03752Z","iopub.status.idle":"2022-03-09T07:43:23.048409Z","shell.execute_reply.started":"2022-03-09T07:43:23.037471Z","shell.execute_reply":"2022-03-09T07:43:23.047502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is practice version of notebook!\nFull credit on Python Machine Learning Perfect Guide by Cheol Min Kwon","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nbike_df = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\nprint(bike_df.shape)\nbike_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:23.049806Z","iopub.execute_input":"2022-03-09T07:43:23.050979Z","iopub.status.idle":"2022-03-09T07:43:23.096455Z","shell.execute_reply.started":"2022-03-09T07:43:23.050922Z","shell.execute_reply":"2022-03-09T07:43:23.095596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_df.info()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:23.097985Z","iopub.execute_input":"2022-03-09T07:43:23.098473Z","iopub.status.idle":"2022-03-09T07:43:23.114448Z","shell.execute_reply.started":"2022-03-09T07:43:23.098429Z","shell.execute_reply":"2022-03-09T07:43:23.113475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bike_df['datetime'] = bike_df.datetime.apply(pd.to_datetime)\n\nbike_df['year'] = bike_df.datetime.apply(lambda x:x.year)\nbike_df['month'] = bike_df.datetime.apply(lambda x:x.month)\nbike_df['day'] = bike_df.datetime.apply(lambda x:x.day)\nbike_df['hour'] = bike_df.datetime.apply(lambda x:x.hour)\n\nbike_df.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:23.117007Z","iopub.execute_input":"2022-03-09T07:43:23.117588Z","iopub.status.idle":"2022-03-09T07:43:24.397756Z","shell.execute_reply.started":"2022-03-09T07:43:23.117541Z","shell.execute_reply":"2022-03-09T07:43:24.396955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"drop_columns = ['datetime','casual','registered']\nbike_df.drop(drop_columns,axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:24.398889Z","iopub.execute_input":"2022-03-09T07:43:24.399261Z","iopub.status.idle":"2022-03-09T07:43:24.406309Z","shell.execute_reply.started":"2022-03-09T07:43:24.399231Z","shell.execute_reply":"2022-03-09T07:43:24.405305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\n#Root Mean Squared Log Error\ndef rmsle(y,pred):\n    log_y = np.log1p(y)\n    log_pred = np.log1p(pred)\n    squared_error = (log_y-log_pred)**2\n    rmsle = np.sqrt(np.mean(squared_error))\n    return rmsle\n    \ndef rmse(y,pred): return np.sqrt(mean_squared_error(y,pred))\n\ndef evaluate_regr(y,pred):\n    rmsle_val = rmsle(y,pred)\n    rmse_val = rmse(y,pred)\n    mae_val = mean_absolute_error(y,pred)\n    return print('RMSLE: {0:.3f},RMSE: {1:.3F},MAE: {2:.3F}'.format(rmsle_val,rmse_val,mae_val))    ","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:24.407596Z","iopub.execute_input":"2022-03-09T07:43:24.407847Z","iopub.status.idle":"2022-03-09T07:43:24.421517Z","shell.execute_reply.started":"2022-03-09T07:43:24.407816Z","shell.execute_reply":"2022-03-09T07:43:24.420233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\n\ny_target = bike_df['count']\nX_features = bike_df.drop(['count'],axis=1,inplace=False)\n\nX_train, X_test, y_train, y_test = train_test_split(X_features,y_target,test_size=0.3, random_state=0)\n\nlr_reg = LinearRegression()\nlr_reg.fit(X_train,y_train)\npred = lr_reg.predict(X_test)\n\nevaluate_regr(y_test,pred)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:24.423155Z","iopub.execute_input":"2022-03-09T07:43:24.423543Z","iopub.status.idle":"2022-03-09T07:43:24.473739Z","shell.execute_reply.started":"2022-03-09T07:43:24.423501Z","shell.execute_reply":"2022-03-09T07:43:24.472662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_top_error_data(y_test,pred,n_tops=5):\n    result_df = pd.DataFrame(y_test.values, columns = ['real_count'])\n    result_df['predicted_count'] = np.round(pred)\n    result_df['diff'] = np.abs(result_df['real_count'] - result_df['predicted_count'])\n    return print(result_df.sort_values('diff',ascending=False)[:n_tops])\n\nget_top_error_data(y_test,pred,n_tops=5)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:24.475658Z","iopub.execute_input":"2022-03-09T07:43:24.477568Z","iopub.status.idle":"2022-03-09T07:43:24.514793Z","shell.execute_reply.started":"2022-03-09T07:43:24.477503Z","shell.execute_reply":"2022-03-09T07:43:24.513782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_target.hist(color='yellow')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:24.516447Z","iopub.execute_input":"2022-03-09T07:43:24.518101Z","iopub.status.idle":"2022-03-09T07:43:24.794996Z","shell.execute_reply.started":"2022-03-09T07:43:24.518036Z","shell.execute_reply":"2022-03-09T07:43:24.794255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_log_transform = np.log1p(y_target)\ny_log_transform.hist(color='orange')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:24.797433Z","iopub.execute_input":"2022-03-09T07:43:24.797703Z","iopub.status.idle":"2022-03-09T07:43:25.168189Z","shell.execute_reply.started":"2022-03-09T07:43:24.797671Z","shell.execute_reply":"2022-03-09T07:43:25.167225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_target_log = np.log1p(y_target)\n\nX_train, X_test, y_train, y_test = train_test_split(X_features,y_target_log,test_size=0.3,random_state=0)\n\nlr_reg.fit(X_train,y_train)\npred = lr_reg.predict(X_test)\n\ny_test_exp = np.expm1(y_test)\npred_exp = np.expm1(pred)\n\nevaluate_regr(y_test_exp,pred_exp)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:25.169548Z","iopub.execute_input":"2022-03-09T07:43:25.170685Z","iopub.status.idle":"2022-03-09T07:43:25.209534Z","shell.execute_reply.started":"2022-03-09T07:43:25.170644Z","shell.execute_reply":"2022-03-09T07:43:25.208453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coef = pd.Series(lr_reg.coef_, index= X_features.columns)\ncoef_sort = coef.sort_values(ascending=False)\nsns.barplot(x=coef_sort.values,y=coef_sort.index)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:25.217044Z","iopub.execute_input":"2022-03-09T07:43:25.217839Z","iopub.status.idle":"2022-03-09T07:43:25.544266Z","shell.execute_reply.started":"2022-03-09T07:43:25.217774Z","shell.execute_reply":"2022-03-09T07:43:25.543088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_features_ohe = pd.get_dummies(X_features,columns = ['year','month','day','hour','holiday','workingday','season','weather'])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:25.545397Z","iopub.execute_input":"2022-03-09T07:43:25.545628Z","iopub.status.idle":"2022-03-09T07:43:25.566705Z","shell.execute_reply.started":"2022-03-09T07:43:25.545599Z","shell.execute_reply":"2022-03-09T07:43:25.565452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_features_ohe,y_target_log,test_size=0.3,random_state=0)\n\ndef get_model_predict(model,X_train,X_test,y_train,y_test,is_expm1=False):\n    model.fit(X_train,y_train)\n    pred = model.predict(X_test)\n    if is_expm1:\n        y_test = np.expm1(y_test)\n        pred = np.expm1(pred)\n    print(\"###\",model.__class__.__name__,\"###\")\n    evaluate_regr(y_test,pred)\n    print(\"\\n\")\n    \nlr_reg = LinearRegression()\nridge_reg = Ridge(alpha=10)\nlasso_reg = Lasso(alpha=0.01)\n\nfor model in [lr_reg,ridge_reg,lasso_reg]:\n    get_model_predict(model,X_train,X_test,y_train,y_test,is_expm1=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:43:25.568165Z","iopub.execute_input":"2022-03-09T07:43:25.568505Z","iopub.status.idle":"2022-03-09T07:43:25.863695Z","shell.execute_reply.started":"2022-03-09T07:43:25.56847Z","shell.execute_reply":"2022-03-09T07:43:25.862664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"coef = pd.Series(lr_reg.coef_,index=X_features_ohe.columns)\ncoef_sort =coef.sort_values(ascending=False)[:20]\nsns.barplot(x=coef_sort.values,y=coef_sort.index)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:44:09.420307Z","iopub.execute_input":"2022-03-09T07:44:09.4206Z","iopub.status.idle":"2022-03-09T07:44:09.784626Z","shell.execute_reply.started":"2022-03-09T07:44:09.420571Z","shell.execute_reply":"2022-03-09T07:44:09.783749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nrf_reg = RandomForestRegressor(n_estimators=500)\ngbm_reg= GradientBoostingRegressor(n_estimators=500)\nxgb_reg = XGBRegressor(n_estimators=500)\nlgbm_reg = LGBMRegressor(n_estimators =500)\n\nfor model in [rf_reg,gbm_reg,xgb_reg,lgbm_reg]:\n    get_model_predict(model,X_train.values,X_test.values,y_train.values,y_test.values,is_expm1=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T07:49:25.954777Z","iopub.execute_input":"2022-03-09T07:49:25.955093Z","iopub.status.idle":"2022-03-09T07:50:13.604947Z","shell.execute_reply.started":"2022-03-09T07:49:25.955063Z","shell.execute_reply":"2022-03-09T07:50:13.604236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}