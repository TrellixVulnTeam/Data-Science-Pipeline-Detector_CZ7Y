{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#Impoting all the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport random\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nprint(os.listdir(\"../input/bike-sharing-demand\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reading the data from CSV file\ndf = pd.read_csv(\"../input/bike-sharing-demand/train.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analysing the data\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analysing the data\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropping unwanted columns\ndf=df.drop([ 'datetime','temp','casual','registered'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#rechecking the data\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analysing the column Weathersit\ndf.weather.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analysing the column Weekday\n#df.weekday.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Conversion of datatypes\ndf[\"weather\"]= df[\"weather\"].astype(object) \ndf[\"season\"]= df[\"season\"].astype(object) \ndf[\"mnth\"]= df[\"mnth\"].astype(object) \ndf[\"weekday\"]= df[\"weekday\"].astype(object) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Renaming the values in Season column\ndf['season'] = np.where((df.season == 1) ,'spring',df.season)\ndf['season'] = np.where((df.season == 2) ,'summer',df.season)\ndf['season'] = np.where((df.season == 3) ,'fall',df.season)\ndf['season'] = np.where((df.season == 4) ,'winter',df.season)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Renaming the values in weathersit column\ndf['weathersit'] = np.where((df.weathersit == 1) ,'Clear',df.weathersit)\ndf['weathersit'] = np.where((df.weathersit == 2) ,'Mist_Cloudy', df.weathersit)\ndf['weathersit'] = np.where((df.weathersit == 3) ,'Light_Snow_Light_Rain' ,df.weathersit)\ndf['weathersit'] = np.where((df.weathersit == 4) ,'Heavy Rain_Ice Pallets' ,df.weathersit)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Renaming the values in weekday column\ndf['weekday'] = np.where((df.weekday == 0) ,'Sun',df.weekday)\ndf['weekday'] = np.where((df.weekday == 1) ,'Mon',df.weekday)\ndf['weekday'] = np.where((df.weekday == 2) ,'Tue',df.weekday)\ndf['weekday'] = np.where((df.weekday == 3) ,'Wed',df.weekday)\ndf['weekday'] = np.where((df.weekday == 4) ,'Thu',df.weekday)\ndf['weekday'] = np.where((df.weekday == 5) ,'Fri',df.weekday)\ndf['weekday'] = np.where((df.weekday == 6) ,'Sat',df.weekday)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Re-Analysing the record in weathersit\n#df.season.value_counts()\n#df.mnth.value_counts()\ndf.weathersit.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Re-Analysing the record in season\ndf.season.value_counts()\n#df.mnth.value_counts()\n#df.weathersit.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Re-Analysing the record in weekday\ndf.weekday.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # Step 1 : EDA Analysis ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Count vs 'humidity', 'atemp', 'windspeed'(Continuous Values)\nsns.pairplot(df, x_vars=['hum', 'atemp', 'windspeed'], y_vars='cnt',size=4, aspect=1, kind='scatter')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1)We are seeing a linear graph for Atemp and humidity \n\n2 We can see less count of bike rental if there is higher windspeed ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"##Count vs'season','weekday','workingday','weathersit' ( Categorical Data)\nsns.pairplot(df, x_vars=['season','weekday','workingday','weathersit'], y_vars='cnt',size=4, aspect=1, kind='scatter')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1)We can see that count of bike rentals seems to be slight high for Fall season\n\n2)We can see that count of bike rentals seems to  be slight high for Saturday in the week of the day\n\n3)We can see the count of bike rentals seems to be slight high for non-working day\n\n4)We can see that count of bike rentals seems to be slight high for Clear weathersit compared to other weathersit","execution_count":null},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Categotical Data Analaysis \nplt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'weathersit', y = 'cnt', data = df)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'season', y = 'cnt', data = df)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'mnth', y = 'cnt', data = df)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'weekday', y = 'cnt', data = df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) We can see highest count for Clear weather\n\n2) Spring seems to have low number of counts of bike renatals\n\n3) We can see lowest count of Rental count in 10 month \n\n4) We can see highest count on saturday and lowest on Monday","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Categotical Data Analaysis on Dependent Variables\nplt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'weathersit', y = 'atemp', data = df)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'season', y = 'atemp', data = df)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'mnth', y = 'atemp', data = df)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'weekday', y = 'atemp', data = df)\nplt.subplot(2,3,1)\nplt.figure(figsize=(20, 12))\nplt.subplot(2,3,1)\nsns.boxplot(x = 'weathersit', y = 'windspeed', data = df)\nplt.subplot(2,3,2)\nsns.boxplot(x = 'season', y = 'windspeed', data = df)\nplt.subplot(2,3,3)\nsns.boxplot(x = 'mnth', y = 'windspeed', data = df)\nplt.subplot(2,3,4)\nsns.boxplot(x = 'weekday', y = 'windspeed', data = df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count vs Season with Weekdays Analysis\nplt.figure(figsize = (10, 5))\nsns.boxplot(x = 'season', y = 'cnt', hue = 'weekday', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1)We can see highest count for Saturday on Summer , Fall and Winter \n\n2)We can see that in Spring season, People opt for Rental during Weekdays more than Weekends( Sat and Sun)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Count vs Weahtersit and Weekdays\nplt.figure(figsize = (20, 10))\nsns.boxplot(x = 'weathersit', y = 'cnt', hue = 'weekday', data = df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) We can see Saturday having highest count in all three weathersits\n\n2) We can see very low count for Sunday with Light Snow Light Rain \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Analysing the Holiday/Non-Holiday Count of Bike Renatals\nHoliday_no=df.loc[df['holiday'] == 0, 'cnt'].sum()\nHoliday_yes=df.loc[df['holiday'] == 1, 'cnt'].sum()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"la = ['Holiday', 'Working'] \n  \ndata = [Holiday_yes, Holiday_no]\n  \n# Creating plot \nfig = plt.figure(figsize =(10, 7)) \nplt.pie(data, labels = la) \n  \n# show plot \nplt.show() ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see most the Rentals happened on Working Day ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Step 2 Correlation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation \ncorrs = df[['atemp','windspeed','hum','cnt']].corr()\nsns.heatmap(corrs,annot=True,vmax=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Heat Map for the Factors \nplt.figure(figsize = (10, 10))\nsns.heatmap(df.corr(), cmap=\"YlGnBu\", annot = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing high correlation for Year and Atemp Columns ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Step 3 Dummifying the Categorical Data \n## Data Preparation ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dummifying Weather column \nweather = pd.get_dummies(df['weathersit'], drop_first = True)\ndf = pd.concat([df, weather], axis = 1)\nweather .head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dummifying Season column \nseasons = pd.get_dummies(df['season'], drop_first = True)\ndf = pd.concat([df, seasons], axis = 1)\nseasons.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dummifying the Column month\nmonth = pd.get_dummies(df['mnth'], drop_first = True)\ndf = pd.concat([df, month], axis = 1)\nmonth.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dummifying month column \nweekdays = pd.get_dummies(df['weekday'], drop_first = True)\ndf = pd.concat([df, weekdays], axis = 1)\nweekdays.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the dummified columns from main Dataframe \ndf.drop(['weathersit'], axis = 1, inplace = True)\ndf.drop(['season'], axis = 1, inplace = True)\ndf.drop(['mnth'], axis = 1, inplace = True)\ndf.drop(['weekday'], axis = 1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 4 Divding the Data into Train and Test ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# We specify this so that the train and test data set always have the same rows, respectively\nnp.random.seed(0)\ndf_train, df_test = train_test_split(df, train_size = 0.7, test_size = 0.3, random_state = 100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step 5 Scaling ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler = MinMaxScaler()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply scaler() to all the columns except the 'yes-no' and 'dummy' variables\nnum_vars = ['atemp', 'hum', 'windspeed', 'cnt']\n\ndf_train[num_vars] = scaler.fit_transform(df_train[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Correlation of Every Column after dummification ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (80, 80))\nsns.heatmap(df_train.corr(), annot = True, cmap=\"YlGnBu\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Step : Building the Regression Model \n### First Model with RFE 15 columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = df_train.pop('cnt')\nX_train = df_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LinearRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm=LinearRegression()\nlm.fit(X_train,y_train)\nrfe=RFE(lm,15)\nrfe=rfe.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(zip(X_train.columns,rfe.support_,rfe.ranking_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#List of Columns selected after RFE \ncol=X_train.columns[rfe.support_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Selection of those columns from X_train ( Train Data from DF )\nX_train_rfe=X_train[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding Constant \nimport statsmodels.api as sm \nX_train_rfe_1=sm.add_constant(X_train_rfe)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fitting the data\nlm_1=sm.OLS(y_train,X_train_rfe_1).fit()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Printing the summary \nprint(lm_1.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing a R2 of 84% and all P values in Range ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nimport pandas as pd ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#VIF Analysing the df Data frame \n#from statsmodels.stats.outlier_influence import variance_inflation_factor\n\n\nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing a High VIF for Atemp , Hum , windspeed ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Second Model with removing Hum Column ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop('hum', 1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nX_train_rfe_2=sm.add_constant(X_train_rfe)\n\nlm_2=sm.OLS(y_train,X_train_rfe_2).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_2.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing a R2 of 83% ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing Higher VIF for Atemp ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":" ### Third Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop('atemp', 1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nX_train_rfe_3=sm.add_constant(X_train_rfe)\n\n\n\nlm_3=sm.OLS(y_train,X_train_rfe_3).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_3.summary())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fourth Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop('winter', 1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nX_train_rfe_4=sm.add_constant(X_train_rfe)\n\n\n\nlm_4=sm.OLS(y_train,X_train_rfe_4).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_4.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fifth Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop(4, 1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nX_train_rfe_5=sm.add_constant(X_train_rfe)\n\n\n\nlm_5=sm.OLS(y_train,X_train_rfe_5).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_5.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sixth Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe = X_train_rfe.drop('windspeed', 1,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nX_train_rfe_6=sm.add_constant(X_train_rfe)\n\n\n\nlm_6=sm.OLS(y_train,X_train_rfe_6).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_6.summary())","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Seventh Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#adding column 10 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe=X_train[['yr','spring','Mist_Cloudy',3, 8, 5, 9, 6, 10, 'holiday','Light_Snow_Light_Rain']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nX_train_rfe_7=sm.add_constant(X_train_rfe)\n\n\n\nlm_7=sm.OLS(y_train,X_train_rfe_7).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_7.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Eigth model  ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_rfe=X_train[['yr','spring',3, 8, 5, 9,6,'Mist_Cloudy','holiday','Light_Snow_Light_Rain','Sun',10]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statsmodels.api as sm \nX_train_rfe_8=sm.add_constant(X_train_rfe)\n\n\n\nlm_8=sm.OLS(y_train,X_train_rfe_8).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_8.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Vif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Final Model ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"RFE Columnms + adding columns 10, 7, 'Sun'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Taking into account Columns after RFE and adding further more Columns after previous Model steps\n\nX_train_rfe=X_train[['yr','spring',3, 8, 5, 9,6,'Mist_Cloudy','holiday','Light_Snow_Light_Rain','Sun',10,7]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Fitting a model \nimport statsmodels.api as sm \nX_train_rfe_9=sm.add_constant(X_train_rfe)\n\nlm_9=sm.OLS(y_train,X_train_rfe_9).fit()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the summary of the model\nprint(lm_9.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are getting a R2 of 79.7 % for these Columns 'yr','spring',3, 8, 5, 9,6,'Mist_Cloudy','holiday','Light_Snow_Light_Rain','Sun',10,7","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Vifs \nVif=pd.DataFrame()\nVif['Columm']=X_train_rfe.columns\nVif['VIF']=[variance_inflation_factor (X_train_rfe.values,i) for i in range(X_train_rfe.shape[1])]\nVif['VIF']=round(Vif['VIF'],2)\nVif=Vif.sort_values(by='VIF',ascending=False)\nVif","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) All Vifs in the Range and all the p Values in range\n2) We are getting a R2 of 79.7 % \n3) Adjusted R2 79.2%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#  Residual Analysis of the train data","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### 1. Normal distribution of error ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ny_train_pred = lm_9.predict(X_train_rfe_9)\nres = (y_train - y_train_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the histogram of the error terms\nfig = plt.figure()\nsns.distplot((y_train - y_train_pred), bins = 20)\nfig.suptitle('Error Terms', fontsize = 20)                  # Plot heading \nplt.xlabel('Errors', fontsize = 18) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing the Errors are in normal Distribution ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 2. Patterns in Errors ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"x_t=X_train_rfe_9.iloc[:,0].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(x_t, res)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are seeing a pattern in Error Terms ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### 3. Homoscedasticity check","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"p = sns.scatterplot(y_train_pred,res)\nplt.xlabel('y_pred/predicted values')\nplt.ylabel('Residuals')\nplt.ylim(-2,2)\nplt.xlim(0,1)\np = sns.lineplot([0,26],[0,0],color='blue')\np = plt.title('Residuals vs fitted values plot for homoscedasticity check')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model is Homoscedasticity","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Applying the scaling on the test sets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_vars=['atemp','hum','windspeed','cnt']\ndf_test[num_vars]=scaler.fit_transform(df_test[num_vars])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = df_test.pop('cnt')\nX_test = df_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test=X_test[['yr','spring',3, 8, 5, 9,6,'Mist_Cloudy','holiday','Light_Snow_Light_Rain','Sun',10,7]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding constant variable to test dataframe\nX_test_sm = sm.add_constant(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lm_9.predict(X_test_sm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nplt.scatter(y_test, y_pred)\nfig.suptitle('y_test vs y_pred', fontsize = 20)              # Plot heading \nplt.xlabel('y_test', fontsize = 18)                          # X-label\nplt.ylabel('y_pred', fontsize = 16)      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Returns the mean squared error; we'll take a square root\nnp.sqrt(mean_squared_error(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#R square for Test data on built model \nr_squared = r2_score(y_test, y_pred)\nr_squared","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Agjusted R square for Test data on built model \nprint(\"Rsquared_adj\\n\",lm_9.rsquared_adj)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1) We are seeing 80.2% R2 for test data\n\n2) We are seeing 79.1% Adjusted R2 for test data ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Conclusion :","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can see that the equation of our best fitted line is:\n\nCount = yr x 0.2469 - spring x 0.1980 + 3 x 0.0635 + 8 X 0.1538 \n        + 5 X 0.1230 + 9 x 0.1937 + 6 X 0.1483 - Mist_Cloudy x 0.0907 \n       - holiday x 0.0836 - Light_Snow_Light_Rain x 0.3212 - Sun X 0.0498 + 10 x 0.1168 + 7 x 0.1264\n        ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Overall We can see that \n\n1)Train data has R2 = 79.7%\n\n2)Train data Adju. R2 = 79.2%\n\n3)Test data has R2= 80.2%\n\n4)Test Data adju. R2 = 79.1%","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"We can see that R2 and adjusted R2 are almost equal , hence predicting it as a good Model ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}