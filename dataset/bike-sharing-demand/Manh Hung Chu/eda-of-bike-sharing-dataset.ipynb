{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**This is my first attempt at an EDA, and thus I would try to make the explanation as detailed as possible for my own understanding. If you find anything that I overlooked or made a mistake on, please let me know so that I can improve in the future. Thank you in advance! **","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.140119Z","iopub.execute_input":"2022-06-25T14:59:27.140642Z","iopub.status.idle":"2022-06-25T14:59:27.155323Z","shell.execute_reply.started":"2022-06-25T14:59:27.140571Z","shell.execute_reply":"2022-06-25T14:59:27.154147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Importing other necessary libraries other than defaults\n# This cell would be updated and run again in the case that I would want to use an extra library\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport missingno as msno\nimport calendar\nfrom datetime import datetime","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.156533Z","iopub.execute_input":"2022-06-25T14:59:27.156921Z","iopub.status.idle":"2022-06-25T14:59:27.644518Z","shell.execute_reply.started":"2022-06-25T14:59:27.156891Z","shell.execute_reply":"2022-06-25T14:59:27.643389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Overview","metadata":{}},{"cell_type":"code","source":"# Reading the train and test datasets\ntrain_path = '/kaggle/input/bike-sharing-demand/train.csv'\ntest_path = '/kaggle/input/bike-sharing-demand/test.csv'\n\n# Since the 'datetime' column represents datetime values, the parse_dates argument is also passed\ntrain = pd.read_csv(train_path, parse_dates=['datetime'])\ntest = pd.read_csv(test_path, parse_dates=['datetime'])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.645795Z","iopub.execute_input":"2022-06-25T14:59:27.646096Z","iopub.status.idle":"2022-06-25T14:59:27.691451Z","shell.execute_reply.started":"2022-06-25T14:59:27.646068Z","shell.execute_reply":"2022-06-25T14:59:27.69014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# View a brief excerpt of the train and test datasets\n#train.head()\n#train.tail()\n#test.head()\n#test.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.69369Z","iopub.execute_input":"2022-06-25T14:59:27.694203Z","iopub.status.idle":"2022-06-25T14:59:27.698652Z","shell.execute_reply.started":"2022-06-25T14:59:27.694153Z","shell.execute_reply":"2022-06-25T14:59:27.697379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of train dataset: {}'.format(train.shape))\nprint('Shape of test dataset: {}'.format(test.shape))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.69981Z","iopub.execute_input":"2022-06-25T14:59:27.701065Z","iopub.status.idle":"2022-06-25T14:59:27.721034Z","shell.execute_reply.started":"2022-06-25T14:59:27.701022Z","shell.execute_reply":"2022-06-25T14:59:27.719871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Checking whether the 'count' column truly is the sum of the 'casual' and 'registered' columns\nprint(train[train['count'] != train['casual'] + train['registered']])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.722701Z","iopub.execute_input":"2022-06-25T14:59:27.724045Z","iopub.status.idle":"2022-06-25T14:59:27.739544Z","shell.execute_reply.started":"2022-06-25T14:59:27.723993Z","shell.execute_reply":"2022-06-25T14:59:27.738276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"According to the results of the previous cells, the train dataset has 10886 observations across 9 features, the test dataset has 6493 observations across the same 9 features, whose details will be described below.\nThe train dataset also has 3 columns containing target values, being \"casual\", \"registered\", and \"count\" which is the sum of the previous two. For this reason, it is possible to ignore the other two and only focus on the \"count\" column.","metadata":{}},{"cell_type":"code","source":"# Basic description of the dataset\ntrain.describe().T","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.741508Z","iopub.execute_input":"2022-06-25T14:59:27.74195Z","iopub.status.idle":"2022-06-25T14:59:27.790377Z","shell.execute_reply.started":"2022-06-25T14:59:27.741911Z","shell.execute_reply":"2022-06-25T14:59:27.789237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The basic description of the dataset shows a intriguing point: there are observations in which the humidity is 0 and the windspeed is also 0. While the 0 windspeed might be an actual situation when there was no wind, it could also be the case that the windspeed is negligibly small that it could not be detected. On the other hand, a 0 humidity is an impossibility in and of itself (at least on Earth that is...). Therefore some attention needs to be paid to these values during model. Let's count the number of observations having such extreme values.","metadata":{}},{"cell_type":"code","source":"num_zero_humidity = train['humidity'].value_counts()[0]\nnum_zero_wind = train['windspeed'].value_counts()[0]\nprint('Number of observations with 0 humidity: {}/{} which is {:.4f}%'.format(num_zero_humidity, len(train), num_zero_humidity/len(train)*100))\nprint('Number of observations with 0 wind: {}/{} which is {:.4f}%'.format(num_zero_wind, len(train), num_zero_wind/len(train)*100))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.791896Z","iopub.execute_input":"2022-06-25T14:59:27.792562Z","iopub.status.idle":"2022-06-25T14:59:27.80224Z","shell.execute_reply.started":"2022-06-25T14:59:27.792523Z","shell.execute_reply":"2022-06-25T14:59:27.801249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"With so few observations with 0 humidity, we could get away with removing them.\n\nWith roughly 12% of the observations having 0 windspeed, however, removing them would result in a huge loss of data. Since these values could very well be depicting the situations when windspeed is negligibly small, it would be reasonable to leave them as they are during the modeling stage, or we could try to impute them.","metadata":{}},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:27.846705Z","iopub.execute_input":"2022-06-25T14:59:27.84786Z","iopub.status.idle":"2022-06-25T14:59:27.856607Z","shell.execute_reply.started":"2022-06-25T14:59:27.847803Z","shell.execute_reply":"2022-06-25T14:59:27.855485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking for missing data","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:28.174929Z","iopub.execute_input":"2022-06-25T14:59:28.175564Z","iopub.status.idle":"2022-06-25T14:59:28.185431Z","shell.execute_reply.started":"2022-06-25T14:59:28.175527Z","shell.execute_reply":"2022-06-25T14:59:28.184263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:28.394874Z","iopub.execute_input":"2022-06-25T14:59:28.395294Z","iopub.status.idle":"2022-06-25T14:59:28.405048Z","shell.execute_reply.started":"2022-06-25T14:59:28.395261Z","shell.execute_reply":"2022-06-25T14:59:28.403748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that we are in luck as there are no missing data!!!!\n\n(Makes sense since this is a beginner-friendly dataset)\n\n\nLet's just visualize this lack of missing data for the sake of it, and for the sake of utilizing the missingno library.","metadata":{}},{"cell_type":"code","source":"msno.matrix(train)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:28.687389Z","iopub.execute_input":"2022-06-25T14:59:28.687761Z","iopub.status.idle":"2022-06-25T14:59:29.164117Z","shell.execute_reply.started":"2022-06-25T14:59:28.687732Z","shell.execute_reply":"2022-06-25T14:59:29.162748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transforming data","metadata":{}},{"cell_type":"markdown","source":"As per the description of the dataset, the \"season\", \"holiday\", \"workingday\", \"weather\" features are *'categorical'* features, yet their their *dtype* is *'int64'*. Given that each feature has at most 4 distinct categorical values, it would make sense to encode them with One-hot Encoding when used for making predictions. For EDA, it would be enough to make their *dtype* into *'category'* (and also give better descritive values than just 1,2,3,...)\n\nAlso, the \"datetime\" column contains information on both the hourly date and the timestamp. It would also make sense to seperate from this the values of \"month\", \"day\", \"dayofweek\", and \"hour\" into their own columns for easier analysis.\n\nSo, the to-do list includes:\n* Separate \"datetime\" values into separate columns: \"date\", \"month\", \"dayofweek\", \"hour\"\n* Change \"season\", \"holiday\", \"workingday\", \"weather\", \"date\", \"month\", \"dayofweek\", \"hour\" features into *'category'*\n","metadata":{}},{"cell_type":"code","source":"train['date'] = train['datetime'].dt.date\ntrain['month'] = train['datetime'].dt.month\ntrain['dayofweek'] = train['date'].apply(lambda x: calendar.day_name[datetime.strptime(str(x), '%Y-%m-%d').weekday()])\ntrain['hour'] = train['datetime'].dt.hour\n\ntrain['season'] = train['season'].map({1: 'Spring', 2: 'Summer', 3: 'Fall', 4: 'Winter'})\ntrain['weather'] = train['weather'].map({\n    1: 'Clear / Cloudy', #Clear, Few clouds, Partly cloudy, Partly cloudy\n    2: 'Misty', #Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n    3: 'Light Snow / Rain', #Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n    4: 'Heavy Snow / Rain' #Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n})\n\ntrain = train.drop('datetime',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:29.165885Z","iopub.execute_input":"2022-06-25T14:59:29.166455Z","iopub.status.idle":"2022-06-25T14:59:29.329488Z","shell.execute_reply.started":"2022-06-25T14:59:29.166422Z","shell.execute_reply":"2022-06-25T14:59:29.328545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CategoryCol = ['season','holiday','workingday','weather','month','dayofweek','hour']\nfor col in CategoryCol:\n    train[col] = train[col].astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:29.330879Z","iopub.execute_input":"2022-06-25T14:59:29.33137Z","iopub.status.idle":"2022-06-25T14:59:29.345274Z","shell.execute_reply.started":"2022-06-25T14:59:29.331341Z","shell.execute_reply":"2022-06-25T14:59:29.344329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:29.513804Z","iopub.execute_input":"2022-06-25T14:59:29.514246Z","iopub.status.idle":"2022-06-25T14:59:29.522225Z","shell.execute_reply.started":"2022-06-25T14:59:29.514209Z","shell.execute_reply":"2022-06-25T14:59:29.521231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Outlier Analysis","metadata":{}},{"cell_type":"markdown","source":"At first glance, it is clear that both the \"casual\" and \"registered\" values are heavily skewed to the right, and there exist a great number of observations lying beyond the Third Quantile.\n\nThe boxplots that plot \"count\" against the categorical features reveal some interesting insights:\n* On average, more people rent bikes on working days than non-working days\n* There are fewer rentals during Spring compared to other seasons\n* When the weather is really bad (heavy snow/rain), the number of rentals drop drastically, which is what would be expected\n* The number of rentals are highest during 7-8AM and 5-6PM, which coincide with rush hours. Due to large number of rentals, there are also virtually no outliers during these hours.\n* Saturday and Sunday contribute significantly fewer outliers compared to other days of the week.\n\nThe 4 plots of \"count\" against the numerical features also reveal the following:\n* Plots of \"count\" against \"temp\" and \"atemp\" have similar shape, as they should, because these two features are closely correlated.\n* There is a gap of windspeed values between 0 and 7. This might have confirmed our suspicion that the \"0 windspeed\" implies the case of negligibly small windspeed. Still, we could treat them as they are, or impute them in order to have coutinuous values in the dataset.","metadata":{}},{"cell_type":"code","source":"def draw_plot(data): #making this a function so that plots can be easily redrawn after data transformation\n    # Boxplots of target values\n    fig1, ax1 = plt.subplots(ncols=3,nrows=2)\n    fig1.set_size_inches(20,12)\n    \n    sns.boxplot(data=data, y='count',orient='v',ax=ax1[0,0])\n    ax1[0,0].set(title='Box Plot on Count of Total Rentals', ylabel='Total')\n    \n    sns.boxplot(data=data, x='workingday', y='count', ax=ax1[0,1],orient='v')\n    ax1[0,1].set(title='Box Plot on Total Rentals across Working days and Non-working days', ylabel='Total', xlabel=None)\n    \n    sns.boxplot(data=data, x='dayofweek', y='count',ax=ax1[0,2],orient='v',order=['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'])\n    ax1[0,2].set_xticklabels(ax1[0,2].get_xticklabels(),rotation=30)\n    ax1[0,2].set(title='Box Plot on Total Rentals across Weekdays', ylabel='Total', xlabel=None)\n\n    sns.boxplot(data=data, x='hour', y='count',ax=ax1[1,0],orient='v')\n    ax1[1,0].set_xticklabels(ax1[1,0].get_xticklabels(),rotation=90)\n    ax1[1,0].set(title='Box Plot on Total Rentals across Hours', ylabel='Total', xlabel='Hour')\n\n    sns.boxplot(data=data, x='weather', y='count',ax=ax1[1,1],orient='v')\n    ax1[1,1].set_xticklabels(ax1[1,1].get_xticklabels(),rotation=45)\n    ax1[1,1].set(title='Box Plot on Total Rentals across Weather Conditions', ylabel='Total', xlabel='Weather')\n\n    sns.boxplot(data=data, x='season', y='count',ax=ax1[1,2],orient='v',order=['Spring','Summer','Fall','Winter'])\n    ax1[1,2].set(title='Box Plot on Total Rentals across Seasons', ylabel='Total', xlabel=None)\n    \n    #Scatterplots of 'count' values against numerical features\n    fig3, ax3 = plt.subplots(ncols=4)\n    fig3.set_size_inches(20,6)\n    \n    sns.regplot(data=data, x='temp', y='count',ax=ax3[0],color='goldenrod')\n    sns.regplot(data=data, x='atemp', y='count',ax=ax3[1],color='green')\n    sns.regplot(data=data, x='humidity', y='count',ax=ax3[2],color='purple')\n    sns.regplot(data=data, x='windspeed', y='count',ax=ax3[3])\n    \ndraw_plot(train)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:29.783615Z","iopub.execute_input":"2022-06-25T14:59:29.784174Z","iopub.status.idle":"2022-06-25T14:59:33.986804Z","shell.execute_reply.started":"2022-06-25T14:59:29.784142Z","shell.execute_reply":"2022-06-25T14:59:33.985511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Consider observations with \"count\" value that lies further than 3 standard deviations on either side of the mean value of the column as outliers. Let's remove the outliers!\n\nBox plots of the dataset after removing outliers show fewer values beyond the Third Quantile.","metadata":{}},{"cell_type":"code","source":"trainNoOutlier = train[(np.abs(train['count']-train['count'].mean()) <= (3*train['count'].std())) &\n                       (train['humidity'] != 0)] #removing 0 humidity values as well \ntrainNoOutlier = trainNoOutlier.drop(['casual','registered'],axis=1)\ndraw_plot(trainNoOutlier)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:33.988585Z","iopub.execute_input":"2022-06-25T14:59:33.988906Z","iopub.status.idle":"2022-06-25T14:59:38.337616Z","shell.execute_reply.started":"2022-06-25T14:59:33.988878Z","shell.execute_reply":"2022-06-25T14:59:38.336796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The number of observations which have been removed is insignificant compared to the size of the dataset.","metadata":{}},{"cell_type":"code","source":"print('Shape of train dataset: {}'.format(train.shape))\nprint('Shape of train dataset without outliers: {}'.format(trainNoOutlier.shape))\nprint('Number of removed observations: {}'.format(train.shape[0] - trainNoOutlier.shape[0]))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:38.338783Z","iopub.execute_input":"2022-06-25T14:59:38.339291Z","iopub.status.idle":"2022-06-25T14:59:38.345222Z","shell.execute_reply.started":"2022-06-25T14:59:38.339257Z","shell.execute_reply":"2022-06-25T14:59:38.344017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Distribution","metadata":{}},{"cell_type":"markdown","source":"As clearly depicted in the figures below, the distribution of target values is right-skewed.\n\nSince the target is a count of the number of bike rentals, we could leave this distribution as it is and try to apply Poisson regression model during analysis. Or we could try to normalize this distribution using log transformation or box-con transformation.","metadata":{}},{"cell_type":"code","source":"def draw_distribution(data): #making this a function for easy reuse\n    fig1, ax1 = plt.subplots(ncols=2)\n    fig1.set_size_inches(10,4)\n    sns.histplot(data=data,x='count',kde=True, ax=ax1[0])\n    stats.probplot(x=data['count'], dist='norm', plot=ax1[1])\n    \ndraw_distribution(trainNoOutlier)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:38.347517Z","iopub.execute_input":"2022-06-25T14:59:38.347904Z","iopub.status.idle":"2022-06-25T14:59:38.804986Z","shell.execute_reply.started":"2022-06-25T14:59:38.347867Z","shell.execute_reply":"2022-06-25T14:59:38.803899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Log transforming the response values:","metadata":{}},{"cell_type":"code","source":"train_log = trainNoOutlier.copy().drop(['count'],axis=1)\ntrain_log['count'] = np.log(trainNoOutlier['count'])\n\ndraw_distribution(train_log)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:38.806424Z","iopub.execute_input":"2022-06-25T14:59:38.807211Z","iopub.status.idle":"2022-06-25T14:59:39.274485Z","shell.execute_reply.started":"2022-06-25T14:59:38.807156Z","shell.execute_reply":"2022-06-25T14:59:39.273406Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The incomplete graphs result from the response take value 0 for a number of observations. However, this would not hinder our contiued analysis.\n\nBox-con transforming the response values:","metadata":{}},{"cell_type":"code","source":"train_boxcox = trainNoOutlier.copy().drop(['count'],axis=1)\ntrain_boxcox['count'],_ = stats.boxcox(trainNoOutlier['count']+0.1) #avoid 0 value\n\ndraw_distribution(train_boxcox)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:39.275646Z","iopub.execute_input":"2022-06-25T14:59:39.27596Z","iopub.status.idle":"2022-06-25T14:59:39.869247Z","shell.execute_reply.started":"2022-06-25T14:59:39.275921Z","shell.execute_reply":"2022-06-25T14:59:39.868191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Judging from the distribution and probability plots, the Box-Cox Transformation did a better job of normaling the response values than the Log Transformation, though the results are still far from a normal distribution.","metadata":{}},{"cell_type":"markdown","source":"# Visualizing Correlation","metadata":{}},{"cell_type":"markdown","source":"Let's plot the correlation of response values to numerical features, using the original data, as well as the log-transformed and box-cox-transformed data.","metadata":{}},{"cell_type":"code","source":"corrMatt = trainNoOutlier.corr()\ncorrMattLog=train_log.corr()\ncorrMattBC=train_boxcox.corr()\nmask = np.array(corrMatt)\nmask[np.tril_indices_from(mask)] = False\n\nfig1,ax1=plt.subplots(ncols=3)\nfig1.set_size_inches(20,6)\nsns.heatmap(corrMatt,mask=mask,annot=True,square=True,cmap='YlOrBr',ax=ax1[0])\nax1[0].set(title='Original Data')\nsns.heatmap(corrMattLog,mask=mask,annot=True,square=True,cmap='YlOrBr',ax=ax1[1])\nax1[1].set(title='Log-Transformed Data')\nsns.heatmap(corrMattBC,mask=mask,annot=True,square=True,cmap='YlOrBr',ax=ax1[2])\nax1[2].set(title='Box-Cox-Transformed Data')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:39.871095Z","iopub.execute_input":"2022-06-25T14:59:39.87143Z","iopub.status.idle":"2022-06-25T14:59:40.627438Z","shell.execute_reply.started":"2022-06-25T14:59:39.871403Z","shell.execute_reply":"2022-06-25T14:59:40.626116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* As expected, \"temp\" and \"atemp\" have strong collinearity which can be inferred from common sense. It would make sense to remove either feature from the model, as having both potentially increases the variance of the model. We would choose to keep \"temp\", people often pay attention to this value rather than \"atemp\" when deciding whether or not to rent a bike.\n* \"temp\", \"humidity\", \"windspeed\" have some correlation with though \"windspeed\" very weakly. However, this is not enough reason to remove from the model.","metadata":{}},{"cell_type":"markdown","source":"Displaying the correlation among features (both categorical and numerical) and the response values in more details with the pairplots.\n\nOverall, there is no discernable trends in the correlation among the features and the respone in each pair. However, one noticable strange point is that, there are a number of observations for which even though the \"temp\" values differ by at most 10 degrees, the \"atemp\" values remain unchanged. This suggests some errors in recording the \"atemp\" values. This constitutes another reason to remove the \"atemp\" column from the model.","metadata":{}},{"cell_type":"code","source":"#pairplots of original data\nsns.set()\nsns.pairplot(trainNoOutlier, height=2.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T14:59:40.629214Z","iopub.execute_input":"2022-06-25T14:59:40.629541Z","iopub.status.idle":"2022-06-25T14:59:45.404756Z","shell.execute_reply.started":"2022-06-25T14:59:40.629512Z","shell.execute_reply":"2022-06-25T14:59:45.403389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pairplots of log-transformed data\nsns.set()\nsns.pairplot(train_log, height=2.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T15:03:34.638221Z","iopub.execute_input":"2022-06-25T15:03:34.638666Z","iopub.status.idle":"2022-06-25T15:03:39.64403Z","shell.execute_reply.started":"2022-06-25T15:03:34.638632Z","shell.execute_reply":"2022-06-25T15:03:39.642851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pairplots of box-cox-transformed data\nsns.set()\nsns.pairplot(train_boxcox, height=2.5)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-25T15:04:40.78735Z","iopub.execute_input":"2022-06-25T15:04:40.787785Z","iopub.status.idle":"2022-06-25T15:04:45.8179Z","shell.execute_reply.started":"2022-06-25T15:04:40.787753Z","shell.execute_reply":"2022-06-25T15:04:45.816751Z"},"trusted":true},"execution_count":null,"outputs":[]}]}