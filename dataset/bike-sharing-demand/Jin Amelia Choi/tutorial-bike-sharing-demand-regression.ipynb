{"cells":[{"metadata":{},"cell_type":"markdown","source":"## [Tutorial] Bike Sharing Demand 자전거 대여 수요 예측\n### 책 <파이썬 머신러닝 완벽 마스터> 필사 코드입니다."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore', category=RuntimeWarning)\n\ndata = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\nprint(data.shape)\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# datatime 칼럼의 경우 가공이 필요\n# 년, 월, 일, 시간과 같이 4가지 속성으로 분리\n# 일단, dtype을 datetime으로 변경\n\ndata['datetime'] = data.datetime.apply(pd.to_datetime)\n\n# 4가지 추출\ndata['year'] = data.datetime.apply(lambda x: x.year)\ndata['month'] = data.datetime.apply(lambda x: x.month)\ndata['day'] = data.datetime.apply(lambda x: x.day)\ndata['hour'] = data.datetime.apply(lambda x: x.hour)\ndata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# `casual` 칼럼은 사전에 등록하지 않은 사용자의 자전거 대여 횟수\n# `registered` 칼럼은 사전에 등록한 사용자의 자전거 대여 횟수\n# 두 칼럼을 더해진 것이 `count`이기 때문에 제거 \n\ndrop_columns = ['datetime', 'casual', 'registered']\ndata.drop(drop_columns, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이번 대회에서 요구한 성능 평가 방법은 RMSLE\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\n\n# log 값 변환 시 NaN 등의 이슈로 log()가 아닌 log1p()를 이용해 RMSLE 계산\ndef rmsle(y, pred):\n    log_y = np.log1p(y)\n    log_pred = np.log1p(pred)\n    squared_error = (log_y - log_pred) ** 2\n    rmsle = np.sqrt(np.mean(squared_error))\n    return rmsle\n\n# sklearn의 mean_squared_error 이용해 RMSE 계산\ndef rmse(y, pred):\n    return np.sqrt(mean_squared_error(y, pred))\n\n# MSE, RMSE, RMSLE 모두 계산\ndef evaluate_regr(y, pred):\n    rmsle_val = rmsle(y, pred)\n    rmse_val = rmse(y, pred)\n    mae_val = mean_absolute_error(y, pred)\n    print('RMSLE: {0:.3f}, RMSE: {1:.3f}, MAE: {2:.3f}'.format(rmsle_val, rmse_val, mae_val))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n#### 로그 변환, 피처 인코딩과 모델 학습/예측/평가"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\n\ny_target = data['count']\nx_features = data.drop(['count'], axis=1, inplace=False)\n\nx_train, x_test, y_train, y_test = train_test_split(x_features, y_target, test_size = .3, random_state=0)\n\nlr = LinearRegression()\nlr.fit(x_train, y_train)\npred = lr.predict(x_test)\n\nevaluate_regr(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 예측 오류로 비교적 큰 값이 나옴\n# 실제 값과 예측 값이 어느 정도 차이나는 지 dataframe 칼럼으로 만들어 오류 값이 가장 큰 순으로 5개만 확인\ndef get_top_error_data(y_test, pred, n_tops=5):\n    # dataframe의 칼럼으로 실제 대여 횟수와 예측값을 서로 비교할 수 있도록 생성\n    result_df = pd.DataFrame(y_test.values,\n                            columns = ['real_count'])\n    result_df['predicted_count'] = np.round(pred)\n    result_df['diff'] = np.abs(result_df['real_count'] - result_df['predicted_count'])\n    \n    # 예측값과 실제 값이 가장 큰 데이터 순으로 출력\n    print(result_df.sort_values('diff', ascending=False)[:n_tops])\n    \nget_top_error_data(y_test, pred, n_tops=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 예측 값과 실제 값의 격차가 클 때 살펴볼 것,\n# 1) target 변수의 분포 확인\n# 2) feature들의 분포 확인\n\ny_target.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 0~200 사이에 왜곡되어 있는 값. 스케일링 필요 \ny_log_transform = np.log1p(y_target)\ny_log_transform.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 이를 적용하여 다시 학습 후 평가 필요 \ny_target_log = np.log1p(y_target)\n\nx_train, x_test, y_train, y_test = train_test_split(x_features, y_target_log,\n                                                   test_size = .3,\n                                                   random_state = 0)\n\nlr = LinearRegression()\nlr.fit(x_train, y_train)\npred = lr.predict(x_test)\n\n# 로그 변환 된건 다시 expm1 이용\ny_test_exp = np.expm1(y_test)\npred_exp = np.expm1(pred)\n\nevaluate_regr(y_test_exp, pred_exp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RMSLE 오류는 줄었지만 RMSE는 늘었다. 이유는?\ncoef = pd.Series(lr.coef_,\n                index = x_features.columns)\ncoef_sort = coef.sort_values(ascending=False)\nsns.barplot(x = coef_sort.values,\n           y = coef_sort.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# `year` 피처의 회귀 계수 값이 독보적으로 큰 값을 가지고 있음\n# 이 변수는 카테고리 변수인데 원핫인코딩을 하지 않아서 발생\n# 카테고리 변수들에 원핫인코딩 적용\n\nx_features_ohe = pd.get_dummies(x_features,\n                               columns = ['year', 'month', 'day', 'hour',\n                                         'holiday', 'workingday', 'season', 'weather'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 원핫인코딩 적용\nx_train, x_test, y_train, y_test = train_test_split(x_features_ohe, y_target_log,\n                                                   test_size=.3, random_state = 0)\n\ndef get_model_predict(model, x_train, x_test, y_train, y_test, is_expm1=False):\n    model.fit(x_train, y_train)\n    pred = model.predict(x_test)\n    if is_expm1:\n        y_test = np.expm1(y_test)\n        pred = np.expm1(pred)\n    print('###', model.__class__.__name__, '###')\n    evaluate_regr(y_test, pred)\n\n# 모델별로 평가 수행\nlr = LinearRegression()\nridge = Ridge()\nlasso = Lasso()\n\nfor model in [lr, ridge, lasso]:\n    get_model_predict(model, x_train, x_test, y_train, y_test, is_expm1=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef = pd.Series(lr.coef_, index=x_features_ohe.columns)\ncoef_sort = coef.sort_values(ascending=False)[:20]\nsns.barplot(x=coef_sort.values,\n           y=coef_sort.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 다른 모델 이용\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nrf = RandomForestRegressor(n_estimators=500)\ngbm = GradientBoostingRegressor(n_estimators=500)\nxgb = XGBRegressor(n_estimators=500)\nlgbm = LGBMRegressor(n_estimators=500)\n\nfor model in [rf, gbm, xgb, lgbm]:\n    get_model_predict(model, x_train.values, x_test.values, y_train.values, y_test.values,\n                     is_expm1=True)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}