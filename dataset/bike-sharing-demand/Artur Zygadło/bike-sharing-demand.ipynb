{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 0. Task description\n\n### Bike Sharing Demand\n\nYou are provided **hourly rental data** spanning two years. For this competition, the **training set is comprised of the first 19 days of each month**, while the **test set is the 20th to the end of the month**. You must predict the **total count of bikes rented during each hour** covered by the test set, using only information available prior to the rental period.\n\nSubmissions are evaluated using the **Root Mean Squared Logarithmic Error (RMSLE)**.\n\nNote: RMSLE is usually used when you don't want to penalize huge differences between the predicted and true values when both predicted and true values are huge numbers:\n    - If both predicted and actual values are small: RMSE and RMSLE is same.\n    - If either predicted or the actual value is big: RMSE > RMSLE\n    - If both predicted and actual values are big: RMSE > RMSLE (RMSLE becomes almost negligible)\n\nThis is a **regression** task. \n\nExample regression algorithms/models:    \n    - linear and polynomial regression \n    - decision trees and random forests \n    - gradient boosting \n    - neural networks\n\n\n### Data description:\n<pre>\ndatetime - hourly date + timestamp\nseason -  1 = spring, 2 = summer, 3 = fall, 4 = winter\nholiday - whether the day is considered a holiday\nworkingday - whether the day is neither a weekend nor holiday\nweather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\ntemp - temperature in Celsius\natemp - \"feels like\" temperature in Celsius\nhumidity - relative humidity\nwindspeed - wind speed\ncasual - number of non-registered user rentals initiated\nregistered - number of registered user rentals initiated\n<b>count - number of total rentals</b></pre>"},{"metadata":{},"cell_type":"markdown","source":"# 1. Data exploration\n\n## 1.1 Read data"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import datetime\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sn\nfrom sklearn.metrics import mean_squared_log_error\nimport os\n\nTRAIN_DATA = os.path.join('../input', 'train.csv')\nTEST_DATA = os.path.join('../input', 'test.csv')\n\ntrain_df = pd.read_csv(TRAIN_DATA)\ntest_df = pd.read_csv(TEST_DATA)\ntest_datetime = test_df['datetime']\nprint('Train data set size: {}'.format(train_df.shape))\nprint('Test data set size: {}'.format(test_df.shape))\n\nprint(train_df.dtypes)\nprint(test_df.dtypes)\nprint('N/A values in train data: \\n{}'.format(train_df.isnull().sum()))\n\nprint('Randomly selected 5 rows from the dataframe:')\ntrain_df.sample(frac=1).head(5)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.2 Exploratory data analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i=0\nfor column in ['season', 'holiday', 'workingday', 'weather']:\n    plt.subplot(1, 4, i+1)\n    sn.countplot(column, data=train_df)\n    i = i+1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1.3 Introduce new features"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# rental hour\ntrain_df['hour'] = train_df['datetime'].apply(lambda x: x.split()[1].split(':')[0]).astype(int)\ntest_df['hour'] = test_df['datetime'].apply(lambda x: x.split()[1].split(':')[0]).astype(int)\n# rental month\ntrain_df['month'] = train_df['datetime'].apply(lambda x: x.split()[0].split('-')[1]).astype(int)\ntest_df['month'] = test_df['datetime'].apply(lambda x: x.split()[0].split('-')[1]).astype(int)\n# day of the week\ntrain_df['weekday'] = train_df['datetime'].apply(lambda x: datetime.datetime.strptime(x.split()[0].split(':')[0], '%Y-%m-%d').strftime('%w')).astype(int)\ntest_df['weekday'] = test_df['datetime'].apply(lambda x: datetime.datetime.strptime(x.split()[0].split(':')[0], '%Y-%m-%d').strftime('%w')).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.swarmplot(x='hour', y='temp', hue='season', data=train_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sn.heatmap(train_df.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see high correlation between:\n    - season and month\n    - temperature and \"feels like\" temperature\n    - number of casual/registered rentals and all rentals\n\nIt is also visible that the temperature is quite highly correlated with the number of rentals."},{"metadata":{"trusted":true},"cell_type":"code","source":"CATEGORICAL_VARS = ['season', 'holiday', 'workingday', 'weather', 'hour', 'month', 'weekday']\nfor var in CATEGORICAL_VARS:\n    train_df[var] = train_df[var].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# drop unnecessary columns\ntrain_df = train_df.drop(['datetime', 'casual', 'registered'], axis=1)\ntest_df = test_df.drop(['datetime'], axis=1)\n\ntrain_df.sample(frac=1).head(5)\n\ny_train = train_df['count']\nX_train = train_df.drop(['count'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Model training\n\n## 2.1 Decision Tree regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor, export_graphviz\n\ndecisionTree = DecisionTreeRegressor()\n\ndecisionTree.fit(X = X_train, y = y_train)\npred_tree = decisionTree.predict(X = X_train)\n\nprint(\"RMSLE on training data for a single Decision Tree with default parameters: {:.4f}\".format(np.sqrt(mean_squared_log_error(y_train, pred_tree))))\n# RMSLSE: 0.01078 - looks like a single Decision Tree with default parameters overfit to the train dataset\nprint('Probable overfitting')\n\ndecisionTree2 = DecisionTreeRegressor(max_depth=5)\ndecisionTree2.fit(X = X_train, y = y_train)\npred_tree2 = decisionTree2.predict(X = X_train)\n\nprint(\"RMSLE on training data for a single Decision Tree with maximum depth 5: {:.4f}\".format(np.sqrt(mean_squared_log_error(y_train, pred_tree2))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{},"cell_type":"markdown","source":"## 2.2 Random Forest regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrandomForest = RandomForestRegressor(n_estimators=100)\n\nrandomForest.fit(X = X_train, y = y_train)\npred_rf = randomForest.predict(X = X_train)\n\nprint(\"RMSLE on training data for Random Forest: {:.4f}\".format(np.sqrt(mean_squared_log_error(y_train, pred_rf))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Gradient Boosting regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbm = GradientBoostingRegressor(n_estimators=1000)\ngbm.fit(X = X_train, y = np.log(y_train))\npred_gbm = gbm.predict(X = X_train)\nprint(\"RMSLE on training data for Gradient Boosting: \", np.sqrt(mean_squared_log_error(y_train, np.exp(pred_gbm))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2.3 Predictions for test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"predsTest = gbm.predict(X= test_df)\nfig,(ax1,ax2)= plt.subplots(ncols=2)\nfig.set_size_inches(12,5)\nsn.distplot(y_train, ax=ax1, bins=50)\nsn.distplot(np.exp(predsTest), ax=ax2, bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame({\n        \"datetime\": test_datetime,\n        \"count\": [max(0, x) for x in np.exp(predsTest)]\n    })\nsubmission_df.to_csv('../submission_gbm.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}