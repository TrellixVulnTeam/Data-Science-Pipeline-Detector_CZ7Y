{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nimport missingno as msno\n\n# Ignore  the warnings\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.005545Z","iopub.execute_input":"2022-05-31T00:29:58.006535Z","iopub.status.idle":"2022-05-31T00:29:58.012162Z","shell.execute_reply.started":"2022-05-31T00:29:58.006494Z","shell.execute_reply":"2022-05-31T00:29:58.011304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Set Overview","metadata":{}},{"cell_type":"code","source":"# Read the data\nmydata = pd.read_csv('../input/bike-sharing-demand/train.csv', parse_dates=True, index_col='datetime')\ntestdata = pd.read_csv('../input/bike-sharing-demand/test.csv', parse_dates=True, index_col='datetime')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.017534Z","iopub.execute_input":"2022-05-31T00:29:58.017907Z","iopub.status.idle":"2022-05-31T00:29:58.119863Z","shell.execute_reply.started":"2022-05-31T00:29:58.017876Z","shell.execute_reply":"2022-05-31T00:29:58.118452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Shape of data: ', mydata.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.121857Z","iopub.execute_input":"2022-05-31T00:29:58.122565Z","iopub.status.idle":"2022-05-31T00:29:58.128962Z","shell.execute_reply.started":"2022-05-31T00:29:58.122512Z","shell.execute_reply":"2022-05-31T00:29:58.127631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydata.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.130322Z","iopub.execute_input":"2022-05-31T00:29:58.131625Z","iopub.status.idle":"2022-05-31T00:29:58.163383Z","shell.execute_reply.started":"2022-05-31T00:29:58.13158Z","shell.execute_reply":"2022-05-31T00:29:58.162538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"testdata.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.165316Z","iopub.execute_input":"2022-05-31T00:29:58.165882Z","iopub.status.idle":"2022-05-31T00:29:58.182718Z","shell.execute_reply.started":"2022-05-31T00:29:58.165847Z","shell.execute_reply":"2022-05-31T00:29:58.181407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydata.info()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.184068Z","iopub.execute_input":"2022-05-31T00:29:58.18557Z","iopub.status.idle":"2022-05-31T00:29:58.215459Z","shell.execute_reply.started":"2022-05-31T00:29:58.185492Z","shell.execute_reply":"2022-05-31T00:29:58.21439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydata.describe()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.217394Z","iopub.execute_input":"2022-05-31T00:29:58.218172Z","iopub.status.idle":"2022-05-31T00:29:58.277733Z","shell.execute_reply.started":"2022-05-31T00:29:58.218122Z","shell.execute_reply":"2022-05-31T00:29:58.276701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(mydata.index[[0, -1]]) # Range of time stamp","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.279636Z","iopub.execute_input":"2022-05-31T00:29:58.280405Z","iopub.status.idle":"2022-05-31T00:29:58.289071Z","shell.execute_reply.started":"2022-05-31T00:29:58.280355Z","shell.execute_reply":"2022-05-31T00:29:58.288056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Casual + Registered = Count? ', ~(mydata.casual + mydata.registered - mydata['count']).any())","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.290389Z","iopub.execute_input":"2022-05-31T00:29:58.291157Z","iopub.status.idle":"2022-05-31T00:29:58.306908Z","shell.execute_reply.started":"2022-05-31T00:29:58.291119Z","shell.execute_reply":"2022-05-31T00:29:58.306127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Converting into categorical data\ncategory_list = ['season', 'holiday', 'workingday', 'weather']\nfor var in category_list:\n    mydata[var] = mydata[var].astype('category')\n    testdata[var] = testdata[var].astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.308227Z","iopub.execute_input":"2022-05-31T00:29:58.309562Z","iopub.status.idle":"2022-05-31T00:29:58.32631Z","shell.execute_reply.started":"2022-05-31T00:29:58.309521Z","shell.execute_reply":"2022-05-31T00:29:58.32468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping numbers to understandable text\nseason_dict = {1:'Spring', 2:'Summer', 3:'Fall', 4:'Winter'}\nweather_dict = {1:'Clear', 2:'Misty+Cloudy', 3:'Light Snow/Rain', 4:'Heavy Snow/Rain'}\nmydata['season'] = mydata['season'].map(season_dict)\nmydata['weather'] = mydata['weather'].map(weather_dict)\n\ntestdata['season'] = testdata['season'].map(season_dict)\ntestdata['weather'] = testdata['weather'].map(weather_dict)\n\nmydata.head(n=3)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.331319Z","iopub.execute_input":"2022-05-31T00:29:58.332443Z","iopub.status.idle":"2022-05-31T00:29:58.360435Z","shell.execute_reply.started":"2022-05-31T00:29:58.332384Z","shell.execute_reply":"2022-05-31T00:29:58.359432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average values\nfig = plt.figure(figsize=(15, 10))\naxes = fig.add_subplot(2, 2, 1)\ngroup_weather = pd.DataFrame(mydata.groupby(['weather'])['count'].mean()).reset_index()\nsns.barplot(data=group_weather, x='weather', y='count', ax=axes)\naxes.set(xlabel='Weather', ylabel='Count', title='Average bike rentals across Weather')\n\naxes = fig.add_subplot(2, 2, 2)\ngroup_season = pd.DataFrame(mydata.groupby(['season'])['count'].mean()).reset_index()\nsns.barplot(data=group_season, x='season', y='count', ax=axes)\naxes.set(xlabel='Season', ylabel='Count', title='Average bike rentals across Seasons')\n\naxes = fig.add_subplot(2, 2, 3)\ngroup_workingday = pd.DataFrame(mydata.groupby(['workingday'])['count'].mean()).reset_index()\nsns.barplot(data=group_workingday, x='workingday', y='count', ax=axes)\naxes.set(xlabel='Working Day', ylabel='Count', title='Average bike rentals across Working Day')\n\naxes = fig.add_subplot(2, 2, 4)\ngroup_season = pd.DataFrame(mydata.groupby(['holiday'])['count'].mean()).reset_index()\nsns.barplot(data=group_season, x='holiday', y='count', ax=axes)\naxes.set(xlabel='Holiday', ylabel='Count', title='Average bike rentals across Holiday')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.361902Z","iopub.execute_input":"2022-05-31T00:29:58.36227Z","iopub.status.idle":"2022-05-31T00:29:58.949968Z","shell.execute_reply.started":"2022-05-31T00:29:58.362238Z","shell.execute_reply":"2022-05-31T00:29:58.948556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Seaborn boxplots\nf, axes = plt.subplots(2, 2, figsize=(15, 12))\nhue_order= ['Clear', 'Heavy Snow/Rain', 'Light Snow/Rain', 'Misty+Cloudy']\nsns.boxplot(data=mydata, y='count', x='weather', ax=axes[0][0], order=hue_order)\nsns.boxplot(data=mydata, y='count', x='workingday', ax=axes[0][1])\nhue_order= ['Fall', 'Spring', 'Summer', 'Winter']\nsns.boxplot(data=mydata, y='count', x='season', ax=axes[1][0], order=hue_order)\nsns.boxplot(data=mydata, y='count', x='holiday', ax=axes[1][1])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:58.95194Z","iopub.execute_input":"2022-05-31T00:29:58.952765Z","iopub.status.idle":"2022-05-31T00:29:59.530916Z","shell.execute_reply.started":"2022-05-31T00:29:58.952711Z","shell.execute_reply":"2022-05-31T00:29:59.529786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting data into working-day and non-working day\nmydata_w = mydata[mydata.workingday==1]\nmydata_nw = mydata[mydata.workingday==0]\n\nbin_size = 4\nmydata_w['temp_round'] = mydata_w['temp']//bin_size\nmydata_nw['temp_round'] = mydata_nw['temp']//bin_size\n\nmean_count_vs_temp_w = mydata_w.groupby('temp_round')['count'].mean()\nmean_count_vs_temp_nw = mydata_nw.groupby('temp_round')['count'].mean()\nidx_w, idx_nw = range(len(mean_count_vs_temp_w)), range(len(mean_count_vs_temp_nw))\nlabels_w = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_w))]\nlabels_nw = [str(bin_size*i)+' to '+str(bin_size*(i+1)) for i in range(len(mean_count_vs_temp_nw))]\n\nfig = plt.figure(figsize=(18, 6))\naxes = fig.add_subplot(1, 2, 1)\nplt.bar(x=idx_w, height=mean_count_vs_temp_w)\nplt.xticks(idx_w, labels_w, rotation=90)\nplt.xlabel('temp bins')\nplt.ylabel('Average Count')\nplt.title('Working Days: Average Count given across temperature range')\n\naxes = fig.add_subplot(1, 2, 2)\nplt.bar(x=idx_nw, height=mean_count_vs_temp_nw)\nplt.xticks(idx_nw, labels_nw, rotation=90)\nplt.xlabel('temp bins')\nplt.ylabel('Average Count')\nplt.title('Non-Working Days: Average Count given across temperature range')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:59.532755Z","iopub.execute_input":"2022-05-31T00:29:59.533157Z","iopub.status.idle":"2022-05-31T00:29:59.904433Z","shell.execute_reply.started":"2022-05-31T00:29:59.533122Z","shell.execute_reply":"2022-05-31T00:29:59.903118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Splitting datetime object into month, date, hour and day category columns\nmydata['month'] = [x.month for x in mydata.index]\nmydata['date'] = [x.day for x in mydata.index]\nmydata['hour'] = [x.hour for x in mydata.index]\nmydata['day'] = [x.weekday() for x in mydata.index]\n\ntestdata['month'] = [x.month for x in testdata.index]\ntestdata['date'] = [x.day for x in testdata.index]\ntestdata['hour'] = [x.hour for x in testdata.index]\ntestdata['day'] = [x.weekday() for x in testdata.index]\n\ncategory_list = ['month', 'date', 'hour', 'day']\nfor var in category_list:\n    mydata[var] = mydata[var].astype('category')\n    testdata[var] = testdata[var].astype('category')","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:29:59.906315Z","iopub.execute_input":"2022-05-31T00:29:59.906918Z","iopub.status.idle":"2022-05-31T00:30:00.269518Z","shell.execute_reply.started":"2022-05-31T00:29:59.906865Z","shell.execute_reply":"2022-05-31T00:30:00.268421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mapping 0 to 6 day indices to Monday to Saturday \nday_dict = {0:'Monday', 1:'Teusday', 2:'Wednesday', 3:'Thursday', 4:'Friday', 5:'Saturday', 6:'Sunday'}\nmydata['day'] = mydata['day'].map(day_dict)\ntestdata['day'] = testdata['day'].map(day_dict)\n\nmydata.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:00.270815Z","iopub.execute_input":"2022-05-31T00:30:00.271195Z","iopub.status.idle":"2022-05-31T00:30:00.303595Z","shell.execute_reply.started":"2022-05-31T00:30:00.271161Z","shell.execute_reply":"2022-05-31T00:30:00.302779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# seaborn boxplots across hours\nf, axes = plt.subplots(1, 1, figsize=(15, 6))\nsns.boxplot(data=mydata, y='count', x='hour', hue='workingday', ax=axes)\nhandles, _ = axes.get_legend_handles_labels()\naxes.legend(handles, ['Not a Working Day', 'Working Day'])\naxes.set(title='Hourly Count based on Working day or not')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:00.30486Z","iopub.execute_input":"2022-05-31T00:30:00.305375Z","iopub.status.idle":"2022-05-31T00:30:01.361346Z","shell.execute_reply.started":"2022-05-31T00:30:00.305308Z","shell.execute_reply":"2022-05-31T00:30:01.360199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plots of average count across hour in a day for various categories\n\nf, axes = plt.subplots(nrows=3, ncols=1, figsize=(15, 18))\ngroup_work_hour = pd.DataFrame(mydata.groupby(['workingday', 'hour'])['count'].mean()).reset_index()\nsns.pointplot(data=group_work_hour, x='hour', y='count', hue='workingday', ax=axes[0], legend=True)\nhandles, _ = axes[0].get_legend_handles_labels()\naxes[0].legend(handles, ['Not a Working Day', 'Working Day'])\naxes[0].set(xlabel='Hour in the day', ylabel='Count', title='Average Bike Rentals by the day if Working day or Not')\n\nhue_order= ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\ngroup_day_hour = pd.DataFrame(mydata.groupby(['day', 'hour'])['count'].mean()).reset_index()\nsns.pointplot(data=group_day_hour, x='hour', y='count', hue='day', ax=axes[1], hue_order=hue_order)\naxes[1].set(xlabel='Hour in the day', ylabel='Count', title='Average Bike Rentals by the day across Weekdays')\n\ndf_melt = pd.melt(frame=mydata, id_vars='hour', value_vars=['casual', 'registered'], value_name='count', var_name='casual_or_registered')\ngroup_casual_hour = pd.DataFrame(df_melt.groupby(['hour', 'casual_or_registered'])['count'].mean()).reset_index()\nsns.pointplot(data=group_casual_hour, x='hour', y='count', hue='casual_or_registered', ax=axes[2])\naxes[2].set(xlabel='Hour in the day', ylabel='Count', title='Average Bike Rentals by the day across Casual/Registered Users')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:01.362792Z","iopub.execute_input":"2022-05-31T00:30:01.363174Z","iopub.status.idle":"2022-05-31T00:30:03.40928Z","shell.execute_reply.started":"2022-05-31T00:30:01.36314Z","shell.execute_reply":"2022-05-31T00:30:03.408256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Average Monthly Count Distribution plot\nf, axes = plt.subplots(nrows=1, ncols=1, figsize=(15, 6))\ngroup_month = pd.DataFrame(mydata.groupby(['month', 'workingday'])['count'].mean()).reset_index()\nsns.barplot(data=group_month, x='month', y='count', hue='workingday', ax=axes)\naxes.set(xlabel='Month', ylabel='Count', title='Average bike rentals per Month')\nhandles, _ = axes.get_legend_handles_labels()\naxes.legend(handles, ['Not a Working Day', 'Working Day'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:03.410482Z","iopub.execute_input":"2022-05-31T00:30:03.410846Z","iopub.status.idle":"2022-05-31T00:30:03.726255Z","shell.execute_reply.started":"2022-05-31T00:30:03.410814Z","shell.execute_reply":"2022-05-31T00:30:03.725103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydata_w = mydata[mydata.workingday==1]\nmydata_nw = mydata[mydata.workingday==0]\n\nfig = plt.figure(figsize=(18, 8))\n# Working Day\naxes = fig.add_subplot(1, 2, 1)\nf = axes.scatter(mydata_w.hour, mydata_w['count'], c=mydata_w.temp, cmap = 'RdBu')\naxes.set(xticks = range(24), xlabel='Hours in day', ylabel='Count', title='Working Day: Count vs. Day Hour with Temperature Gradient')\ncbar = plt.colorbar(f)\ncbar.set_label('Temperature in degree C')\n\n# Non Working Day\naxes = fig.add_subplot(1, 2, 2)\nf = axes.scatter(mydata_nw.hour, mydata_nw['count'], c=mydata_nw.temp, cmap = 'RdBu')\naxes.set(xticks = range(24), xlabel='Hours in day', ylabel='Count', title='Non Working Day: Count vs. Day Hour with Temperature Gradient')\ncbar = plt.colorbar(f)\ncbar.set_label('Temperature in degree C')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:03.728556Z","iopub.execute_input":"2022-05-31T00:30:03.729279Z","iopub.status.idle":"2022-05-31T00:30:04.545683Z","shell.execute_reply.started":"2022-05-31T00:30:03.729213Z","shell.execute_reply":"2022-05-31T00:30:04.544427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heavy_weather_data = mydata.loc[mydata['weather']=='Heavy Snow/Rain', :]\nprint(heavy_weather_data.index)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.547456Z","iopub.execute_input":"2022-05-31T00:30:04.547942Z","iopub.status.idle":"2022-05-31T00:30:04.558643Z","shell.execute_reply.started":"2022-05-31T00:30:04.547899Z","shell.execute_reply":"2022-05-31T00:30:04.557378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydata['2012-01-09 08:00' : '2012-01-09 20:00']","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.560295Z","iopub.execute_input":"2022-05-31T00:30:04.560793Z","iopub.status.idle":"2022-05-31T00:30:04.59788Z","shell.execute_reply.started":"2022-05-31T00:30:04.560746Z","shell.execute_reply":"2022-05-31T00:30:04.596949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replacing Heavy/Snow Rain condition with Light Snow/Rain\nmydata.loc[mydata['weather']=='Heavy Snow/Rain', 'weather'] = 'Light Snow/Rain'\ntestdata.loc[testdata['weather']=='Heavy Snow/Rain', 'weather'] = 'Light Snow/Rain'\n\nmydata['2012-01-09 18:00' : '2012-01-09 18:00']","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.599058Z","iopub.execute_input":"2022-05-31T00:30:04.599918Z","iopub.status.idle":"2022-05-31T00:30:04.628083Z","shell.execute_reply.started":"2022-05-31T00:30:04.59988Z","shell.execute_reply":"2022-05-31T00:30:04.627034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mydata['2012-01-09 18:00' : '2012-01-09 18:00']","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.629647Z","iopub.execute_input":"2022-05-31T00:30:04.630818Z","iopub.status.idle":"2022-05-31T00:30:04.658834Z","shell.execute_reply.started":"2022-05-31T00:30:04.630771Z","shell.execute_reply":"2022-05-31T00:30:04.657918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to calculate zscore\ndef zscore(series): \n    return (series-series.mean())/series.std()\n\nmydata['count_zscore'] = mydata.groupby(['hour', 'workingday'])['count'].transform(zscore)\noutlier_idx = np.abs(mydata['count_zscore'])>4\noutlier_data = mydata.loc[outlier_idx, :]\nprint('Shape of the outlier data entries: ', outlier_data.shape)\noutlier_data","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.66057Z","iopub.execute_input":"2022-05-31T00:30:04.661199Z","iopub.status.idle":"2022-05-31T00:30:04.743547Z","shell.execute_reply.started":"2022-05-31T00:30:04.661164Z","shell.execute_reply":"2022-05-31T00:30:04.742293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing outliers from mydata\nmydata_without_outliers = mydata.loc[~outlier_idx, :]\nprint('Shape of data before outliner pruning: ', mydata.shape)\nprint('Shape of data after outlier pruning: ', mydata_without_outliers.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.744965Z","iopub.execute_input":"2022-05-31T00:30:04.745382Z","iopub.status.idle":"2022-05-31T00:30:04.75472Z","shell.execute_reply.started":"2022-05-31T00:30:04.745322Z","shell.execute_reply":"2022-05-31T00:30:04.753633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping the zscore column\nmydata_without_outliers = mydata_without_outliers.drop('count_zscore', axis=1)\nmydata_without_outliers.head(n=3)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.756265Z","iopub.execute_input":"2022-05-31T00:30:04.756753Z","iopub.status.idle":"2022-05-31T00:30:04.784874Z","shell.execute_reply.started":"2022-05-31T00:30:04.756706Z","shell.execute_reply":"2022-05-31T00:30:04.78368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Regression Plots with respect to Temperature, Humidity and Windspeed\nfig = plt.figure(figsize=(18, 8))\naxes = fig.add_subplot(1, 3, 1)\nsns.regplot(data=mydata_without_outliers, x='temp', y='count',ax=axes)\naxes.set(title='Reg Plot for Temperature vs. Count')\naxes = fig.add_subplot(1, 3, 2)\nsns.regplot(data=mydata_without_outliers, x='humidity', y='count',ax=axes, color='r')\naxes.set(title='Reg Plot for Humidity vs. Count')\naxes = fig.add_subplot(1, 3, 3)\nsns.regplot(data=mydata_without_outliers, x='windspeed', y='count',ax=axes, color='g')\naxes.set(title='Reg Plot for Windspeed vs. Count')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:04.78642Z","iopub.execute_input":"2022-05-31T00:30:04.787307Z","iopub.status.idle":"2022-05-31T00:30:07.45801Z","shell.execute_reply.started":"2022-05-31T00:30:04.787261Z","shell.execute_reply":"2022-05-31T00:30:07.456751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Heatmap relative to all numeric columns\ncorr_matrix = mydata_without_outliers.corr()\nmask = np.array(corr_matrix)\nmask[np.tril_indices_from(mask)] = False\n\nfig = plt.figure(figsize=(10, 10))\nsns.heatmap(corr_matrix, mask=mask, annot=True, cbar=True, vmax=0.8, vmin=-0.8, cmap='RdYlGn')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:07.465292Z","iopub.execute_input":"2022-05-31T00:30:07.466151Z","iopub.status.idle":"2022-05-31T00:30:07.836606Z","shell.execute_reply.started":"2022-05-31T00:30:07.466092Z","shell.execute_reply":"2022-05-31T00:30:07.835378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using numbers to represent categorical data to transform the categorical columns\nseason_inv_dict = {'Spring':1, 'Summer':2, 'Fall':3, 'Winter':4}\nweather_inv_dict = {'Clear':1, 'Misty+Cloudy':2, 'Light Snow/Rain':3, 'Heavy Snow/Rain':4}\nday_inv_dict = {'Monday':0, 'Teusday':1, 'Wednesday':2, 'Thursday':3, 'Friday':4, 'Saturday':5, 'Sunday':6}\n\nmydata_without_outliers['season'] = mydata_without_outliers['season'].map(season_inv_dict)\nmydata_without_outliers['weather'] = mydata_without_outliers['weather'].map(weather_inv_dict)\nmydata_without_outliers['day'] = mydata_without_outliers['day'].map(day_inv_dict)\n\ntestdata['season'] = testdata['season'].map(season_inv_dict)\ntestdata['weather'] = testdata['weather'].map(weather_inv_dict)\ntestdata['day'] = testdata['day'].map(day_inv_dict)\n\n# Dropping columns from the provided data set that are either highly correlated with the existing columns: \n# season with month, holiday and day with workingday, temp with atemp\n# or poorly correlated with the target column: windspeed and date\ndrop_columns_1 = ['season', 'holiday', 'atemp', 'windspeed', 'date', 'day']\nmydata_without_outliers = mydata_without_outliers.drop(drop_columns_1, axis=1)\ntestdata = testdata.drop(drop_columns_1, axis=1)\nmydata_without_outliers.head(n=3)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:07.83838Z","iopub.execute_input":"2022-05-31T00:30:07.838929Z","iopub.status.idle":"2022-05-31T00:30:07.878849Z","shell.execute_reply.started":"2022-05-31T00:30:07.838877Z","shell.execute_reply":"2022-05-31T00:30:07.877582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Transforming all the categorical columns into binary columns\nmonth=pd.get_dummies(mydata_without_outliers['month'], prefix='month')\nweather=pd.get_dummies(mydata_without_outliers['weather'], prefix='weather')\nhour=pd.get_dummies(mydata_without_outliers['hour'], prefix='hour')\nmydata_train=pd.concat([mydata_without_outliers, weather, month, hour],axis=1)\n\nmonth=pd.get_dummies(testdata['month'], prefix='month')\nweather=pd.get_dummies(testdata['weather'], prefix='weather')\nhour=pd.get_dummies(testdata['hour'], prefix='hour')\nmydata_test=pd.concat([testdata, weather, month, hour],axis=1)\n\nmydata_train.columns","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:07.880672Z","iopub.execute_input":"2022-05-31T00:30:07.881081Z","iopub.status.idle":"2022-05-31T00:30:07.905868Z","shell.execute_reply.started":"2022-05-31T00:30:07.881048Z","shell.execute_reply":"2022-05-31T00:30:07.904861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Dropping columns and the last binary vector column \ndrop_columns_2 = ['weather', 'month', 'hour', 'weather_3', 'month_12', 'hour_23']\n\nmydata_train = mydata_train.drop(drop_columns_2+['casual', 'registered'], axis=1)\nmydata_test = mydata_test.drop(drop_columns_2, axis=1)\nmydata_without_outliers = mydata_without_outliers.drop(['casual', 'registered'], axis=1)\n\nmydata_train.columns","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:07.907369Z","iopub.execute_input":"2022-05-31T00:30:07.908468Z","iopub.status.idle":"2022-05-31T00:30:07.92407Z","shell.execute_reply.started":"2022-05-31T00:30:07.908421Z","shell.execute_reply":"2022-05-31T00:30:07.923086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"msno.matrix(mydata)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:07.925658Z","iopub.execute_input":"2022-05-31T00:30:07.926147Z","iopub.status.idle":"2022-05-31T00:30:08.442662Z","shell.execute_reply.started":"2022-05-31T00:30:07.926099Z","shell.execute_reply":"2022-05-31T00:30:08.44143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_train, model_test = mydata_train[mydata_train.index.day<15], mydata_train[mydata_train.index.day>=15]\nmodel_train2, model_test2 = mydata_without_outliers[mydata_without_outliers.index.day<15], mydata_without_outliers[mydata_without_outliers.index.day>=15]\n\n# Separating out the working an non-working data from the training set \nmodel_train_w = model_train[model_train['workingday']==1]\nmodel_train_nw = model_train[model_train['workingday']==0]\nmodel_train2_w = model_train2[model_train2['workingday']==1]\nmodel_train2_nw = model_train2[model_train2['workingday']==0]\n\nmodel_test_w = model_test[model_test['workingday']==1]\nmodel_test_nw = model_test[model_test['workingday']==0]\nmodel_test2_w = model_test2[model_test2['workingday']==1]\nmodel_test2_nw = model_test2[model_test2['workingday']==0]\n\n# Dropping workingday column \nmodel_train_w = model_train_w.drop('workingday', axis=1)\nmodel_train_nw = model_train_nw.drop('workingday', axis=1)\nmodel_train2_w = model_train2_w.drop('workingday', axis=1)\nmodel_train2_nw = model_train2_nw.drop('workingday', axis=1)\n\nmodel_test_w = model_test_w.drop('workingday', axis=1)\nmodel_test_nw = model_test_nw.drop('workingday', axis=1)\nmodel_test2_w = model_test2_w.drop('workingday', axis=1)\nmodel_test2_nw = model_test2_nw.drop('workingday', axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.444362Z","iopub.execute_input":"2022-05-31T00:30:08.445171Z","iopub.status.idle":"2022-05-31T00:30:08.488164Z","shell.execute_reply.started":"2022-05-31T00:30:08.445109Z","shell.execute_reply":"2022-05-31T00:30:08.486728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Contains Binary Vector Form of features (Obtained from OneHotEncoder transformed categorical feature)\nX, X_w, X_nw = model_train.drop('count', axis=1), model_train_w.drop('count', axis=1), model_train_nw.drop('count', axis=1)\ny, y_w, y_nw = model_train['count'], model_train_w['count'], model_train_nw['count']\nlogy, logy_w, logy_nw = np.log1p(y), np.log1p(y_w), np.log1p(y_nw)\n\nXtest, Xtest_w, Xtest_nw = model_test.drop('count', axis=1), model_test_w.drop('count', axis=1), model_test_nw.drop('count', axis=1)\nytest, ytest_w, ytest_nw = model_test['count'], model_test_w['count'], model_test_nw['count']\nlogytest, logytest_w, logytest_nw = np.log1p(y), np.log1p(y_w), np.log1p(y_nw)\n\n# Contains Categorical features instead of the Binary Vector Form\nX2, X2_w, X2_nw = model_train2.drop('count', axis=1), model_train2_w.drop('count', axis=1), model_train2_nw.drop('count', axis=1)\ny2, y2_w, y2_nw = model_train2['count'], model_train2_w['count'], model_train2_nw['count']\nlogy2, logy2_w, logy2_nw = np.log1p(y2), np.log1p(y2_w), np.log1p(y2_nw)\n\nXtest2, Xtest2_w, Xtest2_nw = model_test2.drop('count', axis=1), model_test2_w.drop('count', axis=1), model_test2_nw.drop('count', axis=1)\nytest2, ytest2_w, ytest2_nw = model_test2['count'], model_test2_w['count'], model_test2_nw['count']\nlogytest2, logytest2_w, logytest2_nw = np.log1p(y), np.log1p(y_w), np.log1p(y_nw)\n\n# Data Frame to store all the RMSLE scores for various algorithms\nalgo_score = pd.DataFrame()\nalgo_score.index.name = 'Modelling Algo'\nalgo_score['Train RMSLE (Working Day)'] = None\nalgo_score['Train RMSLE (Non Working Day)'] = None\nalgo_score['Train RMSLE (Average)'] = None\nalgo_score['Test RMSLE (Working Day)'] = None\nalgo_score['Test RMSLE (Non Working Day)'] = None\nalgo_score['Test RMSLE (Average)'] = None\nalgo_score['Validation RMSLE (Working Day)'] = None\nalgo_score['Validation RMSLE (Non Working Day)'] = None\nalgo_score['Validation RMSLE (Average)'] = None\nalgo_score['Hyperparameters-Working'] = None\nalgo_score['Hyperparameters-Non Working'] = None\nalgo_score['Training+Test Time (sec)'] = None\ncv_time = []\n\n# Data Frame for second level of prediction. Collect the predicted y values for training and test set of data\nypred_train = pd.DataFrame(index = X.index)\nypred_test = pd.DataFrame(index = Xtest.index)\nypred_train['count'], ypred_test['count'] = y, ytest ","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.492835Z","iopub.execute_input":"2022-05-31T00:30:08.493379Z","iopub.status.idle":"2022-05-31T00:30:08.540364Z","shell.execute_reply.started":"2022-05-31T00:30:08.49331Z","shell.execute_reply":"2022-05-31T00:30:08.53847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\n\n# Metric used to measure the model (Root Mean Square Log Error)\ndef rmsle(y_actual, y_pred):\n    log1 = np.nan_to_num(np.array([np.log1p(v) for v in y_pred]))\n    log2 = np.nan_to_num(np.array([np.log1p(v) for v in y_actual]))\n    calc = (log1 - log2) ** 2\n    return np.sqrt(np.mean(calc))\n\n# RMSLE function with inputs in log form. Used for CrossValidation scoring\ndef rmsle_log(logy_actual, logy_pred):\n    calc = (logy_actual - logy_pred) ** 2\n    return np.sqrt(np.mean(calc))\nrmsle_cv = make_scorer(rmsle_log, greater_is_better=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.545247Z","iopub.execute_input":"2022-05-31T00:30:08.545771Z","iopub.status.idle":"2022-05-31T00:30:08.787229Z","shell.execute_reply.started":"2022-05-31T00:30:08.545734Z","shell.execute_reply":"2022-05-31T00:30:08.786055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plots True vs. Predictied count values in a particular time interval\ndef plot_true_vs_pred (y_w_actual, y_nw_actual, y_w_pred, y_nw_pred, algo, t_from, t_to):\n    fig = plt.figure(figsize=(18, 16))\n    \n    # Working day plot\n    axes = fig.add_subplot(2, 1, 1)\n    axes.plot(y_w_actual[t_from:t_to], label='Actual', marker='.', markersize=15)\n    axes.plot(y_w_pred[t_from:t_to], label='Predicted', marker='.', markersize=15)\n    axes.set(xlabel='Time', ylabel='Count', title='{0} Model for Working Day: Count between time {1} and {2}'.format(algo, t_from, t_to))\n    axes.legend()\n\n    # Non working day plot\n    axes = fig.add_subplot(2, 1, 2)\n    axes.plot(y_nw_actual[t_from:t_to], label='Actual', marker='.', markersize=15)\n    axes.plot(y_nw_pred[t_from:t_to], label='Predicted', marker='.', markersize=15)\n    axes.set(xlabel='Time', ylabel='Count', title='{0} Model for Non Working Day: Count between time {1} and {2}'.format(algo, t_from, t_to))\n    axes.legend()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.788884Z","iopub.execute_input":"2022-05-31T00:30:08.789248Z","iopub.status.idle":"2022-05-31T00:30:08.801186Z","shell.execute_reply.started":"2022-05-31T00:30:08.789218Z","shell.execute_reply":"2022-05-31T00:30:08.799977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Customized Function to fit/predict training and testing data for:\n# 1. working and non-working days or 2. combined working and non-working days\n# Output: 1. rmsle for training, test data for working, non-working and combined \n#         2. predicted y for training, test for working/non-working or combined\ndef model_fit (model_w, X_tr_w, X_t_w, y_tr_w, y_t_w, model_nw=None, X_tr_nw=None, X_t_nw=None, y_tr_nw=None, y_t_nw=None):\n    ''' Case 1: If separate models for Working day and non-working day\n    model_w, model_nw = Models for Working and non-working days, respectively\n    X_tr_w, y_tr_w = Training data set for Working days\n    X_t_w, y_t_w = Testing data set for Working days\n    X_tr_nw, y_tr_nw = Training data set for Non Working days\n    X_t_nw, y_t_nw = Testing data set for Non Working days \n    \n    Case 2: If single model for working day and non-working day \n    model_w = Single Model for Working and non-working days\n    X_tr_w, y_tr_w = Training data set containing both Working and non-working days (feature list must contain 'workingday')\n    X_t_w, y_t_w = Testing data set containing both Working and non-working days'''\n    \n    # Working Day Modeling of Single Model for Working and Non-Working Day\n    model_w.fit(X_tr_w, np.log1p(y_tr_w))\n    logy_tr_w_predict = model_w.predict(X_tr_w)\n    logy_t_w_predict = model_w.predict(X_t_w)\n    \n    y_tr_w_predict = np.expm1(logy_tr_w_predict)\n    y_t_w_predict = np.expm1(logy_t_w_predict)\n    \n    rmsle_w_tr = rmsle(y_tr_w, y_tr_w_predict)\n    rmsle_w_t = rmsle(y_t_w, y_t_w_predict)\n    \n    if model_nw is None:\n        # Single Model for working and non-working days. The feature list in X should have workingday column\n        [rmsle_avg_tr, rmsle_avg_t] = [rmsle_w_tr, rmsle_w_t] # The RMSLE computed by the first model is the overall RMSLE\n        rmsle_w_tr = rmsle(y_tr_w[X_tr_w.workingday==1], y_tr_w_predict[X_tr_w.workingday==1])\n        rmsle_nw_tr = rmsle(y_tr_w[X_tr_w.workingday==0], y_tr_w_predict[X_tr_w.workingday==0])\n        rmsle_w_t = rmsle(y_t_w[X_t_w.workingday==1], y_t_w_predict[X_t_w.workingday==1])\n        rmsle_nw_t = rmsle(y_t_w[X_t_w.workingday==0], y_t_w_predict[X_t_w.workingday==0])\n        y_tr_nw_predict, y_t_nw_predict = None, None\n    else:\n        # Non-working day Modeling\n        model_nw.fit(X_tr_nw, np.log1p(y_tr_nw))\n        logy_tr_nw_predict = model_nw.predict(X_tr_nw)\n        logy_t_nw_predict = model_nw.predict(X_t_nw)\n\n        y_tr_nw_predict = np.expm1(logy_tr_nw_predict)\n        y_t_nw_predict = np.expm1(logy_t_nw_predict)\n\n        rmsle_nw_tr = rmsle(y_tr_nw, y_tr_nw_predict)\n        rmsle_nw_t = rmsle(y_t_nw, y_t_nw_predict)\n\n        # Combined RMSLE\n        [rmsle_avg_tr, rmsle_avg_t] = [rmsle(np.concatenate([y_tr_w, y_tr_nw]), np.concatenate([y_tr_w_predict, y_tr_nw_predict])), \n                                       rmsle(np.concatenate([y_t_w, y_t_nw]), np.concatenate([y_t_w_predict, y_t_nw_predict]))]\n    \n    rmsle_all = [rmsle_w_tr, rmsle_nw_tr, rmsle_avg_tr, rmsle_w_t, rmsle_nw_t, rmsle_avg_t]\n    y_pred_all = [y_tr_w_predict, y_t_w_predict, y_tr_nw_predict, y_t_nw_predict]\n    \n    return(rmsle_all, y_pred_all)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.803179Z","iopub.execute_input":"2022-05-31T00:30:08.803783Z","iopub.status.idle":"2022-05-31T00:30:08.824902Z","shell.execute_reply.started":"2022-05-31T00:30:08.803729Z","shell.execute_reply":"2022-05-31T00:30:08.823646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cross_val(model_w, X_in_w, y_in_w, model_nw=None, X_in_nw=None, y_in_nw=None, cv=5):\n    y_val_pred_w = pd.Series(index=y_in_w.index)\n    y_val_pred_nw = None if model_nw == None else pd.Series(index=y_in_nw.index)\n    for idx in range(cv):\n        from_, to_ = idx*15/cv, (idx+1)*15/cv\n        \n        val_idx_w = (X_in_w.index.day>from_) & (X_in_w.index.day<=to_)\n        train_idx_w = ~val_idx_w\n        \n        X_idx_w, y_idx_w, X_val_idx_w = X_in_w[train_idx_w], y_in_w[train_idx_w], X_in_w[val_idx_w]\n        model_w.fit(X_idx_w, np.log1p(y_idx_w))\n        logy_val_pred_idx_w = model_w.predict(X_val_idx_w)\n        y_val_pred_w[val_idx_w] = np.expm1(logy_val_pred_idx_w)\n        \n        if model_nw is not None:\n            val_idx_nw = (X_in_nw.index.day>from_) & (X_in_nw.index.day<=to_)\n            train_idx_nw = ~val_idx_nw\n            \n            X_idx_nw, y_idx_nw, X_val_idx_nw = X_in_nw[train_idx_nw], y_in_nw[train_idx_nw], X_in_nw[val_idx_nw]\n            model_nw.fit(X_idx_nw, np.log1p(y_idx_nw))\n            logy_val_pred_idx_nw = model_nw.predict(X_val_idx_nw)\n            y_val_pred_nw[val_idx_nw] = np.expm1(logy_val_pred_idx_nw)\n    \n    if model_nw is None: \n        rmsle_avg = rmsle(y_in_w, y_val_pred_w)\n        rmsle_w = rmsle(y_in_w[X_in_w.workingday==1], y_val_pred_w[X_in_w.workingday==1])\n        rmsle_nw = rmsle(y_in_w[X_in_w.workingday==0], y_val_pred_w[X_in_w.workingday==0])\n    else:\n        rmsle_w = rmsle(y_in_w, y_val_pred_w)\n        rmsle_nw = rmsle(y_in_nw, y_val_pred_nw)\n        rmsle_avg = rmsle(np.concatenate([y_in_w, y_in_nw]), np.concatenate([y_val_pred_w, y_val_pred_nw]))\n    \n    rmsle_all = [rmsle_w, rmsle_nw, rmsle_avg]\n    y_pred_all =[y_val_pred_w, y_val_pred_nw]\n    return(rmsle_all, y_pred_all)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.82616Z","iopub.execute_input":"2022-05-31T00:30:08.82654Z","iopub.status.idle":"2022-05-31T00:30:08.846434Z","shell.execute_reply.started":"2022-05-31T00:30:08.826507Z","shell.execute_reply":"2022-05-31T00:30:08.845182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regressor Ensemble for the above 3 models\ndef stack_model_fit (model, X_tr, X_t, y_tr, y_t):\n    model.fit(X_tr, y_tr)\n    y_tr_pred = model.predict(X_tr)\n    y_t_pred = model.predict(X_t)\n    \n    [rmsle_avg_tr, rmsle_avg_t] = rmsle(y_tr, y_tr_pred), rmsle(y_t, y_t_pred)\n    \n    y_tr_w_pred, y_tr_nw_pred = y_tr_pred[X.workingday==1], y_tr_pred[X.workingday==0]\n    y_t_w_pred, y_t_nw_pred = y_t_pred[Xtest.workingday==1], y_t_pred[Xtest.workingday==0]\n    y_tr_w, y_tr_nw = y_tr[X.workingday==1], y_tr[X.workingday==0]\n    y_t_w, y_t_nw = y_t[Xtest.workingday==1], y_t[Xtest.workingday==0]\n    \n    rmsle_w_tr, rmsle_nw_tr = rmsle(y_tr_w, y_tr_w_pred), rmsle(y_tr_nw, y_tr_nw_pred)\n    rmsle_w_t, rmsle_nw_t = rmsle(y_t_w, y_t_w_pred), rmsle(y_t_nw, y_t_nw_pred)\n    \n    rmsle_all = [rmsle_w_tr, rmsle_nw_tr, rmsle_avg_tr, rmsle_w_t, rmsle_nw_t, rmsle_avg_t]\n    y_pred_all = [y_tr_pred, y_t_pred]\n    \n    return(rmsle_all, y_pred_all)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.84812Z","iopub.execute_input":"2022-05-31T00:30:08.849418Z","iopub.status.idle":"2022-05-31T00:30:08.865724Z","shell.execute_reply.started":"2022-05-31T00:30:08.84936Z","shell.execute_reply":"2022-05-31T00:30:08.86466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlreg_w, lreg_nw = LinearRegression(), LinearRegression()\n\nparam_summary = ['', '', '']\n\nrmsle_summary, y_predict_summary = model_fit(lreg_w, X_w, Xtest_w, y_w, ytest_w, lreg_nw, X_nw, Xtest_nw, y_nw, ytest_nw)\nypred_test.loc[Xtest.workingday==1,'LR'], ypred_test.loc[Xtest.workingday==0,'LR'] = y_predict_summary[1], y_predict_summary[3]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:08.867518Z","iopub.execute_input":"2022-05-31T00:30:08.868282Z","iopub.status.idle":"2022-05-31T00:30:09.29421Z","shell.execute_reply.started":"2022-05-31T00:30:08.868233Z","shell.execute_reply":"2022-05-31T00:30:09.293377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle_val_summary, y_predict_val_summary = cross_val(lreg_w, X_w, y_w, lreg_nw, X_nw, y_nw)\nypred_train.loc[X.workingday==1,'LR'], ypred_train.loc[X.workingday==0,'LR'] = y_predict_val_summary[0], y_predict_val_summary[1]\n\nalgo_score.loc['Linear Regression'] = rmsle_summary+rmsle_val_summary+param_summary\nalgo_score.loc[['Linear Regression']]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:09.297626Z","iopub.execute_input":"2022-05-31T00:30:09.298145Z","iopub.status.idle":"2022-05-31T00:30:09.838531Z","shell.execute_reply.started":"2022-05-31T00:30:09.298105Z","shell.execute_reply":"2022-05-31T00:30:09.836559Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"algo_score.loc['Linear Regression', 'Training+Test Time (sec)'] = 0.197\ncv_time.append(0.237)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:09.840347Z","iopub.execute_input":"2022-05-31T00:30:09.840882Z","iopub.status.idle":"2022-05-31T00:30:09.847089Z","shell.execute_reply.started":"2022-05-31T00:30:09.840841Z","shell.execute_reply":"2022-05-31T00:30:09.846019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear Regression Plot: True vs. Predicted for one week \nt_from, t_to = '2012-08-01', '2012-08-30'\nytest_w_predict, ytest_nw_predict = y_predict_summary[1], y_predict_summary[3]\nytest_w_predict = pd.Series(ytest_w_predict, index = ytest_w.index)\nytest_nw_predict = pd.Series(ytest_nw_predict, index = ytest_nw.index)\n\nplot_true_vs_pred(ytest_w, ytest_nw, ytest_w_predict, ytest_nw_predict, 'Linear Regression', t_from, t_to)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:09.848576Z","iopub.execute_input":"2022-05-31T00:30:09.849874Z","iopub.status.idle":"2022-05-31T00:30:10.638444Z","shell.execute_reply.started":"2022-05-31T00:30:09.84982Z","shell.execute_reply":"2022-05-31T00:30:10.637208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Features and the Estimated Linear Regression Coefficients obtained for Working day and Non-working day models\ndf_coeff = pd.DataFrame({'features': X_w.columns, 'Lin_Coeff_Working': lreg_w.coef_, 'Lin_Coeff_Non_Working': lreg_nw.coef_})","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:10.640595Z","iopub.execute_input":"2022-05-31T00:30:10.641162Z","iopub.status.idle":"2022-05-31T00:30:10.649611Z","shell.execute_reply.started":"2022-05-31T00:30:10.641112Z","shell.execute_reply":"2022-05-31T00:30:10.648281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Head of the Traning data\nX2.head(n=3)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:10.65129Z","iopub.execute_input":"2022-05-31T00:30:10.651831Z","iopub.status.idle":"2022-05-31T00:30:10.674087Z","shell.execute_reply.started":"2022-05-31T00:30:10.651782Z","shell.execute_reply":"2022-05-31T00:30:10.673271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Random Forest Regression Hyperparameter tuning using Grid Search to obtain the best parameters. \n## Commented it out since it takes a lot of time to run. Using the best parameters obtained via the below search\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# param_grid = {'n_estimators': [50, 100, 200, 500, 1000, 2000, 5000]}\n# rf_main = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=rmsle_cv)\n# rf_main.fit(X2, logy2)\n\n# param_grid = {'n_estimators': [500], 'max_features':['auto', 'sqrt', 'log2']}\n# rf_main = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=rmsle_cv)\n# rf_main.fit(X2, logy2)\n\n# param_grid = {'n_estimators': [500], 'max_features':['auto'], 'min_samples_leaf':[1, 3, 7, 10, 20, 50]}\n# rf_main = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=rmsle_cv)\n# rf_main.fit(X2, logy2)\n\n# param_grid = {'n_estimators': [500], 'max_features':['auto'], 'min_samples_leaf':[7], 'max_depth':[5, 8, 10, 20, 30, 40, 50, 70]}\n# rf_main = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=rmsle_cv)\n# rf_main.fit(X2, logy2)\n\n# param_grid = {'n_estimators': [500], 'max_features':['auto'], 'min_samples_leaf':[7], 'max_depth':[10], 'min_samples_split':[0.0001, 0.001, 0.002, 0.005, 0.01]}\n# rf_main = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=rmsle_cv)\n# rf_main.fit(X2, logy2)\n\n# print('Best parameters for Random Forest Regression Model: {}'.format(rf_main.best_params_))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:10.675588Z","iopub.execute_input":"2022-05-31T00:30:10.676138Z","iopub.status.idle":"2022-05-31T00:30:10.842068Z","shell.execute_reply.started":"2022-05-31T00:30:10.676101Z","shell.execute_reply":"2022-05-31T00:30:10.84074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All the below results are obtained from the above GridSearchCV hyperparamter tuning\nfig=plt.figure(figsize=(18, 12))\n\nn_est_array = [50, 100, 200, 500, 1000, 2000, 5000]\nn_est_cv_score = [-0.59522862, -0.59345376, -0.59307606, -0.59260841, -0.59292831,-0.59274538, -0.59279494]\naxes=fig.add_subplot(2, 3, 1)\naxes.plot(n_est_array, n_est_cv_score, marker='.')\naxes.set(xlabel='n_estimators', ylabel='Mean CV Test Score', title='n_estimators vs. Score (best_n_estimator = 500)')\n\nmax_feature_array = ['auto', 'sqrt', 'log2']\nmax_feature_cv_score = [-0.59260841, -0.60178303, -0.60178303]\naxes=fig.add_subplot(2, 3, 2)\naxes.plot(range(3), max_feature_cv_score, marker='.')\nplt.xticks(range(3), max_feature_array)\naxes.set(xlabel='max_feature', ylabel='Mean CV Test Score', title='max_feature vs. Score (best_max_feature = auto)')\n\nmin_samples_leaf_array = [1, 3, 7, 10, 20, 50]\nmin_samples_leaf_cv_score = [-0.59260841, -0.58788348, -0.58764415, -0.59060404, -0.60340495,-0.63367843]\naxes=fig.add_subplot(2, 3, 3)\naxes.plot(min_samples_leaf_array, min_samples_leaf_cv_score, marker='.')\naxes.set(xlabel='min_samples_leaf', ylabel='Mean CV Test Score', title='min_samples_leaf vs. Score (best_min_samples_leaf = 7)')\n\nmax_depth_array = [5, 8, 10, 15, 20, 30, 40, 50, 70]\nmax_depth_cv_score = [-0.71808668, -0.60209726, -0.58727382, -0.58785334, -0.58764068, -0.58764415, -0.58764415, -0.58764415, -0.58764415]\naxes=fig.add_subplot(2, 3, 4)\naxes.plot(max_depth_array, max_depth_cv_score, marker='.')\naxes.set(xlabel='max_depth', ylabel='Mean CV Test Score', title='max_depth vs. Score (best_max_depth = 10)')\n\nmin_samples_split_array = [0.0001, 0.001, 0.002, 0.005, 0.01]\nmin_samples_split_cv_score = [-0.58727382, -0.58727382, -0.58796633, -0.59735637, -0.61832167]\naxes=fig.add_subplot(2, 3, 5)\naxes.plot(min_samples_split_array, min_samples_split_cv_score, marker='.')\naxes.set(xlabel='min_samples_split', ylabel='Mean CV Test Score', title='min_samples_split vs. Score (best_min_samples_split = 0.0001)')\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:10.843485Z","iopub.execute_input":"2022-05-31T00:30:10.84385Z","iopub.status.idle":"2022-05-31T00:30:11.671307Z","shell.execute_reply.started":"2022-05-31T00:30:10.843818Z","shell.execute_reply":"2022-05-31T00:30:11.670439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest Regression\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Best parameters obtained via GridSearchCV above\nbest_n_estimators, best_max_features = 500, 'auto'\nbest_min_samples_leaf, best_max_depth = 7, 10\nparam_summary = ['n_estimators: {}, max_features: {}, min_samples_leaf: {}, max_depth: {}'.format(best_n_estimators, best_max_features, best_min_samples_leaf, best_max_depth), \n                 'n_estimators: {}, max_features: {}, min_samples_leaf: {}, max_depth: {}'.format(best_n_estimators, best_max_features, best_min_samples_leaf, best_max_depth),'']\n\nrfa = RandomForestRegressor(n_estimators = best_n_estimators, max_features = best_max_features, \n                           min_samples_leaf = best_min_samples_leaf, max_depth = best_max_depth, random_state=42)\n\nrmsle_summary, y_predict_summary = model_fit(rfa, X2, Xtest2, y2, ytest2)\nypred_test['RF1'] = y_predict_summary[1]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:11.67261Z","iopub.execute_input":"2022-05-31T00:30:11.673194Z","iopub.status.idle":"2022-05-31T00:30:17.235799Z","shell.execute_reply.started":"2022-05-31T00:30:11.673157Z","shell.execute_reply":"2022-05-31T00:30:17.234848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle_val_summary, y_predict_val_summary = cross_val(rfa, X2, y2)\nypred_train['RF1'] = y_predict_val_summary[0]\n\nalgo_score.loc['Random Forest-Categorical+Single'] = rmsle_summary+rmsle_val_summary+param_summary\nalgo_score.loc[['Random Forest-Categorical+Single']]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:17.237289Z","iopub.execute_input":"2022-05-31T00:30:17.237821Z","iopub.status.idle":"2022-05-31T00:30:39.017322Z","shell.execute_reply.started":"2022-05-31T00:30:17.237776Z","shell.execute_reply":"2022-05-31T00:30:39.016118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"algo_score.loc['Random Forest-Categorical+Single', 'Training+Test Time (sec)'] = 5.48\ncv_time.append(19.9)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:39.01913Z","iopub.execute_input":"2022-05-31T00:30:39.020181Z","iopub.status.idle":"2022-05-31T00:30:39.026511Z","shell.execute_reply.started":"2022-05-31T00:30:39.020133Z","shell.execute_reply":"2022-05-31T00:30:39.025413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest Regression Plot: True vs. Predicted for one month \nt_from, t_to = '2012-08-01', '2012-08-30'\ny_test_predict =  pd.Series(y_predict_summary[1], index = ytest2.index) \nytest_w_predict, ytest_nw_predict = y_test_predict[Xtest2.workingday==1], y_test_predict[Xtest2.workingday==0]\nplot_true_vs_pred(ytest2_w, ytest2_nw, ytest_w_predict, ytest_nw_predict, 'Random Forest Regression', t_from, t_to)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:39.028004Z","iopub.execute_input":"2022-05-31T00:30:39.028706Z","iopub.status.idle":"2022-05-31T00:30:39.546517Z","shell.execute_reply.started":"2022-05-31T00:30:39.028672Z","shell.execute_reply":"2022-05-31T00:30:39.54503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the Feature Importance\nfig = plt.figure(figsize=(8, 6))\naxes = fig.add_subplot(1, 1, 1)\naxes.plot(rfa.feature_importances_, marker='.', markersize=15)\nplt.xticks(range(len(rfa.feature_importances_)), X2.columns)\naxes.set(ylabel='Feature Importance', title='Feature Importance for Random Forest Regression using Categorical Data')\naxes.set(xlim=[-1, len(X2.columns)], ylim=[0, 1])\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:39.548834Z","iopub.execute_input":"2022-05-31T00:30:39.549426Z","iopub.status.idle":"2022-05-31T00:30:39.847077Z","shell.execute_reply.started":"2022-05-31T00:30:39.549372Z","shell.execute_reply":"2022-05-31T00:30:39.845932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Head of the Traning data\nX_w.head(n=2)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:39.84913Z","iopub.execute_input":"2022-05-31T00:30:39.849637Z","iopub.status.idle":"2022-05-31T00:30:39.873658Z","shell.execute_reply.started":"2022-05-31T00:30:39.84959Z","shell.execute_reply":"2022-05-31T00:30:39.872828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Random Forest Regression Grid Search to obtain the best parameters. \n## Commented it out since it takes a lot of time to run. Using the best parameters obtained via the below search\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV\n\n# param_grid = {'n_estimators': [50, 100, 200, 500, 1000, 2000, 5000], 'max_features':['auto', sqrt', 'log2']}\n# rf_w = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=rmsle_cv)\n# rf_nw = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring=rmsle_cv)\n# rf_w.fit(X_w, logy_w)\n# rf_nw.fit(X_nw, logy_nw)\n\n# param_grid_w = {'n_estimators': [2000], 'max_features':['sqrt'], 'min_samples_leaf':[1, 3, 7, 10, 20, 50]}\n# param_grid_nw = {'n_estimators': [200], 'max_features':['log2'], 'min_samples_leaf':[1, 3, 7, 10, 20, 50]}\n# rf_w = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_w, cv=5, scoring=rmsle_cv)\n# rf_nw = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_nw, cv=5, scoring=rmsle_cv)\n# rf_w.fit(X_w, logy_w)\n# rf_nw.fit(X_nw, logy_nw)\n\n# param_grid_w = {'n_estimators': [2000], 'max_features':['sqrt'], 'min_samples_leaf':[1], 'max_depth':[5, 8, 10, 20, 30, 40]}\n# param_grid_nw = {'n_estimators': [200], 'max_features':['log2'], 'min_samples_leaf':[1], 'max_depth':[5, 8, 10, 20, 30, 40]}\n# rf_w = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_w, cv=5, scoring=rmsle_cv)\n# rf_nw = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_nw, cv=5, scoring=rmsle_cv)\n# rf_w.fit(X_w, logy_w)\n# rf_nw.fit(X_nw, logy_nw)\n\n# param_grid_w = {'n_estimators': [2000], 'max_features':['sqrt'], 'min_samples_leaf':[1], 'max_depth':[30], 'min_samples_split':[0.0001, 0.001, 0.002, 0.005, 0.01]}\n# param_grid_nw = {'n_estimators': [200], 'max_features':['log2'], 'min_samples_leaf':[1], 'max_depth':[30], 'min_samples_split':[0.0001, 0.001, 0.002, 0.005, 0.01]}\n# rf_w = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_w, cv=5, scoring=rmsle_cv)\n# rf_nw = GridSearchCV(RandomForestRegressor(random_state=42), param_grid_nw, cv=5, scoring=rmsle_cv)\n# rf_w.fit(X_w, logy_w)\n# rf_nw.fit(X_nw, logy_nw)\n\n# print('Best parameters for Random Forest Regression Model for Working days: {}'.format(rf_w.best_params_))\n# print('Best parameters for Random Forest Regression Model for Non Working days: {}'.format(rf_nw.best_params_))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:39.875036Z","iopub.execute_input":"2022-05-31T00:30:39.875478Z","iopub.status.idle":"2022-05-31T00:30:39.882718Z","shell.execute_reply.started":"2022-05-31T00:30:39.87544Z","shell.execute_reply":"2022-05-31T00:30:39.881863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# All the below results are obtained from the above GridSearchCV hyperparamter tuning\n\nfig=plt.figure(figsize=(21, 6))\n\nmin_samples_leaf_array = [1, 3, 7, 10, 20, 50]\nmin_samples_leaf_cv_score_nw = [-0.6014166 , -0.62586217, -0.6713266 , -0.69684692, -0.76302209, -1.02612827]\nmin_samples_leaf_cv_score_w = [-0.57692764, -0.58339873, -0.61078536, -0.62668656, -0.67648766, -0.806137]\naxes=fig.add_subplot(1, 3, 1)\naxes.plot(min_samples_leaf_array, min_samples_leaf_cv_score_nw, marker='.', label='Non-Working Day')\naxes.plot(min_samples_leaf_array, min_samples_leaf_cv_score_w, marker='.', label='Working Day')\naxes.set(xlabel='min_samples_leaf', ylabel='Mean CV Test Score', title='min_samples_leaf vs. Score: best (W, NW) = (1, 1)')\naxes.legend()\n\nmax_depth_array = [5, 8, 10, 20, 30, 40]\nmax_depth_cv_score_nw = [-0.92512009, -0.7837481 , -0.71864241, -0.61170644, -0.60025831, -0.6007901 ]\nmax_depth_cv_score_w = [-0.97058161, -0.78030942, -0.69859085, -0.57880264, -0.57681758, -0.57689858]\naxes=fig.add_subplot(1, 3, 2)\naxes.plot(max_depth_array, max_depth_cv_score_nw, marker='.', label='Non-Working Day')\naxes.plot(max_depth_array, max_depth_cv_score_w, marker='.', label='Working Day')\naxes.set(xlabel='max_depth', ylabel='Mean CV Test Score', title='max_depth vs. Score: best (W, NW) = (30, 30)')\naxes.legend()\n\nmin_samples_split_array = [0.0001, 0.001, 0.002, 0.005, 0.01]\nmin_samples_split_cv_score_nw = [-0.60025831, -0.6002647 , -0.59716144, -0.59562094, -0.60375905]\nmin_samples_split_cv_score_w = [-0.57681758, -0.57386935, -0.57549636, -0.57868933, -0.58734106]\naxes=fig.add_subplot(1, 3, 3)\naxes.plot(min_samples_split_array, min_samples_split_cv_score_nw, marker='.', label='Non-Working Day')\naxes.plot(min_samples_split_array, min_samples_split_cv_score_w, marker='.', label='Working Day')\naxes.set(xlabel='min_samples_split', ylabel='Mean CV Test Score', title='min_samples_split vs. Score: best (W, NW) = (0.0001, 0.005)')\naxes.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:39.884436Z","iopub.execute_input":"2022-05-31T00:30:39.885086Z","iopub.status.idle":"2022-05-31T00:30:40.482085Z","shell.execute_reply.started":"2022-05-31T00:30:39.885049Z","shell.execute_reply":"2022-05-31T00:30:40.480814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest Regression\n# Best parameters obtained via GridSearchCV above\nbest_n_estimators_w, best_max_features_w, best_min_samples_leaf_w, best_max_depth_w, best_min_samples_split_w = 2000, 'sqrt', 1, 30, 0.0001\nbest_n_estimators_nw, best_max_features_nw ,best_min_samples_leaf_nw, best_max_depth_nw, best_min_samples_split_nw = 200, 'log2', 1, 30, 0.005\nparam_summary = ['n_estimators: {}, max_features: {}, min_samples_leaf: {}, max_depth: {}, min_samples_split: {}'.format(best_n_estimators_w, best_max_features_w, best_min_samples_leaf_w, best_max_depth_w, best_min_samples_split_w), \n                 'n_estimators: {}, max_features: {}, min_samples_leaf: {}, max_depth: {}, min_samples_split: {}'.format(best_n_estimators_nw, best_max_features_nw, best_min_samples_leaf_nw, best_max_depth_nw, best_min_samples_split_nw),'']\n\nprint('Best parameters via GridSearchCV for Working Day:     '+param_summary[0])\nprint('Best parameters via GridSearchCV for Non Working Day: '+param_summary[1])\n\nrfb_w = RandomForestRegressor(n_estimators=best_n_estimators_w, max_features=best_max_features_w, min_samples_leaf=best_min_samples_leaf_w, \n                             max_depth=best_max_depth_w, min_samples_split=best_min_samples_split_w, random_state=42)\nrfb_nw = RandomForestRegressor(n_estimators=best_n_estimators_nw, max_features=best_max_features_nw, min_samples_leaf=best_min_samples_leaf_nw, \n                             max_depth=best_max_depth_nw, min_samples_split=best_min_samples_split_nw, random_state=42)\n\nrmsle_summary, y_predict_summary = model_fit(rfb_w, X_w, Xtest_w, y_w, ytest_w, rfb_nw, X_nw, Xtest_nw, y_nw, ytest_nw)\nypred_test.loc[Xtest.workingday==1,'RF2'], ypred_test.loc[Xtest.workingday==0,'RF2'] = y_predict_summary[1], y_predict_summary[3]","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:30:40.483675Z","iopub.execute_input":"2022-05-31T00:30:40.484169Z","iopub.status.idle":"2022-05-31T00:31:02.344201Z","shell.execute_reply.started":"2022-05-31T00:30:40.484121Z","shell.execute_reply":"2022-05-31T00:31:02.34312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rmsle_val_summary, y_predict_val_summary = cross_val(rfb_w, X_w, y_w, rfb_nw, X_nw, y_nw)\nypred_train.loc[X.workingday==1,'RF2'], ypred_train.loc[X.workingday==0,'RF2'] = y_predict_val_summary[0], y_predict_val_summary[1]\n\nalgo_score.loc['Random Forest-OneHotEncoding'] = rmsle_summary+rmsle_val_summary+param_summary\nalgo_score.loc[['Random Forest-OneHotEncoding']]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:31:02.345802Z","iopub.execute_input":"2022-05-31T00:31:02.346188Z","iopub.status.idle":"2022-05-31T00:32:17.47775Z","shell.execute_reply.started":"2022-05-31T00:31:02.346156Z","shell.execute_reply":"2022-05-31T00:32:17.476561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"algo_score.loc['Random Forest-OneHotEncoding', 'Training+Test Time (sec)'] = 22.4\ncv_time.append(80.3)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:32:17.479198Z","iopub.execute_input":"2022-05-31T00:32:17.47964Z","iopub.status.idle":"2022-05-31T00:32:17.485735Z","shell.execute_reply.started":"2022-05-31T00:32:17.479596Z","shell.execute_reply":"2022-05-31T00:32:17.484941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random Forest Regression Plot: True vs. Predicted for one month \nt_from, t_to = '2012-08-01', '2012-08-30'\nytest_w_predict, ytest_nw_predict = y_predict_summary[1], y_predict_summary[3]\nytest_w_predict = pd.Series(ytest_w_predict, index = ytest_w.index)\nytest_nw_predict = pd.Series(ytest_nw_predict, index = ytest_nw.index)\n\nplot_true_vs_pred(ytest_w, ytest_nw, ytest_w_predict, ytest_nw_predict, 'Random Forest Regression', t_from, t_to)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:32:17.486976Z","iopub.execute_input":"2022-05-31T00:32:17.488218Z","iopub.status.idle":"2022-05-31T00:32:18.272947Z","shell.execute_reply.started":"2022-05-31T00:32:17.488162Z","shell.execute_reply":"2022-05-31T00:32:18.271783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting the Feature Importance\nfig = plt.figure(figsize=(18, 6))\naxes = fig.add_subplot(1, 1, 1)\naxes.plot(rfb_nw.feature_importances_, label='Non Working Day', marker='.', markersize=20)\naxes.plot(rfb_w.feature_importances_, label='Working Day', marker='.', markersize=20)\nplt.xticks(range(len(rfb_w.feature_importances_)), X_w.columns, rotation=90)\naxes.axvline(2-0.5, c='k', ls='--')\naxes.axvline(4-0.5,  c='k', ls='--')\naxes.axvline(15-0.5,  c='k', ls='--')\naxes.set(ylabel='Feature Importance', title='Feature Importance for Random Forest Regression using OneHotEncoder')\naxes.set(xlim=[-1, len(X_w.columns)], ylim=[0, 0.2])\naxes.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:32:18.274477Z","iopub.execute_input":"2022-05-31T00:32:18.274917Z","iopub.status.idle":"2022-05-31T00:32:19.579234Z","shell.execute_reply.started":"2022-05-31T00:32:18.274871Z","shell.execute_reply":"2022-05-31T00:32:19.578339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(10, 6))\naxes=fig.add_subplot(1, 1, 1)\nbar_width = 0.3\nidx = np.array(range(algo_score.shape[0]))\nlabels = algo_score.index\nplt.bar(data=algo_score, height='Train RMSLE (Average)', x=idx, color='#016d9c', width=bar_width, label='Training Data')\nplt.bar(data=algo_score, height='Test RMSLE (Average)', x=idx+bar_width, color='#ff6100', width=bar_width, label='Test Data')\nplt.xticks(idx, labels, rotation=90)\nplt.xlabel('Modelling Algorithms')\nplt.ylabel('RMSLE')\nplt.title('Average RMSLE for different Modelling Algorithms')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:32:19.580531Z","iopub.execute_input":"2022-05-31T00:32:19.581474Z","iopub.status.idle":"2022-05-31T00:32:19.820108Z","shell.execute_reply.started":"2022-05-31T00:32:19.581434Z","shell.execute_reply":"2022-05-31T00:32:19.819241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detailed split of RMSLE\nalgo_score","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:32:19.821702Z","iopub.execute_input":"2022-05-31T00:32:19.822223Z","iopub.status.idle":"2022-05-31T00:32:19.84423Z","shell.execute_reply.started":"2022-05-31T00:32:19.822174Z","shell.execute_reply":"2022-05-31T00:32:19.843069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig=plt.figure(figsize=(10, 6))\naxes=fig.add_subplot(1, 1, 1)\nbar_width = 0.6\nidx = np.array(range(algo_score.shape[0]))\nlabels = algo_score.index\nplt.bar(data=algo_score, height='Training+Test Time (sec)', x=idx, width=bar_width)\nplt.xticks(idx, labels, rotation=90)\nplt.xlabel('Modelling Algorithms')\nplt.ylabel('Training+Test Time (sec)')\nplt.title('(Training Time for 8015 observations + Test Time for 2856 observations) for different Models in seconds')\n#axes.set_yscale('log')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:32:19.845935Z","iopub.execute_input":"2022-05-31T00:32:19.846581Z","iopub.status.idle":"2022-05-31T00:32:20.054315Z","shell.execute_reply.started":"2022-05-31T00:32:19.84654Z","shell.execute_reply":"2022-05-31T00:32:20.053285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Xtrain = mydata_without_outliers.drop('count', axis=1)\nytrain = mydata_without_outliers['count']\nlogytrain = np.log1p(ytrain)\n\n# Best parameters obtained via GridSearchCV above\nbest_n_estimators, best_max_features = 500, 'auto'\nbest_min_samples_leaf, best_max_depth = 7, 10\n\nrf_main = RandomForestRegressor(n_estimators = best_n_estimators, max_features = best_max_features, \n                                min_samples_leaf = best_min_samples_leaf, max_depth = best_max_depth, random_state=42)\nrf_main.fit(Xtrain, logytrain)\nlogytest_predict = rf_main.predict(testdata)\nytest_predict = np.expm1(logytest_predict)\n\nsubmission = pd.DataFrame({'datetime':testdata.index, 'count':ytest_predict})\nsubmission.to_csv('./bikeSharing_submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:33:42.013484Z","iopub.execute_input":"2022-05-31T00:33:42.013916Z","iopub.status.idle":"2022-05-31T00:33:48.969101Z","shell.execute_reply.started":"2022-05-31T00:33:42.013883Z","shell.execute_reply":"2022-05-31T00:33:48.968099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"algo = 'Random Forest Regression'\nt_from, t_to = '2012-12-01', '2012-12-31'\nytest_predict = pd.Series(ytest_predict, index = testdata.index)\nfig = plt.figure(figsize=(18, 16))\n# Working day plot\naxes = fig.add_subplot(2, 1, 1)\naxes.plot(ytest_predict[t_from:t_to], label='Predicted', marker='.', markersize=15)\naxes.set(xlabel='Time', ylabel='Count', title='{0} Model: Count between time {1} and {2}'.format(algo, t_from, t_to))\naxes.legend()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-31T00:33:53.970936Z","iopub.execute_input":"2022-05-31T00:33:53.972269Z","iopub.status.idle":"2022-05-31T00:33:54.205866Z","shell.execute_reply.started":"2022-05-31T00:33:53.972214Z","shell.execute_reply":"2022-05-31T00:33:54.204661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}