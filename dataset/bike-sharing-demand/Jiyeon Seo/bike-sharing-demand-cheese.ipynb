{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 데이터 가져오기 \n- bike shring demand : ****https://www.kaggle.com/c/bike-sharing-demand "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nimport warnings\nwarnings.simplefilter(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(r'../input/bike-sharing-demand/train.csv')\ntest=pd.read_csv(r'../input/bike-sharing-demand/test.csv')\ndf=train.copy()\ntest_df=test.copy()\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"null 인 컬럼은 없고, "},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"null 인 컬럼은 없고, \ntrain과 비교했을 때, 'casual','registered', 'count'가 없다.  "},{"metadata":{},"cell_type":"markdown","source":"# 데이터 전처리"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 날짜 데이터 처리 \ndf['datetime'] = pd.to_datetime(df['datetime'])\ntest_df['datetime'] = pd.to_datetime(test_df['datetime'])\n\ndf['year'] = df['datetime'].apply(lambda x: x.year)\ndf['month'] = df['datetime'].apply(lambda x: x.month)\ndf['day'] = df['datetime'].apply(lambda x: x.day)\ndf['hour'] = df['datetime'].apply(lambda x: x.hour)\n\ntest_df['year'] = test_df['datetime'].apply(lambda x: x.year)\ntest_df['month'] = test_df['datetime'].apply(lambda x: x.month)\ntest_df['day'] = test_df['datetime'].apply(lambda x: x.day)\ntest_df['hour'] = test_df['datetime'].apply(lambda x: x.hour)\n\ndf.drop(['datetime', 'casual', 'registered'], axis=1, inplace=True)\ntest_df.drop(['datetime'], axis=1, inplace=True)\ndf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 판다스의 get_dummies()를 이용해 이러한 year 칼럼을 비롯해 month, day, hour, holiday, workingday, season, weather 칼럼도 모두 원-핫 인코딩한 후에 다시 예측 성능을 확인해 보겠습니다.\ndf = pd.get_dummies(df, columns=['year', 'month', 'day', 'hour', 'holiday', 'workingday', 'season', 'weather'])\ntest_df = pd.get_dummies(test_df, columns=['year', 'month', 'day', 'hour', 'holiday', 'workingday', 'season', 'weather'])\n\ndf, test_df = df.align(test_df, join='left', axis=1)\ntest_df = test_df.drop(['count'], axis=1)\n\nprint(df.shape)\nprint(test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 성능 평가 함수 정의"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y, pred):\n    log_y = np.log1p(y)\n    log_pred = np.log1p(pred)\n    squared_error = (log_y - log_pred)**2\n    rmsle = np.sqrt(np.mean(squared_error))\n    return rmsle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"참고 : https://www.kaggle.com/dogdriip/bike-sharing-demand#%EB%AA%A8%EB%8D%B8-%EC%84%A0%EC%A0%95 "},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/janged/xgb-lgb \nfrom sklearn.model_selection import GridSearchCV\n\ndf_train_target = df['count']\ndf_train_features = df.drop('count',axis=1)\n\n\ndef print_best_params(model, params):\n    grid_model = GridSearchCV(\n        model, \n        param_grid = params,\n        cv=5,\n        scoring='neg_mean_squared_error')\n\n    grid_model.fit(df_train_features, df_train_target)\n    rmse = np.sqrt(-1*grid_model.best_score_)\n    print(\n        '{0} 5 CV 시 최적 평균 RMSE 값 {1}, 최적 alpha:{2}'.format(model.__class__.__name__, np.round(rmse, 4), grid_model.best_params_))\n    return grid_model.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['count'] = np.log1p(df['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 모델 테스트"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 선형 회귀 \nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, Ridge, Lasso\n\n\n# xgb_model = XGBRegressor(n_estimators=500)\n\nx_train,x_test,y_train,y_test=train_test_split(df.drop('count',axis=1),df['count'],test_size=0.3,random_state=42)\n\n# test_df.head()\n# xgb_model.fit(x1_train, y1_train)\n# xgb_pred = xgb_model.predict(x_test)\n\n# y_test_exp = np.expm1(y_test)\n# pred_exp = np.expm1(xgb_pred)\n# print('RMSLE:', rmsle(y_test_exp, pred_exp))\n\nlr_reg = LinearRegression()\nlr_reg.fit(x_train, y_train)\nlr_pred = lr_reg.predict(x_test)\n\n\ny_test_exp = np.expm1(y_test)\nlr_pred_exp = np.expm1(lr_pred)\nprint('LinearRegression RMSLE:', rmsle(y_test_exp, lr_pred_exp))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# RandomForest \nfrom sklearn.ensemble import RandomForestRegressor\n\nrf_model = RandomForestRegressor()\nrf_model.fit(x_train, y_train)\nrf_pred = rf_model.predict(x_test)\n\ny_test_exp = np.expm1(y_test)\nrf_pred_exp = np.expm1(rf_pred)\nprint('RandomForest RMSLE:', rmsle(y_test_exp, rf_pred_exp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# xgboost \nfrom xgboost import XGBRegressor\n\n# xgb_model = XGBRegressor() \n# xgb_model = XGBRegressor(n_estimators=500) # n_estimators : 반복하는 트리 갯수 (크면 성능 올라가지만 너무 크면 과적합)\nxgb_model = XGBRegressor(learning_rate=0.2) # learning_rate\n\nxgb_model.fit(x_train, y_train)\nxgb_pred = xgb_model.predict(x_test)\n\n\ny_test_exp = np.expm1(y_test)\nxgb_pred_exp = np.expm1(xgb_pred)\nprint('xgboost RMSLE:', rmsle(y_test_exp, xgb_pred_exp))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# LightGBM - https://www.youtube.com/watch?v=1dSfWpFnvP0 \n# - 학습과 예측 속도 빠름. 카테고리형 피쳐 자동 변환\n# 트리분할 : 리프 중심(Leaf-wise) 트리 분할 방식(비대칭적 규칙 트리)\n#  - 장점 : 예측 오류 손실 최소화 / 단점 : 오버 피팅에 약함 \nfrom lightgbm import LGBMRegressor\n\nlgb_params = {\n#     'objective':['regression'],\n#     'num_leave' : [1],\n    'learning_rate' : [0.05],\n    'n_estimators':[500],\n    'max_bin' : [80],\n#     'gpu_id':[0] ,         \n#     'tree_method':['gpu_hist'],\n#     'predictor':['gpu_predictor'],\n#     'refit':[True]\n}\n\nlgb_model = LGBMRegressor()\n\n\nlgb_model.fit(x_train, y_train)\nlgb_pred = lgb_model.predict(x_test)\ny_test_exp = np.expm1(y_test)\nlgb_pred_exp = np.expm1(lgb_pred)\nprint('LGBMRegressor RMSLE:', rmsle(y_test_exp,lgb_pred_exp))\n\nlgb_estimator = print_best_params(lgb_model, lgb_params)\n# lgb_best_param_pred = lgb_estimator.predict(x_test)\n# lgb_best_param_pred_exp = np.expm1(lgb_best_param_pred)\n# print('LGBMRegressor with best Param RMSLE:', rmsle(y_test_exp,lgb_best_param_pred_exp))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 제출"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = df.drop(['count'], axis=1)\ny_train = df['count']\nX_test = test_df\n\nX_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgb_model = LGBMRegressor()\nlgb_model.fit(X_train, y_train)\npred = lgb_model.predict(X_test)\npred_exp = np.expm1(pred)\n\nsubmission = pd.read_csv('../input/bike-sharing-demand/sampleSubmission.csv')\nsubmission.loc[:, 'count'] = pred_exp\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}