{"cells":[{"metadata":{},"cell_type":"markdown","source":"This notebook will be less about data exploration and more about data preparation and model building.\nThere are out there multiple notebooks which handle data exploration wonderfuly with excelent visuals.\nI will nevertheless present the general findings and some personal ideas regarding the data."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport datetime\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn import preprocessing","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Read & append train and test"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\ntest = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')\ndata = train.append(test, sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Extract data features from datetime"},{"metadata":{"trusted":true},"cell_type":"code","source":"data['datetime'] = data['datetime'].astype('datetime64[ns]')\ndata['Day'] = pd.DatetimeIndex(data['datetime']).day\ndata['Month'] = pd.DatetimeIndex(data['datetime']).month\ndata['Year'] = pd.DatetimeIndex(data['datetime']).year\ndata['Hour'] = pd.DatetimeIndex(data['datetime']).hour\ndata['weekday'] = pd.DatetimeIndex(data['datetime']).weekday","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now I will ged rid of some unuseful colums:\n- atemp - highly correlated with temp\n- registered, casual - not used as predicted variable, \"count\" will be used instead\n- season - as long as there is Month, season does not add any additional value. \n- Day - the train data has only Days from 1 to 19, the test data has days from 20 to 31. I believe the model cannot predict well on unseen data.\n\nLeaving some of the variables in the model will most certainly overfit the model, nevertheless it will bring a higher public score, as there is just one metric the models are evaluated with.\n\nThis could be the case of workingday, which I decided to keep, although it is mostly explained by weekday and holiday, as workingday 0 means Saturday&Sunday and holiday."},{"metadata":{"trusted":true},"cell_type":"code","source":"df=data.drop(['registered','casual','atemp','Day','season'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replace or not replace 0's in windspeed column?\nI prefer not to replace, as there might be a reasonable explanation in the temperature measurement that leads to 0's."},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"windspeed\"]==0].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No significant **correlation** between continuous variables."},{"metadata":{"trusted":true},"cell_type":"code","source":"%config InlineBackend.figure_format = 'retina'\ncorr1 = df[['temp','humidity','windspeed']].corr() \nmask = np.zeros_like(corr1)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr1, vmax=0.8, mask=mask, square=True,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data preprocessing**\n\n- Year - categorize to integers 0 and 1 \n- Continuos variables normalisation - When  data is comprised of attributes with varying scales,machine learning algorithms benefit from rescaling the attributes to the same scale. The attributes are  rescaled into the range between 0 and 1, thus will be on the same level of magnitude and will have smaller standard deviations, which can suppress the effect of outliers.\nIn particular for random forests, this will not add much optimisation, as they do not benefit that much from scaling methods. \n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"lb = preprocessing.LabelBinarizer()\ndf.Year = lb.fit_transform(df.Year)\ncont=['temp','humidity','windspeed']\nfeat=df[cont]\nminmax_scale = preprocessing.MinMaxScaler().fit(feat.values)\ndf[cont] = minmax_scale.transform(feat.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"windspeed\"]==0].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Categorize variables and create dummy **variables for holiday, weather, workingday. This is because some machine learning algorithms will consider hierarchical values as measure of importance for cathegorical values."},{"metadata":{"trusted":true},"cell_type":"code","source":"categ=['holiday','weather','Month','Year','Hour','weekday','workingday']\nfor var in categ:\n    df[var] = df[var].astype(\"category\")\ndf = pd.get_dummies(data=df, columns=['holiday','weather','workingday','Year'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Outliers**\n\nNormalisation and transformation of the predicted variable will reduce the effect of these outliers, so I will not eliminate them. Also I prefer to keep some variability in the train data, as it might reflect better the variability of the test data."},{"metadata":{},"cell_type":"markdown","source":"**Splitting** the train and test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df[pd.notnull(df['count'])].sort_values(by=['datetime'])\ndf_test = df[~pd.notnull(df['count'])].sort_values(by=['datetime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train=df_train.drop(['datetime'],axis=1)\ntest=df_test.drop(['datetime','count'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Transformation** of the predicted variable\n\n* As the dependant variable is a highly skewed data, I will transform this data using log transformation.  Log transformation will cause less penalisation if there are significant differences in final variable values. This will also be important as the evaluation metric is RMSLE.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_train['count'].plot(kind=\"hist\", bins=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The large skew is evident."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['count'] = np.log1p(df_train['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Random Forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = df_train.drop(['count'],axis=1)\ny=df_train['count']\nX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, train_size=.80, random_state=1)\nrfr = RandomForestRegressor(n_estimators = 100)\nrfr.fit(X_train, y_train)\npred = rfr.predict(X_test)\nsns.scatterplot(x = y_test, y = pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Predictions look reasonably good. Let's calculate the RMSLE score."},{"metadata":{},"cell_type":"markdown","source":"**The RMSLE score **"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics\nprint('RMSLE:', np.sqrt(metrics.mean_squared_log_error(np.expm1(y_test), np.expm1(pred))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Gradient Boost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\ngbm = GradientBoostingRegressor(n_estimators=2000,alpha=0.01)\ngbm.fit(X_train,y_train)\npreds = gbm.predict(X_test)\nprint('RMSLE:', np.sqrt(metrics.mean_squared_log_error(np.expm1(y_test), np.expm1(preds))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Combine methods**"},{"metadata":{"trusted":true},"cell_type":"code","source":"algo_gbm = gbm.predict(X_test)\nalgo_rf = rfr.predict(X_test)\nalgo_mean =np.expm1(algo_gbm)*0.9 + np.expm1(algo_rf)*0.1\nprint('RMSLE:', np.sqrt(metrics.mean_squared_log_error(np.expm1(y_test), algo_mean)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Prepare and submit**"},{"metadata":{"trusted":true},"cell_type":"code","source":"algo_gbm_tst = gbm.predict(test)\nalgo_rf_tst = rfr.predict(test)\nalgo_mean_tst =np.expm1(algo_gbm_tst)*0.9 + np.expm1(algo_rf_tst)*0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'datetime':df_test['datetime'],'count':algo_mean_tst})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('Submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}