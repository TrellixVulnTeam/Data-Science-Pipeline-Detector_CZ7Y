{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# base lib\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\n\n#ignore warning messages \nimport warnings\nwarnings.filterwarnings('ignore') \n\n# set seaborn\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"data nan Count:\")\nprint('Nan in data:\\n',train.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# datetime - hourly date + timestamp  "},{"metadata":{"trusted":true},"cell_type":"code","source":"train['datetime_hour'] = pd.DatetimeIndex(train['datetime']).hour\ntrain['datetime_day'] = pd.DatetimeIndex(train['datetime']).day\ntrain['datetime_dayofweek'] = pd.DatetimeIndex(train['datetime']).dayofweek\ntrain['datetime_month'] = pd.DatetimeIndex(train['datetime']).month\ntrain['datetime_weak'] = pd.DatetimeIndex(train['datetime']).week\ntrain['datetime_year'] = pd.DatetimeIndex(train['datetime']).year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('datetime_weak').mean()['count'].plot.bar(figsize=(14,5), title = \"Weak - Count mean\")\nplt.show()\n\ntrain.groupby('datetime_hour').mean()['count'].plot.bar(figsize=(14,5), title = \"Hour - Count mean\")\nplt.axhline(train['count'].mean(),color = 'b',linestyle='--')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('datetime_year').mean()['count'].plot.bar(title = \"year - Count mean\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# season - 1 = spring, 2 = summer, 3 = fall, 4 = winter "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.groupby('season').size())\ntrain.groupby('season').mean()['count'].plot.bar(title = \"Season - Count mean\")\nplt.show()\n\n\n# in sprint and summer more use","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# temp - temperature in Celsius"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('atemp').mean()['count'].plot(c = 'r', title = \"temp - G , atemp - R\")\ntrain.groupby('temp').mean()['count'].plot(c = 'g')\nplt.show()\n\nplt.title('ATemp - Temp')\nsns.kdeplot(train['atemp'], bw=.2)\nsns.kdeplot(train['temp'], bw=2)\nplt.legend();\nplt.show()\n\ntemp_pca = PCA(n_components = 1)\ntrain[\"temp_pca\"] = temp_pca.fit_transform(train[['atemp','temp']])\n\nsns.kdeplot(train['temp_pca'], bw=2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# weather:\n1: Clear, Few clouds, Partly cloudy, Partly cloudy \n\n2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n\n3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n> \n4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog "},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.groupby('weather').count()['count'])\n# maybe we what to remove 4 ? or get more data from 4.\n\n# For exmple:\n# train.groupby('weather').mean()['count'].plot.bar()\n# plt.show()\n\nsns.distplot(train['weather']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# humidity - relative humidity"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.groupby('humidity').mean()['count'].plot()\nplt.axvline(17,color = 'r',linestyle='--')\nplt.show()\n\n# we can see that the count start in 17 and start to go down from there\n\nsns.distplot(train['humidity']);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* # windspeed -  wind speed"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.groupby('windspeed').count()['count'])\ntrain.groupby('windspeed').count()['count'].plot(title = \"windspeed count\")\nplt.show()\n\ntrain.groupby('windspeed').mean()['count'].plot(title = \"windspeed count mean\")\nplt.show()\n\n# maybe it better to remove 31.0009 and above (very small data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# casual, registered - number of non-registered user rentals initiated"},{"metadata":{},"cell_type":"markdown","source":"Count"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=4, ncols=2, figsize=(20,15))\nrow, colums = 2, 4\n\nplt.subplot(colums, row, 1)\nsns.lineplot(x=\"casual\", y=\"count\", data=train)\n\nplt.subplot(colums, row, 2)\nsns.lineplot(x=\"registered\", y=\"count\", data=train)\n\nplt.subplot(colums, row, 3)\nsns.distplot(train['casual'])\n\nplt.subplot(colums, row, 4)\nsns.distplot(train['registered'])\n\nplt.subplot(colums, row, 5)\nsns.boxplot(train['casual'])\n\nplt.subplot(colums, row, 6)\nsns.boxplot(train['registered'])\n\nplt.subplot(colums, row, 7)\ntrain.groupby('datetime_hour').mean()['casual'].plot.bar()\n\nplt.subplot(colums, row, 8)\ntrain.groupby('datetime_hour').mean()['registered'].plot.bar()\n\nplt.show()\n# we can't use this data for module - this is a memory leak (we dont have this data in the field.)\n# but maybe make 2 models , one for casual and one for registered","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"corr"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.corr(method='pearson').style.format(\"{:.2}\").background_gradient(cmap=plt.get_cmap('coolwarm'), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.pointplot(x=train[\"datetime_hour\"],\n              y=train[\"count\"],\n              hue=train[\"season\"], \n              data=train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ---------------------------------------------------------------"},{"metadata":{},"cell_type":"markdown","source":"# Perper Data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Perper data\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import FeatureUnion\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin , RegressorMixin\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_error # for RMSLE\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nimport xgboost as xgb\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, LSTM , Embedding\nfrom keras.optimizers import RMSprop\nfrom keras import backend as K\nimport keras\n\nimport tensorflow as tf\nimport lime\nimport lime.lime_tabular\nfrom sklearn.metrics import make_scorer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transformers:\n\n# get selected colums\nclass ItemSelector(BaseEstimator, TransformerMixin):\n    def __init__(self, key):\n        self.key = key\n\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, data_dict):\n        return data_dict[self.key]\n\n    \n# Change datetime to day, week, month and year\nclass DatetimeTransformer(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        return\n\n    def fit(self, x, y=None):\n        return self\n\n    def transform(self, data_dict):\n        timedata = data_dict['datetime']\n        \n        day = pd.DatetimeIndex(timedata).day\n        hour = pd.DatetimeIndex(timedata).hour\n        week = pd.DatetimeIndex(timedata).week\n        month = pd.DatetimeIndex(timedata).month\n        year = pd.DatetimeIndex(timedata).year\n        timestamp = pd.DatetimeIndex(timedata).astype(np.int64)\n\n        data_dict['datetime_hour'] = hour\n        data_dict['datetime_day'] = day\n        data_dict['datetime_weak'] = week\n        data_dict['datetime_month'] = month\n        data_dict['datetime_year'] = year\n        data_dict['datetime_timestape'] = timestamp\n        \n        return data_dict\n    \nclass DummyEncoder(BaseEstimator, TransformerMixin):\n\n    def __init__(self, n_values='auto', categories = 'auto'):\n        self.n_values = n_values\n        self.categories = categories\n\n    def transform(self, X):\n        ohe = OneHotEncoder(categories = self.categories,sparse=False, n_values=self.n_values)\n        return ohe.fit_transform(X)[:,:-1]\n\n    def fit(self, X, y=None, **fit_params):\n        return self\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['count','casual','registered'],axis = 1)\ny = train['count']\n\nprdict_feature = ['datetime','season','holiday', 'windspeed' ,\n                  'workingday','weather','temp' , 'atemp', 'humidity']\nX = X[prdict_feature]\n \nX_train_base, X_test_base, y_train, y_test = train_test_split(X, y, shuffle= False)\n_, _, y_train_registered, y_test_registered = train_test_split(X, train['registered'], shuffle= False)\n_, _, y_train_casual, y_test_casual = train_test_split(X, train['casual'], shuffle= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preper data\npreper_data_pipeline = Pipeline([('time_transformer',DatetimeTransformer())])\n\n# one hot\nlabel_pipeline = Pipeline([('hot_columns', ItemSelector(key = ['datetime_year'])),\n                             ('label_encoder', OneHotEncoder())])\n\nlabel_pipeline_weather = Pipeline([('weather_columns', ItemSelector(key = ['weather'])),\n                             ('label_encoder', DummyEncoder(categories = [[1,2,3,4]]))])\n\nlabel_pipeline_season = Pipeline([('season_columns', ItemSelector(key = ['season'])),\n                             ('label_encoder', DummyEncoder(categories = [[1,2,3,4]]))])\n\n# min max\nmin_max_pipeline = Pipeline([('min_max_columns', ItemSelector(key = ['datetime_hour','datetime_day','datetime_weak',\n                                                                     'datetime_month','datetime_timestape','humidity',\n                                                                    'workingday','holiday'])),\n                             ('minMaxScaler', MinMaxScaler())])\n\n# temp\ntemp_pipeline = Pipeline([(\"temp_columns\", ItemSelector(key = ['temp','atemp'])),\n                         (\"pca\", PCA(n_components = 1)),\n                         (\"min_max\", MinMaxScaler())])\n\n# windspeed\nwindspeed_pipline = Pipeline([('windspeed_columns',ItemSelector(key = ['windspeed'])),\n                             ('kbins',KBinsDiscretizer(n_bins=4, encode='ordinal', strategy='uniform')),\n                             (\"min_max\", MinMaxScaler())])\n\n\nfeature_union = FeatureUnion([('label', label_pipeline),\n                              ('label_pipeline_weather',label_pipeline_weather),\n                              ('label_pipeline_season',label_pipeline_season),\n                              ('windspeed',windspeed_pipline),\n                              ('min_max', min_max_pipeline),\n                              ('temp', temp_pipeline)])\n\n# full feature pipline\nfeature_pipeline = Pipeline([('preper_data',preper_data_pipeline),\n                            ('feature_union',feature_union)])\n\n\nfeature_pipeline.fit(X_train_base)\n\nX_train = feature_pipeline.transform(X_train_base)\nX_test = feature_pipeline.transform(X_test_base)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y_true,y_pred):\n    diff=np.log(y_pred+1)-np.log(y_true+1)\n    mean_error = np.square(diff).mean()\n    return np.sqrt(mean_error)\n\ndef rmsle_xgb(predictions, dmat):\n    labels = dmat.get_label()\n    diffs = np.log(predictions + 1) - np.log(labels + 1)\n    squared_diffs = np.square(diffs)\n    avg = np.mean(squared_diffs)\n    return ('RMSLE', np.sqrt(avg))\n\ndef rmsle_K(y, y0):\n    return K.sqrt(K.square(tf.log1p(y) - tf.log1p(y0)))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# registered"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams = {\n    'max_depth': 5, \n    'eta': .01,\n    'booster' : 'dart',\n    'subsample': 0.8, \n    'objective':'count:poisson',\n    'eval_metric':'rmse',\n    'silent': 1\n}\n\nmatrix_train = xgb.DMatrix(X_train,label=y_train_registered)\nmatrix_test = xgb.DMatrix(X_test,label=y_test_registered)\nreg_xgb_registered = xgb.train(params=params,\n                    dtrain=matrix_train,num_boost_round=5000, \n                    early_stopping_rounds=100,verbose_eval=100,\n                    feval = rmsle_xgb,\n                    evals=[(matrix_test,'test')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# result = xgb.cv(params=params, dtrain=matrix_train, num_boost_round=5000, early_stopping_rounds=50, feval = rmsle_xgb)\n# XGB_Cross_train_registered = result['train-RMSLE-mean'].mean()\n\nprdict_result = reg_xgb_registered.predict(xgb.DMatrix(X_train), ntree_limit = reg_xgb_registered.best_ntree_limit)\nXGB_Score_train_registered = rmsle(y_train_registered, prdict_result)\n\nprdict_result = reg_xgb_registered.predict(xgb.DMatrix(X_test), ntree_limit = reg_xgb_registered.best_ntree_limit)\nXGB_Score_test_registered = rmsle(y_test_registered, prdict_result)\n\n# print(\"xgb train cross:\",XGB_Cross_train_registered)\nprint(\"xgb train:\",XGB_Score_train_registered)\nprint(\"xgb test:\",XGB_Score_test_registered)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# casual"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nparams = {\n    'max_depth': 5, \n    'eta': .01,\n    'booster' : 'dart',\n    'subsample': 0.8, \n    'objective':'count:poisson',\n    'eval_metric':'rmse',\n    'silent': 1\n}\n\nmatrix_train = xgb.DMatrix(X_train,label=y_train_casual)\nmatrix_test = xgb.DMatrix(X_test,label=y_test_casual)\nreg_xgb_casual = xgb.train(params=params,\n                    dtrain=matrix_train,num_boost_round=5000, \n                    early_stopping_rounds=100,verbose_eval=100,\n                    feval = rmsle_xgb,\n                    evals=[(matrix_test,'test')])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# result = xgb.cv(params=params, dtrain=matrix_train, num_boost_round=5000, early_stopping_rounds=50, feval = rmsle_xgb)\n# XGB_Cross_train_casual = result['train-RMSLE-mean'].mean()\n\nprdict_result = reg_xgb_casual.predict(xgb.DMatrix(X_train), ntree_limit = reg_xgb_casual.best_ntree_limit)\nXGB_Score_train_casual = rmsle(y_train_casual, prdict_result)\n\nprdict_result = reg_xgb_casual.predict(xgb.DMatrix(X_test), ntree_limit = reg_xgb_casual.best_ntree_limit)\nXGB_Score_test_casual = rmsle(y_test_casual, prdict_result)\n\n# print(\"xgb train cross:\",XGB_Cross_train_casual)\nprint(\"xgb train:\",XGB_Score_train_casual)\nprint(\"xgb test:\",XGB_Score_test_casual)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build full model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class XGB_Combin_regressor(BaseEstimator, RegressorMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y):\n        return self\n\n    def predict(self, X):\n        registered_predict = reg_xgb_registered.predict(xgb.DMatrix(X), ntree_limit = reg_xgb_registered.best_ntree_limit)\n        registered_casual = reg_xgb_casual.predict(xgb.DMatrix(X), ntree_limit = reg_xgb_casual.best_ntree_limit)\n        return (registered_predict + registered_casual).round()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_reg = XGB_Combin_regressor()\ncount_reg.fit(X_train,y_train) \n\ntrain_score = rmsle(y_train, count_reg.predict(X_train).round())\ntest_score = rmsle(y_test, count_reg.predict(X_test).round())\n\nprint(\"train_score:\",train_score)\nprint(\"test_score:\",test_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# full estimator\n\ntest_transform = feature_pipeline.transform(test)\npredict = count_reg.predict(test_transform).round()\ndatetimecol = test[\"datetime\"]","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}