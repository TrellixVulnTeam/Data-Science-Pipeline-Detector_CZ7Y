{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import linear_model\nfrom sklearn import metrics\nimport statsmodels.api as sm\n%matplotlib inline\n\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor \n\n","execution_count":3,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"os.chdir('../input')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train=pd.read_csv('train.csv')\ntest=pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#check for NULL values in the data.\ntrain.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets extract the different date related features from the datetime object\ntrain['hour']=[t.hour for t in pd.DatetimeIndex(train.datetime)]\ntrain['day']=[t.dayofweek for t in pd.DatetimeIndex(train.datetime)]\ntrain['month']=[t.month for t in pd.DatetimeIndex(train.datetime)]\ntrain['year']=[t.year for t in pd.DatetimeIndex(train.datetime)]\ntrain['quarter']=[t.quarter for t in pd.DatetimeIndex(train.datetime)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets extract the different date related features from the datetime object\ntest['hour']=[t.hour for t in pd.DatetimeIndex(test.datetime)]\ntest['day']=[t.dayofweek for t in pd.DatetimeIndex(test.datetime)]\ntest['month']=[t.month for t in pd.DatetimeIndex(test.datetime)]\ntest['year']=[t.year for t in pd.DatetimeIndex(test.datetime)]\ntest['quarter']=[t.quarter for t in pd.DatetimeIndex(test.datetime)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#drop the field datetime\n#train.drop(['datetime'],inplace=True,axis=1)\n#test.drop(['datetime'],inplace=True,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# set some hypothesis based on our initial understanding.we will validate them during the exploratory data analysis","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#H1 : Registered users probably use the bikes more during the office hours compared to non office hours.\n#H2 : Registered users count on the weekends will be lower compared to the weekdays and holidays\n#H3 : Registered users count will increase as the time increases.\n#H4 : people tend to use less bikes during high humidity\n#H5 : demand will be more during the good climate\n#H6 : demand will be low during high temperature\n#H7 : low demand during the wind speed is high.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets confirm whether the hypothesis we have defined are correct by doing EDA.\n#every hypotheis is like a story.we are going to add story to our model in terms of the parameters.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#H1 : Registered users probably use the bikes more during the office hours compared to non office hours.\nf,axis=plt.subplots(1,2,figsize=(15,6))\nb1=sns.barplot(data=train,x='hour',y='registered',ax=axis[0])\nb2=sns.barplot(data=train,x='hour',y='casual',ax=axis[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#EDA support the H1.there are more number of registered users during the office hours.Casual users demand is high during the non\n#office hours.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#define RMSLE.This is the evaluation parameter to check the error.\ndef rmsle(prediction,actual):\n    log1=np.array([np.log(v+1) for v in prediction])\n    log2=np.array([np.log(v+1) for v in actual])\n    calc=(log1-log2)**2\n    return np.sqrt(np.mean(calc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#H2 : Registered users count on the weekends will be lower compared to the weekdays and holidays\n\n\nf,axis=plt.subplots(1,2,figsize=(10,4))\nb1=sns.barplot(data=train,x='day',y='registered',ax=axis[0])\nb2=sns.barplot(data=train,x='day',y='casual',ax=axis[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Hypothesis is true.There are less number of people in the weekends as registered users.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f,axis=plt.subplots(1,2,figsize=(15,6))\nb1=sns.barplot(data=train,x='workingday',y='registered',ax=axis[0])\nb2=sns.barplot(data=train,x='workingday',y='casual',ax=axis[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# EDA proves our hypothesis. On working days the demand is more for registered users.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#H3 : Registered users count will increase as the time increases.\n\n#lets create a field for identifying the quarter\ntrain['Quarter_number']=np.where((train['year']==2011) & (train['month']<=3),1,\n                  np.where((train['year']==2011) & (train['month']>3) & (train['month']<=6),2,\n                         np.where((train['year']==2011) & (train['month']>6) & (train['month']<=9),3,\n                                np.where((train['year']==2011) & (train['month']>9) & (train['month']<=12),4,\n                                       np.where((train['year']==2012) & (train['month']<3) ,5,\n                                              np.where((train['year']==2012) & (train['month']>3) & (train['month']<=6),6,\n                                                     np.where((train['year']==2012) & (train['month']>6) & (train['month']<=9),7,\n                                                            np.where((train['year']==2012) & (train['month']>9) & (train['month']<=12),8,0\n                                                                    ))))))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n\n#lets create a field for identifying the quarter in the test data set\ntest['Quarter_number']=np.where((test['year']==2011) & (test['month']<=3),1,\n                  np.where((test['year']==2011) & (test['month']>3) & (test['month']<=6),2,\n                         np.where((test['year']==2011) & (test['month']>6) & (test['month']<=9),3,\n                                np.where((test['year']==2011) & (test['month']>9) & (test['month']<=12),4,\n                                       np.where((test['year']==2012) & (test['month']<3) ,5,\n                                              np.where((test['year']==2012) & (test['month']>3) & (test['month']<=6),6,\n                                                     np.where((test['year']==2012) & (test['month']>6) & (test['month']<=9),7,\n                                                            np.where((test['year']==2012) & (test['month']>9) & (test['month']<=12),8,0\n                                                                    ))))))))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"f,axis=plt.subplots(1,2,figsize=(15,6))\nb1=sns.barplot(data=train,x='Quarter_number',y='registered',ax=axis[0])\nb2=sns.barplot(data=train,x='Quarter_number',y='casual',ax=axis[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#registered users count clearly showing an incresing pattern as the quarters progress. Casual users also there is an overall\n#increase in deamnd as the quarters progress.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#H4 : people tend to use less bikes during high humidity\n#H6 : demand will be low during high temperature and low temperature\n#H7 : low demand during the wind speed is high.\n#lets do an EDA to confirm our analysis\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig,(ax1,ax2,ax3,ax4)=plt.subplots(ncols=4)\nfig.set_size_inches(12,5)\nsns.regplot(x='temp',y='count',data=train,ax=ax1)\nsns.regplot(x='atemp',y='count',data=train,ax=ax2)\nsns.regplot(x='humidity',y='count',data=train,ax=ax3)\nsns.regplot(x='windspeed',y='count',data=train,ax=ax4)\nsns.distplot\n#regplot will plot data and a regression model fit.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets create buckets for humidity\ntrain['humiditybins']=np.floor(train['humidity'])//5\ntrain['tempbins']=np.floor(train['temp'])//5\ntrain['atempbins']=np.floor(train['atemp'])//5\ntrain['windspeedbins']=np.floor(train['windspeed'])//5\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets create buckets for humidity\ntest['humiditybins']=np.floor(test['humidity'])//5\ntest['tempbins']=np.floor(test['temp'])//5\ntest['atempbins']=np.floor(test['atemp'])//5\ntest['windspeedbins']=np.floor(test['windspeed'])//5\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets drop the original columns\ntrain.drop('humidity',axis=1,inplace=True)\ntest.drop('humidity',axis=1,inplace=True)\ntrain.drop('temp',axis=1,inplace=True)\ntest.drop('temp',axis=1,inplace=True)\ntrain.drop('atemp',axis=1,inplace=True)\ntest.drop('atemp',axis=1,inplace=True)\ntrain.drop('windspeed',axis=1,inplace=True)\ntest.drop('windspeed',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#H5 : Now check the hypothesis about the weather.Demand is high during good weather\n\nf,axis=plt.subplots(1,2,figsize=(10,4))\nb1=sns.barplot(data=train,x='weather',y='registered',ax=axis[0])\nb2=sns.barplot(data=train,x='weather',y='casual',ax=axis[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#registered users demand is high during weather 4 but the casual users demand is low for the same weather.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#now lets check the field season\nfig,(ax1,ax2,ax3)=plt.subplots(ncols=3)\nfig.set_size_inches(12,5)\nsns.barplot(data=train,x='season',y='casual',ax=ax1)\nsns.barplot(data=train,x='season',y='registered',ax=ax2)\nsns.barplot(data=train,x='season',y='count',ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Now lets do the feature engineering with our understanding from the EDA","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets create dummy variables for season,weather,hour,day,month,year,Quarter_number","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def dummies(train,test,columns):\n    for column in columns:\n        train[column]=train[column].apply(lambda x:str(x))\n        test[column]=test[column].apply(lambda x:str(x))\n        good_cols=[column+'_'+i for i in train[column].unique() if i in test[column].unique()]\n        train=pd.concat((train,pd.get_dummies(train[column],prefix=column)[good_cols]),axis=1)\n        test=pd.concat((test,pd.get_dummies(test[column],prefix=column)[good_cols]),axis=1)\n        del train[column]\n        del test[column]\n    return train,test","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data,test_data=dummies(train,test,columns=['season','weather','hour','day','month','year','Quarter_number','humiditybins','tempbins','atempbins','windspeedbins'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#drop the column quarter\ntrain_data.drop(['datetime','quarter'],axis=1,inplace=True)\ntest_data.drop(['datetime','quarter'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#drop the columns casual and registered as well.\ntrain_data.drop(['casual','registered'],axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Now we are done with the feature engineering. Lets move onto the model building.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets divide the train dataset into train and test dataset.\n\n#set Rseed\nRSEED=70","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\n\n#labels are the values we need to predict\nlabels=np.array(train_data['count'])\n\n#remove the labels from the features\nfeatures=train_data.drop('count',axis=1)\n\n#saving feature names for later use\nfeature_list=list(features.columns)\n\n#convert to numpy array\nfeatures=np.array(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Training and Testing Sets\n# Using Skicit-learn to split data into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n#split the data to training and testing set\ntrain_features,test_features,train_labels,test_labels=train_test_split(features,labels,test_size=0.25,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"print('Training features shape',train_features.shape)\nprint('Training labels shape',train_labels.shape)\nprint('Testing features shape',test_features.shape)\nprint('Testing labels shape',test_labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Train the model\n#import the model we are using\nfrom sklearn.ensemble import RandomForestRegressor\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Instantiate model with 1000 decision trees\nrf=RandomForestRegressor(n_estimators=1000,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#train the model on the training data\nrf.fit(train_features,train_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#Make predictions on the test set\n#use the predict method on the test data\npredictions=rf.predict(test_features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#calculate the RMSLE\nrmsle(predictions,test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets check the feature importances.\nimportances=list(rf.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#list of tuples with variable and importance\nfeature_importances=[(feature,round(importance,2)) for feature,\n                    importance in zip(feature_list,importances)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#sort the feature importances by most important first\nfeature_importances = sorted(feature_importances, key = lambda x: x[1], reverse = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Print out the feature and importances \n[print('Variable: {:20} Importance: {}'.format(*pair)) for pair in feature_importances];","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#lets make prediction on the test dataset.","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"features_test=np.array(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"predictions_test=rf.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test=pd.read_csv('test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"d={'datetime':test['datetime'],'count':predictions_test}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"ans=pd.DataFrame(d)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#ans.to_csv('answer.csv',index=False) # saving to a csv file for predictions on kaggle.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":1}