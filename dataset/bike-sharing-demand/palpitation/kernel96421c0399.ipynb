{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n        \nfrom scipy import stats        \n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-1 데이터 로딩"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-2 Train과 Test의 컬럼 정보 차이 확인(컬럼 갯수 차이, 형 차이) 후 조치"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two=train.drop(['casual', 'registered'], axis=1)\ntrain_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_two=test\ntest_two.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-3. 결측치 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-4. feature 타입 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_two.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two['datetime']=train_two['datetime'].astype('datetime64')\ntrain_two.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['datetime']=train['datetime'].astype('datetime64')\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_two['datetime']=test_two['datetime'].astype('datetime64')\ntest_two.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1-5 Indexing"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_two.set_index('datetime', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2. EDA, 2-1 Target 정규분포 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_two['count'], hist=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.probplot(train_two['count'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Shapiro 검정"},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.shapiro(train_two['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2-2 feature 정규분포 여부 확인"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two[['temp', 'atemp', 'humidity', 'windspeed']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_two['temp'], hist=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.probplot(train_two['temp'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_two['humidity'], hist=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.probplot(train_two['humidity'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_two['windspeed'], hist=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stats.probplot(train_two['windspeed'], plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2-3. Features 정규화"},{"metadata":{},"cell_type":"markdown","source":"(1) StandardScaler code"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()\nX_train_scale_stand=scaler.fit_transform(train_two[['temp', 'atemp', 'humidity', 'windspeed']])\nprint('스케일 조정 전 features Min value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].min(axis=0)))\nprint('스케일 조정 전 features Max value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].max(axis=0)))\nprint('스케일 조정 후 features Min value : \\n {}'.format(X_train_scale_stand.min(axis=0)))\nprint('스케일 조정 후 features Max value : \\n {}'.format(X_train_scale_stand.max(axis=0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(2) RobustScaler code"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nscaler=RobustScaler()\nX_train_scale_robust=scaler.fit_transform(train_two[['temp', 'atemp', 'humidity', 'windspeed']])\nprint('스케일 조정 전 features Min value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].min(axis=0)))\nprint('스케일 조정 전 features Max value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].max(axis=0)))\nprint('스케일 조정 후 featcures Min value : \\n {}'.format(X_train_scale_robust.min(axis=0)))\nprint('스케일 조정 후 features Max value : \\n {}'.format(X_train_scale_robust.max(axis=0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(3) MinMaxScaler code\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler=MinMaxScaler()\nX_train_scale_minmax=scaler.fit_transform(train_two[['temp', 'atemp', 'humidity', 'windspeed']])\nprint('스케일 조정 전 features Min value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].min(axis=0)))\nprint('스케일 조정 전 features Max value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].max(axis=0)))\nprint('스케일 조정 후 features Min value : \\n {}'.format(X_train_scale_minmax.min(axis=0)))\nprint('스케일 조정 후 features Max value : \\n {}'.format(X_train_scale_minmax.max(axis=0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(4) Normalizer code"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import Normalizer\nscaler=Normalizer()\nX_train_scale_normal=scaler.fit_transform(train_two[['temp', 'atemp', 'humidity', 'windspeed']])\nprint('스케일 조정 전 features Min value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].min(axis=0)))\nprint('스케일 조정 전 features Max value : \\n {}'.format(train_two[['temp', 'atemp', 'humidity', 'windspeed']].max(axis=0)))\nprint('스케일 조정 후 features Min value : \\n {}'.format(X_train_scale_normal.min(axis=0)))\nprint('스케일 조정 후 features Max value : \\n {}'.format(X_train_scale_normal.max(axis=0)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"정규화 여부 및 Type 별 예측 정확도 비교 분석 필요"},{"metadata":{"trusted":true},"cell_type":"code","source":"#from sklearn.svm import SVC\n#svc=SVC()\n#svc.fit(train_two[train_two.columns.difference(['count'])], train_two['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two[train_two.columns.difference(['season', 'weather', 'workingday'])].corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"2-4 Features 범주형 on-hot encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two.astype({'season' : 'category', 'holiday' : 'category', 'workingday' : 'category', 'weather' : 'category'}).dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two[['season_spring', 'season_summer', 'season_fall', 'season_winter']]=pd.get_dummies(train_two['season'], prefix=['season'])\ntrain_two.drop('season', axis=1, inplace=True)\ntrain_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two[['holiday_true', 'holiday_false']]=pd.get_dummies(train_two['holiday'], prefix=['holiday'])\ntrain_two.drop('holiday', axis=1, inplace=True)\ntrain_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two[['workingday_true', 'workingday_false']]=pd.get_dummies(train_two['workingday'], prefix=['workingday'])\ntrain_two.drop('workingday', axis=1, inplace=True)\ntrain_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two[['weather_1', 'weather_2', 'weather_3', 'weather_4']]=pd.get_dummies(train_two['weather'], prefix=['weather'])\ntrain_two.drop('weather', axis=1, inplace=True)\ntrain_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train_two['count'], hist=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two['year']=train['datetime'].dt.year\ntrain_two['month']=train['datetime'].dt.month\ntrain_two['weekday']=train['datetime'].dt.weekday\ntrain_two['hour']=train['datetime'].dt.hour\ntrain_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_two['year']=test['datetime'].dt.year\ntest_two['month']=test['datetime'].dt.month\ntest_two['weekday']=test['datetime'].dt.weekday\ntest_two['hour']=test['datetime'].dt.hour\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"categoryVariableList=['year', 'month', 'weekday', 'hour']\nfor var in categoryVariableList:\n    train_two[var]=train_two[var].astype('category')\ntrain_two.info()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two.drop(['datetime'], axis=1, inplace=True)\ntrain_two.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_two.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"test_two도 one hot encoding 들어가야 하나봐, 월요일부터 여기부터 하자"},{"metadata":{"trusted":true},"cell_type":"code","source":"categoryVariableList=['year', 'month', 'weekday', 'hour', 'season', 'weather', 'holiday', 'workingday']\nfor var in categoryVariableList:\n    test_two[var]=test_two[var].astype('category')\ntest_two.info()    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_two.dtypes.value_counts()\n#dataTypeDf = pd.DataFrame(train_two.dtypes.value_counts()).reset_index().rename(columns={\"index\":\"variableType\",0:\"count\"})\n#dataTypeDf\n#fig,ax = plt.subplots()\n#fig.set_size_inches(12,5)\n#sns.barplot(data=train_two,x=\"variableType\",y=\"count\",ax=ax)\n#ax.set(xlabel='variableTypeariable Type', ylabel='Count',title=\"Variables DataType Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#이거 왜 에러 해결 못하겟지? ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes=plt.subplots(nrows=4, ncols=3)\nfig.set_size_inches(12, 10)\nsns.boxplot(data=train_two, y='count', orient='v', ax=axes[0][0])\nsns.boxplot(data=train_two, y='count', x='season', orient='v', ax=axes[0][1])\nsns.boxplot(data=train_two, y='count', x='holiday', orient='v', ax=axes[0][2])\nsns.boxplot(data=train_two, y='count', x='holiday', orient='v', ax=axes[1][0])\nsns.boxplot(data=train_two, y='count', x='weather', orient='v', ax=axes[1][1])\nsns.boxplot(data=train_two, y='count', x='year', orient='v', ax=axes[1][2])\nsns.boxplot(data=train_two, y='count', x='month', orient='v', ax=axes[2][0])\nsns.boxplot(data=train_two, y='count', x='weekday', orient='v', ax=axes[2][1])\nsns.boxplot(data=train_two, y='count', x='hour', orient='v', ax=axes[2][2])\nsns.boxplot(data=train_two, y='count', x='workingday', orient='v', ax=axes[3][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two_nonOutliers=train_two[np.abs(train_two['count']-train_two['count'].mean())<=(3*train_two['count'].std())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Shape of The before Outliers : ', train_two.shape)\nprint('Shape of The after Outliers : ', train_two_nonOutliers.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_two.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrMatt=train_two[['temp', 'atemp', 'humidity', 'count']].corr()\nmask=np.array(corrMatt)\nnp.array(corrMatt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask[np.tril_indices_from(mask)]=False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax=plt.subplots()\nfig.set_size_inches(20, 10)\nsns.heatmap(corrMatt, mask=mask, vmax=.8, square=True, annot=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3)=plt.subplots(ncols=3)\nfig.set_size_inches(12, 5)\nsns.regplot(x='temp', y='count', data=train_two, ax=ax1)\nsns.regplot(x='atemp', y='count', data=train_two, ax=ax2)\nsns.regplot(x='humidity', y='count', data=train_two, ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes=plt.subplots(ncols=2, nrows=2)\nfig.set_size_inches(12, 10)\nsns.distplot(train_two['count'], ax=axes[0][0])\nstats.probplot(train_two['count'], dist='norm', fit=True, plot=axes[0][1])\nsns.distplot(np.log(train_two_nonOutliers[\"count\"]),ax=axes[1][0])\nstats.probplot(np.log1p(train_two_nonOutliers[\"count\"]), dist='norm', fit=True, plot=axes[1][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4)  = plt.subplots(nrows=4)\nfig.set_size_inches(12, 20)\nsortOrder = ['January','February','March','April','May','June','July','August','September','October','November','December']\nhueOrder = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']\n\nmonthAggregated=pd.DataFrame(train_two.groupby('month')['count'].mean()).reset_index()\nmonthSorted=monthAggregated.sort_values(by='count', ascending=False)\nsns.barplot(data=monthSorted, x='month', y='count', ax=ax1)\nax1.set(xlabel='Month', ylabel='Average Count', title='Average Count By Month')\n\nhourAggregated=pd.DataFrame(train_two.groupby(['hour', 'season'], sort=True)['count'].mean()).reset_index()\nsns.pointplot(x=hourAggregated['hour'], y=hourAggregated['count'], hue=hourAggregated['season'], data=hourAggregated, join=True, ax=ax2)\nax2.set(xlabel='Hour Of The Day', ylabel='Users Count', title='Average Users Count By Hour Of  The Day Across Season', label='big')\n\nhourAggregated=pd.DataFrame(train_two.groupby(['hour', 'weekday'], sort=True)['count'].mean()).reset_index()\nsns.pointplot(x=hourAggregated['hour'], y=hourAggregated['count'], hue=hourAggregated['weekday'], data=hourAggregated, join=True, ax=ax3)\nax3.set(xlabel='Hour Of The Day', ylabel='Users Count', title='Average Users Count By Hour Of The Day Across Weekdays', label='big')\n\nhourAggregated=pd.DataFrame(train_two.groupby(['hour', 'month'], sort=True)['count'].mean()).reset_index()\nsns.pointplot(x=hourAggregated['hour'], y=hourAggregated['count'], hue=hourAggregated['month'], data=hourAggregated, join=True, ax=ax4)\nax4.set(xlabel='Hour Of The Day', ylabel='Users Count', title='Average Users Count By Hour Of The Day Across Months', label='big')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression,Ridge,Lasso\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn import metrics\nimport warnings\npd.options.mode.chained_assignment = None\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n\n# Initialize logistic regression model\nlModel = LinearRegression()\n\nyLabels=train_two['count']\n\n# Train the model\nyLabelsLog = np.log1p(yLabels)\nlModel.fit(X = train_two.drop(['count'], axis=1), y = yLabelsLog)\n\n\n# Make predictions\npreds = lModel.predict(X= test_two)\npreds=pd.DataFrame(preds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LInear Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv('/kaggle/input/bike-sharing-demand/sampleSubmission.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['count']=preds\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('Linear Regression Mode.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrfModel = RandomForestRegressor(n_estimators=100)\nyLabelsLog = np.log1p(yLabels)\nrfModel.fit(train_two.drop(['count'], axis=1), yLabelsLog)\npreds = rfModel.predict(X= test_two)\npreds=pd.DataFrame(preds)\npreds.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ensemble Models - Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['count']=preds\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('Ensemble Models - Random Forest.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}