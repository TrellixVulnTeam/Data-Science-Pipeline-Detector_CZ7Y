{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.feature_extraction import DictVectorizer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\nimport matplotlib.pyplot as plt\nimport matplotlib\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport time\n\n# Any results you write to the current directory are saved as output.","execution_count":11,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/train.csv')\ntest_data = pd.read_csv('../input/test.csv')\n\nvisualization = train_data.copy()\nvisualization.datetime = pd.to_datetime(visualization.datetime)\nvisualization.head()","execution_count":12,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0fee28ad43ec984f51782aea2e6e8cba01d43b06"},"cell_type":"code","source":"# Visualization\n\ndate = visualization[['datetime', 'count']]\ndate.is_copy = False\ndate = date.groupby(pd.TimeGrouper(key='datetime',freq='M'))\ndate.sum().plot(figsize=(12,6))","execution_count":13,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"731e47ae6ccecb5f61b8374a318a68b66ae5a87a"},"cell_type":"code","source":"seasons = visualization[['datetime','season','count']].rename(columns={'datetime':'year'})\nseasons.is_copy = False\nseasons.year = seasons.year.dt.year\nfig,(ax) = plt.subplots(nrows=1,ncols=1,sharex=True,sharey=True,figsize=(11,10))\nseasons[seasons['year']==2012].groupby(seasons['season']).mean().plot(kind='bar',x='season',y='count',ax=ax,legend=False)\nax.set_title('Demand over seasons')\nax.set_xticklabels((\"Winter\", \"Spring\", \"Summer\", \"Fall\"))\nplt.tight_layout()","execution_count":14,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"863e80abc1d3c2086d990d92890ed485277a9fa7"},"cell_type":"code","source":"weekday = visualization[['datetime', 'count']]\nweekday.is_copy = False\nweekday['weekday'] = weekday.datetime.dt.dayofweek\nfig,(ax) = plt.subplots(nrows=1,ncols=1,sharex=True,sharey=True,figsize=(11,7))\nweekday.groupby(weekday.weekday).mean().plot(x='weekday',y='count',ax=ax,label='Total')\nax.set_xticklabels((\"Monday\", \"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"))\nplt.tight_layout()","execution_count":15,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdeb045c255444250e23cbb2e49225dc86de97a4"},"cell_type":"code","source":"hours = visualization[['datetime', 'count']]\nhours.is_copy = False\nhours['hour'] = hours.datetime.dt.hour\nfig,(ax) = plt.subplots(nrows=1,ncols=1,sharex=True,sharey=True,figsize=(11,7))\nhours.groupby(hours.hour).mean().plot(x='hour',y='count',ax=ax,label='Total')","execution_count":16,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c185fef6f539b486976865e08492d15a3edf07a3"},"cell_type":"code","source":"weather = visualization[['weather','count']]\nweather.is_copy = False\nfig,(ax) = plt.subplots(nrows=1,ncols=1,sharex=True,sharey=True,figsize=(11,7))\nweather.groupby(weather.weather).mean().plot(stacked=True,kind='bar', figsize=(11,5),legend=False, ax=ax)\nax.set_xticklabels((\"Clear\", \"Cloudy\", \"Light rain\", \"Heavy rain\"))","execution_count":17,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb19e7796fdd02582900c620183097b77759d810"},"cell_type":"code","source":"train_data.datetime = train_data.datetime.apply(pd.to_datetime)\ntrain_data['year'] = train_data.datetime.apply(lambda x: x.year)\ntrain_data['month'] = train_data.datetime.apply(lambda x: x.month)\ntrain_data['day'] = train_data.datetime.apply(lambda x: x.day)\ntrain_data['hour'] = train_data.datetime.apply(lambda x: x.hour)\ntrain_data.drop('datetime', axis=1, inplace=True)\ntrain_data.head()","execution_count":18,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"645e52a061f5b1b11ff5a0a85f29c4fe9b317baf"},"cell_type":"code","source":"test_data.datetime = test_data.datetime.apply(pd.to_datetime)\ntest_data['year'] = test_data.datetime.apply(lambda x: x.year)\ntest_data['month'] = test_data.datetime.apply(lambda x: x.month)\ntest_data['day'] = test_data.datetime.apply(lambda x: x.day)\ntest_data['hour'] = test_data.datetime.apply(lambda x: x.hour)\ntest_data.drop('datetime', axis=1, inplace=True)\ntest_data.head()","execution_count":20,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f772109cf005448bacb1aa17851b309f6d01fe97","collapsed":true},"cell_type":"code","source":"train_data.head()","execution_count":183,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7625922506d1f89c63bbf2bc5f83609fbe09b3ba","collapsed":true},"cell_type":"code","source":"# Grouping categorical features\ncategorical_columns = ['season','holiday','workingday','weather', \"month\", \"day\", \"hour\"]\ndf_categorical_columns = train_data[categorical_columns]\ncategorical_feat_dict = df_categorical_columns.T.to_dict().values()\n\n","execution_count":21,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b22c09a94076c553014985f55e3acc306731134","collapsed":true},"cell_type":"code","source":"# Grouping non categorical features\nnoncategorical_columns = ['temp','humidity','windspeed']\ndf_noncategorical_columns = train_data[noncategorical_columns]\nnoncategorical_feat_dict = df_noncategorical_columns.T.to_dict().values()","execution_count":22,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d3215063107b980da2193d98644006081c3deaf6","collapsed":true},"cell_type":"code","source":"# Vectorizing feature groups\nvectorizer = DictVectorizer(sparse = False)\ncategorical_vector = vectorizer.fit_transform(categorical_feat_dict)\n\nvectorizer = DictVectorizer(sparse = False)\nnoncategorical_vector = vectorizer.fit_transform(noncategorical_feat_dict)\n\n# Encoding feature vectors\nencoder = OneHotEncoder()\nencoder.fit(categorical_vector)\ncategorical_vector = encoder.transform(categorical_vector).toarray()","execution_count":23,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d9615c4f1f1a818472409c8d0096154e111ffa1d"},"cell_type":"code","source":"# Combining noncategorical and categorical data\nx = np.concatenate((categorical_vector, noncategorical_vector), axis=1)\nx","execution_count":24,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b49cc968a60277c42fb56b50b1296aec466efe60","collapsed":true},"cell_type":"code","source":"# Splitting test and training data\ny = train_data[\"count\"]\ny_registered = train_data[\"registered\"]\ny_casual = train_data[\"casual\"]\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=42)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"15940ca2a0e3a0c4d8989651caf91f5b5854d373"},"cell_type":"code","source":"len(x_train)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"018e288a17d7a3a08c79e72bb30615a5f3bfa4f2"},"cell_type":"code","source":"len(x_test)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"3aa2659bee9393cad9b5da6399d7aabd0e4ca05e"},"cell_type":"code","source":"# RMSLE for performance measuring\ndef rmsle(y, y_):\n    log1 = np.nan_to_num(np.array([np.log(p + 1) for p in y]))\n    log2 = np.nan_to_num(np.array([np.log(a + 1) for a in y_]))\n    calc = (log1 - log2) ** 2\n    return np.sqrt(np.mean(calc))","execution_count":28,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dbd9850f5b21f1999c0f19116616787c918ea21e"},"cell_type":"code","source":"start_time = time.time()\nregressor = RandomForestRegressor()\nparam_grid = {'n_estimators': np.arange(40, 50)}\ngrid_random_forest = GridSearchCV(regressor, param_grid, cv=5)\ngrid_random_forest.fit(X=x_train, y= np.log1p(y_train))\ny_pred = grid_random_forest.predict(X=x_test)\nelapsed_time = time.time() - start_time\nprint(\"Random Forrest\")\nprint(\"Time\", elapsed_time, \"seconds\")\nprint(\"RMSLE: \", rmsle(y_test,np.exp(y_pred)))","execution_count":29,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1fec768f9150c2ed0525ad2ee0853aeec809b130"},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\npca.fit(train_data)\npca_dataset = pca.transform(train_data)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a5fe843e0403d8eefb4d812932e301eea5e99ee7"},"cell_type":"code","source":"from sklearn import linear_model\n\nx_train, x_test, y_train, y_test = train_test_split(pca_dataset, y, test_size = 0.2, random_state=42)\nlinear_regressor = linear_model.LinearRegression().fit(x_train, np.log1p(y_train))\nstart_time = time.time()\nprediction = linear_regressor.predict(x_test)\nelapsed_time = time.time() - start_time\nprint(\"Linear Regression\")\nprint(\"Time\", elapsed_time, \"seconds\")\nprint(\"RMSLE: \", rmsle(y_test, np.exp(prediction)))","execution_count":38,"outputs":[]},{"metadata":{"_uuid":"b2a74cdb50fd3649c66d4c235d9babd56504f11c"},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"637095edf46581b1b61829f7286ca70988a66976"},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.5","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}