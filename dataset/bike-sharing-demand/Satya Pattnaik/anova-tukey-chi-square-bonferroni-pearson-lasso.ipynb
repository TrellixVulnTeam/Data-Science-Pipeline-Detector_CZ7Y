{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Data Analysis Tools-Assignment 1/2/3([Coursera](https://www.coursera.org/learn/data-analysis-tools))\n\n**This notebook has the relevant code for the Assignments of the Course - Data Analysis Tools**","metadata":{}},{"cell_type":"markdown","source":"## Topics Covered in this Notebook\n**ANOVA and Post Hoc Tukey HSD Test**<br>\n**Chi Square Test of Independence with Bonferroni Adjustment**<br>\n**Pearson Correlation**<br>\n**LASSO based Feature Selection using Lasso Path**","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport seaborn as sns\nsns.color_palette(\"colorblind\")\nimport matplotlib.pyplot as plt\nplt.rcParams['figure.dpi'] = 100\n\nimport gc\n\nfrom itertools import combinations\n\nimport scipy.stats\nimport statsmodels.formula.api as smf\nimport statsmodels.stats.multicomp as multi\nfrom statsmodels.stats.multitest import multipletests\n\nfrom sklearn import linear_model\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.datasets import fetch_openml\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LassoLarsCV","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-------Read Data-------\ndf = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv',parse_dates=['datetime'])\ndf = df.rename({'count':'count_of_rentals'},axis=1)\ndf['month'] = df['datetime'].dt.month\ndf['day_of_week'] = df['datetime'].dt.dayofweek\ndf['hour'] = df['datetime'].dt.hour\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------Continious to Continious----------\n\nsns.regplot(x=\"temp\", y=\"atemp\", fit_reg=True, data=df)\nplt.show()\n\n#Temp and Atemp are very significantly correlated","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['season'] = df['season'].map({  1:'spring', 2:'summer', 3:'fall', 4:'winter' })\ndf[\"season\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['weather'] = df['weather'].map({ \n    1:'Clear, Few clouds, Partly cloudy, Partly cloudy',\\\n    2:'Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist',\\\n    3:'Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\\\n    4:'Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog'\n}) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Let's consider the categorical explanatory variable 'Season' and the response variable The Count of rentals.**","metadata":{}},{"cell_type":"code","source":"#-----Boxplot-----\n#---Categorical to Quantitative---\nsns.boxplot(x='season', y='count_of_rentals', data=df)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=2,ncols=2)\n\nsns.boxplot(x='hour', y='temp', \\\n            data=df.loc[df[\"season\"]==\"spring\",:],ax=axs[0][0])\nsns.boxplot(x='hour', y='temp', \\\n            data=df.loc[df[\"season\"]==\"summer\",:],ax=axs[0][1])\nsns.boxplot(x='hour', y='temp', \\\n            data=df.loc[df[\"season\"]==\"fall\",:],ax=axs[1][0])\nsns.boxplot(x='hour', y='temp', \\\n            data=df.loc[df[\"season\"]==\"winter\",:],ax=axs[1][1])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(nrows=2,ncols=1)\n\nsns.boxplot(x='hour', y='count_of_rentals', \\\n            data=df.loc[df[\"holiday\"]==0,:],ax=axs[0])\nsns.boxplot(x='hour', y='count_of_rentals', \\\n            data=df.loc[df[\"holiday\"]==1,:],ax=axs[1])\n\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('---Means of Rental Counts by Each Season---')\ndf.groupby('season')['count_of_rentals'].agg(['mean','std'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------Crosstab------------------\n#---------Caegorical to Categorical------\npd.crosstab(df['month'], df['weather'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------Crosstab(Proportions)-----------\n#---------Caegorical to Categorical------\npd.crosstab(df['month'], df['weather']).apply(lambda r: r/r.sum(), axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['season'] = df['season'].astype('category')\nseason_map = dict(enumerate(df['season'].cat.categories))\ndf['season'] = df['season'].cat.codes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"season_map","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ANOVA\n\nAn ANOVA test is used to infer if there is any relationship/dependecy between a Categorical Explanatoy Variable and an Continious Response Variable.\n\nIt quantifies the ratio between  variance of the group means to the mean of the within group variances.","metadata":{}},{"cell_type":"code","source":"#------Fit an Ordinary Least Square------\nprint('----Fit an OLS Regression----')\nmodel = smf.ols(formula='count_of_rentals ~ C(season)', data=df).fit()\nprint (model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### ANOVA test Inference:<br>\nSince the p-value of the test is 6.16e-149(approximately 0), we fail to accept the Null Hypothesis and infer that the count of rentals on an avergae do differ for each season.","metadata":{}},{"cell_type":"markdown","source":"# Tukey Post Hoc Test\n\nA ANOVA test which is significant doesn't tell us which groups are different from each other.<br>\nWe need a POST hoc test to tell which pair of groups have a difference of means which is statistically significant.","metadata":{}},{"cell_type":"code","source":"print('----Tukey Test Post Hoc----')\nmc = multi.MultiComparison(df['count_of_rentals'], df['season'])\nres = mc.tukeyhsd()\nprint(res.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Tukey Test Inference:<br>\nThe count of rentals actually differ for each pairs of seasons on an average **(reject=true)**.","metadata":{}},{"cell_type":"markdown","source":"## Inference\nThe mean count of rentals does differ across seasons, like it is certainly higher in the summers/fall as compared to winters/spring.","metadata":{}},{"cell_type":"markdown","source":"# Chi Square Test of Significance\nA Chi square test helps determine if there is any significant relationship between two categorical variables.","metadata":{}},{"cell_type":"code","source":"print ('chi-square value, p value, expected counts',end=\":\\n\")\ncs1= scipy.stats.chi2_contingency(pd.crosstab(df['weather'], df['month']))\nprint (cs1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Chi Square Test Inference\nThe p-value of the test is 1.0505381541371918e-34(approximately 0), so we fail to accept the Null Hypothesis and infer that there is some relationship between Month of the Year and Weather.","metadata":{}},{"cell_type":"markdown","source":"# Bonferroni Adjustment for Chi Square(Post-Hoc)\nSince we have multiple pairs across the two Catgorical levels(Pairs of Month and Weather), hence we do have a chance of rejecting Null Hypothesis when it actually true, essentially commiting a **Type-1 Error**. What if there is one categorical pair for which the proportion difference is significant.  A way to mitigate this is to use Bonferroni **post Chi Square Adjustement**. We compute the Chi square for multiple categorical pairs and our inference is based on a :<br>**new significance level = $\\alpha$/number of comparisons**(where $\\alpha$ is most of the times **0.05**). \n\nInspired by [https://neuhofmo.github.io/chi-square-and-post-hoc-in-python/](http://)","metadata":{}},{"cell_type":"code","source":"#-------------------------Post Hoc Test Chi Square--------------------\n\n# Store p-values of each pair of month\np_vals_chi = []\npairs_of_months = list(combinations(df['month'].unique(),2))\n\n#For Each Pair of Months compute Chi Square Stats\nfor each_pair in pairs_of_months:\n    each_df = df[(df['month']==each_pair[0]) | (df['month']==each_pair[1])]\n    p_vals_chi.append(\\\n          scipy.stats.chi2_contingency(\n            pd.crosstab(each_df['weather'], each_df['month']))[1]\n         )\n    \ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Results of Bonferroni Adjustment\nbonferroni_results = pd.DataFrame(columns=['pair of months',\\\n                                           'original p value',\\\n                                           'corrected p value',\\\n                                           'Reject Null?'])\n\nbonferroni_results['pair of months'] = pairs_of_months\nbonferroni_results['original p value'] = p_vals_chi\n\n#Perform Bonferroni on the p-values and get the reject/fail to reject Null Hypothesis result.\nmulti_test_results_bonferroni = multipletests(p_vals_chi, method='bonferroni')\n\nbonferroni_results['corrected p value'] = multi_test_results_bonferroni[1]\nbonferroni_results['Reject Null?'] = multi_test_results_bonferroni[0]\n\nbonferroni_results.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"{bonferroni_results[bonferroni_results['Reject Null?']==True].shape[0]} pairs of months\\\n have a signifant relationship w.r.t Weather\",end=\".\\n\")\n\nprint(f\"{bonferroni_results[bonferroni_results['Reject Null?']==False].shape[0]} pairs of months\\\n do not have a signifant relationship w.r.t Weather\",end=\".\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bonferroni Adjusted Chi Square Test Inference\n\nFor nearly half of the pairs, we have the null hypotheis rejected and for a similar number of pairs we fail to reject the null hpothesis. Let us have some examples to illustrate this.<br> The month pair(1,2) i.e **January and February** dont vary much in terms of weather and the Null Hypothesis is not rejected.<br> However for months (1,5) - **January and May** the Null Hypothesis has been rejected, we can infer that they do vary in terms of weather(possibly **Light Snow/Rain** is significantly more during the month of May as compared to January). ","metadata":{}},{"cell_type":"markdown","source":"# Pearson Correlation\nPearson Correlation quantifies the association between two Quantitative variables.","metadata":{}},{"cell_type":"code","source":"print ('association between temp and atemp')\nprint (scipy.stats.pearsonr(df['temp'], df['atemp']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pearson Correlation Inference\nA Pearson statistics of 0.98 and a p-value of zero shows a very strong statistical association between temp and atemp","metadata":{"trusted":true}},{"cell_type":"markdown","source":"# Feature Selection-LASSO\n\nWe select the most important features(based on LASSO), the unimportant predictors have their coeffs shrunk to zero. ","metadata":{}},{"cell_type":"code","source":"df = df.drop('datetime',axis=1)\ndf.columns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['temp', 'atemp', 'humidity', 'windspeed','season', 'holiday','workingday', \\\n            'weather','month', 'day_of_week', 'hour']\n\n#--------------Standard Scale Numerical Features----------------\nnumeric_features = ['temp', 'atemp', 'humidity', 'windspeed']\nnumeric_transformer = StandardScaler()\ndf[numeric_features] = numeric_transformer.fit_transform(df[numeric_features])\n\n#--------------Dummify Categorical Features----------------------\ndf = pd.get_dummies(df,\\\n                   columns = ['season', 'holiday', 'workingday', \\\n            'weather','month', 'day_of_week', 'hour'])\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#-----------Train a Lasso Least Angle Regression, Cross Validated on 10 folds---------------\nX,y = df.loc[:,~df.columns.isin([\"casual\",\"registered\",\"count_of_rentals\"])], \\\n    df[\"count_of_rentals\"]\n\nmodel=LassoLarsCV(cv=10, precompute=False).fit(X,y)\nmodel_coefficients = pd.DataFrame.from_dict(dict(zip(X.columns, model.coef_)),orient=\"index\",\n                                           columns=[\"coefficient\"])\nmodel_coefficients.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------Select the Model Coeffs with Nonzero value-------------\n\nmodel_coefficients = model_coefficients.loc[model_coefficients['coefficient']!=0.0]\nmodel_coefficients.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------How the coefficients of the predicors change with changing alphas--------\n\nm_log_alphas = -np.log10(model.alphas_)\n\nlasso_path_df = pd.DataFrame(model.coef_path_.T,\\\n                             columns=X.columns,\\\n                            index=m_log_alphas)\nlasso_path_df = lasso_path_df[model_coefficients.index.tolist()]\nlasso_path_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(m_log_alphas,lasso_path_df.to_numpy())\nplt.legend(lasso_path_df.columns)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(m_log_alphas,lasso_path_df.to_numpy())\n#plt.legend(lasso_path_df.columns)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### LASSO Inference\n**\"temp\"**, **\"atemp\"**, **\"humidity\"** stand out when it comes to explaining the number of rentals booked(the Target). LASSO has shrunk the weight of some predictors(like **\"windspeed\"**) to zero which have little or zero effect on explaining the number of rentals!","metadata":{}},{"cell_type":"markdown","source":"# Test of Moderation","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv',parse_dates=['datetime'])\ndf['month'] = df['datetime'].dt.month\ndf['day_of_week'] = df['datetime'].dt.dayofweek\ndf['hour'] = df['datetime'].dt.hour\ndf = df.rename({'count':'count_of_rentals'},axis=1)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holidays,non_holidays=df.loc[df[\"holiday\"]==1,:],\\\n                      df.loc[df[\"holiday\"]==0,:]\n\nprint(\"Holidays Statistics\")\nprint(holidays.groupby(\"hour\").agg({\"count_of_rentals\":[\"mean\",\"median\"]}))\n\nprint(\"Non Holidays Statistics\")\nprint(non_holidays.groupby(\"hour\").agg({\"count_of_rentals\":[\"mean\",\"median\"]}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"holidays.groupby(\"hour\").agg({\"count_of_rentals\":[\"mean\",\"median\"]}).plot(kind=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"non_holidays.groupby(\"hour\").agg({\"count_of_rentals\":[\"mean\",\"median\"]}).plot(kind=\"bar\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#------Fit an Ordinary Least Square------\nprint('----Fit an OLS Regression----')\nmodel = smf.ols(formula='count_of_rentals ~ C(hour)', data=holidays).fit()\nprint (model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#------Fit an Ordinary Least Square------\nprint('----Fit an OLS Regression----')\nmodel = smf.ols(formula='count_of_rentals ~ C(hour)', data=non_holidays).fit()\nprint (model.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference-Test of Moderation\nAs we see Hour of the day plays a crucial role in determing the count of rentals. However when we compare holidays and non holidays, the time of **13:00 and 14:00 hours** we see more counts in case of holidays as compared to morning hours like **8**. Thus holiday works as a **moderator** between the relationship between Hour of Day and COunt of Rentals.","metadata":{}},{"cell_type":"markdown","source":"# To be Done(Work Under Progress):\n* Ridge/Elastic Net\n* Mututal Information\n\n### Feedbacks Appreciated","metadata":{}}]}