{"cells":[{"metadata":{},"cell_type":"markdown","source":"Centro de Informática - CIn/UFPE\nProfessor:Cleber Zanchettin\n\nPROJETO APRENDIZAGEM DE MÁQUINA\n\n \nAlunos Graduação:\nGiulio Carvalho Cavalcante - gcc\nPedro Kempter Brant - pkb"},{"metadata":{},"cell_type":"markdown","source":"Introdução\n\nO projeto consiste em dar uma resposta para o desafio \"Bike Sharing Demand\". Um problema de regressão onde se é dado o número de alugueis de bicicleta por hora dos primeiros 20 dias do mês e é pedido uma previsão do número de alugueis para os demais dias de cada mês. Após um pequeno tratamento dos dados e uma análise das variáveis, foi usado o XGBoost Regressor para fazer a previsão."},{"metadata":{"_cell_guid":"a10f197b-9d36-4d1a-b917-90a6d28efd69","_uuid":"aa268fffa8b719d737b174a38af46d1355a3fb53","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom scipy.special import boxcox, inv_boxcox\n\ntrain_df=pd.read_csv('../input/train.csv')\n\ntrain_df.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nhttps://stats.libretexts.org/Bookshelves/Introductory_Statistics/Book%3A_Introductory_Statistics_(Shafer_and_Zhang)/02%3A_Descriptive_Statistics/2.5%3A_The_Empirical_Rule_and_Chebyshev's_Theorem\n\nChebychev's rule \nEssa regra preve empiricamente que 99% dos dados estão contidos noo intervalo de até 3 desvios padrões da média. Isso pode ser usado para limpar alguns outliers [gráfico 1]. "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(train_df['count'])\nplt.show()\n\ncnt=train_df['count'].values\nq99=np.percentile(cnt,[99])\n\ntrain_df=train_df[train_df['count']<q99[0]]\nsns.distplot(train_df['count'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c01bd6e9-d9da-4950-87ee-6ab7e1dcab78","_uuid":"f199fa14356c59139ea5361fe66dc921974c0947"},"cell_type":"markdown","source":"https://medium.com/@ODSC/transforming-skewed-data-for-machine-learning-90e6cc364b0\nComo pode ser visto no [gráfico 2] acima, isso é um highly skewed data,ou seja, uma distribuição\"injusta\" que prejudica a classe dos valores menos representados.\n3 modelos foram testados para melhorar isso, sendo respectivamente: o boxcox transformation[explicado no link acima], a raiz quadrada, e o log.\nAs this is a highly skewed data, we will try to transform this data using either log, square-root or box-cox  transformation.\nVisualmente, o último(log), deixa a distribuição um pouco mais \"balanceada\", além de ajudar a diminuir o impacto da diferença nos valores mais altos."},{"metadata":{"_cell_guid":"edc2c634-4719-4360-bb87-8a0d6d96b745","_uuid":"546bebeb1ab5cfea4e8b7a953e4f1568e68332e6","trusted":true},"cell_type":"code","source":"from scipy.stats import boxcox\nsns.distplot(boxcox(train_df['count'])[0])\nplt.show()\n\nsns.distplot(train_df['count'].apply(lambda x:np.log(x)))\nplt.show()\n\nsns.distplot(train_df['count'].apply(lambda x:x**0.5))\nplt.show()\ntrain_df['count']=train_df['count'].apply(lambda x:np.log(x))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c8267692-d43f-411e-b00f-928d5f869dfa","_uuid":"d637d8d018049071f7b62a96439be3668e262c6e"},"cell_type":"markdown","source":"Separando o datetime em variáveis possivelmente mais significativas, como hora/dia/mes."},{"metadata":{"_cell_guid":"751c6fcd-8811-48c5-902b-e7c020aa4498","_uuid":"6a023b875cd5464845950f13f390cfe25fe7672e","trusted":true},"cell_type":"code","source":"\n\nfrom datetime import datetime\n\n#converting string dattime to datetime\n\n\ntrain_df['datetime']=train_df['datetime'].apply(lambda x:datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n\nnew_df=train_df\n\nnew_df['month']=new_df['datetime'].apply(lambda x:x.month)\nnew_df['hour']=new_df['datetime'].apply(lambda x:x.hour)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"14e60325-b201-4942-9cd4-70453ffa58ba","_uuid":"b2147f33f5250752f211fa698ac3c44f2485d8c8"},"cell_type":"markdown","source":"Pode se notar pelo heatmap o grau de correlação entre as variáveis. Partindo das seguintes inferências, foram determinadas quais variáveis descartar:\n- Temp(temperatura) e atemp(sensação térmica) são fortemente correlacionadas, atemp será removida para evitar multi-collinearity.\n- O número de holidays é muito pequeno para poder extrair alguma informação útil(workinday também será removido).\n- A divisão do count em casual ou registered não aparenta ter um comportamento significativamente diferente com a maioria das variáveis.\n- O windspeed possui muitos outliers, o que pode prejudicar o desempenho."},{"metadata":{"_cell_guid":"3dbbca58-5be7-442b-bfb0-042f53c525e7","_uuid":"1ec482e5f9b179fe0bcda7ac5e0e05a56e2e18de","trusted":true},"cell_type":"code","source":"new_df.cov()\nsns.heatmap(new_df.corr())\nplt.show()\n\nsns.boxplot('windspeed',data=train_df)\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"c4662813-40f7-4afb-8926-efd578d3ba9a","_uuid":"ff10dd17efe07da8c5b42f4574aad1d7e9bf812f","trusted":true},"cell_type":"code","source":"new_df.corr()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"69d4f5ed-fafc-4fa4-a5cf-0b43b9f7e48c","_uuid":"76de4d76f0e42730669088304a516cdb910c7bcd","trusted":true},"cell_type":"code","source":"'''\nhumid + temp + month + hour + season + weather\nhumid + temp + month + hour\nhumid + temp + month\nhumid + temp\n'''\n\nfinal_df=new_df.drop(['datetime', 'holiday', 'workingday', 'atemp', 'windspeed', 'casual', 'registered'], axis=1)\n\n#final_df=new_df.drop(['datetime', 'holiday', 'workingday', 'atemp', 'windspeed', 'casual', 'registered', 'season', 'weather'], axis=1)\n\n#final_df=new_df.drop(['datetime', 'holiday', 'workingday', 'atemp', 'windspeed', 'casual', 'registered', 'season', 'weather', 'hour'], axis=1)\n\n#final_df=new_df.drop(['datetime', 'holiday', 'workingday', 'atemp', 'windspeed', 'casual', 'registered', 'season', 'weather', 'hour', 'month'], axis=1)\n\n\nfinal_df.head()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"726c880d-0501-4571-9c13-5a256e40b1a0","_uuid":"44c286f11ad63864738cd68032e6ef5d69daa319"},"cell_type":"markdown","source":"Adding dummy varibles to categorical data"},{"metadata":{"_cell_guid":"6686d7b4-2409-4268-8311-da54db08ee32","_uuid":"4bcca1edc256feb52b843bca14c9b95abbb46a49","trusted":true},"cell_type":"code","source":"\nweather_df=pd.get_dummies(new_df['weather'],prefix='w',drop_first=True)\n#year_df=pd.get_dummies(new_df['year'],prefix='y',drop_first=True)\nmonth_df=pd.get_dummies(new_df['month'],prefix='m',drop_first=True)\nhour_df=pd.get_dummies(new_df['hour'],prefix='h',drop_first=True)\nseason_df=pd.get_dummies(new_df['season'],prefix='s',drop_first=True)\n                     \n\n\nfinal_df=final_df.join(weather_df)\n#final_df=final_df.join(year_df)\nfinal_df=final_df.join(month_df)                     \nfinal_df=final_df.join(hour_df)\nfinal_df=final_df.join(season_df)\n                     \nfinal_df.head()\n\n'''\n#weather_df=pd.get_dummies(new_df['weather'],prefix='w',drop_first=True)\n# year_df=pd.get_dummies(new_df['year'],prefix='y',drop_first=True)\nmonth_df=pd.get_dummies(new_df['month'],prefix='m',drop_first=True)\nhour_df=pd.get_dummies(new_df['hour'],prefix='h',drop_first=True)\n#season_df=pd.get_dummies(new_df['season'],prefix='s',drop_first=True)\n                     \n#final_df=final_df.join(weather_df)\n# final_df=final_df.join(year_df)\nfinal_df=final_df.join(month_df)                     \nfinal_df=final_df.join(hour_df)\n#final_df=final_df.join(season_df)\n'''\n\n'''\n#weather_df=pd.get_dummies(new_df['weather'],prefix='w',drop_first=True)\n# year_df=pd.get_dummies(new_df['year'],prefix='y',drop_first=True)\nmonth_df=pd.get_dummies(new_df['month'],prefix='m',drop_first=True)\n#hour_df=pd.get_dummies(new_df['hour'],prefix='h',drop_first=True)\n#season_df=pd.get_dummies(new_df['season'],prefix='s',drop_first=True)\n                     \n#final_df=final_df.join(weather_df)\n# final_df=final_df.join(year_df)\nfinal_df=final_df.join(month_df)                     \n#final_df=final_df.join(hour_df)\n#final_df=final_df.join(season_df)\n'''\n\n'''\n#weather_df=pd.get_dummies(new_df['weather'],prefix='w',drop_first=True)\n# year_df=pd.get_dummies(new_df['year'],prefix='y',drop_first=True)\n#month_df=pd.get_dummies(new_df['month'],prefix='m',drop_first=True)\n#hour_df=pd.get_dummies(new_df['hour'],prefix='h',drop_first=True)\n#season_df=pd.get_dummies(new_df['season'],prefix='s',drop_first=True)\n                     \n#final_df=final_df.join(weather_df)\n# final_df=final_df.join(year_df)\n#final_df=final_df.join(month_df)                     \n#final_df=final_df.join(hour_df)\n#final_df=final_df.join(season_df)\n'''\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"449cf6b2-ed41-43d9-a096-5644f42372b5","_uuid":"e473b1caa4540f1a80339e31af7137c7deb7c6c4","trusted":true},"cell_type":"code","source":"\nX=final_df.iloc[:,final_df.columns!='count'].values\nprint (X)\n\nY=final_df.iloc[:,4].values\n# Y=final_df.iloc[:,2].values\n\nprint (Y)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"a16d65b8-187e-4433-b004-085343f13d00","_uuid":"9451f2066e46ed46551347d21537b4c0b031ea15"},"cell_type":"markdown","source":"https://www.datacamp.com/community/tutorials/xgboost-in-python\n\nO algoritmo escolhido foi o XGBoost(Extreme Gradient Boosting) por ser paralelizável, ter uma ótima performance de tempo, é ser robusto.\n\nUsa o principio de ensemble, onde vários algoritmos mais fracos são combinados(decision trees) para gerar a saida final. Os que tiverem pior performance recebem um peso maior, ou seja, terão maior foco no treinamento nas demais iterações.\n\nParameters\nmax_depth (int) – Maximum tree depth for base learners.\n\nmin_child_weight (int) – Minimum sum of instance weight(hessian) needed in a child.\n\ngamma (float) – Minimum loss reduction required to make a further partition on a leaf node of the tree.\n\nsubsample (float) – Subsample ratio of the training instance.\n\ncolsample_bytree (float) – Subsample ratio of columns when constructing each tree.\n\n"},{"metadata":{"_cell_guid":"ac982002-02ab-4efe-8e5f-8d939737d143","_uuid":"1799377561f5d1a49c03c0902180c161d350f1d4","trusted":true},"cell_type":"code","source":"import xgboost as xg\nxgr=xg.XGBRegressor(max_depth=8,min_child_weight=6,gamma=0.4)\nxgr.fit(X,Y)\n\n'''import xgboost as xg\nfrom sklearn.model_selection import GridSearchCV\n\ndef grid_search():\n    \n    xgr=xg.XGBRegressor(max_depth=8,min_child_weight=6,gamma=0.4)\n    xgr.fit(X,Y)\n\n    #rf=RandomForestRegressor(n_estimators=100,random_state=0)\n    #rf.fit(X,Y)\n\n    #parameters=[{'max_depth':[8,9,10,11,12],'min_child_weight':[4,5,6,7,8]}]\n    #parameters=[{'gamma':[i/10.0 for i in range(0,5)]}]\n    parameters=[{'subsample':[i/10.0 for i in range(6,10)],\n 'colsample_bytree':[i/10.0 for i in range(6,10)]}]\n\n    grid_search= GridSearchCV(estimator=xgr, param_grid=parameters, cv=10,n_jobs=-1)\n\n    print (1)\n    grid_search=grid_search.fit(X,Y)\n    print (2)\n    best_accuracy=grid_search.best_score_\n    best_parameters=grid_search.best_params_\n    print (best_accuracy)\n    print (best_parameters)\n\n#if __name__ == '__main__':\n   #grid_search()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nfrom sklearn.ensemble import RandomForestRegressor\nrf=RandomForestRegressor(n_estimators=100,random_state=0)\nrf.fit(X,Y)\nimp_list=rf.feature_importances_\nfeats = {} # a dict to hold feature_name: feature_importance\nfor feature, importance in zip(final_df.columns, rf.feature_importances_):\n    feats[feature] = importance #add the name/value pair\n''' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_df.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"70a1d9d3-b097-411c-8823-0c4ae587c052","_uuid":"3bebcb9054f96dc9a04c01b5fbb5a87d5e61ee87","trusted":true},"cell_type":"code","source":"new_df=pd.read_csv('../input/test.csv')\ntest_df=pd.read_csv('../input/test.csv')\n\nnew_df['datetime']=new_df['datetime'].apply(lambda x:datetime.strptime(x,'%Y-%m-%d %H:%M:%S'))\n\nnew_df['month']=new_df['datetime'].apply(lambda x:x.month)\nnew_df['hour']=new_df['datetime'].apply(lambda x:x.hour)\n\nweather_df=pd.get_dummies(new_df['weather'],prefix='w',drop_first=True)\nmonth_df=pd.get_dummies(new_df['month'],prefix='m',drop_first=True)\nhour_df=pd.get_dummies(new_df['hour'],prefix='h',drop_first=True)\nseason_df=pd.get_dummies(new_df['season'],prefix='s',drop_first=True)\n\n\nnew_df=new_df.join(weather_df)\nnew_df=new_df.join(month_df)                     \nnew_df=new_df.join(hour_df)\nnew_df=new_df.join(season_df)\n\nnew_df=new_df.drop(['datetime', 'holiday', 'workingday', 'atemp', 'windspeed'], axis=1)\nnew_df.head()\n                     ","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"e148caf9-239a-4153-877a-ec9c7f3d5c4c","_uuid":"58e2255118b8bc091d370cf52d346263fd61ccfe","trusted":true},"cell_type":"code","source":"import xgboost as xg\nxgr=xg.XGBRegressor(max_depth=8,min_child_weight=6,gamma=0.4,colsample_bytree=0.6,subsample=0.6)\nxgr.fit(X,Y)\n\nX_test=new_df.iloc[:,:].values\nX_test.shape\n#print (new_df.columns)\n\ny_output=xgr.predict(X_test)\ny_output\n\ntest_df['count'] = pd.Series(np.exp(y_output))\ntest_df = test_df.drop(['humidity', 'temp', 'season', 'holiday', 'workingday', 'weather', 'atemp', 'windspeed'], axis=1)\ntest_df.to_csv('sub1.csv', index=False)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Score calculado a partir do erro quadrático médio\n\nResultados \n\nhumid + temp\nPublic Score\t1.20115\n\nhumid + temp + month\nPublic Score\t1.23954\n\nhumid + temp + month + hour\nPublic Score\t0.68263\n\nhumid + temp + month + hour + season + weather\nPublic Score\t0.65384\n\nNota-se uma melhora significativa quando a hora é levada em consideração. O resultado final ficou relativamente próximo dos primeiros colocados(~0.3), demonstrando a efetividade do XGBoost.\n"}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3","language":"python"},"language_info":{"pygments_lexer":"ipython3","name":"python","mimetype":"text/x-python","file_extension":".py","nbconvert_exporter":"python","codemirror_mode":{"version":3,"name":"ipython"},"version":"3.6.3"}},"nbformat":4,"nbformat_minor":1}