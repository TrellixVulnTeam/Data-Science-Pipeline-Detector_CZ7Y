{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfs = {}\nfor name in ['train','test']:\n    df = pd.read_csv('/kaggle/input/bike-sharing-demand/%s.csv' % name)\n    df['_data'] = name\n    dfs[name] = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine train and test data into one df\ndf = dfs['train'].append(dfs['test'])\n\n# lowercase column names\ndf.columns = map(str.lower, df.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# logarithmic transformation of dependent cols\n# (adding 1 first so that 0 values don't become -inf)\nfor col in ['casual', 'registered', 'count']:\n    df['%s_log' % col] = np.log(df[col] + 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# parse datetime colum & add new time related columns\ndt = pd.DatetimeIndex(df['datetime'])\ndf.set_index(dt, inplace=True)\n\ndf['date'] = dt.date\ndf['day'] = dt.day\ndf['month'] = dt.month\ndf['year'] = dt.year\ndf['hour'] = dt.hour\ndf['dow'] = dt.dayofweek\ndf['woy'] = dt.weekofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#def get_day(day_start):\n#    day_end = day_start + pd.offsets.DateOffset(hours=23)\n#    return pd.date_range(day_start, day_end, freq=\"H\")\n\n# tax day\n#df.loc[get_day(pd.datetime(2011, 4, 15)), \"workingday\"] = 1\n#df.loc[get_day(pd.datetime(2012, 4, 16)), \"workingday\"] = 1\n# thanksgiving friday\n#df.loc[get_day(pd.datetime(2011, 11, 25)), \"workingday\"] = 0\n#df.loc[get_day(pd.datetime(2012, 11, 23)), \"workingday\"] = 0\n# tax day\n#df.loc[get_day(pd.datetime(2011, 4, 15)), \"holiday\"] = 0\n#df.loc[get_day(pd.datetime(2012, 4, 16)), \"holiday\"] = 0\n\n# thanksgiving friday\n#df.loc[get_day(pd.datetime(2011, 11, 25)), \"holiday\"] = 1\n#df.loc[get_day(pd.datetime(2012, 11, 23)), \"holiday\"] = 1\n\n#storms\n#df.loc[get_day(pd.datetime(2012, 5, 21)), \"holiday\"] = 1\n#tornado\n#df.loc[get_day(pd.datetime(2012, 6, 1)), \"holiday\"] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['peak'] = df[['hour', 'workingday']].apply(lambda x: (0, 1)[(x['workingday'] == 1 and  ( x['hour'] == 8 or 17 <= x['hour'] <= 18 or 12 <= x['hour'] <= 13)) or (x['workingday'] == 0 and  10 <= x['hour'] <= 19)], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sandy\ndf['holiday'] = df[['month', 'day', 'holiday', 'year']].apply(lambda x: (x['holiday'], 1)[x['year'] == 2012 and x['month'] == 10 and (x['day'] in [30])], axis = 1)\n\n#christmas day and others\ndf['holiday'] = df[['month', 'day', 'holiday']].apply(lambda x: (x['holiday'], 1)[x['month'] == 12 and (x['day'] in [24, 26, 31])], axis = 1)\ndf['workingday'] = df[['month', 'day', 'workingday']].apply(lambda x: (x['workingday'], 0)[x['month'] == 12 and x['day'] in [24, 31]], axis = 1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['ideal'] = df[['temp', 'windspeed']].apply(lambda x: (0, 1)[x['temp'] > 27 and x['windspeed'] < 30], axis = 1)\ndf['sticky'] = df[['humidity', 'workingday']].apply(lambda x: (0, 1)[x['workingday'] == 1 and x['humidity'] >= 60], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #\n\ndef get_rmsle(y_pred, y_actual):\n    diff = np.log(y_pred + 1) - np.log(y_actual + 1)\n    mean_error = np.square(diff).mean()\n    return np.sqrt(mean_error)\n\n\ndef get_data():\n    data = df[df['_data'] == 'train'].copy()\n    return data\n\n\ndef custom_train_test_split(data, cutoff_day=15):\n    train = data[data['day'] <= cutoff_day]\n    test = data[data['day'] > cutoff_day]\n\n    return train, test\n\n\ndef prep_data(data, input_cols):\n    X = data[input_cols]\n    y_r = data['registered_log']\n    y_c = data['casual_log']\n\n    return X, y_r, y_c\n\n\ndef predict_on_validation_set(model, input_cols):\n    data = get_data()\n\n    train, test = custom_train_test_split(data)\n\n    X_train, y_train_r, y_train_c = prep_data(train, input_cols)\n    X_test, y_test_r, y_test_c = prep_data(test, input_cols)\n\n    model_r = model.fit(X_train, y_train_r)\n    y_pred_r = np.exp(model_r.predict(X_test)) - 1\n\n    model_c = model.fit(X_train, y_train_c)\n    y_pred_c = np.exp(model_c.predict(X_test)) - 1\n\n    y_pred_comb = np.round(y_pred_r + y_pred_c)\n    y_pred_comb[y_pred_comb < 0] = 0\n\n    y_test_comb = np.exp(y_test_r) + np.exp(y_test_c) - 2\n\n    score = get_rmsle(y_pred_comb, y_test_comb)\n    return (y_pred_comb, y_test_comb, score)\n\ndf_test = df[df['_data'] == 'test'].copy()\n\n# predict on test set & transform output back from log scale\ndef predict_on_test_set(model, x_cols):\n    # prepare training set\n    df_train = df[df['_data'] == 'train'].copy()\n    X_train = df_train[x_cols]\n    y_train_cas = df_train['casual_log']\n    y_train_reg = df_train['registered_log']\n\n    # prepare test set\n    X_test = df_test[x_cols]\n\n    casual_model = model.fit(X_train, y_train_cas)\n    y_pred_cas = casual_model.predict(X_test)\n    y_pred_cas = np.exp(y_pred_cas) - 1\n    registered_model = model.fit(X_train, y_train_reg)\n    y_pred_reg = registered_model.predict(X_test)\n    y_pred_reg = np.exp(y_pred_reg) - 1\n    # add casual & registered predictions together\n    return y_pred_cas + y_pred_reg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random forest model\nparams = {'n_estimators': 1000, 'max_depth': 15, 'random_state': 0, 'min_samples_split' : 5, 'n_jobs': -1}\nrf_model = RandomForestRegressor(**params)\nrf_cols = [\n    'weather', 'temp', 'atemp', 'windspeed',\n    'workingday', 'season', 'holiday', 'sticky',\n    'hour', 'dow', 'woy', 'peak',\n]\nrf_p, rf_t, rf_score = predict_on_validation_set(rf_model, rf_cols)\nprint(rf_score)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# GBM model\nparams = {'n_estimators': 150, 'max_depth': 5, 'random_state': 0, 'min_samples_leaf' : 10, 'learning_rate': 0.1, 'subsample': 0.7, 'loss': 'ls'}\ngbm_model = GradientBoostingRegressor(**params)\ngbm_cols = [\n    'weather', 'temp', 'atemp', 'humidity', 'windspeed',\n    'holiday', 'workingday', 'season',\n    'hour', 'dow', 'year', 'ideal'\n    ]\n\n\n(gbm_p, gbm_t, gbm_score) = predict_on_validation_set(gbm_model, gbm_cols)\nprint(gbm_score)\n\n# the blend gives a better score on the leaderboard, even though it does not on the validation set\ny_p = np.round(.2*rf_p + .8*gbm_p)\nprint(get_rmsle(y_p, rf_t))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predctions on test dataset\nrf_pred = predict_on_test_set(rf_model, rf_cols)\ngbm_pred = predict_on_test_set(gbm_model, gbm_cols)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# taking weighted average of output from two models\ny_pred = np.round(.20*rf_pred + .80*gbm_pred)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# output predictions for submission\ndf_test['count'] = y_pred\nfinal_df = df_test[['datetime', 'count']].copy()\nfinal_df.to_csv('output5.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}