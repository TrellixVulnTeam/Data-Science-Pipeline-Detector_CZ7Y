{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Problem Statement"},{"metadata":{},"cell_type":"markdown","source":"In this notebook we are trying to predict the bike rental count hourly. Below are the columns definitions present in the dataset \n\n1. instant: record index\n2. dteday : date\n3. season : season (1:springer, 2:summer, 3:fall, 4:winter)\n4. yr : year (0: 2011, 1:2012)\n5. mnth : month ( 1 to 12)\n6. hr : hour (0 to 23)\n7. holiday : weather day is holiday or not\n8. weekday : day of the week\n9. workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n10. weathersit : \n\t\t- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n\t\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n\t\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n\t\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n11. temp : Normalized temperature in Celsius. The values are divided to 41 (max)\n12. atemp: Normalized feeling temperature in Celsius. The values are divided to 50 (max)\n13. hum: Normalized humidity. The values are divided to 100 (max)\n14. windspeed: Normalized wind speed. The values are divided to 67 (max)\n15. casual: count of casual users\n16. registered: count of registered users\n17. cnt: count of total rental bikes including both casual and registered"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nimport calendar\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nplt.style.use('bmh')\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom math import sqrt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import r2_score\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn import model_selection\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sampleSubmission = pd.read_csv(\"../input/bike-sharing-demand/sampleSubmission.csv\")\ntest_df = pd.read_csv(\"../input/bike-sharing-demand/test.csv\")\ndf = pd.read_csv(\"../input/bike-sharing-demand/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"def addfeatures(data):\n    data[\"hour\"] = [t.hour for t in pd.DatetimeIndex(data.datetime)]\n    data[\"day\"] = [t.dayofweek for t in pd.DatetimeIndex(data.datetime)]\n    data[\"month\"] = [t.month for t in pd.DatetimeIndex(data.datetime)]\n    data['year'] = [t.year for t in pd.DatetimeIndex(data.datetime)]\n    data['date'] = pd.to_datetime(data['datetime']).apply(lambda x: x.date())\n    data[\"weekday\"] = pd.to_datetime(data['datetime']).dt.dayofweek\n    data['year'] = data['year'].map({2011:0, 2012:1})\n    data.drop('datetime',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"addfeatures(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"addfeatures(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"based on the info we can see there are no NaN values or null in the dataset. "},{"metadata":{},"cell_type":"markdown","source":"## Visualization \n\n\n1. Understand the effect of weekday, hour of day on the count. Check if there are some days and time when the count is clearly less or negligible compare to other days and hours?\n2. Verify the effect of season on the count. Which season tends to more rental?\n3. Relationship between count, season and working day. Is there any relatioship between rental counts season and working day?"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1) = plt.subplots(ncols=1, nrows=1, sharex=True, sharey=True, figsize = (14, 10))\ndf.groupby('date').mean()['count'].plot(ax =ax1, title='Bike Rent Count per Date')\nplt.xlabel('Date')\nplt.ylabel('Count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(ncols=1, nrows=2, sharex=True, sharey=True, figsize = (14, 10))\n# rent per day per hour \ndf.groupby(['weekday','hour']).mean()['count'].unstack('weekday').plot( ax=ax1, title='Bike Rent Count per day per hour' )\n\n# rent per season per hour\ndf.groupby(['season', 'hour']).mean()['count'].unstack('season').rename(columns={1:'springer', 2:'summer', 3:'fall', 4:'winter'}).plot( ax=ax2, title = 'Bike Rent Count per season per hour')\n# Set common labels\nfig.text(0.5, 0.04, 'Hour of the Day', ha='center', va='center', fontsize = 14)\nfig.text(0.06, 0.5, 'Rental Counts', ha='center', va='center', rotation='vertical', fontsize = 14);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly morning 6-9 AM and evening 4-7 PM there is spike in the rental counts in allmost all the weekdays mostly people are traveling to and from work or school at this time. On weekends afternoon are better in terms of rental as it's leisure time on weekend. "},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2, ax3, ax4) = plt.subplots(ncols=4, sharey=True, figsize = (14, 6))\nsns.regplot(x=\"atemp\", y=\"count\", data=df, ax=ax1)\nsns.regplot(x=\"temp\", y=\"count\", data=df, ax=ax2)\nsns.regplot(x=\"windspeed\", y=\"count\", data=df, ax=ax3)\nsns.regplot(x=\"humidity\", y=\"count\", data=df, ax=ax4);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"atemp, temp have positive relation with count and humidity is negative relationship with the count. One this is there are so many 0 in the windspeed and positive relation with count. Either we could drop the windspeed or impute these 0.  Also, there are 0 in hum lets check these values and try to impu"},{"metadata":{},"cell_type":"markdown","source":"## Imputing Missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Windspeed \nprint('Number of rows with missing Windspeed: ', df[df.windspeed ==0].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Replace nan windspeed with last non-zero digit.\ndf.windspeed = df.windspeed.replace(to_replace=0, method='ffill')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Humidity\nprint('Number of rows with missing Humidity: ', df[df.humidity ==0].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# all of 0 humidity in the data comes from the month of march 2011\ndf[df.humidity ==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"march_mean = df[(df.year == 1) & (df.month ==3)]['humidity'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# replace 0 hum with march mean 2012\ndf.humidity = df.humidity.map( lambda x : march_mean if x == 0 else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\n\n# plot count per working day season wise \nlabels=['springer', 'summer', 'fall', 'winter']\n\nax = sns.barplot(data=df, x='workingday',y='count', hue='season' )\n\nh, l = ax.get_legend_handles_labels()\nax.legend(h, labels, title=\"Season\", loc='upper left');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\n\nyear = [2011, 2012]\nax = sns.boxplot(x=\"workingday\", y=\"count\", hue=\"year\", data=df, palette=\"Set1\", );\nh, l = ax.get_legend_handles_labels()\nax.legend(h, year, title=\"Year\", loc='upper left');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"as seen in the boxplot the outliers lies on the working day and year 2012."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scale features \nscaler = MinMaxScaler()\ncol2scale = ['humidity', 'temp', 'windspeed']\nfor i in col2scale:\n    df[i] = scaler.fit_transform(df[i].values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"noncat = ['temp', 'atemp', 'humidity', 'windspeed', 'casual', 'registered', 'count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Correlation plot \ncor = df.corr()\nplt.figure(figsize=(14,10))\n\nmask = np.zeros_like(cor, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\nax = sns.heatmap(cor, mask = mask, annot=True, cmap=\"YlGnBu\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To avoid Multicollinearity, it is required to drop one of the `temp` or `atemp` temperature and actual temperature. Also Windspeed has a lot of missing value as seen earlier and correlation seems to be very less with count hence will drop the windspeed as well."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop atemp\ndf.drop(['atemp'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.drop(['atemp'], axis=1, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['checkh'] = df.casual + df.registered","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of rows where sum of causal and registered is equal to rental count:', sum(df['count'] == df.checkh))\nprint('Total Rows:', df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Casual and registered always add upto count, Will drop these two features for now."},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['casual', 'registered'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['count'].plot(kind = 'kde');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The log transformation can be used to make highly skewed distributions less skewed."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['cnt_log'] = np.log(df['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the skewness after log transformation \ndf.cnt_log.plot(kind = 'kde');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# remove outlier on count column \n#df = df[df.cnt.between(df.cnt.quantile(.05), df.cnt.quantile(.95))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2)\nfig.suptitle('Count vs Log Transformed Count')\nax1.set_xlabel('Count')\nax1.hist(df['count'])\n\nax2.set_xlabel('Log of Count')\nax2.hist(df.cnt_log);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Droping date and checkh variable (created to verify the resistered and casual) \ndf.drop(['date','checkh'], axis=1, inplace=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat = ['season', 'year', 'month', 'hour', 'holiday', 'weekday', 'workingday', 'weather']\nfor i in cat:\n    df[i] = df[i].astype(\"category\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfdummy = pd.get_dummies(df, columns=cat, drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model and Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = dfdummy[[i for i in list(dfdummy.columns) if i not in ['count', 'cnt_log']]].columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating Test and train dataset\nX = dfdummy.drop(['count', 'cnt_log'], axis=1).values\ny = dfdummy['count'].values\nyl = dfdummy.cnt_log.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metric = pd.DataFrame(columns = ['r2', 'rmse'])\nr2 = []\nrms = []\ndef split_train_test(x,y):\n    # get train test split\n    X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=seed)\n    # linear regression \n    lModel = LinearRegression()\n    print('\\nTraining Linear Reggresor on Train data....')\n    result = lModel.fit(X_train, y_train)\n    r2.append(round((result.score(X_test,y_test)),2))\n    rms.append(round((sqrt(mean_squared_error(y_test, result.predict(X_test)))),2))\n    print('Done!!!')\n    print('\\nTraining Random Forrest Reggresor on Train data....')\n    # Random forrest \n    regr = RandomForestRegressor(n_estimators=300)\n    regr.fit(X_train, y_train)\n    r2.append(round((regr.score(X_test, y_test)),2))\n    rms.append(round((sqrt(mean_squared_error(y_test, regr.predict(X_test)))),2))\n    print('Done!!!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 123\ntarget = [y, yl]\n\n\nfor i in target:\n    if i is y:\n        print('\\nTarget is Count')\n    else:\n        print('\\nTarget is Log of Count')\n    split_train_test(X,i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metric.r2 = r2\nmetric.rmse= rms\nmetric['Target-Model'] = ['LM_count', 'RF_Count', 'LM_Count_log', 'RF_Count_log']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.barplot(x = 'Target-Model', y = 'r2', data = metric)\nax=g\n#annotate axis = seaborn axis\nfor p in ax.patches:\n             ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n                 ha='center', va='center', fontsize=11, color='Blue', xytext=(0, 8),\n                 textcoords='offset points')\n_ = g.set_ylim(0,1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.barplot(x = 'Target-Model', y = 'rmse', data = metric)\nax=g\n#annotate axis = seaborn axis\nfor p in ax.patches:\n             ax.annotate(\"%.2f\" % p.get_height(), (p.get_x() + p.get_width() / 2., p.get_height()),\n                 ha='center', va='center', fontsize=11, color='Blue', xytext=(0, 8),\n                 textcoords='offset points')\n_ = g.set_ylim(0,109) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cross validation\n\nkfold = model_selection.KFold(n_splits=10, random_state=100)\nmodel_kfold = LinearRegression()\nresults_kfold = model_selection.cross_val_score(model_kfold, X, yl, cv=kfold, scoring = 'r2')\nprint(\"R2 score: \",round(results_kfold.mean(),2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\n\nkfold = model_selection.KFold(n_splits=5, random_state=100)\nmodel_kfold = RandomForestRegressor(n_estimators=50)\nresults_kfold = model_selection.cross_val_score(model_kfold, X, yl, cv=kfold, scoring = 'r2')\nprint(\"R2 score: \",round(results_kfold.mean(),2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, yl, test_size=0.3, random_state=123)\n# Random forrest \nregr = RandomForestRegressor(n_estimators=300)\nregr.fit(X_train, y_train)\nprint(\"Root Mean Squared Logarithmic Error: \",sqrt(mean_squared_log_error(y_test, regr.predict(X_test))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importances = regr.feature_importances_\nstd = np.std([tree.feature_importances_ for tree in regr.estimators_], axis=0)\nindices = np.argsort(importances)[::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the feature importances of the forest\nplt.figure(figsize=(25,5))\nplt.title(\"Feature importances\")\nplt.bar(range(X_test.shape[1]), importances[indices], yerr=std[indices], align=\"center\")\nplt.xticks(range(X_test.shape[1]), [features[i] for i in indices], rotation=90)\nplt.xlim([-1, X_test.shape[1]])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Key Findings\n\n1. Removing outliers from the count reduces the prediction accuracy.\n2. Count is left skewed and hence, log transformation of count when used as target gives better R2 and lesser error. \n3. Hour and temp as seen earlier is highly correlated to count.   "},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.scatterplot(x=regr.predict(X_test), y=(y_test-regr.predict(X_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visualize subset of Test count and predicted test coutn \nplt.figure(figsize=(16,5))\nplt.plot(regr.predict(X_test)[200:400],'r')\nplt.plot(y_test[200:400])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.7"}},"nbformat":4,"nbformat_minor":1}