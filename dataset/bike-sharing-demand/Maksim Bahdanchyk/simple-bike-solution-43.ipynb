{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Import modules","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Import Datasets","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\ntest = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')\n# We need timestamps from test to create submission file\ntime = test['datetime']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make datetime column date time format\ntrain['datetime'] = pd.to_datetime(train['datetime'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Extrac day of the week, hout and month\n\ntrain['day_of_week'] = train.datetime.dt.day_name()\ntrain['hour'] = train.datetime.dt.hour\ntrain['month'] = train.datetime.dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Since temp and atemp  have high correlation \n# It make sense to dervice a single feature\n# Let`s use average value between two\n\ntrain['temp'] = (train['temp']+train['atemp'])/2\ntrain = train.drop('atemp',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# here we choose columns that later on will be transformed \n# By OneHotEncoder\n# By OrdinalEncoder\n# Let`s also try to use bins\n# And scale numeric values\n\ncolumns_ohe = ['season','holiday','workingday','day_of_week','month']\ncolumns_bin = ['humidity','windspeed']\ncolumns_num = ['temp','humidity','windspeed']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Remove outliers ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let`s use log(1+x) of target values\n# Because there is postitive skewnees\ntrain['count']=np.log1p(train['count'])\n\ndef remove_outliers(df_in, col_name):\n    q1 = df_in[col_name].quantile(0.25)\n    q3 = df_in[col_name].quantile(0.75)\n    iqr = q3-q1 #Interquartile range\n    fence_low  = q1-1.5*iqr\n    fence_high = q3+1.5*iqr\n    df_out = df_in.loc[(df_in[col_name] > fence_low) & (df_in[col_name] < fence_high)]\n    print('Removed: ',(len(df_in)-len(df_out))/len(df_in)*100,' % of initial dataset')\n    return df_out\n\ntrain = remove_outliers(train,'count')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Modeling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler\nfrom sklearn.preprocessing import KBinsDiscretizer\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_transformer\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_error,mean_squared_log_error\n\n# Column tranformer is usefull function from sklearn library\n# It help to make tranformation of pandas dataframes and put in pipeline if necessary\n\ntrans = make_column_transformer(\n    (OrdinalEncoder(),['weather']),\n    (OneHotEncoder(),columns_ohe),\n    (RobustScaler(),columns_num),\n    (KBinsDiscretizer(n_bins = 4,encode='ordinal'), columns_bin),\n    remainder = 'passthrough'\n)\n\n\n# We use RandomForesrRegressor with already adjusted values by GridSearchCV\nrf_reg = RandomForestRegressor(n_estimators = 3000,\n                               max_depth = 40,\n                               random_state = 42)\n\n# We use GradientBoosting Regressor with already adjusted values by GridSearchCV\ngb_reg = GradientBoostingRegressor(n_estimators=1000, \n                                   min_samples_leaf=6, \n                                   random_state=42)\n\n\n# Create training and validation datasets\nX = train.drop(['count','datetime','casual','registered'],axis=1)\ny = train['count']\n\n# transform X values\nX = trans.fit_transform(X)\n\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n# Split set on traing and test\nX_train,X_val,y_train,y_val = train_test_split(X,y,\n                                               random_state=0,\n                                               test_size = 0.25,\n                                               shuffle=True)\n\n# Fit by two regressors\nrf_reg.fit(X_train,y_train)\n\ngb_reg.fit(X_train,y_train)\n\n\nprint('(RFR) RMSE: ',np.sqrt(mean_squared_error(y_val,rf_reg.predict(X_val))))\nprint('(GBR) RMSE: ',np.sqrt(mean_squared_error(y_val,gb_reg.predict(X_val))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Blending","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# we can blend results from different regressors to improve the score\n# weight parameters are adjusted manualy\n# As you can see score has improved slightly\n\ndef blend_pred(X):\n    pred = 0.3*rf_reg.predict(X) + 0.7*gb_reg.predict(X)\n    return pred\n\nprint('Blended model RMSE: ',np.sqrt(mean_squared_error(y_val,blend_pred(X_val))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prepare submision file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# We must prepare test file in the same way as train\n\ntest['datetime'] = pd.to_datetime(test['datetime'])\ntest['day_of_week'] = test.datetime.dt.day_name()\ntest['hour'] = test.datetime.dt.hour\ntest['month'] = test.datetime.dt.month\ntest['temp'] = (test['temp']+test['atemp'])/2\ntest = test.drop(['datetime','atemp'],axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# then we use the same transformer and predict values\nX_test = trans.transform(test)\n\n# dont forget to transform predicted values with np.exp\npred = np.expm1(rf_reg.predict(X_test)).round()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.DataFrame({'datetime':time,'count':pred})\nsub.to_csv('sub.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}