{"cells":[{"metadata":{},"cell_type":"markdown","source":"## <center> Bike Sharing Demand - Prediction"},{"metadata":{},"cell_type":"markdown","source":"### Ask:\nPredict the total count of bikes rented during each hour in test set."},{"metadata":{},"cell_type":"markdown","source":"### Data:\n<br>\n<li> Hourly rental data spanning two years.\n<li> Training set contains first 19 days of each month.\n<li> Test Set contains 20th to end of month."},{"metadata":{},"cell_type":"markdown","source":"### Features:\n<ol>\n<li> datetime - hourly date + timestamp  \n<li> season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n<li> holiday - whether the day is considered a holiday\n<li> workingday - whether the day is neither a weekend nor holiday\n<li> weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n<li> weather - 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n<li> weather - 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n<li> weather - 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n<li> temp - temperature in Celsius\n<li> atemp - \"feels like\" temperature in Celsius\n<li> humidity - relative humidity\n<li> windspeed - wind speed\n<li> casual - number of non-registered user rentals initiated\n<li> registered - number of registered user rentals initiated\n<li> count - number of total rentals\n    </ol>"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import necessary packages\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sb\nfrom datetime import datetime\nimport calendar\n\n#Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Read Dataset\ndf_train = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv')\ndf_test = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Review training set data\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Review test set data\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Backup data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_copy = df_train.copy()\ndf_test_copy = df_test.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reviewing datatypes\ndf_train.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Saving total number of rows in test and train\nntrain = df_train.shape[0]\nntest = df_test.shape[0]\n\nntrain, ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's remove few columns from training set as they are not available in test set.\ndcols = ['count', 'casual', 'registered']\n\n#Let's backkup the data first\ndf_target = df_train[dcols]\n\n#Let's remove them\ndf_train.drop(dcols, inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's concatenate train and test data\ndf_alldata = pd.concat([df_train, df_test], axis=0).reset_index(drop=True)\n\ndf_alldata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alldata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let start our EDA with datetime\ndf_alldata['datetime'] = pd.to_datetime(df_alldata['datetime'])","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#New values extracted from datetime -> day, date, hour, month, year\ndf_alldata['day'] = df_alldata['datetime'].apply(lambda x: calendar.day_name[x.weekday()])\ndf_alldata['date'] = df_alldata['datetime'].apply(lambda x: x.day)\ndf_alldata['hour'] = df_alldata['datetime'].apply(lambda x: x.hour)\ndf_alldata['month'] = df_alldata['datetime'].apply(lambda x: calendar.month_name[x.month])\ndf_alldata['year'] = df_alldata['datetime'].apply(lambda x:x.year)\n\ndf_alldata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#For simplicity of our model\ndf_alldata['year'] = df_alldata['year'].map({2011:0, 2012:1})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's drop datetime column as we extracted information\ndf_alldata.drop('datetime', inplace=True, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's change few more cols as per their values\ndf_alldata['season'] = df_alldata['season'].map({1:'Spring', 2:'Summer', 3:'Fall', 4:'Winter'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alldata['weather'] = df_alldata['weather'].map({1:'Clear-Cloudy', 2:'Misty-Cloudy', 3:'LightRain-Storm', 4:'Rain-Ice'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's check dataset datatypes\ndf_alldata.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's get catg features\ncatg_feats = df_alldata.dtypes[df_alldata.dtypes == 'object'].index\ncatg_feats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's onehot encode these categorical feats\nfor col in catg_feats:\n    df_temp = pd.get_dummies(df_alldata[col], prefix=col)\n    dcol = df_temp.columns[0]\n    df_temp.drop(dcol, inplace=True, axis=1) #Dropping dummy variable trap col\n    df_alldata.drop(col, inplace=True, axis=1) #Dropping original column\n    df_alldata = pd.concat([df_alldata, df_temp], axis=1).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_alldata.head(3)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df_alldata.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing for Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"#For submission dataframe saving timestamp\nsrs_timestamp = df_test['datetime']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's split train and test set\ndf_train = df_alldata[:ntrain]\ndf_test = df_alldata[ntrain:]\n\ndf_train.shape, df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"## Setting up target variable\ntarget = np.log1p(df_target['count'])\n\nlen(target)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Defining Cross Validation and Error Function"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\ncross_val = KFold(n_splits=10, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Calculating RMSLE\ndef rmsle(y, y_pred):\n    assert len(y) == len(y_pred), 'Error in actual and prediction length.'\n    return np.sqrt(np.mean((np.log1p(y) - np.log1p(y_pred))**2))\n\n#np.sqrt(mean_squared_log_error(y, y_pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model and Parameter Tuning"},{"metadata":{"trusted":true},"cell_type":"code","source":"#List of models to try\nimport xgboost as xgb\nfrom sklearn.linear_model import RidgeCV, Ridge, LassoCV, Lasso, ElasticNetCV, ElasticNet\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nimport lightgbm as lgbm\nfrom sklearn.model_selection import train_test_split, KFold, GridSearchCV\nfrom sklearn.metrics import mean_squared_log_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(df_train.values, target, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function to store model parameters and score\n\ncols = ['Model', 'Parameters', 'Xtrain_RMSLE', 'Xtest_RMSLE', 'dftrain_RMSLE', 'exp_dftrain_RMSLE']\ndf_model_scores = pd.DataFrame(columns=cols)\n\n\ndef model_scores(model, df_model_scores = df_model_scores, X_train = X_train, y_train = y_train, X_test = X_test, \n                 y_test = y_test, df_train = df_train, target = target):\n    #Fit with Xtrain\n    model.fit(X_train, y_train)\n    \n    #Predict X_train\n    pred = model.predict(X_train)\n    \n    #X_train RMSLE\n    xtr_rmsle = rmsle(y_train, pred)\n    \n    #Predict X_test\n    pred = model.predict(X_test)\n    \n    #X_test rmsle\n    xts_rmsle = rmsle(y_test, pred)\n    \n    #Predict df_train\n    model.fit(df_train.values, target)\n    pred = model.predict(df_train.values)\n    dftr_rmsle = rmsle(target, pred)\n    expdftr_rmsle = rmsle(np.expm1(target), np.expm1(pred))\n    \n    #setting up values for data frame\n    mdl = model.__class__.__name__\n    param = str(model.get_params())\n    \n    data = {'Model':[mdl], 'Parameters':[param], 'Xtrain_RMSLE':[xtr_rmsle], 'Xtest_RMSLE':[xts_rmsle], \n                           'dftrain_RMSLE':[dftr_rmsle], 'exp_dftrain_RMSLE':[expdftr_rmsle]}\n    \n    df_temp = pd.DataFrame(data)\n    \n    df_model_scores = pd.concat([df_model_scores, df_temp]).reset_index(drop=True)\n    \n    return df_model_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XGBoost Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Let's find optimum parameters for each model\nmodel_xgb = xgb.XGBRegressor(n_estimators=1000, n_jobs=-1, objective='reg:squarederror', random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_param_grid={'max_depth':[5, 6],\n               'learning_rate':[0.1],\n               'booster':['gbtree','dart']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Implement Grid Search over XGBoost\ngs_xgb_model = GridSearchCV(param_grid=xgb_param_grid, estimator=model_xgb, cv=cross_val, verbose=1, n_jobs=-1)\n# gs_xgb_model.fit(X_train, y_train)#Training the Model\n# print('Best Score:', gs_xgb_model.best_score_)\n# print('Parameters:', gs_xgb_model.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_param_grid = {'booster':['gbtree', 'gblinear', 'dart']}","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#Gathering model scores\nmodel_xgb = xgb.XGBRegressor(n_estimators=1000, n_jobs=-1, objective='reg:squarederror', random_state=42, max_depth=5, \n                             booster='dart')\ndf_model_scores = model_scores(model_xgb, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Training\nmodel_xgb.fit(X_train, y_train)\n\n#Model Prediction\npred=model_xgb.predict(df_test.values)\n\n#Submission\npred = np.expm1(pred)\n\n#Rounding prediction\nsr_pred = pd.Series(data=pred, name='count')\nsr_pred = sr_pred.apply(lambda x: round(x,0))\n\nsubmission = pd.DataFrame({'datetime':srs_timestamp, 'count':sr_pred})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Saving Submission\nsubmission.to_csv('1119_xgb.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Submission Secured 0.40167"},{"metadata":{},"cell_type":"markdown","source":"### Ridge"},{"metadata":{"trusted":true},"cell_type":"code","source":"alphas_ridge = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nalphas_lasso = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\nelastic_alphas = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\nelastic_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RidgeCV\nrcv = RidgeCV(alphas=alphas_ridge, cv=10, scoring='neg_mean_squared_log_error')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcv.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rcv.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding best alpha round 2\nalphas_ridge = [0.1, 1, 5, 8, 10, 12, 14, 14.5]\nrcv = RidgeCV(alphas_ridge, cv=10, scoring='neg_mean_squared_log_error')\nrcv.fit(X_train, y_train)\nrcv.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding best alpha round 3\nalphas_ridge = [0.1, 0.01, 0.5, 0.001, 0.3]\nrcv = RidgeCV(alphas_ridge, cv=10, scoring='neg_mean_squared_log_error')\nrcv.fit(X_train, y_train)\nrcv.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding best alpha round 4\nalphas_ridge = [0.001, 0.005, 0.015, 0.003, 0.008]\nrcv = RidgeCV(alphas_ridge, cv=10, scoring='neg_mean_squared_log_error')\nrcv.fit(X_train, y_train)\nrcv.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ridge = Ridge(alpha=0.001, max_iter=10000, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model_scores = model_scores(model_ridge, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lasso"},{"metadata":{"trusted":true},"cell_type":"code","source":"lcv = LassoCV(alphas=alphas_lasso, max_iter=1000, cv=10, n_jobs=-1, selection='random', random_state=42, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lcv.fit(X_train, y_train)\nlcv.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Computing best alpha round 2\nalphas = [0.0002, 0.0003, 0.00025, 0.0015]\nlcv = LassoCV(alphas = alphas, max_iter=10000, cv=10, n_jobs=-1, selection='random', random_state=42, verbose=1)\nlcv.fit(X_train, y_train)\nlcv.alpha_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lasso = Lasso(alpha=0.0002, max_iter=10000, random_state=42, selection='cyclic')\ndf_model_scores = model_scores(model_lasso, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rf = RandomForestRegressor(random_state=42)\n\ngrid_rf = {'max_depth':[2, 3, 5],\n           'n_estimators':[200],\n          'criterion':['mse','mae']}\n\nGSearch = GridSearchCV(param_grid=grid_rf, estimator=model_rf, cv=10, n_jobs=-1, verbose=1)\n\nGSearch.fit(X_train, y_train)\n\nprint('Best Score:', GSearch.best_score_)\nprint('Parameters:', GSearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GSearch.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_rf = RandomForestRegressor(n_estimators=200, random_state=42, max_depth=5, criterion='mse')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model_scores = model_scores(model_rf, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Light GBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lgbm = lgbm.LGBMRegressor(n_estimators=1000, objective='regression', random_state=42, n_jobs=-1)\n\ngrid_lgbm = {'learning_rate':[0.02, 0.05, 0.08]}\n\nGSearch = GridSearchCV(param_grid=grid_lgbm, estimator=model_lgbm, cv=10, n_jobs=-1, verbose=1)\n\nGSearch.fit(X_train,y_train)\n\nprint('Best Score:', GSearch.best_score_)\nprint('Parameters:', GSearch.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lgbm = lgbm.LGBMRegressor(n_estimators=1000, objective='regression', random_state=42, n_jobs=-1, learning_rate=0.05)\n\ndf_model_scores = model_scores(model_lgbm, df_model_scores)\n\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ElasticNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Round 2\nelastic_alphas = [0.0003, 0.00035, 0.00028]\nelastic_l1ratio = [0.7, 0.75, 0.8]\necv = ElasticNetCV(alphas=elastic_alphas, l1_ratio=elastic_l1ratio, cv=10, n_jobs=-1, random_state=42, max_iter=10000)\necv.fit(X_train, y_train)\necv.alpha_, ecv.l1_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Round 3\nelastic_l1ratio = [0.6, 0.5, 0.7]\nelastic_alphas = [0.0003]\necv = ElasticNetCV(alphas = elastic_alphas, l1_ratio=elastic_l1ratio, cv=10, n_jobs=-1, random_state=42, max_iter=10000)\necv.fit(X_train, y_train)\necv.alpha_, ecv.l1_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Round 4\nelastic_l1ratio = [0.3, 0.2, 0.5]\nelastic_alphas = [0.0003]\necv = ElasticNetCV(alphas = elastic_alphas, l1_ratio=elastic_l1ratio, cv=10, n_jobs=-1, random_state=42, max_iter=10000)\necv.fit(X_train, y_train)\necv.alpha_, ecv.l1_ratio_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_elastic = ElasticNet(alpha=0.0003, l1_ratio=0.5, random_state=42, max_iter=10000)\ndf_model_scores = model_scores(model_elastic, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Gradient Boosting Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_GB = GradientBoostingRegressor(n_estimators=300, random_state=42)\n\nGSearch_param = {'max_depth':[3,5],\n             'learning_rate':[0.1, 0.01, 0.3],\n                'alpha':[0.5, 0.1, 0.9]}\n\nGSearch_GB = GridSearchCV(param_grid=GSearch_param, estimator=model_GB, cv=10, n_jobs=-1, verbose=2)\n\nGSearch_GB.fit(X_train, y_train)\n\nprint('Best Score:', GSearch_GB.best_score_)\nprint('Best Param:', GSearch_GB.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model_gb = GradientBoostingRegressor(n_estimators=300, random_state=42, max_depth=5, alpha=0.5)\ndf_model_scores = model_scores(model_gb, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Voting Regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\n\nmodel_vote = VotingRegressor([('XGBoost', model_xgb), ('LGBM', model_lgbm), ('GradientBoosting', model_gb)])\nmodel_vote.fit(X_train, y_train)\npred = model_vote.predict(df_test.values)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df_model_scores = model_scores(model_vote, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Model Training\nmodel_vote.fit(X_train, y_train)\n\n#Model Prediction\npred=model_vote.predict(df_test.values)\n\n#Submission\npred = np.expm1(pred)\n\n#Rounding prediction\nsr_pred = pd.Series(data=pred, name='count')\nsr_pred = sr_pred.apply(lambda x: round(x,0))\n\nsubmission = pd.DataFrame({'datetime':srs_timestamp, 'count':sr_pred})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('VotingModelResults.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Voting Model Secured 0.38715"},{"metadata":{},"cell_type":"markdown","source":"### Stacking Regressor"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"from mlxtend.regressor import StackingRegressor\n\nstack_reg = StackingRegressor(regressors=[model_gb, model_lgbm], meta_regressor=model_xgb, \n                              use_features_in_secondary=False)\n\ndf_model_scores = model_scores(stack_reg, df_model_scores)\ndf_model_scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_model_scores.to_csv('Kaggle_Bike_Sharing_Model.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stack_reg.fit(X_train, y_train)\npred = stack_reg.predict(df_test.values)\nx = pred[:5]\nnp.expm1(x)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}