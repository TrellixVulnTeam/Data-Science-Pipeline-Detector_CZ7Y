{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### SARIMAX\nSeasonal AutoRegressive Integrated Moving Average with eXogenous regressors\nThis model encompasses not only the non-seasonal (p,d,q) and seasonal (P,D,Q,m) factors, but also introduce the idea that external factors (environmental, economic, etc.), which can also influence a time series, and be used in forecasting.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Install the pmdarima module to use its auto_arima to find the optimal value for p, d, q, and P, D, Q","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Perform standard imports","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n%matplotlib inline\n\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom pmdarima import auto_arima\n\nimport seaborn as sns\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom scipy import stats\nfrom scipy.stats import skew\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load Datasets","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Set datetime column as index, and change its data type to datetime in both train and test dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv', index_col='datetime', parse_dates=True)\ntest = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv', index_col='datetime', parse_dates=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying top five rows of Train dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying top five rows of test dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Calculating quantiles to find and remove the outliers from the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = train.quantile(0.25)\nQ3 = train.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers = train[~((train < (Q1 - 1.5*IQR)) | (train > (Q3 + 1.5*IQR))).any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As wind speed cannot be zero in any of the season, so I am assigning a particular value to windspeed column based on some situations","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def wind(cols):\n    windspeed = cols[0]\n    season = cols[1]\n    \n    if(windspeed == 0):\n        if(season == 1):\n            return 14\n        elif(season == 2):\n            return 14\n        else:\n            return 13\n    else:\n        return windspeed","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating a new column named wind, and assigning the wind speed to it, after appying above function based on different season","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers['wind'] = train_without_outliers[['windspeed', 'season']].apply(wind, axis=1)\ntest['wind'] = test[['windspeed', 'season']].apply(wind, axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Appending train and test dataset and storing the resultant dataframe into data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = train_without_outliers.append(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the tail of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.tail(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the data types of different columns of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the shape of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking for null values in different columns of data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting the first 250 rows of count (target) column to find the periodicity value (m) of the target column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['count'][0:250].plot(figsize=(16, 5))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Replacing the numerical values in Season and Weather column with the string values provided in the description of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data['season'] = data['season'].replace({1: 'spring', 2: 'summer', 3: 'fall', 4: 'winter' })\ndata['weather'] = data['weather'].replace({1: 'Clear, Few clouds, Partly cloudy, Partly cloudy',\n                                        2: 'Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist',\n                                        3: 'Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n                                        4: 'Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog' })","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the count of unique values present in the different columns in the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in data.columns:\n    print(i)\n    print(data[i].value_counts())\n    print('\\n')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the correlation value of target column (count) with other numerical variables present in the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = data.corr()\ncorr['count'][:-1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding whether a variable of object data type is affecting the target variable (count)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in (data.select_dtypes(include ='object').columns):\n    if(i != 'count'):\n        data_crosstab = pd.crosstab(data[i], data['count'], margins = False)\n        stat, p, dof, expected = stats.chi2_contingency(data_crosstab)\n        prob=0.95\n        alpha = 1.0 - prob\n        if p <= alpha:\n            print(i, ' : Dependent (reject H0)')\n        else:\n            print(i, ' : Independent (fail to reject H0)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping the \"casual\" and \"registered\" columns from the dataset, as in test dataset these values are not present at all","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop('casual', axis=1, inplace=True)\ndata.drop('registered', axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding if multi collinearity is present in the data, if it is then drop that particular column from the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix = data.corr().abs()\n\n# Select upper triangle of correlation matrix\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\n\n# Find index of feature columns with correlation greater than 0.95\nto_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\ndata = data.drop(data[to_drop], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again, displaying the head of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting distribution plot for the variables having skewness","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfor i in (data.skew().index):\n    plt.figure(i)\n    sns.distplot(data[i], kde_kws={'bw':0.1})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plotting scatter plot between \"datetime index\" and \"count\" column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(data.index, data['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding if there is any skewness present in the entire dataset and if it is then fixing it through the boxcox1p transformation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def fixing_skewness(df):\n    numeric_feats = df.dtypes[df.dtypes != object].index\n    \n    skew_feats = df[numeric_feats].apply(lambda x: skew(x)).sort_values(ascending=False)\n    \n    high_skew = skew_feats[abs(skew_feats) > 0.5].index\n    \n    for i in high_skew:\n        df[i] = boxcox1p(df[i], boxcox_normmax(df[i] + 1))\n#         print(i)\n        \nfixing_skewness(data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Again displaying the head of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the data types of different columns of the data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the shape of the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Following function helps in reducing, if any overfitting is present in the dataset, that is if any variable in the dataset, contains only one value in  99.94 of the cases","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def overfit_reducer(df):\n    overfit = []\n    for i in df.columns:\n        count = df[i].value_counts()\n        zero_index_value = count.iloc[0]\n        \n        if (((zero_index_value / len(df)) * 100) > 99.94):\n            overfit.append(i)\n            \n    overfit = list(overfit)\n    return overfit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Finding the list of overfitted features using above user-defined function\noverfitted_features = overfit_reducer(data)\n#Dropping the overfitted columns from the final dataframes\ndata.drop(overfitted_features, axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the number of rows and columns in the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the types of data in the dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dropping the null value from the dataset and storing the result in data1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1 = data.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finding the shape of data1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the tail of dataframe data1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.tail()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the head of dataframe data1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Converting the data type of \"count\" (target) column into integer from float","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1['count'] = data1['count'].astype('int64')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Displaying the head of dataframe data1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data1.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot the target column (count)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title = 'Count of bikes rented'\ndata1['count'].plot(figsize=(16,5), legend=True, title=title)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot boxplot between \"count\" traget column and columns having object data type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in (data1.dtypes[data1.dtypes == 'object'].index):\n    plt.figure(i)\n    sns.boxplot(x=i, y='count', data=data1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Plot scatterplot between \"count\" traget column and columns having integer data type","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in (data1.dtypes[data1.dtypes == 'int64'].index):\n    if(i!='count'):\n        plt.figure(i)\n        sns.scatterplot(x=i, y='count', data=data1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can use matplotlib to shade holidays behind bike sharing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('holiday==1').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('holiday==0').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can use matplotlib to shade workingday behind our bike sharing data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('workingday==1').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"title='Count of bikes rented'\n\nax = data1['count'][:1000].plot(figsize=(16,5),title=title)\nax.autoscale(axis='x',tight=True)\nfor x in data1[:1000].query('workingday==0').index:       \n    ax.axvline(x=x, color='k', alpha = 0.3);  ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Run an ETS Decomposition","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"result = seasonal_decompose(data1['count'], model='multiplicative', period=24)\nresult.plot();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Test for stationarity","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n    \n    if result[1] <= 0.05:\n        print(\"Strong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"Weak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adf_test(data1['count'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Run pmdarima.auto_arima to obtain recommended orders\nThis may take awhile as there are a lot of combinations to evaluate.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# For SARIMA Orders we set seasonal=True and pass in an m value\n# auto_arima(data1['count'],seasonal=True,m=24, trace=True, n_jos=-1).summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Creating dummies for object data type and storing the result in data_dummies dataframe","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data_dummies = pd.get_dummies(data, drop_first=True)\ndata_dummies.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creating SARIMAX model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model = SARIMAX(data1['count'], exog=data_dummies[:7026][['holiday', 'workingday', 'temp','humidity', 'wind', \n                                           'season_spring', 'season_summer', 'season_winter',\n                                           'weather_Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog',\n                                           'weather_Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n                                           'weather_Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist']],\n                                            order=(2, 1, 2), seasonal_order=(1, 0, 1, 24), enforce_invertibility=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fitting the model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results=model.fit()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Printing the summary of the result","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"results.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Obtain forecasted values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"start = len(train_without_outliers)\nend = len(train_without_outliers) + len(test) - 1\n# exog_forecast = data[10886:][['holiday', 'workingday', 'temp','humidity', 'windspeed']]\nfcast = results.predict(start=start, end=end, exog=data_dummies[7026:][['holiday', 'workingday', 'temp','humidity', 'wind', \n                                           'season_spring', 'season_summer', 'season_winter',\n                                           'weather_Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog',\n                                           'weather_Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds',\n                                           'weather_Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist']]).rename('SARIMAX(1, 1, 1)x(2, 0, [1, 2], 2) Forecast')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Changing the data type of forecast to integer and dropping the index","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast = fcast.astype('int64')\nfcast = fcast.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fcast.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame()\nsubmission_df['datetime'] = test.index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['count'] = fcast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}