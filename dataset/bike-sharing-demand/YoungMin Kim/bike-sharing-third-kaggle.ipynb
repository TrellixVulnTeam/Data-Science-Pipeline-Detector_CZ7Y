{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nimport datetime as dt\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/bike-sharing-demand/train.csv',parse_dates=['datetime'])\ntest = pd.read_csv('/kaggle/input/bike-sharing-demand/test.csv',parse_dates=['datetime'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import missingno as msno\nmsno.matrix(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.matrix(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['year'] = train['datetime'].dt.year\ntrain['month'] = train['datetime'].dt.month\ntrain['day'] = train['datetime'].dt.day\ntrain['hour'] = train['datetime'].dt.hour\ntrain['weekday'] = train['datetime'].dt.weekday\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,axes = plt.subplots(2,2,figsize=(12,8))\nsns.barplot(x=train['year'],y=train['count'],ax=axes[0,0],ci=False)\nsns.barplot(x=train['month'],y=train['count'],ax=axes[0,1],ci=False)\n#sns.barplot(x=train['day'],y=train['count'],ax=axes[1,0],ci=False)\nsns.barplot(x=train['hour'],y=train['count'],ax=axes[1,0],ci=False)\nsns.barplot(x=train['weekday'],y=train['count'],ax=axes[1,1],ci=False)\naxes[0,0].set(title='Bike sharing count by year')\naxes[0,1].set(title='Bike sharing count by month')\naxes[1,0].set(title='Bike sharing count by hour')\naxes[1,1].set(title='Bike sharing count by weekday')\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=2,ncols=2,figsize=(12,8))\n\nsns.boxplot(data=train,y=\"count\",orient=\"v\",ax=axes[0][0])\nsns.boxplot(data=train,y=\"count\",x=\"season\",orient=\"v\",ax=axes[0][1])\nsns.boxplot(data=train,y=\"count\",x=\"hour\",orient=\"v\",ax=axes[1][0])\nsns.boxplot(data=train,y=\"count\",x=\"workingday\",orient=\"v\",ax=axes[1][1])\n\naxes[0][0].set(ylabel='Count',title=\"Box Plot On Count\")\naxes[0][1].set(xlabel='Season', ylabel='Count',title=\"Box Plot On Count Across Season\")\naxes[1][0].set(xlabel='Hour Of The Day', ylabel='Count',title=\"Box Plot On Count Across Hour Of The Day\")\naxes[1][1].set(xlabel='Working Day', ylabel='Count',title=\"Box Plot On Count Across Working Day\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\ncorr_matrix = train[[\"temp\",\"atemp\",\"casual\",\"registered\",\"humidity\",\"windspeed\",\"count\"]].corr()\nmask = np.zeros_like(corr_matrix)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr_matrix,mask=mask,vmax=.8,square=True,annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- temp and atemp have strong correlation\n- registered and conut have strong correlation."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2,ax3) = plt.subplots(ncols=3,figsize=(12,8))\nsns.regplot(x=train['temp'],y=train['count'],ax=ax1)\nsns.regplot(x=train['humidity'],y=train['count'],ax=ax2)\nsns.regplot(x=train['windspeed'],y=train['count'],ax=ax3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Windspeed has too many 0 values.\n\nMy guess is that the unmeasured value goes into zero.\n\n\nI will adjust these values through xgboostRegressor later"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2,ax3,ax4,ax5) = plt.subplots(nrows=5,figsize=(15,25))\nsns.pointplot(data=train,x='hour',y='count',ax=ax1)\nsns.pointplot(data=train,x='hour',y='count',hue='workingday',ax=ax2)\nsns.pointplot(data=train,x='hour',y='count',hue='weekday',ax=ax3)\nsns.pointplot(data=train,x='hour',y='count',hue='season',ax=ax4)\nsns.pointplot(data=train,x='hour',y='count',hue='weather',ax=ax5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Daytime use on weekends There are many use of commute hours on weekdays.\n- It is also affected by the weather, and the better the weather, the more it is used."},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats import norm, skew\nfrom scipy import stats\nplt.style.use('seaborn')\nsns.distplot(train['count'] , fit=norm)\nmu, sigma = norm.fit(train['count'])\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('Count distribution')\n\n#Get also the QQ-plot\nfig = plt.figure()\nstats.probplot(train['count'],plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Normalization of the dependent variable is desirable for regression, so log1p is used to normalize it."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(np.log1p(train['count']),fit=norm)\nmu,sigma = norm.fit(np.log1p(train['count']))\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],loc='best')\nplt.ylabel('Frequency')\nplt.title('count distribution')\nfig=plt.figure()\nstats.probplot(np.log1p(train['count']),fit=True,plot=plt)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\nYou can see that it has been normalized even a little. Therefore, log1p should be taken for count later."},{"metadata":{},"cell_type":"markdown","source":"\n- I will modify the 0 value of WindSpeed."},{"metadata":{"trusted":true},"cell_type":"code","source":"data= train.append(test)\nwindColumns = [\"season\",\"weather\",\"humidity\",\"month\",\"temp\",\"year\",\"atemp\"]\ndata['year'] = data['datetime'].dt.year\ndata['month'] = data['datetime'].dt.month\ndata['day'] = data['datetime'].dt.day\ndata['hour'] = data['datetime'].dt.hour\ndata['weekday'] = data['datetime'].dt.weekday\ndata['dayofweek'] = data['datetime'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\nX = data[data['windspeed']!=0]\ny = data[data['windspeed']==0]\nwind_train_x = X[windColumns]\nwind_train_y = X['windspeed']\nwind_test_x = y[windColumns]\nwind_test_y_idx = y['windspeed'].index\nxgb=XGBRegressor()\nxgb.fit(wind_train_x,wind_train_y)\npred = xgb.predict(wind_test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y['windspeed'] = pred\ndata = X.append(y).sort_values('datetime')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['windspeed'] == 0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.countplot(np.round(data['windspeed']))\nplt.xticks(rotation=60)\nplt.title('windspeed countplot(int)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"category_features = [\"season\",\"holiday\",\"workingday\",\"weather\",\"weekday\",\"year\"]\nfor i in category_features:\n    data[i] = data[i].astype('category')\nfinal_train = data[data['count'].notnull()]\nfinal_test = data[data['count'].isnull()]\ntrain_x = final_train.drop('count',axis=1)\ntrain_y = final_train['count']\ntest_x = final_test.drop('count',axis=1)\ndatetime = test_x.datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_feat = ['datetime','day','casual','registered']\ntrain_x.drop(drop_feat,axis=1,inplace=True)\ntest_x.drop(drop_feat,axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dummy_train_x = pd.get_dummies(train_x)\ndummy_test_x = pd.get_dummies(test_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_log_error\ndef rmsle(pred_y,test_y):    \n    return np.sqrt(mean_squared_log_error(test_y,pred_y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import RobustScaler\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import RidgeCV,LassoCV,ElasticNetCV\nfrom sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor,AdaBoostRegressor\nfrom sklearn.model_selection import GridSearchCV\nfrom lightgbm.sklearn import LGBMRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"alpha_las=[0.0005,0.0001,0.00005,0.00001]\ne_ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\nlasso = make_pipeline(RobustScaler(),LassoCV(alphas=alpha_las,random_state=42,max_iter=1e7))\nridge = make_pipeline(RobustScaler(),RidgeCV(alphas = alpha_las))\nelastic = make_pipeline(RobustScaler(),ElasticNetCV(max_iter=1e7,alphas=alpha_las,l1_ratio = e_ratio))\nrf = RandomForestRegressor(bootstrap=True,max_depth=70,max_features='auto',min_samples_leaf=4,min_samples_split=10,n_estimators=2200)\ngra = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n                                   max_depth=4, max_features='sqrt',\n                                   min_samples_leaf=15, min_samples_split=10, \n                                   loss='huber', random_state =5)\nxgb = XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n                             learning_rate=0.05, max_depth=3, \n                             min_child_weight=1.7817, n_estimators=2200,\n                             reg_alpha=0.4640, reg_lambda=0.8571,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1)\nlgbm = LGBMRegressor(objective='regression',num_leaves=5,\n                              learning_rate=0.05, n_estimators=720,\n                              max_bin = 55, bagging_fraction = 0.8,\n                              bagging_freq = 5, feature_fraction = 0.2319,\n                              feature_fraction_seed=9, bagging_seed=9,\n                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\nada = AdaBoostRegressor(n_estimators=2200,random_state=42,learning_rate=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = [lasso,ridge,elastic,rf,gra,xgb,lgbm,ada]\nmodel_name = ['Lasso','Ridge','ElasticNet','RandomForest','GradientBoost','XGBoost','LGBM','Ada']\ntmp = pd.DataFrame(columns=['model','rmsle'])\nidx=0\nfor i,j in zip(model,model_name):\n    train_y_log = np.log1p(train_y)\n    i.fit(dummy_train_x,train_y_log)\n    pred = i.predict(dummy_train_x)\n    tmp.loc[idx,'model'] = j\n    tmp.loc[idx,'rmsle'] = rmsle(train_y_log,pred)\n    idx+=1\ntmp = tmp.sort_values(by= 'rmsle')\ntmp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- stacking\n    - Three models with a large Rmsle score will not be included in the stacking."},{"metadata":{"trusted":true},"cell_type":"code","source":"from mlxtend.regressor import StackingCVRegressor\nstack = StackingCVRegressor(regressors=(gra,xgb,lgbm,ada),\n                           meta_regressor=rf,use_features_in_secondary=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y_log = np.log1p(train_y)\nstack.fit(np.array(dummy_train_x),np.array(train_y_log))\npred = stack.predict(np.array(dummy_train_x))\ntmp.loc[idx,'model'] = 'Stack'\ntmp.loc[idx,'rmsle'] = rmsle(train_y_log,pred)\ntmp = tmp.sort_values('rmsle')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp['rmsle2'] = tmp['rmsle'].map('{:.4f}'.format)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nax = fig.add_subplot()\nplt.plot(tmp['model'],tmp['rmsle2'])\nfor i,j in zip(tmp['model'],tmp['rmsle2']):\n#     ax.annotate(str(j),xy=(i,j))\n    plt.text(i, j, str(j),fontsize=15)\nplt.xticks(rotation=60)\nplt.title('RMSLE score by model(train data)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def blend_model(X):\n    return (0.3*rf.predict(X))+(0.25*stack.predict(np.array(X)))+(0.2*gra.predict(X))+(0.1*xgb.predict(X))+(0.1*lgbm.predict(X))+(0.05*ada.predict(X))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = blend_model(dummy_train_x)\nprint(rmsle(train_y_log,pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# final = pd.DataFrame(columns=['datetime','count'])\n# final['datetime'] = datetime\n# final['count'] = np.exp(blend_model(dummy_test_x))\n# final.to_csv('blend bike submission.csv',index=False)\n#0.41146","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final = pd.DataFrame(columns=['datetime','count'])\nfinal['datetime'] = datetime\nfinal['count'] = np.exp(stack.predict(np.array(dummy_test_x)))\nfinal.to_csv('rf bike submission.csv',index=False)\n# 0.404","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":4}