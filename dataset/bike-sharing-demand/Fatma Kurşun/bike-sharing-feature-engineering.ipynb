{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Bike Sharing\n\nOn this notebook, we will try to predict number of total rental using machine learning algorithms. Before this one, we will do feature engineering and exploratory data analysis for examine the data.\n\n**Let's explore the data.**\n\n\n* datetime - hourly date + timestamp  \n* season -  1 = spring, 2 = summer, 3 = fall, 4 = winter \n* holiday - whether the day is considered a holiday\n* workingday - whether the day is neither a weekend nor holiday\n* weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy \n* 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist \n* 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds \n* 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog \n* temp - temperature in Celsius\n* atemp - \"feels like\" temperature in Celsius\n* humidity - relative humidity\n* windspeed - wind speed\n* casual - number of non-registered user rentals initiated\n* registered - number of registered user rentals initiated\n* count - number of total rentals\n\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head() # we can see  first 5 samples with this function","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.isnull().sum().sort_values(ascending = False)) #as you can see there is no null value in the columns\nprint(\"**\"*50)\nprint(test.isnull().sum().sort_values(ascending = False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.info()) # we can see type of features with this info()\nprint('**'*50)\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see, datetime's type is object. We should convert it to datetime."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.datetime = pd.to_datetime(train.datetime)\ntest.datetime = pd.to_datetime(test.datetime)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"let's see again !"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.info())\nprint('**'*50)\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Yes! we converted it. Now, we will separate the datetime column as year,month,day,hour and week"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['year'] = train['datetime'].dt.year\ntrain['month'] = train['datetime'].dt.month\ntrain['day'] = train['datetime'].dt.day\ntrain['hour'] = train['datetime'].dt.hour\ntrain['dayofweek'] = train['datetime'].dt.weekday_name\n\n\ntest['year'] = test['datetime'].dt.year\ntest['month'] = test['datetime'].dt.month\ntest['day'] = test['datetime'].dt.day\ntest['hour'] = test['datetime'].dt.hour\ntest['dayofweek'] = test['datetime'].dt.weekday_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail() # we can see last 5 samples with this function! ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We did it too. Now we can start to data exploratory. Let's start !"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe().T # we can see statistical results with this function ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EDA & Feature Engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.heatmap(train.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.pairplot(train)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.distplot(train['count'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scatter_plot():\n    for i in test.columns:\n        plt.scatter(train[i],train['count'])\n        plt.title(f\"Scatter plot for {i}\")\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scatter_plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.plot(train.set_index('datetime')[\"count\"][0:300])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.boxplot(x='dayofweek',y='count', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we need to convert categorical data to numeric data.\n\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ntrain['dayofweek'] = le.fit_transform(train['dayofweek'])\ntest['dayofweek'] = le.transform(test['dayofweek'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As we can see from above graph. This is positively(right) skewed data.Now we will look the box plot and outliers value."},{"metadata":{},"cell_type":"markdown","source":"Box plot use the IQR method for finding display data and outliers.\n\n\n\n#### Wikipedia Definition\n\nThe interquartile range (IQR), also called the midspread or middle 50%, or technically H-spread, is a measure of statistical dispersion, being equal to the difference between 75th and 25th percentiles, or between upper and lower quartiles, IQR = Q3 âˆ’ Q1.\nIn other words, the IQR is the first quartile subtracted from the third quartile; these quartiles can be clearly seen on a box plot on the data.\nIt is a measure of the dispersion similar to standard deviation or variance, but is much more robust against outliers.\n\n\n* We will clear the outliers values.\n> Okay, let's check!"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.boxplot(x='season', y='count', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we can say of seein this graph, people more rent bike on summer and fall."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.boxplot(x='hour',y='count', data=train) # as we can see there is difference for each hour. We need to use it !","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nsns.boxplot(x='year',y='count', data=train) # bike were rented in 2012!","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can say that people prefer the morning and evening times for renting bike"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.hist(train['count'][train['year'] == 2011], alpha=0.5, label='2011')\nplt.hist(train['count'][train['year'] == 2012], alpha=0.5, label='2012', color='red')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rented more bike in 2012 than 2011.\n\n\n####  Now, let's find the outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index('datetime', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['2011-01-19 23:00:00':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = train.quantile(0.25)\nQ3 = train.quantile(0.75)\nIQR = Q3 - Q1\nprint(IQR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers =train[~((train < (Q1 - 1.5 * IQR)) |(train > (Q3 + 1.5 * IQR))).any(axis=1)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.info())\nprint('*********************************************************************************')\nprint(train_without_outliers.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> We removed outliers data points."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We are going to fill the row that wind speed is equal zero."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 7))\nsns.boxplot(x='season',y='windspeed',data=train_without_outliers,palette='winter')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers['windspeed'] = train_without_outliers['windspeed'].replace(0,np.NaN)\ntest['windspeed'] = test['windspeed'].replace(0,np.NaN) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, We repalced zero as NaN. We will fill NaN with interpolate. Interpolate is using fill NaN value for time series data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers['windspeed'].fillna(method='bfill',inplace=True)\ntrain_without_outliers['windspeed'] = train_without_outliers['windspeed'].interpolate()\ntest['windspeed'] = test['windspeed'].interpolate()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers['windspeed'].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now e are going to convert cateforical data to categorical columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers[['season','holiday','workingday','weather', 'year','month','day','hour','dayofweek']] = train_without_outliers[['season','holiday','workingday','weather', 'year','month','day','hour','dayofweek']].astype('category')\ntest[['season','holiday','workingday','weather', 'year','month','day','hour','dayofweek']] = test[['season','holiday','workingday','weather', 'year','month','day','hour','dayofweek']].astype('category')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_without_outliers.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can start to make predictions"},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Regression"},{"metadata":{},"cell_type":"markdown","source":"A Random Forest is an ensemble technique capable of performing both regression and classification tasks with the use of multiple decision trees and a technique called Bootstrap Aggregation, commonly known as bagging. What is bagging you may ask? Bagging, in the Random Forest method, involves training each decision tree on a different data sample where sampling is done with replacement.\n\n[](http://www.google.com/url?sa=i&url=https%3A%2F%2Fmedium.com%2Fdatadriveninvestor%2Frandom-forest-regression-9871bc9a25eb&psig=AOvVaw01y2FFgzla0z_xdAC60_j8&ust=1608717087340000&source=images&cd=vfe&ved=0CAIQjRxqFwoTCLjXl6io4e0CFQAAAAAdAAAAABAH)"},{"metadata":{},"cell_type":"markdown","source":"### Train test split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train_without_outliers[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp','humidity', 'year', 'month', 'day', 'hour', 'dayofweek','windspeed']]\ny = train_without_outliers['count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom sklearn.preprocessing import MinMaxScaler\nsc_X = MinMaxScaler()\n\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.fit_transform(X_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=100)\nrf.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_prediction = rf.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn import metrics\nprint('RMSE:',np.sqrt(metrics.mean_squared_error(y_test, rf_prediction)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test,rf_prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16,8))\nplt.plot(rf_prediction[0:200],'r')\nplt.plot(y_test[0:200].values)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Regression"},{"metadata":{},"cell_type":"markdown","source":"The decision tree is a simple machine learning model for getting started with regression tasks.\n\nBackground A decision tree is a flow-chart-like structure, where each internal (non-leaf) node denotes a test on an attribute, each branch represents the outcome of a test, and each leaf (or terminal) node holds a class label. The topmost node in a tree is the root node. (see here for more details)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ndt_reg = DecisionTreeRegressor()\ndt_reg.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt_prediction = dt_reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSE:', np.sqrt(metrics.mean_squared_error(y_test, dt_prediction)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test,dt_prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, We will use the test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp','humidity', 'year', 'month', 'day', 'hour', 'dayofweek','windspeed']] = sc_X.fit_transform(test[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp','humidity', 'year', 'month', 'day', 'hour', 'dayofweek','windspeed']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred= rf.predict(test[['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp','humidity', 'year', 'month', 'day', 'hour', 'dayofweek','windspeed']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred=test_pred.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pred = pd.DataFrame(test_pred, columns=['count'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([test['datetime'], test_pred],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['count'] = df['count'].astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission1.csv' , index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}