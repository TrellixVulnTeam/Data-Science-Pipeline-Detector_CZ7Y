{"cells":[{"metadata":{},"cell_type":"markdown","source":"Performing EDA on this bike sharing demand dataset and trying to apply linear regression. Still a work in progress -  need to check for outliers, perform outlier removal and then resume."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nprint(os.listdir(\"../input/bike-sharing-demand/\"))\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Reading the dataset\ntrain = pd.read_csv(\"/kaggle/input/bike-sharing-demand/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/bike-sharing-demand/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Exploratory data analysis\n#Checking for nulls in train\nprint(\"Checking for Nulls in Training set\")\nprint(train.isnull().sum().sort_values(ascending = False))\nprint(\"Checking for Nulls in Test set\")\nprint(test.isnull().sum().sort_values(ascending = False))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#understanding the dataframe for train and test\nprint(\"Checking for Nulls in Training set\")\nprint(train.info())\nprint(\"Checking for Nulls in Test set\")\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since the datatype of the 'datetime' column is an object, it has to be converted to 'datetime' , to perform the date related operations."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Changing the type for column 'datetime' to datetime. This is to help perform subsequent date and time operations\ntrain.datetime = pd.to_datetime(train.datetime)\ntest.datetime = pd.to_datetime(test.datetime)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Checking for Nulls in Training set\")\nprint(train.info())\nprint(\"Checking for Nulls in Test set\")\nprint(test.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now let's derive additional attributes from the datetime column"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['year'] = train['datetime'].dt.year\ntrain['month'] = train['datetime'].dt.month\ntrain['day'] = train['datetime'].dt.day\ntrain['dayofweek'] = train['datetime'].dt.day_name()\ntrain['hour'] = train['datetime'].dt.hour\n\n\n\ntest['year'] = test['datetime'].dt.year\ntest['month'] = test['datetime'].dt.month\ntest['day'] = test['datetime'].dt.day\ntest['dayofweek'] = test['datetime'].dt.day_name()\ntest['hour'] = test['datetime'].dt.hour\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now that the basic features have been set up, we can proceed with exploratory analysis of those features. Starting off with profiling the 'Count' column"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.distplot(train['count'])\nplt.show()\n\nplt.figure(figsize=(10,5))\nplt.plot(train[\"count\"][0:800])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now, we can compare 'season' plays a role in determining the 'count'"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot(x='season', y='count', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, we see that people rent more bikes in seasons 2 and 3, which are Summer and Fall. Winter demand is more than Spring. \n\nNow proceeding further to check the demand against the day of the week and the hour of the day. "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.boxplot(x='dayofweek', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='hour', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='holiday', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='workingday', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='weather', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='year', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='dayofweek', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='casual', y='count', data=train)\n\nplt.figure(figsize=(10,5))\nsns.boxplot(x='registered', y='count', data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Performing graphical analysis on the continuous features"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1,)\nplt.title('Temperature Vs Count')\nplt.xlabel('Temperature')\nplt.ylabel('Count')\nplt.scatter(train['temp'],train['count'],s=2,c='b')\n\nplt.subplot(2,2,2)\nplt.title('Abs Temperature Vs Count')\nplt.xlabel('Abs Temperature')\nplt.ylabel('Count')\nplt.scatter(train['atemp'],train['count'],s=2,c='g')\n\nplt.subplot(2,2,3)\nplt.title('Humidity Vs Count')\nplt.xlabel('Humidity')\nplt.ylabel('Count')\nplt.scatter(train['humidity'],train['count'],c='r')\n\nplt.subplot(2,2,4)\nplt.title('Windspeed Vs Count')\nplt.xlabel('Windspeed')\nplt.ylabel('Count')\nplt.scatter(train['windspeed'],train['count'],c='c')\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking if there are any outliers"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dup = train.copy()\ntrain_dup['count'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dup['count'].quantile([0.1,0.2,0.25,0.8,0.9,0.99])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multicol_check = train_dup[['temp','atemp','humidity','count']].corr()\nmulticol_check","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Dropping the unwanted columns\n\ntrain_dup = train_dup.drop(['atemp','holiday','workingday','year','dayofweek'],axis=1)\ntrain_dup.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dup['season'] = train_dup['season'].astype('category')\ntrain_dup['weather'] = train_dup['weather'].astype('category')\ntrain_dup['month'] = train_dup['month'].astype('category')\ntrain_dup['hour'] = train_dup['hour'].astype('category')\n\nprint(train_dup.info())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Now, to train the model\nfrom sklearn.model_selection import train_test_split\nX = train_dup[['season','weather','temp','humidity','windspeed','casual','registered','month','day','hour']]\ny = train_dup['count']\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression \n\nstd_reg = LinearRegression()\nstd_reg.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r2_train = std_reg.score(X_train,y_train)\nr2_test = std_reg.score(X_test,y_test)\nprint('R Squared Error for Train set:',r2_train)\nprint('R Squared Error for Test set:',r2_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}