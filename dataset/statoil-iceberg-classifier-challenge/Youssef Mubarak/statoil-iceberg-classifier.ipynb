{"cells":[{"metadata":{"_uuid":"66d91da31805f0ccfb3bbac4bdbbb6dbd12de81b"},"cell_type":"markdown","source":"\n\n# Statoil/C-CORE Iceberg Classifier\n\n![cover](https://drive.google.com/uc?export=view&id=1QdSEwYcw0NCXiUflW45ehWiULtD38Tpy)\n\n## Motivation\nDrifting icebergs present threats to navigation and activities in areas such as offshore of the East Coast of Canada.\n\nCurrently, many institutions and companies use aerial reconnaissance and shore-based support to monitor environmental conditions and assess risks from icebergs. However, in remote areas with particularly harsh weather, these methods are not feasible, and the only viable monitoring option is via satellite.\n\n## Goal\nStatoil, an international energy company operating worldwide, has worked closely with companies like C-CORE. C-CORE have been using satellite data for over 30 years and have built a computer vision based surveillance system. To keep operations safe and efficient, Statoil is interested in getting a fresh new perspective on how to use machine learning to more accurately detect and discriminate against threatening icebergs as early as possible.\n\nIn this project we are going to build an algorithm that automatically identifies if a remotely sensed target is a ship or iceberg. Improvements made will help drive the costs down for maintaining safe working conditions."},{"metadata":{"_uuid":"da18658dd7dd6f68388edf4d34e1aa5996bbcf3b"},"cell_type":"markdown","source":"# Data Explortion"},{"metadata":{"_uuid":"f270c2b4ceab0d8847ce7365fbd2694f74627ba8"},"cell_type":"markdown","source":"Dataset found in: `train.json`, `test.json`  \nThe data (`train.json`, `test.json`) is presented in json format.  \nThe training data has 1603 data points, where the testing 8424  data has data points."},{"metadata":{"_uuid":"8899eca3be53e5a9ed6efb02abca51238c99806c"},"cell_type":"markdown","source":"## Data fields\n\n\nThe files consist of a list of images, and for each image, you can find the following fields:\n\n- **id** - the id of the image  \n- **band_1, band_2** - the flattened image data. Each band has 75x75 pixel values in the list, so the list has 5625 elements. Note that these values are not the normal non-negative integers in image files since they have physical meanings - these are float numbers with unit being dB. Band 1 and Band 2 are signals characterized by radar backscatter produced from different polarizations at a particular incidence angle. The polarizations correspond to HH (transmit/receive horizontally) and HV (transmit horizontally and receive vertically). More background on the satellite imagery can be found here.  \n- **inc_angle** - the incidence angle of which the image was taken. Note that this field has missing data marked as \"na\", and those images with \"na\" incidence angles are all in the training data to prevent leakage.  \n- **is_iceberg** - the target variable, set to 1 if it is an iceberg, and 0 if it is a ship. This field only exists in train.json.\n"},{"metadata":{"_uuid":"42a433ca831591965033a8434e58f43cf14b98fa"},"cell_type":"markdown","source":"# Getting Started"},{"metadata":{"_uuid":"27fbb7bc13286d6a237e97d95d12b5c380c170f3","trusted":false},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2                \nimport matplotlib.pyplot as plt\nimport itertools\n\nfrom sklearn.model_selection  import train_test_split\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, accuracy_score, roc_curve, auc\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, GlobalMaxPooling2D\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam, SGD\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":false,"_kg_hide-output":false,"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true},"cell_type":"markdown","source":"## Loading Data"},{"metadata":{"_uuid":"50d56130746b728da16289e6f15fb86e57cd7aeb","trusted":false},"cell_type":"code","source":"# classes\nclasses = ['Ship', 'Iceberg']\nclasses_dict = {0:'Ship', 1:'Iceberg'}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cee5c8eee0ae0d99ec335c92808c81e083f8b0b","trusted":false},"cell_type":"code","source":"train = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/train.json\")\nprint(\"Training data shape:\", train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0b847666984a63fa5c60c7277960054d4a04b2a2","trusted":false},"cell_type":"code","source":"test = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/test.json\")\nprint(\"Testing data shape:\", test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3a4201362e09eecaec5236215a1f185fce4277f"},"cell_type":"markdown","source":"## Data Distribution (training data)"},{"metadata":{"_uuid":"2919e5d5748a6e9e3d3df27bf78e4774eebd6ebe","scrolled":false,"trusted":false},"cell_type":"code","source":"dt = pd.value_counts(train['is_iceberg'], ascending=True)\nprint(dt)\n# convert class id to class name\ndt.index = dt.index.map(classes_dict)\ndt.plot.bar(title=\"Number of instances per Category\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ebcd3940a7ff669d7519df79c88981a0747a0ff9"},"cell_type":"markdown","source":"## Viewing Sample Data"},{"metadata":{"_uuid":"5e4118db854ae16f10ca79c4ccaf06411a3a8b59","trusted":false},"cell_type":"code","source":"# get random samples\nsamlples_num = 3\niceberg_samples = train[train.is_iceberg==1].sample(n=samlples_num)\nships_samples = train[train.is_iceberg==0].sample(n=samlples_num)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a244b6f2e620b10e4a3aacf27bef878a2799525","trusted":false},"cell_type":"code","source":"def plot_bands(imgs):\n    # Plot band_1\n    fig = plt.figure(1,figsize=(15,15))\n    for i in range(samlples_num):\n        ax = fig.add_subplot(1,samlples_num,i+1)\n        img_band1 = np.reshape(np.array(imgs.iloc[i,0]),(75,75))\n        categ = 'iceberg' if imgs['is_iceberg'].iloc[0]==1 else 'ship'\n        plt.title('band_1: ' + categ)\n        ax.imshow(img_band1)\n\n    # Plot band_2\n    plt.show()\n    fig = plt.figure(1,figsize=(15,15))\n    for i in range(samlples_num):\n        ax2 = fig.add_subplot(2,samlples_num,i+1)\n        img_band2 = np.reshape(np.array(imgs.iloc[i,1]),(75,75))\n        plt.title('band_2: ' + categ)\n        ax2.imshow(img_band2)\n\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2613f7457ee702518973a26610eefe6025aeae39","trusted":false},"cell_type":"code","source":"plot_bands(iceberg_samples)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"75b11a3aa8bf3479fa189b7a98c028d5eb21e605","trusted":false},"cell_type":"code","source":"plot_bands(ships_samples)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8661bc238466c3758846e869f6fdcf5b97a1f7b2"},"cell_type":"markdown","source":"As we can see, in some examples it's hard to tell if it's a ship or an iceberg."},{"metadata":{"_uuid":"ada951e43cd1bb114fd591780d99f1996e9941b2"},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"_uuid":"b524aeb6165212c1567fbc3cc0b482779082118b"},"cell_type":"markdown","source":"## Handling missing values"},{"metadata":{"_uuid":"6cdea00daa3cc7e16a1b120b09e39c279a562516","trusted":false},"cell_type":"code","source":"missing_values = (train['inc_angle'] == 'na').sum()\npercentage = missing_values*100/len(train)\nprint(\"Number of missing values in 'inc_angle':\", missing_values)\nprint(\"Percentage: {:.2}%:\".format(percentage))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2138c8302e1a739d379275546e7ff49ff420ed16"},"cell_type":"markdown","source":"As there were 133 missing data in `inc_angle` out of 1604 entris (that is 8.3% of data) where the other columns had no missing values, we will exclude this field."},{"metadata":{"_uuid":"d76e1f25de223eed36fbbf105a6ee6addd8f0686","trusted":false},"cell_type":"code","source":"train.drop(['inc_angle'], axis=1, inplace=True)\n# view train data\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64e5f4be2c3f1096c3a98fe004480e64c6580f61"},"cell_type":"markdown","source":"## Combining Data: Concatenating bands"},{"metadata":{"_uuid":"7055e968174c0e08375e7c266349ed06f41a247c","trusted":false},"cell_type":"code","source":"# Training data\ntrain_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\ntrain_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n\ntrain_features = np.concatenate([train_band_1[:, :, :, np.newaxis],\n                                 train_band_2[:, :, :, np.newaxis]], axis=-1)\ntrain_target = np.array(train[\"is_iceberg\"])\n\nprint(\"Features shape:\", train_features.shape)\nprint(\"Target shape:\", train_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"908f4e8b566b3a540ee67b86f698aac3ad27adc9","trusted":false},"cell_type":"code","source":"# Testing data\ntest_band_1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\ntest_band_2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\n\ntest_features = np.concatenate([test_band_1[:, :, :, np.newaxis],\n                                test_band_2[:, :, :, np.newaxis]], axis=-1)\nprint(\"Features shape:\", test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"61d0c58823e43ca92ca6a96446e06304fd1ff69c"},"cell_type":"markdown","source":"# Dimensionality Reduction With PCA"},{"metadata":{"_uuid":"862a9314fa7b17e53af7221d7ed8ef9be02a7e17","trusted":false},"cell_type":"code","source":"scaler = StandardScaler()\nimages_scaled = scaler.fit_transform([i.flatten() for i in train_features])\n\npca = PCA(n_components=50)\npca_result = pca.fit_transform(images_scaled)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a4c6526fffe0bcb1d7e8c834ebb00aac6ad4b6c","trusted":false},"cell_type":"code","source":"reduced_X_train, reduced_X_test, reduced_y_train, reduced_y_test = train_test_split(pca_result,\n                                                                train_target, \n                                                                test_size=0.25, \n                                                                random_state=42)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e26bf33db360f6e7ed5f9905c005ce864fd018b"},"cell_type":"markdown","source":" # Using (RandomForest, K-NN, Logistic Regression)"},{"metadata":{"_uuid":"a26a872d80ecf5e1c4f567df486fa81c40665173"},"cell_type":"markdown","source":"## Using Random Forest Classifier"},{"metadata":{"_uuid":"b9a52d44767343fb5b86f290cadc8a38bdf7da4c","trusted":false},"cell_type":"code","source":"forest = RandomForestClassifier(n_estimators=50)\nforest = forest.fit(reduced_X_train, reduced_y_train)\n\n## Making Predctions\ntest_predictions = forest.predict(reduced_X_test)\nprecision = accuracy_score(test_predictions, reduced_y_test) * 100\nprint(\"Accuracy with Random Forest: {0:.4f}\".format(precision))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"093ccd67b4907788dcb08626bbb08e18a7115314"},"cell_type":"markdown","source":"## Using K-NN"},{"metadata":{"_uuid":"0e818b759d397f2583f544df071f1cdfa43c77db","trusted":false},"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors=20)\nknn = knn.fit(reduced_X_train, reduced_y_train)\n\n## Making Predctions\ntest_predictions = knn.predict(reduced_X_test)\nprecision = accuracy_score(test_predictions, reduced_y_test) * 100\nprint(\"Accuracy with K-NN: {0:.4f}\".format(precision))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"933810d1816bb610e26701ce50f637125b699f3f"},"cell_type":"markdown","source":"## Using Logistic Regression"},{"metadata":{"_uuid":"f6ebc73e44aa9e04151c8648b0d5f50a2938e48f","trusted":false},"cell_type":"code","source":"lr = LogisticRegression(random_state=20, solver='lbfgs')\nlr = lr.fit(reduced_X_train, reduced_y_train)\n\n## Making Predctions\ntest_predictions = lr.predict(reduced_X_test)\nprecision = accuracy_score(test_predictions, reduced_y_test) * 100\nprint(\"Accuracy with Logistic Regression: {0:.4f}\".format(precision))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5103bb0aa3e25898fd93f4f44b1b68045295db51"},"cell_type":"markdown","source":"ِAs we can see, the previous methods don't result more than 79% accuracy."},{"metadata":{"_uuid":"dd259eaa458b6e2a571cd0796c2a0aa0f59a1540"},"cell_type":"markdown","source":"## Split Data ( training data)"},{"metadata":{"_uuid":"cfb109bfc9c90142d7304570dcfcdb9dfd27c39e","trusted":false},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(train_features,\n                                                    train_target,\n                                                    test_size=0.25,\n                                                    random_state=7)\n\nprint(\"Total size of dataset:\", len(train_features))\nprint(\"Size of training set:\", len(X_train))\nprint(\"Size of testing set:\", len(X_test))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9e29108dc37285d880bb9a79cbbf6eb17af7a83f"},"cell_type":"markdown","source":"# Benchmark Model"},{"metadata":{"_uuid":"ad57df3dd9650a78f1404f1295388becba5fa9b2","scrolled":true,"trusted":false},"cell_type":"code","source":"# define parameters\ninput_shape = X_train[0].shape\n\ndef get_basic_model(input_shape=(75, 75, 2)):\n    # Model Archeticture\n    basic_model = Sequential()\n    # Input layer\n    basic_model.add(Conv2D(32, 3, activation=\"relu\", input_shape=input_shape))\n    basic_model.add(Conv2D(64, 3, activation=\"relu\"))\n    basic_model.add(GlobalAveragePooling2D())\n    basic_model.add(Dropout(0.3))\n    # output layer\n    basic_model.add(Dense(1, activation=\"sigmoid\"))\n    return basic_model\n\nbasic_model = get_basic_model()\n# print model summary\nprint('X_train shape:', X_train.shape)\nprint(X_train.shape[0], 'training samples')\nbasic_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"54e858f6585df6d0a06a46f567394ca48ce03bb3"},"cell_type":"markdown","source":"## Compile model"},{"metadata":{"_uuid":"57720ee7ba8a49fd704a16742ad64fc2aaa3cb69","trusted":false},"cell_type":"code","source":"# compiling model with binary_crossentropy loss function\nbasic_model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d4dbefe4a8f2e48ffc25a3cdb21b80076d6d23cd"},"cell_type":"markdown","source":"## Calculate the Classification Accuracy on the Test Set (Before Training)"},{"metadata":{"_uuid":"85065879751bb0193ecaf49e34f45b66dcfc90c5","trusted":true},"cell_type":"code","source":"# evaluate test accuracy\ndef print_accuracy(model, test_features=X_test, test_target=y_test):\n    score = model.evaluate(test_features, test_target, verbose=0)\n    accuracy = 100*score[1]\n    # print test accuracy\n    print('Test accuracy: %.4f%%' % accuracy)\n    print('Test loss: {:0.4}'.format(score[0]))\n    return accuracy\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"403ddc0ec5eff6abff73042e22ba96162c51b63d","trusted":false},"cell_type":"code","source":"print_accuracy(basic_model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de718b4124e6c2c8f972411fa98ce66e15ed4e88"},"cell_type":"markdown","source":"## Model Training (model 1)"},{"metadata":{"_uuid":"74c93ee4ed1706435fe7c88b381fa1a83305a073","scrolled":true,"trusted":false},"cell_type":"code","source":"# train the model\ndef train_with_kfold(model, checkpoint_path,epochs=50, K=4,batch_size=None):\n    history = None\n    folds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=7).split(X_train, y_train))\n    for i, (train_index, test_index) in enumerate(folds):\n        print('\\nFOLD:',i+1)\n        # saving each fold's results (weights) as its own checkpoint \n        checkpointer = ModelCheckpoint(filepath= str(i+1)+ \"_\" + checkpoint_path,\n                               verbose=1, save_best_only=True)\n        # getting data folds\n        X_train_fold, X_test_fold = X_train[train_index], X_train[test_index]\n        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n        h = model.fit(X_train_fold, y_train_fold,\n                                   epochs=epochs,\n                                   validation_data=(X_test_fold, y_test_fold),\n                                   callbacks=[checkpointer],\n                                   shuffle=True,\n                                   batch_size=batch_size)\n        # concatenating model histories over subsequent folds\n        if history is None:\n            history = h\n        else:\n            history.history['acc'].extend(h.history['acc'])\n            history.history['val_acc'].extend(h.history['val_acc'])\n            history.history['loss'].extend(h.history['loss'])\n            history.history['val_loss'].extend(h.history['val_loss'])\n    \n    return history\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"56be3306d194a278c475bb2d6ade26c46867bf47","scrolled":true,"trusted":false},"cell_type":"code","source":"# train model\nhistory_1 = train_with_kfold(basic_model, 'basic.model.best.hdf5', epochs=150, K=2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"613646b6d8b2be4cf2530eed5b6f8810bcd96318"},"cell_type":"markdown","source":"## Model Evaluation (model 1)"},{"metadata":{"_uuid":"82085ec457a434be05fe676cfb879d35262c1b96"},"cell_type":"markdown","source":"### Calculate the Classification Accuracy on the Test Set"},{"metadata":{"_uuid":"aa75434908ec437793c3ceea11eede7125135e53","scrolled":false,"trusted":true},"cell_type":"code","source":"best =-1\nprint(\"Fold 1\")\nbasic_model.load_weights('1_basic.model.best.hdf5')\nacc = print_accuracy(basic_model)\nif acc > best:\n    best =1\nprint(\"\\nFold 2\")\nbasic_model.load_weights('2_basic.model.best.hdf5')\nacc = print_accuracy(basic_model)\nif acc > best:\n    best =2","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf1129118e6f38139edb9d06087f40fa289283e8","trusted":true},"cell_type":"code","source":"# load best weights\nbasic_model.load_weights(str(best) + '_basic.model.best.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df882d9e952a7aa5412c25d90bce7b27c3c134ed"},"cell_type":"markdown","source":"### Confusion Matrix"},{"metadata":{"_uuid":"5f0b9ac896f4c698a2ff91fe014205a7cadafe3e","trusted":false},"cell_type":"code","source":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        #print(\"Normalized confusion matrix\")\n    else:\n        pass#print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e191cdcad8106b30072f568cccb17a2a19cb29d3","trusted":false},"cell_type":"code","source":"# get predictions\ny_pred = basic_model.predict(X_test)\nfunc = lambda x: 1 if x >= 0.5 else 0\ny_pred_classes = np.array(list(map(func, y_pred)))\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred_classes)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='Confusion matrix, without normalization')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8cc829b12ee7957a02b6910471d59af5bc861888"},"cell_type":"markdown","source":"### Classification Report"},{"metadata":{"_uuid":"cb6fb8b23b119f5c7ca0aad2f0448915c400fec3","trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred_classes, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7cf7f7092c767aca49bfe264c1ff24846d7a1782"},"cell_type":"markdown","source":"### Model History"},{"metadata":{"_uuid":"8a2695ce638a91aa44a568efc0feb88fc5c1e6fb","scrolled":false,"trusted":false},"cell_type":"code","source":"def plot_history(history):\n    # list all data in history\n    #print(history.history.keys())\n    # summarize history for accuracy\n    plt.plot(history.history['acc'])\n    plt.plot(history.history['val_acc'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"235563fefc7081f268149beb58363d547c562000","scrolled":false,"trusted":false},"cell_type":"code","source":"plot_history(history_1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f488fd302424cfb76af39e646836e23bfee8f3fa"},"cell_type":"markdown","source":"# Refining Basic Model"},{"metadata":{"_uuid":"dc2140b3213fb5a3de73bafb43d22d3feced8e58","trusted":false},"cell_type":"code","source":"refined_model = get_basic_model()\nrefined_model.compile(\"adam\", \"binary_crossentropy\", metrics=[\"accuracy\"])\n# train model\nhistory_1_V2 = train_with_kfold(refined_model, 'refined.model.best.hdf5', epochs=250, K=4)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"429afc07da58984d37e849d1eac5e32a1406f2a2"},"cell_type":"markdown","source":"## Model Evaluation"},{"metadata":{"_uuid":"c09c1486af9e13b1d3d23f9ed4f5f142ebf64ca7","trusted":true},"cell_type":"code","source":"best = -1\nprint(\"Fold 1\")\nrefined_model.load_weights('1_refined.model.best.hdf5')\nacc = print_accuracy(refined_model)\nif acc > best:\n    best = 1\nprint(\"\\nFold 2\")\nrefined_model.load_weights('2_refined.model.best.hdf5')\nacc = print_accuracy(refined_model)\nif acc > best:\n    best =2\nprint(\"\\nFold 3\")\nrefined_model.load_weights('3_refined.model.best.hdf5')\nacc = print_accuracy(refined_model)\nif acc > best:\n    best =3\nprint(\"\\nFold 4\")\nrefined_model.load_weights('4_refined.model.best.hdf5')\nacc = print_accuracy(refined_model)\n\nif acc > best:\n    best =4","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"882739203c4cf886c3d84e098332c5efcc5730d8","trusted":true},"cell_type":"code","source":"# load best weights\nrefined_model.load_weights(str(best) + '_refined.model.best.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d19e0862ddd0f7cda5fab5345110a1d6d17e40e0","trusted":false},"cell_type":"code","source":"# get predictions\ny_pred = refined_model.predict(X_test)\nfunc = lambda x: 1 if x >= 0.5 else 0\ny_pred_classes = np.array(list(map(func, y_pred)))\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred_classes)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='Confusion matrix, without normalization')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"95150c2721ab23e290b39b0a52909d5c82975691","trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred_classes, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58a6b4c7366ac6a06c2b82c2e706e762bc3ccd08","trusted":false},"cell_type":"code","source":"plot_history(history_1_V2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"10ebea46cae690369d7c8f14bdcf36ef7ce24903"},"cell_type":"markdown","source":"# Improved Model"},{"metadata":{"_uuid":"cbfceb856d1bd2ed3c13167aa4b473acb9b7ec7c","trusted":false},"cell_type":"code","source":"def get_improved_model(input_shape=(75,75,2)):\n    # create the model and define the architecture.\n    improved_model = Sequential()\n    #\n    improved_model.add(Conv2D(filters=64, kernel_size=(3,3), padding='same',\n                             activation='relu', input_shape=input_shape))\n    improved_model.add(MaxPooling2D(pool_size=2))\n    \n    improved_model.add(Conv2D(filters=128, kernel_size=2, padding='same', activation='relu'))\n    improved_model.add(MaxPooling2D(pool_size=2))\n    \n    improved_model.add(Conv2D(filters=256, kernel_size=2, padding='same', activation='relu'))\n    improved_model.add(MaxPooling2D(pool_size=2))\n    \n    improved_model.add(Conv2D(filters=512, kernel_size=2, padding='same', activation='relu'))\n    improved_model.add(MaxPooling2D(pool_size=2))\n    \n    improved_model.add(Dropout(0.3))\n    improved_model.add(Flatten())\n    improved_model.add(Dropout(0.5))\n    # output layer\n    improved_model.add(Dense(1, activation='sigmoid'))\n    return improved_model\n\nimproved_model = get_improved_model()\n\n# print model summary\nprint('X_train shape:', X_train.shape)\nprint(X_train.shape[0], 'training samples')\nimproved_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"02e2a07305a8df8768bf1dcd52001c7e40767480"},"cell_type":"markdown","source":"## Compile model"},{"metadata":{"_uuid":"63152f162de4a8e81d1113f3772812e9233f16e7","trusted":false},"cell_type":"code","source":"# compiling model with binary_crossentropy loss function\noptimizer = Adam(lr=1e-4)\nimproved_model.compile(optimizer=optimizer, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b99df294ae9214741983a41bfa78475dae88d67c"},"cell_type":"markdown","source":"## Calculate the Classification Accuracy on the Test Set (Before Training)"},{"metadata":{"_uuid":"d24997b2d165abca7c8de5e8d710c1c6839a2309","trusted":false},"cell_type":"code","source":"# evaluate test accuracy\nprint_accuracy(improved_model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ed6bff78169704aa9253e4b99c281d35b492a68a"},"cell_type":"markdown","source":"## Model Training (model 2)"},{"metadata":{"_uuid":"8b7aa84782551a9205bdd2fdcf5058223dcb826b","scrolled":true,"trusted":false},"cell_type":"code","source":"# train the model\nhistory_2 = train_with_kfold(improved_model, 'improved.model.best.hdf5', epochs=50, K=3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ce6ac31f9cabfa2f50dd575b335209ca468e82a8"},"cell_type":"markdown","source":"## Model Evaluation (model 2)"},{"metadata":{"_uuid":"f6fea7f5b025c49594b95b2cc1faa5f90d17a4a9","trusted":true},"cell_type":"code","source":"best = -1\nprint(\"Fold 1\")\nimproved_model.load_weights('1_improved.model.best.hdf5')\nacc = print_accuracy(improved_model)\nif acc > best:\n    best = 1\nprint(\"\\nFold 2\")\nimproved_model.load_weights('2_improved.model.best.hdf5')\nacc = print_accuracy(improved_model)\nif acc > best:\n    best = 2\nprint(\"\\nFold 3\")\nimproved_model.load_weights('3_improved.model.best.hdf5')\nacc = print_accuracy(improved_model)\nif acc > best:\n    best = 3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f1ca3effa9947079e3e748178e936c8267a07ebb","trusted":true},"cell_type":"code","source":"# load best weights\nimproved_model.load_weights( str(best) + '_improved.model.best.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3c7a79c1fa21a5f18c4bab442c4e970227a750aa","trusted":false},"cell_type":"code","source":"# get predictions\ny_pred = improved_model.predict(X_test)\nfunc = lambda x: 1 if x >= 0.5 else 0\ny_pred_classes = np.array(list(map(func, y_pred)))\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred_classes)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='Confusion matrix, without normalization')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8c9d6be279a2e1fd8b6d395a679487babeb0ea14","trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred_classes, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5124364d195fd1c9b288eb556ded528c07e4e347","scrolled":false,"trusted":false},"cell_type":"code","source":"#\nplot_history(history_2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e57577ca251ac067f05ba5ef72d270c02144a5aa"},"cell_type":"markdown","source":"## Best  aquired weights for this model"},{"metadata":{"_uuid":"67e95773cada2938f47356847259d2d3bf8d41b9","trusted":false},"cell_type":"code","source":"# load best acquired models\nimproved_model.load_weights('../input/statoil-model-weights/pretrained.best.hdf5')\n# evaluate test accuracy\nprint_accuracy(improved_model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe91125e6359473f799230e08a4bdb238c58de10","trusted":false},"cell_type":"code","source":"# get predictions\ny_pred = improved_model.predict(X_test)\nfunc = lambda x: 1 if x >= 0.5 else 0\ny_pred_classes = np.array(list(map(func, y_pred)))\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred_classes)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='Confusion matrix, without normalization')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b8d91d0a073b2e02b2fa21f267c5efc47f490e8c","trusted":false},"cell_type":"code","source":"print(classification_report(y_test, y_pred_classes, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0465b435f126b0cb921a87e0e1d17110d05ad9e"},"cell_type":"markdown","source":"## Make A Submission File (model 2)"},{"metadata":{"_uuid":"c94049a870ceb38789f269be2e312a41a00d3579","scrolled":true,"trusted":false},"cell_type":"code","source":"# get predictions of testing data\nprediction = improved_model.predict(test_features, verbose=1)\n\nsubmission= pd.DataFrame({'id': test[\"id\"], 'is_iceberg': prediction.flatten()})\nsubmission.to_csv(\"../working/improved_model_submission.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2de1bcd47975889efab3490ed5e9f59d892c7928"},"cell_type":"markdown","source":"# Transfer Learning + Data Augmentation"},{"metadata":{"_uuid":"dd61ba14bf33e1edb5cd54b6e16c436a8df02914"},"cell_type":"markdown","source":"## Reshaping data: adding a third channel to images"},{"metadata":{"_uuid":"f65da8dc84e9f7efa88f2997b4edec0230803ce6","trusted":false},"cell_type":"code","source":"\ntrain_band_3 =(train_band_1+train_band_2)/2\nmod_train_features = np.concatenate([train_band_1[:, :, :, np.newaxis]\n                          , train_band_2[:, :, :, np.newaxis]\n                         , train_band_3[:, :, :, np.newaxis]], axis=-1)\n\nprint(\"Reshaped features:\", mod_train_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"57830930dfc78dbe4ff611091b8d0e45ceba2214","trusted":false},"cell_type":"code","source":"test_band_3 =(test_band_1+test_band_2)/2\nmod_test_features = np.concatenate([test_band_1[:, :, :, np.newaxis],\n                            test_band_2[:, :, :, np.newaxis],\n                            test_band_3[:, :, :, np.newaxis]], \n                            axis=-1)\n\nprint(\"Reshaped features:\", mod_test_features.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a34ef63cfc10999cbcac8c90f1296fb9d8727c84"},"cell_type":"markdown","source":"## Split Data"},{"metadata":{"_uuid":"4d6c4234cc5270459e4bbb951f93d30bf7655921","trusted":false},"cell_type":"code","source":"mod_X_train, mod_X_test, mod_y_train, mod_y_test = train_test_split(mod_train_features,\n                                                    train_target,\n                                                    test_size=0.25,\n                                                    random_state=7)\n\nprint(\"Total size of dataset:\", len(mod_train_features))\nprint(\"Size of training set:\", len(mod_X_train))\nprint(\"Size of testing set:\", len(mod_X_test))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"62e3fa6cb5583f2dd5f68a08a70a52ee87ce7c9f"},"cell_type":"markdown","source":"## Importing VGG16 model"},{"metadata":{"_uuid":"88840e573b57a5739ba0b8636b2da786a6542e68","scrolled":true,"trusted":false},"cell_type":"code","source":"from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n\n# VGG16 model\nVGG16_model = VGG16(weights='imagenet', include_top=False, input_shape=mod_train_features.shape[1:])\n#\nprint(\"Number of Layers:\", len(VGG16_model.layers))\nVGG16_model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"abd88da2f61460e43eddcfa5272c90d470258fef"},"cell_type":"markdown","source":"## Modified VGG16 model (model 3)"},{"metadata":{"_uuid":"d4552def88765279ab2510f4ce90fcaf940a8ac5","trusted":false},"cell_type":"code","source":"from keras.layers import concatenate\nfrom keras.models import Model\n\ndef get_modified_VGG16():\n    # Create new modified model from VGG16\n    model = VGG16_model.get_layer('block5_pool').output\n    model = GlobalMaxPooling2D()(model)\n    model = Dropout(0.5)(model)\n    predictions = Dense(1, activation='sigmoid')(model)\n    model = Model(input=[VGG16_model.input], output=predictions)\n\n    return model\n\n\nmodified_VGG16 = get_modified_VGG16()\nprint (\"Model Layers: \", len(modified_VGG16.layers))\nmodified_VGG16.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"968005fb6323184aa10ceed1d18db9fc71287a2a"},"cell_type":"markdown","source":"## Compile model"},{"metadata":{"_uuid":"7fa03f5bfe95adc77206a456c2cb82d7144cd33d","trusted":false},"cell_type":"code","source":"from keras.optimizers import Adam\nlearing_rate = 1e-4\n#decay = 1e-6\nadam_opt = Adam(lr=learing_rate)\n# compiling model with binary_crossentropy loss function\nmodified_VGG16.compile(optimizer=adam_opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e986f0d587ed5ef78eef236278f588de430498d1"},"cell_type":"markdown","source":"## Calculate the Classification Accuracy on the Test Set (Before Training)"},{"metadata":{"_uuid":"3e2cd77d95b60f68127ae5474d7a535cfd968acc","scrolled":true,"trusted":false},"cell_type":"code","source":"# evaluate test accuracy\nprint_accuracy(modified_VGG16, test_features=mod_X_test,test_target=mod_y_test)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3d6bd226136eebada0854f5fb04ea3b05b1c890d"},"cell_type":"markdown","source":"## Data Augmentaion"},{"metadata":{"_uuid":"eeab9b97f3e52ccd09b00f0bea889514e53cbd85","trusted":false},"cell_type":"code","source":"from keras.preprocessing import image\n\n# create data generator\ndatagen_train = image.ImageDataGenerator(\n    rotation_range=10,\n    width_shift_range=0.1,\n    height_shift_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True)\n\n\ndatagen_train.fit(mod_X_train, augment=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d88fe6d922bfba58b01b408ba66cde5fb2e34e26"},"cell_type":"markdown","source":"## Model Training (model 3)"},{"metadata":{"_uuid":"9a51bbee51ce9ab585a33819c58c577f9aadd4bb","scrolled":true,"trusted":false},"cell_type":"code","source":"# train the model\nK = 3\nepochs = 40\nhistory = None\nfolds = list(StratifiedKFold(n_splits=K, shuffle=True, random_state=7).split(mod_X_train, mod_y_train))\nfor i, (train_index, test_index) in enumerate(folds):\n    print('\\nFOLD:',i+1)\n    checkpointer = ModelCheckpoint(filepath= str(i+1) + \"_\" + 'transln.model.best.hdf5',\n                                   verbose=1,\n                                   save_best_only=True)\n    X_train_fold, X_test_fold = mod_X_train[train_index], mod_X_train[test_index]\n    y_train_fold, y_test_fold = mod_y_train[train_index], mod_y_train[test_index]\n    batch_size = 32\n    train_generator = datagen_train.flow(\n        X_train_fold,\n        y_train_fold,\n        batch_size=batch_size)\n    \n    h = modified_VGG16.fit_generator(train_generator,\n                    steps_per_epoch=X_train_fold.shape[0] // batch_size,\n                    epochs=epochs, verbose=1, callbacks=[checkpointer],\n                    validation_data=(X_test_fold, y_test_fold),\n                    shuffle=True)\n    if history is None:\n        history = h\n    else:\n        history.history['acc'].extend(h.history['acc'])\n        history.history['val_acc'].extend(h.history['val_acc'])\n        history.history['loss'].extend(h.history['loss'])\n        history.history['val_loss'].extend(h.history['val_loss'])\n\n#\nhistory_3 = history","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8b4096e43f6520fc9bd9b07f3047cf67c42c91b"},"cell_type":"markdown","source":"## Model Evaluation (model 3)"},{"metadata":{"_uuid":"a9f730bded30dcebb913332e8fb66ddb1d2a69d1","trusted":true},"cell_type":"code","source":"# evaluate test accuracy\nbest = -1\nprint(\"Fold 1\")\nmodified_VGG16.load_weights('1_transln.model.best.hdf5')\nacc = print_accuracy(modified_VGG16, test_features=mod_X_test,test_target=mod_y_test)\nif acc > best:\n    best = 1\nprint(\"\\nFold 2\")\nmodified_VGG16.load_weights('2_transln.model.best.hdf5')\nacc = print_accuracy(modified_VGG16, test_features=mod_X_test,test_target=mod_y_test)\nif acc > best\n    best = 2\nprint(\"\\nFold 3\")\nmodified_VGG16.load_weights('3_transln.model.best.hdf5')\nacc = print_accuracy(modified_VGG16, test_features=mod_X_test,test_target=mod_y_test)\nif acc > best:\n    best = 3","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f348f47544855f81cb66eeb4a6d0eff7d6b199b8","trusted":true},"cell_type":"code","source":"# load best weights\nmodified_VGG16.load_weights(str(best) + '_transln.model.best.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1b95655a27ad26e96954bc153522e25766bdc9ac","trusted":false},"cell_type":"code","source":"# get predictions\ny_pred = modified_VGG16.predict(mod_X_test)\nfunc = lambda x: 1 if x >= 0.5 else 0\ny_pred_classes = np.array(list(map(func, y_pred)))\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(mod_y_test, y_pred_classes)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='Confusion matrix, without normalization')\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e2e497f041617f166afa1ca783ca2dc12a70c8c","trusted":false},"cell_type":"code","source":"print(classification_report(mod_y_test, y_pred_classes, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7c3a8c6d1f844749d9d2bef685d9d51cdd2d6d50","trusted":false},"cell_type":"code","source":"plot_history(history_3)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c1874feab7c6436ec27fed7e8d93f70a56ae572e"},"cell_type":"markdown","source":"## Make A Submission (model 3)"},{"metadata":{"_uuid":"33c1b11ea171a4aebb8d9f0cafb7298d61aa6449","trusted":false},"cell_type":"code","source":"# make predictions of testing data\nprediction = modified_VGG16.predict(mod_test_features, verbose=1)\n\nsubmission= pd.DataFrame({'id': test[\"id\"], 'is_iceberg': prediction.flatten()})\nsubmission.to_csv(\"../working/tl_submission.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71b1ede0de0a2c3115f1867e10fb82d4a837cb83"},"cell_type":"markdown","source":"# Semi-Supervised approach: Pseudo Labelling"},{"metadata":{"_uuid":"39f9f43ec6d083bd34e85ce51d5c1f1cce49bd0a","trusted":false},"cell_type":"code","source":"# set the best model\nbest_model = improved_model\nprint_accuracy(best_model)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f054b9d2538975027418620946ead0c97f095b60","trusted":false},"cell_type":"code","source":"portion_size =int(1.5 * len(X_train)) # (that's 21.4% of the testing set)\ntest_features_portion = test_features[:portion_size,:,:,:]\n\n# get labels of test data portion\ny_pred = best_model.predict(test_features_portion)\nfunc = lambda x: 1 if x >= 0.5 else 0\ntest_target_portion = np.array(list(map(func, y_pred)))\n\n# setting new data\nnew_features = np.concatenate((X_train,test_features_portion),axis=0)\nnew_target = np.concatenate((y_train,test_target_portion),axis=0)\n\nprint(\"% of test portion size: {:0.4}%\".format(100*portion_size/len(test_features)))\nprint(\"Shape of Features\", new_features.shape)\nprint(\"Shape of Target\", new_target.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d00124b91550d3e0f123022f82af34dbcda4c623","trusted":false},"cell_type":"code","source":"# splitting data into training and testing sets\nnew_X_train, new_X_test, new_y_train, new_y_test = train_test_split(new_features,\n                                                                    new_target,\n                                                                    test_size=0.25,\n                                                                    random_state=5)\nprint(\"Total size of dataset:\", len(new_features))\nprint(\"Size of training set:\", len(new_X_train))\nprint(\"Size of testing set:\", len(new_X_test))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ac9623b1b78ca85db504ab3eabffdc92eeb9fe97"},"cell_type":"markdown","source":"## Model Training (Model 4)"},{"metadata":{"_uuid":"bb2487dc207fbf5b9aec786a7c2eb0810e7943f1","trusted":false},"cell_type":"code","source":"# recompile the model with a new learning rate\nopt = Adam(lr=1e-4)\nbest_model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3e00b573da058fa28cd20edaadbc698f73c1d17d","scrolled":true,"trusted":false},"cell_type":"code","source":"K = 3\nepochs = 50\n# train the model\nX_train = new_X_train\ny_train = new_y_train\n\nhistory_4 = train_with_kfold(best_model, 'pseudo.labeled.model.best.hdf5', epochs=epochs, K=K)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"358997b226091795e265017612a67ab02fb25388"},"cell_type":"markdown","source":"## Model Evaluation (Model 4)"},{"metadata":{"_uuid":"3bb23378d62822248750fbeab11666824f2fb558","trusted":false},"cell_type":"code","source":"# evaluate test accuracy\nprint(\"Fold 1\")\nbest_model.load_weights('1_pseudo.labeled.model.best.hdf5')\nprint('For the new test set:')\nprint_accuracy(best_model, test_features=new_X_test,test_target=new_y_test)\nprint('\\nFor the old test set:')\nprint_accuracy(best_model, test_features=X_test,test_target=y_test)\nprint(\"----------------------\\n\")\nprint(\"Fold 2\")\nbest_model.load_weights('2_pseudo.labeled.model.best.hdf5')\nprint('For the new test set:')\nprint_accuracy(best_model, test_features=new_X_test,test_target=new_y_test)\nprint('\\nFor the old test set:')\nprint_accuracy(best_model, test_features=X_test,test_target=y_test)\nprint(\"----------------------\\n\")\nprint(\"Fold 3\")\nbest_model.load_weights('3_pseudo.labeled.model.best.hdf5')\nprint('For the new test set:')\nprint_accuracy(best_model, test_features=new_X_test,test_target=new_y_test)\nprint('\\nFor the old test set:')\nprint_accuracy(best_model, test_features=X_test,test_target=y_test)\nprint(\"----------------------\\n\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cd1449040cf48191dbedcd461320ef9547632d20","trusted":false},"cell_type":"code","source":"# load best weights\nbest_model.load_weights('2_pseudo.labeled.model.best.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a2cc71bd809d389430dc84eb90bc06c203e72bd1","scrolled":true,"trusted":false},"cell_type":"code","source":"# get predictions\ny_pred = best_model.predict(new_X_test)\nfunc = lambda x: 1 if x >= 0.5 else 0\ny_pred_classes_1 = np.array(list(map(func, y_pred)))\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(new_y_test, y_pred_classes_1)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='Confusion matrix (for new test set)')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"05855e01141d9e338502753ec92f3c09e4d731ac","trusted":false},"cell_type":"code","source":"# get predictions\ny_pred = best_model.predict(X_test)\nfunc = lambda x: 1 if x >= 0.5 else 0\ny_pred_classes_2 = np.array(list(map(func, y_pred)))\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_pred_classes_2)\nnp.set_printoptions(precision=2)\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=classes,\n                      title='Confusion matrix (for old test set)')\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0395f6a151c59cefd0df5a017a99fb7d55c219c6","trusted":false},"cell_type":"code","source":"# classification report on new test set\nprint(classification_report(new_y_test, y_pred_classes_1, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6d9450155e103ef6a9691a06a6be189e263b66f4","trusted":false},"cell_type":"code","source":"# classification report on old test set\nprint(classification_report(y_test, y_pred_classes_2, target_names=classes))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"be7326ad312c4f8f7312e7cfde64705bc2d91f87","scrolled":false,"trusted":false},"cell_type":"code","source":"plot_history(history_4)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"217b7ddae0fa43f3884b73ede56064df590c339f"},"cell_type":"markdown","source":"## Make A Sumbission File  (model 4)"},{"metadata":{"_uuid":"61565bd8a7729ada85c1b485776a4863975c888b","trusted":false},"cell_type":"code","source":"# make predictions of testing data\nprediction = best_model.predict(test_features, verbose=1)\n\nsubmission= pd.DataFrame({'id': test[\"id\"], 'is_iceberg': prediction.flatten()})\nsubmission.to_csv(\"../working/pseduolabel_submission.csv\", index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"986b9a717ac547ae203fa1fb3c8f39bff9e47c56"},"cell_type":"markdown","source":"With pseduo-labeling, and by retraining the best model on the increased training data we got a better model with 92.02% accuaracy and 0.32 loss."},{"metadata":{"_uuid":"bc2cc46d0b9e6d281ef97c74964975ca29b66070"},"cell_type":"markdown","source":"## AUC of ROC "},{"metadata":{"_uuid":"5f5f7f2794e9f1c4716340c6ca9927ea5cd77238","trusted":false},"cell_type":"code","source":"y_pred = best_model.predict(X_test)\n# Compute roc\nfpr, tpr, thresholds = roc_curve(y_test, y_pred)\nAUC = keras = auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5a3c51ebb309020f194a5c87db66bfafa0f0a946","trusted":false},"cell_type":"code","source":"# plot\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='Final model (area = {:.3f})'.format(AUC))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f4443f3c3f4f57bd1cae75ad96b650d8916fc683"},"cell_type":"markdown","source":"# Conclusion"},{"metadata":{"_uuid":"f6ad3355c63383ed349ce700b571bcb981f7dcd6"},"cell_type":"markdown","source":"In the following table, we compare between the benchmark model and the final model:\n\n|Model\t| Accuracy\t|Loss\t|F1-score (ships)|\tF1-score (icebergs)|\n|-------|---------------|--------|------------------|------------------------|\n|Benchmark Model\t|83%\t|0.35\t|0.88 |\t0.88|\n|Final Model\t|92.02%|0.32\t|0.92\t| 0.92|\n"},{"metadata":{"_uuid":"e9c45094862e638abb2c1f1de76abdcb834678ef"},"cell_type":"markdown","source":"When we compare the ROC curves of both models, we find the following:"},{"metadata":{"_uuid":"25dbf1b8be98ef9baccf394f007b5f08b36f5ed2","scrolled":false,"trusted":false},"cell_type":"code","source":"y_pred2 = basic_model.predict(X_test)\n# Compute roc\nfpr2, tpr2, thresholds2 = roc_curve(y_test, y_pred2)\nAUC2 = keras = auc(fpr2, tpr2)\n\n# plot\nplt.figure(1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='Final model (area = {:.3f})'.format(AUC))\nplt.plot(fpr2, tpr2, label='Benchmak (area = {:.3f})'.format(AUC2))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve: Final Model vs Benchmark model')\nplt.legend(loc='best')\nplt.show()\n\n# Zoom in view of the upper left corner.\nplt.figure(2)\nplt.xlim(-0.05, 0.3)\nplt.ylim(0.4, 1)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='Final model (area = {:.3f})'.format(AUC))\nplt.plot(fpr2, tpr2, label='Benchmak (area = {:.3f})'.format(AUC2))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve (zoomed in at top left)')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2e017e1b12fc48961f0ace965359e4aa5dd2cae4"},"cell_type":"markdown","source":"Attribution: https://hackernoon.com/simple-guide-on-how-to-generate-roc-plot-for-keras-classifier-2ecc6c73115a"},{"metadata":{"_uuid":"19d34ba62a3721fcfcd39775eeca2a9f07e0d26c"},"cell_type":"markdown","source":"The final model did a good job in the classification problem with about 92% accuracy, so we want to explore how it performs with different sample images:"},{"metadata":{"_uuid":"e9695a93384c26a504cd10334592325af797435c","trusted":false},"cell_type":"code","source":"samlples_num = 8\n# train (from 'train.json': the whole thing, containing both the training and testing splits used for training the model\niceberg_samples = train[train.is_iceberg==1].sample(n=samlples_num)\nships_samples = train[train.is_iceberg==0].sample(n=samlples_num)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2ef16c0bcf8fbaa813470d79343e5b3ddcc3dd07","trusted":false},"cell_type":"code","source":"from mpl_toolkits.axes_grid1 import ImageGrid\n\ndef prepocess_image(img):\n    # preprocess images\n    label = img.iloc[3]\n    band_1 = np.array(img.iloc[0]).astype(np.float32).reshape(75, 75)\n    band_2 = np.array(img.iloc[1]).astype(np.float32).reshape(75, 75)\n    img = np.concatenate([band_1[:, :, np.newaxis],\n                                 band_2[:, :, np.newaxis]], axis=-1)\n    img = np.array([img])\n    return img, label\n\ndef predict_icberg(img):\n    predection = best_model.predict(img)\n    prob = predection[0]\n    predected_label = 1 if predection >= 0.5 else 0\n    return predected_label, prob\n\n\ndef show_predictions(images):\n    size = len(images)\n    fig = plt.figure(1, figsize=(16, 16))\n    grid = ImageGrid(fig, 111, nrows_ncols=(2, size//2), axes_pad=0.05)\n    for i, (_,img) in enumerate(images.iterrows()):\n        img, label = prepocess_image(img)\n        predected_label, prob = predict_icberg(img)\n        \n        color = 'g' if label==predected_label else 'r' \n        ax = grid[i]\n        ax.imshow(img[0,:,:,0])\n        ax.text(5, 12, 'Predection: %s (%.2f)' % (predected_label, prob),\n                color='w', backgroundcolor=color)\n        ax.text(3, 5, 'True Label: %s' % label, color='w', backgroundcolor='k')\n        ax.axis('off')\n    plt.show()\n        ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"94c38a890c11c830c0dab83dc30ef0350030498b","trusted":false},"cell_type":"code","source":"# Show predictions on sample images of icebergs\nprint(\"Predictions on sample images of icebergs\")\nshow_predictions(iceberg_samples)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"956a3efed15afb72489539a24728f2cadefb7c8d","trusted":false},"cell_type":"code","source":"# Show predictions on sample images of ships\nprint(\"Predictions on sample images of ships\")\nshow_predictions(ships_samples)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ae7dd6ccba8744da4d27e3fa461f3157bd421942"},"cell_type":"markdown","source":"# Summary"},{"metadata":{"_uuid":"61f06a51442e6066c27d808e016225bc322d543c"},"cell_type":"markdown","source":"* By dimensionality reduction and using classifiers like Random Forest, K-NN and Logistic Regression we didn't get good results and the accuracy didn't exceed 79%.\n* Using CNNs has led to better results where a simple CNN benchmark model outperformed the previous methods with ~83% accuracy and up to 90% accuracy after tuning, 0.26 loss and f1-scores of 0.90 and 091 for ship and iceberg classes, respectively.\n* By increasing the complexity of the CNN model and introducing more layers we got a better model with ~91.8% accuracy, 0.34 loss, and higher f1-scores of 0.92 and 0.91 for ship and iceberg classes, respectively.\n* By making use of transfer learning with VGG16 together with data augmentation, we got 90.5% accuracy, 0.247 loss, and f1-score of 0.91.\n* With pseudo-labeling, and by retraining the best obtained model on the increased training data we got a better model with:\n    * 95.48% accuracy and 0.1214 loss on the test data (after pseudo-labeling: 752 samples), and f1-scores of 0.95 and 0.96 for ship and iceberg classes, respectively. \n    * 92.02% accuracy and 0.32 loss on the test data (before pseudo-labeling: 401 samples), and f1-score of 0.92 for both ship and iceberg classes.\n"},{"metadata":{"_uuid":"c92043bfea93dbf831b1ab7f34152d164cf20a3c","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}