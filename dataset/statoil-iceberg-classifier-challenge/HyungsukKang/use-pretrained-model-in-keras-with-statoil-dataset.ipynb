{"cells":[{"source":"# Processing Stuff\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss, accuracy_score\nimport numpy as np # linear algebra\nnp.random.seed(42)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n# ML modules\nimport xgboost as xgb\nfrom sklearn.linear_model import LogisticRegression\n# DL modules\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.applications import *\nfrom keras.optimizers import *\nfrom keras.regularizers import *\nfrom keras.applications.inception_v3 import preprocess_input\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\n# check directory\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","metadata":{"collapsed":true,"_cell_guid":"1a7e27b0-583d-4976-8ee4-7a049038436e","_uuid":"bc53047da4456c98fbdcf3381f0859268789dd09"},"cell_type":"code","outputs":[],"execution_count":1},{"source":"# Using pretrained model from kaggle dataset\nfrom os import listdir, makedirs, getcwd, remove\nfrom os.path import isfile, join, abspath, exists, isdir, expanduser\ncache_dir = expanduser(join('~', '.keras'))\nif not exists(cache_dir):\n    makedirs(cache_dir)\nmodels_dir = join(cache_dir, 'models')\nif not exists(models_dir):\n    makedirs(models_dir)\n\n!ls ../input/keras-pretrained-models/\n!cp ../input/keras-pretrained-models/* ~/.keras/models/","metadata":{"collapsed":true,"_cell_guid":"d0c15df8-18b2-42c9-8d06-b265f7be32c1","_uuid":"376a53611b1f3471635e813957a2a55f2c77a168"},"cell_type":"code","outputs":[],"execution_count":2},{"source":"#Load data\ntrain = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/train.json\")\ntest = pd.read_json(\"../input/statoil-iceberg-classifier-challenge/test.json\")\ntrain.inc_angle = train.inc_angle.replace('na', 0)\ntrain.inc_angle = train.inc_angle.astype(float).fillna(0.0)\nprint(\"done!\")\n","metadata":{"collapsed":true,"_cell_guid":"f56a1c4e-3643-4bfe-92f1-729fb614b509","_uuid":"8fffb373d28606e1b72d6126161ffc4849f9bbb3"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"# Train data\nx_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nx_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\nX_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n                          , x_band2[:, :, :, np.newaxis]\n                         , ((x_band1+x_band2)/2)[:, :, :, np.newaxis]], axis=-1)\nX_angle_train = np.array(train.inc_angle)\ny_train = np.array(train[\"is_iceberg\"])\n\n# Test data\nx_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nx_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\nX_test = np.concatenate([x_band1[:, :, :, np.newaxis]\n                          , x_band2[:, :, :, np.newaxis]\n                         , ((x_band1+x_band1)/2)[:, :, :, np.newaxis]], axis=-1)\nX_angle_test = np.array(test.inc_angle)\n\n\nX_train, X_valid, X_angle_train, X_angle_valid, y_train, y_valid = train_test_split(X_train\n                    , X_angle_train, y_train, random_state=123, train_size=0.7)","metadata":{"collapsed":true,"_cell_guid":"41e8f9a1-53cc-41e9-8baa-33d5e9d8debc","_uuid":"9c8ca492401b380b7bfe1c2e551f835b80690a69"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"# Resize training / valid / test data","metadata":{"_cell_guid":"baa3152c-3fd0-4422-ba16-0d01725c911a","_uuid":"fa037fc25802b9079b801c8f7f497d5457cbd50c"},"cell_type":"markdown"},{"source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom skimage.transform import resize\n","metadata":{"collapsed":true,"_cell_guid":"322ba66d-d1ba-4d4c-8dcf-7bdb8329d014","_uuid":"6f7d6384a7eee3aed8c4d38de4de3c7416807cae"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"from tqdm import tqdm\n\n# Training data\nwidth = 299\nn = len(X_train)\nX_train_resized = np.zeros((n, width, width, 3), dtype=np.float32)\nfor i in tqdm(range(n)):\n    x = X_train[i]\n    x = (x-x.min())/(x.max()-x.min()) # normalize for each pseudo pixel value\n    X_train_resized[i] = resize(x, (299,299), mode='reflect')\n\n\n# Validation data\nwidth = 299\nn = len(X_valid)\nX_valid_resized = np.zeros((n, width, width, 3), dtype=np.float32)\nfor i in tqdm(range(n)):\n    x = X_valid[i]\n    x = (x-x.min())/(x.max()-x.min())  # normalize for each pseudo pixel value\n    X_valid_resized[i] = resize(x, (299,299), mode='reflect')\n    \n# Test data\nwidth = 299\nn = len(X_test)\nX_test_resized = np.zeros((n, width, width, 3), dtype=np.float32)\nfor i in tqdm(range(n)):\n    x = X_test[i]\n    x = (x-x.min())/(x.max()-x.min())  # normalize for each pseudo pixel value\n    X_test_resized[i] = resize(x, (299,299), mode='reflect')\n\n","metadata":{"collapsed":true,"_cell_guid":"dd3890a4-2f72-44a8-9153-3f5aa0de636e","_uuid":"3dae292713885dba592168ab09c28bdf8e64ac50"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"# Feature Extraction\n\nFeature extraction pipeline from [Yang Peiwan](https://www.kaggle.com/yangpeiwen/keras-inception-xception-0-47)","metadata":{"_cell_guid":"8d873daa-cae2-4123-8cbb-65d56f7b77da","_uuid":"30ffc6d6a853c6e34048ac6856b5681819d500d3"},"cell_type":"markdown"},{"source":"def get_features(MODEL, data=None):\n    cnn_model = MODEL(include_top=False, input_shape=(width, width, 3), weights='imagenet')\n    \n    inputs = Input((width, width, 3))\n    x = inputs\n    x = Lambda(preprocess_input, name='preprocessing')(x)\n    x = cnn_model(x)\n    x = GlobalMaxPooling2D()(x)\n    cnn_model = Model(inputs, x)\n\n    features = cnn_model.predict(data, batch_size=4, verbose=1)\n    return features\n","metadata":{"collapsed":true,"_cell_guid":"14a894db-1fce-4ba1-abfe-7b254a5723d3","_uuid":"d11ec384e85709189525411c7f72cf0dd8d3b32e"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"train_features = get_features(InceptionV3, X_train_resized)\nvalid_features = get_features(InceptionV3, X_valid_resized)\ntest_features = get_features(InceptionV3, X_test_resized)","metadata":{"collapsed":true,"_cell_guid":"c0bb0b0b-feef-46c4-9e84-f9ff9528efd9","_uuid":"895fe29461ab79a357ec59cfbcdcdec04f86eb93"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"# ML pipeline","metadata":{"_cell_guid":"5e2ed64a-18f9-473a-8bfa-3e8b1624517f","_uuid":"742f47b3e5ca36b9b3f215bc93813b3a774a1981"},"cell_type":"markdown"},{"source":"## Logistic Regression","metadata":{"_cell_guid":"b592fe51-6e83-415e-b41f-62b9ae8f20d9","_uuid":"c22330be5ee15d568725e6914f1af9f041fed694"},"cell_type":"markdown"},{"source":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, accuracy_score\n\n# train\nclf = LogisticRegression(multi_class='multinomial', solver='lbfgs', random_state=2017)\nclf.fit(train_features, y_train)\n\n# validate\ny_probs = clf.predict_proba(valid_features)\nprint('Validation Inception-V3 LogLoss {}'.format(log_loss(y_valid, y_probs)))\nprint('Validation Inception-V3 Accuracy {}'.format(accuracy_score(y_valid, y_preds)))\n\n# predict\nlogreg_preds = clf.predict(test_features)","metadata":{"collapsed":true,"_cell_guid":"c047f736-4918-4feb-bab9-0f064b786ce9","_uuid":"2020de1fe3dcfd8de22dac75d0ccf53de95f6708"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"## XGBoost","metadata":{"_cell_guid":"c3df9047-f954-4985-85c3-894389f03f6a","_uuid":"75dc3067e4ace742dc8d16973a0caa78dafa12fb"},"cell_type":"markdown"},{"source":"import xgboost as xgb\n\n\nd_train =  xgb.DMatrix(X_train_resized,label=y_train)\nd_valid =  xgb.DMatrix(X_valid_resized,label=y_valid)\nd_test =  xgb.DMatrix(X_test_resized,label=y_valid)\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\n\nparams = {\n        'objective': 'binary:logistic',\n        'n_estimators':1000,\n        'max_depth': 8,\n        'subsample': 0.9,\n        'colsample_bytree': 0.9 ,\n        'eta': 0.01,\n        'eval_metric': 'logloss'\n        }\n\n# train\nclf =xgb.train(params, d_train, 1600, eval_set=watchlist, early_stopping_rounds=70,  verbose_eval=100)\n\n# validate\ny_probs = clf.predict_proba(d_valid)\nprint('Validation Inception-V3 LogLoss {}'.format(log_loss(y_valid, y_probs)))\nprint('Validation Inception-V3 Accuracy {}'.format(accuracy_score(y_valid, y_preds)))\n\n# predict\nxgb_preds = clf.predict(d_test)","metadata":{"collapsed":true,"_cell_guid":"46252f0f-539e-455f-8671-e4ca331a95d1","_uuid":"b35cac61c7f3141e4eb8a81b7874ba185be52132"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"## Multi Layer Perceptron","metadata":{"_cell_guid":"ed50d29e-7970-4ad6-88ae-e6bed2147495","_uuid":"ddf8b436dd3b86ec8cae41dfda0fcfb96e6297c1"},"cell_type":"markdown"},{"source":"def get_model():\n    bn_model = 0\n    p_activation = \"elu\"\n    input_layer = Input(shape=(4096,), name=\"X_1\")\n    dense_layer = Dropout(0.2) (BatchNormalization(momentum=bn_model) ( Dense(12, activation=p_activation)(input_layer) ))\n    dense_layer = Dropout(0.2) (BatchNormalization(momentum=bn_model) ( Dense(92, activation=p_activation)(dense_layer) ))\n    \n    output = Dense(1, activation=\"sigmoid\")(dense_layer)\n    \n    model = Model(input_layer,  output)\n    optimizer = Adam(lr=0.005, epsilon=1e-08)\n    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model","metadata":{"collapsed":true,"_cell_guid":"ed7320e8-dd6b-4b8b-a09b-6e71ee441bec","_uuid":"dc8bcadb95b92cc0e2c55b51281e76da389fdb24"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"# train\nmodel = get_model()\nmodel.fit(train_features, y_train, epochs=2, validation_data=(valid_features, y_valid))\n\n# validate\nprint(\"Validation: \")\nprint(model.evaluate(valid_features, y_valid, verbose=1, batch_size=200))\n\n# predict\nmlp_preds = model.predict(test_features)","metadata":{"collapsed":true,"_cell_guid":"691df8f8-b69e-42cf-9ee6-856b7a50b269","_uuid":"b3ee6284ae088a392070fed0ade192f51dd21569"},"cell_type":"code","outputs":[],"execution_count":null},{"source":"## Submission","metadata":{"_cell_guid":"99b3b91d-5b18-4158-956c-931c2cb24279","_uuid":"9744046821c28a8c21cf860bf07b45291735e063"},"cell_type":"markdown"},{"source":"logreg_sub = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': logreg_preds})\nlogreg_sub.to_csv(\"./logreg_sub.csv\", index=False)\n\nxgb_sub = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': xgb_preds})\nxgb_sub.to_csv(\"./xgb_sub.csv\", index=False)\n\nmlp_sub = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': mlp_preds.reshape((mlp_preds.shape[0]))})\nmlp_sub.to_csv(\"./mlp_sub.csv\", index=False)\n\n# ensemble with harmonic mean\n","metadata":{"collapsed":true,"_cell_guid":"3edf35f7-cd28-47e9-a535-c5cf8745649d","_uuid":"c22c89b0e9bd014788c18c4c209788bc3ce6265d"},"cell_type":"code","outputs":[],"execution_count":null}],"nbformat":4,"metadata":{"language_info":{"nbconvert_exporter":"python","version":"3.6.3","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"name":"python","file_extension":".py","mimetype":"text/x-python"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat_minor":1}