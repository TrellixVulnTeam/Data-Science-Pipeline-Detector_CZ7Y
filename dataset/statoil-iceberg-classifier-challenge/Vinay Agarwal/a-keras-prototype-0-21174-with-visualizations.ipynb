{"metadata":{"language_info":{"name":"python","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","file_extension":".py","version":"3.6.3","nbconvert_exporter":"python"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat_minor":1,"nbformat":4,"cells":[{"metadata":{"_uuid":"b7d6f28b179d42090917d5a9feb716d724a077cc"},"cell_type":"markdown","source":"1. Forked from [A keras prototype (0.21174 on PL)](https://www.kaggle.com/knowledgegrappler/a-keras-prototype-0-21174-on-pl) by [Miha Skalic](https://www.kaggle.com/mihaskalic)\n2. Added image visualization of correct and incorrect predictions\n3. Added confusion matrix\n4. Modified 3rd image from `((x_band1+x_band1)/2)` to `((x_band1+x_band2)/2)`\n5. Reduced epochs from 25 to 5 (for testing)"},{"metadata":{"_uuid":"14112d83eff81bcfed3d8b0fdf8b4fc37af7d92b","_cell_guid":"003a34b4-ea58-413c-8ee5-dda6c041ded7"},"cell_type":"code","source":"import numpy as np # linear algebra\nnp.random.seed(666)\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))","outputs":[],"execution_count":22},{"metadata":{"_uuid":"4b01d4e424cec7956507f5ac8179049bcd2f0235","_cell_guid":"29a5f133-81c7-486a-82c7-5e643b648e22"},"cell_type":"code","source":"#Load data\ntrain = pd.read_json(\"../input/train.json\")\ntest = pd.read_json(\"../input/test.json\")\ntrain.inc_angle = train.inc_angle.replace('na', 0)\ntrain.inc_angle = train.inc_angle.astype(float).fillna(0.0)\nprint(\"done!\")","outputs":[],"execution_count":23},{"metadata":{"_uuid":"b2eb784dbc8a40a145c5cdad2f6ca929e165ce95","_cell_guid":"2a419a87-0630-4794-8e5b-dff560d2d116"},"cell_type":"code","source":"# Train data\nx_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\nx_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\nX_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n                          , x_band2[:, :, :, np.newaxis]\n                         , ((x_band1+x_band2)/2)[:, :, :, np.newaxis]], axis=-1)\nX_angle_train = np.array(train.inc_angle)\ny_train = np.array(train[\"is_iceberg\"])\n\n# Test data\nx_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_1\"]])\nx_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in test[\"band_2\"]])\nX_test = np.concatenate([x_band1[:, :, :, np.newaxis]\n                          , x_band2[:, :, :, np.newaxis]\n                         , ((x_band1+x_band2)/2)[:, :, :, np.newaxis]], axis=-1)\nX_angle_test = np.array(test.inc_angle)\n\n\nX_train, X_valid, X_angle_train, X_angle_valid, y_train, y_valid = train_test_split(X_train\n                    , X_angle_train, y_train, random_state=123, train_size=0.75)","outputs":[],"execution_count":24},{"metadata":{"_uuid":"d5787df36f2640ba2ae57dad49dc78b7c2a8f8b3","_cell_guid":"48694991-a0af-4e4a-86c9-9e6a106ac21d"},"cell_type":"code","source":"from matplotlib import pyplot\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n\ndef get_callbacks(filepath, patience=2):\n    es = EarlyStopping('val_loss', patience=patience, mode=\"min\")\n    msave = ModelCheckpoint(filepath, save_best_only=True)\n    return [es, msave]\n    \ndef get_model():\n    bn_model = 0\n    p_activation = \"elu\"\n    input_1 = Input(shape=(75, 75, 3), name=\"X_1\")\n    input_2 = Input(shape=[1], name=\"angle\")\n    \n    img_1 = Conv2D(16, kernel_size = (3,3), activation=p_activation) ((BatchNormalization(momentum=bn_model))(input_1))\n    img_1 = Conv2D(16, kernel_size = (3,3), activation=p_activation) (img_1)\n    img_1 = MaxPooling2D((2,2)) (img_1)\n    img_1 = Dropout(0.2)(img_1)\n    img_1 = Conv2D(32, kernel_size = (3,3), activation=p_activation) (img_1)\n    img_1 = Conv2D(32, kernel_size = (3,3), activation=p_activation) (img_1)\n    img_1 = MaxPooling2D((2,2)) (img_1)\n    img_1 = Dropout(0.2)(img_1)\n    img_1 = Conv2D(64, kernel_size = (3,3), activation=p_activation) (img_1)\n    img_1 = Conv2D(64, kernel_size = (3,3), activation=p_activation) (img_1)\n    img_1 = MaxPooling2D((2,2)) (img_1)\n    img_1 = Dropout(0.2)(img_1)\n    img_1 = Conv2D(128, kernel_size = (3,3), activation=p_activation) (img_1)\n    img_1 = MaxPooling2D((2,2)) (img_1)\n    img_1 = Dropout(0.2)(img_1)\n    img_1 = GlobalMaxPooling2D() (img_1)\n    \n    \n    img_2 = Conv2D(128, kernel_size = (3,3), activation=p_activation) ((BatchNormalization(momentum=bn_model))(input_1))\n    img_2 = MaxPooling2D((2,2)) (img_2)\n    img_2 = Dropout(0.2)(img_2)\n    img_2 = GlobalMaxPooling2D() (img_2)\n    \n    img_concat =  (Concatenate()([img_1, img_2, BatchNormalization(momentum=bn_model)(input_2)]))\n    \n    dense_ayer = Dropout(0.5) (BatchNormalization(momentum=bn_model) ( Dense(256, activation=p_activation)(img_concat) ))\n    dense_ayer = Dropout(0.5) (BatchNormalization(momentum=bn_model) ( Dense(64, activation=p_activation)(dense_ayer) ))\n    output = Dense(1, activation=\"sigmoid\")(dense_ayer)\n    \n    model = Model([input_1,input_2],  output)\n    optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n    model.compile(loss=\"binary_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])\n    return model\nmodel = get_model()\nmodel.summary()","outputs":[],"execution_count":25},{"metadata":{"_uuid":"7397f8e25535660a8149786218f0cc54070ddb7b","_cell_guid":"ed3d20e2-9cd3-4aad-9664-c7f3c485cc1e"},"cell_type":"code","source":"file_path = \"model_weights.hdf5\"\n\nmodel = get_model()\nmodel.fit([X_train, X_angle_train], y_train, epochs=5\n          , validation_data=([X_valid, X_angle_valid], y_valid)\n         , batch_size=32)\n\nmodel.save_weights(filepath=file_path)","outputs":[],"execution_count":26},{"metadata":{"_uuid":"f16cda9020fb9e07cb3325ba05061b786e603626","_cell_guid":"aacdccc7-760d-4433-8a6f-554d357722fd"},"cell_type":"code","source":"model.load_weights(filepath=file_path)\n\nprint(\"Train evaluate:\")\nprint(model.evaluate([X_train, X_angle_train], y_train, verbose=1, batch_size=200))\nprint(\"####################\")\nprint(\"watch list evaluate:\")\nprint(model.evaluate([X_valid, X_angle_valid], y_valid, verbose=1, batch_size=200))","outputs":[],"execution_count":27},{"metadata":{"_uuid":"27a7caa8dc5042309054cda9640d01078c38e0c9"},"cell_type":"code","source":"print(\"Visualize trained\")\npred_valid_frac = model.predict([X_valid, X_angle_valid], verbose=1, batch_size=200)\npred_valid = pd.DataFrame(pred_valid_frac[:,0], columns=['fpred'])\npred_valid['pred'] = pred_valid.fpred.round(0)\npred_valid['y'] = y_valid\npred_valid['error'] = np.abs(pred_valid.y - pred_valid.fpred)\npred_valid['i'] = pred_valid.index","outputs":[],"execution_count":28},{"metadata":{"_uuid":"422de47c5da40be3c2f5cee34aeca44af447807f"},"cell_type":"code","source":"from bokeh.io import show, output_notebook\nfrom bokeh.plotting import figure\nfrom bokeh.layouts import row, column\noutput_notebook()\nfrom bokeh.models import LinearColorMapper, Title\ncolor_mapper = LinearColorMapper(palette=\"Greys256\")\n\ndef plot_one(image, error=False):\n    f = figure(x_range=(0,1), y_range=(0,1), plot_width=150, plot_height=150, toolbar_location=None)\n    f.axis.visible = False\n    f.image(image=[image], color_mapper=color_mapper, dh=[1], dw=[1], x=[0], y=[0])\n    if error:\n        f.add_layout(Title(text=\"{0:.4f}\".format(error), align=\"center\"), \"left\")\n    return f\n\ndef plot_row(images, error):\n    p = row([plot_one(images[:, :, 0], error), plot_one(images[:, :, 1]), plot_one(images[:, :, 2])])\n    return p\n    \ndef plot_rows(df, images):\n    p = []\n    for i, r in df.iterrows():\n        idx = int(r.i)\n        p.append(plot_row(images[idx], r.error))\n    show(column(p))\n","outputs":[],"execution_count":29},{"metadata":{"_uuid":"36cf8f103093e301d729a022cefe8bfd2a32de50","scrolled":false},"cell_type":"code","source":"print(\"Icebergs:\")\nicebergs = pred_valid.loc[pred_valid['y'] == 1, :]\nicebergs = icebergs.sort_values(['error'])\nicebergs = icebergs.reset_index(drop=True)\nprint(\"  Easy:\")\niceberg_correct = icebergs.loc[icebergs.y == icebergs.pred, :]\nplot_rows(icebergs.head(4), X_valid)","outputs":[],"execution_count":30},{"metadata":{"_uuid":"87a7e7f847d3aa85c5cf225a4616676539da3932"},"cell_type":"code","source":"print(\"Icebergs:\")\nprint(\"  Barely correct:\")\nplot_rows(iceberg_correct.tail(4), X_valid)","outputs":[],"execution_count":31},{"metadata":{"_uuid":"40143cba440190ec1c62262a4465dbfa52e403c8"},"cell_type":"code","source":"print(\"Icebergs:\")\nprint(\"  Wrong!\")\niceberg_wrong = icebergs.loc[icebergs.y != icebergs.pred, :]\nplot_rows(iceberg_wrong.tail(4), X_valid)","outputs":[],"execution_count":32},{"metadata":{"_uuid":"4c078227560880f1c2ef4d03efc1b5859a75acdd"},"cell_type":"code","source":"print(\"Ships:\")\nships = pred_valid.loc[pred_valid['y'] == 0, :]\nships = ships.sort_values(['error'])\nships = ships.reset_index(drop=True)\nprint(\"  Easy:\")\nship_correct = ships.loc[ships.y == ships.pred, :]\nplot_rows(ship_correct.head(4), X_valid)","outputs":[],"execution_count":33},{"metadata":{"_uuid":"5d391d3ab892ba437889bdc7adea09a52b53dfd7"},"cell_type":"code","source":"print(\"Ships:\")\nprint(\"  Barely correct:\")\nplot_rows(ship_correct.tail(4), X_valid)","outputs":[],"execution_count":34},{"metadata":{"_uuid":"01e77048552cce3a71b45c37d36a7a76bf9b7eea"},"cell_type":"code","source":"print(\"Ships:\")\nprint(\"  Wrong!\")\nship_wrong = ships.loc[ships.y != ships.pred, :]\nplot_rows(ship_wrong.tail(4), X_valid)","outputs":[],"execution_count":35},{"metadata":{"_uuid":"e05f0874baa3b11c83dcf9a45f8991c58e97fe2a"},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom matplotlib import pyplot as plt\nimport itertools\n\ndef plot_confusion_matrix(cm, classes, normalize=False, title='Confusion matrix', cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes)\n    plt.yticks(tick_marks, classes, rotation=90)\n\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    print(cm)\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j], horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n\ncm = confusion_matrix(y_valid, pred_valid.pred)\nplot_confusion_matrix(cm, ['Ship', 'Iceberg'])","outputs":[],"execution_count":36},{"metadata":{"_uuid":"df1410c2fb4d4f124ba89602b3f669de7018728a","_cell_guid":"78dbcf6c-a7ba-49c7-a459-20bed13a2219"},"cell_type":"code","source":"prediction = model.predict([X_test, X_angle_test], verbose=1, batch_size=200)","outputs":[],"execution_count":37},{"metadata":{"_uuid":"a656b27ff563fd4e69c43393280b9227e44aac74","_cell_guid":"52766228-cf82-4cc8-9671-d8391d294bbb"},"cell_type":"code","source":"submission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': prediction.reshape((prediction.shape[0]))})\nsubmission.head(10)","outputs":[],"execution_count":38},{"metadata":{"_uuid":"53646935d88ffa854e33aeb583c6d5c475e9380b","_cell_guid":"da4a9987-2589-48b3-bfd1-5e2076f74f0c","collapsed":true},"cell_type":"code","source":"submission.to_csv(\"./submission.csv\", index=False)","outputs":[],"execution_count":39}]}