{"nbformat_minor":1,"cells":[{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"import numpy as np\nimport pandas as pd\nimport keras as k\nfrom keras.layers import Merge\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom keras.callbacks import History\nfrom keras.layers import Activation\nfrom keras.models import model_from_json\nfrom keras.optimizers import Adam\nfrom matplotlib import pyplot as plt\nfrom scipy.ndimage import rotate as rot\nnp.random.seed(100)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"file_path = '/Users/henok.s.mengistu/Documents/Henok\\'s/Iceberg_challenge/data/processed/train.json'","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"train = pd.read_json(file_path)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print(train.head())\ntrain.shape","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"train[train['inc_angle'] == 'na'].count()","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"train.inc_angle = train.inc_angle.map(lambda x: 0.0 if x == 'na' else x)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"def transform (df):\n    images = []\n    for i, row in df.iterrows():\n        band_1 = np.array(row['band_1']).reshape(75,75)\n        band_2 = np.array(row['band_2']).reshape(75,75)\n        band_3 = band_1 + band_2\n        \n        band_1_norm = (band_1 - band_1.mean()) / (band_1.max() - band_1.min())\n        band_2_norm = (band_2 - band_2. mean()) / (band_2.max() - band_2.min())\n        band_3_norm = (band_3 - band_3.mean()) / (band_3.max() - band_3.min())\n        \n        images.append(np.dstack((band_1_norm, band_2_norm, band_3_norm)))\n    \n    return np.array(images)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"def augment(images):\n    image_mirror_lr = []\n    image_mirror_ud = []\n    image_rotate = []\n    for i in range(0,images.shape[0]):\n        band_1 = images[i,:,:,0]\n        band_2 = images[i,:,:,1]\n        band_3 = images[i,:,:,2]\n            \n        # mirror left-right\n        band_1_mirror_lr = np.flip(band_1, 0)\n        band_2_mirror_lr = np.flip(band_2, 0)\n        band_3_mirror_lr = np.flip(band_3, 0)\n        image_mirror_lr.append(np.dstack((band_1_mirror_lr, band_2_mirror_lr, band_3_mirror_lr)))\n        \n        # mirror up-down\n        band_1_mirror_ud = np.flip(band_1, 1)\n        band_2_mirror_ud = np.flip(band_2, 1)\n        band_3_mirror_ud = np.flip(band_3, 1)\n        image_mirror_ud.append(np.dstack((band_1_mirror_ud, band_2_mirror_ud, band_3_mirror_ud)))\n        \n        #rotate \n        band_1_rotate = rot(band_1, 30, reshape=False)\n        band_2_rotate = rot(band_2, 30, reshape=False)\n        band_3_rotate = rot(band_3, 30, reshape=False)\n        image_rotate.append(np.dstack((band_1_rotate, band_2_rotate, band_3_rotate)))\n        \n    mirrorlr = np.array(image_mirror_lr)\n    mirrorud = np.array(image_mirror_ud)\n    rotated = np.array(image_rotate)\n    images = np.concatenate((images, mirrorlr, mirrorud, rotated))\n    return images","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"train_X = transform(train)\ntrain_y = np.array(train ['is_iceberg'])\n\nindx_tr = np.where(train.inc_angle > 0)\nprint (indx_tr[0].shape)\n\ntrain_y = train_y[indx_tr[0]]\ntrain_X = train_X[indx_tr[0], ...]\n\ntrain_X = augment(train_X)\ntrain_y = np.concatenate((train_y,train_y, train_y, train_y))\n\nprint (train_X.shape)\nprint (train_y.shape)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"model = k.models.Sequential()\n\nmodel.add(k.layers.convolutional.Conv2D(64, kernel_size=(3,3), input_shape=(75,75,3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(3,3), strides=(2,2)))\nmodel.add(k.layers.Dropout(0.2))\n\nmodel.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(k.layers.Dropout(0.2))\n\nmodel.add(k.layers.convolutional.Conv2D(128, kernel_size=(3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(k.layers.Dropout(0.3))\n\nmodel.add(k.layers.convolutional.Conv2D(64, kernel_size=(3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(k.layers.convolutional.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\nmodel.add(k.layers.Dropout(0.3))\n\nmodel.add(k.layers.Flatten())\n\nmodel.add(k.layers.Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(k.layers.Dropout(0.2))\n\nmodel.add(k.layers.Dense(256))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(k.layers.Dropout(0.2))\n\n\nmodel.add(k.layers.Dense(1))\nmodel.add(Activation('sigmoid'))\n\nmypotim=Adam(lr=0.01, decay=0.0)\nmodel.compile(loss='binary_crossentropy', optimizer = mypotim, metrics=['accuracy'])\n\nmodel.summary()","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"batch_size = 64\nearly_stopping = EarlyStopping(monitor = 'val_loss', patience = 10, verbose = 0, mode= 'min')\nreduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor = 0.1, patience = 7, verbose =1, \n                                   epsilon = 1e-4, mode='min', min_lr = 0.0001)\nmodel_filepath='/Users/henok.s.mengistu/Documents/Henok\\'s/Iceberg_challenge/weights.best.hdf5'\ncheckpoint = ModelCheckpoint(model_filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [early_stopping, checkpoint]","cell_type":"code"},{"metadata":{"scrolled":false,"collapsed":true},"outputs":[],"execution_count":null,"source":"history = model.fit(train_X, train_y, batch_size = batch_size, epochs =20, verbose =1, validation_split = 0.1, \n          callbacks=callbacks_list)","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"print (history.history.keys())\nfig = plt.figure()\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train','test'],loc='upper left')\nplt.show()","cell_type":"code"},{"metadata":{},"outputs":[],"execution_count":null,"source":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"model_json = model.to_json()\nwith open(\"/Users/henok.s.mengistu/Documents/Henok\\'s/Iceberg_challenge/model.json\", \"w\") as json_file:\n    json_file.write(model_json)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"# load json and create model\njson_file = open('/Users/henok.s.mengistu/Documents/Henok\\'s/Iceberg_challenge/model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights('/Users/henok.s.mengistu/Documents/Henok\\'s/Iceberg_challenge/weights.best.hdf5')\nprint(\"Loaded model from disk\")\nloaded_model.compile(loss='binary_crossentropy', optimizer = mypotim, metrics=['accuracy'])","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"test_file = '/Users/henok.s.mengistu/Documents/Henok\\'s/Iceberg_challenge/data-1/processed/test.json'\ntest = pd.read_json(test_file)\ntest.inc_angle = test.inc_angle.replace('na',0)\ntest_X = transform(test)\nprint (test_X.shape)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"pred_test = loaded_model.predict(test_X, verbose=1)\nsubmission = pd.DataFrame({'id': test[\"id\"], 'is_iceberg': pred_test.reshape((pred_test.shape[0]))})\nsubmission.to_csv('/Users/henok.s.mengistu/Documents/Henok\\'s/Iceberg_challenge/submission.csv', index=False)","cell_type":"code"},{"metadata":{"collapsed":true},"outputs":[],"execution_count":null,"source":"","cell_type":"code"}],"metadata":{"language_info":{"mimetype":"text/x-python","nbconvert_exporter":"python","name":"python","pygments_lexer":"ipython3","version":"3.6.3","codemirror_mode":{"version":3,"name":"ipython"},"file_extension":".py"},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3"}},"nbformat":4}