{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Simulations Episode Scraper Match Downloader","metadata":{}},{"cell_type":"markdown","source":"This notebook downloads episodes using Kaggle's GetEpisodeReplay API and the [Meta Kaggle](https://www.kaggle.com/kaggle/meta-kaggle) dataset.\n\n**To run this notebook you WILL need to re-add the Meta Kaggle dataset. After opening your copy of the notebook, click \"+ Add data\" top right in the notebook editor.\n**\n\nMeta Kaggle is refreshed daily, but sometimes misses daily refreshes for a few days.\n\nWhy download replays?\n- Train your ML/RL model\n- Inspect the performance of yours and others agents\n- To add to your ever growing json collection \n\nOnly one scraping strategy is implemented: For each top scoring submission, download all missing matches, move on to next submission.\n\nOther scraping strategies can be implemented, but not here. Like download max X matches per submission or per team per day, or ignore certain teams or ignore where some scores < X, or only download some teams.\n\nTodo:\n- Add teamid's once meta kaggle add them. Edit: it's been a long time, it doesn't look like Kaggle is adding this.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport requests\nimport json\nimport datetime\nimport time\nimport glob\nimport collections\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-17T09:27:54.548723Z","iopub.execute_input":"2021-08-17T09:27:54.549148Z","iopub.status.idle":"2021-08-17T09:27:54.554926Z","shell.execute_reply.started":"2021-08-17T09:27:54.549058Z","shell.execute_reply":"2021-08-17T09:27:54.553533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## You should configure these to your needs. Choose one of ...\n# 'hungry-geese', 'rock-paper-scissors', santa-2020', 'halite', 'google-football'\nCOMP = 'kore-2022'\nMAX_CALLS_PER_DAY = 100 # Kaggle says don't do more than 3600 per day and 1 per second\nLOWEST_SCORE_THRESH = 999","metadata":{"execution":{"iopub.status.busy":"2021-08-17T09:28:08.892368Z","iopub.execute_input":"2021-08-17T09:28:08.892716Z","iopub.status.idle":"2021-08-17T09:28:08.897235Z","shell.execute_reply.started":"2021-08-17T09:28:08.892686Z","shell.execute_reply":"2021-08-17T09:28:08.896093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT =\"../working/\"\nMETA = \"../input/meta-kaggle/\"\nMATCH_DIR = '../working/'\nbase_url = \"https://www.kaggle.com/requests/EpisodeService/\"\nget_url = base_url + \"GetEpisodeReplay\"\nBUFFER = 1\nCOMPETITIONS = {\n    'kore-2022': 34419,\n    'lux-ai-2021': 30067,\n    'hungry-geese': 25401,\n    'rock-paper-scissors': 22838,\n    'santa-2020': 24539,\n    'halite': 18011,\n    'google-football': 21723\n}","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-08-17T09:28:27.104372Z","iopub.execute_input":"2021-08-17T09:28:27.104747Z","iopub.status.idle":"2021-08-17T09:28:27.111054Z","shell.execute_reply.started":"2021-08-17T09:28:27.104717Z","shell.execute_reply":"2021-08-17T09:28:27.110258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load Episodes\nepisodes_df = pd.read_csv(META + \"Episodes.csv\")\n\n# Load EpisodeAgents\nepagents_df = pd.read_csv(META + \"EpisodeAgents.csv\")\n\nprint(f'Episodes.csv: {len(episodes_df)} rows before filtering.')\nprint(f'EpisodeAgents.csv: {len(epagents_df)} rows before filtering.')\n\nepisodes_df = episodes_df[episodes_df.CompetitionId == COMPETITIONS[COMP]] \nepagents_df = epagents_df[epagents_df.EpisodeId.isin(episodes_df.Id)]\n\nprint(f'Episodes.csv: {len(episodes_df)} rows after filtering for {COMP}.')\nprint(f'EpisodeAgents.csv: {len(epagents_df)} rows after filtering for {COMP}.')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare dataframes\n\nepisodes_df = episodes_df.set_index(['Id'])\nepisodes_df['CreateTime'] = pd.to_datetime(episodes_df['CreateTime'])\nepisodes_df['EndTime'] = pd.to_datetime(episodes_df['EndTime'])\n\nepagents_df.fillna(0, inplace=True)\nepagents_df = epagents_df.sort_values(by=['Id'], ascending=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get top scoring submissions# Get top scoring submissions\nmax_df = (epagents_df.sort_values(by=['EpisodeId'], ascending=False).groupby('SubmissionId').head(1).drop_duplicates().reset_index(drop=True))\nmax_df = max_df[max_df.UpdatedScore>=LOWEST_SCORE_THRESH]\nmax_df = pd.merge(left=episodes_df, right=max_df, left_on='Id', right_on='EpisodeId')\nsub_to_score_top = pd.Series(max_df.UpdatedScore.values,index=max_df.SubmissionId).to_dict()\nprint(f'{len(sub_to_score_top)} submissions with score over {LOWEST_SCORE_THRESH}')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get episodes for these submissions\nsub_to_episodes = collections.defaultdict(list)\nfor key, value in sorted(sub_to_score_top.items(), key=lambda kv: kv[1], reverse=True):\n    excl = [23132370, 23032370, 23032570, 23036370, 23032370, 22787661, 22888661, 22777661, 23777661, 22777461]\n    if key not in excl: # we can filter subs like this\n        eps = sorted(epagents_df[epagents_df['SubmissionId'].isin([key])]['EpisodeId'].values,reverse=True)\n        sub_to_episodes[key] = eps\ncandidates = len(set([item for sublist in sub_to_episodes.values() for item in sublist]))\nprint(f'{candidates} episodes for these {len(sub_to_score_top)} submissions')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"global num_api_calls_today\nnum_api_calls_today = 0\nall_files = []\nfor root, dirs, files in os.walk(MATCH_DIR, topdown=False):\n    all_files.extend(files)\nseen_episodes = [int(f.split('.')[0]) for f in all_files \n                      if '.' in f and f.split('.')[0].isdigit() and f.split('.')[1] == 'json']\nremaining = np.setdiff1d([item for sublist in sub_to_episodes.values() for item in sublist],seen_episodes)\nprint(f'{len(remaining)} of these {candidates} episodes not yet saved')\nprint('Total of {} games in existing library'.format(len(seen_episodes)))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_info_json(epid):\n    \n    create_seconds = int((episodes_df[episodes_df.index == epid]['CreateTime'].values[0]).item()/1e9)\n    end_seconds = int((episodes_df[episodes_df.index == epid]['CreateTime'].values[0]).item()/1e9)\n\n    agents = []\n    for index, row in epagents_df[epagents_df['EpisodeId'] == epid].sort_values(by=['Index']).iterrows():\n        agent = {\n            \"id\": int(row[\"Id\"]),\n            \"state\": int(row[\"State\"]),\n            \"submissionId\": int(row['SubmissionId']),\n            \"reward\": int(row['Reward']),\n            \"index\": int(row['Index']),\n            \"initialScore\": float(row['InitialScore']),\n            \"initialConfidence\": float(row['InitialConfidence']),\n            \"updatedScore\": float(row['UpdatedScore']),\n            \"updatedConfidence\": float(row['UpdatedConfidence']),\n            \"teamId\": int(99999)\n        }\n        agents.append(agent)\n\n    info = {\n        \"id\": int(epid),\n        \"competitionId\": int(COMPETITIONS[COMP]),\n        \"createTime\": {\n            \"seconds\": int(create_seconds)\n        },\n        \"endTime\": {\n            \"seconds\": int(end_seconds)\n        },\n        \"agents\": agents\n    }\n\n    return info","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def saveEpisode(epid):\n    # request\n    re = requests.post(get_url, json = {\"EpisodeId\": int(epid)})\n        \n    # save replay\n    with open(MATCH_DIR + '{}.json'.format(epid), 'w') as f:\n        f.write(re.json()['result']['replay'])\n\n    # save match info\n    info = create_info_json(epid)\n    with open(MATCH_DIR +  '{}_info.json'.format(epid), 'w') as f:\n        json.dump(info, f)\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"r = BUFFER;\n\nstart_time = datetime.datetime.now()\nse=0\nfor key, value in sorted(sub_to_score_top.items(), key=lambda kv: kv[1], reverse=True):\n    if num_api_calls_today<=MAX_CALLS_PER_DAY:\n        print('')\n        remaining = sorted(np.setdiff1d(sub_to_episodes[key],seen_episodes), reverse=True)\n        print(f'submission={key}, LB={\"{:.0f}\".format(value)}, matches={len(set(sub_to_episodes[key]))}, still to save={len(remaining)}')\n        \n        for epid in remaining:\n            if epid not in seen_episodes and num_api_calls_today<=MAX_CALLS_PER_DAY:\n                saveEpisode(epid); \n                r+=1;\n                se+=1\n                try:\n                    size = os.path.getsize(MATCH_DIR+'{}.json'.format(epid)) / 1e6\n                    print(str(num_api_calls_today) + f': saved episode #{epid}')\n                    seen_episodes.append(epid)\n                    num_api_calls_today+=1\n                except:\n                    print('  file {}.json did not seem to save'.format(epid))    \n                if r > (datetime.datetime.now() - start_time).seconds:\n                    time.sleep( r - (datetime.datetime.now() - start_time).seconds)\n            if num_api_calls_today>(min(3600,MAX_CALLS_PER_DAY)):\n                break\nprint('')\nprint(f'Episodes saved: {se}')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}