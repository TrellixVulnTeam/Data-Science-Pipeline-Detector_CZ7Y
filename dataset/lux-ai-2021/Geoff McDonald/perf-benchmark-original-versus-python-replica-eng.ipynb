{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lux AI 2021 python game engine performance comparison to original\nSee https://github.com/glmcdona/LuxPythonEnvGym for environment project and updates.\n\nThis is a python replica of the Lux game engine to speed up training and allow better game control for RL models. In this notebook we run a simple performance benchmark comparing the game engine performance of the two.","metadata":{}},{"cell_type":"code","source":"!pip install kaggle-environments -U","metadata":{"execution":{"iopub.status.busy":"2021-10-04T03:29:08.96459Z","iopub.execute_input":"2021-10-04T03:29:08.965007Z","iopub.status.idle":"2021-10-04T03:29:17.197102Z","shell.execute_reply.started":"2021-10-04T03:29:08.964922Z","shell.execute_reply":"2021-10-04T03:29:17.196443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# run this if using kaggle notebooks\n!cp -r ../input/lux-ai-2021/* .","metadata":{"execution":{"iopub.status.busy":"2021-10-04T03:30:23.091635Z","iopub.execute_input":"2021-10-04T03:30:23.091952Z","iopub.status.idle":"2021-10-04T03:30:23.403935Z","shell.execute_reply.started":"2021-10-04T03:30:23.091923Z","shell.execute_reply":"2021-10-04T03:30:23.402961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test the original LuxAI2021 engine (TypeScript driven)","metadata":{}},{"cell_type":"code","source":"import time\nfrom kaggle_environments import make\n\nfrom lux.game import Game\nfrom lux.game_map import Cell, RESOURCE_TYPES, Position\nfrom lux.constants import Constants\nfrom lux.game_constants import GAME_CONSTANTS\nfrom lux import annotate\n\ngame_state = None\ndef agent(observation, configuration):\n    global game_state\n\n    ### Do not edit ###\n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation.player\n    else:\n        game_state._update(observation[\"updates\"])\n    \n    actions = []\n\n    ### AI Code goes down here! ### \n    # No logic.\n    \n    return actions\n\n\n# Play N games to measure performance\nstart_time = time.time()\ntotal_steps = 0\nnum_episodes = 2000\n\nfor i in range(num_episodes):\n    env = make(\"lux_ai_2021\", debug=False) # Note, this line is needed here to reset the environment with a new seed. It doesn't effect performance significantly.\n    steps = env.run([agent, agent])\n    total_steps += len(steps)\n\ntotal_time = time.time() - start_time\n\nprint(\"Original game engine: %.3f seconds per full game, mean of %.1f steps per game.\" % (total_time / num_episodes, total_steps / num_episodes))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T03:47:59.269211Z","iopub.execute_input":"2021-10-04T03:47:59.269666Z","iopub.status.idle":"2021-10-04T03:47:59.299631Z","shell.execute_reply.started":"2021-10-04T03:47:59.269638Z","shell.execute_reply":"2021-10-04T03:47:59.297726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Test the python-engine replica game performance","metadata":{}},{"cell_type":"code","source":"!pip install git+https://github.com/glmcdona/LuxPythonEnvGym.git@main","metadata":{"execution":{"iopub.status.busy":"2021-10-04T03:44:07.31467Z","iopub.execute_input":"2021-10-04T03:44:07.314997Z","iopub.status.idle":"2021-10-04T03:45:31.87673Z","shell.execute_reply.started":"2021-10-04T03:44:07.314972Z","shell.execute_reply":"2021-10-04T03:45:31.875439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nfrom luxai2021.game.game import Game\nfrom luxai2021.game.actions import *\nfrom luxai2021.game.constants import LuxMatchConfigs_Default\n\n# Create a game\nconfigs = LuxMatchConfigs_Default\ngame = Game(configs)\n\n# Play N games to measure performance\nstart_time = time.time()\ntotal_steps = 0\nnum_episodes = 2000\nfor i in range(num_episodes):\n    gameOver = False\n    while not gameOver:\n        gameOver = game.run_turn_with_actions(actions=[])\n    \n    total_steps += game.state[\"turn\"]\n    game.reset()\ntotal_time = time.time() - start_time\n\nprint(\"Python replica game engine: %.3f seconds per full game, mean of %.1f steps per game.\" % (total_time / num_episodes, total_steps / num_episodes))\n","metadata":{"execution":{"iopub.status.busy":"2021-10-04T03:48:33.698338Z","iopub.execute_input":"2021-10-04T03:48:33.698645Z","iopub.status.idle":"2021-10-04T03:48:38.818029Z","shell.execute_reply.started":"2021-10-04T03:48:33.698619Z","shell.execute_reply":"2021-10-04T03:48:38.81724Z"},"trusted":true},"execution_count":null,"outputs":[]}]}