{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install kaggle-environments -U > /dev/null 2>&1\n!cp -r ../input/lux-ai-2021/* .","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport json\nfrom pathlib import Path\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.optim as optim\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed_value):\n    #random will be the same if getting the same seed_value \n    random.seed(seed_value)\n    np.random.seed(seed_value)\n    #Sets the seed for generating random numbers for the current GPU\n    torch.manual_seed(seed_value)\n    #set Python Hash Seed to a specific number,making it able to appear again\n    os.environ['PYTHONHASHSEED'] = str(seed_value)\n    \n    #indicate if cuda is available \n    if torch.cuda.is_available(): \n        #Sets the seed for generating random numbers for the current GPU\n        torch.cuda.manual_seed(seed_value)\n        #Sets the seed for generating random numbers on all GPUs.\n        torch.cuda.manual_seed_all(seed_value)\n        #if True, causes cuDNN to only use deterministic convolution algorithms\n        torch.backends.cudnn.deterministic = True\n        # if True, causes cuDNN to benchmark multiple convolution algorithms and select the fastest.\n        torch.backends.cudnn.benchmark = True\n\nseed = 42\nseed_everything(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"def to_label(action):\n    #将action按照空格分成一个长为3的字符串列表\n    strs = action.split(' ')\n    unit_id = strs[1]\n    #m代表move，说明是一个可动单位\n    if strs[0] == 'm':\n        #north、south、west、east\n        label = {'c': None, 'n': 0, 's': 1, 'w': 2, 'e': 3}[strs[2]]\n    #是city\n    elif strs[0] == 'bcity':\n        label = 4\n    else:\n        label = None\n    return unit_id, label\n\n#判断资源是否所有单位全部耗尽的函数（即一方全部消失在黑暗中，游戏结束）\ndef depleted_resources(obs):\n    for u in obs['updates']:\n        if u.split(' ')[0] == 'r':\n            return False\n    return True\n\n\ndef create_dataset_from_json(episode_dir, team_name='Toad Brigade'): \n    obses = {}\n    samples = []\n    append = samples.append\n    #从../input/lux-ai-episodes寻找训练模型，并加入episodes中\n    episodes = [path for path in Path(episode_dir).glob('*.json') if 'output' not in path.name]\n    #tqdm为一个显示进度条的库，使得处理进度GUI化\n    for filepath in tqdm(episodes): \n        with open(filepath) as f:\n            #json_load表示从json文件中读取的数据形成的对象\n            json_load = json.load(f)\n\n        ep_id = json_load['info']['EpisodeId']\n        #返回rewards数组最大值的索引（本质上是选择最后得分更高的player进行学习）\n        index = np.argmax([r or 0 for r in json_load['rewards']])\n        #仅使用自己team定义的json文件\n        if json_load['info']['TeamNames'][index] != team_name:\n            continue\n        #对一个json文件的每一步进行操作\n        for i in range(len(json_load['steps'])-1):\n            #如果在该步执行后存在该\"Active\"状态说明我方存活\n            if json_load['steps'][i][index]['status'] == 'ACTIVE':\n                #如果该步状态后依然我方active，load下一步状态的所有动作，放入actions中\n                actions = json_load['steps'][i+1][index]['action']\n                #load当前步骤后的全地图资源状态\n                obs = json_load['steps'][i][0]['observation']\n                \n                if depleted_resources(obs):\n                    break\n                \n                obs['player'] = index\n                #将obs重新整合为一个字典\n                obs = dict([\n                    (k,v) for k,v in obs.items() \n                    if k in ['step', 'updates', 'player', 'width', 'height']\n                ])\n                obs_id = f'{ep_id}_{i}'\n                #obses为所有obs字典的列表集合\n                obses[obs_id] = obs\n                                \n                for action in actions:\n                    #label为当前执行动作对应的下标\n                    unit_id, label = to_label(action)\n                    if label is not None:\n                        #如果动作有方向或者待在city中，那么添加到列表samples中，定义的append类似于C的宏定义\n                        append((obs_id, unit_id, label))\n#最终得到全地图每一步执行后的包括资源、各palyer单位的字典集合obses,所有存活单位每一回合的移动samples\n    return obses, samples","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"episode_dir = '../input/d/shoheiazuma/lux-ai-episodes'\nobses, samples = create_dataset_from_json(episode_dir)\nprint('obses:', len(obses), 'samples:', len(samples))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#将所有sample的最后一个label，即移动方向制作成list\nlabels = [sample[-1] for sample in samples]\nactions = ['north', 'south', 'west', 'east', 'bcity']\n#打印各个方向动作的总次数\nfor value, count in zip(*np.unique(labels, return_counts=True)):\n    print(f'{actions[value]:^5}: {count:>3}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Input For Training","metadata":{}},{"cell_type":"code","source":"# Input for Neural Network\ndef make_input(obs, unit_id):\n    #x,y coordiantes\n    width, height = obs['width'], obs['height']\n    #//为整数除法，相当于逻辑右移一位\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    #制作一个三维全为浮点数0的列表\n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        #split方法通过指定分隔符分隔字符串\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        #a player unit which contains all information\n        #str[1]为0时表示worker，为1时表示cart\n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,#在第0层有unit的位置标上1\n                    (wood + coal + uranium) / 100#在第1层对应有unit的位置，标记其装载材料的比例\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3#结果为2或者5\n                #在第2层标记非unit_id的本方单位位置，第3层标记本方cooldown / 6，第4层标记其装载材料的比例\n                #在第5层标记非unit_id的敌方单位位置，第6层标记本方cooldown / 6，第7层标记其装载材料的比例\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown / 6,\n                    (wood + coal + uranium) / 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            #第8层标记本方citytile位置，第9层标记该city在黑夜能持续几天\n            #第10层标记敌方citytile位置，第11层标记该city在黑夜能持续几天\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            #第12、13、14层分别放wood、coal、uranium的位置极其装载比例\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            #第15层放我方研究点数\n            #第16层放敌方研究点数\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities参数计算\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    b[17, :] = obs['step'] % 40 / 40\n    # Turns\n    b[18, :] = obs['step'] / 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\n\nclass LuxDataset(Dataset):\n    def __init__(self, obses, samples):\n        self.obses = obses\n        self.samples = samples\n        \n    def __len__(self):\n        return len(self.samples)\n\n    def __getitem__(self, idx):\n        obs_id, unit_id, action = self.samples[idx]\n        obs = self.obses[obs_id]\n        state = make_input(obs, unit_id)\n        \n        return state, action","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model for Training","metadata":{}},{"cell_type":"code","source":"# Neural Network for Lux AI\n#class torch.nn.Module是所有网络的基类，所有模型也应该继承这个类。\n#此为基础的卷积层模型\nclass BasicConv2d(nn.Module):\n    def __init__(self, input_dim, output_dim, kernel_size, bn):\n        super().__init__()\n        #padding(int or tuple, optional) - 输入的每一条边补充0的层数,这是为了防止卷积核的大小与步长使得一些边缘数据无法被遍历，所以需要进行填充\n        #kerner_size(int or tuple) - 卷积核的尺寸\n        #输入的尺度是(N, C_in,H,W)，输出尺度（N,C_out,H_out,W_out）\n        #这里padding填充这个数量的目的是保证在一次卷积操作后其尺寸与原尺寸保持相同\n        self.conv = nn.Conv2d(\n            input_dim, output_dim, \n            kernel_size=kernel_size, \n            padding=(kernel_size[0] // 2, kernel_size[1] // 2)\n        )\n        \n        #对小批量(mini-batch)3d数据组成的4d输入进行批标准化(Batch Normalization)操作\n        #在每一个小批量（mini-batch）数据中，计算输入各个维度的均值和标准差\n        #在训练时，该层计算每次输入的均值与方差，并进行移动平均。移动平均默认的动量值为0.1。\n        #输入输出相同\n        #BatchNorm2d函数是在使用卷积计算后进行归一化，防止relu前的数据过大导致网络不稳定\n        self.bn = nn.BatchNorm2d(output_dim) if bn else None\n\n    def forward(self, x):\n        h = self.conv(x)\n        h = self.bn(h) if self.bn is not None else h\n        return h\n\n\nclass LuxNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        layers, filters = 12, 32\n        #model initialization\n        self.conv0 = BasicConv2d(20, filters, (3, 3), True)\n        #将submodules保存在一个list中。ModuleList可以像一般的Python list一样被索引，即每一个都是用于存储一个layer的\n        self.blocks = nn.ModuleList([BasicConv2d(filters, filters, (3, 3), True) for _ in range(layers)])\n        #nn.Linear（）是用于设置网络中的全连接层的，需要注意在二维图像处理的任务中\n        #全连接层的输入与输出一般都设置为二维张量，形状通常为[batch_size, size]\n        #其中前两个参数分别为in的size，5为输出的size\n        self.head_p = nn.Linear(filters, 5, bias=False)\n\n    #神经网络的前向传播\n    def forward(self, x):\n        #此为激励层的内容，relu_是一种非线性激活函数，本质上在深度神经网络上可以逼近任何类型的函数\n        #relu函数的第二个参数inplace默认值为false，表示不改变输入的数据\n        h = F.relu_(self.conv0(x))\n        for block in self.blocks:\n            h = F.relu_(h + block(h))\n        #view函数相当于resize的功能，将原来的tensor变换成指定的维度\n        #这里是将激励值乘入输入x，再将其重新张成h.size(0)*h.size(1)*剩余的形式并求和\n        h_head = (h * x[:,:1]).view(h.size(0), h.size(1), -1).sum(-1)\n        #调用head_p函数张成二维向量\n        p = self.head_p(h_head)\n        return p","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs):\n    best_acc = 0.0\n    #动态改变学习率的sheduler\n    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.1)\n    \n    for epoch in range(num_epochs):\n        #显式地指定model使用gpu\n        model.cuda()\n        #在Pytorch训练中有两种模式，train为训练模式，eval为评估模式\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                #在使用pytorch构建神经网络的时候，训练过程中会在程序上方添加一句model.train()，作用是启用batch normalization和dropout\n                model.train()\n            else:\n                #测试过程中会使用model.eval()，这时神经网络会沿用batch normalization的值，并不使用dropout，即我们这里不是在训练模型\n                #那么就不需要进行dropout改变模型，故调用该函数保证dropout不变\n                model.eval()\n                \n            epoch_loss = 0.0\n            epoch_acc = 0\n            \n            dataloader = dataloaders_dict[phase]\n            #对模型进行多次训练\n            for item in tqdm(dataloader, leave=False):\n                states = item[0].cuda().float()\n                actions = item[1].cuda().long()\n                #将模型的参数梯度初始化为0\n                optimizer.zero_grad()\n                #在我们处于训练模式下时，允许计算局部梯度\n                with torch.set_grad_enabled(phase == 'train'):\n                    policy = model.forward(states)\n                    #criterion为损失函数，计算损失\n                    loss = criterion(policy, actions)\n                    #返回所有张量最大值\n                    _, preds = torch.max(policy, 1)\n\n                    #如果处于训练模式下，损失函数backward进行反向传播梯度的计算，并使用优化器的step函数来更新参数\n                    if phase == 'train':\n                        #当前Variable对leaf variable求偏导，计算好梯度\n                        loss.backward()\n                        #根据前面求出的梯度更新参数\n                        optimizer.step()\n\n                    epoch_loss += loss.item() * len(policy)\n                    epoch_acc += torch.sum(preds == actions.data)\n            #归一化\n            data_size = len(dataloader.dataset)\n            epoch_loss = epoch_loss / data_size\n            epoch_acc = epoch_acc.double() / data_size\n            if phase == 'train':\n                scheduler.step()\n            print(f'Epoch {epoch + 1}/{num_epochs} | {phase:^5} | Loss: {epoch_loss:.4f} | Acc: {epoch_acc:.4f}')\n        #产生了更好结果的情况\n        if epoch_acc > best_acc:\n            traced = torch.jit.trace(model.cpu(), torch.rand(1, 20, 32, 32))\n            traced.save('model.pth')\n            best_acc = epoch_acc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LuxNet()\n#train_test_split将原始数据按照比例划分为“测试集”“训练集”\n# test_size：样本占比，如果是整数的话就是样本的数量\n\n# random_state：是随机数的种子。\n# 随机数种子：其实就是该组随机数的编号，在需要重复试验的时候，保证得到一组一样的随机数。\n#stratify是为了保持split前类的分布，保证其在训练集中的分布比例不变\ntrain, val = train_test_split(samples, test_size=0.15, random_state=42, stratify=labels)\nbatch_size = 64\n#shuffle为false表示不打乱传入的数据\n#num_workers表示了会有多少进程共同执行\ntrain_loader = DataLoader(\n    LuxDataset(obses, train), \n    batch_size=batch_size, \n    shuffle=True, \n    num_workers=2\n)\nval_loader = DataLoader(\n    LuxDataset(obses, val), \n    batch_size=batch_size, \n    shuffle=False, \n    num_workers=2\n)\ndataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n#交叉熵损失函数，一种使用对数的损失函数\ncriterion = nn.CrossEntropyLoss()\n#利用Adam(Adaptive Moment Estimation)进行优化\n#它的优点主要在于经过偏置校正后，每一次迭代学习率都有个确定范围，使得参数比较平稳\n#lr为学习率，过高会导致不稳定与过拟合\noptimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\ntrain_model(model, dataloaders_dict, criterion, optimizer, num_epochs=25)","metadata":{"_kg_hide-input":false,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"%%writefile agent.py\nimport os\nimport numpy as np\nimport torch\nfrom lux.game import Game\nfrom lux.game_map import Cell, RESOURCE_TYPES, Position\nfrom lux.constants import Constants\nfrom lux.game_constants import GAME_CONSTANTS\nfrom lux import annotate\nimport math\nimport sys\n\n\npath = '/kaggle_simulations/agent' if os.path.exists('/kaggle_simulations') else '.'\nmodel = torch.jit.load(f'{path}/model.pth')\nmodel.eval()\n\n\ndef make_input(obs, unit_id):\n    width, height = obs['width'], obs['height']\n    x_shift = (32 - width) // 2\n    y_shift = (32 - height) // 2\n    cities = {}\n    \n    b = np.zeros((20, 32, 32), dtype=np.float32)\n    \n    for update in obs['updates']:\n        strs = update.split(' ')\n        input_identifier = strs[0]\n        \n        if input_identifier == 'u':\n            x = int(strs[4]) + x_shift\n            y = int(strs[5]) + y_shift\n            wood = int(strs[7])\n            coal = int(strs[8])\n            uranium = int(strs[9])\n            if unit_id == strs[3]:\n                # Position and Cargo\n                b[:2, x, y] = (\n                    1,\n                    (wood + coal + uranium) / 100\n                )\n            else:\n                # Units\n                team = int(strs[2])\n                cooldown = float(strs[6])\n                idx = 2 + (team - obs['player']) % 2 * 3\n                b[idx:idx + 3, x, y] = (\n                    1,\n                    cooldown / 6,\n                    (wood + coal + uranium) / 100\n                )\n        elif input_identifier == 'ct':\n            # CityTiles\n            team = int(strs[1])\n            city_id = strs[2]\n            x = int(strs[3]) + x_shift\n            y = int(strs[4]) + y_shift\n            idx = 8 + (team - obs['player']) % 2 * 2\n            b[idx:idx + 2, x, y] = (\n                1,\n                cities[city_id]\n            )\n        elif input_identifier == 'r':\n            # Resources\n            r_type = strs[1]\n            x = int(strs[2]) + x_shift\n            y = int(strs[3]) + y_shift\n            amt = int(float(strs[4]))\n            b[{'wood': 12, 'coal': 13, 'uranium': 14}[r_type], x, y] = amt / 800\n        elif input_identifier == 'rp':\n            # Research Points\n            team = int(strs[1])\n            rp = int(strs[2])\n            b[15 + (team - obs['player']) % 2, :] = min(rp, 200) / 200\n        elif input_identifier == 'c':\n            # Cities\n            city_id = strs[2]\n            fuel = float(strs[3])\n            lightupkeep = float(strs[4])\n            cities[city_id] = min(fuel / lightupkeep, 10) / 10\n    \n    # Day/Night Cycle\n    b[17, :] = obs['step'] % 40 / 40\n    # Turns\n    b[18, :] = obs['step'] / 360\n    # Map Size\n    b[19, x_shift:32 - x_shift, y_shift:32 - y_shift] = 1\n\n    return b\n\n\ngame_state = None\ndef get_game_state(observation):\n    global game_state\n    \n    if observation[\"step\"] == 0:\n        game_state = Game()\n        game_state._initialize(observation[\"updates\"])\n        game_state._update(observation[\"updates\"][2:])\n        game_state.id = observation[\"player\"]\n    else:\n        game_state._update(observation[\"updates\"])\n    return game_state\n\ndef sum_fuel(unit):\n    return (unit.cargo.wood + unit.cargo.coal * 10 + unit.cargo.uranium * 40)\n\n#判断pos是否在city中的函数\ndef in_city(pos):    \n    try:\n        city = game_state.map.get_cell_by_pos(pos).citytile\n        return city is not None and city.team == game_state.id\n    except:\n        return False\n\ndef call_func(obj, method, args=[]):\n    #获取对象的所有属性值\n    return getattr(obj, method)(*args)\n\n\nunit_actions = [('move', 'n'), ('move', 's'), ('move', 'w'), ('move', 'e'), ('build_city',)]\n\ndef could_get_res(pos, player):\n    is_coal = (player.research_points >= 50)\n    is_uranium = (player.research_points >= 200)\n    fuelparam = {\"coal\":10,\"uranium\":40, \"wood\":1}\n    try:\n        res = game_state.map.get_cell_by_pos(pos).has_resource()\n        if not res:\n            return 0, 0\n        type = game_state.map.get_cell_by_pos(pos).resource.type\n        amount = game_state.map.get_cell_by_pos(pos).resource.amount\n        if ((type == \"coal\" and is_coal) or (type == \"uranium\" and is_uranium) or type == \"wood\"):\n            return amount, fuelparam[type]\n        else:\n            return 0, 0\n    except:\n        return 0, 0\n\n\n# 若某车在city内，判断当前pos是否靠近某可获取资源,用于让夜晚回归的unit再次出去\ndef could_get_res(pos, player):\n    is_coal = (player.research_points >= 50)\n    is_uranium = (player.research_points >= 200)\n    fuelparam = {\"coal\":10,\"uranium\":40, \"wood\":1}\n    try:\n        res = game_state.map.get_cell_by_pos(pos).has_resource()\n        if not res:\n            return 0, 0\n        type = game_state.map.get_cell_by_pos(pos).resource.type\n        amount = game_state.map.get_cell_by_pos(pos).resource.amount\n        if ((type == \"coal\" and is_coal) or (type == \"uranium\" and is_uranium) or type == \"wood\"):\n            return amount, fuelparam[type]\n        else:\n            return 0, 0\n    except:\n        return 0, 0\n\ndef get_units_in_citytile(pos, player):\n    unit_list = []\n    for unit in player.units:\n        if(unit.pos.x == pos.x and unit.pos.y == pos.y and unit.can_act()):\n            unit_list.append(unit)\n    return unit_list\n\n# 若某车在city内，判断当前pos是否靠近某可获取资源,用于让夜晚回归的unit再次出去\ndef step_out_city(unit, player, dest):\n    incitys = get_units_in_citytile(unit.pos, player)\n    x = unit.pos.x\n    y = unit.pos.y\n    subpos1 = Position(x, y - 1)\n    subpos2 = Position(x, y + 1)\n    subpos3 = Position(x - 1, y)\n    subpos4 = Position(x + 1, y)\n    subpossub1 = Position(x, y - 2)  # for 1\n    subpossub2 = Position(x + 1, y - 1)  # for 1 4\n    subpossub3 = Position(x - 1, y - 1)  # for 1 3\n    subpossub4 = Position(x, y + 2)  # for 2\n    subpossub5 = Position(x - 1, y + 1)  # for 2 3\n    subpossub6 = Position(x + 1, y + 1)  # for 2 4\n    subpossub7 = Position(x - 2, y)  # for 3\n    subpossub8 = Position(x + 2, y)  # for 4\n    try:\n        subresamount1, subresparam1 = could_get_res(subpos1, player)\n        subresamount2, subresparam2 = could_get_res(subpos2, player)\n        subresamount3, subresparam3 = could_get_res(subpos3, player)\n        subresamount4, subresparam4 = could_get_res(subpos4, player)\n        cityid = game_state.map.get_cell_by_pos(unit.pos).citytile.cityid\n        light_up_keep = check_light_up_keep(player, cityid)\n        fuel = check_fuel(player, cityid)\n        nightdays = (40 - game_state.turn) % 40\n        fuelneed = nightdays * light_up_keep\n        aroundamount = subresamount1 + subresamount2 + subresamount3 + subresamount4\n        aroundfuel = subresamount1 * subresparam1 + subresamount2 * subresparam2 + \\\n                     subresamount3 * subresparam3 + subresamount4 * subresparam4\n        if (len(incitys) == 1 and fuel < fuelneed and aroundamount > nightdays - (fuelneed - fuel)/light_up_keep\n                and aroundfuel > fuelneed - fuel):\n            return unit.move('c'), unit.pos\n        if(len(incitys) > 1 and incitys[0].id == unit.id):\n            return unit.move('c'), unit.pos\n        subresamountsub1, subresparamsub1 = could_get_res(subpossub1, player)\n        subresamountsub2, subresparamsub2 = could_get_res(subpossub2, player)\n        subresamountsub3, subresparamsub3 = could_get_res(subpossub3, player)\n        if (subpos1 not in dest and ((subresamount1 and y > 0) or (subresamountsub1 and y > 1) or (\n                subresamountsub2 and y > 0 and x < game_state.map.width - 1) or (\n                                             subresamountsub3 and y > 0 and x > 0))):\n            act = unit_actions[0]\n            action1, pos1 = call_func(unit, *act), subpos1\n        else:\n            action1, pos1 = unit.move('c'), unit.pos\n        subresamountsub4, subresparamsub4 = could_get_res(subpossub4, player)\n        subresamountsub5, subresparamsub5 = could_get_res(subpossub5, player)\n        subresamountsub6, subresparamsub6 = could_get_res(subpossub6, player)\n        if (subpos2 not in dest and ((subresamount2 and y < game_state.map.height - 1) or (\n                subresamountsub4 and y < game_state.map.height - 2) or (\n                                             subresamountsub5 and y < game_state.map.height - 1 and x > 0) or (\n                                             subresamountsub6 and y < game_state.map.height - 1 and x < game_state.map.width - 1))):\n            act = unit_actions[1]\n            action2, pos2 = call_func(unit, *act), subpos2\n        else:\n            action2, pos2 = unit.move('c'), unit.pos\n        subresamountsub7, subresparamsub7 = could_get_res(subpossub7, player)\n        if (subpos3 not in dest and ((subresamount3 and x > 0) or (subresamountsub3 and y > 0 and x > 0) or (\n                subresamountsub5 and y < game_state.map.height - 1 and x > 0) or (subresamountsub7 and x > 1))):\n            act = unit_actions[2]\n            action3, pos3 = call_func(unit, *act), subpos3\n        else:\n            action3, pos3 = unit.move('c'), unit.pos\n        subresamountsub8, subresparamsub8 = could_get_res(subpossub8, player)\n        if (subpos4 not in dest and ((subresamount4 and x < game_state.map.width - 1) or (\n                subresamountsub2 and y > 0 and x < game_state.map.width - 1) or (\n                                             subresamountsub6 and y < game_state.map.height - 1 and x < game_state.map.width - 1) or (\n                                             subresamountsub8 and x < game_state.map.width - 2))):\n            act = unit_actions[3]\n            action4, pos4 = call_func(unit, *act), subpos4\n        else:\n            action4, pos4 = unit.move('c'), unit.pos\n        amount1 = subresamount1 + subresamountsub1 + subresamountsub2 + subresamountsub3\n        if(amount1 > 1):\n            fuel1 = subresamount1 * subresparam1 + subresamountsub1 * subresparamsub1 \\\n                    + subresamountsub2 * subresparamsub2 + subresamountsub3 * subresparamsub3\n        else:\n            fuel1 = 0\n\n        amount2 = subresamount2 + subresamountsub4 + subresamountsub5 + subresamountsub6\n        if (amount2 > 1):\n            fuel2 = subresamount2 * subresparam2 + subresamountsub4 * subresparamsub4 \\\n                    + subresamountsub5 * subresparamsub5 + subresamountsub6 * subresparamsub6\n        else:\n            fuel2 = 0\n\n        amount3 = subresamount3 + subresamountsub3 + subresamountsub5 + subresamountsub7\n        if(amount3 > 1):\n            fuel3 = subresamount3 * subresparam3 + subresamountsub3 * subresparamsub3 \\\n                    + subresamountsub5 * subresparamsub5 + subresamountsub7 * subresparamsub7\n        else:\n            fuel3 = 0\n\n        amount4 = subresamount4 + subresamountsub2 + subresamountsub6 + subresamountsub8\n        if(amount4 > 1):\n            fuel4 = subresamount4 * subresparam4 + subresamountsub2 * subresparamsub2 \\\n                    + subresamountsub6 * subresparamsub6 + subresamountsub8 * subresparamsub8\n        else:\n            fuel4 = 0\n\n        if(fuel1 >= 8 and fuel1 >= fuel2 and fuel1 >= fuel3 and fuel1 >= fuel4):\n            return action1, pos1\n        if(fuel2 >= 8 and fuel2 >= fuel1 and fuel2 >= fuel3 and fuel2 >= fuel4):\n            return action2, pos2\n        if(fuel3 >= 8 and fuel3 >= fuel1 and fuel3 >= fuel2 and fuel3 >= fuel4):\n            return action3, pos3\n        if(fuel4 >= 8 and fuel4 >= fuel1 and fuel4 >= fuel2 and fuel4 >= fuel3):\n            return action4, pos4\n\n        return unit.move('c'), unit.pos\n    except:\n        return unit.move('c'), unit.pos\n\ndef check_light_up_keep(player, cityid):\n    for city in player.cities.values():\n        if (city.cityid == cityid):\n            return city.get_light_upkeep()\n    return False\n\n\ndef check_fuel(player, cityid):\n    for city in player.cities.values():\n        if (city.cityid == cityid):\n            return city.fuel\n    return False\n\n\ndef rescue_city(unit, player, dest):\n    x = unit.pos.x\n    y = unit.pos.y\n    subpos1 = Position(x, y - 1)\n    subpos2 = Position(x, y + 1)\n    subpos3 = Position(x - 1, y)\n    subpos4 = Position(x + 1, y)\n    if (y > 0 and in_city(subpos1)):\n        cityid = game_state.map.get_cell_by_pos(subpos1).citytile.cityid\n        light_up_keep = check_light_up_keep(player, cityid)\n        fuel = check_fuel(player, cityid)\n        if (subpos1 not in dest and ((40 - game_state.turn % 40) * light_up_keep > fuel)):\n            act = unit_actions[0]\n            return call_func(unit, *act), subpos1\n    if (y < game_state.map.height - 1 and in_city(subpos2)):\n        cityid = game_state.map.get_cell_by_pos(subpos2).citytile.cityid\n        light_up_keep = check_light_up_keep(player, cityid)\n        fuel = check_fuel(player, cityid)\n        if (subpos2 not in dest and ((40 - game_state.turn % 40) * light_up_keep > fuel)):\n            act = unit_actions[1]\n            return call_func(unit, *act), subpos2\n    if (x > 0 and in_city(subpos3)):\n        cityid = game_state.map.get_cell_by_pos(subpos3).citytile.cityid\n        light_up_keep = check_light_up_keep(player, cityid)\n        fuel = check_fuel(player, cityid)\n        if (subpos3 not in dest and ((40 - game_state.turn % 40) * light_up_keep > fuel)):\n            act = unit_actions[2]\n            return call_func(unit, *act), subpos3\n    if (x < game_state.map.width - 1 and in_city(subpos4)):\n        cityid = game_state.map.get_cell_by_pos(subpos4).citytile.cityid\n        light_up_keep = check_light_up_keep(player, cityid)\n        fuel = check_fuel(player, cityid)\n        if (subpos4 not in dest and ((40 - game_state.turn % 40) * light_up_keep > fuel)):\n            act = unit_actions[3]\n            return call_func(unit, *act), subpos4\n    return False\n\n\n# 最终获得两个列表，列表中的worker与citytile相互绑定送资源\ndef fill_city_fuel_list(player, max_dis):\n    fill_worker_list = []\n    fill_citytile_list = []\n    for city in player.cities.values():\n        cityid = city.cityid\n        light_up_keep = check_light_up_keep(player, cityid)\n        fuel = check_fuel(player, cityid)\n        extra_need = min(10, 40 - (game_state.turn % 40)) * light_up_keep - fuel\n        if (extra_need <= 0):\n            continue\n        min_distance = 100\n        flag = False\n        unit_corr = None\n        citytile = None\n        for city_tile in city.citytiles:\n            for unit in player.units:\n                tmp = abs(city_tile.pos.x - unit.pos.x) + abs(city_tile.pos.y - unit.pos.y)\n                if (sum_fuel(unit) < 40 or not unit.can_act()):\n                    continue\n                if (tmp <= min_distance and tmp <= max_dis):\n                    min_distance = abs(city_tile.pos.x - unit.pos.x) + abs(city_tile.pos.y - unit.pos.y)\n                    citytile = city_tile\n                    unit_corr = unit\n        if (not unit_corr == None and not citytile == None):\n            fill_worker_list.append(unit_corr)\n            fill_citytile_list.append(citytile)\n    return fill_worker_list, fill_citytile_list\n\n\n# 为城市补充燃料的寻路\ndef get_fill_way(unit, citytile, dest):\n    target_x = citytile.pos.x\n    target_y = citytile.pos.y\n    pos_x = unit.pos.x\n    pos_y = unit.pos.y\n    if (target_x == pos_x and target_y > pos_y and Position(pos_x, pos_y + 1) not in dest):\n        act = unit_actions[1]\n        return call_func(unit, *act), Position(pos_x, pos_y + 1)\n    if (target_x == pos_x and target_y < pos_y and Position(pos_x, pos_y - 1) not in dest):\n        act = unit_actions[0]\n        return call_func(unit, *act), Position(pos_x, pos_y - 1)\n    if (target_y == pos_y and target_x > pos_x and Position(pos_x + 1, pos_y) not in dest):\n        act = unit_actions[3]\n        return call_func(unit, *act), Position(pos_x + 1, pos_y)\n    if (target_y == pos_y and target_x < pos_x and Position(pos_x - 1, pos_y) not in dest):\n        act = unit_actions[2]\n        return call_func(unit, *act), Position(pos_x - 1, pos_y)\n    if (target_x > pos_x and target_y > pos_y):\n        if (Position(pos_x, pos_y + 1) not in dest and Position(pos_x + 1, pos_y) not in dest):\n            label = np.random.randint(0, 2) * 2 + 1\n            act = unit_actions[label]\n            pos = unit.pos.translate(act[-1], 1)\n            return call_func(unit, *act), pos\n        if (Position(pos_x, pos_y + 1) not in dest):\n            act = unit_actions[1]\n            return call_func(unit, *act), Position(pos_x, pos_y + 1)\n        if (Position(pos_x + 1, pos_y) not in dest):\n            act = unit_actions[3]\n            return call_func(unit, *act), Position(pos_x + 1, pos_y)\n    if (target_x < pos_x and target_y > pos_y):\n        if (Position(pos_x, pos_y + 1) not in dest and Position(pos_x - 1, pos_y) not in dest):\n            label = np.random.randint(1, 3)\n            act = unit_actions[label]\n            pos = unit.pos.translate(act[-1], 1)\n            return call_func(unit, *act), pos\n        if (Position(pos_x, pos_y + 1) not in dest):\n            act = unit_actions[1]\n            return call_func(unit, *act), Position(pos_x, pos_y + 1)\n        if (Position(pos_x - 1, pos_y) not in dest):\n            act = unit_actions[2]\n            return call_func(unit, *act), Position(pos_x - 1, pos_y)\n    if (target_x > pos_x and target_y < pos_y):\n        if (Position(pos_x, pos_y - 1) not in dest and Position(pos_x + 1, pos_y) not in dest):\n            label = np.random.randint(0, 2) * 3\n            act = unit_actions[label]\n            pos = unit.pos.translate(act[-1], 1)\n            return call_func(unit, *act), pos\n        if (Position(pos_x, pos_y - 1) not in dest):\n            act = unit_actions[0]\n            return call_func(unit, *act), Position(pos_x, pos_y - 1)\n        if (Position(pos_x + 1, pos_y) not in dest):\n            act = unit_actions[3]\n            return call_func(unit, *act), Position(pos_x + 1, pos_y)\n    if (target_x < pos_x and target_y < pos_y):\n        if (Position(pos_x, pos_y - 1) not in dest and Position(pos_x - 1, pos_y) not in dest):\n            label = np.random.randint(0, 2) * 2\n            act = unit_actions[label]\n            pos = unit.pos.translate(act[-1], 1)\n            return call_func(unit, *act), pos\n        if (Position(pos_x, pos_y - 1) not in dest):\n            act = unit_actions[0]\n            return call_func(unit, *act), Position(pos_x, pos_y - 1)\n        if (Position(pos_x - 1, pos_y) not in dest):\n            act = unit_actions[2]\n            return call_func(unit, *act), Position(pos_x - 1, pos_y)\n    return False\n\n\ndef get_action(policy, unit, player, dest):\n    # argsort函数将列表中的元素从小到大排列，提取其对应的index(索引)形成一个新列表\n    for label in np.argsort(policy)[::-1]:\n        if label == 4 and not unit.can_build(game_state.map):\n            # 模型行动不符合行动原则\n\n            return step_out_city(unit, player, dest)\n        act = unit_actions[label]\n        pos = unit.pos.translate(act[-1], 1) or unit.pos\n\n        if pos not in dest or in_city(pos):\n            return call_func(unit, *act), pos\n\n    return unit.move('c'), unit.pos\n\n\ndef agent(observation, configuration):\n    global game_state\n\n    game_state = get_game_state(observation)\n    player = game_state.players[observation.player]\n    actions = []\n\n    # City Actions\n    unit_count = len(player.units)\n    for city in player.cities.values():\n        for city_tile in city.citytiles:\n            # 如果能够行动\n            if city_tile.can_act():\n                # 如果可以创建新的工人\n                if unit_count < player.city_tile_count:\n                    actions.append(city_tile.build_worker())\n                    unit_count += 1\n                # 不能创建新的工人但可行动，那么提升研究点数,达到uranium要求不再提升，以便随时创造unit\n                elif not player.researched_uranium():\n                    actions.append(city_tile.research())\n                    player.research_points += 1\n\n    # Worker Actions\n    dest = []\n    fill_worker_list = []\n    fill_citytile_list = []\n    if (game_state.turn % 40 >= 24 and game_state.turn % 40 <= 34):\n        fill_worker_list, fill_citytile_list = fill_city_fuel_list(player, (34 - game_state.turn % 40) // 2)\n    for unit in player.units:\n        flag = False\n        if (game_state.turn % 40 >= 24 and game_state.turn % 40 <= 34):\n            for i in range(len(fill_worker_list)):\n                if (unit == fill_worker_list[i]):\n                    unit = fill_worker_list[i]\n                    citytile = fill_citytile_list[i]\n                    if (not get_fill_way(unit, citytile, dest) == False):\n                        action, pos = get_fill_way(unit, citytile, dest)\n                        actions.append(action)\n                        if not in_city(pos):\n                            dest.append(pos)\n                        flag = True\n                        break\n        if flag:\n            continue\n        if unit.can_act() and (game_state.turn % 40 >= 30 and not in_city(unit.pos)):\n            if not (rescue_city(unit, player, dest) == False):\n                action, pos = step_out_city(unit, player, dest)\n                # 添加action与dest记录\n                actions.append(action)\n                if not in_city(pos):\n                    dest.append(pos)\n                # print(action, game_state.turn)\n                continue\n        # worker可以行动且处于白天或者不呆在城市里\n        if unit.can_act() and (game_state.turn % 40 < 30 or not in_city(unit.pos)):\n            state = make_input(observation, unit.id)\n            # torch.no_grad()是一个上下文管理器，被该语句wrap起来的部分将不会track梯度，即不会改变之前grad属性\n            with torch.no_grad():\n                # 从nparray中建立一个张量 unsqueeze是升高一个维度，将首个维度置为1\n                p = model(torch.from_numpy(state).unsqueeze(0))\n\n            policy = p.squeeze(0).numpy()\n\n            action, pos = get_action(policy, unit, player, dest)\n            # 添加action与dest记录\n            actions.append(action)\n            if not in_city(pos):\n                dest.append(pos)\n        elif (unit.can_act() and game_state.turn % 40 >= 30 and in_city(unit.pos)):\n            action, pos = step_out_city(unit, player, dest)\n            # 添加action与dest记录\n            actions.append(action)\n            if not in_city(pos):\n                dest.append(pos)\n            # print(action, game_state.turn)\n    return actions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_environments import make\n\nenv = make(\"lux_ai_2021\", configuration={\"width\": 24, \"height\": 24, \"loglevel\": 2, \"annotations\": True}, debug=True)\nsteps = env.run(['agent.py', 'agent.py'])\nenv.render(mode=\"ipython\", width=1200, height=800)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!tar -czf submission.tar.gz *","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}