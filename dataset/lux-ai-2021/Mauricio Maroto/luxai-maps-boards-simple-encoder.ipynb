{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-22T20:59:07.797022Z","iopub.execute_input":"2021-11-22T20:59:07.797909Z","iopub.status.idle":"2021-11-22T20:59:07.817382Z","shell.execute_reply.started":"2021-11-22T20:59:07.797865Z","shell.execute_reply":"2021-11-22T20:59:07.816599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom statistics import mean\nfrom torch import load, max as pt_max, ones, save, no_grad\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.optim import Adam\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\n\n# Here we train a net to classify between 4 classes:\n# 0: 12\n# 1: 16\n# 2: 24\n# 3: 32\n\n# How do I get the board encoder?\n# The trick is to code in the net forward method not only the full feed-forward, \n# but also some intermediate layer, which is suppossed to be an encoder\n\n# So, despite of each board being different heights (and resources placement), \n# the net has achieved a fixed-length output of 8 X 8\n\n# No matter, what board we feed it into, the net will \n# traslate it to a new latent space of 8 X 8\n\n\nclass DS(Dataset):\n    def __init__(self, maps, labels) -> None:\n        self.maps = maps\n        self.labels = labels\n\n    def __len__(self):\n        return len(self.labels)\n\n    def __getitem__(self, idx):\n        X = self.maps[idx]\n        y = self.labels[idx]\n        return X, y\n\n\nclass MAPS_NET(nn.Module):\n    def __init__(\n        self,\n        input_size=2,\n        out_channels=48,\n        kernel_size=3,\n        hidden_layers=9,\n        output_dim=4,\n    ):\n        super().__init__()\n        self.out_channels = out_channels\n\n        self.to_conv2d = nn.Conv2d(in_channels=input_size,\n                                   out_channels=out_channels,\n                                   kernel_size=kernel_size)\n        self.conv2d = nn.Conv2d(in_channels=out_channels,\n                                out_channels=out_channels,\n                                kernel_size=kernel_size)\n\n        self.conv2ds = nn.ModuleList(\n            [self.conv2d for _ in range(hidden_layers)])\n        # self.shape_helper = ones((1, 32, 32))\n\n        self.helper = 432\n\n        self.to_linear = nn.Linear(self.helper, 64)\n        self.output = nn.Linear(64, output_dim)\n\n    def forward(self, x):\n        \"\"\"Forward/Predict\"\"\"\n        step_size = x.shape[0]\n        x = self.to_conv2d(x)\n\n        for conv2d in self.conv2ds:\n            x = F.max_pool2d(F.celu(F.dropout2d(conv2d(x), p=0.4)),\n                             kernel_size=2,\n                             stride=1)\n        x = x.reshape(step_size, x.shape[1] * x.shape[2] * x.shape[3])\n\n        x = self.to_linear(x)\n        res = self.output(x)\n        res = F.log_softmax(res, dim=-1)\n\n        return x, res\n\nif __name__ == '__main__':\n    # Data\n    maps = load('/kaggle/input/envdata4/env_maps.pth')\n    print(maps.shape)\n    labels = load('/kaggle/input/envdata4/env_maps_labels.pth')\n    print(labels.shape)\n\n    # HP\n    BATCH_SIZE = 32\n    LR = 0.00075\n\n    # Net\n    net = MAPS_NET().train().cuda()\n    optimizer = Adam(net.parameters(), lr=LR)\n    criterion = nn.NLLLoss()\n\n    # Split\n    train_X, test_X, train_y, test_y = train_test_split(maps, labels)\n\n    # Train\n    train_ds = DS(train_X, train_y)\n    train_dl = DataLoader(train_ds,\n                        batch_size=BATCH_SIZE,\n                        shuffle=True,\n                        drop_last=True)\n    for epoch in range(5):\n        running_loss = []\n        correct = 0\n        total = 0\n        i = 0\n        for inputs, labels in train_dl:\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            encoder, outputs = net(inputs)\n\n            optimizer.zero_grad()\n            loss = criterion(outputs, labels).mean()\n            loss.backward()\n            optimizer.step()\n\n            # print statistics\n            running_loss.append(loss.item())\n            if i % 10 == 0:\n                print('[%d, %5d] Loss: %.3f' %\n                    (epoch + 1, i + 1, mean(running_loss)),\n                    end=' - ')\n                _, predicted = pt_max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                print('Accuracy: %d %%' % (100 * correct / total))\n\n            i += 1\n\n    # Eval\n    with no_grad():\n        net = net.eval()\n        test_ds = DS(test_X, test_y)\n        test_dl = DataLoader(test_ds,\n                            batch_size=BATCH_SIZE,\n                            shuffle=True,\n                            drop_last=True)\n        running_loss = []\n        correct = 0\n        total = 0\n        i = 0\n        for inputs, labels in test_dl:\n            inputs = inputs.cuda()\n            labels = labels.cuda()\n            encoder, outputs = net(inputs)\n\n            # print statistics\n            running_loss.append(loss.item())\n            if i % 10 == 0:\n                print('Test Loss: %.3f' % (mean(running_loss)), end=' - ')\n                _, predicted = pt_max(outputs.data, 1)\n                total += labels.size(0)\n                correct += (predicted == labels).sum().item()\n                print('Test Accuracy: %d %%' % (100 * correct / total))\n\n            i += 1\n\n    # Persist\n    #save(net.state_dict(), f'env_maps_net_{100 * correct / total:.1f}%.pth')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T21:03:31.769972Z","iopub.execute_input":"2021-11-22T21:03:31.770301Z","iopub.status.idle":"2021-11-22T21:03:37.750783Z","shell.execute_reply.started":"2021-11-22T21:03:31.770262Z","shell.execute_reply":"2021-11-22T21:03:37.749362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import zeros, stack, tensor\n\nimport matplotlib.pyplot as plt\n\nfrom kaggle_environments import make\n\n# Here I just code to extract a board from a env lux game\n\nclass ENV_DATA:\n    def __init__(self) -> None:\n        pass\n\n    def draw_board(self):\n        return make(\"lux_ai_2021\",\n                    configuration={\n                        \"loglevel\": 1,\n                        \"annotations\": True\n                    },\n                    debug=True)\n\n    def get_init_obs(self, board):\n        _ = board.train([None, 'simple_agent'])\n        obs, _ = _.reset(), False\n        return obs\n\n    def resource_type_to_num(self, r_type):\n        dic = {'wood': 1, 'coal': 2, 'uranium': 3}\n        return dic[r_type]\n\n    def create_entity_maps(self, obs):\n        wh = obs['height']\n\n        maps = [zeros((32, 32)) for i in range(2)]\n\n        for entity in (obs['updates']):\n            strs = entity.split(' ')\n            input_identifier = strs[0]\n\n            if input_identifier == 'r':\n                r_type = strs[1]\n                x = int(strs[2])\n                y = int(strs[3])\n                amt = int(float(strs[4]))\n                maps[0][x, y] = 1\n                maps[1][x, y] = self.resource_type_to_num(r_type)\n                # maps[2][x, y] = amt / 800\n\n        return wh, maps\n    \n    def wh_to_y(self, wh):\n        d = {12: 0, 16: 1, 24: 2, 32: 3}\n        return d[wh]\n\n    def get_maps(self):\n        board = self.draw_board()\n        init_obs = self.get_init_obs(board)\n        wh, maps = self.create_entity_maps(init_obs)\n        return stack(maps), tensor(wh)\n    \n    def get_latent(self):\n        wh, maps = self.get_maps()\n        return maps, wh","metadata":{"execution":{"iopub.status.busy":"2021-11-22T21:05:16.658087Z","iopub.execute_input":"2021-11-22T21:05:16.658639Z","iopub.status.idle":"2021-11-22T21:05:16.671256Z","shell.execute_reply.started":"2021-11-22T21:05:16.658598Z","shell.execute_reply":"2021-11-22T21:05:16.670199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maps.shape","metadata":{"execution":{"iopub.status.busy":"2021-11-22T21:05:17.964423Z","iopub.execute_input":"2021-11-22T21:05:17.965274Z","iopub.status.idle":"2021-11-22T21:05:17.970326Z","shell.execute_reply.started":"2021-11-22T21:05:17.96523Z","shell.execute_reply":"2021-11-22T21:05:17.969653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hit this cell many times in order to see different maps\n# and its corresponding encoding\n\nenv_data = ENV_DATA()\n\nfig, ax = plt.subplots(1, 3, figsize=(12,8), constrained_layout=True)\nax = ax.ravel()\n\nwh, maps_ = env_data.get_latent()\n_ = ax[0].imshow(maps_[0])\n_ = ax[0].set_title('Resources Position')\n_ = ax[1].imshow(maps_[1])\n_ = ax[1].set_title('Resources Types')\nencoded = net(maps_.unsqueeze(0).cuda())[0].reshape(8,8)\nencoded = encoded.detach().cpu().numpy()\n_ = ax[2].imshow(encoded)\n_ = ax[2].set_title('Net Representation (+97%)')","metadata":{"execution":{"iopub.status.busy":"2021-11-22T21:09:38.72947Z","iopub.execute_input":"2021-11-22T21:09:38.730256Z","iopub.status.idle":"2021-11-22T21:09:39.763062Z","shell.execute_reply.started":"2021-11-22T21:09:38.73022Z","shell.execute_reply":"2021-11-22T21:09:39.762262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WHY I DID ALL THIS?\n\n# My thinking is that, when you do RL, you are doing many things at once\n# I feel the net gets too much noise\n\n# For once, it's trying to learn the inputs representation\n# all the way to i.e. actions distribution,\n# Also, it's trying to discriminate between good/bad actions\n# All with the same loss value...\n\n# I thought that by, a priori, fitting this representation, \n# the net used in RL will have better inputs for better learning\n# at least for latent maps\n\n# TODO\n# Maybe do not feed into this net the initial resources amounts, and re-fit it,\n# because, as resources amounts will be changing in game due to units gathering\n# The net may have a hard time encoding such never-before-seen scenarios\n# thus giving misleading representations...\n# ### DONE!","metadata":{"execution":{"iopub.status.busy":"2021-11-22T15:46:01.730833Z","iopub.execute_input":"2021-11-22T15:46:01.731234Z","iopub.status.idle":"2021-11-22T15:46:01.736995Z","shell.execute_reply.started":"2021-11-22T15:46:01.731195Z","shell.execute_reply":"2021-11-22T15:46:01.734703Z"},"trusted":true},"execution_count":null,"outputs":[]}]}