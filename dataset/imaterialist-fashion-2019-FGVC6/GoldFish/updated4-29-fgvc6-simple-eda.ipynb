{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Let's segment a variety of clothing types!\n# import modules and define utils"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd\npd.set_option(\"display.max_rows\", 101)\nimport os\nprint(os.listdir(\"../input\"))\nimport cv2\nimport json\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"font.size\"] = 15\nimport seaborn as sns\nfrom collections import Counter\nfrom PIL import Image\nimport math\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"input_dir = \"../input/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def classid2label(class_id):\n    category, *attribute = class_id.split(\"_\")\n    return category, attribute","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def print_dict(dictionary, name_dict):\n    print(\"{}{}{}{}{}\".format(\"rank\".ljust(5), \"id\".center(8), \"name\".center(40), \"amount\".rjust(10), \"ratio(%)\".rjust(10)))\n    all_num = sum(dictionary.values())\n    for i, (key, val) in enumerate(sorted(dictionary.items(), key=lambda x: -x[1])):\n        print(\"{:<5}{:^8}{:^40}{:>10}{:>10.3%}\".format(i+1, key, name_dict[key], val, val/all_num))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def print_img_with_labels(img_name, labels, category_name_dict, attribute_name_dict, ax):\n    img = np.asarray(Image.open(input_dir + \"train/\" + img_name))\n    label_interval = (img.shape[0] * 0.9) / len(labels)\n    ax.imshow(img)\n    for num, attribute_id in enumerate(labels):\n        x_pos = img.shape[1] * 1.1\n        y_pos = (img.shape[0] * 0.9) / len(labels) * (num + 2) + (img.shape[0] * 0.1)\n        if(num == 0):\n            ax.text(x_pos, y_pos-label_interval*2, \"category\", fontsize=12)\n            ax.text(x_pos, y_pos-label_interval, category_name_dict[attribute_id], fontsize=12)\n            if(len(labels) > 1):\n                ax.text(x_pos, y_pos, \"attribute\", fontsize=12)\n        else:\n            ax.text(x_pos, y_pos, attribute_name_dict[attribute_id], fontsize=12)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def print_img(img_name, ax):\n    img_df = train_df[train_df.ImageId == img_name]\n    labels = list(set(img_df[\"ClassId\"].values))\n    print_img_with_labels(img_name, labels, category_name_dict, attribute_name_dict, ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def json2df(data):\n    df = pd.DataFrame()\n    for index, el in enumerate(data):\n        for key, val in el.items():\n            df.loc[index, key] = val\n    return df","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"# check Text Data\n* train.csv  \nTraining annotations, contains images with both segmented apparel categories and fine-grained attributes; and images with segmented apparel categories only.\n\n    * `ImageID` : the unique Id of an image\n    * `EncodedPixels` : masks in **run-length encoded format** (please refer to [evaluation page](https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/overview/evaluation) for details).  \n        * `run-length encoded format` : In summary, '1 3 10 5' implies pixels 1,2,3,10,11,12,13,14 are to be included in the mask.  \n        (The pixels are one-indexed and numbered from top to bottom, then left to right: 1 is pixel (1,1), 2 is pixel (2,1), etc.)\n    * `ClassId` : the class id for this mask. We concatenate both category and attributes (if any) together."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(input_dir + \"train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"A image have some ClassID.  \nNext, check the label description.  \nAfter that, let's check the number of labels in each images and look some images.  "},{"metadata":{},"cell_type":"markdown","source":"* label_descriptions.json  \nA file giving the apparel categories and fine-grained attributes descriptions."},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"with open(input_dir + \"label_descriptions.json\") as f:\n    label_description = json.load(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"this dataset info\")\nprint(json.dumps(label_description[\"info\"], indent=2))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"category_df = json2df(label_description[\"categories\"])\ncategory_df[\"id\"] = category_df[\"id\"].astype(int)\ncategory_df[\"level\"] = category_df[\"level\"].astype(int)\nattribute_df = json2df(label_description[\"attributes\"])\nattribute_df[\"id\"] = attribute_df[\"id\"].astype(int)\nattribute_df[\"level\"] = attribute_df[\"level\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(\"Category Labels\")\ncategory_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Attribute Labels\")\nattribute_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"We have {} categories, and {} attributes.\".format(len(label_description['categories']), len(label_description['attributes'])))\nprint(\"Each label　have ID, name, supercategory, and level.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have 46 categories, and 92 attributes.  \nEach label have ID, name, supercategory, and level.  \nI do not know what **level** represents.  \n\nLet's check the number of labels in each images and look some images!  "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_label_num_df = train_df.groupby(\"ImageId\")[\"ClassId\"].count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(25, 7))\nx = image_label_num_df.value_counts().index.values\ny = image_label_num_df.value_counts().values\nz = zip(x, y)\nz = sorted(z)\nx, y = zip(*z)\nindex = 0\nx_list = []\ny_list = []\nfor i in range(1, max(x)+1):\n    if(i not in x):\n        x_list.append(i)\n        y_list.append(0)\n    else:\n        x_list.append(i)\n        y_list.append(y[index])\n        index += 1\nfor i, j in zip(x_list, y_list):\n    ax.text(i-1, j, j, ha=\"center\", va=\"bottom\", fontsize=13)\nsns.barplot(x=x_list, y=y_list, ax=ax)\nax.set_xticks(list(range(0, len(x_list), 5)))\nax.set_xticklabels(list(range(1, len(x_list), 5)))\nax.set_title(\"the number of labels per image\")\nax.set_xlabel(\"the number of labels\")\nax.set_ylabel(\"amout\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most image have about 1-17 labels.  \nBut some image have too many labels about over 20.  \nMax label in a image is 74!  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"counter_category = Counter()\ncounter_attribute = Counter()\nfor class_id in train_df[\"ClassId\"]:\n    category, attribute = classid2label(class_id)\n    counter_category.update([category])\n    counter_attribute.update(attribute)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(counter_category)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(counter_attribute)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All kinds of label is in the train dataset.  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"category_name_dict = {}\nfor i in label_description[\"categories\"]:\n    category_name_dict[str(i[\"id\"])] = i[\"name\"]\nattribute_name_dict = {}\nfor i in label_description[\"attributes\"]:\n    attribute_name_dict[str(i[\"id\"])] = i[\"name\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Category label frequency\")\nprint_dict(counter_category, category_name_dict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(\"Attribute label frequency\")\nprint_dict(counter_attribute, attribute_name_dict)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Category of 17% in training set is `sleeve`.  \nLeast category is `leg warmer`(112/0.034%).But 112 images, not too few.  \nAttribute of 15% in training set is `symmetrical`.  \nLeast attribute is `burnout`(3/0.004%). OMG....only 3  "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.ClassId.max()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I have to pay enough attention to `ClassId`.  \n`ClassId` is represented　by concatenated both category and attributes (if any) together.  \nSo, we need to predict category and attribute (if any).  \nAll `ClassId` have one category and 0 or more attributes.  \n\n9_9_20_43_61_91 means `category: 9`, `attributes: 9, 20, 43, 61, and 91`  \nyou can see this information in competition [Overview/Evaluation/ClassId](https://www.kaggle.com/c/imaterialist-fashion-2019-FGVC6/overview/evaluation).  \n\nLet's check the ratio of attribute per category.  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"attribute_num_dict = {}\nnone_key = str(len(counter_attribute))\nk = list(map(str, range(len(counter_attribute) + 1)))\nv = [0] * (len(counter_attribute) + 1)\nzipped = zip(k, v)\ninit_dict = dict(zipped)\nfor class_id in train_df[\"ClassId\"].values:\n    category, attributes = classid2label(class_id)\n    if category not in attribute_num_dict.keys():\n        attribute_num_dict[category] = init_dict.copy()\n    if attributes == []:\n        attribute_num_dict[category][none_key] += 1\n        continue\n    for attribute in attributes:\n        attribute_num_dict[category][attribute] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, ax = plt.subplots(math.ceil(len(counter_category)/2), 2,\\\n                       figsize=(8*2, 6*math.ceil(len(counter_category)/2)), sharey=True)\nfor index, key in enumerate(sorted(map(int, attribute_num_dict.keys()))):\n    x = list(map(int, attribute_num_dict[str(key)].keys()))\n    total = sum(attribute_num_dict[str(key)].values())\n    y = list(map(lambda x: x / total, attribute_num_dict[str(key)].values()))\n    sns.barplot(x, y, ax=ax[index//2, index%2])\n    ax[index//2, index%2].set_title(\"category:{}({})\".format(key, category_name_dict[str(key)]))\n    ax[index//2, index%2].set_xticks(list(range(0, int(none_key), 5)))\n    ax[index//2, index%2].set_xticklabels(list(range(0, int(none_key), 5)))\nprint(\"the ratio of attribute per category(x=92 means no attribute)\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Wow!  \nMany category don't have any attribute.  "},{"metadata":{},"cell_type":"markdown","source":"# Check Image data\nLet's check the number of image!"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The number of training image is {}.\".format(len(os.listdir(\"../input/train/\"))))\nprint(\"The number of test image is {}.\".format(len(os.listdir(\"../input/test/\"))))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check image size!"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"image_shape_df = train_df.groupby(\"ImageId\")[\"Height\", \"Width\"].first()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\nax1.hist(image_shape_df.Height, bins=100)\nax1.set_title(\"Height distribution\")\nax2.hist(image_shape_df.Width, bins=100)\nax2.set_title(\"Width distribution\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"img_name = image_shape_df.Height.idxmin()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Minimam height image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"img_name = image_shape_df.Height.idxmax()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Maximum height image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"img_name = image_shape_df.Width.idxmin()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Minimam width image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"img_name = image_shape_df.Width.idxmax()\nheight, width = image_shape_df.loc[img_name, :]\nprint(\"Maximum width image is {},\\n(H, W) = ({}, {})\".format(img_name, height, width))\nfig, ax = plt.subplots()\nprint_img(img_name, ax)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, let's show segmented images.  "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pallete =  [\n    'Pastel1', 'Pastel2', 'Paired', 'Accent', 'Dark2',\n    'Set1', 'Set2', 'Set3', 'tab10', 'tab20', 'tab20b', 'tab20c']\n\n\ndef make_mask_img(segment_df):\n    category_num = len(counter_category)\n    seg_width = segment_df.at[0, \"Width\"]\n    seg_height = segment_df.at[0, \"Height\"]\n    seg_img = np.full(seg_width*seg_height, category_num-1, dtype=np.uint8)\n    for encoded_pixels, class_id in zip(segment_df[\"EncodedPixels\"].values, segment_df[\"ClassId\"].values):\n        pixel_list = list(map(int, encoded_pixels.split(\" \")))\n        for i in range(0, len(pixel_list), 2):\n            start_index = pixel_list[i] - 1\n            index_len = pixel_list[i+1] - 1\n            seg_img[start_index:start_index+index_len] =\\\n                int(int(class_id.split(\"_\")[0]) / (category_num-1) * 255)\n    seg_img = seg_img.reshape((seg_height, seg_width), order='F')\n    return seg_img\n\n\ndef train_generator(df, batch_size):\n    img_ind_num = df.groupby(\"ImageId\")[\"ClassId\"].count()\n    index = df.index.values[0]\n    trn_images = []\n    seg_images = []\n    for i, (img_name, ind_num) in enumerate(img_ind_num.items()):\n        img = cv2.imread(\"../input/train/\" + img_name)\n        segment_df = (df.loc[index:index+ind_num-1, :]).reset_index(drop=True)\n        index += ind_num\n        if segment_df[\"ImageId\"].nunique() != 1:\n            raise Exception(\"Index Range Error\")\n        seg_img = make_mask_img(segment_df)\n        \n        # HWC -> CHW\n        img = img.transpose((2, 0, 1))\n        \n        trn_images.append(img)\n        seg_images.append(seg_img)\n        if((i+1) % batch_size == 0):\n            return trn_images, seg_images","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def cv2plt(img, isColor=True):\n    original_img = img\n    original_img = original_img.transpose(1, 2, 0)\n    original_img = cv2.cvtColor(original_img, cv2.COLOR_BGR2RGB)\n    return original_img","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"original, segmented = train_generator(train_df, 6)\nfig, ax = plt.subplots(3, 2, figsize=(16, 18))\nfor i, (img, seg) in enumerate(zip(original, segmented)):\n    ax[i//2, i%2].imshow(cv2plt(img))\n    seg[seg == 45] = 255\n    ax[i//2, i%2].imshow(seg, cmap='tab20_r', alpha=0.6)\n    ax[i//2, i%2].set_title(\"Sample {}\".format(i))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sample Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv(input_dir + \"sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Thank you for watching!\nPlease tell me if i make a mistake.  \nI hope this kernel will help.  \n"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}