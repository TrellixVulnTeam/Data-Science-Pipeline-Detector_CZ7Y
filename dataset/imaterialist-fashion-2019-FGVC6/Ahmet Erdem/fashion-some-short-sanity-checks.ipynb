{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_test_images = len(os.listdir(\"../input/test\"))\nnum_train_images = len(os.listdir(\"../input/train\"))\n\nprint(\"Number of images in test set: {}\".format(num_test_images))\nprint(\"Number of images in train set: {}\".format(num_train_images))","execution_count":2,"outputs":[{"output_type":"stream","text":"Number of images in test set: 3200\nNumber of images in train set: 45625\n","name":"stdout"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntrain_df.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                                ImageId   ...   ClassId\n0  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   ...         6\n1  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   ...         0\n2  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   ...        28\n3  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   ...        31\n4  00000663ed1ff0c4e0132b9b9ac53f6e.jpg   ...        32\n\n[5 rows x 5 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>EncodedPixels</th>\n      <th>Height</th>\n      <th>Width</th>\n      <th>ClassId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n      <td>6068157 7 6073371 20 6078584 34 6083797 48 608...</td>\n      <td>5214</td>\n      <td>3676</td>\n      <td>6</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n      <td>6323163 11 6328356 32 6333549 53 6338742 75 63...</td>\n      <td>5214</td>\n      <td>3676</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n      <td>8521389 10 8526585 30 8531789 42 8537002 46 85...</td>\n      <td>5214</td>\n      <td>3676</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n      <td>12903854 2 12909064 7 12914275 10 12919485 15 ...</td>\n      <td>5214</td>\n      <td>3676</td>\n      <td>31</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00000663ed1ff0c4e0132b9b9ac53f6e.jpg</td>\n      <td>10837337 5 10842542 14 10847746 24 10852951 33...</td>\n      <td>5214</td>\n      <td>3676</td>\n      <td>32</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"avg_class_per_image = np.round(train_df.shape[0]/num_train_images, 2)\nprint(\"Average number of classes per image: {}\".format(avg_class_per_image))\n\nassert len(train_df[\"ImageId\"].value_counts()) == num_train_images\nprint(\"Every image has at least 1 class\")","execution_count":5,"outputs":[{"output_type":"stream","text":"Average number of classes per image: 7.31\nEvery image has at least 1 class\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"fine_grained\"] = train_df[\"ClassId\"].apply(lambda x: len(x.split(\"_\"))) > 1\ntrain_df[\"main_class\"] = train_df[\"ClassId\"].apply(lambda x: x.split(\"_\")[0])\n\nfine_grained_obj_perc = np.round(train_df[\"fine_grained\"].mean()*100, 1)\nprint(\"{}% of the objects are fine-grained.\".format(fine_grained_obj_perc))","execution_count":8,"outputs":[{"output_type":"stream","text":"3.5% of the objects are fine-grained.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fine_grained_img_perc = np.round((train_df.groupby(\"ImageId\")[\"fine_grained\"].sum() > 0).mean()*100, 1)\nprint(\"{}% of the images have at least one fine-grained object.\".format(fine_grained_img_perc))","execution_count":9,"outputs":[{"output_type":"stream","text":"14.7% of the images have at least one fine-grained object.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_df = train_df.groupby(\"main_class\").agg({\"fine_grained\": \"mean\", \"ImageId\": \"count\"}).reset_index()\nclass_df = class_df.rename(columns={\"ImageId\": \"img_count\"})\nprint(\"Number of classes: {}\".format(class_df.shape[0]))","execution_count":10,"outputs":[{"output_type":"stream","text":"Number of classes: 46\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"{} of the classes are never fine-grained.\".format((class_df[\"fine_grained\"] == 0).sum()))","execution_count":11,"outputs":[{"output_type":"stream","text":"30 of the classes are never fine-grained.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"perc = np.round(100*class_df[class_df[\"fine_grained\"] == 0][\"img_count\"].sum()/train_df.shape[0], 1)\nprint(\"{}% of the objects are from non-fine-grained classes.\".format(perc))","execution_count":13,"outputs":[{"output_type":"stream","text":"63.2% of the objects are from non-fine-grained classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}