{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Intro\n\nCompetition home page: https://www.kaggle.com/c/hubmap-kidney-segmentation","metadata":{}},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"%%capture\n!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T03:52:35.222817Z","iopub.execute_input":"2022-03-10T03:52:35.223598Z","iopub.status.idle":"2022-03-10T03:57:36.461523Z","shell.execute_reply.started":"2022-03-10T03:52:35.223545Z","shell.execute_reply":"2022-03-10T03:57:36.460605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport copy\nimport pickle\nimport argparse\nimport json\nimport random\nimport sys\nimport time\nimport datetime\nimport logging\nfrom tqdm.notebook import tqdm\nfrom joblib import Parallel, delayed\n\nimport pandas as pd\npd.set_option('display.max_columns', None)\nimport numpy as np\n\nfrom PIL import Image\nimport cv2\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nfrom detectron2 import model_zoo\nfrom detectron2.structures import BoxMode\nimport detectron2.data.transforms as T\nfrom detectron2.data import detection_utils as utils\nfrom detectron2.data import build_detection_test_loader, build_detection_train_loader\nfrom detectron2.engine import DefaultPredictor, DefaultTrainer, launch\nfrom detectron2.evaluation import COCOEvaluator, PascalVOCDetectionEvaluator\nfrom detectron2.config import CfgNode as CN\nfrom detectron2.config import get_cfg\nimport detectron2\nfrom detectron2 import model_zoo\nfrom detectron2.config import get_cfg\nfrom detectron2.data import DatasetCatalog, MetadataCatalog\nfrom detectron2.utils.logger import setup_logger, log_every_n_seconds\nfrom detectron2.utils.visualizer import Visualizer, ColorMode\nfrom detectron2.engine.hooks import HookBase\nimport detectron2.utils.comm as comm\nfrom detectron2.data.datasets import register_coco_instances, load_coco_json\n\nfrom pyodi.apps.coco.coco_split import property_split","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:15:11.211827Z","iopub.execute_input":"2022-03-10T04:15:11.212492Z","iopub.status.idle":"2022-03-10T04:15:13.290284Z","shell.execute_reply.started":"2022-03-10T04:15:11.212452Z","shell.execute_reply":"2022-03-10T04:15:13.289539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Set configs","metadata":{}},{"cell_type":"code","source":"cfgDict = {\n    \"dicomPath\": None,\n    \"orgDataPath\": None,\n    \"trainJsonPath\": None,\n    \"validJsonPath\": None,\n    \"newDataPath\": \"../input/hubmap-coco-dataset-512x512-tiled/hubmap-coco-512x512-tiled/coco_train/\",\n    \"cachePath\": \"./\",\n    \"splitCfgFilePath\": \"./splitCfg.json\",\n    \"annoJsonPath\": \"../input/hubmap-coco-dataset-512x512-tiled/hubmap-coco-512x512-tiled/coco_train/train.json\",\n    \"newAnnoJsonPath\": \"./train.json\",\n    \"trainDataName\": \"hubmapTrain\",\n    \"validDataName\": \"hubmapValid\",\n    \"sampleSize\": 1000,\n    \"imSize\": None,\n    \"modelName\": \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n    \"mask_format\": \"polygon\",\n    \"debug\": False,\n    \"outdir\": \"./results/\",\n    \"logFile\": \"log.txt\",\n    \"splitMode\": True,\n    \"seed\": 111,\n    \"device\": \"cuda\",\n    \"iter\": 1000,\n    \"ims_per_batch\": 8,\n    \"roi_batch_size_per_image\": 128,\n    \"eval_period\": 50,\n    \"lr_scheduler_name\": \"WarmupCosineLR\",\n    \"base_lr\": 0.001,\n    \"checkpoint_period\":1000,\n    \"num_workers\": 2,\n    \"score_thresh_test\": 0.5,\n    \"augKwargs\": {\n        \"RandomFlip\": {\"prob\": 0.5},\n        \"RandomRotation\": {\"angle\": [0,360]}\n    },\n    \"thing_classes\": None\n}\n\nsetup_logger(os.path.join(cfgDict[\"outdir\"],cfgDict[\"logFile\"]))","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:37:04.926217Z","iopub.execute_input":"2022-03-10T04:37:04.926493Z","iopub.status.idle":"2022-03-10T04:37:04.937326Z","shell.execute_reply.started":"2022-03-10T04:37:04.926462Z","shell.execute_reply":"2022-03-10T04:37:04.936556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare COCO json\nWe use the dataset https://www.kaggle.com/ammarnassanalhajali/crossvalidationfold5. Note that only 8 out of 14 original tiffs are converted into COCO format in this dataset.","metadata":{}},{"cell_type":"code","source":"!rm -r ./results/\nfor f in os.listdir(\"./\"):\n    os.remove(f)\n\n# Fix COCO format for categories and category_id\nannoDict = json.load(open(cfgDict[\"annoJsonPath\"]))\n# Remove duplicated cat\nannoDict[\"categories\"] = [{'supercategory': None, 'id': 0, 'name': 'glomerule'}]\ncfgDict[\"thing_classes\"] = [c[\"name\"] for c in annoDict[\"categories\"]]\nfor i in range(len(annoDict[\"annotations\"])):\n    # category_id must start from 0\n    annoDict[\"annotations\"][i][\"category_id\"] = 0 \nwith open(cfgDict[\"newAnnoJsonPath\"], 'w', encoding='utf-8') as f:\n    json.dump(annoDict, f, ensure_ascii=True, indent=4)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:37:07.063758Z","iopub.execute_input":"2022-03-10T04:37:07.064473Z","iopub.status.idle":"2022-03-10T04:37:19.525705Z","shell.execute_reply.started":"2022-03-10T04:37:07.064432Z","shell.execute_reply":"2022-03-10T04:37:19.524792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare augmentation","metadata":{}},{"cell_type":"code","source":"class AugMapper:\n    \"\"\"Custom mapper class for augmentations\"\"\"\n\n    def __init__(self, cfg, isTrain=True):\n        augKwargs = cfg[\"augKwargs\"]\n        augList = []\n        # Define a sequence of augmentations\n        if isTrain:\n            augList.extend([getattr(T, name)(**kwargs) for name, kwargs in augKwargs.items()])\n        self.augmentations = T.AugmentationList(augList)\n        self.isTrain = isTrain\n        self.cfg = cfg\n\n    def __call__(self, datasetDict):\n        datasetDict = copy.deepcopy(datasetDict)  # it will be modified by code below\n        image = utils.read_image(datasetDict[\"file_name\"], format=\"BGR\")\n        augInput = T.AugInput(image) # the augmentation input\n        transforms = self.augmentations(augInput) # apply the augmentation\n        image = augInput.image # new image\n        imShape = image.shape[:2]  # h, w\n        datasetDict[\"image\"] = torch.as_tensor(image.transpose(2, 0, 1).astype(\"float32\")) # HWC to CHW\n        annos = [ utils.transform_instance_annotations(annotation, transforms, imShape) \n                    for annotation in datasetDict.pop(\"annotations\") \n                    if annotation.get(\"iscrowd\", 0) == 0 ] # apply the augmentation to annotation\n        instances = utils.annotations_to_instances(annos,imShape,mask_format=self.cfg.INPUT.MASK_FORMAT)\n        datasetDict[\"instances\"] = utils.filter_empty_instances(instances)\n        \n        return datasetDict","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:16:02.725656Z","iopub.execute_input":"2022-03-10T04:16:02.726394Z","iopub.status.idle":"2022-03-10T04:16:02.736537Z","shell.execute_reply.started":"2022-03-10T04:16:02.726353Z","shell.execute_reply":"2022-03-10T04:16:02.734663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare loss eval hook for validation","metadata":{}},{"cell_type":"code","source":"class LossEvalHook(HookBase):\n    def __init__(self, eval_period, model, data_loader):\n        self._model = model\n        self._period = eval_period\n        self._data_loader = data_loader\n    \n    def _do_loss_eval(self):\n        # Copying inference_on_dataset from evaluator.py\n        total = len(self._data_loader)\n        num_warmup = min(5, total - 1)\n            \n        start_time = time.perf_counter()\n        total_compute_time = 0\n        losses = []\n        for idx, inputs in enumerate(self._data_loader):            \n            if idx == num_warmup:\n                start_time = time.perf_counter()\n                total_compute_time = 0\n            start_compute_time = time.perf_counter()\n            if torch.cuda.is_available():\n                torch.cuda.synchronize()\n            total_compute_time += time.perf_counter() - start_compute_time\n            iters_after_start = idx + 1 - num_warmup * int(idx >= num_warmup)\n            seconds_per_img = total_compute_time / iters_after_start\n            if idx >= num_warmup * 2 or seconds_per_img > 5:\n                total_seconds_per_img = (time.perf_counter() - start_time) / iters_after_start\n                eta = datetime.timedelta(seconds=int(total_seconds_per_img * (total - idx - 1)))\n                log_every_n_seconds(\n                    logging.INFO,\n                    \"Loss on Validation  done {}/{}. {:.4f} s / img. ETA={}\".format(\n                        idx + 1, total, seconds_per_img, str(eta)\n                    ),\n                    n=5,\n                )\n            loss_batch = self._get_loss(inputs)\n            losses.append(loss_batch)\n        mean_loss = np.mean(losses)\n        comm.synchronize()\n\n        return mean_loss\n            \n    def _get_loss(self, data):\n        # How loss is calculated on train_loop \n        metrics_dict = self._model(data)\n        metrics_dict = {\n            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n            for k, v in metrics_dict.items()\n        }\n        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n        return total_losses_reduced\n        \n        \n    def after_step(self):\n        next_iter = self.trainer.iter + 1\n        is_final = next_iter == self.trainer.max_iter\n        if is_final or (self._period > 0 and next_iter % self._period == 0):\n            mean_loss = self._do_loss_eval()\n            self.trainer.storage.put_scalars(validation_loss=mean_loss)\n            print(\"validation do loss eval\", mean_loss)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:16:04.071771Z","iopub.execute_input":"2022-03-10T04:16:04.072205Z","iopub.status.idle":"2022-03-10T04:16:04.085896Z","shell.execute_reply.started":"2022-03-10T04:16:04.072167Z","shell.execute_reply":"2022-03-10T04:16:04.085085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom DefaultTrainer","metadata":{}},{"cell_type":"code","source":"class MyTrainer(DefaultTrainer):\n    \"\"\"Overwrite DefaultTrainer methods\"\"\"\n    \n    @classmethod\n    def build_train_loader(cls, cfg, sampler=None):\n        return build_detection_train_loader(\n            cfg, mapper=AugMapper(cfg, True), sampler=sampler\n        )\n\n    @classmethod\n    def build_test_loader(cls, cfg, datasetName):\n        return build_detection_test_loader(\n            cfg, datasetName, mapper=AugMapper(cfg, False)\n        )\n\n    @classmethod\n    def build_evaluator(cls, cfg, datasetName, outputFolder=None):\n        if outputFolder is None:\n            outputFolder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n        return COCOEvaluator(datasetName, (\"bbox\",), False, output_dir=outputFolder)\n    \n    def build_hooks(self):\n        hooks = super(MyTrainer, self).build_hooks()\n        cfg = self.cfg\n        if len(cfg.DATASETS.TEST) > 0:\n            loss_eval_hook = LossEvalHook(\n                cfg.TEST.EVAL_PERIOD,\n                self.model,\n                MyTrainer.build_test_loader(cfg, cfg.DATASETS.TEST[0]),\n            )\n            hooks.insert(-1, loss_eval_hook)\n\n        return hooks","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:16:05.789717Z","iopub.execute_input":"2022-03-10T04:16:05.790455Z","iopub.status.idle":"2022-03-10T04:16:05.798963Z","shell.execute_reply.started":"2022-03-10T04:16:05.790419Z","shell.execute_reply":"2022-03-10T04:16:05.798012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load, split, and register data","metadata":{}},{"cell_type":"code","source":"datasetDicts = load_coco_json(cfgDict[\"newAnnoJsonPath\"],cfgDict[\"newDataPath\"])\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=cfgDict[\"seed\"])\ny = np.array([int(len(d[\"annotations\"]) > 0) for d in datasetDicts])\nsplitIdx = list(skf.split(datasetDicts, y))\ntrainIdx, validIdx = splitIdx[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:37:35.594279Z","iopub.execute_input":"2022-03-10T04:37:35.594605Z","iopub.status.idle":"2022-03-10T04:37:37.348313Z","shell.execute_reply.started":"2022-03-10T04:37:35.594566Z","shell.execute_reply":"2022-03-10T04:37:37.347583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DatasetCatalog.clear()\nMetadataCatalog.clear()\nDatasetCatalog.register(\n        cfgDict[\"trainDataName\"],\n        lambda: [datasetDicts[i] for i in trainIdx]\n    )\nDatasetCatalog.register(\n        cfgDict[\"validDataName\"],\n        lambda: [datasetDicts[i] for i in validIdx]\n    )\nMetadataCatalog.get(cfgDict[\"trainDataName\"]).set(thing_classes=[\"ggg\"])\nMetadataCatalog.get(cfgDict[\"validDataName\"]).set(thing_classes=[\"ggg\"])\nmetadata = MetadataCatalog.get(cfgDict[\"trainDataName\"])\ndatasetTrain = DatasetCatalog.get(cfgDict[\"trainDataName\"])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:37:42.676867Z","iopub.execute_input":"2022-03-10T04:37:42.677476Z","iopub.status.idle":"2022-03-10T04:37:42.685601Z","shell.execute_reply.started":"2022-03-10T04:37:42.677436Z","shell.execute_reply":"2022-03-10T04:37:42.684526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize data","metadata":{}},{"cell_type":"code","source":"for d in datasetTrain:\n    if len(d[\"annotations\"])>0:\n        break\nimg = cv2.imread(d[\"file_name\"])\nvisualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1, instance_mode=ColorMode.IMAGE_BW)\nout = visualizer.draw_dataset_dict(d)\nImage.fromarray(out.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:37:48.197912Z","iopub.execute_input":"2022-03-10T04:37:48.198522Z","iopub.status.idle":"2022-03-10T04:37:48.300217Z","shell.execute_reply.started":"2022-03-10T04:37:48.198482Z","shell.execute_reply":"2022-03-10T04:37:48.299522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Yacs config","metadata":{}},{"cell_type":"code","source":"cfg = get_cfg()\n\ncfg.augKwargs = CN(cfgDict[\"augKwargs\"])  # pass augKwargs to cfg as a CN\ncfg.merge_from_file(model_zoo.get_config_file(cfgDict[\"modelName\"]))\ncfg.MODEL.DEVICE = cfgDict[\"device\"]\ncfg.OUTPUT_DIR = cfgDict[\"outdir\"]\ncfg.DATASETS.TRAIN = (cfgDict[\"trainDataName\"],)\nif cfgDict[\"splitMode\"] is None:\n    cfg.DATASETS.TEST = ()\nelse:\n    cfg.DATASETS.TEST = (cfgDict[\"validDataName\"],)\n    cfg.TEST.EVAL_PERIOD = cfgDict[\"eval_period\"]\ncfg.DATALOADER.NUM_WORKERS = cfgDict[\"num_workers\"]\ncfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(cfgDict[\"modelName\"])\ncfg.SOLVER.IMS_PER_BATCH = cfgDict[\"ims_per_batch\"]\ncfg.SOLVER.LR_SCHEDULER_NAME = cfgDict[\"lr_scheduler_name\"]\ncfg.SOLVER.BASE_LR = cfgDict[\"base_lr\"]\ncfg.SOLVER.MAX_ITER = cfgDict[\"iter\"]\ncfg.SOLVER.CHECKPOINT_PERIOD = cfgDict[\"checkpoint_period\"]\ncfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = cfgDict[\"roi_batch_size_per_image\"]\ncfg.MODEL.ROI_HEADS.NUM_CLASSES = len(set(metadata.get(\"thing_classes\")))\ncfg.INPUT.MASK_FORMAT = cfgDict[\"mask_format\"]\ncfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = cfgDict[\"score_thresh_test\"]\n\nos.makedirs(cfg.OUTPUT_DIR, exist_ok=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:38:01.381351Z","iopub.execute_input":"2022-03-10T04:38:01.381607Z","iopub.status.idle":"2022-03-10T04:38:01.406947Z","shell.execute_reply.started":"2022-03-10T04:38:01.381577Z","shell.execute_reply":"2022-03-10T04:38:01.406249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{}},{"cell_type":"code","source":"trainer = MyTrainer(cfg)\ntrainer.resume_or_load(resume=False)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T04:38:20.954352Z","iopub.execute_input":"2022-03-10T04:38:20.954617Z","iopub.status.idle":"2022-03-10T05:28:39.024381Z","shell.execute_reply.started":"2022-03-10T04:38:20.954586Z","shell.execute_reply":"2022-03-10T05:28:39.023561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"dfMetrics = pd.read_json(os.path.join(cfgDict[\"outdir\"],\"metrics.json\"), orient=\"records\", lines=True)\ndfMetrics = dfMetrics.sort_values(\"iteration\")\ndfMetrics.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T05:28:39.026834Z","iopub.execute_input":"2022-03-10T05:28:39.027351Z","iopub.status.idle":"2022-03-10T05:28:39.071265Z","shell.execute_reply.started":"2022-03-10T05:28:39.027307Z","shell.execute_reply":"2022-03-10T05:28:39.070425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dfTrainLoss = dfMetrics[~dfMetrics[\"total_loss\"].isna()]\nplt.plot(dfTrainLoss[\"iteration\"], dfTrainLoss[\"total_loss\"], c=\"C0\", label=\"train\")\nif \"validation_loss\" in dfMetrics.columns:\n    dfValidLoss = dfMetrics[~dfMetrics[\"validation_loss\"].isna()]\n    plt.plot(dfValidLoss[\"iteration\"], dfValidLoss[\"validation_loss\"], c=\"C1\", label=\"validation\")\n\nplt.legend()\nplt.title(\"Loss curve\")\nplt.xlabel(\"Iteration\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T05:28:39.072652Z","iopub.execute_input":"2022-03-10T05:28:39.072929Z","iopub.status.idle":"2022-03-10T05:28:39.269471Z","shell.execute_reply.started":"2022-03-10T05:28:39.072895Z","shell.execute_reply":"2022-03-10T05:28:39.268759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict","metadata":{}},{"cell_type":"code","source":"# Same cfg from trainer and use the final model output to initialize the predictor\ncfg.MODEL.WEIGHTS = os.path.join(cfgDict[\"outdir\"],\"model_final.pth\")\npredictor = DefaultPredictor(cfg)\n\nfor d in datasetTrain:\n    if len(d[\"annotations\"])>0:\n        break\nim = cv2.imread(d[\"file_name\"])\nif predictor.input_format == \"RGB\":\n    im = im[:, :, ::-1]\nheight, width = im.shape[:2]\nimage = torch.as_tensor(im.astype(\"float32\").transpose(2, 0, 1))\ninputs = [{\"image\": image, \"height\": height, \"width\": width}]\noutputs = predictor.model(inputs)\noutput = outputs[0]\n\nvisualizer = Visualizer(im,metadata=metadata, scale=1, instance_mode=ColorMode.IMAGE_BW)\nout = visualizer.draw_instance_predictions(output[\"instances\"].to(\"cpu\"))\nImage.fromarray(out.get_image()[:, :, ::-1])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T05:28:39.2713Z","iopub.execute_input":"2022-03-10T05:28:39.271748Z","iopub.status.idle":"2022-03-10T05:28:40.421753Z","shell.execute_reply.started":"2022-03-10T05:28:39.271707Z","shell.execute_reply":"2022-03-10T05:28:40.421044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References\n\nhttps://www.kaggle.com/lhd0430/sartorius-cell-instance-segmentation\n\nhttps://www.kaggle.com/lhd0430/vinbigdata-chest-x-ray-abnormalities-detection","metadata":{}}]}