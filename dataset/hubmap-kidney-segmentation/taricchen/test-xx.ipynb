{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!mkdir -p /tmp/pip/cache/\n!cp ../input/segmentation/segmentation_models/efficientnet_pytorch-0.6.3.xyz /tmp/pip/cache/efficientnet_pytorch-0.6.3.tar.gz\n!cp ../input/segmentation/segmentation_models/pretrainedmodels-0.7.4.xyz /tmp/pip/cache/pretrainedmodels-0.7.4.tar.gz\n!cp ../input/segmentation/segmentation_models/segmentation-models-pytorch-0.1.2.xyz /tmp/pip/cache/segmentation_models_pytorch-0.1.2.tar.gz\n!cp ../input/segmentation/segmentation_models/timm-0.1.20-py3-none-any.whl /tmp/pip/cache/\n!cp ../input/segmentation/segmentation_models/timm-0.2.1-py3-none-any.whl /tmp/pip/cache/\n!pip install --no-index --find-links /tmp/pip/cache/ efficientnet-pytorch\n!pip install --no-index --find-links /tmp/pip/cache/ segmentation-models-pytorch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport os\nimport gc\nfrom tqdm.notebook import tqdm\nimport rasterio\nfrom rasterio.windows import Window\n\n# from fastai.vision.all import *\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sz = 512   #the size of tiles\nreduce = 2 #reduce the original images by 4 times\nTH = 0.4  #threshold for positive predictions\nDATA = '../input/hubmap-kidney-segmentation/test/'\n# MODELS = [f'../input/hubmap-fast-ai-starter/model_{i}.pth' for i in range(4)]\ndf_sample = pd.read_csv('../input/hubmap-kidney-segmentation/sample_submission.csv')\n# bs = 64\nDEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\noverlap = 230\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean = np.array([0.65459856,0.48386562,0.69428385])\nstd = np.array([0.15167958,0.23584107,0.13146145])\n\nidentity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n\ndef img2tensor(img,dtype:np.dtype=np.float32):\n    if img.ndim==2 : img = np.expand_dims(img,2)\n    img = np.transpose(img,(2,0,1))\n    return torch.from_numpy(img.astype(dtype, copy=False))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numba\nsubm = {}\nidentity = rasterio.Affine(1, 0, 0, 0, 1, 0)\n\ndef make_grid(shape, window=256, min_overlap=32):\n    \"\"\"\n        Return Array of size (N,4), where N - number of tiles,\n        2nd axis represente slices: x1,x2,y1,y2 \n    \"\"\"\n    x, y = shape\n    nx = x // (window - min_overlap) + 1\n    x1 = np.linspace(0, x, num=nx, endpoint=False, dtype=np.int64)\n    x1[-1] = x - window\n    x2 = (x1 + window).clip(0, x)\n    ny = y // (window - min_overlap) + 1\n    y1 = np.linspace(0, y, num=ny, endpoint=False, dtype=np.int64)\n    y1[-1] = y - window\n    y2 = (y1 + window).clip(0, y)\n    slices = np.zeros((nx,ny, 4), dtype=np.int64)\n    \n    for i in range(nx):\n        for j in range(ny):\n            slices[i,j] = x1[i], x2[i], y1[j], y2[j]    \n    return slices.reshape(nx*ny,4)\n\n# used for converting the decoded image to rle mask\ndef rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order = 'F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\ndef rle_decode(mask_rle, shape=(256, 256)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (height,width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')\n@numba.njit()\ndef rle_numba(pixels):\n    size = len(pixels)\n    points = []\n    if pixels[0] == 1: points.append(0)\n    flag = True\n    for i in range(1, size):\n        if pixels[i] != pixels[i-1]:\n            if flag:\n                points.append(i+1)\n                flag = False\n            else:\n                points.append(i+1 - points[-1])\n                flag = True\n    if pixels[-1] == 1: points.append(size-points[-1]+1)    \n    return points\ndef rle_numba_encode(image):\n    pixels = image.flatten(order = 'F')\n    points = rle_numba(pixels)\n    return ' '.join(str(x) for x in points)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_pred(models, image, tta=None):\n    py = None\n    for model in models:\n        score = model(image)[0][0]\n        if py == None:\n            py = score\n        else:\n            py += score\n    py = py/len(models)\n    return py\n\n# def model_pred(models, image, tta=None):\n#     score = models(image)[0][0]\n#     return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = [1,2,3]\n[model[0],model[1]]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pathlib\nWINDOW = 1024\n\nDATA_PATH = '../input/hubmap-kidney-segmentation/'\n\np = pathlib.Path(DATA_PATH)\nnumk = 0\nfor i, filename in enumerate(p.glob('test/*.tiff')):\n    file = rasterio.open(filename.as_posix())\n    slices = make_grid(file.shape, window=WINDOW, min_overlap=overlap) # this version\n    preds = np.zeros(file.shape, dtype=np.float16)\n    print('staring predict test data:',filename)\n    print(file.shape)\n    print(slices)\n    models = []\n    model = torch.load(f'../input/b7-models/best_0_7.pth')\n    models.append(model)\n    del model; gc.collect()\n    model = torch.load(f'../input/b7-models/best_4.pth')\n    models.append(model)\n    del model; gc.collect()\n    model = torch.load(f'../input/b7-models/best_3.pth')\n    models.append(model)\n    del model; gc.collect()\n    \n    \n    if file.count != 3:\n        print('Image file with subdatasets as channels')\n        layers = [rasterio.open(subd) for subd in file.subdatasets]\n    for (x1,x2,y1,y2) in slices:\n        if file.count == 3: # normal\n            image = file.read([1,2,3],\n                        window=Window.from_slices((x1,x2),(y1,y2)))\n            image = np.moveaxis(image, 0, -1)\n            \n        else:\n            image = np.zeros((WINDOW, WINDOW, 3), dtype=np.uint8)\n            for fl in range(3):\n                image[:,:,fl] = layers[fl].read(window=Window.from_slices((x1,x2),(y1,y2)))\n        image = cv2.resize(image,(image.shape[1]//reduce,image.shape[0]//reduce),\n                           interpolation = cv2.INTER_AREA)\n        image = img2tensor((image/255 - mean)/std)\n\n        with torch.no_grad():\n            image = image.to(DEVICE)\n#             print(image.shape)\n            score = model_pred([models[0]], image[None,...])\n            score2 = model_pred([models[1]], torch.flip(image[None,...], [0, 3]))\n            score2 = torch.flip(score2[None,None,...], [3, 0])[0][0]\n            score3 = model_pred([models[2]], torch.flip(image[None,...], [1, 2]))\n            score3 = torch.flip(score3[None,None,...], [2, 1])[0][0]\n            score = (score + score2 + score3)/3\n            score = score.cpu()\n            score = cv2.resize(np.float32(score), (1024, 1024))\n        \n            preds[x1:x2,y1:y2] = score*score/(preds[x1:x2,y1:y2] + score) + preds[x1:x2,y1:y2]*preds[x1:x2,y1:y2]/(preds[x1:x2,y1:y2] + score)\n            \n    del score,score2,score3,image\n    del slices,models; gc.collect()\n    # -------------------------------------- other overlaps --------------------------------------------------------\n    slices = make_grid(file.shape, window=WINDOW, min_overlap=32) # this version\n    \n    models = []\n    model = torch.load(f'../input/0924model/best_0_924.pth')\n    models.append(model)\n    del model; gc.collect()\n    model = torch.load(f'../input/b5testexternal/b5 -test -external/best_0(5).pth')\n    models.append(model)\n    del model; gc.collect()\n    model = torch.load(f'../input/b5testexternal/b5 -test -external/best_4(1).pth')\n    models.append(model)\n    del model; gc.collect()\n    model = torch.load(f'../input/b5testexternal/b5 -test -external/best_3(1).pth')\n    models.append(model)\n    del model; gc.collect()\n    model = torch.load(f'../input/b5testexternal/b5 -test -external/best_1(1).pth')\n    models.append(model)\n    del model; gc.collect()\n    \n    \n    if file.count != 3:\n        print('Image file with subdatasets as channels')\n        layers = [rasterio.open(subd) for subd in file.subdatasets]\n    for (x1,x2,y1,y2) in slices:\n        if file.count == 3: # normal\n            image = file.read([1,2,3],\n                        window=Window.from_slices((x1,x2),(y1,y2)))\n            image = np.moveaxis(image, 0, -1)\n            \n        else:\n            image = np.zeros((WINDOW, WINDOW, 3), dtype=np.uint8)\n            for fl in range(3):\n                image[:,:,fl] = layers[fl].read(window=Window.from_slices((x1,x2),(y1,y2)))\n        image = cv2.resize(image,(image.shape[1]//reduce,image.shape[0]//reduce),\n                           interpolation = cv2.INTER_AREA)\n        image = img2tensor((image/255 - mean)/std)\n\n        with torch.no_grad():\n            image = image.to(DEVICE)\n#             print(image.shape)\n            score = model_pred([models[0]], image[None,...])\n            score2 = model_pred([models[1], models[2]], torch.flip(image[None,...], [0, 3]))\n            score2 = torch.flip(score2[None,None,...], [3, 0])[0][0]\n            score3 = model_pred([models[3], models[4]], torch.flip(image[None,...], [1, 2]))\n            score3 = torch.flip(score3[None,None,...], [2, 1])[0][0]\n            score = (score+score2+score3)/3\n            \n            score = score.cpu()\n            score = cv2.resize(np.float32(score), (1024, 1024))\n            \n            preds[x1:x2,y1:y2] = (score + preds[x1:x2,y1:y2])/2\n    \n    preds = (preds > TH).astype(np.uint8)    \n    subm[i] = {'id':filename.stem, 'predicted': rle_numba_encode(preds)}\n    \n    del preds; gc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame.from_dict(subm, orient='index')\nsubmission.to_csv(f'submission.csv', index=False)\nsubmission\n%reset -f out","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}