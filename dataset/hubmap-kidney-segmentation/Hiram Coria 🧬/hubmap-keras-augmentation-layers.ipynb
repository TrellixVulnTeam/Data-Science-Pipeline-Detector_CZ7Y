{"cells":[{"metadata":{},"cell_type":"markdown","source":"# <font color = \"blue\">Preambule</font>\n\nThis notebook was made with the purpose of show to more people that Keras gives ten different layers which could be used to do **data augmentation** of images from this competition. I would to add that it would be nice if you comment why **albumentations** is a better option besides the fact that it provides with more methods, like **Color Jitter**. One advantage of using Keras layers is that it would be faster than algumentation because they can use GPU and TPU processors."},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"blue\">Libraries</font>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers.experimental import preprocessing\n\n### Make prettier the prints ###\nfrom colorama import Fore\nb_ = Fore.BLUE\nr_ = Fore.RED","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"blue\">Reproducibility</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"seed = 42\ntf.random.set_seed(seed)\nrandom.seed(seed)\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"blue\">Data</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = \"../input/hubmap-256x256\"\ntrain = os.path.join(BASE_PATH, \"train\")\nmasks = os.path.join(BASE_PATH, \"masks\")\n\nprint(f'{b_}Number of training images: {r_}{len(os.listdir(train))}')\nprint(f'{b_}Numner of masks: {r_}{len(os.listdir(masks))}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_filename = os.listdir(train)[6]\nsample_image = plt.imread(os.path.join(train, sample_filename))\nsample_mask = plt.imread(os.path.join(masks, sample_filename))\n\n_, ax = plt.subplots(1, 2)\nax[0].imshow(sample_image)\nax[0].set_title(\"Sample Image\")\nax[1].imshow(sample_mask)\nax[1].set_title(\"Mask\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"blue\">Image Preprocessing & Augmentation Layers</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_ori_and_aug(aug):\n    \"\"\"\n    Plot the original sample image with its augmentation\n    \"\"\"\n    plt.figure(figsize=(10, 10))\n    _, ax = plt.subplots(1, 2)\n    ax[0].imshow(sample_image)\n    ax[0].set_title(\"Original\")\n    ax[1].imshow(augmented_image[0])\n    ax[1].set_title(aug);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\"> Resizing layer</font>\n\n```\ntf.keras.layers.experimental.preprocessing.Resizing(\n    height, width, interpolation=\"bilinear\", name=None, **kwargs\n)\n```\n\nYou can prove that it worked seeing the axes of the images."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add the image to a batch\nimage = tf.expand_dims(sample_image, 0) # I don't fully understand why this line is necesary but i can't replace it\naugmented_image = preprocessing.Resizing(128, 128, interpolation = \"bilinear\")(image)\n\nplot_ori_and_aug(\"Resizing\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n## <font color = \"green\">Rescaling layer</font>\n\n```\ntf.keras.layers.experimental.preprocessing.Rescaling(\n    scale, offset=0.0, name=None, **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.Rescaling(1./5, offset = 0.5)(image)\n\nplot_ori_and_aug(\"Rescaling\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">CenterCrop layer</font>\n```\ntf.keras.layers.experimental.preprocessing.CenterCrop(\n    height, width, name=None, **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.CenterCrop(height = 64, width = 64)(image)\n\nplot_ori_and_aug(\"CenterCrop\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">RandomCrop layer</font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomCrop(\n    height, width, seed=None, name=None, **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.RandomCrop(height = 64, width = 64, seed = seed)(image)\n\nplot_ori_and_aug(\"RandomCrop\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">RandomFlip layer</font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomFlip(\n    mode=\"horizontal_and_vertical\", seed=None, name=None, **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here i used \"seed + 1\" because 42 retuns exactly the same image.\naugmented_image = preprocessing.RandomFlip(\"horizontal_and_vertical\", seed = seed + 1)(image)\n\nplot_ori_and_aug(\"RandomFlip\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\"> RandomTranslation layer</font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomTranslation(\n    height_factor,\n    width_factor,\n    fill_mode=\"reflect\",\n    interpolation=\"bilinear\",\n    seed=None,\n    name=None,\n    fill_value=0.0,\n    **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.RandomTranslation(\n    height_factor = 0.8,\n    width_factor = 0.6,\n    fill_mode = \"reflect\",\n    interpolation = \"bilinear\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomTranslation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">RandomRotation layer</font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomRotation(\n    factor,\n    fill_mode=\"reflect\",\n    interpolation=\"bilinear\",\n    seed=None,\n    name=None,\n    fill_value=0.0,\n    **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.RandomRotation(\n    factor = 0.8,\n    fill_mode = \"wrap\",\n    interpolation = \"nearest\",\n    seed = seed,\n)(image)\n\nplot_ori_and_aug(\"RandomRotation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">RandomZoom layer</font>\n\n\n```\ntf.keras.layers.experimental.preprocessing.RandomZoom(\n    height_factor,\n    width_factor=None,\n    fill_mode=\"reflect\",\n    interpolation=\"bilinear\",\n    seed=None,\n    name=None,\n    fill_value=0.0,\n    **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.RandomZoom(\n    height_factor = 0.2,\n    width_factor = -0.3,\n    fill_mode = \"constant\",\n    interpolation = \"bilinear\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomZoom\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">RandomHeight layer</font>\n\n\n```\ntf.keras.layers.experimental.preprocessing.RandomHeight(\n    factor, interpolation=\"bilinear\", seed=None, name=None, **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.RandomHeight(\n    factor = 0.7,\n    interpolation = \"nearest\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomHeight\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">RandomWidth layer</font>\n\n```\ntf.keras.layers.experimental.preprocessing.RandomWidth(\n    factor, interpolation=\"bilinear\", seed=None, name=None, **kwargs\n)\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"augmented_image = preprocessing.RandomWidth(\n    factor = 0.2,\n    interpolation = \"bicubic\",\n    seed = seed\n)(image)\n\nplot_ori_and_aug(\"RandomWidth\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = \"green\">Combining Layersr</font>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_augmentation = Sequential([\n    preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    preprocessing.RandomRotation(0.2),\n    preprocessing.RandomZoom(\n        height_factor = 0.2,\n        width_factor = -0.3,\n        fill_mode = \"constant\",\n        interpolation = \"bilinear\",\n    )    \n])\n\nplt.figure(figsize=(10, 10))\nfor i in range(9):\n  augmented_image = data_augmentation(image)\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(augmented_image[0])\n  plt.axis(\"off\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <font color = \"blue\">References</font>\n- [\nImage preprocessing & augmentation layers](https://keras.io/api/layers/preprocessing_layers/image_preprocessing/)\n- [\nData Augmentation in Python: Everything You Need to Know](https://neptune.ai/blog/data-augmentation-in-python)\n- [[Tutorial]Augmentation with mask & VisualizationðŸ”¥](https://www.kaggle.com/piantic/tutorial-augmentation-with-mask-visualization)\n- [Data augmentation](https://www.tensorflow.org/tutorials/images/data_augmentation)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}