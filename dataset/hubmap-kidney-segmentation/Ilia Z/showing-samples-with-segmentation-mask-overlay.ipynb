{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"[In the previous notebook](https://www.kaggle.com/purplejester/reading-tiff-images-with-python), I was trying to read the data into memory. But nothing was done about segmentation masks. Here I implement a simple way to decode the masks and show them on top of a randomly picked training image."},{"metadata":{"trusted":true},"cell_type":"code","source":"from typing import Tuple\n\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom osgeo import gdal","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading TIFF Image"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_tiff(path: str, channels_last: bool = False) -> np.ndarray:\n    \"\"\"Reads TIFF file.\"\"\"\n    \n    dataset = gdal.Open(path, gdal.GA_ReadOnly)\n    n_channels = dataset.RasterCount\n    width = dataset.RasterXSize\n    height = dataset.RasterYSize\n    image = np.zeros((n_channels, height, width), dtype=np.uint8)\n    for i in range(n_channels):\n        band = dataset.GetRasterBand(i+1)\n        channel = band.ReadAsArray()\n        image[i] = channel\n    if channels_last:\n        image = image.transpose(1, 2, 0)\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Reading Segmentation Masks"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_masks = pd.read_csv('/kaggle/input/hubmap-kidney-segmentation/train.csv')\ndf_masks.set_index('id', inplace=True)\ndf_masks","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As the dataset's descritpion reads, the masks are represented with running-length encoding. We convert these encodings into 2D masks to visualize segmentation."},{"metadata":{"trusted":true},"cell_type":"code","source":"def rle_decode(encoded: str, shape: Tuple[int, int]):\n    \"\"\"Decodes an RLE-encoded string.\"\"\"\n    \n    numbers = list(map(int, encoded.split()))\n    starts, runs = [np.asarray(xs) for xs in (numbers[::2], numbers[1::2])]\n\n    # pixels enumerations starts from 1 but arrays are \n    # indexed staring from 0 so need to make an adjustment\n    starts -= 1  \n    \n    mask = np.zeros(shape[0] * shape[1], dtype=np.uint8)\n    for start, run in zip(starts, runs):\n        mask[start:start + run] = 1\n    \n    # In NumPy arrays, first goes height and then goes width; also,\n    # the pixels in the mask are enumerated from top to bottom and \n    # from left to right, but the mask was filled in a different \n    # order so need to transpose\n    return mask.reshape(shape[1], shape[0]).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before applying our decoder to the data, let's check if the implementation works correctly. We use a toy RLE-mask to see what the decoding function gives us back."},{"metadata":{"trusted":true},"cell_type":"code","source":"n, m = 7, 9\nencoded_mask = '9 1 16 4 24 1 39 1 46 1 51 5'\ndecoded_mask = rle_decode(encoded_mask, (n, m))\n\nf, ax = plt.subplots(1, 1, figsize=(8, 6))\nax.imshow(decoded_mask, cmap='gray')\nax.axis('off')\n\nfor x in range(m):           # left to right\n    for y in range(n):       # top to bottom\n        index = x*n + y + 1  # pixels are enumerated starting from 1\n        \n        color = 'black' if decoded_mask[y][x] == 1 else 'white'\n        \n        ax.annotate(str(index), xy=(x, y), \n                    ha='center', va='center',\n                    color=color, fontsize=18)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that:\n- `9 1` is mapped to a single 9th pixel,\n- `16 4` is mapped to a vertical line in the 3rd column,\n- other pixels filled accordingly to the mask as expected.\n\nTherefore, we can conclude that our decoding method works as expected. Now let's try to apply it to the real data.\n\n\n## Showing Segmentation Mask on Top of TIFF Images\n\nAs before, we read an image from the training subset and decode its segmentation mask."},{"metadata":{"trusted":true},"cell_type":"code","source":"image_id = '0486052bb'\ntiff_image = read_tiff(f'/kaggle/input/hubmap-kidney-segmentation/train/{image_id}.tiff')\ntiff_mask = rle_decode(df_masks.loc[image_id].encoding, tiff_image.shape[1:])\ntiff_image.shape, tiff_mask.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following function takes both the image and its segmentation mask, and combines them into a single image array. Note that the function makes some OpenCV transformations and resizing that can easilty fill up all the avaliable RAM in the kernel. Therefore, it can fail for too large images and/or too big `resize` parameter values."},{"metadata":{"trusted":true},"cell_type":"code","source":"def overlay(\n    image: np.ndarray,\n    mask: np.ndarray,\n    color: Tuple[int, int, int] = (255, 0, 0),\n    alpha: float = 0.5, \n    resize: Tuple[int, int] = (1024, 1024)\n) -> np.ndarray:\n    \"\"\"Combines image and its segmentation mask into a single image.\n    \n    Params:\n        image: Training image.\n        mask: Segmentation mask.\n        color: Color for segmentation mask rendering.\n        alpha: Segmentation mask's transparency.\n        resize: If provided, both image and its mask are resized before blending them together.\n    \n    Returns:\n        image_combined: The combined image.\n        \n    \"\"\"\n    color = np.asarray(color).reshape(3, 1, 1)\n    colored_mask = np.expand_dims(mask, 0).repeat(3, axis=0)\n    masked = np.ma.MaskedArray(image, mask=colored_mask, fill_value=color)\n    image_overlay = masked.filled()\n    \n    if resize is not None:\n        image = cv.resize(image.transpose(1, 2, 0), resize)\n        image_overlay = cv.resize(image_overlay.transpose(1, 2, 0), resize)\n    \n    image_combined = cv.addWeighted(image, 1 - alpha, image_overlay, alpha, 0)\n    \n    return image_combined","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Instead of trying to render the whole image, here we take some random patch and show its segments to speed the computations up. You can try to feed the full-size image. Especially, if running this code outside of Kaggle kernels."},{"metadata":{"trusted":true},"cell_type":"code","source":"x0, y0 = 4096, 9000\nx1, y1 = x0 + 1024, y0 + 1024\nf, ax = plt.subplots(1, 1, figsize=(12, 12))\ncut_overlay = overlay(tiff_image[:, y0:y1, x0:x1], tiff_mask[y0:y1, x0:x1], alpha=0.4)\nax.imshow(cut_overlay);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looking at the image, we can suppose that our code correctly reads both the data and masks and combines them together."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}