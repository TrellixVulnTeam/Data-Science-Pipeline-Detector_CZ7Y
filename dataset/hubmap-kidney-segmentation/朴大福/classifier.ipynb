{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install segmentation_models_pytorch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import segmentation_models_pytorch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport tifffile as tiff\nimport cv2\nimport os\nimport gc\nfrom tqdm.notebook import tqdm\nimport rasterio\nfrom rasterio.windows import Window\n\nfrom fastai.vision.all import *\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nDEVICE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.load('../input/classifier-models/resnet34-0-model.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.cvtColor(cv2.imread('../input/test-split/2ec3f1bb9.tiff_104.png'),cv2.COLOR_BGR2RGB)\nmean = np.array([0.65459856,0.48386562,0.69428385])\nstd = np.array([0.15167958,0.23584107,0.13146145])\n\ndef img2tensor(img,dtype:np.dtype=np.float32):\n    if img.ndim==2 : img = np.expand_dims(img,2)  \n    img = np.transpose(img,(2,0,1))\n    return torch.from_numpy(img.astype(dtype, copy=False))\n\n\nimg = img2tensor(img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ResNet(nn.Module):\n    def __init__(self, config, output_dim):\n        super().__init__()  \n        block, n_blocks, channels = config\n        self.in_channels = channels[0]\n        assert len(n_blocks) == len(channels) == 4\n        \n        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n        self.bn1 = nn.BatchNorm2d(self.in_channels)\n        self.relu = nn.ReLU(inplace = True)\n        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n        \n        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n        \n        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n        self.fc = nn.Linear(self.in_channels, output_dim)\n        self.sig_fc =  nn.Sigmoid()\n        \n    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):\n        layers = []\n        if self.in_channels != block.expansion * channels:\n            downsample = True\n        else:\n            downsample = False\n        layers.append(block(self.in_channels, channels, stride, downsample))\n        for i in range(1, n_blocks):\n            layers.append(block(block.expansion * channels, channels))\n        self.in_channels = block.expansion * channels\n        return nn.Sequential(*layers)\n        \n    def forward(self, x):\n        \n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        \n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.avgpool(x)\n        h = x.view(x.shape[0], -1)\n        x = self.fc(h)\n        x = self.sig_fc(x)\n        \n        return x, h","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class BasicBlock(nn.Module):\n    expansion = 1\n    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n        super().__init__()\n                \n        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n                               stride = stride, padding = 1, bias = False)\n        self.bn1 = nn.BatchNorm2d(out_channels)\n        \n        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n                               stride = 1, padding = 1, bias = False)\n        self.bn2 = nn.BatchNorm2d(out_channels)\n        \n        self.relu = nn.ReLU(inplace = True)\n        \n        if downsample:\n            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n                             stride = stride, bias = False)\n            bn = nn.BatchNorm2d(out_channels)\n            downsample = nn.Sequential(conv, bn)\n        else:\n            downsample = None\n        self.downsample = downsample\n        \n    def forward(self, x):\n        i = x\n        x = self.conv1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.conv2(x)\n        x = self.bn2(x)\n        \n        if self.downsample is not None:\n            i = self.downsample(i)\n                        \n        x += i\n        x = self.relu(x)\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])\nresnet18_config = ResNetConfig(block = BasicBlock,\n                               n_blocks = [2,2,2,2],\n                               channels = [64, 128, 256, 512])\n\nresnet34_config = ResNetConfig(block = BasicBlock,\n                               n_blocks = [3,4,6,3],\n                               channels = [64, 128, 256, 512])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ResNet(resnet34_config, 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/classifier-models/resnet34-0-model.pt'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = cv2.cvtColor(cv2.imread('../input/test-split/3589adb90.tiff_57.png'),cv2.COLOR_BGR2RGB)\nmean = np.array([0.65459856,0.48386562,0.69428385])\nstd = np.array([0.15167958,0.23584107,0.13146145])\n\ndef img2tensor(img,dtype:np.dtype=np.float32):\n    if img.ndim==2 : img = np.expand_dims(img,2)  \n    img = np.transpose(img,(2,0,1))\n    return torch.from_numpy(img.astype(dtype, copy=False))\nimg = img2tensor(img)\nmodel(img[None,...])\n# model(torch.ones([1,3,512,512]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}