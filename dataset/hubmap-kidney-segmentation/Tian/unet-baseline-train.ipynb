{"cells":[{"metadata":{},"cell_type":"markdown","source":"### reference:  \n\nhttps://www.kaggle.com/c/hubmap-kidney-segmentation/notebooks   \nhttps://github.com/qubvel/segmentation_models.pytorch/blob/master/examples/cars%20segmentation%20(camvid).ipynb  \n"},{"metadata":{},"cell_type":"markdown","source":"#### data preprocessing:  \n\nhttps://www.kaggle.com/iafoss/256x256-images"},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!pip install segmentation_models_pytorch","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom torch.utils.data import TensorDataset, DataLoader, Dataset\nimport albumentations as albu\nimport segmentation_models_pytorch as smp\nfrom albumentations.pytorch import ToTensor\nimport torch\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DEVICE = ('cuda' if torch.cuda.is_available() else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!mkdir data\n!mkdir data/images\n!unzip ../input/256x256-images/train.zip -d data/images","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"!mkdir data/masks\n!unzip ../input/256x256-images/masks.zip -d data/masks","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class config:\n    images_path = './data/images'\n    masks_path = './data/masks'\n    backbone = 'resnet34'\n    ACTIVATION = 'sigmoid'\n    ENCODER_WEIGHTS = 'imagenet'\n    lr=1e-3\n    epochs=10\n    batch_size=8\n    T_max=500\n    im_size=256\n    num_workers=4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_augmentation = albu.Compose([\n                        albu.HorizontalFlip(),\n                        albu.OneOf([\n                            albu.RandomContrast(),\n                            albu.RandomGamma(),\n                            albu.RandomBrightness(),\n                            ], p=0.3),\n                        albu.OneOf([\n                            albu.ElasticTransform(alpha=120, sigma=120 * 0.05, alpha_affine=120 * 0.03),\n                            albu.GridDistortion(),\n                            albu.OpticalDistortion(distort_limit=2, shift_limit=0.5),\n                            ], p=0.3),\n                        albu.ShiftScaleRotate(),\n                        albu.Resize(config.im_size, config.im_size),\n                        ToTensor()\n\n                    ])\n\nvalid_augmentation = albu.Compose([\n                        albu.Resize(config.im_size, config.im_size),\n                        ToTensor()\n                    ])\n\n\nclass HuBMAPDataset(Dataset):\n    def __init__(self, ids, transforms=None):\n        self.ids = ids\n        self.transforms = transforms\n        \n    def __getitem__(self, idx):\n        name = self.ids[idx]\n        img = cv2.imread(f\"{config.images_path}/{name}\")\n        mask = cv2.imread(f\"{config.masks_path}/{name}\", 0)\n        \n        if self.transforms:\n            augmented = self.transforms(image=img, mask=mask)\n            img = augmented['image']\n            mask = augmented['mask']\n\n        return img, mask\n\n    def __len__(self):\n        return len(self.ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = os.listdir(config.images_path)#[:100]\ntrain_lsit = list(set([row.split(\"_\")[0] for row in data]))\ntrain_idx = [row for row in data if row.split(\"_\")[0] in train_lsit[:-2]]\nvalid_idx = [row for row in data if row.split(\"_\")[0] not in train_lsit[:-2]]\nlen(train_idx), len(valid_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datasets = HuBMAPDataset(train_idx, transforms=train_augmentation)\nvalid_datasets = HuBMAPDataset(valid_idx, transforms=valid_augmentation)\ntrain_loader = DataLoader(train_datasets, batch_size=config.batch_size, shuffle=True, num_workers=config.num_workers)\nvalid_loader = DataLoader(valid_datasets, batch_size=config.batch_size, shuffle=False, num_workers=config.num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x,y = train_datasets[1]\nx.shape,y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# helper function for data visualization\ndef visualize(**images):\n    \"\"\"PLot images in one row.\"\"\"\n    n = len(images)\n    plt.figure(figsize=(16, 5))\n    for i, (name, image) in enumerate(images.items()):\n        plt.subplot(1, n, i + 1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(' '.join(name.split('_')).title())\n        plt.imshow(image)\n    plt.show()\n\n# same image with different random transforms\n\nimage, mask = train_datasets[5]\nvisualize(image=image.permute(1,2,0), mask=mask.squeeze(0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = smp.Unet(\n    config.backbone, \n    encoder_weights=config.ENCODER_WEIGHTS, \n    in_channels=3, \n    classes=1, \n    activation=config.ACTIVATION,\n    decoder_use_batchnorm=False\n)\noptimizer = torch.optim.AdamW(model.parameters(),lr=config.lr)\n\nloss_fn = smp.utils.losses.DiceLoss() # smp.utils.losses.BCEWithLogitsLoss()\n\n#metric = [smp.utils.losses.DiceLoss()]\nmetrics = [\n    smp.utils.metrics.IoU(threshold=0.5),\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_epoch = smp.utils.train.TrainEpoch(\n    model, \n    loss=loss_fn, \n    metrics=metrics, \n    optimizer=optimizer,\n    device=DEVICE,\n    verbose=True,\n)\n\nvalid_epoch = smp.utils.train.ValidEpoch(\n    model, \n    loss=loss_fn, \n    metrics=metrics, \n    device=DEVICE,\n    verbose=True,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def savelogs(logs, name):\n    with open(f'{name}.txt', 'a') as f:\n        for k, v in logs.items():\n            f.write(f'{k} {v}')\n        f.write('\\n')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_score = 1e5\nlosses = {}\nious = {}\nlosses['train'] = []\nlosses['valid'] = []\nious['train'] = []\nious['valid'] = []\n\nfor i in range(0, config.epochs):\n    \n    print('\\nEpoch: {}'.format(i))\n    train_logs = train_epoch.run(train_loader)\n    valid_logs = valid_epoch.run(valid_loader)\n    \n    savelogs(train_logs, f'train_logs.txt')\n    savelogs(valid_logs, f'valid_logs.txt')\n    \n    losses['train'].append(train_logs['dice_loss'])\n    losses['valid'].append(valid_logs['dice_loss'])\n    ious['train'].append(train_logs['iou_score'])\n    ious['valid'].append(valid_logs['iou_score'])\n    #break\n    # do something (save model, change lr, etc.)\n    # val loss\n    if max_score > valid_logs['dice_loss']:\n        max_score = valid_logs['dice_loss']\n        torch.save(model, 'best.pth')\n        print('Model saved!')\n        \n    if i == 15:\n        optimizer.param_groups[0]['lr'] = 1e-5\n        print('Decrease decoder learning rate to 1e-5!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# PLOT\ndef plot(scores, name):\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n    plt.plot(range(len(scores[\"train\"])), scores[\"valid\"], label=f'val {name}')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n    plt.legend(); \n    plt.show()\n\nplot(losses, \"loss\")\nplot(ious, \"iou\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}