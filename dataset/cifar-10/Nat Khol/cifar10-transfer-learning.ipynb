{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Imports & installs.","metadata":{}},{"cell_type":"code","source":"!pip install py7zr","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################### IMPORTS ###################################\n###\nimport numpy as np\nimport pandas as pd\nimport os\nimport copy\nimport matplotlib.pyplot as plt\n\n###\nfrom PIL import Image\n\n###\nimport torch\n# neural network modules, nn.Linear, nn.Conv2d, loss functions\nimport torch.nn as nn\n# activation functions\nimport torch.nn.functional as F\n# optimizers\nimport torch.optim as optim\n# transformations \nimport torchvision.transforms as transforms\n\nfrom torchvision import models\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset, Subset\n\n###\nfrom sklearn.model_selection import train_test_split\n\n# device config\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n###\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n###\nfrom py7zr import unpack_7zarchive\nimport shutil\nshutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T09:45:13.286964Z","iopub.execute_input":"2021-10-31T09:45:13.287374Z","iopub.status.idle":"2021-10-31T09:45:13.299688Z","shell.execute_reply.started":"2021-10-31T09:45:13.287315Z","shell.execute_reply":"2021-10-31T09:45:13.296919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################# HYPERPARAMS #################################\n\nnum_epochs = 3\nbatch_size = 64\nlr = 0.01","metadata":{"execution":{"iopub.status.busy":"2021-10-31T09:45:13.302832Z","iopub.execute_input":"2021-10-31T09:45:13.303648Z","iopub.status.idle":"2021-10-31T09:45:13.314865Z","shell.execute_reply.started":"2021-10-31T09:45:13.303569Z","shell.execute_reply":"2021-10-31T09:45:13.313839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load data.","metadata":{}},{"cell_type":"code","source":"############################# CUSTOM DATASET CLASS #############################\n\nclass CifarLoader(Dataset):\n  def __init__(self, root_dir, csv_file = None, transform = None):\n\n    # images directory \n    self.root_dir = root_dir\n    # transformations if any\n    self.transform = transform\n\n    if csv_file:\n      # read csv file\n      self.df = pd.read_csv(csv_file)\n\n      # {class: lbl}\n      self.annot_dict = {}\n\n      for i, lbl in enumerate(self.df['label'].unique()):\n        self.annot_dict[lbl] = i\n\n      # {lbl: class}\n      self.annot_dict_reversed = {v:k for k,v in self.annot_dict.items()}\n\n      # add a column with decoded labels\n      self.df['encoded'] = self.df['label'].map(self.annot_dict)\n\n    else: \n      # if no csv file provided -> create a df, fill labels with 0's\n      self.df = pd.DataFrame({\n          'id': list(range(1, len(os.listdir(self.root_dir)) + 1)),\n          'label': np.zeros(len(os.listdir(self.root_dir))),\n          'encoded': np.zeros(len(os.listdir(self.root_dir)))\n      })\n\n\n  def __len__(self):\n    # num of records in the df\n    return len(self.df)\n\n  def __getitem__(self, index):\n    # path to the image\n    img_path = os.path.join(self.root_dir, str(self.df.iloc[index, 0]) + '.png')\n    # read image\n    image = np.array(Image.open(img_path).convert('RGB'))\n    # get label\n    y_label = torch.tensor(int(self.df.iloc[index, 2]))\n\n    # apply transformations\n    if self.transform:\n      image = self.transform(image)\n    \n    return (image, y_label)\n","metadata":{"execution":{"iopub.status.busy":"2021-10-31T09:45:14.742682Z","iopub.execute_input":"2021-10-31T09:45:14.742982Z","iopub.status.idle":"2021-10-31T09:45:14.757166Z","shell.execute_reply.started":"2021-10-31T09:45:14.742953Z","shell.execute_reply":"2021-10-31T09:45:14.755865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform tensors to normalized range form [0, 1] to [-1, 1]\nmean = np.array([0.5, 0.5, 0.5])\nstd = np.array([0.5, 0.5, 0.5])\n\ntr = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.Resize((224, 224)),  \n        transforms.ToTensor(),        \n        transforms.Normalize(mean, std)\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-10-31T09:45:17.057724Z","iopub.execute_input":"2021-10-31T09:45:17.058015Z","iopub.status.idle":"2021-10-31T09:45:17.066107Z","shell.execute_reply.started":"2021-10-31T09:45:17.057985Z","shell.execute_reply":"2021-10-31T09:45:17.064781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# unzip train and test data\nshutil.unpack_archive('../input/cifar-10/train.7z')\nshutil.unpack_archive('../input/cifar-10/test.7z')","metadata":{"execution":{"iopub.status.busy":"2021-10-31T09:45:19.140407Z","iopub.execute_input":"2021-10-31T09:45:19.14124Z","iopub.status.idle":"2021-10-31T10:01:15.307766Z","shell.execute_reply.started":"2021-10-31T09:45:19.141173Z","shell.execute_reply":"2021-10-31T10:01:15.306677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset = CifarLoader(csv_file = '../input/cifar-10/trainLabels.csv', \n                      root_dir = './train',\n                      transform = tr)\n\nprint(dataset.df.head())","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:01:15.309832Z","iopub.execute_input":"2021-10-31T10:01:15.310194Z","iopub.status.idle":"2021-10-31T10:01:15.384712Z","shell.execute_reply.started":"2021-10-31T10:01:15.310126Z","shell.execute_reply":"2021-10-31T10:01:15.38373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"############################### SPLIT THE DATA #################################\n\nindexes = list(range(len(dataset)))\n\ntrain_indexes, val_indexes = train_test_split(indexes, test_size=0.2)\n\ndata = {}\ndata['train'] = Subset(dataset, train_indexes)\ndata['val'] = Subset(dataset, val_indexes)\n\ndataloader_train = DataLoader(dataset = data['train'], batch_size = batch_size, shuffle=False)\ndataloader_val = DataLoader(dataset = data['val'], batch_size = batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:01:15.386409Z","iopub.execute_input":"2021-10-31T10:01:15.386751Z","iopub.status.idle":"2021-10-31T10:01:15.420215Z","shell.execute_reply.started":"2021-10-31T10:01:15.386712Z","shell.execute_reply":"2021-10-31T10:01:15.41909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_indexes), len(val_indexes))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:01:15.423288Z","iopub.execute_input":"2021-10-31T10:01:15.423645Z","iopub.status.idle":"2021-10-31T10:01:15.430396Z","shell.execute_reply.started":"2021-10-31T10:01:15.423588Z","shell.execute_reply":"2021-10-31T10:01:15.429072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################ SHOW IMAGES ##################################\n\ndef images_show(images, lbls=None):\n  # show only 4 first images from each batch\n  for i in range(4):\n    plt.subplot(1, 4, i + 1)\n    # convert to numpy\n    img = images[i].numpy().transpose((1, 2, 0))\n    # unnormalize\n    img = img * std + mean \n    img = np.clip(img, a_min=0, a_max=1)\n    plt.imshow(img)\n \n    if lbls != None:\n      # decode labels using reversed annotation dictionary\n      plt.title(dataset.annot_dict_reversed[lbls[i].item()])\n    plt.axis('off')\n  plt.tight_layout(pad=0.5)\n  plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:01:15.432227Z","iopub.execute_input":"2021-10-31T10:01:15.43325Z","iopub.status.idle":"2021-10-31T10:01:15.445133Z","shell.execute_reply.started":"2021-10-31T10:01:15.433206Z","shell.execute_reply":"2021-10-31T10:01:15.443816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(dataloader_train)\nimages, labels = dataiter.next()\n\nprint(f'Shape: {images.shape}')\nprint(f'Max: {torch.max(images[0]):.2f}')\nprint(f'Min: {torch.min(images[0]):.2f}')\n\nfor i in range(3):\n  images, labels = dataiter.next()\n  images_show(images, labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:01:15.447457Z","iopub.execute_input":"2021-10-31T10:01:15.447892Z","iopub.status.idle":"2021-10-31T10:01:17.367675Z","shell.execute_reply.started":"2021-10-31T10:01:15.447848Z","shell.execute_reply":"2021-10-31T10:01:17.366753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load pretrained DenseNet-121.","metadata":{}},{"cell_type":"code","source":"################################ FINETUNING ##################################\n\n# Load a pretrained model and reset final fully connected layer\n\n# load a pretrained model \nmodel = models.densenet121(pretrained=True)\n\n# reset final fully connected layer\nnum_ftrs = model.classifier.in_features\n\nmodel.classifier = nn.Sequential(\n                        nn.Linear(num_ftrs, 256),  \n                        nn.ReLU(), \n                        nn.Dropout(0.3),\n                        nn.Linear(256, 10))\n\n# copy weights for futher retraining on full train dataset\nmodel_wts = copy.deepcopy(model.state_dict())\n\n# move model to a device\nmodel = model.to(device)\n\n# loss\ncriterion = nn.CrossEntropyLoss()\n\n# all parameters are being optimized\noptimizer = optim.SGD(model.parameters(), lr=lr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################ TRAINING FUNC ################################\n\ndef train(model, criterion, optimizer, num_epochs, \n          dataloader_train, dataloader_val = None):\n\n  history = {\n        'loss': [],\n        'accuracy': [],\n        'val_loss': [],\n        'val_accuracy': [],\n        'best train acc': (0, 0)\n        }\n\n  best_model_wts = copy.deepcopy(model.state_dict())\n  best_acc = 0.0\n\n\n  for epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch + 1, num_epochs))\n\n    # set model to the training mode\n    model.train()\n\n    n_samples = 0\n    correct_train = 0\n    epoch_loss_train = 0\n    epoch_loss_val = 0\n\n\n    for i, (images, labels) in enumerate(dataloader_train):\n      # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n    \n      images = images.to(device)\n      labels = labels.to(device)\n\n      # forward pass (pred)\n      pred = model(images)\n\n      # loss\n      loss = criterion(pred, labels)\n\n      # mean loss * num samples in batch\n      epoch_loss_train += labels.shape[0] * loss.item()\n\n      # empty gradients\n      optimizer.zero_grad()\n\n      # gradient (backpropagation)\n      loss.backward()\n\n      # update weights\n      optimizer.step()\n\n      # values, indexes\n      value, predicted = torch.max(pred, 1)\n\n      # += batch_size\n      n_samples += labels.shape[0]\n      # num of correctly predicted in this batch\n      correct_train += (predicted==labels).sum().item()\n\n    # train acc per epoch\n    train_acc = 100 * correct_train / n_samples\n    # train loss per epoch\n    epoch_loss_train = epoch_loss_train / n_samples\n\n    print(f'Train accuracy: {train_acc:.2f}, loss: {epoch_loss_train:.2f}')\n    #print(f'Best accuracy: {best_acc:.2f}')\n\n    history['accuracy'].append(train_acc)\n    history['loss'].append(epoch_loss_train)\n\n    # find best accuracy on training data\n    if train_acc > best_acc:\n\n      #print('*New best accuracy*')\n      best_acc = train_acc\n\n      # copy current model weights\n      best_model_wts = copy.deepcopy(model.state_dict())\n      history['best train acc'] = (epoch, best_acc)\n\n\n\n    if dataloader_val:\n\n      # evaluation mode\n      model.eval()\n\n      with torch.no_grad():\n        correct_val = 0\n        n_samples = 0\n\n        for images, labels in dataloader_val: \n          images = images.to(device)\n          labels = labels.to(device)\n\n          outputs = model(images)\n\n          loss = criterion(outputs, labels)\n          epoch_loss_val += labels.shape[0] * loss.item()\n\n          # value, index\n          _, pred = torch.max(outputs, 1)\n          n_samples += labels.shape[0]\n          correct_val += (pred==labels).sum().item()\n\n        # calculate validation accuracy and loss for each epoch\n        val_acc = 100 * correct_val / len(data['val'])\n        epoch_loss_val = epoch_loss_val / len(data['val'])\n\n        print(f'Val accuracy: {val_acc:.2f}, loss: {epoch_loss_val:.2f}')\n\n        history['val_accuracy'].append(val_acc)\n        history['val_loss'].append(epoch_loss_val)\n      \n    print('=' * 80)\n\n\n  print('Best train acc: {:2f}'.format(best_acc))\n\n  # load best weights\n  model.load_state_dict(best_model_wts)\n\n  return model, history","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:01:21.951069Z","iopub.execute_input":"2021-10-31T10:01:21.951574Z","iopub.status.idle":"2021-10-31T10:01:22.006269Z","shell.execute_reply.started":"2021-10-31T10:01:21.951507Z","shell.execute_reply":"2021-10-31T10:01:22.003809Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = train(model, criterion, optimizer, num_epochs, \n                       dataloader_train, dataloader_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:01:22.008607Z","iopub.execute_input":"2021-10-31T10:01:22.008962Z","iopub.status.idle":"2021-10-31T10:19:03.570043Z","shell.execute_reply.started":"2021-10-31T10:01:22.008882Z","shell.execute_reply":"2021-10-31T10:19:03.568851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history):\n   \n    loss = history['loss']\n    accuracy = history['accuracy']\n    val_loss = history['val_loss']\n    val_accuracy = history['val_accuracy']\n    x = range(len(loss))\n\n    plt.figure(figsize=(12, 5))\n    plt.subplot(1, 2, 1)\n    plt.plot(x, accuracy, label='Training acc', color='#03045e', linewidth=2)\n    if len(val_loss) != 0:\n      plt.plot(x, val_accuracy, label='Validation acc', color='#48cae4', linewidth=2)\n    plt.plot(history['best train acc'][0], \n             history['best train acc'][1], \n             'bo', label='Best train acc', markersize=7, color='black')\n    plt.title('Accuracy')\n    plt.grid(True)\n    plt.legend()\n    \n    \n    plt.subplot(1, 2, 2)\n    plt.plot(x, loss, label='Training loss', color='#03045e', linewidth=2)\n    if len(val_loss) != 0:\n      plt.plot(x, val_loss, label='Validation loss', color='#48cae4', linewidth=2)\n    plt.title('Loss')\n    plt.grid(True)\n    plt.legend()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:03.57471Z","iopub.execute_input":"2021-10-31T10:19:03.575172Z","iopub.status.idle":"2021-10-31T10:19:03.585689Z","shell.execute_reply.started":"2021-10-31T10:19:03.575128Z","shell.execute_reply":"2021-10-31T10:19:03.584659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:03.587544Z","iopub.execute_input":"2021-10-31T10:19:03.588252Z","iopub.status.idle":"2021-10-31T10:19:04.153428Z","shell.execute_reply.started":"2021-10-31T10:19:03.588206Z","shell.execute_reply":"2021-10-31T10:19:04.15241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################## EVALUATE ##################################\ndef evaluate(model, dataloader):\n\n  with torch.no_grad():\n    model.eval()\n    n_correct = 0\n    n_samples = 0\n\n    for images, labels in dataloader: \n      images = images.to(device)\n      labels = labels.to(device)\n\n      outputs = model(images)\n\n      # value, index\n      v, pred = torch.max(outputs, 1)\n\n      n_samples += labels.shape[0]\n      n_correct += (pred==labels).sum().item()\n\n    acc = 100.0 * n_correct / n_samples\n    print(acc)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:04.154978Z","iopub.execute_input":"2021-10-31T10:19:04.155835Z","iopub.status.idle":"2021-10-31T10:19:04.165199Z","shell.execute_reply.started":"2021-10-31T10:19:04.15578Z","shell.execute_reply":"2021-10-31T10:19:04.164408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate(model, dataloader_val)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:04.166875Z","iopub.execute_input":"2021-10-31T10:19:04.167241Z","iopub.status.idle":"2021-10-31T10:19:44.107951Z","shell.execute_reply.started":"2021-10-31T10:19:04.167196Z","shell.execute_reply":"2021-10-31T10:19:44.106952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Retrain model on full training set.","metadata":{}},{"cell_type":"code","source":"############################## COMPLETE DATASET ###############################\n\ndataloader = DataLoader(dataset = dataset, batch_size = batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:44.109465Z","iopub.execute_input":"2021-10-31T10:19:44.11131Z","iopub.status.idle":"2021-10-31T10:19:44.116795Z","shell.execute_reply.started":"2021-10-31T10:19:44.111249Z","shell.execute_reply":"2021-10-31T10:19:44.115467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = CifarLoader(root_dir = './test',\n                      transform = tr)\n\ndataloader_test = DataLoader(dataset = dataset_test, \n                             batch_size = batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:44.118508Z","iopub.execute_input":"2021-10-31T10:19:44.119251Z","iopub.status.idle":"2021-10-31T10:19:44.747797Z","shell.execute_reply.started":"2021-10-31T10:19:44.119207Z","shell.execute_reply":"2021-10-31T10:19:44.746798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################# RESET MODEL ##################################\n\nmodel.load_state_dict(model_wts)\n\n# loss\ncriterion = nn.CrossEntropyLoss()\n\n# all parameters are being optimized\noptimizer = optim.SGD(model.parameters(), lr=lr)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:44.749138Z","iopub.execute_input":"2021-10-31T10:19:44.749443Z","iopub.status.idle":"2021-10-31T10:19:44.863544Z","shell.execute_reply.started":"2021-10-31T10:19:44.749402Z","shell.execute_reply":"2021-10-31T10:19:44.862555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model, history = train(model, criterion, optimizer, 3, dataloader)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:19:44.864955Z","iopub.execute_input":"2021-10-31T10:19:44.865318Z","iopub.status.idle":"2021-10-31T10:39:22.491969Z","shell.execute_reply.started":"2021-10-31T10:19:44.865258Z","shell.execute_reply":"2021-10-31T10:39:22.491069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(dataset_test))","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:39:22.493886Z","iopub.execute_input":"2021-10-31T10:39:22.496236Z","iopub.status.idle":"2021-10-31T10:39:22.503725Z","shell.execute_reply.started":"2021-10-31T10:39:22.496193Z","shell.execute_reply":"2021-10-31T10:39:22.502259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"################################### PREDICT ####################################\n\npredictions = np.array([])\n\nwith torch.no_grad():\n    model.eval()\n\n    for images, _ in dataloader_test:\n      images = images.to(device)\n\n      outputs = model(images)\n\n      # value, index\n      v, pred = torch.max(outputs, 1)\n\n      pred = pred.cpu().numpy()\n\n      predictions = np.concatenate((predictions, pred), axis = None)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:39:22.506462Z","iopub.execute_input":"2021-10-31T10:39:22.507836Z","iopub.status.idle":"2021-10-31T10:59:12.028351Z","shell.execute_reply.started":"2021-10-31T10:39:22.507742Z","shell.execute_reply":"2021-10-31T10:59:12.027392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test.df['encoded'] = predictions.astype(int)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:59:12.029837Z","iopub.execute_input":"2021-10-31T10:59:12.030171Z","iopub.status.idle":"2021-10-31T10:59:12.038344Z","shell.execute_reply.started":"2021-10-31T10:59:12.030131Z","shell.execute_reply":"2021-10-31T10:59:12.037358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test.df['label'] = dataset_test.df['encoded'].map(dataset.annot_dict_reversed)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:59:12.040048Z","iopub.execute_input":"2021-10-31T10:59:12.041194Z","iopub.status.idle":"2021-10-31T10:59:12.056937Z","shell.execute_reply.started":"2021-10-31T10:59:12.041132Z","shell.execute_reply":"2021-10-31T10:59:12.05601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test.df.head()","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:59:12.05891Z","iopub.execute_input":"2021-10-31T10:59:12.059739Z","iopub.status.idle":"2021-10-31T10:59:12.075061Z","shell.execute_reply.started":"2021-10-31T10:59:12.059645Z","shell.execute_reply":"2021-10-31T10:59:12.073874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataiter = iter(dataloader_test)\nimages, labels = dataiter.next()\n\nfor i in range(3):\n  images, labels = dataiter.next()\n  images_show(images, labels)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:59:12.076551Z","iopub.execute_input":"2021-10-31T10:59:12.07693Z","iopub.status.idle":"2021-10-31T10:59:13.726265Z","shell.execute_reply.started":"2021-10-31T10:59:12.076888Z","shell.execute_reply":"2021-10-31T10:59:13.725367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Submission file:","metadata":{}},{"cell_type":"code","source":"dataset_test.df.drop(columns ='encoded', inplace=True)\ndataset_test.df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:59:13.727849Z","iopub.execute_input":"2021-10-31T10:59:13.728489Z","iopub.status.idle":"2021-10-31T10:59:14.28627Z","shell.execute_reply.started":"2021-10-31T10:59:13.728429Z","shell.execute_reply":"2021-10-31T10:59:14.28537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%rm -rf ./train\n%rm -rf ./test","metadata":{"execution":{"iopub.status.busy":"2021-10-31T10:59:14.287756Z","iopub.execute_input":"2021-10-31T10:59:14.288061Z","iopub.status.idle":"2021-10-31T10:59:27.035832Z","shell.execute_reply.started":"2021-10-31T10:59:14.288008Z","shell.execute_reply":"2021-10-31T10:59:27.034519Z"},"trusted":true},"execution_count":null,"outputs":[]}]}