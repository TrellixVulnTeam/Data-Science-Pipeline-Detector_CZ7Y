{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport tensorflow as tf\nfrom keras.datasets import cifar10\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D, BatchNormalization, Conv2DTranspose\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils\nimport os \nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, ReduceLROnPlateau, TensorBoard, EarlyStopping\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nnp.random.seed(10)\n# 导入数据集，如果没有就会自动下载\n(x_img_train,y_label_train),(x_img_test, y_label_test)=cifar10.load_data()\n#print('train:',len(x_img_train))\n#print('test :',len(x_img_test))\n#print('train_image :',x_img_train.shape)\n#print('train_label :',y_label_train.shape)\n#print('test_image :',x_img_test.shape)\n#print('test_label :',y_label_test.shape)\n\n\nlabel_dict={0:\"airplane\",1:\"automobile\",2:\"bird\",3:\"cat\",4:\"deer\",\n            5:\"dog\",6:\"frog\",7:\"horse\",8:\"ship\",9:\"truck\"}\n\ndef plot_images_labels_prediction(images,labels,prediction,idx,num=10):\n    fig = plt.gcf()\n    fig.set_size_inches(12, 14) # 控制图片大小\n    if num>25: num=25  #最多显示25张\n    for i in range(0, num):\n        ax=plt.subplot(5,5, 1+i)\n        ax.imshow(images[idx],cmap='binary')\n        title=str(i)+','+label_dict[labels[i][0]]# i-th张图片对应的类别\n        if len(prediction)>0:\n            title+='=>'+label_dict[prediction[i]]\n        ax.set_title(title,fontsize=10) \n        ax.set_xticks([]);\n        ax.set_yticks([])        \n        idx+=1 \n    plt.savefig('1.png')\n    plt.show()\n\n#plot_images_labels_prediction(x_img_train,y_label_train,[],0,10)\n\n#print(y_label_train[0])\n#print(y_label_train[0][0])\n\n#print(x_img_train[0][0][0]) #（50000，32，32，3）\nx_img_train_normalize = x_img_train.astype('float32') / 255.0\nx_img_test_normalize = x_img_test.astype('float32') / 255.0\n#print(x_img_train_normalize[0][0][0])\n\n#print(y_label_train.shape)\n#print(y_label_train[:5])\n\ny_label_train_OneHot = np_utils.to_categorical(y_label_train)\ny_label_test_OneHot = np_utils.to_categorical(y_label_test)\n#print(y_label_train_OneHot.shape)\n#print(y_label_train_OneHot[:5])\n\nnp.random.seed(10)\n# 载入数据集\n(x_img_train,y_label_train),(x_img_test,y_label_test)=cifar10.load_data()\nprint(\"train data:\",'images:',x_img_train.shape,\n      \" labels:\",y_label_train.shape) \nprint(\"test  data:\",'images:',x_img_test.shape ,\n      \" labels:\",y_label_test.shape) \n# 归一化\nx_img_train_normalize = x_img_train.astype('float32') / 255.0\nx_img_test_normalize = x_img_test.astype('float32') / 255.0\n# One-Hot Encoding\n\ny_label_train_OneHot = np_utils.to_categorical(y_label_train)\ny_label_test_OneHot = np_utils.to_categorical(y_label_test)\ny_label_test_OneHot.shape\n\ndef create_model():\n    inputs = tf.keras.layers.Input(shape=(32, 32, 3))\n\n    x = tf.keras.layers.Conv2D(filters=32,kernel_size=(3, 3),activation='relu', padding='same')(inputs)\n    x = tf.keras.layers.BatchNormalization()(x)    \n    x = tf.keras.layers.Conv2D(filters=32,kernel_size=(3, 3),activation='relu', padding='same')(x)\n    #x = tf.keras.layers.BatchNormalization()(x)\n    x = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid')(x)\n\n    x1 = tf.keras.layers.Conv2D(filters=64,kernel_size=(3, 3),activation='relu', padding='same')(x)\n    x1 = tf.keras.layers.BatchNormalization()(x1)    \n    x1 = tf.keras.layers.Conv2D(filters=64,kernel_size=(3, 3),activation='relu', padding='same')(x1)\n    #x1 = tf.keras.layers.BatchNormalization()(x1)\n    x1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid')(x1)\n\n    x2 = tf.keras.layers.Conv2D(filters=128,kernel_size=(3, 3),activation='relu', padding='same')(x1)\n    x2 = tf.keras.layers.BatchNormalization()(x2)    \n    x2 = tf.keras.layers.Conv2D(filters=128,kernel_size=(3, 3),activation='relu', padding='same')(x2)\n    #x2 = tf.keras.layers.BatchNormalization()(x2)\n    x2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid')(x2)\n\n    x3 = tf.keras.layers.Conv2D(filters=256,kernel_size=(3, 3),activation='relu', padding='same')(x2)\n    x3 = tf.keras.layers.BatchNormalization()(x3)    \n    x3 = tf.keras.layers.Conv2D(filters=256,kernel_size=(3, 3),activation='relu', padding='same')(x3)\n    #x3 = tf.keras.layers.BatchNormalization()(x3)\n    x3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2), padding='valid')(x3)\n\n    y = tf.keras.layers.Flatten()(x3)\n    y = tf.keras.layers.BatchNormalization()(y)\n    y = tf.keras.layers.Dense(1250, activation='relu')(y)\n    y = tf.keras.layers.BatchNormalization()(y)\n    y = tf.keras.layers.Dense(750, activation='relu')(y)\n    y = tf.keras.layers.BatchNormalization()(y)\n\n    output = tf.keras.layers.Dense(10, activation='softmax')(y)\n\n    return tf.keras.Model(inputs=inputs, outputs=output)\n\nmodel = create_model()\nmodel.summary()\n \nos.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"  \n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=6, verbose=1)\n\nfilepath = 'cifarCnnModel.h5'\ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n\nearly = EarlyStopping(monitor='val_loss', min_delta=0, patience=20, verbose=1, mode='auto')\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n\naug_gen = ImageDataGenerator(\n    featurewise_center = False,  # set input mean to 0 over the dataset\n    samplewise_center = False,  # set each sample mean to 0\n    featurewise_std_normalization = False,  # divide inputs by std of the dataset\n    samplewise_std_normalization = False,  # divide each input by its std\n    zca_whitening = False,  # apply ZCA whitening\n    rotation_range = 0,  # randomly rotate images in the range (degrees, 0 to 180)\n    width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n    height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n    horizontal_flip = True,  # randomly flip images\n    vertical_flip = False,  # randomly flip images\n)\n\naug_gen.fit(x_img_train_normalize)\n\n\ntrain_history=model.fit(aug_gen.flow(x_img_train_normalize,  y_label_train_OneHot, batch_size=64), \n                        validation_data=(x_img_test_normalize, y_label_test_OneHot),\n                        epochs=100,  \n                        verbose=2, \n                        shuffle=True,\n                        callbacks=[checkpoint, early, reduce_lr]) \n\n#tensorboard --logdir=C:\\Users\\JingZ\\source\\repos\\PythonApplication8\\PythonApplication8\\logs\n\nmodel = tf.keras.models.load_model('cifarCnnModel.h5')\n\nscores = model.evaluate(x_img_test_normalize, \n                        y_label_test_OneHot, verbose=2)\nprint(scores[1])\n\nrand_id = np.random.choice(range(10000), size=20)\nX_pred = np.array([x_img_test_normalize[i] for i in rand_id])\ny_true = [y_label_test_OneHot[i] for i in rand_id]\ny_true = np.argmax(y_true, axis=1)\ny_true = [label_dict[name] for name in y_true]\ny_pred = model.predict(X_pred)\ny_pred = np.argmax(y_pred, axis=1)\ny_pred = [label_dict[name] for name in y_pred]\nplt.figure(figsize=(15, 7))\nfor i in range(20):\n    plt.subplot(4, 5, i + 1)\n    plt.imshow(X_pred[i].reshape(32, 32, 3), cmap='gray')\n    plt.title('True: %s \\n Pred: %s' % (y_true[i], y_pred[i]), size=15)\nplt.tight_layout()\nplt.show()","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}