{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### https://www.kaggle.com/c/cifar-10","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfor dirname, _, filenames in os.walk('/kaggle/working'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2022-01-26T16:46:46.179402Z","iopub.execute_input":"2022-01-26T16:46:46.179752Z","iopub.status.idle":"2022-01-26T16:46:46.191048Z","shell.execute_reply.started":"2022-01-26T16:46:46.179706Z","shell.execute_reply":"2022-01-26T16:46:46.190086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import everything needed","metadata":{}},{"cell_type":"code","source":"import glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport collections\nimport math\nimport os\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nimport torchvision\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T16:46:46.193219Z","iopub.execute_input":"2022-01-26T16:46:46.193586Z","iopub.status.idle":"2022-01-26T16:46:46.202832Z","shell.execute_reply.started":"2022-01-26T16:46:46.193546Z","shell.execute_reply":"2022-01-26T16:46:46.202084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unzip datasets","metadata":{}},{"cell_type":"code","source":"!pip install py7zr","metadata":{"execution":{"iopub.status.busy":"2022-01-26T16:46:46.204151Z","iopub.execute_input":"2022-01-26T16:46:46.20467Z","iopub.status.idle":"2022-01-26T16:46:58.077707Z","shell.execute_reply.started":"2022-01-26T16:46:46.204623Z","shell.execute_reply":"2022-01-26T16:46:58.07687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m py7zr x /kaggle/input/cifar-10/train.7z","metadata":{"execution":{"iopub.status.busy":"2022-01-26T16:46:58.080369Z","iopub.execute_input":"2022-01-26T16:46:58.080655Z","iopub.status.idle":"2022-01-26T16:47:41.652427Z","shell.execute_reply.started":"2022-01-26T16:46:58.080616Z","shell.execute_reply":"2022-01-26T16:47:41.651428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m py7zr x /kaggle/input/cifar-10/test.7z","metadata":{"execution":{"iopub.status.busy":"2022-01-26T16:47:41.658257Z","iopub.execute_input":"2022-01-26T16:47:41.65885Z","iopub.status.idle":"2022-01-26T17:01:57.345741Z","shell.execute_reply.started":"2022-01-26T16:47:41.658808Z","shell.execute_reply":"2022-01-26T17:01:57.344794Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:01:57.347364Z","iopub.execute_input":"2022-01-26T17:01:57.347623Z","iopub.status.idle":"2022-01-26T17:01:57.352326Z","shell.execute_reply.started":"2022-01-26T17:01:57.347586Z","shell.execute_reply":"2022-01-26T17:01:57.351529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read CSV labels","metadata":{}},{"cell_type":"code","source":"def read_csv_labels(fname):\n    \"\"\"Read `fname` to return a filename to label dictionary.\"\"\"\n    with open(fname, 'r') as f:\n        # Skip the file header line (column name)\n        lines = f.readlines()[1:]\n    tokens = [l.rstrip().split(',') for l in lines]\n    return dict(((name, label) for name, label in tokens))\n\nlabels = read_csv_labels(os.path.join(data_dir, '/kaggle/input/cifar-10/trainLabels.csv'))\nprint(f'Number training examples: {len(labels)}')\nprint(f'Number classes: {len(set(labels.values()))}')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:01:57.353664Z","iopub.execute_input":"2022-01-26T17:01:57.355349Z","iopub.status.idle":"2022-01-26T17:01:57.422335Z","shell.execute_reply.started":"2022-01-26T17:01:57.355287Z","shell.execute_reply":"2022-01-26T17:01:57.421577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data restructuring","metadata":{}},{"cell_type":"markdown","source":"### Copy and reorganize files for training and validation ","metadata":{}},{"cell_type":"code","source":"def copyfile(filename, target_dir):\n    \"\"\"Copy a file into a target directory.\"\"\"\n    os.makedirs(target_dir, exist_ok=True)\n    shutil.copy(filename, target_dir)\n\ndef reorg_train_valid(data_dir, labels, valid_ratio):\n    \"\"\"Split the validation set out of the original training set.\"\"\"\n    # The number of examples of the class that has the fewest examples in the\n    # training dataset\n    n = collections.Counter(labels.values()).most_common()[-1][1]\n    # The number of examples per class for the validation set\n    n_valid_per_label = max(1, math.floor(n * valid_ratio))\n    label_count = {}\n    for train_file in os.listdir(os.path.join(data_dir, 'train')):\n        label = labels[train_file.split('.')[0]]\n        fname = os.path.join(data_dir, 'train', train_file)\n        copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                     'train_valid', label))\n        if label not in label_count or label_count[label] < n_valid_per_label:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'valid', label))\n            label_count[label] = label_count.get(label, 0) + 1\n        else:\n            copyfile(fname, os.path.join(data_dir, 'train_valid_test',\n                                         'train', label))\n    return n_valid_per_label","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:01:57.423489Z","iopub.execute_input":"2022-01-26T17:01:57.423741Z","iopub.status.idle":"2022-01-26T17:01:57.433422Z","shell.execute_reply.started":"2022-01-26T17:01:57.423704Z","shell.execute_reply":"2022-01-26T17:01:57.432141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reorganize files for testing","metadata":{}},{"cell_type":"code","source":"def reorg_test(data_dir):\n    \"\"\"Organize the testing set for data loading during prediction.\"\"\"\n    for test_file in os.listdir(os.path.join(data_dir, 'test')):\n        copyfile(os.path.join(data_dir, 'test', test_file),\n                 os.path.join(data_dir, 'train_valid_test', 'test',\n                              'unknown'))","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:01:57.436333Z","iopub.execute_input":"2022-01-26T17:01:57.436547Z","iopub.status.idle":"2022-01-26T17:01:57.443434Z","shell.execute_reply.started":"2022-01-26T17:01:57.436517Z","shell.execute_reply":"2022-01-26T17:01:57.44256Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read labels from CSV and reorganize the datasets","metadata":{}},{"cell_type":"code","source":"def reorg_cifar10_data(data_dir, valid_ratio):\n    labels = read_csv_labels('/kaggle/input/cifar-10/trainLabels.csv')\n    print(\"Start validation unzipping\")\n    reorg_train_valid(data_dir, labels, valid_ratio)\n    print(\"Start test unzipping\")\n    reorg_test(data_dir)\n    print(\"Done with unzipping\")","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:01:57.444803Z","iopub.execute_input":"2022-01-26T17:01:57.445179Z","iopub.status.idle":"2022-01-26T17:01:57.454669Z","shell.execute_reply.started":"2022-01-26T17:01:57.445142Z","shell.execute_reply":"2022-01-26T17:01:57.453938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Start restructuring","metadata":{}},{"cell_type":"code","source":"batch_size = 64\nvalid_ratio = 0.1\nreorg_cifar10_data(data_dir, valid_ratio)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:01:57.455857Z","iopub.execute_input":"2022-01-26T17:01:57.456276Z","iopub.status.idle":"2022-01-26T17:02:57.221952Z","shell.execute_reply.started":"2022-01-26T17:01:57.456174Z","shell.execute_reply":"2022-01-26T17:02:57.221192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Transform data","metadata":{}},{"cell_type":"code","source":"transform_train = torchvision.transforms.Compose([\n    transforms.RandomCrop(32, padding=4),\n    #transforms.RandomResizedCrop((200, 200), scale=(0.5, 1), ratio=(0.5, 2)) # crop area between 50% and 100% of the image\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3,hue=0.2),\n    # HorizontalFlip, RandomSizeCrop, \"small\" Color Jitter\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n                                     [0.2023, 0.1994, 0.2010])\n])\n\ntransform_test = torchvision.transforms.Compose([\n    torchvision.transforms.ToTensor(),\n    torchvision.transforms.Normalize([0.4914, 0.4822, 0.4465],\n                                     [0.2023, 0.1994, 0.2010])])","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:02:57.223107Z","iopub.execute_input":"2022-01-26T17:02:57.224046Z","iopub.status.idle":"2022-01-26T17:02:57.231199Z","shell.execute_reply.started":"2022-01-26T17:02:57.224005Z","shell.execute_reply":"2022-01-26T17:02:57.23039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Alternative: Direct download","metadata":{}},{"cell_type":"code","source":"\"\"\"train_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=True,\n                                           transform=train_augs, download=True)\ntest_dataset = torchvision.datasets.CIFAR10(root=\"data\", train=False,\n                                           transform=test_augs, download=True)\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\ntest_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:02:57.232482Z","iopub.execute_input":"2022-01-26T17:02:57.23274Z","iopub.status.idle":"2022-01-26T17:02:57.246676Z","shell.execute_reply.started":"2022-01-26T17:02:57.232706Z","shell.execute_reply":"2022-01-26T17:02:57.245938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create data loaders","metadata":{}},{"cell_type":"code","source":"train_ds, train_valid_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_train) for folder in ['train', 'train_valid']]\n\nvalid_ds, test_ds = [torchvision.datasets.ImageFolder(\n    os.path.join(data_dir, 'train_valid_test', folder),\n    transform=transform_test) for folder in ['valid', 'test']]\n\ntrain_iter, train_valid_iter = [torch.utils.data.DataLoader(\n    dataset, batch_size, shuffle=True, drop_last=True)\n    for dataset in (train_ds, train_valid_ds)]\n\nvalid_iter = torch.utils.data.DataLoader(valid_ds, batch_size, shuffle=False,\n                                         drop_last=True)\n\ntest_iter = torch.utils.data.DataLoader(test_ds, batch_size, shuffle=False,\n                                        drop_last=False)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:02:57.250362Z","iopub.execute_input":"2022-01-26T17:02:57.250578Z","iopub.status.idle":"2022-01-26T17:02:59.541991Z","shell.execute_reply.started":"2022-01-26T17:02:57.250552Z","shell.execute_reply":"2022-01-26T17:02:59.541229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TODO: \n* Define the data augmentation technique \n* Fine-tune a pre-trained ResNet-18 on CIFAR-10\n* Submit to Kaggle your submission file and get your accuracy on the test set","metadata":{}},{"cell_type":"markdown","source":"# Start wandb","metadata":{}},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_KEY\")\nwandb.login(key=secret_value_0)\nwandb.init(project='cifar-10', save_code=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:02:59.543476Z","iopub.execute_input":"2022-01-26T17:02:59.54374Z","iopub.status.idle":"2022-01-26T17:03:09.233103Z","shell.execute_reply.started":"2022-01-26T17:02:59.543706Z","shell.execute_reply":"2022-01-26T17:03:09.232242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pretrained net: resnet18","metadata":{}},{"cell_type":"code","source":"pretrained_net = torchvision.models.resnet18(pretrained=True)\npretrained_net.fc","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:03:09.237857Z","iopub.execute_input":"2022-01-26T17:03:09.238253Z","iopub.status.idle":"2022-01-26T17:03:10.629656Z","shell.execute_reply.started":"2022-01-26T17:03:09.238216Z","shell.execute_reply":"2022-01-26T17:03:10.628945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#If you only want to train the head of the network\nif False:\n    for param in pretrained_net.parameters():\n        param.requires_grad = False\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Swap the head with a Linear layer of the correct output shape that we initialize","metadata":{}},{"cell_type":"markdown","source":"## Initialize model","metadata":{}},{"cell_type":"code","source":"pretrained_net.fc = nn.Linear(pretrained_net.fc.in_features, 10) # swap head with linear layer of the correct output shape\nnn.init.xavier_normal_(pretrained_net.fc.weight)\nnn.init.constant_(pretrained_net.fc.bias, 0)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:03:10.63098Z","iopub.execute_input":"2022-01-26T17:03:10.631264Z","iopub.status.idle":"2022-01-26T17:03:11.378258Z","shell.execute_reply.started":"2022-01-26T17:03:10.631227Z","shell.execute_reply":"2022-01-26T17:03:11.377537Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define optimizer, criterion and put on GPU if possible","metadata":{}},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\npretrained_net = pretrained_net.to(device)\nif device == 'cuda':\n    pretrained_net = torch.nn.DataParallel(pretrained_net) # if multiple GPUs use them\ncriterion = nn.CrossEntropyLoss(label_smoothing=0.1)#label_smoothing=0.1)\noptimizer = torch.optim.AdamW(pretrained_net.parameters(), lr=1e-4, weight_decay=0.0001)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3, verbose=True, min_lr=1e-5, factor=0.5)\nwandb.watch(pretrained_net, log=\"all\", criterion=criterion, log_freq=1,  log_graph=(True)) ","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:03:11.379764Z","iopub.execute_input":"2022-01-26T17:03:11.380233Z","iopub.status.idle":"2022-01-26T17:03:15.413588Z","shell.execute_reply.started":"2022-01-26T17:03:11.380196Z","shell.execute_reply":"2022-01-26T17:03:15.412925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"TRAIN = True\n\nif TRAIN:\n    from tqdm.notebook import trange, tqdm\n\n    epochs = 10\n    for epoch in trange(epochs):\n        accurate = 0\n        total = 0\n        losses = 0\n        for X, y in tqdm(train_iter):\n            X = X.to(device)\n            y = y.to(device)\n            y_pred = pretrained_net(X)\n            loss = criterion(y_pred, y)\n            score, predicted = torch.max(y_pred, 1)\n            accurate += (y == predicted).sum().float()\n            losses += loss.item()\n            total += len(y)\n\n            # zero the gradients before running\n            # the backward pass.\n            optimizer.zero_grad()\n\n            # Backward pass to compute the gradient\n            # of loss w.r.t our learnable params. \n            loss.backward()\n\n            # Update params\n            optimizer.step()\n\n        wandb.log({\n                'train_loss': losses / len(train_iter),\n                'train_accuracy': accurate / total\n        })\n        with torch.no_grad(): # validation run\n            accurate = 0\n            total = 0\n            losses = 0\n            pretrained_net.eval() # validation mode\n\n            for X, y in tqdm(valid_iter):\n                X = X.to(device)\n                y = y.to(device)\n                y_pred = pretrained_net(X)\n                loss = criterion(y_pred, y)\n                score, predicted = torch.max(y_pred, 1)\n                accurate += (y == predicted).sum().float()\n                losses += loss.item()\n                total += len(y)\n            wandb.log({\n                'valid_loss': losses / len(valid_iter),\n                'valid_accuracy': accurate / total\n            })\nelse:\n    pretrained_net.load_state_dict(torch.load('model.pt'))#/kaggle/input/model-resnet/model_resnet.pt","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:03:15.414733Z","iopub.execute_input":"2022-01-26T17:03:15.415006Z","iopub.status.idle":"2022-01-26T17:08:43.199122Z","shell.execute_reply.started":"2022-01-26T17:03:15.41497Z","shell.execute_reply":"2022-01-26T17:08:43.196277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save W&B","metadata":{}},{"cell_type":"code","source":"if True:\n    torch.save(pretrained_net.state_dict(), 'model.pt')","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:08:43.200084Z","iopub.status.idle":"2022-01-26T17:08:43.20037Z","shell.execute_reply.started":"2022-01-26T17:08:43.200225Z","shell.execute_reply":"2022-01-26T17:08:43.200241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submission","metadata":{}},{"cell_type":"code","source":"preds = []\n\npretrained_net.eval()\nwith torch.no_grad():\n    for X, _ in test_iter:\n        X = X.to(device)\n        preds.extend(pretrained_net(X).argmax(dim=1).type(torch.int32).cpu().numpy())","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:08:43.201595Z","iopub.status.idle":"2022-01-26T17:08:43.201993Z","shell.execute_reply.started":"2022-01-26T17:08:43.201757Z","shell.execute_reply":"2022-01-26T17:08:43.201778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = list(range(1, len(test_ds)+1))\nids.sort(key=lambda x: str(x))","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:08:43.202991Z","iopub.status.idle":"2022-01-26T17:08:43.203505Z","shell.execute_reply.started":"2022-01-26T17:08:43.203245Z","shell.execute_reply":"2022-01-26T17:08:43.203278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame({'id': ids, 'label': preds})\ndf['label'] = df['label'].apply(lambda x: train_ds.classes[x])\ndf.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-26T17:08:43.204738Z","iopub.status.idle":"2022-01-26T17:08:43.20512Z","shell.execute_reply.started":"2022-01-26T17:08:43.204912Z","shell.execute_reply":"2022-01-26T17:08:43.204935Z"},"trusted":true},"execution_count":null,"outputs":[]}]}