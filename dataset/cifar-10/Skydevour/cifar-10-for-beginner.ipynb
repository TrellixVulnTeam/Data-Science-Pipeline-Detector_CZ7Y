{"cells":[{"metadata":{},"cell_type":"markdown","source":"Because the decompression is too time-consuming, the code has been tested, but this notebook is only used to help understand the process."},{"metadata":{},"cell_type":"markdown","source":"# **First try**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install py7zr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m py7zr x ../input/cifar-10/train.7z /kaggle/working/\n!python -m py7zr x ../input/cifar-10/test.7z /kaggle/working/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../working\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_path = \"/kaggle/working/train\"\ntest_images_path = \"/kaggle/working/test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install tensorflow-gpu\n\n!pip install glob2\n!pip install opencv\n\n!pip install numpy\n!pip install pandas\n\n!pip install scikit-learn \n!pip install pydot\n!pip install matplotlib","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob\nimport os\nimport cv2\nimport numpy as np \n        \n# Since the folders only contain Images, the size of the datasets is the number of files in it's folder\nnum_of_train_images = len(glob.glob(train_images_path+\"/*\"))\nnum_of_test_images = len(glob.glob(test_images_path+\"/*\"))\n\n# Let's create a dataset from the images\ntrain_images = [[]]*num_of_train_images\nfor dir_name, _, filenames in os.walk('/kaggle/working/train'):\n    for filename in filenames:\n        image_index = int(filename.split(\".\")[0])-1\n        img = cv2.imread(os.path.join(dir_name,filename))\n        # Add the image to the dataset\n        train_images[image_index] = img\n        \ntest_images = [[]]*num_of_test_images\nfor dir_name, _, filenames in os.walk('/kaggle/working/test'):\n    for filename in filenames:\n        image_index = int(filename.split(\".\")[0])-1\n        img = cv2.imread(os.path.join(dir_name,filename))\n        # Add the image to the dataset\n        test_images[image_index] = img\n        \n        \n# The RGB values are between 0 and 255, let's divide them so the values will be between 0 and 1\ntrain_images = np.asarray(train_images, dtype=float)/255\ntest_images = np.asarray(test_images, dtype=float)/255\n\n\n\n# # If you want, you can save the dataset and load it, instead of running this block each time\nnp.save(\"../working/train_images.npy\", train_images)\nnp.save(\"../working/test_images.npy\", test_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = np.load(\"../working/train_images.npy\")\ntest_images = np.load(\"../working/test_images.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_images.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels = pd.read_csv('/kaggle/input/cifar-10/trainLabels.csv')\n\nprint(\"Number of train images: \", train_images.shape[0])\nprint(\"Number of test images: \", test_images.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=plt.figure(figsize=(8, 8))\ncolumns = 4\nrows = 2\nfor i in range(1, columns*rows +1):\n    img = train_images[i]\n    fig.add_subplot(rows, columns, i, title=[train_labels.label[i]])\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom tensorflow import keras\n\n# Model architecture\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import Sequential, datasets,models,layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D, DepthwiseConv2D, BatchNormalization\nfrom tensorflow.keras.models import load_model\n\n# Data processing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n# Make sure you are running on a GPU!","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = list(set(list(train_labels.label)))\nclasses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes=len(classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_dict =  {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\nlabels_dict_reversed = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels['Category'] = train_labels.label.map(labels_dict_reversed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The categories are represented by numbers from 0 to 9.\n# Our network needs another representation- a vector of 0's and 1's.\n# This function converts the categories to a One-hot vector.\n# For example, if the label is 3, then the function will return [0,0,0,1,0,0,0,0,0,0]\ntrain_labels_categories = keras.utils.to_categorical(train_labels.Category, num_classes)#.astype('uint8')\n\n# Splitting the training data into train set and validation set\nx_train, x_val, y_train, y_val = train_test_split(train_images, train_labels_categories, random_state=0, test_size=0.05)\n\n# for Keras dataset only\n# x_test = test_images.astype('float32')/255\n# y_test = keras.utils.to_categorical(test_labels, num_classes).astype('uint8')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels_categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data augumetation\ndatagen = ImageDataGenerator(\n        rotation_range=0.3,  \n        zoom_range = 0.1,  \n        width_shift_range=0.1, \n        height_shift_range=0.1,\n        horizontal_flip=True)\ndatagen.fit(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # resnet layer\n# def resnet_layer(inputs,\n#                  num_filters=16,\n#                  kernel_size=3,\n#                  strides=1,\n#                  activation='relu',\n#                  batch_normalization=True,\n#                  conv_first=True):\n\n#     conv = Conv2D(num_filters,\n#                   kernel_size=kernel_size,\n#                   strides=strides,\n#                   padding='same',\n#                   kernel_initializer='he_normal',\n#                   kernel_regularizer=l2(1e-4))\n\n#     x = inputs\n#     if conv_first:\n#         x = conv(x)\n#         if batch_normalization:\n#             x = BatchNormalization()(x)\n#         if activation is not None:\n#             x = Activation(activation)(x)\n#     else:\n#         if batch_normalization:\n#             x = BatchNormalization()(x)\n#         if activation is not None:\n#             x = Activation(activation)(x)\n#         x = conv(x)\n#     return x\n\n\n# def resnet_v1(input_shape, depth, num_classes=10):\n#     # ResNet Version 1 Model builder [a]\n#     if (depth - 2) % 6 != 0:\n#         raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n#     # Start model definition.\n#     num_filters = 16\n#     num_res_blocks = int((depth - 2) / 6)\n\n#     inputs = Input(shape=input_shape)\n#     x = resnet_layer(inputs=inputs)\n#     # Instantiate the stack of residual units\n#     for stack in range(3):\n#         for res_block in range(num_res_blocks):\n#             strides = 1\n#             if stack > 0 and res_block == 0:  # first layer but not first stack\n#                 strides = 2  # downsample\n#             y = resnet_layer(inputs=x,\n#                              num_filters=num_filters,\n#                              strides=strides)\n#             y = resnet_layer(inputs=y,\n#                              num_filters=num_filters,\n#                              activation=None)\n#             if stack > 0 and res_block == 0:  # first layer but not first stack\n#                 # linear projection residual shortcut connection to match\n#                 # changed dims\n#                 x = resnet_layer(inputs=x,\n#                                  num_filters=num_filters,\n#                                  kernel_size=1,\n#                                  strides=strides,\n#                                  activation=None,\n#                                  batch_normalization=False)\n#             x = keras.layers.add([x, y])\n#             x = Activation('relu')(x)\n#         num_filters *= 2\n\n#     # Add classifier on top.\n#     # v1 does not use BN after last shortcut connection-ReLU\n#     x = AveragePooling2D(pool_size=8)(x)\n#     y = Flatten()(x)\n#     outputs = Dense(num_classes,\n#                     activation='softmax',\n#                     kernel_initializer='he_normal')(y)\n\n#     # Instantiate model.\n#     model = Model(inputs=inputs, outputs=outputs)\n#     return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"depth = n * 6 + 2\ninput_shape = x_train.shape[1:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lr_schedule(epoch):\n    lr = 1e-3\n    if epoch > 180:\n        lr *= 0.5e-3\n    elif epoch > 160:\n        lr *= 1e-3\n    elif epoch > 120:\n        lr *= 1e-2\n    elif epoch > 80:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = resnet_v1(input_shape=input_shape, depth=depth, num_classes=num_classes)\n# model.compile(loss='categorical_crossentropy',\n#               optimizer=Adam(lr=lr_schedule(0)),\n#               metrics=['accuracy'])\n\n# model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\n#                     steps_per_epoch=len(x_train) // batch_size,\n#                     validation_data=(x_test, y_test),\n#                     epochs=epochs, verbose=1, workers=4,\n#                     callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_layers = [\n    Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='same', input_shape=(32, 32, 3)),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu, depth_multiplier=3),\n#     MaxPooling2D(2, 2),\n    Dropout(rate =0.1),\n    \n    \n    Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n#     MaxPooling2D(2, 2),\n    Dropout(rate = 0.1),\n    \n    Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n#     MaxPooling2D(2, 2),\n    Dropout(rate = 0.4),\n    \n    Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu),\n    \n    \n    Conv2D(256, (3, 3), activation='relu', strides=(2, 2), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu),\n    \n    \n    \n    Conv2D(512, (1, 1), activation='relu', strides=(2, 2), padding='same'),\n    BatchNormalization(),\n    DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu),\n    \n#     MaxPooling2D(2, 2),\n    Dropout(rate = 0.4),\n    \n    Flatten(),\n    Dropout(rate = 0.3),\n    Dense(2048, activation='relu'),\n    Dropout(rate = 0.3),\n    Dense(512, activation='relu'),\n    Dropout(rate = 0.4),\n    Dense(10, activation='softmax')\n] \nmodel = Sequential(model_layers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# A summary of the model. \n# We can see how many parameters are in each layer and the total number of parameters.\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nmodel.compile(optimizer=Adam(lr=lr_schedule(0)), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization of the model\nkeras.utils.plot_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mcp_save = ModelCheckpoint('../working/best_model', save_best_only=True, monitor='val_accuracy', mode='max')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training the model on the augmented train set\n# We reached a score of ~90% after 100 epochs. 5 epochs won't get a score near that, but on Kaggle each epcoh takes a long time.\n# Choose the number of epochs that fits your machine. Same for batch_size, which we set to 512 on my machine.\nnum_of_epochs = 5\nbatch_size = 64 \n# The number of iteration in one epoch is ceil((size of training data)/(batch size)). ceil(47,500/64)=ceil(742.1875)=743\nmodel.fit(datagen.flow(x_train, y_train, batch_size=batch_size), validation_data=(x_val, y_val), callbacks=[mcp_save], epochs=num_of_epochs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_ = load_model('../working/best_model', compile=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions = model.predict_classes(test_images)\ntest_predictions","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_predictions_df = pd.DataFrame(test_predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# It's easy to use the sample submission file to create our own submission file\nsamples = pd.read_csv(\"../working/cifar-10/sampleSubmission.csv\", index_col=False)\n\n# Replace the sample labels with those our model predicted\nsamples.label= test_predictions\n\n# Our model predicts the number of the classes of each image.\n# Kaggle is expecting a string, for example, if our model predicted \"2\" we need to translate it to \"bird\"\nsamples.replace({\"label\":labels_dict}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's see how our model predicted some images\nfig=plt.figure(figsize=(8, 8))\ncolumns = 4\nrows = 2\nfor i in range(1, columns*rows +1):\n    img = test_images[i]\n    fig.add_subplot(rows, columns, i, title=samples.label[i])\n    plt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"samples.to_csv(\"../working/submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!kaggle competitions submit -c cifar-10 -f ../working/submission.csv -m \"Submitted using the notebook\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}