{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\nimport glob\nimport os\nimport cv2\nimport sys\n!pip install py7zr\nimport py7zr","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd.read_csv('/kaggle/input/cifar-10/trainLabels.csv')\ny_test = pd.read_csv('/kaggle/input/cifar-10/sampleSubmission.csv')\n\ny_train = np.array(y_train['label'])\ny_test = np.array(y_test['label'])\n\ny_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!python -m py7zr x ../input/cifar-10/train.7z\n!python -m py7zr x ../input/cifar-10/test.7z","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nfilelist = glob.glob(\"../working/train/*\")\nfilelist = sorted(filelist,key= lambda x:int(x.split(\"/\")[-1].split(\".\")[0]))\nx_train = np.array([np.array(Image.open(fname)) for fname in filelist])\nprint(f\"X.shape : {x_train.shape} y.shape : {y_train.shape}\")\n\nfilelist = glob.glob(\"../working/test/*\")\nfilelist = sorted(filelist,key= lambda x:int(x.split(\"/\")[-1].split(\".\")[0]))\nx_test = np.array([np.array(Image.open(fname)) for fname in filelist])\nprint(f\"X.shape : {x_test.shape} y.shape : {y_test.shape}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#have a look on some images:\n\ncols = 8\nrows = 2\nfig = plt.figure(figsize=(2 * cols - 1, 2.5 * rows - 1))\nfor i in range(cols):\n    for j in range(rows):\n        random_index = np.random.randint(0, len(y_train))\n        ax = fig.add_subplot(rows, cols, i * rows + j + 1)\n        ax.grid('off')\n        ax.axis('off')\n        ax.imshow(x_train[random_index, :])\n        ax.set_title([y_train[random_index]])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#normalize inputs:\nx_train2 = x_train/255 - 0.5\nx_test2 = x_test/255 - 0.5\n\ncifar10_classes = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\", \"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]\n\ny_train_indexes = []\nfor classs in y_train:\n    y_train_indexes.append(cifar10_classes.index(classs))\n    \n# convert class labels to one-hot encoded:\ny_train2 = keras.utils.to_categorical(y_train_indexes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import necessary building blocks:\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#define CNN architecture:\n\ndef make_model():\n\n    model = Sequential()\n\n    model.add(Conv2D(filters = 16, kernel_size = (3, 3), padding='same', input_shape=(32, 32, 3)))\n    model.add(LeakyReLU(0.1))\n    \n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    \n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    \n    model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(256))\n    model.add(LeakyReLU(0.1))\n\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(10))\n    model.add(Activation(\"softmax\"))\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = make_model()\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INIT_LR = 5e-3 \nBATCH_SIZE = 32\nEPOCHS = 10\n\nmodel = make_model()\n\nmodel.compile(\n    loss='categorical_crossentropy',  \n    optimizer=keras.optimizers.Adamax(lr=INIT_LR), \n    metrics=['accuracy']  # report accuracy during training\n)\n\n# scheduler of learning rate (decay with epochs)\ndef lr_scheduler(epoch):\n    return INIT_LR * 0.9 ** epoch\n\n# callback for printing of actual learning rate used by optimizer\nclass LrHistory(keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs={}):\n        print(\"Learning rate:\", K.get_value(model.optimizer.lr))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fit model:\nimport tensorflow_addons as tfa\ntqdm_callback = tfa.callbacks.TQDMProgressBar()\n\nmodel.fit(\n    x_train2, y_train2,  # prepared data\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler), \n               LrHistory(), \n               tqdm_callback],\n    shuffle=True,\n    verbose=0,\n    initial_epoch=0\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# making test predictions:\n\nx1=x_test2[0:75000]\nx2=x_test2[75000:150000]\nx3=x_test2[150000:225000]\nx4=x_test2[225000:300000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_1 = model.predict(x1)\ny_pred_test_classes_1 = np.argmax(y_pred_test_1, axis=1)\ny_pred_test_classes_1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_2 = model.predict(x2)\ny_pred_test_classes_2 = np.argmax(y_pred_test_2, axis=1)\ny_pred_test_classes_2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_3 = model.predict(x3)\ny_pred_test_classes_3 = np.argmax(y_pred_test_3, axis=1)\ny_pred_test_classes_3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_test_4 = model.predict(x4)\ny_pred_test_classes_4 = np.argmax(y_pred_test_4, axis=1)\ny_pred_test_classes_4","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = list(y_pred_test_classes_1) + list(y_pred_test_classes_2)+ list(y_pred_test_classes_3) + list(y_pred_test_classes_4)\nlen(y_pred)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample = pd.read_csv('/kaggle/input/cifar-10/sampleSubmission.csv')\nsample","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred_names = []\n\nfor ind in y_pred:\n    y_pred_names.append(cifar10_classes[ind])\n    \nlen(y_pred_names)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Saving results:\n\nsample['label'] = y_pred_names\nsample.to_csv(\"submission.csv\", index=False)\n\nsample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}