{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nimport random\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tqdm import tqdm\nimport time\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport os\n# os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"; \n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\nfrom tensorflow.keras.optimizers import Adamax\nfrom tensorflow.keras.metrics import categorical_crossentropy\nfrom tensorflow.keras.models import Model","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-23T03:40:39.388162Z","iopub.execute_input":"2022-05-23T03:40:39.388533Z","iopub.status.idle":"2022-05-23T03:40:45.298301Z","shell.execute_reply.started":"2022-05-23T03:40:39.388449Z","shell.execute_reply":"2022-05-23T03:40:45.297572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val=pd.read_csv('../input/data-csv/df_val.csv')\ndf_train=pd.read_csv('../input/data-csv/df_train.csv')\ndf_test=pd.read_csv('../input/data-csv/df_test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:43:13.880175Z","iopub.execute_input":"2022-05-21T17:43:13.880479Z","iopub.status.idle":"2022-05-21T17:43:13.92735Z","shell.execute_reply.started":"2022-05-21T17:43:13.880435Z","shell.execute_reply":"2022-05-21T17:43:13.926403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image_Width=71\nImage_Height=71\nImage_Size=(Image_Width,Image_Height)\nImage_Channels=3\nbatch_size=128","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:43:16.16548Z","iopub.execute_input":"2022-05-21T17:43:16.166229Z","iopub.status.idle":"2022-05-21T17:43:16.169898Z","shell.execute_reply.started":"2022-05-21T17:43:16.166195Z","shell.execute_reply":"2022-05-21T17:43:16.169109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,width_shift_range=0.1, height_shift_range=0.1, fill_mode=\"nearest\")\ntrain_generator = train_datagen.flow_from_dataframe(df_train, directory=\"../input/cifar10-object-recognition-in-images-zip-file/train_test/train/train/\",x_col='id',y_col='label', target_size=Image_Size, class_mode='categorical', batch_size=batch_size,)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(df_val,  \"../input/cifar10-object-recognition-in-images-zip-file/train_test/train/train/\",x_col='id',y_col='label',shuffle=False,target_size=Image_Size, class_mode='categorical', batch_size=batch_size )\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_dataframe(df_test,  \"../input/cifar10-object-recognition-in-images-zip-file/train_test/train/train/\",x_col='id',y_col='label',shuffle=False,target_size=Image_Size, class_mode='categorical', batch_size=batch_size )\n","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:43:17.807535Z","iopub.execute_input":"2022-05-21T17:43:17.807813Z","iopub.status.idle":"2022-05-21T17:43:39.730542Z","shell.execute_reply.started":"2022-05-21T17:43:17.807783Z","shell.execute_reply":"2022-05-21T17:43:39.729654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Xception","metadata":{}},{"cell_type":"code","source":"\n# Build model\nbase_model = tf.keras.applications.xception.Xception(include_top=False,\n                                                     weights='imagenet',\n                                                     input_shape = (71,71, 3),\n                                                     pooling = \"max\"\n                                                    )\n\nbase_model.trainable = True\n\nx = base_model.output\nx = BatchNormalization() (x)\nx = Dense(64, activation = \"relu\") (x)\nx = Dropout(0.3) (x)\noutputs = Dense(10, activation = \"softmax\") (x)\n\nmodel = Model(inputs = base_model.input, outputs = outputs)\nlr = 0.0001\n\nmodel.compile(optimizer = Adamax(learning_rate = lr), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nckpoint = ModelCheckpoint(\"kaggle/working/best_weights_xception_loss_model.h5\", monitor=\"val_loss\", save_best_only=True, mode=\"auto\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nhistory=model.fit(x = train_generator, \n         epochs = n_epochs,\n         validation_data = validation_generator,\n         callbacks = [ckpoint])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"H=history\n# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\nplt.plot(H.history['accuracy'])\nplt.plot(H.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig('Initial_Xception_Model_Accuracy.png')\nplt.show()\n# summarize history for loss\nplt.plot(H.history['loss'])\nplt.plot(H.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('Initial_Xception_Model_loss.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# predict","metadata":{}},{"cell_type":"code","source":"model=tf.keras.models.load_model ('../input/data-csv/best_weights_xception_loss_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:43:39.732491Z","iopub.execute_input":"2022-05-21T17:43:39.733041Z","iopub.status.idle":"2022-05-21T17:43:44.866603Z","shell.execute_reply.started":"2022-05-21T17:43:39.732996Z","shell.execute_reply":"2022-05-21T17:43:44.865639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(test_generator)","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:43:44.868358Z","iopub.execute_input":"2022-05-21T17:43:44.868674Z","iopub.status.idle":"2022-05-21T17:44:36.851683Z","shell.execute_reply.started":"2022-05-21T17:43:44.868631Z","shell.execute_reply":"2022-05-21T17:44:36.850886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test['actual_lable'] =  test_generator.classes\ndf_test['predict'] = np.argmax(predict, axis=-1)\ndata_label=[]\nfor k,v in test_generator.class_indices.items():\n  data_label.append(str(k))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:47:59.247578Z","iopub.execute_input":"2022-05-21T17:47:59.248164Z","iopub.status.idle":"2022-05-21T17:47:59.25682Z","shell.execute_reply.started":"2022-05-21T17:47:59.248116Z","shell.execute_reply":"2022-05-21T17:47:59.256133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\nprint(classification_report(df_test['actual_lable'], df_test['predict'], target_names = data_label))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:48:01.915657Z","iopub.execute_input":"2022-05-21T17:48:01.916455Z","iopub.status.idle":"2022-05-21T17:48:01.93987Z","shell.execute_reply.started":"2022-05-21T17:48:01.916411Z","shell.execute_reply":"2022-05-21T17:48:01.938974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(df_test['actual_lable'], df_test['predict'])\nplt.figure(figsize = (12, 10))\ncm = pd.DataFrame(cm , index = data_label , columns = data_label)\nimport seaborn as sns\nax = sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.title('Confusion Matrix', size=20)\nplt.xlabel('Predicted Labels', size=14)\nplt.ylabel('Actual Labels', size=14)\nplt.savefig('Initial_Xception_Model_Confusion_Matrix.png')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:48:05.289855Z","iopub.execute_input":"2022-05-21T17:48:05.290156Z","iopub.status.idle":"2022-05-21T17:48:06.780732Z","shell.execute_reply.started":"2022-05-21T17:48:05.290127Z","shell.execute_reply":"2022-05-21T17:48:06.779921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=[]\ncount=0\nfor i in range(len(df_test)):\n    if df_test['actual_lable'][i]== df_test['predict'][i]:\n        a.append(np.max(predict[i],axis=-1))\n        if np.max(predict[i],axis=-1) <0.6:\n            count+=1\n#             print(df_test['id'][i])\n#             print(df_test['label'][i])\n#             print(df_test['predict'][i])\nprint(len(a))\nprint(count)\nprint(np.min(a))\n\n# for i in range(len(df_wrong_val)):\n#     if df_wrong_val['actual_lable'][i]!= df_wrong_val['predict'][i]:\n#         a=np.max(predict[i])\n# print(np.max(a))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T17:58:31.40917Z","iopub.execute_input":"2022-05-21T17:58:31.409475Z","iopub.status.idle":"2022-05-21T17:58:31.574529Z","shell.execute_reply.started":"2022-05-21T17:58:31.409438Z","shell.execute_reply":"2022-05-21T17:58:31.573853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_addition_id=[]\ndata_train_addition_label=[]\nfor i in tqdm(range(len(df_test))):\n    if (df_test['actual_lable'][i] !=df_test['predict'][i]):\n        data_train_addition_id.append(df_test['id'][i])\n        data_train_addition_label.append(df_test['label'][i])\ndf_aug=pd.DataFrame()\ndf_aug['id']=pd.DataFrame(data_train_addition_id)\ndf_aug['label']=pd.DataFrame(data_train_addition_label)\ndf_aug.to_csv('wrong_test.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = model.predict(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_val['actual_lable'] =  validation_generator.classes\ndf_val['predict'] = np.argmax(predict, axis=-1)\ndata_label=[]\nfor k,v in validation_generator.class_indices.items():\n  data_label.append(str(k))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\nprint(classification_report(df_val['actual_lable'], df_val['predict'], target_names = data_label))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_addition_id=[]\ndata_train_addition_label=[]\nfor i in tqdm(range(len(df_val))):\n    if (df_val['actual_lable'][i] !=df_val['predict'][i]):\n        data_train_addition_id.append(df_val['id'][i])\n        data_train_addition_label.append(df_val['label'][i])\ndf_aug=pd.DataFrame()\ndf_aug['id']=pd.DataFrame(data_train_addition_id)\ndf_aug['label']=pd.DataFrame(data_train_addition_label)\ndf_aug.to_csv('wrong_val.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Predict Train","metadata":{}},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255)\ntrain_generator = train_datagen.flow_from_dataframe(df_train, directory=\"../input/cifar10-object-recognition-in-images-zip-file/train_test/train/train/\",shuffle=False,x_col='id',y_col='label', target_size=Image_Size, class_mode='categorical', batch_size=batch_size,)\n\npredict = model.predict(train_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['actual_lable'] =  train_generator.classes\ndf_train['predict'] = np.argmax(predict, axis=-1)\ndata_label=[]\nfor k,v in train_generator.class_indices.items():\n  data_label.append(str(k))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\nprint(classification_report(df_train['actual_lable'], df_train['predict'], target_names = data_label))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(df_train['actual_lable'], df_train['predict'])\nplt.figure(figsize = (12, 10))\ncm = pd.DataFrame(cm , index = data_label , columns = data_label)\nimport seaborn as sns\nax = sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.title('Confusion Matrix', size=20)\nplt.xlabel('Predicted Labels', size=14)\nplt.ylabel('Actual Labels', size=14)\nplt.savefig('Initial_Train_Xception_Model_Confusion_Matrix.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.to_csv('df_train_add.csv',index=False)\ndf_test.to_csv('df_test_add.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train=pd.read_csv('df_train_add.csv')\ndf_test=pd.read_csv('df_test_add.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"df_train","metadata":{}},{"cell_type":"code","source":"for i in tqdm(range(len(df_test))):\n    if (df_test['actual_lable'][i] ==1) and (df_test['predict'][i] ==9):\n        fname=df_test['id'][i]\n        print(fname)\n        img=cv2.imread(os.path.join('../input/cifar10-object-recognition-in-images-zip-file/train_test/train/train/',fname))\n        imgplot = plt.imshow(img)\n        plt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor k in range(0,10):\n    for i in tqdm(range(len(df_test))):\n        if (df_test['actual_lable'][i] !=df_test['predict'][i]):\n            if (df_test['actual_lable'][i]==k):\n                count+=1\n    print(k,count)\n    count=0\n\ncount=0\nprint('TRAINING')\nfor k in range(0,10):\n    for i in tqdm(range(len(df_train))):\n        if (df_train['actual_lable'][i] !=df_train['predict'][i]):\n            if (df_train['actual_lable'][i]==k):\n                count+=1\n    print(k,count)\n    count=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_addition_id=[]\ndata_train_addition_label=[]\nfor i in tqdm(range(len(df_train))):\n    if (df_train['actual_lable'][i] !=df_train['predict'][i]):\n        data_train_addition_id.append(df_train['id'][i])\n        data_train_addition_label.append(df_train['label'][i])\ndf_aug=pd.DataFrame()\ndf_aug['id']=pd.DataFrame(data_train_addition_id)\ndf_aug['label']=pd.DataFrame(data_train_addition_label)\ndf_aug.to_csv('wrong_train.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_aug)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation","metadata":{}},{"cell_type":"code","source":"!pip install py7zr\nimport py7zr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"archive=py7zr.SevenZipFile('../input/cifar-10/train.7z', mode='r')\narchive.extractall(path=\"kaggle/working/temp\")\narchive.close()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_wrong_train=pd.read_csv('../input/data-csv/wrong_train.csv')\ndf_wrong_val=pd.read_csv('./wrong_val.csv')\ndf_wrong_test=pd.read_csv('./wrong_test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# len(os.listdir('kaggle/working/temp/train/'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_addition_id=[]\ndata_train_addition_label=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_wrong_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_dir_save='kaggle/working/temp/train/'\nfrom tqdm import tqdm\nfor i in tqdm(range(len(df_wrong_train))):\n    fname=df_wrong_train['id'][i]\n    img=cv2.imread(os.path.join('kaggle/working/temp/train/',fname))\n    rotated_img=cv2.flip(img, 1)\n    rotated_img_name=fname[:(len(fname)-4)] + '_flip_'+fname[(len(fname)-4):]\n    data_train_addition_id.append(rotated_img_name)\n    data_train_addition_label.append(df_wrong_train['label'][i])\n    cv2.imwrite(os.path.join(path_dir_save, rotated_img_name),rotated_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_wrong_train2=pd.DataFrame()\ndf_wrong_train2['id']=pd.DataFrame(data_train_addition_id)\ndf_wrong_train2['label']=pd.DataFrame(data_train_addition_label)\ndf_wrong_train=pd.concat([df_wrong_train,df_wrong_train2],ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_train_addition_id=[]\ndata_train_addition_label=[]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"goc=10\npath_dir_save='kaggle/working/temp/train/'\nfor i in tqdm(range(len(df_wrong_train))):\n    fname=str(df_wrong_train['id'][i])\n#     print(len(fname))\n#     print(os.path.join('kaggle/working/temp3/train/',fname))\n    img=cv2.imread(os.path.join('kaggle/working/temp/train/',fname))\n    h,w=img.shape[:2]\n    rotation_matrix=cv2.getRotationMatrix2D((w/2,h/2),goc,.8)\n    rotated_img=cv2.warpAffine(img,rotation_matrix,(w,h))\n    rotated_img_name=fname[:(len(fname)-4)] + '_rotated_'+str(goc)+fname[(len(fname)-4):]\n    data_train_addition_id.append(rotated_img_name)\n    data_train_addition_label.append(df_wrong_train['label'][i])\n    cv2.imwrite(os.path.join(path_dir_save, rotated_img_name),rotated_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_wrong_train2=pd.DataFrame()\ndf_wrong_train2['id']=pd.DataFrame(data_train_addition_id)\ndf_wrong_train2['label']=pd.DataFrame(data_train_addition_label)\ndf_wrong_train=pd.concat([df_wrong_train,df_wrong_train2],ignore_index=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df_wrong_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255,width_shift_range=0.1, height_shift_range=0.1, fill_mode=\"nearest\")\ntrain_generator = train_datagen.flow_from_dataframe(df_wrong_train, directory=\"kaggle/working/temp/train/\",x_col='id',y_col='label', target_size=Image_Size, class_mode='categorical', batch_size=batch_size,)\n\nvalidation_datagen = ImageDataGenerator(rescale=1./255)\nvalidation_generator = validation_datagen.flow_from_dataframe(df_wrong_val,  \"kaggle/working/temp/train/\",x_col='id',y_col='label',target_size=Image_Size, class_mode='categorical', batch_size=batch_size )\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_generator = test_datagen.flow_from_dataframe(df_wrong_test,  \"kaggle/working/temp/train/\",x_col='id',y_col='label',shuffle=False,target_size=Image_Size, class_mode='categorical', batch_size=batch_size )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Xception with df_aug","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"\n# Build model\nbase_model = tf.keras.applications.xception.Xception(include_top=False,\n                                                     weights='imagenet',\n                                                     input_shape = (71,71, 3),\n                                                     pooling = \"max\"\n                                                    )\n\nbase_model.trainable = True\n\nx = base_model.output\nx = BatchNormalization() (x)\nx = Dense(32, activation = \"relu\") (x)\nx = Dropout(0.3) (x)\noutputs = Dense(10, activation = \"softmax\") (x)\n\nmodel = Model(inputs = base_model.input, outputs = outputs)\nlr = 0.00001\n\nmodel.compile(optimizer = Adamax(learning_rate = lr), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nckpoint = ModelCheckpoint(\"best_weights_xception_wrong_aug_loss_model.h5\", monitor=\"val_loss\", save_best_only=True, mode=\"auto\")\nckpoint2 = ModelCheckpoint(\"best_weights_xception_wrong_aug_acc_model.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"auto\")\nearlystop = EarlyStopping(monitor=\"val_loss\",\n                          min_delta=0,\n                          mode=\"auto\",\n                          patience=100,\n                          restore_best_weights=True,)\nearlystop2 = EarlyStopping(monitor=\"val_accuracy\",\n                          min_delta=0,\n                          mode=\"auto\",\n                          patience=20,\n                          restore_best_weights=True,)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 300\nhistory=model.fit(x = train_generator, \n         epochs = n_epochs,\n         validation_data = validation_generator,\n         callbacks = [ckpoint,ckpoint2,earlystop2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"H=history\n# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\nplt.plot(H.history['accuracy'])\nplt.plot(H.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig('Initial_Xception_aug_Model_Accuracy.png')\nplt.show()\n# summarize history for loss\nplt.plot(H.history['loss'])\nplt.plot(H.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('Initial_Xception_aug_Model_loss.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CNN with df_aug","metadata":{}},{"cell_type":"code","source":"Image_Width=71\nImage_Height=71\nImage_Channels=3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D,\\\n     Dropout,Flatten,Dense,Activation,\\\n     BatchNormalization\n\nmodel=Sequential()\n\nmodel.add(Conv2D(16,(3,3),activation='relu',input_shape=(Image_Width,Image_Height,Image_Channels)))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(32,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(256,(3,3),activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(64,activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.3))\nmodel.add(Dense(10,activation='softmax'))\nopt = keras.optimizers.Adam(lr=0.01)\nmodel.compile(loss='categorical_crossentropy', optimizer=opt,metrics=['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import LearningRateScheduler, ModelCheckpoint,EarlyStopping\n\ncheckpoint=ModelCheckpoint('model_CNN_acc.h5',\n                           monitor=\"val_accuracy\",\n                           verbose=0,\n                           save_best_only=True,\n                           save_weights_only=False,\n                           mode=\"auto\",\n                           save_freq=\"epoch\")\ncheckpoint2=ModelCheckpoint('model_CNN_loss.h5',\n                           monitor=\"val_loss\",\n                           verbose=0,\n                           save_best_only=True,\n                           save_weights_only=False,\n                           mode=\"auto\",\n                           save_freq=\"epoch\")\n\n\ndef step_decay(epoch):\n    # initialize the base initial learning rate, drop factor, and\n    # epochs to drop every\n    initAlpha = 0.01\n    decay_rate = 0.005\n\n    # compute learning rate for the current epoch\n    alpha = initAlpha * 1/(1 + decay_rate * epoch)\n\n    # return the learning rate\n    return float(alpha)\nearlystop = EarlyStopping(monitor=\"val_accuracy\",\n                          min_delta=0,\n                          mode=\"auto\",\n                          patience=20,\n                          restore_best_weights=True,)\ncallbacks = [LearningRateScheduler(step_decay),checkpoint,checkpoint2,earlystop]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 500\nhistory=model.fit(x = train_generator, \n         epochs = n_epochs,\n         validation_data = validation_generator,\n         callbacks = callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"H=history\n# PLOT MODEL HISTORY OF ACCURACY AND LOSS OVER EPOCHS\nplt.plot(H.history['accuracy'])\nplt.plot(H.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.savefig('Initial_Xception_aug_Model_Accuracy.png')\nplt.show()\n# summarize history for loss\nplt.plot(H.history['loss'])\nplt.plot(H.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.savefig('Initial_Xception_aug_Model_loss.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=tf.keras.models.load_model ('./best_weights_xception_wrong_aug_loss_model.h5')\n# predict = model.predict(test_generator)\npredict = model.predict(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# file1 = open(\"predict_wrong_test.txt\", \"w\") \n# for i in range(len(predict)):\n#     file1.write(str(predict[i]))\n# file1.close()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(validation_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_wrong_test['actual_lable'] =  test_generator.classes\n# df_wrong_test['predict'] = np.argmax(predict, axis=-1)\n# data_label=[]\n# for k,v in test_generator.class_indices.items():\n#   data_label.append(str(k))\n\ndf_wrong_val['actual_lable'] =  validation_generator.classes\ndf_wrong_val['predict'] = np.argmax(predict, axis=-1)\ndata_label=[]\nfor k,v in validation_generator.class_indices.items():\n  data_label.append(str(k))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom sklearn.metrics import classification_report\nprint(classification_report(df_wrong_test['actual_lable'], df_wrong_test['predict'], target_names = data_label))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# # CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION \n# from sklearn.metrics import confusion_matrix\n# cm = confusion_matrix(df_wrong_test['actual_lable'], df_wrong_test['predict'])\n# plt.figure(figsize = (12, 10))\n# cm = pd.DataFrame(cm , index = data_label , columns = data_label)\n# import seaborn as sns\n# ax = sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\n# bottom, top = ax.get_ylim()\n# ax.set_ylim(bottom + 0.5, top - 0.5)\n# plt.title('Confusion Matrix', size=20)\n# plt.xlabel('Predicted Labels', size=14)\n# plt.ylabel('Actual Labels', size=14)\n# plt.savefig('Initial_Xception_aug_acc_Model_Confusion_Matrix.png')\n# plt.show()\n\n# CREATE CONFUSION MATRIX OF ACTUAL VS. PREDICTION \nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(df_wrong_val['actual_lable'], df_wrong_val['predict'])\nplt.figure(figsize = (12, 10))\ncm = pd.DataFrame(cm , index = data_label , columns = data_label)\nimport seaborn as sns\nax = sns.heatmap(cm, linecolor='white', cmap='Blues', linewidth=1, annot=True, fmt='')\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.title('Confusion Matrix', size=20)\nplt.xlabel('Predicted Labels', size=14)\nplt.ylabel('Actual Labels', size=14)\nplt.savefig('Initial_Xception_aug_acc_Model_Confusion_Matrix.png')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(len(df_wrong_test)):\n#     if df_wrong_test['actual_lable'][i]!= df_wrong_test['predict'][i]:\n#         a=np.max(predict[i])\n# print(np.max(a))\n\nfor i in range(len(df_wrong_val)):\n    if df_wrong_val['actual_lable'][i]!= df_wrong_val['predict'][i]:\n        a=np.max(predict[i])\nprint(np.max(a))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficentnetB0","metadata":{}},{"cell_type":"code","source":"\n# Build model\nbase_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False,\n                                                     weights='imagenet',\n                                                     input_shape = (71,71, 3),\n                                                     pooling = \"max\"\n                                                    )\n\nbase_model.trainable = True\n\nx = base_model.output\nx = BatchNormalization() (x)\nx = Dense(64, activation = \"relu\") (x)\nx = Dropout(0.3) (x)\noutputs = Dense(10, activation = \"softmax\") (x)\n\nmodel = Model(inputs = base_model.input, outputs = outputs)\nlr = 0.0001\n\nmodel.compile(optimizer = Adamax(learning_rate = lr), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nckpoint = ModelCheckpoint(\"kaggle/working/best_weights_efficentnetB0_model_.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"auto\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nhistory=model.fit(x = train_generator, \n         epochs = n_epochs,\n         validation_data = validation_generator,\n         callbacks = [ckpoint])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MobileNet","metadata":{}},{"cell_type":"code","source":"\n# Build model\nbase_model = tf.keras.applications.MobileNet(include_top=False,\n                                                                 weights='imagenet',\n                                                                 input_shape = (71,71, 3),\n                                                                 pooling = \"max\"\n                                                                )\n\nbase_model.trainable = True\n\nx = base_model.output\nx = BatchNormalization() (x)\nx = Dense(64, activation = \"relu\") (x)\nx = Dropout(0.3) (x)\noutputs = Dense(10, activation = \"softmax\") (x)\n\nmodel = Model(inputs = base_model.input, outputs = outputs)\nlr = 0.0001\n\nmodel.compile(optimizer = Adamax(learning_rate = lr), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nckpoint = ModelCheckpoint(\"kaggle/working/best_weights_mobilenet_model_.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"auto\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nhistory=model.fit(x = train_generator, \n         epochs = n_epochs,\n         validation_data = validation_generator,\n         callbacks = [ckpoint])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# VGG19","metadata":{}},{"cell_type":"code","source":"\n# Build model\nbase_model = tf.keras.applications.vgg19.VGG19(include_top=False,\n                                                                 weights='imagenet',\n                                                                 input_shape = (71,71, 3),\n                                                                 pooling = \"max\"\n                                                                )\n\nbase_model.trainable = True\n\nx = base_model.output\nx = BatchNormalization() (x)\nx = Dense(64, activation = \"relu\") (x)\nx = Dropout(0.3) (x)\noutputs = Dense(10, activation = \"softmax\") (x)\n\nmodel = Model(inputs = base_model.input, outputs = outputs)\nlr = 0.0001\n\nmodel.compile(optimizer = Adamax(learning_rate = lr), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nckpoint = ModelCheckpoint(\"kaggle/working/best_weights_vgg19_model_.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"auto\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nhistory=model.fit(x = train_generator, \n         epochs = n_epochs,\n         validation_data = validation_generator,\n         callbacks = [ckpoint])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resnet50","metadata":{}},{"cell_type":"code","source":"\n# Build model\nbase_model = tf.keras.applications.resnet50.ResNet50.(include_top=False,\n                                                                 weights='imagenet',\n                                                                 input_shape = (71,71, 3),\n                                                                 pooling = \"max\"\n                                                                )\n\nbase_model.trainable = True\n\nx = base_model.output\nx = BatchNormalization() (x)\nx = Dense(64, activation = \"relu\") (x)\nx = Dropout(0.3) (x)\noutputs = Dense(10, activation = \"softmax\") (x)\n\nmodel = Model(inputs = base_model.input, outputs = outputs)\nlr = 0.0001\n\nmodel.compile(optimizer = Adamax(learning_rate = lr), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nckpoint = ModelCheckpoint(\"kaggle/working/best_weights_resnet50_model_.h5\", monitor=\"val_accuracy\", save_best_only=True, mode=\"auto\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_epochs = 20\nhistory=model.fit(x = train_generator, \n         epochs = n_epochs,\n         validation_data = validation_generator,\n         callbacks = [ckpoint])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}