{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\n# наборы данных для экспериментов\nfrom tensorflow.keras.datasets import cifar10\n# последовательная модель (стек слоев)\nfrom tensorflow.keras.models import Sequential\n# полносвязный слой и слой выпрямляющий матрицу в вектор\nfrom tensorflow.keras.layers import Dense, Flatten\n# слой выключения нейронов и слой нормализации выходных данных (нормализует данные в пределах текущей выборки)\nfrom tensorflow.keras.layers import Dropout, BatchNormalization, SpatialDropout2D, GaussianDropout #Вариации DROPOUT\n# слои свертки и подвыборки\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n# работа с обратной связью от обучающейся нейронной сети\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n# вспомогательные инструменты\nfrom tensorflow.keras import utils\n# работа с изображениями\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Размер мини-выборки: эксперимент 64,128,256, может повлиять на изменение качества обучения и скорость обучения, при 64 скорость уменьшилась\nbatch_size = 128\n# Количество классов изображений, указаны ниже\nnb_classes = 10 \n# Количество эпох для обучения, 20 эпох оказалось не достаточно \nnb_epoch = 31\n# Размер изображений\nimg_rows, img_cols = 32, 32\n# Количество каналов в изображении - 3, так как картинка цветная\nimg_channels = 3\n# Названия классов из набора данных\nclasses=['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 113\nplt.imshow(X_train[n])\nplt.show()\nprint(\"Номер класса:\", y_train[n])\n#print(\"Тип объекта:\", classes[y_train[n]])\n#Лошадь, 7 класс","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# цветовой канал\nX_train = X_train.reshape((50000, 32, 32, 3)) #50000- количество картинок в наборе, 32*32 размерность, 3 -количество каналов\nX_train = X_train.astype('float32')\nX_test = X_test.reshape((10000, 32, 32, 3))\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = utils.to_categorical(y_train, nb_classes)\nY_test = utils.to_categorical(y_test, nb_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Создаем последовательную модель\nmodel = Sequential()\n# Первый сверточный слой\n# padding='same' - не будет меняться размер картинки. padding='valid'\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same',\n                        input_shape=(img_rows, img_cols, img_channels), activation='relu'))\n# Второй сверточный слой\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n# # Первый слой подвыборки\nmodel.add(MaxPooling2D(pool_size=(2, 2)))  #При смене на AveragePooling2D - результаты заметно ухудшились уже в первые эпохи\n# # Первый слой нормализации данных\nmodel.add(BatchNormalization())  #Влючена нормализация данных\n# # Первый Слой регуляризации Dropout\nmodel.add(Dropout(0.25))\n\n# Третий сверточный слой\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n# Четвертый сверточный слой\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n# Второй слой подвыборки\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# # Второй слой нормализации данных\nmodel.add(BatchNormalization())   #Влючена нормализация данных\n# Второй Слой регуляризации Dropout\nmodel.add(Dropout(0.25))\n\n# # Пятый сверточный слой\n# model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n# # Шестой сверточный слой\n# model.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n# # Третий слой подвыборки\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# # Третий слой нормализации данных\n# model.add(BatchNormalization())\n# # Третий Слой регуляризации Dropout\n# model.add(Dropout(0.25))\n\n\n# Слой преобразования данных из 2D представления в плоское\nmodel.add(Flatten())\n# Полносвязный слой для классификации\nmodel.add(Dense(512, activation='relu'))\n# # Четвертый слой нормализации данных\nmodel.add(BatchNormalization())   #Влючена нормализация данных\n# # Четвертый Слой регуляризации Dropout\nmodel.add(Dropout(0.75))\n# Выходной полносвязный слой\nmodel.add(Dense(nb_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EarlyStopping - если patience эпох качество не растет или потери не убывают, то происходит останов обучения\n# ModelCheckpoint - сохраняет в указанную директорию веса лучшей модели и в конце обучения возвращает их.\n# ReduceLROnPlateau - уменьшает шаг обучения в factor раз после patience эпох без улучшения качества обучения\ncallbacks_list = [EarlyStopping(monitor='val_loss', patience=7),#EarlyStopping для остановки обучения после 7 эпох,\n                                                                # в которых не изменилось качество, val_loss эффективнее\n                  ModelCheckpoint(filepath='my_model.h5',\n                                  monitor='val_loss',\n                                  save_best_only=True),\n                  ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3)\n                  ] \n# Согласно Kingma et al., 2014 , метод adam эффективен с точки зрения вычислений, требует небольшого объема памяти, инвариантен к диагональному \n#масштабированию градиентов и хорошо подходит для задач, больших с точки зрения данных / параметров.\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory = model.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=nb_epoch,\n              callbacks=callbacks_list,\n              validation_split=0.1,\n              verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Оценка качества обучения модели на тестовых данных\nscores = model.evaluate(X_test, Y_test, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Доля верных ответов на тестовых данных:\", round(scores[1] * 100, 4),\"%\") ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['accuracy'], \n         label='Доля правильных ответов на обучающем наборе')\nplt.plot(history.history['val_accuracy'], \n         label='Доля правильных ответов на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Доля правильных ответов')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(history.history['loss'], \n         label='Оценка потерь на обучающем наборе')\nplt.plot(history.history['val_loss'], \n         label='Оценка потерь на проверочном наборе')\nplt.xlabel('Эпоха обучения')\nplt.ylabel('Оценка потерь')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index=256\nplt.imshow(X_test[index].reshape((32,32,3)))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = X_test[index]\nx = np.expand_dims(x, axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = np.argmax(prediction)\nprint(classes[prediction])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}