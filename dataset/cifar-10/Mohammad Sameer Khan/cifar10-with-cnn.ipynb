{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense, Activation, BatchNormalization\nimport os\n\nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\n\n%matplotlib inline\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"batch_size = 32  # The default batch size of keras.\nnum_classes = 3  # Number of class for the dataset which are using","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# download cifar10 dataset from keras\n# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint(x_train.shape[0], 'train samples')\nprint(x_test.shape[0], 'test samples')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Make a new dataset for automobile dog and horse**"},{"metadata":{"trusted":true},"cell_type":"code","source":"index = np.where((y_train == 1) | (y_train == 5) | (y_train == 7))\nx_train = x_train[index[0]]\ny_train = y_train[index[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\n#print(x_train.shape[0], 'train samples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = np.where((y_test == 1) | (y_test == 5) | (y_test == 7))\nx_test = x_test[index[0]]\ny_test = y_test[index[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('x_test shape:', x_test.shape)\nprint('y_test shape:', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Re-labeling data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"for n, i in enumerate(y_train):\n    if i == 1:\n        y_train[n] = 0\n    elif i==5:\n        y_train[n]= 1\n    else:\n        y_train[n]= 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for n, i in enumerate(y_test):\n    if i == 1:\n        y_test[n] = 0\n    elif i==5:\n        y_test[n]= 1\n    else:\n        y_test[n]= 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, axs = plt.subplots(1,2,figsize=(15,5)) \n# Count plot for training set\nsns.countplot(y_train.ravel(), ax=axs[0])\naxs[0].set_title('Distribution of training data')\naxs[0].set_xlabel('Classes')\n# Count plot for testing set\nsns.countplot(y_test.ravel(), ax=axs[1])\naxs[1].set_title('Distribution of Testing data')\naxs[1].set_xlabel('Classes')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize the data. Before we need to connvert data type to float for computation.\nx_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\nx_train /= 255.0\nx_test /= 255.0\n\n# Convert class vectors to binary class matrices. This is called one hot encoding.\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define the convnet\nmodel = Sequential()\n# CONV2D => CONV2D => BATCHNORMALIZATION => POOL => DROPOUT\nmodel.add(Conv2D(32, (3, 3), padding='same',input_shape=x_train.shape[1:],activation='relu'))\nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# CONV2D => CONV2D => BATCHNORMALIZATION => POOL => DROPOUT\nmodel.add(Conv2D(64, (3, 3), padding='same',activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# CONV2D => CONV2D => BATCHNORMALIZATION => POOL => DROPOUT\nmodel.add(Conv2D(128, (3, 3), padding='same',activation='relu'))\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\n# FLATTERN => DENSE => RELU => DROPOUT\nmodel.add(Flatten())\n\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dropout(0.5))\n# a softmax classifier\nmodel.add(Dense(num_classes,activation='softmax'))\n\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = None  # For recording the history of trainning process.\ndata_augmentation = True #for using data augmentation \n\nif not data_augmentation:\n    print('Not using data augmentation.')\n    history = model.fit(x_train, y_train,\n              batch_size=batch_size,\n              epochs=epochs,\n              validation_data=(x_test, y_test),\n              shuffle=True)\nelse:\n    print('Using real-time data augmentation.')\n    # This will do preprocessing and realtime data augmentation:\n    datagen = ImageDataGenerator(\n        rotation_range=0,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        shear_range=0., \n        zoom_range=0.,\n        fill_mode='nearest',\n        horizontal_flip=True,\n        vertical_flip=False,\n        rescale=None,\n        validation_split=0.0)\n\n    datagen.fit(x_train)\n    history = model.fit_generator(datagen.flow(x_train, y_train,\n                                    batch_size=batch_size),\n                                    epochs=40,\n                                    validation_data=(x_test, y_test),\n                                    workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotmodelhistory(history): \n    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n    # summarize history for accuracy\n    axs[0].plot(history.history['accuracy']) \n    axs[0].plot(history.history['val_accuracy']) \n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['train', 'validate'], loc='upper left')\n    # summarize history for loss\n    axs[1].plot(history.history['loss']) \n    axs[1].plot(history.history['val_loss']) \n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['train', 'validate'], loc='upper left')\n    plt.show()\n\n# list all data in history\nprint(history.history.keys())\n\nplotmodelhistory(history)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score trained model.\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])\n\n# make prediction.\npred = model.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['Automobile', 'Dog', 'Horse']\n\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(pred, axis=1) \n# Convert validation observations to one hot vectors\nY_true = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(Y_true, Y_pred_classes))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R = 5\nC = 5\nfig, axes = plt.subplots(R, C, figsize=(12,12))\naxes = axes.ravel()\n\nfor i in np.arange(0, R*C):\n    axes[i].imshow(x_test[i])\n    axes[i].set_title(\"True: %s \\nPredict: %s\" % (labels[Y_true[i]], labels[Y_pred_classes[i]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_similar(number,dict_key):\n    for i in range(300): #Only taking few samples from test dataset because its taking to long to find all similar images from 3000 images of test dataset\n        test_image = np.expand_dims(x_test[i], axis=0)\n        test_result = model.predict_classes(test_image)\n        #plt.imshow(x_test[number])\n        dict_key_get = test_result[0]\n        if dict_key==Y_true[i]:\n            plt.figure(figsize=(3, 3))\n            plt.imshow(x_test[i])\n            plt.title(\"Similar images \\nPredicted: {} \\nTrue Label: {}\".format(labels[dict_key_get],labels[Y_true[i]]))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_test(number):\n    fig = plt.figure(figsize = (3,3))\n    test_image = np.expand_dims(x_test[number], axis=0)\n    test_result = model.predict_classes(test_image)\n    plt.imshow(x_test[number])\n    dict_key = test_result[0]\n    plt.title(\"Orignal images \\nPredicted: {} \\nTrue Label: {}\".format(labels[dict_key],labels[Y_true[number]]))\n    #print(dict_key)\n    show_similar(number,Y_true[number])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_test(1000) #similar images are showing according to its true label #25=dog,1000=horse, 2000=automobile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}