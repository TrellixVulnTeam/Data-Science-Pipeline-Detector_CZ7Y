{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport keras\nfrom keras.datasets import cifar10\nfrom keras.utils import np_utils\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.applications.vgg16 import VGG16\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom sklearn.metrics import accuracy_score\nfrom keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"LABEL_NAMES = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\nVALIDATION_SIZE = 10000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get the Data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"(x_train_all, y_train_all), (x_test, y_test) = cifar10.load_data()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Explore Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"LABEL_NAMES[y_train_all[1][0]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess Data\n## Normalisation "},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_all = x_train_all /255.0\nx_test = x_test /255.0 ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Validation Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_val = x_train_all[:VALIDATION_SIZE]\ny_val = y_train_all[:VALIDATION_SIZE]\nx_val.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Rest of Training Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = x_train_all[VALIDATION_SIZE:]\ny_train = y_train_all[VALIDATION_SIZE:]\nx_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert to One Hot Encoding\ny_train_ohe = np_utils.to_categorical(y_train, num_classes=10)\ny_test_ohe = np_utils.to_categorical(y_test, num_classes=10)\ny_val_ohe = np_utils.to_categorical(y_val, num_classes=10)\n\nprint(y_val_ohe)\ny_val_ohe.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Our Model\n## Define the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef create_cnn_model():\n    image_input = Input(shape=(32, 32, 3))\n    \n    vgg_model  = VGG16(weights='imagenet',include_top=False, input_tensor=image_input)\n    \n    flatt = Flatten()(vgg_model.output)\n    \n    couche1 = Dense(128, activation='relu')(flatt) \n    couche1_normalization = BatchNormalization()(couche1)\n    couche1_dropout = Dropout(0.2)(couche1_normalization)\n    couche2 = Dense(64, activation='relu')(couche1_dropout)\n    couche2_normalization = BatchNormalization()(couche2)\n    output = Dense(10, activation='softmax', name='output')(couche2_normalization)     \n    model = Model( image_input, output )\n    return model\n\nmodel = create_cnn_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Compile Our Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmodel.compile(optimizer='adam', \n              loss='categorical_crossentropy',\n                metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fit Our Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Use Data Augmentation\ndatagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, horizontal_flip= True)\nes = EarlyStopping(patience=10, monitor='val_accuracy', mode='max')\nmc = ModelCheckpoint('./weights.h5', monitor='val_accuracy', mode='max', save_best_only=True)\n\nmodel.fit_generator(datagen.flow(x_train, y_train_ohe,batch_size = 32), steps_per_epoch = 1250, epochs=500, validation_data=[x_val, y_val_ohe], callbacks = [es,mc])\n# Load The Best weights in the ModelCheckpoint\nmodel.load_weights('./weights.h5')\n\n# Predict The Test\npreds = model.predict(x_val)\nscore_test = accuracy_score( y_val, np.argmax(preds, axis=1) )\n\nprint (' LE SCORE DE TEST : ', score_test)\nprint('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# after fit we can evaluate our model\n_, evaluate = model.evaluate(x_test, y_test_ohe, verbose=1)\nprint('>%.3f' % (evaluate * 100.0))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}