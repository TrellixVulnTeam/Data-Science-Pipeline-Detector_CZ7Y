{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-10T10:23:42.964786Z","iopub.execute_input":"2022-03-10T10:23:42.965136Z","iopub.status.idle":"2022-03-10T10:23:42.996753Z","shell.execute_reply.started":"2022-03-10T10:23:42.965054Z","shell.execute_reply":"2022-03-10T10:23:42.996051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow \nfrom tensorflow.keras.datasets import cifar10","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:42.998393Z","iopub.execute_input":"2022-03-10T10:23:42.998883Z","iopub.status.idle":"2022-03-10T10:23:47.941572Z","shell.execute_reply.started":"2022-03-10T10:23:42.998847Z","shell.execute_reply":"2022-03-10T10:23:47.94083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(X_train,y_train), (X_test,y_test) = cifar10.load_data()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:47.94421Z","iopub.execute_input":"2022-03-10T10:23:47.945003Z","iopub.status.idle":"2022-03-10T10:23:53.764656Z","shell.execute_reply.started":"2022-03-10T10:23:47.944964Z","shell.execute_reply":"2022-03-10T10:23:53.763716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = X_test/255\nX_train = X_train/255","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:53.766646Z","iopub.execute_input":"2022-03-10T10:23:53.766918Z","iopub.status.idle":"2022-03-10T10:23:54.22011Z","shell.execute_reply.started":"2022-03-10T10:23:53.766882Z","shell.execute_reply":"2022-03-10T10:23:54.219376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import to_categorical","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:54.22142Z","iopub.execute_input":"2022-03-10T10:23:54.221759Z","iopub.status.idle":"2022-03-10T10:23:54.226615Z","shell.execute_reply.started":"2022-03-10T10:23:54.221722Z","shell.execute_reply":"2022-03-10T10:23:54.225854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = to_categorical(y_train) \ny_test = to_categorical(y_test)\ny_train[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:54.22815Z","iopub.execute_input":"2022-03-10T10:23:54.228407Z","iopub.status.idle":"2022-03-10T10:23:54.248279Z","shell.execute_reply.started":"2022-03-10T10:23:54.22836Z","shell.execute_reply":"2022-03-10T10:23:54.247614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train.reshape(X_train.shape[0],32,32,3)\nX_test = X_test.reshape(X_test.shape[0],32,32,3)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:54.249415Z","iopub.execute_input":"2022-03-10T10:23:54.250039Z","iopub.status.idle":"2022-03-10T10:23:54.25518Z","shell.execute_reply.started":"2022-03-10T10:23:54.250001Z","shell.execute_reply":"2022-03-10T10:23:54.254423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_img = tensorflow.keras.layers.Input((32, 32, 3))\n\nencoded = tensorflow.keras.layers.Conv2D(64, (4,4), padding='same', name='e1')(input_img)\nencoded = tensorflow.keras.layers.Activation('relu', name = 'e2')(encoded)\nencoded = tensorflow.keras.layers.MaxPool2D(name = 'e3')(encoded)\n\nencoded = tensorflow.keras.layers.Conv2D(32, (4,4), padding='same', name='e4')(encoded)\nencoded = tensorflow.keras.layers.Activation('relu', name = 'e5')(encoded)\nencoded = tensorflow.keras.layers.MaxPool2D(name = 'e6')(encoded)\n\nencoded = tensorflow.keras.layers.BatchNormalization(name = 'e7')(encoded)\n\nencoded = tensorflow.keras.layers.Conv2D(16, (4,4), padding='same', name='e8')(encoded)\nencoded = tensorflow.keras.layers.Activation('relu', name = 'e9')(encoded)\n\n\ndecoded = tensorflow.keras.layers.Conv2D(16, (4,4), padding='same', name='d1')(encoded)\ndecoded = tensorflow.keras.layers.Activation('relu', name='d2')(decoded)\ndecoded = tensorflow.keras.layers.UpSampling2D(name = 'd3')(decoded)\n\ndecoded = tensorflow.keras.layers.BatchNormalization(name = 'd4')(decoded)\n\ndecoded = tensorflow.keras.layers.Conv2D(32, (4,4), padding='same', name='d5')(decoded)\ndecoded = tensorflow.keras.layers.Activation('relu', name='d6')(decoded)\ndecoded = tensorflow.keras.layers.UpSampling2D(name ='d7')(decoded)\n\ndecoded = tensorflow.keras.layers.Conv2D(64, (4,4), padding='same', name='d8')(decoded)\n\n# Renormalize the image to (32px*32px) * (R,G,B)\ndecoded = tensorflow.keras.layers.Conv2D(3, (3,3), padding='same', name='d9')(decoded)\n\noutput = tensorflow.keras.layers.Activation('sigmoid', name='d10')(decoded)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:54.256624Z","iopub.execute_input":"2022-03-10T10:23:54.257117Z","iopub.status.idle":"2022-03-10T10:23:56.728209Z","shell.execute_reply.started":"2022-03-10T10:23:54.257084Z","shell.execute_reply":"2022-03-10T10:23:56.726434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Model\nautoencoder = Model(inputs=input_img, outputs=output)\nencoder = Model(inputs=input_img, outputs=encoded)\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:56.729576Z","iopub.execute_input":"2022-03-10T10:23:56.729821Z","iopub.status.idle":"2022-03-10T10:23:56.747514Z","shell.execute_reply.started":"2022-03-10T10:23:56.729787Z","shell.execute_reply":"2022-03-10T10:23:56.746852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:56.750281Z","iopub.execute_input":"2022-03-10T10:23:56.750866Z","iopub.status.idle":"2022-03-10T10:23:56.763644Z","shell.execute_reply.started":"2022-03-10T10:23:56.750827Z","shell.execute_reply":"2022-03-10T10:23:56.762961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoded_input = tensorflow.keras.layers.Input((4, 4, 16))\ndecoded_layer = autoencoder.get_layer('d1')(encoded_input)\ndecoded_layer = autoencoder.get_layer('d2')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d3')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d4')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d5')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d6')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d7')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d8')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d9')(decoded_layer)\ndecoded_layer = autoencoder.get_layer('d10')(decoded_layer)\n\ndecoder = Model(inputs=encoded_input, outputs=decoded_layer)\ndecoder.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:56.766078Z","iopub.execute_input":"2022-03-10T10:23:56.76625Z","iopub.status.idle":"2022-03-10T10:23:56.813536Z","shell.execute_reply.started":"2022-03-10T10:23:56.766228Z","shell.execute_reply":"2022-03-10T10:23:56.812926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.compile(optimizer='adam', loss='binary_crossentropy', metrics=['mse'])","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:56.814722Z","iopub.execute_input":"2022-03-10T10:23:56.814946Z","iopub.status.idle":"2022-03-10T10:23:56.827316Z","shell.execute_reply.started":"2022-03-10T10:23:56.814904Z","shell.execute_reply":"2022-03-10T10:23:56.826488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Setup saving the model producing the best val_acc\ncheckpoint_filepath = 'best.h5'\nmodel_checkpoint_callback = tensorflow.keras.callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    save_weights_only=True,\n    monitor = 'val_mse',\n    mode='min',\n    save_best_only=True, verbose=2\n)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:56.82861Z","iopub.execute_input":"2022-03-10T10:23:56.829126Z","iopub.status.idle":"2022-03-10T10:23:56.833908Z","shell.execute_reply.started":"2022-03-10T10:23:56.829092Z","shell.execute_reply":"2022-03-10T10:23:56.833198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.fit(X_train, X_train, validation_data=(X_test, X_test), epochs=50, callbacks=[model_checkpoint_callback], batch_size=128)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:23:56.835159Z","iopub.execute_input":"2022-03-10T10:23:56.835675Z","iopub.status.idle":"2022-03-10T10:29:56.755393Z","shell.execute_reply.started":"2022-03-10T10:23:56.835639Z","shell.execute_reply":"2022-03-10T10:29:56.754745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"autoencoder.load_weights('best.h5')\nautoencoder.evaluate(X_test, X_test)","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:29:56.756622Z","iopub.execute_input":"2022-03-10T10:29:56.756947Z","iopub.status.idle":"2022-03-10T10:29:58.509525Z","shell.execute_reply.started":"2022-03-10T10:29:56.756908Z","shell.execute_reply":"2022-03-10T10:29:58.508729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt \ndecoded_imgs = autoencoder.predict(X_test)\nfig, ax = plt.subplots(nrows=2, ncols=10, figsize=(20, 4))\nplt.gray()\nfor indice, row in enumerate(ax):\n    for indice2, col in enumerate(row):\n        if indice == 0:\n            col.imshow(X_test[indice2].reshape(32,32, 3))\n        else: \n            col.imshow(decoded_imgs[indice2].reshape(32,32, 3))\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-10T10:29:58.510778Z","iopub.execute_input":"2022-03-10T10:29:58.511032Z","iopub.status.idle":"2022-03-10T10:30:01.28878Z","shell.execute_reply.started":"2022-03-10T10:29:58.510998Z","shell.execute_reply":"2022-03-10T10:30:01.287178Z"},"trusted":true},"execution_count":null,"outputs":[]}]}