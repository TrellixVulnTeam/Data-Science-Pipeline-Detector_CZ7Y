{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# test harness for evaluating models on the cifar10 dataset\nimport sys\nfrom matplotlib import pyplot\nfrom keras.datasets import cifar10\nfrom keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.optimizers import SGD","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    (trainX, trainY), (testX, testY) = cifar10.load_data()\n    # one hot encode target values\n    trainY = to_categorical(trainY)\n    testY = to_categorical(testY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n    # convert from integers to floats\n    trainX = trainX.astype('float32')\n    testX = testX.astype('float32')\n    # normalize to range 0-1\n    trainX = trainX / 255.0\n    testX = testX / 255.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg = VGG16(input_shape=[32,32,3], weights='imagenet', include_top=False)\n\n# don't train existing weights\nfor layer in vgg.layers:\n  layer.trainable = False ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Model\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# our layers - you can add more if you want\nx = Flatten()(vgg.output)\n# x = Dense(1000, activation='relu')(x)\nprediction = Dense(10, activation='softmax')(x)\n\n# create a model object\nmodel = Model(inputs=vgg.input, outputs=prediction)\n\n# view the structure of the model\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# compile the model cost and optimization method to use\nmodel.compile(\n  loss='categorical_crossentropy',\n  optimizer='adam',\n  metrics=['accuracy']\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping\nearly_stopping=EarlyStopping()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model\nr = model.fit(trainX,trainY, epochs=50,\ncallbacks=[early_stopping]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plot diagnostic learning curves\ndef summarize_diagnostics(history):\n    # plot loss\n    pyplot.subplot(211)\n    pyplot.title('Cross Entropy Loss')\n    pyplot.plot(r.history['loss'], color='blue', label='train')\n    pyplot.plot(r.history['val_loss'], color='orange', label='test')\n    pyplot.show()\n    # plot accuracy\n    pyplot.subplot(212)\n    pyplot.title('Classification Accuracy')\n    pyplot.plot(r.history['accuracy'], color='blue', label='train')\n    pyplot.plot(r.history['val_accuracy'], color='orange', label='test')\n    pyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate model\n_, acc = model.evaluate(testX, testY, verbose=0)\nprint('> %.3f' % (acc * 100.0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}