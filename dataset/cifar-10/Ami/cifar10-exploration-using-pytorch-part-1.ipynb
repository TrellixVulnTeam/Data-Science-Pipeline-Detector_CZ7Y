{"cells":[{"metadata":{},"cell_type":"markdown","source":"Solving exercises in ch7 Deep Learning with Pytorch book"},{"metadata":{},"cell_type":"markdown","source":"The dataset is zipped, but we can use the cifar10 dataset available in public domain."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from torchvision import datasets","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Q1.  Use torchvision to implement random cropping of the data."},{"metadata":{},"cell_type":"markdown","source":"Lets try and implement random crop using transforms. Lets first see what transforms are available."},{"metadata":{"trusted":true},"cell_type":"code","source":"from torchvision import transforms\n\ndir(transforms)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets initialize a normalize function with values given from the book itself."},{"metadata":{"trusted":true},"cell_type":"code","source":"normalize = transforms.Normalize((0.4915, 0.4823, 0.4468),\n                         (0.2470, 0.2435, 0.2616))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"you can compose a transformation pipeline using transforms.Compose."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_transform = transforms.Compose(\n                    [transforms.RandomCrop(32,32),\n                     transforms.ToTensor(),\n                     normalize]\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets download the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = './'\n\ncifar10 = datasets.CIFAR10(data_path, train=True, download=True, transform=train_transform)\ncifar10_val = datasets.CIFAR10(data_path, train=False, download=True, transform=train_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(cifar10), len(cifar10_val)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we have 50000 images for training and 10000 for validation"},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = cifar10[30000]\n# img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cropped_image(index, number):\n    columns = number\n    rows = 1\n    fig = plt.figure(figsize=(32,32))\n    for i in range(1, columns*rows +1):\n        img, label = cifar10[index]\n        fig.add_subplot(rows, columns, i)\n        plt.imshow(img.permute(1,2,0))\n    plt.show() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_cropped_image(550, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"get_cropped_image(20345,5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random resized crop is definitly as random as it professes out to be. Is it possible to create a classfiier with this? lets find out. We will create a simple classfier that checks between a plane and a bird."},{"metadata":{},"cell_type":"markdown","source":"the classes in cifar10."},{"metadata":{"trusted":true},"cell_type":"code","source":"cifar10.classes, len(cifar10.classes)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lets create a simple model."},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = nn.Sequential(\n#         nn.Linear(3072, 1024),\n#         nn.Tanh(),\n#         nn.Linear(1024, 512),\n#         nn.Tanh(),\n#         nn.Linear(512, 128),\n#         nn.Tanh(),\n#         nn.Linear(128, 10),\n#         nn.LogSoftmax(dim=1)\n# )\n\n#simpler\nmodel = nn.Sequential(\n    nn.Linear(3072, 512),\n    nn.Tanh(),\n    nn.Linear(512, 10),\n    nn.LogSoftmax(dim=1)\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"defining hyperparameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_fn = nn.NLLLoss()\nn_epochs = 30\nlearning_rate = 1e-2\n\noptimizer = optim.SGD(model.parameters(),\n                      lr = learning_rate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"training"},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(n_epochs):\n    for img, label in cifar10:\n        print(\"Current label: \", label, end=\"\\r\")\n        out = model(img.view(-1).unsqueeze(0))\n        loss = loss_fn(out, torch.tensor([label]))\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    print(\"Epoch: \", epoch, \"Loss: \", float(loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correct = 0\ntotal = 0\n\nwith torch.no_grad():\n    for imgs, labels in cifar10_val:\n        outputs = model(img.view(-1).unsqueeze(0))\n        _, predicted = torch.max(outputs, dim=1)\n        total += labels.shape[0]\n        correct += int((predicted==labels).sum())\n\nprint(\"Accuracy: \", correct/total)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can also could have used data loaders for creating batches for iterating over in every epoch."},{"metadata":{},"cell_type":"markdown","source":"# Q2. Switch Loss function"},{"metadata":{},"cell_type":"markdown","source":"We will use MSELoss for testing"},{"metadata":{"trusted":true},"cell_type":"code","source":"loss_fn = nn.MSELoss()\nn_epochs = 1\nlearning_rate = 1e-2\noptimizer = optim.SGD(model.parameters(), lr = learning_rate)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will create a data loader this time."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(cifar10, batch_size=10,shuffle=True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(n_epochs):\n    for imgs, labels in train_loader:\n        batch_size = imgs.shape[0]\n        outputs = model(imgs.view(batch_size, -1))\n        loss = loss_fn(outputs, labels.type(torch.FloatTensor))\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    print(\"Epoch: \", epoch, \" loss: \", float(loss))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Checking on validation set"},{"metadata":{"trusted":true},"cell_type":"code","source":"val_loader = torch.utils.data.DataLoader(cifar10_val, batch_size=10, shuffle=False)\n\ncorrect = 0\ntotal = 0\n\nwith torch.no_grad():\n    for imgs, labels in val_loader:\n        batch_size = imgs.shape[0]\n        outputs = model(imgs.view(batch_size, -1))\n        _, predicted = torch.max(outputs, dim=1)\n        total += labels.shape[0]\n        correct += int((predicted==labels).sum())\n\nprint(\"Accuracy: \", correct/total)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}