{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import os\n#print(os.getcwd())\n\n#import py7zr\n#import py7zr\n\n#with py7zr.SevenZipFile(\n#    '/kaggle/input/cifar-10/test.7z','r') as z:\n#    z.extractall('.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## このプログラムは「CIFAR-10 - Object Recognition in Images」において\n## 作成したノートブックで動作します\n## ローカル環境のJupyter Notebookで作成したノートブックでも動作可能です\n\nimport numpy as np\nfrom tensorflow.keras.datasets import cifar10\n\n# CIFAR-10データセットをロード\n(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n# データの形状を出力\nprint('X_train:',X_train.shape, 'y_train:', y_train.shape)\nprint('X_test :', X_test.shape, 'y_test :', y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(type(X_train))\nprint(type(y_train))\nprint(len(y_train))\nprint(y_train[100][0])\nprint(y_train[100,0])\nprint(np.unique(y_train))\n3+3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    target_class=0\n    target_idx = []\n    \n    # クラスiが正解の場合の正解ラベルのインデックス取得する\n    for i in range(len(y_train)):\n        # i行、0列の正解ラベルがtarget_classと一致するか\n        if y_train[i,0] == target_class:\n            # クラスiが正解であれば正解ラベルのインデックスをtargetIdxに追加\n            target_idx.append(i)\n\nprint(target_idx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# 画像を描画\nnum_classes = 10 # 分類先のクラスの数\npos = 1          # 画像の描画位置を保持する変数\n\n    \nplt.figure(figsize=(20, 20))  # 描画エリアを横25インチ、縦3インチにする\n    \n    # シャフルした最初の10枚の画像を描画\nfor idx in target_idx[:10]:   \n        plt.subplot(10, 10, pos)  # 10行、10列の描画領域のpos番目の位置を指定\n        plt.imshow(X_train[idx])  # Matplotlibのimshow()で画像を描画\n        pos += 1\n\n        \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\n# 画像を描画\nnum_classes = 10 # 分類先のクラスの数\npos = 1          # 画像の描画位置を保持する変数\n\n# クラスの数だけ繰り返す\nfor target_class in range(num_classes):\n    # 各クラスに分類される画像のインデックスを保持するリスト\n    target_idx = []\n    \n    # クラスiが正解の場合の正解ラベルのインデックス取得する\n    for i in range(len(y_train)):\n        # i行、0列の正解ラベルがtarget_classと一致するか\n        if y_train[i,0] == target_class:\n            # クラスiが正解であれば正解ラベルのインデックスをtargetIdxに追加\n            target_idx.append(i)\n    \n    np.random.shuffle(target_idx) # クラスiの画像のインデックスをシャッフル\n    plt.figure(figsize=(20, 20))  # 描画エリアを横25インチ、縦3インチにする\n    \n    # シャフルした最初の10枚の画像を描画\n    for idx in target_idx[:10]:   \n        plt.subplot(10, 10, pos)  # 10行、10列の描画領域のpos番目の位置を指定\n        plt.imshow(X_train[idx])  # Matplotlibのimshow()で画像を描画\n        pos += 1\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## このプログラムは「CIFAR-10 - Object Recognition in Images」において\n## 作成したノートブックで動作します\n## ローカル環境のJupyter Notebookで作成したノートブックでも動作可能です\n\nimport numpy as np\nfrom tensorflow.keras.datasets import cifar10\nfrom tensorflow.keras.utils import to_categorical\n\ndef prepare_data():\n    \"\"\"データを用意する\n    \n    Returns:\n    X_train(ndarray):\n        訓練データ(50000.32.32.3)\n    X_test(ndarray):\n        テストデータ(10000.32.32.3)\n    y_train(ndarray):\n        訓練データのOne-Hot化した正解ラベル(50000,10)\n    y_train(ndarray):\n        テストデータのOne-Hot化した正解ラベル10000,10)\n    y_test_label(ndarray):\n        テストデータの正解ラベル(10000)\n    \"\"\"\n    (x_train, y_train), (x_test, y_test) = cifar10.load_data()\n    \n    # 訓練用とテスト用の画像データを正規化する\n    x_train, x_test = x_train.astype('float32'), x_test.astype('float32')\n    x_train, x_test = x_train/255.0, x_test/255.0\n    \n    # 訓練データとテストデータの正解ラベルを10クラスのOne-Hot表現に変換\n    y_train, y_test = to_categorical(y_train), to_categorical(y_test)\n    \n    return x_train, x_test, y_train, y_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# モデルを生成する\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten # core layers\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D    # convolution layers\nfrom tensorflow.keras import optimizers\n\ndef make_convlayer():\n    # Sequentialオブジェクトを生成\n    model = Sequential()\n\n    # 第1層: 畳み込み層1\n    model.add(Conv2D(filters=64,\n                     kernel_size=3,\n                     padding='same', \n                     activation='relu',\n                     input_shape=(32,32,3)))\n    # 第2層: 2×2のプーリング層を配置\n    model.add(MaxPooling2D(pool_size=2))\n\n    # 第3層: 畳み込み層2\n    model.add(Conv2D(filters = 128,\n                     kernel_size = 3,\n                     padding='same', \n                     activation='relu'))\n    # 第4層: 2×2のプーリング層を配置\n    model.add(MaxPooling2D(pool_size=2))\n\n    # 第5層: 畳み込み層3\n    model.add(Conv2D(filters=256,\n                     kernel_size=3,\n                     padding='same', \n                     activation='relu'))\n    # 第6層: 2×2のプーリング層を配置\n    model.add(MaxPooling2D(pool_size=2))\n\n    # Flatten層\n    model.add(Flatten())\n    # ドロップアウトを設定\n    model.add(Dropout(0.4))\n\n    # 第7層\n    model.add(Dense(512, activation='relu'))\n\n    # 出力層\n    model.add(Dense(10, activation = \"softmax\"))\n\n    # モデルのコンパイル\n    # オプティマイザーはAdam\n    model.compile(loss=\"categorical_crossentropy\",\n                  optimizer=optimizers.Adam(lr=0.001),\n                  metrics=[\"accuracy\"])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import LearningRateScheduler, Callback\n\nclass LRHistory(Callback):\n    def on_train_begin(self, logs={}):\n        self.acc = []\n        self.lr = []\n\n    def on_epoch_end(self, batch, logs={}):\n        self.acc.append(logs.get('acc'))\n        self.lr.append(step_decay(len(self.acc)))\n\n\n# 学習率減衰\ndef step_decay(epoch):\n    initial_lrate = 0.001 # 初期学習率\n    drop = 0.5\n    epochs_drop = 10.0\n    lrate = initial_lrate * math.pow(\n        drop,\n        math.floor((1+epoch)/epochs_drop)\n    )\n    return lrate\n\ndef train(x_train, x_test,\n          y_train, y_test):\n    \n    model = make_convlayer()\n    lr_history = LRHistory()\n    lrate = LearningRateScheduler(step_decay)\n    callbacks_list = [lr_history, lrate]\n\n    # データ拡張\n    datagen = ImageDataGenerator(\n        width_shift_range=0.1,  # 横サイズの0.1の割合でランダムに水平移動\n        height_shift_range=0.1, # 縦サイズの0.1の割合でランダムに垂直移動\n        rotation_range=10,      # 10度の範囲でランダムに回転させる\n        zoom_range=0.1,         # ランダムに拡大\n        horizontal_flip=True)   # 左右反転\n\n    # ミニバッチのサイズ\n    batch_size = 128\n    # 学習回数\n    epochs = 100\n\n    # 学習を行う\n    history = model.fit(\n        # 拡張データをミニバッチの数だけ生成\n        datagen.flow(x_train,\n                     y_train,\n                     batch_size=batch_size),\n        # 1回の学習におけるステップ数\n        # 画像の枚数をミニバッチのサイズで割った整数値\n        steps_per_epoch=x_train.shape[0] // batch_size,\n        epochs=epochs, # 学習回数\n        verbose=1,     # 学習の進捗状況を出力する\n        # テストデータ\n        validation_data=(x_test, y_test),\n        callbacks=callbacks_list\n    )\n    \n    return history, lr_history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = prepare_data()\n\n\nprint(x_train.shape)\nprint(type(x_train))\n\n\nprint(x_test.shape)\nprint(type(x_test))\n\nprint(y_train.shape)\nprint(type(y_train))\n\nprint(y_test.shape)\nprint(type(y_test))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory, lr_history = train(x_train, x_test, y_train, y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 損失と正解率（精度）の推移をグラフにする\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# プロット図のサイズを設定\nplt.ﬁgure(ﬁgsize=(15, 10))\n# プロット図を縮小して図の間のスペースを空ける\nplt.subplots_adjust(wspace=0.2)\n\n# 2×1のグリッドの上部にプロット\nplt.subplot(2, 1, 1)\n# 訓練データの精度をプロット\nplt.plot(\n    history.history['accuracy'], label='train', color='black')\n# テストデータの精度をプロット\nplt.plot(\n    history.history['val_accuracy'], label='Val Acc',color='red')\nplt.legend()         # 凡例を表示\nplt.grid()           # グリッド表示\nplt.xlabel('Epoch')  # x軸ラベル\nplt.ylabel('Acc')    # y軸ラベル\n\n# 2×1のグリッドの下部にプロット\nplt.subplot(2, 1, 2)\n# 学習率をプロット\nplt.plot(lr_history.lr,\n         label='Learning Rate',\n         color='blue')\nplt.legend()         # 凡例を表示\nplt.grid()           # グリッド表示\nplt.xlabel('Epoch')  # x軸ラベル\nplt.ylabel('Learning Rate')    # y軸ラベル\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\n\n# プロット図のサイズを設定\nplt.ﬁgure(ﬁgsize=(15, 10))\n\n# 2×1のグリッドの下部にプロット\nplt.subplot(1, 1, 1)\n# 学習率をプロット\nplt.plot(lr_history.acc,\n         label='Accuracy',\n         color='blue')\nplt.legend()         # 凡例を表示\nplt.grid()           # グリッド表示\nplt.xlabel('Epoch')  # x軸ラベル\nplt.ylabel('Accuracy')    # y軸ラベル\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}