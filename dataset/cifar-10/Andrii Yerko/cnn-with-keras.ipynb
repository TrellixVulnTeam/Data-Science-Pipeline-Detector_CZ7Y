{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom IPython.display import clear_output\n\nimport tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif device_name != '/device:GPU:0':\n    print('GPU device not found')\nprint('Found GPU at: {}'.format(device_name))\ntf.config.threading.set_intra_op_parallelism_threads(0)\n\nfrom tensorflow.keras import Sequential, Input, initializers, optimizers, callbacks, layers\n\nfrom tensorflow.keras.layers import AveragePooling2D, BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPool2D\nfrom tensorflow.keras.metrics import AUC\n\nfrom tensorflow.keras.utils import to_categorical","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install py7zr\nfrom py7zr import unpack_7zarchive\nimport shutil\nshutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\nshutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/working')\nshutil.unpack_archive('/kaggle/input/cifar-10/test.7z', '/kaggle/working')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dir = os.listdir(\"./train\");\ntrain_dir_len = len(train_dir)\nprint(\".\\\\train:\\t\",train_dir_len)\nprint(\"files:\\t\\t\",train_dir[:3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dir = os.listdir(\"./test\");\ntest_dir_len = len(test_dir)\nprint(\".\\\\test:\\t\",test_dir_len)\nprint(\"files:\\t\\t\",test_dir[:3])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import imageio\n\ndef read_images(path, number):\n    a = np.concatenate([imageio.imread(path+f'/{i}.png')[None,...] for i in range(1,number+1)], axis=0)\n    return a","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_labels = pd.read_csv('/kaggle/input/cifar-10/trainLabels.csv', index_col=0)\ntrain_labels = pd.get_dummies(train_labels, prefix='', prefix_sep='')\nlabels = train_labels.columns\ny_train = train_labels.values\n\nX_train = read_images(\"./train\", train_dir_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 5, figsize=(11, 5))\nfig.suptitle(f\"Number of classes: {len(labels)}\", fontsize=16)\n\nfor i, ax in enumerate(axs.flatten()):\n    ind = np.random.choice(np.nonzero(y_train[:, i])[0])\n    ax.imshow(X_train[ind])\n    ax.set_title(f'{labels[i]} ({i})')\n    ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_augmentation = Sequential(\n  [\n      layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n      layers.experimental.preprocessing.RandomZoom(0.1),\n      layers.experimental.preprocessing.RandomRotation(0.15),\n      layers.experimental.preprocessing.RandomContrast(0.2)\n  ],\n  name='RandomAugmentator'\n)\n\nmodel = Sequential(\n  [\n    Input((32, 32, 3)),\n    data_augmentation,\n   \n    Conv2D(48, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    Conv2D(48, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPool2D((2, 2)),\n    Dropout(0.2),\n\n    Conv2D(96, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    Conv2D(96, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    MaxPool2D((2, 2)),\n    Dropout(0.3),\n\n    Conv2D(192, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    Conv2D(192, (3, 3), activation='relu', padding='same'),\n    BatchNormalization(),\n    AveragePooling2D((3, 3), strides=(2, 2)),\n    Dropout(0.4),\n\n    Flatten(),\n    Dense(192, activation='relu'),\n    Dropout(0.4),\n    Dense(10, activation='softmax')\n  ],\n  name=\"CIFAR10-model\"\n)\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(\n    optimizer=optimizers.Adam(0.0001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n    )\n\ncheckpoint_filepath = '/kaggle/temp/checkpoint'\nmodel_checkpoint_callback = callbacks.ModelCheckpoint(\n    filepath=checkpoint_filepath,\n    monitor='val_accuracy',\n    mode='max',\n    save_best_only=True\n    )\n\nearly_stopping = callbacks.EarlyStopping(monitor='val_loss', min_delta=0,\n                                         patience=20, verbose=1, mode='auto',\n                                         restore_best_weights=True)\n\n\nhistory = model.fit(X_train, y_train, epochs=400, initial_epoch=0, validation_split=0.1,\n                    callbacks=[model_checkpoint_callback, early_stopping]\n                    )\n\nmodel.save('./model')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['accuracy'], label='train')\nplt.plot(history.history['val_accuracy'], label='validation')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history['loss'], label='train')\nplt.plot(history.history['val_loss'], label='validation')\nplt.legend();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = read_images(\"./test\", test_dir_len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(X_test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_pred = pd.Series(y_pred.argmax(axis=1), index=pd.RangeIndex(1, test_dir_len+1)).apply(lambda x: labels[x])\nlabels_pred.index.name = 'id'\nlabels_pred.name = 'label'\nlabels_pred.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axs = plt.subplots(2, 5, figsize=(11, 5))\nfig.suptitle(f\"Test set predictions\", fontsize=16)\n\nfor i, ax in enumerate(axs.flatten()):\n    ax.imshow(X_test[i])\n    ax.set_title(labels_pred.iloc[i])\n    ax.axis('off')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels_pred.to_csv('submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}