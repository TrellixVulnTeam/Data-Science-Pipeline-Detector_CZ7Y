{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#from tensorflow.keras.datasets import cifar10\n#import matplotlib.pyplot as plt\n#%matplotlib inline \n#(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n#classes=['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n# наборы данных для экспериментов\n# from tensorflow.keras.datasets import cifar10, fashion_mnist\n# последовательная модель (стек слоев)\nfrom tensorflow.keras.models import Sequential\n# полносвязный слой и слой выпрямляющий матрицу в вектор\nfrom tensorflow.keras.layers import Dense, Flatten\n# слой выключения нейронов и слой нормализации выходных данных (нормализует данные в пределах текущей выборки)\nfrom tensorflow.keras.layers import Dropout, BatchNormalization, SpatialDropout2D, GaussianDropout\n# слои свертки и подвыборки\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n# работа с обратной связью от обучающейся нейронной сети\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n# вспомогательные инструменты\nfrom tensorflow.keras import utils\n# работа с изображениями\nfrom tensorflow.keras.datasets import cifar10\nimport matplotlib.pyplot as plt\n%matplotlib inline ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Размер мини-выборки\n\"\"\"может повлиять на изменение качества обучения и скорость обучения\"\"\"\nbatch_size = 64\n# Количество классов изображений\nnb_classes = 10\n# Количество эпох для обучения\n\"\"\"можно не менять, если будете использовать callbacks\"\"\"\nnb_epoch = 40\n# Размер изображений\n\"\"\"настроить под ваши изображения\"\"\"\nimg_rows, img_cols = 32, 32\n# Количество каналов в изображении: RGB\nimg_channels = 3\n# Названия классов из набора данных\nclasses=['самолет', 'автомобиль', 'птица', 'кот', 'олень', 'собака', 'лягушка', 'лошадь', 'корабль', 'грузовик']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = cifar10.load_data()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# добавляем цветовой канал\nX_train = X_train.reshape((50000, 32, 32, 3))\nX_train = X_train.astype('float32')\nX_test = X_test.reshape((10000, 32, 32, 3))\nX_test = X_test.astype('float32')\nX_train /= 255\nX_test /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_train = utils.to_categorical(y_train, nb_classes)\nY_test = utils.to_categorical(y_test, nb_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Создаем последовательную модель\nmodel = Sequential()\n# Первый сверточный слой\n\"\"\"можно менять:\n- количество сверточных слоев в блоке (блок - это свертка или несколько сверток, которые завершаются пулингом)\n- количество сверточных блоков\n- количество ядер свертки (filters)\n- размер ядра свертки (kernel_size)\n- MaxPooling2D на AveragePooling2D\n- добавлять/убирать BatchNormalization. Его можно ставить после каждого слоя свертки, а можно в конце блока. Экспериментируйте\n- добавлять/убирать Dropout. Его можно ставить после каждого блока свертки, а можно еще и после Dense слоя. Экспериментируйте\n- менять в Dropout процент выключаемых нейронов\n- менять Dropout на SpatialDropout2D, GaussianDropout\n- менять количество слоев Dense\n- менять количество нейронов в слое Dense\"\"\"\n# padding='same' - не будет меняться размер картинки. padding='valid'\nmodel.add(Conv2D(filters=32, kernel_size=(3, 3), padding='same',\n                        input_shape=(img_rows, img_cols, img_channels), activation='relu'))\n# Второй сверточный слой\nmodel.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n# # Первый слой подвыборки\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# # Первый слой нормализации данных\nmodel.add(BatchNormalization())\n# # Первый Слой регуляризации Dropout\nmodel.add(Dropout(0.25))\n\n# Третий сверточный слой\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n# Четвертый сверточный слой\nmodel.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n# Второй слой подвыборки\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# # Второй слой нормализации данных\nmodel.add(BatchNormalization())\n#  # Второй Слой регуляризации Dropout\nmodel.add(Dropout(0.25))\n\n# # Пятый сверточный слой\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n# # Шестой сверточный слой\nmodel.add(Conv2D(128, (3, 3), padding='same', activation='relu'))\n# # Третий слой подвыборки\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n# # Третий слой нормализации данных\nmodel.add(BatchNormalization())\n# # Третий Слой регуляризации Dropout\nmodel.add(Dropout(0.25))\n\n\n# Слой преобразования данных из 2D представления в плоское\nmodel.add(Flatten())\n# Полносвязный слой для классификации\nmodel.add(Dense(512, activation='relu'))\n# # Четвертый слой нормализации данных\nmodel.add(BatchNormalization()) \n# # Четвертый Слой регуляризации Dropout\nmodel.add(Dropout(0.75))\n# Выходной полносвязный слой\nmodel.add(Dense(nb_classes, activation='softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# EarlyStopping - если patience эпох качество не растет или потери не убывают, то происходит останов обучения\n# ModelCheckpoint - сохраняет в указанную директорию веса лучшей модели и в конце обучения возвращает их.\n# ReduceLROnPlateau - уменьшает шаг обучения в factor раз после patience эпох без улучшения качества обучения\n\"\"\"patience у ReduceLROnPlateau меньше, чем  patience у EarlyStopping\nиначе не произойдет ни одного уменьшения шага обучения\nможно следить за monitor=val_loss, а можно monitor=val_accuracy\nменяйте factor в ReduceLROnPlateau - он значим\"\"\"\ncallbacks_list = [EarlyStopping(monitor='val_loss', patience=5),\n                  ModelCheckpoint(filepath='my_model.h5',\n                                  monitor='val_loss',\n                                  save_best_only=True),\n                  ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n                  ] \n# экспериментируйте с optimizer\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nhistory = model.fit(X_train, Y_train,\n              batch_size=batch_size,\n              epochs=nb_epoch,\n              callbacks=callbacks_list,\n              validation_split=0.1,\n              verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.evaluate(X_test, Y_test, verbose=1)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}