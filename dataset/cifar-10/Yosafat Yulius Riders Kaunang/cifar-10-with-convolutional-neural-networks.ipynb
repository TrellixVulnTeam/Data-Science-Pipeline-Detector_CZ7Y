{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-18T15:07:04.67356Z","iopub.execute_input":"2022-02-18T15:07:04.674003Z","iopub.status.idle":"2022-02-18T15:07:04.686138Z","shell.execute_reply.started":"2022-02-18T15:07:04.67396Z","shell.execute_reply":"2022-02-18T15:07:04.685144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Import All Packages**","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport keras\nfrom keras import backend as K\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\nfrom statistics import mean\nimport glob\nimport os\nimport cv2\nimport sys\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:04.695509Z","iopub.execute_input":"2022-02-18T15:07:04.695763Z","iopub.status.idle":"2022-02-18T15:07:04.712444Z","shell.execute_reply.started":"2022-02-18T15:07:04.695738Z","shell.execute_reply":"2022-02-18T15:07:04.711656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install package\n# Library and utility to support 7zip archive compression\n!pip install py7zr\nimport py7zr","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:04.731707Z","iopub.execute_input":"2022-02-18T15:07:04.73197Z","iopub.status.idle":"2022-02-18T15:07:10.6746Z","shell.execute_reply.started":"2022-02-18T15:07:04.731945Z","shell.execute_reply":"2022-02-18T15:07:10.673376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Load the Cifar-10 Dataset from KERAS**\n* 50,000 row data for training dataset, \n* 10,000 row data for testing dataset.\n* Those images are indeed square with 32Ã—32 pixels and color, with three channels.","metadata":{}},{"cell_type":"code","source":"# Import CIFAR 10 dataset\nfrom keras.datasets import cifar10\n\n# Load Dataset\n(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n\n# Summarize Loaded Dataset\nprint('Train data: X=%s, y=%s' % (x_train.shape, y_train.shape))\nprint('Test data: X=%s, y=%s' % (x_test.shape, y_test.shape))\n\n# Plot first nine images\nfor i in range(9):\n\t# define subplot\n\tpyplot.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tpyplot.imshow(x_train[i])\n# show the figure\npyplot.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:10.676885Z","iopub.execute_input":"2022-02-18T15:07:10.677273Z","iopub.status.idle":"2022-02-18T15:07:12.01086Z","shell.execute_reply.started":"2022-02-18T15:07:10.67723Z","shell.execute_reply":"2022-02-18T15:07:12.01005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.012709Z","iopub.execute_input":"2022-02-18T15:07:12.013087Z","iopub.status.idle":"2022-02-18T15:07:12.01891Z","shell.execute_reply.started":"2022-02-18T15:07:12.013049Z","shell.execute_reply":"2022-02-18T15:07:12.017939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.02088Z","iopub.execute_input":"2022-02-18T15:07:12.021286Z","iopub.status.idle":"2022-02-18T15:07:12.034012Z","shell.execute_reply.started":"2022-02-18T15:07:12.021249Z","shell.execute_reply":"2022-02-18T15:07:12.033207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Normalize Inputs**","metadata":{}},{"cell_type":"code","source":"#x_train2 = x_train/255\n#x_test2 = x_test/255\nx_train2 = x_train/255 - 0.5\nx_test2 = x_test/255 - 0.5\n\n# Convert class labels to one-hot encoded\ny_train2 = keras.utils.to_categorical(y_train)\ny_test2 = keras.utils.to_categorical(y_test)\n\n# Print labels\ny_train2","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.035276Z","iopub.execute_input":"2022-02-18T15:07:12.035643Z","iopub.status.idle":"2022-02-18T15:07:12.624658Z","shell.execute_reply.started":"2022-02-18T15:07:12.035607Z","shell.execute_reply":"2022-02-18T15:07:12.623636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Import Necessary CNN Building Blocks**","metadata":{}},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Activation, Dropout\nfrom keras.layers.advanced_activations import LeakyReLU","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.626148Z","iopub.execute_input":"2022-02-18T15:07:12.626506Z","iopub.status.idle":"2022-02-18T15:07:12.630932Z","shell.execute_reply.started":"2022-02-18T15:07:12.626468Z","shell.execute_reply":"2022-02-18T15:07:12.630043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Define/Create CNN Architecture**","metadata":{}},{"cell_type":"code","source":"# Create a model function\ndef make_model():\n    model = Sequential()\n\n    model.add(Conv2D(filters = 16, kernel_size = (3, 3), padding='same', input_shape=(32, 32, 3)))\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    \n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters = 32, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n    model.add(Conv2D(filters = 64, kernel_size = (3, 3), padding='same'))\n    model.add(LeakyReLU(0.1))\n\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Flatten())\n    \n    model.add(Dense(256))\n    model.add(LeakyReLU(0.1))\n\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(10))\n    model.add(Activation(\"softmax\"))\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.632386Z","iopub.execute_input":"2022-02-18T15:07:12.632903Z","iopub.status.idle":"2022-02-18T15:07:12.645443Z","shell.execute_reply.started":"2022-02-18T15:07:12.632857Z","shell.execute_reply":"2022-02-18T15:07:12.644373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Summarize a model\nmodel = make_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.648221Z","iopub.execute_input":"2022-02-18T15:07:12.648606Z","iopub.status.idle":"2022-02-18T15:07:12.751756Z","shell.execute_reply.started":"2022-02-18T15:07:12.648565Z","shell.execute_reply":"2022-02-18T15:07:12.750986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Define the loss function, the optimizer (Adamax) and the metrics**","metadata":{}},{"cell_type":"code","source":"INIT_LR = 3e-3 # Learning rate, is default schedule in all Keras Optimizers\nBATCH_SIZE = 32 # Batch size is a hyperparameter of gradient descent that controls the number of training samples\nEPOCHS = 30 # Number of epochs\n\n# Create object of deep learning model\nmodel = make_model()\n\n# Define the loss function, the optimizer (Adamax) and the metrics\nmodel.compile(\n    loss='categorical_crossentropy',  \n    optimizer=keras.optimizers.Nadam(lr=INIT_LR), \n    metrics=['accuracy']  # report accuracy during training\n)\n\n# Scheduler of learning rate (decay with epochs)\ndef lr_scheduler(epoch):\n    return INIT_LR * 0.9 ** epoch\n\n# Callback for printing of actual learning rate used by optimizer\nclass LrHistory(keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs={}):\n        print(\"Learning rate:\", K.get_value(model.optimizer.lr))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.754219Z","iopub.execute_input":"2022-02-18T15:07:12.754473Z","iopub.status.idle":"2022-02-18T15:07:12.845696Z","shell.execute_reply.started":"2022-02-18T15:07:12.754448Z","shell.execute_reply":"2022-02-18T15:07:12.844919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Check if GPU accelerator is enabled in Kaggle**","metadata":{}},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.846778Z","iopub.execute_input":"2022-02-18T15:07:12.847092Z","iopub.status.idle":"2022-02-18T15:07:12.855592Z","shell.execute_reply.started":"2022-02-18T15:07:12.847059Z","shell.execute_reply":"2022-02-18T15:07:12.85473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Fit the Deep Learning Model**","metadata":{}},{"cell_type":"code","source":"import tensorflow_addons as tfa\ntqdm_callback = tfa.callbacks.TQDMProgressBar()\n\nmodel.fit(\n    x_train2, y_train2,  # Prepared data\n    batch_size=BATCH_SIZE,\n    epochs=EPOCHS,\n    callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler), \n               LrHistory(), \n               tqdm_callback],\n    shuffle=True,\n    verbose=0,\n    initial_epoch=0\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:07:12.856611Z","iopub.execute_input":"2022-02-18T15:07:12.856939Z","iopub.status.idle":"2022-02-18T15:11:22.828298Z","shell.execute_reply.started":"2022-02-18T15:07:12.856906Z","shell.execute_reply":"2022-02-18T15:11:22.827471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **# Predict New Samples**","metadata":{}},{"cell_type":"code","source":"# Predict using testing data without labels/classes\ny_pred_test = model.predict(x_test2)\ny_pred_test_classes = np.argmax(y_pred_test, axis=1) # Change to normal classes\ny_pred_test_classes","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:11:22.829672Z","iopub.execute_input":"2022-02-18T15:11:22.830229Z","iopub.status.idle":"2022-02-18T15:11:23.569896Z","shell.execute_reply.started":"2022-02-18T15:11:22.830177Z","shell.execute_reply":"2022-02-18T15:11:23.569086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the same format for actual classes\ny_actual_test_classes = np.argmax(y_test2, axis=1) # Change to normal classes\ny_actual_test_classes","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:11:23.571276Z","iopub.execute_input":"2022-02-18T15:11:23.571632Z","iopub.status.idle":"2022-02-18T15:11:23.579229Z","shell.execute_reply.started":"2022-02-18T15:11:23.571593Z","shell.execute_reply":"2022-02-18T15:11:23.578133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##########################################################\n# MULTI-CLASS CONFUSION MATRIX FOR EACH CLASS\n##########################################################\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom math import sqrt\n\n# Actual and predicted classes\nlst_actual_class = y_actual_test_classes\nlst_predicted_class = y_pred_test_classes\n\n# Class = Label 0 to 9\nlst_classes = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\n# Compute multi-class confusion matrix\narr_out_matrix = multilabel_confusion_matrix(lst_actual_class, lst_predicted_class, labels=lst_classes)\n\n# Temp store results\nstore_sens = [];\nstore_spec = [];\nstore_acc = [];\nstore_bal_acc = [];\nstore_prec = [];\nstore_fscore = [];\nstore_mcc = [];\nfor no_class in range(len(lst_classes)):\n    arr_data = arr_out_matrix[no_class];\n    print(\"Print Class: {0}\".format(no_class));\n\n    tp = arr_data[1][1]\n    fp = arr_data[0][1]\n    tn = arr_data[0][0]\n    fn = arr_data[1][0]\n    \n    sensitivity = round(tp/(tp+fn), 3);\n    specificity = round(tn/(tn+fp), 3);\n    accuracy = round((tp+tn)/(tp+fp+tn+fn), 3);\n    balanced_accuracy = round((sensitivity+specificity)/2, 3);\n    precision = round(tp/(tp+fp), 3);\n    f1Score = round((2*tp/(2*tp + fp + fn)), 3);\n    x = (tp+fp) * (tp+fn) * (tn+fp) * (tn+fn)\n    MCC = round(((tp * tn) - (fp * fn)) / sqrt(x), 3)\n    store_sens.append(sensitivity);\n    store_spec.append(specificity);\n    store_acc.append(accuracy);\n    store_bal_acc.append(balanced_accuracy);\n    store_prec.append(precision);\n    store_fscore.append(f1Score);\n    store_mcc.append(MCC);\n    print(\"TP={0}, FP={1}, TN={2}, FN={3}\".format(tp, fp, tn, fn));\n    print(\"Sensitivity: {0}\".format(sensitivity));\n    print(\"Specificity: {0}\".format(specificity));\n    print(\"Accuracy: {0}\".format(accuracy));\n    print(\"Balanced Accuracy: {0}\".format(balanced_accuracy));\n    print(\"Precision: {0}\".format(precision));\n    print(\"F1-Score: {0}\".format(f1Score));\n    print(\"MCC: {0}\\n\".format(MCC));","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:11:23.580818Z","iopub.execute_input":"2022-02-18T15:11:23.581191Z","iopub.status.idle":"2022-02-18T15:11:23.61397Z","shell.execute_reply.started":"2022-02-18T15:11:23.58114Z","shell.execute_reply":"2022-02-18T15:11:23.613213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##########################################################\n# OVERALL - FINAL PERFORMANCE PREDICTION \n##########################################################\n\nprint(\"Overall Performance Prediction:\");\nprint(\"Sensitivity: {0}%\".format(round(mean(store_sens)*100, 4)));\nprint(\"Specificity: {0}%\".format(round(mean(store_spec)*100, 4)));\nprint(\"Accuracy: {0}%\".format(round(mean(store_acc)*100, 4)));\nprint(\"Balanced Accuracy: {0}%\".format(round(mean(store_bal_acc)*100, 4)));\nprint(\"Precision: {0}%\".format(round(mean(store_prec)*100, 4)));\nprint(\"F1-Score: {0}%\".format(round(mean(store_fscore)*100, 4)))\nprint(\"MCC: {0}\\n\".format(round(mean(store_mcc), 4)))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:11:23.616513Z","iopub.execute_input":"2022-02-18T15:11:23.616757Z","iopub.status.idle":"2022-02-18T15:11:23.626711Z","shell.execute_reply.started":"2022-02-18T15:11:23.616733Z","shell.execute_reply":"2022-02-18T15:11:23.625774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}