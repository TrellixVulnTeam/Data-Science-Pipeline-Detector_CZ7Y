{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-18T15:18:17.6261Z","iopub.execute_input":"2022-02-18T15:18:17.626751Z","iopub.status.idle":"2022-02-18T15:18:17.636723Z","shell.execute_reply.started":"2022-02-18T15:18:17.626713Z","shell.execute_reply":"2022-02-18T15:18:17.635915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A - Préparation de datasets (train et test)\n# A-1- Extraction des datasets\n# A-1-1- Extrain de dataset train.7z\n\n!pip install py7zr\n!python -m py7zr x ../input/cifar-10/train.7z /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:18:25.485484Z","iopub.execute_input":"2022-02-18T15:18:25.486017Z","iopub.status.idle":"2022-02-18T15:19:20.693643Z","shell.execute_reply.started":"2022-02-18T15:18:25.485977Z","shell.execute_reply":"2022-02-18T15:19:20.692746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A-1-2- Extrain de dataset test.7z\n!python -m py7zr x ../input/cifar-10/test.7z /kaggle/working/","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:20:47.955581Z","iopub.execute_input":"2022-02-18T15:20:47.956037Z","iopub.status.idle":"2022-02-18T15:34:36.101676Z","shell.execute_reply.started":"2022-02-18T15:20:47.955996Z","shell.execute_reply":"2022-02-18T15:34:36.100721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# A-2- Création de dataset\nimport glob\nimport os\nimport cv2\nimport numpy as np \n\n   #nombre d'images de train data\ntrain_images_path = \"/kaggle/working/train\"\nnum_of_train_images= len(glob.glob(train_images_path+\"/*\"))\nprint(\"Le nombre d'images de train data est\",num_of_train_images)\n\n   #nombre d'images de test data\ntest_images_path = \"/kaggle/working/test\"    \nnum_of_test_images= len(glob.glob(test_images_path+\"/*\"))\nprint(\"Le nombre d'images de test data est\", num_of_test_images)\n\n    # Ajouter les images de train  au dataset créée\ntrain_images = [[]]*num_of_train_images\nfor dir_name, _, filenames in os.walk('/kaggle/working/train'):\n    for filename in filenames:\n        image_index = int(filename.split(\".\")[0])-1\n        img = cv2.imread(os.path.join(dir_name,filename))\n        train_images[image_index] = img\n        \n     # Ajouter les images de test  au dataset créée\ntest_images = [[]]*num_of_test_images\nfor dir_name, _, filenames in os.walk('/kaggle/working/test'):\n    for filename in filenames:\n        image_index = int(filename.split(\".\")[0])-1\n        img = cv2.imread(os.path.join(dir_name,filename))\n        test_images[image_index] = img","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:38:32.138706Z","iopub.execute_input":"2022-02-18T15:38:32.139471Z","iopub.status.idle":"2022-02-18T15:39:06.799324Z","shell.execute_reply.started":"2022-02-18T15:38:32.139423Z","shell.execute_reply":"2022-02-18T15:39:06.798613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # normalisation des datasets \ntrain_images = np.asarray(train_images, dtype=float)/255\ntest_images = np.asarray(test_images, dtype=float)/255\ntrain_images[0]\n   #Enregistrement des datasets sous forme de matrices\nnp.save(\"../working/train_images.npy\", train_images)\nnp.save(\"../working/test_images.npy\", test_images)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:43:46.957037Z","iopub.execute_input":"2022-02-18T15:43:46.957311Z","iopub.status.idle":"2022-02-18T15:44:25.60808Z","shell.execute_reply.started":"2022-02-18T15:43:46.957281Z","shell.execute_reply":"2022-02-18T15:44:25.604765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"     #Vérifier le nombre d'image dans chaque data\nprint(\"train data:\",train_images.shape)\nprint(\"test data:\",test_images.shape)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-18T11:25:18.822154Z","iopub.execute_input":"2022-02-18T11:25:18.822739Z","iopub.status.idle":"2022-02-18T11:25:18.831189Z","shell.execute_reply.started":"2022-02-18T11:25:18.822696Z","shell.execute_reply":"2022-02-18T11:25:18.830372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"      # Affichage des dix premières images\nimport matplotlib.pyplot as plt\nimport pandas as pd\ntrain_labels=pd.read_csv(\"../input/cifar-10/trainLabels.csv\")\nfig=plt.figure(figsize=(8, 8))\ncolumns = 5\nrows = 2\nfor i in range(1, columns*rows +1):\n    img = train_images[i]\n    fig.add_subplot(rows, columns, i, title=[train_labels.label[i]])\n    plt.imshow(img)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T11:42:29.230608Z","iopub.execute_input":"2022-02-18T11:42:29.231819Z","iopub.status.idle":"2022-02-18T11:42:30.358395Z","shell.execute_reply.started":"2022-02-18T11:42:29.231765Z","shell.execute_reply":"2022-02-18T11:42:30.357424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    # L'augmentation de datasets\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import to_categorical\ndatagen = ImageDataGenerator(\n        rotation_range=0.3,  \n        zoom_range = 0.1,  \n        width_shift_range=0.1, \n        height_shift_range=0.1,\n        horizontal_flip=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T11:45:29.053891Z","iopub.execute_input":"2022-02-18T11:45:29.054287Z","iopub.status.idle":"2022-02-18T11:45:36.856994Z","shell.execute_reply.started":"2022-02-18T11:45:29.054251Z","shell.execute_reply":"2022-02-18T11:45:36.855943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# B - Création du modèle\nfrom tensorflow import keras\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import Sequential, datasets,models,layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D, DepthwiseConv2D, BatchNormalization\nfrom tensorflow.keras.models import load_model\n\n# B- 1- Création du modèle\nmodel=Sequential()\n\n# B-2- Création des couches \n       # La couche de convolution 1\nmodel.add(Conv2D(32, (3, 3), activation='relu', strides=(1,1), padding='same', input_shape=(32, 32, 3)))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu, depth_multiplier=3))\nmodel.add(Dropout(rate =0.1))\n    \n    \nmodel.add(Conv2D(64, (3, 3), activation='relu', strides=(2, 2), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu))\nmodel.add(Dropout(rate = 0.1))\n    \nmodel.add(Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu))\nmodel.add(Dropout(rate = 0.4))\n    \nmodel.add(Conv2D(128, (3, 3), activation='relu', strides=(1, 1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu))\n    \n    \nmodel.add(Conv2D(256, (3, 3), activation='relu', strides=(2, 2), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=(3,3), strides=(1, 1), padding='same', activation=keras.activations.relu))\n    \n    \n    \nmodel.add(Conv2D(512, (1, 1), activation='relu', strides=(2, 2), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(DepthwiseConv2D(kernel_size=(1,1), strides=(1, 1), padding='same', activation=keras.activations.relu))\nmodel.add(Dropout(rate = 0.4))\n    \nmodel.add(Flatten())\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Dense(2048, activation='relu'))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(rate = 0.4))\nmodel.add(Dense(10, activation='softmax'))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-18T12:52:03.194022Z","iopub.execute_input":"2022-02-18T12:52:03.19503Z","iopub.status.idle":"2022-02-18T12:52:03.875866Z","shell.execute_reply.started":"2022-02-18T12:52:03.194978Z","shell.execute_reply":"2022-02-18T12:52:03.87459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" # Afficher un résumé\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T12:53:42.224146Z","iopub.execute_input":"2022-02-18T12:53:42.225774Z","iopub.status.idle":"2022-02-18T12:53:42.250707Z","shell.execute_reply.started":"2022-02-18T12:53:42.225721Z","shell.execute_reply":"2022-02-18T12:53:42.24953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.python.client import device_lib\nprint(device_lib.list_local_devices())","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:17:03.095229Z","iopub.execute_input":"2022-02-18T15:17:03.095533Z","iopub.status.idle":"2022-02-18T15:17:09.45816Z","shell.execute_reply.started":"2022-02-18T15:17:03.095456Z","shell.execute_reply":"2022-02-18T15:17:09.457429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-18T15:08:03.461873Z","iopub.execute_input":"2022-02-18T15:08:03.46219Z","iopub.status.idle":"2022-02-18T15:08:03.874727Z","shell.execute_reply.started":"2022-02-18T15:08:03.462158Z","shell.execute_reply":"2022-02-18T15:08:03.873567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# C- L'entraînement du modèle \nlabels_dict =  {0:'airplane', 1:'automobile', 2:'bird', 3:'cat', 4:'deer', 5:'dog', 6:'frog', 7:'horse', 8:'ship', 9:'truck'}\nlabels_dict_reversed = {'airplane':0, 'automobile':1, 'bird':2, 'cat':3, 'deer':4, 'dog':5, 'frog':6, 'horse':7, 'ship':8, 'truck':9}\ntrain_labels['Category'] = train_labels.label.map(labels_dict_reversed)\ntrain_labels_categories = keras.utils.to_categorical(train_labels.Category, num_classes)#.astype('uint8')\nx_train, x_val, y_train, y_val = train_test_split(train_images, train_labels_categories, random_state=0, test_size=0.05)    \n    \n    \n    # Compiler le modèle\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    # Conserver le meilleur modèle\nmcp_save = ModelCheckpoint('../working/best_model', save_best_only=True, monitor='val_accuracy', mode='max')\n    # Entraînement du modèle\n    \nnum_of_epochs = 5\nbatch_size = 64 \nmodel.fit(datagen.flow(x_train, y_train, batch_size=batch_size), validation_data=(x_val, y_val), callbacks=[mcp_save], epochs=num_of_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T14:09:24.201633Z","iopub.execute_input":"2022-02-18T14:09:24.202526Z","iopub.status.idle":"2022-02-18T14:09:24.30003Z","shell.execute_reply.started":"2022-02-18T14:09:24.202414Z","shell.execute_reply":"2022-02-18T14:09:24.298896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-18T12:56:54.647581Z","iopub.execute_input":"2022-02-18T12:56:54.647918Z","iopub.status.idle":"2022-02-18T12:56:56.046043Z","shell.execute_reply.started":"2022-02-18T12:56:54.647888Z","shell.execute_reply":"2022-02-18T12:56:56.044957Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-02-12T18:56:17.277409Z","iopub.execute_input":"2022-02-12T18:56:17.27827Z","iopub.status.idle":"2022-02-12T18:56:26.603822Z","shell.execute_reply.started":"2022-02-12T18:56:17.278226Z","shell.execute_reply":"2022-02-12T18:56:26.600925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}