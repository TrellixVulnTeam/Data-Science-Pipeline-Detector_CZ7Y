{"cells":[{"metadata":{"papermill":{"duration":0.023291,"end_time":"2020-09-11T21:22:52.945341","exception":false,"start_time":"2020-09-11T21:22:52.92205","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# ****importing all libraries****"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-09-11T21:22:53.004286Z","iopub.status.busy":"2020-09-11T21:22:53.003456Z","iopub.status.idle":"2020-09-11T21:22:59.91625Z","shell.execute_reply":"2020-09-11T21:22:59.916778Z"},"papermill":{"duration":6.949389,"end_time":"2020-09-11T21:22:59.916945","exception":false,"start_time":"2020-09-11T21:22:52.967556","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport re\n%pylab inline\nimport matplotlib.image as mpimg\nfrom keras.models import  Sequential\nfrom keras.layers.core import  Lambda , Dense, Flatten, Dropout\nfrom keras.callbacks import EarlyStopping\nfrom keras.layers import BatchNormalization, Convolution2D , MaxPooling2D\n\nfrom keras.preprocessing import image\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.02444,"end_time":"2020-09-11T21:22:59.965881","exception":false,"start_time":"2020-09-11T21:22:59.941441","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Loading training and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\nprint('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint(x_train.shape[0], 'taken for training the model')\nprint(x_test.shape[0], 'taken for testing')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# this is a multiclass classification problem\n*Here multiple classes are present in the y_train part of dataset*"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)\nprint('classes ', y_train.ravel())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfig, ax = plt.subplots(1,2,figsize=(15,5)) \n\nsns.countplot(y_train.ravel(), ax=ax[0] )\nax[0].set_title(\"Visualization of training dataset\", y=1.01, fontsize=20)\nax[0].set_ylabel(\"Name of pictures\", labelpad=15)\nax[0].set_xlabel(\"classes of pictures\", labelpad=15)\n\nsns.countplot(y_test.ravel(), ax=ax[1] )\nplt.title(\"Visualization of the test dataset\", y=1.01, fontsize=20)\nplt.ylabel(\"Name of pictures\", labelpad=15)\nplt.xlabel(\"classes of pictures\", labelpad=15)\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.028602,"end_time":"2020-09-11T21:23:05.202669","exception":false,"start_time":"2020-09-11T21:23:05.174067","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Convert train datset to (num_images, img_rows, img_cols) format"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:05.268461Z","iopub.status.busy":"2020-09-11T21:23:05.267727Z","iopub.status.idle":"2020-09-11T21:23:05.273796Z","shell.execute_reply":"2020-09-11T21:23:05.274258Z"},"papermill":{"duration":0.04347,"end_time":"2020-09-11T21:23:05.274385","exception":false,"start_time":"2020-09-11T21:23:05.230915","status":"completed"},"tags":[]},"cell_type":"markdown","source":"X_train_dataset = X_train_dataset.reshape(\n*                         X_train_dataset.shape[0], 28, 28)\n* print(X_train_dataset.shape)\n* print(y_train_dataset.shape)\n\nx_test_dataset = x_test_dataset.reshape(x_test_dataset.shape[0], 28, 28)\nx_test_dataset.shape"},{"metadata":{"papermill":{"duration":0.028166,"end_time":"2020-09-11T21:23:05.330052","exception":false,"start_time":"2020-09-11T21:23:05.301886","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Visualizing the dataset"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:05.392578Z","iopub.status.busy":"2020-09-11T21:23:05.391891Z","iopub.status.idle":"2020-09-11T21:23:06.150952Z","shell.execute_reply":"2020-09-11T21:23:06.151546Z"},"papermill":{"duration":0.79339,"end_time":"2020-09-11T21:23:06.15172","exception":false,"start_time":"2020-09-11T21:23:05.35833","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"\nfig=plt.figure(figsize=(10, 10))\ncolumns = 3\nrows = 2\nfor i in range(1, columns*rows +1):\n    fig.add_subplot(rows, columns, i)\n    img = x_train[i]\n    plt.imshow(img)\n    # if want to show gray image\n    # plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n    plt.title(y_train[i])\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.027461,"end_time":"2020-09-11T21:23:06.208192","exception":false,"start_time":"2020-09-11T21:23:06.180731","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data type conversion\ni am converting data to float as it's efficient for computation"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:06.271443Z","iopub.status.busy":"2020-09-11T21:23:06.270802Z","iopub.status.idle":"2020-09-11T21:23:06.27704Z","shell.execute_reply":"2020-09-11T21:23:06.276434Z"},"papermill":{"duration":0.041065,"end_time":"2020-09-11T21:23:06.277143","exception":false,"start_time":"2020-09-11T21:23:06.236078","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')\n\nx_test.shape","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.032159,"end_time":"2020-09-11T21:23:07.091381","exception":false,"start_time":"2020-09-11T21:23:07.059222","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Preprocessing images"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:07.162461Z","iopub.status.busy":"2020-09-11T21:23:07.161192Z","iopub.status.idle":"2020-09-11T21:23:07.256202Z","shell.execute_reply":"2020-09-11T21:23:07.255624Z"},"papermill":{"duration":0.13351,"end_time":"2020-09-11T21:23:07.256316","exception":false,"start_time":"2020-09-11T21:23:07.122806","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"mean_px = x_train.mean().astype(np.float32)\nstd_px = x_train.std().astype(np.float32)\n\ndef standardize(x): \n    return (x-mean_px)/std_px","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.033447,"end_time":"2020-09-11T21:23:07.393436","exception":false,"start_time":"2020-09-11T21:23:07.359989","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Transform categorical data\n**Transforming all the labels into dummy variables as it is a multiclass classification problem.**"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Normalize\n\nx_train, x_test = x_train / 255.0, x_test / 255.0","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:07.460822Z","iopub.status.busy":"2020-09-11T21:23:07.45995Z","iopub.status.idle":"2020-09-11T21:23:07.477265Z","shell.execute_reply":"2020-09-11T21:23:07.476646Z"},"papermill":{"duration":0.054433,"end_time":"2020-09-11T21:23:07.477356","exception":false,"start_time":"2020-09-11T21:23:07.422923","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\n\nprint(y_train[:3])\n\ny_train = to_categorical(y_train, 10)\ny_test = to_categorical(y_test, 10)\n\nprint(y_train[:3])","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:07.543788Z","iopub.status.busy":"2020-09-11T21:23:07.5429Z","iopub.status.idle":"2020-09-11T21:23:07.546257Z","shell.execute_reply":"2020-09-11T21:23:07.545746Z"},"papermill":{"duration":0.037915,"end_time":"2020-09-11T21:23:07.546361","exception":false,"start_time":"2020-09-11T21:23:07.508446","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# fixing random seed for reproducibility\nseed = 43\nnp.random.seed(seed)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.030352,"end_time":"2020-09-11T21:23:07.6078","exception":false,"start_time":"2020-09-11T21:23:07.577448","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Convolutional Neural Network\n> making change in images so that the classifier can learn more uniquely"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:07.677825Z","iopub.status.busy":"2020-09-11T21:23:07.676943Z","iopub.status.idle":"2020-09-11T21:23:07.731397Z","shell.execute_reply":"2020-09-11T21:23:07.730801Z"},"papermill":{"duration":0.092267,"end_time":"2020-09-11T21:23:07.731532","exception":false,"start_time":"2020-09-11T21:23:07.639265","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"gen = image.ImageDataGenerator()\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, \n        width_shift_range=0.1,  \n        height_shift_range=0.1, \n        horizontal_flip=False,  \n        vertical_flip=False)\n\ndatagen.fit(x_train)\n","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.059178,"end_time":"2020-09-11T21:23:08.431102","exception":false,"start_time":"2020-09-11T21:23:08.371924","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# **Building CNN model**"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:08.539469Z","iopub.status.busy":"2020-09-11T21:23:08.538748Z","iopub.status.idle":"2020-09-11T21:23:08.545036Z","shell.execute_reply":"2020-09-11T21:23:08.545995Z"},"papermill":{"duration":0.061808,"end_time":"2020-09-11T21:23:08.546143","exception":false,"start_time":"2020-09-11T21:23:08.484335","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"#define the convnet\nfrom keras.layers import Conv2D, MaxPool2D\nfrom keras.layers import Dense, Dropout, Activation, Flatten\n\nfrom keras.layers import Convolution2D, MaxPooling2D\n\nmodel6 = Sequential()\nmodel6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(32, 32, 3)))\nmodel6.add(BatchNormalization())\nmodel6.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(MaxPool2D((2, 2)))\nmodel6.add(Dropout(0.2))\nmodel6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(MaxPool2D((2, 2)))\nmodel6.add(Dropout(0.3))\nmodel6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\nmodel6.add(BatchNormalization())\nmodel6.add(MaxPool2D((2, 2)))\nmodel6.add(Dropout(0.4))\nmodel6.add(Flatten())\nmodel6.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\nmodel6.add(BatchNormalization())\nmodel6.add(Dropout(0.5))\nmodel6.add(Dense(10, activation='softmax'))\n# compile model\n# opt = SGD(lr=0.001, momentum=0.9)\nmodel6.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel = model6\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.04086,"end_time":"2020-09-11T21:23:08.631195","exception":false,"start_time":"2020-09-11T21:23:08.590335","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**compiling the model**"},{"metadata":{},"cell_type":"markdown","source":"*In keras, fit() is much similar to sklearn's fit method, where you pass array of features as x values and target as y values. You pass your whole dataset at once in fit method. Also, use it if you can load whole data into your memory (small dataset).*\n\nIn fit_generator(), you don't pass the x and y directly, instead they come from a generator. As it is written in keras documentation, generator is used when you want to avoid duplicate data when using multiprocessing. "},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:08.7189Z","iopub.status.busy":"2020-09-11T21:23:08.718177Z","iopub.status.idle":"2020-09-11T21:23:32.693986Z","shell.execute_reply":"2020-09-11T21:23:32.694459Z"},"papermill":{"duration":24.01431,"end_time":"2020-09-11T21:23:32.69468","exception":false,"start_time":"2020-09-11T21:23:08.68037","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"opt = tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n\nhistory = model.fit_generator(datagen.flow(x_train, y_train,\n                                batch_size=64),\n                                epochs=40,\n                              steps_per_epoch=int(x_train.shape[0] / 64),\n                                validation_data=(x_test, y_test),\n                                workers=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotmodelhistory(history): \n    fig, axs = plt.subplots(1,2,figsize=(15,5)) \n    # summarize history for accuracy\n    axs[0].plot(history.history['accuracy']) \n    axs[0].plot(history.history['val_accuracy']) \n    axs[0].set_title('Model Accuracy')\n    axs[0].set_ylabel('Accuracy') \n    axs[0].set_xlabel('Epoch')\n    axs[0].legend(['train', 'validate'], loc='upper left')\n    # summarize history for loss\n    axs[1].plot(history.history['loss']) \n    axs[1].plot(history.history['val_loss']) \n    axs[1].set_title('Model Loss')\n    axs[1].set_ylabel('Loss') \n    axs[1].set_xlabel('Epoch')\n    axs[1].legend(['train', 'validate'], loc='upper left')\n    plt.show()\n\n\nplotmodelhistory(history)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluating the model"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:32.941773Z","iopub.status.busy":"2020-09-11T21:23:32.940752Z","iopub.status.idle":"2020-09-11T21:23:33.324535Z","shell.execute_reply":"2020-09-11T21:23:33.32334Z"},"papermill":{"duration":0.50899,"end_time":"2020-09-11T21:23:33.324673","exception":false,"start_time":"2020-09-11T21:23:32.815683","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# Predict the values from the validation dataset\nY_pred = model.predict(x_test)\n# Convert predictions classes to one hot vectors \nY_pred_classes = np.argmax(Y_pred,axis = 1)  \nY_pred_classes[:5]\n\nY_true = np.argmax(y_test, axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Y_pred_classes[:4])\nprint(Y_true[:4])","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.121623,"end_time":"2020-09-11T21:23:33.566642","exception":false,"start_time":"2020-09-11T21:23:33.445019","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# confusion matrix\n**calculating confusion matrix to get the false negative, false positive, true negative and true positive values predicted by the classfier.**"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:33.814067Z","iopub.status.busy":"2020-09-11T21:23:33.813136Z","iopub.status.idle":"2020-09-11T21:23:33.8269Z","shell.execute_reply":"2020-09-11T21:23:33.82615Z"},"papermill":{"duration":0.139336,"end_time":"2020-09-11T21:23:33.82702","exception":false,"start_time":"2020-09-11T21:23:33.687684","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n# compute the confusion matrix\nconfusion_mtx = confusion_matrix(Y_true, Y_pred_classes) \nconfusion_mtx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def heatmap(data, row_labels, col_labels, ax=None, cbar_kw={}, cbarlabel=\"\", **kwargs):\n    \"\"\"\n    Create a heatmap from a numpy array and two lists of labels.\n    \"\"\"\n    if not ax:\n        ax = plt.gca()\n\n    # Plot the heatmap\n    im = ax.imshow(data, **kwargs)\n\n    # Create colorbar\n    cbar = ax.figure.colorbar(im, ax=ax, **cbar_kw)\n    cbar.ax.set_ylabel(cbarlabel, rotation=-90, va=\"bottom\")\n\n    # Let the horizontal axes labeling appear on top.\n    ax.tick_params(top=True, bottom=False,\n                   labeltop=True, labelbottom=False)\n    # We want to show all ticks...\n    ax.set_xticks(np.arange(data.shape[1]))\n    ax.set_yticks(np.arange(data.shape[0]))\n    # ... and label them with the respective list entries.\n    ax.set_xticklabels(col_labels)\n    ax.set_yticklabels(row_labels)\n    \n    ax.set_xlabel('Predicted Label') \n    ax.set_ylabel('True Label')\n    \n    return im, cbar\n\ndef annotate_heatmap(im, data=None, fmt=\"d\", threshold=None):\n    \"\"\"\n    A function to annotate a heatmap.\n    \"\"\"\n    # Change the text's color depending on the data.\n    texts = []\n    for i in range(data.shape[0]):\n        for j in range(data.shape[1]):\n            text = im.axes.text(j, i, format(data[i, j], fmt), horizontalalignment=\"center\",\n                                 color=\"white\" if data[i, j] > thresh else \"black\")\n            texts.append(text)\n\n    return texts","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:34.092037Z","iopub.status.busy":"2020-09-11T21:23:34.091243Z","iopub.status.idle":"2020-09-11T21:23:34.721878Z","shell.execute_reply":"2020-09-11T21:23:34.721324Z"},"papermill":{"duration":0.765762,"end_time":"2020-09-11T21:23:34.721998","exception":false,"start_time":"2020-09-11T21:23:33.956236","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport itertools\nimport matplotlib.pyplot as plt\n\nlabels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', \n          'ship', 'truck']\n# Errors are difference between predicted labels and true labels\nerrors = (Y_pred_classes - Y_true != 0)\n\nY_pred_classes_errors = Y_pred_classes[errors]\nY_pred_errors = Y_pred[errors]\nY_true_errors = Y_true[errors]\nX_test_errors = x_test[errors]\n\ncm = confusion_matrix(Y_true, Y_pred_classes) \nthresh = cm.max() / 2.\n\nfig, ax = plt.subplots(figsize=(12,12))\nim, cbar = heatmap(cm, labels, labels, ax=ax,\n                   cmap=plt.cm.Blues, cbarlabel=\"count of predictions\")\ntexts = annotate_heatmap(im, data=cm, threshold=thresh)\n\nfig.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Classification report**"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(Y_true, Y_pred_classes))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**incorrect prediction**"},{"metadata":{"trusted":true},"cell_type":"code","source":"R = 2\nC = 4\nfig, axes = plt.subplots(R, C, figsize=(12,8))\naxes = axes.ravel()\n\nmisclassified_idx = np.where(Y_pred_classes != Y_true)[0]\nfor i in np.arange(0, R*C):\n    axes[i].imshow(x_test[misclassified_idx[i]])\n    axes[i].set_title(\"True: %s \\nPredicted: %s\" % (labels[Y_true[misclassified_idx[i]]], \n                                                  labels[Y_pred_classes[misclassified_idx[i]]]))\n    axes[i].axis('off')\n    plt.subplots_adjust(wspace=1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.128063,"end_time":"2020-09-11T21:23:34.975713","exception":false,"start_time":"2020-09-11T21:23:34.84765","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Predicting new value using the trained model.**"},{"metadata":{"execution":{"iopub.execute_input":"2020-09-11T21:23:35.237396Z","iopub.status.busy":"2020-09-11T21:23:35.23635Z","iopub.status.idle":"2020-09-11T21:23:36.843084Z","shell.execute_reply":"2020-09-11T21:23:36.843652Z"},"papermill":{"duration":1.738,"end_time":"2020-09-11T21:23:36.843817","exception":false,"start_time":"2020-09-11T21:23:35.105817","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize = (3,3))\ntest_image = np.expand_dims(x_test[26], axis=0)\ntest_result = model.predict_classes(test_image)\nplt.imshow(x_test[26])\ndict_key = test_result[0]\nplt.title(\"Predicted: {} \\nTrue Label: {}\".format(labels[dict_key], labels[Y_true[26]]))","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.133682,"end_time":"2020-09-11T21:23:37.112627","exception":false,"start_time":"2020-09-11T21:23:36.978945","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**saving the prediction to a csv file**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nsave_dir = os.path.join(os.getcwd(), 'saved_models')\nmodel_name = 'cifar10_trained_model.h5'\n\n# Save model and weights\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nmodel_path = os.path.join(save_dir, model_name)\nmodel.save(model_path)\nprint('Saved trained model at %s ' % model_path)\n\n# checking the model\nscores = model.evaluate(x_test, y_test, verbose=1)\nprint('Test loss:', scores[0])\nprint('Test accuracy:', scores[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred_classes[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install py7zr\nfrom py7zr import unpack_7zarchive\nimport shutil\nimport os\n\nshutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shutil.unpack_archive('/kaggle/input/cifar-10/test.7z', '/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dir = os.listdir(\"./test\")\ntest_dir_len = len(test_dir)\n\nprint(\".\\\\test:\\t\",test_dir_len)\nprint(\"files:\\t\\t\",test_dir[:3])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_generator = ImageDataGenerator(rescale=1./255.)\ntest_generator = test_data_generator.flow_from_directory(directory='/kaggle/working',\n            batch_size=64,\n            shuffle=False,color_mode='rgb',\n            target_size=(32,32),\n            class_mode=None)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_prediction = model.predict_generator(test_generator)\n\npredicted_class = np.argmax(test_prediction, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(predicted_class[:3])\npredicted_class.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission1 = [labels[i] for i in predicted_class]\n\nsubmission = pd.DataFrame({\"id\": list(range(1, len(predicted_class)+1)),\n                          \"label\": submission1})\n\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var = pd.read_csv(\"./submission.csv\")\nvar.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"var.head(101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.image as mpimg\nfig = plt.figure(figsize = (3,3))\nimg = mpimg.imread(\"/kaggle/working/test/\"+ str(test_dir[1]))\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"index = 0    \nfig = plt.figure(figsize = (16,10))\nfor item in submission.values[50:70]:\n    index += 1\n    plt.subplot(5, 5, index)\n    test_path = '/kaggle/working/test/'+str(item[0])+'.png'\n    print(test_path)\n    test_image = image.load_img(test_path, target_size=(32,32))\n    plt.imshow(test_image)\n    plt.colorbar()\n    plt.grid(False)\n    plt.axis(\"off\")\n    \n    test_result = model.predict_classes(test_image)\n    dict_key = test_result[0]\n    plt.title(labels[dict_key])\nplt.show()\n\n\n# test_result = model.predict_classes(test_image)\n# plt.imshow(x_test[26])\n# dict_key = test_result[0]\n# plt.title(\"Predicted: {} \\nTrue Label: {}\".format(labels[dict_key], labels[Y_true[26]]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}