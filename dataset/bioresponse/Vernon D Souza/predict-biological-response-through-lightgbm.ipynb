{"cells":[{"metadata":{},"cell_type":"markdown","source":"<img src=\"https://www.pbiforum.net/mag/wp-content/uploads/2017/11/shutterstock_31312693.jpg\">","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- This project deals with the prediction of biological response based on molecular data in each column. \n\n- Drug development depends on the biological response with respect to many factors. Machine learning can help us understand if the drug makes a difference with regard to treatment. \n\n- Each column represents molecular data.\n\n- Since, they are many feature columns. The challenge would be to reduce the feature space.\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- Steps\n  - General understanding of the data\n  - Dimensionality Reduction through PCA and t-sne\n  - Check for covariate shift between training and test set\n  - Hyperparameter search through RandomizedSearchCV\n  - Feature Importance of the individual column data\n  - Implementation of model on test set","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Libraries","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \n\nimport pandas as pd \n\nimport os\n\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import confusion_matrix\n\nimport time\n\nfrom lightgbm import LGBMClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## References\n\n- https://towardsdatascience.com/why-you-are-using-t-sne-wrong-502412aab0c0\n- https://www.analyticsvidhya.com/blog/2017/07/covariate-shift-the-hidden-problem-of-real-world-data-science/\n- https://datatofish.com/confusion-matrix-python/","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Read Data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/bioresponse/train.csv\")\nprint(data.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Check for Missing values\n- Check name of columns\n- Find categorical and numerical columns","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Missing Values\",data.isnull().sum().sum())\nprint(\"Column names\",data.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# select the float columns\ndf_float = data.select_dtypes(include=[np.float])\nprint(\"Float Columns\",df_float.columns)\n\n# select int columns\ndf_int = data.select_dtypes(include=[np.int])\nprint(\"Int columns\",df_int.columns)\n\n# select object columns\ndf_object = data.select_dtypes(include=[object])\nprint(\"object columns\",df_object.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Find Distribution of the labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"g1 = sns.countplot(x=data[\"Activity\"])\n    \n\ng1.set_xticklabels(g1.get_xticklabels(),rotation=45)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Fair share of distribution for both labels. No need for sampling techniques","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Dimensionality Reduction","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- This is a high dimensional data set with too many dimensions. Let's use PCA and t-sne to see if we can extract features","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"Scaleddata = MinMaxScaler().fit_transform(data)\ndata = pd.DataFrame(Scaleddata,columns=data.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Let's look at the cumulative variance with repsect to the number of the components","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pca = PCA().fit(data)\nplt.plot(np.cumsum(pca.explained_variance_ratio_))\nplt.xlabel('number of components')\nplt.ylabel('cumulative explained variance');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- We need 500 components to describe 95 - 100 % of the variance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reduce dimensionality through PCA\n\ny = data[\"Activity\"]\nX = data.drop(columns=['Activity'])\n\npca = PCA(n_components=750)\nX_pca = pca.fit_transform(X) \n\n\n# Then reduce further with t-sne\ntsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=1000, learning_rate=200)\ntsne_results = tsne.fit_transform(X_pca[:,:])\n\ndf_tsne = pd.DataFrame(tsne_results, columns=['comp1', 'comp2'])\ndf_tsne['label'] = y[:]\nsns.scatterplot(x='comp1', y='comp2', data=df_tsne, hue='label')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- No clear seggregation of classes\n- Not a good idea to take PCA and t-sne data for prediction\n- We will have to utilize the entire dataset","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Check for covariate shift between training and testing data set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"<img src=\"https://cdn.analyticsvidhya.com/wp-content/uploads/2017/07/07230628/plot1.png\">\n\n\n\n\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"- In case of drug trials, there could be a difference between the testing environments.\n- This could lead to discrepancy while predicting test features, if the test features contain a different data distribution compared to training data\n- Below, let's check if the difference actually exists","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/bioresponse/train.csv\")\ntest = pd.read_csv(\"../input/bioresponse/test.csv\")\n\n\n# Label for predicting a strong adherence to the testing sets\ntrain['label'] = 0\ntest['label'] = 1\n\ntraining = train.drop('Activity',axis=1) \n\n# Combine testing and training sets\ncombine = training.append(test)\ny =combine['label']\ncombine.drop(columns = ['label'],inplace=True)\n\n\nmodel = LGBMClassifier(n_estimators = 50)\ndrop_list = []\n\nfor col in combine.columns:\n    score = cross_val_score(model,pd.DataFrame(combine[col]),y,cv=2,scoring='roc_auc')\n    #print(score)\n    if (np.mean(score) > 0.7):\n        drop_list.append(col)\n        print(\"Column with covariate shift:\", col)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if len(drop_list)==0: \n    print(\"No presence of covariate shift\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implementation with LightGBM and Hyperparameter search through RandomizedSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/bioresponse/train.csv\")\n\nX = data\nX = X.drop(columns='Activity')\n\ny = data['Activity']\ny = y.values\ny = y.reshape((len(y), 1))\n\n# split into train and test sets\nX_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=32)\n\ncolumns  = X_train.columns\n\n# Normalizing Column values\nfor col in columns:\n    MinMax = MinMaxScaler()\n    \n    X_train_arr = X_train[col].astype(float).values\n    X_test_arr = X_test[col].astype(float).values   \n        \n            \n    X_train_arr = MinMax.fit_transform(X_train_arr.reshape(-1,1))\n    X_test_arr = MinMax.transform(X_test_arr.reshape(-1,1))\n            \n    X_train[col]  = X_train_arr \n    X_test[col]   = X_test_arr\n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#fit_params={\"early_stopping_rounds\":100, \n           # \"eval_metric\" : 'binary_logloss', \n          #\"eval_set\" : [(X_test,y_test)],\n          #'eval_names': ['valid'],\n          #'verbose': 100,\n          #'categorical_feature': 'auto'}\n\n#param_test ={  'n_estimators': [50,100,200,400, 700, 1000],\n  #'colsample_bytree': [0.7, 0.8],\n  #'max_depth': [15,20,25],\n  #'num_leaves': [50, 100, 200],\n  #'reg_alpha': [1.1, 1.2, 1.3],\n #'reg_lambda': [1.1, 1.2, 1.3],\n# 'min_split_gain': [0.3, 0.4],\n#'subsample': [0.7, 0.8, 0.9],\n # 'subsample_freq': [20]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#clf = LGBMClassifier(random_state=314, silent=True, metric='None', n_jobs=2)\n#model = RandomizedSearchCV(\n   #estimator=clf, param_distributions=param_test, \n   # scoring='neg_log_loss',\n   # cv=3,\n   # refit=True,\n  # random_state=314,\n  # verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.fit(X_train, y_train, **fit_params)\n#print('Best score reached: {} with params: {} '.format(model.best_score_, model.best_params_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier(random_state=314, silent=True, n_jobs=2,subsample_freq = 20, subsample = 0.9, \n                       reg_lambda = 1.2, reg_alpha = 1.1,num_leaves= 200, n_estimators = 700, \n                       min_split_gain =  0.4, max_depth =  15, colsample_bytree = 0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train)\npred = model.predict_proba(X_test)\n\nprint(\"Log Loss Probability: \",log_loss(y_test,pred))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Plot confusion Matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(X_test)\ny_test = y_test.flatten()\n\n#print(np.shape(y_test))\n\ndata = {'y_Actual':    y_test,\n        'y_Predicted': pred\n        }\n\ndf = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])\nconfusion_matrix = pd.crosstab(df['y_Actual'], df['y_Predicted'], rownames=['Actual'], colnames=['Predicted'])\n\nsns.heatmap(confusion_matrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Feature Importance","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def plotImp(model, X , num = 20):\n    \n    feature_imp = pd.DataFrame({'Value':model.feature_importances_,'Feature':X.columns})\n    plt.figure(figsize=(100, 500))    \n    sns.set(font_scale = 5)\n    \n    #columns = feature_imp.sort_values(by=\"Value\",ascending=False)[0:num]['Feature'].to_list()\n    \n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n                                                        ascending=False)[0:num])\n    plt.title('LightGBM Feature imprtances')\n    plt.tight_layout()\n    \n    plt.show()\n    \n    \nplotImp(model, X_train , num =300)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Implement model on Test Set","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = pd.read_csv(\"../input/bioresponse/train.csv\")\nX_test =  pd.read_csv(\"../input/bioresponse/test.csv\")\n\ny_train = X_train[\"Activity\"]\n\nX_train.drop(columns=[\"Activity\"],inplace=True)\n\n\ncolumns  = X_train.columns\n\n# Normalizing column values\nfor col in columns:\n    MinMax = MinMaxScaler()\n    \n    X_train_arr = X_train[col].astype(float).values\n    X_test_arr = X_test[col].astype(float).values   \n        \n            \n    X_train_arr = MinMax.fit_transform(X_train_arr.reshape(-1,1))\n    X_test_arr = MinMax.transform(X_test_arr.reshape(-1,1))\n            \n    X_train[col]  = X_train_arr \n    X_test[col]   = X_test_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = LGBMClassifier(random_state=314, silent=True, n_jobs=2,subsample_freq = 20, subsample = 0.9, \n                       reg_lambda = 1.2, reg_alpha = 1.1,num_leaves= 200, n_estimators = 700, \n                       min_split_gain =  0.4, max_depth =  15, colsample_bytree = 0.8)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_prob = model.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Probability = predicted_prob[:,1]\nMoleculeId = np.array(range(1,len(X_test)+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame()\nsubmission[\"MoleculeId\"] = MoleculeId\nsubmission['PredictedProbability'] = Probability","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(submission)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"- Summary\n  - Feature D10, D8, D101,D104 seems to play a major role in prediction\n  - However, Feature elimination through feature importance seems to not improve the scores.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Would love to recieve feedback!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}