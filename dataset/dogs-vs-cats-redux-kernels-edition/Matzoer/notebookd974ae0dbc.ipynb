{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Kaggle link: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-30T13:53:59.870626Z","iopub.execute_input":"2021-12-30T13:53:59.870983Z","iopub.status.idle":"2021-12-30T13:53:59.882517Z","shell.execute_reply.started":"2021-12-30T13:53:59.870901Z","shell.execute_reply":"2021-12-30T13:53:59.881771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import everything needed","metadata":{}},{"cell_type":"code","source":"import zipfile\nimport glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:53:59.884226Z","iopub.execute_input":"2021-12-30T13:53:59.884613Z","iopub.status.idle":"2021-12-30T13:53:59.894125Z","shell.execute_reply.started":"2021-12-30T13:53:59.884559Z","shell.execute_reply":"2021-12-30T13:53:59.893464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unzip datasets","metadata":{}},{"cell_type":"code","source":"train_dir = 'train'\ntest_dir = 'test'\nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip') as train_zip:\n    train_zip.extractall('')\n    \nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip') as test_zip:\n    test_zip.extractall('')\ntrain_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:53:59.897083Z","iopub.execute_input":"2021-12-30T13:53:59.897321Z","iopub.status.idle":"2021-12-30T13:54:14.626975Z","shell.execute_reply.started":"2021-12-30T13:53:59.897296Z","shell.execute_reply":"2021-12-30T13:54:14.626226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [path.split('/')[-1].split('.')[0] for path in train_list]","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:14.628975Z","iopub.execute_input":"2021-12-30T13:54:14.629398Z","iopub.status.idle":"2021-12-30T13:54:14.647141Z","shell.execute_reply.started":"2021-12-30T13:54:14.629357Z","shell.execute_reply":"2021-12-30T13:54:14.646355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot random image with their label","metadata":{}},{"cell_type":"code","source":"random_idx = np.random.randint(1, len(train_list), size=9)\nfig, axes = plt.subplots(3, 3, figsize=(16, 12))\n\nfor idx, ax in enumerate(axes.ravel()):\n    img = Image.open(train_list[idx])\n    ax.set_title(labels[idx])\n    ax.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:14.648355Z","iopub.execute_input":"2021-12-30T13:54:14.64861Z","iopub.status.idle":"2021-12-30T13:54:16.058585Z","shell.execute_reply.started":"2021-12-30T13:54:14.648577Z","shell.execute_reply":"2021-12-30T13:54:16.054995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Sklearn to split data","metadata":{}},{"cell_type":"code","source":"train_list, valid_list = train_test_split(train_list, \n                                          test_size=0.2,\n                                          stratify=labels,\n                                          random_state=0)\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Validation Data: {len(valid_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:16.059861Z","iopub.execute_input":"2021-12-30T13:54:16.060629Z","iopub.status.idle":"2021-12-30T13:54:16.105441Z","shell.execute_reply.started":"2021-12-30T13:54:16.060591Z","shell.execute_reply":"2021-12-30T13:54:16.104758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will discuss this in more detail in a near future...","metadata":{}},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n        transforms.Resize(128), # makes it easier for the GPU\n        transforms.RandomResizedCrop(112),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor()])\n\nval_transforms = transforms.Compose([\n        transforms.Resize(128),\n        transforms.CenterCrop(112),\n        transforms.ToTensor()])\n\n\ntest_transforms = transforms.Compose([\n        transforms.Resize(128),\n        transforms.CenterCrop(112),\n        transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:16.106553Z","iopub.execute_input":"2021-12-30T13:54:16.106889Z","iopub.status.idle":"2021-12-30T13:54:16.113112Z","shell.execute_reply.started":"2021-12-30T13:54:16.106851Z","shell.execute_reply":"2021-12-30T13:54:16.112243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the dataset using PIL to read image","metadata":{}},{"cell_type":"code","source":"class CatsDogsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.file_list = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n        label = img_path.split(\"/\")[-1].split(\".\")[0]\n        label = 1 if label == \"dog\" else 0\n        return img_transformed, label","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:16.114697Z","iopub.execute_input":"2021-12-30T13:54:16.114953Z","iopub.status.idle":"2021-12-30T13:54:16.122576Z","shell.execute_reply.started":"2021-12-30T13:54:16.11492Z","shell.execute_reply":"2021-12-30T13:54:16.121787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = CatsDogsDataset(train_list, transform=train_transforms)\nvalid_data = CatsDogsDataset(valid_list, transform=test_transforms)\ntest_data = CatsDogsDataset(test_list, transform=test_transforms)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:16.123942Z","iopub.execute_input":"2021-12-30T13:54:16.124259Z","iopub.status.idle":"2021-12-30T13:54:16.134731Z","shell.execute_reply.started":"2021-12-30T13:54:16.12422Z","shell.execute_reply":"2021-12-30T13:54:16.133976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create dataloader, you can modify the batch size if needed","metadata":{}},{"cell_type":"code","source":"batch_size = 100\ntrain_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(dataset=valid_data, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T15:49:49.742874Z","iopub.execute_input":"2021-12-30T15:49:49.743146Z","iopub.status.idle":"2021-12-30T15:49:50.455805Z","shell.execute_reply.started":"2021-12-30T15:49:49.743114Z","shell.execute_reply":"2021-12-30T15:49:50.455139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_my_layer(m):\n    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))\n    torch.nn.init.constant(m.bias, 0)\n    return m\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.relu = nn.ReLU()\n        self.conv1 = init_my_layer(nn.Conv2d(3, 64, 3, padding=1))\n        self.conv2 = init_my_layer(nn.Conv2d(64, 128, 3, padding=1))\n        self.conv3 = init_my_layer(nn.Conv2d(128, 256, 3, padding=1))\n        self.conv4 = init_my_layer(nn.Conv2d(256, 512, 3))\n        self.conv5 = init_my_layer(nn.Conv2d(512, 512, 3))\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.ln1 = init_my_layer(nn.Linear(2048, 256))\n        self.ln2 = init_my_layer(nn.Linear(256, 2))\n        self.drop = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.max_pool(self.relu(self.conv1(x)))\n        x = self.max_pool(self.relu(self.conv2(x)))\n        x = self.max_pool(self.relu(self.conv3(x)))\n        x = self.max_pool(self.relu(self.conv4(x)))\n        x = self.max_pool(self.relu(self.conv5(x)))\n        x = x.reshape(x.size(0), -1)\n        x = self.drop(self.relu(self.ln1(x)))\n        return self.ln2(x)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:16.148881Z","iopub.execute_input":"2021-12-30T13:54:16.149081Z","iopub.status.idle":"2021-12-30T13:54:16.161826Z","shell.execute_reply.started":"2021-12-30T13:54:16.149051Z","shell.execute_reply":"2021-12-30T13:54:16.161027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel = Net()\nmodel.to(device)\nmodel.train()","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:16.163152Z","iopub.execute_input":"2021-12-30T13:54:16.16354Z","iopub.status.idle":"2021-12-30T13:54:16.242901Z","shell.execute_reply.started":"2021-12-30T13:54:16.163503Z","shell.execute_reply":"2021-12-30T13:54:16.242241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n#wandb.init(project='Dogs_vs_Cats', save_code=True)\nwandb.init(mode=\"disabled\")\nwandb.config.epochs = 50\nwandb.config['learning_rate'] = 5e-2\nwandb.config['weight_decay'] = 1e-3","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:16.244206Z","iopub.execute_input":"2021-12-30T13:54:16.244666Z","iopub.status.idle":"2021-12-30T13:54:28.031746Z","shell.execute_reply.started":"2021-12-30T13:54:16.24463Z","shell.execute_reply":"2021-12-30T13:54:28.03087Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=wandb.config['learning_rate'])\n\nfor i in range(wandb.config.epochs):\n    train_loss = 0\n    train_cor = 0\n    total = 0\n    for X, y in train_loader:\n        X, y = X.to(device), y.to(device)\n        predictions = model(X)\n        train_loss = criterion(predictions, y)\n        optimizer.zero_grad()\n        train_loss.backward()\n        optimizer.step()\n        \n        _, predictions = torch.max(predictions, 1)\n        train_cor += torch.sum(predictions == y)\n        total += len(y)\n        if total % batch_size == 0:\n            wandb.log({'training_loss': train_loss, 'training_accuracy': (train_cor / total)})\n    val_loss = 0\n    val_cor = 0\n    with torch.no_grad():\n        total = 0\n        for X, y in val_loader:\n            X, y = X.to(device), y.to(device)\n            predictions = model(X)\n            val_loss = criterion(predictions, y)\n            _, predictions = torch.max(predictions, 1)\n            val_cor += torch.sum(predictions == y)\n            total += len(y)\n            if total % batch_size == 0:\n                wandb.log({'validation_loss': val_loss, 'validation_accuracy': (val_cor / total)})","metadata":{"execution":{"iopub.status.busy":"2021-12-30T13:54:28.033696Z","iopub.execute_input":"2021-12-30T13:54:28.034208Z","iopub.status.idle":"2021-12-30T15:22:28.644362Z","shell.execute_reply.started":"2021-12-30T13:54:28.034168Z","shell.execute_reply":"2021-12-30T15:22:28.643661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dog_probs = []\nmodel.eval()\nwith torch.no_grad():\n    count = 0\n    for data, _ in test_loader:\n        data = data.to(device)\n        preds = model(data)\n        preds_list = F.softmax(preds, dim=1)[:, 1].tolist()\n        res = []\n        for prob in probs:\n            if prob > 0.95:\n                res.append(0.95)\n            elif prob < 0.05:\n                res.append(0.05)\n            else:\n                res.append(prob)\n        dog_probs += list(zip(list(np.arange(1+(batch_size*count), batch_size*(count+1)+1)), res))\n        count += 1\n\nidx = list(map(lambda x: x[0],dog_probs))\nprob = list(map(lambda x: x[1],dog_probs))\nsubmission = pd.DataFrame({'id':idx,'label':prob})\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2021-12-30T15:49:57.899143Z","iopub.execute_input":"2021-12-30T15:49:57.899956Z","iopub.status.idle":"2021-12-30T15:50:43.96835Z","shell.execute_reply.started":"2021-12-30T15:49:57.89991Z","shell.execute_reply":"2021-12-30T15:50:43.967568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'my_model.pt')","metadata":{"execution":{"iopub.status.busy":"2021-12-30T15:25:49.096855Z","iopub.execute_input":"2021-12-30T15:25:49.097134Z","iopub.status.idle":"2021-12-30T15:25:49.69888Z","shell.execute_reply.started":"2021-12-30T15:25:49.097096Z","shell.execute_reply":"2021-12-30T15:25:49.698167Z"},"trusted":true},"execution_count":null,"outputs":[]}]}