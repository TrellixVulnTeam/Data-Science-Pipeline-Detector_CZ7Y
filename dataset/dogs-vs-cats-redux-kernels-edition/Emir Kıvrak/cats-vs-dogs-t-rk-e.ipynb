{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-on,ly \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Zipleri çıkartma\n\n-> train ve test ziplerini kaggle/working subdirectorysine çıkartalım.\n\nnot : normalde kaggle de bu zip dosyalarını okuduğum zaman kendisi otomatik unzipliyor fakat, bu sefer ısrarla unziplemedi"},{"metadata":{"trusted":true},"cell_type":"code","source":"# çıkartma işlemi 30 sn sürebilir\nimport os\nimport zipfile\n\nUnzipped_data = ['train_base','test_base']\n[os.mkdir(path) for path in Unzipped_data]\nDataset = ['train','test']\nfor unzipped_data,dataset in zip(Unzipped_data,Dataset):\n    path = '../input/dogs-vs-cats-redux-kernels-edition/{}.zip'.format(dataset)\n    with zipfile.ZipFile(path,\"r\") as z:\n        z.extractall(unzipped_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('toplam train :' , len(os.listdir('/kaggle/working/train_base/train')))\n\nprint('Toplam test : ' , len(os.listdir('/kaggle/working/test_base/test')))\nbase_dir = './'\nbase_train_path = 'train_base/train'\nbase_test_path = 'test_base/test'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## jpeg dosyalarını train, validation olarak ikiye ayıracağız\n\n### o iki dizinin altına da cat ve dog olarak ayıracağız\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = './' # eğer başka bir dizinde oluşturmak istersek bunu değiştirebiliriz.\ntry:\n    train_dir = os.path.join(base_dir,'train')\n    os.mkdir(train_dir)\n    \n    validation_dir = os.path.join(base_dir,'validation')\n    os.mkdir(validation_dir)\n    \n    test_dir = os.path.join(base_dir,'test')\n    os.mkdir(test_dir)\n    \n    # üstte oluşturuğumz üç ana klasörün içine kedi ve köpek ayrı klasörler oluşturacağız\n    \n    train_cats_dir = os.path.join(train_dir,'cats')\n    os.mkdir(train_cats_dir)\n    \n    train_dogs_dir = os.path.join(train_dir,'dogs')\n    os.mkdir(train_dogs_dir)\n    \n    validation_cats_dir = os.path.join(validation_dir, 'cats')\n    os.mkdir(validation_cats_dir)\n\n    validation_dogs_dir = os.path.join(validation_dir, 'dogs')\n    os.mkdir(validation_dogs_dir)\n\n   # test_cats_dir = os.path.join(test_dir, 'cats')\n   # os.mkdir(test_cats_dir)\n\n   #test_dogs_dir = os.path.join(test_dir, 'dogs')\n   #os.mkdir(test_dogs_dir)\n    \nexcept FileExistsError:\n    pass","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('çalışma dizinimiz')\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# kitapta söylenen veri setinin büyüklüğü çok arttığından daha fazla veri ile eğitebilirim.\n# 3 bin kedi 3 bin köpek ve biner de validation alacağım.\nimport shutil\n\ntrain_dosya_adedi = 3000\nvalidation_dosya_adedi = 1000\ntest_dosya_adedi = 1000\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(train_dosya_adedi)] # ilk 3000 kedi train\nfor fname in fnames:\n    src = os.path.join(base_train_path,fname)\n    dst = os.path.join(train_cats_dir,fname)\n    shutil.copyfile(src,dst)\nprint('kedi train dosyaları kopyalandı' ,len(os.listdir(train_cats_dir)), 'adet dosya.')\n\nfnames = ['cat.{}.jpg'.format(i) for i in range(train_dosya_adedi,train_dosya_adedi+test_dosya_adedi)] # 3000 ile 4000 arasındakiler kedi validation\nfor fname in fnames:\n    src = os.path.join(base_train_path,fname)\n    dst = os.path.join(validation_cats_dir,fname)\n    shutil.copyfile(src,dst)\nprint('kedi validation dosyaları kopyalandı', len(os.listdir(validation_cats_dir)), 'adet dosya.')\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(train_dosya_adedi)]\nfor fname in fnames:\n    src = os.path.join(base_train_path,fname)\n    dst = os.path.join(train_dogs_dir,fname)\n    shutil.copy(src,dst)\n\nprint('köpek validation dosyaları kopyalandı', len(os.listdir(train_dogs_dir)), 'adet dosya.')\n\nfnames = ['dog.{}.jpg'.format(i) for i in range(train_dosya_adedi,train_dosya_adedi+test_dosya_adedi)]\nfor fname in fnames:\n    src = os.path.join(base_train_path,fname)\n    dst = os.path.join(validation_dogs_dir,fname)\n    shutil.copy(src,dst)\nprint('köpek validation dosyaları kopyalandı', len(os.listdir(validation_dogs_dir)), 'adet dosya.')\n\ntest_fnames = ['{}.jpg'. format(i) for i in range(1,test_dosya_adedi+1)]\n\nfor fname in test_fnames:\n    src = os.path.join('test_base/test',fname)\n    dst = os.path.join('test',fname)\n    shutil.copy(src,dst)\nprint('test_dosyaları_kopyalandı', len(os.listdir(test_dir)))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelimizi oluşturalım.\n\n***Model Mimarisi*** \n\n***3 adet relu kullanan conv+max pooling*** katmanı ardından ***1 adet relu kullanan dense katmanı*** ve son  olarak sınıflandırmayı yapabilmek için için bir ***sigmoid kullanan dense katmanı***\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# CNN modeli\nfrom keras import layers\nfrom keras import models\ndef build_model():\n    # kanal sayısı giderek artarken 32->128 nitelik haritası boyutu ufalıyor 150x150 -> 7x7\n    model = models.Sequential()\n    model.add(layers.Conv2D(32,(3,3),activation = 'relu', input_shape = (150,150,3)))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(64,(3,3), activation = 'relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Flatten())\n    \n    model.add(layers.Dense(512, activation = 'relu'))\n    \n    model.add(layers.Dense(1, activation = 'sigmoid'))\n    \n    return model\n\nmy_model = build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# her model oluşturduğumuzda inceletebileceğimiz bir fonksiyon yazalım \nfrom keras.utils.vis_utils import plot_model\n%pylab inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom matplotlib.pyplot import figure\n\ndef examine_model(model, show_shapes = True, display_png = True):\n    model.summary()\n    \n    print(\"/n\")\n    \n    plot_model(\n    model,\n    to_file=\"model.png\",\n    show_shapes=show_shapes,\n    show_layer_names=True,\n    rankdir=\"TB\",\n    expand_nested=False,\n    dpi=96,\n    )\n    \n    if(display_png):\n        figure(num=None, figsize=(8, 12), dpi=80, facecolor='w', edgecolor='k')\n        img = mpimg.imread('model.png')\n        imgplot = plt.imshow(img)\n        plt.show()\n        \n    \n    \nexamine_model(my_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeli derleyelim \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import optimizers\n# modelimizi derleyelim.\nmy_model.compile(loss = 'binary_crossentropy', #evet hayır seçimi olduğu için binary_crossentropy\n                 optimizer = optimizers.RMSprop(), # ?\n                 metrics = ['acc']\n                ) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## JPEG verilerin ön işlenmesi \n\n***jpeg verilerini sinir ağına yollayabilmek için uygun bir şekilde tensörlere çevirmeliyiz***\n\nbunun için keras.preproccesing'den imagedatagenerator üretecini kullanalım."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale = 1./255) # 1/255 ölçeklendirme\ntest_datagen = ImageDataGenerator(rescale = 1./255)\n\ntrain_generator = train_datagen.flow_from_directory('./train',\n                                                   target_size =(150,150),\n                                                   batch_size = 20,\n                                                   class_mode = 'binary')\n\nvalidation_generator = train_datagen.flow_from_directory('./validation',\n                                                   target_size =(150,150),\n                                                   batch_size = 20,\n                                                   class_mode = 'binary')\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# modeli eğitelim.\n\nbirinci parametre generator,\n\nsteps_per_epoch parametresi train veri setindeki veri sayısı bölü generatorun batch size'ı çünkü generatorler sonsuz döngüde calısıyor, ne zaman durduracağını modele bu şekilde söylüyoruz.\n\nbunlar validation veri seti için de validation_data ve validation_steps olarak geçmiş.\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# işlem süresinin kısalması için sağdaki üç nokta - > accelerator -> GPU\nsteps_per_epoch = (train_dosya_adedi * 2) / 20\nvalidation_steps = (validation_dosya_adedi * 2) / 20\nhistory = my_model.fit_generator(train_generator,\n                             steps_per_epoch = steps_per_epoch,\n                             epochs = 30,\n                             validation_data = validation_generator,\n                             validation_steps = validation_steps )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Eğitim kaybı ve başarımı çizdirelim"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='egitim basarimi')\nplt.plot(epochs, val_acc, 'b', label='dogrulama basarimi')\nplt.title('egitim ve dogrulama basarimi')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='egitim kaybı')\nplt.plot(epochs, val_loss, 'b', label='dogrulama kaybı')\nplt.title('Egitim ve dogrulama kaybı')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"yukarıdaki grafiklerde bir overfitting oluştuğunu görüyoruz.\noverfitting ile baş etmek için daha çeşitli veriler ekleyerek veri setimizi arttırabılır veya orijinal verilerden bir takım işlemler ile veriler üretmeye calisabiliriz.\n# Data augmentation ( veri arttırırımı)\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n      rotation_range=40, # derece cinsinden rastgele döndürme açısı\n      width_shift_range=0.2, # yatay ve dikey kaydırma oranları\n      height_shift_range=0.2,\n      shear_range=0.2, # burkma \n      zoom_range=0.2, # yakınlaştırma\n      horizontal_flip=True, # dikeyde resmi döndürme\n      fill_mode='nearest') # ortaya çıkan fazla görüntü noktalarını doldurma","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ön işleme yapacağımız modülü import edelim\nfrom keras.preprocessing import image\n\nfnames = [os.path.join(train_cats_dir, fname) for fname in os.listdir(train_cats_dir)]\n\n\nimg_path = fnames[11] #rasgele bir dosya \n\n\nimg = image.load_img(img_path, target_size=(150, 150))\n\n\nx = image.img_to_array(img)\n\n\nx = x.reshape((1,) + x.shape)\n\ni = 0\nfor batch in datagen.flow(x, batch_size=1):\n    plt.figure(i)\n    imgplot = plt.imshow(image.array_to_img(batch[0]))\n    i += 1\n    if i % 4 == 0: # 4 adet üretiyoruz.\n        break\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Dropout (iletim sönümü) Katmanı eklemek \n\naşırı öğrenme ile baş etmede veri çeşitlendirmenin yanı sıra dropout katmanları ekleyebiliriz."},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    # dense katmanlarından hemen önce bir dropout ekleyelim\n    model = models.Sequential()\n    model.add(layers.Conv2D(32,(3,3),activation = 'relu', input_shape = (150,150,3)))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(64,(3,3), activation = 'relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Conv2D(128,(3,3), activation = 'relu'))\n    model.add(layers.MaxPooling2D((2,2)))\n    \n    model.add(layers.Flatten())\n    \n    model.add(layers.Dropout(0.5)) # !!\n    \n    model.add(layers.Dense(512, activation = 'relu'))\n    \n    model.add(layers.Dense(1, activation = 'sigmoid'))\n    \n    return model\n\nmy_model = build_model()\n\nmy_model.compile(loss = 'binary_crossentropy' , optimizer = optimizers.RMSprop(), metrics = ['acc'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train ve validation generator olusturalım. \n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        # This is the target directory\n        './train',\n        # All images will be resized to 150x150\n        target_size=(150, 150),\n        batch_size=32,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\nvalidation_generator = test_datagen.flow_from_directory(\n        './validation',\n        target_size=(150, 150),\n        batch_size=32,\n        class_mode='binary')\n\nhistory = my_model.fit_generator(\n      train_generator,\n      steps_per_epoch=100,\n      epochs=100,\n      validation_data=validation_generator,\n      validation_steps=50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #tekrar çizdirelim\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'bo', label='egitim basarimi')\nplt.plot(epochs, val_acc, 'b', label='dogrulama basarimi')\nplt.title('egitim ve dogrulama basarimi')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, loss, 'bo', label='egitim kaybı')\nplt.plot(epochs, val_loss, 'b', label='dogrulama kaybı')\nplt.title('Egitim ve dogrulama kaybı')\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# modeli kaydedelim\nmodel.save('cats_and_dogs_v1.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}