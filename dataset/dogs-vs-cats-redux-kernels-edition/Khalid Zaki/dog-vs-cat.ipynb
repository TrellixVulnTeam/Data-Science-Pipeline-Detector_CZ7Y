{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\n\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\nfrom keras.layers import Dense, Flatten","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import cv2                        \nfrom random import shuffle\nfrom tqdm import tqdm \nimport os \nprint(os.listdir('../input'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"category = [\"cat\", \"dog\"]\n\nEPOCHS                  = 50\nIMGSIZE                 = 128\nBATCH_SIZE              = 32\nSTOPPING_PATIENCE       = 15\nVERBOSE                 = 1\nMODEL_NAME              = 'cnn_50epochs_imgsize128'\nOPTIMIZER               = 'adam'\nTRAINING_DIR            = '../input/train'\nTEST_DIR                = '../input/test'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img in os.listdir(TRAINING_DIR)[7890:]:\n    img_path = os.path.join(TRAINING_DIR, img)\n    img_arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n    img_arr = cv2.resize(img_arr, dsize=(IMGSIZE, IMGSIZE))\n    plt.imshow(img_arr, cmap='gray')\n    plt.title(img.split('.')[0])\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_train_data(path):\n    X = []\n    y = []\n    for img in os.listdir(path):\n        try:\n            img_path = os.path.join(path, img)\n            img_arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n            img_arr = cv2.resize(img_arr, dsize=(IMGSIZE, IMGSIZE))\n            img_arr = img_arr / 255.0\n            cat = np.where(img.split('.')[0] == 'dog', 1, 0)\n        except Exception as e:\n                continue\n        X.append(img_arr)\n        y.append(cat)\n\n    X = np.array(X).reshape(-1, IMGSIZE, IMGSIZE, 1)\n    y = np.array(y)\n    \n    return X, y     ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X, y = create_train_data(TRAINING_DIR)\n\nprint(f\"features shape {X.shape}.\\nlabel shape {y.shape}.\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = to_categorical(y, 2)\nprint(f\"features shape {X.shape}.\\nlabel shape {y.shape}.\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=1/3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2,horizontal_flip=True)\ntrain_gen = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\ntest_gen = train_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=X.shape[1:]))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Conv2D(256, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.5))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(2, activation='sigmoid'))\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(X, y, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_split=1/3)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights(\"CATSvsDOGS_model.h5\")\nmodel.save('CNN_CAT.model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_acc = model.evaluate(X_train, y_train, batch_size=BATCH_SIZE)\ntest_acc = model.evaluate(X_test, y_test, batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(18, 10))\nax1.plot(history.history['loss'], color='b', label=\"Training loss : {:0.4f}\".format(train_acc[0]))\nax1.plot(history.history['val_loss'], color='r', label=\"validation loss : {:0.4f}\".format(test_acc[0]))\nax1.set_xticks(np.arange(1, EPOCHS, 1))\nax1.set_yticks(np.arange(0, 1., 0.1))\nax1.legend()\n\nax2.plot(history.history['acc'], color='b', label=\"Training accuracy : {0:.4f}\".format(train_acc[1]))\nax2.plot(history.history['val_acc'], color='r',label=\"Validation accuracy : {0:.4f}\".format(test_acc[1]))\nax2.set_xticks(np.arange(1, EPOCHS, 1))\nax2.set_yticks(np.arange(0.4, 1.2, 0.1))\n\nlegend = plt.legend(loc='best', shadow=True)\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_test = []\n\nfor img in os.listdir(TEST_DIR):\n    try:\n        img_path = os.path.join(TEST_DIR, img)\n        img_arr = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n        img_arr = cv2.resize(img_arr, (IMGSIZE, IMGSIZE))\n        img_arr = img_arr / 255.0\n    except Exception as e:\n        continue\n    im_test.append(img_arr)\n\nim_test = np.array(im_test).reshape(-1, IMGSIZE, IMGSIZE, 1)\nim_pred = model.predict(im_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig , ax = plt.subplots(3, 3, figsize=(30, 25))\nfor i, axis in enumerate(ax.flat):\n    axis.imshow(im_test[i].reshape(128, 128), cmap='gray')\n    #axis.set(title=f'{im_pred[i].max()} => {category[im_pred[i].argmax()]}')\n    axis.set_title(f'Predict: {im_pred[i].max()} => {category[im_pred[i].argmax()]}', fontsize=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_imgs = ['../input/dogs-vs-cats-redux-kernels-edition/test/{}'.format(i) for i in os.listdir(TEST_DIR)] #get test images\nX = []\nfor i in test_imgs:\n    if '.jpg' in i:\n        X.append(int(i.split('/')[4].replace('.jpg', '')))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"solution = pd.DataFrame({\"id\": X, \"label\":list(im_pred)})\n\nsolution.to_csv(\"dogsVScats.csv\", index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}