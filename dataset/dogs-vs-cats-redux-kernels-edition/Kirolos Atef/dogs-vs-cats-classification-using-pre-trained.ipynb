{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Code reference for pretrained models\nhttps://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/","metadata":{}},{"cell_type":"markdown","source":"# You can change the number of epoch in the training process to get better accuraces,but here for running time it set it to 1 ","metadata":{}},{"cell_type":"markdown","source":"# Check the tensorflow GPU and torch GPU","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import pandas as pd\nimport tensorflow as tf\nprint(len(tf.config.list_physical_devices('GPU')))\nimport torch\nprint(torch.cuda.is_available())","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:35:09.546807Z","iopub.execute_input":"2022-06-29T00:35:09.547594Z","iopub.status.idle":"2022-06-29T00:35:09.554518Z","shell.execute_reply.started":"2022-06-29T00:35:09.547554Z","shell.execute_reply":"2022-06-29T00:35:09.553153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import important libraries","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Activation, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom PIL import Image\nfrom skimage import transform","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:35:14.247671Z","iopub.execute_input":"2022-06-29T00:35:14.248038Z","iopub.status.idle":"2022-06-29T00:35:14.254337Z","shell.execute_reply.started":"2022-06-29T00:35:14.248007Z","shell.execute_reply":"2022-06-29T00:35:14.253062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"photo_size=200","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:35:16.0834Z","iopub.execute_input":"2022-06-29T00:35:16.08375Z","iopub.status.idle":"2022-06-29T00:35:16.088619Z","shell.execute_reply.started":"2022-06-29T00:35:16.08372Z","shell.execute_reply":"2022-06-29T00:35:16.087094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare dataset and add some augmentation","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def prepare_dataset(data_dir):\n    datagen = ImageDataGenerator(\n        rescale=1 / 255,\n        rotation_range=40,\n        width_shift_range=.2,\n        height_shift_range=.2,\n        shear_range=.1,\n        horizontal_flip=True,\n        fill_mode='nearest',\n        zoom_range=.2,\n    )\n    generator = datagen.flow_from_directory(\n        data_dir,\n        target_size=(photo_size,photo_size),\n        class_mode='binary',\n        batch_size=128,\n        # classes=[str(i) for i in range(2)]\n    )\n    return generator","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:35:17.109236Z","iopub.execute_input":"2022-06-29T00:35:17.109585Z","iopub.status.idle":"2022-06-29T00:35:17.115735Z","shell.execute_reply.started":"2022-06-29T00:35:17.109555Z","shell.execute_reply":"2022-06-29T00:35:17.114759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\nzip_df = zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip\", 'r')\nzip_df.extractall(\"/kaggle/working/\")\nzip_df.close()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T00:31:50.250244Z","iopub.execute_input":"2022-06-29T00:31:50.251239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Spliting Dogs and Cats in the training file to determine the classes","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import os\nfrom shutil import copyfile,move\nfile_path = \"./train/\"\nos.mkdir(os.path.join(file_path, 'Cats'))\nos.mkdir(os.path.join(file_path, 'Dogs'))\nfor i,image_name in enumerate(os.listdir(file_path)):\n    if 'cat'in image_name :\n        move(os.path.join(file_path, image_name),os.path.join(os.path.join(file_path, 'Cats'),image_name))\n\nfor i,image_name in enumerate(os.listdir(file_path)):\n    if 'dog'in image_name :\n        move(os.path.join(file_path, image_name),os.path.join(os.path.join(file_path, 'Dogs'),image_name))\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:35:50.981753Z","iopub.execute_input":"2022-06-29T00:35:50.982707Z","iopub.status.idle":"2022-06-29T00:35:51.700049Z","shell.execute_reply.started":"2022-06-29T00:35:50.982661Z","shell.execute_reply":"2022-06-29T00:35:51.699049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create validation directory","metadata":{}},{"cell_type":"code","source":"os.mkdir(os.path.join('./', 'validation'))","metadata":{"execution":{"iopub.status.busy":"2022-06-29T00:37:38.729185Z","iopub.execute_input":"2022-06-29T00:37:38.729542Z","iopub.status.idle":"2022-06-29T00:37:38.734809Z","shell.execute_reply.started":"2022-06-29T00:37:38.729515Z","shell.execute_reply":"2022-06-29T00:37:38.733583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# Split training ,validation and  testing Dataset","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import shutil\nimport os\nimport numpy as np\nimport argparse\n\ndef get_files_from_folder(path):\n    files = os.listdir(path)\n    return np.asarray(files)\n\ndef image_train_test_split(path_to_data, path_to_test_data, train_ratio):\n    # get dirs\n    _, dirs, _ = next(os.walk(path_to_data))\n\n    # calculates how many train data per class\n    data_counter_per_class = np.zeros((len(dirs)))\n    for i in range(len(dirs)):\n        path = os.path.join(path_to_data, dirs[i])\n        files = get_files_from_folder(path)\n        data_counter_per_class[i] = len(files)\n    test_counter = np.round(data_counter_per_class * (1 - train_ratio))\n\n    # transfers files\n    for i in range(len(dirs)):\n        path_to_original = os.path.join(path_to_data, dirs[i])\n        path_to_save = os.path.join(path_to_test_data, dirs[i])\n\n        #creates dir\n        if not os.path.exists(path_to_save):\n            os.makedirs(path_to_save)\n        files = get_files_from_folder(path_to_original)\n        # moves data\n        for j in range(int(test_counter[i])):\n            dst = os.path.join(path_to_save, files[j])\n            src = os.path.join(path_to_original, files[j])\n            shutil.move(src, dst)\n\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:38:19.618842Z","iopub.execute_input":"2022-06-29T00:38:19.619511Z","iopub.status.idle":"2022-06-29T00:38:19.62926Z","shell.execute_reply.started":"2022-06-29T00:38:19.619476Z","shell.execute_reply":"2022-06-29T00:38:19.628289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_train_test_split('./train/', './validation/', float(0.9))","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:38:34.278411Z","iopub.execute_input":"2022-06-29T00:38:34.278757Z","iopub.status.idle":"2022-06-29T00:38:34.392471Z","shell.execute_reply.started":"2022-06-29T00:38:34.278727Z","shell.execute_reply":"2022-06-29T00:38:34.39155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Dataset from directory","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"train_data=prepare_dataset('./train/')\nvalidation_data = prepare_dataset('./validation/')\n\n","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:39:21.1703Z","iopub.execute_input":"2022-06-29T00:39:21.170724Z","iopub.status.idle":"2022-06-29T00:39:22.377603Z","shell.execute_reply.started":"2022-06-29T00:39:21.170685Z","shell.execute_reply":"2022-06-29T00:39:22.376603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Unzip test data","metadata":{}},{"cell_type":"code","source":"import zipfile\nzip_df = zipfile.ZipFile(\"/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip\", 'r')\nzip_df.extractall(\"/kaggle/working/\")\nzip_df.close()","metadata":{"execution":{"iopub.status.busy":"2022-06-29T00:41:00.006068Z","iopub.execute_input":"2022-06-29T00:41:00.006665Z","iopub.status.idle":"2022-06-29T00:41:06.518603Z","shell.execute_reply.started":"2022-06-29T00:41:00.006628Z","shell.execute_reply":"2022-06-29T00:41:06.517639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_data.class_indices","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:41:08.560128Z","iopub.execute_input":"2022-06-29T00:41:08.560574Z","iopub.status.idle":"2022-06-29T00:41:08.571489Z","shell.execute_reply.started":"2022-06-29T00:41:08.560533Z","shell.execute_reply":"2022-06-29T00:41:08.57035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load pre-trained models","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"markdown","source":"## Vgg model","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"# example of tending the vgg16 model\ndef create_vgg_model():\n    from keras.applications.vgg16 import VGG16\n    from keras.models import Model\n    from keras.layers import Dense\n    from keras.layers import Flatten\n    # load model without classifier layers\n    model = VGG16(include_top=False, input_shape=(photo_size, photo_size, 3))\n    for layer_idx in range(len(model.layers)):\n        if layer_idx not in [1,2,3,15,16,17,18]:\n            model.layers[layer_idx].trainable = False\n    # add new classifier layers\n    flat1 = Flatten()(model.layers[-1].output)\n    class1 = Dense(128, activation='relu')(flat1)\n    # class1 = Dense(256, activation='relu')(class1)\n    output = Dense(1, activation='sigmoid')(class1)\n    # define new model\n    model = Model(inputs=model.inputs, outputs=output)\n    return model","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:41:19.02568Z","iopub.execute_input":"2022-06-29T00:41:19.026379Z","iopub.status.idle":"2022-06-29T00:41:19.034409Z","shell.execute_reply.started":"2022-06-29T00:41:19.026339Z","shell.execute_reply":"2022-06-29T00:41:19.033292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model=create_vgg_model()\nvgg_model.summary()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:41:25.759232Z","iopub.execute_input":"2022-06-29T00:41:25.7601Z","iopub.status.idle":"2022-06-29T00:41:31.685966Z","shell.execute_reply.started":"2022-06-29T00:41:25.760063Z","shell.execute_reply":"2022-06-29T00:41:31.684075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vgg_model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\nvgg_model.fit(\n    train_data,\n    epochs=1,\n    validation_data=validation_data\n)\nvgg_model.save(\"Dogs_vs_cats_vgg_model30.h5\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:41:31.687894Z","iopub.execute_input":"2022-06-29T00:41:31.688257Z","iopub.status.idle":"2022-06-29T00:47:06.295978Z","shell.execute_reply.started":"2022-06-29T00:41:31.688222Z","shell.execute_reply":"2022-06-29T00:47:06.294985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inception model","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def create_inception_model():\n    from tensorflow.keras.applications.inception_v3 import InceptionV3\n    base_model = InceptionV3(input_shape = (photo_size, photo_size, 3), include_top = False, weights = 'imagenet')\n    for layer in base_model.layers:\n        layer.trainable = False\n    # for layer_idx in range(len(pretrained_model.layers)):\n    #     if layer_idx not in [1,2,3,305,306,307,308,309,310]:\n    #         pretrained_model.layers[layer_idx].trainable = False\n    from tensorflow.keras.optimizers import RMSprop\n    from tensorflow.keras import layers\n    x = layers.Flatten()(base_model.output)\n    x = layers.Dense(512, activation='relu')(x)\n    x = layers.Dropout(0.2)(x)\n    x = layers.Dense(256, activation='relu')(x)\n    # Add a final sigmoid layer with 1 node for classification output\n    x = layers.Dense(1, activation='sigmoid')(x)\n    model = tf.keras.models.Model(base_model.input, x)\n    model.compile(optimizer = RMSprop(learning_rate=0.0001), loss = 'binary_crossentropy', metrics = ['accuracy'])\n    return model","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:47:06.297789Z","iopub.execute_input":"2022-06-29T00:47:06.298167Z","iopub.status.idle":"2022-06-29T00:47:06.308114Z","shell.execute_reply.started":"2022-06-29T00:47:06.298131Z","shell.execute_reply":"2022-06-29T00:47:06.307116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_model=create_inception_model()\ninception_model.summary()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:47:06.309486Z","iopub.execute_input":"2022-06-29T00:47:06.309918Z","iopub.status.idle":"2022-06-29T00:47:08.536427Z","shell.execute_reply.started":"2022-06-29T00:47:06.30988Z","shell.execute_reply":"2022-06-29T00:47:08.53543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inception_model.fit(\n    train_data,\n    epochs=1,\n    validation_data=validation_data,steps_per_epoch=5\n)\ninception_model.save(\"Dogs_vs_cats_inception_model_1_5step.h5\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:47:08.538616Z","iopub.execute_input":"2022-06-29T00:47:08.538998Z","iopub.status.idle":"2022-06-29T00:47:52.300685Z","shell.execute_reply.started":"2022-06-29T00:47:08.538961Z","shell.execute_reply":"2022-06-29T00:47:52.299686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet","metadata":{"execution":{"iopub.status.busy":"2022-06-29T00:52:44.266756Z","iopub.execute_input":"2022-06-29T00:52:44.267518Z","iopub.status.idle":"2022-06-29T00:52:56.011238Z","shell.execute_reply.started":"2022-06-29T00:52:44.267481Z","shell.execute_reply":"2022-06-29T00:52:56.009868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Efficient net","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"def use_efficient_net(model_type='B0'):\n    from tensorflow.keras.optimizers import RMSprop\n    from tensorflow.keras.models import Model\n    from efficientnet.tfkeras import EfficientNetB0,EfficientNetB7\n    if model_type=='B0':\n        efn_model = EfficientNetB0(input_shape = (photo_size, photo_size, 3), include_top = False, weights = 'imagenet')\n    else:\n        efn_model = EfficientNetB7(input_shape = (photo_size, photo_size, 3), include_top = False, weights = 'imagenet')\n    for layer in efn_model.layers:\n        layer.trainable = False\n    #\n    x = efn_model.output\n    x = Flatten()(x)\n    x = Dense(256, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation=\"relu\")(x)\n    # Add a final sigmoid layer with 1 node for classification output\n    predictions = Dense(1, activation=\"sigmoid\")(x)\n    efficient_net = Model(efn_model.input,predictions)\n\n    efficient_net.compile(RMSprop(learning_rate=0.0001, decay=1e-6),loss='binary_crossentropy',metrics=['accuracy'])\n    return efficient_net\nefficient_net=use_efficient_net('B0')\nefficient_net.summary()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T01:13:48.893077Z","iopub.execute_input":"2022-06-29T01:13:48.893604Z","iopub.status.idle":"2022-06-29T01:13:50.00718Z","shell.execute_reply.started":"2022-06-29T01:13:48.893572Z","shell.execute_reply":"2022-06-29T01:13:50.005873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"eff_history = efficient_net.fit(train_data, validation_data = validation_data, epochs = 1,steps_per_epoch=3)\nefficient_net.save(\"Dog_vs_cats_efficient_netB0_1_3step.h5\")","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:52:56.073219Z","iopub.status.idle":"2022-06-29T00:52:56.074127Z","shell.execute_reply.started":"2022-06-29T00:52:56.073838Z","shell.execute_reply":"2022-06-29T00:52:56.073863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Champion model Inference","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"!pip install efficientnet","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T00:47:52.350571Z","iopub.status.idle":"2022-06-29T00:47:52.351356Z","shell.execute_reply.started":"2022-06-29T00:47:52.351098Z","shell.execute_reply":"2022-06-29T00:47:52.351122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet.tfkeras import EfficientNetB0\nfrom keras.models import load_model\nefficient_net_model= load_model(\"Dogs_vs_cats_inception_model_1_5step.h5\")\nefficient_net_model.summary()","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T01:14:35.060464Z","iopub.execute_input":"2022-06-29T01:14:35.061352Z","iopub.status.idle":"2022-06-29T01:14:37.513364Z","shell.execute_reply.started":"2022-06-29T01:14:35.061314Z","shell.execute_reply":"2022-06-29T01:14:37.512407Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load Images from path","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"from PIL import Image\nimport numpy as np\nfrom skimage import transform\nphoto_size=200\ndef load_image_from_path(filename):\n    np_image = Image.open(filename)\n    np_image = np.array(np_image).astype('float32') / 255\n    np_image = transform.resize(np_image, (photo_size, photo_size, 3))\n    np_image = np.expand_dims(np_image, axis=0)\n    return np_image","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T01:14:46.2014Z","iopub.execute_input":"2022-06-29T01:14:46.201743Z","iopub.status.idle":"2022-06-29T01:14:46.208858Z","shell.execute_reply.started":"2022-06-29T01:14:46.201713Z","shell.execute_reply":"2022-06-29T01:14:46.207605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mTestPath = \"test/\"\nsubmission={'id':[],'label':[]}\nfor i,test in enumerate(os.listdir(mTestPath)):\n    img = load_image_from_path(os.path.join(mTestPath, test))\n    submission['id'].append(i+1)\n    res = efficient_net_model.predict(img)[0][0]\n    submission['label'].append(res)\n    # print(test, \"\\t\", res)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T01:14:50.134354Z","iopub.execute_input":"2022-06-29T01:14:50.134703Z","iopub.status.idle":"2022-06-29T01:36:27.877959Z","shell.execute_reply.started":"2022-06-29T01:14:50.134674Z","shell.execute_reply":"2022-06-29T01:36:27.876628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"pycharm":{"name":"#%% md\n"}}},{"cell_type":"code","source":"import pandas as pd\nsubmission_df=pd.DataFrame(submission)\nsubmission_df.to_csv('Dogs_vs_cats_inception_model_1_5step.csv',index=False)","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-06-29T01:36:27.879682Z","iopub.execute_input":"2022-06-29T01:36:27.880064Z","iopub.status.idle":"2022-06-29T01:36:27.946207Z","shell.execute_reply.started":"2022-06-29T01:36:27.880029Z","shell.execute_reply":"2022-06-29T01:36:27.945208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"collapsed":false,"pycharm":{"name":"#%%\n"},"jupyter":{"outputs_hidden":false}},"execution_count":null,"outputs":[]}]}