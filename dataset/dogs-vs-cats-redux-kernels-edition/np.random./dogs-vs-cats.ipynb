{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Kaggle link: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition","metadata":{"_uuid":"9c761b7b-4dc7-4a3f-877b-37aa9c4c9cc4","_cell_guid":"6c8f1b2b-9816-4a2c-9278-f92330d8a02b","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T17:34:42.530834Z","iopub.execute_input":"2022-01-09T17:34:42.531599Z","iopub.status.idle":"2022-01-09T17:34:42.564552Z","shell.execute_reply.started":"2022-01-09T17:34:42.5315Z","shell.execute_reply":"2022-01-09T17:34:42.562659Z"},"trusted":true}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"994c9bf6-69e5-4904-bec1-b014705821d3","_cell_guid":"6a0695c7-edc3-43e8-a270-c4a0cbaede9f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:36:24.650214Z","iopub.execute_input":"2022-02-14T02:36:24.650557Z","iopub.status.idle":"2022-02-14T02:36:24.675037Z","shell.execute_reply.started":"2022-02-14T02:36:24.650474Z","shell.execute_reply":"2022-02-14T02:36:24.674361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import everything needed","metadata":{"_uuid":"54b71fe6-8006-473e-8b6a-ff13d6727e64","_cell_guid":"a2f66a42-695c-49a9-8e91-2bcc926f27a5","trusted":true}},{"cell_type":"code","source":"import zipfile\nimport glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\n\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")\n\nwandb.login(key=secret_value_0)\nwandb.init(project='CatvsDog-11', save_code=True) #, mode=\"disabled\")","metadata":{"_uuid":"0fcc42b5-8920-4d9e-b9f1-812a136a262b","_cell_guid":"ed15812a-fca0-4727-b20f-9ac7f9f3170c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:36:30.523134Z","iopub.execute_input":"2022-02-14T02:36:30.523608Z","iopub.status.idle":"2022-02-14T02:36:44.659384Z","shell.execute_reply.started":"2022-02-14T02:36:30.523569Z","shell.execute_reply":"2022-02-14T02:36:44.658644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unzip datasets","metadata":{"_uuid":"32d52610-1ced-4130-91f4-a3b9a2ab6dac","_cell_guid":"189fa120-68ce-403d-b563-e500ec090db2","trusted":true}},{"cell_type":"code","source":"train_dir = 'train'\ntest_dir = 'test'\nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip') as train_zip:\n    train_zip.extractall('')\n    \nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip') as test_zip:\n    test_zip.extractall('')\ntrain_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"_uuid":"e01bc4b4-b6d1-436a-b771-f1791720606e","_cell_guid":"9e84d5f5-0729-44a2-baa8-77513e40d701","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:37:09.99896Z","iopub.execute_input":"2022-02-14T02:37:09.999235Z","iopub.status.idle":"2022-02-14T02:37:28.219754Z","shell.execute_reply.started":"2022-02-14T02:37:09.999204Z","shell.execute_reply":"2022-02-14T02:37:28.218994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [path.split('/')[-1].split('.')[0] for path in train_list]","metadata":{"_uuid":"65925334-c10b-46b2-9fef-1b2a28433f9b","_cell_guid":"8c9d8c7a-139e-46fd-9ded-836091f7a4a9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:39:20.751471Z","iopub.execute_input":"2022-02-14T02:39:20.751968Z","iopub.status.idle":"2022-02-14T02:39:21.930169Z","shell.execute_reply.started":"2022-02-14T02:39:20.751927Z","shell.execute_reply":"2022-02-14T02:39:21.929452Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Sklearn to split data","metadata":{"_uuid":"571a6798-d06b-4ada-aeb1-cd27e65c21cb","_cell_guid":"fc50cbb2-b0ea-4aac-bbda-ee13bc95bc16","trusted":true}},{"cell_type":"code","source":"train_list, valid_list = train_test_split(train_list, \n                                          test_size=0.2,\n                                          stratify=labels,\n                                          random_state=0)\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Validation Data: {len(valid_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"_uuid":"9efb6063-62f4-46d2-94d4-f4efd467a72d","_cell_guid":"925206b8-6958-4b0d-850d-4e2b05344867","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:39:23.983836Z","iopub.execute_input":"2022-02-14T02:39:23.984117Z","iopub.status.idle":"2022-02-14T02:39:26.204246Z","shell.execute_reply.started":"2022-02-14T02:39:23.984081Z","shell.execute_reply":"2022-02-14T02:39:26.203541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will discuss this in more detail in a near future...","metadata":{"_uuid":"5f92417b-170d-42c2-a173-5139bea90250","_cell_guid":"5a26a11c-eec8-4d07-9d16-1aec3160ad0d","trusted":true}},{"cell_type":"code","source":"\n# 图像增强\ndataset_transform = {\n    'train': transforms.Compose([\n        transforms.RandomRotation(45),  # 随机反转-45到45度之间\n        transforms.Resize(300),\n        transforms.CenterCrop(224),  # 从中心开始裁剪224\n        transforms.RandomHorizontalFlip(p=0.5),  # 随机水平翻转， 选择一个概率\n        transforms.RandomVerticalFlip(p=0.5),  # 随机垂直翻转\n        transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.1, hue=0.1),\n        # 参数1为亮度， 参数2为对比度， 参数3为饱和度， 参数4为色相\n        transforms.RandomGrayscale(p=0.025),  # 概率转换成灰度率， 3通道是R G B\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))  # 均值 标准差\n    ]),\n\n    'vaild': transforms.Compose([\n        transforms.Resize(300),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ]),\n\n    'test': transforms.Compose([\n        transforms.Resize(300),\n        transforms.CenterCrop(224),\n        transforms.ToTensor(),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n    ])\n}\n","metadata":{"_uuid":"cf930514-d214-4008-85fe-b41dcb44241f","_cell_guid":"88e39d0a-c17f-49db-b35b-d3a14118566d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:39:27.527483Z","iopub.execute_input":"2022-02-14T02:39:27.527813Z","iopub.status.idle":"2022-02-14T02:39:28.687335Z","shell.execute_reply.started":"2022-02-14T02:39:27.527778Z","shell.execute_reply":"2022-02-14T02:39:28.686659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the dataset using PIL to read image","metadata":{"_uuid":"c13a7fdd-109e-4df4-aa07-11d21970940d","_cell_guid":"595f754a-b18b-4f61-adf2-b138c6deb420","trusted":true}},{"cell_type":"code","source":"class CatsDogsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.file_list = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n        label = img_path.split(\"/\")[-1].split(\".\")[0]\n        label = 1 if label == \"dog\" else 0\n        return img_transformed, label","metadata":{"_uuid":"68fa7b4c-8dbf-4e5d-94e2-786c95e070a5","_cell_guid":"58576e5a-3941-4d04-87c8-bd6149891c2b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:40:12.545825Z","iopub.execute_input":"2022-02-14T02:40:12.546088Z","iopub.status.idle":"2022-02-14T02:40:13.729994Z","shell.execute_reply.started":"2022-02-14T02:40:12.546059Z","shell.execute_reply":"2022-02-14T02:40:13.729316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = CatsDogsDataset(train_list, transform=dataset_transform['train'])\nvalid_data = CatsDogsDataset(valid_list, transform=dataset_transform['vaild'])\ntest_data = CatsDogsDataset(test_list, transform=dataset_transform['test'])","metadata":{"_uuid":"a27a0cef-dccf-4f0e-a204-09c9b32aecca","_cell_guid":"e4054f84-ccab-4030-b6c7-cd877798d8aa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:40:17.678812Z","iopub.execute_input":"2022-02-14T02:40:17.679258Z","iopub.status.idle":"2022-02-14T02:40:18.801928Z","shell.execute_reply.started":"2022-02-14T02:40:17.67922Z","shell.execute_reply":"2022-02-14T02:40:18.801211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create dataloader, you can modify the batch size if needed","metadata":{"_uuid":"14ff676e-8fef-437a-bb2f-08e7c5a69f24","_cell_guid":"0bed416b-5fd7-4768-b7f7-ab1640dac8ec","trusted":true}},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True, drop_last=True, num_workers=2)\nvalid_loader = DataLoader(dataset=valid_data, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)","metadata":{"_uuid":"f6795b9f-a4d6-4d14-b776-220c28e4de23","_cell_guid":"377a3a21-52cf-44f0-b186-778e6c7f1ba9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:40:48.941048Z","iopub.execute_input":"2022-02-14T02:40:48.941608Z","iopub.status.idle":"2022-02-14T02:40:50.176244Z","shell.execute_reply.started":"2022-02-14T02:40:48.941566Z","shell.execute_reply":"2022-02-14T02:40:50.175531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchvision --upgrade","metadata":{"execution":{"iopub.status.busy":"2022-02-13T14:05:24.56289Z","iopub.execute_input":"2022-02-13T14:05:24.563469Z","iopub.status.idle":"2022-02-13T14:06:57.023801Z","shell.execute_reply.started":"2022-02-13T14:05:24.563429Z","shell.execute_reply":"2022-02-13T14:06:57.023009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torchvision\nmodel = torchvision.models.resnet18(pretrained=True)\nmodel.fc = nn.Sequential(\n           nn.Linear(in_features=512, out_features=2, bias=True)         \n )\n\n\nnet = model.cuda()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('Detected device: {}'.format(device))\nnet.to(device)\n\nnum_epochs = 30\nlr = 5e-3\n\ncriterion = nn.CrossEntropyLoss()\nparams = net.parameters()\n# optimizer = torch.optim.AdamW(params, lr=lr,weight_decay=1e-3)\noptimizer = torch.optim.SGD(params, lr=lr)\n\nwandb.watch(net, log=\"all\", criterion=criterion, log_freq=1,  log_graph=(True))\nparams","metadata":{"_uuid":"0301b0f3-bd0f-422d-87f5-1b3b5f03bdfe","_cell_guid":"68f780e8-0484-42f2-83e0-e6e3f94841ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:47:12.819204Z","iopub.execute_input":"2022-02-14T02:47:12.819461Z","iopub.status.idle":"2022-02-14T02:47:21.54066Z","shell.execute_reply.started":"2022-02-14T02:47:12.819432Z","shell.execute_reply":"2022-02-14T02:47:21.539692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    net.train()\n\n    for X, y in train_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        optimizer.zero_grad()\n        prediction = net(X)\n        loss = criterion(prediction, y)\n        loss.backward()\n        optimizer.step()\n\n        _, predictions = torch.max(prediction, 1)\n        \n        wandb.log({\n            'mlp/train_loss': loss.item(),\n            'mlp/train_accuracy': (y == predictions).sum()/len(y),\n        })\n\n\n    with torch.no_grad():\n        net.eval()\n        for X, y in valid_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            prediction = net(X)\n\n            loss = criterion(prediction, y)\n            _, predictions = torch.max(prediction, 1)\n        \n            wandb.log({\n                'mlp/val_loss': loss.item(),\n                'mlp/val_accuracy': (y == predictions).sum()/len(y),\n            })\n","metadata":{"_uuid":"c8eabc9a-2575-40b2-87ba-37978df132d6","_cell_guid":"2659b612-4db2-49d4-95a9-babb8088b5ec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T02:47:41.991163Z","iopub.execute_input":"2022-02-14T02:47:41.991641Z","iopub.status.idle":"2022-02-14T06:52:16.334394Z","shell.execute_reply.started":"2022-02-14T02:47:41.991589Z","shell.execute_reply":"2022-02-14T06:52:16.333378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission**","metadata":{"_uuid":"91280ceb-b314-4465-bde5-0e40c300bb53","_cell_guid":"876e6144-5665-4dc0-8e6b-b4a62ef96d5d","trusted":true}},{"cell_type":"code","source":"with torch.no_grad():\n    net.eval()\n    test_pred = torch.LongTensor()\n    test_pred = test_pred.to(device)\n    for data, i in test_loader:\n        data = data.to(device)\n\n        prediction = net(data)\n        dog_props =  F.softmax(prediction, dim=1)[:, 1]\n        test_pred = torch.cat((test_pred, dog_props), dim=0)\n    out_df = pd.DataFrame(np.c_[np.arange(1, len(test_list)+1)[:, None],\n                                test_pred.cpu().numpy()], columns=['ImageId', 'Label'])\n    # out_df = out_df.astype({'id':'str', 'label':'str'})\n    out_df.to_csv('submission.csv', index=False)\n\nout_df","metadata":{"_uuid":"18138e77-5c10-4c2b-95e3-745472956ec6","_cell_guid":"a8233ab9-1ab0-4358-9110-88b43b640528","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-02-14T07:02:48.497528Z","iopub.execute_input":"2022-02-14T07:02:48.498331Z","iopub.status.idle":"2022-02-14T07:05:57.627441Z","shell.execute_reply.started":"2022-02-14T07:02:48.498289Z","shell.execute_reply":"2022-02-14T07:05:57.626759Z"},"trusted":true},"execution_count":null,"outputs":[]}]}