{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"c50a8200-9ee2-b6ad-5e1b-ff66132eda42"},"outputs":[],"source":"\nimport cv2\t\t\t\t # working with, mainly resizing, images\nimport numpy as np\t\t # dealing with arrays\nimport os\t\t\t\t  # dealing with directories\nfrom random import shuffle # mixing up or currently ordered data that might lead our network astray in training.\nfrom tqdm import tqdm\t  # a nice pretty percentage bar for tasks. Thanks to viewer Daniel BA1/4hler for this suggestion\nimport tflearn\nfrom tflearn.layers.conv import conv_2d, max_pool_2d\nfrom tflearn.layers.core import input_data, dropout, fully_connected\nfrom tflearn.layers.estimator import regression\nimport tensorflow as tf\n\ntrainDir = '../input/train/'\ntestDir = '../input/test'\n#testDir = '../input/train/'\nLR = 1e-3\n\nimageSize = 50\n#MODEL_NAME = 'dogsvscats-{}-{}.model'.format(LR, '2conv-basic') # just so we remember which saved model is which, sizes must match\n\ndef label_img(img):\n\tword_label = img.split('.')[-3]\n\t# conversion to one-hot array [cat,dog]\n\t#\t\t\t\t\t\t\t[much cat, no dog]\n\tif word_label == 'cat': return [1,0]\n\t#\t\t\t\t\t\t\t [no cat, very doggo]\n\telif word_label == 'dog': return [0,1]\n\t\n\t\ndef create_train_data():\n\ttraining_data = []\n\tfor img in os.listdir(trainDir):\n\t\tlabel = label_img(img)\n\t\tpath = os.path.join(trainDir,img)\n\t\timg = cv2.imread(path)\n\t\timg = cv2.resize(img, (imageSize,imageSize))\n\t\ttraining_data.append([np.array(img),np.array(label), ])\n\tshuffle(training_data)\n\t#np.save('train_data.npy', training_data)\n\treturn training_data\n\t\n\t\ndef process_test_data():\n\ttesting_data = []\n\tfor img in os.listdir(testDir):\n\t\tpath = os.path.join(testDir,img)\n\t\timg_num = img.split('.')[0]\n\t\timg = cv2.imread(path)\n\t\timg = cv2.resize(img, (imageSize,imageSize))\n\t\ttesting_data.append([np.array(img), img_num])\n\t\t\n\tshuffle(testing_data)\n\t#np.save('test_data.npy', testing_data)\n\treturn testing_data\n\t\ntrain_data = create_train_data()\n\ntestDataCount = int(len(train_data) / 5)\n\ntestData = train_data[:testDataCount]\ntrain_data = train_data[testDataCount:]\n\nconvnet = input_data(shape=[None, imageSize, imageSize, 3], name='input')\n\nconvnet = conv_2d(convnet, 32, 5, activation='relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 64, 5, activation='relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 128, 5, activation='relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 64, 5, activation='relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = conv_2d(convnet, 32, 5, activation='relu')\nconvnet = max_pool_2d(convnet, 5)\n\nconvnet = fully_connected(convnet, 1024, activation='relu')\nconvnet = dropout(convnet, 0.8)\n\nconvnet = fully_connected(convnet, 2, activation='softmax')\nconvnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n\nmodel = tflearn.DNN(convnet, tensorboard_dir='log')\n\n\t\nX = np.array([i[0] for i in train_data]).reshape(-1,imageSize,imageSize,3)\nY = [i[1] for i in train_data]\n\ntest_x = np.array([i[0] for i in testData]).reshape(-1,imageSize,imageSize,3)\ntest_y = [i[1] for i in testData]\n\nmodel.fit({'input': X}, {'targets': Y}, n_epoch=10, validation_set=({'input': test_x}, {'targets': test_y}), \n\tsnapshot_step=5000, show_metric=True)\ntestData = process_test_data()\n\nfor data in testData:\n\timg_num = data[1]\n\timg_data = data[0]\n\torig = img_data\n\tdata = img_data.reshape(imageSize,imageSize,3)\n\tmodel_out = model.predict([data])[0]\n\tprint('{},{}\\n'.format(img_num,model_out[1]))"}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.0"}},"nbformat":4,"nbformat_minor":0}