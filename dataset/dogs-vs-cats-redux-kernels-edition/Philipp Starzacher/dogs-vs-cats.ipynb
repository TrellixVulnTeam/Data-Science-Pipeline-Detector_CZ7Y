{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Kaggle link: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition","metadata":{"_uuid":"9c761b7b-4dc7-4a3f-877b-37aa9c4c9cc4","_cell_guid":"6c8f1b2b-9816-4a2c-9278-f92330d8a02b","jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T17:34:42.530834Z","iopub.execute_input":"2022-01-09T17:34:42.531599Z","iopub.status.idle":"2022-01-09T17:34:42.564552Z","shell.execute_reply.started":"2022-01-09T17:34:42.5315Z","shell.execute_reply":"2022-01-09T17:34:42.562659Z"},"trusted":true}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"994c9bf6-69e5-4904-bec1-b014705821d3","_cell_guid":"6a0695c7-edc3-43e8-a270-c4a0cbaede9f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:04.878842Z","iopub.execute_input":"2022-01-09T22:46:04.879437Z","iopub.status.idle":"2022-01-09T22:46:04.888283Z","shell.execute_reply.started":"2022-01-09T22:46:04.879396Z","shell.execute_reply":"2022-01-09T22:46:04.887276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import everything needed","metadata":{"_uuid":"54b71fe6-8006-473e-8b6a-ff13d6727e64","_cell_guid":"a2f66a42-695c-49a9-8e91-2bcc926f27a5","trusted":true}},{"cell_type":"code","source":"import zipfile\nimport glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)\n\nimport wandb\nfrom kaggle_secrets import UserSecretsClient\n\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"wandb\")\nwandb.login(key=secret_value_0)\nwandb.init(project='CatvsDog', save_code=True) #, mode=\"disabled\")","metadata":{"_uuid":"0fcc42b5-8920-4d9e-b9f1-812a136a262b","_cell_guid":"ed15812a-fca0-4727-b20f-9ac7f9f3170c","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:04.894162Z","iopub.execute_input":"2022-01-09T22:46:04.894392Z","iopub.status.idle":"2022-01-09T22:46:16.450303Z","shell.execute_reply.started":"2022-01-09T22:46:04.894358Z","shell.execute_reply":"2022-01-09T22:46:16.449524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unzip datasets","metadata":{"_uuid":"32d52610-1ced-4130-91f4-a3b9a2ab6dac","_cell_guid":"189fa120-68ce-403d-b563-e500ec090db2","trusted":true}},{"cell_type":"code","source":"train_dir = 'train'\ntest_dir = 'test'\nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip') as train_zip:\n    train_zip.extractall('')\n    \nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip') as test_zip:\n    test_zip.extractall('')\ntrain_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"_uuid":"e01bc4b4-b6d1-436a-b771-f1791720606e","_cell_guid":"9e84d5f5-0729-44a2-baa8-77513e40d701","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:16.452387Z","iopub.execute_input":"2022-01-09T22:46:16.454385Z","iopub.status.idle":"2022-01-09T22:46:30.593666Z","shell.execute_reply.started":"2022-01-09T22:46:16.454339Z","shell.execute_reply":"2022-01-09T22:46:30.592917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [path.split('/')[-1].split('.')[0] for path in train_list]","metadata":{"_uuid":"65925334-c10b-46b2-9fef-1b2a28433f9b","_cell_guid":"8c9d8c7a-139e-46fd-9ded-836091f7a4a9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:30.595964Z","iopub.execute_input":"2022-01-09T22:46:30.596216Z","iopub.status.idle":"2022-01-09T22:46:31.232847Z","shell.execute_reply.started":"2022-01-09T22:46:30.596182Z","shell.execute_reply":"2022-01-09T22:46:31.23204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot random image with their label","metadata":{"_uuid":"619f623d-e322-400d-8dc4-df4706d25b61","_cell_guid":"9bb0bde6-2ad5-4b3f-8e93-5ec81639ac46","trusted":true}},{"cell_type":"code","source":"random_idx = np.random.randint(1, len(train_list), size=9)\nfig, axes = plt.subplots(3, 3, figsize=(16, 12))\n\nfor idx, ax in enumerate(axes.ravel()):\n    img = Image.open(train_list[idx])\n    ax.set_title(labels[idx])\n    ax.imshow(img)","metadata":{"_uuid":"bf3c12e3-49ab-4847-b93a-9f61a158f58f","_cell_guid":"ed740a12-bfbc-4d16-9f24-3fe6d6e91d6f","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:31.235895Z","iopub.execute_input":"2022-01-09T22:46:31.236549Z","iopub.status.idle":"2022-01-09T22:46:34.05484Z","shell.execute_reply.started":"2022-01-09T22:46:31.236492Z","shell.execute_reply":"2022-01-09T22:46:34.054104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Sklearn to split data","metadata":{"_uuid":"571a6798-d06b-4ada-aeb1-cd27e65c21cb","_cell_guid":"fc50cbb2-b0ea-4aac-bbda-ee13bc95bc16","trusted":true}},{"cell_type":"code","source":"train_list, valid_list = train_test_split(train_list, \n                                          test_size=0.2,\n                                          stratify=labels,\n                                          random_state=0)\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Validation Data: {len(valid_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"_uuid":"9efb6063-62f4-46d2-94d4-f4efd467a72d","_cell_guid":"925206b8-6958-4b0d-850d-4e2b05344867","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:34.05877Z","iopub.execute_input":"2022-01-09T22:46:34.05899Z","iopub.status.idle":"2022-01-09T22:46:34.689853Z","shell.execute_reply.started":"2022-01-09T22:46:34.058963Z","shell.execute_reply":"2022-01-09T22:46:34.689004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will discuss this in more detail in a near future...","metadata":{"_uuid":"5f92417b-170d-42c2-a173-5139bea90250","_cell_guid":"5a26a11c-eec8-4d07-9d16-1aec3160ad0d","trusted":true}},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n        transforms.Resize(128), # makes it easier for the GPU\n        transforms.RandomResizedCrop(112),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor()])\n\nval_transforms = transforms.Compose([\n        transforms.Resize(128),\n        transforms.CenterCrop(112),\n        transforms.ToTensor()])\n\n\ntest_transforms = transforms.Compose([\n        transforms.Resize(128),\n        transforms.CenterCrop(112),\n        transforms.ToTensor()])","metadata":{"_uuid":"cf930514-d214-4008-85fe-b41dcb44241f","_cell_guid":"88e39d0a-c17f-49db-b35b-d3a14118566d","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:34.691099Z","iopub.execute_input":"2022-01-09T22:46:34.691377Z","iopub.status.idle":"2022-01-09T22:46:35.183051Z","shell.execute_reply.started":"2022-01-09T22:46:34.69134Z","shell.execute_reply":"2022-01-09T22:46:35.182327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the dataset using PIL to read image","metadata":{"_uuid":"c13a7fdd-109e-4df4-aa07-11d21970940d","_cell_guid":"595f754a-b18b-4f61-adf2-b138c6deb420","trusted":true}},{"cell_type":"code","source":"class CatsDogsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.file_list = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n        label = img_path.split(\"/\")[-1].split(\".\")[0]\n        label = 1 if label == \"dog\" else 0\n        return img_transformed, label","metadata":{"_uuid":"68fa7b4c-8dbf-4e5d-94e2-786c95e070a5","_cell_guid":"58576e5a-3941-4d04-87c8-bd6149891c2b","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:35.186237Z","iopub.execute_input":"2022-01-09T22:46:35.186444Z","iopub.status.idle":"2022-01-09T22:46:35.822165Z","shell.execute_reply.started":"2022-01-09T22:46:35.186418Z","shell.execute_reply":"2022-01-09T22:46:35.821448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = CatsDogsDataset(train_list, transform=train_transforms)\nvalid_data = CatsDogsDataset(valid_list, transform=test_transforms)\ntest_data = CatsDogsDataset(test_list, transform=test_transforms)","metadata":{"_uuid":"a27a0cef-dccf-4f0e-a204-09c9b32aecca","_cell_guid":"e4054f84-ccab-4030-b6c7-cd877798d8aa","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:35.823528Z","iopub.execute_input":"2022-01-09T22:46:35.823775Z","iopub.status.idle":"2022-01-09T22:46:36.328934Z","shell.execute_reply.started":"2022-01-09T22:46:35.82374Z","shell.execute_reply":"2022-01-09T22:46:36.328232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create dataloader, you can modify the batch size if needed","metadata":{"_uuid":"14ff676e-8fef-437a-bb2f-08e7c5a69f24","_cell_guid":"0bed416b-5fd7-4768-b7f7-ab1640dac8ec","trusted":true}},{"cell_type":"code","source":"batch_size = 96\ntrain_loader = DataLoader(\n    dataset=train_data, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(\n    dataset=valid_data, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(\n    dataset=test_data, batch_size=batch_size, shuffle=False)","metadata":{"_uuid":"f6795b9f-a4d6-4d14-b776-220c28e4de23","_cell_guid":"377a3a21-52cf-44f0-b186-778e6c7f1ba9","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:36.334884Z","iopub.execute_input":"2022-01-09T22:46:36.336906Z","iopub.status.idle":"2022-01-09T22:46:36.797306Z","shell.execute_reply.started":"2022-01-09T22:46:36.336864Z","shell.execute_reply":"2022-01-09T22:46:36.796543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ndef init_my_layer(m):\n    torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))\n    torch.nn.init.constant(m.bias, 0)\n    return m\n\n\nclass AlexNet(nn.Module):\n    def __init__(self):\n        super(AlexNet, self).__init__()\n        self.relu = nn.ReLU()\n        self.conv1 = init_my_layer(nn.Conv2d(3, 64, 3, padding=1))\n        self.conv2 = init_my_layer(nn.Conv2d(64, 128, 3, padding=1))\n        self.conv3 = init_my_layer(nn.Conv2d(128, 256, 3, padding=1))\n        self.conv4 = init_my_layer(nn.Conv2d(256, 384, 3))\n        self.conv5 = init_my_layer(nn.Conv2d(384, 256, 3))\n        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2)\n        self.ln1 = init_my_layer(nn.Linear(1024, 1024))\n        self.ln2 = init_my_layer(nn.Linear(1024, 2))\n        self.drop = nn.Dropout(0.5)\n\n    def forward(self, x):\n        x = self.max_pool(self.relu(self.conv1(x)))\n        x = self.max_pool(self.relu(self.conv2(x)))\n        x = self.max_pool(self.relu(self.conv3(x)))\n        x = self.max_pool(self.relu(self.conv4(x)))\n        x = self.max_pool(self.relu(self.conv5(x)))\n        x = x.reshape(x.size(0), -1)\n        x = self.drop(self.relu(self.ln1(x)))\n        return self.ln2(x)","metadata":{"_uuid":"6509d147-bb3b-498c-af18-7a51b5855b87","_cell_guid":"52716b33-b890-4c2b-8b2d-db5e59ecb4da","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:36.798746Z","iopub.execute_input":"2022-01-09T22:46:36.799013Z","iopub.status.idle":"2022-01-09T22:46:37.313518Z","shell.execute_reply.started":"2022-01-09T22:46:36.798977Z","shell.execute_reply":"2022-01-09T22:46:37.31278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = AlexNet()\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint('Detected device: {}'.format(device))\nnet.to(device)\n\nnum_epochs = 20\nlr = 1e-3\n\ncriterion = nn.CrossEntropyLoss()\nparams = net.parameters()\n# optimizer = torch.optim.AdamW(params, lr=lr,weight_decay=1e-3)\noptimizer = torch.optim.SGD(params, lr=lr)\n\nwandb.watch(net, log=\"all\", criterion=criterion, log_freq=1,  log_graph=(True))\nparams","metadata":{"_uuid":"0301b0f3-bd0f-422d-87f5-1b3b5f03bdfe","_cell_guid":"68f780e8-0484-42f2-83e0-e6e3f94841ab","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:37.316559Z","iopub.execute_input":"2022-01-09T22:46:37.316755Z","iopub.status.idle":"2022-01-09T22:46:37.855344Z","shell.execute_reply.started":"2022-01-09T22:46:37.31673Z","shell.execute_reply":"2022-01-09T22:46:37.854613Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    net.train()\n\n    for X, y in train_loader:\n        X = X.to(device)\n        y = y.to(device)\n\n        optimizer.zero_grad()\n        prediction = net(X)\n        loss = criterion(prediction, y)\n        loss.backward()\n        optimizer.step()\n\n        _, predictions = torch.max(prediction, 1)\n        \n        wandb.log({\n            'mlp/train_loss': loss.item(),\n            'mlp/train_accuracy': (y == predictions).sum()/len(y),\n        })\n\n\n    with torch.no_grad():\n        net.eval()\n        for X, y in valid_loader:\n            X = X.to(device)\n            y = y.to(device)\n\n            prediction = net(X)\n\n            loss = criterion(prediction, y)\n            _, predictions = torch.max(prediction, 1)\n        \n            wandb.log({\n                'mlp/val_loss': loss.item(),\n                'mlp/val_accuracy': (y == predictions).sum()/len(y),\n            })\n","metadata":{"_uuid":"c8eabc9a-2575-40b2-87ba-37978df132d6","_cell_guid":"2659b612-4db2-49d4-95a9-babb8088b5ec","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-01-09T22:46:37.856775Z","iopub.execute_input":"2022-01-09T22:46:37.857031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Submission**","metadata":{"_uuid":"91280ceb-b314-4465-bde5-0e40c300bb53","_cell_guid":"876e6144-5665-4dc0-8e6b-b4a62ef96d5d","trusted":true}},{"cell_type":"code","source":"with torch.no_grad():\n    net.eval()\n    test_pred = torch.LongTensor()\n    test_pred = test_pred.to(device)\n    for data, i in test_loader:\n        data = data.to(device)\n\n        prediction = net(data)\n        dog_props =  F.softmax(prediction, dim=1)[:, 0]\n        test_pred = torch.cat((test_pred, dog_props), dim=0)\n    out_df = pd.DataFrame(np.c_[np.arange(1, len(test_list)+1)[:, None],\n                                test_pred.cpu().numpy()], columns=['id', 'label'])\n    # out_df = out_df.astype({'id':'str', 'label':'str'})\n    out_df.to_csv('submission.csv', index=False)\n\nout_df","metadata":{"_uuid":"18138e77-5c10-4c2b-95e3-745472956ec6","_cell_guid":"a8233ab9-1ab0-4358-9110-88b43b640528","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}]}