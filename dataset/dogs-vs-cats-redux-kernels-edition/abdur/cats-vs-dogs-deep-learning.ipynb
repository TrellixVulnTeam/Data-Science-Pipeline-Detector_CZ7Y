{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Setting up the notebook by importing relevant packages"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import cv2                 \nimport os                  \nfrom tqdm import tqdm\nfrom random import shuffle","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extraction the training Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unzipping the input folder using command. \n!unzip ../input/dogs-vs-cats-redux-kernels-edition/train.zip -d train\n!unzip ../input/dogs-vs-cats-redux-kernels-edition/test.zip -d test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Defining the Parameters (directory, size etc.)"},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = '../working/train/train/'\nTEST_DIR = '../working/test/test/'\nIMG_SIZE = 64","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating the training and the test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntrain_dogs =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'dog' in i]\ntrain_cats =   [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR) if 'cat' in i]\n\ntest_images =  [TEST_DIR + i for i in os.listdir(TEST_DIR)]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bf417a41ec868563e785ce8eb94c1378a007ddfc","trusted":true},"cell_type":"code","source":"len(train_cats), len(train_dogs), len(train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# each record is path and name of the image. \ntrain_cats[0]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a7b4ddd56a5c6afdf72c067cbf481a3908012d3e","trusted":true},"cell_type":"code","source":"# Creating training and validation splits\ntrain_list = train_cats[:10000] + train_dogs[:10000]\nval_list = train_cats[10000:] + train_dogs[10000:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7b05ea5b748a4376c14802c3deab38bb52d22e7f","trusted":true},"cell_type":"code","source":"len(train_list), len(val_list)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4cdbe21640f736f1bf0d6b1e6388e20e1aceeacb","trusted":true},"cell_type":"code","source":"#Function for defining label\ndef label_img(img):\n    if 'cat' in img: return [0, 1]\n    elif 'dog' in img: return [1, 0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing the data "},{"metadata":{},"cell_type":"markdown","source":"## You see here that the training dats is still list of images. We have not converted the same into structured data"},{"metadata":{"_uuid":"ef15d28e7e33e1fbfbbe3939b363518066c29a7d","trusted":true},"cell_type":"code","source":"train_list[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Converting the data into arrays"},{"metadata":{"_uuid":"9bd0649abce0323da619ccdd3829f2fad0fa7f95","trusted":true},"cell_type":"code","source":"def create_train_data(train_list):\n    training_data = []\n    for img in tqdm(train_list):\n        label = label_img(img)\n        path = img\n        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([np.array(img),label])\n    shuffle(training_data)\n    return training_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"15135c267b5e0ba218393dd9ff882757149b45a2","scrolled":true,"trusted":true},"cell_type":"code","source":"#Creating array with data\ntrain = create_train_data(train_list)\nval = create_train_data(val_list)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding how data for each images has beeen created"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_list[1000]\n\ntrain[1000][1]\ntrain[1000][0]\n\nimport matplotlib.pyplot as plt\nprint('Label is ', train[1000][1])\nplt.imshow(train[1000][0])\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0978c870f75cd8caa2200f4daa12cc75e71a8719","trusted":true},"cell_type":"code","source":"#Creating training ad Validation arrays\nX = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE)\nY = [i[1] for i in train]\n\nval_X = np.array([i[0] for i in val]).reshape(-1,IMG_SIZE,IMG_SIZE)\nval_Y = [i[1] for i in val]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e3f8d348776024fb48a4afda1af5d04fb93dba58","trusted":true},"cell_type":"code","source":"#Scaling data for neural network\nX = X/float(255)\nval_X = val_X/float(255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f6cd0a98ad0dd45d50e4e16480f36c6edd858e34","trusted":true},"cell_type":"code","source":"Y = np.asarray(Y)\nval_Y = np.asarray(val_Y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final shape of your training and validation data"},{"metadata":{"_uuid":"4d740dbe6b4814cf11270273eb74cbfc40b8c6a0","trusted":true},"cell_type":"code","source":"X.shape, val_X.shape\nY.shape, val_Y.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Imorting relevant modules from Keras\nLayers, optimizers, model"},{"metadata":{"_uuid":"11c90e93ba999798859338f77e71b30da50578d7","trusted":true},"cell_type":"code","source":"#Importing keras libraries\nimport keras\nfrom keras.layers import Input, Dense, Flatten, Dropout\nfrom keras.optimizers import SGD, Adam\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using ANN (no convolutuional layers) to solve classification"},{"metadata":{"_uuid":"b0d6efa5e25bb9fba8633c0655b45c01893b857a","trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\n\n# Network Architecture\nx_input = Input(shape=(IMG_SIZE, IMG_SIZE))\nx = Flatten()(x_input)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dense(256, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dense(16, activation=\"relu\")(x)\nx_out = Dense(2, activation=\"softmax\")(x)\n\n#Specifying input and output\nmodel = Model(inputs=x_input, outputs=x_out)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"aa710764162ef1e854165e567a94bd22f1fa5046","trusted":true},"cell_type":"code","source":"# SGD with no momentum\nsgd = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\nmodel.compile(optimizer=sgd, loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6c77eca42acd74d698939f4442dda8d31f0b8fd","scrolled":true,"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46f805c7e7332c998dfd7ada92972a162acf4d12","scrolled":true,"trusted":true},"cell_type":"code","source":"history = model.fit(x=X, \n                    y=Y, \n                    validation_data=(val_X, val_Y), \n                    epochs = 30, \n                    batch_size=128, \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ca531b281c6d5b63bd62c98148db18dfbb1c918f","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();\n\nplt.figure()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modifying few hyper parameters and running the model - Checking the improvement in the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Running for more number of epochs\nkeras.backend.clear_session()\n\n# Network Architecture\nx_input = Input(shape=(IMG_SIZE, IMG_SIZE))\nx = Flatten()(x_input)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dense(256, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dense(16, activation=\"relu\")(x)\nx_out = Dense(2, activation=\"softmax\")(x)\n\n#Specifying input and output\nmodel = Model(inputs=x_input, outputs=x_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SGD with no momentum\nsgd = SGD(lr=0.001, momentum=0.0, decay=0.0, nesterov=False)\nmodel.compile(optimizer=sgd, loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=X, \n                    y=Y, \n                    validation_data=(val_X, val_Y), \n                    epochs = 80, \n                    batch_size=128, \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Evaluation the model - accuracy improvement"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();\n\nplt.figure()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using momentum (usually helps with faster convergence)\nkeras.backend.clear_session()\n\n# Network Architecture\nx_input = Input(shape=(IMG_SIZE, IMG_SIZE))\nx = Flatten()(x_input)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dense(256, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dense(16, activation=\"relu\")(x)\nx_out = Dense(2, activation=\"softmax\")(x)\n\n#Specifying input and output\nmodel = Model(inputs=x_input, outputs=x_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SGD with no momentum\nsgd = SGD(lr=0.001, momentum=0.9, decay=0.0, nesterov=False)\nmodel.compile(optimizer=sgd, loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=X, \n                    y=Y, \n                    validation_data=(val_X, val_Y), \n                    epochs = 80, \n                    batch_size=128, \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();\n\nplt.figure()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using Adam Optimizer (Adam can converge faster but sometimes may have convergence issues.)\n# SGD + momentum can have better convergence than Adam (but Adam is more fast)\nkeras.backend.clear_session()\n\n# Network Architecture\nx_input = Input(shape=(IMG_SIZE, IMG_SIZE))\nx = Flatten()(x_input)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dense(256, activation=\"relu\")(x)\nx = Dense(64, activation=\"relu\")(x)\nx = Dense(16, activation=\"relu\")(x)\nx_out = Dense(2, activation=\"softmax\")(x)\n\n#Specifying input and output\nmodel = Model(inputs=x_input, outputs=x_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adam with no momentum\nadam = Adam(lr=0.001, beta_1=0.9, beta_2=0.9, decay=0.0, amsgrad=False)\nmodel.compile(optimizer=adam, loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=X, \n                    y=Y, \n                    validation_data=(val_X, val_Y), \n                    epochs = 80, \n                    batch_size=512, \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();\n\nplt.figure()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using CNN to solve the image classification problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.layers import Input, Dense, Flatten, Dropout\nfrom keras.layers import MaxPooling2D, Conv2D\nfrom keras.optimizers import SGD, Adam\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\n#Network Architecture\nx_input = Input(shape=(IMG_SIZE, IMG_SIZE, 1))\n\nx = Conv2D(64, (3, 3), padding=\"same\", activation='relu')(x_input)\nx = MaxPooling2D(pool_size=(2, 2))(x)\nx = Conv2D(64, (3, 3), padding=\"same\", activation='relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\n#Additional Layer\nx = Conv2D(128, (3, 3), padding=\"same\", activation='relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\nx = Conv2D(128, (3, 3), padding=\"same\", activation='relu')(x)\nx = MaxPooling2D(pool_size=(2, 2))(x)\n\nx = Flatten()(x)\n\n#Additional Layer\nx = Dense(512, activation=\"relu\")(x)\n\n#x = Dropout(0.3)(x)\n\nx = Dense(16, activation=\"relu\")(x)\nx_out = Dense(2, activation=\"softmax\")(x)\n\n#Specifying input and output\nmodel = Model(inputs=x_input, outputs=x_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = SGD(lr=0.01, momentum=0.8, decay=0.00, nesterov=False)\n\nmodel.compile(optimizer=sgd, loss = \"binary_crossentropy\", metrics=[\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=X.reshape(X.shape[0], X.shape[1], X.shape[2], 1), \n                    y=Y, \n                    validation_data=(val_X.reshape(val_X.shape[0], val_X.shape[1], val_X.shape[2], 1), val_Y), \n                    epochs = 80, \n                    batch_size=512, \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(val_X.reshape(val_X.shape[0], val_X.shape[1], val_X.shape[2], 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(val_X.reshape(val_X.shape[0], val_X.shape[1], val_X.shape[2], 1)).argmax(axis= 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Using Transfer Learning to Solve The Classification Problem"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import VGG16\nlower_layers = VGG16(weights= 'imagenet',\n                    include_top= False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\n#Network Architecture\nx_input = Input(shape=(IMG_SIZE, IMG_SIZE, 3))\n\nx = lower_layers(x_input)\nx = Flatten()(x)\n\n#Additional Layer\nx = Dense(256, activation=\"relu\")(x)\nx_out = Dense(2, activation=\"softmax\")(x)\n\n#Specifying input and output\nmodel = Model(inputs=x_input, outputs=x_out)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_layers.trainable = True\nfor layer in lower_layers.layers:\n    if layer.name == 'block5_conv1':\n        layer.trainable = True\n    else:\n        layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sgd = SGD(lr=0.01, momentum=0.8, decay=0.00, nesterov=False)\n\nmodel.compile(loss= 'binary_crossentropy', optimizer= sgd, metrics= ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function for resizing images\ndef create_train_data(train_list):\n    training_data = []\n    for img in tqdm(train_list):\n        label = label_img(img)\n        path = img\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([np.array(img),label])\n    shuffle(training_data)\n    return training_data\n\n\n#Creating array with data\ntrain_transfer = create_train_data(train_list)\nval_transfer = create_train_data(val_list)\n\n#Creating training ad Validation arrays\nX_transfer = np.array([i[0] for i in train_transfer]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nY_transfer = [i[1] for i in train_transfer]\n\nval_X_transfer = np.array([i[0] for i in val_transfer]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nval_Y_transfer = [i[1] for i in val_transfer]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling data for neural network\nX_transfer = X_transfer/float(255)\nval_X_transfer = val_X_transfer/float(255)\n\nY_transfer = np.asarray(Y_transfer)\nval_Y_transfer = np.asarray(val_Y_transfer)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_Y_transfer.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x=X_transfer, \n                    y=Y_transfer, \n                    validation_data=(val_X_transfer, val_Y_transfer), \n                    epochs = 50, \n                    batch_size=512, \n                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();\n\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'validation'], loc='upper left')\nplt.show();","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}