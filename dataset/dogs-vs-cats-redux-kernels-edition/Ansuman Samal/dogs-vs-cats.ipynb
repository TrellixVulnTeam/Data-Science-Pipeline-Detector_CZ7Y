{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-17T06:47:03.285718Z","iopub.execute_input":"2022-03-17T06:47:03.286111Z","iopub.status.idle":"2022-03-17T06:47:03.312662Z","shell.execute_reply.started":"2022-03-17T06:47:03.286017Z","shell.execute_reply":"2022-03-17T06:47:03.311808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# This is an attempt on testing the Cats vs Dogs dataset on a smaller version of the GooleNet\nFirst We Extract the files into the working directory","metadata":{}},{"cell_type":"code","source":"import zipfile\n\ntrain_zip='/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip'\nzip_ref=zipfile.ZipFile(train_zip,'r')\nzip_ref.extractall('/kaggle/working/')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:03.314308Z","iopub.execute_input":"2022-03-17T06:47:03.314571Z","iopub.status.idle":"2022-03-17T06:47:16.710747Z","shell.execute_reply.started":"2022-03-17T06:47:03.314543Z","shell.execute_reply":"2022-03-17T06:47:16.709875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Lets view our image files**","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nwork='/kaggle/working'\ntrain_path='/kaggle/working/train/'\nfile_items=os.listdir(train_path)\n\nfig,([ax1,ax2,ax3,ax4,ax5],[ax6,ax7,ax8,ax9,ax10])=plt.subplots(2,5,figsize=(15,10))\nfigs=[ax1,ax2,ax3,ax4,ax5,ax6,ax7,ax8,ax9,ax10]\n\nfor i in range(10):\n    k=mpimg.imread(os.path.join(train_path,file_items[i]))\n    figs[i].imshow(k)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:16.712318Z","iopub.execute_input":"2022-03-17T06:47:16.712936Z","iopub.status.idle":"2022-03-17T06:47:18.097437Z","shell.execute_reply.started":"2022-03-17T06:47:16.712892Z","shell.execute_reply":"2022-03-17T06:47:18.096753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We sort the files into categories by checking the file name","metadata":{}},{"cell_type":"code","source":"import re\n\ndef labeler(value):\n    cat_or_dog=re.findall('\\w{3}',value)[0].lower()\n    if cat_or_dog=='dog':\n        return 1\n    elif cat_or_dog=='cat':\n        return 0\n    else:\n        return None\n\n# listed=['dog.10667.jpg','cat']\nlabels=list(map(labeler,file_items))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:18.098776Z","iopub.execute_input":"2022-03-17T06:47:18.099407Z","iopub.status.idle":"2022-03-17T06:47:18.148527Z","shell.execute_reply.started":"2022-03-17T06:47:18.099376Z","shell.execute_reply":"2022-03-17T06:47:18.147741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creating the directories for separating the images into Train & Valid set of two categories  ","metadata":{}},{"cell_type":"markdown","source":"**code to create directory**","metadata":{}},{"cell_type":"code","source":"os.mkdir(f'{work}/valid')\nos.mkdir(f'{work}/valid/dogs')\nos.mkdir(f'{work}/valid/cats')\nos.mkdir(f'{train_path}dogs')\nos.mkdir(f'{train_path}cats')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:18.149867Z","iopub.execute_input":"2022-03-17T06:47:18.150301Z","iopub.status.idle":"2022-03-17T06:47:18.154212Z","shell.execute_reply.started":"2022-03-17T06:47:18.15026Z","shell.execute_reply":"2022-03-17T06:47:18.153397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The following code is to separate the data into train and test sets","metadata":{}},{"cell_type":"code","source":"df_dc=pd.DataFrame([file_items,labels],['file','label'])\ndf_dc=df_dc.transpose()\ndf_dc.iloc[3]['label']\nvalid_df=df_dc.iloc[-6250:]\ntrain_df=df_dc.iloc[:-6250] \n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:18.155326Z","iopub.execute_input":"2022-03-17T06:47:18.15609Z","iopub.status.idle":"2022-03-17T06:47:19.004257Z","shell.execute_reply.started":"2022-03-17T06:47:18.156048Z","shell.execute_reply":"2022-03-17T06:47:19.003546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets transfer the cats and dogs pictures into thier respective directories","metadata":{}},{"cell_type":"code","source":"#train_directory\ncat_train=f'{train_path}cats/'\ndog_train=f'{train_path}dogs/'\n\n#valid_directory\ncat_val=f'{work}/valid/cats/'\ndog_val=f'{work}/valid/dogs/'\n\ndef change_dir_train(value):\n    if value.label==0:\n        os.rename(f'{train_path}{value.file}',f'{cat_train}{value.file}')\n    elif value.label==1:\n        os.rename(f'{train_path}{value.file}',f'{dog_train}{value.file}')\n        \ndef change_dir_valid(value):\n    if value.label==0:\n        os.rename(f'{train_path}{value.file}',f'{cat_val}{value.file}')\n    elif value.label==1:\n        os.rename(f'{train_path}{value.file}',f'{dog_val}{value.file}')\n        \n#send to directory\ntrain_df.apply(change_dir_train,axis=1)\nvalid_df.apply(change_dir_valid,axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:19.005632Z","iopub.execute_input":"2022-03-17T06:47:19.006036Z","iopub.status.idle":"2022-03-17T06:47:20.406666Z","shell.execute_reply.started":"2022-03-17T06:47:19.005992Z","shell.execute_reply":"2022-03-17T06:47:20.405849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Checking the number of items in each of the directories","metadata":{}},{"cell_type":"code","source":"dog_train_path='/kaggle/working/train/dogs'\ncat_train_path='/kaggle/working/train/cats'\ndog_valid_path='/kaggle/working/valid/dogs'\ncat_valid_path='/kaggle/working/valid/cats'\n\ndog_train_items=os.listdir(dog_train_path)\ncat_train_items=os.listdir(cat_train_path)\ncat_val_items=os.listdir(cat_valid_path)\ndog_val_items=os.listdir(dog_valid_path)\nprint(f'''train set items for dogs: {len(dog_train_items)}\ntrain set items for cats: {len(cat_train_items)}\nvalid set items for dogs: {len(dog_val_items)}\nvalid set items for cats: {len(cat_val_items)}''')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:20.407784Z","iopub.execute_input":"2022-03-17T06:47:20.408053Z","iopub.status.idle":"2022-03-17T06:47:20.427272Z","shell.execute_reply.started":"2022-03-17T06:47:20.408025Z","shell.execute_reply":"2022-03-17T06:47:20.426394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**code to remove all directories**","metadata":{}},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('/kaggle/working/valid')\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:20.429503Z","iopub.execute_input":"2022-03-17T06:47:20.429734Z","iopub.status.idle":"2022-03-17T06:47:20.433054Z","shell.execute_reply.started":"2022-03-17T06:47:20.429706Z","shell.execute_reply":"2022-03-17T06:47:20.432136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Image preprocessing**\n\nImage preprocessing is only done to identify the categories and rescaling..\nNot much Data Augmentation was done here since our goal was just to test the network.","metadata":{}},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen=ImageDataGenerator(rescale=1/255)\nvalid_datagen=ImageDataGenerator(rescale=1/255)\n\n\ntrain_generator=train_datagen.flow_from_directory(\n    train_path,\n    target_size=(150,150),\n    batch_size=32,\n    class_mode='binary')\n\nvalid_generator=valid_datagen.flow_from_directory(\n    f'{work}/valid',\n    target_size=(150,150),\n    batch_size=64,\n    class_mode='binary')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:20.434327Z","iopub.execute_input":"2022-03-17T06:47:20.434551Z","iopub.status.idle":"2022-03-17T06:47:27.628527Z","shell.execute_reply.started":"2022-03-17T06:47:20.434524Z","shell.execute_reply":"2022-03-17T06:47:27.627469Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Making the ConvNet \n\nCreating inception layers narrows down the computing cost and the number of parameters\n","metadata":{}},{"cell_type":"code","source":"\nimport tensorflow as tf\nfrom tensorflow import keras\n\ninput=keras.layers.Input(shape=(150,150,3))\nlayer0=keras.layers.Conv2D(32,(3,3),activation='relu')(input)\nlayer1=keras.layers.MaxPooling2D(2,2)(layer0)\n#1st inception layer\npool=keras.layers.MaxPooling2D(3,1)(layer1)\npool_transfer=keras.layers.Conv2D(4,(1,1),activation='relu')(pool)\nconv1=keras.layers.Conv2D(4,(3,3),activation='relu')(layer1)\nlayer2=keras.layers.Conv2D(28,(1,1),activation='relu')(layer1)\nlayer3=keras.layers.Conv2D(28,(1,1),activation='relu')(layer1)\nlayer4=keras.layers.Conv2D(28,(3,3),activation='relu')(layer2)\nlayered=keras.layers.Conv2D(28,(3,3),activation='relu')(layer3)\nlayer5=keras.layers.Concatenate()([layered,layer4,pool_transfer,conv1])\n#2nd inception layer\nlayer1_=keras.layers.MaxPool2D(3,3)(layer5)\npool_=keras.layers.MaxPooling2D(3,1)(layer1_)\npool_transfer_=keras.layers.Conv2D(4,(1,1),activation='relu')(pool_)\nconv11_=keras.layers.Conv2D(4,(3,3),activation='relu')(layer1_)\nlayer2_=keras.layers.Conv2D(28,(1,1),activation='relu')(layer1_)\nlayer3_=keras.layers.Conv2D(28,(1,1),activation='relu')(layer1_)\nlayer4_=keras.layers.Conv2D(28,(3,3),activation='relu')(layer2_)\nlayered_=keras.layers.Conv2D(28,(3,3),activation='relu')(layer3_)\nlayer8_=keras.layers.Concatenate()([layered_,layer4_,pool_transfer_,conv11_])\n#3rd inception layer\nlayer1_1=keras.layers.MaxPool2D(3,3)(layer8_)\npool_1=keras.layers.MaxPooling2D(3,1)(layer1_1)\npool_transfer_1=keras.layers.Conv2D(8,(1,1),activation='relu')(pool_1)\nconv11=keras.layers.Conv2D(8,(3,3),activation='relu')(layer1_1)\nlayer2_1=keras.layers.Conv2D(36,(1,1),activation='relu')(layer1_1)\nlayer3_1=keras.layers.Conv2D(36,(1,1),activation='relu')(layer1_1)\nlayer4_1=keras.layers.Conv2D(36,(3,3),activation='relu')(layer2_1)\nlayered_1=keras.layers.Conv2D(36,(3,3),activation='relu')(layer3_1)\nlayer8_1=keras.layers.Concatenate()([layered_1,layer4_1,pool_transfer_1,conv11])\nle12=keras.layers.Flatten()(layer8_1)\nle2=keras.layers.Dense(128,activation='relu')(le12)\noutput=keras.layers.Dense(1,activation='sigmoid')(le2)\nmodel=keras.models.Model(inputs=input,outputs=output)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:27.630423Z","iopub.execute_input":"2022-03-17T06:47:27.630676Z","iopub.status.idle":"2022-03-17T06:47:27.949733Z","shell.execute_reply.started":"2022-03-17T06:47:27.630648Z","shell.execute_reply":"2022-03-17T06:47:27.948874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Lets Checkout the model ","metadata":{}},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:27.951009Z","iopub.execute_input":"2022-03-17T06:47:27.951274Z","iopub.status.idle":"2022-03-17T06:47:27.973747Z","shell.execute_reply.started":"2022-03-17T06:47:27.951245Z","shell.execute_reply":"2022-03-17T06:47:27.972889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='binary_crossentropy',\n             optimizer=RMSprop(learning_rate=0.001),\n             metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:27.975306Z","iopub.execute_input":"2022-03-17T06:47:27.975596Z","iopub.status.idle":"2022-03-17T06:47:27.990864Z","shell.execute_reply.started":"2022-03-17T06:47:27.975559Z","shell.execute_reply":"2022-03-17T06:47:27.990064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Fitting the model to the Train set. Here the Image Data Generator passes 32 images in each step and calculates the loss... The procedure is similar to Mini-Batch Gradient Descent where we pass a batch of data step by step instead of the whole data.","metadata":{}},{"cell_type":"code","source":"model.fit(train_generator,\n         steps_per_epoch=585,\n         epochs=10,\n         verbose=1,\n         validation_data=valid_generator,\n         validation_steps=97)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T06:47:27.992508Z","iopub.execute_input":"2022-03-17T06:47:27.992737Z","iopub.status.idle":"2022-03-17T07:38:33.475468Z","shell.execute_reply.started":"2022-03-17T06:47:27.992711Z","shell.execute_reply":"2022-03-17T07:38:33.474132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model shows almost 88% accuracy on the test set... With a Few more iterations we can reach above 90% accuraccy for the calssifier.","metadata":{}}]}