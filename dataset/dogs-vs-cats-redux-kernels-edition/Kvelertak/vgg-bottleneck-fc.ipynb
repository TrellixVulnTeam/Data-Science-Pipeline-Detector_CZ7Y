{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"collapsed":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the \"../input/\" directory.\n# # For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# import os\n# print(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"collapsed":true},"cell_type":"code","source":"# !mkdir dataset\n# !mkdir dataset/dogs\n# !mkdir dataset/cats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b700ea7ea12a5293ef86518c5c05ba93a619ac27"},"cell_type":"code","source":"!ls -ltr dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"eb9a1a30687896d6a1afe154ca0c1c0cee9c771c"},"cell_type":"code","source":"import numpy as np\nimport keras\nfrom keras.models import Model\nfrom keras.applications import mobilenet\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.vgg16 import preprocess_input\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nimport os\nimport re\nfrom random import shuffle\nfrom glob import glob\nimport shutil  as sh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"932e0c29e8eeb66c59ddb2c083f23e7f2f0213e1","collapsed":true},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"757ac57ea9c58e4e15ca0de5a7e0a7d4fe94631e","collapsed":true},"cell_type":"code","source":"IMG_SIZE = (224, 224)  # размер входного изображения сети","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b382c2877d4167506497a63e98e6462dfaf34b64","collapsed":true},"cell_type":"code","source":"train_files = glob('../input/train/*.jpg')\ntest_files = glob('../input/test/*.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"249724188959c12fba4a260c6f347b0be3695c6c","collapsed":true},"cell_type":"code","source":"#Only once for creating train dir - uncomment to execute\n\n# dataset_dir = 'dataset'\n# for path  in train_files:\n#     fname =  os.path.basename(path)\n# #     print(os.path.join(dataset_dir,'dogs',fname))\n# #     break\n    \n#     if re.match('.*/dog\\.\\d', path):        \n#         sh.copyfile(path, os.path.join(dataset_dir,'dogs',fname))\n#     else:\n#         sh.copyfile(path, os.path.join(dataset_dir,'cats',fname))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8ee1556791417b4cdd8712818f78f87dbb32a43d","collapsed":true},"cell_type":"code","source":"train_dir = 'dataset/'\ntest_dir = '../input/test'   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"250e66cfd886d64eb2647697e6f96ec511106e5e","collapsed":true},"cell_type":"code","source":"# !ls -ltr dataset/cats\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5f0aea835688c271eb752cdd2c4a3a89f9d0698b"},"cell_type":"markdown","source":"**MobileNet model**"},{"metadata":{"_uuid":"87ec7a7875a001018f9be5c535047ec5446e326d"},"cell_type":"markdown","source":"train top features"},{"metadata":{"trusted":true,"_uuid":"5fca5be89bcadc992686c221c8b8118ce1964d42","collapsed":true},"cell_type":"code","source":"# #save_bottlebeck_features()\n# batch_size=8\n# datagen = ImageDataGenerator(rescale=1. / 255,\n#                                  validation_split = 0.12,\n#                                  preprocessing_function = mobilenet.preprocess_input)\n\n# # build the VGG16 network\n# model = VGG16(include_top = False,\n#                    weights = 'imagenet',\n#                    input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3))\n\n# generator = datagen.flow_from_directory(\n#     train_dir,\n#     target_size=IMG_SIZE,\n#     batch_size=batch_size,\n#     class_mode='binary',\n#     shuffle=False,\n#     subset = 'training')\n# nb_train_samples = generator.n\n# bottleneck_features_train = model.predict_generator(\n#     generator, nb_train_samples // batch_size , max_queue_size=500)\n# np.save(open('bottleneck_features_train.npy', 'wb'),\n#         bottleneck_features_train)\n\n# generator = datagen.flow_from_directory(\n#     train_dir,\n#     target_size=IMG_SIZE,\n#     batch_size=batch_size,\n#     class_mode='binary',\n#     shuffle=False,\n#     subset = 'validation')\n# nb_validation_samples = generator.n\n# bottleneck_features_validation = model.predict_generator(\n#     generator, nb_validation_samples // batch_size , max_queue_size=500)\n# np.save(open('bottleneck_features_validation.npy', 'wb'),\n#         bottleneck_features_validation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ab716bb5c065a31c87e1b0a68a919a41b16ae71a","collapsed":true},"cell_type":"code","source":"# batch_size=8\n# datagen = ImageDataGenerator(rescale=1. / 255,\n#                                  validation_split = 0.12,\n#                                  preprocessing_function = preprocess_input)\n\n# train_generator = datagen.flow_from_directory(\n#     train_dir,\n#     target_size=IMG_SIZE,\n#     batch_size=batch_size,\n#     class_mode='binary',\n#     shuffle=False,\n#     subset = 'training')\n\n# valid_generator = datagen.flow_from_directory(\n#     train_dir,\n#     target_size=IMG_SIZE,\n#     batch_size=batch_size,\n#     class_mode='binary',\n#     shuffle=False,\n#     subset = 'validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"87fbe2fac39b4f3f2d8d8f5df9a5c77d77cc0602","collapsed":true},"cell_type":"code","source":"# train_data = np.load(open('bottleneck_features_train.npy','rb'))\n# # the features were saved in order, so recreating the labels is easy\n# train_labels = train_generator.classes\n\n# validation_data = np.load(open('bottleneck_features_validation.npy','rb'))\n# validation_labels = valid_generator.classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"411589eba0e7e13e2b2df4e9072ab80f19ddac9e","collapsed":true},"cell_type":"code","source":"# fig = plt.figure(figsize=(20, 20))\n# for i, path in enumerate(train_data[:10], 1):\n#     subplot = fig.add_subplot(i // 5 + 1, 5, i)\n#     plt.imshow(plt.imread(path));\n#     subplot.set_title('%d', train_labels[i]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1a35724c5b19dc04fd418f6fd128297c5e364feb","collapsed":true},"cell_type":"code","source":"# train_data.shape, train_labels.shape, validation_data.shape, validation_labels.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c95c0639e8985cd38cbea9b960138bc00f903fbc"},"cell_type":"code","source":"batch_size = 16\n\n# this is the augmentation configuration we will use for training\ntrain_datagen = ImageDataGenerator(                            \n                            rotation_range=40,\n                            width_shift_range=0.3,\n                            height_shift_range=0.3,\n                            rescale=1./255,\n                            shear_range=0.2,\n                            zoom_range=0.3,\n                            horizontal_flip=True,\n                            fill_mode='nearest',\n                            validation_split = 0.12,\n                            preprocessing_function = preprocess_input)\n\n# this is the augmentation configuration we will use for testing:\n# only rescaling\npredict_datagen = ImageDataGenerator(rescale=1./255)\n\n# this is a generator that will read pictures found in\n# subfolers of 'data/train', and indefinitely generate\n# batches of augmented image data\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # this is the target directory\n        target_size=IMG_SIZE,  # all images will be resized to 150x150\n        shuffle=True, \n        seed=13,\n        batch_size=batch_size,\n        class_mode='binary',\n        subset = 'training')  \n# this is a similar generator, for validation data\nvalidation_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=IMG_SIZE,\n        shuffle=True, \n        seed=13,\n        batch_size=batch_size,\n        class_mode='binary',\n        subset=\"validation\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1864f9baeb8103985e3e8907bf5ca177b4986914"},"cell_type":"code","source":"base_model = VGG16(include_top = False,\n                   weights = 'imagenet',\n                   input_shape = (IMG_SIZE[0], IMG_SIZE[1], 3))\n# фиксируем все веса предобученной сети\nfor layer in base_model.layers:\n    layer.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43a089d8b53a27a85daea7cbebfe653fe6f871a2"},"cell_type":"code","source":"# base_model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc4390c33589d49c5c9c87f20323b61f9732ba33","collapsed":true},"cell_type":"code","source":"# define the checkpoint\nbottleneck_filepath = 'bottleneck_fc_model_1.h5'\ncheckpoint = ModelCheckpoint(bottleneck_filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\ncallbacks_list = [checkpoint]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23c260a871aba4d6475e6e9cc33b9c6b7718238d","collapsed":true},"cell_type":"code","source":"x = base_model.layers[-1].output\nx = keras.layers.Flatten()(x)\nx = keras.layers.Dense(2048, activation='relu',\n                          kernel_regularizer=keras.regularizers.l2(1e-5))(x)\nx = keras.layers.Dropout(0.5)(x)\nx = keras.layers.Dense(1024, activation='relu',\n                          kernel_regularizer=keras.regularizers.l2(1e-5))(x)\nx = keras.layers.Dropout(0.5)(x)\nx = keras.layers.Dense(1,  # один выход\n                activation='sigmoid',  # функция активации  \n                kernel_regularizer=keras.regularizers.l2(1e-4))(x)\ntopLayersModel = Model(inputs=base_model.input, outputs=x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d9504f2078616cf986094a889be7e18a031e801"},"cell_type":"code","source":"# topLayersModel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"b387c9a794922eaa3722217c98a20ccce1138e38"},"cell_type":"code","source":"topLayersModel.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6a03033c6c1ef3b57a5f7519f060ce24f5508099"},"cell_type":"code","source":"# topLayersModel.fit_generator(train_generator,  # данные читаем функцией-генератором\n#                     steps_per_epoch=22500 // batch_size , # число вызовов генератора за эпоху\n#                     epochs=10,  # число эпох обучения\n#                     validation_data=validation_generator,\n#                     validation_steps=2500 // batch_size,\n#                     callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"90efe54be2d5b7197304d39cec91a9e17d544e46"},"cell_type":"code","source":"topLayersModel= keras.models.load_model('bottleneck_fc_model_1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"c6e1135882e21e6adb56734f7794901fb34db37a"},"cell_type":"code","source":"# загружаем входное изображение и предобрабатываем\ndef load_image(path, target_size=IMG_SIZE):\n    img = load_img(path, target_size=target_size)  # загрузка и масштабирование изображения\n    array = img_to_array(img)\n    return preprocess_input(array)  # предобработка для VGG16\n# генератор последовательного чтения тестовых данных с диска\ndef test_generator(files):\n    while True:\n        for path in files:\n            yield np.array([load_image(path)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a49ccf45f29dbaefac0bdac31897724d8be5cb03"},"cell_type":"code","source":"pred = topLayersModel.predict_generator(test_generator(test_files), len(test_files), max_queue_size=500)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cbe165d10d1345a8e3bbe4e18c793be8e0f88288"},"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(figsize=(20, 20))\nfor i, (path, score) in enumerate(zip(test_files[90:][:10], pred[90:][:10]), 1):\n    subplot = fig.add_subplot(i // 5 + 1, 5, i)\n    plt.imshow(plt.imread(path));\n    subplot.set_title('%.3f' % score);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"61ebbe317f222710ba6c553c4e49934852001238"},"cell_type":"code","source":"with open('submit_vgg_bottleneck.txt', 'w') as dst:\n    dst.write('id,label\\n')\n    for path, score in zip(test_files, pred):\n        dst.write('%s,%f\\n' % (re.search('(\\d+)', path).group(0), score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"dfa6281ed75c3a2fbbc8b176bb0d3b1494d18e40"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true,"_uuid":"1e08afe822073562dc00958892e2e43ae95810b6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}