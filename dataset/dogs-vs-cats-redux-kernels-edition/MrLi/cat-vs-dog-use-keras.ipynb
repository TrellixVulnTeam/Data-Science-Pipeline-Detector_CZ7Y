{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Prepare data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_dir = '../input/train/'\ntest_dir = '../input/test/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images = [train_dir + i for i in os.listdir(train_dir)]\ntrain_cats = [train_dir + i for i in os.listdir(train_dir) if 'cat' in i]\ntrain_dogs = [train_dir + i for i in os.listdir(train_dir) if 'dog' in i]\n\ntest_images =  [test_dir + i for i in os.listdir(test_dir)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('the number of total train images:',len(train_images))\nprint('the number of train cats images:',len(train_cats))\nprint('the number of train dogs images:',len(train_dogs))\nprint('the number of total test images:',len(test_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(100)\n\noriginal_train_images = train_dogs[:12000] + train_cats[:12000]\n\nevaluation_images = train_dogs[12000:12500] + train_cats[12000:12500]\n\nrandom.shuffle(evaluation_images)\nrandom.shuffle(original_train_images)\n\nsection = int(len(original_train_images) * 0.75)\n\ntrain_images = original_train_images[:section]\nvalidation_images = original_train_images[section:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_images))\nprint(len(validation_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# imgsize = 150\n# channels = 3\n\n# def read_images(one_img):\n#     img = cv2.imread(one_img,cv2.IMREAD_ANYCOLOR)\n#     img_arr = cv2.resize(img,(imgsize,imgsize),interpolation=cv2.INTER_CUBIC)\n#     img_arr = img_arr / 255.0\n#     return img_arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# im = read_images(tr_images[0])\n# plt.imshow(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# def pre_data(images):\n#     lens = len(images)\n#     data = np.ndarray((lens,imgsize,imgsize,channels), dtype=np.uint8)\n    \n#     for i, img_file in enumerate(images):\n#         image = read_images(img_file)\n#         label = np.where('dog' in tr_images[i],1,0)\n#         data[i] = image\n        \n#     return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import image\n\nimgsize = 150\nchannels = 3\n\ndef prep_data(images):\n    count = len(images)\n    X = np.ndarray((count, imgsize, imgsize, channels), dtype=np.float32)\n    y = np.zeros((count,), dtype=np.float32)\n    \n    for i, image_file in enumerate(images):\n        img = image.load_img(image_file, target_size=(imgsize, imgsize))\n        X[i] = image.img_to_array(img)\n        if 'dog' in image_file:\n            y[i] = 1.\n        if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n    \n    return X, y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = prep_data(train_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train shape: \",X_train.shape)\nprint(\"Train shape: \",y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_validation, y_validation = prep_data(validation_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = image.ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,)\n\nvalidation_datagen = image.ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 128\n\ntrain_generator = train_datagen.flow(\n    X_train,\n    y_train,\n    batch_size=BATCH_SIZE)\n\nvalidation_generator = validation_datagen.flow(\n    X_validation,\n    y_validation,\n    batch_size=BATCH_SIZE)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model**"},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten\nfrom keras.optimizers import RMSprop\nfrom keras.models import Sequential\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation = 'relu',input_shape = (imgsize,imgsize,channels)))\nmodel.add(MaxPooling2D((2,2)))\n\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = Sequential()\n\n# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=train.shape[1:]))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(64, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(128, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(256, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Flatten())\n# model.add(Dense(512, activation='relu'))\n# model.add(Dropout(0.5))\n\n# model.add(Dense(1, activation='sigmoid'))\n\n# model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"train_steps = len(train_images)/BATCH_SIZE\nvalidation_steps = len(validation_images)/BATCH_SIZE\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_steps,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=validation_steps,\n    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1,len(acc)+1)\nplt.plot(epochs,acc,'bo',label = 'Training acc')\nplt.plot(epochs,val_acc,'b',label = 'Validation acc')\nplt.title('Training and Validation accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.figure()\n\nepochs = range(1,len(acc)+1)\nplt.plot(epochs,loss,'bo',label = 'Training loss')\nplt.plot(epochs,val_loss,'b',label = 'Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('dogs-v-cat-data-1.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nwith open('dogs-v-cat-data-1.h5-history.json', 'w') as f:\n    json.dump(history.history, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_evaluation, y_evaluation = prep_data(evaluation_images)\nX_evaluation /= 255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation = model.evaluate(X_evaluation, y_evaluation)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluation","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test, _ = prep_data(test_images)\nX_test /= 255.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(0,10):\n    if predictions[i, 0] >= 0.5: \n        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n    else: \n        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n        \n    plt.imshow(image.array_to_img(X_test[i]))\n    plt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}