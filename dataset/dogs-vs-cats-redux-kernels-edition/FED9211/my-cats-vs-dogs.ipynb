{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-12T13:12:11.956238Z","iopub.execute_input":"2022-04-12T13:12:11.956572Z","iopub.status.idle":"2022-04-12T13:12:11.960698Z","shell.execute_reply.started":"2022-04-12T13:12:11.956542Z","shell.execute_reply":"2022-04-12T13:12:11.959817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.applications import vgg16\n\nprint(tf.__version__)\nprint(tf.executing_eagerly())\n\nimport os\nfrom random import shuffle\nfrom glob import glob\n\nimport seaborn as sns","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:13.727769Z","iopub.execute_input":"2022-04-12T13:12:13.728162Z","iopub.status.idle":"2022-04-12T13:12:18.549623Z","shell.execute_reply.started":"2022-04-12T13:12:13.728134Z","shell.execute_reply":"2022-04-12T13:12:18.54886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!unzip -q ../input/dogs-vs-cats-redux-kernels-edition/test.zip\n!unzip -q ../input/dogs-vs-cats-redux-kernels-edition/train.zip","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:21.435522Z","iopub.execute_input":"2022-04-12T13:12:21.435863Z","iopub.status.idle":"2022-04-12T13:12:35.718105Z","shell.execute_reply.started":"2022-04-12T13:12:21.435828Z","shell.execute_reply":"2022-04-12T13:12:35.717014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMG_SIZE = (224, 224)  # размер входного изображения сети\n\ntrain_files = glob('./train/*.jpg')\ntest_files = glob('./test/*.jpg')\n# train_files_full = glob('data/train/*.jpg')\n# test_files_full = glob('data/test/*.jpg')\n\nprint(f'Количество тренировочных файлов', len(train_files))\nprint(f'Количество тестовых файлов',len(test_files))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:39.613217Z","iopub.execute_input":"2022-04-12T13:12:39.613572Z","iopub.status.idle":"2022-04-12T13:12:39.740719Z","shell.execute_reply.started":"2022-04-12T13:12:39.613541Z","shell.execute_reply":"2022-04-12T13:12:39.739877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# загружаем входное изображение и предобрабатываем\ndef load_image(path, target_size=IMG_SIZE):\n    img = cv2.imread(path)[...,::-1]\n    img = cv2.resize(img, target_size)\n    return vgg16.preprocess_input(img)  # предобработка для VGG16\n\n# функция-генератор загрузки обучающих данных с диска\ndef fit_generator(files, batch_size=32):\n    batch_size = min(batch_size, len(files))\n    while True:\n        shuffle(files)\n        for k in range(len(files) // batch_size):\n            i = k * batch_size\n            j = i + batch_size\n            if j > len(files):\n                j = - j % len(files)\n            x = np.array([load_image(path) for path in files[i:j]])\n            y = np.array([1. if os.path.basename(path).startswith('dog') else 0.\n                          for path in files[i:j]])\n            yield (x, y)\n\n# функция-генератор загрузки тестовых изображений с диска\ndef predict_generator(files):\n    while True:\n        for path in files:\n            yield np.array([load_image(path)])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:41.727532Z","iopub.execute_input":"2022-04-12T13:12:41.728106Z","iopub.status.idle":"2022-04-12T13:12:41.737874Z","shell.execute_reply.started":"2022-04-12T13:12:41.728063Z","shell.execute_reply":"2022-04-12T13:12:41.7366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%matplotlib inline\nfrom matplotlib import pyplot as plt\nfig = plt.figure(figsize=(16, 8))\nfor i, path in enumerate(train_files[:10], 1):\n    subplot = fig.add_subplot(2, 5, i)\n    subplot.set_title('%s' % path.split('/')[-1])\n    img = cv2.imread(path)[...,::-1]\n    img = cv2.resize(img, IMG_SIZE)\n    plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:42.121818Z","iopub.execute_input":"2022-04-12T13:12:42.122161Z","iopub.status.idle":"2022-04-12T13:12:43.398386Z","shell.execute_reply.started":"2022-04-12T13:12:42.12213Z","shell.execute_reply":"2022-04-12T13:12:43.397443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# base_model - объект класса keras.models.Model (Functional Model)\nbase_model = vgg16.VGG16(weights='imagenet',\n                         include_top=False,\n                         input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3))","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:43.400077Z","iopub.execute_input":"2022-04-12T13:12:43.400394Z","iopub.status.idle":"2022-04-12T13:12:48.895844Z","shell.execute_reply.started":"2022-04-12T13:12:43.400363Z","shell.execute_reply":"2022-04-12T13:12:48.89481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:48.899249Z","iopub.execute_input":"2022-04-12T13:12:48.899524Z","iopub.status.idle":"2022-04-12T13:12:48.914859Z","shell.execute_reply.started":"2022-04-12T13:12:48.899497Z","shell.execute_reply":"2022-04-12T13:12:48.914033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# фиксируем все веса предобученной сети\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.layers[-1].output\nx = tf.keras.layers.Dropout(rate=0.2, noise_shape=None, seed=None)(x)\nx = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Flatten()(x)\n# x = tf.keras.layers.BatchNormalization()(x)\n# x = tf.keras.layers.Dense(4,  # один выход (бинарная классификация)\n#                           activation='sigmoid',  # функция активации  \n#                           kernel_regularizer=tf.keras.regularizers.l1(1e-4))(x)\n# x = tf.keras.layers.BatchNormalization()(x)\nx = tf.keras.layers.Dense(1,  # один выход (бинарная классификация)\n                          activation='sigmoid',  # функция активации  \n                          kernel_regularizer=tf.keras.regularizers.l1(1e-4))(x)\n\nmodel = tf.keras.Model(inputs=base_model.input, outputs=x, name='dogs_vs_cats')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:48.918441Z","iopub.execute_input":"2022-04-12T13:12:48.918695Z","iopub.status.idle":"2022-04-12T13:12:48.953798Z","shell.execute_reply.started":"2022-04-12T13:12:48.918669Z","shell.execute_reply":"2022-04-12T13:12:48.953017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:48.956083Z","iopub.execute_input":"2022-04-12T13:12:48.956327Z","iopub.status.idle":"2022-04-12T13:12:48.97105Z","shell.execute_reply.started":"2022-04-12T13:12:48.956303Z","shell.execute_reply":"2022-04-12T13:12:48.969479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer='adam', \n              loss='binary_crossentropy',  # функция потерь binary_crossentropy (log loss\n              metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:12:48.972527Z","iopub.execute_input":"2022-04-12T13:12:48.972908Z","iopub.status.idle":"2022-04-12T13:12:49.182151Z","shell.execute_reply.started":"2022-04-12T13:12:48.972865Z","shell.execute_reply":"2022-04-12T13:12:49.18106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\n\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.001,\n                           patience=30, verbose=1, mode='auto')\nchkpt = ModelCheckpoint('cats-dogs-vgg16.hdf5', \n                        monitor='loss', \n                        verbose=1, \n                        save_best_only=True, \n                        mode='auto')\ncallbacks = [early_stop, chkpt]","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:13:45.087671Z","iopub.execute_input":"2022-04-12T13:13:45.088049Z","iopub.status.idle":"2022-04-12T13:13:45.094048Z","shell.execute_reply.started":"2022-04-12T13:13:45.088019Z","shell.execute_reply":"2022-04-12T13:13:45.093046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_samples = 5  # число изображений в валидационной выборке\nepochs=100\n\nshuffle(train_files)  # перемешиваем обучающую выборку\nvalidation_data = next(fit_generator(train_files[:val_samples], val_samples))\ntrain_data = fit_generator(train_files[val_samples:])  # данные читаем функцией-генератором\n\n# запускаем процесс обучения\nmodel.fit(train_data,\n          steps_per_epoch=10,  # число вызовов генератора за эпоху\n          epochs=epochs,  # число эпох обучения\n          validation_data=validation_data,\n          callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:13:46.508463Z","iopub.execute_input":"2022-04-12T13:13:46.508806Z","iopub.status.idle":"2022-04-12T13:14:37.485209Z","shell.execute_reply.started":"2022-04-12T13:13:46.508773Z","shell.execute_reply":"2022-04-12T13:14:37.484291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('cats-dogs-vgg16.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:14:42.740025Z","iopub.execute_input":"2022-04-12T13:14:42.740418Z","iopub.status.idle":"2022-04-12T13:14:42.887573Z","shell.execute_reply.started":"2022-04-12T13:14:42.740367Z","shell.execute_reply":"2022-04-12T13:14:42.886596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model.load_weights('cats-dogs-vgg16.hdf5')","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:14:44.033535Z","iopub.execute_input":"2022-04-12T13:14:44.034124Z","iopub.status.idle":"2022-04-12T13:14:44.038643Z","shell.execute_reply.started":"2022-04-12T13:14:44.034078Z","shell.execute_reply":"2022-04-12T13:14:44.037127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred = model.predict(\n    predict_generator(test_files), steps=len(test_files), verbose=1)","metadata":{"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-04-12T13:14:44.408947Z","iopub.execute_input":"2022-04-12T13:14:44.409265Z","iopub.status.idle":"2022-04-12T13:16:06.513332Z","shell.execute_reply.started":"2022-04-12T13:14:44.409235Z","shell.execute_reply":"2022-04-12T13:16:06.512536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(16, 8))\nfor i, (path, score) in enumerate(zip(test_files[:10], test_pred[:10]), 1):\n    subplot = fig.add_subplot(2, 5, i)\n    subplot.set_title('%.2f %s' % (score, os.path.basename(path)))\n    img = cv2.imread(path)[...,::-1]\n    img = cv2.resize(img, IMG_SIZE)\n    subplot.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:16:18.159858Z","iopub.execute_input":"2022-04-12T13:16:18.16019Z","iopub.status.idle":"2022-04-12T13:16:19.330516Z","shell.execute_reply.started":"2022-04-12T13:16:18.160158Z","shell.execute_reply":"2022-04-12T13:16:19.329717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score = model.evaluate(fit_generator(train_files[:1000]), verbose=1, steps=len(train_files[:1000]))\nprint('Train Validation loss:', score[0])\nprint('Train Validation accuracy:', score[1])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:16:33.704909Z","iopub.execute_input":"2022-04-12T13:16:33.705238Z","iopub.status.idle":"2022-04-12T13:19:08.408997Z","shell.execute_reply.started":"2022-04-12T13:16:33.70521Z","shell.execute_reply":"2022-04-12T13:19:08.408084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ids = []\nprob = []\nfor path, score in zip(test_files, test_pred):\n    ids.append((os.path.basename(path)).split('.')[-2])\n    prob.append(score[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:20:57.279446Z","iopub.execute_input":"2022-04-12T13:20:57.279893Z","iopub.status.idle":"2022-04-12T13:20:57.312863Z","shell.execute_reply.started":"2022-04-12T13:20:57.279839Z","shell.execute_reply":"2022-04-12T13:20:57.312088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'id': ids, 'label': prob})\noutput.to_csv('submission.csv', index=False)\nprint(output)","metadata":{"execution":{"iopub.status.busy":"2022-04-12T13:20:58.798394Z","iopub.execute_input":"2022-04-12T13:20:58.799072Z","iopub.status.idle":"2022-04-12T13:20:59.0127Z","shell.execute_reply.started":"2022-04-12T13:20:58.799038Z","shell.execute_reply":"2022-04-12T13:20:59.011773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}