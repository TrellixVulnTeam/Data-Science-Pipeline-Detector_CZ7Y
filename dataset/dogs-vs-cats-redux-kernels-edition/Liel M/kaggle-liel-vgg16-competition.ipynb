{"cells":[{"metadata":{"id":"qtE8CiFUZ9-W","colab_type":"text"},"cell_type":"markdown","source":"**read me**\nI recommend using a gpu either google colab gpu ,kaggle gpu, or your own\nFull train dataset is  25,000 (224,224,3) images\n22,500 train set\n2,500 validation\n12,500 test\n\n**versions**\nI used python 3.7 \nkeras 2.2.4\nsklearn 0.20.1\nnumpy 1.15.4\npandas 0.23.4"},{"metadata":{"id":"-_ONCPLMpufk","colab_type":"code","colab":{},"trusted":true},"cell_type":"markdown","source":"**Sources of inspiration, code, and ideas**\n1.  most of the ideas are from the this[ post](http://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html) \n1. keras 2 stage 2 s adjustments see comments at  [bottom](http://gist.github.com/fchollet/7eb39b44eb9e16e59632d25fb3119975)\n1. support for ideas [ from](http://towardsdatascience.com/a-simple-cnn-multi-image-classifier-31c463324fa)\n1. explanation on [ generators:](http://towardsdatascience.com/keras-data-generators-and-how-to-use-them-b69129ed779c)\n1. Tutorial on using Keras flow_from_directory and  [generators](http://medium.com/@vijayabhaskar96/tutorial-image-classification-with-keras-flow-from-directory-and-generators-95f75ebe5720)\n1. other helpful[ stufff ](http://medium.com/@toselvam/how-to-work-with-large-training-dataset-in-google-colab-platform-c3499fc10c24)\n1. helpful kaggle [kernel](http://https://www.kaggle.com/shivamb/cnn-architectures-vgg-resnet-inception-tl)"},{"metadata":{"trusted":true},"cell_type":"code","source":"#only if unable to load vgg16 weights- see comments bellow\n#!pip install wget","execution_count":null,"outputs":[]},{"metadata":{"id":"8GvCTGQzhgBU","colab_type":"code","outputId":"2d4b5f5e-99e6-4915-a282-34fccad903dc","executionInfo":{"status":"ok","timestamp":1575306720253,"user_tz":-120,"elapsed":4217,"user":{"displayName":"Liel Magen","photoUrl":"","userId":"08936758462179639315"}},"colab":{"base_uri":"https://localhost:8080/","height":82},"trusted":true},"cell_type":"code","source":"##imports\n#basic\nimport pandas as pd\nimport numpy as np \n\n#sklearn\nfrom sklearn.metrics import confusion_matrix,classification_report\n#from sklearn.utils import class_weight, shuffle\nfrom sklearn.model_selection import train_test_split\n\n#keras\nfrom keras.preprocessing.image import ImageDataGenerator#, img_to_array, load_img \nfrom keras.models import Sequential,  Model\nfrom keras import optimizers,applications \nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.utils.np_utils import to_categorical \n\n#matplotlib\nimport matplotlib.pyplot as plt \nimport matplotlib.image as mpimg\n%matplotlib inline\n\n#misc\nimport math \nimport datetime\nimport time\nimport os\nimport cv2\n#import wget\n\n#to show predictions\n#from keras.applications.vgg16 import decode_predictions\n#from keras.applications.vgg16 import preprocess_input\n#from keras.preprocessing import image\n#how to migrate fro tf1 to tf2\n#https://www.tensorflow.org/guide/migrate\n\ntic = time.process_time()","execution_count":null,"outputs":[]},{"metadata":{"id":"uXU7KB8ShgBW","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"# set random seeds for more reproducible results\nfrom numpy.random import seed\nseed(42)\n#from tensorflow import set_random_seed #dosen't work on kaggle \n#set_random_seed(43)","execution_count":null,"outputs":[]},{"metadata":{"id":"p_zOiSNehgBY","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#global variables\nimg_width,img_height=224,224\nbatch_size=16\nepochs=4\n#filepaths\n\n#input datasets \nbase_in='../input/dogs-vs-cats-redux-kernels-edition'\ntrain_dir = \"train\"\ntest_dir=\"test\"\n\n#output data- will be saved in output/kaggle/working\nbottleneck_features_train_path=\"bottleneck_features_train.npy\"\nbottleneck_features_validation_path=\"bottleneck_features_validation.npy\"\ntop_model_weights_path = \"bottleneck_fc_model.h5\"\nfinal_model_weights_path=\"final_model_weights.h5\"","execution_count":null,"outputs":[]},{"metadata":{"id":"ungWw-fohgBe","colab_type":"text"},"cell_type":"markdown","source":"#unzipping dataset #only if not working on kaggle kernel\n#import os\nstart = datetime.datetime.now()\n\nimport zipfile\n##loading the datasets- unzipping them from zipped files\n\n\n!mkdir \"/content/drive/My Drive/DS_projects/DL_cats_dogs_vgg16_model_with_improvements/data/cats\"\n#with zipfile.ZipFile('dogs-vs-cats.zip',\"r\") as zip_ref:\n #   zip_ref.extractall(\"data\")\n#print(\"extract all zip ok\")\n\nprint(os.listdir(base_path+\"data/cats\"))\n\nwith zipfile.ZipFile(base_path+\"data/cats/train.zip\",\"r\") as zip_ref:\n    zip_ref.extractall(base_path+\"data/cats\")\nprint(\"extract all train zip ok\")\n\n#with zipfile.ZipFile(\"data/cats/test1.zip\",\"r\") as zip_ref:\n#    zip_ref.extractall(\"data/cats\")\n#print(\"extract all test zip ok\")\n\nprint(os.listdir(base_path+\"data/cats\"))\n\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)"},{"metadata":{"id":"v1jbfWqshgBc","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"times=[]","execution_count":null,"outputs":[]},{"metadata":{"id":"7gRh9s_ahgBe","colab_type":"code","outputId":"a940db55-9665-4b9d-c0e4-241654e1d7e7","executionInfo":{"status":"ok","timestamp":1575289350305,"user_tz":-120,"elapsed":6929,"user":{"displayName":"Liel Magen","photoUrl":"","userId":"08936758462179639315"}},"colab":{"base_uri":"https://localhost:8080/","height":269},"trusted":true},"cell_type":"code","source":"#view image\npath = os.path.join(base_in,train_dir)\ni=0\nfor p in os.listdir(path):\n    category = p.split(\".\")[0]\n    img_array = cv2.imread(os.path.join(path,p))\n    new_img_array = cv2.resize(img_array, dsize=(img_width,img_height))\n    plt.imshow(new_img_array,cmap=\"gray\")\n    i+=1\n    if i==3:\n      break","execution_count":null,"outputs":[]},{"metadata":{"id":"RPLpDc7RhgBl","colab_type":"code","outputId":"5eeded11-4fd6-4894-e53a-1f2fa96a88e7","executionInfo":{"status":"error","timestamp":1575306947193,"user_tz":-120,"elapsed":60865,"user":{"displayName":"Liel Magen","photoUrl":"","userId":"08936758462179639315"}},"colab":{"base_uri":"https://localhost:8080/","height":239},"trusted":true},"cell_type":"code","source":"#train data prep \nfilenames = os.listdir(base_in+ \"/\" +train_dir)\nfiles = []\nlabels = []\nconvert = lambda category : int(category == 'dog')\nfor file in filenames:\n    if file.split(\".\")[-1]==\"jpg\":\n        files.append(base_in+\"/\" +train_dir + \"/\" + file)\n        category = file.split(\".\")[0]\n        category = convert(category)\n        labels.append(category)\n\ndf = pd.DataFrame({\n    'filename': files,\n    'label': labels\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.iloc[0,0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test data prep \nfilenames = os.listdir(base_in+ \"/\" +test_dir)\nfiles = []\n#labels = []\n#convert = lambda category : int(category == 'dog')\nfor file in filenames:\n    if file.split(\".\")[-1]==\"jpg\":\n        files.append(base_in+\"/\" +test_dir + \"/\" + file)\n        #category = file.split(\".\")[0]\n        #category = convert(category)\n        #labels.append(category)\n\ndf_test = pd.DataFrame({\n    'filename': files,\n  #  'label': labels\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.iloc[1,0]","execution_count":null,"outputs":[]},{"metadata":{"id":"oue71f1fhgBp","colab_type":"code","outputId":"2841c67c-9fc9-495c-c67d-2260e25b21c6","executionInfo":{"status":"ok","timestamp":1575289360592,"user_tz":-120,"elapsed":630,"user":{"displayName":"Liel Magen","photoUrl":"","userId":"08936758462179639315"}},"colab":{"base_uri":"https://localhost:8080/","height":35},"trusted":true},"cell_type":"code","source":"#split training set\nX_train, X_val = train_test_split(df.iloc[:,:], test_size=0.1, random_state=42)\nprint(\"y_train includes:\",np.unique(X_train.iloc[:,1],return_counts=True),\"total iages:\",X_train.shape[0])\nprint(\"y_val includes:\",np.unique(X_val.iloc[:,1],return_counts=True),\"total iages:\",X_val.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"id":"CX799_XGhgBr","colab_type":"code","outputId":"e68e02fe-e1f3-42aa-a48d-3a5cadce2388","executionInfo":{"status":"ok","timestamp":1575289366495,"user_tz":-120,"elapsed":614,"user":{"displayName":"Liel Magen","photoUrl":"","userId":"08936758462179639315"}},"colab":{"base_uri":"https://localhost:8080/","height":52},"trusted":true},"cell_type":"code","source":"#splt val and test sets\nX_test = df_test\nprint(\"y_test total images:\", X_test.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# the weights for the following vgg16 model can be loaded useing:\n#option 1:\n#weights=\"imagenet\" #easiest\n#option 2:\n#if that dosen't work you can download them manualy like I did from : \n#https://github.com/fchollet/deep-learning-models/releases/  \n#make sure to use vgg16 weights NO TOP\n# or https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n#OPTION 3 use wget\n#import wget\n#url= https://github.com/fchollet/deep-learning-models/releases/\n#weights= wget.download(url)","execution_count":null,"outputs":[]},{"metadata":{"id":"1PiBFLc_hgBt","colab_type":"code","outputId":"163609d9-ebd6-414b-c01e-60a78b97cc08","executionInfo":{"status":"ok","timestamp":1575220011324,"user_tz":-120,"elapsed":6076,"user":{"displayName":"liel mag","photoUrl":"","userId":"16560626659460352785"}},"colab":{"base_uri":"https://localhost:8080/","height":52},"trusted":true},"cell_type":"code","source":"#Loading vgc16 model\n#vgg16_weights = \"../input/vgg16-w-notop/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nvgg16 = applications.VGG16(include_top=False, weights='imagenet',input_shape=(img_width,img_height,3))","execution_count":null,"outputs":[]},{"metadata":{"id":"t14foYcLhgBv","colab_type":"text"},"cell_type":"markdown","source":"#Stage 1 :Using the bottleneck features of a pre-trained network"},{"metadata":{"id":"YQ0XlIK1hgBv","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#initialize data generator instance\naugment= False\nif augment:\n    datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\nelse:\n    datagen=ImageDataGenerator(rescale=1. / 255)","execution_count":null,"outputs":[]},{"metadata":{"id":"5u0MFyIXhgBy","colab_type":"code","outputId":"9a85a052-5e50-44ce-84ba-33954f1ee1fc","colab":{"base_uri":"https://localhost:8080/","height":35},"trusted":true},"cell_type":"code","source":"# datagenerator from df\n#this predicts all train data vgg16 model final conv layer output using generator which passes data batch by batch \n#\"Using the bottleneck features of a pre-trained network\"\n#training data\nstart = datetime.datetime.now()\n\ngenerator = datagen.flow_from_dataframe(\n        dataframe=X_train,\n        x_col=\"filename\",\n        y_col=\"label\",\n        target_size=(img_width,img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\nnb_train_samples = len(generator.filenames) \nnum_classes = 2\npredict_size_train = int(math.ceil(nb_train_samples / batch_size)) \n\nbottleneck_features_train = vgg16.predict_generator(generator,predict_size_train)\nnp.save(bottleneck_features_train_path, bottleneck_features_train)\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"id":"Lol1s9G_hgB0","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"bottleneck_features_train.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"B0KNlU9DhgB2","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#this predicts all validation data vgg16 model final conv layer output using generator which passes data batch by batch \n#validation data\nstart = datetime.datetime.now()\ngenerator = datagen.flow_from_dataframe(\n        dataframe=X_val,\n        x_col='filename',\n        y_col=\"label\",\n        target_size=(img_width,img_height),\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False)\nnb_val_samples = len(generator.filenames) \nnum_classes = 2\npredict_size_val = int(math.ceil(nb_val_samples / batch_size)) \nbottleneck_features_validation = vgg16.predict_generator(generator, predict_size_val)\nnp.save(bottleneck_features_validation_path, bottleneck_features_validation)\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"id":"8sRmKu8PhgB4","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"bottleneck_features_validation.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"YMy7JD-bhgB6","colab_type":"code","outputId":"2f63d893-cff1-4ce5-a3f4-32cbecdfcb0d","executionInfo":{"status":"ok","timestamp":1575291001255,"user_tz":-120,"elapsed":1619462,"user":{"displayName":"Liel Magen","photoUrl":"","userId":"08936758462179639315"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"trusted":true},"cell_type":"code","source":"#We can then load our saved data (vgg16 final conv output) and train a small fully-connected model:\nstart = datetime.datetime.now()\n\ntrain_data = np.load(bottleneck_features_train_path)\ntrain_labels = X_train.iloc[:,1]\n\nvalidation_data = np.load(bottleneck_features_validation_path)\nvalidation_labels = X_val.iloc[:,1]\n\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=train_data.shape[1:],name=\"flat1\"))\ntop_model.add(Dense(256, activation='relu',name=\"class1\"))\ntop_model.add(Dropout(0.5,name=\"drop1\"))\ntop_model.add(Dense(1, activation='sigmoid',name=\"output\"))\n\n\ntop_model.compile(optimizer='rmsprop',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nhistory1=top_model.fit(train_data, train_labels,\n          epochs=epochs,\n          batch_size=batch_size,\n          validation_data=(validation_data, validation_labels))\ntop_model.save_weights(top_model_weights_path)\n\n(eval_loss, eval_accuracy) = top_model.evaluate(validation_data, validation_labels, batch_size=batch_size, verbose=1)\nprint(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \nprint(\"[INFO] Loss: {}\".format(eval_loss)) \n\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"id":"rOeNYutFhgCF","colab_type":"text"},"cell_type":"markdown","source":"#Stage 2 - Fine-tuning the top layers of a a pre-trained network"},{"metadata":{"id":"5R_wnKKRhgCG","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#After instantiating the VGG base and loading its weights, we add our previously trained fully-connected classifier on top:\nstart = datetime.datetime.now()\n\n# build a classifier model to put on top of the convolutional model\ntop_model = Sequential()\ntop_model.add(Flatten(input_shape=vgg16.output_shape[1:]))\ntop_model.add(Dense(256, activation='relu'))\ntop_model.add(Dropout(0.5))\ntop_model.add(Dense(1, activation='sigmoid'))\n\n# note that it is necessary to start with a fully-trained\n# classifier (vgg16 w/ imagenet weights and \"top classfier\"- just trained above)\n# in order to successfully do fine-tuning\ntop_model.load_weights(top_model_weights_path)\n\n# add the model on top of the convolutional base\nfull_model = Model(inputs=vgg16.input, outputs=top_model(vgg16.output))\n\n\n#We then proceed to freeze all convolutional layers up to the last convolutional block:\n# set the first 15 layers (up to the last conv block)\n# to non-trainable (weights will not be updated)\nfor layer in full_model.layers[:15]:\n    layer.trainable = False\n\n# compile the model with a SGD/momentum optimizer\n# and a very slow learning rate.\nfull_model.compile(loss='binary_crossentropy',\n              optimizer=optimizers.SGD(lr=1e-4, momentum=0.9),\n              metrics=['accuracy'])\n#lets see the full model\nfull_model.summary()\n#full_model.load_weights(final_model_weights_path)# to load weights of the model I previously trained\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"id":"3wYlqfw9skX5","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"###in stage 2 we will use binary data generators, all y and y_pred need to be strings\n#conversion to strings for binary class\nX_train.label=X_train.label.astype(\"str\")\nprint(\"X_train.dtypes:\",\"\\n\",X_train.dtypes)\nX_val.label=X_val.label.astype(\"str\")\nprint(\"X_val.dtypes:\",\"\\n\",X_val.dtypes)\n#X_test.label=X_test.label.astype(\"str\")\n#print(\"X_test.dtypes:\",\"\\n\",X_test.dtypes)","execution_count":null,"outputs":[]},{"metadata":{"id":"gl4TyKaIhgCI","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#Finally, we start training the whole thing, with a very slow learning rate:\nstart = datetime.datetime.now()\n\nepochs=5\n\n# prepare data and optional augmentation configuration\naugment= False\nif augment:\n    train_datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\nelse:\n    train_datagen=ImageDataGenerator(rescale=1. / 255)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\n#will augment and throw the train data into full model\ntrain_generator = train_datagen.flow_from_dataframe(\n        dataframe=X_train,\n        x_col='filename',\n        y_col=\"label\",\n        target_size=(img_height,img_width),\n        batch_size=batch_size,\n        class_mode='binary')\n#will a throw the val data into full model\nvalidation_generator = test_datagen.flow_from_dataframe(\n        dataframe=X_val,\n        x_col='filename',\n        y_col=\"label\",\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='binary')\n\nnb_train_samples = len(train_generator.filenames) \nnb_val_samples = len(validation_generator.filenames) \n\n\n# fine-tune the model\nhistory2=full_model.fit_generator(\n        train_generator,\n        steps_per_epoch=int(math.ceil(nb_train_samples / batch_size)),\n        epochs=epochs,\n        validation_data=validation_generator,\n        validation_steps=int(math.ceil(nb_val_samples / batch_size)))\n#steps_per_epoch= how many batches to pass before epoch is finished. In current setting whole dataset passed. \nfull_model.save_weights(final_model_weights_path)\n\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"id":"IVRVEc4fHn66","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"#test model on val data\nstart = datetime.datetime.now()\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n#will a throw the val data into full model\nval_generator = test_datagen.flow_from_dataframe(\n        dataframe=X_val,\n        x_col='filename',\n        y_col=\"label\",\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode='binary')\nnb_val_samples = len(val_generator.filenames) \nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"id":"BSC_q86ws6JH","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"start = datetime.datetime.now()\n(eval_loss, eval_accuracy) =full_model.evaluate_generator(val_generator,steps=int(math.ceil(nb_val_samples / batch_size)))\nprint(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100)) \nprint(\"[INFO] Loss: {}\".format(eval_loss)) \n\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test generator\nstart = datetime.datetime.now()\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\ntest_generator = test_datagen.flow_from_dataframe(\n        dataframe=X_test,\n        x_col='filename',\n        target_size=(img_height, img_width),\n        batch_size=batch_size,\n        class_mode=None)\nnb_test_samples = len(test_generator.filenames) \n\n#Y_test_pred = full_model.predict_generator(test_generator, steps=int(math.ceil(nb_test_samples / batch_size)))\n#y_prob=Y_test_pred \n\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make predictions\nstart = datetime.datetime.now()\nY_test_pred = full_model.predict_generator(test_generator, steps=int(math.ceil(nb_test_samples / batch_size)))\nend= datetime.datetime.now()\nelapsed= end-start\nprint (\"Time: \", elapsed)\ntimes.append(elapsed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#test data prep  to df and csv\nfilenames =X_test.filename\nids = []\nlabels = Y_test_pred.flatten()\n#convert = lambda category : int(category == 'dog')\nfor file in filenames:\n    #if file.split(\".\")[-1]==\"jpg\":\n    # files.append(base_in+\"/\" +train_dir + \"/\" + file)\n    new_id = file.split(\".\")[0]\n    #category = convert(category)\n    ids.append(new_id)\n\ndf_sub = pd.DataFrame({\n    'id': ids,\n    'label': labels\n})\nsub1=df_sub.to_csv('submission.csv',index=True)\n#kaggle competitions submit -c dogs-vs-cats-redux-kernels-edition -f sub1","execution_count":null,"outputs":[]},{"metadata":{"id":"87CJTH9RYM3I","colab_type":"code","colab":{},"trusted":true},"cell_type":"code","source":"print(\"total net runtime:\",np.sum(times))\ntoc= time.process_time()\nprint(\"start to end time:\",(toc-tic)/60,\"min\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink('submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink(\"bottleneck_features_train.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink(\"bottleneck_features_validation.npy\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FileLink(\"bottleneck_fc_model.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"colab":{"name":"final_Liel's version  DL vgg16 model with improvements_ cats v dogs.ipynb","provenance":[{"file_id":"1tmIggUa5g8BFC9LN7ai5Md31txWEB3tA","timestamp":1575307499016}],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":1}