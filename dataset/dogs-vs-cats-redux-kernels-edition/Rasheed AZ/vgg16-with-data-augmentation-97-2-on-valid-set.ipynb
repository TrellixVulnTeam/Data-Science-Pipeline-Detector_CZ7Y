{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!conda install -y gdown","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:09:13.697611Z","iopub.execute_input":"2021-05-26T13:09:13.69806Z","iopub.status.idle":"2021-05-26T13:10:38.482507Z","shell.execute_reply.started":"2021-05-26T13:09:13.697976Z","shell.execute_reply":"2021-05-26T13:10:38.48097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Packages and Weights for My Custom model","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport zipfile\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.pyplot as plt\nimport os \n\nimport torchvision\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, ConcatDataset\nimport torch.nn.functional as F\n\nimport PIL\n\nfrom sklearn.metrics import confusion_matrix\n\nfrom collections import OrderedDict\n\nimport time\nimport gc\n\ngc.enable()\ntorch.__version__","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-26T13:22:24.539162Z","iopub.execute_input":"2021-05-26T13:22:24.539476Z","iopub.status.idle":"2021-05-26T13:22:24.548593Z","shell.execute_reply.started":"2021-05-26T13:22:24.539449Z","shell.execute_reply":"2021-05-26T13:22:24.547622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!gdown --id 1fpu2IATXJBoCD0adJDVjGYZ0qwDnQ4e8","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:17:39.265548Z","iopub.execute_input":"2021-05-26T13:17:39.265912Z","iopub.status.idle":"2021-05-26T13:17:59.831688Z","shell.execute_reply.started":"2021-05-26T13:17:39.265883Z","shell.execute_reply":"2021-05-26T13:17:59.830503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.path.exists(\"/kaggle/working/vgg_cat_vs_dog.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:17:59.834031Z","iopub.execute_input":"2021-05-26T13:17:59.834429Z","iopub.status.idle":"2021-05-26T13:17:59.842428Z","shell.execute_reply.started":"2021-05-26T13:17:59.834395Z","shell.execute_reply":"2021-05-26T13:17:59.840973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (10, 10)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:17:59.844451Z","iopub.execute_input":"2021-05-26T13:17:59.844849Z","iopub.status.idle":"2021-05-26T13:17:59.860041Z","shell.execute_reply.started":"2021-05-26T13:17:59.844809Z","shell.execute_reply":"2021-05-26T13:17:59.859293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Extracting the training and test set","metadata":{}},{"cell_type":"code","source":"with zipfile.ZipFile(\"../input/dogs-vs-cats-redux-kernels-edition/\" + \"train.zip\",\"r\") as z:\n    z.extractall(\".\")\nwith zipfile.ZipFile(\"../input/dogs-vs-cats-redux-kernels-edition/\" + \"test.zip\",\"r\") as z:\n    z.extractall(\".\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:17:59.860981Z","iopub.execute_input":"2021-05-26T13:17:59.861195Z","iopub.status.idle":"2021-05-26T13:18:21.466955Z","shell.execute_reply.started":"2021-05-26T13:17:59.861171Z","shell.execute_reply":"2021-05-26T13:18:21.465423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadFileNames(trainTestFlag=True, start=0, end=12500, root=os.getcwd()):\n    fileNames = []\n    for ind in range(start, end):\n        fileName = []\n        if trainTestFlag:\n            fileName = [\"cat.\" + str(ind) + \".jpg\", \"dog.\" + str(ind) + \".jpg\"]\n        else:\n            fileName = [str(ind) + \".jpg\"]\n        \n        for ind, p in enumerate(fileName):\n            if trainTestFlag:\n                path = \"/kaggle/working/train/\" + p\n                if os.path.exists(path):\n                    if ind == 0:\n                        fileNames.append((path, 0))\n                    else:\n                        fileNames.append((path, 1))\n            else:\n                path = \"/kaggle/working/test/\" + p\n                if os.path.exists(path):\n                    fileNames.append((path, -1))\n    return fileNames","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:18:21.468674Z","iopub.execute_input":"2021-05-26T13:18:21.469094Z","iopub.status.idle":"2021-05-26T13:18:21.477993Z","shell.execute_reply.started":"2021-05-26T13:18:21.469054Z","shell.execute_reply":"2021-05-26T13:18:21.476585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Validation and Training Split","metadata":{}},{"cell_type":"code","source":"fileNames = np.array(loadFileNames())\nindeces = np.random.choice(len(fileNames), len(fileNames), replace=False)\ntrainTestRatio = 0.8\ntrainIndeces, validationIndeces = indeces[:int(0.8 * len(indeces))], indeces[int(0.8 * len(indeces)):] \nfileNamesTest = loadFileNames(False, 1, 12501)\n","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:18:21.480969Z","iopub.execute_input":"2021-05-26T13:18:21.481381Z","iopub.status.idle":"2021-05-26T13:18:21.71733Z","shell.execute_reply.started":"2021-05-26T13:18:21.481316Z","shell.execute_reply":"2021-05-26T13:18:21.715674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Augmentation and Data Loading","metadata":{}},{"cell_type":"code","source":"class DataAugmentation(Dataset):\n\n    def __init__(self, imgSize, fileNames, *args, **kwargs):\n        super(DataAugmentation, self).__init__(*args, **kwargs)\n        self.files = fileNames\n        self.tensorTransform = torchvision.transforms.ToTensor()\n        self.resize = torchvision.transforms.Resize((imgSize, imgSize))\n        self.tranlationTransform = torchvision.transforms.RandomAffine(degrees=0, translate=(0.1, 0.1))\n        self.rotationalTransformation = torchvision.transforms.RandomRotation(45, center=(imgSize/2, imgSize/2) )\n        self.imgSize = imgSize\n    \n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, index):\n        img = PIL.Image.open(self.files[index][0])\n        label = self.files[index][1]\n        img = self.resize(img)\n        img = self.tranlationTransform(img)\n        img = self.rotationalTransformation(img)\n        #img = np.array(img, dtype=np.float32)\n        img = self.tensorTransform(img)#Will read it into 3xheightxwidth\n        #Standard normalize images\n        ravel = img.view(3, -1)\n        means = torch.mean(ravel, dim=1)\n        ravel -= torch.transpose(means.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        std = torch.std(ravel, dim=1)\n        ravel /= torch.transpose(std.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        \n        img = ravel.view(3, self.imgSize, self.imgSize)\n\n        return img, label\n\nclass OriginalImages(Dataset):\n\n    def __init__(self, imgSize, fileNames, *args, **kwargs):\n        super(OriginalImages).__init__(*args, **kwargs)\n        self.files = fileNames\n        self.tensorTransform = torchvision.transforms.ToTensor()\n        self.resize = torchvision.transforms.Resize((imgSize, imgSize))\n        self.imgSize = imgSize\n    \n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, index):\n        img = PIL.Image.open(self.files[index][0])\n        label = self.files[index][1]\n        img = self.resize(img)\n        img = self.tensorTransform(img)\n        \n        #Standard normalize images\n        ravel = img.view(3, -1)\n        means = torch.mean(ravel, dim=1)\n        ravel -= torch.transpose(means.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        std = torch.std(ravel, dim=1)\n        ravel /= torch.transpose(std.repeat(ravel.shape[1]).reshape(-1, 3), 0, 1)\n        \n        img = ravel.view(3, self.imgSize, self.imgSize)\n        return img, label","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:18:21.719462Z","iopub.execute_input":"2021-05-26T13:18:21.719778Z","iopub.status.idle":"2021-05-26T13:18:21.741116Z","shell.execute_reply.started":"2021-05-26T13:18:21.719749Z","shell.execute_reply":"2021-05-26T13:18:21.739829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"augmentedDataTrain = DataAugmentation(224, fileNames[trainIndeces])\noriginalDataTrain = OriginalImages(224, fileNames[trainIndeces])\noriginalDataValidation = OriginalImages(224, fileNames[validationIndeces])\noriginalDataTest =  OriginalImages(224, fileNamesTest)\n\ndataLoaderTrain = DataLoader(ConcatDataset([originalDataTrain, augmentedDataTrain]), batch_size=256, shuffle=True)\ndataLoaderValid = DataLoader(originalDataValidation, batch_size=256, shuffle=True)\ndataLoaderTest = DataLoader(originalDataTest, batch_size=256)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:18:21.742473Z","iopub.execute_input":"2021-05-26T13:18:21.742818Z","iopub.status.idle":"2021-05-26T13:18:21.781198Z","shell.execute_reply.started":"2021-05-26T13:18:21.742787Z","shell.execute_reply":"2021-05-26T13:18:21.780232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating VGG13 from Scratch and Using Custom model with the pretrained model of the VGG16","metadata":{}},{"cell_type":"code","source":"class VGG13(torch.nn.Module):\n\n    def __init__(self, *args, **kwargs):\n        super(VGG13, self).__init__(*args, **kwargs)\n        self.conv1 = torch.nn.Conv2d(3, 64, (3, 3), 1)\n        self.conv2 = torch.nn.Conv2d(64, 64, (3, 3), 1)\n        self.pool1 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv3 = torch.nn.Conv2d(128, 128, (3, 3), 1)\n        self.conv4 = torch.nn.Conv2d(128, 128, (3, 3), 1)\n        self.pool2 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv5 = torch.nn.Conv2d(256, 256, (3, 3), 1)\n        self.conv6 = torch.nn.Conv2d(256, 256, (3, 3), 1)\n        self.pool3 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv7 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.conv8 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.pool4 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n        self.conv9 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.conv10 = torch.nn.Conv2d(512, 512, (3, 3), 1)\n        self.pool5 = torch.nn.MaxPool2d((2, 2), 2)#non-overlapping\n\n        self.fc1 = torch.nn.Linear(512 * 7 * 7, 4096)\n        self.fc2 = torch.nn.Linear(4096, 4096)\n        self.fc3 = torch.nn.Linear(4096, 2)\n\n\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv2(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool1(x)\n        #print(x.shape)\n        x = self.conv3(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv4(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool2(x)\n        #print(x.shape)\n\n        x = self.conv5(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv6(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool3(x)\n        #print(x.shape)\n\n        x = self.conv7(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv8(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool4(x)\n        #print(x.shape)\n\n        x = self.conv9(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.conv10(x)\n        x = torch.relu(F.pad(x, (1, 1, 1, 1)))\n        x = self.pool5(x)\n        #print(x.shape)\n\n        x = x.view(-1, 512 * 7 * 7)\n        #print(x.shape)\n\n        x = torch.relu(self.fc1(x))\n        x = torch.relu(self.fc2(x))\n        x = self.fc3(x)\n\n        x = F.softmax(x, dim=2)\n\n        return x\n    \n    @staticmethod\n    def init_param(layer):\n        if type(layer) == torch.nn.Conv2d:\n            torch.nn.init.xavier_normal_(layer.weight)\n        if type(layer) == torch.nn.Linear:\n            torch.nn.init.xavier_uniform_(layer.weight)\n    \n    def initialize_parameters(self, verbose=False):\n        self.apply(self.init_param)\n        numberParameters = 0\n        for p in self.parameters():\n            numberParameters += p.numel() if p.requires_grad else 0\n        if verbose:\n            counter = 0\n            for param in self.parameters():\n                print(f\"Layer {counter}\")\n                print(param)\n                counter += 1\n        print(\"Number of parameters is {:,}\".format(numberParameters))","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:18:21.78254Z","iopub.execute_input":"2021-05-26T13:18:21.782824Z","iopub.status.idle":"2021-05-26T13:18:21.813125Z","shell.execute_reply.started":"2021-05-26T13:18:21.782793Z","shell.execute_reply":"2021-05-26T13:18:21.812252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class VggWithCustomLayers(torch.nn.Module):\n\n    def __init__(self, *args, **kwargs):\n        super(VggWithCustomLayers, self).__init__(*args, **kwargs)\n        self.vgg = torchvision.models.vgg16(pretrained=True)\n        for param in self.vgg.parameters():\n            param.requires_grad = False\n        in_features = self.vgg.classifier[-1].in_features\n        block = torch.nn.Sequential(OrderedDict([\n            (\"conv_1\", torch.nn.Linear(in_features, 2)),\n            #(\"non-linear-1\", torch.nn.ReLU()),\n            #(\"last\", torch.nn.Linear(128, 1)),\n            (\"softmax\", torch.nn.Softmax(dim=1))\n        ]))\n        self.vgg.classifier[-1] = block\n\n    def forward(self, x):\n        x = self.vgg(x)\n        return x\n\ndef predict(loader, model, y_pred, y_true, images):\n    counter = 0\n    for batch, labels in loader:\n        gc.collect()\n        y_p = model(batch)\n        y = list(np.array(labels, dtype=np.int8))\n        _, y_p_max = torch.max(y_p, dim=1)\n        y_pred.extend(y_p_max.tolist())\n        y_true.extend(y)\n        print(f\"batch#{counter}\")\n        if counter < 10:\n            images.append(batch[0]) \n        del batch\n        del y_p\n        del y\n        del y_p_max\n        del _\n        counter += 1","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:43:09.169462Z","iopub.execute_input":"2021-05-26T13:43:09.170078Z","iopub.status.idle":"2021-05-26T13:43:09.182663Z","shell.execute_reply.started":"2021-05-26T13:43:09.170045Z","shell.execute_reply":"2021-05-26T13:43:09.18151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Instantiation of the Model","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Assuming that we are on a CUDA machine, this should print a CUDA device:\n\nprint(device)\n\nmodel = VggWithCustomLayers()\nmodel.load_state_dict(torch.load(\"/kaggle/working/vgg_cat_vs_dog.h5\"))\nprint(model)\n\n#model.initialize_parameters(False)\noptimizer = torch.optim.SGD(params=model.parameters(), lr=0.001, momentum=0.9)\nloss_fn = torch.nn.CrossEntropyLoss()\nvalidation_errors = []\ntraining_errors = []\nprint(model)\nmodel =model.to(device)\nfor name, param in model.named_parameters():\n    print(f\"{name} {param.requires_grad}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:18:21.83783Z","iopub.execute_input":"2021-05-26T13:18:21.838059Z","iopub.status.idle":"2021-05-26T13:18:35.767078Z","shell.execute_reply.started":"2021-05-26T13:18:21.838036Z","shell.execute_reply":"2021-05-26T13:18:35.764769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training of the Model","metadata":{}},{"cell_type":"code","source":"epochs = 1\ndef train_model(epochs, model, dataLoaderTrain, dataLoaderValid):\n    y_pred_train = []\n    y_pred_valid = []\n    y_true_train = []\n    y_true_valid = []\n    for epoch in range(0, epochs):\n        batchNum = 0\n        begin = time.time()\n        trainingErrorBatches = []\n        validationErrorBatches = []\n\n        for batch, labels in dataLoaderTrain:\n            batch = batch.to(device)\n            optimizer.zero_grad()\n            y_pred = model(batch)\n            y = torch.tensor(np.array(labels, dtype=np.int8)).type(torch.LongTensor)\n            y = y.to(device)\n            loss = loss_fn(y_pred, y)\n            loss.backward()\n            optimizer.step()\n            if epoch + 1 == epochs:\n                y_pred_train.extend(list(np.argmax(y_pred.detach().numpy(), axis=1)))\n                y_true_train.extend(y.tolist())\n            trainingErrorBatches.append(loss.item())\n            print(f\"{epoch}:{batchNum}, -log-likelihood {np.round(loss.item(), 3)}\")\n            cnf = confusion_matrix(y, np.argmax(y_pred.detach().numpy(), axis=1))\n            print(f\"Accuracy: {np.round(np.sum(np.diag(cnf))/np.sum(cnf), 3)*100}, \\n {cnf}\")\n            batchNum += 1\n\n        for batch, labels in dataLoaderValid:\n            optimizer.zero_grad()\n            y = torch.tensor(np.array(labels, dtype=np.int8)).type(torch.LongTensor)\n            y_pred = model(batch)\n            y = y.to(device)\n            loss = loss_fn(y_pred, y)\n            if epoch + 1 == epochs:\n                y_pred_valid.extend(list(np.argmax(y_pred.detach().numpy(), axis=1)))\n                y_true_valid.extend(y.tolist())\n            validationErrorBatches.append(loss.item())\n        training_errors.append(np.mean(trainingErrorBatches))\n        validation_errors.append(np.mean(validationErrorBatches))\n\n        end = time.time()\n        print(f\"{epoch} the avg -log-likelihood for training is {np.round(training_errors[-1], 2)} and it took {(end - begin)/60} min\")\n        print(f\"{epoch} the avg -log-likelihood for validation is {np.round(validation_errors[-1], 2)} and it took {(end - begin)/60} min\")\n    return y_pred_train, y_true_train, y_pred_valid, y_true_valid","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:18:35.773615Z","iopub.execute_input":"2021-05-26T13:18:35.774114Z","iopub.status.idle":"2021-05-26T13:18:35.808778Z","shell.execute_reply.started":"2021-05-26T13:18:35.774071Z","shell.execute_reply":"2021-05-26T13:18:35.804639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Performance on the Training Set","metadata":{}},{"cell_type":"code","source":"# Training Performance\ny_pred = []\ny_true = [] \nimages = [] \n#predict(dataLoaderTrain, model, y_pred, y_true, images)\n#cnf = confusion_matrix(y_pred, y_true)\n#cnf = confusion_matrix(y_pred_train, y_true_train)\n#print(f\"Accuracy on training set {np.round(np.sum(np.diag(cnf))/np.sum(cnf), 3) * 100} \\n {cnf}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T13:44:22.123851Z","iopub.execute_input":"2021-05-26T13:44:22.124228Z","iopub.status.idle":"2021-05-26T16:44:05.559953Z","shell.execute_reply.started":"2021-05-26T13:44:22.124196Z","shell.execute_reply":"2021-05-26T16:44:05.559125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# gs = GridSpec(2, 5)\n# gs.update(left=0.12, bottom=0.08, right=2, top=0.92, wspace=0.2, hspace=0.5)\n# lab = [\"cat\", \"dog\"]\n# colors = [\"red\", \"green\"]\n# for i in range(0, 2):\n#     for j in range(0, 5):\n#         ax = plt.subplot(gs[i, j])\n#         ax.imshow(images[i*2 + j].transpose(0, 2)[:, :, 0], cmap=\"gray\")\n#         ax.set_xticks([])\n#         ax.set_yticks([])\n#         ax.set_title(f\"y_true: {lab[y_true[i* 2 + j]]} and y_pred: {lab[y_pred[i*2 +j]]}\", color=colors[(y_true[i* 2 + j] == y_pred[i*2 +j])*1] )\n        \n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:34:38.330082Z","iopub.execute_input":"2021-05-26T17:34:38.330611Z","iopub.status.idle":"2021-05-26T17:34:39.599877Z","shell.execute_reply.started":"2021-05-26T17:34:38.330566Z","shell.execute_reply":"2021-05-26T17:34:39.598742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Performance on the Validation Set","metadata":{}},{"cell_type":"code","source":"# del y_pred\n# del y_true\n# del images \n# del dataLoaderTrain\n# del cnf\n\n# Validation Performance\ny_pred = []\ny_true = [] \nimages = [] \npredict(dataLoaderValid, model, y_pred, y_true, images)\n#cnf = confusion_matrix(y_pred_valid, y_true_valid)\ncnf = confusion_matrix(y_pred, y_true)\nprint(f\"Accuracy on validation set {np.round(np.sum(np.diag(cnf))/np.sum(cnf), 3) * 100} \\n {cnf}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:35:19.237359Z","iopub.execute_input":"2021-05-26T17:35:19.237848Z","iopub.status.idle":"2021-05-26T17:57:47.705417Z","shell.execute_reply.started":"2021-05-26T17:35:19.237816Z","shell.execute_reply":"2021-05-26T17:57:47.703843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs = GridSpec(2, 5)\ngs.update(left=0.12, bottom=0.08, right=2, top=0.92, wspace=0.2, hspace=0.5)\nlab = [\"cat\", \"dog\"]\ncolors = [\"red\", \"green\"]\nfor i in range(0, 2):\n    for j in range(0, 5):\n        ax = plt.subplot(gs[i, j])\n        ax.imshow(images[i*2 + j].transpose(0, 2)[:, :, 0], cmap=\"gray\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"y_true: {lab[y_true[i* 2 + j]]} and y_pred: {lab[y_pred[i*2 +j]]}\", color=colors[(y_true[i* 2 + j] == y_pred[i*2 +j])*1] )\n        \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T17:57:57.259404Z","iopub.execute_input":"2021-05-26T17:57:57.259788Z","iopub.status.idle":"2021-05-26T17:57:57.928476Z","shell.execute_reply.started":"2021-05-26T17:57:57.259754Z","shell.execute_reply":"2021-05-26T17:57:57.927244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Performance on the Test Set","metadata":{}},{"cell_type":"code","source":"del dataLoaderValid\n#del cnf\n# Test Performance\ny_pred = []\ny_true = [] \nimages = [] \npredict(dataLoaderTest, model, y_pred, y_true, images)\ndf = pd.DataFrame(np.c_[np.arange(1, len(y_pred) + 1), y_pred], columns=[\"id\", \"label\"])\ndf.to_csv(\"submission.csv\", header=True, index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T18:01:15.867113Z","iopub.execute_input":"2021-05-26T18:01:15.867595Z","iopub.status.idle":"2021-05-26T18:56:32.669454Z","shell.execute_reply.started":"2021-05-26T18:01:15.867564Z","shell.execute_reply":"2021-05-26T18:56:32.667161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gs = GridSpec(2, 5)\ngs.update(left=0.12, bottom=0.08, right=2, top=0.92, wspace=0.2, hspace=0.5)\nlab = [\"cat\", \"dog\"]\nfor i in range(0, 2):\n    for j in range(0, 5):\n        ax = plt.subplot(gs[i, j])\n        ax.imshow(images[i*2 + j].transpose(0, 2)[:, :, 0], cmap=\"gray\")\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"y_pred: {lab[y_pred[i*2 +j]]}\")\n        \nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-26T19:09:54.316889Z","iopub.execute_input":"2021-05-26T19:09:54.317386Z","iopub.status.idle":"2021-05-26T19:09:55.144385Z","shell.execute_reply.started":"2021-05-26T19:09:54.317337Z","shell.execute_reply":"2021-05-26T19:09:55.143106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To download file, from https://www.kaggle.com/rtatman/download-a-csv-file-from-a-kernel\n#from IPython.display import HTML\n# import base64\n#html = '<a  href=\"{filename}\" target=\"_blank\">{title}</a>'\n#html = html.format(title=\"file\",filename=\"submission.csv\")\n#HTML(html)","metadata":{"execution":{"iopub.status.busy":"2021-05-26T19:10:14.204503Z","iopub.execute_input":"2021-05-26T19:10:14.20488Z","iopub.status.idle":"2021-05-26T19:10:14.215359Z","shell.execute_reply.started":"2021-05-26T19:10:14.204838Z","shell.execute_reply":"2021-05-26T19:10:14.213637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References \n* https://arxiv.org/abs/1409.1556","metadata":{}}]}