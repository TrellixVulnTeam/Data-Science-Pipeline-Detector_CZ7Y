{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%matplotlib inline\n#DATASET\nimport numpy\nimport pandas\nimport cv2\nfrom PIL import Image, ImageFilter\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport math\nimport sys\nimport itertools\nimport shutil\nimport glob\nfrom distutils.dir_util import copy_tree\nimport copy\nimport zipfile\n#TORCH\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport torchvision\nfrom torchvision import models\nfrom torchvision import transforms\nfrom torchvision import datasets\nfrom torchvision.io import read_image\n#METRICS\nfrom tqdm import tqdm\nfrom tqdm import trange\nfrom IPython.display import clear_output\nfrom sklearn.metrics import confusion_matrix\nimport time\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ndir_name = './Dataset'\nif os.path.exists(dir_name) != True:\n    \n    os.makedirs(dir_name)\n    \n    with zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/train.zip', 'r') as z1:\n        z1.extractall(dir_name)\n\n    with zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/test.zip', 'r') as z2:\n        z2.extractall(dir_name)\n        \n    del z1, z2\n    print('Done')\n    \ntrain_path = list()\ntrain_label = list()\ntest_path = list()\ntest_label = list()\ntest_id = list()\n\nfor var in os.listdir(dir_name + '/train'):\n    train_path.append(os.path.join(dir_name, 'train', var))\n    \n    if 'dog' in var:\n        train_label.append(1)\n    \n    else:\n        train_label.append(0)\n\nfor var in os.listdir(dir_name + '/test'):\n    test_path.append(os.path.join(dir_name, 'test', var))\n    test_label.append(0.5)\n    test_id.append(int(var[:var.find('.')]))\n\ntrain_csv = pandas.DataFrame({'id': train_path, 'label': train_label})\ntest_csv = pandas.DataFrame({'id' : test_path, 'label' : test_label, 'real_id' : test_id})\ntest_csv = test_csv.sort_values(by=['real_id'])\nsubmission_csv = pandas.read_csv('../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv')\n\ndel train_path, train_label, test_path, test_label\n\ndevice1 = 'cpu'\ndevice2 = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:16:56.97067Z","iopub.execute_input":"2022-01-30T06:16:56.970924Z","iopub.status.idle":"2022-01-30T06:16:57.143063Z","shell.execute_reply.started":"2022-01-30T06:16:56.970897Z","shell.execute_reply":"2022-01-30T06:16:57.142395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    \n    def __init__(self, img_dir, dir_file, transform=None, target_transform=None):\n        self.img_labels = dir_file\n        self.img_dir = img_dir\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = self.img_dir.iloc[idx]\n        \n        image = read_image(img_path)\n        \n        image = image / image.max()\n        image = image.type(torch.float64)\n        \n        if self.transform: \n            image = self.transform(image)\n            \n        label = self.img_labels.iloc[idx]\n        label = torch.tensor(label)\n        \n        if self.target_transform: \n            label = self.target_transform(label)\n        \n        return image, label","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:17:00.141424Z","iopub.execute_input":"2022-01-30T06:17:00.141682Z","iopub.status.idle":"2022-01-30T06:17:00.149095Z","shell.execute_reply.started":"2022-01-30T06:17:00.141654Z","shell.execute_reply":"2022-01-30T06:17:00.148128Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform =   transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n])\n\ntraining_data = CustomImageDataset(\n    train_csv.id,\n    train_csv.label,\n    transform = transform, \n    target_transform = None\n)\n\ntrain_dataloader = DataLoader(training_data, batch_size=100, shuffle=True)\n\ntest_data = CustomImageDataset(\n    test_csv.id,\n    test_csv.label,\n    transform = transform, \n    target_transform = None\n)\n\ntest_dataloader = DataLoader(test_data, batch_size=100, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:17:01.32139Z","iopub.execute_input":"2022-01-30T06:17:01.321656Z","iopub.status.idle":"2022-01-30T06:17:01.328761Z","shell.execute_reply.started":"2022-01-30T06:17:01.321627Z","shell.execute_reply":"2022-01-30T06:17:01.327961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 2)\nclear_output(True)\n\nmodel.load_state_dict(torch.load('../input/classification-model-learning/classifier_model.pt', map_location=torch.device(device2)))\nmodel.eval()\nmodel = model.to(device2)\nclear_output()","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:17:11.174003Z","iopub.execute_input":"2022-01-30T06:17:11.174298Z","iopub.status.idle":"2022-01-30T06:17:11.548615Z","shell.execute_reply.started":"2022-01-30T06:17:11.17427Z","shell.execute_reply":"2022-01-30T06:17:11.547903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_model(model, f_n  : str = 'prediction1'):\n    \n    global device2, submission_csv\n    since = time.time()\n    pred = list()\n    sample_sub = submission_csv\n    \n    #set model to evaluate mode\n    model.eval()\n    \n    for inputs, _ in tqdm(test_dataloader):\n        \n        inputs = inputs.type(model.conv1.weight.dtype)\n        inputs = inputs.to(device2)\n        \n        with torch.no_grad():\n            \n            #forward pass\n            output = model(inputs)\n            #_, preds = torch.max(output, 1)\n            preds = output[:, 1]\n            \n            for pr in preds:\n                pred.append(pr)\n    \n    \n    del pr, preds, output, inputs;\n    \n    pred = torch.tensor(pred, dtype = torch.int32, device = 'cpu')\n    \n    assert pred.shape[0] == len(sample_sub)\n    \n    sample_sub.label = pred\n    \n    sample_sub.to_csv('{}.csv'.format(f_n), index=False)\n    \n    return pandas.read_csv('./{}.csv'.format(f_n))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:17:28.241839Z","iopub.execute_input":"2022-01-30T06:17:28.244165Z","iopub.status.idle":"2022-01-30T06:17:28.266465Z","shell.execute_reply.started":"2022-01-30T06:17:28.244117Z","shell.execute_reply":"2022-01-30T06:17:28.26518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv = test_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:17:29.015205Z","iopub.execute_input":"2022-01-30T06:17:29.015764Z","iopub.status.idle":"2022-01-30T06:18:42.543143Z","shell.execute_reply.started":"2022-01-30T06:17:29.015726Z","shell.execute_reply":"2022-01-30T06:18:42.542382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-01-30T06:18:43.953569Z","iopub.execute_input":"2022-01-30T06:18:43.95383Z","iopub.status.idle":"2022-01-30T06:18:43.963952Z","shell.execute_reply.started":"2022-01-30T06:18:43.953803Z","shell.execute_reply":"2022-01-30T06:18:43.963237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"def training_data_acc(model, f_n  : str = 'prediction'):\n    \n    since = time.time()\n    pred = list()\n    acc = list()\n    \n    #set model to evaluate mode\n    model.eval()\n    \n    for inputs, label in train_dataloader:\n        \n        inputs = inputs.type(model.conv1.weight.dtype)\n        inputs = inputs.to(device2)\n        \n        with torch.no_grad():\n            \n            #forward pass\n            output = model(inputs)\n            _, preds = torch.max(output, 1)\n            \n            for pr in preds:\n                pred.append(pr)\n            \n            for pr in label:\n                acc.append(pr)\n    \n    pred = torch.tensor(pred, dtype = torch.int32, device = 'cpu')\n    acc = torch.tensor(acc, dtype = torch.int32, device = 'cpu')\n    \n    print('{}/{}'.format(a.eq(p).sum().item(), a.shape[0]))\n    print('Accuracy : {}'.format(a.eq(p).sum().item() / a.shape[0]))\n    \n    return pred, acc, a.eq(p).sum().item() / a.shape[0]\n    \np, a = training_data_acc(model)","metadata":{"execution":{"iopub.status.busy":"2022-01-29T15:32:02.327455Z","iopub.execute_input":"2022-01-29T15:32:02.327791Z","iopub.status.idle":"2022-01-29T15:32:02.337189Z","shell.execute_reply.started":"2022-01-29T15:32:02.32776Z","shell.execute_reply":"2022-01-29T15:32:02.336212Z"}}}]}