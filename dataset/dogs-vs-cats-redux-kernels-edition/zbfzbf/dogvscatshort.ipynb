{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#about torch...\nimport torch\nimport torch.nn as nn\nimport torch\nimport torch.optim as optim\nimport torch.nn.functional as F\n\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, Dataset\n\n#using numpy\nimport numpy as np\n\n#for data load or save\nimport pandas as pd\n\n#visualize some datasets\nimport matplotlib.pyplot as plt\n\n#check our work directory\nimport os\n\n#to unzip datasets\nimport zipfile\n\nos.listdir('../input/dogs-vs-cats-redux-kernels-edition')\nos.makedirs('../data', exist_ok=True)\nbase_dir = '../input/dogs-vs-cats-redux-kernels-edition'\ntrain_dir = '../data/train'\ntest_dir = '../data/test'\n\nwith zipfile.ZipFile(os.path.join(base_dir, 'train.zip')) as train_zip:\n    train_zip.extractall('../data')\n    \nwith zipfile.ZipFile(os.path.join(base_dir, 'test.zip')) as test_zip:\n    test_zip.extractall('../data')\n    \n    \nimport glob\ntrain_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))\n\nfrom PIL import Image\nrandom_idx = np.random.randint(1,25000,size=10)\n\nfig = plt.figure()\ni=1\nfor idx in random_idx:\n    ax = fig.add_subplot(2,5,i)\n    img = Image.open(train_list[idx])\n    plt.imshow(img)\n    i+=1\n\nplt.axis('off')\nplt.show()\n\n\nfrom sklearn.model_selection import train_test_split\ntrain_list, val_list = train_test_split(train_list, test_size=0.2)\n\n\n#data Augumentation\ntrain_transforms =  transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ])\n\nval_transforms = transforms.Compose([\n        transforms.Resize((224, 224)),\n        transforms.RandomResizedCrop(224),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n    ])\n\n\ntest_transforms = transforms.Compose([   \n    transforms.Resize((224, 224)),\n     transforms.RandomResizedCrop(224),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor()\n    ])\n\nclass dataset(torch.utils.data.Dataset):\n    def __init__(self,file_list,transform=None):\n        self.file_list = file_list\n        self.transform = transform\n        \n        \n    #dataset length\n    def __len__(self):\n        self.filelength = len(self.file_list)\n        return self.filelength\n    \n    #load an one of images\n    def __getitem__(self,idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n        \n        label = img_path.split('/')[-1].split('.')[0]\n        if label == 'dog':\n            label=1\n        elif label == 'cat':\n            label=0\n            \n        return img_transformed,label\n    \ntrain_data = dataset(train_list, transform=train_transforms)\ntest_data = dataset(test_list, transform=test_transforms)\nval_data = dataset(val_list, transform=test_transforms)\n\n\n\n\nlr = 0.001 # learning_rate\nbatch_size = 350 # we will use mini-batch method\nepochs = 10 # How much to train a model\n\n\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_data, batch_size=batch_size, shuffle=True )\ntest_loader = torch.utils.data.DataLoader(dataset = test_data, batch_size=batch_size, shuffle=True)\nval_loader = torch.utils.data.DataLoader(dataset = val_data, batch_size=batch_size, shuffle=True)\n\n\nclass ResidualBlock(nn.Module):\n    # 实现子module: Residual    Block\n    def __init__(self, inchannel, outchannel, stride=1, shortcut=None):\n        super(ResidualBlock, self).__init__()\n        self.left = nn.Sequential(\n            nn.Conv2d(inchannel, outchannel, 3, stride, 1, bias=False),\n            nn.BatchNorm2d(outchannel),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(outchannel, outchannel, 3, 1, 1, bias=False),\n            nn.BatchNorm2d(outchannel)\n        )\n\n        self.right = shortcut\n\n    def forward(self, x):\n        out = self.left(x)\n        residual = x if self.right is None else self.right(x)\n        out += residual\n        return F.relu(out)\n\n\nclass ResNet(nn.Module):\n    # 实现主module:ResNet34\n    # ResNet34包含多个layer,每个layer又包含多个residual block\n    # 用子module实现residual block , 用 _make_layer 函数实现layer\n    def __init__(self, num_classes=2):\n        super(ResNet, self).__init__()\n        self.pre = nn.Sequential(\n            nn.Conv2d(3, 64, 7, 2, 3, bias=False),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(3, 2, 1)\n        )\n        # 重复的layer,分别有3,4,6,3个residual block\n        self.layer1 = self._make_layer(64, 64, 3)\n        self.layer2 = self._make_layer(64, 128, 4, stride=2)\n        self.layer3 = self._make_layer(128, 256, 6, stride=2)\n        self.layer4 = self._make_layer(256, 512, 3, stride=2)\n\n        # 分类用的全连接\n        self.fc = nn.Linear(512, num_classes)\n    \n\n    def _make_layer(self, inchannel, outchannel, block_num, stride=1):\n        # 构建layer,包含多个residual block\n        shortcut = nn.Sequential(\n            nn.Conv2d(inchannel, outchannel, 1, stride, bias=False),\n            nn.BatchNorm2d(outchannel))\n\n        layers = []\n        layers.append(ResidualBlock(inchannel, outchannel, stride, shortcut))\n\n        for i in range(1, block_num):\n            layers.append(ResidualBlock(outchannel, outchannel))\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        x = self.pre(x)\n\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n\n        x = F.avg_pool2d(x, 7)\n        x = x.view(x.size(0), -1)\n        x=self.fc(x)\n        return nn.Sigmoid()(x)\n    \n    \n    \ndevice = 'cuda'if torch.cuda.is_available() else 'cpu'\n\ntorch.manual_seed(1234)\nif device =='cuda':\n    torch.cuda.manual_seed_all(1234)\n    \n    \nmodel =ResNet().to(device)\nmodel.train()\n\n\noptimizer = optim.Adam(params = model.parameters(),lr=0.001)\ncriterion = nn.CrossEntropyLoss()\n\n\n\nepochs = 100\n\nfor epoch in range(epochs):\n    epoch_loss = 0\n    epoch_accuracy = 0\n    \n    for data, label in train_loader:\n        data = data.to(device)\n        label = label.to(device)\n        \n        output = model(data)\n        loss = criterion(output, label)\n        \n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        acc = ((output.argmax(dim=1) == label).float().mean())\n        epoch_accuracy += acc/len(train_loader)\n        epoch_loss += loss/len(train_loader)\n        \n    print('Epoch : {}, train accuracy : {}, train loss : {}'.format(epoch+1, epoch_accuracy,epoch_loss))\n    \n    \n    with torch.no_grad():\n        epoch_val_accuracy=0\n        epoch_val_loss =0\n        for data, label in val_loader:\n            data = data.to(device)\n            label = label.to(device)\n            \n            val_output = model(data)\n            val_loss = criterion(val_output,label)\n            \n            \n            acc = ((val_output.argmax(dim=1) == label).float().mean())\n            epoch_val_accuracy += acc/ len(val_loader)\n            epoch_val_loss += val_loss/ len(val_loader)\n            if epoch%2==0:\n                torch.save(model,'net.pkl')\n        print('Epoch : {}, val_accuracy : {}, val_loss : {}'.format(epoch+1, epoch_val_accuracy,epoch_val_loss))\nprint('ok')","metadata":{"execution":{"iopub.status.busy":"2022-01-30T02:00:49.67597Z","iopub.execute_input":"2022-01-30T02:00:49.676352Z","iopub.status.idle":"2022-01-30T02:21:39.914201Z","shell.execute_reply.started":"2022-01-30T02:00:49.676266Z","shell.execute_reply":"2022-01-30T02:21:39.912852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}