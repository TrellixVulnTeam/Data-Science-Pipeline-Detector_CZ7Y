{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score, accuracy_score\nfrom keras.utils import Sequence\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_path = '../input'\n\ntrain = os.path.join(data_path, r'train')\ntest = os.path.join(data_path, r'test')\n\ntrain_images = sorted(os.listdir(train))\ntest_images = sorted(os.listdir(test))\nprint(\"Total number of images in the training set: \", len(train_images))\nprint(\"Total number of samples in the test set: \", len(test_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"../input/train/train\")\ncategories = []\nfor filename in filenames:\n    category = filename.split('.')[0]\n    if category == 'dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf = pd.DataFrame({\n    'filename': filenames,\n    'category': categories\n})\n\ndf[\"category\"] = df[\"category\"].replace({0: 'cat', 1: 'dog'})\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, random_state=42)\ntrain_df = train_df.reset_index(drop=True)\nvalid_df = valid_df.reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"WORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSIZE = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class My_Generator(Sequence):\n\n    def __init__(self, image_filenames, labels,\n                 batch_size, is_train=False,\n                 mix=False, augment=False):\n        self.image_filenames, self.labels = image_filenames, labels\n        self.batch_size = batch_size\n        self.is_train = is_train\n        self.is_augment = augment\n        if(self.is_train):\n            self.on_epoch_end()\n        self.is_mix = mix\n\n    def __len__(self):\n        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n\n    def __getitem__(self, idx):\n        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n\n        if(self.is_train):\n            return self.train_generate(batch_x, batch_y)\n        return self.valid_generate(batch_x, batch_y)\n\n    def on_epoch_end(self):\n        if(self.is_train):\n            self.image_filenames, self.labels = shuffle(self.image_filenames, self.labels)\n    \n    def mix_up(self, x, y):\n        lam = np.random.beta(0.2, 0.4)\n        ori_index = np.arange(int(len(x)))\n        index_array = np.arange(int(len(x)))\n        np.random.shuffle(index_array)        \n        \n        mixed_x = lam * x[ori_index] + (1 - lam) * x[index_array]\n        mixed_y = lam * y[ori_index] + (1 - lam) * y[index_array]\n        \n        return mixed_x, mixed_y\n\n    def train_generate(self, batch_x, batch_y):\n        batch_images = []\n        for (sample, label) in zip(batch_x, batch_y):\n            img = cv2.imread('../input/train/'+sample)\n            img = cv2.resize(img, (SIZE, SIZE))\n            if(self.is_augment):\n                img = seq.augment_image(img)\n            batch_images.append(img)\n        batch_images = np.array(batch_images, np.float32) / 255\n        # batch_y = np.array(batch_y, np.float32)\n        return batch_images, batch_images\n\n    def valid_generate(self, batch_x, batch_y):\n        batch_images = []\n        for (sample, label) in zip(batch_x, batch_y):\n            img = cv2.imread('../input/train/'+sample)\n            img = cv2.resize(img, (SIZE, SIZE))\n            batch_images.append(img)\n        batch_images = np.array(batch_images, np.float32) / 255\n        # batch_y = np.array(batch_y, np.float32)\n        return batch_images, batch_images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,\n                         UpSampling2D)\nfrom keras.applications.resnet50 import ResNet50\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nimport keras\nfrom keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Lets' define our autoencoder now\ndef create_model(input_shape):\n    input_tensor = Input(shape=input_shape)\n    \n    # encoder \n    encoded = Conv2D(8, (2,2), activation='relu', strides=(2,2))(input_tensor) # 128x128\n    encoded = Conv2D(16, (2,2), activation='relu', strides=(2,2))(encoded) # 64x64\n    encoded = Conv2D(32, (2,2), activation='relu', strides=(2,2))(encoded) # 32x32\n    encoded = Conv2D(64, (2,2), activation='relu', strides=(2,2))(encoded) # 16x16\n    \n    # coded\n    code = Conv2D(128, (2,2), activation='relu', strides=(2,2))(encoded) # 8x8\n    \n    # decoder\n    decoded = Conv2D(128, (2,2), activation='relu', padding='same')(code) # 8x8\n    decoded = UpSampling2D((2,2))(decoded) # 16x16\n    decoded = Conv2D(64, (2,2), activation='relu', padding='same')(decoded) # 16x16\n    decoded = UpSampling2D((2,2))(decoded) # 32x32\n    decoded = Conv2D(32, (2,2), activation='relu', padding='same')(decoded) # 32x32\n    decoded = UpSampling2D((2,2))(decoded) # 64x64\n    decoded = Conv2D(16, (2,2), activation='relu', padding='same')(decoded) # 64x64\n    decoded = UpSampling2D((2,2))(decoded) # 128x128\n    decoded = Conv2D(8, (2,2), activation='relu', padding='same')(decoded) # 128x128\n    decoded = UpSampling2D((2,2))(decoded) # 256x256\n    \n    output_tensor = Conv2D(3, (1,1), activation='sigmoid')(decoded)\n    \n    #model\n    autoencoder = Model(inputs=input_tensor, outputs=output_tensor)\n    return autoencoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create callbacks list\nfrom keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                             EarlyStopping, ReduceLROnPlateau,CSVLogger)\n\nepochs = 50; batch_size = 16\ncheckpoint = ModelCheckpoint('../working/auto_encoder.h5', monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=2, \n                                   verbose=1, mode='min', epsilon=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=5)\n\ncsv_logger = CSVLogger(filename='../working/training_log.csv',\n                       separator=',',\n                       append=True)\n\ntrain_generator = My_Generator(train_df['filename'], train_df['category'], batch_size, is_train=True)\nvalid_generator = My_Generator(valid_df['filename'], valid_df['category'], batch_size, is_train=False)\n\nmodel = create_model(input_shape=(SIZE,SIZE,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(1e-3))\n\ncallbacks_list = [checkpoint, csv_logger, reduceLROnPlat, early]\n\nmodel.fit_generator(\n    train_generator,\n    steps_per_epoch=np.ceil(float(len(train_df)) / float(batch_size)),\n    validation_data=valid_generator,\n    validation_steps=np.ceil(float(len(valid_df)) / float(batch_size)),\n    epochs=epochs,\n    workers=WORKERS, use_multiprocessing=False,\n    verbose=1,\n    callbacks=callbacks_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n\nfor file_name in tqdm(test_images[:1]):\n    path = os.path.join('../input/test/', file_name)\n    image = cv2.imread(path)\n    image = cv2.resize(image, (SIZE, SIZE))\n    decoded_image = model.predict((image[np.newaxis])/255)[0]\n    \n    ax = plt.subplot(1, 2, 1)\n    plt.imshow(image)\n\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    ax = plt.subplot(1, 2, 2)\n    plt.imshow(decoded_image)\n\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    plt.show()    \n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}