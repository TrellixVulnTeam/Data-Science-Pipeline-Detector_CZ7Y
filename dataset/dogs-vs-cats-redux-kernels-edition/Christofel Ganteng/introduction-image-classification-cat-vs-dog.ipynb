{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nimport scipy\nimport csv as csv\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn as sk\nfrom numpy import array\nimport cv2\nimport os\nimport skimage as ski\nimport random\nimport PIL\nfrom PIL import ImageOps\nfrom PIL import Image \nfrom PIL import ImageFilter\nfrom sklearn.svm import LinearSVC, SVC\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss\nimport re\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\nfrom sklearn import preprocessing\n\nfrom subprocess import check_output","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"scrolled":true},"cell_type":"code","source":"# Unzip the dataset\n!unzip ../input/dogs-vs-cats-redux-kernels-edition/train.zip -d train\n!unzip ../input/dogs-vs-cats-redux-kernels-edition/test.zip -d test","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"#get full dataset\nTRAIN_DIR = '../working/train/train/'\ntrain_images = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for training images\n\n\nTEST_DIR = '../working/test/test/'\ntest_images = [TEST_DIR+i for i in os.listdir(TEST_DIR)] # use this for test images","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"#get labels\npredictedlabels=[]\nlabels=[]\ntrain_dogs=[]\nimages=[]\n\n\n#def baseline():         #flips a coin for each image\n #   predictedlabels=[]\n  #  for i in os.listdir(TRAIN_DIR):\n   #     test = random.randint(1,10)\n    #    if test>5:\n     #       predictedlabels.append(1)\n      #  else:\n       #     predictedlabels.append(0)\n   \n    \ndef train():            #gets correct class for each image\n\n    for i in os.listdir(TRAIN_DIR):\n        if 'dog' in i:\n            train_dogs.append(i)\n            labels.append(1)\n        else:\n            labels.append(0)\n            \n    return labels\n    \n    \n    \ndef getResults(predictedlabels, labels):    #outputs accuracy\n\n    total=0\n    newpredict=[]\n    for r in range(0,len(labels)):\n   \n        #if predictedlabels[r] == labels[r]:\n        \n        if float(predictedlabels[r])>0.5:\n            newpredict.append(1)\n        else:\n            newpredict.append(0)\n\n        if newpredict[r] == labels[r]:\n            total+=1\n         \n    print(\"Accuracy:\",total,\"/\",len(labels),\"* 100 =\",\"{0:.3f}\".format(total/len(labels)*100),\"%\")\n  \n\n\ndef nn(correctlabels):             \n    \n    #convert to one hot labels\n    onehotlabels=correctlabels[:]\n    for i in range(0,len(correctlabels)):\n        if correctlabels[i] == 0:\n            onehotlabels[i]=[1,0]\n        else:\n            onehotlabels[i]=[0,1]   \n    \n    testlabels= onehotlabels[24000:]  #last 1k images\n    trainlabels= onehotlabels[:24000] #first 24k images\n    \n    predictedlabels=[]\n    testimagepixels=[]\n    actuallabels=[]\n    \n    #tensorflow variables\n    \n    sess=tf.compat.v1.InteractiveSession()\n    x = tf.placeholder(tf.float32, shape=[None, 16384]) #no_samples,how many pixels image has\n    W = tf.Variable(tf.random_normal([16384,2],stddev=0.00001))\n    b = tf.Variable(tf.zeros([2]))      #two classes\n    sess.run(tf.global_variables_initializer())\n    y = tf.matmul(x,W) + b\n    \n    #training\n    y_ = tf.placeholder(tf.float32, shape=[None,2]) #no_samples,how many different classes\n    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=y, labels=y_))\n    \n    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n    \n    init = tf.global_variables_initializer()\n\n    sess=tf.compat.v1.InteractiveSession()\n    \n    sess.run(init) \n    \n    #train classifier\n    for i in range(0,24000):    \n        \n        trainimg = Image.open(train_images[i]).convert('L')    #preprocess images\n        size=128,128\n        trainimg =trainimg.resize(size, Image.ANTIALIAS)             \n        trainimg = trainimg.filter(ImageFilter.BLUR)\n        trainimg = trainimg.filter(ImageFilter.FIND_EDGES)\n        \n        \n        trainimg = list(trainimg.getdata())\n        label = trainlabels[i]    #get correct label and format\n        trainimg = preprocessing.normalize([trainimg])\n           \n        train_step.run(feed_dict={x: trainimg, y_: [label]}) #run with image, correct label\n        \n    #test classifier    \n    for i in range(0,1000):\n        \n        testimg = Image.open(train_images[24000+i]).convert('L')    #preprocess images\n        size=128,128\n        testimg =testimg.resize(size, Image.ANTIALIAS)\n        \n        \n        testimg = testimg.filter(ImageFilter.BLUR)\n        testimg = testimg.filter(ImageFilter.FIND_EDGES)\n       \n        testimg = list(testimg.getdata())\n        \n        testimg = preprocessing.normalize([testimg])        \n     \n        testimg=testimg[0]\n        testimagepixels.append(testimg)\n        \n        label = testlabels[i]     #get correct label and format\n        actuallabels.append(label)\n      \n        classification = sess.run(tf.argmax(y, 1), feed_dict={x:[testimg]})    \n        predictedlabels.append(classification)\n    \n    prediction=y\n    results=prediction.eval(feed_dict={x: testimagepixels})\n    results=preprocessing.MinMaxScaler(feature_range=(0, 1), copy=True).fit_transform(results)\n    \n    correct_prediction = tf.equal(tf.argmax(y,1), tf.argmax(y_,1))\n    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n    flattened = [val for sublist in predictedlabels for val in sublist]  \n    \n    #double check the accuracy\n    print(float(sess.run(accuracy, feed_dict={x:testimagepixels, y_: actuallabels})))\n   # print(\"Log Loss\",sk.metrics.log_loss(correctlabels[24000:],predictedlabels))\n    getResults(flattened,correctlabels[24000:25000])  \n   \n    \n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"def kaggletest(correctlabels):\n    \n    \n    \n    myfile = open('results.csv', 'w')\n    wr = csv.writer(myfile, quoting=csv.QUOTE_NONE,quotechar='',escapechar='\\\\')\n    wr.writerow([\"id\",\"label\"])\n    \n     #convert to one hot labels\n    onehotlabels=correctlabels[:]\n    for i in range(0,len(correctlabels)):\n        if correctlabels[i] == 0:\n            onehotlabels[i]=[1,0]\n        else:\n            onehotlabels[i]=[0,1]\n    \n    \n    \n    \n    trainlabels= onehotlabels[:] #first 24k images\n    \n    predictedlabels=[]\n    testimagepixels=[]\n    actuallabels=[]\n    \n    #tensorflow variables\n    sess = tf.InteractiveSession()\n    x = tf.placeholder(tf.float32, shape=[None, 16384]) #no_samples,how many pixels image has\n    W = tf.Variable(tf.random_normal([16384,2],stddev=0.00001))\n   #W = tf.Variable(tf.truncated_normal([16384,2],mean=5.0,stddev=10)) #no_pixels,two outputs\n    b = tf.Variable(tf.zeros([2]))      #two classes\n    sess.run(tf.global_variables_initializer())\n    y = tf.matmul(x,W) + b\n    \n    #training\n    y_ = tf.placeholder(tf.float32, shape=[None,2]) #no_samples,how many different classes\n    cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, y_))\n    #tweak this and measure results \n    train_step = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy)\n    \n    init = tf.global_variables_initializer()\n    sess = tf.InteractiveSession()\n    sess.run(init) \n    guesses=[] \n    #train\n    for i in range(0,25000):    \n        \n        trainimg = Image.open(train_images[i]).convert('L')    #preprocess images\n        \n        size=128,128\n        trainimg =trainimg.resize(size, Image.ANTIALIAS)\n        \n        trainimg = trainimg.filter(ImageFilter.BLUR)\n        trainimg = trainimg.filter(ImageFilter.FIND_EDGES)\n        \n        trainimg = list(trainimg.getdata())\n        \n        #trainimg = [float(i)/sum(trainimg) for i in trainimg]\n        label = trainlabels[i]    #get correct label and format\n        trainimg = preprocessing.normalize([trainimg])\n      # trainimg = preprocessing.binarize(trainimg)\n       \n        train_step.run(feed_dict={x: trainimg, y_: [label]}) #run with image, correct label\n    \n    \n    #test\n    for i in range(0,len(test_images)):\n        \n        testimg = Image.open(test_images[i]).convert('L')    #preprocess images\n        size=128,128\n        testimg =testimg.resize(size, Image.ANTIALIAS)\n        \n        testimg = testimg.filter(ImageFilter.BLUR)\n        testimg = testimg.filter(ImageFilter.FIND_EDGES)\n        \n        testimg = list(testimg.getdata())\n           \n        testimg = preprocessing.normalize([testimg])\n        \n        testimg=testimg[0]\n        testimagepixels.append(testimg)\n        '''\n        #this is tensorflows guess at which class the image belongs to\n        classification = sess.run(tf.argmax(y, 1), feed_dict={x:[testimg]})    \n        predictedlabels.append(classification)\n        '''\n        prediction=y\n       \n        results=prediction.eval(feed_dict={x: [testimg]})\n       \n        results = [results[0][1]]\n        #print(results)\n        \n        guesses.append(results)\n\n    results=preprocessing.MinMaxScaler(feature_range=(0, 1), copy=True).fit_transform(guesses)\n    \n    test=[]\n    for i in range(0,len(test_images)):    \n        test.append([i+1,results[i][0]])\n        wr.writerow([i+1,results[i][0]])\n    print(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"y=train()   #get correct labels\n\nclf=nn(y)   #get trained svm ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}