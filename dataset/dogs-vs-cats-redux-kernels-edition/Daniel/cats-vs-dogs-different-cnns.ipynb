{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport requests\nimport os\nfrom zipfile import ZipFile\nimport pandas as pd\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.python.keras.layers import Dense, Dropout, Input, Activation, Conv2D, MaxPooling2D, Flatten\nfrom tensorflow.python.keras import Sequential\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import *","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# HTTPS Requests, to send status via TelegramBot"},{"metadata":{"trusted":true},"cell_type":"code","source":"def telegram_bot_sendtext(bot_message):\n    \n    bot_token = '862297446:AAFooZ12e_PUVe1Nv59uzl3ceO_TqiTCnoc'\n    bot_chatID = '660201452'\n    send_text = 'https://api.telegram.org/bot' + bot_token + '/sendMessage?chat_id=' + bot_chatID + '&parse_mode=Markdown&text=' + bot_message\n\n    response = requests.get(send_text)\n\n    return response.json()\n\ntelegram_bot_sendtext('Start Script')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data\n\n\n1. Add the *Dogs vs. Cats Redux: Kernels Edition* on the top right __+ Add Data__\n   \n   Now we have the folling folder structure:  \n   \n   ├── Dogs vs. Cats Redux: Kernels Edition  \n   │   ├── test.zip  \n   │   ├── train.zip  \n   │   └── sample_submission.csv  \n   \n   \n2. Next we need to extract train and test data. We will use __ZipFile__ for that. Since the input directory is a __read only__ directory, we have to extract the zip files into the output directory."},{"metadata":{"trusted":true},"cell_type":"code","source":"with ZipFile('../input/dogs-vs-cats-redux-kernels-edition/train.zip') as zipobj:\n    zipobj.extractall('../working')\nwith ZipFile('../input/dogs-vs-cats-redux-kernels-edition/test.zip') as zipobj:\n    zipobj.extractall('../working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = os.listdir('../working/train')\ntest_data = os.listdir('../working/test')\n\nos.mkdir('../working/train/cats')\nos.mkdir('../working/train/dogs')\nos.mkdir('../working/test/cats')\nos.mkdir('../working/test/dogs')\nos.mkdir('../working/models')\n\nfor i in train_data:\n    #print(i)\n    if (i != 'cats') and (i != 'dogs'):\n        if 'cat' in i:\n            os.replace(\"../working/train/\"+i, \"../working/train/cats/\"+i)\n        elif 'dog' in i:\n            os.replace(\"../working/train/\"+i, \"../working/train/dogs/\"+i)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" 3. After extraction and sorting we have the following folder structure:\n \n ├── working   \n │   ├── train   \n │   │    ├── cats  \n │   │    └── dogs  \n │   ├── test    \n │   └── sample_submission.csv    "},{"metadata":{},"cell_type":"markdown","source":"# Data Generator"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"bs=32\n\ntrain_datagen = ImageDataGenerator(\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        validation_split=0.2)\n\ntest_datagen = ImageDataGenerator(rescale=1./255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        '../working/train',\n        target_size=(128, 128),\n        batch_size=bs,\n        class_mode='binary',\n        subset='training') # set as training data\n\nvalidation_generator = train_datagen.flow_from_directory(\n        '../working/train',\n        target_size=(128, 128),\n        batch_size=bs,\n        class_mode='binary',\n        subset='validation') # set as validation data\n\ntest_generator = test_datagen.flow_from_directory(\n        '../working',\n        target_size=(128, 128),\n        batch_size=1,\n        classes=['test'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define and Train model"},{"metadata":{"trusted":true},"cell_type":"code","source":"lr=None\nmodelname=''\nmodel_destination = '../working/models/'\noptimizer = ''\n\n# Callbacks\ncheckpoint = ModelCheckpoint(f\"{model_destination}{modelname}_bs_{bs}_{optimizer}_{lr}.h5\",\n                             monitor='val_loss',\n                             verbose=0, save_best_only=True, save_weights_only=False)    \nes = EarlyStopping(monitor='val_loss', patience=3, baseline=None, restore_best_weights=False)\n\ncallbacks = [checkpoint, es]\n# define cnn model\ndef vgg():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(128, 128, 3)))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    model.add(Dropout(0.5))\n    model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1, activation='sigmoid'))\n    # compile model\n    opt = SGD(lr=0.001, momentum=0.9)\n    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n    optimizer = opt.__dict__['_name']\n    lr = opt.__dict__['_hyper']['learning_rate']\n    global modelname\n    modelname ='VGG'\n    return model\n\nclassification_model = vgg()\nprint('Done!')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training = classification_model.fit_generator(train_generator, epochs=60, validation_data=validation_generator, callbacks=callbacks)\nhistory = training.history\ntelegram_bot_sendtext('Training finished!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save Model and training history"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#classification_model.save(f\"{model_destination}{modelname}_bs_{bs}_{optimizer}_{lr}.h5\")\n\nhist_df = pd.DataFrame(history)\nhist_df.to_csv(f'history{modelname}_bs_{bs}_{optimizer}_{lr}.csv')\ntelegram_bot_sendtext(str(history))\ntelegram_bot_sendtext('Model saved!')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Evaluate Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('dark_background')\n#history['loss'] = [1,2,3,4,5]\n#history['accuracy'] = [5,4,3,2,1]\n#history['val_loss'] = [2,4,6,8,10]\n#history['val_accuracy'] = [10,8,6,4,2]\n#history = training.history\n\nplt.figure(num=None, figsize=(8, 6), dpi=80)\nplt.title('Loss')\nplt.plot(history['loss'], color='red')\nplt.plot(history['val_loss'], color='green')\nplt.legend(['Training Loss', 'Validation Loss'])\nplt.show()\n\nplt.figure(num=None, figsize=(8, 6), dpi=80)\nplt.title('Accuracy')\nplt.plot(history['accuracy'], color='red')\nplt.plot(history['val_accuracy'], color='green')\nplt.legend(['Training accuracy', 'Validation accuracy'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sn\nimport numpy as np\n\nvalidation_generator.shuffle = False\nvalidation_generator.index_array = None\n\ny_pred = classification_model.predict_generator(validation_generator)\ny_label = validation_generator.classes\n\n# Save y_pred and y_label into Dataframe\n#pd.DataFrame({'y_pred':y_pred, 'y_label':y_label})\n\n# Confusion MATRIX cat=0 dog=1\n# roundpredictions\ny_pred_bin = np.where(y_pred > 0.5, 1, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n[[tn, fp], [fn, tp]] = confusion_matrix(y_label, y_pred_bin, labels=[0, 1])# normalize='all')\narray = [[tn/(tn+fp),fp/(tn+fp)], \n        [fn/(tp+fn),tp/(tp+fn)]]\ndf_cm = pd.DataFrame(array, index = [\"Cat\",\"Dog\"],\n                  columns = [\"Cat\",\"Dog\"])\nplt.figure(figsize = (10,7))\nsn.heatmap(df_cm, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prepare Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted = classification_model.predict_generator(test_generator)\nsample_submission = pd.read_csv(\"../input/dogs-vs-cats-redux-kernels-edition/sample_submission.csv\")\nsample_submission.label = predicted\nsample_submission.to_csv('next_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Delete Dataset from working directory\n\nWe delete it in order to keep our output section clean"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\n\nshutil.rmtree('../working/train')\nshutil.rmtree('../working/test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(test_generator.__getitem__(0))\n\n\n#import base64\n#data = open(f\"{model_destination}{modelname}_bs_{bs}_{optimizer}_{lr}.h5\", \"rb\").read()\n#data = open(f\"158d.jpg\", \"rb\").read() \n#no_enc = repr(data)\n#encoded = base64.b64encode(no_enc)\n#telegram_bot_sendtext(data)\n#print(encoded)\n#telegram_bot_sendtext('Model as Text (BASE64)')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}