{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-14T07:08:51.657054Z","iopub.execute_input":"2021-07-14T07:08:51.657538Z","iopub.status.idle":"2021-07-14T07:08:51.667554Z","shell.execute_reply.started":"2021-07-14T07:08:51.657489Z","shell.execute_reply":"2021-07-14T07:08:51.666536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import zipfile\n\nwith zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/test.zip') as existing_zip:\n    existing_zip.extractall()\nwith zipfile.ZipFile('../input/dogs-vs-cats-redux-kernels-edition/train.zip') as existing_zip:\n    existing_zip.extractall()","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:08:51.669523Z","iopub.execute_input":"2021-07-14T07:08:51.670125Z","iopub.status.idle":"2021-07-14T07:09:09.460747Z","shell.execute_reply.started":"2021-07-14T07:08:51.670086Z","shell.execute_reply":"2021-07-14T07:09:09.459815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls ../input/dogs-vs-cats-redux-kernels-edition","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:09.462743Z","iopub.execute_input":"2021-07-14T07:09:09.463098Z","iopub.status.idle":"2021-07-14T07:09:10.143747Z","shell.execute_reply.started":"2021-07-14T07:09:09.463068Z","shell.execute_reply":"2021-07-14T07:09:10.142796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd train","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:10.145722Z","iopub.execute_input":"2021-07-14T07:09:10.146163Z","iopub.status.idle":"2021-07-14T07:09:10.152632Z","shell.execute_reply.started":"2021-07-14T07:09:10.146117Z","shell.execute_reply":"2021-07-14T07:09:10.151552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir cat","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:10.154144Z","iopub.execute_input":"2021-07-14T07:09:10.154729Z","iopub.status.idle":"2021-07-14T07:09:10.822628Z","shell.execute_reply.started":"2021-07-14T07:09:10.154691Z","shell.execute_reply":"2021-07-14T07:09:10.821473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mkdir dog","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:10.824386Z","iopub.execute_input":"2021-07-14T07:09:10.824726Z","iopub.status.idle":"2021-07-14T07:09:11.498839Z","shell.execute_reply.started":"2021-07-14T07:09:10.824685Z","shell.execute_reply":"2021-07-14T07:09:11.497605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nimport glob\nimport os\n\ndef move_glob(dst_path, pathname, recursive=True):\n    for p in glob.glob(pathname, recursive=recursive):\n        shutil.move(p, dst_path)\n\nmove_glob('./dog', 'dog*.jpg')\n\nmove_glob('./cat', 'cat*.jpg')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:11.502731Z","iopub.execute_input":"2021-07-14T07:09:11.503068Z","iopub.status.idle":"2021-07-14T07:09:12.426601Z","shell.execute_reply.started":"2021-07-14T07:09:11.503032Z","shell.execute_reply":"2021-07-14T07:09:12.425644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip install openpyxl","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:12.427901Z","iopub.execute_input":"2021-07-14T07:09:12.428282Z","iopub.status.idle":"2021-07-14T07:09:22.078551Z","shell.execute_reply.started":"2021-07-14T07:09:12.428244Z","shell.execute_reply":"2021-07-14T07:09:22.077618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cd ../","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:22.081542Z","iopub.execute_input":"2021-07-14T07:09:22.081811Z","iopub.status.idle":"2021-07-14T07:09:22.089697Z","shell.execute_reply.started":"2021-07-14T07:09:22.081781Z","shell.execute_reply":"2021-07-14T07:09:22.088858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch # 基本モジュール\nfrom torch.autograd import Variable # 自動微分用\nimport torch.nn as nn # ネットワーク構築用\nimport torch.optim as optim # 最適化関数\nimport torch.nn.functional as F # ネットワーク用の様々な関数\nimport torch.utils.data # データセット読み込み関連\nfrom torchvision import transforms\nfrom torch.utils.tensorboard import SummaryWriter\nimport torchvision.models as models\nimport math\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n\nimport matplotlib.pyplot as plt\nimport cloudpickle\nimport random\nimport cv2\n\nimport pandas as pd\nfrom PIL import Image,ImageFilter\nimport numpy as np\nimport openpyxl as px\n\nimport sys\nimport time\nimport datetime\nLABEL_IDX = 1\nIMG_IDX = 0","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:22.091431Z","iopub.execute_input":"2021-07-14T07:09:22.091695Z","iopub.status.idle":"2021-07-14T07:09:23.99726Z","shell.execute_reply.started":"2021-07-14T07:09:22.091668Z","shell.execute_reply":"2021-07-14T07:09:23.996395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('./test.txt', mode='w') as f:\n  f.write(\"name,label\")\n  for num in range(1,12501):\n    f.write('\\n')\n    f.write(\"test/\" + (str)(num) + \",0\")\n    \nwith open('./dog.txt', mode='w') as f:\n  f.write(\"name,label\")\n  for num in range(1,12500):\n    f.write('\\n')\n    f.write(\"dog/dog.\" + (str)(num) + \",0\")\n    \nwith open('./cat.txt', mode='w') as f:\n  f.write(\"name,label\")\n  for num in range(1,12500):\n    f.write('\\n')\n    f.write(\"cat/cat.\" + (str)(num) + \",1\")\n    \n# 学習データのパス\nTRAIN_PATH = [\n    r\"./cat.txt\",\n    r\"./dog.txt\",\n    r\"./test.txt\"\n]\n\n# ミニバッチ\nBATCH_SIZE = 100","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:23.998541Z","iopub.execute_input":"2021-07-14T07:09:23.99887Z","iopub.status.idle":"2021-07-14T07:09:24.03787Z","shell.execute_reply.started":"2021-07-14T07:09:23.998835Z","shell.execute_reply":"2021-07-14T07:09:24.037113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:24.039239Z","iopub.execute_input":"2021-07-14T07:09:24.039602Z","iopub.status.idle":"2021-07-14T07:09:24.676115Z","shell.execute_reply.started":"2021-07-14T07:09:24.039564Z","shell.execute_reply":"2021-07-14T07:09:24.675095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#データロード及びリサイズ\nclass uDataset(Dataset):\n\n    def __init__(self, csv_file_path, root_dir, training=True):\n        #pandasでcsvデータの読み出し\n        self.image_dataframe = pd.read_csv(csv_file_path)\n        self.root_dir = root_dir\n\n        #学習or推論\n        self.training = training\n\n    def __len__(self):\n        return len(self.image_dataframe)\n\n    def __getitem__(self, idx):\n        #dataframeから画像へのパスとラベルを読み出す\n        label = self.image_dataframe.iat[idx, LABEL_IDX]\n\n        img_name = os.path.join(self.root_dir, self.image_dataframe.iat[idx, IMG_IDX])\n\n        path = img_name + '.jpg'\n        val = np.mean(Image.open(path))\n\n        # 選択したインデックスの画像の読み込み\n        image = Image.open(path)\n\n        # 画像への前処理\n        if self.training == True:\n            # 画像の切り出し範囲をランダムに決定\n            if image.width > image.height:\n                dff_leng = image.width - image.height\n                shift = random.randint(0, dff_leng)\n                image = image.crop((shift, 0, image.width - (dff_leng - shift), image.height))\n            elif image.height > image.width:\n                dff_leng = image.height - image.width\n                shift = random.randint(0, dff_leng)\n                image = image.crop((0, shift, image.width, image.height  - (dff_leng - shift)))\n            else:\n                image = image.crop((0, 0, image.width, image.height))\n\n            p = random.randint(1, 100)\n            if p > 50:\n                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n\n        else:\n            if image.width > image.height:\n                dff_leng = image.width - image.height\n                shift = dff_leng / 2\n                image = image.crop((shift, 0, image.width - (dff_leng - shift), image.height))\n            elif image.height > image.width:\n                dff_leng = image.height - image.width\n                shift = dff_leng / 2\n                image = image.crop((0, shift, image.width, image.height  - (dff_leng - shift)))\n            else:\n                image = image.crop((0, 0, image.width, image.height))\n            \n        if image.width != 224 or image.height != 224:\n            image = image.resize((224, 224),Image.BICUBIC)\n            \n        \n        # numpy型への変換\n        image = np.concatenate([image],2)\n        imageNP = np.array(image).astype(np.float32)\n\n\n        # 標準化を行う\n        ave_1 = np.mean(imageNP[:,:,0])\n        ave_2 = np.mean(imageNP[:,:,1])\n        ave_3 = np.mean(imageNP[:,:,2])\n        std_1 = np.std(imageNP[:,:,0])\n        std_2 = np.std(imageNP[:,:,1])\n        std_3 = np.std(imageNP[:,:,2])\n        \n        \n        if std_1 > 0:\n            imageNP[:,:,0] = (imageNP[:,:,0] - ave_1) / std_1\n        if std_2 > 0:\n            imageNP[:,:,1] = (imageNP[:,:,1] - ave_2) / std_2\n        if std_3 > 0:\n            imageNP[:,:,2] = (imageNP[:,:,2] - ave_3) / std_3\n\n        image = transforms.ToTensor()(imageNP)\n\n\n        return image, label\n    \n    def filepath(self, idx):\n        img_name = os.path.join(self.root_dir, self.image_dataframe.iat[idx, IMG_IDX])\n        return img_name","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:24.679554Z","iopub.execute_input":"2021-07-14T07:09:24.679849Z","iopub.status.idle":"2021-07-14T07:09:24.699405Z","shell.execute_reply.started":"2021-07-14T07:09:24.679819Z","shell.execute_reply":"2021-07-14T07:09:24.698522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#ネットワーク構造\nclass Block(nn.Module):\n    def __init__(self, channel_in, channel_out):\n        super().__init__()\n        channel = channel_out // 4\n\n        # 1x1 の畳み込み\n        self.conv1 = nn.Conv2d(channel_in, channel,\n                               kernel_size=(1, 1))\n        self.bn1 = nn.BatchNorm2d(channel)\n        self.relu1 = nn.ReLU()\n\n        # 3x3 の畳み込み\n        self.conv2 = nn.Conv2d(channel, channel,\n                               kernel_size=(3, 3),\n                               padding=1)\n        self.bn2 = nn.BatchNorm2d(channel)\n        self.relu2 = nn.ReLU()\n\n        # 1x1 の畳み込み\n        self.conv3 = nn.Conv2d(channel, channel_out,\n                               kernel_size=(1, 1),\n                               padding=0)\n        self.bn3 = nn.BatchNorm2d(channel_out)\n\n        # skip connection用のチャネル数調整        \n        self.shortcut = self._shortcut(channel_in, channel_out)\n        \n        self.relu3 = nn.ReLU()\n\n    def forward(self, x):\n        #print(\"//////////////////////////////\")\n        #print(x.size())\n        h = self.conv1(x)\n        #print(h.shape)\n        h = self.bn1(h)\n        #print(h.shape)\n        h = self.relu1(h)\n        #print(h.shape)\n        h = self.conv2(h)\n        #print(h.shape)\n        h = self.bn2(h)\n        #print(h.shape)\n        h = self.relu2(h)\n        #print(h.shape)\n        h = self.conv3(h)\n        #print(h.shape)\n        h = self.bn3(h)\n        #print(h.shape)\n        shortcut = self.shortcut(x)\n        #print(h.shape)\n        y = self.relu3(h + shortcut)  # skip connection\n        #print(y.shape)\n        return y\n\n    def _shortcut(self, channel_in, channel_out):\n        if channel_in != channel_out:\n            return self._projection(channel_in, channel_out)\n        else:\n            return lambda x: x\n\n    def _projection(self, channel_in, channel_out):\n        return nn.Conv2d(channel_in, channel_out,\n                         kernel_size=(1, 1),\n                         padding=0)\n\nclass ResNet50(nn.Module):\n    def __init__(self, output_dim):\n        super().__init__()\n\n        self.conv1 = nn.Conv2d(3, 64,\n                               kernel_size=(7, 7),\n                               stride=(2, 2),\n                               padding=3)\n        self.bn1 = nn.BatchNorm2d(64)\n        self.relu1 = nn.ReLU()\n        self.pool1 = nn.MaxPool2d(kernel_size=(3, 3),\n                                  stride=(2, 2),\n                                  padding=1)\n\n        # Block 1\n        self.block0 = self._building_block(256, channel_in=64)\n        \n        self.block1 = nn.ModuleList([\n            self._building_block(256) for _ in range(2)\n        ])\n\n        self.conv2 = nn.Conv2d(256, 512,\n                               kernel_size=(1, 1),\n                               stride=(2, 2))\n\n        # Block 2\n        self.block2 = nn.ModuleList([\n            self._building_block(512) for _ in range(4)\n        ])\n\n        self.conv3 = nn.Conv2d(512, 1024,\n                               kernel_size=(1, 1),\n                               stride=(2, 2))\n\n        # Block 3\n        self.block3 = nn.ModuleList([\n            self._building_block(1024) for _ in range(6)\n        ])\n\n        self.conv4 = nn.Conv2d(1024, 2048,\n                               kernel_size=(1, 1),\n                               stride=(2, 2))\n\n        # Block 4\n        self.block4 = nn.ModuleList([\n            self._building_block(2048) for _ in range(3)\n        ])\n\n        self.avg_pool = GlobalAvgPool2d()  # TODO: GlobalAvgPool2d\n        self.fc = nn.Linear(2048, 1000)\n        self.out = nn.Linear(1000, output_dim)\n\n    def forward(self, x):\n        #print(\"?????????????????????????????????????\")\n        #print(x.size())\n        h = self.conv1(x)\n        #print(h.shape)\n        h = self.bn1(h)\n        #print(h.shape)\n        h = self.relu1(h)\n        #print(h.shape)\n        h = self.pool1(h)\n        #print(h.shape)\n        h = self.block0(h)\n        #print(h.shape)\n        for block in self.block1:\n            h = block(h)\n        h = self.conv2(h)\n        for block in self.block2:\n            h = block(h)\n        h = self.conv3(h)\n        for block in self.block3:\n            h = block(h)\n        h = self.conv4(h)\n        for block in self.block4:\n            h = block(h)\n        h = self.avg_pool(h)\n        #print(h.shape)\n        h = self.fc(h)\n        #print(h.shape)\n        h = torch.relu(h)\n        #print(h.shape)\n        h = self.out(h)\n        #print(h.shape)\n        y = torch.log_softmax(h, dim=-1)\n\n        return y\n\n    def _building_block(self,\n                        channel_out,\n                        channel_in=None):\n        if channel_in is None:\n            channel_in = channel_out\n        return Block(channel_in, channel_out)\n\nclass GlobalAvgPool2d(nn.Module):\n    def __init__(self,\n                 device='cpu'):\n        super().__init__()\n\n    def forward(self, x):\n        return F.avg_pool2d(x, kernel_size=x.size()[2:]).view(-1, x.size(1))","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:24.701091Z","iopub.execute_input":"2021-07-14T07:09:24.701708Z","iopub.status.idle":"2021-07-14T07:09:24.72763Z","shell.execute_reply.started":"2021-07-14T07:09:24.70167Z","shell.execute_reply":"2021-07-14T07:09:24.726797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loadData():\n    # データセットの作成\n    dataset1 = uDataset(TRAIN_PATH[0], r\"./train/\")\n    dataset2 = uDataset(TRAIN_PATH[1], r\"./train/\")\n    dataset3 = uDataset(TRAIN_PATH[2], r\"./\")\n\n    trainDataset = dataset1 + dataset2\n    testDataset = dataset3\n\n    # データの読み込み\n    trainDataloader = torch.utils.data.DataLoader(trainDataset, batch_size=BATCH_SIZE, shuffle=True)\n    testDataloader = torch.utils.data.DataLoader(testDataset, batch_size=256 , shuffle=True)\n\n    return trainDataloader, testDataloader\n\n# ハイパーパラメータの設定\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")                   # 学習に使用するデバイス\nmodel = ResNet50(2).to(device)\ncriterion = nn.CrossEntropyLoss()                                                       # loss関数\noptimizer = optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08)\ntrainDataloader, testDataloader = loadData()                                            # データの読み込み\n\n    \ndef train(dataLoader, epoch):\n    model.train()\n    trainLoss = 0\n    correct = 0\n\n    for batchIdx, (image, label) in enumerate(dataLoader):\n        image, label = image.to(device), label.to(device)\n        optimizer.zero_grad()\n        output = model(image)\n        loss = criterion(output, label)\n        trainLoss += loss.item()\n        pred = output.argmax(dim=1, keepdim=True)\n        correct += pred.eq(label.view_as(pred)).sum().item()\n            \n        loss.backward()\n        optimizer.step()\n\n        if batchIdx * BATCH_SIZE % 100 == 0:\n            print('Train Epoch: {} [{}/{} ({:.0f}%)], Loss: {:.6f}'.format(\n                epoch, batchIdx * BATCH_SIZE, len(dataLoader.dataset),\n                100. * batchIdx / len(dataLoader), loss.item()))\n        \n    return trainLoss, correct\n\ndef test(dataLoader):\n    model.eval()\n    testLoss = 0\n    correct = 0\n    with torch.no_grad():\n        for(image, label) in dataLoader:\n            \n            #print()\n            image, label = image.to(device), label.to(device)\n            output = model(image)\n            loss = criterion(output, label)\n            testLoss += loss.item()\n            pred = output.argmax(dim=1, keepdim=True)\n            correct += pred.eq(label.view_as(pred)).sum().item()\n\n        testLoss /= len(dataLoader)\n        print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n            testLoss, correct, len(dataLoader.dataset),\n            100. * correct / len(dataLoader.dataset)))\n\n    return testLoss, correct\n\ndef learning(model):\n\n    #学習\n    numEpochs = 30\n\n    lossList = []\n    accList = []\n\n    # 学習の収束結果をtensorboardに出力\n    writer = SummaryWriter(log_dir=\"./logs/sgd\")\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n\n    for epoch in range(1, numEpochs + 1):\n        loss, acc = train(trainDataloader, epoch)\n\n        #test(testDataloader)\n\n        writer.add_scalar(\"loss/train\", loss / len(trainDataloader), epoch)\n        writer.add_scalar(\"accuracy/train\", 100. * float(acc) / len(trainDataloader.dataset), epoch)\n\n        lossList.append(loss / len(trainDataloader))\n        accList.append(100. * float(acc) / len(trainDataloader.dataset))\n\n        # 10エポック毎に結果を保存\n        if epoch % 10 == 0:\n            savePath = \"./cnn_interlude_\" + \"{:05}\".format(epoch)\n            torch.save(model.state_dict(), savePath + \".weight\")\n            with open(savePath + \".pkl\", 'wb') as f:\n                cloudpickle.dump(model, f)\n        \n        scheduler.step()\n\n    writer.close()\n    \n    # 最終結果を保存\n    torch.save(model.state_dict(), './cnn_result.pkl')\n    with open('cnn_result.pkl', 'wb') as f:\n        cloudpickle.dump(model, f)","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-07-14T07:09:24.729141Z","iopub.execute_input":"2021-07-14T07:09:24.729616Z","iopub.status.idle":"2021-07-14T07:09:29.247615Z","shell.execute_reply.started":"2021-07-14T07:09:24.729577Z","shell.execute_reply":"2021-07-14T07:09:29.246795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:29.24885Z","iopub.execute_input":"2021-07-14T07:09:29.249368Z","iopub.status.idle":"2021-07-14T07:09:29.912933Z","shell.execute_reply.started":"2021-07-14T07:09:29.24932Z","shell.execute_reply":"2021-07-14T07:09:29.912029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"       \ndef inference(folderIndex):\n\n    \n    book = px.Workbook()\n    book.save('../' + 'submission.xlsx')\n    wb = px.Workbook()\n    ws = wb.active\n    #Sheetの名前を設定\n    ws.title = \"Sheet_1\"\n\n\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(device)\n    \n\n    # データセットの作成\n    dataset = uDataset(TRAIN_PATH[folderIndex], r\"./\", training=False)\n    dataLoader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=False)\n\n    with open('./cnn_result.pkl', 'rb') as f:\n        model = cloudpickle.load(f)\n        #shutil.copy2('./cnn_result.pkl', saveFolderPath + \"cnn_result.pkl\")\n        #print(model)\n        model.to(device)\n\n\n        model.eval()\n        a = 2\n        ws.cell(row = 1, column = 2, value = \"label\")\n        ws.cell(row = 1, column = 1, value = \"id\")\n\n        with torch.no_grad():\n            for idx, (image, label) in enumerate(dataLoader):\n                image, label = image.to(device), label.to(device)\n                start2 = time.time()\n                output = model(image)\n                #print(model(image))\n                \n                # softmaxで犬とする確率の確率を算出\n                outputS = F.softmax(model(image), dim=1)\n                \n                #csvファイルに書き込み\n                ws.cell(row = a, column = 2, value = float(outputS[0][0]))\n                ws.cell(row = a, column = 1, value = a-1)\n                a += 1\n                print(a)\n                \n    wb.save('./' + 'submission.xlsx')","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:29.91623Z","iopub.execute_input":"2021-07-14T07:09:29.916515Z","iopub.status.idle":"2021-07-14T07:09:29.927182Z","shell.execute_reply.started":"2021-07-14T07:09:29.916487Z","shell.execute_reply":"2021-07-14T07:09:29.926303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == '__main__':\n    # 学習モデルのサイズ\n    print('Total params: %.2fM' % (sum(p.numel() for p in model.parameters())/1000000.0))\n    learning(model)\n    idx = 2\n    inference(idx)\n    change_csv = pd.read_excel('./' + 'submission.xlsx', sheet_name=0)\n    change_csv.to_csv('./' + 'submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-14T07:09:29.928753Z","iopub.execute_input":"2021-07-14T07:09:29.929429Z","iopub.status.idle":"2021-07-14T10:28:08.213254Z","shell.execute_reply.started":"2021-07-14T07:09:29.929369Z","shell.execute_reply":"2021-07-14T10:28:08.211105Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pwd","metadata":{"execution":{"iopub.status.busy":"2021-07-14T10:28:08.214067Z","iopub.status.idle":"2021-07-14T10:28:08.214438Z"},"trusted":true},"execution_count":null,"outputs":[]}]}