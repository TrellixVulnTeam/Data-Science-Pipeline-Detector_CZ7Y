{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Kaggle link: https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nsecret_value_0 = user_secrets.get_secret(\"WANDB_KEY\")\n\nimport wandb\nwandb.login(key=secret_value_0)\nwandb.init(project='DogsVsCatsCNN', save_code=True)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-04T22:31:22.354501Z","iopub.execute_input":"2022-01-04T22:31:22.354896Z","iopub.status.idle":"2022-01-04T22:31:33.202013Z","shell.execute_reply.started":"2022-01-04T22:31:22.354793Z","shell.execute_reply":"2022-01-04T22:31:33.200898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Import everything needed","metadata":{}},{"cell_type":"code","source":"import zipfile\nimport glob\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import datasets, transforms\nnp.random.seed(0)\ntorch.manual_seed(0)\ntorch.cuda.manual_seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:31:46.04641Z","iopub.execute_input":"2022-01-04T22:31:46.046977Z","iopub.status.idle":"2022-01-04T22:31:49.14994Z","shell.execute_reply.started":"2022-01-04T22:31:46.046908Z","shell.execute_reply":"2022-01-04T22:31:49.148793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unzip datasets","metadata":{}},{"cell_type":"code","source":"train_dir = 'train'\ntest_dir = 'test'\nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/train.zip') as train_zip:\n    train_zip.extractall('')\n    \nwith zipfile.ZipFile('/kaggle/input/dogs-vs-cats-redux-kernels-edition/test.zip') as test_zip:\n    test_zip.extractall('')\ntrain_list = glob.glob(os.path.join(train_dir,'*.jpg'))\ntest_list = glob.glob(os.path.join(test_dir, '*.jpg'))\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:31:52.732398Z","iopub.execute_input":"2022-01-04T22:31:52.733424Z","iopub.status.idle":"2022-01-04T22:32:17.08462Z","shell.execute_reply.started":"2022-01-04T22:31:52.73336Z","shell.execute_reply":"2022-01-04T22:32:17.08367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [path.split('/')[-1].split('.')[0] for path in train_list]","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:32:17.086719Z","iopub.execute_input":"2022-01-04T22:32:17.087899Z","iopub.status.idle":"2022-01-04T22:32:17.924485Z","shell.execute_reply.started":"2022-01-04T22:32:17.087834Z","shell.execute_reply":"2022-01-04T22:32:17.92368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot random image with their label","metadata":{}},{"cell_type":"code","source":"random_idx = np.random.randint(1, len(train_list), size=9)\nfig, axes = plt.subplots(3, 3, figsize=(16, 12))\n\nfor idx, ax in enumerate(axes.ravel()):\n    img = Image.open(train_list[idx])\n    ax.set_title(labels[idx])\n    ax.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:32:17.928176Z","iopub.execute_input":"2022-01-04T22:32:17.931591Z","iopub.status.idle":"2022-01-04T22:32:20.844903Z","shell.execute_reply.started":"2022-01-04T22:32:17.931524Z","shell.execute_reply":"2022-01-04T22:32:20.843991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Use Sklearn to split data","metadata":{}},{"cell_type":"code","source":"train_list, valid_list = train_test_split(train_list, \n                                          test_size=0.2,\n                                          stratify=labels,\n                                          random_state=0)\nprint(f\"Train Data: {len(train_list)}\")\nprint(f\"Validation Data: {len(valid_list)}\")\nprint(f\"Test Data: {len(test_list)}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:32:20.846725Z","iopub.execute_input":"2022-01-04T22:32:20.847002Z","iopub.status.idle":"2022-01-04T22:32:21.667354Z","shell.execute_reply.started":"2022-01-04T22:32:20.84697Z","shell.execute_reply":"2022-01-04T22:32:21.66648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will discuss this in more detail in a near future...","metadata":{}},{"cell_type":"code","source":"train_transforms = transforms.Compose([\n        transforms.Resize(128), # makes it easier for the GPU\n        transforms.RandomResizedCrop(112),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor()])\n\nval_transforms = transforms.Compose([\n        transforms.Resize(128),\n        transforms.CenterCrop(112),\n        transforms.ToTensor()])\n\n\ntest_transforms = transforms.Compose([\n        transforms.Resize(128),\n        transforms.CenterCrop(112),\n        transforms.ToTensor()])","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:32:21.668632Z","iopub.execute_input":"2022-01-04T22:32:21.669226Z","iopub.status.idle":"2022-01-04T22:32:22.394843Z","shell.execute_reply.started":"2022-01-04T22:32:21.669185Z","shell.execute_reply":"2022-01-04T22:32:22.393892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Define the dataset using PIL to read image","metadata":{}},{"cell_type":"code","source":"class CatsDogsDataset(Dataset):\n    def __init__(self, file_list, transform=None):\n        self.file_list = file_list\n        self.transform = transform\n        self.filelength = len(file_list)\n\n    def __len__(self):\n        return self.filelength\n\n    def __getitem__(self, idx):\n        img_path = self.file_list[idx]\n        img = Image.open(img_path)\n        img_transformed = self.transform(img)\n        label = img_path.split(\"/\")[-1].split(\".\")[0]\n        label = 1 if label == \"dog\" else 0\n        return img_transformed, label","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:32:22.396192Z","iopub.execute_input":"2022-01-04T22:32:22.396443Z","iopub.status.idle":"2022-01-04T22:32:23.161312Z","shell.execute_reply.started":"2022-01-04T22:32:22.396412Z","shell.execute_reply":"2022-01-04T22:32:23.16052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = CatsDogsDataset(train_list, transform=train_transforms)\nvalid_data = CatsDogsDataset(valid_list, transform=test_transforms)\ntest_data = CatsDogsDataset(test_list, transform=test_transforms)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:32:23.434128Z","iopub.execute_input":"2022-01-04T22:32:23.434503Z","iopub.status.idle":"2022-01-04T22:32:24.776818Z","shell.execute_reply.started":"2022-01-04T22:32:23.434464Z","shell.execute_reply":"2022-01-04T22:32:24.775958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create dataloader, you can modify the batch size if needed","metadata":{}},{"cell_type":"code","source":"batch_size = 32\ntrain_loader = DataLoader(dataset=train_data, batch_size=batch_size, shuffle=True)\nvalid_loader = DataLoader(dataset=valid_data, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:32:25.75207Z","iopub.execute_input":"2022-01-04T22:32:25.752496Z","iopub.status.idle":"2022-01-04T22:32:26.563752Z","shell.execute_reply.started":"2022-01-04T22:32:25.752452Z","shell.execute_reply":"2022-01-04T22:32:26.561373Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_weights(m):\n    if isinstance(m, nn.Linear):\n        torch.nn.init.xavier_normal_(m.weight, nn.init.calculate_gain('relu'))\n        torch.nn.init.constant_(m.bias, 0)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:37:50.277744Z","iopub.execute_input":"2022-01-04T22:37:50.279423Z","iopub.status.idle":"2022-01-04T22:37:50.982699Z","shell.execute_reply.started":"2022-01-04T22:37:50.279342Z","shell.execute_reply":"2022-01-04T22:37:50.981463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# AlexNet\n\nIn 2012, Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton proposed a CNN architecture and implemented it on Cuda GPUs to compete in the ImageNet competition.","metadata":{}},{"cell_type":"code","source":"\nclass AlexNet(nn.Module):\n    \n    def __init__(self):\n        super(AlexNet, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels= 96, kernel_size= 11, stride=4)\n        self.maxpool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.conv2 = nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride= 1, padding= 2)\n        self.maxpool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.conv3 = nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride= 1, padding= 1)\n        self.conv4 = nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1)\n        self.conv5 = nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1)\n        self.maxpool3 = nn.MaxPool2d(kernel_size=3, stride=2)\n        self.fc1  = nn.Linear(in_features= 1024, out_features= 4096)\n        self.fc2  = nn.Linear(in_features= 4096, out_features= 4096)\n        self.fc3 = nn.Linear(in_features=4096 , out_features=1)\n    \n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.maxpool1(x)\n        x = F.relu(self.conv2(x))\n        x = self.maxpool2(x)\n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv5(x))\n        x = self.maxpool3(x)\n        x = x.reshape(x.shape[0], -1)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc3(x)\n        return F.sigmoid(x)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:57:48.012711Z","iopub.execute_input":"2022-01-04T22:57:48.013146Z","iopub.status.idle":"2022-01-04T22:57:48.89169Z","shell.execute_reply.started":"2022-01-04T22:57:48.013103Z","shell.execute_reply":"2022-01-04T22:57:48.89045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nmodel = AlexNet()\nmodel.apply(init_weights)\n\nnum_epochs = 100\nlr =  0.01\nweight_decay = 1e-4\n\noptimizer = torch.optim.SGD(model.parameters(),lr = lr)#torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay) #AdamW to aviod coupling problem between the L2 regularization and the adaptive learning rate\ncriterion = torch.nn.BCELoss()\n\n#logging configuration and model\nwandb.config.learningrate = lr\nwandb.config.num_iterations = num_epochs\nwandb.config.optimizer = \"SGD\"\nwandb.config.criterion = \"BCELoss\"\n\nwandb.watch(model, log=\"all\", criterion=criterion, log_freq=1,  log_graph=(True)) #log frequency depend on your training\n\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") #0, first GPU if multiple one\nprint(device)\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:57:53.672083Z","iopub.execute_input":"2022-01-04T22:57:53.672415Z","iopub.status.idle":"2022-01-04T22:57:54.931906Z","shell.execute_reply.started":"2022-01-04T22:57:53.672385Z","shell.execute_reply":"2022-01-04T22:57:54.930883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    \n    #TRAINING LOOP\n    training_loss = 0\n    correct_classified = 0\n    model.train()\n    for train_features, train_labels in train_loader:\n        optimizer.zero_grad() # please don't forget!\n        \n        out = model(train_features)\n        l = criterion(out, train_labels.unsqueeze(1).type(torch.FloatTensor))\n        \n        l.backward() # compute gradient\n        optimizer.step() # do a step in the gradient direction\n        \n        training_loss += l.item()\n        #Sum correct classified...\n        _, predicted = torch.max(out.data, 1)\n        correct_classified += int(predicted.eq(train_labels.unsqueeze(1)).sum().item())\n        \n    train_acc = correct_classified / training_size\n    \n    #VALIDATION LOOP\n    validation_loss = 0\n    correct_classified = 0\n    model.eval()\n    with torch.no_grad():\n        for val_features, val_labels in valid_loader:\n            out = model(val_features)\n            l = criterion(out, val_labels.unsqueeze(1))\n            \n            validation_loss += l.item()\n            #Sum correct classified...\n            predicted = torch.ge(out, 0.5)\n            correct_classified += int(predicted.eq(val_labels.unsqueeze(1)).sum().item())\n            \n    val_acc = correct_classified / validation_size         \n    wandb.log({'training_loss': training_loss, 'validation_loss': validation_loss, 'validation_accuracy': val_acc, 'training_accuracy': train_acc})\n    \n    \n# SAVE THE MODEL\ntorch.save(model.state_dict(), 'my_model_' + wandb.run.name + '_' + wandb.run.id +'.pt')\nprint(\"finished...\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T22:57:58.901481Z","iopub.execute_input":"2022-01-04T22:57:58.901804Z","iopub.status.idle":"2022-01-04T22:58:56.90572Z","shell.execute_reply.started":"2022-01-04T22:57:58.901771Z","shell.execute_reply":"2022-01-04T22:58:56.903842Z"},"trusted":true},"execution_count":null,"outputs":[]}]}