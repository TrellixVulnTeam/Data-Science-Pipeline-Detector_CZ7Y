{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":1,"outputs":[{"output_type":"stream","text":"['test', 'sample_submission.csv', 'train']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Dense, Flatten, Dropout, Lambda, Input, Concatenate, concatenate\nfrom keras.models import Model\nfrom keras.applications import *\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import regularizers","execution_count":2,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames = os.listdir(\"../input/train/train\")\nlabels = []\nfor file in filenames:\n    category = file.split('.')[0]\n    if category == 'cat':\n        labels.append('cat')\n    else:\n        labels.append('dog')","execution_count":3,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df = pd.DataFrame({\n    'filename': filenames,\n    'label': labels\n})\ntrain_df, validation_df = train_test_split(df, test_size=0.1, random_state = 42)\ntrain_df = train_df.reset_index(drop=True)\nvalidation_df = validation_df.reset_index(drop=True)\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\ntrain_num = len(train_df)\nvalidation_num = len(validation_df)","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def two_image_generator(generator, df, directory, batch_size,\n                        x_col = 'filename', y_col = None, model = None, shuffle = False,\n                        img_size1 = (224, 224), img_size2 = (299,299)):\n    gen1 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size1,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    gen2 = generator.flow_from_dataframe(\n        df,\n        directory,\n        x_col = x_col,\n        y_col = y_col,\n        target_size = img_size2,\n        class_mode = model,\n        batch_size = batch_size,\n        shuffle = shuffle,\n        seed = 1)\n    \n    while True:\n        X1i = gen1.next()\n        X2i = gen2.next()\n        if y_col:\n            yield [X1i[0], X2i[0]], X1i[1]  #X1i[1] is the label\n        else:\n            yield [X1i, X2i]\n        ","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n#test if the generator generates same images with two different sizes\n\nex_df = pd.DataFrame()\nex_df['filename'] = filenames[:5]\nex_df['label'] = labels[:5]\nex_df.head()\n\ntrain_aug_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True\n)\ne1 = two_image_generator(train_aug_datagen, ex_df, '../input/train/train/',\n                                      batch_size = 2, y_col = 'label',\n                                      model = 'binary', shuffle = True)\n\nfig = plt.figure(figsize = (10,10))\nbatches = 0\nrows = 4\ncols = 5\ni = 0\nj = 0\nindices_a = [1, 2, 3, 4, 5, 11, 12, 13, 14, 15]\nindices_b = [6, 7, 8, 9, 10, 16, 17, 18, 19, 20]\nfor [x_batch, x_batch2], y_batch in e1:\n    for image in x_batch:\n        fig.add_subplot(rows, cols, indices_a[i])\n        i += 1\n        plt.imshow(image.astype('uint8'))\n        \n    for image in x_batch2:\n        fig.add_subplot(rows, cols, indices_b[j])\n        j += 1\n        plt.imshow(image.astype('uint8'))\n    \n    batches += 1\n    if batches >= 6:\n        break\nplt.show()\n\n\"\"\"","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"\"\\n#test if the generator generates same images with two different sizes\\n\\nex_df = pd.DataFrame()\\nex_df['filename'] = filenames[:5]\\nex_df['label'] = labels[:5]\\nex_df.head()\\n\\ntrain_aug_datagen = ImageDataGenerator(\\n    rotation_range = 20,\\n    shear_range = 0.1,\\n    zoom_range = 0.2,\\n    width_shift_range = 0.1,\\n    height_shift_range = 0.1,\\n    horizontal_flip = True\\n)\\ne1 = two_image_generator(train_aug_datagen, ex_df, '../input/train/train/',\\n                                      batch_size = 2, y_col = 'label',\\n                                      model = 'binary', shuffle = True)\\n\\nfig = plt.figure(figsize = (10,10))\\nbatches = 0\\nrows = 4\\ncols = 5\\ni = 0\\nj = 0\\nindices_a = [1, 2, 3, 4, 5, 11, 12, 13, 14, 15]\\nindices_b = [6, 7, 8, 9, 10, 16, 17, 18, 19, 20]\\nfor [x_batch, x_batch2], y_batch in e1:\\n    for image in x_batch:\\n        fig.add_subplot(rows, cols, indices_a[i])\\n        i += 1\\n        plt.imshow(image.astype('uint8'))\\n        \\n    for image in x_batch2:\\n        fig.add_subplot(rows, cols, indices_b[j])\\n        j += 1\\n        plt.imshow(image.astype('uint8'))\\n    \\n    batches += 1\\n    if batches >= 6:\\n        break\\nplt.show()\\n\\n\""},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#add data_augmentation\ntrain_aug_datagen = ImageDataGenerator(\n    rotation_range = 20,\n    shear_range = 0.1,\n    zoom_range = 0.2,\n    width_shift_range = 0.1,\n    height_shift_range = 0.1,\n    horizontal_flip = True\n)\ntrain_generator = two_image_generator(train_aug_datagen, train_df, '../input/train/train/',\n                                      batch_size = batch_size, y_col = 'label',\n                                      model = 'binary', shuffle = True)","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_datagen = ImageDataGenerator()\n\nvalidation_generator = two_image_generator(validation_datagen, validation_df,\n                                           '../input/train/train/', batch_size = batch_size,\n                                           y_col = 'label',model = 'binary', shuffle = True)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_base_model(MODEL, img_size, lambda_fun = None):\n    inp = Input(shape = (img_size[0], img_size[1], 3))\n    x = inp\n    if lambda_fun:\n        x = Lambda(lambda_fun)(x)\n    \n    base_model = MODEL(input_tensor = x, weights = 'imagenet', include_top = False, pooling = 'avg')\n        \n    model = Model(inp, base_model.output)\n    return model","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#define vgg + resnet50 + densenet\nmodel1 = create_base_model(vgg16.VGG16, (224, 224), vgg16.preprocess_input)\nmodel2 = create_base_model(resnet50.ResNet50, (224, 224), resnet50.preprocess_input)\nmodel3 = create_base_model(inception_v3.InceptionV3, (299, 299), inception_v3.preprocess_input)\nmodel1.trainable = False\nmodel2.trainable = False\nmodel3.trainable = False\n\ninpA = Input(shape = (224, 224, 3))\ninpB = Input(shape = (299, 299, 3))\nout1 = model1(inpA)\nout2 = model2(inpA)\nout3 = model3(inpB)\n\nx = Concatenate()([out1, out2, out3])                \nx = Dropout(0.6)(x)\nx = Dense(1, activation='sigmoid')(x)\nmultiple_pretained_model = Model([inpA, inpB], x)\n\nmultiple_pretained_model.compile(loss = 'binary_crossentropy',\n                          optimizer = 'rmsprop',\n                          metrics = ['accuracy'])\n\nmultiple_pretained_model.summary()","execution_count":11,"outputs":[{"output_type":"stream","text":"WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n58892288/58889256 [==============================] - 2s 0us/step\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.2/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n94658560/94653016 [==============================] - 3s 0us/step\nDownloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n87916544/87910968 [==============================] - 2s 0us/step\nWARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_4 (InputLayer)            (None, 224, 224, 3)  0                                            \n__________________________________________________________________________________________________\ninput_5 (InputLayer)            (None, 299, 299, 3)  0                                            \n__________________________________________________________________________________________________\nmodel_1 (Model)                 (None, 512)          14714688    input_4[0][0]                    \n__________________________________________________________________________________________________\nmodel_2 (Model)                 (None, 2048)         23587712    input_4[0][0]                    \n__________________________________________________________________________________________________\nmodel_3 (Model)                 (None, 2048)         21802784    input_5[0][0]                    \n__________________________________________________________________________________________________\nconcatenate_3 (Concatenate)     (None, 4608)         0           model_1[1][0]                    \n                                                                 model_2[1][0]                    \n                                                                 model_3[1][0]                    \n__________________________________________________________________________________________________\ndropout_1 (Dropout)             (None, 4608)         0           concatenate_3[0][0]              \n__________________________________________________________________________________________________\ndense_1 (Dense)                 (None, 1)            4609        dropout_1[0][0]                  \n==================================================================================================\nTotal params: 60,109,793\nTrainable params: 4,609\nNon-trainable params: 60,105,184\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpointer = ModelCheckpoint(filepath='dogcat.weights.best.hdf5', verbose=1, \n                               save_best_only=True, save_weights_only=True)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multiple_pretained_model.fit_generator(\n    train_generator,\n    epochs = 5,\n    steps_per_epoch = train_num // batch_size,\n    validation_data = validation_generator,\n    validation_steps = validation_num // batch_size,\n    verbose = 1,\n    callbacks = [checkpointer]\n)","execution_count":27,"outputs":[{"output_type":"stream","text":"Epoch 1/5\nFound 2500 images belonging to 2 classes.\nFound 2500 images belonging to 2 classes.\nFound 22500 images belonging to 2 classes.\nFound 22500 images belonging to 2 classes.\n  2/351 [..............................] - ETA: 31:10 - loss: 0.0476 - acc: 0.9922","name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-27-749a3bc6bbd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_num\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mverbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcallbacks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcheckpointer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m )\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"multiple_pretained_model.load_weights('dogcat.weights.best.hdf5')","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filenames = os.listdir(\"../input/test/test\")\ntest_df = pd.DataFrame({\n    'filename': test_filenames\n})\nnum_test = len(test_df)\n\ntest_datagen = ImageDataGenerator()\n\ntest_generator = two_image_generator(test_datagen, test_df, '../input/test/test/', batch_size = batch_size)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = multiple_pretained_model.predict_generator(test_generator, \n                                         steps=np.ceil(num_test/batch_size))\nprediction = prediction.clip(min = 0.005, max = 0.995)","execution_count":20,"outputs":[{"output_type":"stream","text":"Found 12500 images.\nFound 12500 images.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/sample_submission.csv')\nfor i, fname in enumerate(test_filenames):\n    index = int(fname[fname.rfind('/')+1:fname.rfind('.')])\n    submission_df.at[index-1, 'label'] = prediction[i]\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"   id  label\n0   1  0.995\n1   2  0.995\n2   3  0.995\n3   4  0.995\n4   5  0.005","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0.995</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0.995</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0.995</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0.995</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0.005</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}