{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n#import imutils\n#from imutils import paths\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.image import extract_patches_2d\nimport progressbar\nimport tqdm\nfrom tqdm import tqdm_notebook\nimport json\nimport csv\nimport cv2\nimport h5py\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input/Dogs_vs_Cats_Alexnet_Trained_Model'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Part of imutils library. Cannot insert custom library for GPU, so adding code for function\nimport os\n\nimage_types = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n\n\ndef list_images(basePath, contains=None):\n    # return the set of files that are valid\n    return list_files(basePath, validExts=image_types, contains=contains)\n\n\ndef list_files(basePath, validExts=None, contains=None):\n    # loop over the directory structure\n    for (rootDir, dirNames, filenames) in os.walk(basePath):\n        # loop over the filenames in the current directory\n        for filename in filenames:\n            # if the contains string is not none and the filename does not contain\n            # the supplied string, then ignore the file\n            if contains is not None and filename.find(contains) == -1:\n                continue\n\n            # determine the file extension of the current file\n            ext = filename[filename.rfind(\".\"):].lower()\n\n            # check to see if the file is an image and should be processed\n            if validExts is None or ext.endswith(validExts):\n                # construct the path to the image and yield it\n                imagePath = os.path.join(rootDir, filename)\n                yield imagePath\n\ndef resize(image, width=None, height=None, inter=cv2.INTER_AREA):\n    # initialize the dimensions of the image to be resized and\n    # grab the image size\n    dim = None\n    (h, w) = image.shape[:2]\n\n    # if both the width and height are None, then return the\n    # original image\n    if width is None and height is None:\n        return image\n\n    # check to see if the width is None\n    if width is None:\n        # calculate the ratio of the height and construct the\n        # dimensions\n        r = height / float(h)\n        dim = (int(w * r), height)\n\n    # otherwise, the height is None\n    else:\n        # calculate the ratio of the width and construct the\n        # dimensions\n        r = width / float(w)\n        dim = (width, int(h * r))\n\n    # resize the image\n    resized = cv2.resize(image, dim, interpolation=inter)\n\n    # return the resized image\n    return resized","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#/input/dogs-vs-cats-redux-kernels-edition/test/test/\n#/input/dogs-vs-cats-redux-kernels-edition/train/train/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/dogs-vs-cats-redux-kernels-edition/train/train/'\nfinal_test_path = '../input/dogs-vs-cats-redux-kernels-edition/test/test/'\n#train_img=[train_path+'/'+i for i in os.listdir(train_path)]\ntrain_img_paths = list(list_images(train_path))\nfinal_test_img_paths = list(list_images(final_test_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_img_paths), len(final_test_img_paths)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# os.listdir(train_path),","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_CLASSES=2\nNUM_VAL_IMAGES = 1250*NUM_CLASSES\nNUM_TEST_IMAGES = 1250*NUM_CLASSES\n\ntrain_hdf5 = '/kaggle/working/train.hdf5'\nval_hdf5 = '/kaggle/working/val.hdf5'\ntest_hdf5 = '/kaggle/working/test.hdf5'\nMODEL_PATH = '/kaggle/working/alexnet_dogs_vs_cats.model'\ndataset_mean = '/kaggle/working/dogs_vs_cats_mean.json'\noutput_path = '/kaggle/working/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\n\nclass SimplePreprocessor:\n    def __init__(self, width, height, inter = cv2.INTER_AREA):\n        # store the target image width, height, and interpolation\n        # method used when resizing \n        self.width = width\n        self.height = height\n        self.inter = inter\n    def preprocess(self, image):\n         # resize the image to a fixed size, ignoring the aspect ratio\n        return cv2.resize(image,(self.width, self.height), interpolation = self.inter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AspectAwarePreprocessor:\n    \n    def __init__(self, width, height, inter = cv2.INTER_AREA):\n        self.width = width \n        self.height= height\n        self.inter = inter \n        \n    def preprocess(self, image):\n        (h,w) = image.shape[:2]\n        dH, dW = 0, 0\n        \n        if w < h:\n            image = resize(image, width = self.width, inter = self.inter)\n            dH = (image.shape[0] - self.height)//2\n            \n        else:\n            image = resize(image, height = self.height, inter = self.inter)\n            dW = (image.shape[1] - self.width)//2      \n            \n        (h,w) = image.shape[:2]\n        #print('new',image.shape)\n        image = image[dH:h-dH, dW:w-dW]\n        \n        return cv2.resize(image, (self.width, self.height), interpolation = self.inter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class HDF5DatasetWriter:\n    def __init__(self, dims, outputPath, dataKey = 'images', bufSize=1000):\n        if os.path.exists(outputPath):\n            raise ValueError('The supplied \"outputPath\" already exists. Manually delete the file before continuing.',outputPath)\n            \n        self.db = h5py.File(outputPath, mode='w')\n        self.data = self.db.create_dataset(dataKey, dims, dtype='float')\n        self.labels = self.db.create_dataset('labels', (dims[0],), dtype='int')\n        \n        self.bufSize = bufSize\n        self.buffer = {'data':[], 'labels':[]}\n        self.idx = 0\n        \n    def add(self, rows, labels):\n        self.buffer['data'].extend(rows)\n        self.buffer['labels'].extend(labels)\n        \n        if len(self.buffer['data']) >= self.bufSize:\n            self.flush()\n    \n    def flush(self):\n        i = self.idx + len(self.buffer['data'])\n        self.data[self.idx:i] = self.buffer['data']\n        self.labels[self.idx:i] = self.buffer['labels']\n        self.idx = i\n        \n        self.buffer = {'data':[], 'labels':[]}\n        \n    def storeClassLabels(self, classLabels):\n        \n        dt = h5py.special_dtype(vlen=str)\n        labelSet = self.db.create_dataset('label_name', (len(classLabels),), dtype = dt)\n        labelSet[:] = classLabels\n        \n    def close(self):\n        if len(self.buffer['data']) > 0:\n            self.flush()\n        \n        self.db.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainLabels = []\ncount_rej = 0\nfor p in train_img_paths:\n    if p.split(os.path.sep)[-1].split('.')[-1] == 'jpg':\n        trainLabels.append(p.split(os.path.sep)[-1].split('.')[0])\n    else:\n        count_rej +=1\nprint(len(trainLabels),'\\n', np.unique(trainLabels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"le = LabelEncoder()\ntrainLabels = le.fit_transform(trainLabels)\nprint(len(trainLabels),'\\n', np.unique(trainLabels))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(trainLabels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_paths, test_img_paths, y_train, y_test = train_test_split(train_img_paths, trainLabels,\n                                                                    test_size = NUM_TEST_IMAGES, random_state=42,\n                                                                    stratify=trainLabels\n                                                                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_paths, val_img_paths, y_train, y_val = train_test_split(train_img_paths, y_train,\n                                                                    test_size = NUM_VAL_IMAGES, random_state=42,\n                                                                    stratify=y_train\n                                                                   )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset, val_dataset, test_dataset=[], [], []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = [('train',train_img_paths, y_train, train_dataset)]\n#             ('val',val_img_paths, y_train, val_hdf5),\n#             ('test',test_img_paths, y_train, test_hdf5)\n#            ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aap = AspectAwarePreprocessor(227, 227)\n#R, G, B = [], [], []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"R, G, B = [], [], []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/working/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for dtype, paths, labels, outputPath in datasets:\n    print(dtype)\n#     writer = HDF5DatasetWriter((len(paths),256,256,3),outputPath)\n    for i,(path,label) in tqdm.tqdm(enumerate(zip(paths, labels))):\n        image = cv2.imread(path)\n        image = aap.preprocess(image)\n        \n        if dtype == 'train':\n            (b,g,r) = cv2.mean(image)[:3]\n            R.append(r)\n            G.append(g)\n            B.append(b)\n#             writer.add([image],[label])\n#    writer.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"B_mean = np.mean(B)\nG_mean = np.mean(G)\nR_mean = np.mean(R)\nB_mean, G_mean, R_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MeanPreprocessor:\n    def __init__(self, rMean, gMean, bMean):\n        self.rMean = rMean\n        self.gMean = gMean\n        self.bMean = bMean\n    \n    def preprocess(self, image):\n        (B, G, R) = cv2.split(image.astype('float32'))\n        R -= self.rMean\n        G -= self.gMean\n        B -= self.bMean\n        return cv2.merge([B,G,R])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PatchPreprocessor:\n    def __init__(self, width, height):\n        self.width = width\n        self.height = height\n    \n    def preprocess(self, image):\n        (h,w) = image.shape[:2]\n        if h <= self.height:\n            image = aap.preprocess(image)\n        elif w <= self.width:\n            image = aap.preprocess(image)\n        else:\n            image = image\n        return extract_patches_2d(image, (self.height, self.width), max_patches=1)[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CropPreprocessor:\n    def __init__(self, height, width, horiz=True, inter = cv2.INTER_AREA):\n        self.width = width\n        self.height = height\n        self.horiz = horiz\n        self.inter = inter\n    def preprocess(self,image):\n        crops = []\n        (h,w) = image.shape[:2]\n        coords = [[0,0, self.width, self.height],\n                  [w-self.width, 0, w,self.height],\n                  [w-self.width, h-self.height, w,h],\n                  [0, h-self.height, self.width, h]\n                 ]\n        dW = int(0.5*(w-self.width))\n        dH = int(0.5*(h-self.height))\n        coords.append([dW, dH, w-dW, h-dH])\n        \n        for (startX, startY, endX, endY) in coords:\n            #print(image.shape)\n            crop = image[startY:endY, startX:endX]\n            crop = cv2.resize(crop, (self.width, self.height), interpolation = self.inter)\n            crops.append(crop)\n        if self.horiz:\n            mirrors = [cv2.flip(c,1) for c in crops]\n            crops.extend(mirrors)\n        return np.array(crops)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils import np_utils\nimport numpy as np\nimport cv2\n\nclass HDF5DatasetGenerator:\n    def __init__(self, dbPath, batchSize, preprocessors=None, aug=None, binarize=True, classes=2):\n        self.dbPath =dbPath\n        self.batchSize =batchSize\n        self.preprocessors =preprocessors\n        self.aug =aug\n        self.binarize =binarize\n        self.classes =classes\n        \n        self.db = h5py.File(dbPath)\n        self.numImages = self.db['labels'].shape[0]\n        \n    def generator(passes = np.inf):\n        epochs=0\n        if epochs < passes:\n            for i in np.arange(0, self.numImages, self.batchSize):\n                images = self.db['images'][i:i+self.batchSize]\n                labels = se;f.db['labels'][i:i+self.batchSize]\n                if self.binarize:\n                    labels = np_utils.to_categorical(labels, self.classes)\n                \n                if self.preprocessors is not None:\n                    procImages=[]\n                    \n                    for image in images:\n                        for p in self.preprocessors:\n                            image = p.preprocess(image)\n                            procImages.append(image)\n                            \n                    images = np.array(procImages)\n                \n                if self.aug is not None:\n                    (images,labels) = next(self.aug.flow(images, labels, batch_size = self.batchSize))\n                    yield (images, labels)\n                    \n        epochs +=1\n    \n    def close(self):\n        sef.db.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import BatchNormalization, Conv2D, MaxPooling2D, Activation, Flatten, Dropout, Dense\nfrom keras.regularizers import l2\nfrom keras import backend as K\n\nclass Alexnet:\n    def build (width, height, depth, classes, reg = 0.0002):\n        model = Sequential()\n        inputShape = (height, width, depth)\n        chanDim = -1\n        \n        if K.image_data_format() == 'channels_first':\n            inputShape = (depth, height, width)\n            chanDim = 1\n        \n        model.add(Conv2D(96, (11,11), strides=(4,4), input_shape = inputShape, padding='same', kernel_regularizer=l2(reg)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(256, (5,5), strides=(1,1), padding='same', kernel_regularizer=l2(reg)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n        model.add(Dropout(0.25))\n        \n        model.add(Conv2D(384, (3,3), strides=(1,1), padding='same', kernel_regularizer=l2(reg)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(384, (3,3), strides=(1,1), padding='same', kernel_regularizer=l2(reg)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=chanDim))\n        model.add(Conv2D(256, (3,3), strides=(1,1), padding='same', kernel_regularizer=l2(reg)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization(axis=chanDim))\n        \n        model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2)))\n        model.add(Dropout(0.25))\n        \n        model.add(Flatten())\n        model.add(Dense(4096, kernel_regularizer=l2(reg)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n        model.add(Dense(4096, kernel_regularizer=l2(reg)))\n        model.add(Activation('relu'))\n        model.add(BatchNormalization())\n        model.add(Dropout(0.5))\n        \n        model.add(Dense(classes, activation='softmax', kernel_regularizer=l2(reg)))\n        \n        return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import img_to_array\n\nclass imageToArrayPreprocessor:\n    def __init__(self, dataFormat=None):\n        self.dataFormat = dataFormat\n    \n    def preprocess(self, image):\n        return img_to_array(image, data_format = self.dataFormat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\naug = ImageDataGenerator(rotation_range = 20, zoom_range=0.15, shear_range=0.15,\n                         width_shift_range = 0.2, height_shift_range=0.2,\n                         horizontal_flip=True, fill_mode='nearest'\n                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sp = SimplePreprocessor(227, 227)\npp = PatchPreprocessor(227, 227)\nmp = MeanPreprocessor(R_mean, G_mean, B_mean)\niap = imageToArrayPreprocessor()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def image_data_generator(directory_list, labels, bs = 128, mode='train', aug=None):\n#     i=0\n#     #imagePaths\n#     while True:\n#         image_batch=[]\n#         label_batch=[]\n#         #labels=[]\n#         for j in range(bs):\n#             if i == len(directory_list):\n#                 i=0\n#             if mode=='train':\n#                 imagePath = directory_list[i]\n#             #print(imagePath)\n#                 image = cv2.imread(imagePath)\n            \n#                 image = pp.preprocess(image)\n#                 image = mp.preprocess(image)\n#                 image = iap.preprocess(image)\n#                 label = labels[i]\n#                 image_batch.append(image)\n#                 label_batch.append(label)\n            \n#                 i+=1\n#             else:\n#                 imagePath = directory_list[i]\n#             #print(imagePath)\n#                 image = cv2.imread(imagePath)\n            \n#                 image = sp.preprocess(image)\n#                 image = mp.preprocess(image)\n#                 image = iap.preprocess(image)\n#                 label = labels[i]\n#                 image_batch.append(image)\n#                 label_batch.append(label)\n            \n#                 i+=1\n#         if aug is not None:\n#             (image_batch,label_batch) = next(aug.flow(np.array(image_batch),label_batch, batch_size=bs))\n        \n#         yield (np.array(image_batch),label_batch)\n            \n            \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def image_data_generator(directory_list, labels, bs = 5, mode='train', preprocessors=None, aug=None,classes=2):\n#     i=0\n#     #imagePaths\n#     while True:\n#         image_batch=[]\n#         label_batch=[]\n#         #labels=[]\n#         for j in range(bs):\n#             if i == len(directory_list):\n#                 i=0\n#             #if mode=='train':\n#             imagePath = directory_list[i]\n#             #print(imagePath)\n#             image = cv2.imread(imagePath)\n#             label = labels[i]\n#             if preprocessors is not None:\n#                 procImages=[]\n#                 labelImages=[]\n#                 for p in preprocessors:\n#                     image = p.preprocess(image)\n#                     procImages.append(image)\n#                     labelImages.append(label)\n#                 image=np.array(procImages)\n#                 label=np.array(labelImages)\n# #           image = pp.preprocess(image)\n# #           image = mp.preprocess(image)\n# #           image = iap.preprocess(image)\n#             #label = labels[i]\n#             #label_cat= np_utils.to_categorical(label,classes)\n            \n#             i+=1\n#             print(np.array(image).shape, label)#, label_cat)\n#             if aug is not None:\n#                 (image, label) = next(aug.flow(np.array(image),label, batch_size=bs))\n#             image_batch.append(image)\n#             label_batch.append(label)\n#         print('bat',np.array(image_batch).shape, label_batch) \n#         return (np.array(image_batch),label_batch)\n            \n            \n# #            print(image.shape)\n# #             image_batch.append(image)\n# #             label_batch.append(label_cat)\n# #             print('bat',np.array(image_batch).shape, label_batch) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_data_generator(directory_list, labels, bs = 128, mode='train', binarize=True,preprocessors=None, aug=None,classes=2):\n    while True:\n        for i in range(0, labels.shape[0], bs):\n            images=[]\n            imagePaths = directory_list[i:i+bs]\n            label_vals = labels[i:i+bs]\n#            print(label_vals)\n            if binarize:\n                label_vals = np_utils.to_categorical(label_vals, classes)\n#                print(label_vals.shape)\n            if preprocessors is not None:\n                procImages=[]\n#                 labelImages=[]     \n                for path in imagePaths:\n                    image = cv2.imread(path)\n                    #print(image.shape, path)\n                    for p in preprocessors:\n                        image = p.preprocess(image)\n                    procImages.append(image)\n#                        labelImages.append(label_vals[x])      \n                images = np.array(procImages)\n#                label_vals = np.array(labelImages)\n        # print(images.shape, label_vals.shape)\n            if aug is not None:\n                (images,label_vals) = next(aug.flow(images, label_vals, batch_size = bs))\n           \n            yield (images, label_vals)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[:8].shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_paths[:4], y_train[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_image_batch,train_label_batch = image_data_generator(train_img_paths[:8], y_train[:8], preprocessors=[pp,mp,iap],aug=aug)\n# train_image_batch.shape, len(train_image_batch), train_label_batch\nyield_chk=image_data_generator(train_img_paths[:8], y_train[:8], preprocessors=[pp,mp,iap],aug=aug)\nyield_chk#.Generator()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom keras.models import load_model\nmodel = load_model('/kaggle/input/dogs-vs-cats-alexnet-trained-model/alexnet_dogs_vs_cats_model_same_padd.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from keras.optimizers import Adam\n# opt = Adam(lr=1e-3)\n# model = Alexnet.build(width=227, height=227, classes=2, depth=3, reg=0.0002)\n# model.compile(loss='binary_crossentropy', optimizer = opt, metrics=['accuracy'])\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.load_weights('/kaggle/input/dogs-vs-cats-alexnet-trained-model/alexnet_dogs_vs_cats_model_same_padd.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = image_data_generator(train_img_paths, y_train, bs=64,preprocessors=[pp,mp,iap],aug=aug)\nval_gen = image_data_generator(val_img_paths, y_val, bs=64,preprocessors=[sp,mp,iap])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# history = model.fit_generator(train_gen, steps_per_epoch=y_train.shape[0]//64, validation_data=val_gen,\n#                     validation_steps=y_val.shape[0]//64, epochs=25, max_queue_size=64*2, verbose=1\n#                    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.save('alexnet_dogs_vs_cats_model_same_padd.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from IPython.display import FileLink\n# FileLink('alexnet_dogs_vs_cats_model_same_padd.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img_try=cv2.imread('../input/dogs-vs-cats-redux-kernels-edition/train/dog.897.jpg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print([p.split(os.path.sep)[-1][:3] for p in train_img_paths])\n#y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_img_paths),y_test.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_data_generator(directory_list, bs=128, mode='test', binarize=False,preprocessors=None, aug=None,classes=2, passes=np.inf):\n    epochs=0\n    if epochs<passes:\n        for i in range(0, len(directory_list), bs):\n            images=[]\n            imagePaths = directory_list[i:i+bs]\n#            label_vals = labels[i:i+bs]\n#            print(label_vals)\n            if binarize:\n                label_vals = np_utils.to_categorical(label_vals, classes)\n#                print(label_vals.shape)\n            if preprocessors is not None:\n                procImages=[]\n#                 labelImages=[]     \n                for path in imagePaths:\n                    image = cv2.imread(path)\n                    #print(image.shape, path)\n                    for p in preprocessors:\n                        image = p.preprocess(image)\n                    procImages.append(image)\n#                        labelImages.append(label_vals[x])      \n                images = np.array(procImages)\n#                label_vals = np.array(labelImages)\n        # print(images.shape, label_vals.shape)\n            if aug is not None:\n                (images,label_vals) = next(aug.flow(images, label_vals, batch_size = bs))\n           \n            yield images\n        epochs+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testgen = test_data_generator(test_img_paths, bs=64,preprocessors=[sp,mp,iap])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testgen, y_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict_generator(testgen, steps = y_test.shape[0]//64, max_queue_size = 64*2, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rank5_accuracy(preds, labels):\n    rank1=0\n    rank5=0\n    \n    for pred,label in zip(preds, labels):\n        pred  = np.argsort(pred)[::-1]\n        \n        if label in pred[:5]:\n            rank5 += 1\n        \n        if label == pred[0]:\n            rank1 += 1\n    \n    rank5 /= float(len(labels))\n    rank1 /= float(len(labels))\n    \n    return (rank1, rank5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(rank1, _) = rank5_accuracy(predictions, y_test)\nrank1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfinal_predict=[]\ncp = CropPreprocessor(227,227)\naap2 = AspectAwarePreprocessor(256,256)\npredictions2=[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import pyprind\n# pbar = pyprind.ProgBar(y_test.shape[0])\n# for i,images in enumerate(test_data_generator(test_img_paths, bs=128,preprocessors=[mp], passes=1)):\n#     #print(i)\n#     for image in images:\n#         (h,w)=image.shape[:2]\n#         if h <= 227:\n#             image = aap2.preprocess(image)\n#         elif w <= 227:\n#             image = aap2.preprocess(image)\n#         else:\n#             image = image\n#         crops = cp.preprocess(image)\n#         crops = np.array([iap.preprocess(c) for c in crops])\n#         pred = model.predict(crops)\n#         predictions2.append(pred.mean(axis=0))\n#        # print('predictions2',len(predictions2))\n#     pbar.update(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# (rank1, _) = rank5_accuracy(predictions2, y_test)\n# rank1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pyprind\npbar = pyprind.ProgBar(y_test.shape[0])\nfor i,images in enumerate(test_data_generator(final_test_img_paths, bs=128,preprocessors=[mp], passes=1)):\n    #print(i)\n    for image in images:\n        (h,w)=image.shape[:2]\n        if h <= 227:\n            image = aap2.preprocess(image)\n        elif w <= 227:\n            image = aap2.preprocess(image)\n        else:\n            image = image\n        crops = cp.preprocess(image)\n        crops = np.array([iap.preprocess(c) for c in crops])\n        pred = model.predict(crops)\n        final_predict.append(pred.mean(axis=0))\n       # print('predictions2',len(predictions2))\n    pbar.update(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(final_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_outs=[]\nfor i in final_predict:\n    val_outs.append(i[1])\n    #print(i[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(val_outs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_img_names=[i.split(os.path.sep)[-1].split('.jpg')[0] for i in final_test_img_paths]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({'id':final_img_names, 'label':val_outs})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}