{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport torch \nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom PIL import Image \nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir datasets/\n!mkdir datasets/train\n!mkdir datasets/test\n!unzip ../input/train.zip  -d datasets/train/\n!unzip ../input/test.zip -d datasets/test/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class catsvsdogsDataset(Dataset):\n    def __init__(self, root_dir, train = True, val = False, test = False, transform=None):\n        super(catsvsdogsDataset, self).__init__()\n        self.root_dir = root_dir \n        self.transform = transform\n        self.training_file = self.root_dir + \"train/train\"\n        self.testing_file = self.root_dir + \"test/test\"\n        self.train = train\n        self.val = val\n        self.test = test\n        \n        if self.train:\n            self.data = os.listdir(self.training_file)[int(len(os.listdir(self.training_file))*0.1):]\n        elif self.val: \n            self.data = os.listdir(self.training_file)[:int(len(os.listdir(self.training_file))*0.1)]\n        else:\n            self.data = os.listdir(self.testing_file)\n            \n        if self.train or self.val:\n            self.targets = self.label_img(self.data)\n        \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        if self.train or self.val:\n            img, target = self.data[index], self.targets[index]\n            img = Image.open(os.path.join(self.training_file, img))\n        else:\n            img = self.data[index]\n            img = Image.open(os.path.join(self.testing_file, img))\n\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        if self.train or self.val:\n            return img, torch.tensor(target)\n        else:\n            return img\n    \n    def label_img(self, data_files):\n        labels = []\n        for files in data_files:\n            word_label = files.split('.')[-3]\n            if word_label == 'cat':  # cat -> 0\n                labels.append(0.0)\n            elif word_label == 'dog': # dog -> 1\n                labels.append(1.0)\n        return labels","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"transform_train  = transforms.Compose([transforms.Resize((227,227)),\n                                       transforms.RandomApply([\n                                           transforms.RandomChoice([transforms.ColorJitter(hue=.05, saturation=.05),\n                                                                    transforms.RandomRotation(20, resample=Image.NEAREST),\n                                                                    transforms.RandomAffine(0, shear=0.2, resample=Image.NEAREST)])],\n                                           p = 0.5),\n                                       transforms.RandomHorizontalFlip(p= 0.4),\n                                       transforms.ToTensor(),\n                                       transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\ntransform_val  = transforms.Compose([transforms.Resize((227,227)),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainset = catsvsdogsDataset(root_dir = 'datasets/', train = True,transform = transform_train)\n\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size = 32,\n                                         shuffle  = True, num_workers = 0)\n\nvalset = catsvsdogsDataset(root_dir = 'datasets/', train = False, val = True, transform = transform_val)\n\nvalloader = torch.utils.data.DataLoader(valset, batch_size = 32,\n                                         shuffle  = False, num_workers = 0)\n\nprint(\"Number of training samples = \",len(trainset))\nprint(\"Number of testing samples = \",len(valset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def imshow(img):\n    img = img / 2 + 0.5   \n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\nclasses = {1:\"dog\", 0:\"cat\"}\n\nn = 4\ndataiter = iter(trainloader)\nimages, labels = dataiter.next()\nimshow(torchvision.utils.make_grid(images[:n]))\nprint(' '.join('%5s' % classes[labels[j].item()] for j in range(n)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class AlexNet(nn.Module):\n    def __init__(self):\n        super(AlexNet, self).__init__()\n        self.conv1 = nn.Conv2d(3, 16, kernel_size = 11, stride = 4)\n        self.bn1 = nn.BatchNorm2d(16)\n        self.maxpool1 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n        self.conv2 = nn.Conv2d(16, 32, kernel_size = 5, padding = 2)\n        self.bn2 = nn.BatchNorm2d(32)\n        self.maxpool2 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n        self.conv3 = nn.Conv2d(32, 64, kernel_size = 3, padding = 1)\n        self.bn3 = nn.BatchNorm2d(64)\n        self.conv4 = nn.Conv2d(64, 64, kernel_size = 3, padding = 1)\n        self.bn4 = nn.BatchNorm2d(64)\n        self.conv5 = nn.Conv2d(64, 32, kernel_size = 3, padding = 1)\n        self.bn5 = nn.BatchNorm2d(32)\n        self.maxpool3 = nn.MaxPool2d(kernel_size = 3, stride = 2)\n        self.fc1 = nn.Linear(1152, 256)\n        self.fc2 = nn.Linear(256, 64)\n        self.fc3 = nn.Linear(64, 1)\n\n    def forward(self, x):\n        x = F.relu(self.bn1(self.conv1(x)))\n        x = self.maxpool1(x)\n        x = F.relu(self.bn2(self.conv2(x)))\n        x = self.maxpool2(x)\n        x = F.relu(self.bn3(self.conv3(x)))\n        x = F.relu(self.bn4(self.conv4(x)))\n        x = F.relu(self.bn5(self.conv5(x)))\n        x = self.maxpool3(x)\n        x = x.view(-1, 1152)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, 0.5)\n        x = F.relu(self.fc2(x))\n        x = F.dropout(x, 0.5)\n        x = self.fc3(x)\n        return torch.sigmoid(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def updateStats(correct, running_loss, phase):\n    if phase == 'train':\n        Dset = trainset\n    else:\n        Dset = valset\n    acc = 100 * correct/len(Dset)\n    epoch_loss = running_loss/len(Dset)\n    return acc, epoch_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = AlexNet()\noptimizer = optim.Adam(model.parameters(), lr=0.0001,weight_decay = 0.0005)\nmodel.to(device)\n\ncriterion = nn.BCELoss()\n\nloss_count_train = []\nacc_count_train = []\nloss_count_val = []\nacc_count_val = []\nepochs = 100\nfor epoch in range(epochs): \n    print(\"At epoch {}:\".format(epoch+1))\n    for phase in ['train', 'val']:\n        correct = 0.0\n        running_loss = 0.0\n        if phase == 'train': \n            model.train()\n            loader = trainloader\n        else:\n            model.eval()\n            loader = valloader\n        for data in loader:\n            inputs, labels = data[0].to(device), data[1].to(device)\n            labels = labels.unsqueeze(1)\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            if phase == 'train':\n                optimizer.zero_grad()\n                loss.backward()\n                optimizer.step()\n            ones = torch.ones_like(outputs, dtype = torch.float32)\n            zeros = torch.zeros_like(outputs, dtype = torch.float32)\n            predicted = torch.where(outputs > 0.5, ones, zeros)\n            correct += (predicted == labels).sum().item()\n            running_loss += loss.item() * labels.size(0)\n        acc, epoch_loss = updateStats(correct,running_loss,phase)\n        if phase == 'train':\n            acc_count_train.append(acc)\n            loss_count_train.append(epoch_loss)\n        else:\n            acc_count_val.append(acc)\n            loss_count_val.append(epoch_loss)\n        print(phase+\":\\n Accuracy = {:.2f}\\t Loss = {}\".format(acc,epoch_loss))\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"range_epochs = list(range(epochs))\nplt.plot(range_epochs,acc_count_train, label = \"Training Accuracy\")\nplt.plot(range_epochs,acc_count_val, label = \"Validation Accuracy\")\nplt.legend()\nplt.show()\nplt.plot(range_epochs,loss_count_train, label = \"Training Loss\")\nplt.plot(range_epochs,loss_count_val, label = \"Validation Loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transform_test  = torchvision.transforms.Compose([torchvision.transforms.Resize((227,227)),\n                                             torchvision.transforms.ToTensor(),\n                                             torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n    \ntestset = catsvsdogsDataset(root_dir = 'datasets/', train = False, test = True, transform = transform_test)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = 32,\n                                         shuffle  = False, num_workers = 0)\n\nprint(\"Number of training samples = \",len(testset))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = []\nmodel.eval()\nfor data in testloader:\n    outputs = model(data.to(device))\n    result.extend(outputs.view(-1).tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = list(range(1, len(testset)+1))\ndata = pd.DataFrame({\"id\":ids, \"label\":result})\ndata.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.rmtree('datasets', ignore_errors=False, onerror=None)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}