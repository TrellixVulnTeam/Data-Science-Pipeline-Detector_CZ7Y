{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom PIL import Image\nfrom tqdm import tqdm\nimport os\nimport cv2\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Conv2D, MaxPool2D, Dropout, BatchNormalization, Dense, Activation, GlobalAveragePooling2D\nfrom keras.models import Model,Sequential\nfrom keras.regularizers import l2\nfrom keras.preprocessing.image import load_img,img_to_array\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.layers import AveragePooling2D,Flatten,add,Input,MaxPooling2D,ZeroPadding2D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#制作训练集的图片id和标签\ntraining_dir = '../input/train/'\ntesting_dir = '../input/test/'\n\ntrain_files = os.listdir(training_dir)\ntest_files = os.listdir(testing_dir)\n\ntrain_labels = []\nfor file in train_files:\n    train_labels.append(file.split(\".\")[0])\n    \ndf_train = pd.DataFrame({\"id\": train_files, \"label\": train_labels})\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.DataFrame({\"id\": test_files})\ndf_test[\"label\"] = [\"cat\"]*(len(test_files))\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#制作keras数据生成器\nclasses = ['cat', 'dog']\n\ndef get_data(batch_size=32, target_size=(96,96), class_mode=\"categorical\", training_dir=training_dir,\n             testing_dir=testing_dir, classes=classes, df_train=df_train, df_test=df_test):\n    \n    train_datagen = ImageDataGenerator(horizontal_flip=True, shear_range=0.2,zoom_range=0.2,\n        rescale=1.0/255,validation_split=0.25)\n    test_datagen = ImageDataGenerator(rescale=1.0/255)\n    \n    train_generator = train_datagen.flow_from_dataframe(df_train, training_dir, x_col='id', y_col='label', \n        has_ext=True, target_size=target_size, classes = classes, class_mode=class_mode, \n        batch_size=batch_size, shuffle=True, seed=42,subset='training')\n    \n    validation_generator = train_datagen.flow_from_dataframe(df_train, training_dir, x_col='id', y_col='label', \n        has_ext=True, target_size=target_size, classes = classes, class_mode=class_mode, \n        batch_size=batch_size, shuffle=True, seed=42, subset='validation')\n\n    test_generator = test_datagen.flow_from_dataframe(df_test, testing_dir, x_col='id', y_col='label', \n        has_ext=True, target_size=target_size, classes = classes, class_mode=class_mode, \n        batch_size=batch_size, shuffle=False)\n    \n    steps_per_epoch = len(train_generator)\n    validation_steps = len(validation_generator)\n    \n    return train_generator, validation_generator, test_generator,  steps_per_epoch, validation_steps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#接下来定义网络结构，这里仿照resnet的结构进行定义。\n#先定义卷积-BN结构\ndef Conv2d_BN(x, nb_filter,kernel_size, strides=(1,1), padding='same'):\n    x = Conv2D(nb_filter,kernel_size,padding=padding,strides=strides,activation='relu')(x)\n    x = BatchNormalization(axis=3)(x)\n    return x\n\n#定义resnet的残差结构，其中with_conv_shortcut参数是使用卷积防止通道不一致。\ndef Conv_Block(inpt,nb_filter,kernel_size,strides=(1,1), with_conv_shortcut=False):\n    x = Conv2d_BN(inpt, nb_filter=nb_filter, kernel_size=kernel_size, strides=strides, padding='same')\n    x = Conv2d_BN(x, nb_filter=nb_filter, kernel_size=kernel_size, padding='same')\n    if with_conv_shortcut:\n        shortcut = Conv2d_BN(inpt, nb_filter=nb_filter, strides=strides, kernel_size=kernel_size)\n        x = add([x, shortcut])\n        return x\n    else:\n        x = add([x, inpt])\n        return x\n    \n    #定义resnet网络结构\ndef Resnet():\n    inpt = Input(shape=(299,299,3))\n    x = ZeroPadding2D((3, 3))(inpt)\n    x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')\n    x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)\n    # (56,56,64)\n    x = Conv_Block(x, nb_filter=64, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=64, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=64, kernel_size=(3, 3))\n    # (28,28,128)\n    x = Conv_Block(x, nb_filter=128, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n    x = Conv_Block(x, nb_filter=128, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=128, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=128, kernel_size=(3, 3))\n    # (14,14,256)\n    x = Conv_Block(x, nb_filter=256, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n    x = Conv_Block(x, nb_filter=256, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=256, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=256, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=256, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=256, kernel_size=(3, 3))\n    # (7,7,512)\n    x = Conv_Block(x, nb_filter=512, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)\n    x = Conv_Block(x, nb_filter=512, kernel_size=(3, 3))\n    x = Conv_Block(x, nb_filter=512, kernel_size=(3, 3))\n    x = AveragePooling2D(pool_size=(7, 7))(x)\n    x = Flatten()(x)\n    x = Dense(2, activation='softmax')(x)\n \n    model = Model(inpt,x)\n    #model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#读取数据\nbatch_size = 32\ntarget_size = (299, 299)\ntrain_generator, validation_generator, test_generator, steps_per_epoch, validation_steps = get_data(batch_size=batch_size, target_size=target_size, classes=classes, df_test=df_test)\n#建立模型\nmodel = Resnet()\noptimizer = Adam(0.0001)\nmodel.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'] )\ncheckpoint = ModelCheckpoint('model.hdf5', monitor='val_acc', save_best_only=True)\ncallbacks = [checkpoint]\n#开始训练\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=steps_per_epoch,\n    epochs=3,\n    verbose=1,\n    callbacks=callbacks,\n    validation_data=validation_generator,\n    validation_steps=validation_steps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_result(model, test_generator, nsteps=len(test_generator)):\n    y_preds = model.predict_generator(test_generator, steps=nsteps, verbose=1) \n    return y_preds, y_preds[:,1]\n\ny_preds_all, y_preds = generate_result(model, test_generator)       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.DataFrame({\"id\": test_generator.filenames, \"label\": y_preds})\ndf_test['id'] = df_test['id'].map(lambda x: x.split('.')[0])\ndf_test['id'] = df_test['id'].astype(int)\ndf_test = df_test.sort_values('id')\ndf_test.to_csv('submission.csv', index=False)\ndf_test.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}