{"cells":[{"metadata":{},"cell_type":"markdown","source":"Through this notebook, I am trying to give very basic introduction to natural language processing pipeline. This notebook is related to this [blog](http://) on medium. "},{"metadata":{},"cell_type":"markdown","source":"# Introduction to competition\n\nQuora is a platform that empowers people to learn from each others. In this platform people can ask question and any member can answer to the questions. But there are some questions that intend to make statement rather than look for answers. These questions are labeled as 'insincere'.\n\nIn this kernel we use the dataset provided in the above mentioned [competiotion](https://www.kaggle.com/c/quora-insincere-questions-classification), where we are supposed to label each question if it is 'insincere' or not. The dataset contained 1.31 million questions which are labeled 0 or 1 (1 is for 'insincere' and 0 is for 'sincere'). Out of 1.31 million there are about 80k questions that are labeled as 'insincere'.\n\n"},{"metadata":{},"cell_type":"markdown","source":"# Planning\n\nIn order to solve this problem, we need to build a model that can classify a question if its sincere or not."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\n\nprint(os.listdir(\"../input\"))\nimport operator \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6fc0108c231dc52717f47a46328ac03d7ec06a8a"},"cell_type":"code","source":"from gensim.models import KeyedVectors","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a0111115b44a9c03ec8e12715b616ba9e9e9d2f4"},"cell_type":"code","source":"import re, string\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import train_test_split\nimport keras\n\nfrom keras.layers import Input, Embedding, SpatialDropout1D, Bidirectional, Dense\nfrom keras.layers import concatenate, CuDNNGRU, GlobalAveragePooling1D, GlobalMaxPooling1D\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.models import load_model\nfrom keras.models import Model\n\n\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nimport tqdm\nimport nltk\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"653aeac0650291ac33f969b5fdb0ca98ab7898b6"},"cell_type":"code","source":"test_df = pd.read_csv('../input/test.csv')\ntest_df.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7ff933f5c8ec9861b31b61c0c24527b1ff296ba8"},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a7afd7a540a1e0dbc0f90ffc97904eed8e0df014"},"cell_type":"code","source":"lens = train_df.question_text.str.len()\nlens.mean(), lens.std(), lens.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"611d346c1aed30f2d733767ca1e5ac3686dec349"},"cell_type":"code","source":"all_df = pd.concat([train_df ,test_df])\n\nprint(\"Total number of questions: \", all_df.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5d5f56f704f4b7bb9c20573e15717aa63bc143e"},"cell_type":"code","source":"max_features = 100000\nques_len= 72","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9880452b510f3fb936669149c86400b5cea93f7d"},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"UNKNOWN_WORD = \"_UNK_\"\nEND_WORD = \"_END_\"\nNAN_WORD = \"_NAN_\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df[\"question_text\"] = train_df[\"question_text\"].fillna(NAN_WORD)\ntest_df[\"question_text\"] = test_df[\"question_text\"].fillna(NAN_WORD)\nsub = test_df[['qid']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9dc175bc369d07b279c673a165bfbed24ac91760"},"cell_type":"code","source":"re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n\ndef clean_text(s):\n    return re_tok.sub(r' \\1 ', s).lower()\n\n\ndef clean_numbers(x):\n    x = re.sub('[0-9]{5,}', '#####', x)\n    x = re.sub('[0-9]{4}', '####', x)\n    x = re.sub('[0-9]{3}', '###', x)\n    x = re.sub('[0-9]{2}', '##', x)\n    return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nprint(\"    Cleaning train questions\")\ntrain_df[\"question_text\"] = train_df[\"question_text\"].apply(clean_text)\nprint(\"    Cleaning test questions\")\ntest_df[\"question_text\"] = test_df[\"question_text\"].apply(clean_text)\n\nprint(\"    Removing numbers from train questions\")\ntrain_df[\"question_text\"] = train_df[\"question_text\"].apply(clean_numbers)\nprint(\"    Removing numbers from test questions\")\ntest_df[\"question_text\"] = test_df[\"question_text\"].apply(clean_numbers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tokenize text"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntokenizer = Tokenizer(num_words=max_features, oov_token=UNKNOWN_WORD)\ntokenizer.fit_on_texts(list(train_df[\"question_text\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_X = tokenizer.texts_to_sequences(train_df[\"question_text\"])\ntest_X = tokenizer.texts_to_sequences(test_df[\"question_text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_X = pad_sequences(train_X, maxlen=ques_len)\ntest_X = pad_sequences(test_X, maxlen=ques_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train_df['target'].values\n# test_y = test_df['target'].values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5cf5c43e43254053a4b66fb96334bf55c98ea924"},"cell_type":"markdown","source":"## Loading Embedding file\n\n"},{"metadata":{"trusted":true,"_uuid":"0796e9c3a9dde1d0f67a4733ed299bcb50ba6526"},"cell_type":"code","source":"embd_file =  '../input/embeddings/paragram_300_sl999/paragram_300_sl999.txt'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9ee2de86ab439250183450280e89140245cb889b"},"cell_type":"code","source":"def load_embed(file):\n    def get_coefs(word,*arr): \n        return word, np.asarray(arr, dtype='float32')\n    \n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(file, encoding='latin'))\n        \n    return embeddings_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6433ff0287a8dd3defe727f32e9f9606ac6bd07"},"cell_type":"code","source":"%%time\nprint(\"Extracting Paragram embedding\")\nembeddings_index = load_embed(embd_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating Embedding matrics"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nall_embs = np.stack(embeddings_index.values())\nemb_mean,emb_std = all_embs.mean(), all_embs.std()\nembed_size = all_embs.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## rebuilding embedding matrics\nnb_words = min(max_features, len(tokenizer.word_index))\nembedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n\nfor word, i in tokenizer.word_index.items():\n    if i >= max_features:\n        continue\n    embedding_vector = embeddings_index.get(word)\n    if embedding_vector is not None: \n        embedding_matrix[i] = embedding_vector\n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Building classification model"},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer = Input(shape=(ques_len,))\nembedding_layer = Embedding(embedding_matrix.shape[0], embedding_matrix.shape[1],\n                            weights=[embedding_matrix], trainable=False)(input_layer)\nx = SpatialDropout1D(0.2)(embedding_layer)\nx = Bidirectional(CuDNNGRU(90, return_sequences=True))(x)\nx = Bidirectional(CuDNNGRU(90, return_sequences=True))(x)\navg_pool = GlobalAveragePooling1D()(x)\nmax_pool = GlobalMaxPooling1D()(x)\nx = concatenate([avg_pool, max_pool])\nx = Dense(256, activation=\"relu\")(x)\noutput_layer = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=input_layer, outputs=output_layer)\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=Adam(lr=1e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0),\n    metrics=['accuracy']\n)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint\n\ncheckpoint = ModelCheckpoint('saved-dmodel-{acc:03f}.h5', verbose=1, monitor='val_acc',save_best_only=True, mode='auto')  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(train_X, train_y, batch_size=128, validation_split=0.1, callbacks=[checkpoint], epochs=8)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generating the prediction"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict([test_X], batch_size=1024, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = preds.reshape((-1, 1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test_y = (preds>0.5).astype(int)\nsub['prediction'] = pred_test_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}