{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"* Họ tên: Nguyễn Hoàng Việt\n* MSSV: 18021419\n* Đề tài: Quora Insincere Questions Classification","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-05T09:24:48.213215Z","iopub.execute_input":"2022-01-05T09:24:48.213523Z","iopub.status.idle":"2022-01-05T09:24:48.226388Z","shell.execute_reply.started":"2022-01-05T09:24:48.213493Z","shell.execute_reply":"2022-01-05T09:24:48.225269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **1. Phân tích bài toán:**\n\n* Quora là một nền tảng Q&A nổi tiếng nơi mọi người có thể đăng lên những câu hỏi của mình và người khác có thể giúp trả lời, bàn luận về những vấn đề đó. Tuy nhiên có những câu hỏi được đặt ra có thể không phù hợp với các quy chuẩn của nền tảng, có tính chất nhạy cảm, xúc phạm, ....\n* Nhiệm vụ của bài toán là phân loại các câu hỏi không phù hợp(Insincere) và câu hỏi phù hợp(Sincere) có trên hệ thống của Quora.\n* Tập đầu vào là tập các câu hỏi tiếng anh được cho dưới dạng text và đi kèm là id của từng câu cũng như nhãn dán (label) cho từng câu. \n* Trong đó Insincere là 1 và Sincere là 0. Đầu ra là các giá trị 1 hoặc 0 tương ứng.\n* Để giải quyết bài toán trên, ta sẽ chuyển dữ liệu từ dạng text sang ma trận đặc trưng dưới dạng số sau đó kết hợp với mô hình học máy (mô hình Logistic Regression) để huấn luyện và dự đoán kết quả đầu ra\n","metadata":{}},{"cell_type":"code","source":"# Đọc dữ liệu từ bài toán: \ndf = pd.read_csv('../input/quora-insincere-questions-classification/train.csv')\n# Lấy ra 1 số câu trong tập dữ liệu\ndf.head(7)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:48.229237Z","iopub.execute_input":"2022-01-05T09:24:48.229962Z","iopub.status.idle":"2022-01-05T09:24:52.312153Z","shell.execute_reply.started":"2022-01-05T09:24:48.229908Z","shell.execute_reply":"2022-01-05T09:24:52.311504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thông tin về tập dữ liệu:\ndf.info()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:52.313336Z","iopub.execute_input":"2022-01-05T09:24:52.313663Z","iopub.status.idle":"2022-01-05T09:24:52.635219Z","shell.execute_reply.started":"2022-01-05T09:24:52.313634Z","shell.execute_reply":"2022-01-05T09:24:52.634116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#     **2. Phân tích dữ liệu**\n    \n* Dữ liệu có thuộc tính qid, question_text, target\n* Tổng cộng 1306122 câu hỏi dưới dạng text được gán nhãn và không có giá trị null\n* Target (nhãn) là tập số nguyên gồm 2 giá trị 1 và 0\n* Tổng số câu sincere là 1225312 số câu insincere là 80810\n\n=> Dữ liệu insincere chỉ chiếm tỉ lệ 0.062.\nCòn so với dữ liệu sincere chiếm tỉ lệ 0.94 => Dữ liệu mất cân bằng\n\n=> Sử dụng F1-score để đánh giá hiệu năng của mô hình. F1 score là độ cân bằng đồng đều giữa precision và recall","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Mô phỏng về độ tương quan giữa các câu insincere và sincere dưới dạng biểu đồ:\n\nval = df.target.value_counts().values\nnames = ['Sincere', 'Insincere']\nplt.bar(names, val)\nplt.suptitle('Number of Sincere and Insincere Questions')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:52.636678Z","iopub.execute_input":"2022-01-05T09:24:52.636904Z","iopub.status.idle":"2022-01-05T09:24:52.816Z","shell.execute_reply.started":"2022-01-05T09:24:52.636877Z","shell.execute_reply":"2022-01-05T09:24:52.815139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **3. Tiền xử lý dữ liệu đầu vào:**\n\n* Với dữ liệu dạng text, ta cần chuyển sang số và biểu diễn thông qua các ma trận để huấn luyện mô hình học máy\n* Các bước tiền xử lý trong bài gồm có:\n    * Loại bỏ các dấu câu, và các từ stopwords có trong câu hỏi (các từ stopwords thường là những từ viết tắt và không mang nhiều ý nghĩa và có thể ảnh hưởng đến trọng số của những từ quan trọng trong câu)\n    * Loại bỏ các số có trong câu (cũng giống như stopwords các số thường không mang nhiều ý nghĩa trong việc phân loại câu nên cần loại bỏ)\n    * Sử dụng phương pháp TF_IDF hoặc đếm số lần xuất hiện của những từ đặc trưng trong câu để biểu diễn ma trận trọng số của những từ quan trọng trong câu hỏi (trong bài này ta sẽ kiểm tra cả 2 cách và so sánh kết quả giữa chúng)\n* Sau đó, ta sẽ chia tập input thành 2 phần: 1 phần để huấn luyện và 1 phần để kiểm tra độ chính xác của mô hình (tỉ lệ là 7:3)\n\n     **Phương pháp TF_IDF:**\n* Là phương pháp cơ bản trong việc xử lý dữ liệu văn bản trong xử lý ngôn ngữ tự nhiên.\n* Mục đích: Cân bằng mức độ quan trọng giữa các từ và loại bỏ 1 số những từ không cần thiết bằng cách tính trọng số TF (Term frequence) và IDF (Inverse document frequence)\n* TF (Term frequence) được tính như sau: TF(t, d) = (số lần từ t xuất hiện trong văn bản d) / (tổng số từ trong văn bản d) => Tần suất của từ t (trong khoảng [0,1])\n* IDF (Inverse document frequence) được tính như sau: IDF(t, D) = log_e(Tổng số văn bản trong tập mẫu D / Số văn bản có chứa từ t) => Mức độ quan trọng của từ t\n* Trọng số TF_IDF của từ t là TF(t, d) * IDF(t, D)","metadata":{}},{"cell_type":"code","source":"from string import punctuation, digits\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer\n\nwordnet_lemmatizer = WordNetLemmatizer()\n# Khai báo tập các dấu câu và tập các stop_words của tiếng Anh\npuncs = set(punctuation)\nstop_w = set(stopwords.words('english'))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:52.81838Z","iopub.execute_input":"2022-01-05T09:24:52.818749Z","iopub.status.idle":"2022-01-05T09:24:52.826301Z","shell.execute_reply.started":"2022-01-05T09:24:52.818713Z","shell.execute_reply":"2022-01-05T09:24:52.825231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(puncs)\nprint(stop_w)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:52.827672Z","iopub.execute_input":"2022-01-05T09:24:52.828051Z","iopub.status.idle":"2022-01-05T09:24:52.844272Z","shell.execute_reply.started":"2022-01-05T09:24:52.828015Z","shell.execute_reply":"2022-01-05T09:24:52.843116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Tiền xử lý dữ liệu:\ndef lemSentence(sentence): # Xây dựng lại cấu trúc câu sau khi đã loại bỏ các ký tự và các từ không cần thiết\n    token_words = word_tokenize(sentence)\n    lem_sentence = []\n    for word in token_words:\n        lem_sentence.append(wordnet_lemmatizer.lemmatize(word, pos=\"v\"))\n        lem_sentence.append(\" \")\n    return \"\".join(lem_sentence)\n\ndef clean(text): # Loại bỏ các ký tự không cần thiết \n    # Loại bỏ các dấu câu\n    text = text.translate(str.maketrans('', '', punctuation))\n    # Loại bỏ các số\n    text = text.translate(str.maketrans('', '', digits))\n    # Loại bỏ các stop_words\n    text = [w for w in word_tokenize(text) if not w.lower() in stop_w]\n    text = ' '.join(text)\n    # Thiết lập lại cấu trúc của câu\n    text = lemSentence(text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:52.845721Z","iopub.execute_input":"2022-01-05T09:24:52.846056Z","iopub.status.idle":"2022-01-05T09:24:52.856722Z","shell.execute_reply.started":"2022-01-05T09:24:52.846022Z","shell.execute_reply":"2022-01-05T09:24:52.855895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lấy ra tập train và tập nhãn dán của dữ liệu\ntrain_quests = df.question_text\ntrain_labels = df.target","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:52.858768Z","iopub.execute_input":"2022-01-05T09:24:52.859324Z","iopub.status.idle":"2022-01-05T09:24:52.869545Z","shell.execute_reply.started":"2022-01-05T09:24:52.859263Z","shell.execute_reply":"2022-01-05T09:24:52.868587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thực hiện việc tiền xử lý với dữ liệu đầu vào và lưu kết quả vào 1 hàng mới có tên là \"question_text_cleaned\"\ndf['question_text_cleaned'] = df.question_text.apply(lambda x: clean(x))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:24:52.87102Z","iopub.execute_input":"2022-01-05T09:24:52.871284Z","iopub.status.idle":"2022-01-05T09:33:32.567026Z","shell.execute_reply.started":"2022-01-05T09:24:52.871251Z","shell.execute_reply":"2022-01-05T09:33:32.565959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lấy ra 1 số câu sau khi đã thực hiện tiền xử lý\ndf.head(7)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:33:32.568784Z","iopub.execute_input":"2022-01-05T09:33:32.569579Z","iopub.status.idle":"2022-01-05T09:33:32.583365Z","shell.execute_reply.started":"2022-01-05T09:33:32.569531Z","shell.execute_reply":"2022-01-05T09:33:32.582228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report, plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:33:32.584815Z","iopub.execute_input":"2022-01-05T09:33:32.585069Z","iopub.status.idle":"2022-01-05T09:33:32.596785Z","shell.execute_reply.started":"2022-01-05T09:33:32.585039Z","shell.execute_reply":"2022-01-05T09:33:32.595825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Sau khi thực hiện việc loại bỏ các ký tự và các từ ngữ không cần thiết, ta sẽ thực hiện việc mã hóa TF_IDF cho tập từ vựng mới\n* Thư viện sklearn đã hỗ trợ việc tính toán cũng như chuyển đổi ma trận TF_IDF (tính toán trọng số và chuyển đổi từ dạng text sang ma trận trọng số) https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html tương tự với cách đếm số từ quan trọng trong 1 câu hỏi https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n\n    ","metadata":{}},{"cell_type":"code","source":"# Khai báo hàm thực hiện tính trọng số\ncount_vectorizer = CountVectorizer()\ntf_idf_vectorizer = TfidfVectorizer()\n# Chia tập dữ liệu đầu vào thành 2 phần (tập train và test theo tỷ lệ (7:3))\nx_train, x_test, y_train, y_test = train_test_split(df['question_text_cleaned'], train_labels, test_size=0.3)\n# Tiến hành tính toán trọng số của các từ trong tập huấn luyện\ncount_vectorizer.fit(x_train)\ntf_idf_vectorizer.fit(x_train)\n# Biến đổi các câu trong tập train thành ma trận trọng số\nvt_count_train = count_vectorizer.transform(x_train)\nvt_count_test = count_vectorizer.transform(x_test)\n\ntfidf_vt_train = tf_idf_vectorizer.transform(x_train)\ntfidf_vt_test = tf_idf_vectorizer.transform(x_test)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:33:32.597893Z","iopub.execute_input":"2022-01-05T09:33:32.598181Z","iopub.status.idle":"2022-01-05T09:34:39.536544Z","shell.execute_reply.started":"2022-01-05T09:33:32.598141Z","shell.execute_reply":"2022-01-05T09:34:39.535413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ma trận trọng số của các câu hỏi sẽ là input cho mô hình và có shape là (914285, 176283)\n# trong đó: 914285 là số lượng các câu hỏi \n#           176283 là kích thước mà trận trọng số dại diện cho câu hỏi đó được xây dựng từ tập từ vựng của dữ liệu đầu vào \ntfidf_vt_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:34:39.538299Z","iopub.execute_input":"2022-01-05T09:34:39.538635Z","iopub.status.idle":"2022-01-05T09:34:39.546416Z","shell.execute_reply.started":"2022-01-05T09:34:39.538591Z","shell.execute_reply":"2022-01-05T09:34:39.54568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Huấn luyện mô hình:\n\n* Sử dụng mô hình học máy Logistics Regression để thực thiện huấn luyện và kiểm tra độ chính xác","metadata":{}},{"cell_type":"code","source":"# Khái báo mô hình\nmodel_1 = LogisticRegression(n_jobs=10, solver='saga', C=0.1, verbose=1)\nmodel_2 = LogisticRegression(n_jobs=10, solver='sag', C=0.1, verbose=1)\n# Tiến hành huấn luyện trên tập dữ liệu đã được mã hóa bằng TF_IDF\nmodel_1.fit(vt_count_train, y_train)\nmodel_2.fit(tfidf_vt_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:34:39.548892Z","iopub.execute_input":"2022-01-05T09:34:39.549296Z","iopub.status.idle":"2022-01-05T09:36:28.500115Z","shell.execute_reply.started":"2022-01-05T09:34:39.549257Z","shell.execute_reply":"2022-01-05T09:36:28.49892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Độ chính xác trên tập train\npreds = model_1.predict(vt_count_train)\naccuracy = accuracy_score(y_train, preds)\nprint(\"Accuracy in train set: \", accuracy)\n# Dự đoán bằng mô hình vừa huấn luyện\ny_preds = model_1.predict(vt_count_test)\n# Ma trận lỗi của mô hình\nprint(f\"Confusion matrix: \") \nprint(confusion_matrix(y_test, y_preds))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:36:28.502069Z","iopub.execute_input":"2022-01-05T09:36:28.502349Z","iopub.status.idle":"2022-01-05T09:36:29.270269Z","shell.execute_reply.started":"2022-01-05T09:36:28.502317Z","shell.execute_reply":"2022-01-05T09:36:29.269121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ma trận lỗi của mô hình:\nplot_confusion_matrix(model_1, vt_count_test, y_test)\nplot_confusion_matrix(model_2, tfidf_vt_test, y_test)\nplt.show()  ","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:36:29.271549Z","iopub.execute_input":"2022-01-05T09:36:29.271772Z","iopub.status.idle":"2022-01-05T09:36:31.289191Z","shell.execute_reply.started":"2022-01-05T09:36:29.271745Z","shell.execute_reply":"2022-01-05T09:36:31.287935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Từ 2 ma trận lỗi trên, ta có thể thấy việc mã hóa dữ liệu đầu vào bằng cách đếm số lần xuất hiện của các từ trong câu cho độ chính xác cao hơn việc mã hóa bằng phương pháp TF_IDF","metadata":{}},{"cell_type":"markdown","source":"# 5. Kết quả:","metadata":{}},{"cell_type":"code","source":"# Kết quả\nprint(\"Classificaiton report:\\n\", classification_report(y_test, y_preds, target_names=[\"Sincere\", \"Insincere\"]))","metadata":{"execution":{"iopub.status.busy":"2022-01-05T09:36:31.29242Z","iopub.execute_input":"2022-01-05T09:36:31.293014Z","iopub.status.idle":"2022-01-05T09:36:31.869811Z","shell.execute_reply.started":"2022-01-05T09:36:31.292969Z","shell.execute_reply":"2022-01-05T09:36:31.868635Z"},"trusted":true},"execution_count":null,"outputs":[]}]}