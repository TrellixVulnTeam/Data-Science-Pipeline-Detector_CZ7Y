{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n# Keras\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten, LSTM, Conv1D, MaxPooling1D, Dropout, Activation\nfrom keras.layers.embeddings import Embedding\n\n\n\n# NLTK\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import SnowballStemmer\n\n# Other\nimport re\nimport string\nimport numpy as np\nimport pandas as pd\nfrom sklearn.manifold import TSNE\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\n\ndf = pd.read_csv(\"../input/train.csv\")\ntrain_df, val_df = train_test_split(df, test_size=0.1, random_state=2018)\nvocabulary_size = 50000\n\nt = Tokenizer(num_words=vocabulary_size)\nt.fit_on_texts(train_df['question_text'])\n# integer encode the documents\n# pad documents to a max length of 4 words\nmax_length = 100\ntrain_X = t.texts_to_sequences(train_df['question_text'])\nval_X = t.texts_to_sequences(val_df['question_text'])\n\n## Pad the sentences \ntrain_X = pad_sequences(train_X, maxlen=max_length,padding='post')\nval_X = pad_sequences(val_X, maxlen=max_length,padding='post')\n\n## Get the target values\ntrain_y = train_df['target'].values\nval_y = val_df['target'].values\n\nembeddings_index = {}\nf = open(r'../input/embeddings/glove.840B.300d/glove.840B.300d.txt',encoding=\"utf-8\")\nfor line in f:\n    values = line.split(' ')\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\n# create a weight matrix for words in training docs\nembedding_matrix = np.zeros((vocabulary_size, 300))\nfor word, index in t.word_index.items():\n    if index > vocabulary_size - 1:\n        break\n    else:\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None:\n            embedding_matrix[index] = embedding_vector\n\ndef create_conv_model():\n    model_conv = Sequential()\n    model_conv.add(Embedding(vocabulary_size, 300, input_length=100))\n    model_conv.add(Dropout(0.2))\n    model_conv.add(Conv1D(64, 5, activation='relu'))\n    model_conv.add(MaxPooling1D(pool_size=4))\n    model_conv.add(LSTM(300))\n    model_conv.add(Dense(1, activation='sigmoid'))\n    model_conv.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model_conv\n#develop a model\nmodel_glove = Sequential()\nmodel_glove.add(Embedding(vocabulary_size, 300, input_length=100, weights=[embedding_matrix], trainable=False))\nmodel_glove.add(Dropout(0.2))\nmodel_glove.add(Conv1D(64, 5, activation='relu'))\nmodel_glove.add(MaxPooling1D(pool_size=4))\nmodel_glove.add(LSTM(300))\nmodel_glove.add(Dense(1, activation='sigmoid'))\nmodel_glove.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nlabels = df['target']\n\nmodel_glove.fit(train_X, train_y, batch_size=512,epochs = 2,validation_data=(val_X, val_y))\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"print(model_glove.summary())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_noemb_val_y = model_glove.predict([val_X], batch_size=1024, verbose=1)\nfrom sklearn import metrics\nfor thresh in np.arange(0.1, 0.501, 0.01):\n    thresh = np.round(thresh, 2)\n    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(val_y, (pred_noemb_val_y>thresh).astype(int))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/test.csv\")\ntest_X = t.texts_to_sequences(test_df['question_text'])\ntest_X = pad_sequences(test_X, maxlen=max_length,padding='post')\n\npred_test_y = model_glove.predict([test_X], batch_size=1024, verbose=1)\npred_test_y = (pred_test_y>0.35).astype(int)\nout_df = pd.DataFrame({\"qid\":test_df[\"qid\"].values})\nout_df['prediction'] = pred_test_y\nout_df.to_csv(\"submission.csv\", index=False)\n","execution_count":1,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'pd' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-bdc8e51b915f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../input/test.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtexts_to_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question_text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_X\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpred_test_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_glove\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}