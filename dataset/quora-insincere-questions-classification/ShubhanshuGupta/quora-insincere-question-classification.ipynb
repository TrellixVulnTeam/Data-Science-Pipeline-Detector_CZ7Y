{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import confusion_matrix, f1_score\n\n\n","execution_count":1,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"quora = pd.read_csv('../input/train.csv', nrows=100000)\ntest = pd.read_csv('../input/test.csv')","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"quora.shape","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"(100000, 3)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import string\nfrom nltk.corpus import stopwords\n\n#Tokenization function\ndef text_process(mess):\n    \"\"\"\n    Takes in a string of text, then performs the following:\n    1. Remove all punctuation\n    2. Remove all stopwords\n    3. Returns a list of the cleaned text\n    \"\"\"\n    # Check characters to see if they are in punctuation\n    nopunc = [char for char in mess if char not in string.punctuation]\n\n    # Join the characters again to form the string.\n    nopunc = ''.join(nopunc)\n    \n    # Now just remove any stopwords\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_pipeline = Pipeline([\n    ('vectorizer', CountVectorizer(analyzer=text_process)),\n    ('tfidf_transformer', TfidfTransformer())\n])","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k_fold = KFold(n_splits = 3)\nnb_f1_scores = []\nnb_conf_mat = np.array([[0, 0], [0, 0]])\n\nfor train_indices, test_indices in k_fold.split(quora):\n    \n    train_text = quora.iloc[train_indices]['question_text'].values\n    train_y = quora.iloc[train_indices]['target'].values\n\n    test_text = quora.iloc[test_indices]['question_text'].values\n    test_y = quora.iloc[test_indices]['target'].values\n\n    vectorized_text = nb_pipeline.fit_transform(train_text)\n\n    sm = SMOTE(sampling_strategy=0.2,random_state=42,n_jobs=-1)\n    train_text_res, train_y_res = sm.fit_sample(vectorized_text, train_y)\n\n    clf = MultinomialNB()\n    clf.fit(train_text_res, train_y_res)\n    predictions = clf.predict(nb_pipeline.transform(test_text))\n    \n    nb_conf_mat += confusion_matrix(test_y, predictions)\n    score1 = f1_score(test_y, predictions)\n    nb_f1_scores.append(score1)\n\nprint(\"F1 Score: \", sum(nb_f1_scores)/len(nb_f1_scores))\nprint(\"Confusion Matrix: \")\nprint(nb_conf_mat)\n","execution_count":9,"outputs":[{"output_type":"stream","text":"F1 Score:  0.3380986047079797\nConfusion Matrix: \n[[93025   828]\n [ 4728  1419]]\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}