{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!git clone https://github.com/JaeminBest/cs376_qiqc","metadata":{"execution":{"iopub.status.busy":"2021-06-18T11:00:20.51757Z","iopub.execute_input":"2021-06-18T11:00:20.518011Z","iopub.status.idle":"2021-06-18T11:00:22.019469Z","shell.execute_reply.started":"2021-06-18T11:00:20.517925Z","shell.execute_reply":"2021-06-18T11:00:22.018339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd cs376_qiqc\n!mkdir input\n!cp /kaggle/input/quora-insincere-questions-classification/*.csv ./input/\n!unzip /kaggle/input/quora-insincere-questions-classification/embeddings.zip \n%cd ..","metadata":{"execution":{"iopub.status.busy":"2021-06-18T11:09:55.383659Z","iopub.execute_input":"2021-06-18T11:09:55.384034Z","iopub.status.idle":"2021-06-18T11:09:56.981478Z","shell.execute_reply.started":"2021-06-18T11:09:55.383998Z","shell.execute_reply":"2021-06-18T11:09:56.97996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 현재 디렉토리 세팅, pip 패키지 설치\n!git checkout -b rollback-old origin/rollback-old\n!pip install -r requirements.txt\n\n!python -m nltk.downloader punkt\n!python setup.py build_ext\n!python setup.py develop\n\n%env DATADIR=input","metadata":{"execution":{"iopub.status.busy":"2021-06-18T11:10:00.552826Z","iopub.execute_input":"2021-06-18T11:10:00.553182Z","iopub.status.idle":"2021-06-18T11:10:13.14268Z","shell.execute_reply.started":"2021-06-18T11:10:00.55315Z","shell.execute_reply":"2021-06-18T11:10:13.14169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport torch","metadata":{"execution":{"iopub.status.busy":"2021-06-18T11:10:13.14573Z","iopub.execute_input":"2021-06-18T11:10:13.14601Z","iopub.status.idle":"2021-06-18T11:10:13.152324Z","shell.execute_reply.started":"2021-06-18T11:10:13.145979Z","shell.execute_reply":"2021-06-18T11:10:13.151482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from qiqc.config import ExperimentConfigBuilderBase\nfrom qiqc.modules import BinaryClassifier\nfrom qiqc.presets.hparam import TextNormalizerPresets\nfrom qiqc.presets.hparam import TextTokenizerPresets\nfrom qiqc.presets.hparam import WordEmbeddingFeaturizerPresets\nfrom qiqc.presets.hparam import WordExtraFeaturizerPresets\nfrom qiqc.presets.hparam import SentenceExtraFeaturizerPresets\nfrom qiqc.presets.hparam import PreprocessorPresets\nfrom qiqc.presets.hparam import EmbeddingPresets\nfrom qiqc.presets.hparam import EncoderPresets\nfrom qiqc.presets.hparam import AggregatorPresets\nfrom qiqc.presets.hparam import MLPPresets\nfrom qiqc.presets.hparam import EnsemblerPresets  # NOQA","metadata":{"execution":{"iopub.status.busy":"2021-06-18T11:10:13.154247Z","iopub.execute_input":"2021-06-18T11:10:13.154643Z","iopub.status.idle":"2021-06-18T11:10:13.163346Z","shell.execute_reply.started":"2021-06-18T11:10:13.154606Z","shell.execute_reply":"2021-06-18T11:10:13.162542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport os\nfrom pathlib import Path\n\ndir_time = time.strftime('%c', time.localtime(time.time()))\ndir_str = 'output'\n\ndir_path = Path(dir_str)\nos.makedirs(dir_path)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T12:55:39.458254Z","iopub.execute_input":"2021-06-18T12:55:39.45857Z","iopub.status.idle":"2021-06-18T12:55:39.463485Z","shell.execute_reply.started":"2021-06-18T12:55:39.45854Z","shell.execute_reply":"2021-06-18T12:55:39.462449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Submit setting (from original repo)\n\nclass ExperimentConfigBuilder(ExperimentConfigBuilderBase):\n\n    default_config = dict(\n        test=False,\n        device=0,\n        maxlen=72,\n        vocab_mincount=5,\n        scale_batchsize=[],\n        validate_from=4,\n\t\toutdir_share = dir_path,\n        \n        scheduler='exponential',\n        gamma=0.5,\n    )\n\n    @property\n    def modules(self):\n        return [\n            TextNormalizer,\n            TextTokenizer,\n            WordEmbeddingFeaturizer,\n            WordExtraFeaturizer,\n            SentenceExtraFeaturizer,\n            Embedding,\n            Encoder,\n            Aggregator,\n            MLP,\n        ]\n\n\ndef build_model(config, embedding_matrix, n_sentence_extra_features):\n    embedding = Embedding(config, embedding_matrix)\n    encoder = Encoder(config, embedding.out_size)\n    aggregator = Aggregator(config)\n    mlp = MLP(config, encoder.out_size + n_sentence_extra_features)\n    out = torch.nn.Linear(config.mlp_n_hiddens[-1], 1)\n    lossfunc = torch.nn.BCEWithLogitsLoss()\n\n    return BinaryClassifier(\n        embedding=embedding,\n        encoder=encoder,\n        aggregator=aggregator,\n        mlp=mlp,\n        out=out,\n        lossfunc=lossfunc,\n    )\n\n\n# =======  Preprocessing modules  =======\n\nclass TextNormalizer(TextNormalizerPresets):\n    pass\n\n\nclass TextTokenizer(TextTokenizerPresets):\n    pass\n\n\nclass WordEmbeddingFeaturizer(WordEmbeddingFeaturizerPresets):\n    pass\n\n\nclass WordExtraFeaturizer(WordExtraFeaturizerPresets):\n\n    default_config = dict(\n        word_extra_features=['idf', 'unk'],\n    )\n\n\nclass SentenceExtraFeaturizer(SentenceExtraFeaturizerPresets):\n\n    default_config = dict(\n        sentence_extra_features=['char', 'word'],\n    )\n\n\nclass Preprocessor(PreprocessorPresets):\n\n    embedding_sampling = 400\n\n    def build_word_features(self, word_embedding_featurizer,\n                            embedding_matrices, word_extra_features):\n        embedding = np.stack(list(embedding_matrices.values()))\n\n        # Concat embedding\n        embedding = np.concatenate(embedding, axis=1)\n        vocab = word_embedding_featurizer.vocab\n        embedding[vocab.lfq & vocab.unk] = 0\n\n        # Embedding random sampling\n        n_embed = embedding.shape[1]\n        n_select = self.embedding_sampling\n        idx = np.random.permutation(n_embed)[:n_select]\n        embedding = embedding[:, idx]\n\n        word_features = np.concatenate(\n            [embedding, word_extra_features], axis=1)\n        return word_features\n\n\n# =======  Training modules  =======\n\nclass Embedding(EmbeddingPresets):\n    pass\n\n\nclass Encoder(EncoderPresets):\n    pass\n\n\nclass Aggregator(AggregatorPresets):\n    pass\n\n\nclass MLP(MLPPresets):\n    pass\n\n\nclass Ensembler(EnsemblerPresets):\n    pass","metadata":{"execution":{"iopub.status.busy":"2021-06-18T11:10:13.176209Z","iopub.execute_input":"2021-06-18T11:10:13.176481Z","iopub.status.idle":"2021-06-18T11:10:13.19084Z","shell.execute_reply.started":"2021-06-18T11:10:13.176457Z","shell.execute_reply":"2021-06-18T11:10:13.189904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from qiqc.utils import rmtree_after_confirmation\nfrom train import train\nimport argparse\nimport pickle\n\n# FIXME: you should change some hparam with your own model name and hparam\n# for more detail, checkout qiqc/config.py\n# if you want to change hparam just change it in ExperimentConfigBuilder class\nconfig = ExperimentConfigBuilder().build(args=['--modelfile','test'])\n\nconfig.encoder='lstmgru'\nconfig.outdir=Path('output')\n\n# this will remove recursively all file in outdir and test\nrmtree_after_confirmation(config.outdir, config.test) \ntrain(config, build_model, Preprocessor, TextNormalizer,\n      TextTokenizer, WordEmbeddingFeaturizer, WordExtraFeaturizer,\n      SentenceExtraFeaturizer, Ensembler)","metadata":{"execution":{"iopub.status.busy":"2021-06-18T11:10:13.192481Z","iopub.execute_input":"2021-06-18T11:10:13.19291Z","iopub.status.idle":"2021-06-18T11:56:15.031391Z","shell.execute_reply.started":"2021-06-18T11:10:13.192874Z","shell.execute_reply":"2021-06-18T11:56:15.030527Z"},"trusted":true},"execution_count":null,"outputs":[]}]}