{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"1. Họ và tên: Nguyễn Duy Hiếu\n2. Lớp học: INT3405_1\n3. Bài tập lớn môn học máy cuối kỳ\n4. Chủ đề: Classify Toxic Question","metadata":{}},{"cell_type":"code","source":"import os\nimport time\nimport numpy as np \nfrom tqdm import tqdm\nimport math\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\n\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers\n\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, LSTM, GRU, CuDNNGRU\n\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.stem import PorterStemmer\nimport string\nimport pandas as pd\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:47:48.58217Z","iopub.execute_input":"2022-01-04T12:47:48.582593Z","iopub.status.idle":"2022-01-04T12:47:48.591717Z","shell.execute_reply.started":"2022-01-04T12:47:48.582548Z","shell.execute_reply":"2022-01-04T12:47:48.590929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**ĐỌC DỮ LIỆU VÀO**","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/train.csv')\nprint(df_train.shape)\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:47:48.595063Z","iopub.execute_input":"2022-01-04T12:47:48.595725Z","iopub.status.idle":"2022-01-04T12:47:51.062475Z","shell.execute_reply.started":"2022-01-04T12:47:48.59569Z","shell.execute_reply":"2022-01-04T12:47:51.061611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/test.csv')\nprint(df_test.shape)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:47:51.063904Z","iopub.execute_input":"2022-01-04T12:47:51.064323Z","iopub.status.idle":"2022-01-04T12:47:51.739481Z","shell.execute_reply.started":"2022-01-04T12:47:51.064275Z","shell.execute_reply":"2022-01-04T12:47:51.738776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**PHÂN TÍCH DỮ LIỆU**","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt \ntarget = df_train['target']\ntarget_1 = 0\nfor target_value in target:\n    if target_value == 1:\n        target_1 += 1\nprint(\"Số câu hỏi trong tệp train:\", len(target))\nprint(\"Số câu hỏi được gán nhãn là 1:\", target_1)\nmyLabels = [\"insincere question\", \"sincere question\"]\nmyCounts = [target_1, len(target) - target_1]\nplt.pie(myCounts, labels = myLabels, autopct='%1.1f%%', shadow=True, startangle=90)\nplt.axis('equal')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:47:51.741709Z","iopub.execute_input":"2022-01-04T12:47:51.742372Z","iopub.status.idle":"2022-01-04T12:47:52.099273Z","shell.execute_reply.started":"2022-01-04T12:47:51.742328Z","shell.execute_reply":"2022-01-04T12:47:52.097731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nprint(\"Word cloud thể  hiện các câu hỏi sincere: \")\nsincere_wordcloud = WordCloud(width=700, height=500, background_color='black', min_font_size=10).generate(str(df_train[df_train[\"target\"] == 0][\"question_text\"]))\nplt.figure(figsize=(10,9), facecolor=None)\nplt.imshow(sincere_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:47:52.102042Z","iopub.execute_input":"2022-01-04T12:47:52.102602Z","iopub.status.idle":"2022-01-04T12:47:53.165595Z","shell.execute_reply.started":"2022-01-04T12:47:52.102518Z","shell.execute_reply":"2022-01-04T12:47:53.164914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nprint(\"Word cloud thể  hiện các câu hỏi insincere: \")\nsincere_wordcloud = WordCloud(width=700, height=500, background_color='black', min_font_size=10).generate(str(df_train[df_train[\"target\"] == 1][\"question_text\"]))\nplt.figure(figsize=(10,9), facecolor=None)\nplt.imshow(sincere_wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:47:53.167212Z","iopub.execute_input":"2022-01-04T12:47:53.174995Z","iopub.status.idle":"2022-01-04T12:47:53.837498Z","shell.execute_reply.started":"2022-01-04T12:47:53.174953Z","shell.execute_reply":"2022-01-04T12:47:53.836819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**TIỀN XỬ LÝ**","metadata":{}},{"cell_type":"code","source":"df_train, df_val = train_test_split(df_train, test_size=0.1, random_state=2018)\n\nembed_size = 300 # độ dài mỗi vector từ\nmax_features = 50000 # số lượng các từ được sử dụng tối đa\nmaxlen = 100 # max number of words in a question to use\n\nX_train = df_train[\"question_text\"].fillna(\"_NA_\").values\nX_val = df_val[\"question_text\"].fillna(\"_NA_\").values\nX_test = df_test[\"question_text\"].fillna(\"_NA_\").values\n\ntokenizer = Tokenizer(num_words=max_features)\ntokenizer.fit_on_texts(list(X_train))\nX_train = tokenizer.texts_to_sequences(X_train)\nX_val = tokenizer.texts_to_sequences(X_val)\nX_test = tokenizer.texts_to_sequences(X_test)\n\nX_train = pad_sequences(X_train, maxlen=maxlen)\nX_val = pad_sequences(X_val, maxlen=maxlen)\nX_test = pad_sequences(X_test, maxlen=maxlen)\n\ny_train = df_train['target'].values\ny_val = df_val['target'].values","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:47:53.838569Z","iopub.execute_input":"2022-01-04T12:47:53.83893Z","iopub.status.idle":"2022-01-04T12:48:57.626531Z","shell.execute_reply.started":"2022-01-04T12:47:53.838897Z","shell.execute_reply":"2022-01-04T12:48:57.625467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**NAIVE BAYES**","metadata":{}},{"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n\nMulNB = MultinomialNB()\nMulNB.fit(X_train,y_train)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:48:57.633724Z","iopub.execute_input":"2022-01-04T12:48:57.634001Z","iopub.status.idle":"2022-01-04T12:49:00.529483Z","shell.execute_reply.started":"2022-01-04T12:48:57.633965Z","shell.execute_reply":"2022-01-04T12:49:00.528758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MulNB\npredictions = model.predict(X_train)\ntrain_acc = accuracy_score(y_train, predictions)\ntrain_f1 = f1_score(y_train, predictions)*4\nprint(f\"Training accuracy: {train_acc:.2%}, F1 score: {train_f1:.4f}\") \ntest_predictions = model.predict(X_val)\ntest_acc = accuracy_score(y_val, test_predictions) \ntest_f1 = f1_score(y_val, test_predictions)*4\nprint(f\"Testing accuracy:  {test_acc:.2%}, F1 score: {test_f1:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:49:00.532567Z","iopub.execute_input":"2022-01-04T12:49:00.533159Z","iopub.status.idle":"2022-01-04T12:49:01.58595Z","shell.execute_reply.started":"2022-01-04T12:49:00.533115Z","shell.execute_reply":"2022-01-04T12:49:01.581572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SỬ DỤNG LSTM**","metadata":{}},{"cell_type":"code","source":"inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size)(inp)\nx = Bidirectional(LSTM(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nclf = Model(inputs=inp, outputs=x)\nclf.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(clf.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:49:01.587438Z","iopub.execute_input":"2022-01-04T12:49:01.587712Z","iopub.status.idle":"2022-01-04T12:49:02.027136Z","shell.execute_reply.started":"2022-01-04T12:49:01.587677Z","shell.execute_reply":"2022-01-04T12:49:02.026422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clf.fit(X_train, y_train, batch_size=512, epochs=2, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:49:02.028274Z","iopub.execute_input":"2022-01-04T12:49:02.028603Z","iopub.status.idle":"2022-01-04T12:52:02.338785Z","shell.execute_reply.started":"2022-01-04T12:49:02.028563Z","shell.execute_reply":"2022-01-04T12:52:02.338031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_val_y = clf.predict([X_val], batch_size=1024, verbose=1)\nmaxLSTM = 0\nmaxThresh = 0\nthreshMatrixLSTM = []\nmetricsF1MatrixLSTM = []\nfor thresh in np.arange(0.1, 0.501, 0.01):\n    thresh = np.round(thresh, 2)\n    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(y_val, (pred_val_y>thresh).astype(int))))\n    threshMatrixLSTM.append(thresh)\n    metricsF1MatrixLSTM.append(metrics.f1_score(y_val, (pred_val_y>thresh).astype(int)))\n    if (metrics.f1_score(y_val, (pred_val_y>thresh).astype(int)) > maxLSTM):\n        maxLSTM = metrics.f1_score(y_val, (pred_val_y>thresh).astype(int))\n        maxThresh = thresh\nplt.plot(threshMatrixLSTM, metricsF1MatrixLSTM)\nplt.xlabel('thresh')\nplt.ylabel('F1_Score')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:25:31.692305Z","iopub.execute_input":"2022-01-04T13:25:31.693021Z","iopub.status.idle":"2022-01-04T13:25:38.716148Z","shell.execute_reply.started":"2022-01-04T13:25:31.692983Z","shell.execute_reply":"2022-01-04T13:25:38.715514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxLSTM","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:13:02.674692Z","iopub.execute_input":"2022-01-04T13:13:02.675468Z","iopub.status.idle":"2022-01-04T13:13:02.680703Z","shell.execute_reply.started":"2022-01-04T13:13:02.675416Z","shell.execute_reply":"2022-01-04T13:13:02.680028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxThresh","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:13:04.710925Z","iopub.execute_input":"2022-01-04T13:13:04.711238Z","iopub.status.idle":"2022-01-04T13:13:04.723374Z","shell.execute_reply.started":"2022-01-04T13:13:04.711199Z","shell.execute_reply":"2022-01-04T13:13:04.722248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_test_y = clf.predict([X_test], batch_size=1024, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:52:06.743092Z","iopub.execute_input":"2022-01-04T12:52:06.743894Z","iopub.status.idle":"2022-01-04T12:52:12.58108Z","shell.execute_reply.started":"2022-01-04T12:52:06.743841Z","shell.execute_reply":"2022-01-04T12:52:12.580322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Sử dụng GRU Model**","metadata":{}},{"cell_type":"code","source":"inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size)(inp)\nx = Bidirectional(GRU(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:52:12.582489Z","iopub.execute_input":"2022-01-04T12:52:12.58333Z","iopub.status.idle":"2022-01-04T12:52:13.12484Z","shell.execute_reply.started":"2022-01-04T12:52:12.583291Z","shell.execute_reply":"2022-01-04T12:52:13.124191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, batch_size=512, epochs=2, validation_data=(X_val, y_val))","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:52:13.129814Z","iopub.execute_input":"2022-01-04T12:52:13.130259Z","iopub.status.idle":"2022-01-04T12:55:08.108465Z","shell.execute_reply.started":"2022-01-04T12:52:13.130213Z","shell.execute_reply":"2022-01-04T12:55:08.107736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_noemb_y_val = model.predict([X_val], batch_size=1024, verbose=1)\nthreshMatrixGRU = []\nmetricsF1MatrixGRU = []\nmaxGRU = 0\nmaxThresh = 0\nfor thresh in np.arange(0.1, 0.501, 0.01):\n    thresh = np.round(thresh, 2)\n    print(\"F1 score at threshold {0} is {1}\".format(thresh, metrics.f1_score(y_val, (pred_noemb_y_val>thresh).astype(int))))\n    threshMatrixGRU.append(thresh)\n    metricsF1MatrixGRU.append(metrics.f1_score(y_val, (pred_noemb_y_val>thresh).astype(int)))\n    if (metrics.f1_score(y_val, (pred_noemb_y_val>thresh).astype(int)) > maxGRU): \n        maxGRU = metrics.f1_score(y_val, (pred_noemb_y_val>thresh).astype(int))\n        maxThresh = thresh\nplt.plot(threshMatrixGRU,metricsF1MatrixGRU)\nplt.xlabel('thresh')\nplt.ylabel('F1_score')","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:30:01.789897Z","iopub.execute_input":"2022-01-04T13:30:01.790703Z","iopub.status.idle":"2022-01-04T13:30:09.378409Z","shell.execute_reply.started":"2022-01-04T13:30:01.790661Z","shell.execute_reply":"2022-01-04T13:30:09.377766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxGRU","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:05:50.494299Z","iopub.execute_input":"2022-01-04T13:05:50.494854Z","iopub.status.idle":"2022-01-04T13:05:50.500073Z","shell.execute_reply.started":"2022-01-04T13:05:50.494815Z","shell.execute_reply":"2022-01-04T13:05:50.499325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maxThresh","metadata":{"execution":{"iopub.status.busy":"2022-01-04T13:05:48.399729Z","iopub.execute_input":"2022-01-04T13:05:48.400321Z","iopub.status.idle":"2022-01-04T13:05:48.406282Z","shell.execute_reply.started":"2022-01-04T13:05:48.400279Z","shell.execute_reply":"2022-01-04T13:05:48.405548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"pred_test_y_GRU = clf.predict([X_test], batch_size=1024, verbose=1)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:55:11.779094Z","iopub.execute_input":"2022-01-04T12:55:11.779519Z","iopub.status.idle":"2022-01-04T12:55:17.604058Z","shell.execute_reply.started":"2022-01-04T12:55:11.779478Z","shell.execute_reply":"2022-01-04T12:55:17.603327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**SUBMIT**","metadata":{}},{"cell_type":"code","source":"df_submission = pd.read_csv('../input/quora-insincere-questions-classification/sample_submission.csv')\ndf_submission['prediction'] = (0.34*pred_test_y).astype(int) # Best threshold for f1-Score\n# df_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:55:17.605262Z","iopub.execute_input":"2022-01-04T12:55:17.60577Z","iopub.status.idle":"2022-01-04T12:55:17.947029Z","shell.execute_reply.started":"2022-01-04T12:55:17.605727Z","shell.execute_reply":"2022-01-04T12:55:17.946174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_submission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-01-04T12:55:17.948278Z","iopub.execute_input":"2022-01-04T12:55:17.948546Z","iopub.status.idle":"2022-01-04T12:55:18.741804Z","shell.execute_reply.started":"2022-01-04T12:55:17.94851Z","shell.execute_reply":"2022-01-04T12:55:18.741037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}