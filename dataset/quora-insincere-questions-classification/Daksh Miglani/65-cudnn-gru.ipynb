{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"442ef6651b3acfa8a82977d3f61061d2ccf4c1b0"},"cell_type":"code","source":"print(os.listdir(\"../input/embeddings\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c549d3d740c6c98d4567e488f4cd76201a70e957"},"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"41ecc64e6af5a35906b33d5dd48f76a0b7cdb04c"},"cell_type":"code","source":"def clean_text(text):\n    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n    \n    # Convert words to lower case\n    text = text.lower()\n    \n    # Format words and remove unwanted characters\n    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n    text = re.sub(r'\\<a href', ' ', text)\n    text = re.sub(r'&amp;', '', text) \n    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n    text = re.sub(r'<br />', ' ', text)\n    text = re.sub(r'\\'', ' ', text)\n    text = text.replace(\"  \", \" \")\n    for punct in puncts:\n        text = text.replace(punct, f\" {punct} \")\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"177a2589254f81f0f61163c7a8d92d64aa860745"},"cell_type":"code","source":"df = pd.read_csv(\"../input/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7866983986a2e127c774de868b404982e90d349"},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"362340c0986494fc788dc7d2f835d3921d0f9642"},"cell_type":"code","source":"df = df.drop([\"qid\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ad0a8d9aa30c129bdb7a60749d670b132bb69cbe"},"cell_type":"code","source":"df.head(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f6830f10708f0bc04c9667efe0e3144be474ded7"},"cell_type":"code","source":"df = df.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"17484e6d042b05f5c572e8d9d610717024092e7e"},"cell_type":"code","source":"embed_size = 300 # 300 dim vector\nmax_features = None\nmaxlen = 150 # quora has a hard limit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0ef9ed22b1fba243e2bedc91fb597a2e99c3ab32"},"cell_type":"code","source":"X, Y = df[\"question_text\"].values, df[\"target\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"21ac399294594a678636f487d7329b19a3904ea6"},"cell_type":"code","source":"import pickle as pkl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cb0b963da79f12ec98242189245aedab1ef000f0"},"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a808f7bd67a1e343f4407be01322adb4e92dff95"},"cell_type":"code","source":"if os.path.exists(\"./tokenizer.pkl\"):\n    with open(\"./tokenizer.pkl\", \"rb\") as f:\n        tokenizer = pkl.load(f)\nelse:\n    tokenizer = Tokenizer(num_words=max_features)\n    tokenizer.fit_on_texts(list(X))\n    with open('./tokenizer.pkl', 'wb') as f:\n        pkl.dump(tokenizer, f, protocol=pkl.HIGHEST_PROTOCOL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b280e0a283bd3c99b2d8481a6c3b1de904048fb"},"cell_type":"code","source":"X = tokenizer.texts_to_sequences(X)\nX = pad_sequences(X, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8c5b9020ae812ad4cdf0b51c739cfc9678a29c44"},"cell_type":"code","source":"word_index = tokenizer.word_index\nmax_features = len(word_index)+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73be0d08d41504316844faaa780d78845a106589"},"cell_type":"code","source":"import gc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b3286246e5a31dfd58ccd09f118ecf162eb7c5f9"},"cell_type":"code","source":"del df\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"aecd5a23e808ec04471ef85c884f7098e7943884"},"cell_type":"code","source":"def load_glove(word_index):\n    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if o.split(\" \")[0] in word_index)\n\n    all_embs = np.stack(embeddings_index.values())\n    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n    embed_size = all_embs.shape[1]\n\n    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n    for word, i in word_index.items():\n        if i >= max_features: continue\n        embedding_vector = embeddings_index.get(word)\n        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n            \n    return embedding_matrix","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12c42af0c0f740823051cd930288eeb00b11bfb4"},"cell_type":"code","source":"embedding_matrix = load_glove(word_index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e61a7b9b5df81443c06cc3ee7bcb56b61246ec0"},"cell_type":"code","source":"from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, CuDNNGRU, Conv1D\nfrom keras.layers import Bidirectional, GlobalMaxPool1D\nfrom keras.models import Model\nfrom keras import initializers, regularizers, constraints, optimizers, layers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c089fc933c9339a2e703297f19a0f5021f6c90af"},"cell_type":"code","source":"inp = Input(shape=(maxlen,))\nx = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\nx = Bidirectional(CuDNNGRU(64, return_sequences=True))(x)\nx = GlobalMaxPool1D()(x)\nx = Dense(16, activation=\"relu\")(x)\nx = Dropout(0.1)(x)\nx = Dense(1, activation=\"sigmoid\")(x)\nmodel = Model(inputs=inp, outputs=x)\nmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"dd9ece8c913e739c4c0ebdb1b21da09706998dff"},"cell_type":"code","source":"model.fit(X, Y, batch_size=512, epochs=2, validation_split=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37cc321f7397fa91bcb7e48cb2a56cd7b6371577"},"cell_type":"code","source":"model.save(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3d7d28e35308663fa9979a1345e8d40ebaab8bdc"},"cell_type":"code","source":"del X\ndel Y\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"edd5b421f2badd1b0f711c43b3742288e0852b76"},"cell_type":"code","source":"test_df = pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f7c21eae7bc5e09e3b302cedb2d65062309d3803"},"cell_type":"code","source":"qids = test_df[\"qid\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ccdbc3e2909318d2d4614c99124bfa2bfab7000c"},"cell_type":"code","source":"testX = test_df[\"question_text\"].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1d035570d45303d35ea0f51de68978a0843aeca0"},"cell_type":"code","source":"testX = tokenizer.texts_to_sequences(testX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"08b6508c52a40c97f71727e53d02de0b622433ff"},"cell_type":"code","source":"testX = pad_sequences(testX, maxlen=maxlen)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"91675e7e35decb7577fb0cbd1ea53748edb694af"},"cell_type":"code","source":"testY = model.predict(testX)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9bcabe7d3f460fcbadcf59c9d2053a4ed1c3991b"},"cell_type":"code","source":"testY = testY.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf8d8f958f6252adfe20d8b40c0ed373f6b8617e"},"cell_type":"code","source":"for i in range(len(testY)):\n    testY[i] = round(testY[i][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a4517abb82c9d878fa9351d67728afa06142b889"},"cell_type":"code","source":"df = pd.DataFrame(columns=[\"qid\", \"prediction\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b134cafa7c865c2cb25aea946b7ffa93d2d0e451"},"cell_type":"code","source":"df[\"qid\"] = qids\ndf[\"prediction\"] = testY","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b52e3c1f0299b1edc77f9567bbab23c91ba2b3e1"},"cell_type":"code","source":"df.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}