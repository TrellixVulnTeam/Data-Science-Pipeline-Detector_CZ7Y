{"cells":[{"metadata":{},"cell_type":"markdown","source":"# BERT using Pytorch"},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"!pip install transformers --quiet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the required Libraries\nimport transformers\nfrom transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\nimport torch\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nimport re\nfrom textblob import TextBlob\nfrom collections import Counter\nfrom nltk import word_tokenize, ngrams\nfrom tqdm import tqdm\nfrom string import punctuation\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nfrom matplotlib import rc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, f1_score\nfrom collections import defaultdict\nfrom textwrap import wrap\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.utils import resample\nimport warnings\nfrom nltk import word_tokenize, ngrams\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\nwarnings.filterwarnings('ignore')\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\nRANDOM_SEED = 42\nnp.random.seed(RANDOM_SEED)\ntorch.manual_seed(RANDOM_SEED)\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n\n# Stopwords\nstop_words = set(stopwords.words('english'))\n\n# Punctuations\npunctuation = punctuation + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing the dataset\ndf = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['target'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checing for the null values\ndf.isnull().sum(axis = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Exploratory Data Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the target values for the EDA for now\ndf['target'] = df['target'].map({1 : 'Insincere', 0 : 'Sincere'})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Distribution of Insincere and Sincere Questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of the Insincere and Sincere Questions\nplt.rcParams['figure.figsize'] = [10, 20]\n# fig, ax = plt.subplots(2, 1)\n# sns.set(font_scale = 1.4, style = 'whitegrid')\n# distribution = sns.countplot(df['target'], palette = ['darkcyan', 'crimson'], orient = 'h', ax = ax[0])\n# distribution.set(title = 'Distribution of the Question Types', xlabel = 'Question type', ylabel = 'Count');\n\n# # Creating the labels for the piechart\ntypes = df['target'].value_counts()\nlabels = list(types.index)\naggregate = list(types.values)\npercentage = [(x*100)/sum(aggregate) for x in aggregate]\nprint (\"The percentages of Sincere and Insincere Questions are : \", percentage)\n\n# Plotting the Piechart to see the percentage distribution of the questions\nplt.rcParams.update({'font.size': 16})\nexplode = (0, 0.1)\n# ax[1].pie(aggregate, labels = labels, autopct='%1.2f%%', shadow=True, colors = ['darkcyan', 'crimson'])\nplt.pie(aggregate, labels = labels, autopct='%1.2f%%', shadow=True, colors = ['darkcyan', 'crimson'])\nplt.legend(labels, loc = 'best')\n#plt.axis('equal')\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Ngrams (Unigrams and Bigrams)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copying the dataset for the ngrams so that it won't effect the further processes\ndf_ = df.copy()\ndf_['question_text'] = df_['question_text'].str.replace(r'[^\\w\\d\\s]',' ')\n\n# Segregating the questions\ndf_insincere = \" \".join(df_.loc[df_.target == 'Insincere', 'question_text'])\ndf_sincere = \" \".join(df_.loc[df_.target == 'Sincere', 'question_text'])\n\n# Tokenizing the Sentences\ntokenized_insincere = word_tokenize(df_insincere)\ntokenized_sincere = word_tokenize(df_sincere)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unigrams\nsns.set(style = 'whitegrid', font_scale = 1.5)\nunigram_insincere = ngrams(tokenized_insincere, 1)\nunigram_sincere = ngrams(tokenized_sincere, 1)\n\n# Making the Frequency chart for the Unigrams\nfrequency_insincere = Counter(unigram_insincere) \nfrequency_sincere = Counter(unigram_sincere)\n\ndf_freq_insincere = pd.DataFrame(frequency_insincere.most_common(20))\ndf_freq_sincere = pd.DataFrame(frequency_sincere.most_common(20))\n\n# Barplot that shows the top 20 Unigrams\nplt.rcParams['figure.figsize'] = [20, 12]\nfig, ax = plt.subplots(1, 2)\nsns.set(font_scale = 1.3, style = 'darkgrid')\n\nsns_sincere = sns.barplot(x = df_freq_sincere[1], y = df_freq_sincere[0], color = 'darkslateblue', ax = ax[0])\nsns_insincere = sns.barplot(x = df_freq_insincere[1], y = df_freq_insincere[0], color = 'cadetblue', ax = ax[1])\n\n# Setting axes\nsns_sincere.set(title = \"Top 20 Unigrams of the Sincere Questions\", ylabel = \"Unigrams\", xlabel = \"Frequency\")\nsns_insincere.set(title = \"Top 20 Unigrams of the Insincere Questions\", xlabel = \"Frequency\", ylabel = \"\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bigrams\nsns.set(style = 'whitegrid', font_scale = 1.3)\nbigram_insincere = ngrams(tokenized_insincere, 2)\nbigram_sincere = ngrams(tokenized_sincere, 2)\n\n# Making the Frequency chart for the Bigrams\nfrequency_insincere = Counter(bigram_insincere) \nfrequency_sincere = Counter(bigram_sincere)\n\ndf_freq_insincere = pd.DataFrame(frequency_insincere.most_common(20))\ndf_freq_sincere = pd.DataFrame(frequency_sincere.most_common(20))\n\n# Barplot that shows the top 20 Bigrams\nplt.rcParams['figure.figsize'] = [20, 12]\nfig, ax = plt.subplots(1, 2)\nsns.set(font_scale = 1.3, style = 'darkgrid')\n\nsns_sincere = sns.barplot(x = df_freq_sincere[1], y = df_freq_sincere[0], color = 'darkslateblue', ax = ax[0])\nsns_insincere = sns.barplot(x = df_freq_insincere[1], y = df_freq_insincere[0], color = 'cadetblue', ax = ax[1])\n\n# Setting axes\nsns_sincere.set(title = \"Top 20 Bigrams of the Sincere Questions\", ylabel = \"Bigrams\", xlabel = \"Frequency\")\nsns_insincere.set(title = \"Top 20 Bigrams of the Insincere Questions\", xlabel = \"Frequency\", ylabel = \"\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Distribution of Polarity and Subjectivity of the questions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Polarity of the questions \ndef sentiment_polarity(questions):\n    # Sentiment polarity of the questions\n    pol = []\n    for i in questions:\n        analysis = TextBlob(i)\n        pol.append(analysis.sentiment.polarity)\n    return pol\n\n# Subjectivity of the questions\ndef sentiment_subjectivity(questions):\n    # Sentiment subjectivity of the questions\n    sub = []\n    for i in questions:\n        analysis = TextBlob(i)\n        sub.append(analysis.sentiment.subjectivity)\n    return sub\n\n# Appeding the polarity and subjectivity of the text in the dataframe\ndf['polarity'] = sentiment_polarity(df['question_text'])\ndf['subjectivity'] = sentiment_subjectivity(df['question_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution plot\nplt.rcParams['figure.figsize'] = [20, 10]\nsns.set(style = 'white', font_scale = 1.5)\n\ndist_ = sns.distplot(df['polarity'], kde = False, color = 'deepskyblue')\n# Setting the axes\ndist_.set(title = 'Distribution of the Polarity', xlabel = 'Polarity', ylabel = 'Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution plot\nplt.rcParams['figure.figsize'] = [20, 10]\nsns.set(style = 'white', font_scale = 1.5)\ndist_ = sns.distplot(df['subjectivity'], kde = False, color = 'red')\n# Setting the axes\ndist_.set(title = 'Distribution of the Subjectivity', xlabel = 'Subjectivity', ylabel = 'Frequency');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Changing the target values for BERT\ndf['target'] = df['target'].map({'Insincere' : 1, 'Sincere' : 0})\n\n# Dropping polarity and subjectivity as it's not going to be used in training BERT\ndf.drop(columns = ['polarity', 'subjectivity'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Contraction Dictionary for the expansion\ncontractions_dict = {\n    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\",\n    \"could've\": \"could have\", \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\",\n    \"doesn’t\": \"does not\", \"don't\": \"do not\", \"don’t\": \"do not\", \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\",\n    \"haven't\": \"have not\", \"he'd\": \"he had\", \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he'll've\": \"he will have\", \"he's\": \"he is\",\n    \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"i'd\": \"i would\", \"i'd've\": \"i would have\",\n    \"i'll\": \"i will\", \"i'll've\": \"i will have\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\",\n    \"it'll\": \"it will\", \"it'll've\": \"it will have\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\",\"might've\": \"might have\",\n    \"mightn't\": \"might not\", \"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\",\n    \"needn't\": \"need not\", \"needn't've\": \"need not have\", \"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\",\n    \"shan't\": \"shall not\",\"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\",\n    \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\",\n    \"shouldn't've\": \"should not have\", \"so've\": \"so have\", \"so's\": \"so is\", \"that'd\": \"that would\", \"that'd've\": \"that would have\",\n    \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"they'd\": \"they would\",\n    \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\",\n    \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\",\n    \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",\n    \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n    \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\",\n    \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\",\n    \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y’all\": \"you all\", \"y'all'd\": \"you all would\",\n    \"y'all'd've\": \"you all would have\", \"y'all're\": \"you all are\", \"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\",\n    \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\", \"ain’t\": \"am not\", \"aren’t\": \"are not\",\n    \"can’t\": \"cannot\", \"can’t’ve\": \"cannot have\", \"’cause\": \"because\", \"could’ve\": \"could have\", \"couldn’t\": \"could not\", \"couldn’t’ve\": \"could not have\",\n    \"didn’t\": \"did not\", \"doesn’t\": \"does not\", \"don’t\": \"do not\", \"don’t\": \"do not\", \"hadn’t\": \"had not\", \"hadn’t’ve\": \"had not have\",\n    \"hasn’t\": \"has not\", \"haven’t\": \"have not\", \"he’d\": \"he had\", \"he’d’ve\": \"he would have\", \"he’ll\": \"he will\", \"he’ll’ve\": \"he will have\",\n    \"he’s\": \"he is\", \"how’d\": \"how did\", \"how’d’y\": \"how do you\", \"how’ll\": \"how will\", \"how’s\": \"how is\", \"i’d\": \"i would\", \"i’d’ve\": \"i would have\",\n    \"i’ll\": \"i will\", \"i’ll’ve\": \"i will have\", \"i’m\": \"i am\", \"i’ve\": \"i have\", \"isn’t\": \"is not\", \"it’d\": \"it would\", \"it’d’ve\": \"it would have\",\n    \"it’ll\": \"it will\", \"it’ll’ve\": \"it will have\", \"it’s\": \"it is\", \"let’s\": \"let us\", \"ma’am\": \"madam\", \"mayn’t\": \"may not\",\n    \"might’ve\": \"might have\", \"mightn’t\": \"might not\", \"mightn’t’ve\": \"might not have\", \"must’ve\": \"must have\", \"mustn’t\": \"must not\",\n    \"mustn’t’ve\": \"must not have\", \"needn’t\": \"need not\", \"needn’t’ve\": \"need not have\", \"o’clock\": \"of the clock\",\n    \"oughtn’t\": \"ought not\", \"oughtn’t’ve\": \"ought not have\", \"shan’t\": \"shall not\", \"sha’n’t\": \"shall not\", \"shan’t’ve\": \"shall not have\",\n    \"she’d\": \"she would\", \"she’d’ve\": \"she would have\", \"she’ll\": \"she will\", \"she’ll’ve\": \"she will have\", \"she’s\": \"she is\",\n    \"should’ve\": \"should have\", \"shouldn’t\": \"should not\", \"shouldn’t’ve\": \"should not have\", \"so’ve\": \"so have\", \"so’s\": \"so is\",\n    \"that’d\": \"that would\", \"that’d’ve\": \"that would have\", \"that’s\": \"that is\", \"there’d\": \"there would\", \"there’d’ve\": \"there would have\",\n    \"there’s\": \"there is\", \"they’d\": \"they would\", \"they’d’ve\": \"they would have\", \"they’ll\": \"they will\", \"they’ll’ve\": \"they will have\",\n    \"they’re\": \"they are\", \"they’ve\": \"they have\", \"to’ve\": \"to have\", \"wasn’t\": \"was not\", \"we’d\": \"we would\", \"we’d’ve\": \"we would have\",\n    \"we’ll\": \"we will\", \"we’ll’ve\": \"we will have\", \"we’re\": \"we are\", \"we’ve\": \"we have\", \"weren’t\": \"were not\", \"what’ll\": \"what will\",\n    \"what’ll’ve\": \"what will have\", \"what’re\": \"what are\", \"what’s\": \"what is\", \"what’ve\": \"what have\", \"when’s\": \"when is\",\n    \"when’ve\": \"when have\", \"where’d\": \"where did\", \"where’s\": \"where is\", \"where’ve\": \"where have\", \"who’ll\": \"who will\",\n    \"who’ll’ve\": \"who will have\", \"who’s\": \"who is\", \"who’ve\": \"who have\",\"why’s\": \"why is\", \"why’ve\": \"why have\", \"will’ve\": \"will have\",\n    \"won’t\": \"will not\", \"won’t’ve\": \"will not have\", \"would’ve\": \"would have\", \"wouldn’t\": \"would not\", \"wouldn’t’ve\": \"would not have\",\n    \"y’all\": \"you all\", \"y’all\": \"you all\", \"y’all’d\": \"you all would\", \"y’all’d’ve\": \"you all would have\", \"y’all’re\": \"you all are\",\n    \"y’all’ve\": \"you all have\", \"you’d\": \"you would\", \"you’d’ve\": \"you would have\", \"you’ll\": \"you will\", \"you’ll’ve\": \"you will have\",\n    \"you’re\": \"you are\", \"you’re\": \"you are\", \"you’ve\": \"you have\"\n}\n\ncontractions_re = re.compile('(%s)' % '|'.join(contractions_dict.keys()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to clean the html from the Questions\ndef cleanhtml(raw_html):\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, '', raw_html)\n    return cleantext\n\n# Function expand the contractions if there's any\ndef expand_contractions(s, contractions_dict=contractions_dict):\n    def replace(match):\n        return contractions_dict[match.group(0)]\n    return contractions_re.sub(replace, s)\n\n# Function to preprocess the questions\ndef preprocessing(question):\n    global question_sent\n    \n    # Converting to lowercase\n#     question = question.str.lower()\n    \n    # Removing the HTML\n    question = question.apply(lambda x: cleanhtml(x))\n    \n    # Removing the email ids\n    question = question.apply(lambda x: re.sub('\\S+@\\S+','', x))\n    \n    # Removing The URLS\n    question = question.apply(lambda x: re.sub(\"((http\\://|https\\://|ftp\\://)|(www.))+(([a-zA-Z0-9\\.-]+\\.[a-zA-Z]{2,4})|([0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}))(/[a-zA-Z0-9%:/-_\\?\\.'~]*)?\",'', x))\n    \n    # Mapping the contractions\n    question = question.apply(lambda x: expand_contractions(x))\n    \n    # Stripping the possessives\n    question = question.apply(lambda x: x.replace(\"'s\", ''))\n    question = question.apply(lambda x: x.replace('’s', ''))\n    question = question.apply(lambda x: x.replace(\"\\'s\", ''))\n    question = question.apply(lambda x: x.replace(\"\\’s\", ''))\n    \n    # Removing the Trailing and leading whitespace and double spaces\n    question = question.apply(lambda x: re.sub(' +', ' ',x))\n    \n    # Removing punctuations from the question\n    question = question.apply(lambda x: ''.join(word for word in x if word not in punctuation))\n    \n    # Removing the Trailing and leading whitespace and double spaces again as removing punctuation might lead to a white space\n    question = question.apply(lambda x: re.sub(' +', ' ',x))\n    \n    # Removing the Stopwords\n    # question = question.apply(lambda x: ' '.join(word for word in x.split() if word not in stop_words))\n    \n    return question","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['processed_text'] = preprocessing(df['question_text'])\n\n# Lemmatization using WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\ndf['processed_text'] = df['processed_text'].apply(lambda x: \" \".join(lemmatizer.lemmatize(word) for word in x.split()))\n\ndf['processed_text'] = df['processed_text'].astype('str')\ndf = resample(df, random_state = RANDOM_SEED)\n\ndf.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## BERT Modeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bert Parameters\n\nPRE_TRAINED_MODEL_NAME = 'bert-base-cased'\nMAX_LEN = 160\nBATCH_SIZE = 16\nEPOCHS = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Bert Tokenizer\ntokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\n# Bert Tokenizer with example\nsample_txt = 'Corona Sucks so bad,my final year is kinda ruined, man!!'\n\ntokens = tokenizer.tokenize(sample_txt)\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\nprint(f' Sentence: {sample_txt}')\nprint(f'   Tokens: {tokens}')\nprint(f'Token IDs: {token_ids}')\n\nencoding = tokenizer.encode_plus(\n  sample_txt,\n  max_length=32,\n  add_special_tokens=True, # Add '[CLS]' and '[SEP]'\n  return_token_type_ids=False,\n  pad_to_max_length=True,\n  return_attention_mask=True,\n  return_tensors='pt',  # Return PyTorch tensors\n)\nencoding.keys()","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"# Using the Bert tokenizer for encoding the questions\ntoken_lens = []\nfor txt in tqdm(df.processed_text):\n    tokens = tokenizer.encode(txt, max_length=512, truncation = True)\n    token_lens.append(len(tokens))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of tokens\nsns.distplot(token_lens)\nplt.xlim([0, 256]);\nplt.xlabel('Token count');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preparing the dataset with input ids and attention_masks\n\nclass GPquestionDataset(Dataset):\n    \n    def __init__(self, questions, targets, tokenizer, max_len):\n        self.questions = questions\n        self.targets = targets\n        self.tokenizer = tokenizer\n        self.max_len = max_len\n    def __len__(self):\n        return len(self.questions)\n    def __getitem__(self, item):\n        question = str(self.questions[item])\n        target = self.targets[item]\n        encoding = self.tokenizer.encode_plus(\n          question,\n          add_special_tokens=True,\n          max_length=self.max_len,\n          return_token_type_ids=False,\n          pad_to_max_length=True,\n          return_attention_mask=True,\n          return_tensors='pt',\n          truncation=True  \n        )\n        return {\n          'question_text': question,\n          'input_ids': encoding['input_ids'].flatten(),\n          'attention_mask': encoding['attention_mask'].flatten(),\n          'targets': torch.tensor(target, dtype=torch.long)\n      }","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"# Splitting the dataset for training, validation and testing\n\ndf_train, df_test = train_test_split(\n  df,\n  test_size = 0.4,\n  random_state = RANDOM_SEED\n)\ndf_val, df_test = train_test_split(\n  df_test,\n  test_size = 0.6,\n  random_state = RANDOM_SEED\n)\nprint (\"The shape of the training dataset : \", df_train.shape)\nprint (\"The shape of the validation dataset : \", df_val.shape)\nprint (\"The shape of the testing dataset : \", df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the data loader for training, validation and testing using the pytorch DataLoader\n\ndef create_data_loader(df, tokenizer, max_len, batch_size):\n    ds = GPquestionDataset(\n      questions = df.processed_text.to_numpy(),\n      targets = df.target.to_numpy(),\n      tokenizer = tokenizer,\n      max_len = max_len\n    )\n    return DataLoader(\n      ds,\n      batch_size = batch_size,\n      num_workers = 0\n    )\n\ntrain_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\nval_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\ntest_data_loader = create_data_loader(df_test, tokenizer, MAX_LEN, BATCH_SIZE)\n\ndata = next(iter(train_data_loader))\ndata.keys()\n\nprint (len(train_data_loader))\nprint (len(val_data_loader))\nprint (len(test_data_loader))","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"# Shape of the torch\nprint(data['input_ids'].shape)\nprint(data['attention_mask'].shape)\nprint(data['targets'].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Using the Bert Model 'bert-base-cased'\n\nbert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n\nlast_hidden_state, pooled_output = bert_model(\n  input_ids=encoding['input_ids'],\n  attention_mask=encoding['attention_mask']\n)\n\nprint (last_hidden_state.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Model with BERT layer and Dropout\n\nclass QuestionClassifier(nn.Module):\n    def __init__(self, n_classes):\n        super(QuestionClassifier, self).__init__()\n        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n        self.drop = nn.Dropout(p=0.3)\n        self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n    def forward(self, input_ids, attention_mask):\n        _, pooled_output = self.bert(\n          input_ids=input_ids,\n          attention_mask=attention_mask\n        )\n        output = self.drop(pooled_output)\n        return self.out(output)\n\nmodel = QuestionClassifier(2)\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"input_ids = data['input_ids'].to(device)\nattention_mask = data['attention_mask'].to(device)\n\nprint(input_ids.shape) # batch size x seq length\nprint(attention_mask.shape) # batch size x seq length\n\nmodel(input_ids, attention_mask)\n\noptimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\ntotal_steps = len(train_data_loader) * EPOCHS\nscheduler = get_linear_schedule_with_warmup(\n  optimizer,\n  num_warmup_steps=0,\n  num_training_steps=total_steps\n)\nloss_fn = nn.CrossEntropyLoss().to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training function\n\ndef train_epoch(\n    model,\n    data_loader,\n    loss_fn,\n    optimizer,\n    device,\n    scheduler,\n    n_examples\n):  \n    # Putting the model in the training mode\n    model = model.train()\n    \n    losses = []\n    correct_predictions = 0\n    \n    for d in data_loader:\n        input_ids = d[\"input_ids\"].to(device)\n        attention_mask = d[\"attention_mask\"].to(device)\n        targets = d[\"targets\"].to(device)\n        outputs = model(\n          input_ids=input_ids,\n          attention_mask=attention_mask\n        )\n        _, preds = torch.max(outputs, dim=1)\n        loss = loss_fn(outputs, targets)\n        correct_predictions += torch.sum(preds == targets)\n        losses.append(loss.item())\n        loss.backward()\n        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n        \n    return correct_predictions.double() / n_examples, np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation Functions\ndef eval_model(model, data_loader, loss_fn, device, n_examples):\n    \n    # Putting the model in the Evaluation mode\n    model = model.eval()\n    \n    losses = []\n    correct_predictions = 0\n    \n    with torch.no_grad():\n        for d in data_loader:\n            input_ids = d[\"input_ids\"].to(device)\n            attention_mask = d[\"attention_mask\"].to(device)\n            targets = d[\"targets\"].to(device)\n            outputs = model(\n              input_ids=input_ids,\n              attention_mask=attention_mask\n            )\n            _, preds = torch.max(outputs, dim=1)\n            loss = loss_fn(outputs, targets)\n            correct_predictions += torch.sum(preds == targets)\n            losses.append(loss.item())\n            \n    return correct_predictions.double() / n_examples, np.mean(losses)","execution_count":null,"outputs":[]},{"metadata":{"tags":[],"trusted":true},"cell_type":"code","source":"%%time\nhistory = defaultdict(list)\nbest_accuracy = 0\nfor epoch in range(EPOCHS):\n    print(f'Epoch {epoch + 1}/{EPOCHS}')\n    print('-' * 70)\n    train_acc, train_loss = train_epoch(\n      model,\n      train_data_loader,\n      loss_fn,\n      optimizer,\n      device,\n      scheduler,\n      len(df_train)\n    )\n    print(f'Train loss {train_loss} accuracy {train_acc}')\n    val_acc, val_loss = eval_model(\n      model,\n      val_data_loader,\n      loss_fn,\n      device,\n      len(df_val)\n    )\n    print(f'Val   loss {val_loss} accuracy {val_acc}')\n    print()\n    history['train_acc'].append(train_acc)\n    history['train_loss'].append(train_loss)\n    history['val_acc'].append(val_acc)\n    history['val_loss'].append(val_loss)\n    if val_acc > best_accuracy:\n        torch.save(model.state_dict(), 'best_model_state.bin')\n        best_accuracy = val_acc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The accuracy of the model\ntest_acc, _ = eval_model(\n  model,\n  test_data_loader,\n  loss_fn,\n  device,\n  len(df_test)\n)\n\nprint (test_acc)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\n\ndef get_predictions(model, data_loader):\n    model = model.eval()\n    question_texts = []\n    predictions = []\n    prediction_probs = []\n    real_values = []\n    with torch.no_grad():\n        for d in data_loader:\n            texts = d[\"question_text\"]\n            input_ids = d[\"input_ids\"].to(device)\n            attention_mask = d[\"attention_mask\"].to(device)\n            targets = d[\"targets\"].to(device)\n            outputs = model(\n              input_ids=input_ids,\n              attention_mask=attention_mask\n            )\n            _, preds = torch.max(outputs, dim=1)\n            question_texts.extend(texts)\n            predictions.extend(preds)\n            prediction_probs.extend(outputs)\n            real_values.extend(targets)\n    predictions = torch.stack(predictions).cpu()\n    prediction_probs = torch.stack(prediction_probs).cpu()\n    real_values = torch.stack(real_values).cpu()\n    return question_texts, predictions, prediction_probs, real_values\n\ny_question_texts, y_pred, y_pred_probs, y_test = get_predictions(\n  model,\n  test_data_loader\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First 10 predictions and text\ni = 0\nfor t, pred, prob in zip(y_question_texts, y_pred, y_pred_probs):\n    print (t, end = \"   \")\n    print (pred, end = \"   \")\n    print (prob)\n    i+=1\n    if i == 10:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Classification_report\nprint(classification_report(y_test, y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Confusion matrix\n\nconf = confusion_matrix(y_test, y_pred)\nprint (conf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# f1_score\nprint (f1_score(y_test, y_pred))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}