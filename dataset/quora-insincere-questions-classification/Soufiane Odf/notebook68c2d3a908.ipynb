{"cells":[{"metadata":{"id":"DME5GLCEUOCw"},"cell_type":"markdown","source":"# **Quora Insincere Questions Classification**"},{"metadata":{"id":"RU9vZAg6UgxX"},"cell_type":"markdown","source":"using Deep learning and NLP"},{"metadata":{"id":"WmFVs5qMTLyX","outputId":"6cd809fe-4d47-4b2b-e604-35cc2c2ef7b4","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport re\nimport spacy\nimport nltk\nfrom nltk.stem.snowball import SnowballStemmer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Embedding,Bidirectional,LSTM,Dropout,Conv1D,MaxPooling1D,Dense\nfrom keras import callbacks \nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly\nimport plotly.offline as py\nimport plotly.graph_objs as go","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('../input/quora-insincere-questions-classification/train.csv')\ntest_data = pd.read_csv('/kaggle/input/quora-insincere-questions-classification/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Check for missing values:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### **Check for empty strings:**"},{"metadata":{"trusted":true},"cell_type":"code","source":"blanks = []\n\nfor i, qid, question_text, target in train_data.itertuples():\n    if type(question_text)==str:\n        if question_text.isspace():\n            blanks.append(i)\n        \nprint(len(blanks), 'blanks: ', blanks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Train set shape : \",train_data.shape)\nprint(\"Test set shape : \",test_data.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# no. of observations with distinct targets\ncount_targets = train_data['target'].value_counts()\n\n# setting up the above results in form of a bar chart using python graph objects module\ntrace = go.Bar(x = count_targets.index, y = count_targets, marker = dict(color = count_targets.values))\n# setting up parameters for layout of the bar chart \nlayout = go.Layout(title = 'Target counts', font = dict(size=12))\n\ndata = [trace] \nfig = go.Figure(data = data, layout = layout) # inserting defined traces and layout as parameters of the plotly figure method\npy.iplot(fig, filename = \"TargetCount\") # Plotting the bar chart\n\n\n# Further, plotting the observations for each class in form of a pie chart\n\nlabels = (np.array(count_targets.index)) # defining the targets of the dataset in the labels object\n# defining the proportions of count of each target out of total count\nproportions = (np.array((count_targets/count_targets.sum())*100)) \n\n# setting up our results as parameters in the trace object i.e. the data to plot\ntrace = go.Pie(labels = labels, values = proportions)\nlayout = go.Layout(                       \n    title = \"Target proportion pie\",     # pie chart layout specifications \n    font = dict(size = 12),\n    width = 600,\n    height = 600)\n\ndata = [trace]\nfig = go.Figure(data = data, layout = layout) \npy.iplot(fig, filename = \"usertype\")  # Plotting the pie chart","execution_count":null,"outputs":[]},{"metadata":{"id":"Njqman7Pg5Yp"},"cell_type":"markdown","source":"### Clean Text"},{"metadata":{"id":"mRz9Mi1OgpIR","trusted":true},"cell_type":"code","source":"nlp = spacy.load('en',disable=['parser', 'tagger','ner'])\n\nnlp.max_length = 16981599","execution_count":null,"outputs":[]},{"metadata":{"id":"Q9pkxmUfsN-X","trusted":true},"cell_type":"code","source":"puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \n          \"'\",  '&', '/', '[', ']', '>', '<', '%', '=', '#', '+', \n          '\\\\',  '§', '″', '′','¿','═', '$', '^', '*', '@', '^', '_', \n          '`', '{', '}', '~']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def replace_numbers(sentence):\n    # Replace numbers by hash characters\n    sentence = re.sub('[0-9]{5,}', '#####', sentence)\n    sentence = re.sub('[0-9]{4}', '####', sentence)\n    sentence = re.sub('[0-9]{3}', '###', sentence)\n    sentence = re.sub('[0-9]{2}', '##', sentence)\n    return sentence","execution_count":null,"outputs":[]},{"metadata":{"id":"ov1rrWpyCQZc"},"cell_type":"markdown","source":"## Stemming"},{"metadata":{"id":"AEO3nki2CUaK","trusted":true},"cell_type":"code","source":"s_stemmer = SnowballStemmer(language='english')","execution_count":null,"outputs":[]},{"metadata":{"id":"zzvVg_e5HOFt"},"cell_type":"markdown","source":"## Stop words"},{"metadata":{"id":"Dyh2AwXkHP5T","outputId":"42905818-4894-462e-b835-ce01246a7bd6","trusted":true},"cell_type":"code","source":"stop_words = nlp.Defaults.stop_words\n\nprint(nlp.Defaults.stop_words)\nprint(len(nlp.Defaults.stop_words))","execution_count":null,"outputs":[]},{"metadata":{"id":"9NtUrj6rjqfH"},"cell_type":"markdown","source":"### Spliting data"},{"metadata":{"id":"ZgM48aLqjpvv","trusted":true},"cell_type":"code","source":"train_input = train_data['question_text'].apply(replace_numbers)\ntrain_label = train_data['target']\n\ntest_input  = test_data['question_text'].apply(replace_numbers)\n\ntrain_input_rsw_punc_stem = [[s_stemmer.stem(token.text.lower()) for token in nlp(question) if token.text not in puncts and token.text not in stop_words] for question in train_input]\n\ntest_input_rsw_punc_stem  = [[s_stemmer.stem(token.text.lower()) for token in nlp(question) if token.text not in puncts and token.text not in stop_words] for question in test_input]","execution_count":null,"outputs":[]},{"metadata":{"id":"Rx_wsc0Qazhg","outputId":"0dbc3148-419a-4a5b-e8f4-cad9618be61d","trusted":true},"cell_type":"code","source":"print(train_label.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"id":"OgCctibX8kZ4","outputId":"81c6eae1-fb7e-4293-f4dc-55676077c38d","trusted":true},"cell_type":"code","source":"train_input[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"M4k-gvw6valq","outputId":"358cbd06-15f6-4dd9-a7aa-3653e51219b6","trusted":true},"cell_type":"code","source":"train_input_rsw_punc_stem[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input_rsw_punc_stem[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"gn0oNnzui9kV"},"cell_type":"markdown","source":"# KerasX"},{"metadata":{"id":"0vi_Q_yojBCO"},"cell_type":"markdown","source":"### Keras Tokenization"},{"metadata":{"id":"vEe8_qkgjISR","trusted":true},"cell_type":"code","source":"# integer encode sequences of words\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(train_input_rsw_punc_stem)\nsequences = tokenizer.texts_to_sequences(train_input_rsw_punc_stem)\n\n# tokenizer_test = Tokenizer()\n# tokenizer_test.fit_on_texts(test_input_rsw_punc_stem)\n# sequences_test = tokenizer_test.texts_to_sequences(test_input_rsw_punc_stem)\n\ntokenizer.fit_on_texts(test_input_rsw_punc_stem)\nsequences_test = tokenizer.texts_to_sequences(test_input_rsw_punc_stem)","execution_count":null,"outputs":[]},{"metadata":{"id":"5DK3-vBaKyNW"},"cell_type":"markdown","source":"## Padding"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_length = 55","execution_count":null,"outputs":[]},{"metadata":{"id":"TzZgZA4aumA9","trusted":true},"cell_type":"code","source":"train_input_padded = pad_sequences(sequences, maxlen=max_length, padding='post')\n\ntest_input_padded = pad_sequences(sequences_test, maxlen=max_length, padding='post')\n\nprint(train_input_padded.shape)\nprint(test_input_padded.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"tY8MfZv0u3ua","outputId":"5982d661-5cd9-4779-8815-803b7de2ed09","trusted":true},"cell_type":"code","source":"tokenizer.index_word","execution_count":null,"outputs":[]},{"metadata":{"id":"N4GD26LvwHCl","outputId":"03af9dd8-5909-4a6a-8dd7-1c206944cfce","trusted":true},"cell_type":"code","source":"tokenizer.word_counts","execution_count":null,"outputs":[]},{"metadata":{"id":"7okMM0irwRv9","outputId":"30c79e58-fdce-4cb8-db10-9a328ca0703f","trusted":true},"cell_type":"code","source":"vocabulary_size = len(tokenizer.word_counts)\nvocabulary_size","execution_count":null,"outputs":[]},{"metadata":{"id":"fvo3htEjwjJb"},"cell_type":"markdown","source":"### Convert to Numpy Matrix"},{"metadata":{"id":"R2WqGm78wmcg","trusted":true},"cell_type":"code","source":"train_input_padded = np.array(train_input_padded)\n\ntest_input_padded = np.array(test_input_padded)","execution_count":null,"outputs":[]},{"metadata":{"id":"pCFu8-RvwoO4","outputId":"9ec06860-f206-4bd3-c18c-faf59ad877de","trusted":true},"cell_type":"code","source":"train_input_padded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_input_padded","execution_count":null,"outputs":[]},{"metadata":{"id":"-k3CJH_jC1WV","trusted":true},"cell_type":"code","source":"### splitting dataset in to train_set and val_set\nx_train,x_val,y_train,y_val = train_test_split(train_input_padded, train_label, test_size=0.1, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"id":"wJY2vMFlF0UD"},"cell_type":"markdown","source":"# Creating an LSTM based model"},{"metadata":{"id":"sg5zZSf7lflf","trusted":true},"cell_type":"code","source":"def create_model(vocabulary_size, max_length):\n    model = Sequential()\n    model.add(Embedding(vocabulary_size, 300, input_length=max_length, trainable=True))\n    model.add(Bidirectional(LSTM(256,return_sequences=True)))\n    model.add(Dropout(0.2))\n    model.add(Conv1D(100,5,activation='relu'))\n    model.add(MaxPooling1D(pool_size=4))\n    model.add(LSTM(128))\n    model.add(Dropout(0.4))\n    model.add(Dense(1,activation='sigmoid'))\n    \n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n   \n    model.summary()\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"id":"qbS0-vFhlo3p","outputId":"88ff2f95-cf0b-4ba9-9b7f-f7f3564bd971","trusted":true},"cell_type":"code","source":"model = create_model(vocabulary_size + 1, max_length)","execution_count":null,"outputs":[]},{"metadata":{"id":"kg8Wog-0ltwt"},"cell_type":"markdown","source":"## Fit (Train) the Model"},{"metadata":{"id":"8nUNM_kHlq6u","outputId":"70b50d05-761f-4121-ede9-877550d09722","trusted":true},"cell_type":"code","source":"es = callbacks.EarlyStopping(patience=2)\nmc = callbacks.ModelCheckpoint('./w.h5', save_best_only=True, save_weights_only=True)\n\nhistory = model.fit(x_train, y_train, epochs=128, validation_data=(x_val,y_val),batch_size=1024, verbose=1,callbacks=[es, mc])","execution_count":null,"outputs":[]},{"metadata":{"id":"esVikyzDiOsG","trusted":true},"cell_type":"code","source":"def plot_loss_acc(history_dict):\n    acc = history_dict['accuracy']\n    val_acc = history_dict['val_accuracy']\n    loss = history_dict['loss']\n    val_loss = history_dict['val_loss']\n\n    epochs = range(1, len(acc) + 1)\n\n    plt.plot(epochs, loss, 'r', label='Training loss')\n    plt.plot(epochs, val_loss, 'b', label='Validation loss')\n    plt.title('Training and validation loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n    plt.plot(epochs, acc, 'r', label='Training acc')\n    plt.plot(epochs, val_acc, 'b', label='Validation acc')\n    plt.title('Training and validation accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(loc='lower right')\n    plt.ylim((0.5,1))\n    plt.show()\n    \nplot_loss_acc(history.history)","execution_count":null,"outputs":[]},{"metadata":{"id":"RvUlFNdzl3Id"},"cell_type":"markdown","source":"# Evaluating Model Performance"},{"metadata":{"id":"RJ9-_kvFmBXr","trusted":true},"cell_type":"code","source":"model.evaluate(x_val,y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('./w.h5')\nmodel.evaluate(x_val,y_val)","execution_count":null,"outputs":[]},{"metadata":{"id":"wkCri7gEmERz","trusted":true},"cell_type":"code","source":"predictions = model.predict_classes(x_val)","execution_count":null,"outputs":[]},{"metadata":{"id":"cJ7YQInUmF8r","trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"id":"1TnfCpYimM6s","trusted":true},"cell_type":"code","source":"confusion_matrix(y_val,predictions)","execution_count":null,"outputs":[]},{"metadata":{"id":"hQu0NwKSmOcF","trusted":true},"cell_type":"code","source":"print(classification_report(y_val,predictions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_test = model.predict_classes(test_input_padded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y = (predictions_test>0.9).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame({\"qid\":test_data[\"qid\"].values})\nsubmission[\"prediction\"] = test_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission[\"prediction\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}