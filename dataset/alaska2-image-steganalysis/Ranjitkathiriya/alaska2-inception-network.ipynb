{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport glob\n\nimport cv2\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\n\nimport random\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# from PIL import Image\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class My():\n    \n    def __init__(self,NUM_EPOCHS):\n        self.NUM_EPOCHS = NUM_EPOCHS\n        \n    \n    def getData(self,path,dataset_length):\n        files_path = [path+\"JMiPOD/*.jpg\",path+\"JUNIWARD/*.jpg\",path+\"UERD/*.jpg\"]\n    \n        paths_algorithm = []\n        for i in files_path:\n            paths_algorithm += glob.glob(i)\n        # Getting Random Images from all folders - With Algorithm (JMiPOD,JUNIWARD,UERD) \n        random_pathSelect_Algo =  np.random.randint(0, len(paths_algorithm), dataset_length) \n        with_algorithm_image = []\n        for i in random_pathSelect_Algo:\n            with_algorithm_image.append(paths_algorithm[i])\n        # Getting Random Images from a folder - Without Algorithm (Cover Folder)\n        paths_non_algorithm = glob.glob(path+\"Cover/*.jpg\")\n        random_pathSelect_nonAlgo =  np.random.randint(0, len(paths_non_algorithm), dataset_length)\n        \n        without_algorithm_image = []\n        for i in random_pathSelect_nonAlgo:\n            without_algorithm_image.append(paths_non_algorithm[i])\n            \n        # Joining both data with their labels\n        train_paths = with_algorithm_image + without_algorithm_image\n        train_labels = list([1] * len(with_algorithm_image) + [0] * len(without_algorithm_image))\n        # extracting path and converting it to numpy\n        images = np.zeros((len(train_paths),128,128,3))\n        labels = np.zeros(len(train_labels))\n\n        for i in range(len(train_paths)):\n            images[i] = cv2.cvtColor(cv2.resize(cv2.imread(train_paths[i]),(128,128)),cv2.COLOR_BGR2RGB)\n            labels[i] = train_labels[i]\n\n        return images,labels\n    \n    def Inception(self,width, height, depth, classes):\n        print(\"Inception Network ...\")\n        inputShape = (height, width, depth)\n        \n        base_model = keras.applications.inception_v3.InceptionV3(weights= None, include_top=False, input_shape= inputShape)\n        x = base_model.output\n        x = keras.layers.GlobalAveragePooling2D()(x)\n        x = keras.layers.Dropout(0.7)(x)\n        predictions = keras.layers.Dense(classes, activation= 'sigmoid')(x)\n        model = keras.models.Model(inputs = base_model.input, outputs = predictions)\n        opt = tf.keras.optimizers.Adam(lr=0.0001)\n        model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n#         model.summary()\n        return model\n    \n    def compile_fit_data_aug(self,model,train_generator,trainX, testX, testY,callbacks_list):\n\n        print(\"Training network...\")\n        H = model.fit(X_train,y_train,validation_data=(testX, testY),epochs=self.NUM_EPOCHS,\n                    steps_per_epoch=len(trainX)/32, verbose=1,callbacks=callbacks_list)\n        print (\"Test Data Loss and Accuracy: \", model.evaluate(testX, testY))\n        \n        return H\n    \n    def plotImage(self,H):\n        # plot the training loss and accuracy\n        plt.style.use(\"ggplot\")\n        plt.figure()\n        plt.plot(np.arange(0, self.NUM_EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n        plt.plot(np.arange(0, self.NUM_EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n        plt.plot(np.arange(0, self.NUM_EPOCHS), H.history[\"accuracy\"], label=\"train_acc\")\n        plt.plot(np.arange(0, self.NUM_EPOCHS), H.history[\"val_accuracy\"], label=\"val_acc\")\n        plt.title(\"Training Loss and Accuracy\")\n        plt.xlabel(\"Epoch #\")\n        plt.ylabel(\"Loss/Accuracy\")\n        plt.legend()\n        plt.show()\n        \n    def data_augmentation_2(self,trainX,trainY):\n        trainDataGenerator = ImageDataGenerator(rotation_range=40,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        rescale=1./255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True,\n        fill_mode='nearest')\n        train_generator = trainDataGenerator.flow(trainX,trainY, batch_size=32)\n        return train_generator\n    \n    def checkpoint_model_impovement(self):\n        filepath=  \"./Model_Save.hdf5\"\n        checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n        # checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n        callbacks_list = [checkpoint]\n        return callbacks_list\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Path = \"../input/alaska2-image-steganalysis/\"\nTrain_data_generate = 2000\nTest_data_generate = 200 \nNUM_EPOCHS = 250\n\nmy = My(NUM_EPOCHS)\nX_train,y_train = my.getData(Path,Train_data_generate)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test,y_test = my.getData(Path,Test_data_generate)\n\nmodel = my.Inception(width=128, height=128, depth=3, classes=1)\n\n# model.fit(X_train,y_train,10\ntrain_generator = my.data_augmentation_2(X_train, y_train)\ncallbacks_list = my.checkpoint_model_impovement()\n                           \nH = my.compile_fit_data_aug(model,train_generator,X_train, X_test,y_test,callbacks_list)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my.plotImage(H)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\nimport glob\n\nimport cv2\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def Inception(width, height, depth, classes):\n \n    print(\"Inception Network ...\")\n    inputShape = (height, width, depth)\n\n    base_model = keras.applications.inception_v3.InceptionV3(weights= None, include_top=False, input_shape= inputShape)\n    x = base_model.output\n    x = keras.layers.GlobalAveragePooling2D()(x)\n    x = keras.layers.Dropout(0.7)(x)\n    predictions = keras.layers.Dense(classes, activation= 'sigmoid')(x)\n    model = keras.models.Model(inputs = base_model.input, outputs = predictions)\n    opt = tf.keras.optimizers.Adam(lr=0.0001)\n    model.compile(loss=\"binary_crossentropy\", optimizer=opt, metrics=[\"accuracy\"])\n#         model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Inception(width=128, height=128, depth=3, classes=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('./Model_Save.hdf5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf = pd.read_csv('../input/alaska2-image-steganalysis/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = glob.glob(\"../input/alaska2-image-steganalysis/Test/*.jpg\")\n# test_path = test_path[:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def data(train_paths,train_labels):\n    images = np.zeros((len(train_paths),128,128,3))\n    labels = np.zeros(len(train_labels))\n    for i in range(len(train_paths)):\n        images[i] = cv2.cvtColor(cv2.resize(cv2.imread(train_paths[i]),(128,128)),cv2.COLOR_BGR2RGB)\n        labels[i] = train_labels[i]\n\n    return images,labels\n\ntest_X, test_y = data(test_path,[0]*len(test_path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = model.predict(test_X, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Label'] = pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('./sample_submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Exit","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image = cv2.cvtColor(cv2.resize(cv2.imread(\"../input/alaska2-image-steganalysis/Test/0001.jpg\"),(256,256)),cv2.COLOR_BGR2RGB)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}