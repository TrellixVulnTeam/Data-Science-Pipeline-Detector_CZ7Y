{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Notebook, Image preprocessing OpenCV library with ALASKA img"},{"metadata":{},"cell_type":"markdown","source":"Create a summary of Image preprocessing OpenCV library and its application result susing ALASKA data as the subject.\n\nNotebooks<br>\nClassification method<br>\nhttps://www.kaggle.com/urayukitaka/notebook-classification-method<br>\nRegression method<br>\nhttps://www.kaggle.com/urayukitaka/notebook-regression-method<br>\nDimension reduction method<br>\nhttps://www.kaggle.com/urayukitaka/notebook-dimension-reduction"},{"metadata":{},"cell_type":"markdown","source":"### Basis Library"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Basic library\nimport numpy as np \nimport pandas as pd \n\n# Data preprocessing\nimport cv2# Open cv\nfrom sklearn.model_selection import train_test_split\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nplt.style.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataloading"},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"/kaggle/input/alaska2-image-steganalysis/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# path\npath_Test = \"/kaggle/input/alaska2-image-steganalysis/Test/\"\npath_juni =  \"/kaggle/input/alaska2-image-steganalysis/JUNIWARD/\"\npath_jmi =  \"/kaggle/input/alaska2-image-steganalysis/JMiPOD\"\npath_cov =  \"/kaggle/input/alaska2-image-steganalysis/Cover/\"\npath_uer = \"/kaggle/input/alaska2-image-steganalysis/UERD/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dir_name = os.listdir(\"/kaggle/input/alaska2-image-steganalysis/\")\ndir_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Drop csv from dir_name\ndir_name = ['Test', 'JUNIWARD', 'JMiPOD', 'Cover', 'UERD']\n\n# Create empty dataframe and list\ndf = pd.DataFrame({})\nlists = []\ncate = []\n\n# get the filenames\nfor dir_ in dir_name:\n    # file name\n    list_ = os.listdir(\"/kaggle/input/alaska2-image-steganalysis/\"+dir_+\"/\")\n    lists = lists+list_\n    # category name\n    cate_ = np.tile(dir_,len(list_))\n    cate = np.concatenate([cate,cate_])\n    \n# insert dataframe\ndf[\"cate\"] = cate\ndf[\"name\"] = lists","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data loading\n# Define data size\nsize = 256\n\n# Create image data list\nimg_data = []\n\n# Data loading\nfor dir_ in dir_name:\n    for name in df[df[\"cate\"]==dir_][\"name\"]:\n        path = \"/kaggle/input/alaska2-image-steganalysis/\"+dir_+\"/\"+name+\"\"\n        img = cv2.imread(path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # Change to color array, BGR⇒RGB\n        image = cv2.resize(img, (size,size), interpolation=cv2.INTER_AREA)\n        img_data.append(image)\n\n# Add to dataframe\ndf[\"img\"] = img_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image check"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image check\ncate_name = df[\"cate\"].value_counts().index\n\nfig, ax = plt.subplots(5,4, figsize=(20,30))\nfor i in range(5):\n    for j in range(4):\n        ax[i,j].imshow(df[df[\"cate\"]==cate_name[i]][\"img\"].values[j])\n        ax[i,j].set_title(cate_name[i])\n        ax[i,j].grid()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Sample image"},{"metadata":{},"cell_type":"markdown","source":"The following images were used as the library for confirming the image effect of each live."},{"metadata":{"trusted":true},"cell_type":"code","source":"# 154631\n# sample image and Red,Green,Blue image\nsample_img = df.reset_index()[\"img\"][10]\n\nred = sample_img.copy()\nred[:,:,(1, 2)] = 0 #Cancel green and blue value to 0\ngreen = sample_img.copy()\ngreen[:,:,(0, 2)] = 0\nblue = sample_img.copy()\nblue[:,:,(0, 1)] = 0\n\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(sample_img)\nax[0].set_title(\"row data\")\nax[1].imshow(red)\nax[1].set_title(\"red\")\nax[2].imshow(green)\nax[2].set_title(\"green\")\nax[3].imshow(blue)\nax[3].set_title(\"blue\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Changing Colorspaces\nHow to convert images from one color-space to another, like BGR ↔ Gray, BGR ↔ HSV, etc.<br>\nIn addition to that, how to create an application to extract a colored object in a video\n\nFor OpneCV's HSV, hue range is [0,179], saturation range is [0,255], and value range is [0,255]. \n\nhttps://docs.opencv.org/master/df/d9d/tutorial_py_colorspaces.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Conversion list\nflags = [i for i in dir(cv2) if i.startswith('COLOR_')]\nprint( flags )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gray, hsv, rgba, hls\ngray = cv2.cvtColor(sample_img, cv2.COLOR_RGB2GRAY)\nhsv = cv2.cvtColor(sample_img, cv2.COLOR_RGB2HSV)\nxyz = cv2.cvtColor(sample_img, cv2.COLOR_RGB2XYZ)\nhls = cv2.cvtColor(sample_img, cv2.COLOR_RGB2HLS)\n\n# imshow\nfig, ax = plt.subplots(1,5, figsize=(20,4))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_img\")\nax[1].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255) # with gray scale, it need to specify color map.\nax[1].set_title(\"gray\")\nax[2].imshow(hsv)\nax[2].set_title(\"hsv\")\nax[3].imshow(xyz)\nax[3].set_title(\"xyz\")\nax[4].imshow(hls)\nax[4].set_title(\"hls\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to visualize hsv image with imshow, need to separate, and gray scale view\nh, s, v = cv2.split(hsv)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(hsv)\nax[0].set_title(\"total hsv image\")\nax[1].imshow(h, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"Hue\")\nax[2].imshow(s, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"Saturation\")\nax[3].imshow(v, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"Value\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# to visualize hls image with imshow, need to separate, and gray scale view\nh, l, s = cv2.split(hls)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(hls)\nax[0].set_title(\"total hls image\")\nax[1].imshow(h, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"Hue\")\nax[2].imshow(l, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"Lightness\")\nax[3].imshow(s, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"Saturation\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Only the components of each color are extracted from the HSV image."},{"metadata":{"trusted":true},"cell_type":"code","source":"lower_blue = np.array([20,50,50])\nupper_blue = np.array([130,255,255])\n\nmask = cv2.inRange(hsv, lower_blue, upper_blue)\nres = cv2.bitwise_and(hsv,hsv, mask=mask)\n\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_img\")\nax[1].imshow(hsv)\nax[1].set_title(\"hsv\")\nax[2].imshow(mask)\nax[2].set_title(\"mask\")\nax[3].imshow(res)\nax[3].set_title(\"res\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Geometric Transformations of Images\n\n geometric transformations to images, like translation, rotation, affine transformation.\n \n https://docs.opencv.org/master/da/d6e/tutorial_py_geometric_transformations.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Scaling \nscale = cv2.resize(sample_img, (64,64), interpolation=cv2.INTER_AREA)\n# Transformation\nM = np.float32([[1,0,100],[0,1,50]])\ntrans= cv2.warpAffine(sample_img, M, (128,128))\n# Rotation\nM = cv2.getRotationMatrix2D(((128-1)/2.0,(128-1)/2.0),90,1)\nrotation = cv2.warpAffine(sample_img, M, (128,128))\n# Affine Transformation 3point ⇒ 3point\npts1 = np.float32([[50,50],[128,50],[50,100]])\npts2 = np.float32([[10,100],[128,50],[70,128]])\nM = cv2.getAffineTransform(pts1,pts2)\nAffine = cv2.warpAffine(sample_img, M, (128,128))\n# Perspective Transformation 4point ⇒ 4point\npts1 = np.float32([[56,65],[128,52],[28,128],[128,128]])\npts2 = np.float32([[0,0],[128,0],[0,100],[100,100]])\nM = cv2.getPerspectiveTransform(pts1,pts2)\nperspec = cv2.warpPerspective(sample_img, M, (128,128))\n\n# imshow\nfig, ax = plt.subplots(1,5, figsize=(20,4))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_img\")\nax[1].imshow(scale)\nax[1].set_title(\"scale\")\nax[2].imshow(rotation)\nax[2].set_title(\"rotation\")\nax[3].imshow(Affine)\nax[3].set_title(\"Affine\")\nax[4].imshow(perspec)\nax[4].set_title(\"perspec\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Thresholding\n\nhttps://docs.opencv.org/master/d7/d4d/tutorial_py_thresholding.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# binary\nret,th1 = cv2.threshold(gray, 164, 255, cv2.THRESH_BINARY)\n\n# mean_c\nth2 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n\n# goussian_c\nth3 = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(th1, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"binary\")\nax[2].imshow(th2, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"mean_c\")\nax[3].imshow(th3, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"goussian_c\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Smoothing images\n\nBlur images with various low pass filters\n\nhttps://docs.opencv.org/master/d4/d13/tutorial_py_filtering.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2D Convolution ( Image Filtering )\nkernel = np.ones((5,5),np.float32)/25\ndst = cv2.filter2D(sample_img, -1, kernel)\n\n# Averaging blur\nblur = cv2.blur(sample_img, (5,5))\n\n# Gaussian Blurring\nblur_g = cv2.GaussianBlur(sample_img, (5,5), 0)\n\n# Median Blurring\nmedian = cv2.medianBlur(sample_img, 5)\n\n# Bilateral Filtering\nblur_b = cv2.bilateralFilter(sample_img, 9, 75, 75)\n\n# imshow\nfig, ax = plt.subplots(2,3, figsize=(16,10))\nax[0,0].imshow(sample_img)\nax[0,0].set_title(\"sample_img\")\nax[0,1].imshow(dst)\nax[0,1].set_title(\"2D Convolution\")\nax[0,2].imshow(blur)\nax[0,2].set_title(\"Averaging blur\")\nax[1,0].imshow(blur_g)\nax[1,0].set_title(\"Gaussian Blurring\")\nax[1,1].imshow(median)\nax[1,1].set_title(\"Median Blurring\")\nax[1,2].imshow(blur_b)\nax[1,2].set_title(\"Bilateral Filtering\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Morphological Transformations\n\nhttps://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Erosion\nkernel = np.ones((5,5), np.float32)\nero = cv2.erode(gray, kernel, iterations=1)\n\n# Dilation\ndila = cv2.dilate(gray, kernel, iterations=1)\n\n# Opening\nopening = cv2.morphologyEx(gray, cv2.MORPH_OPEN, kernel)\n\n# Closing\nclosing = cv2.morphologyEx(gray, cv2.MORPH_CLOSE, kernel)\n\n# Morphological Gradient\ngrad = cv2.morphologyEx(gray, cv2.MORPH_GRADIENT, kernel)\n\n# Top Hat\ntophat = cv2.morphologyEx(gray, cv2.MORPH_TOPHAT, kernel)\n\n# Black Hat\nblackhat = cv2.morphologyEx(gray, cv2.MORPH_BLACKHAT, kernel)\n\n# imshow\nfig, ax = plt.subplots(2,4, figsize=(20,10))\nax[0,0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,0].set_title(\"gray\")\nax[0,1].imshow(ero, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,1].set_title(\"Erosion\")\nax[0,2].imshow(dila, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,2].set_title(\"Dilation\")\nax[0,3].imshow(opening, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0,3].set_title(\"Opening\")\nax[1,0].imshow(closing, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,0].set_title(\"Closing\")\nax[1,1].imshow(grad, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,1].set_title(\"Morphological Gradient\")\nax[1,2].imshow(tophat, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,2].set_title(\"Top Hatr\")\nax[1,3].imshow(blackhat, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1,3].set_title(\"Black Hat\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Image Gradients\n\nhttps://docs.opencv.org/master/d5/d0f/tutorial_py_gradients.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Laplacian Derivatives\nlap = cv2.Laplacian(gray, cv2.CV_64F)\n\n# sobelx\nsobelx = cv2.Sobel(gray, cv2.CV_64F,1,0,ksize=5)\n\n# sobely\nsobely = cv2.Sobel(gray, cv2.CV_64F,0,1,ksize=5)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,6))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(lap, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"Laplacian\")\nax[2].imshow(sobelx, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"sobelx\")\nax[3].imshow(sobely, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"sobely\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Canny edge detections\n\nhttps://docs.opencv.org/master/da/d22/tutorial_py_canny.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# min_val100, max_val200\nedge1 = cv2.Canny(sample_img, 100, 200)\n\n# min_val50, max_val200\nedge2 = cv2.Canny(sample_img, 50, 200)\n\n# min_val100, max_val300\nedge3 = cv2.Canny(sample_img, 100, 300)\n\n# imshow\nfig, ax = plt.subplots(1,4, figsize=(20,4))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(edge1, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"min_val100, max_val200\")\nax[2].imshow(edge2, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[2].set_title(\"min_val50, max_val200\")\nax[3].imshow(edge3, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[3].set_title(\"min_val100, max_val300\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Histgrams\n\nhttps://docs.opencv.org/master/de/db2/tutorial_py_table_of_contents_histograms.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate histgrams\n# cv.calcHist(images, channels, mask, histSize, ranges[, hist[, accumulate]])\n# channels, if gray [0], if color [0] or [1] or [2]\nhist = cv2.calcHist([sample_img],[0],None, [256],[0,256])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\ncolor=[\"red\", \"green\", \"blue\"]\nax[0].imshow(sample_img)\nax[0].grid()\nfor i in range(3):\n    ax[1].plot(cv2.calcHist([sample_img],[i], None, [256],[0,256]), color=color[i])\nax[1].set_xlim([0,256])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Histogram Equalization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate histgrams for gray image\nhist = cv2.calcHist([gray],[0],None, [256],[0,256])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].grid()\nax[1].hist(cv2.calcHist([gray],[0], None, [256],[0,256]), color=\"gray\", bins=128)\nax[1].set_xlim([0,256])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Equalization\nequ = cv2.equalizeHist(gray)\n\n# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(equ, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].grid()\nax[1].hist(cv2.calcHist([equ],[0], None, [256],[0,256]), color=\"gray\", bins=128)\nax[1].set_xlim([0,256])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## CLAHE (Contrast Limited Adaptive Histogram Equalization)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Equalization\nclahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\ncl1 = clahe.apply(gray)\n\n# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(cl1, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].grid()\nax[1].hist(cv2.calcHist([cl1],[0], None, [256],[0,256]), color=\"gray\", bins=128)\nax[1].set_xlim([0,256])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## 2D Histogram in OpenCV"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate histgram, after change to hsv\nhsv = cv2.cvtColor(sample_img, cv2.COLOR_RGB2HSV)\n\nhist = cv2.calcHist([hsv], [0,1], None, [180,256], [0,180,0,256])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Visualization\nfig, ax = plt.subplots(1,2,figsize=(15,6))\nax[0].imshow(hsv)\nax[0].grid()\nax[1].imshow(hist) # X axis shows S values and Y axis shows Hue\nax[1].grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Color Quantization by K-means clustering\n\nhttps://docs.opencv.org/master/d1/d5c/tutorial_py_kmeans_opencv.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing the image\nimg = np.float32(sample_img)\n\n# define criteria, number of cluster(K) and apply kmeans.\ncriteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1)\nK = 8\nret, label, center = cv2.kmeans(img, K, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)\n\n# cnvert bak into unit8, and make original image\ncenter = center.astype(\"uint8\")\nres = center[label.flatten()]\nres2 = res.reshape((img.shape))\n\nfig, ax = plt.subplots(1, 4, figsize=(20,6))\nax[0].imshow(sample_img)\nax[0].set_title(\"sample image\")\nax[1].imshow(img)\nax[1].set_title(\"convert float32 image\")\nax[2].imshow(res)\nax[2].set_title(\"center\")\nax[3].imshow(res2)\nax[3].set_title(\"result\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Image Denoising\n\nhttps://docs.opencv.org/master/d5/d69/tutorial_py_non_local_means.html"},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculate dst\ndst = cv2.fastNlMeansDenoisingColored(sample_img, None, 10, 10, 7, 21)\n\n# visalization\nfig, ax = plt.subplots(1,2, figsize=(12,6))\n\nax[0].imshow(sample_img)\nax[0].set_title(\"sample_image\")\nax[1].imshow(dst)\nax[1].set_title(\"image denoising\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Reference) Noise filtering by PCA"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Library\nfrom sklearn.decomposition import PCA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# sample of gray image\nimg = gray.copy()\n\n# Create instance\npca = PCA()\n\n# Fitting, Holds 99% of variance\npca = PCA(0.99).fit(img)\n\n# components\ncomponents = pca.transform(img)\nfilterd = pca.inverse_transform(components)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# visalization\nfig, ax = plt.subplots(1,2, figsize=(12,12))\n\nax[0].imshow(gray, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[0].set_title(\"gray\")\nax[1].imshow(filterd, cmap=plt.get_cmap('gray'), vmin=0, vmax=255)\nax[1].set_title(\"pca filtered\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}