{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import KFold\nimport numpy as np, pandas as pd, os\nimport matplotlib.pyplot as plt, cv2\nimport tensorflow as tf\nimport random, re, math, os\nfrom glob import glob\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def _bytes_feature(value):\n  \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n  if isinstance(value, type(tf.constant(0))):\n    value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n  return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n  \"\"\"Returns a float_list from a float / double.\"\"\"\n  return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n  \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n  return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_example(feature0, feature2):\n  feature = {\n      'image': _bytes_feature(feature0),\n      #'path': _bytes_feature(feature1),\n      'label': _int64_feature(feature2)\n  }\n  example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n  return example_proto.SerializeToString()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n\nSEED=37\nseed_everything(SEED)\n\ndataset = []\n\nfor label, kind in enumerate(['Cover', 'JMiPOD', 'JUNIWARD', 'UERD']):\n    for path in glob('../input/alaska2-image-steganalysis/Cover/*.jpg'):\n        dataset.append({\n            'kind': kind,\n            'image_name': path.split('/')[-1],\n            'label': label\n        })\n\nrandom.shuffle(dataset)\ndataset = pd.DataFrame(dataset)\ngkf = KFold(n_splits=10)\n\ndataset.loc[:, 'fold'] = 0\nfor fold_number, (train_index, val_index) in enumerate(gkf.split(X=dataset.index, y=dataset['label'], groups=dataset['image_name'])):\n    dataset.loc[dataset.iloc[val_index].index, 'fold'] = fold_number\n\ndataset.sort_values(\"image_name\",inplace=True)\ndataset.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold_number = 0\ntrain_df = dataset[dataset['fold'] != fold_number]\nval_df = dataset[dataset['fold'] == fold_number]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\n#GCS_DS_PATH = KaggleDatasets().get_gcs_path() \nGCS_DS_PATH = '../input/alaska2-image-steganalysis'\ntrain_paths = []\ntrain_labels = []\n\nfor i in range(len(train_df['kind'])):\n    kind = train_df['kind'].iloc[i]\n    im_id = train_df['image_name'].iloc[i]\n    label = train_df['label'].iloc[i]\n    path = os.path.join(GCS_DS_PATH, kind, im_id)\n    \n    train_paths.append(path)\n    train_labels.append(label)\n    \nlen(train_paths), len(train_labels)\nprint(train_paths[0:5])\nprint(train_labels[0:5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nvalid_paths = []\nvalid_labels = []\n\nfor i in range(len(val_df['kind'])):\n    kind = val_df['kind'].iloc[i]\n    im_id = val_df['image_name'].iloc[i]\n    label = val_df['label'].iloc[i]\n    path = os.path.join(GCS_DS_PATH, kind, im_id)\n    \n    valid_paths.append(path)\n    valid_labels.append(label)\n    \nlen(valid_paths), len(valid_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SIZE = 10000\n# CT = len(train_paths)//SIZE + int(len(train_paths)%SIZE!=0)\n# for j in range(CT):\n#     print('Writing TFRecord %i of %i...'%(j,CT))\n#     CT2 = min(SIZE,len(train_paths)-j*SIZE)\n#     with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(j,CT2)) as writer:\n#         for k in range(CT2):\n#             path=train_paths[j*SIZE+k]\n#             img = open(path, 'rb').read()\n#             label=train_labels[j*SIZE+k]\n#             example = serialize_example(img,label)#,str.encode(path)                \n#             writer.write(example)\n#             if k%1000==0: print(k,', ',end='')\n\n#             img = cv2.imread(train_paths[j*SIZE+k])\n#             img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n#             img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SIZE = 10000\nCT = len(valid_paths)//SIZE + int(len(valid_paths)%SIZE!=0)\nfor j in range(CT):\n    print('Writing TFRecord %i of %i...'%(j,CT))\n    CT2 = min(SIZE,len(valid_paths)-j*SIZE)\n    with tf.io.TFRecordWriter('valid%.2i-%i.tfrec'%(j,CT2)) as writer:\n        for k in range(CT2):\n            path=valid_paths[j*SIZE+k]\n            img = open(path, 'rb').read()\n#             img = cv2.imread(valid_paths[j*SIZE+k])\n#             #img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) # Fix incorrect colors\n#             img = cv2.imencode('.jpg', img, (cv2.IMWRITE_JPEG_QUALITY, 94))[1].tostring()\n            label=valid_labels[j*SIZE+k]\n            example = serialize_example(img,label)#,str.encode(path)                \n            writer.write(example)\n            if k%1000==0: print(k,', ',end='')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}