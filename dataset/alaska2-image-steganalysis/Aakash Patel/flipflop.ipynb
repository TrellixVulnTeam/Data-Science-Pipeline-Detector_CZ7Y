{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    print(dirname)\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nCover = pathlib.Path(\"../input/alaska2-image-steganalysis/Cover\")\nJUNIWARD = pathlib.Path(\"../input/alaska2-image-steganalysis/JUNIWARD\")\nJMiPOD = pathlib.Path(\"../input/alaska2-image-steganalysis/JMiPOD\")\nUERD = pathlib.Path(\"../input/alaska2-image-steganalysis/UERD\")\n\n# save it as binary data with (image , lable), where if paracsitized ==1 , else 0\nfrom PIL import Image\nimport h5py\nfrom tqdm import tqdm\nimport numpy as np\n\nfolders = [Cover , JUNIWARD]\nfilepath= []\nfor folder in folders:\n    f = list(folder.glob('*.jpg'))[:250]\n    filepath.extend(f)\n\nCLASS_NAMES = np.array([\"Cover\",\"JUNIWARD\"])\nprint(CLASS_NAMES)\n\nwith h5py.File('AlaskaBinary1.h5', 'w') as hf:\n  print(\"creating trainX\")\n  trainX = []\n  trainY = []\n  np.random.shuffle(filepath)\n  for i in tqdm(filepath, ascii = True, desc = \"Train data\"):\n    img = Image.open(i)\n    #img  = img.resize((,100))\n    img = np.asarray(img)\n    img = img.astype('float32')\n    # normalize to the range 0-1\n    img /= 255.0\n    name = i.parts\n    lable = True\n    if name[3] == 'Cover':\n       lable = False\n    trainX.append(img)\n    trainY.append(lable)\n  trainX = np.asarray(trainX)\n  trainY = np.asarray(trainY)\n  print(trainX.shape)\n  print(trainX[0].shape)\n  print(\"Train done\")\n  hf.create_dataset(\"trainX\",  data=trainX)\n  hf.create_dataset(\"trainY\",  data=trainY)\n  del trainX, trainY\nprint(\"All done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport h5py\n# import the necessary packages\nimport tensorflow as tf\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport numpy as np\n\n# plot the training loss and accuracy\ndef plot_graph(H):\n  list_loss = H.history[\"val_loss\"]\n  min_val = min(list_loss)\n  min_index = list_loss.index(min_val)\n  t_acc = H.history[\"accuracy\"][min_index]\n  v_acc = H.history[\"val_accuracy\"][min_index]\n  print(f\"The model {H.model.name} has the lowest val_loss {min_val} at epoch {min_index+1} with \\ntrain accuracy of {t_acc} and validation accuracy {v_acc}.\" )\n  plt.style.use(\"ggplot\")\n  plt.figure()\n  plt.plot(np.arange(0, 100), H.history[\"loss\"], label=\"train_loss\")\n  plt.plot(np.arange(0, 100), H.history[\"val_loss\"], label=\"val_loss\")\n  plt.plot(np.arange(0, 100), H.history[\"accuracy\"], label=\"train_acc\")\n  plt.plot(np.arange(0, 100), H.history[\"val_accuracy\"], label=\"val_acc\")\n  plt.title(\"Training Loss and Accuracy\")\n  plt.xlabel(\"Epoch #\")\n  plt.ylabel(\"Loss/Accuracy\")\n  plt.legend()\n  plt.savefig(f\"{H.model.name}_{v_acc}.png\")\n\ndef loadDataH5():\n    with h5py.File('AlaskaBinary1.h5','r') as hf:\n        trainX = np.array(hf.get('trainX'))\n        trainY = np.array(hf.get('trainY'))\n#         valX = np.array(hf.get('valX'))\n#         valY = np.array(hf.get('valY'))\n        print (trainX.shape,trainY.shape)\n        #print (valX.shape,valY.shape)\n    return trainX, trainY\n\nX, Y = loadDataH5()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrainX,testX, trainY, testY = train_test_split(X, Y, test_size=0.20, random_state=13)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n\ndef runmodel(model):\n  # defining common params.\n  NUM_EPOCHS = 100\n  opt = tf.keras.optimizers.SGD(lr=0.01)\n  # initialize the optimizer and model\n  print(\"Compiling model...\")\n  print (model.summary())\n  tmpdir = f\"./{model.name}\"\n  os.makedirs(tmpdir, exist_ok=True)\n  fname = \"checkpoint.hdf5\"\n  f = os.path.join(tmpdir, fname)\n  checkpoint = tf.keras.callbacks.ModelCheckpoint(f, monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n  model.compile(loss=\"BinaryCrossentropy\", optimizer=opt,\n    metrics=[\"accuracy\"])\n  # train the network\n  print(\"Training network...\")\n  H = model.fit(trainX, trainY,batch_size = 32, validation_data=(testX, testY),steps_per_epoch=len(trainX) / 32,callbacks=[checkpoint], epochs=NUM_EPOCHS)\n  plot_graph(H)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainY[:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def LeNet_5(width, height, depth):\n  # alternate maxpooling\n  # initialize the model along with the input shape to be \"channels last\"\n  model = tf.keras.Sequential(name='LeNet_5-Esem3') \n  inputShape = (height, width, depth)\n  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=inputShape))\n  model.add(tf.keras.layers.MaxPool2D(strides=2))\n  model.add(tf.keras.layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n  model.add(tf.keras.layers.MaxPool2D(strides=2))\n  model.add(tf.keras.layers.Flatten())\n  model.add(tf.keras.layers.Dense(256, activation='relu'))\n  model.add(tf.keras.layers.Dense(84, activation='relu'))\n  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n  return model\nrunmodel(LeNet_5(width=512, height=512, depth=3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nCover = pathlib.Path(\"../input/alaska2-image-steganalysis/Cover\")\nJUNIWARD = pathlib.Path(\"../input/alaska2-image-steganalysis/JUNIWARD\")\nJMiPOD = pathlib.Path(\"../input/alaska2-image-steganalysis/JMiPOD\")\nUERD = pathlib.Path(\"../input/alaska2-image-steganalysis/UERD\")\n\n# save it as binary data with (image , lable), where if paracsitized ==1 , else 0\nfrom PIL import Image\nimport h5py\nfrom tqdm import tqdm\nimport numpy as np\n\nfolders = [Cover , JMiPOD]\nfilepath= []\nfor folder in folders:\n    f = list(folder.glob('*.jpg'))[:250]\n    filepath.extend(f)\n\nCLASS_NAMES = np.array([\"Cover\",\"JMiPOD\"])\nprint(CLASS_NAMES)\n\nwith h5py.File('AlaskaBinary2.h5', 'w') as hf:\n  print(\"creating trainX\")\n  trainX = []\n  trainY = []\n  np.random.shuffle(filepath)\n  for i in tqdm(filepath, ascii = True, desc = \"Train data\"):\n    img = Image.open(i)\n    #img  = img.resize((,100))\n    img = np.asarray(img)\n    img = img.astype('float32')\n    # normalize to the range 0-1\n    img /= 255.0\n    name = i.parts\n    lable = True\n    if name[3] == 'Cover':\n       lable = False\n    trainX.append(img)\n    trainY.append(lable)\n  trainX = np.asarray(trainX)\n  trainY = np.asarray(trainY)\n  print(trainX.shape)\n  print(trainX[0].shape)\n  print(\"Train done\")\n  hf.create_dataset(\"trainX\",  data=trainX)\n  hf.create_dataset(\"trainY\",  data=trainY)\n  del trainX, trainY\nprint(\"All done\")\n\ndef loadDataH5(name):\n    with h5py.File(name,'r') as hf:\n        trainX = np.array(hf.get('trainX'))\n        trainY = np.array(hf.get('trainY'))\n#         valX = np.array(hf.get('valX'))\n#         valY = np.array(hf.get('valY'))\n        print (trainX.shape,trainY.shape)\n        #print (valX.shape,valY.shape)\n    return trainX, trainY\n\nX, Y = loadDataH5('AlaskaBinary2.h5')\n\ntrainX,testX, trainY, testY = train_test_split(X, Y, test_size=0.20, random_state=13)\n\ndef LeNet_5(width, height, depth):\n  # alternate maxpooling\n  # initialize the model along with the input shape to be \"channels last\"\n  model = tf.keras.Sequential(name='LeNet_5-Esem2') \n  inputShape = (height, width, depth)\n  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=inputShape))\n  model.add(tf.keras.layers.MaxPool2D(strides=2))\n  model.add(tf.keras.layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n  model.add(tf.keras.layers.MaxPool2D(strides=2))\n  model.add(tf.keras.layers.Flatten())\n  model.add(tf.keras.layers.Dense(256, activation='relu'))\n  model.add(tf.keras.layers.Dense(84, activation='relu'))\n  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n  return model\nrunmodel(LeNet_5(width=512, height=512, depth=3))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.remove(\"./AlaskaBinary2.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pathlib\nCover = pathlib.Path(\"../input/alaska2-image-steganalysis/Cover\")\nJUNIWARD = pathlib.Path(\"../input/alaska2-image-steganalysis/JUNIWARD\")\nJMiPOD = pathlib.Path(\"../input/alaska2-image-steganalysis/JMiPOD\")\nUERD = pathlib.Path(\"../input/alaska2-image-steganalysis/UERD\")\n\n# save it as binary data with (image , lable), where if paracsitized ==1 , else 0\nfrom PIL import Image\nimport h5py\nfrom tqdm import tqdm\nimport numpy as np\n\nfolders = [Cover , UERD]\nfilepath= []\nfor folder in folders:\n    f = list(folder.glob('*.jpg'))[:250]\n    filepath.extend(f)\n\nCLASS_NAMES = np.array([\"Cover\",\"UERD\"])\nprint(CLASS_NAMES)\n\nwith h5py.File('AlaskaBinary3.h5', 'w') as hf:\n  print(\"creating trainX\")\n  trainX = []\n  trainY = []\n  np.random.shuffle(filepath)\n  for i in tqdm(filepath, ascii = True, desc = \"Train data\"):\n    img = Image.open(i)\n    #img  = img.resize((,100))\n    img = np.asarray(img)\n    img = img.astype('float32')\n    # normalize to the range 0-1\n    img /= 255.0\n    name = i.parts\n    lable = True\n    if name[3] == 'Cover':\n       lable = False\n    trainX.append(img)\n    trainY.append(lable)\n  trainX = np.asarray(trainX)\n  trainY = np.asarray(trainY)\n  print(trainX.shape)\n  print(trainX[0].shape)\n  print(\"Train done\")\n  hf.create_dataset(\"trainX\",  data=trainX)\n  hf.create_dataset(\"trainY\",  data=trainY)\n  del trainX, trainY\nprint(\"All done\")\n\ndef loadDataH5(name):\n    with h5py.File(name,'r') as hf:\n        trainX = np.array(hf.get('trainX'))\n        trainY = np.array(hf.get('trainY'))\n#         valX = np.array(hf.get('valX'))\n#         valY = np.array(hf.get('valY'))\n        print (trainX.shape,trainY.shape)\n        #print (valX.shape,valY.shape)\n    return trainX, trainY\n\nX, Y = loadDataH5('AlaskaBinary3.h5')\n\ntrainX,testX, trainY, testY = train_test_split(X, Y, test_size=0.20, random_state=13)\n\ndef LeNet_5(width, height, depth):\n  # alternate maxpooling\n  # initialize the model along with the input shape to be \"channels last\"\n  model = tf.keras.Sequential(name='LeNet_5-Esem1') \n  inputShape = (height, width, depth)\n  model.add(tf.keras.layers.Conv2D(filters=32, kernel_size=(5,5), padding='same', activation='relu', input_shape=inputShape))\n  model.add(tf.keras.layers.MaxPool2D(strides=2))\n  model.add(tf.keras.layers.Conv2D(filters=48, kernel_size=(5,5), padding='valid', activation='relu'))\n  model.add(tf.keras.layers.MaxPool2D(strides=2))\n  model.add(tf.keras.layers.Flatten())\n  model.add(tf.keras.layers.Dense(256, activation='relu'))\n  model.add(tf.keras.layers.Dense(84, activation='relu'))\n  model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n  return model\nrunmodel(LeNet_5(width=512, height=512, depth=3))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.remove(\"./AlaskaBinary3.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom kaggle_datasets import KaggleDatasets\n\n# For tf.dataset\nAUTO = tf.data.experimental.AUTOTUNE\n\n# load submission\nsub = pd.read_csv('/kaggle/input/alaska2-image-steganalysis/sample_submission.csv')\n\n\n# Data access\nGCS_DS_PATH = '/kaggle/input/alaska2-image-steganalysis'\n\ndef append_path(pre):\n    return np.vectorize(lambda file: os.path.join(GCS_DS_PATH, pre, file))\n\ntest_paths = append_path('Test')(sub.Id.values)\nprint(test_paths)\n\ndef decode_image(filename, label=None, image_size=(512, 512)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0\n    image = tf.image.resize(image, image_size)\n    return image\n\n\ntest_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(test_paths)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(32)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating ensemble\nmodel1 = tf.keras.models.load_model('./LeNet_5-Esem1/checkpoint.hdf5')\nmodel2 = tf.keras.models.load_model('./LeNet_5-Esem2/checkpoint.hdf5')\nmodel3 = tf.keras.models.load_model('./LeNet_5-Esem3/checkpoint.hdf5')\ny_pred1 = model1.predict(test_dataset, verbose=1)\ny_pred2= model2.predict(test_dataset, verbose=1)\ny_pred3= model3.predict(test_dataset, verbose=1)\n\nsub.Label = (y_pred1+y_pred2+y_pred3)/3\nsub.to_csv('submission.csv', index=False)\nsub.head()\n                    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}