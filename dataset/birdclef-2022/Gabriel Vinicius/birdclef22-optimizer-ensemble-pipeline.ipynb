{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<a id=\"0\"></a>\n<p style=\"background-color:#281F2F;height: 60px;text-align: center;vertical-align: middle;line-height: 60px;;font-family:helvetica;color:#FFFFFF;font-size:120%;text-align:center;border-radius:12px 12px;\">~ ~ ~ ~ Libraries ~ ~ ~ ~</p>","metadata":{}},{"cell_type":"code","source":"!pip install ../input/torchlibrosa/torchlibrosa-0.0.5-py3-none-any.whl > /dev/null","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:00:38.4041Z","iopub.execute_input":"2022-05-25T20:00:38.404393Z","iopub.status.idle":"2022-05-25T20:01:05.745289Z","shell.execute_reply.started":"2022-05-25T20:00:38.404365Z","shell.execute_reply":"2022-05-25T20:01:05.744462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install  ../input/wheat-head-detection-packages/timm-0.5.4-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:05.747662Z","iopub.execute_input":"2022-05-25T20:01:05.747934Z","iopub.status.idle":"2022-05-25T20:01:33.380609Z","shell.execute_reply.started":"2022-05-25T20:01:05.747898Z","shell.execute_reply":"2022-05-25T20:01:33.379768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# basics\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport time\nimport random # for torch seed\nfrom tqdm import tqdm\nimport json\n\nfrom pathlib import Path\nimport warnings\nfrom contextlib import contextmanager\nfrom typing import List\nfrom typing import Optional\nimport logging\n\n# audio\nimport librosa\nimport soundfile as sf\nfrom torchlibrosa.stft import LogmelFilterBank, Spectrogram\nfrom torchlibrosa.augmentation import SpecAugmentation\nimport torchaudio\n\n# sklearn\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\n\n# torch\nimport torch\nfrom torch import nn\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.utils.data as torchdata\nfrom torch.optim import Adam, AdamW, RMSprop # optmizers\nfrom torch.optim.lr_scheduler import CosineAnnealingLR, ReduceLROnPlateau # Learning rate schedulers\nfrom torch.cuda.amp import autocast, GradScaler\nimport torch.nn.functional as F\nfrom albumentations.pytorch import ToTensorV2\n\n\n# albumentations\n# from albumentations.core.transforms_interface import ImageOnlyTransform\nimport albumentations as A\nimport albumentations.pytorch.transforms as T\n\n# timm\nimport sys\n#sys.path.append('../input/../input/timmmaster')\nimport timm\n\nprint(\"Timm version: \", timm.__version__)\nprint(\"Librosa version: \", librosa.__version__)\nprint(\"Albumentations version: \", A.__version__)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.382379Z","iopub.execute_input":"2022-05-25T20:01:33.382649Z","iopub.status.idle":"2022-05-25T20:01:33.395933Z","shell.execute_reply.started":"2022-05-25T20:01:33.382614Z","shell.execute_reply":"2022-05-25T20:01:33.395144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"1\"></a>\n# <p style=\"background-color:#281F2F;height: 60px;text-align: center;vertical-align: middle;line-height: 60px;;font-family:helvetica;color:#FFFFFF;font-size:120%;text-align:center;border-radius:12px 12px;\">~ ~ ~ ~ Introduction ~ ~ ~ ~</p>\n\nThis notebook implements the final Ensemble pipeline developed for the BirdCLEF 2022 competition where our team achieve the Bronze medal in 65th position. \n\nWe had two big challenges to carry out the ensemble:\n\n- 1 Inference kernel timeout\n- 2 Tuning the contribution of each backbones \n\nFor solve de problem 1 we merge all checkpoints into a single Ensemble class, with this it was possible to make inference for all models in one loop of test dataloader.\n\n![image.png](attachment:8af2fa37-be1d-49a8-8599-37082912bcd4.png)\n\n\nTo solve problem 2 we implement two strategies of ensemble , the first is the simple global average of the checkpoints and the second is the weighted sum of the averages of each backbone.\n\n\n*backbone(n):* $\\frac{1}{Nfolds}\\sum_{0}^{n} fold({n})$\n\n*Global average* : $\\frac{\\sum_{0}^{n} backbone(n)}{Nbackbones} $\n\n*Wheighted sum*: $\\sum_{0}^{n} backbone(n)*W(n)$\n\nWhere $W(n)$ is wheight of contribution for $backbone(n)$.\n\nThis process is done for each spectogram of each audio in the test database,if you want seen the impleentation in code jump to [here](#ensemble_class).\n\nIn order for our team solution uses two backbones with five folds each, totaling 10 checkpints. With this pipeline this inference took approximately 5h.","metadata":{},"attachments":{"8af2fa37-be1d-49a8-8599-37082912bcd4.png":{"image/png":"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"}}},{"cell_type":"markdown","source":"# Master CFG","metadata":{}},{"cell_type":"code","source":"class CFG:\n          DEBUG = False # True # False\n        \n          EXP_ID = 'N001'\n\n          N_CLASS = 152 # len(np.unique(train['primary_label']))\n          target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                      barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                      brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                      cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                      comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                      fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                      hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                      jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                      madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                      norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                      reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                      saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                      towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n          random_seed = 42","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.397182Z","iopub.execute_input":"2022-05-25T20:01:33.39747Z","iopub.status.idle":"2022-05-25T20:01:33.406334Z","shell.execute_reply.started":"2022-05-25T20:01:33.397434Z","shell.execute_reply":"2022-05-25T20:01:33.405647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFGs for Backbone 1","metadata":{}},{"cell_type":"code","source":"class CFG_01:\n    DEBUG = False \n    EXP_ID = 'N001'   \n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'seresnext26tn_32x4d'\n    \n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \n    \nclass CFG_02:\n\n    DEBUG = False \n    EXP_ID = 'N001'\n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'seresnext26tn_32x4d'\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128,\n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \n    \nclass CFG_03:\n\n    DEBUG = False \n\n    EXP_ID = 'N001'\n    \n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    model_name = 'seresnext26tn_32x4d'\n    \n    \n    period = 5\n    n_mels = 128 # 256 # 224\n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \nclass CFG_04:\n\n    DEBUG = False \n\n    EXP_ID = 'N001'\n    \n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'seresnext26tn_32x4d'\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \nclass CFG_05:\n\n    DEBUG = False \n    EXP_ID = 'N001'\n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    model_name = 'seresnext26tn_32x4d'\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.409219Z","iopub.execute_input":"2022-05-25T20:01:33.409526Z","iopub.status.idle":"2022-05-25T20:01:33.439369Z","shell.execute_reply.started":"2022-05-25T20:01:33.409496Z","shell.execute_reply":"2022-05-25T20:01:33.438539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CFGs for Backbone 2","metadata":{}},{"cell_type":"code","source":"class CFG_06:\n\n    DEBUG = False \n\n    EXP_ID = 'N001'\n    \n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'efficientnet_b0'\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \n    \nclass CFG_07:\n\n    DEBUG = False \n    EXP_ID = 'N001'\n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'efficientnet_b0'\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \n    \nclass CFG_08:\n\n    DEBUG = False \n    EXP_ID = 'N001'\n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'efficientnet_b0'\n    ### dataset\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \nclass CFG_09:\n\n    DEBUG = False\n    EXP_ID = 'N001'\n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'efficientnet_b0'  \n    ### dataset\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3,  \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }\n    \nclass CFG_010:\n\n    DEBUG = False \n    EXP_ID = 'N001'\n    IMG_HEIGHT = 256  \n    IMG_WIDTH = 313\n    IN_CHANS = 3  \n    N_CLASS = 152 \n    target_columns = 'afrsil1 akekee akepa1 akiapo akikik amewig aniani apapan arcter \\\n                  barpet bcnher belkin1 bkbplo bknsti bkwpet blkfra blknod bongul \\\n                  brant brnboo brnnod brnowl brtcur bubsan buffle bulpet burpar buwtea \\\n                  cacgoo1 calqua cangoo canvas caster1 categr chbsan chemun chukar cintea \\\n                  comgal1 commyn compea comsan comwax coopet crehon dunlin elepai ercfra eurwig \\\n                  fragul gadwal gamqua glwgul gnwtea golphe grbher3 grefri gresca gryfra gwfgoo \\\n                  hawama hawcoo hawcre hawgoo hawhaw hawpet1 hoomer houfin houspa hudgod iiwi incter1 \\\n                  jabwar japqua kalphe kauama laugul layalb lcspet leasan leater1 lessca lesyel lobdow lotjae \\\n                  madpet magpet1 mallar3 masboo mauala maupar merlin mitpar moudov norcar norhar2 normoc norpin \\\n                  norsho nutman oahama omao osprey pagplo palila parjae pecsan peflov perfal pibgre pomjae puaioh \\\n                  reccar redava redjun redpha1 refboo rempar rettro ribgul rinduc rinphe rocpig rorpar rudtur ruff \\\n                  saffin sander semplo sheowl shtsan skylar snogoo sooshe sooter1 sopsku1 sora spodov sposan \\\n                  towsol wantat1 warwhe1 wesmea wessan wetshe whfibi whiter whttro wiltur yebcar yefcan zebdov'.split()\n\n    random_seed = 42\n    ### model\n    model_name = 'efficientnet_b0'\n    ### dataset\n    period = 5\n    n_mels = 128 \n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n            \"n_mels\": 128, \n            \"fmin\": 20,\n            \"fmax\": 16000\n    }\n    \n    loader_params = {\n    \"train\": {\n        \"batch_size\": 3, \n        \"num_workers\": 0,\n        \"shuffle\": True\n    },\n    \"valid\": {\n        \"batch_size\": 64, \n        \"num_workers\": 0,\n        \"shuffle\": False\n    }\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.441205Z","iopub.execute_input":"2022-05-25T20:01:33.441819Z","iopub.status.idle":"2022-05-25T20:01:33.468144Z","shell.execute_reply.started":"2022-05-25T20:01:33.44178Z","shell.execute_reply":"2022-05-25T20:01:33.467398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ebirds = np.array(CFG_01.target_columns) # name of the bird\nibird_idx = np.array([np.where(ebirds == x) for x in CFG_02.target_columns]).squeeze() # index of the bird\nibird_idx","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.469697Z","iopub.execute_input":"2022-05-25T20:01:33.470232Z","iopub.status.idle":"2022-05-25T20:01:33.484869Z","shell.execute_reply.started":"2022-05-25T20:01:33.470193Z","shell.execute_reply":"2022-05-25T20:01:33.48401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# detect and define device \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.486267Z","iopub.execute_input":"2022-05-25T20:01:33.486653Z","iopub.status.idle":"2022-05-25T20:01:33.493839Z","shell.execute_reply.started":"2022-05-25T20:01:33.486616Z","shell.execute_reply":"2022-05-25T20:01:33.492801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for reproducibility\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed = CFG.random_seed)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.496148Z","iopub.execute_input":"2022-05-25T20:01:33.496972Z","iopub.status.idle":"2022-05-25T20:01:33.50344Z","shell.execute_reply.started":"2022-05-25T20:01:33.496933Z","shell.execute_reply":"2022-05-25T20:01:33.502742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_labels = json.load(open(\"../input/birdclef-2022/scored_birds.json\", \"r\"))\nprint(class_labels)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.504772Z","iopub.execute_input":"2022-05-25T20:01:33.505197Z","iopub.status.idle":"2022-05-25T20:01:33.515168Z","shell.execute_reply.started":"2022-05-25T20:01:33.50516Z","shell.execute_reply":"2022-05-25T20:01:33.514382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scored_ebirds = [np.where(np.array(CFG.target_columns) == i)[0].tolist()[0] for i in class_labels]\nprint(\"Scored classes: \", scored_ebirds)\nprint(\"Num scored classes: \", len(scored_ebirds))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.517138Z","iopub.execute_input":"2022-05-25T20:01:33.518388Z","iopub.status.idle":"2022-05-25T20:01:33.525922Z","shell.execute_reply.started":"2022-05-25T20:01:33.518349Z","shell.execute_reply":"2022-05-25T20:01:33.524958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.DEBUG:\n  CFG.N_EPOCHS = 2\n  train = train.sample(frac = 0.1).reset_index(drop=True) # n = 10_000\n#   CFG.N_CLASS = len(np.unique(train['primary_label']))\n\nprint(f'Using {CFG.N_CLASS} classes to train')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.527025Z","iopub.execute_input":"2022-05-25T20:01:33.527561Z","iopub.status.idle":"2022-05-25T20:01:33.536676Z","shell.execute_reply.started":"2022-05-25T20:01:33.527523Z","shell.execute_reply":"2022-05-25T20:01:33.535911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\nImage shape (H, W, C): ({CFG_01.IMG_HEIGHT}, {CFG_01.IMG_WIDTH}, {CFG_01.IN_CHANS})\")\nprint(\"Number of classes in train dataset: \", CFG.N_CLASS)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.537855Z","iopub.execute_input":"2022-05-25T20:01:33.538303Z","iopub.status.idle":"2022-05-25T20:01:33.544693Z","shell.execute_reply.started":"2022-05-25T20:01:33.538237Z","shell.execute_reply":"2022-05-25T20:01:33.543866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models Classes","metadata":{}},{"cell_type":"code","source":"def init_layer(layer):\n    nn.init.xavier_uniform_(layer.weight)\n\n    if hasattr(layer, \"bias\"):\n        if layer.bias is not None:\n            layer.bias.data.fill_(0.)\n\n\ndef init_bn(bn):\n    bn.bias.data.fill_(0.)\n    bn.weight.data.fill_(1.0)\n\n\ndef init_weights(model):\n    classname = model.__class__.__name__\n    if classname.find(\"Conv2d\") != -1:\n        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n        model.bias.data.fill_(0)\n    elif classname.find(\"BatchNorm\") != -1:\n        model.weight.data.normal_(1.0, 0.02)\n        model.bias.data.fill_(0)\n    elif classname.find(\"GRU\") != -1:\n        for weight in model.parameters():\n            if len(weight.size()) > 1:\n                nn.init.orghogonal_(weight.data)\n    elif classname.find(\"Linear\") != -1:\n        model.weight.data.normal_(0, 0.01)\n        model.bias.data.zero_()\n\n\ndef interpolate(x: torch.Tensor, ratio: int):\n    \"\"\"Interpolate data in time domain. This is used to compensate the\n    resolution reduction in downsampling of a CNN.\n    Args:\n      x: (batch_size, time_steps, classes_num)\n      ratio: int, ratio to interpolate\n    Returns:\n      upsampled: (batch_size, time_steps * ratio, classes_num)\n    \"\"\"\n    (batch_size, time_steps, classes_num) = x.shape\n    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n    return upsampled\n\n\ndef pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n    is the same as the value of the last frame.\n    Args:\n      framewise_output: (batch_size, frames_num, classes_num)\n      frames_num: int, number of frames to pad\n    Outputs:\n      output: (batch_size, frames_num, classes_num)\n    \"\"\"\n    output = F.interpolate(\n        framewise_output.unsqueeze(1),\n        size=(frames_num, framewise_output.size(2)),\n        align_corners=True,\n        mode=\"bilinear\").squeeze(1)\n\n    return output\n\n\n\nclass AttBlockV2(nn.Module):\n    def __init__(self,\n                 in_features: int,\n                 out_features: int,\n                 activation=\"linear\"):\n        super().__init__()\n\n        self.activation = activation\n        self.att = nn.Conv1d(\n            in_channels=in_features,\n            out_channels=out_features,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True)\n        self.cla = nn.Conv1d(\n            in_channels=in_features,\n            out_channels=out_features,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True)\n\n        self.init_weights()\n\n    def init_weights(self):\n        init_layer(self.att)\n        init_layer(self.cla)\n\n    def forward(self, x):\n        # x: (n_samples, n_in, n_time)\n        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n        cla = self.nonlinear_transform(self.cla(x))\n        x = torch.sum(norm_att * cla, dim=2)\n        return x, norm_att, cla\n\n    def nonlinear_transform(self, x):\n        if self.activation == 'linear':\n            return x\n        elif self.activation == 'sigmoid':\n            return torch.sigmoid(x)\n\n\nclass TimmSED(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        \n        self.spec_augmenter = SpecAugmentation(time_drop_width=64//2, time_stripes_num=2,\n                                               freq_drop_width=8//2, freq_stripes_num=2)\n\n        self.bn0 = nn.BatchNorm2d(CFG_01.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n\n        if hasattr(base_model, \"fc\"):\n            in_features = base_model.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n\n        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_bn(self.bn0)\n        init_layer(self.fc1)\n        \n\n    def forward(self, input_data):\n        x = input_data # (batch_size, 3, time_steps, mel_bins)\n\n        frames_num = x.shape[2]\n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n\n        if self.training:\n            if random.random() < 0.25:\n                x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n\n        x = self.encoder(x)\n        \n        # Aggregate in frequency axis\n        x = torch.mean(x, dim=3)\n\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x = x1 + x2\n\n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n\n        output_dict = {\n            'framewise_output': framewise_output,\n            'clipwise_output': clipwise_output,\n            'logit': logit,\n            'framewise_logit': framewise_logit,\n        }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.548833Z","iopub.execute_input":"2022-05-25T20:01:33.549215Z","iopub.status.idle":"2022-05-25T20:01:33.580611Z","shell.execute_reply.started":"2022-05-25T20:01:33.549187Z","shell.execute_reply":"2022-05-25T20:01:33.579934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"mean = (0.485, 0.456, 0.406) # RGB IMAGENET_DEFAULT_MEAN\nstd = (0.229, 0.224, 0.225) # RGB IMAGENET_DEFAULT_STD\n\nalbu_transforms = {\n    'train' : A.Compose([\n            A.HorizontalFlip(p=0.5),\n            A.OneOf([\n                A.Cutout(max_h_size=5, max_w_size=16),\n                A.CoarseDropout(max_holes=4),\n            ], p=0.5),\n            A.Normalize(mean, std),\n    ]),\n    'valid' : A.Compose([\n            A.Normalize(mean, std),\n    ]),\n}","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.581857Z","iopub.execute_input":"2022-05-25T20:01:33.582273Z","iopub.status.idle":"2022-05-25T20:01:33.592398Z","shell.execute_reply.started":"2022-05-25T20:01:33.582216Z","shell.execute_reply":"2022-05-25T20:01:33.591623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read & Audio Params","metadata":{}},{"cell_type":"code","source":"AUDIO_PATH = '../input/birdclef-2022/train_audio'\nCLASSES = sorted(os.listdir(AUDIO_PATH))\nNUM_CLASSES = len(class_labels)\n\nclass AudioParams_01:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_01.sample_rate \n    duration = CFG_01.period \n    # Melspectrogram\n    n_mels = CFG_01.melspectrogram_parameters['n_mels']\n    fmin = CFG_01.melspectrogram_parameters['fmin'] \n    fmax = CFG_01.melspectrogram_parameters['fmax']\n    \nclass AudioParams_02:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_02.sample_rate \n    duration = CFG_02.period \n    # Melspectrogram\n    n_mels = CFG_02.melspectrogram_parameters['n_mels']\n    fmin = CFG_02.melspectrogram_parameters['fmin'] \n    fmax = CFG_02.melspectrogram_parameters['fmax']\n\nclass AudioParams_03:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_03.sample_rate \n    duration = CFG_03.period \n    # Melspectrogram\n    n_mels = CFG_03.melspectrogram_parameters['n_mels']\n    fmin = CFG_03.melspectrogram_parameters['fmin'] \n    fmax = CFG_03.melspectrogram_parameters['fmax']\n    \nclass AudioParams_04:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_04.sample_rate # 32000\n    duration = CFG_04.period # 5\n    # Melspectrogram\n    n_mels = CFG_04.melspectrogram_parameters['n_mels']\n    fmin = CFG_04.melspectrogram_parameters['fmin'] \n    fmax = CFG_04.melspectrogram_parameters['fmax']\n    \nclass AudioParams_05:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_05.sample_rate # 32000\n    duration = CFG_05.period # 5\n    # Melspectrogram\n    n_mels = CFG_05.melspectrogram_parameters['n_mels']\n    fmin = CFG_05.melspectrogram_parameters['fmin'] # 20\n    fmax = CFG_05.melspectrogram_parameters['fmax']\n    \nclass AudioParams_06:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_06.sample_rate # 32000\n    duration = CFG_06.period # 5\n    # Melspectrogram\n    n_mels = CFG_06.melspectrogram_parameters['n_mels']\n    fmin = CFG_06.melspectrogram_parameters['fmin']\n    fmax = CFG_06.melspectrogram_parameters['fmax']\n    \nclass AudioParams_07:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_07.sample_rate # 32000\n    duration = CFG_07.period # 5\n    # Melspectrogram\n    n_mels = CFG_07.melspectrogram_parameters['n_mels']\n    fmin = CFG_07.melspectrogram_parameters['fmin'] \n    fmax = CFG_07.melspectrogram_parameters['fmax']\n    \nclass AudioParams_08:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_08.sample_rate # 32000\n    duration = CFG_08.period # 5\n    # Melspectrogram\n    n_mels = CFG_08.melspectrogram_parameters['n_mels']\n    fmin = CFG_08.melspectrogram_parameters['fmin'] \n    fmax = CFG_08.melspectrogram_parameters['fmax']\n    \nclass AudioParams_09:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_09.sample_rate # 32000\n    duration = CFG_09.period # 5\n    # Melspectrogram\n    n_mels = CFG_09.melspectrogram_parameters['n_mels']\n    fmin = CFG_09.melspectrogram_parameters['fmin'] \n    fmax = CFG_09.melspectrogram_parameters['fmax']\n    \nclass AudioParams_010:\n    \"\"\"\n    Parameters used for the audio data\n    \"\"\"\n    sr = CFG_010.sample_rate # 32000\n    duration = CFG_010.period # 5\n    # Melspectrogram\n    n_mels = CFG_010.melspectrogram_parameters['n_mels']\n    fmin = CFG_010.melspectrogram_parameters['fmin'] \n    fmax = CFG_010.melspectrogram_parameters['fmax']","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.594887Z","iopub.execute_input":"2022-05-25T20:01:33.5951Z","iopub.status.idle":"2022-05-25T20:01:33.614685Z","shell.execute_reply.started":"2022-05-25T20:01:33.595075Z","shell.execute_reply":"2022-05-25T20:01:33.613826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# MelSpec & mono_to_color for Models","metadata":{}},{"cell_type":"code","source":"#just diference\ndef melspect_transform(wave):\n    transfomer = torchaudio.transforms.MelSpectrogram(sample_rate = 22050,\n                                                     n_fft = 2048, \n                                                     win_length = 1024,\n                                                     n_mels = 250 ).double()\n\n\n    wave = torch.from_numpy(wave.copy())\n\n    mel_spectrogram = transfomer(wave)\n    mel_spectrogram = librosa.amplitude_to_db(mel_spectrogram).astype(np.float32)\n\n    return mel_spectrogram\n\n\ndef compute_melspec(y, params):\n    \"\"\"\n    Computes a mel-spectrogram and puts it at decibel scale\n    Arguments:\n        y {np array} -- signal\n        params {AudioParams} -- Parameters to use for the spectrogram. Expected to have the attributes sr, n_mels, f_min, f_max\n    Returns:\n        np array -- Mel-spectrogram\n    \"\"\"\n    melspec = librosa.feature.melspectrogram(\n        y=y, sr=params.sr, n_mels=params.n_mels, fmin=params.fmin, fmax=params.fmax,\n    )\n\n    melspec = librosa.power_to_db(melspec).astype(np.float32)\n    return melspec\n\n\ndef mono_to_color(X, eps=1e-6, mean=None, std=None):\n    \"\"\"\n    Converts a one channel array to a 3 channel one in [0, 255]\n    Arguments:\n        X {numpy array [H x W]} -- 2D array to convert\n    Keyword Arguments:\n        eps {float} -- To avoid dividing by 0 (default: {1e-6})\n        mean {None or np array} -- Mean for normalization (default: {None})\n        std {None or np array} -- Std for normalization (default: {None})\n    Returns:\n        numpy array [3 x H x W] -- RGB numpy array\n    \"\"\"\n    X = np.stack([X, X, X], axis=-1)\n\n    # Standardize\n    mean = mean or X.mean()\n    std = std or X.std()\n    X = (X - mean) / (std + eps)\n\n    # Normalize to [0, 255]\n    _min, _max = X.min(), X.max()\n\n    if (_max - _min) > eps:\n        V = np.clip(X, _min, _max)\n        V = 255 * (V - _min) / (_max - _min)\n        V = V.astype(np.uint8)\n    else:\n        V = np.zeros_like(X, dtype=np.uint8)\n\n    return V","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.616271Z","iopub.execute_input":"2022-05-25T20:01:33.616943Z","iopub.status.idle":"2022-05-25T20:01:33.629157Z","shell.execute_reply.started":"2022-05-25T20:01:33.616903Z","shell.execute_reply":"2022-05-25T20:01:33.628482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Dataset class","metadata":{}},{"cell_type":"code","source":"class TestDataset(torchdata.Dataset):\n    def __init__(self, df: pd.DataFrame, clip: np.ndarray):\n        self.df = df\n        self.mode='valid'\n        self.clip = clip\n        # self.clip = np.concatenate([clip, clip, clip])\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx: int):\n        SR = 32000\n        sample = self.df.loc[idx, :]\n        row_id = sample.row_id\n\n        end_seconds = int(sample.seconds)\n        start_seconds = int(end_seconds - 5)\n        \n \n        \n        image = self.clip[SR*start_seconds:SR*end_seconds].astype(np.float32)\n        image = np.nan_to_num(image)\n        \n        # Audio to Image\n        image = compute_melspec(image, AudioParams_01)\n        image = mono_to_color(image)\n               \n        image = image.astype(np.uint8)\n\n\n        image = albu_transforms[self.mode](image=image)['image'].T\n            \n        return {\n            \"image\": image,\n            \"row_id\": row_id,\n        }\n\n      \n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.630447Z","iopub.execute_input":"2022-05-25T20:01:33.630867Z","iopub.status.idle":"2022-05-25T20:01:33.641193Z","shell.execute_reply.started":"2022-05-25T20:01:33.630829Z","shell.execute_reply":"2022-05-25T20:01:33.640459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checkpoint and Models","metadata":{}},{"cell_type":"code","source":"checkpoints_list_backbone1 = [\n \n    #Ensemble 5 folds for backbone seresnext26tn_32x4d\n   '../input/birdclfe-2002-ensemble-5-folds/seresnext26tn_32x4d_mels128_best_loss_fold0_ep026 (1).bin',\n    '../input/birdclfe-2002-ensemble-5-folds/seresnext26tn_32x4d_mels128_best_loss_fold1_ep026.bin',\n    '../input/birdclfe-2002-ensemble-5-folds/seresnext26tn_32x4d_mels128_best_loss_fold2_ep027.bin',\n    '../input/birdclfe-2002-ensemble-5-folds/seresnext26tn_32x4d_mels128_best_loss_fold3_ep026.bin',\n    '../input/birdclfe-2002-ensemble-5-folds/seresnext26tn_32x4d_mels128_best_loss_fold4_ep025.bin',    \n\n\n]\n\n\n\ncheckpoints_list_backbone2 = [\n        #Ensemble 5 folds for backbone tf_efficientnet_b0_ns    \n    '../input/effnet-ns-all-folds/tf_efficientnet_b0_ns_mels128_best_loss_fold0_ep021.bin',\n    '../input/effnet-ns-all-folds/tf_efficientnet_b0_ns_mels128_best_loss_fold1_ep022.bin',\n    '../input/effnet-ns-all-folds/tf_efficientnet_b0_ns_mels128_best_loss_fold2_ep020.bin',\n    '../input/effnet-ns-all-folds/tf_efficientnet_b0_ns_mels128_best_loss_fold3_ep019.bin',\n    '../input/effnet-ns-all-folds/tf_efficientnet_b0_ns_mels128_best_loss_fold4_ep014.bin',\n]\n\ncheckpoints_list = checkpoints_list_backbone1 + checkpoints_list_backbone2\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.64245Z","iopub.execute_input":"2022-05-25T20:01:33.64281Z","iopub.status.idle":"2022-05-25T20:01:33.653267Z","shell.execute_reply.started":"2022-05-25T20:01:33.642775Z","shell.execute_reply":"2022-05-25T20:01:33.65238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Models","metadata":{}},{"cell_type":"code","source":"model_01 = TimmSED(base_model_name=CFG_01.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_01.N_CLASS,\n                in_channels=CFG_01.IN_CHANS)\n\n#models.append(model_01)\n\nmodel_02 = TimmSED(base_model_name=CFG_02.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes=CFG_02.N_CLASS, # CFG.num_classes\n                in_channels=CFG_02.IN_CHANS)\n\n#models.append(model_02)\n\nmodel_03 = TimmSED(base_model_name=CFG_03.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_03.N_CLASS,\n                in_channels=CFG_03.IN_CHANS)\n\n\n#models.append(model_03)\n\nmodel_04 = TimmSED(base_model_name=CFG_04.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_04.N_CLASS,\n                in_channels=CFG_04.IN_CHANS)\n\n\n#models.append(model_04)\n\nmodel_05 = TimmSED(base_model_name=CFG_05.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_05.N_CLASS,\n                in_channels=CFG_05.IN_CHANS)\n\n\n#models.append(model_05)\n\nmodel_06 = TimmSED(base_model_name=CFG_06.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_06.N_CLASS,\n                in_channels=CFG_06.IN_CHANS)\n\n\n#models.append(model_06)\n\n\nmodel_07 = TimmSED(base_model_name=CFG_07.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_07.N_CLASS,\n                in_channels=CFG_07.IN_CHANS)\n\n\n#models.append(model_07)\n\nmodel_08 = TimmSED(base_model_name=CFG_08.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_08.N_CLASS,\n                in_channels=CFG_08.IN_CHANS)\n\n\n#models.append(model_08)\n\nmodel_09 = TimmSED(base_model_name=CFG_09.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_09.N_CLASS,\n                in_channels=CFG_09.IN_CHANS)\n\n\n#models.append(model_09)\n\nmodel_010 = TimmSED(base_model_name=CFG_010.model_name,\n                pretrained=False, # CFG.pretrained: False if inference only\n                num_classes= CFG_010.N_CLASS,\n                in_channels=CFG_010.IN_CHANS)\n\n\n#models.append(model_010)\n\n#print(\"Number of checkpoints: \", len(models))","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:33.654955Z","iopub.execute_input":"2022-05-25T20:01:33.655532Z","iopub.status.idle":"2022-05-25T20:01:35.976187Z","shell.execute_reply.started":"2022-05-25T20:01:33.655492Z","shell.execute_reply":"2022-05-25T20:01:35.975394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models_backbone1 = []\nmodels_backbone2 = []\nfor idx,model_path in enumerate(checkpoints_list):\n\n#         print('i: ', i)\n#         print('index i: ', checkpoints_list.index(i))\n\n    # create test Dataset object\n    #print(idx)\n    if idx == 0: # < 5\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_01.load_state_dict(torch.load(model_path))\n        #model_01.to(device)\n        models_backbone1.append(model_01)\n    elif  idx == 1:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_02.load_state_dict(torch.load(model_path))\n        #model_02.to(device)\n        models_backbone1.append(model_02)\n    elif  idx == 2:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_03.load_state_dict(torch.load(model_path))\n        #model_03.to(device)\n        models_backbone1.append(model_03)\n    elif  idx == 3:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_04.load_state_dict(torch.load(model_path))\n        #model_04.to(device)\n        models_backbone1.append(model_04)\n    elif  idx == 4:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_05.load_state_dict(torch.load(model_path))\n        #model_05.to(device)\n        models_backbone1.append(model_05)\n    elif  idx == 5:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_06.load_state_dict(torch.load(model_path))\n        #model_06.to(device)\n        models_backbone2.append(model_06)\n    elif  idx == 6:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_07.load_state_dict(torch.load(model_path))\n        #model_07.to(device)\n        models_backbone2.append(model_07)\n    elif  idx == 7:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_08.load_state_dict(torch.load(model_path))\n        #model_08.to(device)\n        models_backbone2.append(model_08)\n        \n    elif  idx == 8:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_09.load_state_dict(torch.load(model_path))\n        #model_09.to(device)\n        models_backbone2.append(model_09)\n    elif  idx == 9:\n        print(f\"\\nInference with Model_{idx}\")\n        print(f\"Current checkpoint: {model_path.split('/')[-1]}\\n\")\n        model_010.load_state_dict(torch.load(model_path))\n        #model_010.to(device)\n        models_backbone2.append(model_010)\n    else:\n        print(\"No Dataset class instatiated.\")\n        \nprint(f'Checkpoints for Backbone 1: {len(models_backbone1)}',f'\\nCheckpoints for Backbone 2: {len(models_backbone2)}')","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:35.977806Z","iopub.execute_input":"2022-05-25T20:01:35.978066Z","iopub.status.idle":"2022-05-25T20:01:37.103798Z","shell.execute_reply.started":"2022-05-25T20:01:35.97803Z","shell.execute_reply":"2022-05-25T20:01:37.103069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET_SR = 32000\nDATADIR = Path(\"../input/birdclef-2022/test_soundscapes/\")","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:37.106173Z","iopub.execute_input":"2022-05-25T20:01:37.106729Z","iopub.status.idle":"2022-05-25T20:01:37.110471Z","shell.execute_reply.started":"2022-05-25T20:01:37.106697Z","shell.execute_reply":"2022-05-25T20:01:37.10954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_audios = list(DATADIR.glob(\"*.ogg\"))\nsample_submission = pd.read_csv('../input/birdclef-2022/sample_submission.csv')\nsample_submission","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:37.111593Z","iopub.execute_input":"2022-05-25T20:01:37.111905Z","iopub.status.idle":"2022-05-25T20:01:37.129142Z","shell.execute_reply.started":"2022-05-25T20:01:37.111868Z","shell.execute_reply":"2022-05-25T20:01:37.12846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a name=\"ensemble_class\"></a>\n#  Ensemble Class","metadata":{}},{"cell_type":"code","source":"class Ensemble(nn.Module):\n    def __init__(self,model_1,model_2,model_3,model_4,model_5,model_6,model_7,model_8,model_9,model_10,typeEnsemble='global_average'):\n        super(Ensemble, self).__init__()\n        #Bakbone1\n        self.model_1 = model_1\n        self.model_2 = model_2\n        self.model_3 = model_3\n        self.model_4 = model_4\n        self.model_5 = model_5\n        #Bakbone 2\n        self.model_6 = model_6\n        self.model_7 = model_7\n        self.model_8 = model_8\n        self.model_9 = model_9\n        self.model_10 = model_10\n        \n        self.typeEnsemble = typeEnsemble \n       \n        \n    def forward(self, image):\n        out1 = self.model_1(image)['clipwise_output']\n        out2 = self.model_2(image)['clipwise_output']\n        out3 = self.model_3(image)['clipwise_output']\n        out4 = self.model_4(image)['clipwise_output']\n        out5 = self.model_5(image)['clipwise_output']\n        \n        out6 = self.model_6(image)['clipwise_output']\n        out7 = self.model_7(image)['clipwise_output']\n        out8 = self.model_8(image)['clipwise_output']\n        out9 = self.model_9(image)['clipwise_output']\n        out10 = self.model_10(image)['clipwise_output']\n        \n        #Calculate out for backbone(n)\n        out_bkbn1= out1+out2+out3+out4+out5 #seresnext\n        out_bkbn2= out6+out7+out8+out9+out10 #eficientnet\n        \n        if self.typeEnsemble == 'global_average':\n            out_ensemble = (out_bkbn1 + out_bkbn2 )/ len(checkpoints_list)\n        elif self.typeEnsemble == 'weight_sum':\n            out_bkbn1/=len(checkpoints_list_backbone1) \n            out_bkbn2/=len(checkpoints_list_backbone2)\n            out_ensemble = out_bkbn1 * 0.7 + out_bkbn2*0.3 \n            \n       \n        return out_ensemble","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:37.130537Z","iopub.execute_input":"2022-05-25T20:01:37.131012Z","iopub.status.idle":"2022-05-25T20:01:37.142455Z","shell.execute_reply.started":"2022-05-25T20:01:37.130975Z","shell.execute_reply":"2022-05-25T20:01:37.141631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction functions - Ensemble","metadata":{}},{"cell_type":"code","source":"def calculate_probas_for_models_class(test_df: pd.DataFrame, \n                                clip: np.ndarray,\n                                model_21_class=False):\n\n    model_probas = []\n    probas_stacked = []\n    final_probas = []\n\n    #probas_dict = {f'Model_{i+1}': {} for i in range(len(checkpoints_list))}\n    probas_dict = {}\n\n    print(probas_dict)\n\n    print(\"\\nTotal number of checkpoints: \", len(checkpoints_list), \"\\n\")\n\n\n    # create test DataLoader object\n    dataset = TestDataset(df=test_df,clip=clip,)\n    loader = torchdata.DataLoader(dataset, batch_size=1, shuffle=False)\n    print('Input image shape', dataset[0]['image'].shape, '\\n')\n\n    ensembleModel = Ensemble(model_01,model_02,model_03,model_04,model_05,\n                             model_06,model_07,model_08,model_09,model_010, \n                             typeEnsemble='weight_sum')\n    \n    ensembleModel = ensembleModel.to(device)\n    ensembleModel.eval()\n\n    for data in tqdm(loader):\n        row_id = data['row_id'][0]\n        image = data['image'].to(device)\n        #probas_dict[row_id]= []   \n\n        with torch.no_grad():\n            probas = []\n            probas_long = []\n            with torch.cuda.amp.autocast():\n                output = ensembleModel(image)\n            probas.append(output.detach().cpu().numpy().reshape(-1))\n            probas = np.array(probas)\n            #print(f'Model {model_path}', row_id, probas.shape)\n            #print(probas_dict[f'Model {checkpoints_list.index(i+1)}'])\n            #probas_dict[f'Model {checkpoints_list.index(i)}'] = {row_id:probas}\n            #probas_dict[f'Model {checkpoints_list.index(i)+1}'].append({row_id:probas.flatten()})\n            probas_dict[row_id] = probas.flatten()\n    return probas_dict\n\ndef ensemble_soundscapes(probas_dict_clip, modelsList=None):\n    if modelsList is  None:\n        models_list = list(probas_dict_clip.keys())\n    else:\n        models_list = modelsList\n    print('Selected Checkpoints: ',models_list)\n    soundscapes_list = list(probas_dict_clip[models_list[0]].keys()) #assumindo que todos os modelos rodaram para todos os soundscapes\n    ensemble_soundscape_probas = {}\n    \n    for soundscape in soundscapes_list:\n        final_probas_soundscape = None\n        for idx,model in enumerate(models_list):\n            \n            if idx  == 0:\n                #print(soundscape, model)\n                final_probas_soundscape = probas_dict_clip[model][soundscape]\n                #print(probas_dict_clip[model][soundscape])\n            else:\n                #print(soundscape, model)\n                final_probas_soundscape += probas_dict_clip[model][soundscape]#para modelos treinados com o mesmo shape\n                #final_probas_soundscape[ibird_idx]*=probas_dict_clip[model][soundscape] #mu\n                #print(probas_dict_clip[model][soundscape])\n        final_probas_soundscape /= len(models_list) #media ponderada #para modelos treinados com o mesmo shape\n        #print(final_probas_soundscape)\n        ensemble_soundscape_probas[soundscape] =  final_probas_soundscape\n    \n    return ensemble_soundscape_probas\n\ndef create_prediction_dict(ensemble_soundscape_probas, treshold, percetile=None):\n    \n    prediction_dict = {}\n    \n\n    for soundscapes in list(ensemble_soundscape_probas.keys()):\n        probas =  ensemble_soundscape_probas[soundscapes]\n        if percetile is not None:\n         \n            treshold = np.quantile(probas.flatten(), percetile)\n        events = probas >= treshold\n        labels = np.argwhere(events).reshape(-1).tolist()\n        print(soundscapes, len(labels))\n\n        labels_str_list = list(map(lambda x: CFG_01.target_columns[x], labels))\n\n        label_string = \" \".join(labels_str_list)\n        prediction_dict[str(soundscapes)] = label_string\n        \n    return prediction_dict\n\ndef prediction_ensemble(test_audios,\n                       threshold=0.05, \n                       threshold_long=None,\n                       percetile=None,\n                       modelsList=None):\n    \n\n    warnings.filterwarnings(\"ignore\")\n    prediction_dicts = {}\n    \n    \n    time_velho = []\n    time_novo= []\n    for audio_path in test_audios:\n            print(f\"Loading {str(audio_path)}\")\n            clip, _ = sf.read(audio_path, always_2d=True)\n            clip = np.mean(clip, 1)\n            \n            seconds = []\n            row_ids = []\n        \n            for second in range(5, 65, 5):\n                row_id = \"_\".join(audio_path.name.split(\".\")[:-1]) + f\"_{second}\"\n                seconds.append(second)\n                row_ids.append(row_id)\n            \n            print(row_ids)\n\n            test_df = pd.DataFrame({\n                \"row_id\": row_ids,\n                \"seconds\": seconds\n            })\n            \n            print(f\"Prediction on {audio_path}\")\n\n            \n            ensemble_soundscape_probas = calculate_probas_for_models_class(test_df, \n                                                                            clip, \n                                                                            model_21_class=True)\n        \n      \n    \n            prediction_dict = create_prediction_dict(ensemble_soundscape_probas, treshold=threshold, percetile=percetile)\n            \n    \n                \n            prediction_dicts.update(prediction_dict)\n    \n    return prediction_dicts\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:37.143993Z","iopub.execute_input":"2022-05-25T20:01:37.144423Z","iopub.status.idle":"2022-05-25T20:01:37.167971Z","shell.execute_reply.started":"2022-05-25T20:01:37.144386Z","shell.execute_reply":"2022-05-25T20:01:37.166997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference ","metadata":{}},{"cell_type":"code","source":"q = 70 \ntresh_quantile = None\nprediction_dicts = prediction_ensemble(test_audios=all_audios,\n                                       threshold=0.27, \n                                       threshold_long=None,\n                                       percetile=tresh_quantile,\n                                       modelsList=None)\n\n# print(prediction_dicts)\n\nfor i in range(len(sample_submission)):\n    sample = sample_submission.row_id[i]\n    key = sample.split(\"_\")[0] + \"_\" + sample.split(\"_\")[1] + \"_\" + sample.split(\"_\")[3]\n    target_bird = sample.split(\"_\")[2]\n    print(key, target_bird)\n    if key in prediction_dicts:\n        sample_submission.iat[i, 1] = (target_bird in prediction_dicts[key])\n        \n       \nsample_submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:37.169475Z","iopub.execute_input":"2022-05-25T20:01:37.169961Z","iopub.status.idle":"2022-05-25T20:01:39.826001Z","shell.execute_reply.started":"2022-05-25T20:01:37.169923Z","shell.execute_reply":"2022-05-25T20:01:39.825313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sub","metadata":{}},{"cell_type":"code","source":" pd.read_csv('./submission.csv').head(10)","metadata":{"execution":{"iopub.status.busy":"2022-05-25T20:01:39.827564Z","iopub.execute_input":"2022-05-25T20:01:39.827813Z","iopub.status.idle":"2022-05-25T20:01:39.840216Z","shell.execute_reply.started":"2022-05-25T20:01:39.827778Z","shell.execute_reply":"2022-05-25T20:01:39.839314Z"},"trusted":true},"execution_count":null,"outputs":[]}]}