{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Inference using 21Classes","metadata":{}},{"cell_type":"markdown","source":"#### Code copied with minimal changes from this Notebook:\nhttps://www.kaggle.com/code/myso1987/birdclef2022-pytorch-resnet34-starter-lb-0-50","metadata":{}},{"cell_type":"markdown","source":"# Install required packages","metadata":{}},{"cell_type":"code","source":"!cp -r ../input/timm-pytorch-image-models .","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:08:44.412208Z","iopub.execute_input":"2022-05-24T04:08:44.412692Z","iopub.status.idle":"2022-05-24T04:08:46.721938Z","shell.execute_reply.started":"2022-05-24T04:08:44.4126Z","shell.execute_reply":"2022-05-24T04:08:46.720978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install timm-pytorch-image-models/pytorch-image-models-master/","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:08:46.724174Z","iopub.execute_input":"2022-05-24T04:08:46.724456Z","iopub.status.idle":"2022-05-24T04:09:17.897082Z","shell.execute_reply.started":"2022-05-24T04:08:46.724422Z","shell.execute_reply":"2022-05-24T04:09:17.896208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/torchlibrosa .","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:17.898555Z","iopub.execute_input":"2022-05-24T04:09:17.898828Z","iopub.status.idle":"2022-05-24T04:09:18.576151Z","shell.execute_reply.started":"2022-05-24T04:09:17.89879Z","shell.execute_reply":"2022-05-24T04:09:18.575197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchlibrosa/torchlibrosa-0.0.5-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:18.578551Z","iopub.execute_input":"2022-05-24T04:09:18.578839Z","iopub.status.idle":"2022-05-24T04:09:46.042147Z","shell.execute_reply.started":"2022-05-24T04:09:18.5788Z","shell.execute_reply":"2022-05-24T04:09:46.041333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install catalyst==20.12","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:46.043593Z","iopub.execute_input":"2022-05-24T04:09:46.043835Z","iopub.status.idle":"2022-05-24T04:09:46.049617Z","shell.execute_reply.started":"2022-05-24T04:09:46.043801Z","shell.execute_reply":"2022-05-24T04:09:46.048472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Library","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nimport tqdm\nimport random\nimport shutil\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nimport torchaudio\nimport torchaudio.transforms as T\nfrom torchvision.models.resnet import ResNet, BasicBlock\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import f1_score ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-24T04:09:46.051251Z","iopub.execute_input":"2022-05-24T04:09:46.051835Z","iopub.status.idle":"2022-05-24T04:09:48.669895Z","shell.execute_reply.started":"2022-05-24T04:09:46.051799Z","shell.execute_reply":"2022-05-24T04:09:48.668887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\nimport os\nimport math\nimport random\nimport warnings\n\nimport albumentations as A\nimport cv2\nimport librosa\nimport numpy as np\nimport pandas as pd\nimport soundfile as sf\nimport timm\nimport torch\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data as torchdata\n\nfrom pathlib import Path\nfrom typing import List\n\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations.core.transforms_interface import ImageOnlyTransform\nfrom sklearn import model_selection\nfrom sklearn import metrics\nfrom timm.models.layers import SelectAdaptivePool2d\nfrom torch.optim.optimizer import Optimizer\nfrom torchlibrosa.stft import LogmelFilterBank, Spectrogram\nfrom torchlibrosa.augmentation import SpecAugmentation\nimport logging\nfrom logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:48.671373Z","iopub.execute_input":"2022-05-24T04:09:48.67164Z","iopub.status.idle":"2022-05-24T04:09:51.699621Z","shell.execute_reply.started":"2022-05-24T04:09:48.671605Z","shell.execute_reply":"2022-05-24T04:09:51.698751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed: int = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)  # type: ignore\n    torch.backends.cudnn.deterministic = True  # type: ignore\n    torch.backends.cudnn.benchmark = True  # type: ignore\n\ndef init_logger(log_file='train.log'):\n    \n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n    \ndef get_logger(out_file=None):\n    logger = logging.getLogger()\n    formatter = logging.Formatter(\"%(asctime)s - %(levelname)s - %(message)s\")\n    logger.handlers = []\n    logger.setLevel(logging.INFO)\n\n    handler = logging.StreamHandler()\n    handler.setFormatter(formatter)\n    handler.setLevel(logging.INFO)\n    logger.addHandler(handler)\n\n    if out_file is not None:\n        fh = logging.FileHandler(out_file)\n        fh.setFormatter(formatter)\n        fh.setLevel(logging.INFO)\n        logger.addHandler(fh)\n    logger.info(\"logger set up\")\n    return logger\n\ndef get_device() -> torch.device:\n    return torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.701301Z","iopub.execute_input":"2022-05-24T04:09:51.701625Z","iopub.status.idle":"2022-05-24T04:09:51.714097Z","shell.execute_reply.started":"2022-05-24T04:09:51.701581Z","shell.execute_reply":"2022-05-24T04:09:51.71343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"logger = get_logger(\"main.log\")\nset_seed(1213)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.715324Z","iopub.execute_input":"2022-05-24T04:09:51.716022Z","iopub.status.idle":"2022-05-24T04:09:51.732399Z","shell.execute_reply.started":"2022-05-24T04:09:51.715983Z","shell.execute_reply":"2022-05-24T04:09:51.731532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = get_device()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.736576Z","iopub.execute_input":"2022-05-24T04:09:51.736763Z","iopub.status.idle":"2022-05-24T04:09:51.792253Z","shell.execute_reply.started":"2022-05-24T04:09:51.73674Z","shell.execute_reply":"2022-05-24T04:09:51.791215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"root_path = \"../input/birdclef-2022/\"\ninput_path = root_path + '/train_audio/'\nout_path = \"./train/\"\n\ntry:\n    os.mkdir(out_path)\nexcept FileExistsError:\n    pass\n\n\ntrain_meta = pd.read_csv(root_path + 'train_metadata.csv')\n\nwith open(root_path + '/scored_birds.json') as sbfile:\n    scored_birds = json.load(sbfile)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.793723Z","iopub.execute_input":"2022-05-24T04:09:51.794473Z","iopub.status.idle":"2022-05-24T04:09:51.896137Z","shell.execute_reply.started":"2022-05-24T04:09:51.794435Z","shell.execute_reply":"2022-05-24T04:09:51.895389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(scored_birds)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.897396Z","iopub.execute_input":"2022-05-24T04:09:51.897892Z","iopub.status.idle":"2022-05-24T04:09:51.90619Z","shell.execute_reply.started":"2022-05-24T04:09:51.897854Z","shell.execute_reply":"2022-05-24T04:09:51.905476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scored_birds","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.907531Z","iopub.execute_input":"2022-05-24T04:09:51.907875Z","iopub.status.idle":"2022-05-24T04:09:51.916257Z","shell.execute_reply.started":"2022-05-24T04:09:51.90784Z","shell.execute_reply":"2022-05-24T04:09:51.915397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### only 21 classes","metadata":{}},{"cell_type":"code","source":"train_meta_21classes = train_meta[train_meta['primary_label'].isin(scored_birds)]\nbird_label_21classes = sorted(train_meta_21classes[\"primary_label\"].unique())\nbird_label_total = sorted(train_meta[\"primary_label\"].unique())\nprint(bird_label_21classes,\"\\n\", bird_label_total)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.91739Z","iopub.execute_input":"2022-05-24T04:09:51.91786Z","iopub.status.idle":"2022-05-24T04:09:51.938468Z","shell.execute_reply.started":"2022-05-24T04:09:51.917823Z","shell.execute_reply":"2022-05-24T04:09:51.937671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from ast import literal_eval\n#train_meta['secondary_labels'] = train_meta['secondary_labels'].map(lambda x: literal_eval(x))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.939914Z","iopub.execute_input":"2022-05-24T04:09:51.94034Z","iopub.status.idle":"2022-05-24T04:09:51.947904Z","shell.execute_reply.started":"2022-05-24T04:09:51.940309Z","shell.execute_reply":"2022-05-24T04:09:51.947223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#total = []\n#second_labels =  train_meta['secondary_labels'].tolist()\n#for s in second_labels:\n#    total.extend(s)\n#secondary_labels = list(set(total))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.950855Z","iopub.execute_input":"2022-05-24T04:09:51.95109Z","iopub.status.idle":"2022-05-24T04:09:51.956977Z","shell.execute_reply.started":"2022-05-24T04:09:51.951065Z","shell.execute_reply":"2022-05-24T04:09:51.956329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    ######################\n    # Globals #\n    ######################\n    seed = 1213\n    epochs = 35\n    train = True\n    folds = [0]\n    img_size = 224\n    main_metric = \"epoch_f1_at_05\"\n    minimize_metric = False\n\n    ######################\n    # Data #\n    ######################\n    train_datadir = Path(\"../input/birdclef-2022/train_audio\")\n    train_csv = train_meta\n    #train_soundscape = \"../input/birdclef-2021/train_soundscape_labels.csv\"\n\n    ######################\n    # Dataset #\n    ######################\n    transforms = {\n        \"train\": [{\"name\": \"Normalize\"}],\n        \"valid\": [{\"name\": \"Normalize\"}],\n        \"test\": [{\"name\": \"Normalize\"}]\n    }\n    period = 20\n    n_mels = 256\n    fmin = 20\n    fmax = 16000\n    n_fft = 2048\n    hop_length = 512\n    sample_rate = 32000\n    melspectrogram_parameters = {\n        \"n_mels\": 256,\n        \"fmin\": 20,\n        \"fmax\": 16000\n    }\n\n    target_columns = scored_birds\n\n    ######################\n    # Loaders #\n    ######################\n    loader_params = {\n        \"train\": {\n            \"batch_size\": 32,\n            \"num_workers\": 20,\n            \"shuffle\": True\n        },\n        \"valid\": {\n            \"batch_size\": 64,\n            \"num_workers\": 20,\n            \"shuffle\": False\n        },\n        \"test\": {\n            \"batch_size\": 64,\n            \"num_workers\": 20,\n            \"shuffle\": False\n        }\n    }\n\n    ######################\n    # Split #\n    ######################\n    split = \"StratifiedKFold\"\n    split_params = {\n        \"n_splits\": 5,\n        \"shuffle\": True,\n        \"random_state\": 1213\n    }\n\n    ######################\n    # Model #\n    ######################\n    base_model_name = \"tf_efficientnet_b0_ns\"\n    pooling = \"max\"\n    pretrained = True\n    num_classes = 21\n    n_pretrain_classes = 131\n    in_channels = 1\n\n    ######################\n    # Criterion #\n    ######################\n    loss_name = \"BCEFocal2WayLoss\"\n    loss_params: dict = {}\n\n    ######################\n    # Optimizer #\n    ######################\n    optimizer_name = \"Adam\"\n    base_optimizer = \"Adam\"\n    optimizer_params = {\n        \"lr\": 0.001\n    }\n    # For SAM optimizer\n    base_optimizer = \"Adam\"\n\n    ######################\n    # Scheduler #\n    ######################\n    scheduler_name = \"CosineAnnealingLR\"\n    scheduler_params = {\n        \"T_max\": 10\n    }","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.959774Z","iopub.execute_input":"2022-05-24T04:09:51.960108Z","iopub.status.idle":"2022-05-24T04:09:51.973109Z","shell.execute_reply.started":"2022-05-24T04:09:51.960075Z","shell.execute_reply":"2022-05-24T04:09:51.971727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_NFNETMIXUP:\n    ######################\n    # Globals #\n    ######################\n        fold = 4\n        DEBUG = False\n        mixed_precision = False\n        period = 5\n        hop_length = 320\n        seed = 1213\n        epochs = 100\n        train = True\n        folds = [0]\n        img_size = 224\n        main_metric = \"epoch_f1_at_02\"\n        minimize_metric = False\n\n        ######################\n        # Data #\n        ######################\n        train_datadir = Path(\"../input/birdclef-2022/train_audio\")\n        train_csv = train_meta\n        #train_soundscape = \"../input/birdclef-2021/train_soundscape_labels.csv\"\n\n        ######################\n        # Dataset #\n        ######################\n        transforms = {\n            \"train\": [{\"name\": \"Normalize\"}],\n            \"valid\": [{\"name\": \"Normalize\"}],\n            \"test\": [{\"name\": \"Normalize\"}]\n        }\n        \n        n_mels = 256\n        #256 change 비교 필요\n        fmin = 10\n        fmax = 16000\n        n_fft = 2048\n        \n        sample_rate = 32000\n        melspectrogram_parameters = {\n            \"n_mels\": 256,\n            \"fmin\": 20,\n            \"fmax\": 16000\n        }\n\n        target_columns = bird_label_total\n\n        ######################\n        # Loaders #\n        ######################\n        loader_params = {\n            \"train\": {\n                \"batch_size\": 32,\n                \"num_workers\": 20,\n                \"shuffle\": True\n            },\n            \"valid\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            },\n            \"test\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            }\n        }\n\n        ######################\n        # Split #\n        ######################\n        split = \"StratifiedKFold\"\n        split_params = {\n            \"n_splits\": 5,\n            \"shuffle\": True,\n            \"random_state\": 1213\n        }\n\n        ######################\n        # Model #\n        ######################\n        base_model_name = \"eca_nfnet_l0\"\n        pooling = \"max\"\n        pretrained = False\n        num_classes = len(bird_label_total)\n        in_channels = 1\n\n        ######################\n        # Criterion #\n        ######################\n        loss_name = \"BCEFocal2WayLoss\"\n        loss_params: dict = {}\n\n        ######################\n        # Optimizer #\n        ######################\n        optimizer_name = \"Adam\"\n        base_optimizer = \"Adam\"\n        optimizer_params = {\n            \"lr\": 0.0005,\n            #\"weight_decay\":1e-2,\n        }\n\n        ######################\n        # Scheduler #\n        ######################\n        scheduler_name = \"CosineAnnealingLR\"","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.974735Z","iopub.execute_input":"2022-05-24T04:09:51.975015Z","iopub.status.idle":"2022-05-24T04:09:51.987862Z","shell.execute_reply.started":"2022-05-24T04:09:51.974965Z","shell.execute_reply":"2022-05-24T04:09:51.987188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_EFFV2DOUBLEMIXUP:\n    ######################\n    # Globals #\n    ######################\n        fold = 4\n        DEBUG = False\n        mixed_precision = False\n        period = 5\n        hop_length = 320\n        seed = 1213\n        epochs = 100\n        train = True\n        folds = [0]\n        img_size = 224\n        main_metric = \"epoch_f1_at_02\"\n        minimize_metric = False\n\n        ######################\n        # Data #\n        ######################\n        train_datadir = Path(\"../input/birdclef-2022/train_audio\")\n        train_csv = train_meta\n        #train_soundscape = \"../input/birdclef-2021/train_soundscape_labels.csv\"\n\n        ######################\n        # Dataset #\n        ######################\n        transforms = {\n            \"train\": [{\"name\": \"Normalize\"}],\n            \"valid\": [{\"name\": \"Normalize\"}],\n            \"test\": [{\"name\": \"Normalize\"}]\n        }\n        \n        n_mels = 128\n        #256 change 비교 필요\n        fmin = 10\n        fmax = 16000\n        n_fft = 1024\n        \n        sample_rate = 32000\n        melspectrogram_parameters = {\n            \"n_mels\": 128,\n            \"fmin\": 20,\n            \"fmax\": 16000\n        }\n\n        target_columns = bird_label_total\n\n        ######################\n        # Loaders #\n        ######################\n        loader_params = {\n            \"train\": {\n                \"batch_size\": 32,\n                \"num_workers\": 20,\n                \"shuffle\": True\n            },\n            \"valid\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            },\n            \"test\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            }\n        }\n\n        ######################\n        # Split #\n        ######################\n        split = \"StratifiedKFold\"\n        split_params = {\n            \"n_splits\": 4,\n            \"shuffle\": True,\n            \"random_state\": 1213\n        }\n\n        ######################\n        # Model #\n        ######################\n        base_model_name = \"tf_efficientnetv2_s_in21k\"\n        pooling = \"max\"\n        pretrained = False\n        num_classes = len(bird_label_total)\n        in_channels = 1\n\n        ######################\n        # Criterion #\n        ######################\n        loss_name = \"BCEFocal2WayLoss\"\n        loss_params: dict = {}\n\n        ######################\n        # Optimizer #\n        ######################\n        optimizer_name = \"Adam\"\n        base_optimizer = \"Adam\"\n        optimizer_params = {\n            \"lr\": 0.0005,\n            #\"weight_decay\":1e-2,\n        }\n\n        ######################\n        # Scheduler #\n        ######################\n        scheduler_name = \"CosineAnnealingLR\"","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:51.989531Z","iopub.execute_input":"2022-05-24T04:09:51.990036Z","iopub.status.idle":"2022-05-24T04:09:52.003434Z","shell.execute_reply.started":"2022-05-24T04:09:51.989964Z","shell.execute_reply":"2022-05-24T04:09:52.002749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_EFFV2DOUBLEMIXUP_64MEL:\n    ######################\n    # Globals #\n    ######################\n        fold = 4\n        DEBUG = False\n        mixed_precision = False\n        period = 5\n        hop_length = 512\n        seed = 1213\n        epochs = 100\n        train = True\n        folds = [0]\n        img_size = 224\n        main_metric = \"epoch_f1_at_02\"\n        minimize_metric = False\n\n        ######################\n        # Data #\n        ######################\n        train_datadir = Path(\"../input/birdclef-2022/train_audio\")\n        train_csv = train_meta\n        #train_soundscape = \"../input/birdclef-2021/train_soundscape_labels.csv\"\n\n        ######################\n        # Dataset #\n        ######################\n        transforms = {\n            \"train\": [{\"name\": \"Normalize\"}],\n            \"valid\": [{\"name\": \"Normalize\"}],\n            \"test\": [{\"name\": \"Normalize\"}]\n        }\n        \n        n_mels = 64\n        #256 change 비교 필요\n        fmin = 10\n        fmax = 16000\n        n_fft = 2048\n        \n        sample_rate = 32000\n        melspectrogram_parameters = {\n            \"n_mels\": 64,\n            \"fmin\": 20,\n            \"fmax\": 16000\n        }\n\n        target_columns = bird_label_total\n\n        ######################\n        # Loaders #\n        ######################\n        loader_params = {\n            \"train\": {\n                \"batch_size\": 32,\n                \"num_workers\": 20,\n                \"shuffle\": True\n            },\n            \"valid\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            },\n            \"test\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            }\n        }\n\n        ######################\n        # Split #\n        ######################\n        split = \"StratifiedKFold\"\n        split_params = {\n            \"n_splits\": 4,\n            \"shuffle\": True,\n            \"random_state\": 1213\n        }\n\n        ######################\n        # Model #\n        ######################\n        base_model_name = \"tf_efficientnetv2_s_in21k\"\n        pooling = \"max\"\n        pretrained = False\n        num_classes = len(bird_label_total)\n        in_channels = 1\n\n        ######################\n        # Criterion #\n        ######################\n        loss_name = \"BCEFocal2WayLoss\"\n        loss_params: dict = {}\n\n        ######################\n        # Optimizer #\n        ######################\n        optimizer_name = \"Adam\"\n        base_optimizer = \"Adam\"\n        optimizer_params = {\n            \"lr\": 0.0005,\n            #\"weight_decay\":1e-2,\n        }\n\n        ######################\n        # Scheduler #\n        ######################\n        scheduler_name = \"CosineAnnealingLR\"","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.005045Z","iopub.execute_input":"2022-05-24T04:09:52.005538Z","iopub.status.idle":"2022-05-24T04:09:52.018991Z","shell.execute_reply.started":"2022-05-24T04:09:52.005488Z","shell.execute_reply":"2022-05-24T04:09:52.018262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_EFFV2MDOUBLEMIXUP:\n    ######################\n    # Globals #\n    ######################\n        fold = 4\n        DEBUG = False\n        mixed_precision = False\n        period = 5\n        hop_length = 320\n        seed = 1213\n        epochs = 100\n        train = True\n        folds = [0]\n        img_size = 224\n        main_metric = \"epoch_f1_at_02\"\n        minimize_metric = False\n\n        ######################\n        # Data #\n        ######################\n        train_datadir = Path(\"../input/birdclef-2022/train_audio\")\n        train_csv = train_meta\n        #train_soundscape = \"../input/birdclef-2021/train_soundscape_labels.csv\"\n\n        ######################\n        # Dataset #\n        ######################\n        transforms = {\n            \"train\": [{\"name\": \"Normalize\"}],\n            \"valid\": [{\"name\": \"Normalize\"}],\n            \"test\": [{\"name\": \"Normalize\"}]\n        }\n        \n        n_mels = 128\n        #256 change 비교 필요\n        fmin = 10\n        fmax = 16000\n        n_fft = 1024\n        \n        sample_rate = 32000\n        melspectrogram_parameters = {\n            \"n_mels\": 128,\n            \"fmin\": 20,\n            \"fmax\": 16000\n        }\n\n        target_columns = bird_label_total\n\n        ######################\n        # Loaders #\n        ######################\n        loader_params = {\n            \"train\": {\n                \"batch_size\": 32,\n                \"num_workers\": 20,\n                \"shuffle\": True\n            },\n            \"valid\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            },\n            \"test\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            }\n        }\n\n        ######################\n        # Split #\n        ######################\n        split = \"StratifiedKFold\"\n        split_params = {\n            \"n_splits\": 4,\n            \"shuffle\": True,\n            \"random_state\": 1213\n        }\n\n        ######################\n        # Model #\n        ######################\n        base_model_name = \"tf_efficientnetv2_m_in21k\"\n        pooling = \"max\"\n        pretrained = False\n        num_classes = len(bird_label_total)\n        in_channels = 1\n\n        ######################\n        # Criterion #\n        ######################\n        loss_name = \"BCEFocal2WayLoss\"\n        loss_params: dict = {}\n\n        ######################\n        # Optimizer #\n        ######################\n        optimizer_name = \"Adam\"\n        base_optimizer = \"Adam\"\n        optimizer_params = {\n            \"lr\": 0.0005,\n            #\"weight_decay\":1e-2,\n        }\n\n        ######################\n        # Scheduler #\n        ######################\n        scheduler_name = \"CosineAnnealingLR\"","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.020669Z","iopub.execute_input":"2022-05-24T04:09:52.020981Z","iopub.status.idle":"2022-05-24T04:09:52.034618Z","shell.execute_reply.started":"2022-05-24T04:09:52.020946Z","shell.execute_reply":"2022-05-24T04:09:52.033665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG_NFNET0_SPEC_64MEL_15SEC:\n    ######################\n    # Globals #\n    ######################\n        fold = 0\n        DEBUG = False\n        mixed_precision = False\n        savename = f\"totalclass-doublemixup-5sec-length2048-64mel-512hop-weightmixed-nfnet-pretrain-fold-{fold}\"\n        period = 15\n        hop_length = 512\n        seed = 888\n        epochs = 100\n        train = True\n        folds = [0]\n        img_size = 224\n        main_metric = \"epoch_f1_at_02\"\n        minimize_metric = False\n\n        ######################\n        # Data #\n        ######################\n        train_datadir = Path(\"train\")\n        train_csv = train_meta\n        #train_soundscape = \"../input/birdclef-2021/train_soundscape_labels.csv\"\n\n        ######################\n        # Dataset #\n        ######################\n        transforms = {\n            #\"train\": [{\"name\":\"PitchShift\"},{\"name\":\"PinkNoise\"},{\"name\":\"RandomVolume\"},{\"name\": \"Normalize\"}],\n            \"train\": [{\"name\":\"GaussianNoise\"},{\"name\":\"PinkNoise\"},{\"name\":\"RandomVolume\"},{\"name\": \"Normalize\"}],\n            \"valid\": [{\"name\": \"Normalize\"}],\n            \"test\": [{\"name\": \"Normalize\"}]\n        }\n        \n        n_mels = 64\n        #256 change 비교 필요\n        fmin = 10\n        fmax = 16000\n        n_fft = 2048\n        \n        sample_rate = 32000\n        melspectrogram_parameters = {\n            \"n_mels\": n_mels,\n            \"fmin\": 20,\n            \"fmax\": 16000\n        }\n\n        target_columns = bird_label_total\n\n        ######################\n        # Loaders #\n        ######################\n        loader_params = {\n            \"train\": {\n                \"batch_size\": 32,\n                \"num_workers\": 20,\n                \"shuffle\": True\n            },\n            \"valid\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            },\n            \"test\": {\n                \"batch_size\": 64,\n                \"num_workers\": 20,\n                \"shuffle\": False\n            }\n        }\n\n        ######################\n        # Split #\n        ######################\n        split = \"StratifiedKFold\"\n        split_params = {\n            \"n_splits\": 4,\n            \"shuffle\": True,\n            \"random_state\": 888\n        }\n\n        ######################\n        # Model #\n        ######################\n        base_model_name = \"eca_nfnet_l0\"\n        pooling = \"max\"\n        pretrained = False\n        num_classes = len(bird_label_total)\n        in_channels = 1\n\n        ######################\n        # Criterion #\n        ######################\n        loss_name = \"BCEFocal2WayLoss\"\n        loss_params: dict = {}\n\n        ######################\n        # Optimizer #\n        ######################\n        optimizer_name = \"Adam\"\n        base_optimizer = \"Adam\"\n        optimizer_params = {\n            \"lr\": 0.0005,\n            #\"weight_decay\":1e-2,\n        }\n\n        ######################\n        # Scheduler #\n        ######################\n        scheduler_name = \"CosineAnnealingLR\"\n        #scheduler_params = {\n        #    #\"T_max\": 25,\n        #    \"eta_min\": 1e-5,\n        #}","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.036214Z","iopub.execute_input":"2022-05-24T04:09:52.036477Z","iopub.status.idle":"2022-05-24T04:09:52.050886Z","shell.execute_reply.started":"2022-05-24T04:09:52.036427Z","shell.execute_reply":"2022-05-24T04:09:52.05007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MixupTimmNFNETSPECSED\n#CFG_NFNET0_SPEC_64MEL_15SEC","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.052479Z","iopub.execute_input":"2022-05-24T04:09:52.052752Z","iopub.status.idle":"2022-05-24T04:09:52.07556Z","shell.execute_reply.started":"2022-05-24T04:09:52.052718Z","shell.execute_reply":"2022-05-24T04:09:52.074873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MixupTimmNFNETSPECSED(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG_NFNET0_SPEC_64MEL_15SEC.n_fft, hop_length=CFG_NFNET0_SPEC_64MEL_15SEC.hop_length,\n                                                 win_length=CFG_NFNET0_SPEC_64MEL_15SEC.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG_NFNET0_SPEC_64MEL_15SEC.sample_rate, n_fft=CFG_NFNET0_SPEC_64MEL_15SEC.n_fft,\n                                                 n_mels=CFG_NFNET0_SPEC_64MEL_15SEC.n_mels, fmin=CFG_NFNET0_SPEC_64MEL_15SEC.fmin, fmax=CFG_NFNET0_SPEC_64MEL_15SEC.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        \n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n\n        self.mixup = Mixup()\n        self.bn0 = nn.BatchNorm2d(CFG_NFNET0_SPEC_64MEL_15SEC.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n        if hasattr(base_model, \"head\"):\n            in_features = base_model.head.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n\n        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n\n    def forward(self, batch):\n        # batch -> image, target for mixup\n        input, target = batch\n\n\n        # (batch_size, 1, time_steps, freq_bins)\n        x = self.spectrogram_extractor(input)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n        frames_num = x.shape[2]\n\n        if self.training:\n            \n            x, mixup_target = self.mixup(x, target)\n            if np.random.uniform() < 0.5:\n                x, mixup_target = self.mixup(x, mixup_target)\n\n            #mixup_target = mixup_target * weight.view(-1,1)\n            #print(\"mixuped :\", mixup_target, \"before : \", target)\n        \n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n        if self.training:\n            x = self.spec_augmenter(x)\n        #if self.training:\n        #    x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        #(x, _) = self.gru(x)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num : \", frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n        if self.training:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":mixup_target\n            }\n        else:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":target\n            }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.077006Z","iopub.execute_input":"2022-05-24T04:09:52.077325Z","iopub.status.idle":"2022-05-24T04:09:52.099942Z","shell.execute_reply.started":"2022-05-24T04:09:52.077293Z","shell.execute_reply":"2022-05-24T04:09:52.098819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MixupTimmEFFV2SED(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG_EFFV2DOUBLEMIXUP.n_fft, hop_length=CFG_EFFV2DOUBLEMIXUP.hop_length,\n                                                 win_length=CFG_EFFV2DOUBLEMIXUP.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG_EFFV2DOUBLEMIXUP.sample_rate, n_fft=CFG_EFFV2DOUBLEMIXUP.n_fft,\n                                                 n_mels=CFG_EFFV2DOUBLEMIXUP.n_mels, fmin=CFG_EFFV2DOUBLEMIXUP.fmin, fmax=CFG_EFFV2DOUBLEMIXUP.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        \n        self.mixup = Mixup()\n        self.bn0 = nn.BatchNorm2d(CFG_EFFV2DOUBLEMIXUP.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n        if hasattr(base_model, \"head\"):\n            in_features = base_model.head.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n\n        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n\n    def forward(self, batch):\n        # batch -> image, target for mixup\n        input, target = batch\n        if CFG_EFFV2DOUBLEMIXUP.DEBUG:\n            print(\"mixup before image shape: \", input.shape, \"target before mixup shape: \", target.shape)\n\n        # (batch_size, 1, time_steps, freq_bins)\n        x = self.spectrogram_extractor(input)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n        frames_num = x.shape[2]\n\n        if self.training:\n            \n            x, mixup_target, weight = self.mixup(x, target)\n            if np.random.uniform() < 0.5:\n                x, mixup_target, weight = self.mixup(x, mixup_target)\n\n            #mixup_target = mixup_target * weight.view(-1,1)\n            #print(\"mixuped :\", mixup_target, \"before : \", target)\n        \n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n\n        #if self.training:\n        #    x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        #(x, _) = self.gru(x)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num : \", frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n        if self.training:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":mixup_target\n            }\n        else:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":target\n            }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.101374Z","iopub.execute_input":"2022-05-24T04:09:52.101922Z","iopub.status.idle":"2022-05-24T04:09:52.125092Z","shell.execute_reply.started":"2022-05-24T04:09:52.101886Z","shell.execute_reply":"2022-05-24T04:09:52.124365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# this notebook is by default run on debug mode (only train one epoch).\n# If you'd like to get the results on par with that of inference notebook, you'll need to train the model around 30 epochs\nDEBUG = False\nif DEBUG:\n    CFG.epochs = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.126175Z","iopub.execute_input":"2022-05-24T04:09:52.126902Z","iopub.status.idle":"2022-05-24T04:09:52.137145Z","shell.execute_reply.started":"2022-05-24T04:09:52.126867Z","shell.execute_reply":"2022-05-24T04:09:52.136394Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Utils","metadata":{}},{"cell_type":"code","source":"#sample_rate = 32000\n#n_fft = 4096\n#win_length = None\n#hop_length = 512\n#n_mels = 256\n#min_sec_proc = sample_rate*5\n\n#mel_spectrogram = T.MelSpectrogram(\n#    sample_rate=sample_rate,\n#    n_fft=n_fft,\n#    win_length=win_length,\n#    hop_length=hop_length,\n#    center=True,\n#    pad_mode=\"reflect\",\n#    power=2.0,\n#    norm='slaney',\n#    onesided=True,\n#    n_mels=n_mels,\n#    mel_scale=\"htk\",\n#)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.138301Z","iopub.execute_input":"2022-05-24T04:09:52.138624Z","iopub.status.idle":"2022-05-24T04:09:52.146614Z","shell.execute_reply.started":"2022-05-24T04:09:52.138589Z","shell.execute_reply":"2022-05-24T04:09:52.145946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class WaveformDataset(Dataset):\n    def __init__(self,\n                 df: pd.DataFrame,\n                 datadir: Path,\n                 img_size=224,\n                 waveform_transforms=None,\n                 period=5,\n                 validation=False):\n        self.df = df\n        self.datadir = datadir\n        self.img_size = img_size\n        self.waveform_transforms = waveform_transforms\n        self.period = period\n        self.validation = validation\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx: int):\n        sample = self.df.loc[idx, :]\n        wav_name = sample[\"filename\"]\n        ebird_code = sample[\"primary_label\"]\n        \n        y, sr = sf.read(self.datadir / wav_name)\n        len_wav_shape = len(y.shape)\n        if len_wav_shape == 1:\n            pass\n        else:\n            y = y[:,0]\n        \n       # print(\"shape y : \", y.shape)\n        len_y = len(y)\n        effective_length = sr * self.period\n        if len_y < effective_length:\n            new_y = np.zeros(effective_length, dtype=y.dtype)\n            if not self.validation:\n                start = np.random.randint(effective_length - len_y)\n            else:\n                start = 0\n            new_y[start:start + len_y] = y\n            y = new_y.astype(np.float32)\n        elif len_y > effective_length:\n            if not self.validation:\n                start = np.random.randint(len_y - effective_length)\n            else:\n                start = 0\n            y = y[start:start + effective_length].astype(np.float32)\n        else:\n            y = y.astype(np.float32)\n\n        y = np.nan_to_num(y)\n\n        if self.waveform_transforms:\n            y = self.waveform_transforms(y)\n\n        y = np.nan_to_num(y)\n\n        labels = np.zeros(len(CFG.target_columns), dtype=float)\n        labels[CFG.target_columns.index(ebird_code)] = 1.0\n\n        return {\n            \"image\": y,\n            \"targets\": labels\n        }","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.152947Z","iopub.execute_input":"2022-05-24T04:09:52.153482Z","iopub.status.idle":"2022-05-24T04:09:52.166318Z","shell.execute_reply.started":"2022-05-24T04:09:52.153451Z","shell.execute_reply":"2022-05-24T04:09:52.165471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(phase: str):\n    #transforms = {\n    #    \"train\": [{\"name\": \"Normalize\"}],\n    #    \"valid\": [{\"name\": \"Normalize\"}]\n    #}\n    transforms = CFG.transforms\n    if transforms is None:\n        return None\n    else:\n        if transforms[phase] is None:\n            return None\n        trns_list = []\n        for trns_conf in transforms[phase]:\n            trns_name = trns_conf[\"name\"]\n            trns_params = {} if trns_conf.get(\"params\") is None else \\\n                trns_conf[\"params\"]\n            if globals().get(trns_name) is not None:\n                trns_cls = globals()[trns_name]\n                trns_list.append(trns_cls(**trns_params))\n\n        if len(trns_list) > 0:\n            return Compose(trns_list)\n        else:\n            return None\n        \n        \nclass Normalize:\n    def __call__(self, y: np.ndarray):\n        max_vol = np.abs(y).max()\n        y_vol = y * 1 / max_vol\n        return np.asfortranarray(y_vol)\n\n\nclass Compose:\n    def __init__(self, transforms: list):\n        self.transforms = transforms\n\n    def __call__(self, y: np.ndarray):\n        for trns in self.transforms:\n            y = trns(y)\n        return y","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.167633Z","iopub.execute_input":"2022-05-24T04:09:52.167934Z","iopub.status.idle":"2022-05-24T04:09:52.179207Z","shell.execute_reply.started":"2022-05-24T04:09:52.1679Z","shell.execute_reply":"2022-05-24T04:09:52.178544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def init_layer(layer):\n    nn.init.xavier_uniform_(layer.weight)\n\n    if hasattr(layer, \"bias\"):\n        if layer.bias is not None:\n            layer.bias.data.fill_(0.)\n\n\ndef init_bn(bn):\n    bn.bias.data.fill_(0.)\n    bn.weight.data.fill_(1.0)\n\n\ndef init_weights(model):\n    classname = model.__class__.__name__\n    if classname.find(\"Conv2d\") != -1:\n        nn.init.xavier_uniform_(model.weight, gain=np.sqrt(2))\n        model.bias.data.fill_(0)\n    elif classname.find(\"BatchNorm\") != -1:\n        model.weight.data.normal_(1.0, 0.02)\n        model.bias.data.fill_(0)\n    elif classname.find(\"GRU\") != -1:\n        for weight in model.parameters():\n            if len(weight.size()) > 1:\n                nn.init.orghogonal_(weight.data)\n    elif classname.find(\"Linear\") != -1:\n        model.weight.data.normal_(0, 0.01)\n        model.bias.data.zero_()\n\n\ndef interpolate(x: torch.Tensor, ratio: int):\n    \"\"\"Interpolate data in time domain. This is used to compensate the\n    resolution reduction in downsampling of a CNN.\n    Args:\n      x: (batch_size, time_steps, classes_num)\n      ratio: int, ratio to interpolate\n    Returns:\n      upsampled: (batch_size, time_steps * ratio, classes_num)\n    \"\"\"\n    (batch_size, time_steps, classes_num) = x.shape\n    upsampled = x[:, :, None, :].repeat(1, 1, ratio, 1)\n    upsampled = upsampled.reshape(batch_size, time_steps * ratio, classes_num)\n    return upsampled\n\n\ndef pad_framewise_output(framewise_output: torch.Tensor, frames_num: int):\n    \"\"\"Pad framewise_output to the same length as input frames. The pad value\n    is the same as the value of the last frame.\n    Args:\n      framewise_output: (batch_size, frames_num, classes_num)\n      frames_num: int, number of frames to pad\n    Outputs:\n      output: (batch_size, frames_num, classes_num)\n    \"\"\"\n    output = F.interpolate(\n        framewise_output.unsqueeze(1),\n        size=(frames_num, framewise_output.size(2)),\n        align_corners=True,\n        mode=\"bilinear\").squeeze(1)\n\n    return output\n\n\ndef gem(x: torch.Tensor, p=3, eps=1e-6):\n    \"\"\"\n    Input Tensor : (batch_size, channels, height, width)\n    Output Tensor : (batch_size, channels, 1, 1)\n    \"\"\"\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1. / p)\n\n\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super().__init__()\n        self.p = nn.Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)\n\n    def __repr__(self):\n        return self.__class__.__name__ + f\"(p={self.p.data.tolist()[0]:.4f}, eps={self.eps})\"\n\n\nclass AttBlockV2(nn.Module):\n    def __init__(self,\n                 in_features: int,\n                 out_features: int,\n                 activation=\"linear\"):\n        super().__init__()\n\n        self.activation = activation\n        self.att = nn.Conv1d(\n            in_channels=in_features,\n            out_channels=out_features,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True)\n        self.cla = nn.Conv1d(\n            in_channels=in_features,\n            out_channels=out_features,\n            kernel_size=1,\n            stride=1,\n            padding=0,\n            bias=True)\n\n        self.init_weights()\n\n    def init_weights(self):\n        init_layer(self.att)\n        init_layer(self.cla)\n\n    def forward(self, x):\n        # (batch_size, channels*some, frames) (From network output)\n        \n        # x: (n_samples, n_in, n_time)\n        norm_att = torch.softmax(torch.tanh(self.att(x)), dim=-1)\n        cla = self.nonlinear_transform(self.cla(x))\n        x = torch.sum(norm_att * cla, dim=2)\n        \n        \"\"\"\n        # x shape : (batch_size, channels*some)\n        # norm_att shape : (batch_size,channels*some, frames)\n        # cla shape : (batch_size, channels*some, frames)\n        \"\"\"\n        return x, norm_att, cla\n\n    def nonlinear_transform(self, x):\n        if self.activation == 'linear':\n            return x\n        elif self.activation == 'sigmoid':\n            return torch.sigmoid(x)\n\n\nclass TimmSED(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG.n_fft, hop_length=CFG.hop_length,\n                                                 win_length=CFG.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG.sample_rate, n_fft=CFG.n_fft,\n                                                 n_mels=CFG.n_mels, fmin=CFG.fmin, fmax=CFG.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        # Spec augmenter\n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n\n        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n\n        if hasattr(base_model, \"fc\"):\n            in_features = base_model.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n\n    def forward(self, input):\n        # (batch_size, 1, time_steps, freq_bins)\n        x = self.spectrogram_extractor(input)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n\n        frames_num = x.shape[2]\n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n\n        #if self.training:\n        #    x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        # (batch_size, channels, freq, frames)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        #print(\"before segmentwise_logit:\",x,x.shape)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        #print(\"after segmentwise_logit:\",segmentwise_logit,segmentwise_logit.shape)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num:\",frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n        #print(\"after framewise_logit:\",framewise_logit,framewise_logit.shape)\n        output_dict = {\n            \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n            \"segmentwise_output\": segmentwise_output,\n            \"logit\": logit,\n            \"framewise_logit\": framewise_logit,\n            \"clipwise_output\": clipwise_output\n        }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.182061Z","iopub.execute_input":"2022-05-24T04:09:52.18242Z","iopub.status.idle":"2022-05-24T04:09:52.22054Z","shell.execute_reply.started":"2022-05-24T04:09:52.182394Z","shell.execute_reply":"2022-05-24T04:09:52.219836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class PretrainedTimmSED(TimmSED):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=21, in_channels=1):\n        super().__init__(base_model_name=base_model_name, pretrained=False, num_classes=131,in_channels=in_channels)\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG.n_fft, hop_length=CFG.hop_length,\n                                                 win_length=CFG.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG.sample_rate, n_fft=CFG.n_fft,\n                                                 n_mels=CFG.n_mels, fmin=CFG.fmin, fmax=CFG.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        # Spec augmenter\n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n        print(\"timm base_model_name : \", base_model_name)\n        base_model = TimmSED(\n            base_model_name=CFG.base_model_name,\n            pretrained=False,\n            num_classes=131,\n            in_channels=CFG.in_channels)\n        \n        #ckpt = torch.load(CFG.pretrain_checkpoint)\n        #base_model.load_state_dict(ckpt['model_state_dict'])\n        \n\n        \n        layers = list(base_model.children())[4:-2]\n        self.encoder = nn.Sequential(*layers)\n\n        #if hasattr(base_model, \"fc\"):\n        #    in_features = base_model.fc.in_features\n        #else:\n        #    in_features = base_model.classifier.in_features\n        #self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.fc1 = nn.Linear(1280, 1280, bias=True)\n        self.att_block = AttBlockV2(\n            1280, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n        return\n    \n    def forward(self, input):\n        # (batch_size, 1, time_steps, freq_bins)\n        x = self.spectrogram_extractor(input)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n\n        frames_num = x.shape[2]\n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n\n        if self.training:\n            x = self.spec_augmenter(x)\n        \n        x = x.transpose(2, 3)\n        # (batch_size, channels, freq, frames)\n        #print(\"before encoder : \", x, x.shape)\n        #print(self.encoder)\n        x = self.encoder(x)\n        #print(\"after encoder : \", x, x.shape)\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        \n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n\n        output_dict = {\n            \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n            \"segmentwise_output\": segmentwise_output,\n            \"logit\": logit,\n            \"framewise_logit\": framewise_logit,\n            \"clipwise_output\": clipwise_output\n        }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.223992Z","iopub.execute_input":"2022-05-24T04:09:52.224332Z","iopub.status.idle":"2022-05-24T04:09:52.244145Z","shell.execute_reply.started":"2022-05-24T04:09:52.224296Z","shell.execute_reply":"2022-05-24T04:09:52.243364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TimmNFNETGRUSED(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG.n_fft, hop_length=CFG.hop_length,\n                                                 win_length=CFG.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG.sample_rate, n_fft=CFG.n_fft,\n                                                 n_mels=CFG.n_mels, fmin=CFG.fmin, fmax=CFG.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        # Spec augmenter\n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n\n        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n        #print(base_model)\n        if hasattr(base_model, \"head\"):\n            in_features = base_model.head.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n        self.gru = torch.nn.GRU(input_size=in_features, hidden_size=in_features, \n                        num_layers=2, dropout=0.3, batch_first=True, bidirectional=True)\n        self.fc1 = nn.Linear(in_features*2, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n\n    def forward(self, input):\n        # (batch_size, 1, time_steps, freq_bins)\n        #print(\"input : \", input, input.shape)\n        x = self.spectrogram_extractor(input)\n        #print(\"after spectrogram : \", x, x.shape)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n\n        frames_num = x.shape[2]\n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n\n        if self.training:\n            x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        # (batch_size, channels, freq, frames)\n        #print(\"before encoder : \", x, x.shape)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        (x, _) = self.gru(x)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num : \", frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n\n        output_dict = {\n            \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n            \"segmentwise_output\": segmentwise_output,\n            \"logit\": logit,\n            \"framewise_logit\": framewise_logit,\n            \"clipwise_output\": clipwise_output\n        }\n\n        return output_dict\n\n\nclass PretrainedNFNETGRUTimmSED(TimmNFNETGRUSED):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=21, in_channels=1):\n        super().__init__(base_model_name=base_model_name, pretrained=pretrained, num_classes=CFG.n_pretrain_classes,in_channels=in_channels)\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG.n_fft, hop_length=CFG.hop_length,\n                                                 win_length=CFG.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG.sample_rate, n_fft=CFG.n_fft,\n                                                 n_mels=CFG.n_mels, fmin=CFG.fmin, fmax=CFG.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        # Spec augmenter\n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n        self.bn0 = nn.BatchNorm2d(CFG.n_mels)\n        print(\"timm base_model_name : \", base_model_name)\n        base_model = TimmNFNETGRUSED(\n            base_model_name=\"eca_nfnet_l0\",\n            pretrained=False,\n            num_classes=131,\n            in_channels=CFG.in_channels)\n        \n        #ckpt = torch.load(CFG.pretrain_checkpoint)\n        #base_model.load_state_dict(ckpt['model_state_dict'])\n        \n        #print(base_model)\n        \n        layers = list(base_model.children())[4:-3]\n        self.encoder = nn.Sequential(*layers)\n\n        #if hasattr(base_model, \"head\"):\n        #    in_features = base_model.head.fc.in_features\n        #else:\n        #    in_features = base_model.classifier.in_features\n        in_features=2304\n        self.gru = torch.nn.GRU(input_size=in_features, hidden_size=in_features, \n                        num_layers=2, dropout=0.3, batch_first=True, bidirectional=True)\n        self.fc1 = nn.Linear(in_features*2, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        #init_bn(self.bn0)\n\n    def forward(self, input):\n        # (batch_size, 1, time_steps, freq_bins)\n        #print(\"input : \", input, input.shape)\n        x = self.spectrogram_extractor(input)\n        #print(\"after spectrogram : \", x, x.shape)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n\n        frames_num = x.shape[2]\n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n\n        if self.training:\n            x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        # (batch_size, channels, freq, frames)\n        #print(\"before encoder : \", x, x.shape)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        (x, _) = self.gru(x)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num : \", frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n\n        output_dict = {\n            \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n            \"segmentwise_output\": segmentwise_output,\n            \"logit\": logit,\n            \"framewise_logit\": framewise_logit,\n            \"clipwise_output\": clipwise_output\n        }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.245557Z","iopub.execute_input":"2022-05-24T04:09:52.245949Z","iopub.status.idle":"2022-05-24T04:09:52.283346Z","shell.execute_reply.started":"2022-05-24T04:09:52.245915Z","shell.execute_reply":"2022-05-24T04:09:52.282533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Mixup(nn.Module):\n    def __init__(self, mix_beta=1):\n\n        super(Mixup, self).__init__()\n        self.beta_distribution = torch.distributions.Beta(mix_beta, mix_beta)\n\n    def forward(self, X, Y, weight=None):\n\n        bs = X.shape[0]\n        n_dims = len(X.shape)\n        perm = torch.randperm(bs)\n        coeffs = self.beta_distribution.rsample(torch.Size((bs,))).to(X.device)\n\n        if n_dims == 2:\n            X = coeffs.view(-1, 1) * X + (1 - coeffs.view(-1, 1)) * X[perm]\n        elif n_dims == 3:\n            X = coeffs.view(-1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1)) * X[perm]\n        else:\n            X = coeffs.view(-1, 1, 1, 1) * X + (1 - coeffs.view(-1, 1, 1, 1)) * X[perm]\n\n        Y = coeffs.view(-1, 1) * Y + (1 - coeffs.view(-1, 1)) * Y[perm]\n\n        if weight is None:\n            return X, Y\n        else:\n            weight = coeffs.view(-1) * weight + (1 - coeffs.view(-1)) * weight[perm]\n            return X, Y, weight\n\nclass MixupTimmNFNETSED(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG_NFNETMIXUP.n_fft, hop_length=CFG_NFNETMIXUP.hop_length,\n                                                 win_length=CFG_NFNETMIXUP.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG_NFNETMIXUP.sample_rate, n_fft=CFG_NFNETMIXUP.n_fft,\n                                                 n_mels=CFG_NFNETMIXUP.n_mels, fmin=CFG_NFNETMIXUP.fmin, fmax=CFG_NFNETMIXUP.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        # Spec augmenter\n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n\n        \n        self.mixup = Mixup()\n        self.bn0 = nn.BatchNorm2d(CFG_NFNETMIXUP.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n        if hasattr(base_model, \"head\"):\n            in_features = base_model.head.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n\n        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n\n    def forward(self, batch):\n        # batch -> image, target for mixup\n        input, target = batch\n\n        # (batch_size, 1, time_steps, freq_bins)\n        x = self.spectrogram_extractor(input)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n        frames_num = x.shape[2]\n\n        if self.training:\n            x, mixup_target = self.mixup(x, target)\n            #if CFG.DEBUG:\n            #    print(mixup_target.shape, weight.shape)\n            #mixup_target = mixup_target * weight.view(-1,1)\n            #print(\"mixuped :\", mixup_target, \"before : \", target)\n        \n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n\n        #if self.training:\n        #    x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        #(x, _) = self.gru(x)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num : \", frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n        if self.training:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":mixup_target\n            }\n        else:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":target\n            }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.284688Z","iopub.execute_input":"2022-05-24T04:09:52.285112Z","iopub.status.idle":"2022-05-24T04:09:52.313015Z","shell.execute_reply.started":"2022-05-24T04:09:52.285077Z","shell.execute_reply":"2022-05-24T04:09:52.312277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MixupTimmEFFV2SPECSED_LOW(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG_EFFV2DOUBLEMIXUP.n_fft, hop_length=CFG_EFFV2DOUBLEMIXUP.hop_length,\n                                                 win_length=CFG_EFFV2DOUBLEMIXUP.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG_EFFV2DOUBLEMIXUP.sample_rate, n_fft=CFG_EFFV2DOUBLEMIXUP.n_fft,\n                                                 n_mels=CFG_EFFV2DOUBLEMIXUP.n_mels, fmin=CFG_EFFV2DOUBLEMIXUP.fmin, fmax=CFG_EFFV2DOUBLEMIXUP.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        \n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n\n        self.mixup = Mixup()\n        self.bn0 = nn.BatchNorm2d(CFG_EFFV2DOUBLEMIXUP.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n        if hasattr(base_model, \"head\"):\n            in_features = base_model.head.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n\n        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n\n    def forward(self, batch):\n        # batch -> image, target for mixup\n        input, target = batch\n\n        # (batch_size, 1, time_steps, freq_bins)\n        x = self.spectrogram_extractor(input)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n        frames_num = x.shape[2]\n\n        if self.training:\n            \n            x, mixup_target, weight = self.mixup(x, target)\n            if np.random.uniform() < 0.5:\n                x, mixup_target, weight = self.mixup(x, mixup_target)\n\n            #mixup_target = mixup_target * weight.view(-1,1)\n            #print(\"mixuped :\", mixup_target, \"before : \", target)\n        \n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n        if self.training:\n            x = self.spec_augmenter(x)\n        #if self.training:\n        #    x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        #(x, _) = self.gru(x)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num : \", frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n        if self.training:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":mixup_target\n            }\n        else:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":target\n            }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.316084Z","iopub.execute_input":"2022-05-24T04:09:52.316279Z","iopub.status.idle":"2022-05-24T04:09:52.339809Z","shell.execute_reply.started":"2022-05-24T04:09:52.316249Z","shell.execute_reply":"2022-05-24T04:09:52.338561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MixupTimmEFFV2SPECSED_64MEL(nn.Module):\n    def __init__(self, base_model_name: str, pretrained=False, num_classes=24, in_channels=1):\n        super().__init__()\n        # Spectrogram extractor\n        self.spectrogram_extractor = Spectrogram(n_fft=CFG_EFFV2DOUBLEMIXUP_64MEL.n_fft, hop_length=CFG_EFFV2DOUBLEMIXUP_64MEL.hop_length,\n                                                 win_length=CFG_EFFV2DOUBLEMIXUP_64MEL.n_fft, window=\"hann\", center=True, pad_mode=\"reflect\",\n                                                 freeze_parameters=True)\n\n        # Logmel feature extractor\n        self.logmel_extractor = LogmelFilterBank(sr=CFG_EFFV2DOUBLEMIXUP_64MEL.sample_rate, n_fft=CFG_EFFV2DOUBLEMIXUP_64MEL.n_fft,\n                                                 n_mels=CFG_EFFV2DOUBLEMIXUP_64MEL.n_mels, fmin=CFG_EFFV2DOUBLEMIXUP_64MEL.fmin, fmax=CFG_EFFV2DOUBLEMIXUP_64MEL.fmax, ref=1.0, amin=1e-10, top_db=None,\n                                                 freeze_parameters=True)\n\n        \n        self.spec_augmenter = SpecAugmentation(time_drop_width=64, time_stripes_num=2,\n                                               freq_drop_width=8, freq_stripes_num=2)\n\n        self.mixup = Mixup()\n        self.bn0 = nn.BatchNorm2d(CFG_EFFV2DOUBLEMIXUP_64MEL.n_mels)\n\n        base_model = timm.create_model(\n            base_model_name, pretrained=pretrained, in_chans=in_channels)\n        layers = list(base_model.children())[:-2]\n        self.encoder = nn.Sequential(*layers)\n        if hasattr(base_model, \"head\"):\n            in_features = base_model.head.fc.in_features\n        else:\n            in_features = base_model.classifier.in_features\n\n        self.fc1 = nn.Linear(in_features, in_features, bias=True)\n        self.att_block = AttBlockV2(\n            in_features, num_classes, activation=\"sigmoid\")\n\n        self.init_weight()\n\n    def init_weight(self):\n        init_layer(self.fc1)\n        init_bn(self.bn0)\n\n    def forward(self, batch):\n        # batch -> image, target for mixup\n        input, target = batch\n\n        # (batch_size, 1, time_steps, freq_bins)\n        x = self.spectrogram_extractor(input)\n        x = self.logmel_extractor(x)    # (batch_size, 1, time_steps, mel_bins)\n        frames_num = x.shape[2]\n\n        if self.training:\n            \n            x, mixup_target = self.mixup(x, target)\n            if np.random.uniform() < 0.5:\n                x, mixup_target = self.mixup(x, mixup_target)\n\n            #mixup_target = mixup_target * weight.view(-1,1)\n            #print(\"mixuped :\", mixup_target, \"before : \", target)\n        \n\n        x = x.transpose(1, 3)\n        x = self.bn0(x)\n        x = x.transpose(1, 3)\n        if self.training:\n            x = self.spec_augmenter(x)\n        #if self.training:\n        #    x = self.spec_augmenter(x)\n\n        x = x.transpose(2, 3)\n        x = self.encoder(x)\n\n        # (batch_size, channels, frames)\n        x = torch.mean(x, dim=2)\n\n        # channel smoothing\n        x1 = F.max_pool1d(x, kernel_size=3, stride=1, padding=1)\n        x2 = F.avg_pool1d(x, kernel_size=3, stride=1, padding=1)\n        # (batch_size, channels, frames)\n        x = x1 + x2\n        \n        x = F.dropout(x, p=0.5, training=self.training)\n        x = x.transpose(1, 2)\n        #(x, _) = self.gru(x)\n        # (batch_size, channels*some, frames)\n        x = F.relu_(self.fc1(x))\n        x = x.transpose(1, 2)\n        x = F.dropout(x, p=0.5, training=self.training)\n        # x shape : (batch_size, channels*some, frames)\n        # clipwise_output shape : (batch_size, channels*some*some2)\n        # norm_att shape : (batch_size,channels*some*some2, frames)\n        # segmentwise_output shape : (batch_size, channels*some*some2, frames) ->sigmoid(self.cla(x))\n        (clipwise_output, norm_att, segmentwise_output) = self.att_block(x)\n        logit = torch.sum(norm_att * self.att_block.cla(x), dim=2)\n        segmentwise_logit = self.att_block.cla(x).transpose(1, 2)\n        segmentwise_output = segmentwise_output.transpose(1, 2)\n        #print(\"frames_num : \", frames_num)\n        interpolate_ratio = frames_num // segmentwise_output.size(1)\n\n        # Get framewise output\n        framewise_output = interpolate(segmentwise_output,\n                                       interpolate_ratio)\n        framewise_output = pad_framewise_output(framewise_output, frames_num)\n\n        framewise_logit = interpolate(segmentwise_logit, interpolate_ratio)\n        framewise_logit = pad_framewise_output(framewise_logit, frames_num)\n        if self.training:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":mixup_target\n            }\n        else:\n            output_dict = {\n                \"framewise_output\": framewise_output, # applied interpolation at segmentwise_output\n                \"segmentwise_output\": segmentwise_output,\n                \"logit\": logit,\n                \"framewise_logit\": framewise_logit,\n                \"clipwise_output\": clipwise_output,\n                \"target\":target\n            }\n\n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.341335Z","iopub.execute_input":"2022-05-24T04:09:52.341951Z","iopub.status.idle":"2022-05-24T04:09:52.364559Z","shell.execute_reply.started":"2022-05-24T04:09:52.341915Z","shell.execute_reply":"2022-05-24T04:09:52.363717Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/c/rfcx-species-audio-detection/discussion/213075\nclass BCEFocalLoss(nn.Module):\n    def __init__(self, alpha=0.25, gamma=2.0):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, preds, targets):\n        bce_loss = nn.BCEWithLogitsLoss(reduction='none')(preds, targets)\n        probas = torch.sigmoid(preds)\n        loss = targets * self.alpha * \\\n            (1. - probas)**self.gamma * bce_loss + \\\n            (1. - targets) * probas**self.gamma * bce_loss\n        loss = loss.mean()\n        return loss\n\n\nclass BCEFocal2WayLoss(nn.Module):\n    def __init__(self, weights=[1, 1], class_weights=None):\n        super().__init__()\n\n        self.focal = BCEFocalLoss()\n\n        self.weights = weights\n\n    def forward(self, input, target):\n        input_ = input[\"logit\"]\n        target = target.float()\n\n        framewise_output = input[\"framewise_logit\"]\n        clipwise_output_with_max, _ = framewise_output.max(dim=1)\n\n        loss = self.focal(input_, target)\n        aux_loss = self.focal(clipwise_output_with_max, target)\n\n        return self.weights[0] * loss + self.weights[1] * aux_loss","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.365984Z","iopub.execute_input":"2022-05-24T04:09:52.36644Z","iopub.status.idle":"2022-05-24T04:09:52.377983Z","shell.execute_reply.started":"2022-05-24T04:09:52.366403Z","shell.execute_reply":"2022-05-24T04:09:52.377196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"__CRITERIONS__ = {\n    \"BCEFocalLoss\": BCEFocalLoss,\n    \"BCEFocal2WayLoss\": BCEFocal2WayLoss\n}\n\n\ndef get_criterion():\n    if hasattr(nn, CFG.loss_name):\n        return nn.__getattribute__(CFG.loss_name)(**CFG.loss_params)\n    elif __CRITERIONS__.get(CFG.loss_name) is not None:\n        return __CRITERIONS__[CFG.loss_name](**CFG.loss_params)\n    else:\n        raise NotImplementedError","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.379265Z","iopub.execute_input":"2022-05-24T04:09:52.380006Z","iopub.status.idle":"2022-05-24T04:09:52.390932Z","shell.execute_reply.started":"2022-05-24T04:09:52.379971Z","shell.execute_reply":"2022-05-24T04:09:52.390066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Custom optimizer\n__OPTIMIZERS__ = {}\n\n\ndef get_optimizer(model: nn.Module):\n    optimizer_name = CFG.optimizer_name\n    if optimizer_name == \"SAM\":\n        base_optimizer_name = CFG.base_optimizer\n        if __OPTIMIZERS__.get(base_optimizer_name) is not None:\n            base_optimizer = __OPTIMIZERS__[base_optimizer_name]\n        else:\n            base_optimizer = optim.__getattribute__(base_optimizer_name)\n        return SAM(model.parameters(), base_optimizer, **CFG.optimizer_params)\n\n    if __OPTIMIZERS__.get(optimizer_name) is not None:\n        return __OPTIMIZERS__[optimizer_name](model.parameters(),\n                                              **CFG.optimizer_params)\n    else:\n        return optim.__getattribute__(optimizer_name)(model.parameters(),\n                                                      **CFG.optimizer_params)\n\n\ndef get_scheduler(optimizer):\n    scheduler_name = CFG.scheduler_name\n\n    if scheduler_name is None:\n        return\n    else:\n        return optim.lr_scheduler.__getattribute__(scheduler_name)(\n            optimizer, **CFG.scheduler_params)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.392439Z","iopub.execute_input":"2022-05-24T04:09:52.393233Z","iopub.status.idle":"2022-05-24T04:09:52.402699Z","shell.execute_reply.started":"2022-05-24T04:09:52.393168Z","shell.execute_reply":"2022-05-24T04:09:52.40193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"warnings.filterwarnings(\"ignore\")\n\nlogdir = Path(\"out\")\nlogdir.mkdir(exist_ok=True, parents=True)\nif (logdir / \"train.log\").exists():\n    os.remove(logdir / \"train.log\")\nlogger = init_logger(log_file=logdir / \"train.log\")","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.404147Z","iopub.execute_input":"2022-05-24T04:09:52.404832Z","iopub.status.idle":"2022-05-24T04:09:52.415227Z","shell.execute_reply.started":"2022-05-24T04:09:52.404794Z","shell.execute_reply":"2022-05-24T04:09:52.414468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# environment\nset_seed(CFG.seed)\ndevice = get_device()\n\n# validation\nsplitter = getattr(model_selection, CFG.split)(**CFG.split_params)\n\n# data\ntrain = train_meta","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.416693Z","iopub.execute_input":"2022-05-24T04:09:52.417478Z","iopub.status.idle":"2022-05-24T04:09:52.425002Z","shell.execute_reply.started":"2022-05-24T04:09:52.417445Z","shell.execute_reply":"2022-05-24T04:09:52.424264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.426288Z","iopub.execute_input":"2022-05-24T04:09:52.426758Z","iopub.status.idle":"2022-05-24T04:09:52.434541Z","shell.execute_reply.started":"2022-05-24T04:09:52.426718Z","shell.execute_reply":"2022-05-24T04:09:52.433832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from contextlib import contextmanager\nfrom typing import Optional\nimport time\n@contextmanager\ndef timer(name: str, logger: Optional[logging.Logger] = None):\n    t0 = time.time()\n    msg = f\"[{name}] start\"\n    if logger is None:\n        print(msg)\n    else:\n        logger.info(msg)\n    yield\n\n    msg = f\"[{name}] done in {time.time() - t0:.2f} s\"\n    if logger is None:\n        print(msg)\n    else:\n        logger.info(msg)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.435846Z","iopub.execute_input":"2022-05-24T04:09:52.436362Z","iopub.status.idle":"2022-05-24T04:09:52.443566Z","shell.execute_reply.started":"2022-05-24T04:09:52.436323Z","shell.execute_reply":"2022-05-24T04:09:52.442823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For Test Prepraration","metadata":{}},{"cell_type":"code","source":"test_audio_dir = '../input/birdclef-2022/test_soundscapes/'\nfile_list = [f.split('.')[0] for f in sorted(os.listdir(test_audio_dir))]\n\nprint('Number of test soundscapes:', len(file_list))","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.445902Z","iopub.execute_input":"2022-05-24T04:09:52.446553Z","iopub.status.idle":"2022-05-24T04:09:52.457325Z","shell.execute_reply.started":"2022-05-24T04:09:52.446514Z","shell.execute_reply":"2022-05-24T04:09:52.456378Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, clip: np.ndarray,afile='woong',index_list=[],\n                 waveform_transforms=None):\n        self.clip = clip\n        self.waveform_transforms=waveform_transforms\n        self.afile = afile\n        self.index_list = index_list\n        \n    def __len__(self):\n        return len(self.clip)\n    \n    def __getitem__(self, idx: int):\n        afile=self.afile\n        SR = 32000\n        sample = self.clip[idx]\n        index = self.index_list[idx]\n\n        y = sample.astype(np.float32)\n\n        y = np.nan_to_num(y)\n\n        if self.waveform_transforms:\n            y = self.waveform_transforms(y)\n\n        y = np.nan_to_num(y)\n        return y, afile, index","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.458846Z","iopub.execute_input":"2022-05-24T04:09:52.459178Z","iopub.status.idle":"2022-05-24T04:09:52.468655Z","shell.execute_reply.started":"2022-05-24T04:09:52.459126Z","shell.execute_reply":"2022-05-24T04:09:52.467445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_model_for_inference(model, path: Path):\n    if not torch.cuda.is_available():\n        ckpt = torch.load(path, map_location=\"cpu\")\n    else:\n        ckpt = torch.load(path)\n    model.load_state_dict(ckpt[\"model_state_dict\"])\n    model.eval()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.469674Z","iopub.execute_input":"2022-05-24T04:09:52.470161Z","iopub.status.idle":"2022-05-24T04:09:52.477925Z","shell.execute_reply.started":"2022-05-24T04:09:52.470126Z","shell.execute_reply":"2022-05-24T04:09:52.477211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prepare_model_for_mixup_inference(model, path: Path):\n    if not torch.cuda.is_available():\n        ckpt = torch.load(path, map_location=\"cpu\")\n    else:\n        ckpt = torch.load(path)\n    model.load_state_dict(ckpt[\"model\"])\n    model.eval()\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.478853Z","iopub.execute_input":"2022-05-24T04:09:52.479342Z","iopub.status.idle":"2022-05-24T04:09:52.487495Z","shell.execute_reply.started":"2022-05-24T04:09:52.479316Z","shell.execute_reply":"2022-05-24T04:09:52.48675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_for_clip(clip: np.ndarray,\n                        afile: str,\n                        model, \n                        threshold=0.5):\n\n    dataset = TestDataset(clip=clip,\n                          afile=afile,\n                          waveform_transforms=get_transforms(phase=\"test\"))\n    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    model.eval()\n    prediction_dict = {}\n    pred = {'row_id': [], 'target': []}\n    for i, (image,afile) in enumerate(tqdm(loader)):\n        \n        image = image.to(device)\n        #print(image, image.shape)\n        with torch.no_grad():\n            prediction = model(image)\n            #print(prediction, prediction.shape)\n            proba = prediction[\"clipwise_output\"].detach().cpu().numpy().reshape(-1)\n        \n        chunk_end_time = (i + 1) * 5\n        \n        for bird in scored_birds:\n            try:\n                score = proba[np.where(np.array(scored_birds)==bird)]\n                #print(score)\n                #print(\"npwhere\",np.where(scored_birds==bird))\n                #print(\"score : \", score)\n                \n            except IndexError:\n                score = 0\n            #print(\"afile:\",afile)\n            #print(\"type afile:\",type(afile))\n            #print(\"bird:\",bird)\n            #print(\"chunk_end_time:\",chunk_end_time)\n            \n            row_id = afile[0] + '_' + bird + '_' + str(chunk_end_time)\n            #print(\"row_id:\",row_id)\n            pred['row_id'].append(row_id)\n            pred['target'].append(True if score > threshold else False)\n            #pred['score'].append(score)\n\n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.488539Z","iopub.execute_input":"2022-05-24T04:09:52.489082Z","iopub.status.idle":"2022-05-24T04:09:52.500838Z","shell.execute_reply.started":"2022-05-24T04:09:52.489043Z","shell.execute_reply":"2022-05-24T04:09:52.500075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_each_for_framewise(clip: np.ndarray,\n                             afile: str,\n                             index_list: list,\n                             model, \n                             threshold=0.5):\n\n    dataset = TestDataset(clip=clip,\n                          afile=afile,\n                          index_list=index_list,\n                          waveform_transforms=get_transforms(phase=\"test\"))\n    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    #print(\"len loader : \", len(loader))\n    model.eval()\n    prediction_dict = {}\n    pred = {'row_id': [], 'target': []}\n    before_proba_split = None\n    for i, (image,afile,idx) in enumerate(tqdm(loader)):\n        #print(\"image shape: \", image.shape)\n        image = image.to(device)\n        with torch.no_grad():\n            prediction = model(image)\n            #print(prediction, prediction.shape)\n            #proba = torch.sigmoid(prediction[\"framewise_logit\"]).detach().cpu().numpy().reshape(-1)\n            proba = torch.sigmoid(prediction[\"framewise_logit\"])\n            proba = proba.detach().cpu().numpy()[0]\n        \n        #chunk_end_time = (i + 1) * 5\n        chunk_start_time = idx.detach().cpu().numpy()[0]\n        chunk_start_time *= 20\n        #print(\"chunk start time : \", chunk_start_time)\n        proba_split = np.array_split(proba, 8, axis=0)\n        cur_proba_split = proba_split[:4]\n        \n        #print(\"proba split shape: \", proba_split, len(proba_split), \"proba last shape:\", proba_split[-1].shape)\n        \n        for time_index, each_proba in enumerate(cur_proba_split):\n            #first_each_proba = each_proba[::2].copy()\n            #second_each_proba = each_proba[1::2].copy()\n            #if len(each_proba)%2==0:\n            #    first_each_proba = (first_each_proba + second_each_proba) / 2\n            #    avg_each_proba = first_each_proba.copy()\n            #else:\n            #    first_each_proba = first_each_proba[:-1]\n            #    avg_each_proba = ((first_each_proba + second_each_proba) / 2).copy()\n            if before_proba_split is not None:\n                avg_each_proba = np.vstack([each_proba,before_proba_split[time_index]])\n            else:\n                avg_each_proba = each_proba\n            for bird in scored_birds:\n                #print(\"bird: \", bird)\n                try:\n                    \n                    \n                        \n                    #print(\"before each_proba: \", each_proba)\n                        result_proba = np.max(avg_each_proba, axis=0)\n\n                        score = result_proba[np.where(np.array(scored_birds)==bird)]\n                    #print(\"each_proba_success\")\n                except IndexError:\n                    score = 0\n                    #print(\"each_proba_failed\")\n\n                #row_id = afile[0] + '_' + bird + '_' + str(chunk_end_time)\n                row_id = afile[0] + '_' + bird + '_' + str(chunk_start_time + (time_index+1)*5)\n\n                pred['row_id'].append(row_id)\n                pred['target'].append(True if score > threshold else False)\n        \n        if i < len(loader):\n            before_proba_split = proba_split[4:]\n            #pred['score'].append(score)\n\n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.502593Z","iopub.execute_input":"2022-05-24T04:09:52.502985Z","iopub.status.idle":"2022-05-24T04:09:52.519073Z","shell.execute_reply.started":"2022-05-24T04:09:52.50295Z","shell.execute_reply":"2022-05-24T04:09:52.518343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_each_for_framewise_ensemble(clip: np.ndarray,\n                             afile: str,\n                             index_list: list,\n                             model_list: list, \n                             threshold=0.5):\n\n    dataset = TestDataset(clip=clip,\n                          afile=afile,\n                          index_list=index_list,\n                          waveform_transforms=get_transforms(phase=\"test\"))\n    loader = DataLoader(dataset, batch_size=1, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    #print(\"len loader : \", len(loader))\n    for model in model_list:\n        model.eval()\n    prediction_dict = {}\n    pred = {'row_id': [], 'target': []}\n    before_proba_split = None\n    for i, (image,afile,idx) in enumerate(tqdm(loader)):\n        #print(\"image shape: \", image.shape)\n        image = image.to(device)\n        for model_idx, model in enumerate(model_list):\n            with torch.no_grad():\n                if model_idx == 0:\n                    prediction = model(image)\n                    proba_before = torch.sigmoid(prediction[\"framewise_logit\"]) / len(model_list)\n                    proba_after = proba_before.detach().cpu().numpy()[0]\n                else:\n                    prediction = model(image)\n                    proba_before = torch.sigmoid(prediction[\"framewise_logit\"]) / len(model_list)\n                    proba_after += proba_before.detach().cpu().numpy()[0]\n        proba = proba_after.copy()\n        chunk_start_time = idx.detach().cpu().numpy()[0]\n        chunk_start_time *= 10\n        #print(proba, proba.shape)\n        proba_split = np.array_split(proba, 4, axis=0)\n        cur_proba_split = proba_split[:2]\n        \n        for time_index, each_proba in enumerate(cur_proba_split):\n            if before_proba_split is not None:\n                #print(time_index)\n                avg_each_proba = np.vstack([each_proba,before_proba_split[time_index]])\n            else:\n                avg_each_proba = each_proba\n            for bird in scored_birds:\n                #print(\"bird: \", bird)\n                try:\n                        result_proba = np.max(avg_each_proba, axis=0)\n\n                        score = result_proba[np.where(np.array(scored_birds)==bird)]\n                    #print(\"each_proba_success\")\n                except IndexError:\n                    score = 0\n                    #print(\"each_proba_failed\")\n\n                #row_id = afile[0] + '_' + bird + '_' + str(chunk_end_time)\n                row_id = afile[0] + '_' + bird + '_' + str(chunk_start_time + (time_index+1)*5)\n\n                pred['row_id'].append(row_id)\n                pred['target'].append(True if score > threshold else False)\n        \n        if i < len(loader):\n            before_proba_split = proba_split[1:]\n            #pred['score'].append(score)\n\n    return pred","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.52151Z","iopub.execute_input":"2022-05-24T04:09:52.521946Z","iopub.status.idle":"2022-05-24T04:09:52.537565Z","shell.execute_reply.started":"2022-05-24T04:09:52.521908Z","shell.execute_reply":"2022-05-24T04:09:52.536844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_each_for_framewise_voting_10sec(clip: np.ndarray,\n                             afile: str,\n                             index_list: list,\n                             model_list: list, \n                             threshold=0.5,\n                             model_with_mixup_bool = list()):\n    batch_size=64\n    dataset = TestDataset(clip=clip,\n                          afile=afile,\n                          index_list=index_list,\n                          waveform_transforms=get_transforms(phase=\"test\"))\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    #for model in model_list:\n    #    model.eval()\n    prediction_dict = {}\n    pred_list = []\n    before_proba_split = None\n    for model_idx, (model, mixup_bool) in enumerate(zip(model_list, model_with_mixup_bool)):\n        pred = {'row_id': [], 'target': [], 'score':[]}\n        with torch.no_grad():\n            for i, (image,afile,idx) in enumerate(tqdm(loader)):\n                #print(image.shape, afile, \"at batch size: \", batch_size)\n\n                image = image.to(device)\n                target = torch.normal(2, 3, size=(image.shape[0], 1)).to(device)\n                with torch.no_grad():\n                    if mixup_bool==False:\n                        prediction = model(image)\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                    else:\n                        prediction = model((image,target))\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                #print(proba_after.shape, afile, idx)\n                proba_length = proba_after.shape[0]\n                for interval_idx in range(proba_length):\n                    proba = proba_after[interval_idx]\n                    chunk_start_time = idx.cpu().numpy()[interval_idx]\n                    chunk_start_time *= 10\n            #print(proba, proba.shape)\n                    proba_split = np.array_split(proba, 4, axis=0)\n                    cur_proba_split = proba_split[:2]\n\n                    for time_index, each_proba in enumerate(cur_proba_split):\n                        if before_proba_split is not None:\n                        #print(time_index)\n                            avg_each_proba = np.vstack([each_proba,before_proba_split[time_index]])\n                        else:\n                            avg_each_proba = each_proba\n                        for bird in scored_birds:\n                            #print(\"bird: \", bird)\n                            try:\n                                result_proba = np.max(avg_each_proba, axis=0)\n\n                                score = result_proba[np.where(np.array(bird_label_total)==bird)]\n                            #print(\"each_proba_success\")\n                            except IndexError:\n                                score = 0\n                            #print(\"each_proba_failed\")\n\n                        #row_id = afile[0] + '_' + bird + '_' + str(chunk_end_time)\n                            row_id = afile[0] + '_' + bird + '_' + str(chunk_start_time + (time_index+1)*5)\n                            #print(row_id)\n                            pred['row_id'].append(row_id)\n                            pred['score'].append(score[0])\n                            pred['target'].append(True if score > threshold else False)\n\n                    if i < len(loader):\n                        before_proba_split = proba_split[2:]\n            pred_list.append(pred)\n            #pred['score'].append(score)\n\n    return pred_list","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.538863Z","iopub.execute_input":"2022-05-24T04:09:52.539589Z","iopub.status.idle":"2022-05-24T04:09:52.557956Z","shell.execute_reply.started":"2022-05-24T04:09:52.539549Z","shell.execute_reply":"2022-05-24T04:09:52.557135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_each_for_framewise_voting_15sec(clip: np.ndarray,\n                             afile: str,\n                             index_list: list,\n                             model_list: list, \n                             threshold=0.5,\n                             model_with_mixup_bool = list()):\n    batch_size=64\n    dataset = TestDataset(clip=clip,\n                          afile=afile,\n                          index_list=index_list,\n                          waveform_transforms=get_transforms(phase=\"test\"))\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    #for model in model_list:\n    #    model.eval()\n    prediction_dict = {}\n    pred_list = []\n    before_proba_split = None\n    for model_idx, (model, mixup_bool) in enumerate(zip(model_list, model_with_mixup_bool)):\n        pred = {'row_id': [], 'target': [], 'score':[]}\n        with torch.no_grad():\n            for i, (image,afile,idx) in enumerate(tqdm(loader)):\n                #print(image.shape, afile, \"at batch size: \", batch_size)\n\n                image = image.to(device)\n                target = torch.normal(2, 3, size=(image.shape[0], 1)).to(device)\n                with torch.no_grad():\n                    if mixup_bool==False:\n                        prediction = model(image)\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                    else:\n                        prediction = model((image,target))\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                #print(proba_after.shape, afile, idx)\n                proba_length = proba_after.shape[0]\n                for interval_idx in range(proba_length):\n                    proba = proba_after[interval_idx]\n                    chunk_start_time = idx.cpu().numpy()[interval_idx]\n                    chunk_start_time *= 30\n            #print(proba, proba.shape)\n                    proba_split = np.array_split(proba, 6, axis=0)\n                    cur_proba_split = proba_split[:6]\n\n                    for time_index, each_proba in enumerate(cur_proba_split):\n                        if before_proba_split is not None:\n                        #print(time_index)\n                            avg_each_proba = np.vstack([each_proba,before_proba_split[time_index]])\n                        else:\n                            avg_each_proba = each_proba\n                        for bird in scored_birds:\n                            #print(\"bird: \", bird)\n                            try:\n                                result_proba = np.max(avg_each_proba, axis=0)\n\n                                score = result_proba[np.where(np.array(bird_label_total)==bird)]\n                            #print(\"each_proba_success\")\n                            except IndexError:\n                                score = 0\n                            #print(\"each_proba_failed\")\n\n                        #row_id = afile[0] + '_' + bird + '_' + str(chunk_end_time)\n                            row_id = afile[0] + '_' + bird + '_' + str(chunk_start_time + (time_index+1)*5)\n                            #print(row_id)\n                            pred['row_id'].append(row_id)\n                            pred['score'].append(score[0])\n                            pred['target'].append(True if score > threshold else False)\n\n                    if i < len(loader):\n                        before_proba_split = proba_split[6:]\n            pred_list.append(pred)\n            #pred['score'].append(score)\n\n    return pred_list\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.559541Z","iopub.execute_input":"2022-05-24T04:09:52.560294Z","iopub.status.idle":"2022-05-24T04:09:52.578228Z","shell.execute_reply.started":"2022-05-24T04:09:52.560258Z","shell.execute_reply":"2022-05-24T04:09:52.577483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndef prediction_framewise_ensemble(test_audios,\n               weights_path: list,\n               threshold):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_list = []\n    for i in range(len(weights_path)):\n        if i <= 14:\n            model = PretrainedTimmNFNETGRUSED(base_model_name=\"nfnet_eca_l0\",\n                            pretrained=False,\n                            num_classes=21,\n                            in_channels=CFG.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        else:\n            model = TimmSED(base_model_name=CFG.base_model_name,\n                        pretrained=False,\n                        num_classes=CFG.num_classes,\n                        in_channels=CFG.in_channels)\n            model_list.append(prepare_model_for_inference(model, weights_path[i]).to(device).eval())\n        gc.collect()\n    \n    warnings.filterwarnings(\"ignore\")\n    prediction_dfs = []\n    \n    pred = {'row_id': [], 'target': []}\n    \n    for audio_path in test_audios:\n        #[(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\n        afile = audio_path.name.split(\".\")[0]\n        #print(\"first afile\")\n        with timer(f\"Loading {str(audio_path)}\", logger):\n            clip, _ = sf.read(audio_path)\n        len_wav_shape = len(clip.shape)\n        if len_wav_shape == 1:\n            pass\n        else:\n            clip = clip[:,0]\n        length_clip = clip.shape[0]\n        cal_frame_for_interval = 5\n        intervals = round(length_clip/32000/cal_frame_for_interval)\n        \n        #effective_test_length = 32000*cal_frame*intervals\n        #if not length_clip < 32000*5*12:\n        #clip = clip[:effective_test_length]\n        clip_list = []\n        #print(intervals)\n        index_list = []\n        for index in range(intervals):\n            added_clip = clip[index*32000*cal_frame_for_interval:(index+1)*32000*cal_frame_for_interval+32000*cal_frame_for_interval]\n            print(len(added_clip))\n            clip_list.append(added_clip)\n            index_list.append(index)\n        clip_list = np.array(clip_list)\n        with timer(f\"Prediction on {audio_path}\", logger):\n            prediction_dict = prediction_each_for_framewise_ensemble(clip=clip_list,\n                                                       afile=afile,\n                                                       index_list = index_list,\n                                                       model_list=model_list,\n                                                       threshold=threshold)\n        row_id = list(prediction_dict['row_id'])\n        target = list(prediction_dict['target'])\n        prediction_df = pd.DataFrame({\n            \"row_id\": row_id,\n            \"target\": target,\n        })\n        prediction_dfs.append(prediction_df)\n    \n    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n    return prediction_df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.579613Z","iopub.execute_input":"2022-05-24T04:09:52.580275Z","iopub.status.idle":"2022-05-24T04:09:52.596432Z","shell.execute_reply.started":"2022-05-24T04:09:52.58024Z","shell.execute_reply":"2022-05-24T04:09:52.595765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\ndef prediction_each_for_framewise_voting_15sec_speedup(clip: np.ndarray,\n                             afile: str,\n                             index_list: list,\n                             model_list: list, \n                             threshold=0.5,\n                             model_with_mixup_bool = list()):\n    batch_size=64\n    dataset = TestDataset(clip=clip,\n                          afile=afile,\n                          index_list=index_list,\n                          waveform_transforms=get_transforms(phase=\"test\"))\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    #for model in model_list:\n    #    model.eval()\n    prediction_dict = {}\n    #pred_dict = OrderedDict(k:list() for k in range(len(model_list))}\n    pred_dict = OrderedDict()\n    for idx in range(len(model_list)):\n        pred_dict[idx] = list()\n    #for model_idx, (model, mixup_bool) in enumerate(zip(model_list, model_with_mixup_bool)):\n    if True:\n        #pred = {'row_id': [], 'target': [], 'score':[]}\n        with torch.no_grad():\n            for i, (image,afile,idx) in enumerate(tqdm(loader)):\n                \n                for model_idx, (model, mixup_bool) in enumerate(zip(model_list, model_with_mixup_bool)):\n                #print(image.shape, afile, \"at batch size: \", batch_size)\n                    before_proba_split = None\n                    each_pred = {'row_id': [], 'target': [], 'score':[]}\n                    image = image.to(device)\n                    target = torch.normal(2, 3, size=(image.shape[0], 1)).to(device)\n\n                    if mixup_bool==False:\n                        prediction = model(image)\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                    else:\n                        prediction = model((image,target))\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                #print(proba_after.shape, afile, idx)\n                    proba_length = proba_after.shape[0]\n                    for interval_idx in range(proba_length):\n                        proba = proba_after[interval_idx]\n                        chunk_start_time = idx.cpu().numpy()[interval_idx]\n                        chunk_start_time *= 30\n            #print(proba, proba.shape)\n                        proba_split = np.array_split(proba, 12, axis=0)\n                        cur_proba_split = proba_split[:6]\n\n                        for time_index, each_proba in enumerate(cur_proba_split):\n                            if before_proba_split is not None:\n                        #print(time_index)\n                                avg_each_proba = np.vstack([each_proba,before_proba_split[time_index]])\n                            else:\n                                avg_each_proba = each_proba\n                            for bird in scored_birds:\n                            #print(\"bird: \", bird)\n                                try:\n                                    result_proba = np.max(avg_each_proba, axis=0)\n\n                                    score = result_proba[np.where(np.array(bird_label_total)==bird)]\n                            #print(\"each_proba_success\")\n                                except IndexError:\n                                    score = 0\n                            #print(\"each_proba_failed\")\n\n                        #row_id = afile[0] + '_' + bird + '_' + str(chunk_end_time)\n                                row_id = afile[0] + '_' + bird + '_' + str(chunk_start_time + (time_index+1)*5)\n                            #print(row_id)\n                                each_pred['row_id'].append(row_id)\n                                each_pred['score'].append(score[0])\n                                each_pred['target'].append(True if score > threshold else False)\n\n                        if i < len(loader):\n                            before_proba_split = proba_split[6:]\n                    pred_dict[model_idx].append(each_pred)\n            #pred['score'].append(score)\n\n    return pred_dict\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.599173Z","iopub.execute_input":"2022-05-24T04:09:52.599417Z","iopub.status.idle":"2022-05-24T04:09:52.617719Z","shell.execute_reply.started":"2022-05-24T04:09:52.599386Z","shell.execute_reply":"2022-05-24T04:09:52.616994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\ndef prediction_each_for_framewise_voting_10sec_speedup(clip: np.ndarray,\n                             afile: str,\n                             index_list: list,\n                             model_list: list, \n                             threshold=0.5,\n                             model_with_mixup_bool = list()):\n    batch_size=64\n    dataset = TestDataset(clip=clip,\n                          afile=afile,\n                          index_list=index_list,\n                          waveform_transforms=get_transforms(phase=\"test\"))\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    #for model in model_list:\n    #    model.eval()\n    prediction_dict = {}\n    #pred_dict = OrderedDict(k:list() for k in range(len(model_list))}\n    pred_dict = OrderedDict()\n    for idx in range(len(model_list)):\n        pred_dict[idx] = list()\n    #for model_idx, (model, mixup_bool) in enumerate(zip(model_list, model_with_mixup_bool)):\n    if True:\n        #pred = {'row_id': [], 'target': [], 'score':[]}\n        with torch.no_grad():\n            for i, (image,afile,idx) in enumerate(tqdm(loader)):\n                \n                for model_idx, (model, mixup_bool) in enumerate(zip(model_list, model_with_mixup_bool)):\n                #print(image.shape, afile, \"at batch size: \", batch_size)\n                    before_proba_split = None\n                    each_pred = {'row_id': [], 'target': [], 'score':[]}\n                    image = image.to(device)\n                    target = torch.normal(2, 3, size=(image.shape[0], 1)).to(device)\n\n                    if mixup_bool==False:\n                        prediction = model(image)\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                    else:\n                        prediction = model((image,target))\n                        proba_before = torch.sigmoid(prediction[\"framewise_logit\"])\n                        proba_after = proba_before.cpu().numpy()\n                #print(proba_after.shape, afile, idx)\n                    proba_length = proba_after.shape[0]\n                    for interval_idx in range(proba_length):\n                        proba = proba_after[interval_idx]\n                        chunk_start_time = idx.cpu().numpy()[interval_idx]\n                        chunk_start_time *= 10\n            #print(proba, proba.shape)\n                        proba_split = np.array_split(proba, 4, axis=0)\n                        cur_proba_split = proba_split[:2]\n\n                        for time_index, each_proba in enumerate(cur_proba_split):\n                            if before_proba_split is not None:\n                        #print(time_index)\n                                avg_each_proba = np.vstack([each_proba,before_proba_split[time_index]])\n                            else:\n                                avg_each_proba = each_proba\n                            for bird in scored_birds:\n                            #print(\"bird: \", bird)\n                                try:\n                                    result_proba = np.max(avg_each_proba, axis=0)\n\n                                    score = result_proba[np.where(np.array(bird_label_total)==bird)]\n                            #print(\"each_proba_success\")\n                                except IndexError:\n                                    score = 0\n                            #print(\"each_proba_failed\")\n\n                        #row_id = afile[0] + '_' + bird + '_' + str(chunk_end_time)\n                                row_id = afile[0] + '_' + bird + '_' + str(chunk_start_time + (time_index+1)*5)\n                            #print(row_id)\n                                each_pred['row_id'].append(row_id)\n                                each_pred['score'].append(score[0])\n                                each_pred['target'].append(True if score > threshold else False)\n\n                        if i < len(loader):\n                            before_proba_split = proba_split[2:]\n                    pred_dict[model_idx].append(each_pred)\n            #pred['score'].append(score)\n\n    return pred_dict\n","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.620562Z","iopub.execute_input":"2022-05-24T04:09:52.620747Z","iopub.status.idle":"2022-05-24T04:09:52.641426Z","shell.execute_reply.started":"2022-05-24T04:09:52.620723Z","shell.execute_reply":"2022-05-24T04:09:52.640555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndef prediction_framewise_voting_10sec_speedup(test_audios,\n               weights_path: list,\n               threshold):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_list = []\n    model_with_mixup_bool = [True]*len(weights_path)\n    for i in range(len(weights_path)):\n        if i <=3:\n            model = MixupTimmEFFV2SED(\n                                    base_model_name=CFG_EFFV2DOUBLEMIXUP.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_EFFV2DOUBLEMIXUP.num_classes,\n                                    in_channels=CFG_EFFV2DOUBLEMIXUP.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i >= 4:\n            model = MixupTimmEFFV2SED(\n                                    base_model_name=CFG_EFFV2MDOUBLEMIXUP.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_EFFV2MDOUBLEMIXUP.num_classes,\n                                    in_channels=CFG_EFFV2MDOUBLEMIXUP.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i >= 8:\n            #CFG_EFFV2MDOUBLEMIXUP\n            model = MixupTimmEFFV2SPECSED_LOW(\n                                    base_model_name=CFG_EFFV2MDOUBLEMIXUP.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_EFFV2MDOUBLEMIXUP.num_classes,\n                                    in_channels=CFG_EFFV2MDOUBLEMIXUP.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        else:\n            model = TimmSED(base_model_name=CFG.base_model_name,\n                        pretrained=False,\n                        num_classes=CFG.num_classes,\n                        in_channels=CFG.in_channels)\n            model_list.append(prepare_model_for_inference(model, weights_path[i]).to(device).eval())\n        gc.collect()\n\n    warnings.filterwarnings(\"ignore\")\n    prediction_dfs = []\n    \n    pred = {'row_id': [], 'target': []}\n    \n    for audio_path in test_audios:\n        #[(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\n        afile = audio_path.name.split(\".\")[0]\n        #print(\"first afile\")\n        with timer(f\"Loading {str(audio_path)}\", logger):\n            clip, _ = sf.read(audio_path)\n        len_wav_shape = len(clip.shape)\n        if len_wav_shape == 1:\n            pass\n        else:\n            clip = clip[:,0]\n        length_clip = clip.shape[0]\n        cal_frame_for_interval = 10\n        intervals = round(length_clip/32000/cal_frame_for_interval)\n        \n        #effective_test_length = 32000*cal_frame*intervals\n        #if not length_clip < 32000*5*12:\n        #clip = clip[:effective_test_length]\n        clip_list = []\n        #print(intervals)\n        index_list = []\n        for index in range(intervals):\n            added_clip = clip[index*32000*cal_frame_for_interval:(index+1)*32000*cal_frame_for_interval+32000*cal_frame_for_interval]\n            #print(len(added_clip))\n            if len(added_clip)<640000:\n                added_clip = np.pad(added_clip, (0,640000-len(added_clip)))\n            clip_list.append(added_clip)\n            index_list.append(index)\n        clip_list = np.array(clip_list)\n        with timer(f\"Prediction on {audio_path}\", logger):\n            prediction_dict = prediction_each_for_framewise_voting_10sec_speedup(clip=clip_list,\n                                                       afile=afile,\n                                                       index_list = index_list,\n                                                       model_list=model_list,\n                                                       threshold=threshold,\n                                                       model_with_mixup_bool = model_with_mixup_bool)\n        for idx,(model_idx, each_pred_dict) in enumerate(prediction_dict.items()):\n            #print(each_pred_dict)\n            row = []\n            score = []\n            target = []\n            for row_idx, each_row in enumerate(each_pred_dict):\n                #print(each_row)\n                if idx == 0:\n                    row += each_row['row_id']\n                score += each_row['score']\n                target += each_row['target']\n            if idx == 0:\n                prediction_df = pd.DataFrame({\n                    \"row_id\":row,\n                    f\"target_{idx}\":target,\n                    f\"score_{idx}\":score\n                })\n            else:\n                prediction_df[f\"target_{idx}\"]=target\n                prediction_df[f\"score_{idx}\"]=score\n        #if pred_idx==0:\n        #        row_id = list(each_pred_dict['row_id'])\n        #    target = list(each_pred_dict['target'])\n        #    score = list(each_pred_dict['score'])\n        #    if pred_idx==0:\n        #        prediction_df = pd.DataFrame({\n        #            \"row_id\": row_id,\n        #            f\"target_{pred_idx}\": target,\n        #            f\"score_{pred_idx}\" : score\n        #        })\n        #    else:\n        #        \n        #        prediction_df[f\"target_{pred_idx}\"]=target\n        #        prediction_df[f\"score_{pred_idx}\"]=score\n            #print(prediction_df)\n        prediction_dfs.append(prediction_df)\n    \n    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n    return prediction_df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.64297Z","iopub.execute_input":"2022-05-24T04:09:52.643542Z","iopub.status.idle":"2022-05-24T04:09:52.665297Z","shell.execute_reply.started":"2022-05-24T04:09:52.643505Z","shell.execute_reply":"2022-05-24T04:09:52.664622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_framewise_voting_15sec_low_speedup(test_audios,\n               weights_path: list,\n               threshold):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_list = []\n    model_with_mixup_bool = [True]*len(weights_path)\n    for i in range(len(weights_path)):\n        if i <= 4:\n            model = MixupTimmEFFV2SPECSED_LOW(\n                                    base_model_name=CFG_EFFV2DOUBLEMIXUP.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_EFFV2DOUBLEMIXUP.num_classes,\n                                    in_channels=CFG_EFFV2DOUBLEMIXUP.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i <=5:\n            model = HighMixupTimmEFFV2SED(\n                                    base_model_name=CFG_HIGH_EFFV2DOUBLEMIXUP.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_HIGH_EFFV2DOUBLEMIXUP.num_classes,\n                                    in_channels=CFG_HIGH_EFFV2DOUBLEMIXUP.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i > 7:\n            model = MixupTimmNFNETSED(\n                                    base_model_name=CFG_NFNETMIXUP.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_NFNETMIXUP.num_classes,\n                                    in_channels=CFG_NFNETMIXUP.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i <= 12:\n            model = PretrainedNFNETGRUTimmSED(base_model_name=CFG.base_model_name,\n                            pretrained=False,\n                            num_classes=21,\n                            in_channels=CFG.in_channels)\n            model_list.append(prepare_model_for_inference(model, weights_path[i]).to(device).eval())\n        else:\n            model = TimmSED(base_model_name=CFG.base_model_name,\n                        pretrained=False,\n                        num_classes=CFG.num_classes,\n                        in_channels=CFG.in_channels)\n            model_list.append(prepare_model_for_inference(model, weights_path[i]).to(device).eval())\n        gc.collect()\n\n    warnings.filterwarnings(\"ignore\")\n    prediction_dfs = []\n    \n    pred = {'row_id': [], 'target': []}\n    \n    for audio_path in test_audios:\n        #[(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\n        afile = audio_path.name.split(\".\")[0]\n        #print(\"first afile\")\n        with timer(f\"Loading {str(audio_path)}\", logger):\n            clip, _ = sf.read(audio_path)\n        len_wav_shape = len(clip.shape)\n        if len_wav_shape == 1:\n            pass\n        else:\n            clip = clip[:,0]\n        length_clip = clip.shape[0]\n        cal_frame_for_interval = 30\n        intervals = round(length_clip/32000/cal_frame_for_interval)\n        \n        #effective_test_length = 32000*cal_frame*intervals\n        #if not length_clip < 32000*5*12:\n        #clip = clip[:effective_test_length]\n        clip_list = []\n        #print(intervals)\n        index_list = []\n        for index in range(intervals):\n            added_clip = clip[index*32000*cal_frame_for_interval:(index+1)*32000*cal_frame_for_interval+32000*cal_frame_for_interval]\n            #print(len(added_clip))\n            if len(added_clip)<320000*6:\n                added_clip = np.pad(added_clip, (0,320000*6-len(added_clip)))\n            clip_list.append(added_clip)\n            index_list.append(index)\n        clip_list = np.array(clip_list)\n        with timer(f\"Prediction on {audio_path}\", logger):\n            prediction_dict = prediction_each_for_framewise_voting_15sec_speedup(clip=clip_list,\n                                                       afile=afile,\n                                                       index_list = index_list,\n                                                       model_list=model_list,\n                                                       threshold=threshold,\n                                                       model_with_mixup_bool = model_with_mixup_bool)\n        #OrderedDict([(0, [{'row_id': ['soundscape_453028782_akiapo_5', \n        #'soundscape_453028782_aniani_5', 'soundscape_453028782_apapan_5', 'soundscape_453028782_barpet_5', \n        #'soundscape_453028782_crehon_5', 'soundscape_453028782_elepai_5', 'soundscape_453028782_ercfra_5', 'soundscape_453028782_hawama_5', 'soundscape_453028782_hawcre_5', 'soundscape_453028782_hawgoo_5', 'soundscape_453028782_hawhaw_5', 'soundscape_453028782_hawpet1_5', 'soundscape_453028782_houfin_5', 'soundscape_453028782_iiwi_5', 'soundscape_453028782_jabwar_5', 'soundscape_453028782_maupar_5', 'soundscape_453028782_omao_5', 'soundscape_453028782_puaioh_5', 'soundscape_453028782_skylar_5', 'soundscape_453028782_warwhe1_5', 'soundscape_453028782_yefcan_5', 'soundscape_453028782_akiapo_10', 'soundscape_453028782_aniani_10', 'soundscape_453028782_apapan_10', 'soundscape_453028782_barpet_10', 'soundscape_453028782_crehon_10', 'soundscape_453028782_elepai_10', 'soundscape_453028782_ercfra_10', 'soundscape_453028782_hawama_10', 'soundscape_453028782_hawcre_10', 'soundscape_453028782_hawgoo_10', 'soundscape_453028782_hawhaw_10', 'soundscape_453028782_hawpet1_10', 'soundscape_453028782_houfin_10', 'soundscape_453028782_iiwi_10', 'soundscape_453028782_jabwar_10', 'soundscape_453028782_maupar_10', 'soundscape_453028782_omao_10', 'soundscape_453028782_puaioh_10', 'soundscape_453028782_skylar_10', 'soundscape_453028782_warwhe1_10', 'soundscape_453028782_yefcan_10', 'soundscape_453028782_akiapo_15', 'so\n        \n        #print(prediction_dict)\n        for idx,(model_idx, each_pred_dict) in enumerate(prediction_dict.items()):\n            #print(each_pred_dict)\n            row = []\n            score = []\n            target = []\n            for row_idx, each_row in enumerate(each_pred_dict):\n                #print(each_row)\n                if idx == 0:\n                    row += each_row['row_id']\n                score += each_row['score']\n                target += each_row['target']\n            if idx == 0:\n                prediction_df = pd.DataFrame({\n                    \"row_id\":row,\n                    f\"target_{idx}\":target,\n                    f\"score_{idx}\":score\n                })\n            else:\n                prediction_df[f\"target_{idx}\"]=target\n                prediction_df[f\"score_{idx}\"]=score\n        #if pred_idx==0:\n        #        row_id = list(each_pred_dict['row_id'])\n        #    target = list(each_pred_dict['target'])\n        #    score = list(each_pred_dict['score'])\n        #    if pred_idx==0:\n        #        prediction_df = pd.DataFrame({\n        #            \"row_id\": row_id,\n        #            f\"target_{pred_idx}\": target,\n        #            f\"score_{pred_idx}\" : score\n        #        })\n        #    else:\n        #        \n        #        prediction_df[f\"target_{pred_idx}\"]=target\n        #        prediction_df[f\"score_{pred_idx}\"]=score\n            #print(prediction_df)\n        prediction_dfs.append(prediction_df)\n    \n    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n    return prediction_df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.66841Z","iopub.execute_input":"2022-05-24T04:09:52.669067Z","iopub.status.idle":"2022-05-24T04:09:52.692045Z","shell.execute_reply.started":"2022-05-24T04:09:52.669029Z","shell.execute_reply":"2022-05-24T04:09:52.69132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MixupTimmNFNETSPECSED\n#CFG_NFNET0_SPEC_64MEL_15SEC","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:09:52.694458Z","iopub.execute_input":"2022-05-24T04:09:52.695025Z","iopub.status.idle":"2022-05-24T04:09:52.703836Z","shell.execute_reply.started":"2022-05-24T04:09:52.694986Z","shell.execute_reply":"2022-05-24T04:09:52.703142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def prediction_framewise_voting_15sec_64mel_speedup(test_audios,\n               weights_path: list,\n               threshold):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model_list = []\n    model_with_mixup_bool = [True]*len(weights_path)\n    for i in range(len(weights_path)):\n        if i <= 2:\n            model = MixupTimmEFFV2SPECSED_64MEL(\n                                    base_model_name=CFG_EFFV2DOUBLEMIXUP_64MEL.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_EFFV2DOUBLEMIXUP_64MEL.num_classes,\n                                    in_channels=CFG_EFFV2DOUBLEMIXUP_64MEL.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i <=6:\n            model = MixupTimmNFNETSPECSED(\n                                    base_model_name=CFG_NFNET0_SPEC_64MEL_15SEC.base_model_name,\n                                    pretrained=False,\n                                    num_classes=CFG_NFNET0_SPEC_64MEL_15SEC.num_classes,\n                                    in_channels=CFG_NFNET0_SPEC_64MEL_15SEC.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i <=10:\n            model = MixupTimmNFNETSPECSED(\n                                    base_model_name=\"eca_nfnet_l1\",\n                                    pretrained=False,\n                                    num_classes=CFG_NFNET0_SPEC_64MEL_15SEC.num_classes,\n                                    in_channels=CFG_NFNET0_SPEC_64MEL_15SEC.in_channels)\n            model_list.append(prepare_model_for_mixup_inference(model, weights_path[i]).to(device).eval())\n        elif i <= 12:\n            model = PretrainedNFNETGRUTimmSED(base_model_name=CFG.base_model_name,\n                            pretrained=False,\n                            num_classes=21,\n                            in_channels=CFG.in_channels)\n            model_list.append(prepare_model_for_inference(model, weights_path[i]).to(device).eval())\n        else:\n            model = TimmSED(base_model_name=CFG.base_model_name,\n                        pretrained=False,\n                        num_classes=CFG.num_classes,\n                        in_channels=CFG.in_channels)\n            model_list.append(prepare_model_for_inference(model, weights_path[i]).to(device).eval())\n        gc.collect()\n\n    warnings.filterwarnings(\"ignore\")\n    prediction_dfs = []\n    \n    pred = {'row_id': [], 'target': []}\n    \n    for audio_path in test_audios:\n        #[(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\n        afile = audio_path.name.split(\".\")[0]\n        #print(\"first afile\")\n        with timer(f\"Loading {str(audio_path)}\", logger):\n            clip, _ = sf.read(audio_path)\n        len_wav_shape = len(clip.shape)\n        if len_wav_shape == 1:\n            pass\n        else:\n            clip = clip[:,0]\n        length_clip = clip.shape[0]\n        cal_frame_for_interval = 30\n        intervals = round(length_clip/32000/cal_frame_for_interval)\n        \n        #effective_test_length = 32000*cal_frame*intervals\n        #if not length_clip < 32000*5*12:\n        #clip = clip[:effective_test_length]\n        clip_list = []\n        #print(intervals)\n        index_list = []\n        for index in range(intervals):\n            added_clip = clip[index*32000*cal_frame_for_interval:(index+1)*32000*cal_frame_for_interval+32000*cal_frame_for_interval]\n            #print(len(added_clip))\n            if len(added_clip)<320000*6:\n                added_clip = np.pad(added_clip, (0,320000*6-len(added_clip)))\n            clip_list.append(added_clip)\n            index_list.append(index)\n        clip_list = np.array(clip_list)\n        with timer(f\"Prediction on {audio_path}\", logger):\n            prediction_dict = prediction_each_for_framewise_voting_15sec_speedup(clip=clip_list,\n                                                       afile=afile,\n                                                       index_list = index_list,\n                                                       model_list=model_list,\n                                                       threshold=threshold,\n                                                       model_with_mixup_bool = model_with_mixup_bool)\n        #OrderedDict([(0, [{'row_id': ['soundscape_453028782_akiapo_5', \n        #'soundscape_453028782_aniani_5', 'soundscape_453028782_apapan_5', 'soundscape_453028782_barpet_5', \n        #'soundscape_453028782_crehon_5', 'soundscape_453028782_elepai_5', 'soundscape_453028782_ercfra_5', 'soundscape_453028782_hawama_5', 'soundscape_453028782_hawcre_5', 'soundscape_453028782_hawgoo_5', 'soundscape_453028782_hawhaw_5', 'soundscape_453028782_hawpet1_5', 'soundscape_453028782_houfin_5', 'soundscape_453028782_iiwi_5', 'soundscape_453028782_jabwar_5', 'soundscape_453028782_maupar_5', 'soundscape_453028782_omao_5', 'soundscape_453028782_puaioh_5', 'soundscape_453028782_skylar_5', 'soundscape_453028782_warwhe1_5', 'soundscape_453028782_yefcan_5', 'soundscape_453028782_akiapo_10', 'soundscape_453028782_aniani_10', 'soundscape_453028782_apapan_10', 'soundscape_453028782_barpet_10', 'soundscape_453028782_crehon_10', 'soundscape_453028782_elepai_10', 'soundscape_453028782_ercfra_10', 'soundscape_453028782_hawama_10', 'soundscape_453028782_hawcre_10', 'soundscape_453028782_hawgoo_10', 'soundscape_453028782_hawhaw_10', 'soundscape_453028782_hawpet1_10', 'soundscape_453028782_houfin_10', 'soundscape_453028782_iiwi_10', 'soundscape_453028782_jabwar_10', 'soundscape_453028782_maupar_10', 'soundscape_453028782_omao_10', 'soundscape_453028782_puaioh_10', 'soundscape_453028782_skylar_10', 'soundscape_453028782_warwhe1_10', 'soundscape_453028782_yefcan_10', 'soundscape_453028782_akiapo_15', 'so\n        \n        #print(prediction_dict)\n        for idx,(model_idx, each_pred_dict) in enumerate(prediction_dict.items()):\n            #print(each_pred_dict)\n            row = []\n            score = []\n            target = []\n            for row_idx, each_row in enumerate(each_pred_dict):\n                #print(each_row)\n                if idx == 0:\n                    row += each_row['row_id']\n                score += each_row['score']\n                target += each_row['target']\n            if idx == 0:\n                prediction_df = pd.DataFrame({\n                    \"row_id\":row,\n                    f\"target_{idx}\":target,\n                    f\"score_{idx}\":score\n                })\n            else:\n                prediction_df[f\"target_{idx}\"]=target\n                prediction_df[f\"score_{idx}\"]=score\n        #if pred_idx==0:\n        #        row_id = list(each_pred_dict['row_id'])\n        #    target = list(each_pred_dict['target'])\n        #    score = list(each_pred_dict['score'])\n        #    if pred_idx==0:\n        #        prediction_df = pd.DataFrame({\n        #            \"row_id\": row_id,\n        #            f\"target_{pred_idx}\": target,\n        #            f\"score_{pred_idx}\" : score\n        #        })\n        #    else:\n        #        \n        #        prediction_df[f\"target_{pred_idx}\"]=target\n        #        prediction_df[f\"score_{pred_idx}\"]=score\n            #print(prediction_df)\n        prediction_dfs.append(prediction_df)\n    \n    prediction_df = pd.concat(prediction_dfs, axis=0, sort=False).reset_index(drop=True)\n    return prediction_df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:17:48.590741Z","iopub.execute_input":"2022-05-24T04:17:48.591094Z","iopub.status.idle":"2022-05-24T04:17:48.636444Z","shell.execute_reply.started":"2022-05-24T04:17:48.591049Z","shell.execute_reply":"2022-05-24T04:17:48.635509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TARGET_SR = 32000\n\nDATADIR = Path(\"../input/birdclef-2022/test_soundscapes/\")\n\nall_audios = list(DATADIR.glob(\"*.ogg\"))\nall_audio_ids = [\"_\".join(audio_id.name.split(\"_\")[:2]) for audio_id in all_audios]\nsubmission_df = pd.DataFrame({\n    \"row_id\": all_audio_ids\n})\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:17:49.438178Z","iopub.execute_input":"2022-05-24T04:17:49.438461Z","iopub.status.idle":"2022-05-24T04:17:49.455859Z","shell.execute_reply.started":"2022-05-24T04:17:49.438421Z","shell.execute_reply":"2022-05-24T04:17:49.454769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"weights_path_10sec = [Path(\"../input/fulleffv2320hop1024nft/totalclass-doublemixup-5sec-length1024-128mel-320hop-weightmixed-tf-efficientnet-v2s-pretrain-fold-0.pth\"),\n                Path(\"../input/fulleffv2320hop1024nft/totalclass-doublemixup-5sec-length1024-128mel-320hop-weightmixed-tf-efficientnet-v2s-pretrain-fold-1.pth\"),\n                Path(\"../input/fulleffv2320hop1024nft/totalclass-doublemixup-5sec-length1024-128mel-320hop-weightmixed-tf-efficientnet-v2s-pretrain-fold-2.pth\"),\n                Path(\"../input/fulleffv2320hop1024nft/totalclass-doublemixup-5sec-length1024-128mel-320hop-weightmixed-tf-efficientnet-v2s-pretrain-fold-3.pth\"),\n                Path(\"../input/effv2m128mel1024nfftdoublemixup/128mel-5sec-effv2m-fold0.pth\"),\n                Path(\"../input/effv2m128mel1024nfftdoublemixup/128mel-5sec-effv2m-fold1.pth\"),\n                Path(\"../input/effv2m128mel1024nfftdoublemixup/128mel-5sec-effv2m-fold2.pth\"),\n                Path(\"../input/effv2m128mel1024nfftdoublemixup/128mel-5sec-effv2m-fold3.pth\"),\n                Path(\"../input/specdiffseed128meleffv2m/fold0-320hop-spec-diffseed-tf-efficientnet-v2m.pth\"),\n                Path(\"../input/specdiffseed128meleffv2m/fold1-320hop-spec-diffseed-tf-efficientnet-v2m.pth\"),\n                Path(\"../input/specdiffseed128meleffv2m/fold3-320hop-spec-diffseed-tf-efficientnet-v2m.pth\"),\n                #Path(\"../input/fullnfnetmixup320hop5sec/totalclass-5sec-320hop-weightmixed-eca-nfnet-l0-pretrain-fold-0.pth\"),\n                #Path(\"../input/nfnetgrufromfinetune/nfnetl0grufromfinetune-10sec-fold0.pth\"),\n                #Path(\"../input/nfnetgrufromfinetune/nfnetl0grufromfinetune-10sec-fold1.pth\"),\n                #Path(\"../input/nfnetgrufromfinetune/nfnetl0grufromfinetune-10sec-fold2.pth\"),\n                #Path(\"../input/nfnetgrufromfinetune/nfnetl0grufromfinetune-10sec-fold3.pth\"),\n                #Path(\"../input/nfnetgrufromfinetune/nfnetl0grufromfinetune-10sec-fold4.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0-frompretrain-5sec-fold2-train.49_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0-frompretrain-5sec-train.35_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0-frompretrain-5sec-train.38_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0-frompretrain-5sec-train.42_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0-frompretrain-5sec-train.49_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_10sec_fold0_train.31_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_10sec_fold1_train.47_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_10sec_fold2_train.50_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_10sec_fold3_train.48_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_10sec_fold4_train.49_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/fold0-frompretrain-effb0-15sec-train.50_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/fold1-frompretrain-effb0-15sec-train.50_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/fold2-frompretrain-effb0-15sec-train.28_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/fold3-frompretrain-effb0-15sec-train.34_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/fold4-frompretrain-effb0-15sec-train.46_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_aug_fold4_train.88_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_aug_fold0_train.94_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_aug_fold1_train.91_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_aug_fold2_train.75_full.pth\"),\n                #Path(\"../input/birdclefclass21effb0aug/effb0_aug_fold3_train.91_full.pth\")\n               ]\nweights_path_15sec = [Path(\"../input/fulleffv2320hop1024nft/fold0-spec-15sec-effv2-320hop.pth\"),\n                      Path(\"../input/speceffv2diffseed1281024/fold0_spec_320hop_diffseed_128mel_effv2s.pth\"),\n                      Path(\"../input/speceffv2diffseed1281024/fold1_spec_320hop_diffseed_128mel_effv2s.pth\"),\n                      Path(\"../input/speceffv2diffseed1281024/fold2_spec_320hop_diffseed_128mel_effv2s.pth\"),\n                      Path(\"../input/speceffv2diffseed1281024/fold3_spec_320hop_diffseed_128mel_effv2s.pth\")\n                     ]\nweights_path_15sec_64mel = [Path(\"../input/15seceffv2sspec64mel2048nfftdoublemixup/spec-64mel-15sec-effv2s-fold1.pth\"),\n                      Path(\"../input/15seceffv2sspec64mel2048nfftdoublemixup/spec-64mel-15sec-effv2s-fold2.pth\"),\n                      Path(\"../input/15seceffv2sspec64mel2048nfftdoublemixup/spec-64mel-15sec-effv2s-fold3.pth\"),\n                      Path(\"../input/nfnet64melspec/fold0-64mel-spec-diffseed-nfnetecal0.pth\"),\n                      Path(\"../input/nfnet64melspec/fold1-64mel-spec-diffseed-nfnetecal0.pth\"),\n                      Path(\"../input/nfnet64melspec/fold2-64mel-spec-diffseed-nfnetecal0.pth\"),\n                      Path(\"../input/nfnet64melspec/fold3-64mel-spec-diffseed-nfnetecal0.pth\"),\n                      Path(\"../input/nfnet64melspec/fold0-64mel-spec-diffseed-nfnetecal1.pth.pth\"),\n                      Path(\"../input/nfnet64melspec/fold1-64mel-spec-diffseed-nfnetecal1.pth.pth\"),\n                      Path(\"../input/nfnet64melspec/fold2-64mel-spec-diffseed-nfnetecal1.pth\"),\n                      Path(\"../input/nfnet64melspec/fold3-64mel-spec-diffseed-nfnetecal1.pth\"),\n                     ]\n#submission = prediction_framewise_ensemble(test_audios=all_audios,\ntemp_submission = prediction_framewise_voting_10sec_speedup(test_audios=all_audios,\n                        weights_path=weights_path_10sec,\n                        threshold=0.065)\ntemp_submission1 = prediction_framewise_voting_15sec_low_speedup(test_audios=all_audios,\n                        weights_path=weights_path_15sec,\n                        threshold=0.065)\ntemp_submission2 = prediction_framewise_voting_15sec_64mel_speedup(test_audios=all_audios,\n                        weights_path=weights_path_15sec_64mel,\n                        threshold=0.065)\n#submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:17:50.219598Z","iopub.execute_input":"2022-05-24T04:17:50.220107Z","iopub.status.idle":"2022-05-24T04:19:16.298172Z","shell.execute_reply.started":"2022-05-24T04:17:50.220069Z","shell.execute_reply":"2022-05-24T04:19:16.297524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:16.300434Z","iopub.execute_input":"2022-05-24T04:19:16.30069Z","iopub.status.idle":"2022-05-24T04:19:16.344515Z","shell.execute_reply.started":"2022-05-24T04:19:16.300655Z","shell.execute_reply":"2022-05-24T04:19:16.343723Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission1","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:16.345747Z","iopub.execute_input":"2022-05-24T04:19:16.34605Z","iopub.status.idle":"2022-05-24T04:19:16.370188Z","shell.execute_reply.started":"2022-05-24T04:19:16.346015Z","shell.execute_reply":"2022-05-24T04:19:16.369451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission2","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:16.37201Z","iopub.execute_input":"2022-05-24T04:19:16.372252Z","iopub.status.idle":"2022-05-24T04:19:16.404678Z","shell.execute_reply.started":"2022-05-24T04:19:16.372219Z","shell.execute_reply":"2022-05-24T04:19:16.403887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission1 = temp_submission1.rename(columns={\"target_0\":\"target_11\", \"score_0\":\"score_11\",'row_id':\"row_id_backup\"})\ntemp_submission1 = temp_submission1.rename(columns={\"target_1\":\"target_12\", \"score_1\":\"score_12\",'row_id':\"row_id_backup\"})\ntemp_submission1 = temp_submission1.rename(columns={\"target_2\":\"target_13\", \"score_2\":\"score_13\",'row_id':\"row_id_backup\"})\ntemp_submission1 = temp_submission1.rename(columns={\"target_3\":\"target_14\", \"score_3\":\"score_14\",'row_id':\"row_id_backup\"})\ntemp_submission1 = temp_submission1.rename(columns={\"target_4\":\"target_15\", \"score_4\":\"score_15\",'row_id':\"row_id_backup\"})","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:16.405916Z","iopub.execute_input":"2022-05-24T04:19:16.406213Z","iopub.status.idle":"2022-05-24T04:19:16.420156Z","shell.execute_reply.started":"2022-05-24T04:19:16.406177Z","shell.execute_reply":"2022-05-24T04:19:16.419377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission2 = temp_submission2.rename(columns={\"target_0\":\"target_16\", \"score_0\":\"score_16\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_1\":\"target_17\", \"score_1\":\"score_17\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_2\":\"target_18\", \"score_2\":\"score_18\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_3\":\"target_19\", \"score_3\":\"score_19\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_4\":\"target_20\", \"score_4\":\"score_20\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_5\":\"target_21\", \"score_5\":\"score_21\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_6\":\"target_22\", \"score_6\":\"score_22\",'row_id':\"row_id_backup\"})","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:16.421553Z","iopub.execute_input":"2022-05-24T04:19:16.421865Z","iopub.status.idle":"2022-05-24T04:19:16.432637Z","shell.execute_reply.started":"2022-05-24T04:19:16.421831Z","shell.execute_reply":"2022-05-24T04:19:16.431806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission2 = temp_submission2.rename(columns={\"target_7\":\"target_23\", \"score_7\":\"score_23\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_8\":\"target_24\", \"score_8\":\"score_24\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_9\":\"target_25\", \"score_9\":\"score_25\",'row_id':\"row_id_backup\"})\ntemp_submission2 = temp_submission2.rename(columns={\"target_10\":\"target_26\", \"score_10\":\"score_26\",'row_id':\"row_id_backup\"})","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:16.434142Z","iopub.execute_input":"2022-05-24T04:19:16.434473Z","iopub.status.idle":"2022-05-24T04:19:16.443824Z","shell.execute_reply.started":"2022-05-24T04:19:16.434419Z","shell.execute_reply":"2022-05-24T04:19:16.442972Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:35.585441Z","iopub.execute_input":"2022-05-24T04:19:35.58602Z","iopub.status.idle":"2022-05-24T04:19:35.621009Z","shell.execute_reply.started":"2022-05-24T04:19:35.585983Z","shell.execute_reply":"2022-05-24T04:19:35.620321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission = pd.concat([temp_submission,temp_submission1,temp_submission2],axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:35.786436Z","iopub.execute_input":"2022-05-24T04:19:35.786997Z","iopub.status.idle":"2022-05-24T04:19:35.79655Z","shell.execute_reply.started":"2022-05-24T04:19:35.78696Z","shell.execute_reply":"2022-05-24T04:19:35.795867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:35.986533Z","iopub.execute_input":"2022-05-24T04:19:35.986883Z","iopub.status.idle":"2022-05-24T04:19:36.020957Z","shell.execute_reply.started":"2022-05-24T04:19:35.986754Z","shell.execute_reply":"2022-05-24T04:19:36.020121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission1","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:36.195858Z","iopub.execute_input":"2022-05-24T04:19:36.196609Z","iopub.status.idle":"2022-05-24T04:19:36.221984Z","shell.execute_reply.started":"2022-05-24T04:19:36.196559Z","shell.execute_reply":"2022-05-24T04:19:36.22134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission2","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:37.488984Z","iopub.execute_input":"2022-05-24T04:19:37.489439Z","iopub.status.idle":"2022-05-24T04:19:37.54Z","shell.execute_reply.started":"2022-05-24T04:19:37.489402Z","shell.execute_reply":"2022-05-24T04:19:37.53909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len_target = len([x for x in temp_submission.columns if x.startswith(\"target\")])","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:39.286451Z","iopub.execute_input":"2022-05-24T04:19:39.287454Z","iopub.status.idle":"2022-05-24T04:19:39.292438Z","shell.execute_reply.started":"2022-05-24T04:19:39.287403Z","shell.execute_reply":"2022-05-24T04:19:39.291484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len_target)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:40.103645Z","iopub.execute_input":"2022-05-24T04:19:40.104397Z","iopub.status.idle":"2022-05-24T04:19:40.108734Z","shell.execute_reply.started":"2022-05-24T04:19:40.104355Z","shell.execute_reply":"2022-05-24T04:19:40.107844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_columns = [\"target_\"+str(i) for i in range(len_target)]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:41.376045Z","iopub.execute_input":"2022-05-24T04:19:41.376549Z","iopub.status.idle":"2022-05-24T04:19:41.381202Z","shell.execute_reply.started":"2022-05-24T04:19:41.376509Z","shell.execute_reply":"2022-05-24T04:19:41.380361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score_columns = [\"score_\"+str(i) for i in range(len_target)]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:42.462183Z","iopub.execute_input":"2022-05-24T04:19:42.462979Z","iopub.status.idle":"2022-05-24T04:19:42.470138Z","shell.execute_reply.started":"2022-05-24T04:19:42.462933Z","shell.execute_reply":"2022-05-24T04:19:42.469188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_colwidth', -1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:43.17103Z","iopub.execute_input":"2022-05-24T04:19:43.171572Z","iopub.status.idle":"2022-05-24T04:19:43.176747Z","shell.execute_reply.started":"2022-05-24T04:19:43.171532Z","shell.execute_reply":"2022-05-24T04:19:43.1758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission = temp_submission[['row_id']+[\"target_\"+str(i) for i in range(len_target)]+[\"score_\"+str(i) for i in range(len_target)]]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:43.410276Z","iopub.execute_input":"2022-05-24T04:19:43.410821Z","iopub.status.idle":"2022-05-24T04:19:43.422968Z","shell.execute_reply.started":"2022-05-24T04:19:43.410775Z","shell.execute_reply":"2022-05-24T04:19:43.42222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#temp_submission[[f\"score_{i}\" for i in range(11)]][-20:]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:44.535538Z","iopub.execute_input":"2022-05-24T04:19:44.536103Z","iopub.status.idle":"2022-05-24T04:19:44.540054Z","shell.execute_reply.started":"2022-05-24T04:19:44.536062Z","shell.execute_reply":"2022-05-24T04:19:44.538985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_max_score(df):\n    score_list = []\n    for col in score_columns:\n        score_list.append(df[col])\n\n    return max(score_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:44.786757Z","iopub.execute_input":"2022-05-24T04:19:44.787018Z","iopub.status.idle":"2022-05-24T04:19:44.792034Z","shell.execute_reply.started":"2022-05-24T04:19:44.78699Z","shell.execute_reply":"2022-05-24T04:19:44.790977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mean_score(df):\n    score_list = []\n    for col in score_columns:\n        score_list.append(df[col])\n\n    return np.mean(score_list)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:45.443765Z","iopub.execute_input":"2022-05-24T04:19:45.444024Z","iopub.status.idle":"2022-05-24T04:19:45.44894Z","shell.execute_reply.started":"2022-05-24T04:19:45.443998Z","shell.execute_reply":"2022-05-24T04:19:45.448152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_second_score(df):\n    score_list = []\n    for col in score_columns:\n        score_list.append(df[col])\n\n    return score_list[np.argsort(-np.array(score_list))[1]]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:34:57.110885Z","iopub.execute_input":"2022-05-24T04:34:57.111199Z","iopub.status.idle":"2022-05-24T04:34:57.120207Z","shell.execute_reply.started":"2022-05-24T04:34:57.111167Z","shell.execute_reply":"2022-05-24T04:34:57.119503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:46.287513Z","iopub.execute_input":"2022-05-24T04:19:46.28813Z","iopub.status.idle":"2022-05-24T04:19:46.312707Z","shell.execute_reply.started":"2022-05-24T04:19:46.288094Z","shell.execute_reply":"2022-05-24T04:19:46.311977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission.tail()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:46.522245Z","iopub.execute_input":"2022-05-24T04:19:46.522613Z","iopub.status.idle":"2022-05-24T04:19:46.546221Z","shell.execute_reply.started":"2022-05-24T04:19:46.522577Z","shell.execute_reply":"2022-05-24T04:19:46.545535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_real_target(df):\n    init = 0\n    for col in target_columns:\n        init += df[col]\n\n    return init >= int((len(target_columns) / 2) + 1)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:49.957625Z","iopub.execute_input":"2022-05-24T04:19:49.957884Z","iopub.status.idle":"2022-05-24T04:19:49.962099Z","shell.execute_reply.started":"2022-05-24T04:19:49.957852Z","shell.execute_reply":"2022-05-24T04:19:49.961459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"temp_submission['target'] = temp_submission.apply(get_real_target, axis=1)\ntemp_submission['max_score'] = temp_submission.apply(get_max_score, axis=1)\ntemp_submission['mean_score'] = temp_submission.apply(get_mean_score, axis=1)\ntemp_submission['second_score'] = temp_submission.apply(get_second_score, axis=1)\ntemp_submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:34:58.919088Z","iopub.execute_input":"2022-05-24T04:34:58.919347Z","iopub.status.idle":"2022-05-24T04:34:59.084977Z","shell.execute_reply.started":"2022-05-24T04:34:58.919317Z","shell.execute_reply":"2022-05-24T04:34:59.084166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#temp_submission[[f\"target_{x}\" for x in range(23)]]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:51.770013Z","iopub.execute_input":"2022-05-24T04:19:51.770693Z","iopub.status.idle":"2022-05-24T04:19:51.774649Z","shell.execute_reply.started":"2022-05-24T04:19:51.770636Z","shell.execute_reply":"2022-05-24T04:19:51.773603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(temp_submission['max_score']>0.200).sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:19:52.59319Z","iopub.execute_input":"2022-05-24T04:19:52.593513Z","iopub.status.idle":"2022-05-24T04:19:52.599784Z","shell.execute_reply.started":"2022-05-24T04:19:52.593463Z","shell.execute_reply":"2022-05-24T04:19:52.599131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(temp_submission['mean_score']>0.0855).sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:22:26.984476Z","iopub.execute_input":"2022-05-24T04:22:26.985198Z","iopub.status.idle":"2022-05-24T04:22:26.990916Z","shell.execute_reply.started":"2022-05-24T04:22:26.985161Z","shell.execute_reply":"2022-05-24T04:22:26.990214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"(temp_submission['second_score']>0.20).sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:35:16.115963Z","iopub.execute_input":"2022-05-24T04:35:16.116381Z","iopub.status.idle":"2022-05-24T04:35:16.123234Z","shell.execute_reply.started":"2022-05-24T04:35:16.116325Z","shell.execute_reply":"2022-05-24T04:35:16.122587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#temp_submission['target'] = temp_submission['max_score']>0.2\ntemp_submission['target'] = temp_submission['second_score']>0.20","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:35:27.823653Z","iopub.execute_input":"2022-05-24T04:35:27.823904Z","iopub.status.idle":"2022-05-24T04:35:27.830437Z","shell.execute_reply.started":"2022-05-24T04:35:27.823878Z","shell.execute_reply":"2022-05-24T04:35:27.829725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = temp_submission[['row_id','target']]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:35:31.439272Z","iopub.execute_input":"2022-05-24T04:35:31.439674Z","iopub.status.idle":"2022-05-24T04:35:31.445313Z","shell.execute_reply.started":"2022-05-24T04:35:31.439639Z","shell.execute_reply":"2022-05-24T04:35:31.444385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:35:31.623079Z","iopub.execute_input":"2022-05-24T04:35:31.623723Z","iopub.status.idle":"2022-05-24T04:35:31.630586Z","shell.execute_reply.started":"2022-05-24T04:35:31.623686Z","shell.execute_reply":"2022-05-24T04:35:31.629822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:35:31.813091Z","iopub.execute_input":"2022-05-24T04:35:31.813579Z","iopub.status.idle":"2022-05-24T04:35:31.824124Z","shell.execute_reply.started":"2022-05-24T04:35:31.813544Z","shell.execute_reply":"2022-05-24T04:35:31.823209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'].sum()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T04:35:32.757019Z","iopub.execute_input":"2022-05-24T04:35:32.757708Z","iopub.status.idle":"2022-05-24T04:35:32.763579Z","shell.execute_reply.started":"2022-05-24T04:35:32.75767Z","shell.execute_reply":"2022-05-24T04:35:32.762802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}