{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport pandas as pd\nimport numpy as np\nimport re\nimport librosa\nimport cv2\nimport pathlib\nimport os, shutil\nfrom PIL import Image\nfrom scipy import signal as sig\nfrom sklearn.preprocessing import LabelEncoder, minmax_scale\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.utils import image_dataset_from_directory as idfd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:26:39.455524Z","iopub.execute_input":"2022-05-02T17:26:39.455775Z","iopub.status.idle":"2022-05-02T17:26:39.463367Z","shell.execute_reply.started":"2022-05-02T17:26:39.455749Z","shell.execute_reply":"2022-05-02T17:26:39.462012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#now the goal is to create model for every bird in the json file.\ndef librosa_stft(signal):\n    \n    X = librosa.stft(signal, window=sig.windows.tukey(M=2048, alpha=.9)) #using default values n_fft=2048, hop_length=win_length/4, win_length=n_fft, center=true\n    Xdb = librosa.amplitude_to_db(abs(X)).astype('float16')\n    time = librosa.times_like(X, sr=32000).astype('float16') # n_fft=2048, hop_length=512, center=True, filename=None\n    \n    return Xdb, time\n\n#get the index in the array that is sec in time array. For example for time array sec=3 that is 188\ndef get_mark(time, sec):\n\n    mark = np.where(np.logical_and(time >= sec, time <= sec + .1))[0][0]\n    return mark\n\n                \ndef create_images_test(sec, norm, audio_path):\n    \n    '''\n    finds the loudest part of the audio and creates images for the loudest parts\n    - finds segments audio in sec intervals and finds the norm\n    - if norm is less than the norm provided it rejects discards that part of the audio\n    - the shape of all the images should be the same\n    \n    returns shape of the an image.\n    '''\n    \n    rgb_img = []\n    time_sec = []\n    time_mark = 0\n    files = []\n          \n    audio = librosa.load(audio_path, sr=32000)[0]\n    duration = librosa.get_duration(y=audio, sr=32000)\n\n    #print(row['test_files'])\n\n    #get the spectrogram\n    Xdb, time = librosa_stft(audio)\n    #Xdb = minmax_scale(Xdb, feature_range=(0, 255))\n        \n    if time[-1] <= sec:\n\n        interval = time[1] #second element gives the interval since the first element is 0\n        last_time_element = time[-1]\n        extended_time_arr = np.arange(last_time_element+interval, sec+.5, interval)\n\n        num_of_rows = Xdb.shape[0]\n        len_extended_time = len(extended_time_arr)\n        columns_to_append = np.ones([num_of_rows, len_extended_time])*(-100)\n        time_arr_new = np.hstack((time, extended_time_arr))\n        Xdb_new = np.hstack([Xdb, columns_to_append])\n\n        length = len(time_arr_new)\n        intervals = round(length/duration)\n        mark = get_mark(time_arr_new, sec)\n\n        for shift in range(mark, length+mark, mark):\n            ext_Dmat = np.exp(0.1*Xdb_new[:, (shift-mark):shift])\n            norm_ext_Dmat = np.linalg.norm(ext_Dmat)\n            time_mark = time_mark+5\n            time_sec.append(time_mark)\n\n            if norm_ext_Dmat>norm:\n                ext_Dmat = minmax_scale(ext_Dmat, feature_range=(0, 255))\n                img = np.dstack((ext_Dmat, ext_Dmat, ext_Dmat))\n                rgb_img.append(img)\n            else:\n                pass    \n    else:\n\n        length = len(time)\n        mark = get_mark(time, sec)\n        intervals = round(length/duration)\n\n        for shift in range(mark, length+mark, mark):\n            trun_Dmat = np.exp(0.1*Xdb[:, (shift-mark):shift])\n            norm_trun_Dmat = np.linalg.norm(trun_Dmat)\n            time_mark = time_mark+5\n            time_sec.append(time_mark)\n\n            if norm_trun_Dmat >norm:\n                trun_Dmat = minmax_scale(trun_Dmat, feature_range=(0, 255))\n                img = np.dstack((trun_Dmat, trun_Dmat, trun_Dmat))\n                rgb_img.append(img)\n            else:\n                pass\n                 \n    return rgb_img, time_sec","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T17:26:39.484211Z","iopub.execute_input":"2022-05-02T17:26:39.484657Z","iopub.status.idle":"2022-05-02T17:26:39.501849Z","shell.execute_reply.started":"2022-05-02T17:26:39.484618Z","shell.execute_reply":"2022-05-02T17:26:39.501149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = tf.keras.models.load_model('../input/d/datasets/rumman18/vgg19-with-class-csv/trained_model')","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:26:39.504232Z","iopub.execute_input":"2022-05-02T17:26:39.504471Z","iopub.status.idle":"2022-05-02T17:26:41.344345Z","shell.execute_reply.started":"2022-05-02T17:26:39.504443Z","shell.execute_reply":"2022-05-02T17:26:41.343474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/d/datasets/rumman18/vgg19-with-class-csv/Class_encoder.csv')\nkey_list = list(df['Class'])\nval_list = list(df['Encoder'])","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:26:41.350812Z","iopub.execute_input":"2022-05-02T17:26:41.351067Z","iopub.status.idle":"2022-05-02T17:26:41.36523Z","shell.execute_reply.started":"2022-05-02T17:26:41.35104Z","shell.execute_reply":"2022-05-02T17:26:41.36431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_bird_label(prediction, key_list):\n    bird_idx = np.argmax(prediction)\n    bird = key_list[bird_idx]\n    return bird\n\nsubmission = []\n\nfor dirname, _, filenames in os.walk('/kaggle/input/birdclef-2022/test_soundscapes'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n\n        birds = json.load(open('/kaggle/input/birdclef-2022/scored_birds.json'))\n        imgs, time = create_images_test(5, 60, path)\n        \n        for index, image in enumerate(imgs):\n            \n            #make prediction and get the probability \n            if image.shape[1] != 313:\n                rows_to_append = image.shape[0]\n                columns_to_append = 313-image.shape[1]\n                mat = np.zeros([rows_to_append,columns_to_append])\n                mat = np.dstack((mat,mat,mat))\n                image = np.hstack((image,mat))\n            \n            \n            image = image.astype('float16')\n            prediction = model.predict(image.reshape((1,1025,313,3)))\n            #prediction returns a list of list. use prediction[0] get the prediction list\n            predicted_idxs = [i for i,v in enumerate(prediction[0]) if v > .3]\n            pred_birds = []\n\n            for idx in predicted_idxs: \n                pred_bird = key_list[idx]\n                pred_birds.append(pred_bird)\n                \n            birds = json.load(open('/kaggle/input/birdclef-2022/scored_birds.json'))\n            \n            #get the prediction and check if it exceeds some threshold. if it does then set that bird == True else False\n            for pred_bird in pred_birds:\n                row = {\n                    \"row_id\": f\"{filename.replace('.ogg', '')}_{pred_bird}_{time[index]}\",\n                    \"target\": 'True'\n                }\n                submission.append(row)\n                birds.remove(pred_bird)\n                \n            for bird in birds:\n                row = {\n                    \"row_id\": f\"{filename.replace('.ogg', '')}_{bird}_{time[index]}\",\n                    \"target\": 'False'\n                }\n                submission.append(row)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:26:41.366296Z","iopub.execute_input":"2022-05-02T17:26:41.366496Z","iopub.status.idle":"2022-05-02T17:27:06.203449Z","shell.execute_reply.started":"2022-05-02T17:26:41.366471Z","shell.execute_reply":"2022-05-02T17:27:06.202652Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(submission)\ndf.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:27:06.204734Z","iopub.execute_input":"2022-05-02T17:27:06.204974Z","iopub.status.idle":"2022-05-02T17:27:06.213593Z","shell.execute_reply.started":"2022-05-02T17:27:06.204924Z","shell.execute_reply":"2022-05-02T17:27:06.212768Z"},"trusted":true},"execution_count":null,"outputs":[]}]}