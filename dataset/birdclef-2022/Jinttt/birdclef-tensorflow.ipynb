{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nprint(\"TensorFlow version:\", tf.__version__)\nimport tensorflow.keras as tfk\nfrom tensorflow.keras.layers import Dense, Flatten, Conv1D, Embedding, Normalization, Conv1DTranspose,InputLayer\nimport tensorflow.keras.layers as tfkl\nfrom tensorflow.keras import Model\nimport math\nimport time\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport librosa\nimport json\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nimport os\nimport matplotlib.pyplot as plt\nimport tensorflow_io as tfio\nimport random\nimport tensorflow as tf\nfrom pathlib import Path\nprint(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T12:38:49.72153Z","iopub.execute_input":"2022-04-22T12:38:49.721877Z","iopub.status.idle":"2022-04-22T12:39:01.283517Z","shell.execute_reply.started":"2022-04-22T12:38:49.721784Z","shell.execute_reply":"2022-04-22T12:39:01.282426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/birdclef-2022/scored_birds.json','r') as sb:\n  s_b = json.load(sb)\nfile_path = '../input/birdclef-2022'\ntrain_df = pd.read_csv('../input/birdclef-2022/train_metadata.csv')\ntrain_df = train_df[train_df['primary_label'].isin(s_b)]\nbird_label = train_df[\"primary_label\"].unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:39:01.285255Z","iopub.execute_input":"2022-04-22T12:39:01.285504Z","iopub.status.idle":"2022-04-22T12:39:01.43583Z","shell.execute_reply.started":"2022-04-22T12:39:01.285471Z","shell.execute_reply":"2022-04-22T12:39:01.435073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df = pd.read_csv('../input/birdclef-2022/sample_submission.csv')\ntest_df = pd.read_csv('../input/birdclef-2022/test.csv')\nif test_df.shape[0] != submission_df.shape[0]:\n    raise ValueError('test submission row number didnt match')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:39:01.436934Z","iopub.execute_input":"2022-04-22T12:39:01.437782Z","iopub.status.idle":"2022-04-22T12:39:01.458634Z","shell.execute_reply.started":"2022-04-22T12:39:01.437742Z","shell.execute_reply":"2022-04-22T12:39:01.457523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path = '../input/birdclef-2022/train_audio'\n\ndef preprocessing(df, path,bird_label):\n  le = 160000\n  step = int((le/2))\n  sample_rate = 32000\n  train = []\n  for label in tqdm(bird_label):\n    files = librosa.util.find_files(os.path.join(path, label))\n    for f in tqdm(files):\n      yi = np.where(bird_label == label)\n      # load audio\n      y, sr = librosa.load(f,sr=sample_rate)\n      y = ((y-np.amin(y))*2)/(np.amax(y) - np.amin(y)) - 1\n\n      org_len = len(y)\n      intervals = librosa.effects.split(y, top_db= 15, ref= np.max)\n      intervals = intervals.tolist()\n      y = (y.flatten()).tolist()\n      nonsilent_y = []\n\n      for p,q in intervals :\n       nonsilent_y = nonsilent_y + y[p:q+1] \n\n      y = np.array(nonsilent_y).astype('float32')\n      if len(y) < le:\n        while len(y) < le:\n          y = np.concatenate((y, y))\n        y = y[:le]\n      # A 1024-point STFT with frames of 5 s and 50% overlap.\n      stfts = tf.signal.stft(y, frame_length=le, frame_step=step,\n                       fft_length=4096)\n      spectrograms = tf.abs(stfts)\n\n      # Warp the linear scale spectrograms into the mel-scale.\n      num_spectrogram_bins = stfts.shape[-1]\n\n      lower_edge_hertz, upper_edge_hertz, num_mel_bins = 1000.0, 8000.0, 4096\n\n      linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n        num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n        upper_edge_hertz)\n      \n      mel_spectrograms = tf.tensordot(\n        spectrograms, linear_to_mel_weight_matrix, 1)\n      \n      mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n        linear_to_mel_weight_matrix.shape[-1:]))\n\n      # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n      log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n\n      \n      mfccs = tf.signal.mfccs_from_log_mel_spectrograms(\n        log_mel_spectrograms)\n\n      for mfc in mfccs:\n        train.append((mfc, yi))\n  return train","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:39:01.461003Z","iopub.execute_input":"2022-04-22T12:39:01.461239Z","iopub.status.idle":"2022-04-22T12:39:01.477755Z","shell.execute_reply.started":"2022-04-22T12:39:01.461212Z","shell.execute_reply":"2022-04-22T12:39:01.476763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = preprocessing(train_df, train_path, bird_label)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:39:01.478769Z","iopub.execute_input":"2022-04-22T12:39:01.479346Z","iopub.status.idle":"2022-04-22T12:58:38.858683Z","shell.execute_reply.started":"2022-04-22T12:39:01.479304Z","shell.execute_reply":"2022-04-22T12:58:38.857816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TensorflowDataGenerator():\n    'Characterizes a dataset for Tensorflow'\n    def __init__(self, mel_list, batch_size):\n      self.mel_list = mel_list\n      self.batch_size = batch_size\n      self.index_helper = 0\n      self.le = len(mel_list)\n    def __len__(self):\n        return math.ceil(self.le/ self.batch_size)\n\n    def __getitem__(self, index):\n      if self.index_helper >= self.le:\n        raise IndexError\n      x, y = [], []\n      for b in range(self.batch_size):\n        if self.index_helper < self.le:\n          x.append(tf.expand_dims(self.mel_list[self.index_helper][0],0))\n          y.append(tf.squeeze(self.mel_list[self.index_helper][1]))\n          self.index_helper += 1\n          \n      return np.array(x).astype('float32'), np.array(y).astype('float32')\n\n    def reset(self):\n      self.index_helper = 0\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:58:38.860538Z","iopub.execute_input":"2022-04-22T12:58:38.861262Z","iopub.status.idle":"2022-04-22T12:58:38.872829Z","shell.execute_reply.started":"2022-04-22T12:58:38.861219Z","shell.execute_reply":"2022-04-22T12:58:38.871824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random.seed(2022)\nrandom.shuffle(train_data)  # shuffle it randomly\n\ntraining_data = train_data[:int(0.9*len(train_data))]\nval_data = train_data[int(0.9*len(train_data)):]\n\nbatch_size = 32\n\n\ntrain_set = TensorflowDataGenerator(training_data,batch_size)\n\n\nval_set = TensorflowDataGenerator(val_data,batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:58:38.873919Z","iopub.execute_input":"2022-04-22T12:58:38.874113Z","iopub.status.idle":"2022-04-22T12:58:38.90405Z","shell.execute_reply.started":"2022-04-22T12:58:38.874089Z","shell.execute_reply":"2022-04-22T12:58:38.903188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.layers import Input, Conv1D, BatchNormalization, Dense, Dropout\nfrom tensorflow.keras.layers import AvgPool1D, GlobalAveragePooling1D, MaxPool1D, Conv1DTranspose\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import ReLU, concatenate\nimport tensorflow.keras.backend as K\n# Creating Densenet121\ntf.random.set_seed(2022)\ndef densenet(input_shape, n_classes, filters = 32):   \n    #batch norm + relu + conv\n    def bn_rl_conv(x,filters,kernel=1,strides=1):\n        x = BatchNormalization()(x)\n        x = ReLU()(x)\n        x = Conv1D(filters, kernel, strides=strides,padding = 'same')(x)\n        x = Dropout(0.1)(x)\n        return x\n    \n    def dense_block(x, repetition):\n        \n        for _ in range(repetition):\n            y = bn_rl_conv(x, 4*filters)\n            y = bn_rl_conv(y, filters, 3)\n            x = concatenate([y,x])\n        return x\n        \n    def transition_layer(x):\n        \n        x = bn_rl_conv(x, K.int_shape(x)[-1] //2 )\n        x = AvgPool1D(2, strides = 2, padding = 'same')(x)\n        return x\n    \n    input = Input (input_shape)\n    x = Conv1D(64, 3, strides=1, padding='causal', dilation_rate = 2, activation = 'relu')(input)\n    x = BatchNormalization()(x)\n    x = Conv1D(64, 3, strides=1, padding='causal', dilation_rate = 4, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(64, 3, strides=1, padding='causal', dilation_rate = 8, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1D(64, 7, strides = 2, padding = 'same')(x)\n    x = Conv1DTranspose(32, 3,strides=1, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1DTranspose(64, 3,strides=1, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = Conv1DTranspose(128, 3,strides=1, activation = 'relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool1D(3, strides = 2, padding = 'same')(x)\n    \n    for repetition in [6,12,32,32]:\n        \n        d = dense_block(x, repetition)\n        x = transition_layer(d)\n    x = GlobalAveragePooling1D()(d)\n    x = Dense(2048 , activation = 'relu',kernel_regularizer=tf.keras.regularizers.L1(0.01),\n    activity_regularizer=tf.keras.regularizers.L2(0.01))(x)\n    x = Dropout(0.25)(x)\n    output = Dense(n_classes, activation = 'softmax')(x)\n    model = Model(input, output)\n    return model\ninput_shape = (1, 4096)\nn_classes = 21\nmodel = densenet(input_shape,n_classes)\n# [6,12,32,32]:","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:12.990322Z","iopub.execute_input":"2022-04-22T12:59:12.9906Z","iopub.status.idle":"2022-04-22T12:59:18.445454Z","shell.execute_reply.started":"2022-04-22T12:59:12.990569Z","shell.execute_reply":"2022-04-22T12:59:18.444705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# learning_rate=1e-4 Adadelta\noptimizer = tf.keras.optimizers.SGD(learning_rate=1e-3)\nepoches = 9\nloss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\ntrain_acc = tf.keras.metrics.Mean()\ntrain_loss = tf.keras.metrics.Mean()\nval_acc = tf.keras.metrics.Mean()\nval_loss = tf.keras.metrics.Mean()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:19.186615Z","iopub.execute_input":"2022-04-22T12:59:19.186956Z","iopub.status.idle":"2022-04-22T12:59:19.209395Z","shell.execute_reply.started":"2022-04-22T12:59:19.186923Z","shell.execute_reply":"2022-04-22T12:59:19.208751Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef train_step(x_batch, y_batch):\n  with tf.GradientTape() as tape:\n    logits = model(x_batch, training=True)\n    loss_value = loss_fn(y_batch, logits)\n    grads = tape.gradient(loss_value, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n\n    acc_value = tf.math.equal(y_batch, tf.cast(tf.math.argmax(logits, 1),dtype=tf.float32))\n    train_acc.update_state(acc_value)\n    train_loss.update_state(loss_value)\n    \ndef val_step(x_batch_val, y_batch_val):\n\n  val_logits = model(x_batch_val, training=False)\n  loss_value = loss_fn(y_batch_val,val_logits) # check input and ground truth shape \n\n  acc_value = tf.math.equal(y_batch_val, tf.cast(tf.math.argmax(val_logits, 1),dtype=tf.float32))\n  val_acc.update_state(acc_value)\n  val_loss.update_state(loss_value)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:24.996126Z","iopub.execute_input":"2022-04-22T12:59:24.997102Z","iopub.status.idle":"2022-04-22T12:59:25.00685Z","shell.execute_reply.started":"2022-04-22T12:59:24.997043Z","shell.execute_reply":"2022-04-22T12:59:25.00596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epoches):\n  if epoch == 2:\n    optimizer.lr.assign(1e-6)\n  elif epoch == 3:\n    optimizer.lr.assign(1e-5)\n  elif epoch == 5:\n    optimizer.lr.assign(1e-6)\n  start_time = time.time()\n  train_set.reset()\n  val_set.reset()\n  for x_batch, y_batch in tqdm(train_set):\n    train_step(x_batch, y_batch)\n    \n  for x_batch_val, y_batch_val in tqdm(val_set):\n    val_step(x_batch_val, y_batch_val)\n  end_time = time.time()\n  print(f'Epoch: {epoch} \\tTraining Loss: {train_loss.result()} \\tValidation Loss: {val_loss.result()} \\tTraining Accuracy: {train_acc.result()} \\tValidation Accuracy: {val_acc.result()} \\tTime taken: {end_time - start_time}')\n\n    \n  train_acc.reset_states()\n  train_loss.reset_states()\n  val_acc.reset_states()\n  val_loss.reset_states()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:27.18701Z","iopub.execute_input":"2022-04-22T12:59:27.187289Z","iopub.status.idle":"2022-04-22T13:11:55.124579Z","shell.execute_reply.started":"2022-04-22T12:59:27.18725Z","shell.execute_reply":"2022-04-22T13:11:55.123628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"@tf.function\ndef test_step(x_batch_val):\n  val_logits = model(x_batch_val, training=False)\n  return tf.math.argmax(val_logits,1)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.215465Z","iopub.status.idle":"2022-04-22T12:59:07.215785Z","shell.execute_reply.started":"2022-04-22T12:59:07.215612Z","shell.execute_reply":"2022-04-22T12:59:07.215629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = '../input/birdclef-2022/test_soundscapes/'\ntest_files = os.listdir(test_path)\ndef preprocessing_test_dat(test_path, files):\n  le = 160000\n  step = int((le/2))\n  sample_rate = 32000\n  test = []\n  for file in tqdm(files):\n    y, sr = librosa.load(test_path + file, sr=sample_rate)\n    # y = y[:le + 1]\n    for segment in range(0, len(y), sample_rate*5):\n        row_id = file[:-4] + '_' + str(int((segment + (sample_rate * 5)) / (sample_rate)))\n        if segment+le > len(y):\n            yi = y[segment:]\n            while len(yi) < le:\n              yi = np.concatenate((yi, yi))\n            yi = yi[:le]\n        else:\n            yi = y[segment:segment+le]\n            \n        stfts = tf.signal.stft(yi, frame_length=le, frame_step=le,\n                       fft_length=4096)\n        spectrograms = tf.abs(stfts)\n\n        # Warp the linear scale spectrograms into the mel-scale.\n        num_spectrogram_bins = stfts.shape[-1]\n        lower_edge_hertz, upper_edge_hertz, num_mel_bins = 1000.0, 8000.0, 4096\n\n        linear_to_mel_weight_matrix = tf.signal.linear_to_mel_weight_matrix(\n        num_mel_bins, num_spectrogram_bins, sample_rate, lower_edge_hertz,\n        upper_edge_hertz)\n      \n        mel_spectrograms = tf.tensordot(spectrograms, linear_to_mel_weight_matrix, 1)\n        mel_spectrograms.set_shape(spectrograms.shape[:-1].concatenate(\n          linear_to_mel_weight_matrix.shape[-1:]))\n\n        # Compute a stabilized log to get log-magnitude mel-scale spectrograms.\n        log_mel_spectrograms = tf.math.log(mel_spectrograms + 1e-6)\n  \n        mfccs = tf.signal.mfccs_from_log_mel_spectrograms(log_mel_spectrograms)\n        test.append((row_id, mfccs))\n  return test","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.218808Z","iopub.status.idle":"2022-04-22T12:59:07.219117Z","shell.execute_reply.started":"2022-04-22T12:59:07.218961Z","shell.execute_reply":"2022-04-22T12:59:07.218978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TensorflowDataGenerator_test():\n    'Characterizes a dataset for Tensorflow'\n    def __init__(self, mel_list, batch_size):\n      self.mel_list = mel_list\n      self.batch_size = batch_size\n      self.index_helper = 0\n      self.le = len(mel_list)\n    def __len__(self):\n        return math.ceil(self.le/ self.batch_size)\n\n    def __getitem__(self, index):\n      if self.index_helper >= self.le:\n        raise IndexError\n      x, y = [], []\n      for b in range(self.batch_size):\n        if self.index_helper < self.le:\n          x.append(self.mel_list[self.index_helper][0])\n          y.append(self.mel_list[self.index_helper][1])\n          self.index_helper += 1\n          \n      return x, np.array(y).astype('float32')\n\n    def reset(self):\n      self.index_helper = 0\n        ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.22058Z","iopub.status.idle":"2022-04-22T12:59:07.220919Z","shell.execute_reply.started":"2022-04-22T12:59:07.220744Z","shell.execute_reply":"2022-04-22T12:59:07.22076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dat = preprocessing_test_dat(test_path, test_files)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.222026Z","iopub.status.idle":"2022-04-22T12:59:07.222317Z","shell.execute_reply.started":"2022-04-22T12:59:07.222164Z","shell.execute_reply":"2022-04-22T12:59:07.22218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\n\ntest_set = TensorflowDataGenerator_test(test_dat,batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.223218Z","iopub.status.idle":"2022-04-22T12:59:07.223509Z","shell.execute_reply.started":"2022-04-22T12:59:07.223354Z","shell.execute_reply":"2022-04-22T12:59:07.223369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = []\ntest_set.reset()\nfor x_batch, y_batch in tqdm(test_set):\n    preds = test_step(y_batch)\n    for idx, pred in enumerate(preds):\n        split_code = x_batch[idx].split('_')\n        for bird in bird_label:\n            row_id = split_code[0] +'_'+ split_code[1]+'_' + bird+'_'+split_code[2]\n            predictions.append([row_id, True if bird == bird_label[pred] else False])","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.224483Z","iopub.status.idle":"2022-04-22T12:59:07.224845Z","shell.execute_reply.started":"2022-04-22T12:59:07.224632Z","shell.execute_reply":"2022-04-22T12:59:07.224648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame(predictions,columns=['row_id', 'target'])\nsub_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.225823Z","iopub.status.idle":"2022-04-22T12:59:07.226129Z","shell.execute_reply.started":"2022-04-22T12:59:07.225972Z","shell.execute_reply":"2022-04-22T12:59:07.225988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T12:59:07.226988Z","iopub.status.idle":"2022-04-22T12:59:07.227274Z","shell.execute_reply.started":"2022-04-22T12:59:07.227123Z","shell.execute_reply":"2022-04-22T12:59:07.227138Z"},"trusted":true},"execution_count":null,"outputs":[]}]}