{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport warnings\nimport shutil\nwarnings.filterwarnings(action='ignore')\nimport argparse\nimport math\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport numpy as np\nimport seaborn as sns; sns.set(style='whitegrid')\nimport matplotlib.pyplot as plt\n\nfrom sklearn.utils import shuffle\nfrom PIL import Image\nfrom tqdm import tqdm,tnrange,tqdm_notebook\nimport tensorflow as tf\nfrom tqdm.keras import TqdmCallback\nfrom keras.callbacks import ReduceLROnPlateau,EarlyStopping,ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras import applications as app\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten,AveragePooling2D\nfrom tensorflow.keras.layers import Dense,BatchNormalization,Dropout\nfrom tensorflow.keras.models import Sequential \nimport pickle\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.layers import GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.metrics import classification_report\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:40:36.804035Z","iopub.execute_input":"2022-04-09T11:40:36.804494Z","iopub.status.idle":"2022-04-09T11:40:44.075768Z","shell.execute_reply.started":"2022-04-09T11:40:36.804398Z","shell.execute_reply":"2022-04-09T11:40:44.074651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Global vars\nRANDOM_SEED = 1337\nSAMPLE_RATE = 32000\nSIGNAL_LENGTH = 5 # seconds\nSPEC_SHAPE = (224, 224) # height x width\nFMIN = 500\nFMAX = 12500\n# MAX_AUDIO_FILES = 10000\nEPOCHS=10","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:07:47.930146Z","iopub.execute_input":"2022-04-09T12:07:47.930494Z","iopub.status.idle":"2022-04-09T12:07:47.937231Z","shell.execute_reply.started":"2022-04-09T12:07:47.930438Z","shell.execute_reply":"2022-04-09T12:07:47.936091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load metadata file\ntrain = pd.read_csv('../input/birdclef-2022/train_metadata.csv',)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-09T13:03:26.979685Z","iopub.execute_input":"2022-04-09T13:03:26.980534Z","iopub.status.idle":"2022-04-09T13:03:27.049253Z","shell.execute_reply.started":"2022-04-09T13:03:26.980489Z","shell.execute_reply":"2022-04-09T13:03:27.048515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"EDA","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(24, 8))\nsns.countplot(data= train, x='primary_label', ax=ax, order= train['primary_label'].value_counts().index)\nplt.xticks(rotation=90);","metadata":{"execution":{"iopub.status.busy":"2022-04-09T13:03:37.06424Z","iopub.execute_input":"2022-04-09T13:03:37.064522Z","iopub.status.idle":"2022-04-09T13:03:41.181676Z","shell.execute_reply.started":"2022-04-09T13:03:37.064491Z","shell.execute_reply":"2022-04-09T13:03:41.180991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.primary_label.unique()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T13:03:53.699969Z","iopub.execute_input":"2022-04-09T13:03:53.700229Z","iopub.status.idle":"2022-04-09T13:03:53.708577Z","shell.execute_reply.started":"2022-04-09T13:03:53.700199Z","shell.execute_reply":"2022-04-09T13:03:53.707793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"avg_ratings = train.groupby(\"primary_label\").agg({\"rating\" : \"mean\"})\nplt.figure(figsize = (20, 6))\nsns.barplot(avg_ratings.index, avg_ratings.rating)\nplt.title(\"Average ratings on specific bird codes\")\nplt.xlabel(\"Bird Codes\")\nplt.ylabel(\"Rating\")\nplt.xticks(rotation = 90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T13:05:49.745901Z","iopub.execute_input":"2022-04-09T13:05:49.746214Z","iopub.status.idle":"2022-04-09T13:05:53.194015Z","shell.execute_reply.started":"2022-04-09T13:05:49.746181Z","shell.execute_reply":"2022-04-09T13:05:53.193326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_feature_dist = train.primary_label.value_counts()\nplt.figure(figsize = (8, 8))\nplt.pie(target_feature_dist.values, labels= target_feature_dist.index)\nplt.title(\"Target Feature Distribution\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T13:06:16.760717Z","iopub.execute_input":"2022-04-09T13:06:16.761157Z","iopub.status.idle":"2022-04-09T13:06:18.56306Z","shell.execute_reply.started":"2022-04-09T13:06:16.761118Z","shell.execute_reply":"2022-04-09T13:06:18.562186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Limit the number of training samples and classes\n# First, only use high quality samples\ntrain = train.query('rating>=4')\n\n# Second, assume that birds with the most training samples are also the most common\n# A species needs at least 200 recordings with a rating above 4 to be considered common\nbirds_count = {}\nfor bird_species, count in zip(train.primary_label.unique(), \n                               train.groupby('primary_label')['primary_label'].count().values):\n    birds_count[bird_species] = count\nmost_represented_birds = [key for key,value in birds_count.items() if value >= 175] \n\nTRAIN = train.query('primary_label in @most_represented_birds')\nLABELS = sorted(TRAIN.primary_label.unique())\n\n# Let's see how many species and samples we have left\nprint('NUMBER OF SPECIES IN TRAIN DATA:', len(LABELS))\nprint('NUMBER OF SAMPLES IN TRAIN DATA:', len(TRAIN))\nprint('LABELS:', most_represented_birds)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:40:44.091071Z","iopub.execute_input":"2022-04-09T11:40:44.091361Z","iopub.status.idle":"2022-04-09T11:40:44.231083Z","shell.execute_reply.started":"2022-04-09T11:40:44.091322Z","shell.execute_reply":"2022-04-09T11:40:44.229948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# saving labels \nwith open('LABELS.pkl','wb') as f:\n    pickle.dump(LABELS,f)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:40:44.23345Z","iopub.execute_input":"2022-04-09T11:40:44.233757Z","iopub.status.idle":"2022-04-09T11:40:44.239878Z","shell.execute_reply.started":"2022-04-09T11:40:44.233711Z","shell.execute_reply":"2022-04-09T11:40:44.239112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Shuffle the training data and limit the number of audio files to MAX_AUDIO_FILES\nTRAIN = shuffle(TRAIN, random_state=RANDOM_SEED)\n\n# Define a function that splits an audio file, \n# extracts spectrograms and saves them in a working directory\ndef get_spectrograms(filepath, primary_label, output_dir):\n    \n    # Open the file with librosa (limited to the first 15 seconds)\n    sig, rate = librosa.load(filepath, sr=SAMPLE_RATE, offset=None, duration=15)\n    \n    # Split signal into five second chunks\n    sig_splits = []\n    for i in range(0, len(sig), int(SIGNAL_LENGTH * SAMPLE_RATE)):\n        split = sig[i:i + int(SIGNAL_LENGTH * SAMPLE_RATE)]\n\n        # End of signal?\n        if len(split) < int(SIGNAL_LENGTH * SAMPLE_RATE):\n            break\n        \n        sig_splits.append(split)\n        \n    # Extract mel spectrograms for each audio chunk\n    s_cnt = 0\n    saved_samples = []\n    for chunk in sig_splits:\n        \n        hop_length = int(SIGNAL_LENGTH * SAMPLE_RATE / (SPEC_SHAPE[1] - 1))\n        mel_spec = librosa.feature.melspectrogram(y=chunk, \n                                                  sr=SAMPLE_RATE, \n                                                  n_fft=1024, \n                                                  hop_length=hop_length, \n                                                  n_mels=SPEC_SHAPE[0], \n                                                  fmin=FMIN, \n                                                  fmax=FMAX)\n    \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n        \n        # Normalize\n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        # Save as image file\n        save_dir = os.path.join(output_dir, primary_label)\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        save_path = os.path.join(save_dir, filepath.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0] + \n                                 '_' + str(s_cnt) + '.png')\n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\")\n        im.save(save_path)\n        \n        saved_samples.append(save_path)\n        s_cnt += 1\n        \n        \n    return saved_samples\n\nprint('FINAL NUMBER OF AUDIO FILES IN TRAINING DATA:', len(TRAIN))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:40:44.242184Z","iopub.execute_input":"2022-04-09T11:40:44.242881Z","iopub.status.idle":"2022-04-09T11:40:44.261108Z","shell.execute_reply.started":"2022-04-09T11:40:44.242799Z","shell.execute_reply":"2022-04-09T11:40:44.260146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Parse audio files and extract training samples\ninput_dir = '../input/birdclef-2022/train_audio'\noutput_dir = '../working/melspectrogram_dataset/'\nsamples = []\nwith tqdm(total=len(TRAIN)) as pbar:\n    for idx, row in TRAIN.iterrows():\n        pbar.update(1)\n        \n        if row.primary_label in most_represented_birds:\n            audio_file_path = os.path.join(input_dir, row.filename)\n            samples += get_spectrograms(audio_file_path, row.primary_label, output_dir)\n            \nTRAIN_SPECS = shuffle(samples, random_state=RANDOM_SEED)\nprint('SUCCESSFULLY EXTRACTED {} SPECTROGRAMS'.format(len(TRAIN_SPECS)))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:40:44.262386Z","iopub.execute_input":"2022-04-09T11:40:44.262779Z","iopub.status.idle":"2022-04-09T11:47:42.40926Z","shell.execute_reply.started":"2022-04-09T11:40:44.26273Z","shell.execute_reply":"2022-04-09T11:47:42.408521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:47:42.413898Z","iopub.execute_input":"2022-04-09T11:47:42.414337Z","iopub.status.idle":"2022-04-09T11:47:42.429437Z","shell.execute_reply.started":"2022-04-09T11:47:42.414294Z","shell.execute_reply":"2022-04-09T11:47:42.428314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_folder = './melspectrogram_dataset'\n# valid_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\",\n    preprocessing_function=preprocess_input,\n    validation_split=0.2)\n\ntrain_generator = datagen.flow_from_directory(train_folder, \n#                         target_size=(coefs.sshape[0],coefs.sshape[1]),  # target size\n                        target_size=(224,224),\n                        batch_size=64, \n                        seed=2022,\n                        shuffle=True,\n                        subset = \"training\",\n                        class_mode='categorical')    # batch size\nvalidation_generator = datagen.flow_from_directory(train_folder, \n#                         target_size=(coefs.sshape[0],coefs.sshape[1]),  # target size\n                        target_size=(224,224),\n                        batch_size=64,\n                        seed=2022,\n                        shuffle=True,\n                        subset = \"validation\",\n                        class_mode='categorical')    # batch size","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:47:42.434835Z","iopub.execute_input":"2022-04-09T11:47:42.436747Z","iopub.status.idle":"2022-04-09T11:47:43.077638Z","shell.execute_reply.started":"2022-04-09T11:47:42.436696Z","shell.execute_reply":"2022-04-09T11:47:43.076959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimg = cv2.imread('./melspectrogram_dataset/brnowl/XC635289_2.png')\n\nimg.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:47:43.078979Z","iopub.execute_input":"2022-04-09T11:47:43.079225Z","iopub.status.idle":"2022-04-09T11:47:43.406045Z","shell.execute_reply.started":"2022-04-09T11:47:43.079191Z","shell.execute_reply":"2022-04-09T11:47:43.405372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LEARNING_RATE = 0.001\nnum_epochs = 10\nBATCH_SIZE = 64\nIMG_SIZE = 224","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:07:58.295173Z","iopub.execute_input":"2022-04-09T12:07:58.295751Z","iopub.status.idle":"2022-04-09T12:07:58.299202Z","shell.execute_reply.started":"2022-04-09T12:07:58.295709Z","shell.execute_reply":"2022-04-09T12:07:58.298529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Flatten, Dropout, Activation, LSTM, SimpleRNN, Conv1D, Input, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nfrom keras.utils.vis_utils import model_to_dot\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.applications import ResNet50","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:49:20.5192Z","iopub.execute_input":"2022-04-09T11:49:20.519459Z","iopub.status.idle":"2022-04-09T11:49:20.526178Z","shell.execute_reply.started":"2022-04-09T11:49:20.519428Z","shell.execute_reply":"2022-04-09T11:49:20.525529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CNN","metadata":{}},{"cell_type":"code","source":"def My_CNNmodel():\n\n  model = tf.keras.models.Sequential()\n  model.add(layers.Conv2D(8, (3, 3), padding='same',activation='relu', input_shape=(224,224, 3)))\n  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n  model.add(layers.Conv2D(16, (3, 3), padding='same',activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n  model.add(layers.Conv2D(32, (3, 3), padding='same',activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n  model.add(layers.Conv2D(64, (3, 3), padding='same',activation='relu'))\n  model.add(layers.MaxPooling2D(pool_size=(2,2)))\n  model.add(layers.Flatten())\n  model.add(layers.Dense(512, activation='relu'))\n  model.add(layers.Dense(16, activation='sigmoid'))\n\n  opt=tf.keras.optimizers.Adam(0.001)\n  model.compile(optimizer=opt,\n              loss='binary_crossentropy', # loss='categorical_crossentropy' if softmax\n              metrics=['accuracy'])\n\n  return model","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:49:21.959189Z","iopub.execute_input":"2022-04-09T11:49:21.959742Z","iopub.status.idle":"2022-04-09T11:49:21.970646Z","shell.execute_reply.started":"2022-04-09T11:49:21.959685Z","shell.execute_reply":"2022-04-09T11:49:21.969512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=My_CNNmodel()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:49:24.439032Z","iopub.execute_input":"2022-04-09T11:49:24.439294Z","iopub.status.idle":"2022-04-09T11:49:24.510795Z","shell.execute_reply.started":"2022-04-09T11:49:24.439265Z","shell.execute_reply":"2022-04-09T11:49:24.510093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss=\"categorical_crossentropy\", optimizer='adam')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:49:28.7742Z","iopub.execute_input":"2022-04-09T11:49:28.774807Z","iopub.status.idle":"2022-04-09T11:49:28.784821Z","shell.execute_reply.started":"2022-04-09T11:49:28.774756Z","shell.execute_reply":"2022-04-09T11:49:28.783992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_generator,\n          epochs = 5, \n          validation_data=validation_generator)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T11:57:45.364495Z","iopub.execute_input":"2022-04-09T11:57:45.365211Z","iopub.status.idle":"2022-04-09T12:07:25.217726Z","shell.execute_reply.started":"2022-04-09T11:57:45.365161Z","shell.execute_reply":"2022-04-09T12:07:25.216994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"H = history\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, len(H.history[\"loss\"])), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, len(H.history[\"val_loss\"])), H.history[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Training Loss\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\")\nplt.legend(loc=\"lower left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:07:27.598939Z","iopub.execute_input":"2022-04-09T12:07:27.599697Z","iopub.status.idle":"2022-04-09T12:07:27.865277Z","shell.execute_reply.started":"2022-04-09T12:07:27.59966Z","shell.execute_reply":"2022-04-09T12:07:27.864611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('bird_model_cnn.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:07:32.43901Z","iopub.execute_input":"2022-04-09T12:07:32.439301Z","iopub.status.idle":"2022-04-09T12:07:32.576593Z","shell.execute_reply.started":"2022-04-09T12:07:32.43927Z","shell.execute_reply":"2022-04-09T12:07:32.575838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Resnet 50","metadata":{}},{"cell_type":"code","source":" \nbase_model = ResNet50(weights='imagenet',include_top=False, input_shape=(224,224,3))\n\n# Construct the head of the model that will be placed on top of the base model\nhead_model = base_model.output\nhead_model = GlobalAveragePooling2D()(head_model)\nhead_model = Flatten(name=\"flatten\")(head_model)\nhead_model = Dense(16, activation=\"softmax\")(head_model)\nmodel = Model(inputs=base_model.input, outputs=head_model)\n\nfor layer in base_model.layers:\n    layer.trainable = True\nmodel.summary()\nmodel.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n\n\nH = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // validation_generator.batch_size,\n    epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:08:29.644828Z","iopub.execute_input":"2022-04-09T12:08:29.645085Z","iopub.status.idle":"2022-04-09T12:31:43.051826Z","shell.execute_reply.started":"2022-04-09T12:08:29.645057Z","shell.execute_reply":"2022-04-09T12:31:43.051097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, len(H.history[\"loss\"])), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, len(H.history[\"val_loss\"])), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, len(H.history[\"accuracy\"])), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, len(H.history[\"val_accuracy\"])), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:32:25.240375Z","iopub.execute_input":"2022-04-09T12:32:25.240936Z","iopub.status.idle":"2022-04-09T12:32:25.484972Z","shell.execute_reply.started":"2022-04-09T12:32:25.240896Z","shell.execute_reply":"2022-04-09T12:32:25.484317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('bird_model_resnet50.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:32:37.699819Z","iopub.execute_input":"2022-04-09T12:32:37.700364Z","iopub.status.idle":"2022-04-09T12:32:38.63212Z","shell.execute_reply.started":"2022-04-09T12:32:37.700327Z","shell.execute_reply":"2022-04-09T12:32:38.63136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"EfficientNetB0","metadata":{}},{"cell_type":"code","source":" \nbase_model = EfficientNetB0(weights='imagenet',include_top=False, input_shape=(224,224,3))\n\n# Construct the head of the model that will be placed on top of the base model\nhead_model = base_model.output\nhead_model = GlobalAveragePooling2D()(head_model)\nhead_model = Flatten(name=\"flatten\")(head_model)\nhead_model = Dense(16, activation=\"softmax\")(head_model)\nmodel = Model(inputs=base_model.input, outputs=head_model)\n\nfor layer in base_model.layers:\n    layer.trainable = True\nmodel.summary()\nmodel.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=[\"accuracy\"])\n\nH = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // validation_generator.batch_size,\n    epochs=num_epochs)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:32:41.705024Z","iopub.execute_input":"2022-04-09T12:32:41.70567Z","iopub.status.idle":"2022-04-09T12:56:09.048673Z","shell.execute_reply.started":"2022-04-09T12:32:41.705631Z","shell.execute_reply":"2022-04-09T12:56:09.04786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, len(H.history[\"loss\"])), H.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, len(H.history[\"val_loss\"])), H.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, len(H.history[\"accuracy\"])), H.history[\"accuracy\"], label=\"train_acc\")\nplt.plot(np.arange(0, len(H.history[\"val_accuracy\"])), H.history[\"val_accuracy\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"lower left\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:23.810584Z","iopub.execute_input":"2022-04-09T12:56:23.811586Z","iopub.status.idle":"2022-04-09T12:56:24.04382Z","shell.execute_reply.started":"2022-04-09T12:56:23.811526Z","shell.execute_reply":"2022-04-09T12:56:24.043163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('bird_model_efficientnetB0.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:32.795354Z","iopub.execute_input":"2022-04-09T12:56:32.795823Z","iopub.status.idle":"2022-04-09T12:56:33.45512Z","shell.execute_reply.started":"2022-04-09T12:56:32.795785Z","shell.execute_reply":"2022-04-09T12:56:33.454364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_audio_dir = '../input/birdclef-2022/test_soundscapes/'\nfile_list = [f.split('.')[0] for f in sorted(os.listdir(test_audio_dir))]\n\nprint('Number of test soundscapes:', len(file_list))","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:35.319674Z","iopub.execute_input":"2022-04-09T12:56:35.320376Z","iopub.status.idle":"2022-04-09T12:56:35.330867Z","shell.execute_reply.started":"2022-04-09T12:56:35.320338Z","shell.execute_reply":"2022-04-09T12:56:35.329963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nwith open('../input/birdclef-2022/scored_birds.json') as sbfile:\n    scored_birds = json.load(sbfile)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:37.394909Z","iopub.execute_input":"2022-04-09T12:56:37.395163Z","iopub.status.idle":"2022-04-09T12:56:37.401738Z","shell.execute_reply.started":"2022-04-09T12:56:37.395133Z","shell.execute_reply":"2022-04-09T12:56:37.400893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(threshold):\n#     row_id = []\n    pred = {'row_id': [], 'target': []}\n    scnt = 0\n    for afile in file_list:\n        # Open it with librosa\n        path = test_audio_dir + afile + '.ogg'\n        sig, rate = librosa.load(path, sr=SAMPLE_RATE)\n        sig_splits = []\n        for i in range(0, len(sig), int(SIGNAL_LENGTH * SAMPLE_RATE)):\n            split = sig[i:i + int(SIGNAL_LENGTH * SAMPLE_RATE)]\n\n            # End of signal?\n            if len(split) < int(SIGNAL_LENGTH * SAMPLE_RATE):\n                break\n\n            sig_splits.append(split)\n\n        seconds= 0\n        for chunk in sig_splits:\n\n            # Keep track of the end time of each chunk\n            seconds += 5\n\n            # Get the spectrogram\n            hop_length = int(SIGNAL_LENGTH * SAMPLE_RATE / (SPEC_SHAPE[1] - 1))\n            mel_spec = librosa.feature.melspectrogram(y=chunk, \n                                                      sr=SAMPLE_RATE, \n                                                      n_fft=1024, \n                                                      hop_length=hop_length, \n                                                      n_mels=SPEC_SHAPE[0], \n                                                      fmin=FMIN, \n                                                      fmax=FMAX)\n\n            mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n\n            # Normalize to match the value range we used during training.\n            # That's something you should always double check!\n            mel_spec -= mel_spec.min()\n            mel_spec /= mel_spec.max()\n\n            # Add channel axis to 2D array\n            mel_spec = np.expand_dims(mel_spec, -1)\n\n            # Add new dimension for batch size\n            mel_spec = np.expand_dims(mel_spec, 0)\n\n            # Predict\n            p = 0.5*model.predict(mel_spec)[0] \n\n            # Get highest scoring species\n            idx = p.argmax()\n            species = LABELS[idx]\n            score = p[idx]\n            chunks = [[] for i in range(12)]\n            for idx,i in enumerate(range(len(chunks))):        \n                for bird in scored_birds:\n                    chunk_end_time = (i + 1) * 5\n                # Prepare submission entry\n                    row_id = afile + '_' + bird + '_' + str(chunk_end_time)\n#                     row_id.append(afile.split(os.sep)[-1].rsplit('_', 1)[0] + \n#                                   '_' + str(seconds))  \n                    # Decide if it's a \"nocall\" or a species by applying a threshold\n#                     pred['row_id'].append(row_id)\n#                     pred['target'].append(True if score > threshold else False)\n            \n                    pred['row_id'].append(row_id)\n                    pred['target'].append(True if score > threshold else False)\n                       \n\n    result = pd.DataFrame(pred, columns = ['row_id', 'target'])\n    return result","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:38.601802Z","iopub.execute_input":"2022-04-09T12:56:38.602051Z","iopub.status.idle":"2022-04-09T12:56:38.61494Z","shell.execute_reply.started":"2022-04-09T12:56:38.602024Z","shell.execute_reply":"2022-04-09T12:56:38.6143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=predict(0.3)\nresult","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:44.735268Z","iopub.execute_input":"2022-04-09T12:56:44.736745Z","iopub.status.idle":"2022-04-09T12:56:47.136482Z","shell.execute_reply.started":"2022-04-09T12:56:44.736695Z","shell.execute_reply":"2022-04-09T12:56:47.13568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result\nresults = result.to_csv('submission_bird.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:50.719769Z","iopub.execute_input":"2022-04-09T12:56:50.720032Z","iopub.status.idle":"2022-04-09T12:56:50.735439Z","shell.execute_reply.started":"2022-04-09T12:56:50.720004Z","shell.execute_reply":"2022-04-09T12:56:50.734776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.read_csv('./submission_bird.csv')\nresults","metadata":{"execution":{"iopub.status.busy":"2022-04-09T12:56:52.31976Z","iopub.execute_input":"2022-04-09T12:56:52.320318Z","iopub.status.idle":"2022-04-09T12:56:52.336758Z","shell.execute_reply.started":"2022-04-09T12:56:52.320281Z","shell.execute_reply":"2022-04-09T12:56:52.336118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}