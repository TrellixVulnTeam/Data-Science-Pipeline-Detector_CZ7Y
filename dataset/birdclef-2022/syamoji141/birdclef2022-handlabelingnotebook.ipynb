{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import random\nimport numpy as np\nimport random,os\nimport torch\nimport pandas as pd\nfrom pathlib import Path\nimport librosa\nfrom matplotlib import pyplot as plt\nimport IPython\n\nfrom PIL import Image\nimport ipywidgets as widgets\nfrom ipywidgets import Layout\nfrom matplotlib import pyplot as plt\n\nfrom glob import glob\nfrom IPython.display import display\n\n#Deep learning from pytorch\nimport torch\nimport torchvision\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.optim as optim\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n!pip install timm\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-24T06:05:52.332518Z","iopub.execute_input":"2022-05-24T06:05:52.333249Z","iopub.status.idle":"2022-05-24T06:06:03.015801Z","shell.execute_reply.started":"2022-05-24T06:05:52.333199Z","shell.execute_reply":"2022-05-24T06:06:03.014531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\njson_open = open('/kaggle/input/birdclef-2022/scored_birds.json', 'r')\nbird_target = json.load(json_open)\nbird_target","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:03.019837Z","iopub.execute_input":"2022-05-24T06:06:03.020244Z","iopub.status.idle":"2022-05-24T06:06:03.030582Z","shell.execute_reply.started":"2022-05-24T06:06:03.020187Z","shell.execute_reply":"2022-05-24T06:06:03.029773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self,name,pretrained=False):\n        super(Model, self).__init__()\n        self.model = timm.create_model(name,pretrained=pretrained, in_chans=1)\n        self.model.reset_classifier(num_classes=0) \n        in_features = self.model.num_features\n        self.fc = nn.Linear(in_features, 21)\n\n    def forward(self, x):\n        x = self.model(x)\n        x = self.fc(x)\n        return x\n    \npaths = [\n    \"../input/bridclef2022dataset/eca_nfnet_l0_p7CV0.881.bin\",\n    \"../input/bridclef2022dataset/resnest50d_CV0.852.bin\",\n    \"../input/bridclef2022dataset/convnext_tiny_CV0.83.bin\",\n]\n\nnames = [\n    \"eca_nfnet_l0\",\n    \"resnest50d\",\n    \"convnext_tiny\",\n]\n    \nmodels = []\nfor path, name in zip(paths, names):\n    model = Model(name=name)#.to(device)\n    model.load_state_dict(torch.load(path,map_location=torch.device('cpu')))\n    model.eval()\n    models.append(model)","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:03.032313Z","iopub.execute_input":"2022-05-24T06:06:03.032631Z","iopub.status.idle":"2022-05-24T06:06:04.733835Z","shell.execute_reply.started":"2022-05-24T06:06:03.03259Z","shell.execute_reply":"2022-05-24T06:06:04.732936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/fulllabeldataset/train.csv\",index_col=0)\ntrain = train[train.num != 0]\ntrain = train[train.primary_label.isin(bird_target)]\ntrain[\"filepath\"] = \"../input/fulllabeldataset/image_128/\" + train[\"path\"]\ntrain[\"sort_index\"] = train.filename_id.apply(lambda x: int(x.split(\"_\")[-1])//5)\ntrain[\"file_id\"] = train.filename_id.apply(lambda x: x.split(\"_\")[0])\ntrain['secondary_labels_array'] =  train.secondary_labels.apply(eval)\ntrain[\"sleng\"] = train.secondary_labels_array.apply(lambda x: len(x))\nunique_key = sorted(bird_target)\nLABEL_IDS = {label: label_id for label_id, label in enumerate(unique_key)}\nINV_LABEL_IDS = {val: key for key,val in LABEL_IDS.items()}\nprint(LABEL_IDS)\ntrain[\"label_id\"] = train[\"primary_label\"].map(LABEL_IDS)\n\ndf_label = train[train.sleng > 0]\ndf_label['labels_id'] = df_label.secondary_labels_array.apply(lambda x: np.vectorize(lambda s: LABEL_IDS[s] if s in unique_key else -1)(x))\ndf_label.labels_id = df_label.labels_id.apply(lambda x: x[x != -1])\ndf_label.labels_id = df_label.apply(lambda x: x.labels_id[x.labels_id != x.label_id],axis=1)\ndf_label['num'] = df_label.labels_id.apply(lambda x: len(x))\ndf_label = df_label[df_label.num != 0]\ndf_label[\"sec1\"] = df_label.labels_id.apply(lambda x: x[0])\ndf_label[\"sec2\"] = df_label.labels_id.apply(lambda x: x[1] if len(x) > 1 else 0)\ndf_label[\"sec3\"] = df_label.labels_id.apply(lambda x: x[2] if len(x) > 2 else 0)\ndf_label[\"sec4\"] = df_label.labels_id.apply(lambda x: x[3] if len(x) > 3 else 0)\ndf_label[\"sec5\"] = df_label.labels_id.apply(lambda x: x[4] if len(x) > 4 else 0)\ndf_label[\"sec6\"] = df_label.labels_id.apply(lambda x: x[5] if len(x) > 5 else 0)\n\n\n\ndf_label[\"label_array\"] = 0\ndf_label.loc[df_label.num == 0, \"label_array\"] = df_label.label_id.apply(lambda x: np.array([x]))\ndf_label.loc[df_label.num != 0, \"label_array\"] = df_label.loc[df_label.num != 0 ,[\"labels_id\",\"label_id\"]].apply(lambda x: np.append(x.labels_id,x.label_id),axis=1)\ntrain = pd.concat([df_label]).sort_values([\"file_id\",\"sort_index\"]).reset_index(drop=True)\n\npathdf = pd.DataFrame(glob(\"../input/birdclef-2022/train_audio/**/*.ogg\"),columns=[\"audio_path\"])\npathdf[\"file_id\"] = pathdf.audio_path.apply(lambda x: x.split(\"/\")[-1].replace(\".ogg\",\"\"))\ntrain = pd.merge(train,pathdf,on=[\"file_id\"])\ntrain","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:04.736583Z","iopub.execute_input":"2022-05-24T06:06:04.737Z","iopub.status.idle":"2022-05-24T06:06:05.371436Z","shell.execute_reply.started":"2022-05-24T06:06:04.736952Z","shell.execute_reply":"2022-05-24T06:06:05.370545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reflect previous results\n!cp ../input/handlabelingnotebook/results.txt /kaggle/working/results.txt","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:05.372826Z","iopub.execute_input":"2022-05-24T06:06:05.373955Z","iopub.status.idle":"2022-05-24T06:06:06.143185Z","shell.execute_reply.started":"2022-05-24T06:06:05.373902Z","shell.execute_reply":"2022-05-24T06:06:06.142249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = train[(train.num == 3)]#&(train.sleng >= 2)\n# train = train[~train.primary_label.isin([\"houfin\",\"skylar\"])]\nprint(len(train))\n\n\n#train = train[~train.primary_label.isin([\"skylar\",\"houfin\",])]","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:06.1451Z","iopub.execute_input":"2022-05-24T06:06:06.145601Z","iopub.status.idle":"2022-05-24T06:06:06.150932Z","shell.execute_reply.started":"2022-05-24T06:06:06.145562Z","shell.execute_reply":"2022-05-24T06:06:06.150088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.primary_label.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:06.152338Z","iopub.execute_input":"2022-05-24T06:06:06.15324Z","iopub.status.idle":"2022-05-24T06:06:06.166378Z","shell.execute_reply.started":"2022-05-24T06:06:06.153189Z","shell.execute_reply":"2022-05-24T06:06:06.165199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AnnotationOnJupyter:\n    def __init__(self, df, labels=np.append(bird_target,\"nocall\")) -> None:\n\n        self.df = df\n        self.labels = labels\n        self.prev_img_id = \"\"\n\n        self.output = widgets.Output()\n        self.ax = plt.gca()\n        \n        self.iter = 0\n        self.display = None\n\n        btns = []\n        for label in labels:\n            btn = widgets.Button(description=label)\n            btn.on_click(self.on_click)\n            btns.append(btn)\n        self.btns = btns\n\n    def start(self):\n        \n        box_layout = Layout(display='flex',\n                    flex_flow='row',\n                    align_items='stretch',\n                    width='500pt'\n        )\n        box_layout2 = Layout(display='flex',\n                    flex_flow='row',\n                    align_items='stretch',\n                    width='700pt'\n        )\n        box1 = widgets.Box(self.btns[0:5], layout=box_layout)\n        box2 = widgets.Box(self.btns[5:10], layout=box_layout)\n        box3 = widgets.Box(self.btns[10:15], layout=box_layout)\n        box4 = widgets.Box(self.btns[15:], layout=box_layout2)\n        box = widgets.VBox([box1, box2, box3, box4])\n        \n        #display(*self.btns, self.output)\n        display(box, self.output)\n        \n        plt.close()\n\n        blank_btn = widgets.Button(description=\"blank\")\n        blank_btn.on_click(lambda x: self.on_click(x))\n        blank_btn.click()\n\n    def on_click(self, b: widgets.Button) -> None:\n        row = self.df.iloc[self.iter]\n        if self.prev_img_id != \"\":\n            with open(\"./results_sec3_3.txt\", \"a\") as f:\n                f.write(f\"{self.prev_img_id},{b.description}\\n\")\n\n        self.ax.clear()\n        \n        img_path = row.filepath\n        self.prev_img_id = row.filename_id\n        img = np.load(img_path)\n        image = torch.tensor(img.astype(\"float32\", copy=False) / 255.0)[None,None,:,:]\n        for idx,model in enumerate(models):\n            pred = model(image)\n            if idx==0:\n                preds = pred.sigmoid().detach().cpu().numpy()\n            else:\n                preds += pred.sigmoid().detach().cpu().numpy()\n            \n        preds = preds/len(models)\n        preds = np.array([round(pred,2) for pred in preds[0]])\n        self.ax.set_title(f\"{self.prev_img_id}_{row.primary_label}_targetlabel:{bird_target[row.sec1]}_seclabel:{row.secondary_labels}_secprob:{preds[row.label_array]}\")\n        self.ax.imshow(img)\n        \n        \n        y, sr = librosa.load(row.audio_path, offset=int(row[\"sort_index\"]*5), duration=20)\n        \n\n        with self.output:\n            self.output.clear_output(wait=True)\n            display(self.ax.figure)\n            display(IPython.display.Audio(data=y, rate=sr))\n        \n            \n        self.iter += 1","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:06.168378Z","iopub.execute_input":"2022-05-24T06:06:06.168945Z","iopub.status.idle":"2022-05-24T06:06:06.19314Z","shell.execute_reply.started":"2022-05-24T06:06:06.168897Z","shell.execute_reply":"2022-05-24T06:06:06.192194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    annotator = AnnotationOnJupyter(train)\n    annotator.start()","metadata":{"execution":{"iopub.status.busy":"2022-05-24T06:06:06.194341Z","iopub.execute_input":"2022-05-24T06:06:06.194781Z","iopub.status.idle":"2022-05-24T06:06:08.144545Z","shell.execute_reply.started":"2022-05-24T06:06:06.194736Z","shell.execute_reply":"2022-05-24T06:06:08.143728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}