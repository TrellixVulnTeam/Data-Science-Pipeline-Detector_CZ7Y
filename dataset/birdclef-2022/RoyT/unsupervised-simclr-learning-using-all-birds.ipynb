{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#This kernal is based on simCLR unsupervised learning (link below) to learn the birds audio representation,\n#with some adjustments to audio data.\n\nalgorithm blocks:\n1. Get path to data\n2. Algorithm hyperparameter set and bird encoding\n3. Explore audio exmple\n4. Set dataloaders\n5. Define simclr unsupervised model with lstm and transformer backbone\n6. Define unsupervised and supervised training datasets and nets\n7. Unsupervised training loop\n8. Freeze weights for supervised linear NN based on unsupervised embedding \n9. Supervised helper functions\n10. Supervised training loop\n11. Prediction on test set\n12. Submit\n#https://arxiv.org/abs/2002.05709","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:16:29.703913Z","iopub.execute_input":"2022-05-08T19:16:29.704213Z","iopub.status.idle":"2022-05-08T19:16:29.71152Z","shell.execute_reply.started":"2022-05-08T19:16:29.704174Z","shell.execute_reply":"2022-05-08T19:16:29.710088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport random\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport soundfile as sf\nimport math\nimport torchaudio\nfrom torchaudio import transforms\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn import preprocessing\n\nfrom tqdm import tqdm\nfrom collections import defaultdict\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:16:29.721021Z","iopub.execute_input":"2022-05-08T19:16:29.721256Z","iopub.status.idle":"2022-05-08T19:16:29.731554Z","shell.execute_reply.started":"2022-05-08T19:16:29.721226Z","shell.execute_reply":"2022-05-08T19:16:29.730409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 1. Get path to data\nroot_dir = '../input/birdclef-2022'\ntrain_df = pd.read_csv(root_dir + '/train_metadata.csv')\n\n# Load scored birds\nimport json\ntest_audio_dir = '../input/birdclef-2022/test_soundscapes/'\nfile_list = [f.split('.')[0] for f in sorted(os.listdir(test_audio_dir))]\nwith open('../input/birdclef-2022/scored_birds.json') as sbfile:\n    scored_birds = json.load(sbfile)\ntrain_meta = train_df[train_df['primary_label'].isin(scored_birds)]\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:16:29.736475Z","iopub.execute_input":"2022-05-08T19:16:29.736731Z","iopub.status.idle":"2022-05-08T19:16:29.822927Z","shell.execute_reply.started":"2022-05-08T19:16:29.736693Z","shell.execute_reply":"2022-05-08T19:16:29.821963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 2. Algorithm hyperparameter set and bird encoding\nn_epochs_unsuper = 2\nn_epochs_super = 10\ntrain_on_gpu = torch.cuda.is_available()\nle = preprocessing.LabelEncoder().fit(train_df['primary_label'])\nlen(le.classes_)\n\nScored_bird_index = le.transform(scored_birds)\nScored_bird_index_dict = dict(enumerate(Scored_bird_index))\nScored_bird_index_dict_inv = {j:i for i,j in enumerate(Scored_bird_index)}\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:16:29.824849Z","iopub.execute_input":"2022-05-08T19:16:29.825158Z","iopub.status.idle":"2022-05-08T19:16:29.834467Z","shell.execute_reply.started":"2022-05-08T19:16:29.825116Z","shell.execute_reply":"2022-05-08T19:16:29.833354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_df = pd.read_csv('../input/birdclef-2022/test.csv')\n# print(os.listdir('../input/birdclef-2022/test_soundscapes/'))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:16:29.836092Z","iopub.execute_input":"2022-05-08T19:16:29.83668Z","iopub.status.idle":"2022-05-08T19:16:29.847475Z","shell.execute_reply.started":"2022-05-08T19:16:29.836632Z","shell.execute_reply":"2022-05-08T19:16:29.84621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 3. Explore audio exmple\ntrain_audio_dir = '../input/birdclef-2022/train_audio'\nidx = random.randint(0, len(train_df))\nfilename = train_df.loc[idx,'filename']\nsig, sr = torchaudio.load(os.path.join(train_audio_dir, filename),)\naudio_sample = (sig, sr)\nMelSpec = torchaudio.transforms.MelSpectrogram(sample_rate=sr,n_fft=800)(sig[0,:])\nplt.figure(figsize=(12,6))\nmeldata = torch.log(MelSpec-MelSpec.min()+1e-5)\nmeldata = (meldata-meldata.mean())/meldata.std()\nplt.imshow(meldata\n           ,aspect='auto')\nplt.colorbar()\nprint(sig.shape[1]/sr,sr)\nprint(meldata.shape)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:16:29.850415Z","iopub.execute_input":"2022-05-08T19:16:29.851383Z","iopub.status.idle":"2022-05-08T19:16:30.363645Z","shell.execute_reply.started":"2022-05-08T19:16:29.851318Z","shell.execute_reply":"2022-05-08T19:16:30.362581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 4. set dataloaders\n\ndef normRec(Mel_All):\n    Mel_All = Mel_All - Mel_All.min()+ 1e-8\n    Mel_All = torch.log(Mel_All)\n    Mel_All = (Mel_All-Mel_All.mean())/Mel_All.std()\n    return Mel_All\n\nclass Dataset(Dataset):\n    def __init__(self,train_df,le,train_audio_dir,Scored_bird_index_dict_inv,Rec_mel = 500,min_mel_size = 800,zero_rand_low_freq=False):\n        'Initialization'\n        self.train_df = train_df.copy()\n        self.DataPath = train_audio_dir\n        self.MelSpec = torchaudio.transforms.MelSpectrogram(sample_rate=sr,n_fft=800)\n        self.Rec_mel = Rec_mel\n        self.min_mel_size = min_mel_size\n        self.train_audio_dir = train_audio_dir \n        self.le = le\n        self.Scored_bird_index_dict_inv = Scored_bird_index_dict_inv\n        self.zero_rand_low_freq = zero_rand_low_freq\n        \n    def __len__(self):\n        'Denotes the total number of samples'\n        return len(self.train_df)\n\n    \n    def __getitem__(self, index):\n        'Generates one sample of data'\n        filename = self.train_df.loc[index,'filename']\n        \n        lebal_all_birds = self.le.transform([self.train_df.loc[index,'primary_label']])[0]\n        label = torch.zeros(len(self.Scored_bird_index_dict_inv))\n        if lebal_all_birds in self.Scored_bird_index_dict_inv.keys():\n            label[self.Scored_bird_index_dict_inv[lebal_all_birds]] = 1\n            \n        sig, sr = torchaudio.load(os.path.join(self.train_audio_dir, filename),)\n        \n        S = sig.shape[0] # random channel select\n        Mel_All = self.MelSpec(sig[np.random.randint(S),:])\n        #Mel_All = normRec(Mel_All)\n        while Mel_All.shape[1] <self.min_mel_size : #duplicate short signals\n            Mel_All = torch.cat((Mel_All,Mel_All),dim=1)\n        StartRange = Mel_All.shape[1] - self.Rec_mel\n        RecStarts = np.random.randint(0,StartRange,2)\n        Rec1 = Mel_All[:,RecStarts[0]:RecStarts[0]+self.Rec_mel]\n        Rec2 = Mel_All[:,RecStarts[1]:RecStarts[1]+self.Rec_mel]\n        # random zero coefficients\n        if self.zero_rand_low_freq : \n            zero_lines = np.random.randint(0,Rec1.shape[0]//2,2)\n            Rec1[:zero_lines[0],:] = 0\n            Rec2[:zero_lines[1],:] = 0\n            zero_lines = np.random.randint(0,Rec1.shape[0]//2,2)\n            Rec1[-zero_lines[0]:,:] = 0\n            Rec2[-zero_lines[1]:,:] = 0\n        Rec1 = normRec(Rec1)\n        Rec2 = normRec(Rec2)\n        return Rec1,Rec2,label","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:56:24.472073Z","iopub.execute_input":"2022-05-08T19:56:24.472381Z","iopub.status.idle":"2022-05-08T19:56:24.491896Z","shell.execute_reply.started":"2022-05-08T19:56:24.47232Z","shell.execute_reply":"2022-05-08T19:56:24.490599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 5. define simclr unsupervised with lstm and transformer\nclass SimClr_bird(nn.Module):\n    def __init__(self,N_heads,EmbeddingSize =128,dim_ff=2048,N_transormer_L=6,temp = 64,device= 'cuda'):\n        super(SimClr_bird,self).__init__()\n        \n        self.EmbeddingSize = EmbeddingSize\n        self.encoderL = nn.TransformerEncoderLayer(EmbeddingSize,N_heads,dim_feedforward=dim_ff,batch_first=True)\n        self.Transformer = nn.TransformerEncoder(self.encoderL,N_transormer_L)\n        self.lstm = nn.LSTM(EmbeddingSize,EmbeddingSize,2,batch_first=True)\n        self.weight = nn.Parameter(torch.randn(EmbeddingSize, EmbeddingSize))\n        #self.pos_encoder = PositionalEncoding(d_model= 128,500, 0.1)\n        self.Lin = nn.Linear(EmbeddingSize, EmbeddingSize)\n        self.temp = temp\n        self.rezero = nn.Parameter(torch.FloatTensor([0]))\n        self.device = device\n        self.bn = nn.LayerNorm(128)\n        self.bn2 = nn.LayerNorm(128)\n    def Init_hidden(self,bs):\n        h0 = torch.zeros((2,bs,self.EmbeddingSize )).to(self.device)\n        c0 = torch.zeros((2,bs,self.EmbeddingSize )).to(self.device)\n        return h0,c0\n    \n    def forward(self,x1,x2,return_features = False):\n        \n        s = x1.shape[0]\n        x = torch.cat((x1,x2),dim=0)\n        #x_zero = torch.zeros(x.shape[0],1,x.shape[2])\n        #x = torch.cat((x_zero,x),dim=1)\n        #x = self.pos_encoder(x)\n        #x = self.Lin(x)\n        h0,c0 = self.Init_hidden(2*s)\n        x,_ = self.lstm(x,(h0,c0 ))\n        x = self.bn(x)\n        x = x+self.Transformer(x)*self.rezero\n        x = x[:,-1,:]\n        x = self.bn2(x)\n        x1_t = x[:s,:]\n        x2_t = x[s:,:]\n        if return_features:\n            return x1_t,x2_t\n        \n        value = torch.matmul(x2_t, torch.matmul(self.weight, x1_t.transpose(0,1)))\n        #return value/(self.temp)\n        #return value/(self.temp**2)\n        return value\n\n\nclass Pred_head(nn.Module):\n    def __init__(self,N_classes,EmbeddingSize =128,device= 'cuda'):\n        super(Pred_head,self).__init__()\n        self.device = device\n        self.featureBack = SimClr_bird(4,dim_ff=2048,N_transormer_L=4,device=self.device)\n        self.fc = nn.Linear(EmbeddingSize,EmbeddingSize)\n        self.relu = nn.ReLU()\n        self.bn = nn.BatchNorm1d(EmbeddingSize)\n        self.bn2 = nn.BatchNorm1d(EmbeddingSize)\n        self.classier = nn.Linear(EmbeddingSize,N_classes)\n        self.drop = nn.Dropout()\n    def forward(self,x1,x2):\n        \n        x1,x2 = self.featureBack(x1,x2,return_features = True)\n        x1 = self.drop(self.bn(self.relu(x1)))\n        #x1 = self.bn2(self.relu(self.fc(x1)))\n        x1 = self.classier(x1)\n        x2 = self.drop(self.bn(self.relu(x2)))\n        #x2 = self.bn2(self.relu(self.fc(x2)))\n        x2 = self.classier(x2)\n        return x1+x2\n# simclr loss        \ndef Diag_loss(output):\n    #output = torch.exp(output)\n    output = torch.sigmoid(output)\n    Nodiag = output.flatten()[1:].view(output.shape[0]-1,output.shape[0]+1)[:,:-1].reshape(output.shape[0],output.shape[0]-1)\n    diag = output.diag()\n    loss = torch.sum(-torch.log(diag/Nodiag.sum(1)+1e-15) )\n    \n    return   loss   \n        \ndef Cos_loss(out1,out2):\n    output = nn.CosineSimilarity(dim=2)(out1.unsqueeze(1),out2.unsqueeze(0))\n    output = nn.ReLU()(output)\n    Nodiag = output.flatten()[1:].view(output.shape[0]-1,output.shape[0]+1)[:,:-1].reshape(output.shape[0],output.shape[0]-1)\n    diag = output.diag()\n    \n    return torch.sum(-torch.log(diag/Nodiag.sum(1)+1e-15) )   \n                ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:39.329082Z","iopub.execute_input":"2022-05-08T20:00:39.329441Z","iopub.status.idle":"2022-05-08T20:00:39.357752Z","shell.execute_reply.started":"2022-05-08T20:00:39.329402Z","shell.execute_reply":"2022-05-08T20:00:39.356701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 6. define unsupervised and supervised training datasets and nets\ndevice = 'cuda' if train_on_gpu else 'cpu'\nmodel = SimClr_bird(4,dim_ff=2048,N_transormer_L=4,device=device)\nif train_on_gpu:\n    model.cuda()\n#print(model)\n\ncriterion = nn.BCEWithLogitsLoss()\nbatch_size = 48\nbatch_size_super = 48\nparams = {'batch_size': batch_size,'shuffle': True, 'num_workers': 5}\nparams_super = {'batch_size': batch_size_super,'shuffle': True, 'num_workers': 3}\nparams_super_val = {'batch_size': batch_size_super,'shuffle': False, 'num_workers': 3}\n\ntraining_set = Dataset(train_df, le , train_audio_dir,Scored_bird_index_dict_inv,zero_rand_low_freq=True)\ntraining_generator = DataLoader(training_set, **params)\noptimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\n\n\ntrain_df_super,val_df_super = train_test_split(train_meta,test_size=0.2)\ntrain_df_super = train_df_super.reset_index(drop=True)\nval_df_super = val_df_super.reset_index(drop=True)\ntraining_set_super = Dataset(train_df_super, le,train_audio_dir,Scored_bird_index_dict_inv)\ntraining_generator_super = DataLoader(training_set_super, **params_super)\nval_set_super = Dataset(val_df_super, le,train_audio_dir,Scored_bird_index_dict_inv)\nval_generator_super = DataLoader(val_set_super, **params_super_val)\nmodel_P = Pred_head(len(Scored_bird_index_dict_inv))\n\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:39.751159Z","iopub.execute_input":"2022-05-08T20:00:39.751457Z","iopub.status.idle":"2022-05-08T20:00:39.823397Z","shell.execute_reply.started":"2022-05-08T20:00:39.75141Z","shell.execute_reply":"2022-05-08T20:00:39.82241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 7. Unsupervised training loop:\nprint_every = 30\nfor epoch in range(1, n_epochs_unsuper+1):\n\n    # keep track of training and validation loss\n    train_loss = 0.0    \n    model.train()\n\n    #for data1,data2 in tqdm(training_generator):\n    loss_itm = 0\n    for data1,data2,_ in tqdm(training_generator):\n        \n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data1, data2 = data1.cuda(), data2.cuda()\n        # clear the gradients of all optimized variables\n        optimizer.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        #out1,out2 = model(data1.transpose(1,2),data2.transpose(1,2))\n        output = model(data1.transpose(1,2),data2.transpose(1,2))\n        # calculate the batch loss\n        #loss = criterion(output,torch.diag(torch.ones(output.shape[0])))    \n        loss = Diag_loss(output)\n        #loss = Cos_loss(out1,out2)\n        # backward pass: compute gradient of the loss with respect to model parameters\n\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer.step()\n    # update training loss\n        train_loss += loss.item()\n        loss_itm +=1\n        if loss_itm % print_every   == 0 :\n            print(train_loss/loss_itm)\n\n        \n    print('Epoch: {} \\t  Train batch loss: {:.6f} '.format(epoch,train_loss))","metadata":{"execution":{"iopub.status.busy":"2022-05-08T20:00:40.20799Z","iopub.execute_input":"2022-05-08T20:00:40.208264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 8. Freeze weights for supervised linear NN based on unsupervised embedding \nmodel_P = Pred_head(len(Scored_bird_index_dict_inv),device=device)\nmodel_P.featureBack.load_state_dict(model.state_dict())\nfor param in model_P.featureBack.parameters():\n    param.requires_grad = False\n    \n# model_p.fc.weight.requires_grad = True\n# model_p.classifier.weight.requires_grad = True\n# model_p.bn.weight.requires_grad = True\n# model_p.bn2.weight.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.832598Z","iopub.status.idle":"2022-05-08T19:17:15.833923Z","shell.execute_reply.started":"2022-05-08T19:17:15.833558Z","shell.execute_reply":"2022-05-08T19:17:15.833608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#data1,data2,labels = next(iter(training_generator_super))\n#out = model_P(data1.transpose(1,2).cuda(),data2.transpose(1,2).cuda())\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.835354Z","iopub.status.idle":"2022-05-08T19:17:15.836289Z","shell.execute_reply.started":"2022-05-08T19:17:15.836011Z","shell.execute_reply":"2022-05-08T19:17:15.836041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 9. Supervised helper functions\n\ndef BCE_weighted_loss(pred,label,w=3):\n    pred_sig = torch.sigmoid(pred)\n    \n    return -1*torch.sum(torch.log(pred_sig+1e-10)*label*w) - torch.sum( (1-label)*torch.log(1-pred_sig+1e-10) )\n    \n    \ndef get_stats(labels,pred,thr=0):\n    TP = torch.sum((labels ==1)& (pred>thr))\n    FP = torch.sum((labels ==0)& (pred>thr))\n    TN = torch.sum((labels ==0)& (pred<thr))\n    FN = torch.sum((labels ==1)& (pred<thr))\n    \n    return TP,FP,TN,FN\n\ndef Get_pre_rec_f1(TP,FP,TN,FN):\n    precision = TP/(TP+FP)\n    recall = TP/(TP+FN)\n    f1 = (2*precision*recall)/(precision+recall)\n    return precision, recall,f1\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.837875Z","iopub.status.idle":"2022-05-08T19:17:15.838918Z","shell.execute_reply.started":"2022-05-08T19:17:15.838638Z","shell.execute_reply":"2022-05-08T19:17:15.838669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Criterion_Super = torch.nn.CrossEntropyLoss()\noptimizer_super = torch.optim.Adam(params=model_P.parameters(), lr=0.01)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.840586Z","iopub.status.idle":"2022-05-08T19:17:15.841602Z","shell.execute_reply.started":"2022-05-08T19:17:15.841256Z","shell.execute_reply":"2022-05-08T19:17:15.841285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 10. Supervised training loop\nprint_every = 10\nif train_on_gpu:\n    model_P = model_P.cuda()\nfor epoch in range(1, n_epochs_super+1):\n    TP_tr,FP_tr,TN_tr,FN_tr = 0,0,0,0\n    # keep track of training and validation loss\n    train_loss = 0.0    \n    model_P.train()\n    score_pos,score_neg = 0,0\n    #for data1,data2 in tqdm(training_generator):\n    loss_itm = 0\n    for data1,data2,labels in tqdm(training_generator_super):\n        \n        # move tensors to GPU if CUDA is available\n        if train_on_gpu:\n            data1, data2 ,labels = data1.cuda(), data2.cuda(),labels.cuda()\n        # clear the gradients of all optimized variables\n        optimizer_super.zero_grad()\n        # forward pass: compute predicted outputs by passing inputs to the model\n        #out1,out2 = model(data1.transpose(1,2),data2.transpose(1,2))\n        output = model_P(data1.transpose(1,2),data2.transpose(1,2))\n        # calculate the batch loss\n        loss = Criterion_Super(output,torch.argmax(labels,dim=1))    \n        #loss = BCE_weighted_loss(output,labels)\n        train_loss += float(loss)\n        # backward pass: compute gradient of the loss with respect to model parameters\n        TP,FP,TN,FN = get_stats(labels,output)\n        TP_tr,FP_tr,TN_tr,FN_tr = TP_tr+TP,FP_tr+FP,TN_tr+TN,FN_tr+FN\n        loss.backward()\n        # perform a single optimization step (parameter update)\n        optimizer_super.step()\n        loss_itm +=1\n        if loss_itm % print_every   == 0 :\n            print(\"train loss loss: {:.3f}  mean pos score: {:.3f}  mean neg score {:.3f}\".format(train_loss/loss_itm,score_pos/loss_itm,score_neg/loss_itm))\n            print(\"train precision: {:.3f} recall: {:.3f} F1: {:.3f} \".format(TP_tr/(TP_tr+FN_tr),TP_tr/(TP_tr+FP_tr),TP_tr/(TP_tr+0.5*FN_tr+0.5*FP_tr)))\n            loss_itm,train_loss,score_pos,score_neg = 0,0,0,0\n    val_loss ,score_val_pos,score_val_neg,loss_itm = 0,0,0,0\n    model_P.eval()\n    with torch.no_grad():\n        TP_ts,FP_ts,TN_ts,FN_ts = 0,0,0,0\n        for data1,data2,labels in tqdm(val_generator_super):\n            if train_on_gpu:\n                data1, data2 ,labels = data1.cuda(), data2.cuda(),labels.cuda()\n\n            output = model_P(data1.transpose(1,2),data2.transpose(1,2))\n            TP,FP,TN,FN = get_stats(labels,output)\n            TP_ts,FP_ts,TN_ts,FN_ts = TP_ts+TP,FP_ts+FP,TN_ts+TN,FN_ts+FN\n\n            # calculate the batch loss\n            #loss = BCE_weighted_loss(output,labels)\n            loss = Criterion_Super(output,torch.argmax(labels,dim=1))    \n            val_loss += float(loss)\n            score_val_pos += torch.mean(torch.sigmoid(output[labels==1]))\n            score_val_neg += torch.mean(torch.sigmoid(output[labels==0]))\n            loss_itm +=1\n        print(\"test loss: {:.3f}  test pos {:.3f} test neg {:.3f}\".format(val_loss/loss_itm,score_val_pos/loss_itm,score_val_neg/loss_itm))\n        print(\"test precision: {:.3f} recall: {:.3f} F1 {:.3f}: \".format(TP_ts/(TP_ts+FN_ts),TP_ts/(TP_ts+FP_ts),TP_ts/(TP_ts+0.5*FN_ts+0.5*FP_ts)))\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.843259Z","iopub.status.idle":"2022-05-08T19:17:15.844199Z","shell.execute_reply.started":"2022-05-08T19:17:15.843924Z","shell.execute_reply":"2022-05-08T19:17:15.843954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for i in range(20):\n#     data1, data2 ,labels  = next(iter(training_generator_super))\n#     data1, data2 ,labels = data1.cuda(), data2.cuda(),labels.cuda()\n#     output = model_P(data1.transpose(1,2),data2.transpose(1,2))\n#     outputs = torch.sigmoid(output)\n#     print(outputs[labels==1],outputs.mean())\n\n#\n# calculate the batch loss\n#loss = criterion(output,torch.diag(torch.ones(output.shape[0])))    \n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.846023Z","iopub.status.idle":"2022-05-08T19:17:15.846587Z","shell.execute_reply.started":"2022-05-08T19:17:15.846299Z","shell.execute_reply":"2022-05-08T19:17:15.846343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#TP,FP,TN,FN\n# output = model_P(data1.transpose(1,2),data2.transpose(1,2))\n# get_stats(labels,output,0)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.848734Z","iopub.status.idle":"2022-05-08T19:17:15.849256Z","shell.execute_reply.started":"2022-05-08T19:17:15.848968Z","shell.execute_reply":"2022-05-08T19:17:15.848996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 11. Prediction:\npred = {'row_id': [], 'target': []}\nthr_score = 0\nMelSpec = torchaudio.transforms.MelSpectrogram(sample_rate=sr,n_fft=800)\nS = sig.shape[0]\nmodel_P.eval()\n# Process audio files and make predictions\nfor afile in file_list:\n    \n    # Complete file path\n    path = test_audio_dir + afile + '.ogg'\n    \n    # Open file with librosa and split signal into 5-second chunks\n    sig, sr = torchaudio.load(path)\n \n    # Let's assume we have a list of 12 audio chunks (1min / 5s == 12 segments)\n    chunks = [[] for i in range(12)]\n    \n    # Make prediction for each chunk\n    # Each scored bird gets a random value in our case\n    # since we don't actually have a model\n    for i in range(len(chunks)):        \n        chunk_end_time = (i + 1) * 5\n        audio_seg = sig[0,i*5*sr:(i+1)*5*sr]\n        mel_seg = MelSpec(audio_seg.unsqueeze(0))\n        mel_seg = normRec(mel_seg)\n        if train_on_gpu:\n            mel_seg = mel_seg.cuda()\n        output = model_P(mel_seg.transpose(1,2),mel_seg.transpose(1,2))\n\n        for bird in scored_birds:\n            bired_index = Scored_bird_index_dict_inv[le.transform([bird])[0]]\n            # This is our random prediction score for this bird\n            try:\n                score = torch.sigmoid(output[0,bired_index])\n            except IndexError:\n                print(\"some error\")\n                score = -1\n            # Assemble the row_id which we need to do for each scored bird\n            row_id = afile + '_' + bird + '_' + str(chunk_end_time)\n            \n            # Put the result into our prediction dict and\n            # apply a \"confidence\" threshold of 0.5\n            pred['row_id'].append(row_id)\n            pred['target'].append(True if score > thr_score else False)","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.851098Z","iopub.status.idle":"2022-05-08T19:17:15.851657Z","shell.execute_reply.started":"2022-05-08T19:17:15.851319Z","shell.execute_reply":"2022-05-08T19:17:15.851366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 12. Submit\nresults = pd.DataFrame(pred, columns = ['row_id', 'target'])\n\n# Quick sanity check\nprint(results.head()) \n    \n# Convert our results to csv\nresults.to_csv(\"submission.csv\", index=False) ","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.853692Z","iopub.status.idle":"2022-05-08T19:17:15.854223Z","shell.execute_reply.started":"2022-05-08T19:17:15.853945Z","shell.execute_reply":"2022-05-08T19:17:15.853974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"execution":{"iopub.status.busy":"2022-05-08T19:17:15.856345Z","iopub.status.idle":"2022-05-08T19:17:15.856919Z","shell.execute_reply.started":"2022-05-08T19:17:15.856635Z","shell.execute_reply":"2022-05-08T19:17:15.856664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}