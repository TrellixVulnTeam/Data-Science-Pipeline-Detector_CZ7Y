{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os  #provides functions for interacting with the operating system\nimport json  #used to work with JSON data\nimport librosa #librosa is a python package for music and audio analysis\nimport numpy as np #NumPy is a Python library used for working with arrays\nimport pandas as pd #data analysis toolkit\nfrom sklearn.model_selection import train_test_split #Split arrays or matrices into random train and test subsets\nimport tensorflow as tf #TensorFlow is a Python library for fast numerical computing\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.utils import plot_model, Sequence\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Input, Concatenate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-09T19:12:47.352348Z","iopub.execute_input":"2022-05-09T19:12:47.352647Z","iopub.status.idle":"2022-05-09T19:12:54.094618Z","shell.execute_reply.started":"2022-05-09T19:12:47.352561Z","shell.execute_reply":"2022-05-09T19:12:54.093823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trained Data Loading\ntrain_meta = pd.read_csv(\"/kaggle/input/birdclef-2022/train_metadata.csv\")\ntrain_meta#species","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.096377Z","iopub.execute_input":"2022-05-09T19:12:54.096654Z","iopub.status.idle":"2022-05-09T19:12:54.224623Z","shell.execute_reply.started":"2022-05-09T19:12:54.096611Z","shell.execute_reply":"2022-05-09T19:12:54.223974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Split audio into 5 seconds chunks","metadata":{}},{"cell_type":"code","source":"train_meta","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.225909Z","iopub.execute_input":"2022-05-09T19:12:54.226636Z","iopub.status.idle":"2022-05-09T19:12:54.249781Z","shell.execute_reply.started":"2022-05-09T19:12:54.226597Z","shell.execute_reply":"2022-05-09T19:12:54.24903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta2 = pd.read_csv(\"../input/xenocantoazcsv/train_extended_A-Z_ogg.csv\")\ntrain_meta2","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.252288Z","iopub.execute_input":"2022-05-09T19:12:54.252719Z","iopub.status.idle":"2022-05-09T19:12:54.618663Z","shell.execute_reply.started":"2022-05-09T19:12:54.252682Z","shell.execute_reply":"2022-05-09T19:12:54.617968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta2","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.619919Z","iopub.execute_input":"2022-05-09T19:12:54.620317Z","iopub.status.idle":"2022-05-09T19:12:54.66612Z","shell.execute_reply.started":"2022-05-09T19:12:54.620278Z","shell.execute_reply":"2022-05-09T19:12:54.665425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta2 = pd.read_csv(\"../input/xenocantoazcsv/train_extended_A-Z_ogg.csv\")\n\n\n#train_meta2 = train_meta2.rename(columns={\"species\": \"primary_label\"})\n\n#train_meta2 = train_meta2[['species','filename']]\n\n\ntrain_meta2 = train_meta2[['ebird_code', 'species', 'filename']]\ntrain_meta2\n\npathAll = []\nfor each, path in zip(train_meta2['ebird_code'].values, train_meta2['filename'].values):\n    if each[0] < \"n\":\n        temp = '../input/xenocantoamogg/A-M-ogg/' + each + '/' + path\n        pathAll.append(temp)\n    else:\n        temp = '../input/xenocantonzogg/N-Z-ogg/' + each + '/' + path\n        pathAll.append(temp)\ntrain_meta2['filename'] = pathAll\ntrain_meta2 = train_meta2[['species', 'filename']]\n                          \ntrain_meta2 = train_meta2.rename(columns={\"species\": \"primary_label\"})\n\n\n\n\ntrain_meta = pd.read_csv(\"/kaggle/input/birdclef-2022/train_metadata.csv\")\ntrain_meta = train_meta[['scientific_name', 'filename']]\ntrain_meta = train_meta.rename(columns={\"scientific_name\": \"primary_label\"})\n\n\nfilePath = '../input/birdclef-2022/train_audio/'\n\narr = []\nfor each in train_meta['filename'].values:\n    arr.append(filePath+each)\ntrain_meta['filename'] = arr\n\ntrain_meta #.head().iloc[1]\n\n\ntrain_meta['source'] = 0\ntrain_meta2['source'] = 1","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.667348Z","iopub.execute_input":"2022-05-09T19:12:54.668054Z","iopub.status.idle":"2022-05-09T19:12:54.973998Z","shell.execute_reply.started":"2022-05-09T19:12:54.668024Z","shell.execute_reply":"2022-05-09T19:12:54.973254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df = pd.concat([train_meta, train_meta2])\ntrain_meta = data_df","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.97512Z","iopub.execute_input":"2022-05-09T19:12:54.975366Z","iopub.status.idle":"2022-05-09T19:12:54.981223Z","shell.execute_reply.started":"2022-05-09T19:12:54.975333Z","shell.execute_reply":"2022-05-09T19:12:54.980483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta.iloc[3]['filename']","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.982554Z","iopub.execute_input":"2022-05-09T19:12:54.983035Z","iopub.status.idle":"2022-05-09T19:12:54.990935Z","shell.execute_reply.started":"2022-05-09T19:12:54.982998Z","shell.execute_reply":"2022-05-09T19:12:54.990167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = list(train_meta['primary_label'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:54.992507Z","iopub.execute_input":"2022-05-09T19:12:54.992982Z","iopub.status.idle":"2022-05-09T19:12:55.002475Z","shell.execute_reply.started":"2022-05-09T19:12:54.992945Z","shell.execute_reply":"2022-05-09T19:12:55.00177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for Cutting Audio If There is any extra Noise.\nimport soundfile as sf\nimport os\ndef cutAudio(file_path, is_save):\n    # First load the file\n    filename = file_path.split('/')[-1]\n    file_path =  file_path\n    audio, sr = librosa.load(file_path)\n\n    # Get number of samples for 5 seconds; replace 5 by any number\n    buffer = 5 * sr\n\n    samples_total = len(audio)\n    samples_wrote = 0\n    counter = 1\n\n    audio_split = []\n    audio_filenames = []\n    while samples_wrote < samples_total:\n        #check if the buffer is not exceeding total samples \n        if buffer > (samples_total - samples_wrote):\n            buffer = samples_total - samples_wrote\n\n        block = audio[samples_wrote : (samples_wrote + buffer)]\n        audio_split.append(block)\n\n        # Write 5 second segment\n        if is_save == True:\n            out_filename = \"/kaggle/working/each5s/split_\" + str(counter) + \"_\" + filename\n            audio_filenames.append(out_filename)\n            sf.write(out_filename, block, sr)\n        counter += 1\n        samples_wrote += buffer\n    return audio_split, sr, audio_filenames","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:55.007289Z","iopub.execute_input":"2022-05-09T19:12:55.00748Z","iopub.status.idle":"2022-05-09T19:12:55.014702Z","shell.execute_reply.started":"2022-05-09T19:12:55.007456Z","shell.execute_reply":"2022-05-09T19:12:55.014013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for splitting Trained audio\ndef splitTrainAudio(_df):\n    data = []\n    for index, row in _df.iterrows():\n        cutAudio(row[\"filename\"], True)\n        audio_lst, sr, filenames = cutAudio(row[\"filename\"], True)\n        for idx, y in enumerate(audio_lst):\n            data.append([row[\"primary_label\"], row[\"filename\"], filenames[idx]])\n\n    data_df = pd.DataFrame(data, columns=['primary_label', 'original_filename', 'filename'])\n    data_df.to_csv(\"/kaggle/working/data_df.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:55.016092Z","iopub.execute_input":"2022-05-09T19:12:55.016538Z","iopub.status.idle":"2022-05-09T19:12:55.025922Z","shell.execute_reply.started":"2022-05-09T19:12:55.016503Z","shell.execute_reply":"2022-05-09T19:12:55.025204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Input Sampleling Data to data_frame List\ndata_frames = []\nfor label in labels:\n    tmp_df = train_meta[train_meta[\"primary_label\"] == label].sample(n=1, replace=True).reset_index(drop=True)\n    data_frames.append(tmp_df)\nsample_df = pd.concat(data_frames).reset_index(drop=True)\nsample_df","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:55.027094Z","iopub.execute_input":"2022-05-09T19:12:55.027541Z","iopub.status.idle":"2022-05-09T19:12:57.622277Z","shell.execute_reply.started":"2022-05-09T19:12:55.027503Z","shell.execute_reply":"2022-05-09T19:12:57.621608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_meta2['filename'][0].split('/')[-1]","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:57.623612Z","iopub.execute_input":"2022-05-09T19:12:57.624062Z","iopub.status.idle":"2022-05-09T19:12:57.627623Z","shell.execute_reply.started":"2022-05-09T19:12:57.624026Z","shell.execute_reply":"2022-05-09T19:12:57.626408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating a directory named path\n!mkdir -p \"/kaggle/working/each5s\"\nsplitTrainAudio(sample_df)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:12:57.629102Z","iopub.execute_input":"2022-05-09T19:12:57.62965Z","iopub.status.idle":"2022-05-09T19:41:54.480742Z","shell.execute_reply.started":"2022-05-09T19:12:57.629613Z","shell.execute_reply":"2022-05-09T19:41:54.47981Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.481931Z","iopub.execute_input":"2022-05-09T19:41:54.482201Z","iopub.status.idle":"2022-05-09T19:41:54.500445Z","shell.execute_reply.started":"2022-05-09T19:41:54.482166Z","shell.execute_reply":"2022-05-09T19:41:54.499813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#After processing the data we store it in DataFrame\ndata_df = pd.read_csv(\"/kaggle/working/data_df.csv\")\ndata_df","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.502731Z","iopub.execute_input":"2022-05-09T19:41:54.504086Z","iopub.status.idle":"2022-05-09T19:41:54.531257Z","shell.execute_reply.started":"2022-05-09T19:41:54.504051Z","shell.execute_reply":"2022-05-09T19:41:54.530619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### The full data can be found [here](https://www.kaggle.com/duythanhng/birdclef-2022-audio-per-5-second)","metadata":{}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"#From this function we extarting features of Sample data/audio file\nnum_rows = 216\nnum_columns = 216\nnum_channels = 1\nn_mels = 512\n\ndef extractFeatures(y, sr):\n    feat = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=num_rows, n_mels=n_mels)\n    if feat.shape[1] <= num_columns:\n        pad_width = num_columns - feat.shape[1]\n        feat = np.pad(feat, pad_width=((0,0),(0,pad_width)), mode='constant')\n    return feat","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.533382Z","iopub.execute_input":"2022-05-09T19:41:54.53463Z","iopub.status.idle":"2022-05-09T19:41:54.542547Z","shell.execute_reply.started":"2022-05-09T19:41:54.534593Z","shell.execute_reply":"2022-05-09T19:41:54.54165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Here we are setting how many data sample/audio file will enter in each time in the network.#Data Managing\nclass DataGenerator(Sequence):\n    def __init__(self,\n                _X,\n                batch_size=32,\n                n_channels=1,\n                n_columns=470,\n                n_rows=120,\n                shuffle=True):\n        self.batch_size = batch_size\n        self.X = _X\n        self.n_channels = n_channels\n        self.n_columns = n_columns\n        self.n_rows = n_rows\n        self.shuffle = shuffle\n        self.img_indexes = np.arange(len(self.X))\n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.img_indexes) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        # Find list of IDs\n        list_IDs_temps = [self.img_indexes[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temps)\n        return X, y\n     \n        \n    #Function for Updates indexes after each epoch\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.X))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temps):\n        X = np.empty((self.batch_size, self.n_rows, self.n_columns))\n        y = np.empty((self.batch_size), dtype=int)\n        for i, ID in enumerate(list_IDs_temps):\n            file_path = self.X.iloc[ID][\"filename\"]\n            audio, sr = librosa.load(file_path)\n            feat = extractFeatures(audio, sr)\n            x_features = feat.tolist()\n            label = self.X.iloc[ID][\"target\"]\n            X[i] = np.array(x_features)\n            y[i] = label\n        X = X.reshape(X.shape[0], self.n_rows, self.n_columns, self.n_channels)\n        \n        return X, to_categorical(y, num_classes=len(labels))","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.544964Z","iopub.execute_input":"2022-05-09T19:41:54.546463Z","iopub.status.idle":"2022-05-09T19:41:54.56553Z","shell.execute_reply.started":"2022-05-09T19:41:54.546425Z","shell.execute_reply":"2022-05-09T19:41:54.564699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = dict(\n    batch_size=128,\n    n_rows=num_rows,\n    n_columns=num_columns,\n    n_channels=num_channels,\n)\nparams_train = dict(\n    shuffle=True,\n    **params\n)\nparams_valid = dict(\n    shuffle=False,\n    **params\n)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.567915Z","iopub.execute_input":"2022-05-09T19:41:54.569497Z","iopub.status.idle":"2022-05-09T19:41:54.576676Z","shell.execute_reply.started":"2022-05-09T19:41:54.569457Z","shell.execute_reply":"2022-05-09T19:41:54.575937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for data visualization of audio sample\nimport matplotlib.pyplot as plt\n\ndef plot_his(history):\n    plt.figure(1, figsize = (15,8))\n    plt.subplot(221)\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'])\n    plt.subplot(222)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'valid'])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.579526Z","iopub.execute_input":"2022-05-09T19:41:54.580912Z","iopub.status.idle":"2022-05-09T19:41:54.590967Z","shell.execute_reply.started":"2022-05-09T19:41:54.580873Z","shell.execute_reply":"2022-05-09T19:41:54.5902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for creating Convolutional neural network\ndef create_cnn():\n    img_input = Input(shape=(num_rows, num_columns, num_channels))\n    img_conc = Concatenate()([img_input, img_input, img_input])\n    base_model = MobileNetV2(\n        include_top=False,\n        weights='/kaggle/input/keras-pretrain-model-weights/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5',\n        input_tensor=img_conc\n    )\n    # base_model.trainable = False\n    avgpool = GlobalAveragePooling2D()(base_model.output)\n    outputs = Dense(len(labels), activation='softmax')(avgpool)\n\n    model = Model(inputs=base_model.input, outputs=outputs)\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.593669Z","iopub.execute_input":"2022-05-09T19:41:54.595241Z","iopub.status.idle":"2022-05-09T19:41:54.604041Z","shell.execute_reply.started":"2022-05-09T19:41:54.595182Z","shell.execute_reply":"2022-05-09T19:41:54.603148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_df['target'] = data_df['primary_label'].apply(lambda x: labels.index(x))\ndata_df","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.605358Z","iopub.execute_input":"2022-05-09T19:41:54.605997Z","iopub.status.idle":"2022-05-09T19:41:54.657881Z","shell.execute_reply.started":"2022-05-09T19:41:54.605956Z","shell.execute_reply":"2022-05-09T19:41:54.657205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function for Input Data Training  for Model\ndef train_model(model, train_gen, val_gen):\n    checkpoint_model_path = \"/kaggle/working/mobilnetv2.h5\"\n    metric = \"val_accuracy\"\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=[\"accuracy\"])\n    num_epochs = 50\n    checkpointer = ModelCheckpoint(\n        filepath=checkpoint_model_path,\n        monitor=metric, verbose=1, save_best_only=True)\n    es_callback = EarlyStopping(monitor=metric, patience=5, verbose=1)\n    reduce_lr = ReduceLROnPlateau(monitor=metric, factor=0.3, patience=1, verbose=1, min_delta=0.0001, cooldown=1, min_lr=0.00001)\n\n    history = model.fit(\n        train_gen,\n        epochs=num_epochs,\n        validation_data=val_gen,\n        callbacks=[checkpointer,es_callback,reduce_lr],\n        verbose=1\n    )\n\n    plot_his(history)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.659379Z","iopub.execute_input":"2022-05-09T19:41:54.660012Z","iopub.status.idle":"2022-05-09T19:41:54.669523Z","shell.execute_reply.started":"2022-05-09T19:41:54.659975Z","shell.execute_reply":"2022-05-09T19:41:54.668862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function Calling\nX_train, X_valid, _, _ = train_test_split(data_df, data_df[\"target\"], test_size=0.1, random_state=42)\ntrain_generator = DataGenerator(X_train, **params_train)\nvalid_generator = DataGenerator(X_valid, **params_valid)\ncnn_model = create_cnn()\ntrain_model(cnn_model, train_generator, valid_generator)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T19:41:54.670737Z","iopub.execute_input":"2022-05-09T19:41:54.671479Z","iopub.status.idle":"2022-05-09T22:49:20.363823Z","shell.execute_reply.started":"2022-05-09T19:41:54.671426Z","shell.execute_reply":"2022-05-09T22:49:20.362749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"#CNN Function Calling\ncnn_model = create_cnn()\n# cnn_model.load_weights(\"/kaggle/input/birdclef-2022-keras-model/mobilenetv20_0.8545.h5\")\ncnn_model.load_weights(\"/kaggle/working/mobilnetv2.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-05-09T22:49:20.365378Z","iopub.execute_input":"2022-05-09T22:49:20.365803Z","iopub.status.idle":"2022-05-09T22:49:22.00854Z","shell.execute_reply.started":"2022-05-09T22:49:20.365752Z","shell.execute_reply":"2022-05-09T22:49:22.007816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting an entire data table into a NumPy matrix array\n# data_df = pd.read_csv(\"/kaggle/input/birdclef-2022-keras-model/data_df.csv\")\ndata_df = pd.read_csv(\"/kaggle/working/data_df.csv\")\nlabels = list(data_df['primary_label'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-05-09T22:49:22.01128Z","iopub.execute_input":"2022-05-09T22:49:22.011532Z","iopub.status.idle":"2022-05-09T22:49:22.028927Z","shell.execute_reply.started":"2022-05-09T22:49:22.011497Z","shell.execute_reply":"2022-05-09T22:49:22.028244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_path = \"/kaggle/input/birdclef-2022/test_soundscapes/\"\nfiles = [f.split('.')[0] for f in sorted(os.listdir(test_path))]\n\nbirds_path = \"/kaggle/input/birdclef-2022/scored_birds.json\"\nwith open(birds_path) as bf:\n    birds = json.load(bf)\n\ndata = []\nfor f in files:\n    file_path = test_path + f + '.ogg'\n    audio, sr = librosa.load(file_path)\n    # Get number of samples for 5 seconds; replace 5 by any number\n    buffer = 5 * sr\n    samples_total = len(audio)\n    samples_wrote = 0\n    counter = 1\n\n    while samples_wrote < samples_total:\n        #check if the buffer is not exceeding total samples \n        if buffer > (samples_total - samples_wrote):\n            buffer = samples_total - samples_wrote\n\n        block = audio[samples_wrote : (samples_wrote + buffer)]\n        feat = extractFeatures(block, sr)\n        x = feat.reshape(1, num_rows, num_columns, num_channels)\n        pred = cnn_model.predict(x)\n        label_index = np.argmax(pred,axis=1)[0]\n        \n        for b in birds:\n            segment_end = counter * 5   \n            row_id = f + '_' + b + '_' + str(segment_end)\n            target = False\n            if labels[label_index] == b:\n                target = True\n            data.append([row_id, target])\n        counter += 1\n        samples_wrote += buffer\n        \nsubmission_df = pd.DataFrame(data, columns=['row_id', 'target'])\nsubmission_df","metadata":{"execution":{"iopub.status.busy":"2022-05-09T22:49:22.030282Z","iopub.execute_input":"2022-05-09T22:49:22.03072Z","iopub.status.idle":"2022-05-09T22:49:25.750797Z","shell.execute_reply.started":"2022-05-09T22:49:22.030683Z","shell.execute_reply":"2022-05-09T22:49:25.749805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_df.to_csv(\"/kaggle/working/submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T22:49:25.76405Z","iopub.execute_input":"2022-05-09T22:49:25.772922Z","iopub.status.idle":"2022-05-09T22:49:25.799727Z","shell.execute_reply.started":"2022-05-09T22:49:25.772871Z","shell.execute_reply":"2022-05-09T22:49:25.799057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}