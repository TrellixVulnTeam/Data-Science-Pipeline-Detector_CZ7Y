{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#UPVOTE IF YOU FIND IT USEFUL :D\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport json\nimport librosa\nimport librosa.display\nimport matplotlib.pyplot as plt\nfrom scipy import signal\nfrom scipy.io import wavfile\n#reading CSV with pandas\nTaxonomy = pd.read_csv('../input/birdclef-2022/eBird_Taxonomy_v2021.csv')\ntest = pd.read_csv('../input/birdclef-2022/test.csv')\ntrain_metadata = pd.read_csv('../input/birdclef-2022/train_metadata.csv')\nsubmission = pd.read_csv('../input/birdclef-2022/sample_submission.csv')\nfrom os import path\nfrom pydub import AudioSegment\nimport seaborn as sns\nfrom scipy.io.wavfile import read\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom scipy import signal\nfrom scipy.io import wavfile\n\n\n#transform into dataframe\ndf_taxonomy = pd.DataFrame(Taxonomy)\n\ndf_test = pd.DataFrame(test)\n\ndf_train = pd.DataFrame(train_metadata)\n\ndf_submission = pd.DataFrame(submission)\n\n\n\n\n\n\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-18T19:28:22.162753Z","iopub.execute_input":"2022-05-18T19:28:22.163746Z","iopub.status.idle":"2022-05-18T19:28:25.693036Z","shell.execute_reply.started":"2022-05-18T19:28:22.163639Z","shell.execute_reply":"2022-05-18T19:28:25.692077Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#opening the scored bird file\nwith open('../input/birdclef-2022/scored_birds.json','r') as f:\n    data = json.load(f)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-18T19:28:25.69469Z","iopub.execute_input":"2022-05-18T19:28:25.694969Z","iopub.status.idle":"2022-05-18T19:28:25.702264Z","shell.execute_reply.started":"2022-05-18T19:28:25.694931Z","shell.execute_reply":"2022-05-18T19:28:25.701104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#index of the scored rows\nindex_row_scored = []\nfor i in data:\n    a=i.strip('\"')\n    for j in range(len(df_train[\"primary_label\"])):\n        if df_train[\"primary_label\"][j] == a:\n            index_row_scored.append(j)\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T19:28:25.703818Z","iopub.execute_input":"2022-05-18T19:28:25.704267Z","iopub.status.idle":"2022-05-18T19:28:28.113618Z","shell.execute_reply.started":"2022-05-18T19:28:25.70422Z","shell.execute_reply":"2022-05-18T19:28:28.112726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom os import listdir\nfrom os.path import isfile, join\nrated_list = []\nfor i in data:\n    onlyfiles = [f for f in listdir(\"../input/birdclef-2022/train_audio/\"+i) if isfile(join(\"../input/birdclef-2022/train_audio/\"+i,f))]\n    rated_list.append(i)\n    rated_list.append(onlyfiles)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-05-18T19:28:28.115344Z","iopub.execute_input":"2022-05-18T19:28:28.115586Z","iopub.status.idle":"2022-05-18T19:28:28.34683Z","shell.execute_reply.started":"2022-05-18T19:28:28.115558Z","shell.execute_reply":"2022-05-18T19:28:28.346065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Function to extract features from the audios\ndef features_extractor(file):\n    #load the file (audio)\n    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n    #we extract mfcc\n    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n    #in order to find out scaled feature we do mean of transpose of value\n    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n    return mfccs_scaled_features\n","metadata":{"execution":{"iopub.status.busy":"2022-05-18T19:28:28.347836Z","iopub.execute_input":"2022-05-18T19:28:28.348623Z","iopub.status.idle":"2022-05-18T19:28:28.355042Z","shell.execute_reply.started":"2022-05-18T19:28:28.348584Z","shell.execute_reply":"2022-05-18T19:28:28.353685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We will use a dataframe with the scored birds just to see that everything works fine \n#without spending so much time\ndf_scored = df_train.copy()\nfor i in df_train.index:\n    #if df_train['rating'][i]<2.5:\n        #df_train.drop([i],axis = 0, inplace = True)\n    if i not in index_row_scored:\n        df_scored.loc[i,'primary_label'] = 'other'","metadata":{"execution":{"iopub.status.busy":"2022-05-18T19:28:28.35628Z","iopub.execute_input":"2022-05-18T19:28:28.356678Z","iopub.status.idle":"2022-05-18T19:28:34.023352Z","shell.execute_reply.started":"2022-05-18T19:28:28.356633Z","shell.execute_reply":"2022-05-18T19:28:34.022436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_scored","metadata":{"execution":{"iopub.status.busy":"2022-05-18T19:28:34.024798Z","iopub.execute_input":"2022-05-18T19:28:34.025037Z","iopub.status.idle":"2022-05-18T19:28:34.062462Z","shell.execute_reply.started":"2022-05-18T19:28:34.025009Z","shell.execute_reply":"2022-05-18T19:28:34.061524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tqdm import tqdm\n# Now we iterate through every audio file and extract features \n# using Mel-Frequency Cepstral Coefficients\nextracted_features=[]\nfor index_num,row in tqdm(df_scored.iterrows()):\n    file_name = os.path.join(os.path.abspath(\"../input/birdclef-2022/train_audio/\"),str(row[\"filename\"]))\n    final_class_labels=row[\"primary_label\"]\n    data=features_extractor(file_name)\n    extracted_features.append([data,final_class_labels])","metadata":{"execution":{"iopub.status.busy":"2022-05-18T19:28:34.063553Z","iopub.execute_input":"2022-05-18T19:28:34.063764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"extracted_features_df=pd.DataFrame(extracted_features,columns=['feature','primary_label'])\nextracted_features_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Now we split the data into train and test\nfrom imblearn.over_sampling import RandomOverSampler #we improved accuracy with this!\noversample = RandomOverSampler(sampling_strategy='minority')\n# Split the dataset into independent and dependent dataset\nX=np.array(extracted_features_df['feature'].tolist())\ny=np.array(extracted_features_df['primary_label'].tolist())\n# Label Encoding -> Label Encoder\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder=LabelEncoder()\ny=to_categorical(labelencoder.fit_transform(y))\n### Train Test Split\nfrom sklearn.model_selection import train_test_split\nX,y = oversample.fit_resample(X, y)\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.02)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\ntrainedforest = RandomForestClassifier(n_estimators = 700).fit(X_train, y_train)\npredictionforest = trainedforest.predict(X_test)\nprint(classification_report(y_test,predictionforest))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#we create feature names\n#X=np.array(extracted_features_df['feature'].tolist())\nX_t = []\nX__t = []\nfor j in range(0,40):\n    X_t = []\n    for i in range(len(X)):\n        X_t.append(X[i][j])\n    X__t.append(X_t)\n    \nfeature_names = [f\"feature {i}\" for i in range(X.shape[1])]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Feature importance\nfrom matplotlib.pyplot import figure\nfigure(num = None, figsize=(10,11), dpi = 80, facecolor = 'w', edgecolor = 'k')\nfeat_importances = pd.Series(trainedforest.feature_importances_, index = feature_names)\nfeat_importances.nlargest(40).plot(kind = 'barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We use 7 features\n\nfrom matplotlib.pyplot import figure\nfigure(num = None, figsize=(10,11), dpi = 80, facecolor = 'w', edgecolor = 'k')\nfeat_importances = pd.Series(trainedforest.feature_importances_, index = feature_names)\nfeat_importances.nlargest(7).plot(kind = 'barh')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We select the 7 features with more importance in our data\nX_prueba = X\nX_prueb = X_prueba.tolist()\nX_pru = []\nX_pri = []\n\nfor i in range(len(X)):\n    for j in range(0,40):\n        if j==6 or j==8 or j==2 or j==16 or j==12 or j==24 or j==36:\n            X_pru.append(X_prueb[i][j])\n    X_pri.append(X_pru)\n    X_pru = []\n            \n                \nX_pro = np.array([np.array(xi) for xi in X_pri])\nprint(X_pro)\nlen(X_pro)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wedivide again between train and test\n#X_train,X_test,y_train,y_test=train_test_split(X_pro,y,test_size=0.2)\n#X_train.shape\n#X_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn import metrics\n# No of classes\nnum_labels=y.shape[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Creation of the model\nmodel=Sequential()\n###first layer\nmodel.add(Dense(100,input_shape=(7,)))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dropout(0.5))\n###second layer\nmodel.add(Dense(200))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dropout(0.5))\n###third layer\nmodel.add(Dense(100))\nmodel.add(Activation('sigmoid'))\nmodel.add(Dropout(0.5))\n###final layer\nmodel.add(Dense(num_labels))\nmodel.add(Activation('softmax'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer='adam')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Trianing my model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom datetime import datetime \nnum_epochs = 200\nnum_batch_size = 32\ncheckpointer = ModelCheckpoint(filepath='./audio_classification.hdf5', \n                               verbose=1, save_best_only=True)\nstart = datetime.now()\nmodel.fit(X_pro, y, batch_size=num_batch_size, epochs=num_epochs)\nduration = datetime.now() - start\nprint(\"Training completed in time: \", duration)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Let's check the accuracy!\n#test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n#print(test_accuracy[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predict_x = model.predict(X_test)\n#classes_x = np.argmax(predict_x, axis = 1)\n#predict_x[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Here we split the test audio file\ntest_audio_dir = '../input/birdclef-2022/test_soundscapes/'\nfile_list = [f.split('.')[0] for f in sorted(os.listdir(test_audio_dir))]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/birdclef-2022/scored_birds.json') as sbfile:\n    scored_birds = json.load(sbfile)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = {'row_id': [], 'target': []}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Process audio files and make predictions\nfor afile in file_list:\n    \n    # Complete file path\n    path = test_audio_dir + afile + '.ogg'\n    \n    # Open file with librosa and split signal into 5-second chunks\n    # sig, rate = librosa.load(path)\n    # ...\n    \n    # Let's assume we have a list of 12 audio chunks (1min / 5s == 12 segments)\n    chunks = [[] for i in range(12)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"chunks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#y_test.shape\n#predict_x.shape\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\n#score = f1_score(str(y_test[1]),str(predict_x[1]).replace(\".\", \"\"), average = None)\n#fil_acc_orig = accuracy_score(X_test,predict_x)\n\n#X_test\n\n#y\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's prepare the test file to create the submision csv","metadata":{}},{"cell_type":"code","source":"# we will divide the test audio in 12 audios of 5 seconds.\n\nfrom pydub import AudioSegment\nfrom pydub.utils import make_chunks \nsound = AudioSegment.from_file(\"../input/birdclef-2022/test_soundscapes/soundscape_453028782.ogg\")\n\nchunk_length_ms = 5000 # pydub calculates in millisec \nchunks = make_chunks(sound,chunk_length_ms) #Make chunks of one sec \nfor i, chunk in enumerate(chunks): \n    chunk_name = \"{0}.ogg\".format(i) \n    print (\"exporting\", chunk_name) \n    chunk.export(chunk_name, format=\"ogg\") \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets exstract the features from the test audio\nimport librosa\nimport numpy as np\n\ndef features_extractor(file):\n    #load the file (audio)\n    audio, sample_rate = librosa.load(file_name, res_type='kaiser_fast') \n    #we extract mfcc\n    mfccs_features = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n    #in order to find out scaled feature we do mean of transpose of value\n    mfccs_scaled_features = np.mean(mfccs_features.T,axis=0)\n    return mfccs_scaled_features\n\n\nimport os\nextracted_features_=[]\nfor i in range(0,12):\n    file_name = os.path.join(os.path.abspath(\"./\"),str(i) + \".ogg\")\n    data=features_extractor(file_name)\n    extracted_features_.append([data])","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nextracted_features_df_=pd.DataFrame(extracted_features_,columns=['feature'])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_=np.array(extracted_features_df_['feature'].tolist())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We use the same features than before\nX_prueba = X_\nX_prueb = X_prueba.tolist()\nX_pru = []\nX_pri = []\n\nfor i in range(len(X_)):\n    for j in range(0,40):\n        if j==6 or j==8 or j==12 or j==16 or j==24 or j==36 or j==2:\n            X_pru.append(X_prueb[i][j])\n    X_pri.append(X_pru)\n    X_pru = []\n            \n                \nX_pro = np.array([np.array(xi) for xi in X_pri])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('../input/birdclef-2022/scored_birds.json') as sbfile:\n    scored_birds = json.load(sbfile)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict__=model.predict(X_pro)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This is where we will store our results\npred = {'row_id': [], 'target': []}\n\n# Process audio files and make predictions\nfor afile in file_list:\n    \n    # Complete file path\n    path = test_audio_dir + afile + '.ogg'\n    \n    # Open file with librosa and split signal into 5-second chunks\n    # sig, rate = librosa.load(path)\n    # ...\n    \n    # Let's assume we have a list of 12 audio chunks (1min / 5s == 12 segments)\n    chunks = [[] for i in range(12)]\n    \n    # Make prediction for each chunk\n    # Each scored bird gets a random value in our case\n    # since we don't actually have a model\n    for i in range(len(chunks)):        \n        chunk_end_time = (i + 1) * 5\n        j=0\n        for bird in scored_birds:\n            \n            # This is our random prediction score for this bird\n            score = predict__[i][j]\n            maximun = max(predict__[i])\n            j=j+1\n            # Assemble the row_id which we need to do for each scored bird\n            row_id = afile + '_' + bird + '_' + str(chunk_end_time)\n            \n            # Put the result into our prediction dict and\n            # apply a \"confidence\" threshold of 0.5\n            pred['row_id'].append(row_id)\n            pred['target'].append(True if score > 0.008 else False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = pd.DataFrame(pred, columns = ['row_id', 'target'])\n\n# Quick sanity check\nprint(results.head()) \n    \n# Convert our results to csv\nresults.to_csv(\"submission.csv\", index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}