{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"motivation\n\nI found that there is a significant difference in the prediction results between columns with only one na and columns with two or more na, using the previous method.\n\nIt seems that multiple columns of na filled with mean, etc. are interacting with each other and adversely affecting the results.\n\nPredicting by how many na columns there are improves the score.","metadata":{}},{"cell_type":"code","source":"# For Google Colab\n\"\"\"\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Install kaggle packages\n!pip install -q kaggle\n!pip install -q kaggle-cli\n\n# Lib\nfrom google.colab import files\n\n# Please Upload `kaggle.json` file\nuploaded = files.upload()\n\n# Then copy kaggle.json into the folder where the API expects to find it.\n!mkdir -p ~/.kaggle\n!cp kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n!ls ~/.kaggle\n\n!kaggle competitions download -c tabular-playground-series-jun-2022\n!unzip -o tabular-playground-series-jun-2022.zip -d tabular-playground-series-jun-2022\n!kaggle kernels output oxzplvifi/tps2206-gbm-resnet-imputation -p ./DataSet\n\"\"\"","metadata":{"id":"08ede1b7","outputId":"4ffb1a38-ff20-4add-e248-b96c183a771c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install wandb\n!pip install pytorch_lightning","metadata":{"id":"95312a76"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\ntry:\n    # add-ons -> secrets -> set your wandb api key\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=secret_value_0)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')\n","metadata":{"id":"e50babc2","outputId":"4f1e5462-46b2-4922-f1d6-cc2dc6aff8f2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.init(project=\"tps2206\")","metadata":{"id":"_9KqWkq8KIuu","outputId":"0ffbb9a4-e468-42d1-8971-eec759211c37"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lib","metadata":{"id":"74ff08e2"}},{"cell_type":"code","source":"# common\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport time, gc, string, math\nfrom tqdm.notebook import tqdm\nimport warnings\nimport shutil\nfrom collections import defaultdict\nimport heapq\nimport datetime\nimport random\nfrom collections import OrderedDict\nimport glob\nimport copy\n\n# sklearn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# pytorch\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import optim\nfrom torch.optim import lr_scheduler\n\n# pytorch lightning\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\n","metadata":{"id":"baeddd0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.set_option('display.max_columns', 200)\npd.set_option('display.max_rows', 200)","metadata":{"id":"HmNa5M7LXKOV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for google colab\n# os.chdir(\"/content/drive/MyDrive/colab_data/TPS2206\")","metadata":{"id":"yWDSyU66tnEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nos.makedirs('model', exist_ok=True)\nshutil.rmtree('./model/')\nos.makedirs('model', exist_ok=True)\n\"\"\"","metadata":{"id":"dcec1181","outputId":"3b730855-171b-476c-8f2c-234dce48b847"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read DF","metadata":{"id":"d671d1ab"}},{"cell_type":"code","source":"data = pd.read_csv('../input/tabular-playground-series-jun-2022/data.csv', index_col='row_id')\nsub = pd.read_csv('../input/tabular-playground-series-jun-2022/sample_submission.csv', index_col='row-col')","metadata":{"id":"50249fa9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for col in data.columns:\n    if \"F_4\" not in col:\n        data[col] = data[col].fillna(data[col].mean())","metadata":{"id":"BfU09bCzohwR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na_col_list = []\nfor col in data.columns:\n    if data[col].isna().sum() != 0:\n        na_col_list.append(col)","metadata":{"id":"tAE_QGSQuL3J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f4data = data[na_col_list]","metadata":{"id":"k71_UFuTura4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na_index_of = {}\nno_na_index_of = {}\nfor col in na_col_list:\n    na_index = f4data[f4data[col].isna() == True].index\n    na_index_of[col] = na_index\n    no_na_index = f4data[f4data[col].isna() == False].index\n    no_na_index_of[col] = no_na_index","metadata":{"id":"ac89d698"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na_cnt = pd.DataFrame(f4data.isna().sum(axis=1))","metadata":{"id":"GlCaCEMBvkeI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na_cnt.groupby([0]).size()","metadata":{"id":"w79idpU4v93e","outputId":"015767e6-b010-4039-9b02-617b40146a5a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na_cnt_max = 5\nna_cnt_index_of = {}\nfor cnt in range(0, na_cnt_max+1):\n    na_cnt_index = na_cnt[na_cnt[0] == cnt].index\n    na_cnt_index_of[cnt] = na_cnt_index","metadata":{"id":"5fZZXIGTwv3x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def na_no_na_index_of(col, cnt):\n    na_index = na_index_of[col]\n    no_na_index = no_na_index_of[col]\n    na_cnt_index = na_cnt_index_of[cnt]\n    na_index = na_index.intersection(na_cnt_index)\n    no_na_index = no_na_index.intersection(na_cnt_index)\n    return na_index, no_na_index","metadata":{"id":"be3aru3Xwln2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na_no_na_index_of('F_4_0', 1)","metadata":{"id":"rpqgSsNsxZux","outputId":"9027b891-48fb-444e-9902-0aa272f5decd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f4data = f4data.fillna(-1)","metadata":{"id":"Lxb-v76xEmT6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"ACmm1FBgep7p"}},{"cell_type":"markdown","source":"## Pytorch","metadata":{"id":"eb1655fa"}},{"cell_type":"markdown","source":"### DataSet and DataLoader","metadata":{"id":"b1554fbf"}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, X, y, na_num):\n        self.X = X\n        self.y = y\n        self.na_num = na_num\n        self.index_end = X.shape[1]\n        self.index_list = [i for i in range(self.index_end)]\n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, item):\n        if self.na_num != 0:\n            X = self.X[item]\n            # must use torch.rand* . np.random cause same seed with gpu.\n            na_index_list = torch.randperm(self.index_end)[:self.na_num].tolist()\n            for na_index in na_index_list:\n                X[na_index] = -1\n        else:\n            X = self.X[item]\n        inputs = torch.tensor(X, dtype=torch.float32)\n        outputs = torch.tensor(self.y[item], dtype=torch.float32)\n\n        return inputs, outputs","metadata":{"id":"850b174a"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataModule(pl.LightningDataModule):\n    # train, val, testの3つのDataLoaderを定義する\n    # trainerにこれを渡すと、train, val, testのそれぞれのステップでこれを渡してくれる\n    def __init__(self, X_train, y_train, X_valid, y_valid, X_test, na_num, batch_size):\n        self.X_train = X_train.values\n        self.y_train = y_train.values\n        self.X_valid = X_valid.values\n        self.y_valid = y_valid.values\n        self.X_test = X_test.values\n        self.y_test = np.zeros(X_test.shape[0])\n        self.na_num = na_num\n        self.batch_size = batch_size\n        self._log_hyperparams = None  # ナニコレ・・・\n\n    def train_dataloader(self):\n        ds = TrainDataset(self.X_train, self.y_train, self.na_num)\n        dl = DataLoader(ds, batch_size=self.batch_size, shuffle=True, pin_memory=True, drop_last=True, num_workers=CFG.num_workers, persistent_workers=False)\n        return dl\n\n    def val_dataloader(self):\n        ds = TrainDataset(self.X_valid, self.y_valid, self.na_num)\n        dl = DataLoader(ds, batch_size=self.batch_size, shuffle=False, pin_memory=True, drop_last=False, num_workers=CFG.num_workers, persistent_workers=False)\n        return dl\n\n    def predict_dataloader(self):\n        ds = TrainDataset(self.X_test, self.y_test, 0)  # when predict, already fill -1\n        dl = DataLoader(ds, batch_size=self.batch_size, shuffle=False, pin_memory=True, drop_last=False, num_workers=CFG.num_workers, persistent_workers=False)\n        return dl\n\n    def prepare_data_per_node(self):\n        # TODO 本来要らないはずなんだけど・・・\n        pass\n\n    def teardown(self, stage=None):\n        torch.cuda.empty_cache()  # TODO: これであってるのか不明　何も出てこないんだよね\n        gc.collect()","metadata":{"id":"d1741d8e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pytorch Model","metadata":{"id":"0050d402"}},{"cell_type":"code","source":"class DNN(nn.Module):\n    def __init__(self, input_size):\n        super().__init__()\n        hidden_size = 100\n        output_size = 1\n        emb_dim = 8\n        self.fc1 = nn.Linear(input_size, hidden_size*4)\n        self.bn1 = nn.BatchNorm1d(hidden_size*4)\n        self.fc2 = nn.Linear(hidden_size*4, hidden_size*4)\n        self.fc3 = nn.Linear(hidden_size*4, hidden_size*2)\n        self.fc4 = nn.Linear(hidden_size*2, hidden_size)\n        self.fc5 = nn.Linear(hidden_size, output_size)\n    \n    def forward(self, x):\n        # dropoutとbnの併用禁止\n        # bnは活性化関数の前に\n        x = F.silu(self.bn1((self.fc1(x))))\n        x = F.silu(self.fc2(x))\n        x = F.silu(self.fc3(x))\n        x = F.silu(self.fc4(x))\n        x = self.fc5(x)\n        return x","metadata":{"id":"48355fe7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self, yhat, y):\n        return torch.sqrt(self.mse(yhat,y))","metadata":{"id":"41717aa5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NNModel(pl.LightningModule):\n    # https://pytorch-lightning.readthedocs.io/en/stable/notebooks/lightning_examples/basic-gan.html\n    def __init__(self, model: nn.Module):\n        super().__init__()\n        self.model = model\n        self.criterion = RMSELoss()\n        self.lr = CFG.lr\n\n    def forward(self, x) -> torch.Tensor:\n        return self.model(x)\n\n    # Setup Optimizer and Scheduler\n    def configure_optimizers(self):\n        model_params = [p for n, p in self.model.named_parameters()]\n        optimizer_params = [\n            {\"params\":  model_params,\n             \"weight_decay\": CFG.weight_decay,\n             \"lr\": 1e-3\n            },\n        ]\n\n        optimizer = optim.Adam(optimizer_params)\n\n        scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                'min',\n                                                patience=3,\n                                                factor=0.5\n                                                )\n        interval = \"epoch\"\n        monitor = \"valid_avg_loss\"\n\n        return [optimizer], [{\"scheduler\": scheduler, \"interval\": interval, \"monitor\": monitor}]\n\n    # training valid test steps\n    def training_step(self, batch_data, batch_idx):\n        # batch_data: DataModuleで定義したtrain_dataloaderの結果\n        # 戻値: lossであることが必須(裏でoptimizerに渡すため)\n        X, y = batch_data\n        op = self(X).squeeze()\n        loss = self.criterion(op, y)\n        return loss\n\n    def training_epoch_end(self, outputs):\n        # 1epoch分の処理(全バッチの処理)のreturn値をlistで受け取る\n        loss_list = [x['loss'] for x in outputs]\n        avg_loss = torch.stack(loss_list).mean()\n        self.log('train_avg_loss', avg_loss, prog_bar=True)\n        if (self.current_epoch+1) % CFG.print_epoch_freq == 0:\n            print(\"epoch:\", self.current_epoch, \"train_avg_loss:\", avg_loss.item())\n\n    def validation_step(self, batch_data, batch_idx):\n        # 戻値: 任意の辞書\n        X, y = batch_data\n        op = self(X).squeeze()\n        loss = self.criterion(op, y)\n        return {'valid_loss': loss}\n\n    def validation_epoch_end(self, outputs):\n        loss_list = [x['valid_loss'] for x in outputs]\n        avg_loss = torch.stack(loss_list).mean()\n        self.log('valid_avg_loss', avg_loss, prog_bar=True)\n        if (self.current_epoch+1) % CFG.print_epoch_freq == 0:\n            print(\"epoch:\", self.current_epoch, \"valid_avg_loss:\", avg_loss.item())\n        return avg_loss\n\n    def predict_step(self, batch_data, batch_idx):\n        # 実際に予測させるときに使う\n        X, _ = batch_data\n        outputs = self(X).squeeze()\n        # criterionがwithLogit系の場合は、sigmoidを追加する。\n        # outputs = torch.sigmoid(outputs)\n        return outputs","metadata":{"id":"5e923f02"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    num_workers = 2  # colabは4, kaggleは2?\n    weight_decay=0\n    print_epoch_freq=1\n    max_epochs=30\n    max_batch_size=1000\n    lr = 1e-3\n    min_lr = 1e-6\n    debug = False\n\nif CFG.debug:\n    CFG.max_epochs=1\n    na_col_list = na_col_list[:1]","metadata":{"id":"5893d5c7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_path_of = defaultdict(str)","metadata":{"id":"HNWeULNYuVZL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_name_prefix = datetime.datetime.now().strftime('%m%d%H%M%S')\n\nfor cnt in range(0, na_cnt_max):  # uso cnt+1\n    print(\"=\"*10, \"na_cnt {}/{}\".format(cnt+1, na_cnt_max), \"=\"*10)\n    result_f4data = copy.deepcopy(f4data)\n    for col in na_col_list:\n        print(\"=\"*10, col, \"=\"*10)\n        # split data\n        # train cnt == 0 then test cnt == 1\n        _, no_na_index = na_no_na_index_of(col, 0)  # select non na records.\n        train = f4data.loc[no_na_index]\n        na_index, _ = na_no_na_index_of(col, cnt+1)\n        if len(na_index) == 0:\n            break\n        test = f4data.loc[na_index]\n        X = train.drop(col, axis=1)\n        y = train[col]\n        X_test = test.drop(col, axis=1)\n        X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=42)\n\n        # data module\n        batch_size = min(CFG.max_batch_size, (len(X_train)+100-1)//100)  # len(X) == batch then raise errer.\n        print(\"batch_size :{}\".format(batch_size))\n        dm = DataModule(X_train, y_train, X_valid, y_valid, X_test, cnt, batch_size)\n\n        # create model\n        cur_model_name = \"model\" + model_name_prefix+\"_\" + col+ \"_\" + str(cnt)\n        dirpath = \"./model/\"\n        dnn = DNN(X_train.shape[1])\n        model = NNModel(dnn)\n\n        # train\n        logger = WandbLogger()\n        logger.log_hyperparams(CFG.__dict__)\n        callbacks = [\n                    pl.callbacks.EarlyStopping('valid_avg_loss', patience=10),  # validation_epoch_endの戻値が10ターン改善がなかったら打ち止め\n                    pl.callbacks.ModelCheckpoint(dirpath=\"./model/\", filename=cur_model_name, save_top_k=1, monitor=\"valid_avg_loss\", save_weights_only=False),  # model保存の設定\n                    pl.callbacks.LearningRateMonitor(),  # ログに学習率を吐き出す設定\n        ]\n        trainer = pl.Trainer(accelerator=\"auto\", devices=\"auto\", max_epochs=CFG.max_epochs, logger=logger, callbacks=callbacks, enable_progress_bar=False)\n        trainer.fit(model, datamodule=dm)\n        wandb.finish()\n\n        # load_best_model\n        checkpoint_path = glob.glob(dirpath+cur_model_name+\"*.ckpt\")[0]\n        model.load_from_checkpoint(checkpoint_path, model=dnn)\n        checkpoint_path_of[cur_model_name] = checkpoint_path\n\n        # predict\n        dm = DataModule(X_train, y_train, X_valid, y_valid, X_test, cnt, batch_size)\n        results = trainer.predict(model=model, datamodule=dm)\n        preds = []\n        for batch in results:\n            preds.append(batch)\n        outputs = torch.cat(preds, dim=0)\n\n        # write result\n        result_f4data.loc[na_index, col] = outputs.tolist()\n        display(result_f4data.loc[na_index, col].head())\n\n        torch.cuda.empty_cache()\n        gc.collect()\n    f4data = result_f4data\n    f4data.to_pickle(\"f4data_{}.pkl\".format(cnt))\n","metadata":{"id":"670c0a6b","outputId":"096a12f8-004d-43bf-d94a-195ee90d8c77"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.loc[:, f4data.columns] = f4data","metadata":{"id":"XvLZ1p45kVqD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"id":"1yfBoZfcHFqw","outputId":"61ce7f16-54e2-476a-8ce9-37d9c32a4e11"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind_list = []\nval_list = []\nfor i in tqdm(sub.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    val = data[col][row]\n    ind_list.append(i)\n    val_list.append(val)","metadata":{"id":"4c531db5","outputId":"b3d74d1d-1ef0-4782-fdff-06098a5b181c"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['value'].loc[ind_list] = val_list","metadata":{"id":"43c08dc7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=True)\nsub","metadata":{"id":"a2c00839","outputId":"553129d7-043e-4778-eeb7-49d92a0688a1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"TODO: fine tune版も試してみる。案外悪くないかも・・・？","metadata":{"id":"SQCR3PeCpyiV"}}]}