{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# For Google Colab\n\"\"\"\nfrom google.colab import drive\ndrive.mount('/content/drive')\n\n# Install kaggle packages\n!pip install -q kaggle\n!pip install -q kaggle-cli\n\n# Lib\nfrom google.colab import files\n\n# Please Upload `kaggle.json` file\nuploaded = files.upload()\n\n# Then copy kaggle.json into the folder where the API expects to find it.\n!mkdir -p ~/.kaggle\n!cp kaggle.json ~/.kaggle/\n!chmod 600 ~/.kaggle/kaggle.json\n!ls ~/.kaggle\n\n!kaggle competitions download -c tabular-playground-series-jun-2022\n!unzip -o tabular-playground-series-jun-2022.zip -d tabular-playground-series-jun-2022\n!kaggle kernels output ehekatlact/tps2206-lgbm-gpu-loop -p ./DataSet\n\"\"\"","metadata":{"id":"ZdIlm7aF1a4p","outputId":"0aa35d60-f5a1-4e9c-f535-6d3509ca94a7","execution":{"iopub.status.busy":"2022-06-05T09:16:26.161767Z","iopub.execute_input":"2022-06-05T09:16:26.162306Z","iopub.status.idle":"2022-06-05T09:16:26.191994Z","shell.execute_reply.started":"2022-06-05T09:16:26.162167Z","shell.execute_reply":"2022-06-05T09:16:26.191299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install wandb\n!pip install pytorch_lightning","metadata":{"id":"WzvlFx3vVi0Q","execution":{"iopub.status.busy":"2022-06-05T09:16:26.366359Z","iopub.execute_input":"2022-06-05T09:16:26.366756Z","iopub.status.idle":"2022-06-05T09:16:46.766434Z","shell.execute_reply.started":"2022-06-05T09:16:26.366726Z","shell.execute_reply":"2022-06-05T09:16:46.765368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import wandb\n\ntry:\n    # add-ons -> secrets -> set your wandb api key\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"wandb_api\")\n    wandb.login(key=secret_value_0)\n    anony = None\nexcept:\n    anony = \"must\"\n    print('If you want to use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:16:46.768716Z","iopub.execute_input":"2022-06-05T09:16:46.769123Z","iopub.status.idle":"2022-06-05T09:16:49.003057Z","shell.execute_reply.started":"2022-06-05T09:16:46.769079Z","shell.execute_reply":"2022-06-05T09:16:49.002238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lib","metadata":{"id":"4Au-x_kJXiGb"}},{"cell_type":"code","source":"# common\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nimport time, gc, string, math\nfrom tqdm.notebook import tqdm\nimport warnings\nimport shutil\nfrom collections import defaultdict\n\n# sklearn\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\n\n# pytorch\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch import optim\nfrom torch.optim import lr_scheduler\n\n# pytorch lightning\nimport pytorch_lightning as pl\nfrom pytorch_lightning.loggers import WandbLogger\n","metadata":{"id":"5f9dMGLCVShc","execution":{"iopub.status.busy":"2022-06-05T09:16:49.004584Z","iopub.execute_input":"2022-06-05T09:16:49.005251Z","iopub.status.idle":"2022-06-05T09:16:55.659241Z","shell.execute_reply.started":"2022-06-05T09:16:49.005209Z","shell.execute_reply":"2022-06-05T09:16:55.658446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.makedirs('model', exist_ok=True)\nshutil.rmtree('./model/')\nos.makedirs('model', exist_ok=True)","metadata":{"id":"dZXaNvKR68Wo","execution":{"iopub.status.busy":"2022-06-05T09:16:55.661384Z","iopub.execute_input":"2022-06-05T09:16:55.661876Z","iopub.status.idle":"2022-06-05T09:16:55.665948Z","shell.execute_reply.started":"2022-06-05T09:16:55.66185Z","shell.execute_reply":"2022-06-05T09:16:55.665264Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Read DF","metadata":{"id":"7uSkdpFKXk9V"}},{"cell_type":"code","source":"data = pd.read_csv('../input/tabular-playground-series-jun-2022/data.csv')\nsub = pd.read_csv('../input/tabular-playground-series-jun-2022/sample_submission.csv', index_col='row-col')","metadata":{"id":"O5rX6G7EVhEk","execution":{"iopub.status.busy":"2022-06-05T09:16:55.667242Z","iopub.execute_input":"2022-06-05T09:16:55.667623Z","iopub.status.idle":"2022-06-05T09:17:12.541583Z","shell.execute_reply.started":"2022-06-05T09:16:55.667587Z","shell.execute_reply":"2022-06-05T09:17:12.540748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"na_columns_list = data.columns.to_list()\n# Process from columns with high NA\nna_columns_list.sort(key=lambda x: data[x].isna().sum(), reverse=True)\nwhile data[na_columns_list[-1]].isna().sum() == 0:\n    na_columns_list.pop()","metadata":{"id":"iBORPeLAKnFU","execution":{"iopub.status.busy":"2022-06-05T09:17:12.543077Z","iopub.execute_input":"2022-06-05T09:17:12.543453Z","iopub.status.idle":"2022-06-05T09:17:12.718038Z","shell.execute_reply.started":"2022-06-05T09:17:12.543417Z","shell.execute_reply":"2022-06-05T09:17:12.717189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"missing_list_of = {}\nno_missing_list_of = {}\nfor col in na_columns_list:\n    missing_list = list(np.where(data[col].isnull())[0])\n    no_missing_list = list(np.where(data[col].isnull() == False)[0])\n    missing_list_of[col] = missing_list\n    no_missing_list_of[col] = no_missing_list","metadata":{"id":"4MOa8LlcK2Qa","execution":{"iopub.status.busy":"2022-06-05T09:17:12.719539Z","iopub.execute_input":"2022-06-05T09:17:12.719923Z","iopub.status.idle":"2022-06-05T09:17:17.584446Z","shell.execute_reply.started":"2022-06-05T09:17:12.719887Z","shell.execute_reply":"2022-06-05T09:17:17.583576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nnon_na_columns = []\nfor col in data.columns:\n    if data[col].isna().sum() == 0:\n        non_na_columns.append(col)\n\ndata[non_na_columns] = scaler.fit_transform(data[non_na_columns])","metadata":{"id":"nyxtkp59BOj-","execution":{"iopub.status.busy":"2022-06-05T09:17:17.585858Z","iopub.execute_input":"2022-06-05T09:17:17.58649Z","iopub.status.idle":"2022-06-05T09:17:19.238244Z","shell.execute_reply.started":"2022-06-05T09:17:17.586448Z","shell.execute_reply":"2022-06-05T09:17:19.237436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"other_sub = pd.read_csv(\"../input/tps2206-lgbm-gpu-loop/submission.csv\", index_col='row-col')","metadata":{"id":"LBHXaIpRElgR","execution":{"iopub.status.busy":"2022-06-05T09:17:19.239532Z","iopub.execute_input":"2022-06-05T09:17:19.239979Z","iopub.status.idle":"2022-06-05T09:17:20.378674Z","shell.execute_reply.started":"2022-06-05T09:17:19.239933Z","shell.execute_reply":"2022-06-05T09:17:20.377852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"other_sub_dic = defaultdict(list)\nfor i in tqdm(other_sub.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    val = other_sub.loc[i, 'value']\n    other_sub_dic[col].append((row, val))\n\nfor col in tqdm(data.columns):\n    if not other_sub_dic[col]:\n        continue\n    index_value_list = other_sub_dic[col]\n    index_list = []\n    value_list = []\n    for index, value in index_value_list:\n        index_list.append(index)\n        value_list.append(value)\n    data[col].loc[index_list] = value_list","metadata":{"id":"ymHE76tXFW2S","outputId":"2dd5a721-4862-45b9-c335-5e67d9833881","execution":{"iopub.status.busy":"2022-06-05T09:17:20.381522Z","iopub.execute_input":"2022-06-05T09:17:20.381902Z","iopub.status.idle":"2022-06-05T09:17:36.876722Z","shell.execute_reply.started":"2022-06-05T09:17:20.381864Z","shell.execute_reply":"2022-06-05T09:17:36.875821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Pytorch","metadata":{"id":"3GFlnTVdX6Kd"}},{"cell_type":"code","source":"class CFG:\n    num_workers = 2\n    weight_decay=1e-6\n    scheduler_type=\"ReduceLR\"\n    print_epoch_freq=1\n    max_epochs=120\n    batch_size=1000\n    lr = 1e-2\n    debug = False\n\nif CFG.debug:\n    CFG.max_epochs=1\n    na_columns_list = na_columns_list[:2]","metadata":{"id":"IeoxXToDY-FH","execution":{"iopub.status.busy":"2022-06-05T09:17:36.878019Z","iopub.execute_input":"2022-06-05T09:17:36.878461Z","iopub.status.idle":"2022-06-05T09:17:36.884915Z","shell.execute_reply.started":"2022-06-05T09:17:36.878424Z","shell.execute_reply":"2022-06-05T09:17:36.884027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### DataSet and DataLoader","metadata":{"id":"8NiVYTi0YJkd"}},{"cell_type":"code","source":"class TrainDataset(Dataset):\n    def __init__(self, X_train, y_train):\n        self.X = X_train\n        if y_train is not None:\n            self.y = y_train\n        else:\n            self.y = torch.zeros(len(self.X), dtype=torch.float) \n\n    def __len__(self):\n        return len(self.X)\n\n    def __getitem__(self, item):\n        inputs = torch.tensor(self.X[item], dtype=torch.float32)\n        if self.y is None:\n            outputs = None\n        else:\n            outputs = torch.tensor(self.y[item], dtype=torch.float32)\n\n        return inputs, outputs","metadata":{"id":"zvlzv7KbYIJM","execution":{"iopub.status.busy":"2022-06-05T09:17:36.886674Z","iopub.execute_input":"2022-06-05T09:17:36.887061Z","iopub.status.idle":"2022-06-05T09:17:36.896365Z","shell.execute_reply.started":"2022-06-05T09:17:36.887022Z","shell.execute_reply":"2022-06-05T09:17:36.89545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataModule(pl.LightningDataModule):\n    # train, val, testの3つのDataLoaderを定義する\n    # trainerにこれを渡すと、train, val, testのそれぞれのステップでこれを渡してくれる\n    def __init__(self, X_train, y_train, X_valid, y_valid, X_test, batch_size):\n        self.X_train = X_train.values\n        self.X_valid = X_valid.values\n        self.X_test = X_test.values\n        self.Y_train = y_train.values\n        self.Y_valid = y_valid.values\n        self.Y_test = None\n        self.batch_size = batch_size\n        self._log_hyperparams = None  # ナニコレ・・・\n\n    def train_dataloader(self):\n        ds = TrainDataset(self.X_train, self.Y_train)\n        dl = DataLoader(ds, batch_size=self.batch_size, shuffle=True, pin_memory=True, drop_last=True, num_workers=CFG.num_workers, persistent_workers=True)\n        return dl\n\n    def val_dataloader(self):\n        ds = TrainDataset(self.X_valid, self.Y_valid)\n        dl = DataLoader(ds, batch_size=self.batch_size, shuffle=False, pin_memory=True, drop_last=True, num_workers=CFG.num_workers, persistent_workers=True)\n        return dl\n\n    def predict_dataloader(self):\n        ds = TrainDataset(self.X_test, self.Y_test)\n        dl = DataLoader(ds, batch_size=self.batch_size, shuffle=False, pin_memory=True, drop_last=True, num_workers=CFG.num_workers, persistent_workers=True)\n        return dl\n\n    def prepare_data_per_node(self):\n        # TODO 本来要らないはずなんだけど・・・\n        pass\n\n    def teardown(self, stage=None):\n        self.X_train = None\n        self.X_valid = None\n        self.X_test = None\n        torch.cuda.empty_cache()  # TODO: これであってるのか不明　何も出てこないんだよね\n        gc.collect()","metadata":{"id":"WghSjRGhYiI1","execution":{"iopub.status.busy":"2022-06-05T09:17:36.897914Z","iopub.execute_input":"2022-06-05T09:17:36.898571Z","iopub.status.idle":"2022-06-05T09:17:36.911688Z","shell.execute_reply.started":"2022-06-05T09:17:36.898525Z","shell.execute_reply":"2022-06-05T09:17:36.910967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Pytorch Model","metadata":{"id":"UsbohQXZZXts"}},{"cell_type":"code","source":"class DNN(nn.Module):\n    def __init__(self, model_name, input_size):\n        self.name = model_name\n        super().__init__()\n        self.fc1 = nn.Linear(input_size, 512)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.fc2 = nn.Linear(512, 256)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.fc3 = nn.Linear(256, 128)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.fc4 = nn.Linear(128, 64)\n        self.bn4 = nn.BatchNorm1d(64)\n        self.fc5 = nn.Linear(64, 32)\n        self.bn5 = nn.BatchNorm1d(32)\n        self.fc6 = nn.Linear(32, 1)\n        self.bn6 = nn.BatchNorm1d(1)\n    \n    def forward(self, x):\n        # dropoutとbnの併用禁止\n        # bnは活性化関数の前に\n        x = F.silu(self.bn1((self.fc1(x))))\n        x = F.silu(self.bn2((self.fc2(x))))\n        x = F.silu(self.bn3((self.fc3(x))))\n        x = F.silu(self.bn4((self.fc4(x))))\n        x = F.silu(self.bn5((self.fc5(x))))\n        x = self.bn6((self.fc6(x)))\n        return x","metadata":{"id":"xRkralqKZZoF","execution":{"iopub.status.busy":"2022-06-05T09:17:36.913606Z","iopub.execute_input":"2022-06-05T09:17:36.913864Z","iopub.status.idle":"2022-06-05T09:17:36.92871Z","shell.execute_reply.started":"2022-06-05T09:17:36.91384Z","shell.execute_reply":"2022-06-05T09:17:36.927911Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RMSELoss(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        \n    def forward(self,yhat,y):\n        return torch.sqrt(self.mse(yhat,y))","metadata":{"id":"RU5QCeb64Br6","execution":{"iopub.status.busy":"2022-06-05T09:17:36.931254Z","iopub.execute_input":"2022-06-05T09:17:36.931896Z","iopub.status.idle":"2022-06-05T09:17:36.939554Z","shell.execute_reply.started":"2022-06-05T09:17:36.931855Z","shell.execute_reply":"2022-06-05T09:17:36.938704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class NNModel(pl.LightningModule):\n    def __init__(self, model: nn.Module):\n        super().__init__()\n        self.model = model\n        self.criterion = RMSELoss()\n\n    def forward(self, x) -> torch.Tensor:\n        return self.model(x)\n\n    # Setup Optimizer and Scheduler\n    def configure_optimizers(self):\n        model_params = [p for n, p in self.model.named_parameters()]\n        # decoder_params = [p for n, p in self.decoder.named_parameters()]\n        optimizer_params = [\n            {\"params\":  model_params,\n             \"weight_decay\": CFG.weight_decay,\n             \"lr\": CFG.lr\n            },\n        ]\n        optimizer = optim.Adam(optimizer_params)\n\n        monitor = \"\"\n        if CFG.scheduler_type == \"StepLR\":\n            # 一定stepごとに学習率を引き下げる\n            scheduler = lr_scheduler.StepLR(optimizer, step_size=10_000, gamma=0.9)\n            interval = \"step\"\n        elif CFG.scheduler_type == \"Cosine\":\n            # 一定step単位で周期的に学習率を増減させる\n            scheduler = lr_scheduler.CosineAnnealingLR(optimizer,\n                                                    T_max=1000,\n                                                    eta_min=1e-5,\n                                                    )\n            interval = \"step\"\n        elif CFG.scheduler_type == \"ReduceLR\":\n            # 一定epoch、valid_lossが改善しない場合、学習率を引き下げる\n            scheduler = lr_scheduler.ReduceLROnPlateau(optimizer,\n                                        'min',\n                                        patience=1,\n                                        factor=0.5\n                                        )\n            interval = \"epoch\"\n            monitor = \"valid_avg_loss\"\n        else:\n            print(\"scheduler_type\", CFG.scheduler_type, \"is wrong\")\n            raise \"not defined scheduler_type\"\n        return [optimizer],  [{\"scheduler\": scheduler, \"interval\": interval, \"monitor\": monitor}]\n\n    # training valid test steps\n    def training_step(self, batch_data, batch_idx):\n        # batch_data: DataModuleで定義したtrain_dataloaderの結果\n        # 戻値: lossであることが必須(裏でoptimizerに渡すため)\n        X, y = batch_data\n        outputs = self(X).squeeze()\n        loss = self.criterion(outputs, y)\n        return loss\n\n    def training_epoch_end(self, outputs):\n        # 1epoch分の処理(全バッチの処理)のreturn値をlistで受け取る\n        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n        self.log('train_avg_loss', avg_loss, prog_bar=True)\n        if (self.current_epoch+1) % CFG.print_epoch_freq == 0:\n            print(\"epoch:\", self.current_epoch, \"train_avg_loss:\", avg_loss.item())\n\n    def validation_step(self, batch_data, batch_idx):\n        # 戻値: 任意の辞書\n        X, y = batch_data\n        outputs = self(X).squeeze()\n        loss = self.criterion(outputs, y)\n        # outputs = torch.sigmoid(outputs)  # criterionがwithloss系の時はsigmoid掛ける\n        return {'valid_loss': loss}\n\n    def validation_epoch_end(self, outputs):\n        # validation_stepの戻値をリストで受け取る\n        avg_loss = torch.stack([x['valid_loss'] for x in outputs]).mean()\n        self.log('valid_avg_loss', avg_loss, prog_bar=True)\n        if (self.current_epoch+1) % CFG.print_epoch_freq == 0:\n            print(\"epoch:\", self.current_epoch, \"valid_avg_loss:\", avg_loss.item())\n        return avg_loss\n\n    def predict_step(self, batch_data, batch_idx):\n        # 実際に予測させるときに使う\n        X, _ = batch_data\n        outputs = self(X).squeeze()\n        # criterionがwithLogit系の場合は、sigmoidを追加する。\n        # outputs = torch.sigmoid(outputs)\n        return outputs","metadata":{"id":"kyUqJyQwazB-","execution":{"iopub.status.busy":"2022-06-05T09:17:36.941104Z","iopub.execute_input":"2022-06-05T09:17:36.941761Z","iopub.status.idle":"2022-06-05T09:17:36.961617Z","shell.execute_reply.started":"2022-06-05T09:17:36.941708Z","shell.execute_reply":"2022-06-05T09:17:36.960923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport time\n\nst_time = time.time()\nfor i, col in enumerate(na_columns_list):\n    print(\"=\"*10, col, \"=\"*10)\n    print(\"{}/{}\".format(i+1, len(na_columns_list)))\n    if \"F_4\" not in col:\n        print(\"skip {}\".format(col))\n        continue\n\n    # split data\n    missing_list = missing_list_of[col]\n    no_missing_list = no_missing_list_of[col]\n\n    train = data.iloc[no_missing_list,]\n    test = data.iloc[missing_list,]\n    X = train.drop([col,'row_id'],axis=1)\n    y = train[col]\n    X_test = test.drop([col,'row_id'],axis=1)\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, random_state=42)\n    dm = DataModule(X_train, y_train, X_valid, y_valid, X_test, CFG.batch_size)\n\n    model_name = \"name\" + col\n    dirpath = \"./model/\"\n    dnn = DNN(model_name, len(X_train.columns))\n    model = NNModel(dnn)\n\n    # train\n    logger = WandbLogger()\n    logger.log_hyperparams(CFG.__dict__)\n    callbacks = [\n                pl.callbacks.EarlyStopping('valid_avg_loss', patience=3),  # validation_epoch_endの戻値が10ターン改善がなかったら打ち止め\n                pl.callbacks.ModelCheckpoint(dirpath=\"./model/\", filename=model_name, save_top_k=1, monitor=\"valid_avg_loss\"),  # model保存の設定\n                pl.callbacks.LearningRateMonitor(),  # ログに学習率を吐き出す設定\n    ]\n    trainer = pl.Trainer(accelerator=\"auto\", devices=\"auto\", max_epochs=CFG.max_epochs, logger=logger, callbacks=callbacks, enable_progress_bar=False)\n    trainer.fit(model, datamodule=dm)\n\n    # predict\n    checkpoint = torch.load(dirpath+model_name+\".ckpt\")\n    model.load_state_dict(checkpoint['state_dict'])\n    dm = DataModule(X_train, y_train, X_valid, y_valid, X_test, CFG.batch_size)\n    results = trainer.predict(model=model, datamodule=dm)\n    preds = []\n    for batch in results:\n        preds.append(batch)\n    outputs = torch.cat(preds, dim=0)\n\n    data_all = data[col].iloc[missing_list,] = outputs.tolist()\n\n    en_time = time.time()\n    print(\"elapse\", en_time-st_time)\n    gc.collect()","metadata":{"id":"iSbizTLh4wSY","outputId":"ce5afc5a-4e98-4ccd-f1f3-6824f927cdfe","execution":{"iopub.status.busy":"2022-06-05T09:17:36.963203Z","iopub.execute_input":"2022-06-05T09:17:36.96386Z","iopub.status.idle":"2022-06-05T09:18:20.618219Z","shell.execute_reply.started":"2022-06-05T09:17:36.96382Z","shell.execute_reply":"2022-06-05T09:18:20.617146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind_list = []\nval_list = []\nfor i in tqdm(sub.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    val = data[col][row]\n    ind_list.append(i)\n    val_list.append(val)","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:28:14.295538Z","iopub.execute_input":"2022-06-05T09:28:14.29622Z","iopub.status.idle":"2022-06-05T09:28:23.563718Z","shell.execute_reply.started":"2022-06-05T09:28:14.296181Z","shell.execute_reply":"2022-06-05T09:28:23.56295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['value'].loc[ind_list] = val_list","metadata":{"execution":{"iopub.status.busy":"2022-06-05T09:28:23.56534Z","iopub.execute_input":"2022-06-05T09:28:23.566135Z","iopub.status.idle":"2022-06-05T09:28:24.293141Z","shell.execute_reply.started":"2022-06-05T09:28:23.566094Z","shell.execute_reply":"2022-06-05T09:28:24.291865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=True)\nsub","metadata":{"id":"_eRdDcjh1pqq","execution":{"iopub.status.busy":"2022-06-05T09:28:24.294377Z","iopub.execute_input":"2022-06-05T09:28:24.294826Z","iopub.status.idle":"2022-06-05T09:28:27.659505Z","shell.execute_reply.started":"2022-06-05T09:28:24.294787Z","shell.execute_reply":"2022-06-05T09:28:27.658734Z"},"trusted":true},"execution_count":null,"outputs":[]}]}