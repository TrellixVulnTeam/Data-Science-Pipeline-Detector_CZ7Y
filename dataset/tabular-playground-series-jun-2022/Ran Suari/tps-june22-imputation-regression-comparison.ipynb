{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom random import choices,choice\nimport catboost as cb \nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.impute import SimpleImputer\nfrom lightgbm import LGBMRegressor\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-16T16:26:44.917421Z","iopub.execute_input":"2022-06-16T16:26:44.917881Z","iopub.status.idle":"2022-06-16T16:26:47.034618Z","shell.execute_reply.started":"2022-06-16T16:26:44.917843Z","shell.execute_reply":"2022-06-16T16:26:47.031857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2022/data.csv\")\nsample = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv\")\ndf_toy = df.sample(frac = 0.01, random_state=1)  #used for quick testing during writing the code\nwith pd.option_context('display.max_columns', 90):\n    display (df)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:26:47.036765Z","iopub.execute_input":"2022-06-16T16:26:47.037231Z","iopub.status.idle":"2022-06-16T16:27:07.838526Z","shell.execute_reply.started":"2022-06-16T16:26:47.03718Z","shell.execute_reply":"2022-06-16T16:27:07.837595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### EDA Summary\nPrevious great notebooks have shown the main insights regarding the data: \n * There are 4 main Feature groups F_1 - F_4.\n * F_2 contains descrete values with 15-35 values per feature and doesn't contain any missing values.\n * F_1 and F_3 - each feature shows no correlation to other features \n * F_4 shows good correlation between features.\n * The NA's are randomly distributed in the data (rows and cols wise).\n \n","metadata":{}},{"cell_type":"code","source":"#Some subset of the columns for future use\ncont_cols = [df.columns[i] for i,typ in enumerate(df.dtypes) if str(typ) == 'float64']\nF_4_cols = [col for col in cont_cols if col.find(\"F_4\") != -1]\nF_13_cols = [col for col in cont_cols if col not in F_4_cols]\nF_2_cols = [col for col in df.columns if col.find(\"F_2\") != -1]\nint_cols = [i for i,typ in enumerate(df.dtypes) if str(typ) == 'int64'][1:]\noutput_cols = cont_cols + [\"row_id\"]","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:27:07.84087Z","iopub.execute_input":"2022-06-16T16:27:07.841278Z","iopub.status.idle":"2022-06-16T16:27:07.851143Z","shell.execute_reply.started":"2022-06-16T16:27:07.841245Z","shell.execute_reply":"2022-06-16T16:27:07.850003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a sample format output\ndef return_melted_res(df, val = \"\"):\n    '''\n    transform df to melted/long format, similar to the submission file\n    '''\n    if val : val = \"_\" + val\n    return (df\n         .loc[:,output_cols]\n         .melt(id_vars = ['row_id'])\n         .assign(row_col = lambda df : df\n                    .row_id.astype(str).str.cat(df.variable, sep = \"-\")) #generate row_col column\n         .loc[:,['value', 'row_col']] #keep only value and row_col columns\n         .reindex(columns = ['row_col','value']) #Change col order\n         .rename (columns  = {\"row_col\": \"row-col\", \"value\": f'value{val}'}) #rename columns\n    )\nreturn_melted_res(df_toy, \"Test_Toy\").head(3)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:27:07.852625Z","iopub.execute_input":"2022-06-16T16:27:07.853191Z","iopub.status.idle":"2022-06-16T16:27:08.882076Z","shell.execute_reply.started":"2022-06-16T16:27:07.853127Z","shell.execute_reply":"2022-06-16T16:27:08.880967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Defining some helper functions\nFor testing and validation I created the following function that sample the Dataframe and add a random NA to one of the columns in each row.\nlater we will be able to compare the predicted value to the original value for accuracy calculations.\nSince we adding NA's, the results are expected to be slightly worse compared to final training but shouldn't change the big picture and give us easy way to check our model.\nfor simplicity I decided to go for this direction instead of splitting the data to train/validaion. ","metadata":{}},{"cell_type":"code","source":"def return_train_vals (df_train_orig, df_train):\n    '''\n    Get the training data before and after adding NA's\n    return in long/submission format only the added NA's with the original value\n    '''\n    return (df_train_orig\n     .pipe(return_melted_res) #switch to long/submission format\n     .query(f'~{\"value\"}.isna()', engine='python') #keep only non NA\n     .merge ((df_train\n                       .pipe(return_melted_res)\n                       .query(f'{\"value\"}.isna()', engine='python'))\n             , left_on =\"row-col\", right_on = \"row-col\", how = 'inner'\n            )\n     .drop(columns = \"value_y\")\n     .rename (columns = {\"value_x\":\"value\"})\n                       )\n             \n    \n\ndef get_train_subset(df, f = 0.1, sample = True):\n    ''' Sample the DataFrame and add random NA's to cont_columns\n        return (df_train_vals with the original values at long format,\n                the train dataframe with the new random NA's)\n        \n    '''\n    if sample: df = df.sample(frac = f, random_state=1)\n    else: df = df.loc[:int(df.shape[0]*f),:]\n    df_ = df.copy()\n    \n    nrows = df_.shape[0]\n    rows_update = choices (df_.index.values, k=nrows)\n    \n    for row in rows_update:\n        df_.loc[row,choice(cont_cols)] = np.nan\n    \n    df_train_vals = return_train_vals(df,df_)\n    \n    return df_train_vals,df_\n\nprint (f'Before: {df_toy.isna().mean().head(3)}, After : {get_train_subset(df_toy)[1].isna().mean().head(3)}')\nprint (f'Long format of the original values that Will be used for accuraccy:\\n {get_train_subset(df_toy)[0].head(3)}')","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:27:08.883715Z","iopub.execute_input":"2022-06-16T16:27:08.884006Z","iopub.status.idle":"2022-06-16T16:27:09.82566Z","shell.execute_reply.started":"2022-06-16T16:27:08.88398Z","shell.execute_reply":"2022-06-16T16:27:09.824625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will also add addition function to calculate the MSE of the models prediction based on the prediction of the generated NA's, which we know what was the actual values.\nSince I wanted to compare the results between different features, I normalized the MSE (NRMSE) by divide the RMSE by the range of that feature.\n\nWe know that there is a major difference between F_1 + F_3 to the F_4, I assumed we will need different model for each group of features.\n","metadata":{}},{"cell_type":"code","source":"def calc_MSE(df_preds,df_train_vals):\n    '''\n    Receive three Dataframes in melt format\n    df_preds - current predicition\n    df_train_vals - dataframe with the added NA's cells with the original values\n    \n    return MSE of predicted values and original values'''\n    \n    df_acc = (df_preds\n         .merge(df_train_vals)\n    )\n\n    return df_acc, mean_squared_error (df_acc.value_preds.values,df_acc.value.values)\n\ndef calc_MSE_group (df_, col_name):\n    '''\n    Calculate the NRMSE for each column\n    the RMSE is normalized by the columns range\n    '''\n    return (df_\n     .rename (columns = {\"row-col\":\"row_col\"})\n     .assign (row = lambda df_ : df_.row_col.str.split(\"-\", expand = True)[0],\n              col = lambda df_ : df_.row_col.str.split(\"-\", expand = True)[1],\n              ss = lambda df_ : (df_.value - df_.value_preds)**2\n             )\n     .groupby(by = 'col')\n     .agg( ss_mean =( 'ss' , np.mean ) , val_max =( 'value' , max ) ,val_min =( 'value' , min ))\n     .assign (NRMSE = lambda df: (df.ss_mean)**0.5/((df.val_max)-df.val_min))\n     .rename (columns = {\"NRMSE\" : \"NRMSE_\" + col_name})\n     .sort_index()\n     .loc[:,\"NRMSE_\" + col_name]\n     .to_frame()\n           )\n\ndef get_mse_from_trained(df_train_vals,df_F4_trained,df_F13_trained, name = \"Train_Res\"):\n    '''\n    get three dataframes as input and return the MSE\n    df_train - current subset we work on\n    df_F4_trained - the trained DF of F4 columns (including row id)\n    df_13_trained - the trained DF of F13 columns\n    \n    output the MSE score of current training and NRMSE per feature\n    '''\n    df_trained = pd.concat([df_F4_trained, df_F13_trained], axis = 1)\n    df_trained_melt = return_melted_res(df_trained, \"preds\")\n    \n    df_mse_trained, mse_trained = calc_MSE (df_trained_melt,df_train_vals)\n    df_NRMSE_per_grop = calc_MSE_group(df_mse_trained, name)\n    print (f'MSE of Prediction is {mse_trained}')\n    \n    return df_NRMSE_per_grop, mse_trained","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:27:09.82691Z","iopub.execute_input":"2022-06-16T16:27:09.827198Z","iopub.status.idle":"2022-06-16T16:27:09.839487Z","shell.execute_reply.started":"2022-06-16T16:27:09.82717Z","shell.execute_reply":"2022-06-16T16:27:09.838569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## And lets add some model functions\n\nThe code for using GBM for calculating missing values is from the great effective pandas book by Matt Harrison.\nit shows elegant way to impute the missing values based on other feature.\nSince F_4 features show strong correlation to each other, we will want to use this model for it.\nI added option to use either LGBM or CatBoost regressors.\n\nAnd I also added SKLearn Simple Imputer for F_1 and F_3 features (for now).","metadata":{}},{"cell_type":"code","source":"\ndef prep_for_ml(df):\n    return (df\n               .assign(**{col:df[col].astype(float) for col in df.select_dtypes('number')},\n                      **{col:df[col].astype(str).fillna('') for col in df.select_dtypes(['object','category'])})\n           )\n\ndef predict_col(df_,col,iters, modelType = \"CatBoost\"):\n    '''\n    Predict NAs based on other features and return the updated column\n    '''\n    df_ = prep_for_ml(df_)\n    print(col)\n    missing = df_.query(f'~{col}.isna()', engine='python')\n    cat_idx = [i for i,typ in enumerate(df_.drop(columns = [col]).dtypes) if str(typ) == 'int64'][1:]\n    X = (missing\n            .drop(columns = [col])\n            .values\n        )\n    y = missing[col]\n    \n    if modelType == \"CatBoost\":\n        model = cb.CatBoostRegressor(iterations = iters, cat_features = cat_idx, logging_level= \"Silent\")\n        model.fit (X, y, cat_features = cat_idx)\n    else:\n        model = LGBMRegressor(n_estimators=iters,metric='r2')\n        model.fit (X, y)\n        \n    print (f'Col: {col}, Score: {model.score(X,y)}')\n    pred = model.predict(df_.drop(columns = [col]))\n    return df_[col].where (~df_[col].isna(), pred)\n\ndef train_GBM(df,iters,col_names, modelType):\n    '''\n    Iterate through col_names and update NA's with predicted values\n    '''\n    df_cat = (df[col_names]\n                  .copy(deep = True)\n             )\n    for c,col in enumerate(col_names):\n        df_cat.loc[:,col] = predict_col(df_cat,col,iters,modelType)\n        print (f'finished col {c} out of {len(col_names)}')\n    \n    df_cat.row_id = df_cat.row_id.astype('int64')\n    return df_cat\n\n\n    '''\n    use SKLearn to return the imputed mean value\n    '''\ndef train_impute(df,col_names, strategy = \"mean\"):\n    df_imp = df[col_names].copy(deep = True)\n    imp = SimpleImputer(\n            missing_values=np.nan,\n            strategy=strategy) \n    \n\n    df_imp[:] = imp.fit_transform(df_imp[col_names])\n    return df_imp","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:27:16.256547Z","iopub.execute_input":"2022-06-16T16:27:16.257012Z","iopub.status.idle":"2022-06-16T16:27:16.273835Z","shell.execute_reply.started":"2022-06-16T16:27:16.256977Z","shell.execute_reply":"2022-06-16T16:27:16.272862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Finally, let's train a model and see some results","metadata":{}},{"cell_type":"code","source":"df_train_vals ,df_train = get_train_subset(df, f=0.01)\n\n# ************************************************ #\ndf_F4_trained = train_GBM(df_train, iters = 200, col_names = F_4_cols + [\"row_id\"], modelType = \"CatBoost\")\ndf_F13_trained = train_impute(df_train,F_13_cols, strategy = \"mean\")\n\n\ndf_NRMSE_per_grop,mse_trained = get_mse_from_trained(df_train_vals,df_F4_trained,df_F13_trained, \"test1_F13_MeanImpute_F4_Catboost_200iters\")\ndf_NRMSE_per_grop.to_csv('Training_test1.csv',index = True)\n\n# # ************************************************ #\n\ndf_F4_trained = train_GBM(df_train, iters = 2000, col_names = F_4_cols + [\"row_id\"], modelType = \"CatBoost\")\ndf_F13_trained = train_impute(df_train,F_13_cols, strategy = \"median\")\n\n\ndf_NRMSE_per_grop,mse_trained = get_mse_from_trained(df_train_vals,df_F4_trained,df_F13_trained, \"test2_F13_MedianImpute_F4_Catboost_2000iters\")\ndf_NRMSE_per_grop.to_csv('Training_test2.csv',index = True)\n\n# ************************************************ #\n\ndf_train_vals ,df_train = get_train_subset(df, f=0.01, sample = False) \n\ndf_F4_trained = train_GBM(df_train, iters = 20, col_names = F_4_cols + [\"row_id\"], modelType = \"LGBMRegressor\")\ndf_F13_trained = df_train[F_13_cols].fillna(method='ffill').fillna(0)\n\n\ndf_NRMSE_per_grop,mse_trained = get_mse_from_trained(df_train_vals,df_F4_trained,df_F13_trained, \"test3_F13_FFill_F4_LGBM_20estimators\")\ndf_NRMSE_per_grop.to_csv('Training_test3.csv',index = True)\n\n# # ************************************************ #\n# df_train_vals ,df_train = get_train_subset(df, f=0.01, sample = True) \n\n# df_F4_trained = train_GBM(df_train, iters = 20000, col_names = F_4_cols + [\"row_id\"], modelType = \"LGBMRegressor\")\n# df_F13_trained = train_impute(df_train,F_13_cols, strategy = \"mean\")\n\n\n# df_NRMSE_per_grop,mse_trained = get_mse_from_trained(df_train_vals,df_F4_trained,df_F13_trained, \"test4_F13_Mean_F4_LGBM_20000estimators\")\n# df_NRMSE_per_grop.to_csv('Training_test4.csv',index = True)\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-16T16:27:21.416703Z","iopub.execute_input":"2022-06-16T16:27:21.417119Z","iopub.status.idle":"2022-06-16T16:29:42.369654Z","shell.execute_reply.started":"2022-06-16T16:27:21.417083Z","shell.execute_reply":"2022-06-16T16:29:42.368679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# res_list = [\"Training_test1.csv\",\"Training_test2.csv\",\"Training_test3.csv\",\"Training_test4.csv\"]\nres_list = [\"Training_test1.csv\",\"Training_test2.csv\",\"Training_test3.csv\"]\nres_dfs = [pd.read_csv(cur_df,index_col = \"col\") for cur_df in res_list]\nres_df_all = pd.concat(res_dfs, axis = 1)\n\nfig,ax = plt.subplots(dpi = 600, figsize = (10,5))\nplt.xticks(np.arange(len(res_df_all.index)), label =res_df_all.index )\n\nres_df_all.plot(kind = 'line', ax=ax, linewidth = 2)\n\nplt.xticks(rotation = 90 )\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:29:42.371314Z","iopub.execute_input":"2022-06-16T16:29:42.37166Z","iopub.status.idle":"2022-06-16T16:29:44.17233Z","shell.execute_reply.started":"2022-06-16T16:29:42.371628Z","shell.execute_reply":"2022-06-16T16:29:44.171633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions \nF_1 and F_3:\n* columns we can't see a difference between mean and median impute. \n* all the columns shows similar NRMSE accuracy.\n* Forward Fill shows surprisingly bad results.\n\nF_4 : \n* we can clearly see the regression models find good predictions. \n* We expect that the higher the regression depth/iterations the better the prediction will be, but we don't see it on this subset of data. we might need to use larger subset.\n* LGBM shows slightly better performance compared to the Catboost\n* for sure further parameter optimization will improve the performance on both models.","metadata":{"execution":{"iopub.status.busy":"2022-06-16T08:42:35.795374Z","iopub.execute_input":"2022-06-16T08:42:35.796285Z","iopub.status.idle":"2022-06-16T08:42:35.804518Z","shell.execute_reply.started":"2022-06-16T08:42:35.796247Z","shell.execute_reply":"2022-06-16T08:42:35.803695Z"}}},{"cell_type":"markdown","source":"# Prepare submission","metadata":{}},{"cell_type":"code","source":"def prepare_submission (df_F4_trained,df_F13_trained,sample):\n    '''\n    get Trained DFs for F_4 cols and F1 + F3 columns and return the result in submission format\n    '''\n    df_trained = pd.concat([df_F4_trained, df_F13_trained], axis = 1)\n    # This method works faster compared to a for loop but require more memory then available by kaggle\n    # We first remove all the lines without NA since they are not part of the submission file\n    df_trained = df_trained[df.isna().sum(axis=1) != 0]\n        \n    df_trained_melted = return_melted_res(df_trained, \"preds\")\n    print (\"Finish Melting, Start merge\")\n    \n    return (sample\n        .drop(axis =1 , columns =['value'])\n        .merge(df_trained_melted)\n        .rename (columns = {'value_preds':'value'}))\n\n    \n\n\n\n\ndf_F4_trained = train_GBM(df, iters = 20, col_names = F_4_cols + [\"row_id\"], modelType = \"CatBoost\")\nprint (\"Finished F4\")\ndf_F13_trained = train_impute(df,F_13_cols, strategy = \"median\")\nprint (\"Finished F13\")\ndf_sub = prepare_submission(df_F4_trained,df_F13_trained,sample)\n\ndf_sub.to_csv('Submission.csv',index = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T12:02:44.929161Z","iopub.execute_input":"2022-06-16T12:02:44.92958Z","iopub.status.idle":"2022-06-16T12:05:07.70703Z","shell.execute_reply.started":"2022-06-16T12:02:44.929548Z","shell.execute_reply":"2022-06-16T12:05:07.705953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Next Step : Time Series Prediction for F1_3\n\nI find it hard to believe that features in F1 and F3 are totaly random. I just start to learn time-series, so i'll try to see if any techniqe from the Kaggle Time Series course will be usefull here.\n\nI'm sure there is a better way, but I'll try to treat the series as a time date to get all the great pandas timedate features.","metadata":{}},{"cell_type":"code","source":"df.index = pd.date_range(\"2018-01-01\", periods=df.shape[0], freq=\"180s\")\n\n#first let see if there is a trend\n# df.loc[:,[\"F_1_0\"]].plot()\n(df.loc[:,[\"F_1_0\"]].resample('D')\n         .mean()\n         .plot(figsize = (10,4), alpha = .5 , linewidth = 1, label ='Daily')\n)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:29:44.173397Z","iopub.execute_input":"2022-06-16T16:29:44.174342Z","iopub.status.idle":"2022-06-16T16:29:44.479672Z","shell.execute_reply.started":"2022-06-16T16:29:44.174295Z","shell.execute_reply":"2022-06-16T16:29:44.478795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Clearly there is no global trend in the data.\n\nlets check if there are any cycles  in data data","metadata":{}},{"cell_type":"code","source":"from statsmodels.graphics.tsaplots import plot_pacf\n\nplot_pacf(df.F_1_1.resample('D').mean(), lags=8)","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:39:44.816871Z","iopub.execute_input":"2022-06-16T16:39:44.817284Z","iopub.status.idle":"2022-06-16T16:39:45.383085Z","shell.execute_reply.started":"2022-06-16T16:39:44.81725Z","shell.execute_reply":"2022-06-16T16:39:45.382395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Again, there isn't any auto-correlation signal. \nLets check for seasonality:","metadata":{}},{"cell_type":"code","source":"\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"1Y\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots()\n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\n            \"Annual (1)\",\n            \"Semiannual (2)\",\n            \"Quarterly (4)\",\n            \"Bimonthly (6)\",\n            \"Monthly (12)\",\n            \"Biweekly (26)\",\n            \"Weekly (52)\",\n            \"Semiweekly (104)\",\n        ],\n        rotation=30,\n    )\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n\nplot_periodogram(df.F_1_0.resample('D').mean());","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:29:44.481306Z","iopub.execute_input":"2022-06-16T16:29:44.481696Z","iopub.status.idle":"2022-06-16T16:29:44.916084Z","shell.execute_reply.started":"2022-06-16T16:29:44.481667Z","shell.execute_reply":"2022-06-16T16:29:44.915172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As I wrote above, I just took the kaggle Time Series course so I'm not sure how to iterperate this graph. I think since we see peek on every period, it means there is no clear seasonality. \nlets assume the graph drops between Bimonthly and Monthly and add the Furier features.","metadata":{}},{"cell_type":"code","source":"from statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\n\nfourier = CalendarFourier(freq=\"A\", order=8)  # 10 sin/cos pairs for \"A\"nnual seasonality\n\ndp = DeterministicProcess(\n    index=df.index,\n    constant=True,               # dummy feature for bias (y-intercept)\n    order=1,                     # trend (order 1 means linear)\n    seasonal=False,               # weekly seasonality (indicators)\n    additional_terms=[fourier],  # annual seasonality (fourier)\n    drop=True,                   # drop terms to avoid collinearity\n)\n\nX = dp.in_sample()  # create features for dates in tunnel.index\nfreq_cols = list(X.columns.values)\ndf_freq = pd.concat ([df, X], axis = 1)\n\n\n\ndef train_GBM_freq(df,iters,col_names,freq_cols,modelType = \"CatBoost\"):\n    df_cat = (df[col_names + freq_cols]\n                  .copy(deep = True)\n             )\n    for c,col in enumerate(col_names):\n        df_cat.loc[:,col] = predict_col(df_cat[freq_cols + [col]],col,iters, modelType)\n#         print (f'finished col {c} out of {len(col_names)}')\n    \n#     df_cat.row_id = df_cat.row_id.astype('int64')\n    return df_cat[col_names]","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:29:44.917338Z","iopub.execute_input":"2022-06-16T16:29:44.917694Z","iopub.status.idle":"2022-06-16T16:29:47.092024Z","shell.execute_reply.started":"2022-06-16T16:29:44.917662Z","shell.execute_reply":"2022-06-16T16:29:47.090967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train_vals ,df_train = get_train_subset(df_freq, f=0.01)\ndf_F4_trained = train_impute(df_train,F_4_cols + [\"row_id\"], strategy = \"mean\")\ndf_F4_trained.row_id = df_F4_trained.row_id.astype('int64')\n\ndf_F13_trained_freq = train_GBM_freq(df_train,20,F_13_cols,freq_cols)\n\ndf_NRMSE_per_grop,mse_trained = get_mse_from_trained(df_train_vals,df_F4_trained,df_F13_trained_freq, \"test5_F13_Freq8_F4_mean\")\ndf_NRMSE_per_grop.to_csv('Training_test5.csv',index = True)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:29:47.093281Z","iopub.execute_input":"2022-06-16T16:29:47.093633Z","iopub.status.idle":"2022-06-16T16:30:00.160587Z","shell.execute_reply.started":"2022-06-16T16:29:47.093597Z","shell.execute_reply":"2022-06-16T16:30:00.159629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res_list = [\"Training_test1.csv\",\"Training_test2.csv\",\"Training_test3.csv\",\"Training_test5.csv\"]\nres_dfs = [pd.read_csv(cur_df,index_col = \"col\") for cur_df in res_list]\nres_df_all = pd.concat(res_dfs, axis = 1)\n\nfig,ax = plt.subplots(dpi = 600, figsize = (10,5))\nplt.xticks(np.arange(len(res_df_all.index)), label =res_df_all.index )\n\nres_df_all.loc[F_13_cols[:20],:].plot(kind = 'line', ax=ax, linewidth = 2)\n\nplt.xticks(rotation = 90 )\n\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-16T16:30:28.816677Z","iopub.execute_input":"2022-06-16T16:30:28.81707Z","iopub.status.idle":"2022-06-16T16:30:30.196858Z","shell.execute_reply.started":"2022-06-16T16:30:28.817038Z","shell.execute_reply":"2022-06-16T16:30:30.195848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bottom Line\n* L_4 features can be easily modeled with a GBM regression models.\n* It doesn't appear to be any clear trend/seasonality/cycles in features F1-F3.\n* Since L_2 aren't correlated to any of the features with the missing data it is also not clear how it can be used.\n\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}