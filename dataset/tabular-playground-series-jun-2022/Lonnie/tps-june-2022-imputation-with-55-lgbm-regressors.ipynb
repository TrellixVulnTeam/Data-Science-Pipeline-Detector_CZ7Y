{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## JPS-June-2022: Imputation with 55 LGBM Regressors\nIn this notebook, I will create 55 LGBM Regressors to predict missing value because there are 55 columns with missing value. For each column with missing value, other columns will be feature columns and current column will be target column; rows with missing value of target column will be test data otherwise train data; in training phase I will also use train test split strategy.","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport glob\nimport gc\nimport pandas as pd\nimport lightgbm as lgb\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:41:13.815177Z","iopub.execute_input":"2022-06-03T09:41:13.815544Z","iopub.status.idle":"2022-06-03T09:41:13.820811Z","shell.execute_reply.started":"2022-06-03T09:41:13.815514Z","shell.execute_reply":"2022-06-03T09:41:13.819914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_pickle(glob.glob(\"../input/**/data.pkl\")[0])\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:34:31.70495Z","iopub.execute_input":"2022-06-03T09:34:31.705302Z","iopub.status.idle":"2022-06-03T09:34:31.831071Z","shell.execute_reply.started":"2022-06-03T09:34:31.705273Z","shell.execute_reply":"2022-06-03T09:34:31.83015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Find all columns with missing value","metadata":{}},{"cell_type":"code","source":"null_columns = []\nall_columns = list(train.columns)\nfor column in train.columns:\n    is_null = train[column].isnull().value_counts()\n    if is_null[0] != 1000000:\n         null_columns.append(column)\nprint(\"Columns with missing value:\", null_columns)\nprint(\"Number of columns:\", len(null_columns))","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:34:34.239465Z","iopub.execute_input":"2022-06-03T09:34:34.240066Z","iopub.status.idle":"2022-06-03T09:34:34.880925Z","shell.execute_reply.started":"2022-06-03T09:34:34.240032Z","shell.execute_reply":"2022-06-03T09:34:34.880161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nbegin = time.time()\nresults = dict()\nrmse_scores = []\nfor i, target_column in enumerate(null_columns):\n    feature_columns = [column for column in all_columns if column not in [target_column, \"row_id\"]]\n    null_rows = pd.isna(train[target_column])\n    train_data = train[null_rows == False]\n    test_data = train[null_rows == True]\n    if len(test_data) == 0:\n        print(f\"no missing value for {target_column}\")\n        continue\n    train_df, valid_df = train_test_split(train_data, test_size=0.1, shuffle=True, random_state=42)\n    params = {\n        \"objective\": \"rmse\",\n        \"learning_rate\": 0.03,\n        \"num_iterations\": 1000,\n        \"early_stopping_round\": 400\n    }\n    lgbm = lgb.LGBMRegressor(**params)\n    x_val = valid_df[feature_columns]\n    y_val = valid_df[target_column]\n    lgbm.fit(train_df[feature_columns], train_df[target_column], eval_set=(x_val, y_val), verbose=-1)\n    y_val_pred = lgbm.predict(x_val)\n    rmse_score = np.sqrt(mean_squared_error(y_val, y_val_pred))\n    rmse_scores.append(rmse_score)\n    print(f\"RMSE Score:{rmse_score:.3f}\")\n    y_pred = lgbm.predict(test_data[feature_columns]).reshape(-1) \n    train.loc[null_rows == True, target_column] = y_pred\n    name = f\"lgbm_\" + target_column + \".pkl\"\n    joblib.dump(lgbm, name)\n    elapsed = time.time() - begin\n    estimated = elapsed / (i + 1) * len(null_columns)\n    print(f\"{elapsed:.2f}s/{estimated:.2f}s\")\n    gc.collect()\noof = np.mean(rmse_scores)\nprint(f\"OOF:{oof}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-03T09:41:17.431616Z","iopub.execute_input":"2022-06-03T09:41:17.432486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"%%time\nsubmission = pd.read_csv(glob.glob(\"../input/**/sample_submission.csv\")[0])  \ndef post_processing(item):\n    items = item.split(\"-\")\n    row = int(items[0])\n    column = items[1]\n    return train.iloc[row][column]\nsubmission['value'] = submission['row-col'].apply(post_processing)\nsubmission.to_csv(\"submission.csv\", index=False)\nsubmission.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-03T08:32:15.664514Z","iopub.execute_input":"2022-06-03T08:32:15.665007Z","iopub.status.idle":"2022-06-03T08:35:43.456021Z","shell.execute_reply.started":"2022-06-03T08:32:15.664974Z","shell.execute_reply":"2022-06-03T08:35:43.454857Z"},"trusted":true},"execution_count":null,"outputs":[]}]}