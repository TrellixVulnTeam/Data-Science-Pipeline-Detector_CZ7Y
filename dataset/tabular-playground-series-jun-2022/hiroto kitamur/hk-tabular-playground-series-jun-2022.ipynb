{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Read data\n\nimport pandas as pd\nfrom pathlib import Path\n\ninput_path = Path('../input/tabular-playground-series-jun-2022/')\ndata = pd.read_csv(input_path / 'data.csv', index_col='row_id')\n\nsample_submission = pd.read_csv(\n    input_path / 'sample_submission.csv',\n    index_col='row-col'\n)\n\nprint(data.shape)\ndata.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create imputed data.\nimport numpy as np\n\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.impute import IterativeImputer\n\n\ndef create_imputed_data(\n    imputer, base_data: pd.DataFrame, name: str\n) -> pd.DataFrame:\n    imputed_data = pd.DataFrame(\n        imputer.fit_transform(base_data.copy()),\n        columns=base_data.columns,\n        index=base_data.index\n    )\n    print(\"finish create impute by {}.\".format(name))\n    return imputed_data\n\n\nimputers = {\n    'BayesianRidge': IterativeImputer(),\n    'RandomForest': IterativeImputer(RandomForestRegressor()),\n    'AdaBoostRegressor': IterativeImputer(AdaBoostRegressor()),\n    'SimpleMean': SimpleImputer(missing_values=np.nan, strategy='mean')\n}\n\n# key = 'BayesianRidge'\n# key = 'RandomForest'\n# key = 'AdaBoostRegressor'\nkey = 'SimpleMean'\n\nimputed_data = create_imputed_data(imputers[key], data, key)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncolumns_with_missing = [\n    column for column in data.columns.values\n    if data[column].isnull().values.any()\n]\n\n# Make new columns indicating what was missing.\nimputed_data_with_flag = imputed_data.copy()\nfor col in columns_with_missing:\n    imputed_data_with_flag[col + '_was_missing'] = data[col].isnull()\n\nimputed_data_with_flag.head()\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict missing value by LightGBM\n\nfrom sklearn.model_selection import train_test_split\nimport lightgbm as lgb\n\n\ndef create_lgb_model(train: pd.DataFrame, predict_column: str) -> lgb.Booster:\n    x_train, x_test, y_train, y_test = train_test_split(\n        train.drop(columns=[predict_column]),\n        train.loc[:, predict_column],\n        test_size=0.25\n    )\n\n    lgb_train = lgb.Dataset(x_train, y_train)\n    lgb_eval = lgb.Dataset(x_test, y_test, reference=lgb_train)\n\n    params = {\n        'objective': 'regression_l2',\n        'force_col_wise': True,\n    }\n\n    return lgb.train(\n        params,\n        lgb_train,\n        valid_sets=[lgb_train, lgb_eval],\n        num_boost_round=1000,\n        callbacks=[lgb.log_evaluation(10), lgb.early_stopping(10)]\n    )\n\n\ndef predict_missing_value(\n    column: str,\n    imputed_data_with_flag_for_predict: pd.DataFrame\n) -> pd.DataFrame:\n    predict_data = imputed_data_with_flag_for_predict.copy()\n    predict_data[column] = data.loc[:, column]\n\n    train = predict_data[(predict_data[column].notnull())]\n    model = create_lgb_model(train, column)\n\n    valid = predict_data[(predict_data[column].isnull())]\n    predict = model.predict(\n        valid.drop(columns=[column]),\n        num_iteration=model.best_iteration\n    )\n\n    print(\"finish predict : {}\".format(column))\n\n    return pd.DataFrame(predict, index=valid.index, columns=[column])\n\n\npredict_dictionary = {\n    column: predict_missing_value(column, imputed_data_with_flag)\n    for column in columns_with_missing\n}\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict missing value by predict data\nfrom tqdm import tqdm\nfrom typing import Dict\n\n\ndef predict_by_predict(predict_dic: Dict[str, pd.DataFrame]) -> Dict[str, pd.DataFrame]:\n    data_for_predict = imputed_data_with_flag.copy()\n\n    for column in predict_dic:\n        target_data = data[(data[column].isnull())]\n        for i in tqdm(target_data.index):\n            predict_value = predict_dic[column].loc[i, column]\n            data_for_predict.loc[i, column] = predict_value\n\n    return {\n        column: predict_missing_value(column, data_for_predict)\n        for column in columns_with_missing\n    }\n\n\nfor _ in range(3):\n    predict_dictionary = predict_by_predict(predict_dictionary)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create submission file\n\nfrom tqdm import tqdm\n\nfor i in tqdm(sample_submission.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    sample_submission.loc[i, 'value'] = predict_dictionary[col].loc[row, col]\n\nsample_submission.to_csv('impute_and_predict.csv')\n","metadata":{},"execution_count":null,"outputs":[]}]}