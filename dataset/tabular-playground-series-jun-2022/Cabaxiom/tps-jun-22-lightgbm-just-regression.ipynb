{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Tabular Plaground Series June 2022","metadata":{}},{"cell_type":"markdown","source":"This notebook contains:\n\n- A very brief EDA\n- Using K-Fold Validation to assess performance of the regression model to impute.\n- A comparison of imputation techniques for each feature.\n- Using LightGBM to impute missing values of F_4_X features.\n- Using the mean values to impute F_1_X and F_3_X features.","metadata":{}},{"cell_type":"markdown","source":"View my EDA here: https://www.kaggle.com/code/cabaxiom/tps-jun-22-eda","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n\nsns.set_style('darkgrid')","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-04T15:55:53.688315Z","iopub.execute_input":"2022-06-04T15:55:53.68871Z","iopub.status.idle":"2022-06-04T15:55:55.288591Z","shell.execute_reply.started":"2022-06-04T15:55:53.688677Z","shell.execute_reply":"2022-06-04T15:55:55.28783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:27:49.737203Z","iopub.execute_input":"2022-06-04T16:27:49.73761Z","iopub.status.idle":"2022-06-04T16:28:04.500649Z","shell.execute_reply.started":"2022-06-04T16:27:49.737579Z","shell.execute_reply":"2022-06-04T16:28:04.499584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group features for later use\n\nfeature_cols = [i for i in df.columns if \"F\" in i]\nfloat_cols = [i for i in df.columns if df[i].dtype == float]\nint_cols = [i for i in df.columns if df[i].dtype == int and \"F\" in i]\n\nF_1_cols = [i for i in df.columns if \"F_1\" in i]\nF_2_cols = [i for i in df.columns if \"F_2\" in i]\nF_3_cols = [i for i in df.columns if \"F_3\" in i]\nF_4_cols = [i for i in df.columns if \"F_4\" in i]\n\nF_123_cols = F_1_cols + F_2_cols + F_3_cols","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:19:09.159767Z","iopub.execute_input":"2022-06-04T16:19:09.161534Z","iopub.status.idle":"2022-06-04T16:19:09.173763Z","shell.execute_reply.started":"2022-06-04T16:19:09.161483Z","shell.execute_reply":"2022-06-04T16:19:09.172706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"There are: \", len(float_cols), \"float features\")\nprint(\"There are: \", len(int_cols), \"integer features\")\n\nprint(\"There are: \", len(F_1_cols), \"F1 features\")\nprint(\"There are: \", len(F_2_cols), \"F2 features\")\nprint(\"There are: \", len(F_3_cols), \"F3 features\")\nprint(\"There are: \", len(F_4_cols), \"F4 features\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T17:40:32.368353Z","iopub.execute_input":"2022-06-04T17:40:32.369206Z","iopub.status.idle":"2022-06-04T17:40:32.375385Z","shell.execute_reply.started":"2022-06-04T17:40:32.369168Z","shell.execute_reply":"2022-06-04T17:40:32.374665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(25,20))\nsns.heatmap(df[feature_cols].corr(), annot= True, cmap=\"RdYlGn\", fmt = '0.1f', vmin=-0.6, vmax=0.6, cbar=False);","metadata":{"execution":{"iopub.status.busy":"2022-06-04T17:45:37.758886Z","iopub.execute_input":"2022-06-04T17:45:37.759197Z","iopub.status.idle":"2022-06-04T17:46:18.608557Z","shell.execute_reply.started":"2022-06-04T17:45:37.759168Z","shell.execute_reply":"2022-06-04T17:46:18.607597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.subplots(figsize=(25,20))\nsns.heatmap(df[float_cols].corr(), annot= True, cmap=\"RdYlGn\", fmt = '0.2f', vmin=-1, vmax=1, cbar=False);","metadata":{"execution":{"iopub.status.busy":"2022-06-04T17:45:16.722726Z","iopub.execute_input":"2022-06-04T17:45:16.723255Z","iopub.status.idle":"2022-06-04T17:45:37.740631Z","shell.execute_reply.started":"2022-06-04T17:45:16.72322Z","shell.execute_reply":"2022-06-04T17:45:37.739711Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n\n- The F_4_X features are only correlated with other F_4_X features.\n- The integer (discrete) F_2_X features are only correlated with other F_2_X features. (Note: theres no missing F_2_X features).\n- F_1_X and F_3_X features are not correlated with any other feature.\n\n**Insight:**\n- Consider using a regression model to predict F_1_1 values. There are no other columns correlated with this feature. This gives some indication that perhaps these other features are redundent for predictions. However its still possible that:\n    1. There no overall correlation with the target feature but the feature is still useful for predictions (high mutual information score)\n    2. Other features are useful for predictions when we consider feature interactions.","metadata":{}},{"cell_type":"markdown","source":"# K-Fold Cross-Validation","metadata":{}},{"cell_type":"markdown","source":"We take a single feature (here F_4_1) and train and evaluate how good the models predictions of this feature are. Once we have a good model we can use it to impute the missing values.","metadata":{}},{"cell_type":"code","source":"y_col = \"F_4_1\"\ny = df[y_col].dropna()\nX = df.loc[y.index].drop(columns=[y_col,\"row_id\"]).reset_index(drop=True)\ny = y.reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:33:36.847476Z","iopub.execute_input":"2022-06-04T16:33:36.847924Z","iopub.status.idle":"2022-06-04T16:33:37.593192Z","shell.execute_reply.started":"2022-06-04T16:33:36.847889Z","shell.execute_reply":"2022-06-04T16:33:37.592134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LGBMRegressor(n_estimators = 50, learning_rate = 0.1, random_state=0, n_jobs=-1)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T18:02:43.004135Z","iopub.execute_input":"2022-06-04T18:02:43.004598Z","iopub.status.idle":"2022-06-04T18:02:43.010112Z","shell.execute_reply.started":"2022-06-04T18:02:43.004565Z","shell.execute_reply":"2022-06-04T18:02:43.009131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def k_fold_cv(model,X,y):\n    kfold = KFold(n_splits = 5, shuffle=True, random_state = 0)\n\n    feature_imp, y_pred_list, y_true_list, mse_list  = [],[],[],[]\n    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n        print(\"==fold==\", fold)\n        X_train = X.loc[train_index]\n        X_val = X.loc[val_index]\n\n        y_train = y.loc[train_index]\n        y_val = y.loc[val_index]\n\n        model.fit(X_train,y_train)\n        y_pred = model.predict(X_val)\n            \n        y_pred_list = np.append(y_pred_list, y_pred)\n        y_true_list = np.append(y_true_list, y_val)\n\n        mse_list.append(mean_squared_error(y_val,y_pred))\n        print(\"MSE\", mean_squared_error(y_val,y_pred))\n\n        try:\n            feature_imp.append(model.feature_importances_)\n        except AttributeError: # if model does not have .feature_importances_ attribute\n            pass # returns empty list\n    return feature_imp, y_pred_list, y_true_list,mse_list, X_val, y_val","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:33:38.634326Z","iopub.execute_input":"2022-06-04T16:33:38.635164Z","iopub.status.idle":"2022-06-04T16:33:38.645216Z","shell.execute_reply.started":"2022-06-04T16:33:38.635126Z","shell.execute_reply":"2022-06-04T16:33:38.644169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfeature_imp, y_pred_list, y_true_list, mse_list, X_val, y_val = k_fold_cv(model=model,X=X,y=y)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:33:39.316809Z","iopub.execute_input":"2022-06-04T16:33:39.317427Z","iopub.status.idle":"2022-06-04T16:35:40.254946Z","shell.execute_reply.started":"2022-06-04T16:33:39.31737Z","shell.execute_reply":"2022-06-04T16:35:40.254019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Mean MSE:\", np.mean(mse_list))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:38:43.267409Z","iopub.execute_input":"2022-06-04T16:38:43.267876Z","iopub.status.idle":"2022-06-04T16:38:43.273559Z","shell.execute_reply.started":"2022-06-04T16:38:43.267843Z","shell.execute_reply":"2022-06-04T16:38:43.272638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f,ax = plt.subplots(figsize=(8,8))\nsns.histplot(y_pred_list, color=\"blue\")\nsns.histplot(y_true_list, color=\"red\", alpha=0.2);","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:38:44.321375Z","iopub.execute_input":"2022-06-04T16:38:44.322112Z","iopub.status.idle":"2022-06-04T16:38:47.471408Z","shell.execute_reply.started":"2022-06-04T16:38:44.322075Z","shell.execute_reply":"2022-06-04T16:38:47.470757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fold_feature_importances(model_importances, column_names, model_name, n_folds = 5, ax=None, boxplot=False):\n    importances_df = pd.DataFrame({\"feature_cols\": column_names, \"importances_fold_0\": model_importances[0]})\n    for i in range(1,n_folds):\n        importances_df[\"importances_fold_\"+str(i)] = model_importances[i]\n    importances_df[\"importances_fold_median\"] = importances_df.drop(columns=[\"feature_cols\"]).median(axis=1)\n    importances_df = importances_df.sort_values(by=\"importances_fold_median\", ascending=False)\n    if ax == None:\n        f, ax = plt.subplots(figsize=(15, 25))\n    if boxplot == False:\n        ax = sns.barplot(data = importances_df, x = \"importances_fold_median\", y=\"feature_cols\", color=\"blue\")\n        ax.set_xlabel(\"Median Feature importance across all folds\");\n    elif boxplot == True:\n        importances_df = importances_df.drop(columns=\"importances_fold_median\")\n        importances_df = importances_df.set_index(\"feature_cols\").stack().reset_index().rename(columns={0:\"feature_importance\"})\n        ax = sns.boxplot(data = importances_df, y = \"feature_cols\", x=\"feature_importance\", color=\"blue\", orient=\"h\")\n        ax.set_xlabel(\"Feature importance across all folds\");\n    plt.title(model_name)\n    ax.set_ylabel(\"Feature Columns\")\n    return ax","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:21:12.104986Z","iopub.execute_input":"2022-06-04T16:21:12.106039Z","iopub.status.idle":"2022-06-04T16:21:12.116284Z","shell.execute_reply.started":"2022-06-04T16:21:12.105998Z","shell.execute_reply":"2022-06-04T16:21:12.115665Z"}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, ax = plt.subplots(figsize=(15, 20))\nfold_feature_importances(model_importances = feature_imp, column_names = X_val.columns, model_name = \"LGBM\", n_folds = 5, ax=ax, boxplot=False);","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:21:12.279319Z","iopub.execute_input":"2022-06-04T16:21:12.279928Z","iopub.status.idle":"2022-06-04T16:21:13.407524Z","shell.execute_reply.started":"2022-06-04T16:21:12.27988Z","shell.execute_reply":"2022-06-04T16:21:13.406598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observations:**\n- Only the F_4 features are useful for predicting other f_4 columns.","metadata":{}},{"cell_type":"markdown","source":"# Comparing imputation methods","metadata":{}},{"cell_type":"markdown","source":"We now compare the prediction performance for each feature investigating whether its better to:\n\n1. Use the mean value to impute.\n2. Use the median value to impute.\n3. Use all 0 values to impute.\n3. Use a regression model to impute.","metadata":{}},{"cell_type":"code","source":"def compare_methods_fold(model,X,y):\n    kfold = KFold(n_splits = 5, shuffle=True, random_state = 0)\n\n    for fold, (train_index, val_index) in enumerate(kfold.split(X, y)):\n        if fold < 1: # only evaluate 1/5 folds to save time\n            X_train = X.loc[train_index]\n            X_val = X.loc[val_index]\n\n            y_train = y.loc[train_index]\n            y_val = y.loc[val_index]\n\n            model.fit(X_train,y_train)\n\n            y_pred_model = model.predict(X_val)\n            y_pred_mean = np.full(len(y_val), y_train.mean())\n            y_pred_median = np.full(len(y_val), y_train.median())\n            y_pred_zeros = np.zeros(len(y_val))\n            \n            mse_model =  mean_squared_error(y_val,y_pred_model)\n            mse_mean =  mean_squared_error(y_val,y_pred_mean)\n            mse_median =  mean_squared_error(y_val,y_pred_median)\n            mse_zeros =  mean_squared_error(y_val,y_pred_zeros)\n\n    return [mse_model, mse_mean, mse_median, mse_zeros]","metadata":{"execution":{"iopub.status.busy":"2022-06-04T18:02:47.555811Z","iopub.execute_input":"2022-06-04T18:02:47.556253Z","iopub.status.idle":"2022-06-04T18:02:47.566616Z","shell.execute_reply.started":"2022-06-04T18:02:47.556219Z","shell.execute_reply":"2022-06-04T18:02:47.565618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compare_methods():\n    mse_lists = []\n    for y_col in float_cols:\n    \n        y = df[y_col].dropna()\n        X = df.loc[y.index].drop(columns=[y_col,\"row_id\"]).reset_index(drop=True)\n        y = y.reset_index(drop=True)\n        \n        mse_lists.append(compare_methods_fold(model,X,y))\n        \n    new_df = pd.DataFrame(mse_lists, columns=[\"model\",\"mean\",\"median\",\"zeros\"], index=float_cols)\n    return new_df","metadata":{"execution":{"iopub.status.busy":"2022-06-04T18:13:34.665496Z","iopub.execute_input":"2022-06-04T18:13:34.665995Z","iopub.status.idle":"2022-06-04T18:13:34.673797Z","shell.execute_reply.started":"2022-06-04T18:13:34.665957Z","shell.execute_reply":"2022-06-04T18:13:34.67271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"comparison_df = compare_methods()\ncomparison_df[\"best_method\"] = comparison_df.idxmin(axis=1)\ncomparison_df","metadata":{"execution":{"iopub.status.busy":"2022-06-04T18:35:03.699261Z","iopub.execute_input":"2022-06-04T18:35:03.6997Z","iopub.status.idle":"2022-06-04T18:45:17.476453Z","shell.execute_reply.started":"2022-06-04T18:35:03.699668Z","shell.execute_reply":"2022-06-04T18:45:17.47552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"markdown","source":"Now we perform are actual imputations on the missing values. Based on our experiments we decide to:\n\n- For imputing F_1 and F_3 columns we use the mean value.\n- For imputing F_4 columns we use a regression model which is only fit to other F_4 columns.","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-jun-2022/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T18:49:22.356863Z","iopub.execute_input":"2022-06-04T18:49:22.358Z","iopub.status.idle":"2022-06-04T18:49:23.190153Z","shell.execute_reply.started":"2022-06-04T18:49:22.357958Z","shell.execute_reply":"2022-06-04T18:49:23.189228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def impute():\n    \"\"\"\n    This function takes each feature one at a time e.g. F_1_0, F_1,1, ... , F_4_14 to be used as y (the column to predict)\n    \n    The method of prediction depends on whether the column we are predictiing is a F_1, F_3 or F_4.\n    For predicting F_1 and F_3 columns the mean y value is used as the prediction.\n    For F_4 columns we train a model on relevant columns (other F_4 colums).\n    \n    Once predictions have been made the relevant rows in the submission DataFrame are set to the predictions\n    \"\"\"\n    for y_col in float_cols:\n        \n        y = df[y_col].dropna() #non-missing y values \n        X = df.loc[y.index].drop(columns=[y_col,\"row_id\"]).reset_index(drop=True) #corresponding non-missing X values\n        y = y.reset_index(drop=True)\n        \n        #Columns with missing target values to be used to make predictions from\n        X_test = df.loc[df[y_col].isna() == True].drop(columns=[y_col,\"row_id\"])\n        \n        if (y_col[2] == \"1\") or (y_col[2] == \"3\"):\n            # predictions are the mean value of that column (mean impute)\n            preds = np.full(len(X_test), y.mean()) \n            \n        if y_col[2] == '4':\n            #Predictions are based on the regression model\n            model = LGBMRegressor(n_estimators = 80000, learning_rate = 0.1, random_state=0, max_bins=511, n_jobs=-1)\n            X = X.drop(columns = F_123_cols) #Remove redundent columns\n            model.fit(X,y)\n            preds = model.predict(X_test.drop(columns = F_123_cols ))\n        \n        submission.loc[submission[\"row-col\"].str.endswith(y_col), \"value\"] = preds\n        ","metadata":{"execution":{"iopub.status.busy":"2022-06-04T18:49:23.191481Z","iopub.execute_input":"2022-06-04T18:49:23.192536Z","iopub.status.idle":"2022-06-04T18:49:23.202594Z","shell.execute_reply.started":"2022-06-04T18:49:23.1925Z","shell.execute_reply":"2022-06-04T18:49:23.201934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimpute()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T18:49:24.297985Z","iopub.execute_input":"2022-06-04T18:49:24.298648Z","iopub.status.idle":"2022-06-04T18:49:43.64477Z","shell.execute_reply.started":"2022-06-04T18:49:24.298612Z","shell.execute_reply":"2022-06-04T18:49:43.643843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T16:29:46.249257Z","iopub.execute_input":"2022-06-04T16:29:46.249909Z","iopub.status.idle":"2022-06-04T16:29:49.65738Z","shell.execute_reply.started":"2022-06-04T16:29:46.249877Z","shell.execute_reply":"2022-06-04T16:29:49.656625Z"},"trusted":true},"execution_count":null,"outputs":[]}]}