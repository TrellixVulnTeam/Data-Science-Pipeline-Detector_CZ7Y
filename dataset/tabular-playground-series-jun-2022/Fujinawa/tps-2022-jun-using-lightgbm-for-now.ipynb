{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T09:00:34.273637Z","iopub.execute_input":"2022-06-13T09:00:34.27447Z","iopub.status.idle":"2022-06-13T09:00:34.312445Z","shell.execute_reply.started":"2022-06-13T09:00:34.274013Z","shell.execute_reply":"2022-06-13T09:00:34.310263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Libray import","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.403403Z","iopub.status.idle":"2022-06-12T06:09:17.404009Z","shell.execute_reply.started":"2022-06-12T06:09:17.403722Z","shell.execute_reply":"2022-06-12T06:09:17.403758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data loading","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2022/data.csv')\nsub = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.768391Z","iopub.execute_input":"2022-06-12T06:09:17.769103Z","iopub.status.idle":"2022-06-12T06:09:17.785004Z","shell.execute_reply.started":"2022-06-12T06:09:17.769064Z","shell.execute_reply":"2022-06-12T06:09:17.783348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.786245Z","iopub.status.idle":"2022-06-12T06:09:17.786966Z","shell.execute_reply.started":"2022-06-12T06:09:17.78672Z","shell.execute_reply":"2022-06-12T06:09:17.786745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"F_1: from 0 to 14   \nF_2: from 0 to 24  \nF_3: from 0 to 24  \nF_4: from 0 to 14  ","metadata":{}},{"cell_type":"markdown","source":"First, let's look at the missing values for each data set.\nAs you can see, there are no missing values for a particular data set.","metadata":{}},{"cell_type":"code","source":"plt.bar(df.isnull().sum().index, df.isnull().sum())\nplt.ylabel('missing value counts')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.788207Z","iopub.status.idle":"2022-06-12T06:09:17.788816Z","shell.execute_reply.started":"2022-06-12T06:09:17.788579Z","shell.execute_reply":"2022-06-12T06:09:17.788603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"isnull_df = df.isnull().sum()\nisnull_df[isnull_df==0]","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.78989Z","iopub.status.idle":"2022-06-12T06:09:17.790493Z","shell.execute_reply.started":"2022-06-12T06:09:17.790268Z","shell.execute_reply":"2022-06-12T06:09:17.790291Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We found that F_2 data is no missing value","metadata":{}},{"cell_type":"code","source":"f1_columns = [c for c in df.columns if 'F_1' in c]\nf2_columns = [c for c in df.columns if 'F_2' in c]\nf3_columns = [c for c in df.columns if 'F_3' in c]\nf4_columns = [c for c in df.columns if 'F_4' in c]","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.79154Z","iopub.status.idle":"2022-06-12T06:09:17.792251Z","shell.execute_reply.started":"2022-06-12T06:09:17.791981Z","shell.execute_reply":"2022-06-12T06:09:17.792007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's look at a histogram of each data","metadata":{}},{"cell_type":"code","source":"data_groups = [f1_columns, f2_columns, f3_columns, f4_columns]\nfor n, g in enumerate(data_groups):\n    x = len(g)//5\n    fig = plt.figure(figsize=(18,x*3))\n    fig.suptitle(f'histgram of F_{n+1} ', fontsize =16)\n    plt.subplots_adjust(wspace=0.4, hspace=0.3)\n    for i, column in enumerate(g):\n        plt.subplot(x, 5, i+1)\n        plt.hist(df[column], bins =100)\n        plt.ylabel('count')\n        plt.xlabel(f'{column}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.793519Z","iopub.status.idle":"2022-06-12T06:09:17.794217Z","shell.execute_reply.started":"2022-06-12T06:09:17.793927Z","shell.execute_reply":"2022-06-12T06:09:17.793967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_groups = [f1_columns, f2_columns, f3_columns, f4_columns]\nouterline_ratio = 0.005\nfor n, g in enumerate(data_groups):\n    x = len(g)//5\n    fig = plt.figure(figsize=(18,x*3))\n    fig.suptitle(f'histgram of F_{n+1} without 0.5% outlier', fontsize =16)\n    plt.subplots_adjust(wspace=0.4, hspace=0.3)\n    for i, column in enumerate(g):\n        tempup = df[column].quantile(1-outerline_ratio)\n        tempdown = df[column].quantile(outerline_ratio)\n        temp = df[(df[column] <= tempup) & (df[column] >= tempdown)]\n        plt.subplot(x, 5, i+1)\n        plt.hist(temp[column], bins =100)\n        plt.ylabel('count')\n        plt.xlabel(f'{column}')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-12T06:09:17.795313Z","iopub.status.idle":"2022-06-12T06:09:17.795877Z","shell.execute_reply.started":"2022-06-12T06:09:17.795654Z","shell.execute_reply":"2022-06-12T06:09:17.795676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are a little outlier.   \nI tried to remove 0.5% of the outliers, but the score did not improve.   \nTherefore, I do not remove outliers.","metadata":{}},{"cell_type":"code","source":"submission_f1_df = pd.DataFrame(index=[], columns=['row-col', 'value'])\nf1_column_results = []\nfor column in f1_columns:\n    temp_test = df[df[column].isnull()]\n    temp_train = df[~df[column].isnull()]\n    result_df = temp_test[['row_id']]\n    del temp_test[column]\n    del temp_test['row_id']\n    del temp_train['row_id']\n\n    y = temp_train[column]\n    X = temp_train.drop(column, axis = 1)\n\n    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=100)\n    train_set = lgb.Dataset(train_X, train_y)\n    valid_set = lgb.Dataset(test_X, test_y)\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\"}\n    print(f'\\n\\n {column}_calulate')\n    model = lgb.train(\n        params = params,\n        train_set = train_set,\n        valid_sets = [train_set, valid_set],\n        num_boost_round = 4000)\n    \n    pred_test = model.predict(test_X)\n    mse = mean_squared_error(test_y, pred_test)\n    rmse = np.sqrt(mse)\n    f1_column_results.append([column, rmse])\n    \n    pred = model.predict(temp_test)\n    result_df['row-col'] = result_df['row_id'].astype(str) + f'-{column}'\n    result_df['value']= pred\n    result_df.reset_index(inplace=True, drop=True)\n    submission_f1_df = pd.concat([submission_f1_df, result_df], join='inner')\nsubmission_f1_df","metadata":{"_kg_hide-input":false,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-12T03:55:38.803415Z","iopub.execute_input":"2022-06-12T03:55:38.804308Z","iopub.status.idle":"2022-06-12T04:01:06.419275Z","shell.execute_reply.started":"2022-06-12T03:55:38.804268Z","shell.execute_reply":"2022-06-12T04:01:06.418395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f1_column_results","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:01:06.420509Z","iopub.execute_input":"2022-06-12T04:01:06.421377Z","iopub.status.idle":"2022-06-12T04:01:06.427542Z","shell.execute_reply.started":"2022-06-12T04:01:06.421328Z","shell.execute_reply":"2022-06-12T04:01:06.426722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_f3_df = pd.DataFrame(index=[], columns=['row-col', 'value'])\nf3_column_results = []\nfor column in f3_columns:\n    temp_test = df[df[column].isnull()]\n    temp_train = df[~df[column].isnull()]\n    result_df = temp_test[['row_id']]\n    del temp_test[column]\n    del temp_test['row_id']\n    del temp_train['row_id']\n\n    y = temp_train[column]\n    X = temp_train.drop(column, axis = 1)\n    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=100)\n    train_set = lgb.Dataset(train_X, train_y)\n    valid_set = lgb.Dataset(test_X, test_y)\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\"}\n    print(f'\\n\\n {column}_calulate')\n    model = lgb.train(\n        params = params,\n        train_set = train_set,\n        valid_sets = [train_set, valid_set],\n        num_boost_round = 4000)\n    \n    pred_test = model.predict(test_X)\n    mse = mean_squared_error(test_y, pred_test)\n    rmse = np.sqrt(mse)\n    f3_column_results.append([column, rmse])\n    \n    pred = model.predict(temp_test)\n    result_df['row-col'] = result_df['row_id'].astype(str) + f'-{column}'\n    result_df['value']= pred\n    result_df.reset_index(inplace=True, drop=True)\n    submission_f3_df = pd.concat([submission_f3_df, result_df], join='inner')\nsubmission_f3_df","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-12T04:01:06.428889Z","iopub.execute_input":"2022-06-12T04:01:06.4294Z","iopub.status.idle":"2022-06-12T04:10:05.121131Z","shell.execute_reply.started":"2022-06-12T04:01:06.429362Z","shell.execute_reply":"2022-06-12T04:10:05.120391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f3_column_results","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:10:05.12229Z","iopub.execute_input":"2022-06-12T04:10:05.122653Z","iopub.status.idle":"2022-06-12T04:10:05.129313Z","shell.execute_reply.started":"2022-06-12T04:10:05.122617Z","shell.execute_reply":"2022-06-12T04:10:05.128553Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_f4_df = pd.DataFrame(index=[], columns=['row-col', 'value'])\nf4_column_results = []\nfor column in f4_columns:\n    temp_test = df[df[column].isnull()]\n    temp_train = df[~df[column].isnull()]\n    result_df = temp_test[['row_id']]\n    del temp_test[column]\n    del temp_test['row_id']\n    del temp_train['row_id']\n\n    y = temp_train[column]\n    X = temp_train.drop(column, axis = 1)\n    \n    train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.3, random_state=100)\n    train_set = lgb.Dataset(train_X, train_y)\n    valid_set = lgb.Dataset(test_X, test_y)\n    params = {\n        \"objective\" : \"regression\",\n        \"metric\" : \"rmse\"}\n    print(f'\\n\\n {column}_calulate')\n    model = lgb.train(\n        params = params,\n        train_set = train_set,\n        valid_sets = [train_set, valid_set],\n        num_boost_round = 4000)\n    \n    pred_test = model.predict(test_X)\n    mse = mean_squared_error(test_y, pred_test)\n    rmse = np.sqrt(mse)\n    f4_column_results.append([column, rmse])\n        \n    pred = model.predict(temp_test)\n    result_df['row-col'] = result_df['row_id'].astype(str) + f'-{column}'\n    result_df['value']= pred\n    result_df.reset_index(inplace=True, drop=True)\n    submission_f4_df = pd.concat([submission_f4_df, result_df], join='inner')\nsubmission_f4_df","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-12T04:10:05.130693Z","iopub.execute_input":"2022-06-12T04:10:05.131613Z","iopub.status.idle":"2022-06-12T04:19:18.805142Z","shell.execute_reply.started":"2022-06-12T04:10:05.131575Z","shell.execute_reply":"2022-06-12T04:19:18.80438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f4_column_results","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:19:18.80658Z","iopub.execute_input":"2022-06-12T04:19:18.80695Z","iopub.status.idle":"2022-06-12T04:19:18.814209Z","shell.execute_reply.started":"2022-06-12T04:19:18.806914Z","shell.execute_reply":"2022-06-12T04:19:18.813016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_all_df = pd.concat([submission_f1_df, submission_f3_df, submission_f4_df], join='inner')\nsubmission_all_df","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:19:18.816038Z","iopub.execute_input":"2022-06-12T04:19:18.816645Z","iopub.status.idle":"2022-06-12T04:19:18.847163Z","shell.execute_reply.started":"2022-06-12T04:19:18.816605Z","shell.execute_reply":"2022-06-12T04:19:18.846435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del sub['value']","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:19:18.848272Z","iopub.execute_input":"2022-06-12T04:19:18.848666Z","iopub.status.idle":"2022-06-12T04:19:18.853474Z","shell.execute_reply.started":"2022-06-12T04:19:18.84862Z","shell.execute_reply":"2022-06-12T04:19:18.852416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.merge(sub, submission_all_df, on='row-col', how='left')","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:19:18.854759Z","iopub.execute_input":"2022-06-12T04:19:18.855297Z","iopub.status.idle":"2022-06-12T04:19:19.734196Z","shell.execute_reply.started":"2022-06-12T04:19:18.855259Z","shell.execute_reply":"2022-06-12T04:19:19.733377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv(\"/kaggle/working/submission6.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:19:19.736946Z","iopub.execute_input":"2022-06-12T04:19:19.737336Z","iopub.status.idle":"2022-06-12T04:19:22.906421Z","shell.execute_reply.started":"2022-06-12T04:19:19.737299Z","shell.execute_reply":"2022-06-12T04:19:22.905572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_results = []\ncolumn_results.append(f1_column_results)\ncolumn_results.append(f3_column_results)\ncolumn_results.append(f4_column_results)","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:19:22.907674Z","iopub.execute_input":"2022-06-12T04:19:22.908049Z","iopub.status.idle":"2022-06-12T04:19:22.912687Z","shell.execute_reply.started":"2022-06-12T04:19:22.908013Z","shell.execute_reply":"2022-06-12T04:19:22.911944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"column_results","metadata":{"execution":{"iopub.status.busy":"2022-06-12T04:19:22.913944Z","iopub.execute_input":"2022-06-12T04:19:22.914432Z","iopub.status.idle":"2022-06-12T04:19:22.928058Z","shell.execute_reply.started":"2022-06-12T04:19:22.914396Z","shell.execute_reply":"2022-06-12T04:19:22.927262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Next\nF4_0,F_4_1, F4_4, F4_5, F4_6, F4_7, F4_12   \nSince these data are clearly inaccurate, something needs to be done.","metadata":{}}]}