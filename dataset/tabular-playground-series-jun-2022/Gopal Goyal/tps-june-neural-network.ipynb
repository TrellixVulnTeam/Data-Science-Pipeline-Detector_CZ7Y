{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-13T03:09:46.381514Z","iopub.execute_input":"2022-06-13T03:09:46.38191Z","iopub.status.idle":"2022-06-13T03:09:46.412064Z","shell.execute_reply.started":"2022-06-13T03:09:46.38184Z","shell.execute_reply":"2022-06-13T03:09:46.411178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset=pd.read_csv('/kaggle/input/tabular-playground-series-jun-2022/data.csv')\nsubmission=pd.read_csv('/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T06:36:40.580738Z","iopub.execute_input":"2022-06-13T06:36:40.581124Z","iopub.status.idle":"2022-06-13T06:36:51.861158Z","shell.execute_reply.started":"2022-06-13T06:36:40.58109Z","shell.execute_reply":"2022-06-13T06:36:51.860294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:21:01.926484Z","iopub.execute_input":"2022-06-13T03:21:01.926883Z","iopub.status.idle":"2022-06-13T03:21:01.951111Z","shell.execute_reply.started":"2022-06-13T03:21:01.926843Z","shell.execute_reply":"2022-06-13T03:21:01.950251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau,LearningRateScheduler,EarlyStopping\nfrom tensorflow.keras.layers import Dense,Input,InputLayer,Add,BatchNormalization,Dropout\n\nfrom sklearn.preprocessing import StandardScaler,RobustScaler,MinMaxScaler\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_absolute_error\nimport random\nimport math","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:10:04.769451Z","iopub.execute_input":"2022-06-13T03:10:04.769795Z","iopub.status.idle":"2022-06-13T03:10:10.927243Z","shell.execute_reply.started":"2022-06-13T03:10:04.769758Z","shell.execute_reply":"2022-06-13T03:10:10.926338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# define model parameters","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE=2048\nEPOCHS = 30\nVERBOSE= 0\nNUM_FOLDS=3","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:10:10.92848Z","iopub.execute_input":"2022-06-13T03:10:10.929245Z","iopub.status.idle":"2022-06-13T03:10:10.933606Z","shell.execute_reply.started":"2022-06-13T03:10:10.929206Z","shell.execute_reply":"2022-06-13T03:10:10.932891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = dataset.columns.to_list()","metadata":{"execution":{"iopub.status.busy":"2022-06-13T06:24:39.774445Z","iopub.execute_input":"2022-06-13T06:24:39.775035Z","iopub.status.idle":"2022-06-13T06:24:39.779712Z","shell.execute_reply.started":"2022-06-13T06:24:39.774995Z","shell.execute_reply":"2022-06-13T06:24:39.778774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple Network Architecture","metadata":{}},{"cell_type":"code","source":"def nn_model():\n    L2=50e-6\n    activation_function=\"relu\"\n    \n    inputs=Input(shape=(len(features)-2))\n    \n    x=Dense(128,kernel_regularizer=tf.keras.regularizers.l2(L2),\n           activation=\"relu\")(inputs)\n    x=BatchNormalization()(x)\n    \n    x=Dense(64,kernel_regularizer=tf.keras.regularizers.l2(L2),\n           activation=\"relu\")(x)\n    x=BatchNormalization()(x)\n    \n    x=Dense(32,kernel_regularizer=tf.keras.regularizers.l2(L2),\n           activation=\"relu\")(x)\n    x=BatchNormalization()(x)\n    \n    x = Dense(1 , activation = 'linear')(x) \n    \n    model=Model(inputs,x)\n    \n    return model\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:20:09.706177Z","iopub.execute_input":"2022-06-13T03:20:09.706839Z","iopub.status.idle":"2022-06-13T03:20:09.716084Z","shell.execute_reply.started":"2022-06-13T03:20:09.706802Z","shell.execute_reply":"2022-06-13T03:20:09.715278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_model(X_train, y_train, X_val, y_val, X_test, run = 0):\n    '''\n    '''\n    lr_start = 0.01\n    start_time = datetime.datetime.now()\n    \n    scaler = StandardScaler()\n    X_train = scaler.fit_transform(X_train)\n\n    epochs = EPOCHS    \n    lr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.7, patience = 4, verbose = VERBOSE)\n    es = EarlyStopping(monitor = 'val_loss',patience = 12, verbose = 1, mode = 'min', restore_best_weights = True)\n    callbacks = [lr, es]\n    \n    model = nn_model()\n    optimizer_func = tf.keras.optimizers.Adam(learning_rate = lr_start)\n    loss_func = tf.keras.losses.MeanSquaredError()\n    \n    model.compile(optimizer = optimizer_func, loss = loss_func)\n    \n    X_val = scaler.transform(X_val)\n    validation_data = (X_val, y_val)\n    \n    history = model.fit(X_train, \n                        y_train, \n                        validation_data = validation_data, \n                        epochs          = epochs,\n                        verbose         = VERBOSE,\n                        batch_size      = BATCH_SIZE,\n                        shuffle         = True,\n                        callbacks       = callbacks\n                       )\n    \n    history_list.append(history.history)\n    #print(f'Training Loss:{history_list[-1][\"loss\"][-1]:.5f}')\n    callbacks, es, lr, history = None, None, None, None\n    \n    \n    y_val_pred = model.predict(X_val, batch_size = BATCH_SIZE, verbose = VERBOSE)\n    score = mean_absolute_error(y_val, y_val_pred)\n    \n    #print(f'Fold {run}.{fold} | {str(datetime.datetime.now() - start_time)[-12:-7]}'\n    #      f'| MSE: {score:.5f}')\n    \n    score_list.append(score)\n    \n    tst_data_scaled = scaler.transform(X_test)\n    tst_pred = model.predict(tst_data_scaled)\n    predictions.append(tst_pred)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:21:08.9918Z","iopub.execute_input":"2022-06-13T03:21:08.992163Z","iopub.status.idle":"2022-06-13T03:21:09.002727Z","shell.execute_reply.started":"2022-06-13T03:21:08.992131Z","shell.execute_reply":"2022-06-13T03:21:09.001931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nimport datetime\n# missing_values = list(np.where(data[features[1]].isnull()))\n# missing_values","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:21:09.43114Z","iopub.execute_input":"2022-06-13T03:21:09.431668Z","iopub.status.idle":"2022-06-13T03:21:09.441405Z","shell.execute_reply.started":"2022-06-13T03:21:09.431634Z","shell.execute_reply":"2022-06-13T03:21:09.44024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = dataset.columns.to_list()\ndata_completed = pd.DataFrame()\n\n\nfor feat in tqdm(features):\n    # Create empty lists to store NN training metrics and predictions\n    history_list = []\n    score_list   = []\n    predictions  = []\n    \n    if dataset[feat].isnull().any():\n        #print('Training Model For: ',feat)\n        \n        # Identify missing values...\n        missing_values = list(np.where(dataset[feat].isnull())[0])\n        not_missing_values = list(np.where(dataset[feat].isnull() == False)[0])\n        \n        \n        trn_data = dataset.iloc[not_missing_values,]\n        tst_data = dataset.iloc[missing_values,]\n        \n        # Define kfolds for training purposes...\n        kf = KFold(n_splits = NUM_FOLDS)\n\n        for fold, (trn_idx, val_idx) in enumerate(kf.split(trn_data)):\n            #print(f' Training fold: {fold}...')\n            X_train, X_val = trn_data.iloc[trn_idx].drop([feat,'row_id'],axis = 1), trn_data.iloc[val_idx].drop([feat,'row_id'], axis = 1)\n            y_train, y_val = trn_data.iloc[trn_idx][feat], trn_data.iloc[val_idx][feat]\n            X_test = tst_data.drop([feat,'row_id'], axis = 1)\n            \n            X_train, X_val = X_train.fillna(X_train.mean()), X_val.fillna(X_val.mean())\n            X_test = X_test.fillna(X_test.mean())\n            \n            fit_model(X_train, y_train, X_val, y_val, X_test)\n        \n        mean_values = np.array(predictions).mean(axis = 0)\n        imputed_data = dataset[feat]\n        imputed_data.iloc[missing_values] = mean_values.ravel()\n        data_completed = pd.concat([data_completed, imputed_data],axis = 1)\n    \n    else:\n        data_completed = pd.concat([data_completed, dataset[feat]],axis = 1)","metadata":{"execution":{"iopub.status.busy":"2022-06-13T03:21:09.949387Z","iopub.execute_input":"2022-06-13T03:21:09.949735Z","iopub.status.idle":"2022-06-13T06:24:39.772673Z","shell.execute_reply.started":"2022-06-13T03:21:09.949705Z","shell.execute_reply":"2022-06-13T06:24:39.771824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# For submission","metadata":{}},{"cell_type":"code","source":"data_completed","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv', index_col='row-col')","metadata":{"execution":{"iopub.status.busy":"2022-06-13T06:37:42.04208Z","iopub.execute_input":"2022-06-13T06:37:42.042943Z","iopub.status.idle":"2022-06-13T06:37:42.762201Z","shell.execute_reply.started":"2022-06-13T06:37:42.042899Z","shell.execute_reply":"2022-06-13T06:37:42.761376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(submission.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    submission.loc[i, 'value'] = data_completed.loc[row, col]\n\nsubmission.to_csv(\"submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-13T06:37:56.417615Z","iopub.execute_input":"2022-06-13T06:37:56.418281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}