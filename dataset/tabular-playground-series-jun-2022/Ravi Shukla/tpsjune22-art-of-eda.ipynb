{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Art of EDA\n> - In this Notebook, I will perform the Exploratory Data Analysis with the aim to describe the nuances in the data which would help one to do strong feature engineering and build robust models.\n> - My biggest motive is to promote the use of statistics in the EDA process.\n> - Please Upvote if you find this notebook useful.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T06:28:24.927368Z","iopub.execute_input":"2022-06-01T06:28:24.92784Z","iopub.status.idle":"2022-06-01T06:28:24.935352Z","shell.execute_reply.started":"2022-06-01T06:28:24.927801Z","shell.execute_reply":"2022-06-01T06:28:24.934457Z"}}},{"cell_type":"markdown","source":"---\n\n# Import Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:26:51.153492Z","iopub.execute_input":"2022-06-01T07:26:51.154205Z","iopub.status.idle":"2022-06-01T07:26:52.319872Z","shell.execute_reply.started":"2022-06-01T07:26:51.154036Z","shell.execute_reply":"2022-06-01T07:26:52.318901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Data Loading","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")\nsub = pd.read_csv(\"../input/tabular-playground-series-jun-2022/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:26:52.321868Z","iopub.execute_input":"2022-06-01T07:26:52.322413Z","iopub.status.idle":"2022-06-01T07:27:16.646237Z","shell.execute_reply.started":"2022-06-01T07:26:52.322361Z","shell.execute_reply":"2022-06-01T07:27:16.645071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# EDA","metadata":{}},{"cell_type":"code","source":"print(data.shape)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:16.647744Z","iopub.execute_input":"2022-06-01T07:27:16.648114Z","iopub.status.idle":"2022-06-01T07:27:16.721325Z","shell.execute_reply.started":"2022-06-01T07:27:16.64808Z","shell.execute_reply":"2022-06-01T07:27:16.720234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.tail()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:16.723495Z","iopub.execute_input":"2022-06-01T07:27:16.723921Z","iopub.status.idle":"2022-06-01T07:27:16.788238Z","shell.execute_reply.started":"2022-06-01T07:27:16.723884Z","shell.execute_reply":"2022-06-01T07:27:16.787084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Summary","metadata":{}},{"cell_type":"code","source":"print(\"Data Summary\")\nprint(\"-\"*50)\nprint(f\"Total number of rows -- {data.shape[0]}\")\nprint(f\"Total number of columns -- {data.shape[1]}\")\nprint(\"-\"*50)\nprint(f\"Missing values per column -- \\n{data.isnull().sum()}\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:16.789789Z","iopub.execute_input":"2022-06-01T07:27:16.790174Z","iopub.status.idle":"2022-06-01T07:27:16.96854Z","shell.execute_reply.started":"2022-06-01T07:27:16.79014Z","shell.execute_reply":"2022-06-01T07:27:16.967149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In the above summary, we can see that all the columns except `row_id` and the columns with prefix `F_2` have null values\n\nLets do some more analysis on columns ","metadata":{}},{"cell_type":"markdown","source":"## Column Summary","metadata":{}},{"cell_type":"code","source":"def print_column_summary(data):\n    name = []\n    dtype = []\n    unique_values = []\n    missing = []\n    for column in data.columns:\n        name.append(str(column))\n        data_type = str(data[column].dtypes)\n        dtype.append(data_type)\n        if(data_type == 'float64'):\n            unique_values.append(\"\")\n        else:\n            unique_values.append(str(data[column].nunique()))\n        missing.append(\"{:0.2f} % \".format(data[column].isnull().sum() / data.shape[0] * 100))\n    \n    dfSummary = pd.DataFrame(name,columns = [\"Name\"])\n    dfSummary[\"Dtypes\"] = dtype\n    dfSummary[\"Unique Value Count\"] = unique_values\n    dfSummary[\"Missing Value %\"] = missing\n    return dfSummary","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:01:24.087376Z","iopub.execute_input":"2022-06-01T08:01:24.088889Z","iopub.status.idle":"2022-06-01T08:01:24.100474Z","shell.execute_reply.started":"2022-06-01T08:01:24.088831Z","shell.execute_reply":"2022-06-01T08:01:24.099351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"summary = print_column_summary(data)\nsummary","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:01:26.462265Z","iopub.execute_input":"2022-06-01T08:01:26.462793Z","iopub.status.idle":"2022-06-01T08:01:26.913112Z","shell.execute_reply.started":"2022-06-01T08:01:26.462749Z","shell.execute_reply":"2022-06-01T08:01:26.911697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Note on Columns -- \n\n> - row_id is the primary key\n> - The columns with prefix `F_2` are categorical and have no nulls\n> - All the other columns have float values and have nulls which we need to impute in this competetion\n> - All the float columns have nearly 1.8% null values","metadata":{}},{"cell_type":"code","source":"print(\"-\"*50)\nprint(\"Variable Dataypes :-\")\nprint(summary.Dtypes.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:17.435324Z","iopub.execute_input":"2022-06-01T07:27:17.436021Z","iopub.status.idle":"2022-06-01T07:27:17.446812Z","shell.execute_reply.started":"2022-06-01T07:27:17.43597Z","shell.execute_reply":"2022-06-01T07:27:17.445678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Analyze float64 features\n\nThere are 55 float64 features, lets plot there histogram individually\n\n","metadata":{}},{"cell_type":"code","source":"float_features = [f for f in data.columns if data[f].dtype == 'float64']\n\n# Training histograms\nfig, axs = plt.subplots(len(float_features)//4 + 1, 4, figsize=(16, 50))\nfor f, ax in zip(float_features, axs.ravel()):\n    ax.hist(data[f], density=True, bins=100)\n    ax.set_title(f'data {f}, std={data[f].std():.1f}')\nplt.suptitle('Histograms of the float features')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:17.448091Z","iopub.execute_input":"2022-06-01T07:27:17.448463Z","iopub.status.idle":"2022-06-01T07:27:36.96558Z","shell.execute_reply.started":"2022-06-01T07:27:17.44843Z","shell.execute_reply":"2022-06-01T07:27:36.96414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All the float 64 columns are standardized so that they have near to normal distribution","metadata":{}},{"cell_type":"markdown","source":"## Correlation Plot","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(30, 30))\nsns.heatmap(data[float_features].corr(), center=0, annot=True, fmt='.1f')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:36.969308Z","iopub.execute_input":"2022-06-01T07:27:36.969974Z","iopub.status.idle":"2022-06-01T07:27:57.923282Z","shell.execute_reply.started":"2022-06-01T07:27:36.969929Z","shell.execute_reply":"2022-06-01T07:27:57.922317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_redundant_pairs(df):\n    '''Get diagonal and lower triangular pairs of correlation matrix'''\n    pairs_to_drop = set()\n    cols = df.columns\n    for i in range(0, df.shape[1]):\n        for j in range(0, i+1):\n            pairs_to_drop.add((cols[i], cols[j]))\n    return pairs_to_drop\n\ndef get_top_abs_correlations(df, n=5):\n    au_corr = df.corr().abs().unstack()\n    labels_to_drop = get_redundant_pairs(df)\n    au_corr = au_corr.drop(labels=labels_to_drop).sort_values(ascending=False)\n    return au_corr[0:n]\n\nprint(\"Top 2 Absolute Correlations\")\nprint(get_top_abs_correlations(data[float_features], 2))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:27:57.924623Z","iopub.execute_input":"2022-06-01T07:27:57.925599Z","iopub.status.idle":"2022-06-01T07:28:07.096202Z","shell.execute_reply.started":"2022-06-01T07:27:57.925557Z","shell.execute_reply":"2022-06-01T07:28:07.094967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Columns `F_4_8` and `F_4_11` have the highest correlation. \n\nCorrelation among different columns might be useful while performing the imputation","metadata":{}},{"cell_type":"markdown","source":"## Plot the bar graph to demonstrate number of missing values per column\n\nIn our previous analysis, we have seen all the float64 columns have nearly 1.8% null values, lets plot them for more clarity.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(20, 60))\nmissing_values = data[float_features].isnull().sum()\nmissing_values.plot(\n    kind=\"barh\", title=\"Number of Missing Values per Sample\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:28:07.098106Z","iopub.execute_input":"2022-06-01T07:28:07.098558Z","iopub.status.idle":"2022-06-01T07:28:08.404789Z","shell.execute_reply.started":"2022-06-01T07:28:07.098517Z","shell.execute_reply":"2022-06-01T07:28:08.403577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets analyze first 200 rows for missing values\n\nWe are analyzing only `float64` columns since they are the ones with missing values","metadata":{}},{"cell_type":"code","source":"import missingno as msno\nmsno.matrix(data[float_features].sample(200))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:33:56.898699Z","iopub.execute_input":"2022-06-01T07:33:56.899402Z","iopub.status.idle":"2022-06-01T07:33:57.600789Z","shell.execute_reply.started":"2022-06-01T07:33:56.899346Z","shell.execute_reply":"2022-06-01T07:33:57.599549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of missing values per sample","metadata":{}},{"cell_type":"code","source":"n_missing = data[float_features].isnull().sum(axis=1)\nn_missing.value_counts().plot(\n    kind=\"bar\", title=\"Number of Missing Values per Sample\"\n)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:45:19.018152Z","iopub.execute_input":"2022-06-01T07:45:19.018709Z","iopub.status.idle":"2022-06-01T07:45:19.58884Z","shell.execute_reply.started":"2022-06-01T07:45:19.018664Z","shell.execute_reply":"2022-06-01T07:45:19.588094Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Analyze int64 features\n\nThere are 26 int64 features, lets plot their value counts\n\n","metadata":{}},{"cell_type":"code","source":"int_features = [f for f in data.columns if data[f].dtype == 'int64']\nint_features.pop(0) \nfig, axs = plt.subplots(len(int_features)//3 + 1, 3, figsize=(20, 30))\n\nfor i,col in enumerate(int_features):\n    data[col].value_counts(normalize = True).plot(kind = 'bar',ax = axs[i//3][i%3], title =col )","metadata":{"execution":{"iopub.status.busy":"2022-06-01T07:28:08.40632Z","iopub.execute_input":"2022-06-01T07:28:08.406856Z","iopub.status.idle":"2022-06-01T07:28:13.554936Z","shell.execute_reply.started":"2022-06-01T07:28:08.40681Z","shell.execute_reply":"2022-06-01T07:28:13.553767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> - All the `int64` have rare class problem\n> - None of the `int64` columns are binary or ternary","metadata":{}},{"cell_type":"markdown","source":"---\n\n# Simple mean imputer\n\nLets try to build a simple mean imputer\n\nFollowing implementation has been motivated by @reymaster's work <a href = \"https://www.kaggle.com/code/reymaster/starter-code-sklearn-simpleimputer/notebook?scriptVersionId=97156185\"> link here</a>\n","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimputer = SimpleImputer()\nimputed_df = pd.DataFrame(imputer.fit_transform(data), columns = data.columns)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:28:48.501225Z","iopub.execute_input":"2022-06-01T08:28:48.501718Z","iopub.status.idle":"2022-06-01T08:28:51.730647Z","shell.execute_reply.started":"2022-06-01T08:28:48.501683Z","shell.execute_reply":"2022-06-01T08:28:51.729399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, row in enumerate(sub.values):\n    row_col = row[0]\n    imputed_row = row_col.split(\"-\")[0] #get the row index\n    imputed_col = row_col.split(\"-\")[1] #get the column index\n    sub.at[i, \"value\"] = imputed_df.iloc[int(imputed_row)][imputed_col]","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:28:53.754102Z","iopub.execute_input":"2022-06-01T08:28:53.75492Z","iopub.status.idle":"2022-06-01T08:30:31.060987Z","shell.execute_reply.started":"2022-06-01T08:28:53.754873Z","shell.execute_reply":"2022-06-01T08:30:31.059808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:31:11.507025Z","iopub.execute_input":"2022-06-01T08:31:11.507607Z","iopub.status.idle":"2022-06-01T08:31:11.519286Z","shell.execute_reply.started":"2022-06-01T08:31:11.50756Z","shell.execute_reply":"2022-06-01T08:31:11.518427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T08:31:11.521307Z","iopub.execute_input":"2022-06-01T08:31:11.521954Z","iopub.status.idle":"2022-06-01T08:31:15.572768Z","shell.execute_reply.started":"2022-06-01T08:31:11.521907Z","shell.execute_reply":"2022-06-01T08:31:15.571539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# To be continued ..","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}