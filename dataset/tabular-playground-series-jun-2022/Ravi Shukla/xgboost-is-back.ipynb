{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# XGBoost is Back!!\n## Imputation Using XGBoost\n\n> - In this notebook, we will use XGBoost to impute the missing values\n> - This notebook is based on the EDA done in the notebook <a href = \"https://www.kaggle.com/code/raviista/tpsjune22-art-of-eda\">link here</a>\n> - Please Upvote if you find my work useful","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-01T10:58:57.791907Z","iopub.execute_input":"2022-06-01T10:58:57.79281Z","iopub.status.idle":"2022-06-01T10:58:58.466641Z","shell.execute_reply.started":"2022-06-01T10:58:57.792764Z","shell.execute_reply":"2022-06-01T10:58:58.465841Z"}}},{"cell_type":"markdown","source":"---\n\n# Import Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n\nfrom xgboost import XGBRegressor\nfrom tqdm import tqdm\n\n## For Suppressing the warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:42:55.828853Z","iopub.execute_input":"2022-06-01T12:42:55.829326Z","iopub.status.idle":"2022-06-01T12:42:55.841455Z","shell.execute_reply.started":"2022-06-01T12:42:55.829287Z","shell.execute_reply":"2022-06-01T12:42:55.839655Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Load the data","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")\nsub = pd.read_csv('../input/tabular-playground-series-jun-2022/sample_submission.csv', index_col='row-col') #, index_col='row_id'","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:40:58.76717Z","iopub.execute_input":"2022-06-01T12:40:58.768269Z","iopub.status.idle":"2022-06-01T12:41:11.174598Z","shell.execute_reply.started":"2022-06-01T12:40:58.768218Z","shell.execute_reply":"2022-06-01T12:41:11.173562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:41:11.175989Z","iopub.execute_input":"2022-06-01T12:41:11.176364Z","iopub.status.idle":"2022-06-01T12:41:11.202247Z","shell.execute_reply.started":"2022-06-01T12:41:11.176328Z","shell.execute_reply":"2022-06-01T12:41:11.20136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Creating Categorical features while handling rare class problem in int64 features","metadata":{}},{"cell_type":"code","source":"def categorize(data,col,threshold = 2 ):\n    series = pd.value_counts(data[col], normalize = True)\n    mask = (series* 100).lt(threshold)\n    data[f\"cat_{col}\"] = np.where(data[col].isin(series[mask].index),'Other',data[col])\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:41:11.203362Z","iopub.execute_input":"2022-06-01T12:41:11.204354Z","iopub.status.idle":"2022-06-01T12:41:11.213588Z","shell.execute_reply.started":"2022-06-01T12:41:11.204311Z","shell.execute_reply":"2022-06-01T12:41:11.21254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int_features = [f for f in data.columns if data[f].dtype == 'int64' and f != 'row_id' and f.startswith(\"F_2\")]\n\nprint(\"Preprocessing int64 feature starts !!\")\nfor col in int_features:\n    print(f\"Feature -- {col}\")\n    data = categorize(data, col)\nprint(\"Done!!\")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:41:11.215271Z","iopub.execute_input":"2022-06-01T12:41:11.215709Z","iopub.status.idle":"2022-06-01T12:41:29.202286Z","shell.execute_reply.started":"2022-06-01T12:41:11.215668Z","shell.execute_reply":"2022-06-01T12:41:29.201306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cat_cols = [col for col in data.columns if col.startswith(\"cat_F_2\")]\nprint(cat_cols)\ndata_cat_cols = pd.get_dummies(data[cat_cols])\ndata_cat_cols.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:41:29.204844Z","iopub.execute_input":"2022-06-01T12:41:29.205268Z","iopub.status.idle":"2022-06-01T12:41:32.659274Z","shell.execute_reply.started":"2022-06-01T12:41:29.205228Z","shell.execute_reply":"2022-06-01T12:41:32.657439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Concatening the data","metadata":{}},{"cell_type":"code","source":"float_features = [f for f in data.columns if data[f].dtype == 'float64']\n\ntotal_data = pd.concat([data[\"row_id\"] , data_cat_cols,data[float_features]], axis = 1)\ntotal_data.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:41:32.660843Z","iopub.execute_input":"2022-06-01T12:41:32.661259Z","iopub.status.idle":"2022-06-01T12:41:33.006232Z","shell.execute_reply.started":"2022-06-01T12:41:32.661223Z","shell.execute_reply":"2022-06-01T12:41:33.005399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"total_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:41:33.007685Z","iopub.execute_input":"2022-06-01T12:41:33.00806Z","iopub.status.idle":"2022-06-01T12:41:33.03421Z","shell.execute_reply.started":"2022-06-01T12:41:33.008032Z","shell.execute_reply":"2022-06-01T12:41:33.033347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Modeling\n\nFor modeling, I am using xgBoost in this notebook \n\nFor every `float64` feature, I am setting train, validation and test as follow :-\n> - Filtering all the rows having non-null for that feature\n> - Imputing null values for remaining features with -999, which will be used to inform xgboost regarding missing values. (Here we are using imputation approach provided by XGBoost)\n> - 80% of the above comprises train\n> - 20% of remaining comprises validation\n> - All the rows having nulls for that feature are set as test\n\nI am creating the dataset with above split for every `float64` feature and training xgBoost model to predict for null records of that features","metadata":{}},{"cell_type":"code","source":"for column in float_features:\n    print(\"-\"*50)\n    print(f\"Modeling for the column - {column}\")\n    featuresToUse = list(total_data.columns)\n    featuresToUse.remove(column)\n    featuresToUse.remove(\"row_id\")\n\n    test = total_data[total_data[column].isna()]\n    print(f\"Shape of test data - {test.shape}\")\n    total_data_left = total_data.loc[(~total_data.index.isin(test.index))]\n\n    train = total_data_left.sample(frac=0.8, random_state=18)\n\n    val  = total_data_left.loc[(~total_data_left.index.isin(train.index)) ]\n    train_x = train[featuresToUse]\n    train_y = train[column]\n    val_x = val[featuresToUse]\n    val_y = val[column]    \n    print(f\"Number of records for training - {train_x.shape[0]}, for validation -  {val_x.shape[0]}\")\n    train_x = train_x.fillna(-999)\n    val_x = val_x.fillna(-999)\n\n    xgb =  XGBRegressor(n_estimators = 100 , learning_rate = 0.1,missing=-999.0,tree_method = \"gpu_hist\")\n\n    xgb.fit(train_x, train_y, eval_set=[(train_x,train_y),(val_x, val_y)], eval_metric='rmse',early_stopping_rounds = 10,verbose = False)\n\n    test_x = test[featuresToUse]\n    pred = xgb.predict(test_x)\n    test[\"output\"] = pred\n    test = test[[\"row_id\",\"output\"]]\n    print(f\"Null records in column - {column} before imputation - {data[column].isnull().sum()} \")\n    for i, row in enumerate(test.values):\n        row_id = row[0]      \n        pred = row[1]\n        data.loc[row_id,column] = pred\n    print(f\"Null records in column - {column} after imputation - {data[column].isnull().sum()} \")\n","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:45:53.814229Z","iopub.execute_input":"2022-06-01T12:45:53.814649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n\n# Generating the submission data","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:04:17.508751Z","iopub.execute_input":"2022-06-01T12:04:17.5091Z","iopub.status.idle":"2022-06-01T12:04:17.5207Z","shell.execute_reply.started":"2022-06-01T12:04:17.50907Z","shell.execute_reply":"2022-06-01T12:04:17.519611Z"}}},{"cell_type":"code","source":"for i in tqdm(sub.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    sub.loc[i, 'value'] = data.loc[row, col]\n\nsub.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:20:39.342559Z","iopub.execute_input":"2022-06-01T12:20:39.343131Z","iopub.status.idle":"2022-06-01T12:22:13.055827Z","shell.execute_reply.started":"2022-06-01T12:20:39.343093Z","shell.execute_reply":"2022-06-01T12:22:13.054917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T12:22:13.060735Z","iopub.execute_input":"2022-06-01T12:22:13.063324Z","iopub.status.idle":"2022-06-01T12:22:13.078055Z","shell.execute_reply.started":"2022-06-01T12:22:13.063282Z","shell.execute_reply":"2022-06-01T12:22:13.076773Z"},"trusted":true},"execution_count":null,"outputs":[]}]}