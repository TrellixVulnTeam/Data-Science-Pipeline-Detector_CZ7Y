{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection\nfrom sklearn.metrics import r2_score\nimport lightgbm as lgb","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-24T23:05:53.007928Z","iopub.execute_input":"2022-06-24T23:05:53.008355Z","iopub.status.idle":"2022-06-24T23:05:55.440854Z","shell.execute_reply.started":"2022-06-24T23:05:53.008267Z","shell.execute_reply":"2022-06-24T23:05:55.439951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check on the panda version and its dependencies\n# i run this from time to time to ensure all is up to date\npd.__version__\n#pd.show_versions()","metadata":{"execution":{"iopub.status.busy":"2022-06-24T23:06:25.15211Z","iopub.execute_input":"2022-06-24T23:06:25.152593Z","iopub.status.idle":"2022-06-24T23:06:25.159379Z","shell.execute_reply.started":"2022-06-24T23:06:25.152501Z","shell.execute_reply":"2022-06-24T23:06:25.158509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i use these to input the relevant file names\n# which i downloaded earlier and sit in the same directory as this\nfile_train = '/kaggle/input/tabular-playground-series-jun-2022/data.csv'\nfile_test = '/kaggle/input/tabular-playground-series-jun-2022/data.csv'\nfile_sampleSubmission = '/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv'\nsubmission_dataframe = '/kaggle/working/submission_1.csv'\nsubmission_dataframe_1 = '/kaggle/input/submission-1/submission_1.csv'","metadata":{"execution":{"iopub.status.busy":"2022-06-24T23:06:29.22147Z","iopub.execute_input":"2022-06-24T23:06:29.221873Z","iopub.status.idle":"2022-06-24T23:06:29.227817Z","shell.execute_reply.started":"2022-06-24T23:06:29.221838Z","shell.execute_reply":"2022-06-24T23:06:29.226635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# which makes this a standard cell and keeps the original traing and test data in memory\n# use train for the training data, test for the test data\n# and also download the sample submission for quick reference\ndf_train = pd.read_csv(file_train)\ndf_test = pd.read_csv(file_test)\ndf_sampleSubmission = pd.read_csv(file_sampleSubmission)\n\n# check if a submission dataframe exists\ntry:\n    submission = pd.read_csv(submission_dataframe)\n    submission_file = 1\n    print('file on kaggle')\n\nexcept:\n    # check if a submission dataframe exists on my PC that i uploaded to kaggle\n    try:\n        submission = pd.read_csv(submission_dataframe_1)\n        submission_file = 1\n        print('file from PC')\n        \n    except:\n        # i will need to create a submission datafrom from the start\n        submission_file = 0","metadata":{"execution":{"iopub.status.busy":"2022-06-24T23:06:33.259718Z","iopub.execute_input":"2022-06-24T23:06:33.260778Z","iopub.status.idle":"2022-06-24T23:07:10.388767Z","shell.execute_reply.started":"2022-06-24T23:06:33.260714Z","shell.execute_reply":"2022-06-24T23:07:10.386774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-06-24T23:08:08.815161Z","iopub.execute_input":"2022-06-24T23:08:08.815667Z","iopub.status.idle":"2022-06-24T23:08:09.004845Z","shell.execute_reply.started":"2022-06-24T23:08:08.815614Z","shell.execute_reply":"2022-06-24T23:08:09.003636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# my plan here is to go through each column that has null data\n# make it the target column and that defines the test data set\n# i.e. all the rows with null values in that column\n# and then use the rest of the rows as training data for that column\n# sp this will be many models trained and executed in one program\n# i will use lightgbm given it ignores missing data\n# also, as i go along i will save the submission file\n# therefore, if the code stops i can restart it from where it left off","metadata":{"execution":{"iopub.status.busy":"2022-06-24T23:08:12.289023Z","iopub.execute_input":"2022-06-24T23:08:12.289448Z","iopub.status.idle":"2022-06-24T23:08:12.294299Z","shell.execute_reply.started":"2022-06-24T23:08:12.289388Z","shell.execute_reply":"2022-06-24T23:08:12.293488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up the submission dataframe\n# i will delete the first dummy row at the end\n\n# check if the submission file exists otherwise create one\n\nif submission_file == 0:\n    submission = pd.DataFrame(['remove me'],columns=['row-col'])\n    submission['value'] = 0.00\nelse:\n    pass","metadata":{"execution":{"iopub.status.busy":"2022-06-24T23:08:13.989004Z","iopub.execute_input":"2022-06-24T23:08:13.989415Z","iopub.status.idle":"2022-06-24T23:08:13.995756Z","shell.execute_reply.started":"2022-06-24T23:08:13.98938Z","shell.execute_reply":"2022-06-24T23:08:13.994518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-24T23:08:16.291036Z","iopub.execute_input":"2022-06-24T23:08:16.291401Z","iopub.status.idle":"2022-06-24T23:08:16.308883Z","shell.execute_reply.started":"2022-06-24T23:08:16.291373Z","shell.execute_reply":"2022-06-24T23:08:16.307227Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the targets will be every column in the test data with missing data\n# i will loop through them making each on the target in turn\n\ncol_targets_all = df_train.columns[df_train.isnull().any()].tolist()\n\nprint('number of targets', len(col_targets_all), col_targets_all)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T21:35:52.003348Z","iopub.status.idle":"2022-06-24T21:35:52.003958Z","shell.execute_reply.started":"2022-06-24T21:35:52.003646Z","shell.execute_reply":"2022-06-24T21:35:52.003673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# eliminate any items in col_targets_all that are already in the submission dataframe\n# i.e. only run on the columns that have not yet been done in prior running of the code\n\nsubmission_list = submission['row-col'].tolist()\ncombined = '\\t'.join(submission_list)\npresent=[]\n\nfor i in range(len(col_targets_all)):\n    if col_targets_all[i] in combined:\n        present.append(col_targets_all[i])\n        \ncol_targets = sorted(list(set(col_targets_all) - set(present)))\nprint('number of targets', len(col_targets), col_targets)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T21:35:52.006054Z","iopub.status.idle":"2022-06-24T21:35:52.006624Z","shell.execute_reply.started":"2022-06-24T21:35:52.00633Z","shell.execute_reply":"2022-06-24T21:35:52.006357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loop through each column with null values\n# that column is the target and a new model is trained each time\n\n# loop through those data sets creating a new model for each\nfor i in range(len(col_targets)):\n\n    # keep a printed record of where we are\n    print('starting', col_targets[i], i, 'of', len(col_targets)-1)\n    \n    final_predictions = []\n    final_valid_predictions = {}\n    scores = []\n\n    # set up the test data\n    df_test_new = df_test.copy()\n    df_test_new = df_test_new[df_test_new[col_targets[i]].isnull()]\n    df_test_new = df_test_new.reset_index()\n    \n    # set up the training data\n    df_train_new = df_train.copy()\n    df_train_new = df_train_new[~df_train_new[col_targets[i]].isnull()]\n    df_train_new = df_train_new.reset_index()\n\n    # set up the kfolds\n    df_train_new['kfolds'] = -1\n    \n    # now populate the 'folds' column with a fold identifier\n    # try 5 folds for now\n    fold_no = 5\n    kf = model_selection.KFold(n_splits=fold_no, shuffle=True, random_state=0)\n    for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train_new)):\n        df_train_new.loc[valid_indicies, \"kfolds\"] = fold\n    \n    # go through the folds running the model on each\n    for fold in range(fold_no):\n        \n        # set up the training, validity and test data\n        xtrain =  df_train_new[df_train_new['kfolds'] != fold].reset_index(drop=True)\n        xvalid = df_train_new[df_train_new['kfolds'] == fold].reset_index(drop=True)\n        xtest = df_test_new.copy()\n\n        # i need to keep a record of the row_id for the submission and validity scores\n        xtest_ids = xtest.row_id.values.tolist()     \n        valid_ids = xvalid.row_id.values.tolist()\n\n        # set up the useful features\n        # which is the column headers except index, row_id and kfolds\n        useful_features = xtrain.columns.tolist()\n        useful_features.remove('index')\n        useful_features.remove('row_id')\n        useful_features.remove('kfolds')\n  \n        # set the target column\n        ytrain = xtrain[col_targets[i]]\n        yvalid = xvalid[col_targets[i]]\n\n        # set the useful_features\n        xtrain = xtrain[useful_features]\n        xvalid = xvalid[useful_features]\n        xtest = xtest[useful_features]\n        \n        # remove the target column from the training, validity and test data\n        xtrain = xtrain.drop(col_targets[i], axis=1)\n        xvalid = xvalid.drop(col_targets[i], axis=1)        \n        xtest = xtest.drop(col_targets[i], axis=1)\n\n        # run the model\n        # n_esimators limited by processing time allowed\n        model = lgb.LGBMRegressor(random_state=0, n_jobs=-1, \n                                  n_estimators=10000)\n        model.fit(xtrain, ytrain, eval_set=[(xvalid, yvalid)],\n                 callbacks=[lgb.early_stopping(stopping_rounds=1000)])\n\n        # get the validity and test predictions\n        preds_valid = model.predict(xvalid)\n        test_preds = model.predict(xtest)\n        final_predictions.append(test_preds)\n        final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n        \n        # print the validity score\n        model_score = r2_score(yvalid, preds_valid)\n        print(fold, model_score)\n        scores.append(model_score)\n\n    print(np.mean(scores), np.std(scores))\n    \n    # get the mean of the final_predictions across the folds\n    df_final_predictions = pd.DataFrame(final_predictions).T\n    df_final_predictions['mean_preds'] = df_final_predictions.mean(axis=1)    \n    \n    # build up the submission file\n    strings = [str(x) for x in xtest_ids]\n    strings = [s + '-' for s in strings]\n    row_col_ids = [s + col_targets[i] for s in strings]\n    submission_add = pd.DataFrame(row_col_ids,columns=['row-col'])\n    submission_add['value'] = df_final_predictions['mean_preds'].tolist()\n\n    # combine the submission dataframes so far to build up the total submission dataframe\n    submission = pd.concat([submission, submission_add])\n    \n    # save the submission dataframe as we go\n    submission.to_csv(\"submission_1.csv\", header=[\"row-col\", \"value\"], index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T21:35:52.008299Z","iopub.status.idle":"2022-06-24T21:35:52.008871Z","shell.execute_reply.started":"2022-06-24T21:35:52.008571Z","shell.execute_reply":"2022-06-24T21:35:52.008597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove the dummy first row\nsubmission = submission.iloc[1: , :]","metadata":{"execution":{"iopub.status.busy":"2022-06-24T21:35:52.011116Z","iopub.status.idle":"2022-06-24T21:35:52.01167Z","shell.execute_reply.started":"2022-06-24T21:35:52.011375Z","shell.execute_reply":"2022-06-24T21:35:52.0114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-24T21:35:52.012848Z","iopub.status.idle":"2022-06-24T21:35:52.013388Z","shell.execute_reply.started":"2022-06-24T21:35:52.013104Z","shell.execute_reply":"2022-06-24T21:35:52.01313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save as a csv for submission\ncolumn_names = [\"row-col\", \"value\"]\nsubmission.to_csv(\"submission.csv\", header=column_names, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-24T21:35:52.014803Z","iopub.status.idle":"2022-06-24T21:35:52.015335Z","shell.execute_reply.started":"2022-06-24T21:35:52.015064Z","shell.execute_reply":"2022-06-24T21:35:52.015088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}