{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom IPython.display import display\nimport matplotlib.pyplot as plt\n\nfrom sklearn import model_selection\nfrom sklearn.metrics import r2_score\nimport lightgbm as lgb","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:56:49.806524Z","iopub.execute_input":"2022-06-22T16:56:49.807437Z","iopub.status.idle":"2022-06-22T16:56:51.063073Z","shell.execute_reply.started":"2022-06-22T16:56:49.807357Z","shell.execute_reply":"2022-06-22T16:56:51.061515Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check on the panda version and its dependencies\n# i run this from time to time to ensure all is up to date\npd.__version__\n#pd.show_versions()","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:56:51.06945Z","iopub.execute_input":"2022-06-22T16:56:51.06982Z","iopub.status.idle":"2022-06-22T16:56:51.078923Z","shell.execute_reply.started":"2022-06-22T16:56:51.069784Z","shell.execute_reply":"2022-06-22T16:56:51.07756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# i use these to input the relevant file names\n# which i downloaded earlier and sit in the same directory as this\nfile_train = '/kaggle/input/tabular-playground-series-jun-2022/data.csv'\nfile_test = '/kaggle/input/tabular-playground-series-jun-2022/data.csv'\nfile_sampleSubmission = '/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv'","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:56:51.080513Z","iopub.execute_input":"2022-06-22T16:56:51.08093Z","iopub.status.idle":"2022-06-22T16:56:51.089658Z","shell.execute_reply.started":"2022-06-22T16:56:51.080894Z","shell.execute_reply":"2022-06-22T16:56:51.088727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# which makes this a standard cell and keeps the original traing and test data in memory\n# use train for the training data, test for the test data\n# and also download the sample submission for quick reference\ndf_train = pd.read_csv(file_train)\ndf_test = pd.read_csv(file_test)\ndf_sampleSubmission = pd.read_csv(file_sampleSubmission)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:56:51.093046Z","iopub.execute_input":"2022-06-22T16:56:51.093584Z","iopub.status.idle":"2022-06-22T16:57:28.242627Z","shell.execute_reply.started":"2022-06-22T16:56:51.093546Z","shell.execute_reply":"2022-06-22T16:57:28.240993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:57:28.244659Z","iopub.execute_input":"2022-06-22T16:57:28.24521Z","iopub.status.idle":"2022-06-22T16:57:28.437035Z","shell.execute_reply.started":"2022-06-22T16:57:28.245156Z","shell.execute_reply":"2022-06-22T16:57:28.435444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# my plan here is to go through each column that has null data\n# make it the target column and that defines the test data set\n# i.e. all the rows with null values in that column\n# and then use the rest of the rows as training data for that column\n# sp this will be many models trained and executed in one program\n# i will use lightgbm given it ignores missing data","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:57:28.439041Z","iopub.execute_input":"2022-06-22T16:57:28.44019Z","iopub.status.idle":"2022-06-22T16:57:28.446105Z","shell.execute_reply.started":"2022-06-22T16:57:28.440122Z","shell.execute_reply":"2022-06-22T16:57:28.444813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# the targets will be every column in the test data with missing data\n# i will loop through them making each on the target in turn\n\ncol_targets = df_train.columns[df_train.isnull().any()].tolist()\n\nprint('number of targets', len(col_targets), col_targets)","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:57:28.448819Z","iopub.execute_input":"2022-06-22T16:57:28.44994Z","iopub.status.idle":"2022-06-22T16:57:28.542354Z","shell.execute_reply.started":"2022-06-22T16:57:28.449881Z","shell.execute_reply":"2022-06-22T16:57:28.541081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set up the submission dataframe\n# i will delete the first dummy row at the end\n\nsubmission = pd.DataFrame(['remove me'],columns=['row-col'])\nsubmission['value'] = 0.00\nsubmission","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:57:28.544077Z","iopub.execute_input":"2022-06-22T16:57:28.544628Z","iopub.status.idle":"2022-06-22T16:57:28.564005Z","shell.execute_reply.started":"2022-06-22T16:57:28.544577Z","shell.execute_reply":"2022-06-22T16:57:28.560199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# loop through each column with null values\n# that column is the target and a new model is trained each time\n\n# loop through those data sets creating a new model for each\nfor i in range(len(col_targets)):\n\n    # keep a printed record of where we are\n    print('starting', col_targets[i], i, 'of', len(col_targets)-1)\n    \n    final_predictions = []\n    final_valid_predictions = {}\n    scores = []\n\n    # set up the test data\n    df_test_new = df_test.copy()\n    df_test_new = df_test_new[df_test_new[col_targets[i]].isnull()]\n    df_test_new = df_test_new.reset_index()\n    \n    # set up the training data\n    df_train_new = df_train.copy()\n    df_train_new = df_train_new[~df_train_new[col_targets[i]].isnull()]\n    df_train_new = df_train_new.reset_index()\n\n    # set up the kfolds\n    df_train_new['kfolds'] = -1\n    \n    # now populate the 'folds' column with a fold identifier\n    # try 5 folds for now\n    fold_no = 5\n    kf = model_selection.KFold(n_splits=fold_no, shuffle=True, random_state=0)\n    for fold, (train_indicies, valid_indicies) in enumerate(kf.split(X=df_train_new)):\n        df_train_new.loc[valid_indicies, \"kfolds\"] = fold\n    \n    # go through the folds running the model on each\n    for fold in range(fold_no):\n        \n        # set up the training, validity and test data\n        xtrain =  df_train_new[df_train_new['kfolds'] != fold].reset_index(drop=True)\n        xvalid = df_train_new[df_train_new['kfolds'] == fold].reset_index(drop=True)\n        xtest = df_test_new.copy()\n\n        # i need to keep a record of the row_id for the submission and validity scores\n        xtest_ids = xtest.row_id.values.tolist()     \n        valid_ids = xvalid.row_id.values.tolist()\n\n        # set up the useful features\n        # which is the column headers except index, row_id and kfolds\n        useful_features = xtrain.columns.tolist()\n        useful_features.remove('index')\n        useful_features.remove('row_id')\n        useful_features.remove('kfolds')\n  \n        # set the target column\n        ytrain = xtrain[col_targets[i]]\n        yvalid = xvalid[col_targets[i]]\n\n        # set the useful_features\n        xtrain = xtrain[useful_features]\n        xvalid = xvalid[useful_features]\n        xtest = xtest[useful_features]\n        \n        # remove the target column from the training, validity and test data\n        xtrain = xtrain.drop(col_targets[i], axis=1)\n        xvalid = xvalid.drop(col_targets[i], axis=1)        \n        xtest = xtest.drop(col_targets[i], axis=1)\n\n        # run the model\n        # n_esimators limited by processing time allowed\n        model = lgb.LGBMRegressor(random_state=0, n_jobs=-1, \n                                  n_estimators=1000)\n        model.fit(xtrain, ytrain, eval_set=[(xvalid, yvalid)],\n                 callbacks=[lgb.early_stopping(stopping_rounds=1000)])\n\n        # get the validity and test predictions\n        preds_valid = model.predict(xvalid)\n        test_preds = model.predict(xtest)\n        final_predictions.append(test_preds)\n        final_valid_predictions.update(dict(zip(valid_ids, preds_valid)))\n        \n        # print the validity score\n        model_score = r2_score(yvalid, preds_valid)\n        print(fold, model_score)\n        scores.append(model_score)\n\n    print(np.mean(scores), np.std(scores))\n    \n    # get the mean of the final_predictions across the folds\n    df_final_predictions = pd.DataFrame(final_predictions).T\n    df_final_predictions['mean_preds'] = df_final_predictions.mean(axis=1)    \n    \n    # build up the submission file\n    strings = [str(x) for x in xtest_ids]\n    strings = [s + '-' for s in strings]\n    row_col_ids = [s + col_targets[i] for s in strings]\n    submission_add = pd.DataFrame(row_col_ids,columns=['row-col'])\n    submission_add['value'] = df_final_predictions['mean_preds'].tolist()\n\n    # combine the submission dataframes so far to build up the total submission dataframe\n    submission = pd.concat([submission, submission_add])","metadata":{"execution":{"iopub.status.busy":"2022-06-22T16:57:28.569696Z","iopub.execute_input":"2022-06-22T16:57:28.570178Z","iopub.status.idle":"2022-06-23T02:19:59.686679Z","shell.execute_reply.started":"2022-06-22T16:57:28.570141Z","shell.execute_reply":"2022-06-23T02:19:59.68231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# remove the dummy first row\nsubmission = submission.iloc[1: , :]","metadata":{"execution":{"iopub.status.busy":"2022-06-23T02:19:59.693114Z","iopub.execute_input":"2022-06-23T02:19:59.694256Z","iopub.status.idle":"2022-06-23T02:19:59.711562Z","shell.execute_reply.started":"2022-06-23T02:19:59.69417Z","shell.execute_reply":"2022-06-23T02:19:59.709949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-23T02:19:59.713435Z","iopub.execute_input":"2022-06-23T02:19:59.713878Z","iopub.status.idle":"2022-06-23T02:19:59.745177Z","shell.execute_reply.started":"2022-06-23T02:19:59.713842Z","shell.execute_reply":"2022-06-23T02:19:59.744002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# save as a csv for submission\ncolumn_names = [\"row-col\", \"value\"]\nsubmission.to_csv(\"submission.csv\", header=column_names, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-23T02:19:59.748056Z","iopub.execute_input":"2022-06-23T02:19:59.748652Z","iopub.status.idle":"2022-06-23T02:20:03.690522Z","shell.execute_reply.started":"2022-06-23T02:19:59.7486Z","shell.execute_reply":"2022-06-23T02:20:03.688986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}