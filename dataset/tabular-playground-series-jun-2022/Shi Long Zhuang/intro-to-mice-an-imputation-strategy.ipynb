{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport xgboost\n\nimport matplotlib.pyplot as plt\nimport matplotlib.colors\nimport seaborn as sns\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:02:35.491478Z","iopub.execute_input":"2022-06-20T08:02:35.492077Z","iopub.status.idle":"2022-06-20T08:02:35.499784Z","shell.execute_reply.started":"2022-06-20T08:02:35.492046Z","shell.execute_reply":"2022-06-20T08:02:35.498695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://psychology.osu.edu/sites/default/files/mouse.jpg)","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n            display:fill;\n            border-radius:8px;\n            background-color:#4D4C7D;\n            font-size:120%;\n            letter-spacing:0.5px\">\n    <p style=\"padding: 8px;\n              color:white;\">\n        <b>1 | INTRODUCTION</b></p>\n</div>\n\nAlso known as **Multivariate Imputation by Chained Equation (MICE)**, it is a multiple imputation method wherein each of the missing data are replaced with m values which are obtained from iterating m times (where m > 1 and it normally lies between **3 and 10**). So, why should we use this? over the simple and blunt `SimpleImputer`.\n- Results in unbiased estimates as it considers the uncertainty of missing data\n- Provides more validity by making use of available data, as we know, some of our available features may be correlated with one another","metadata":{}},{"cell_type":"markdown","source":"<div style=\"color:white;\n            display:fill;\n            border-radius:8px;\n            background-color:#4D4C7D;\n            font-size:120%;\n            letter-spacing:0.5px\">\n    <p style=\"padding: 8px;\n              color:white;\">\n        <b>2 | METHODOLOGY</b></p>\n</div>\n\n[Khan and Hoque (2020)](https://journalofbigdata.springeropen.com/articles/10.1186/s40537-020-00313-w/figures/2) clearly captures the methodology of MICE through a visual flowchart as shown below.\n\nOther useful resources are in the form of video tutorials.\n- https://www.youtube.com/watch?v=WPiYOS3qK70&t=132s\n- https://www.youtube.com/watch?v=1n7ld38PjEc&t=8s\n\n![](https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs40537-020-00313-w/MediaObjects/40537_2020_313_Fig2_HTML.png)\n\n---\nTo demonstrate the **MICE** method in action on a very simple data set, I provided a dummy example of a simple dataset containing the height and weight of people. Fortunately, the workflows of this method are included and available in the sklearn.impute package by calling `IterativeImputer`.","metadata":{}},{"cell_type":"code","source":"df = pd.DataFrame(data = {\n                          'Height(cm)': [180, 174, 172, 175, 162, np.nan],\n                          'Weight(kg)': [65, 62, 61, np.nan, 56, 59],\n                    }\n)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:02:35.643866Z","iopub.execute_input":"2022-06-20T08:02:35.644532Z","iopub.status.idle":"2022-06-20T08:02:35.658029Z","shell.execute_reply.started":"2022-06-20T08:02:35.644495Z","shell.execute_reply":"2022-06-20T08:02:35.65721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some nice to know parameters to take note of when using the IterativeImputer. More information can be found in the [documentation](https://scikit-learn.org/stable/modules/generated/sklearn.impute.IterativeImputer.html):\n\n1. `initial_strategy` - simple imputation is performed first for every missing value to create the initial data set / placeholder.\n> Aside from mean, `initial_strategy` can accept other measures of central tendency such as **median, most_frequent, constant**.\n2. `estimator` - the predictive algorithm to use in estimating the best prediction for each missing value from other columns.\n > In our case, since we know that heigh and weight is linearly correlated with one another, a simple `LinearRegression()` can be assigned in this parameter. Other more advanced and sophisticated algorithms like XGBRegressor(), SVC(), etc. can also be used.\n3. `max_iter` - the maximum number of imputation rounds to perform.\n > The number usually lies between 3 and 10.\n4. `tol` - This is defined as the stopping criterion. \n > Given the default value of 0.001, if the difference of imputed values between the previous iteration and the subsequent iteration fall below 0.001, the iteration stops and returns the dataset with the filled missing values.\n5. `imputation_order` - order in which the features will be imputed. Possible values include:\n - **ascending:** From features with fewest missing values to most.\n - **descending:** From features with most missing values to fewest.\n - **roman:** Left to right.\n - **arabic:** Right to left.\n - **random:** A random order for each round.","metadata":{}},{"cell_type":"markdown","source":"Keeping these parameters in mind, I can now apply the IterativeImputer on the working example, thus arriving at the final imputed dataset.","metadata":{}},{"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nlr = LinearRegression()\nimp = IterativeImputer(\n    estimator = lr,\n    max_iter = 10,\n    tol = 1e-10,\n    imputation_order = 'roman',\n)\n\ndf = imp.fit_transform(df)\ndf","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:04:15.197538Z","iopub.execute_input":"2022-06-20T08:04:15.197962Z","iopub.status.idle":"2022-06-20T08:04:15.210307Z","shell.execute_reply.started":"2022-06-20T08:04:15.197925Z","shell.execute_reply":"2022-06-20T08:04:15.209582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<div style=\"color:white;\n            display:fill;\n            border-radius:8px;\n            background-color:#4D4C7D;\n            font-size:120%;\n            letter-spacing:0.5px\">\n    <p style=\"padding: 8px;\n              color:white;\">\n        <b>3 | APPLICATION</b></p>\n</div>","metadata":{}},{"cell_type":"code","source":"data = pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")\nsub = pd.read_csv(\"/kaggle/input/tabular-playground-series-jun-2022/sample_submission.csv\", index_col='row-col')","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:02:35.837086Z","iopub.execute_input":"2022-06-20T08:02:35.837491Z","iopub.status.idle":"2022-06-20T08:02:51.329479Z","shell.execute_reply.started":"2022-06-20T08:02:35.837459Z","shell.execute_reply":"2022-06-20T08:02:51.328482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"MICE is best performed with features that are highly correlated with another. With this in mind, let's plot the correlation matrix in F_4.","metadata":{}},{"cell_type":"code","source":"f4 = data[['F_4_0', 'F_4_1', 'F_4_2', 'F_4_3', 'F_4_4', 'F_4_5', 'F_4_6', 'F_4_7', 'F_4_8', 'F_4_9', 'F_4_10', 'F_4_11', 'F_4_12', 'F_4_13', 'F_4_14']]\n\nplt.subplots(figsize = (12, 12))\ncmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\",\n                                                           ['#363062',\n                                                            '#E9D5CA',\n                                                            '#363062',\n                                                           ])\n\nmask = np.triu(np.ones_like(f4.corr() ))\nsns.heatmap(f4.corr(),\n            mask = mask,\n            cmap = cmap,\n            cbar = False,\n            square = True,\n            annot = True,\n            linewidths = 3,\n           )","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:02:51.331382Z","iopub.execute_input":"2022-06-20T08:02:51.331835Z","iopub.status.idle":"2022-06-20T08:02:53.902587Z","shell.execute_reply.started":"2022-06-20T08:02:51.331792Z","shell.execute_reply":"2022-06-20T08:02:53.901945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I am particularly interested in F_4_11, as it had one of the highest correlation -0.58 with respect to F_4_8. I will simply select the 5 most highly correlated features with F_4_11 as candidates for IterativeImputer. To be specific, they are\n- F_4_1\n- F_4_3\n- F_4_4\n- F_4_5\n- F_4_8","metadata":{}},{"cell_type":"code","source":"f4_selectbest = f4[['F_4_1', 'F_4_3','F_4_4','F_4_5','F_4_8',]]\nf4_selectbest = f4_selectbest[:10000]","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:08:10.054985Z","iopub.execute_input":"2022-06-20T08:08:10.055991Z","iopub.status.idle":"2022-06-20T08:08:10.072638Z","shell.execute_reply.started":"2022-06-20T08:08:10.055946Z","shell.execute_reply":"2022-06-20T08:08:10.071626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only the first 10000 rows will be selected for the interest of time because the purpose is only to demonstrate the imputation process.","metadata":{}},{"cell_type":"code","source":"f4_selectbest","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:08:12.219063Z","iopub.execute_input":"2022-06-20T08:08:12.219681Z","iopub.status.idle":"2022-06-20T08:08:12.235826Z","shell.execute_reply.started":"2022-06-20T08:08:12.219647Z","shell.execute_reply":"2022-06-20T08:08:12.235177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"iimp = IterativeImputer(\n    estimator = xgboost.XGBRegressor(),\n    random_state = 42,\n    verbose = 2,\n)\n\nfinal = iimp.fit_transform(f4_selectbest)\nfinal","metadata":{"execution":{"iopub.status.busy":"2022-06-20T08:08:14.76158Z","iopub.execute_input":"2022-06-20T08:08:14.762019Z","iopub.status.idle":"2022-06-20T08:09:05.125139Z","shell.execute_reply.started":"2022-06-20T08:08:14.761983Z","shell.execute_reply":"2022-06-20T08:09:05.124402Z"},"trusted":true},"execution_count":null,"outputs":[]}]}