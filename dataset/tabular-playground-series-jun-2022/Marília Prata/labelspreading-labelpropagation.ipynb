{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-01T22:21:08.105558Z","iopub.execute_input":"2022-06-01T22:21:08.105957Z","iopub.status.idle":"2022-06-01T22:21:08.121138Z","shell.execute_reply.started":"2022-06-01T22:21:08.105925Z","shell.execute_reply":"2022-06-01T22:21:08.119684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://slidetodoc.com/presentation_image/53cdb36ec5d2f9c3437ea4791f425e03/image-13.jpg)SlideToDoc.com","metadata":{}},{"cell_type":"code","source":"# Get the unified BCG Strain spreadsheet\ndf = pd.read_csv('/kaggle/input/tabular-playground-series-jun-2022/data.csv', delimiter=',')\npd.set_option('display.max_columns', None)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:21:19.617748Z","iopub.execute_input":"2022-06-01T22:21:19.618531Z","iopub.status.idle":"2022-06-01T22:21:37.895639Z","shell.execute_reply.started":"2022-06-01T22:21:19.618489Z","shell.execute_reply":"2022-06-01T22:21:37.894879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#All script by Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook","metadata":{}},{"cell_type":"code","source":"#Code by Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook\n\nimport seaborn as sns\nfrom sklearn.datasets import make_classification\n\nX, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n                           n_redundant=0, n_repeated=0, n_classes=3,\n                           n_clusters_per_class=1,\n                           weights=[0.01, 0.05, 0.94],\n                           class_sep=0.8, random_state=0)\n\nimport matplotlib.pyplot as plt\ncolors = ['#ef8a62' if v == 0 else '#f7f7f7' if v == 1 else '#67a9cf' for v in y]\nkwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\nfig = plt.Figure(figsize=(12,6))\nplt.scatter(X[:, 0], X[:, 1], c=colors, **kwarg_params);","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-01T22:21:46.188663Z","iopub.execute_input":"2022-06-01T22:21:46.18953Z","iopub.status.idle":"2022-06-01T22:21:46.57054Z","shell.execute_reply.started":"2022-06-01T22:21:46.189485Z","shell.execute_reply":"2022-06-01T22:21:46.569493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook\n\nfrom sklearn.semi_supervised import LabelPropagation\nfrom sklearn.datasets import make_classification\n\n\ndef label(df, class_sep, trans=LabelPropagation()):\n    \"\"\"Label a point cloud with the given class separation \"\"\"\n    X, y = make_classification(n_samples=5000, n_features=2, n_informative=2,\n                               n_redundant=0, n_repeated=0, n_classes=3,\n                               n_clusters_per_class=1,\n                               weights=[0.05, 0.10, 0.85],\n                               class_sep=class_sep, random_state=0)\n    \n    X_l = X.shape[0]\n    np.random.seed(42)\n    unl_idx = np.random.randint(0, len(X), size=X_l - 500)\n    l_idx = list(set(range(X_l)).difference(set(unl_idx)))\n    X_unlabeled, X_labeled = X[unl_idx], X[l_idx]\n    y_unlabeled, y_labeled = y[unl_idx], y[l_idx]\n    \n    trans = LabelPropagation()\n    trans.fit(X_labeled, y_labeled)\n\n    y_unlabeled_pred = trans.predict(X_unlabeled)\n    \n    r = (pd.DataFrame({'y': y_unlabeled, 'y_pred': y_unlabeled_pred}))\n    \n    return X_unlabeled, X_labeled, y_unlabeled, y_labeled, r","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:21:52.208583Z","iopub.execute_input":"2022-06-01T22:21:52.209449Z","iopub.status.idle":"2022-06-01T22:21:52.222932Z","shell.execute_reply.started":"2022-06-01T22:21:52.20939Z","shell.execute_reply":"2022-06-01T22:21:52.221609Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\ncmap = {0: '#ef8a62',1: '#f7f7f7', 2: '#67a9cf'}\nfig, axarr = plt.subplots(2, 4, figsize=(12, 6))\n\nfor plot_n, sep in enumerate([0.1, 0.5, 1, 2]):\n    X_unlabeled, X_labeled, y_unlabeled, y_labeled, r = label(X, sep, trans=LabelPropagation())\n\n    for classnum, color in cmap.items():\n        k_idx_labeled = np.where(y_labeled == classnum)[0]\n        X_v, y_v = X_labeled[k_idx_labeled], y_labeled[k_idx_labeled]\n        axarr[0][plot_n].plot(X_v[:, 0], X_v[:, 1], marker='o', linewidth=0, alpha=0.25, c=color)\n        \n        k_idx_unlabeled_misclassified = np.where(r.query(\"y == @classnum & y != y_pred\").values)[0]\n        X_v, y_v = X_unlabeled[k_idx_unlabeled_misclassified], y_unlabeled[k_idx_unlabeled_misclassified]\n        axarr[0][plot_n].plot(X_v[:, 0], X_v[:, 1], marker='o', \n                              markeredgewidth=1, markeredgecolor='black', linewidth=0, c='None', zorder=10)\n        \n        result = r.rename_axis(None).groupby('y').apply(lambda df: (df.y == df.y_pred).sum() / len(df))\n        result.plot.bar(color=cmap.values(), ax=axarr[1][plot_n])\n        \nplt.suptitle(\"$LabelPropagation$ Performance Benchmark, $Sep \\in [0.1, 0.5, 1, 2]$\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-01T22:21:59.050662Z","iopub.execute_input":"2022-06-01T22:21:59.051209Z","iopub.status.idle":"2022-06-01T22:22:02.027382Z","shell.execute_reply.started":"2022-06-01T22:21:59.051168Z","shell.execute_reply":"2022-06-01T22:22:02.026336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook\n\nfrom sklearn.semi_supervised import LabelSpreading\n\nfig, axarr = plt.subplots(2, 4, figsize=(12, 6))\n\nfor plot_n, sep in enumerate([0.1, 0.5, 1, 2]):\n    X_unlabeled, X_labeled, y_unlabeled, y_labeled, r = label(X, sep, trans=LabelSpreading())\n\n    for classnum, color in cmap.items():\n        k_idx_labeled = np.where(y_labeled == classnum)[0]\n        X_v, y_v = X_labeled[k_idx_labeled], y_labeled[k_idx_labeled]\n        axarr[0][plot_n].plot(X_v[:, 0], X_v[:, 1], marker='o', linewidth=0, alpha=0.25, c=color)\n        \n        k_idx_unlabeled_misclassified = np.where(r.query(\"y == @classnum & y != y_pred\").values)[0]\n        X_v, y_v = X_unlabeled[k_idx_unlabeled_misclassified], y_unlabeled[k_idx_unlabeled_misclassified]\n        axarr[0][plot_n].plot(X_v[:, 0], X_v[:, 1], marker='o', \n                              markeredgewidth=1, markeredgecolor='black', linewidth=0, c='None', zorder=10)\n        \n        result = r.rename_axis(None).groupby('y').apply(lambda df: (df.y == df.y_pred).sum() / len(df))\n        result.plot.bar(color=cmap.values(), ax=axarr[1][plot_n])\n        \nplt.suptitle(\"$LabelSpreading$ Performance Benchmark, $Sep \\in [0.1, 0.5, 1, 2]$\");","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-01T22:22:08.046527Z","iopub.execute_input":"2022-06-01T22:22:08.047685Z","iopub.status.idle":"2022-06-01T22:22:11.017074Z","shell.execute_reply.started":"2022-06-01T22:22:08.04764Z","shell.execute_reply":"2022-06-01T22:22:11.016055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:22:17.286453Z","iopub.execute_input":"2022-06-01T22:22:17.287003Z","iopub.status.idle":"2022-06-01T22:22:17.489117Z","shell.execute_reply.started":"2022-06-01T22:22:17.28696Z","shell.execute_reply":"2022-06-01T22:22:17.487674Z"},"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Application benchmark","metadata":{}},{"cell_type":"markdown","source":"\"Aleksey tried to apply this algorithm to a real dataset, the Open Powerlifting Database, to assign Division information to fields lacking it. However, this turned out to be foolish, as the class clusters were not sufficiently well-distributed. The accuracy was nearly 0.\"","metadata":{}},{"cell_type":"markdown","source":"#I changed Division to F_2_0 and the columns too. Obviously, it didn't work.","metadata":{}},{"cell_type":"code","source":"#Code by Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook\n\nimport pandas as pd\ndf = pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")\n\n# import missingno as msno\n# msno.matrix(df.sample(1000))\n\nimport numpy as np\nnp.random.seed(42)\n\ncols = ['F_2_0', 'F_2_1', 'F_2_2', 'F_2_3', 'F_2_4', 'F_2_5', 'F_2_6', 'F_2_7', 'F_2_8', 'F_2_9', 'F_2_10', 'F_2_11', 'F_2_12', 'F_2_13', 'F_2_14', 'F_2_15', 'F_2_16', 'F_2_17', 'F_2_18', 'F_2_19', 'F_2_20', 'F_2_21', 'F_2_22', 'F_2_23', 'F_2_24']\n\ndf_nonempty = (df\n   .dropna(subset=['F_2_0'])\n   #.drop(['MeetID', 'Name', 'Place', 'WeightClassKg'], axis='columns')\n   .pipe(lambda df: df.assign(\n        # Sex=df.Sex.astype('category').cat.codes,\n         F_2_0=df.F_2_0.astype('uint8').int.codes,\n         #Equipment=df.Equipment.astype('category').cat.codes\n   ))\n   .pipe(lambda df: df[df.F_2_0.isin(df.F_2_0.value_counts().head(10).index.values)])\n  # .loc[:, cols]\n  # .dropna()\n  # .reset_index(drop=True)               \n)\nunl_idx = np.random.randint(0, len(df_nonempty), size=len(df_nonempty) - 500)\nl_idx = list(set(range(len(df_nonempty))).difference(set(unl_idx)))\n\n#cols = [c for c in cols if c != 'Division']\n\n#X_unlabeled, X_labeled = df_nonempty.loc[unl_idx, cols].head(5000), df_nonempty.loc[l_idx, cols].head(5000)\n#y_unlabeled, y_labeled = df_nonempty.loc[unl_idx, 'Division'].head(5000), df_nonempty.loc[l_idx, 'Division'].head(5000)","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:03:13.73656Z","iopub.execute_input":"2022-06-01T22:03:13.737856Z","iopub.status.idle":"2022-06-01T22:03:32.305511Z","shell.execute_reply.started":"2022-06-01T22:03:13.737798Z","shell.execute_reply":"2022-06-01T22:03:32.304022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Code by Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook\n\nfrom sklearn.semi_supervised import LabelPropagation\n\ntrans = LabelPropagation()\ntrans.fit(X_labeled, y_labeled)\n\nnp.random.seed(42)\ny_unlabeled_pred = trans.predict(X_unlabeled)\n\nprint(\"Performance on division imputation: {0}% Accuracy\".format((y_unlabeled_pred == y_unlabeled)\\\n                                                                 .pipe(lambda df: df.sum() / len(df))))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T22:04:58.799671Z","iopub.execute_input":"2022-06-01T22:04:58.800717Z","iopub.status.idle":"2022-06-01T22:04:59.354889Z","shell.execute_reply.started":"2022-06-01T22:04:58.800647Z","shell.execute_reply":"2022-06-01T22:04:59.353465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#Another script that I screwed and can't fix it.","metadata":{}},{"cell_type":"markdown","source":"#Conclusion\n\n\"Semi-supervised learning is a restatement of the missing data imputation problem which is specific to the small-sample, missing-label case. This problem gets its own name likely because it is so commonly encountered in research and dataset generation contexts. It's a useful tool to know about more generally for missing data imputation from a limited sample size, but the algorithms have poor performance characteristics for larger samples. In those cases, perhaps try applying machine learning to the problem directly.\"\n\nBy Aleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook","metadata":{}},{"cell_type":"markdown","source":"Acknowledgement:\n\nAleksey Bilogur https://www.kaggle.com/code/residentmario/notes-on-semi-supervised-learning/notebook","metadata":{}}]}