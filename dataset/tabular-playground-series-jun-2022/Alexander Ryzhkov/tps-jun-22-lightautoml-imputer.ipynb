{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.core.display import display, HTML, Javascript\n\n# ----- Notebook Theme -----\ncolor_map = ['#16a085', '#e8f6f3', '#d0ece7', '#a2d9ce', '#73c6b6', '#45b39d', \n                        '#16a085', '#138d75', '#117a65', '#0e6655', '#0b5345']\n\nprompt = color_map[-1]\nmain_color = color_map[0]\nstrong_main_color = color_map[1]\ncustom_colors = [strong_main_color, main_color]\n\ncss_file = ''' \n\ndiv #notebook {\nbackground-color: white;\nline-height: 20px;\n}\n\n#notebook-container {\n%s\nmargin-top: 2em;\npadding-top: 2em;\nborder-top: 4px solid %s; /* light orange */\n-webkit-box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n    box-shadow: 0px 0px 8px 2px rgba(224, 212, 226, 0.5); /* pink */\n}\n\ndiv .input {\nmargin-bottom: 1em;\n}\n\n.rendered_html h1, .rendered_html h2, .rendered_html h3, .rendered_html h4, .rendered_html h5, .rendered_html h6 {\ncolor: %s; /* light orange */\nfont-weight: 600;\n}\n\ndiv.input_area {\nborder: none;\n    background-color: %s; /* rgba(229, 143, 101, 0.1); light orange [exactly #E58F65] */\n    border-top: 2px solid %s; /* light orange */\n}\n\ndiv.input_prompt {\ncolor: %s; /* light blue */\n}\n\ndiv.output_prompt {\ncolor: %s; /* strong orange */\n}\n\ndiv.cell.selected:before, div.cell.selected.jupyter-soft-selected:before {\nbackground: %s; /* light orange */\n}\n\ndiv.cell.selected, div.cell.selected.jupyter-soft-selected {\n    border-color: %s; /* light orange */\n}\n\n.edit_mode div.cell.selected:before {\nbackground: %s; /* light orange */\n}\n\n.edit_mode div.cell.selected {\nborder-color: %s; /* light orange */\n\n}\n'''\ndef to_rgb(h): \n    return tuple(int(h[i:i+2], 16) for i in [0, 2, 4])\n\nmain_color_rgba = 'rgba(%s, %s, %s, 0.1)' % (to_rgb(main_color[1:]))\nopen('notebook.css', 'w').write(css_file % ('width: 95%;', main_color, main_color, main_color_rgba, main_color,  main_color, prompt, main_color, main_color, main_color, main_color))\n\ndef nb(): \n    return HTML(\"<style>\" + open(\"notebook.css\", \"r\").read() + \"</style>\")\nnb()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"papermill":{"duration":0.037047,"end_time":"2022-06-01T18:53:05.824081","exception":false,"start_time":"2022-06-01T18:53:05.787034","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:02:45.642741Z","iopub.execute_input":"2022-06-09T21:02:45.643047Z","iopub.status.idle":"2022-06-09T21:02:45.678135Z","shell.execute_reply.started":"2022-06-09T21:02:45.64298Z","shell.execute_reply":"2022-06-09T21:02:45.677225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<img src=\"https://github.com/AILab-MLTools/LightAutoML/raw/master/imgs/LightAutoML_logo_big.png\" alt=\"LightAutoML logo\" style=\"width:70%;\"/>","metadata":{"papermill":{"duration":0.009173,"end_time":"2022-06-01T18:53:05.842817","exception":false,"start_time":"2022-06-01T18:53:05.833644","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# LightAutoML baseline\n\nOfficial LightAutoML github repository is [here](https://github.com/AILab-MLTools/LightAutoML). \n\n### Do not forget to put upvote for the notebook and the ⭐️ for github repo if you like it - one click for you, great pleasure for us ☺️ ","metadata":{"papermill":{"duration":0.010158,"end_time":"2022-06-01T18:53:05.863396","exception":false,"start_time":"2022-06-01T18:53:05.853238","status":"completed"},"tags":[]}},{"cell_type":"code","source":"s = '<iframe src=\"https://ghbtns.com/github-btn.html?user=sb-ai-lab&repo=LightAutoML&type=star&count=true&size=large\" frameborder=\"0\" scrolling=\"0\" width=\"170\" height=\"30\" title=\"LightAutoML GitHub\"></iframe>'\nHTML(s)","metadata":{"_kg_hide-input":true,"papermill":{"duration":0.026178,"end_time":"2022-06-01T18:53:05.901313","exception":false,"start_time":"2022-06-01T18:53:05.875135","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:02:49.377021Z","iopub.execute_input":"2022-06-09T21:02:49.377712Z","iopub.status.idle":"2022-06-09T21:02:49.39492Z","shell.execute_reply.started":"2022-06-09T21:02:49.377638Z","shell.execute_reply":"2022-06-09T21:02:49.393442Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## This notebook is the updated copy of our [Tutorial_1 from the GIT repository](https://github.com/AILab-MLTools/LightAutoML/blob/master/examples/tutorials/Tutorial_1_basics.ipynb). Please check our [tutorials folder](https://github.com/AILab-MLTools/LightAutoML/blob/master/examples/tutorials) if you are interested in other examples of LightAutoML functionality.","metadata":{"papermill":{"duration":0.010428,"end_time":"2022-06-01T18:53:05.922352","exception":false,"start_time":"2022-06-01T18:53:05.911924","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## 0. Prerequisites","metadata":{"papermill":{"duration":0.009422,"end_time":"2022-06-01T18:53:05.941835","exception":false,"start_time":"2022-06-01T18:53:05.932413","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### 0.0. install LightAutoML","metadata":{"papermill":{"duration":0.010377,"end_time":"2022-06-01T18:53:05.962371","exception":false,"start_time":"2022-06-01T18:53:05.951994","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# %%capture\n# !pip3 install -U lightautoml\n\n# # QUICK WORKAROUND FOR PROBLEM WITH PANDAS\n# !pip3 install -U pandas","metadata":{"_kg_hide-output":true,"papermill":{"duration":153.387533,"end_time":"2022-06-01T18:55:39.359981","exception":false,"start_time":"2022-06-01T18:53:05.972448","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-06-09T10:23:38.761574Z","iopub.execute_input":"2022-06-09T10:23:38.762058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.1. Import libraries\n\nHere we will import the libraries we use in this kernel:\n- Standard python libraries for timing, working with OS etc.\n- Essential python DS libraries like numpy, pandas, scikit-learn and torch (the last we will use in the next cell)\n- LightAutoML modules: `TabularAutoML` preset for AutoML model creation and Task class to setup what kind of ML problem we solve (binary/multiclass classification or regression)","metadata":{"papermill":{"duration":0.005707,"end_time":"2022-06-01T18:55:39.373919","exception":false,"start_time":"2022-06-01T18:55:39.368212","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# Standard python libraries\nimport os\nimport time\n\n# Essential DS libraries\nimport numpy as np\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\nimport torch\n\n# LightAutoML presets, task and report generation\n# from lightautoml.automl.presets.tabular_presets import TabularAutoML\n# from lightautoml.tasks import Task\n\n# For NN training\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.layers import Dense, Input, Dropout, Embedding, Concatenate\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import MeanSquaredError\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.preprocessing import StandardScaler","metadata":{"papermill":{"duration":3.590345,"end_time":"2022-06-01T18:55:42.969853","exception":false,"start_time":"2022-06-01T18:55:39.379508","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:29:02.006715Z","iopub.execute_input":"2022-06-09T21:29:02.007602Z","iopub.status.idle":"2022-06-09T21:29:02.023674Z","shell.execute_reply.started":"2022-06-09T21:29:02.007501Z","shell.execute_reply":"2022-06-09T21:29:02.021769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.2. Constants\n\nHere we setup the constants to use in the kernel:\n- `N_THREADS` - number of vCPUs for LightAutoML model creation\n- `N_FOLDS` - number of folds in LightAutoML inner CV\n- `RANDOM_STATE` - random seed for better reproducibility\n- `TIMEOUT` - limit in seconds for model to train","metadata":{"papermill":{"duration":0.005711,"end_time":"2022-06-01T18:55:42.981988","exception":false,"start_time":"2022-06-01T18:55:42.976277","status":"completed"},"tags":[]}},{"cell_type":"code","source":"N_THREADS = 4\nN_FOLDS = 5\nRANDOM_STATE = 42\nTIMEOUT = 1800","metadata":{"papermill":{"duration":0.017751,"end_time":"2022-06-01T18:55:43.005793","exception":false,"start_time":"2022-06-01T18:55:42.988042","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:03:08.632904Z","iopub.execute_input":"2022-06-09T21:03:08.633494Z","iopub.status.idle":"2022-06-09T21:03:08.640667Z","shell.execute_reply.started":"2022-06-09T21:03:08.633466Z","shell.execute_reply":"2022-06-09T21:03:08.638949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.3. Imported models setup\n\nFor better reproducibility fix numpy random seed with max number of threads for Torch (which usually try to use all the threads on server):","metadata":{"papermill":{"duration":0.009438,"end_time":"2022-06-01T18:55:43.025633","exception":false,"start_time":"2022-06-01T18:55:43.016195","status":"completed"},"tags":[]}},{"cell_type":"code","source":"np.random.seed(RANDOM_STATE)\ntorch.set_num_threads(N_THREADS)","metadata":{"papermill":{"duration":0.056351,"end_time":"2022-06-01T18:55:43.092638","exception":false,"start_time":"2022-06-01T18:55:43.036287","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:03:08.642695Z","iopub.execute_input":"2022-06-09T21:03:08.643562Z","iopub.status.idle":"2022-06-09T21:03:08.688807Z","shell.execute_reply.started":"2022-06-09T21:03:08.643526Z","shell.execute_reply":"2022-06-09T21:03:08.688048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 0.4. Data loading\nLet's check the data we have:","metadata":{"papermill":{"duration":0.010239,"end_time":"2022-06-01T18:55:43.115445","exception":false,"start_time":"2022-06-01T18:55:43.105206","status":"completed"},"tags":[]}},{"cell_type":"code","source":"INPUT_DIR = '../input/tabular-playground-series-jun-2022/'","metadata":{"papermill":{"duration":0.018124,"end_time":"2022-06-01T18:55:43.143741","exception":false,"start_time":"2022-06-01T18:55:43.125617","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:03:08.692757Z","iopub.execute_input":"2022-06-09T21:03:08.69311Z","iopub.status.idle":"2022-06-09T21:03:08.699672Z","shell.execute_reply.started":"2022-06-09T21:03:08.693082Z","shell.execute_reply":"2022-06-09T21:03:08.699073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"columns = ['row_id', \n           'F_1_0', 'F_1_1', 'F_1_2', 'F_1_3', 'F_1_4', 'F_1_5', 'F_1_6', 'F_1_7', 'F_1_8', \n           'F_1_9', 'F_1_10', 'F_1_11', 'F_1_12', 'F_1_13', 'F_1_14', \n           'F_2_0', 'F_2_1', 'F_2_2', 'F_2_3', 'F_2_4', 'F_2_5', 'F_2_6', 'F_2_7', \n           'F_2_8', 'F_2_9', 'F_2_10', 'F_2_11', 'F_2_12', 'F_2_13', 'F_2_14', 'F_2_15', \n           'F_2_16', 'F_2_17', 'F_2_18', 'F_2_19', 'F_2_20', 'F_2_21', 'F_2_22', 'F_2_23', 'F_2_24', \n           'F_3_0', 'F_3_1', 'F_3_2', 'F_3_3', 'F_3_4', 'F_3_5', 'F_3_6', 'F_3_7', 'F_3_8', 'F_3_9', \n           'F_3_10', 'F_3_11', 'F_3_12', 'F_3_13', 'F_3_14', 'F_3_15', 'F_3_16', 'F_3_17', 'F_3_18', \n           'F_3_19', 'F_3_20', 'F_3_21', 'F_3_22', 'F_3_23', 'F_3_24', \n           'F_4_0', 'F_4_1', 'F_4_2', 'F_4_3', 'F_4_4', 'F_4_5', \n           'F_4_6', 'F_4_7', 'F_4_8', 'F_4_9', 'F_4_10', 'F_4_11', \n           'F_4_12', 'F_4_13', 'F_4_14']\n\ntypes_mapper = {}\nfor col in columns:\n    if col == 'row_id' or col.startswith('F_2'):\n        types_mapper[col] = 'int32'\n    else:\n        types_mapper[col] = 'float32'","metadata":{"execution":{"iopub.status.busy":"2022-06-09T21:03:08.701674Z","iopub.execute_input":"2022-06-09T21:03:08.70247Z","iopub.status.idle":"2022-06-09T21:03:08.720611Z","shell.execute_reply.started":"2022-06-09T21:03:08.702438Z","shell.execute_reply":"2022-06-09T21:03:08.719993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(INPUT_DIR + 'data.csv', dtype = types_mapper)\nprint(data.shape)\ndata.head()","metadata":{"papermill":{"duration":17.79657,"end_time":"2022-06-01T18:56:00.951316","exception":false,"start_time":"2022-06-01T18:55:43.154746","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:03:08.724906Z","iopub.execute_input":"2022-06-09T21:03:08.728185Z","iopub.status.idle":"2022-06-09T21:03:24.540081Z","shell.execute_reply.started":"2022-06-09T21:03:08.728153Z","shell.execute_reply":"2022-06-09T21:03:24.539172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(INPUT_DIR + 'sample_submission.csv')\nprint(submission.shape)\nsubmission.head()","metadata":{"papermill":{"duration":1.11808,"end_time":"2022-06-01T18:56:02.080311","exception":false,"start_time":"2022-06-01T18:56:00.962231","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:03:24.541963Z","iopub.execute_input":"2022-06-09T21:03:24.542436Z","iopub.status.idle":"2022-06-09T21:03:25.222066Z","shell.execute_reply.started":"2022-06-09T21:03:24.542389Z","shell.execute_reply":"2022-06-09T21:03:25.221213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LightAutoML training","metadata":{"papermill":{"duration":0.010102,"end_time":"2022-06-01T18:56:02.101538","exception":false,"start_time":"2022-06-01T18:56:02.091436","status":"completed"},"tags":[]}},{"cell_type":"code","source":"FINAL_PREDS = []","metadata":{"papermill":{"duration":0.022216,"end_time":"2022-06-01T18:56:02.134282","exception":false,"start_time":"2022-06-01T18:56:02.112066","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:05:40.973103Z","iopub.execute_input":"2022-06-09T21:05:40.973467Z","iopub.status.idle":"2022-06-09T21:05:40.977544Z","shell.execute_reply.started":"2022-06-09T21:05:40.973436Z","shell.execute_reply":"2022-06-09T21:05:40.976432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cols_to_predict = data.isnull().sum(axis = 0)\ncols_to_predict = cols_to_predict[cols_to_predict > 0].index.values\nN_targets = len(cols_to_predict)\ncols_to_predict","metadata":{"papermill":{"duration":0.128887,"end_time":"2022-06-01T18:56:02.274584","exception":false,"start_time":"2022-06-01T18:56:02.145697","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2022-06-09T21:05:41.668772Z","iopub.execute_input":"2022-06-09T21:05:41.669125Z","iopub.status.idle":"2022-06-09T21:05:41.781249Z","shell.execute_reply.started":"2022-06-09T21:05:41.669097Z","shell.execute_reply":"2022-06-09T21:05:41.780338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CATs = ['F_2_'+str(i) for i in range(25)]\n\ndef nn_model_hard(n_feats_num, n_feats_cat):\n    inputs_num = Input(shape=(n_feats_num))\n    inputs_cat = Input(shape=(n_feats_cat))\n    \n    activation = 'swish'\n    hid_num = Dense(512, activation=activation)(inputs_num)\n    \n    cat_layers = [hid_num]\n    for i in range(n_feats_cat):\n        cat_layers.append(Embedding(20, 1)(inputs_cat[:, i]))\n    \n    concated_hid = Concatenate()(cat_layers)\n    hid2 = Dense(256, activation=activation)(concated_hid)\n    hid3 = Dense(128, activation=activation)(Concatenate()([concated_hid, hid2]))\n    x = Dense(64, activation=activation)(Concatenate()([concated_hid, hid2, hid3]))\n    x = Dense(1, activation='linear')(x)\n    model = Model([inputs_num, inputs_cat], x)\n    return model\n\n\ndef fit_model_hard(X_train, y_train, \n                  X_valid, y_valid, \n                  X_test, n_epochs = 50):\n    #print(X_train.shape, X_valid.shape, X_test.shape)\n    not_cats = [col for col in X_train.columns if col not in CATs]\n    X_tr_cat = X_train[CATs]\n    X_va_cat = X_valid[CATs]\n    X_te_cat = X_test[CATs]\n    X_tr = X_train[not_cats]\n    X_va = X_valid[not_cats]\n    X_te = X_test[not_cats]\n    #print(X_tr.shape, X_va.shape, X_te.shape)\n    \n    scaler = StandardScaler()\n    X_tr = scaler.fit_transform(X_tr)\n    X_va = scaler.transform(X_va)\n    X_te = scaler.transform(X_te)\n    valid_data = ([X_va, X_va_cat], y_valid)\n\n    lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.75, \n                           patience = 5, verbose = 0)\n    es = EarlyStopping(monitor = \"val_loss\", patience = 10, \n                       verbose = 1, restore_best_weights = True)\n    model = nn_model_hard(X_tr.shape[1], X_tr_cat.shape[1])\n    model.compile(optimizer = Adam(learning_rate = 0.01),\n                  loss = MeanSquaredError())\n\n    history = model.fit([X_tr, X_tr_cat], y_train, \n                        validation_data = valid_data, \n                        epochs = n_epochs,\n                        verbose = 0,\n                        batch_size = 4096,\n                        shuffle = True,\n                        callbacks = [lr, es])\n    \n    y_valid_pred = model.predict([X_va, X_va_cat]).reshape(1, -1)[0]\n    y_test_pred = model.predict([X_te, X_te_cat]).reshape(1, -1)[0]\n\n    return y_valid_pred, y_test_pred\n\ndef nn_model(n_feats):\n    inputs = Input(shape=(n_feats))\n    activation = 'swish'\n    x = Dense(512, activation=activation)(inputs)\n    #x = Dropout(0.1)(x)\n    x = Dense(256, activation=activation)(x)\n    x = Dense(128, activation=activation)(x)\n    #x = Dropout(0.1)(x)\n    x = Dense(64, activation=activation)(x)\n    x = Dense(1, activation='linear')(x)\n    model = Model(inputs, x)\n    return model\n\n\ndef fit_model(X_train, y_train, \n              X_valid, y_valid, \n              X_test, n_epochs = 50):\n    \n    scaler = StandardScaler()\n    X_tr = scaler.fit_transform(X_train)\n    X_va = scaler.transform(X_valid)\n    X_te = scaler.transform(X_test)\n    valid_data = (X_va, y_valid)\n\n    lr = ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.75, \n                           patience = 5, verbose = 0)\n    es = EarlyStopping(monitor = \"val_loss\", patience = 10, \n                       verbose = 1, restore_best_weights = True)\n    model = nn_model(X_train.shape[1])\n    model.compile(optimizer = Adam(learning_rate = 0.01),\n                  loss = MeanSquaredError())\n\n    history = model.fit(X_tr, y_train, \n                        validation_data = valid_data, \n                        epochs = n_epochs,\n                        verbose = 0,\n                        batch_size = 4096,\n                        shuffle = True,\n                        callbacks = [lr, es])\n    \n    y_valid_pred = model.predict(X_va).reshape(1, -1)[0]\n    y_test_pred = model.predict(X_te).reshape(1, -1)[0]\n\n    return y_valid_pred, y_test_pred","metadata":{"execution":{"iopub.status.busy":"2022-06-09T22:59:28.774101Z","iopub.execute_input":"2022-06-09T22:59:28.774479Z","iopub.status.idle":"2022-06-09T22:59:28.799451Z","shell.execute_reply.started":"2022-06-09T22:59:28.774446Z","shell.execute_reply":"2022-06-09T22:59:28.79847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nimport gc\n\nhard_targets = ['F_1_7', 'F_1_12', 'F_1_13', 'F_3_19', 'F_3_21'] + ['F_4_'+str(i) for i in range(15)]\n\nfor it, TARGET_NAME in enumerate(cols_to_predict):\n    print('='*50)\n    print('START COLUMN {}/{} {}'.format(it+1, N_targets, TARGET_NAME))\n    train_data = data[~data[TARGET_NAME].isna()]\n    test_data = data[data[TARGET_NAME].isna()]\n    print(train_data.shape, test_data.shape)\n\n    features = [x for x in train_data.columns if x not in ['row_id', TARGET_NAME]]\n    NN_OOF_PRED = np.zeros(len(train_data))\n    NN_TEST_PRED = np.zeros(len(test_data))\n\n    y = train_data[TARGET_NAME].values\n    train_data = train_data[features].fillna(train_data.mean())\n    X_test = test_data[features].fillna(train_data.mean())\n    N_START = 2\n    print(N_START)\n    T0 = time.time()\n    for it in range(N_START):\n        T = time.time()\n        skf = KFold(n_splits = N_FOLDS, random_state = RANDOM_STATE + it, shuffle = True)\n        for fold, (train_idx, valid_idx) in enumerate(skf.split(y, y)):\n            X_train = train_data.iloc[train_idx, :]\n            X_valid = train_data.iloc[valid_idx, :]\n            y_train = y[train_idx]\n            y_valid = y[valid_idx]\n\n            if TARGET_NAME in hard_targets:\n                print('TRAIN HARD')\n                val_pred, test_pred = fit_model_hard(X_train, y_train, \n                                                    X_valid, y_valid, \n                                                    X_test, 50)\n            else:\n                print('TRAIN EASY')\n                val_pred, test_pred = fit_model(X_train, y_train, \n                                                X_valid, y_valid, \n                                                X_test, 50)\n\n            print('ITER = {} FOLD {} score {:.5f}'.format(it, fold, mean_squared_error(y_valid, val_pred, squared = False)))\n\n            NN_OOF_PRED[valid_idx] += val_pred / N_START\n            NN_TEST_PRED += test_pred / N_FOLDS / N_START\n            del X_train, X_valid\n            gc.collect()\n        print('AFTER ITER {} NN OOF score {:.5f}, time {:.2f}'.format(it, \n                                                                  mean_squared_error(y, NN_OOF_PRED / (it + 1) * N_START, squared = False), \n                                                                  time.time() - T))\n\n    print('NN OOF score {:.5f}, time {:.2f}'.format(mean_squared_error(y, NN_OOF_PRED, squared = False), time.time() - T0))\n    FINAL_PREDS.append(pd.DataFrame([[str(idx) + '-' + TARGET_NAME, val] for idx,val in zip(test_data['row_id'].values, NN_TEST_PRED)], \n                                    columns = submission.columns))","metadata":{"_kg_hide-output":true,"papermill":{"duration":21103.686335,"end_time":"2022-06-02T00:47:45.972346","exception":false,"start_time":"2022-06-01T18:56:02.286011","status":"completed"},"scrolled":true,"tags":[],"execution":{"iopub.status.busy":"2022-06-09T22:59:30.399244Z","iopub.execute_input":"2022-06-09T22:59:30.39981Z","iopub.status.idle":"2022-06-09T23:00:15.328012Z","shell.execute_reply.started":"2022-06-09T22:59:30.399774Z","shell.execute_reply":"2022-06-09T23:00:15.327136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_data = data[~data[TARGET_NAME].isna()]\n# test_data = data[data[TARGET_NAME].isna()]\n# train_data['NN_preds'] = NN_OOF_PRED\n# test_data['NN_preds'] = NN_TEST_PRED","metadata":{"execution":{"iopub.status.busy":"2022-06-09T10:20:49.89665Z","iopub.execute_input":"2022-06-09T10:20:49.89816Z","iopub.status.idle":"2022-06-09T10:20:50.163975Z","shell.execute_reply.started":"2022-06-09T10:20:49.898116Z","shell.execute_reply":"2022-06-09T10:20:50.16259Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# task = Task('reg',)\n\n# roles = {\n#     'target': TARGET_NAME,\n#     'drop': ['row_id']\n# }\n\n# automl = TabularAutoML(\n#     task = task, \n#     timeout = TIMEOUT,\n#     cpu_limit = N_THREADS,\n#     general_params = {'use_algos': [['cb']]},\n#     reader_params = {'n_jobs': N_THREADS, 'cv': N_FOLDS, 'random_state': RANDOM_STATE},\n#     selection_params = {'mode': 0}\n# )\n\n# oof_pred = automl.fit_predict(train_data.sample(100000), roles = roles, verbose = 3)","metadata":{"execution":{"iopub.status.busy":"2022-06-09T10:21:14.32192Z","iopub.execute_input":"2022-06-09T10:21:14.322333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create submission\n\nWe are now ready for submission file creation:","metadata":{"papermill":{"duration":0.145279,"end_time":"2022-06-02T00:47:46.265091","exception":false,"start_time":"2022-06-02T00:47:46.119812","status":"completed"},"tags":[]}},{"cell_type":"code","source":"submission = pd.concat(FINAL_PREDS)\nsubmission.to_csv('nn_imputer.csv', index = False)\nsubmission","metadata":{"execution":{"iopub.execute_input":"2022-06-02T00:47:46.559408Z","iopub.status.busy":"2022-06-02T00:47:46.558493Z","iopub.status.idle":"2022-06-02T00:47:49.666379Z","shell.execute_reply":"2022-06-02T00:47:49.664207Z"},"papermill":{"duration":3.259886,"end_time":"2022-06-02T00:47:49.669343","exception":false,"start_time":"2022-06-02T00:47:46.409457","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Additional materials","metadata":{"papermill":{"duration":0.086568,"end_time":"2022-06-02T00:47:49.843819","exception":false,"start_time":"2022-06-02T00:47:49.757251","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"- [Official LightAutoML github repo](https://github.com/AILab-MLTools/LightAutoML)\n- [LightAutoML documentation](https://lightautoml.readthedocs.io/en/latest)\n- [LightAutoML tutorials](https://github.com/AILab-MLTools/LightAutoML/tree/master/examples/tutorials)\n- LightAutoML course:\n    - [Part 1 - general overview](https://ods.ai/tracks/automl-course-part1) \n    - [Part 2 - LightAutoML specific applications](https://ods.ai/tracks/automl-course-part2)\n    - [Part 3 - LightAutoML customization](https://ods.ai/tracks/automl-course-part3)\n- [OpenDataScience AutoML benchmark leaderboard](https://ods.ai/competitions/automl-benchmark/leaderboard)","metadata":{"papermill":{"duration":0.087298,"end_time":"2022-06-02T00:47:50.017805","exception":false,"start_time":"2022-06-02T00:47:49.930507","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"### If you still like the notebook, do not forget to put upvote for the notebook and the ⭐️ for github repo if you like it using the button below - one click for you, great pleasure for us ☺️","metadata":{"papermill":{"duration":0.087433,"end_time":"2022-06-02T00:47:50.19255","exception":false,"start_time":"2022-06-02T00:47:50.105117","status":"completed"},"tags":[]}},{"cell_type":"code","source":"s = '<iframe src=\"https://ghbtns.com/github-btn.html?user=AILab-MLTools&repo=LightAutoML&type=star&count=true&size=large\" frameborder=\"0\" scrolling=\"0\" width=\"170\" height=\"30\" title=\"LightAutoML GitHub\"></iframe>'\nHTML(s)","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2022-06-02T00:47:50.373217Z","iopub.status.busy":"2022-06-02T00:47:50.372669Z","iopub.status.idle":"2022-06-02T00:47:50.381566Z","shell.execute_reply":"2022-06-02T00:47:50.380685Z"},"papermill":{"duration":0.10428,"end_time":"2022-06-02T00:47:50.384757","exception":false,"start_time":"2022-06-02T00:47:50.280477","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}