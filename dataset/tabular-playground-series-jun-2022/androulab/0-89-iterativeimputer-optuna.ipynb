{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport random\nimport itertools\n\nfrom lightgbm import LGBMRegressor\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nfrom sklearn.metrics import mean_squared_error\nimport optuna\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-27T00:56:06.67474Z","iopub.execute_input":"2022-06-27T00:56:06.675219Z","iopub.status.idle":"2022-06-27T00:56:09.535226Z","shell.execute_reply.started":"2022-06-27T00:56:06.675122Z","shell.execute_reply":"2022-06-27T00:56:09.534126Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/tabular-playground-series-jun-2022/data.csv', index_col='row_id')\nsub = pd.read_csv('../input/tabular-playground-series-jun-2022/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:56:09.537137Z","iopub.execute_input":"2022-06-27T00:56:09.537456Z","iopub.status.idle":"2022-06-27T00:56:29.347661Z","shell.execute_reply.started":"2022-06-27T00:56:09.537427Z","shell.execute_reply":"2022-06-27T00:56:29.34642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Optuna tuning\nIn order to reduce the training time from a few days to several hours, I will take a small sample from a large dataset. For model evaluation, some valid values may be changed to Nan.","metadata":{}},{"cell_type":"code","source":"SAMPLES_TEST = 100        # 100 valid cells will be changed to Nan\nROWS_TRAIN = (120, 4000)  # Train DF will be composed of 4000 valid rows and 120 rows for each column with Nan values","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:56:29.349482Z","iopub.execute_input":"2022-06-27T00:56:29.349872Z","iopub.status.idle":"2022-06-27T00:56:29.354998Z","shell.execute_reply.started":"2022-06-27T00:56:29.349838Z","shell.execute_reply":"2022-06-27T00:56:29.353974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# some important values\n\nmiss_cols = df.columns[df.isna().any()].tolist()\nnot_nan_rows = df[~df.isna().any(axis=1)].index.tolist()\n\ncolumns = df.columns.tolist()\nmiss_col_indx = {col: df[df[col].isna()].index.tolist() for col in miss_cols}","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:56:39.632343Z","iopub.execute_input":"2022-06-27T00:56:39.632783Z","iopub.status.idle":"2022-06-27T00:56:41.233972Z","shell.execute_reply.started":"2022-06-27T00:56:39.632751Z","shell.execute_reply":"2022-06-27T00:56:41.232926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def objective(trial, DF, y_test, idx):\n\n    params = {'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 10.0),\n              'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 10.0),\n              'colsample_bytree': trial.suggest_categorical('colsample_bytree', [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]),\n              'subsample': trial.suggest_categorical('subsample', [0.4, 0.5, 0.6, 0.7, 0.8, 1.0]),\n              'learning_rate': trial.suggest_float('learning_rate', 0.01, 1),\n              'max_depth': trial.suggest_int('max_depth', 4, 14),\n              'num_leaves' : trial.suggest_int('num_leaves', 1, 1000),\n              'min_child_samples': trial.suggest_int('min_child_samples', 1, 300),\n              'cat_smooth' : trial.suggest_int('cat_smooth', 1, 100),\n                \n              'random_state': trial.suggest_int('random_state', 300, 1500, 200),\n    }\n\n    \n    model = LGBMRegressor(metric='rmse', n_estimators=3000, random_state=1500,\n                          **dict(itertools.islice(params.items(), 9)))\n\n    imp = IterativeImputer(estimator=model, verbose=2, max_iter=3, \n                           imputation_order='ascending', initial_strategy='mean',\n                           **dict(itertools.islice(params.items(), 9, 10)))\n    \n    new_array = imp.fit_transform(DF)\n    predicted = new_array[idx[0], idx[1]]\n    \n    rmse = mean_squared_error(y_test, predicted)\n\n    return rmse\n\n\ndef optimize(DF, y_test, idx):\n    func = lambda trial: objective(trial, DF, y_test, idx)\n    study = optuna.create_study(direction='minimize')\n    study.optimize(func, show_progress_bar=True, n_trials=50)\n    return study","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:56:49.649325Z","iopub.execute_input":"2022-06-27T00:56:49.651231Z","iopub.status.idle":"2022-06-27T00:56:49.672799Z","shell.execute_reply.started":"2022-06-27T00:56:49.651169Z","shell.execute_reply":"2022-06-27T00:56:49.671139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**creating a sample**","metadata":{}},{"cell_type":"code","source":"def sample():\n    idx = []\n    for indicies in miss_col_indx.values():\n        idx += random.choices(indicies, k=ROWS_TRAIN[0])\n    \n    idx += random.choices(not_nan_rows, k=ROWS_TRAIN[1])\n    \n    DF = df.iloc[idx].reset_index(drop=True)\n\n    not_nan_rows_sub = DF[~DF.isna().any(axis=1)].index.tolist()\n    \n    rows_idx = random.choices(not_nan_rows_sub, k=SAMPLES_TEST)\n    cols_name = random.choices(miss_cols, k=SAMPLES_TEST)\n    cols_idx = [columns.index(name) for name in cols_name]\n\n    values_test = DF.to_numpy()[rows_idx, cols_idx]\n    for r_id, c_name in zip(rows_idx, cols_name):\n        DF.at[r_id, c_name] = np.nan\n    \n    return DF, values_test, [rows_idx, cols_idx]","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:56:55.832713Z","iopub.execute_input":"2022-06-27T00:56:55.833735Z","iopub.status.idle":"2022-06-27T00:56:55.843925Z","shell.execute_reply.started":"2022-06-27T00:56:55.833689Z","shell.execute_reply":"2022-06-27T00:56:55.842853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DF, values_test, idx = sample()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:03.044194Z","iopub.execute_input":"2022-06-27T00:57:03.044627Z","iopub.status.idle":"2022-06-27T00:57:03.118293Z","shell.execute_reply.started":"2022-06-27T00:57:03.04459Z","shell.execute_reply":"2022-06-27T00:57:03.117169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# opt = optimize(DF, values_test, idx)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:05.973026Z","iopub.execute_input":"2022-06-27T00:57:05.973396Z","iopub.status.idle":"2022-06-27T00:57:05.9776Z","shell.execute_reply.started":"2022-06-27T00:57:05.973363Z","shell.execute_reply":"2022-06-27T00:57:05.976757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I found the following params:\nparams = {\n              'reg_alpha': 0.02,\n              'reg_lambda': 0.06,\n              'colsample_bytree': 0.4,\n              'subsample': 1.0,\n              'learning_rate': 0.06,\n              'max_depth': 13,\n              'num_leaves' : 47,\n              'min_child_samples': 248,\n              'cat_smooth' : 44,\n                \n              'random_state': 900,\n        }\n","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:14.394717Z","iopub.execute_input":"2022-06-27T00:57:14.395473Z","iopub.status.idle":"2022-06-27T00:57:14.400976Z","shell.execute_reply.started":"2022-06-27T00:57:14.395437Z","shell.execute_reply":"2022-06-27T00:57:14.399806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train final model","metadata":{}},{"cell_type":"code","source":"SAMPLES_TEST_FINAL = 6000 # 6000 valid cells will be changed to Nan, for model evaluating","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:46.12486Z","iopub.execute_input":"2022-06-27T00:57:46.125492Z","iopub.status.idle":"2022-06-27T00:57:46.129791Z","shell.execute_reply.started":"2022-06-27T00:57:46.125459Z","shell.execute_reply":"2022-06-27T00:57:46.12862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sample_final():\n    rows_idx = random.choices(not_nan_rows, k=SAMPLES_TEST_FINAL)\n    cols_name = random.choices(miss_cols, k=SAMPLES_TEST_FINAL)\n    cols_idx = [columns.index(name) for name in cols_name]\n\n    values_test = df.to_numpy()[rows_idx, cols_idx]\n    for r_id, c_name in zip(rows_idx, cols_name):\n        df.at[r_id, c_name] = np.nan\n    \n    return values_test, [rows_idx, cols_idx]","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:46.304832Z","iopub.execute_input":"2022-06-27T00:57:46.305299Z","iopub.status.idle":"2022-06-27T00:57:46.558085Z","shell.execute_reply.started":"2022-06-27T00:57:46.305258Z","shell.execute_reply":"2022-06-27T00:57:46.556603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_test, idx = sample_final()","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:46.767031Z","iopub.execute_input":"2022-06-27T00:57:46.767415Z","iopub.status.idle":"2022-06-27T00:57:47.233556Z","shell.execute_reply.started":"2022-06-27T00:57:46.767385Z","shell.execute_reply":"2022-06-27T00:57:47.232398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LGBMRegressor(metric='rmse', n_estimators=3000, verbose=0, random_state=1500,\n                      **dict(itertools.islice(params.items(), 9)))\n\nimp = IterativeImputer(estimator=model, verbose=2, max_iter=5, \n                       imputation_order='ascending', initial_strategy='mean',\n                       **dict(itertools.islice(params.items(), 9, 10)))\n\n# new_array = imp.fit_transform(df)\n# It took me about 9000 sec / it","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:54.738445Z","iopub.execute_input":"2022-06-27T00:57:54.738967Z","iopub.status.idle":"2022-06-27T00:57:54.747565Z","shell.execute_reply.started":"2022-06-27T00:57:54.738923Z","shell.execute_reply":"2022-06-27T00:57:54.746639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# score\n# predicted = new_array[idx[0], idx[1]]\n# mean_squared_error(y_test, predicted)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:57:56.824964Z","iopub.execute_input":"2022-06-27T00:57:56.82551Z","iopub.status.idle":"2022-06-27T00:57:56.832547Z","shell.execute_reply.started":"2022-06-27T00:57:56.825463Z","shell.execute_reply":"2022-06-27T00:57:56.830808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df2 = pd.DataFrame(new_array, columns=columns)\n\n# for i, row_col in enumerate(sub['row-col'].tolist()):\n#     row, col = row_col.split('-')\n#     sub.at[i, 'value'] = df2.loc[int(row), col]\n\n# sub.set_index('row-col', inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:58:13.9478Z","iopub.execute_input":"2022-06-27T00:58:13.94817Z","iopub.status.idle":"2022-06-27T00:58:13.953402Z","shell.execute_reply.started":"2022-06-27T00:58:13.948141Z","shell.execute_reply":"2022-06-27T00:58:13.952118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub.to_csv('sub.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-27T00:58:14.322441Z","iopub.execute_input":"2022-06-27T00:58:14.322874Z","iopub.status.idle":"2022-06-27T00:58:14.328033Z","shell.execute_reply.started":"2022-06-27T00:58:14.322842Z","shell.execute_reply":"2022-06-27T00:58:14.326696Z"},"trusted":true},"execution_count":null,"outputs":[]}]}