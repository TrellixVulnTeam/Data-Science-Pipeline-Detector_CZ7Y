{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-28T17:48:45.931249Z","iopub.execute_input":"2022-06-28T17:48:45.931673Z","iopub.status.idle":"2022-06-28T17:48:45.968696Z","shell.execute_reply.started":"2022-06-28T17:48:45.931583Z","shell.execute_reply":"2022-06-28T17:48:45.967624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# load dataset","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv('../input/tabular-playground-series-jun-2022/data.csv')\n#test_data = \ntrain_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-28T17:48:45.970996Z","iopub.execute_input":"2022-06-28T17:48:45.97168Z","iopub.status.idle":"2022-06-28T17:49:05.888352Z","shell.execute_reply.started":"2022-06-28T17:48:45.971641Z","shell.execute_reply":"2022-06-28T17:49:05.887169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.reset_index(drop=True, inplace=True)\n\ntrain_data.shape\n","metadata":{"execution":{"iopub.status.busy":"2022-06-28T17:49:05.890202Z","iopub.execute_input":"2022-06-28T17:49:05.890956Z","iopub.status.idle":"2022-06-28T17:49:05.8992Z","shell.execute_reply.started":"2022-06-28T17:49:05.890907Z","shell.execute_reply":"2022-06-28T17:49:05.89824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking for null values and imputing missing values\nas we can see we have a large number of missing data for each column\nwhat i'm doing here is replacing all the missing values with their mean","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nprint(train_data.isnull().sum())\nfor k in train_data:\n    X = pd.DataFrame(train_data, columns=[k])\n    imp = SimpleImputer(missing_values=np.nan, strategy='mean')\n    X = imp.fit_transform(X)\n    train_data[k] = X","metadata":{"execution":{"iopub.status.busy":"2022-06-28T17:49:05.901549Z","iopub.execute_input":"2022-06-28T17:49:05.902613Z","iopub.status.idle":"2022-06-28T17:49:19.845537Z","shell.execute_reply.started":"2022-06-28T17:49:05.902572Z","shell.execute_reply":"2022-06-28T17:49:19.844185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# let's check if it worked","metadata":{}},{"cell_type":"code","source":"print(train_data.isnull().sum())\n\n","metadata":{"execution":{"iopub.status.busy":"2022-06-28T17:49:19.847585Z","iopub.execute_input":"2022-06-28T17:49:19.848063Z","iopub.status.idle":"2022-06-28T17:49:20.019134Z","shell.execute_reply.started":"2022-06-28T17:49:19.848015Z","shell.execute_reply":"2022-06-28T17:49:20.017806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Taking a look at our data's description","metadata":{}},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T17:49:20.021014Z","iopub.execute_input":"2022-06-28T17:49:20.021354Z","iopub.status.idle":"2022-06-28T17:49:24.11143Z","shell.execute_reply.started":"2022-06-28T17:49:20.021321Z","shell.execute_reply":"2022-06-28T17:49:24.110053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submission","metadata":{}},{"cell_type":"markdown","source":"improting the submission csv","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv(\"../input/tabular-playground-series-jun-2022/sample_submission.csv\", index_col='row-col')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-28T17:57:05.595437Z","iopub.execute_input":"2022-06-28T17:57:05.595893Z","iopub.status.idle":"2022-06-28T17:57:06.895615Z","shell.execute_reply.started":"2022-06-28T17:57:05.595857Z","shell.execute_reply":"2022-06-28T17:57:06.894474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\n\nfor i in tqdm(submission.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    submission.loc[i, 'value'] = train_data.loc[row, col]\n\nsubmission.to_csv('mean_benchmark.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-28T17:57:41.207684Z","iopub.execute_input":"2022-06-28T17:57:41.208786Z","iopub.status.idle":"2022-06-28T17:59:29.571724Z","shell.execute_reply.started":"2022-06-28T17:57:41.208742Z","shell.execute_reply":"2022-06-28T17:59:29.570223Z"},"trusted":true},"execution_count":null,"outputs":[]}]}