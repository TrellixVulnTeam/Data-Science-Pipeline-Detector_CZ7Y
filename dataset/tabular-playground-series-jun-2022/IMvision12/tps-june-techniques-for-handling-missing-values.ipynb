{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<div style=\"padding:20px;color:white;margin:0;font-size:200%;text-align:center;display:fill;border-radius:5px;background-color:#38A6A5;overflow:hidden;font-weight:500\">TPS June 2022</div>\n\n# <b><span style='color:#444444'>1 |</span><span style='color:#38A6A5'> Competition Overview</span></b>\n\nThe June edition of the 2022 Tabular Playground series is all about data imputation. The dataset has similarities to the May 2022 Tabular Playground, except that there are no targets. Rather, there are missing data values in the dataset, and your task is to predict what these values should be.","metadata":{}},{"cell_type":"code","source":"# Reference : https://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook\n# Credits : PARUL PANDEY","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\npd.set_option('display.max_columns', None) #Shows all columns","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:00:39.905469Z","iopub.execute_input":"2022-06-01T04:00:39.905896Z","iopub.status.idle":"2022-06-01T04:00:39.911907Z","shell.execute_reply.started":"2022-06-01T04:00:39.905862Z","shell.execute_reply":"2022-06-01T04:00:39.910712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:00:40.61266Z","iopub.execute_input":"2022-06-01T04:00:40.613182Z","iopub.status.idle":"2022-06-01T04:01:03.516106Z","shell.execute_reply.started":"2022-06-01T04:00:40.613145Z","shell.execute_reply":"2022-06-01T04:01:03.514757Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_describe = df.describe()\ndisplay(df_describe.style.format('{:,.3f}')\n        .background_gradient(subset=(df_describe.index[1:],df_describe.columns[:]), cmap='GnBu'))","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:49:40.755024Z","iopub.execute_input":"2022-06-01T03:49:40.75548Z","iopub.status.idle":"2022-06-01T03:49:44.957317Z","shell.execute_reply.started":"2022-06-01T03:49:40.755444Z","shell.execute_reply":"2022-06-01T03:49:44.956494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"null_columns = dict(df.isnull().sum())\nnull_columns","metadata":{"execution":{"iopub.status.busy":"2022-06-01T03:47:15.606291Z","iopub.execute_input":"2022-06-01T03:47:15.60679Z","iopub.status.idle":"2022-06-01T03:47:15.771662Z","shell.execute_reply.started":"2022-06-01T03:47:15.606755Z","shell.execute_reply":"2022-06-01T03:47:15.770538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Handling Missing Values\n\n<img src=\"https://i.imgur.com/68u0dD2.png\"/>","metadata":{}},{"cell_type":"markdown","source":"# Deletion","metadata":{}},{"cell_type":"markdown","source":"#### Pairwise Deletions\n\nParwise Deletion is used when values are missing completely at random i.e MCAR. During Pairwise deletion, only the missing values are deleted. All operations in pandas like mean,sum etc intrinsically skip missing values.","metadata":{}},{"cell_type":"code","source":"df_1 = df.copy()\nprint(df_1['F_1_10'].mean())\nprint(df_1['F_3_5'].mean())\nprint(df_1['F_4_5'].mean())\nprint(df_1['F_4_4'].mean())\nprint(df_1['F_1_12'].mean())","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:00:03.097396Z","iopub.execute_input":"2022-06-01T04:00:03.097822Z","iopub.status.idle":"2022-06-01T04:00:03.473359Z","shell.execute_reply.started":"2022-06-01T04:00:03.097788Z","shell.execute_reply":"2022-06-01T04:00:03.472102Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Listwise Deletion\n\nIn statistics, listwise deletion is a method for handling missing data. In this method, an entire record is excluded from analysis if any single value is missing.","metadata":{}},{"cell_type":"code","source":"print(df_1.F_3_13.isnull().sum())\ndf_1.dropna(subset=['F_3_13'],inplace=True)\nprint(df_1.F_3_13.isnull().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:03:49.069466Z","iopub.execute_input":"2022-06-01T04:03:49.070256Z","iopub.status.idle":"2022-06-01T04:03:49.47203Z","shell.execute_reply.started":"2022-06-01T04:03:49.070215Z","shell.execute_reply":"2022-06-01T04:03:49.470639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dropping complete columns\n\nIf a column contains a lot of missing values, say more than 80%, and the feature is not significant, you might want to delete that feature. However, again, it is not a good methodology to delete data.","metadata":{}},{"cell_type":"markdown","source":"# Imputations","metadata":{}},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:14:34.17069Z","iopub.execute_input":"2022-06-01T04:14:34.171347Z","iopub.status.idle":"2022-06-01T04:14:34.461453Z","shell.execute_reply.started":"2022-06-01T04:14:34.171312Z","shell.execute_reply":"2022-06-01T04:14:34.460401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndf_2 = df.copy()\nconst = SimpleImputer(strategy='constant') # imputing using constant value\ndf_2.iloc[:,:] = const.fit_transform(df_2)\ndf_2.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:15:19.664364Z","iopub.execute_input":"2022-06-01T04:15:19.665052Z","iopub.status.idle":"2022-06-01T04:15:41.381565Z","shell.execute_reply.started":"2022-06-01T04:15:19.665015Z","shell.execute_reply":"2022-06-01T04:15:41.380271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndf_3 = df.copy()\n# Missing values will be imputed with values which are occuring most frequently\nconst = SimpleImputer(strategy='most_frequent') # imputing using most_frequent\ndf_3.iloc[:,:] = const.fit_transform(df_3)\ndf_3.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:17:09.996875Z","iopub.execute_input":"2022-06-01T04:17:09.997267Z","iopub.status.idle":"2022-06-01T04:17:38.632084Z","shell.execute_reply.started":"2022-06-01T04:17:09.997235Z","shell.execute_reply":"2022-06-01T04:17:38.630771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndf_4 = df.copy()\nconst = SimpleImputer(strategy='mean') # imputing using mean\ndf_4.iloc[:,:] = const.fit_transform(df_4)\ndf_4.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:17:38.634229Z","iopub.execute_input":"2022-06-01T04:17:38.634781Z","iopub.status.idle":"2022-06-01T04:18:00.861629Z","shell.execute_reply.started":"2022-06-01T04:17:38.634729Z","shell.execute_reply":"2022-06-01T04:18:00.860569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndf_5 = df.copy()\nconst = SimpleImputer(strategy='median') # imputing using median\ndf_5.iloc[:,:] = const.fit_transform(df_5)\ndf_5.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:18:39.490258Z","iopub.execute_input":"2022-06-01T04:18:39.490684Z","iopub.status.idle":"2022-06-01T04:19:23.904276Z","shell.execute_reply.started":"2022-06-01T04:18:39.490651Z","shell.execute_reply":"2022-06-01T04:19:23.903056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imputations Techniques for Time Series Problems\n\nBasic Imputation Techniques\n1. 'ffill' or 'pad' - Replace NULL values with the value from the previous row's value\n2. 'bfill' or 'backfill' - Replace NULL values with the value from the next row's value\n3. Linear interpolation method","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://miro.medium.com/max/1348/0*EigRTqT8ybMMUZZe\"/>","metadata":{}},{"cell_type":"markdown","source":"#### 1.ffill","metadata":{}},{"cell_type":"code","source":"df_ffill = df.copy()\ndf_ffill.fillna(method='ffill',inplace=True)\ndf_ffill.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:23:11.336242Z","iopub.execute_input":"2022-06-01T04:23:11.336726Z","iopub.status.idle":"2022-06-01T04:23:11.901664Z","shell.execute_reply.started":"2022-06-01T04:23:11.336691Z","shell.execute_reply":"2022-06-01T04:23:11.900434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For imputiting in specific column\ndf_ffill[['F_1_2', 'F_4_14']] = df_ffill.loc[:,['F_1_2', 'F_4_14']].fillna(method='ffill')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:25:45.817667Z","iopub.execute_input":"2022-06-01T04:25:45.818132Z","iopub.status.idle":"2022-06-01T04:25:45.845919Z","shell.execute_reply.started":"2022-06-01T04:25:45.818098Z","shell.execute_reply":"2022-06-01T04:25:45.844712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 1.bfill","metadata":{}},{"cell_type":"code","source":"df_bfill = df.copy()\ndf_bfill.fillna(method='bfill',inplace=True)\ndf_bfill.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:26:04.434989Z","iopub.execute_input":"2022-06-01T04:26:04.435415Z","iopub.status.idle":"2022-06-01T04:26:05.007904Z","shell.execute_reply.started":"2022-06-01T04:26:04.435358Z","shell.execute_reply":"2022-06-01T04:26:05.006653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# For imputiting in specific column\ndf_bfill[['F_1_2', 'F_4_14']] = df_bfill.loc[:,['F_1_2', 'F_4_14']].fillna(method='bfill')","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:26:16.940354Z","iopub.execute_input":"2022-06-01T04:26:16.94078Z","iopub.status.idle":"2022-06-01T04:26:16.96592Z","shell.execute_reply.started":"2022-06-01T04:26:16.940749Z","shell.execute_reply":"2022-06-01T04:26:16.965066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"####  Linear Interpolation method\n\nLinear interpolation is an imputation technique that assumes a linear relationship between data points and utilises non-missing values from adjacent data points to compute a value for a missing data point.","metadata":{}},{"cell_type":"code","source":"interpolate = df.copy()\ninterpolate.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:27:39.868406Z","iopub.execute_input":"2022-06-01T04:27:39.868957Z","iopub.status.idle":"2022-06-01T04:27:40.309895Z","shell.execute_reply.started":"2022-06-01T04:27:39.868922Z","shell.execute_reply":"2022-06-01T04:27:40.308542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"interpolate['F_1_0'].interpolate(limit_direction=\"both\",inplace=True)\ninterpolate.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-01T04:28:01.468122Z","iopub.execute_input":"2022-06-01T04:28:01.468581Z","iopub.status.idle":"2022-06-01T04:28:01.651452Z","shell.execute_reply.started":"2022-06-01T04:28:01.468547Z","shell.execute_reply":"2022-06-01T04:28:01.650653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Checkout this wonderfull [Notebook](https://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python/notebook) for Advanced Imputation Techniques","metadata":{}}]}