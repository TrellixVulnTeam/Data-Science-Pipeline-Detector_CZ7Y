{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TPS-JUN22, Multivariate Feature Imputation ðŸ”¥\n## ...\nMultivariate imputer that estimates each feature from all the others.\nA strategy for imputing missing values by modeling each feature with missing values as a function of other features in a round-robin fashion.\n\nA more sophisticated approach is to use the IterativeImputer class, which models each feature with missing values as a function of other features, and uses that estimate for imputation. It does so in an iterated round-robin fashion: at each step, a feature column is designated as output y and the other feature columns are treated as inputs X. A regressor is fit on (X, y) for known y. Then, the regressor is used to predict the missing values of y. This is done for each feature in an iterative fashion, and then is repeated for max_iter imputation rounds. The results of the final imputation round are returned.\n\nhttps://scikit-learn.org/stable/modules/impute.html#iterative-imputer\n\n#### Credits...\nI used some or majority of the work or ideas in these Notebooks, Thanks to the authors.\n\n* https://www.kaggle.com/code/inversion/get-started-with-mean-imputation\n* https://www.kaggle.com/code/hiro5299834/tps-jun-2022-iterativeimputer-baseline","metadata":{}},{"cell_type":"markdown","source":"# 1. Loading the Requiered Libraries","metadata":{}},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-04T03:17:11.709424Z","iopub.execute_input":"2022-06-04T03:17:11.71048Z","iopub.status.idle":"2022-06-04T03:17:11.741238Z","shell.execute_reply.started":"2022-06-04T03:17:11.710375Z","shell.execute_reply":"2022-06-04T03:17:11.74029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom tqdm import tqdm\nfrom pathlib import Path\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom xgboost import XGBRegressor\nfrom catboost import CatBoostRegressor","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:11.743085Z","iopub.execute_input":"2022-06-04T03:17:11.743879Z","iopub.status.idle":"2022-06-04T03:17:12.698938Z","shell.execute_reply.started":"2022-06-04T03:17:11.743838Z","shell.execute_reply":"2022-06-04T03:17:12.698038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 2. Setting the Notebook","metadata":{}},{"cell_type":"code","source":"%%time\n# I like to disable my Notebook Warnings.\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:12.700251Z","iopub.execute_input":"2022-06-04T03:17:12.701818Z","iopub.status.idle":"2022-06-04T03:17:12.708498Z","shell.execute_reply.started":"2022-06-04T03:17:12.701774Z","shell.execute_reply":"2022-06-04T03:17:12.707548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Notebook Configuration...\n\n# Amount of data we want to load into the Model...\nDATA_ROWS = None\n# Dataframe, the amount of rows and cols to visualize...\nNROWS = 50\nNCOLS = 15\n# Main data location path...\nBASE_PATH = '...'","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:12.711311Z","iopub.execute_input":"2022-06-04T03:17:12.711924Z","iopub.status.idle":"2022-06-04T03:17:12.719024Z","shell.execute_reply.started":"2022-06-04T03:17:12.711894Z","shell.execute_reply":"2022-06-04T03:17:12.717997Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Configure notebook display settings to only use 2 decimal places, tables look nicer.\npd.options.display.float_format = '{:,.5f}'.format\npd.set_option('display.max_columns', NCOLS) \npd.set_option('display.max_rows', NROWS)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:12.720574Z","iopub.execute_input":"2022-06-04T03:17:12.721009Z","iopub.status.idle":"2022-06-04T03:17:12.72884Z","shell.execute_reply.started":"2022-06-04T03:17:12.720971Z","shell.execute_reply":"2022-06-04T03:17:12.727831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 3. Loading the Information (CSV) Into A Dataframe","metadata":{}},{"cell_type":"code","source":"%%time\n# Load the CSV information into a Pandas DataFrame...\ninput_path = Path('/kaggle/input/tabular-playground-series-jun-2022/')\n\ndataset = pd.read_csv(input_path / 'data.csv', index_col='row_id')\nsubmission = pd.read_csv(input_path / 'sample_submission.csv', index_col='row-col')","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:12.730422Z","iopub.execute_input":"2022-06-04T03:17:12.730949Z","iopub.status.idle":"2022-06-04T03:17:29.815645Z","shell.execute_reply.started":"2022-06-04T03:17:12.730911Z","shell.execute_reply":"2022-06-04T03:17:29.813906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 4. Exploring the Information Available","metadata":{}},{"cell_type":"code","source":"%%time\n# Explore the shape of the DataFrame...\ndataset.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:29.817138Z","iopub.execute_input":"2022-06-04T03:17:29.817592Z","iopub.status.idle":"2022-06-04T03:17:29.827163Z","shell.execute_reply.started":"2022-06-04T03:17:29.817531Z","shell.execute_reply":"2022-06-04T03:17:29.826398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display simple information of the variables in the dataset...\ndataset.info(verbose = False)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:29.828618Z","iopub.execute_input":"2022-06-04T03:17:29.829262Z","iopub.status.idle":"2022-06-04T03:17:29.850821Z","shell.execute_reply.started":"2022-06-04T03:17:29.829224Z","shell.execute_reply":"2022-06-04T03:17:29.849765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the first few rows of the DataFrame...\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:29.852267Z","iopub.execute_input":"2022-06-04T03:17:29.852762Z","iopub.status.idle":"2022-06-04T03:17:29.877075Z","shell.execute_reply.started":"2022-06-04T03:17:29.852723Z","shell.execute_reply":"2022-06-04T03:17:29.876085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Generate a simple statistical summary of the DataFrame, Only Numerical...\ndataset.describe()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:29.880025Z","iopub.execute_input":"2022-06-04T03:17:29.88038Z","iopub.status.idle":"2022-06-04T03:17:33.246614Z","shell.execute_reply.started":"2022-06-04T03:17:29.880345Z","shell.execute_reply":"2022-06-04T03:17:33.245734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Calculates the total number of missing values...\ndataset.isnull().sum().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:33.248079Z","iopub.execute_input":"2022-06-04T03:17:33.248685Z","iopub.status.idle":"2022-06-04T03:17:33.372932Z","shell.execute_reply.started":"2022-06-04T03:17:33.248646Z","shell.execute_reply":"2022-06-04T03:17:33.371979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the number of missing values by variable...\ndataset.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:33.374406Z","iopub.execute_input":"2022-06-04T03:17:33.374809Z","iopub.status.idle":"2022-06-04T03:17:33.501039Z","shell.execute_reply.started":"2022-06-04T03:17:33.374772Z","shell.execute_reply":"2022-06-04T03:17:33.500086Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the number of missing values by variable...\ndataset.isnull().sum().sort_values()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:33.503402Z","iopub.execute_input":"2022-06-04T03:17:33.504303Z","iopub.status.idle":"2022-06-04T03:17:33.630946Z","shell.execute_reply.started":"2022-06-04T03:17:33.504264Z","shell.execute_reply":"2022-06-04T03:17:33.629995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the number of unique values for each variable...\ndataset.nunique()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:33.632434Z","iopub.execute_input":"2022-06-04T03:17:33.632827Z","iopub.status.idle":"2022-06-04T03:17:36.590648Z","shell.execute_reply.started":"2022-06-04T03:17:33.632791Z","shell.execute_reply":"2022-06-04T03:17:36.589439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n# Display the number of unique values for each variable, sorted by quantity...\ndataset.nunique().sort_values(ascending = True)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:36.592198Z","iopub.execute_input":"2022-06-04T03:17:36.592883Z","iopub.status.idle":"2022-06-04T03:17:39.396864Z","shell.execute_reply.started":"2022-06-04T03:17:36.592839Z","shell.execute_reply":"2022-06-04T03:17:39.3959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 5. Multivariate Feature Imputation","metadata":{}},{"cell_type":"code","source":"%%time\nSEED = 22\nESTIMATORS = 1024\nITERATIONS_IMPUTER = 32\n\nparams = {'n_estimators': ESTIMATORS,\n          'random_state': SEED,\n          'tree_method' : 'gpu_hist',}\n\nestimator = XGBRegressor(**params)\n\nimp = IterativeImputer(estimator = estimator,\n                       missing_values = np.nan,\n                       max_iter = ITERATIONS_IMPUTER,\n                       initial_strategy = 'mean',\n                       imputation_order = 'ascending',\n                       verbose = 2,\n                       random_state = SEED,\n                      )\n\ndataset[:] = imp.fit_transform(dataset)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T03:17:39.398082Z","iopub.execute_input":"2022-06-04T03:17:39.398563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"code","source":"# %%time\n# SEED = 22\n# ITERATIONS_CATBOOST = 10\n# ITERATIONS_IMPUTER  = 5\n\n# params = {'iterations': ITERATIONS_CATBOOST,\n#           'task_type' :'GPU',\n#           'devices'   :'0:1',\n#           'verbose'   : 0}\n\n# estimator = CatBoostRegressor(**params)\n\n# imp = IterativeImputer(estimator = estimator,\n#                        missing_values = np.nan,\n#                        max_iter = ITERATIONS_IMPUTER,\n#                        initial_strategy = 'mean',\n#                        imputation_order = 'ascending',\n#                        verbose = 2,\n#                        random_state = SEED,\n#                       )\n\n# dataset[:] = imp.fit_transform(dataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# 6.0 Submission ","metadata":{}},{"cell_type":"code","source":"%%time\nfor i in tqdm(submission.index):\n    row = int(i.split('-')[0])\n    col = i.split('-')[1]\n    submission.loc[i, 'value'] = dataset.loc[row, col]\n\nsubmission.to_csv(\"submission.csv\")\nsubmission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---\n","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}