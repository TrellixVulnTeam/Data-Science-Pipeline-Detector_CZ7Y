{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"*This notebook is the Second expermentation done as a part of **Tabular Playground June 2022**, here we have been given the task to impute the values in the dataset. Lets start by importing the libraries*\n\n\nHere I have experimented with 3 values avaiable in sklearn, simple Imputor namely\n\n- Mean\n- Median\n- Most-frequent\n\n**Till now Mean gives the best result**","metadata":{}},{"cell_type":"code","source":"#Importing the Libs\n\n#General\nimport pandas as pd\nimport numpy as np\n\n# Time tracking\nfrom tqdm import tqdm\n\n# Path\nfrom pathlib import Path\n\n# Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Sklearn\nfrom sklearn.impute import SimpleImputer\n\n\n# Settings\npd.set_option('display.max_rows', 300)\npd.set_option('display.max_columns', 300)","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:11:36.626408Z","iopub.execute_input":"2022-06-21T12:11:36.626978Z","iopub.status.idle":"2022-06-21T12:11:36.635301Z","shell.execute_reply.started":"2022-06-21T12:11:36.626934Z","shell.execute_reply":"2022-06-21T12:11:36.634084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the dataset\ndf = pd.read_csv('../input/tabular-playground-series-jun-2022/data.csv', index_col='row_id') # setting row_id as index column\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:11:36.665184Z","iopub.execute_input":"2022-06-21T12:11:36.665984Z","iopub.status.idle":"2022-06-21T12:11:50.321105Z","shell.execute_reply.started":"2022-06-21T12:11:36.665931Z","shell.execute_reply":"2022-06-21T12:11:50.320132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reading the submission file\nsubmission = pd.read_csv('../input/tabular-playground-series-jun-2022/sample_submission.csv', index_col='row-col') #setting row-col as index\nsubmission.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:11:50.323184Z","iopub.execute_input":"2022-06-21T12:11:50.324293Z","iopub.status.idle":"2022-06-21T12:11:51.404421Z","shell.execute_reply.started":"2022-06-21T12:11:50.324242Z","shell.execute_reply":"2022-06-21T12:11:51.403472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have loaded the data, lets check the missing values & data shape for the dataframe","metadata":{}},{"cell_type":"code","source":"print('# of rows in the dataframe is: ', df.shape[0])\nprint('# of columns in the dataframe is: ', df.shape[1])","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:11:51.406199Z","iopub.execute_input":"2022-06-21T12:11:51.406685Z","iopub.status.idle":"2022-06-21T12:11:51.413083Z","shell.execute_reply.started":"2022-06-21T12:11:51.406639Z","shell.execute_reply":"2022-06-21T12:11:51.412001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing data \ndf.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:11:51.415711Z","iopub.execute_input":"2022-06-21T12:11:51.416234Z","iopub.status.idle":"2022-06-21T12:11:51.56842Z","shell.execute_reply.started":"2022-06-21T12:11:51.416186Z","shell.execute_reply":"2022-06-21T12:11:51.567384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So, we see that out of the 80 columns, we have missing values in the columns with the following prefix's\n\n- F_1_X\n- F_3_X\n- F_4_X","metadata":{}},{"cell_type":"markdown","source":"As the first strategy, let's try simple imputor from sklearn taking mean as the strategy as \"mean\", this is also the baseline solution provided with the dataset.","metadata":{}},{"cell_type":"code","source":"# Instiate the imputor\nimp = SimpleImputer(missing_values=np.nan,\n                   strategy='most_frequent')\n\n#fiting the data\ndata = imp.fit_transform(df)\n\n# Display, just curious :)\ndata","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:11:51.570287Z","iopub.execute_input":"2022-06-21T12:11:51.570648Z","iopub.status.idle":"2022-06-21T12:12:00.861862Z","shell.execute_reply.started":"2022-06-21T12:11:51.570615Z","shell.execute_reply":"2022-06-21T12:12:00.860803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now that we have found the missing values, we have to fill them up in the submissions file. ","metadata":{}},{"cell_type":"code","source":"#converting the Numpy array to pandas df\ndata = pd.DataFrame(data, columns=df.columns)\ndata.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:12:00.863246Z","iopub.execute_input":"2022-06-21T12:12:00.863598Z","iopub.status.idle":"2022-06-21T12:12:00.941282Z","shell.execute_reply.started":"2022-06-21T12:12:00.863567Z","shell.execute_reply":"2022-06-21T12:12:00.940325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in tqdm(submission.index):\n    row  = int(i.split('-')[0])\n    col = i.split('-')[1]\n    submission.loc[i, 'value'] = data.loc[row,col]\n    \n#save the file\nsubmission.to_csv('submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2022-06-21T12:12:00.942532Z","iopub.execute_input":"2022-06-21T12:12:00.942928Z","iopub.status.idle":"2022-06-21T12:13:45.569444Z","shell.execute_reply.started":"2022-06-21T12:12:00.942895Z","shell.execute_reply":"2022-06-21T12:13:45.568671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}