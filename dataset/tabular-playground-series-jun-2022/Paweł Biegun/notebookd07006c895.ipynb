{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-28T05:49:46.508313Z","iopub.execute_input":"2022-06-28T05:49:46.509312Z","iopub.status.idle":"2022-06-28T05:49:46.515333Z","shell.execute_reply.started":"2022-06-28T05:49:46.509271Z","shell.execute_reply":"2022-06-28T05:49:46.514011Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2022-06-28T05:49:47.349702Z","iopub.execute_input":"2022-06-28T05:49:47.350313Z","iopub.status.idle":"2022-06-28T05:49:48.07418Z","shell.execute_reply.started":"2022-06-28T05:49:47.350271Z","shell.execute_reply":"2022-06-28T05:49:48.073001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv(\"../input/tabular-playground-series-jun-2022/data.csv\")\ndata = data.drop(columns=[\"row_id\"])","metadata":{"execution":{"iopub.status.busy":"2022-06-28T05:49:53.652161Z","iopub.execute_input":"2022-06-28T05:49:53.652796Z","iopub.status.idle":"2022-06-28T05:50:11.652687Z","shell.execute_reply.started":"2022-06-28T05:49:53.65276Z","shell.execute_reply":"2022-06-28T05:50:11.651672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T05:50:11.654549Z","iopub.execute_input":"2022-06-28T05:50:11.655157Z","iopub.status.idle":"2022-06-28T05:50:11.68874Z","shell.execute_reply.started":"2022-06-28T05:50:11.655117Z","shell.execute_reply":"2022-06-28T05:50:11.687612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#We can see that the values are acceptably small and don't have to be normalised\nfor column in data:\n    print(f\"min: {min(data[column])}\")\n    print(f\"max: {max(data[column])}\")","metadata":{"execution":{"iopub.status.busy":"2022-06-27T15:28:18.656806Z","iopub.execute_input":"2022-06-27T15:28:18.657328Z","iopub.status.idle":"2022-06-27T15:28:42.432062Z","shell.execute_reply.started":"2022-06-27T15:28:18.657293Z","shell.execute_reply":"2022-06-27T15:28:42.430534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Dense(256, activation=\"relu\", input_shape=(79,)))\n\nmodel.add(Dense(128, activation=\"relu\"))\nmodel.add(Dropout(0.5))    # Dropout To Avoid Overfit\n\nmodel.add(Dense(64, activation=\"relu\"))\nmodel.add(Dropout(0.25))\n\nmodel.add(Dense(64, activation=\"relu\"))\n\nmodel.add(Dense(32, activation=\"relu\"))\n\nmodel.add(Dense(1, activation=\"linear\"))","metadata":{"execution":{"iopub.status.busy":"2022-06-28T05:50:18.741843Z","iopub.execute_input":"2022-06-28T05:50:18.74258Z","iopub.status.idle":"2022-06-28T05:50:21.435026Z","shell.execute_reply.started":"2022-06-28T05:50:18.742542Z","shell.execute_reply":"2022-06-28T05:50:21.43399Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for column in data:\n    X = data[data[column].notna()]\n    #print(f\"X initial, shape: {X.shape}\")\n    #print(X.head())\n    \n    #becuase -1000 is much lower than any value that naturally occours in the data it'll tell\n    #the neural network that this value is missing\n    X = X.fillna(-1000)\n    #print(f\"X after filling nan with -1000, shape: {X.shape}\")\n    #print(X.head())\n    \n    Y = X[column]\n    print(f\"Y std dev: {Y.std()}, Y mean: {Y.mean()}\")\n    #print(f\"Y initail, shape: {Y.shape}\")\n    #print(Y.head())\n    \n    X = X.drop(columns=[column])\n    #print(f\"X after dropping the label, shape: {X.shape}\")\n    #print(X.head())\n    \n    model.compile(loss='mean_squared_error', optimizer='adam')\n    \n    # check if the model doesn't overfit first then for the final submission don't use validations\n    model.fit(X, Y, epochs=3, batch_size=256, validation_split = 0.1)\n    \n    #print(\"model predictions\")\n    #print(model.predict(X[0:5]))\n    predictions = model.predict(X[0:10])\n    print(len(predictions))\n    for n in range(10):\n        print(f\"model predicted: {predictions[n]}, the actual value was: {Y[n]}\")\n    \n    gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-28T05:50:27.083289Z","iopub.execute_input":"2022-06-28T05:50:27.084103Z","iopub.status.idle":"2022-06-28T05:51:26.553636Z","shell.execute_reply.started":"2022-06-28T05:50:27.084054Z","shell.execute_reply":"2022-06-28T05:51:26.551958Z"},"trusted":true},"execution_count":null,"outputs":[]}]}