{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-09T06:07:44.173078Z","iopub.execute_input":"2022-06-09T06:07:44.173881Z","iopub.status.idle":"2022-06-09T06:07:44.208119Z","shell.execute_reply.started":"2022-06-09T06:07:44.17372Z","shell.execute_reply":"2022-06-09T06:07:44.206903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pathlib import Path","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:07:44.387919Z","iopub.execute_input":"2022-06-09T06:07:44.388366Z","iopub.status.idle":"2022-06-09T06:07:44.394114Z","shell.execute_reply.started":"2022-06-09T06:07:44.388331Z","shell.execute_reply":"2022-06-09T06:07:44.392827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_path= Path(\"/kaggle/input/tabular-playground-series-jun-2022/\")","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:07:44.53965Z","iopub.execute_input":"2022-06-09T06:07:44.540051Z","iopub.status.idle":"2022-06-09T06:07:44.544697Z","shell.execute_reply.started":"2022-06-09T06:07:44.540017Z","shell.execute_reply":"2022-06-09T06:07:44.543691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data= pd.read_csv(input_path / 'data.csv', index_col='row_id')\nprint(\"input shape:\",data.shape)\nprint(\" input nan count:\",data.isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:07:44.670581Z","iopub.execute_input":"2022-06-09T06:07:44.67164Z","iopub.status.idle":"2022-06-09T06:08:05.035681Z","shell.execute_reply.started":"2022-06-09T06:07:44.671594Z","shell.execute_reply":"2022-06-09T06:08:05.034605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.impute import SimpleImputer\n\nimp = SimpleImputer(\nmissing_values=np.nan, strategy=\"mean\")\noutput = data.copy()\noutput[:]=imp.fit_transform(data)\nprint('output shape:',output.shape)\nprint('output nan count:',output.isna().sum().sum())","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:08:05.037865Z","iopub.execute_input":"2022-06-09T06:08:05.038276Z","iopub.status.idle":"2022-06-09T06:08:32.748114Z","shell.execute_reply.started":"2022-06-09T06:08:05.038237Z","shell.execute_reply":"2022-06-09T06:08:32.746989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef generate_submission(source_df: pd.DataFrame, output_df: pd.DataFrame) -> pd.DataFrame:\n    # Melt source dataframe filtered on NaN values to form [row_id, col, isNull] ...\n    # ... with MultiIndex on (row_id, col)\n    nan_only = (source_df\n                .isna()\n                .melt(ignore_index=False, var_name='col', value_name='isNull')\n                .query('isNull == True')\n                .set_index(['col'], append=True))\n       # Melt output dataframe to form [row_id, col, value] with MultiIndex on (row_id, col)\n    out = (output_df\n            .melt(ignore_index=False, var_name='col')\n            .set_index(['col'], append=True))\n     # Filter output's MultiIndex on nan_only's MultiIndex\n    out = (out.loc[nan_only.index]\n               .sort_index())\n        # Flatten MultiIndex to Index & rename to desired column\n    out.index = [f'{r}-{c}' for r, c in out.index]\n    out.index.name = 'row-col'\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:08:32.749938Z","iopub.execute_input":"2022-06-09T06:08:32.750629Z","iopub.status.idle":"2022-06-09T06:08:32.761275Z","shell.execute_reply.started":"2022-06-09T06:08:32.750579Z","shell.execute_reply":"2022-06-09T06:08:32.75995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n\ndef generate_submission(source_df: pd.DataFrame, output_df: pd.DataFrame) -> pd.DataFrame:\n    # Melt source dataframe filtered on NaN values to form [row_id, col, isNull] ...\n    # ... with MultiIndex on (row_id, col)\n    nan_only = (source_df\n                .isna()\n                .melt(ignore_index=False, var_name='col', value_name='isNull')\n                .query('isNull == True')\n                .set_index(['col'], append=True))\n\n    # Melt output dataframe to form [row_id, col, value] with MultiIndex on (row_id, col)\n    out = (output_df\n            .melt(ignore_index=False, var_name='col')\n            .set_index(['col'], append=True))\n\n    # Filter output's MultiIndex on nan_only's MultiIndex\n    out = (out.loc[nan_only.index]\n               .sort_index())\n    \n    # Flatten MultiIndex to Index & rename to desired column\n    out.index = [f'{r}-{c}' for r, c in out.index]\n    out.index.name = 'row-col'\n    return out","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:08:32.763247Z","iopub.execute_input":"2022-06-09T06:08:32.763671Z","iopub.status.idle":"2022-06-09T06:08:32.784005Z","shell.execute_reply.started":"2022-06-09T06:08:32.763637Z","shell.execute_reply":"2022-06-09T06:08:32.782782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = generate_submission(data, output)\nresult","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:08:32.785891Z","iopub.execute_input":"2022-06-09T06:08:32.786573Z","iopub.status.idle":"2022-06-09T06:09:33.671309Z","shell.execute_reply.started":"2022-06-09T06:08:32.786531Z","shell.execute_reply":"2022-06-09T06:09:33.670354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv(input_path / 'sample_submission.csv',index_col='row-col')","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:26:22.871916Z","iopub.execute_input":"2022-06-09T06:26:22.87244Z","iopub.status.idle":"2022-06-09T06:26:24.27638Z","shell.execute_reply.started":"2022-06-09T06:26:22.872406Z","shell.execute_reply":"2022-06-09T06:26:24.275241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2022-06-09T06:26:31.691528Z","iopub.execute_input":"2022-06-09T06:26:31.692712Z","iopub.status.idle":"2022-06-09T06:26:31.706941Z","shell.execute_reply.started":"2022-06-09T06:26:31.692658Z","shell.execute_reply":"2022-06-09T06:26:31.706141Z"},"trusted":true},"execution_count":null,"outputs":[]}]}