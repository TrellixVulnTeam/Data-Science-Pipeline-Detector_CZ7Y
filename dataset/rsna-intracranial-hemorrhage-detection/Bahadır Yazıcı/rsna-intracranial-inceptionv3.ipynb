{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport json\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pydicom\nfrom keras import layers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.initializers import Constant\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom tensorflow.python.ops import array_ops\nfrom tqdm import tqdm\nfrom keras import backend as K\nimport tensorflow as tf\nimport keras\nfrom math import ceil, floor\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.metrics import log_loss\nfrom keras.layers import Dense, Dropout, Activation, Conv2D, MaxPool2D, Flatten","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Define Paths and dataframes."},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path = '/kaggle/input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/'\ntest_image_dir = base_path + 'stage_2_test/'\ntrain_image_dir= base_path + 'stage_2_train/'\ntrain_df = pd.read_csv('../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train.csv')\ntest_df = pd.read_csv('../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_train(train_df):\n    \n    train_df['type'] = train_df.ID.str.slice(start = 13)\n    train_df['filename'] = train_df.ID.str.slice(stop = 12)\n    train_df = train_df.drop_duplicates()\n    train_df = train_df.reset_index()\n    train_df = train_df.drop('ID', axis =1)\n    train_df = train_df.set_index(['filename', 'type']).unstack(level=-1)\n    train_df = train_df.drop('index', axis =1)\n    return train_df \n\ndef read_test(test_df):\n    test_df['type'] = test_df.ID.str.slice(start = 13)\n    test_df['filename'] = test_df.ID.str.slice(stop = 12)\n    test_df = test_df.drop_duplicates()\n    test_df= test_df.drop('ID', axis =1)\n    test_df = test_df.set_index(['filename', 'type']).unstack(level=-1)\n    return test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = read_train(train_df)\ntest_df = read_test(test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'test_df shape: {test_df.shape}')\nprint(f'train_df shape: {train_df.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=train_df.reset_index(level=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_names = df['filename']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"def Visualize_Ten_Image(train_df , type1):\n    row = 2\n    col = 5\n    fig = plt.figure(figsize = (15, 5)) \n    count = 0\n    for i in range(len(train_df)):\n\n        \n        if train_df['Label'][type1][i] == 1:\n            ds = pydicom.dcmread(train_image_dir + str(img_names[i]+'.dcm'))\n            fig.add_subplot(row, col, count+1)\n            plt.suptitle(type1, fontsize = 20)\n            plt.imshow(ds.pixel_array, cmap=plt.cm.bone)\n            plt.axis('off')\n            count += 1\n            if count == 10:\n                break\n                ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Visualize_Ten_Image(train_df, 'epidural')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Visualize_Ten_Image(train_df, 'intraparenchymal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Visualize_Ten_Image(train_df, 'intraventricular')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Visualize_Ten_Image(train_df, 'subarachnoid')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Visualize_Ten_Image(train_df, 'subdural')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read Images and windowing"},{"metadata":{},"cell_type":"markdown","source":"many thanks to Ryan Epp. this code below was taken from Ryan Epp. if you want to check his kernel here is the link:: [Ryan Epp](https://www.kaggle.com/reppic/gradient-sigmoid-windowing)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def correct_dcm(dcm):\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000\n\ndef window_image(dcm, window_center, window_width):    \n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    \n    # Resize\n    img = cv2.resize(img, SHAPE[:2], interpolation = cv2.INTER_LINEAR)\n   \n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef bsb_window(dcm):\n    brain_img = window_image(dcm, 40, 80)\n    subdural_img = window_image(dcm, 80, 200)\n    soft_img = window_image(dcm, 40, 380)\n    \n    brain_img = (brain_img - 0) / 80\n    subdural_img = (subdural_img - (-20)) / 200\n    soft_img = (soft_img - (-150)) / 380\n    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n    return bsb_img\n\ndef _read(path, SHAPE):\n    dcm = pydicom.dcmread(path)\n    try:\n        img = bsb_window(dcm)\n    except:\n        img = np.zeros(SHAPE)\n    return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create Data Generators"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Train_Val_Data_Generator(keras.utils.Sequence):\n    \n    def __init__(self, data, labels, batch_size = 32, img_size = (256, 256, 3), img_dir = train_image_dir, shuffle = False,*args, **kwargs):\n        self.data = data\n        self.ids = data.index\n        self.labels = labels\n        self.batch_size = batch_size\n        self.img_dir = img_dir\n        self.img_size = img_size\n        self.shuffle = shuffle\n        self.on_epoch_end()\n    \n    def __len__(self):\n        return int(ceil(len(self.ids) / self.batch_size))\n    \n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        X, Y = self.__data_generate(indices)\n        return X, Y\n\n    def on_epoch_end(self):\n        \n        self.indices = np.arange(len(self.ids))\n        \n        if self.shuffle:\n            np.random.shuffle(self.indices)\n    \n    def __data_generate(self, indices):\n        X = np.empty((self.batch_size, *self.img_size))\n        Y = np.empty((self.batch_size, 6), dtype=np.float32)\n        \n        for i, index in enumerate(indices):\n            ID = self.ids[index]\n            image = _read(str(self.img_dir)+str(ID)+\".dcm\", self.img_size)\n            X[i,] = image\n            Y[i,] = self.labels.iloc[index].values        \n        return X, Y\n    \n\nclass Test_Data_Generator(keras.utils.Sequence):\n    \n    def __init__(self, data, labels, batch_size = 32, img_size = (256, 256, 3), img_dir = test_image_dir, *args, **kwargs):\n        self.data = data\n        self.ids = data.index\n        self.labels = labels\n        self.img_size = img_size\n        self.batch_size = batch_size\n        self.img_dir = img_dir\n        self.on_epoch_end()\n    \n    def __len__(self):\n        return int(ceil(len(self.ids) / self.batch_size))\n    \n    def __getitem__(self, index):\n        indices = self.indices[index*self.batch_size:(index+1)*self.batch_size]\n        X= self.__data_generate(indices)\n        return X\n\n    def on_epoch_end(self):\n        \n        self.indices = np.arange(len(self.ids))\n        \n    \n    def __data_generate(self, indices):\n            X = np.empty((self.batch_size, *self.img_size))\n            \n            for i, index in enumerate(indices):\n                ID = self.ids[index]\n                image = _read(str(self.img_dir)+str(ID)+\".dcm\", self.img_size)\n                X[i,] = image\n                return X\n    \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss = ShuffleSplit(n_splits=10, test_size=0.1, random_state=42).split(train_df.index)\ntrain_idx, valid_idx = next(ss)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_gen = Train_Val_Data_Generator(train_df.iloc[train_idx], \n                                     train_df.iloc[train_idx],\n                                     shuffle = False)\nval_gen = Train_Val_Data_Generator(train_df.iloc[valid_idx], \n                                   train_df.iloc[valid_idx],\n                                   shuffle = False)\n\ntest_gen = Test_Data_Generator(test_df, None,32, (256,256,3), test_image_dir,verbose =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inceptionv3 =tf.keras.applications.InceptionV3(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=(256,256,3),\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Create the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    print('Building Model..')\n    model = Sequential()\n    model.add(inceptionv3)\n    model.add(Conv2D(64, kernel_size=(3,3),activation='relu'))\n    model.add(MaxPool2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.3))\n    model.add(layers.Dense(6, activation='sigmoid'))\n    \n    model.compile(optimizer = keras.optimizers.Adam(), \n                  loss = 'binary_crossentropy',\n                  metrics =  ['acc'])\n    return model\n\nmodel = build_model()\n    \nprint(f'Model Summary: {model.summary()} ')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_STEPS = int(len(train_gen) / 32)\nTRAIN_STEPS","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Callbacks"},{"metadata":{"trusted":true},"cell_type":"code","source":"Early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=1, \n                                              mode='auto', baseline=None, restore_best_weights=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator = train_gen,\n                    validation_data = val_gen,\n                    steps_per_epoch = TRAIN_STEPS,\n                    callbacks = [Early_stop],\n                    epochs = 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_steps = len(test_gen)\ntest_steps","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Many thanks to Robin Smits. The code below is taken from Robin Smits to submit Test predictions. if you want to check his kernel here is the link [Robin Smits](https://www.kaggle.com/rsmits/keras-efficientnet-b2-starter-code/notebook)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predictions(test_df, model):    \n    test_preds = model.predict_generator(test_gen, verbose = 1)\n    return test_preds[:test_df.iloc[range(test_df.shape[0])].shape[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_predictions =[]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = predictions(test_df, model)\nsubmission_predictions.append(preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.iloc[:, :] = np.average(submission_predictions, axis = 0, weights = [2**i for i in range(len(submission_predictions))])\ntest_df = test_df.stack().reset_index()\ntest_df.insert(loc = 0, column = 'ID', value = test_df['filename'].astype(str) + \"_\" + test_df['type'])\ntest_df = test_df.drop([\"filename\", \"type\"], axis=1)\ntest_df.to_csv('submission.csv', index = False)\n\nprint(test_df.head(12))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}