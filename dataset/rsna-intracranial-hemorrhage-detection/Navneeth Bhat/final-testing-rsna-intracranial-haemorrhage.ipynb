{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing libraries\nimport os\nimport random\nimport glob\nimport pandas as pd\nimport numpy as np\nimport pydicom \nfrom torch.hub import load_state_dict_from_url\nfrom torchvision.models.resnet import ResNet, Bottleneck\nimport torch\nimport torch.optim as optim\nfrom albumentations import Compose, ShiftScaleRotate, Resize, Normalize, HorizontalFlip, RandomBrightnessContrast,CenterCrop\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset,Subset\n# import cv2\n#from sklearn.decomposition import PCA\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import roc_auc_score, classification_report, recall_score, f1_score, accuracy_score, precision_score, jaccard_score\nfrom tqdm import notebook as tqdm\n\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#!pip install opencv-python","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_csv = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection'\n\ntrain_images_dir = '../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\ntest_images_dir = '../input/rsna-test-stage-1-images-png-224x/stage_1_test_png_224x'\n# train_metadata_csv = '/home/navneeth/ICH_Code/input/train_metadata_noidx.csv'\n# test_metadata_csv = '/home/navneeth/ICH_Code/input/test_metadata_noidx.csv'","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:31:45.047961Z","iopub.execute_input":"2022-06-25T16:31:45.048344Z","iopub.status.idle":"2022-06-25T16:31:45.052802Z","shell.execute_reply.started":"2022-06-25T16:31:45.048312Z","shell.execute_reply":"2022-06-25T16:31:45.051892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PARAMS\nn_classes = 6\nn_epochs = 10\nbatch_size = 32\n\nCOLS = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:48:58.73873Z","iopub.execute_input":"2022-06-25T16:48:58.740622Z","iopub.status.idle":"2022-06-25T16:48:58.745985Z","shell.execute_reply.started":"2022-06-25T16:48:58.740584Z","shell.execute_reply":"2022-06-25T16:48:58.744791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(os.path.join(dir_csv, 'stage_2_train.csv'))\ntest = pd.read_csv(os.path.join(dir_csv, 'stage_2_sample_submission.csv'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IntracranialDataset(Dataset):\n\n    def __init__(self, csv_file, path, labels, transform=None):\n        \n        self.path = path\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.labels = labels\n\n    def __len__(self):\n        \n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \n        img_name = os.path.join(self.path, self.data.loc[idx, 'Image'] + '.png')\n        img = cv2.imread(img_name)\n        \n        if self.transform:       \n            \n            augmented = self.transform(image=img)\n            img = augmented['image']   \n            \n        if self.labels:\n            \n            labels = torch.tensor(\n                self.data.loc[idx, ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']])\n            return {'image': img, 'labels': labels}    \n        \n        else:      \n            \n            return {'image': img}\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preparing data\ntrain[['ID', 'Image', 'Diagnosis']] = train['ID'].str.split('_', expand=True)\ntrain = train[['Image', 'Diagnosis', 'Label']]\ntrain.drop_duplicates(inplace=True)\ntrain = train.pivot(index='Image', columns='Diagnosis', values='Label').reset_index()\ntrain['Image'] = 'ID_' + train['Image']\n\n#remove images that are not saved properly as png \npng = glob.glob(os.path.join(train_images_dir, '*.png'))\npng = [os.path.basename(png)[:-4] for png in png]\npng = np.array(png)\n\n\ntrain = train[train['Image'].isin(png)]\ntrain.to_csv('train.csv',index=False)","metadata":{"_kg_hide-input":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['ID','Image','Diagnosis']] = test['ID'].str.split('_', expand=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Image'] = 'ID_' + test['Image']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['Image', 'Label']]\ntest.drop_duplicates(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"png = glob.glob(os.path.join(test_images_dir, '*.png'))\npng = [os.path.basename(png)[:-4] for png in png]\npng = np.array(png)\n\ntest = test[test['Image'].isin(png)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()\nprint(len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No instances of Image IDs in csv found in image dataset","metadata":{}},{"cell_type":"code","source":"# Prepare test table\ntest.to_csv('test1.csv', index=False)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1 = pd.read_csv('../input/mydata/test.csv')\ntest1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform_train = Compose([CenterCrop(200,200),HorizontalFlip(),\n#                            ShiftScaleRotate(),\n#                            RandomBrightnessContrast(),\n#                            ToTensorV2()])\n\ntransform_test = Compose([CenterCrop(200,200),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:32:27.009995Z","iopub.execute_input":"2022-06-25T16:32:27.010708Z","iopub.status.idle":"2022-06-25T16:32:27.016125Z","shell.execute_reply.started":"2022-06-25T16:32:27.010669Z","shell.execute_reply":"2022-06-25T16:32:27.014949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = IntracranialDataset(\n    csv_file='../input/mydata/test.csv', path=test_images_dir, transform=transform_test, labels=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_dataset))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nprint(len(data_loader_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the model\nmodel_urls = {\n    'resnext101_32x8d': 'https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth',\n    'resnext101_32x16d': 'https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth',\n    'resnext101_32x32d': 'https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth',\n    'resnext101_32x48d': 'https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth',\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T16:32:29.950228Z","iopub.execute_input":"2022-06-25T16:32:29.9509Z","iopub.status.idle":"2022-06-25T16:32:29.955908Z","shell.execute_reply.started":"2022-06-25T16:32:29.950865Z","shell.execute_reply":"2022-06-25T16:32:29.954737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting up the model\ndef _resnext(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n    model.load_state_dict(state_dict)\n    return model\n\ndef resnext101_32x8d_wsl(progress=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 8\n    return _resnext('resnext101_32x8d', Bottleneck, [3, 4, 23, 3], True, progress, **kwargs)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-25T16:32:31.617013Z","iopub.execute_input":"2022-06-25T16:32:31.617608Z","iopub.status.idle":"2022-06-25T16:32:31.624697Z","shell.execute_reply.started":"2022-06-25T16:32:31.617571Z","shell.execute_reply":"2022-06-25T16:32:31.623517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:32:34.653631Z","iopub.execute_input":"2022-06-25T16:32:34.654016Z","iopub.status.idle":"2022-06-25T16:32:34.659047Z","shell.execute_reply.started":"2022-06-25T16:32:34.653985Z","shell.execute_reply":"2022-06-25T16:32:34.657772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnext101_32x8d_wsl()\nmodel.fc = torch.nn.Linear(2048,n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:32:36.328277Z","iopub.execute_input":"2022-06-25T16:32:36.328664Z","iopub.status.idle":"2022-06-25T16:32:38.072542Z","shell.execute_reply.started":"2022-06-25T16:32:36.328633Z","shell.execute_reply":"2022-06-25T16:32:38.071417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading state dictionaries\nmodel = torch.nn.DataParallel(model)\ncheckpoint = torch.load('../input/models/png_model_e10_final.pt')\nmodel.load_state_dict(checkpoint['model'])","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:32:39.752881Z","iopub.execute_input":"2022-06-25T16:32:39.753576Z","iopub.status.idle":"2022-06-25T16:32:42.127914Z","shell.execute_reply.started":"2022-06-25T16:32:39.753541Z","shell.execute_reply":"2022-06-25T16:32:42.126884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-25T16:32:44.086189Z","iopub.execute_input":"2022-06-25T16:32:44.086817Z","iopub.status.idle":"2022-06-25T16:32:44.122174Z","shell.execute_reply.started":"2022-06-25T16:32:44.08677Z","shell.execute_reply":"2022-06-25T16:32:44.120914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(data_loader_test))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(data_loader_test))\nfig, axs = plt.subplots(1, 5, figsize=(15,5))\n\nfor i in np.arange(5):\n    \n    axs[i].imshow(np.transpose(batch['image'][i].numpy(), (1,2,0))[:,:,0], cmap=plt.cm.bone)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\nmodel.eval()\n\ntest_pred = np.zeros((len(test_dataset) * n_classes, 1))\n\nfor i, x_batch in enumerate(tqdm.tqdm(data_loader_test)):\n    \n    x_batch = x_batch[\"image\"]\n    x_batch = x_batch.to(device, dtype=torch.float)\n    \n    with torch.no_grad():\n        \n        pred = model(x_batch)\n        \n        test_pred[(i * batch_size * n_classes):((i + 1) * batch_size * n_classes)] = torch.sigmoid(\n            pred).detach().cpu().reshape((len(x_batch) * n_classes, 1))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing with single image","metadata":{}},{"cell_type":"code","source":"img1 = cv2.imread(\"../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x/ID_aec8e68b3.png\")\n# augmented = transform_test(image=img1)\nsample_img = transform_test(image=img1)['image'].unsqueeze(0)\nprint(sample_img.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input = sample_img.to(device, dtype=torch.float)\nprint(test_input.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model(test_input)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba = torch.sigmoid(pred).detach().cpu()\nproba","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_b = torch.round(proba)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_list = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_lbl = np.where(out_b.float() == 1)[1]\npred_lbl","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = []\nfor i in pred_lbl:\n    label.append(label_list[i])\n    \nlabel","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchcam\nfrom torchcam.methods import SmoothGradCAMpp, LayerCAM\nfrom torchcam.utils import overlay_mask","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cam_extractor = SmoothGradCAMpp(model)\ncams = cam_extractor(out.squeeze(0).argmax().item(), out)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom functions(WIP)","metadata":{}},{"cell_type":"code","source":"def get_tensor(img):\n    tfms_img = Compose([CenterCrop(200,200),\n                           ToTensorV2()])\n    img = cv2.imread(img)\n    return tfms_img(image=img)['image'].unsqueeze(0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(img, model, label_list):\n    \n    input_tensor = get_tensor(img)\n    \n#     if device == \"cuda:0\":\n    input_tensor = input_tensor.to(device, dtype=torch.float)\n#     else:\n        #code for CPU device\n        \n    pred = model(input_tensor)\n    \n    #probabilities\n#     if device == \"cuda:0\":\n    proba = torch.sigmoid(pred).detach().cpu()\n#     else:\n        #code for CPU device\n    \n    #labels\n    out = torch.round(proba)\n    pred_lbl = np.where(out == 1)[1]\n    \n    label = []\n    for i in pred_lbl:\n        label.append(label_list[i])\n        \n    return proba, out, label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing function on sample image\npredict('../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x/ID_aec8e68b3.png', model, label_list)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual explanations using Grad-CAM","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport os\nimport random\nimport glob\nimport pandas as pd\nimport numpy as np\nimport pydicom \nfrom torch.hub import load_state_dict_from_url\nfrom torchvision.models.resnet import ResNet, Bottleneck\nimport torch\nimport torch.optim as optim\nfrom albumentations import Compose, ShiftScaleRotate, Resize, Normalize, HorizontalFlip, RandomBrightnessContrast,CenterCrop\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset,Subset\nimport cv2\n#from sklearn.decomposition import PCA\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import roc_auc_score, classification_report, recall_score, f1_score, accuracy_score, precision_score, jaccard_score\nfrom tqdm import notebook as tqdm\n\nfrom matplotlib import pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:19.456331Z","iopub.execute_input":"2022-06-26T09:14:19.456937Z","iopub.status.idle":"2022-06-26T09:14:19.470457Z","shell.execute_reply.started":"2022-06-26T09:14:19.456878Z","shell.execute_reply":"2022-06-26T09:14:19.46884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_csv = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection'\n\ntrain_images_dir = '../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\ntest_images_dir = '../input/rsna-test-stage-1-images-png-224x/stage_1_test_png_224x'","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:23.434626Z","iopub.execute_input":"2022-06-26T09:14:23.435018Z","iopub.status.idle":"2022-06-26T09:14:23.44207Z","shell.execute_reply.started":"2022-06-26T09:14:23.434986Z","shell.execute_reply":"2022-06-26T09:14:23.440333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = 6\nn_epochs = 10\nbatch_size = 32\n\nCOLS = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:26.063338Z","iopub.execute_input":"2022-06-26T09:14:26.063792Z","iopub.status.idle":"2022-06-26T09:14:26.07159Z","shell.execute_reply.started":"2022-06-26T09:14:26.063759Z","shell.execute_reply":"2022-06-26T09:14:26.069015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_test = Compose([CenterCrop(200,200),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:29.282555Z","iopub.execute_input":"2022-06-26T09:14:29.282983Z","iopub.status.idle":"2022-06-26T09:14:29.288853Z","shell.execute_reply.started":"2022-06-26T09:14:29.282951Z","shell.execute_reply":"2022-06-26T09:14:29.287477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the model\nmodel_urls = {\n    'resnext101_32x8d': 'https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth',\n    'resnext101_32x16d': 'https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth',\n    'resnext101_32x32d': 'https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth',\n    'resnext101_32x48d': 'https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth',\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:32.594086Z","iopub.execute_input":"2022-06-26T09:14:32.594845Z","iopub.status.idle":"2022-06-26T09:14:32.60264Z","shell.execute_reply.started":"2022-06-26T09:14:32.594791Z","shell.execute_reply":"2022-06-26T09:14:32.60058Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting up the model\ndef _resnext(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n    model.load_state_dict(state_dict)\n    return model\n\ndef resnext101_32x8d_wsl(progress=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 8\n    return _resnext('resnext101_32x8d', Bottleneck, [3, 4, 23, 3], True, progress, **kwargs)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:35.263281Z","iopub.execute_input":"2022-06-26T09:14:35.263892Z","iopub.status.idle":"2022-06-26T09:14:35.279951Z","shell.execute_reply.started":"2022-06-26T09:14:35.263842Z","shell.execute_reply":"2022-06-26T09:14:35.278664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:38.914446Z","iopub.execute_input":"2022-06-26T09:14:38.91494Z","iopub.status.idle":"2022-06-26T09:14:38.994731Z","shell.execute_reply.started":"2022-06-26T09:14:38.914909Z","shell.execute_reply":"2022-06-26T09:14:38.993179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnext101_32x8d_wsl()\nmodel.fc = torch.nn.Linear(2048,n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:41.853699Z","iopub.execute_input":"2022-06-26T09:14:41.854089Z","iopub.status.idle":"2022-06-26T09:14:54.112153Z","shell.execute_reply.started":"2022-06-26T09:14:41.854058Z","shell.execute_reply":"2022-06-26T09:14:54.110683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = torch.nn.DataParallel(model)\ncheckpoint = torch.load('../input/models/png_model_e10_final.pt')\nmodel.load_state_dict(checkpoint['model'])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:15:03.390808Z","iopub.execute_input":"2022-06-26T09:15:03.391338Z","iopub.status.idle":"2022-06-26T09:15:16.985356Z","shell.execute_reply.started":"2022-06-26T09:15:03.391293Z","shell.execute_reply":"2022-06-26T09:15:16.98267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:15:21.046839Z","iopub.execute_input":"2022-06-26T09:15:21.047505Z","iopub.status.idle":"2022-06-26T09:15:21.080613Z","shell.execute_reply.started":"2022-06-26T09:15:21.047457Z","shell.execute_reply":"2022-06-26T09:15:21.079322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install grad-cam","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T09:15:28.493563Z","iopub.execute_input":"2022-06-26T09:15:28.493981Z","iopub.status.idle":"2022-06-26T09:16:09.353938Z","shell.execute_reply.started":"2022-06-26T09:15:28.493949Z","shell.execute_reply":"2022-06-26T09:16:09.352321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:16:58.819007Z","iopub.execute_input":"2022-06-26T09:16:58.8194Z","iopub.status.idle":"2022-06-26T09:16:58.826163Z","shell.execute_reply.started":"2022-06-26T09:16:58.819354Z","shell.execute_reply":"2022-06-26T09:16:58.824789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_layers = [model.module.layer4[-1]]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:17:06.083844Z","iopub.execute_input":"2022-06-26T09:17:06.084222Z","iopub.status.idle":"2022-06-26T09:17:06.090351Z","shell.execute_reply.started":"2022-06-26T09:17:06.084192Z","shell.execute_reply":"2022-06-26T09:17:06.088826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = cv2.imread(\"../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x/ID_ff7125125.png\")\nprint(img1.shape)\naug_img1 = transform_test(image=img1)\ntest_img = aug_img1['image'].unsqueeze(0)\nprint(test_img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:22:47.885479Z","iopub.execute_input":"2022-06-26T09:22:47.886353Z","iopub.status.idle":"2022-06-26T09:22:47.903618Z","shell.execute_reply.started":"2022-06-26T09:22:47.886209Z","shell.execute_reply":"2022-06-26T09:22:47.902157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torchcam\nfrom torchcam.methods import SmoothGradCAMpp, LayerCAM\nfrom torchcam.utils import overlay_mask","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:17:20.671117Z","iopub.execute_input":"2022-06-26T09:17:20.671536Z","iopub.status.idle":"2022-06-26T09:17:34.008075Z","shell.execute_reply.started":"2022-06-26T09:17:20.671503Z","shell.execute_reply":"2022-06-26T09:17:34.006679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = test_img.to(device, dtype=torch.float)\nprint(test_img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:22:52.614066Z","iopub.execute_input":"2022-06-26T09:22:52.614753Z","iopub.status.idle":"2022-06-26T09:22:52.624565Z","shell.execute_reply.started":"2022-06-26T09:22:52.614707Z","shell.execute_reply":"2022-06-26T09:22:52.623092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cam_extractor = SmoothGradCAMpp(model,target_layers)\nout = model(test_img)\ncams = cam_extractor(out.squeeze(0).argmax().item(), out)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:22:55.862213Z","iopub.execute_input":"2022-06-26T09:22:55.862706Z","iopub.status.idle":"2022-06-26T09:22:56.40057Z","shell.execute_reply.started":"2022-06-26T09:22:55.862659Z","shell.execute_reply":"2022-06-26T09:22:56.399202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision.transforms.functional import normalize, resize, to_pil_image","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:18:52.617507Z","iopub.execute_input":"2022-06-26T09:18:52.617993Z","iopub.status.idle":"2022-06-26T09:18:52.624426Z","shell.execute_reply.started":"2022-06-26T09:18:52.61796Z","shell.execute_reply":"2022-06-26T09:18:52.623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_img = test_img.to(device, dtype=torch.float)\nprint(test_img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:42.563803Z","iopub.execute_input":"2022-06-25T16:33:42.564718Z","iopub.status.idle":"2022-06-25T16:33:42.572758Z","shell.execute_reply.started":"2022-06-25T16:33:42.56468Z","shell.execute_reply":"2022-06-25T16:33:42.571548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for name, cam in zip(cam_extractor.target_names, cams):\n        result = overlay_mask(to_pil_image(test_img.squeeze(0)), to_pil_image(cam, mode='F'), alpha=0.5)\n        plt.imshow(result); plt.axis('off'); plt.title(name); plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:22:59.884106Z","iopub.execute_input":"2022-06-26T09:22:59.884517Z","iopub.status.idle":"2022-06-26T09:23:00.031932Z","shell.execute_reply.started":"2022-06-26T09:22:59.884484Z","shell.execute_reply":"2022-06-26T09:23:00.030345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#STOP HERE\n# Construct the CAM object once, and then re-use it on many images:\ncam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:44.921686Z","iopub.execute_input":"2022-06-25T16:33:44.922371Z","iopub.status.idle":"2022-06-25T16:33:44.929149Z","shell.execute_reply.started":"2022-06-25T16:33:44.92233Z","shell.execute_reply":"2022-06-25T16:33:44.927621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grayscale_cam = cam(input_tensor=test_input1, targets=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:47.700793Z","iopub.execute_input":"2022-06-25T16:33:47.701494Z","iopub.status.idle":"2022-06-25T16:33:48.861893Z","shell.execute_reply.started":"2022-06-25T16:33:47.701454Z","shell.execute_reply":"2022-06-25T16:33:48.860837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(img1))\nprint(type(np.array(grayscale_cam)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.imshow('CAM',grayscale_cam)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:34:46.99852Z","iopub.execute_input":"2022-06-25T16:34:46.999399Z","iopub.status.idle":"2022-06-25T16:34:47.016309Z","shell.execute_reply.started":"2022-06-25T16:34:46.999363Z","shell.execute_reply":"2022-06-25T16:34:47.01499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grayscale_cam_np = np.array(grayscale_cam)\ngrayscale_cam_np.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:52.417603Z","iopub.execute_input":"2022-06-25T16:33:52.417977Z","iopub.status.idle":"2022-06-25T16:33:52.425433Z","shell.execute_reply.started":"2022-06-25T16:33:52.41794Z","shell.execute_reply":"2022-06-25T16:33:52.424374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(grayscale_cam_np.reshape(200, 200, 1))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:55.578739Z","iopub.execute_input":"2022-06-25T16:33:55.579124Z","iopub.status.idle":"2022-06-25T16:33:55.778988Z","shell.execute_reply.started":"2022-06-25T16:33:55.579093Z","shell.execute_reply":"2022-06-25T16:33:55.777875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grayscale_cam","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall opencv-python-headless -y","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:29:32.367214Z","iopub.execute_input":"2022-06-25T16:29:32.367578Z","iopub.status.idle":"2022-06-25T16:29:34.000332Z","shell.execute_reply.started":"2022-06-25T16:29:32.367547Z","shell.execute_reply":"2022-06-25T16:29:33.999211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install opencv-python --upgrade\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:00.856698Z","iopub.execute_input":"2022-06-25T16:33:00.857096Z","iopub.status.idle":"2022-06-25T16:33:10.632465Z","shell.execute_reply.started":"2022-06-25T16:33:00.857062Z","shell.execute_reply":"2022-06-25T16:33:10.631309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:46:20.48511Z","iopub.execute_input":"2022-06-25T16:46:20.486126Z","iopub.status.idle":"2022-06-25T16:46:20.522991Z","shell.execute_reply.started":"2022-06-25T16:46:20.48609Z","shell.execute_reply":"2022-06-25T16:46:20.522055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam_np), cv2.COLOR_BG2RGB)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:48:33.723192Z","iopub.execute_input":"2022-06-25T16:48:33.724094Z","iopub.status.idle":"2022-06-25T16:48:33.74341Z","shell.execute_reply.started":"2022-06-25T16:48:33.724058Z","shell.execute_reply":"2022-06-25T16:48:33.741977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" if use_rgb:\n        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    heatmap = np.float32(heatmap) / 255\n\n    if np.max(img) > 1:\n        raise Exception(\n            \"The input image should np.float32 in the range [0, 1]\")\n\n    cam = heatmap + img\n    cam = cam / np.max(cam)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualization = show_cam_on_image(img1, grayscale_cam_np, use_rgb=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:34:06.323085Z","iopub.execute_input":"2022-06-25T16:34:06.323451Z","iopub.status.idle":"2022-06-25T16:34:06.357189Z","shell.execute_reply.started":"2022-06-25T16:34:06.323421Z","shell.execute_reply":"2022-06-25T16:34:06.355886Z"},"trusted":true},"execution_count":null,"outputs":[]}]}