{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Input the datasets\n\ndir_csv = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection'\ndir_train_img = '../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\ndir_test_img = '../input/rsna-test-stage-1-images-png-224x/stage_1_test_png_224x'\n\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:01:44.091754Z","iopub.execute_input":"2022-04-22T16:01:44.092084Z","iopub.status.idle":"2022-04-22T16:01:44.09649Z","shell.execute_reply.started":"2022-04-22T16:01:44.092027Z","shell.execute_reply":"2022-04-22T16:01:44.09562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Parameters\n\nn_classes = 6\nn_epochs = 50\nbatch_size = 64\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:06:18.58606Z","iopub.execute_input":"2022-04-22T16:06:18.586345Z","iopub.status.idle":"2022-04-22T16:06:18.591022Z","shell.execute_reply.started":"2022-04-22T16:06:18.586296Z","shell.execute_reply":"2022-04-22T16:06:18.590178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#from apex import amp\nimport os\nimport cv2\nimport glob\nimport pydicom\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.optim as optim\nfrom albumentations import Compose, ShiftScaleRotate, Resize, CenterCrop, HorizontalFlip, RandomBrightnessContrast\nfrom albumentations.pytorch import ToTensor\nfrom torch.utils.data import Dataset,Subset\nfrom tqdm import tqdm_notebook as tqdm\nfrom matplotlib import pyplot as plt\nfrom torchvision import transforms\nfrom sklearn.metrics import accuracy_score,jaccard_similarity_score,f1_score,recall_score","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:06:20.442501Z","iopub.execute_input":"2022-04-22T16:06:20.442804Z","iopub.status.idle":"2022-04-22T16:06:23.527669Z","shell.execute_reply.started":"2022-04-22T16:06:20.442753Z","shell.execute_reply":"2022-04-22T16:06:23.526764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Functions\n\nclass IntracranialDataset(Dataset):\n\n    def __init__(self, csv_file, path, labels, transform=None):\n        \n        self.path = path\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.labels = labels\n\n    def __len__(self):\n        \n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \n        img_name = os.path.join(self.path, self.data.loc[idx, 'Image'] + '.png')\n        img = cv2.imread(img_name)   \n        \n        if self.transform:       \n            \n            augmented = self.transform(image=img)\n            img = augmented['image']   \n            \n        if self.labels:\n            \n            labels = torch.tensor(\n                self.data.loc[idx, ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']])\n            return {'image': img, 'labels': labels}    \n        \n        else:      \n            \n            return {'image': img}\n    \n    \n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:06:23.529593Z","iopub.execute_input":"2022-04-22T16:06:23.52996Z","iopub.status.idle":"2022-04-22T16:06:23.540701Z","shell.execute_reply.started":"2022-04-22T16:06:23.529898Z","shell.execute_reply":"2022-04-22T16:06:23.539879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tmp = os.path.join(dir_csv, 'stage_2_train.csv')\nos.path.exists(train_tmp)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CSV","metadata":{}},{"cell_type":"code","source":"# CSVs\n\ntrain = pd.read_csv(os.path.join(dir_csv, 'stage_2_train.csv'))\ntest = pd.read_csv(os.path.join(dir_csv, 'stage_2_sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:06:24.680299Z","iopub.execute_input":"2022-04-22T16:06:24.68063Z","iopub.status.idle":"2022-04-22T16:06:29.944134Z","shell.execute_reply.started":"2022-04-22T16:06:24.680576Z","shell.execute_reply":"2022-04-22T16:06:29.943346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Split train out into row per image and save a sample\n\ntrain[['ID', 'Image', 'Diagnosis']] = train['ID'].str.split('_', expand=True)\ntrain = train[['Image', 'Diagnosis', 'Label']]\ntrain.drop_duplicates(inplace=True)\ntrain = train.pivot(index='Image', columns='Diagnosis', values='Label').reset_index()\ntrain['Image'] = 'ID_' + train['Image']\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:06:29.94605Z","iopub.execute_input":"2022-04-22T16:06:29.946319Z","iopub.status.idle":"2022-04-22T16:07:01.217267Z","shell.execute_reply.started":"2022-04-22T16:06:29.946275Z","shell.execute_reply":"2022-04-22T16:07:01.216563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Some files didn't contain legitimate images, so we need to remove them\n\npng = glob.glob(os.path.join(dir_train_img, '*.png'))\npng = [os.path.basename(png)[:-4] for png in png]\npng = np.array(png)\n\ntrain = train[train['Image'].isin(png)]\ntrain.to_csv('train.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:07:01.218724Z","iopub.execute_input":"2022-04-22T16:07:01.219025Z","iopub.status.idle":"2022-04-22T16:07:24.070448Z","shell.execute_reply.started":"2022-04-22T16:07:01.21896Z","shell.execute_reply":"2022-04-22T16:07:24.069521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['ID','Image','Diagnosis']] = test['ID'].str.split('_', expand=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:07:24.073134Z","iopub.execute_input":"2022-04-22T16:07:24.073477Z","iopub.status.idle":"2022-04-22T16:07:27.219975Z","shell.execute_reply.started":"2022-04-22T16:07:24.073409Z","shell.execute_reply":"2022-04-22T16:07:27.219045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Image'] = 'ID_' + test['Image']","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:07:27.221617Z","iopub.execute_input":"2022-04-22T16:07:27.221888Z","iopub.status.idle":"2022-04-22T16:07:27.422385Z","shell.execute_reply.started":"2022-04-22T16:07:27.221844Z","shell.execute_reply":"2022-04-22T16:07:27.421604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['Image', 'Label']]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:07:27.423826Z","iopub.execute_input":"2022-04-22T16:07:27.424129Z","iopub.status.idle":"2022-04-22T16:07:27.794631Z","shell.execute_reply.started":"2022-04-22T16:07:27.424081Z","shell.execute_reply":"2022-04-22T16:07:27.793861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.drop_duplicates(inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:07:27.79657Z","iopub.execute_input":"2022-04-22T16:07:27.797033Z","iopub.status.idle":"2022-04-22T16:07:27.964199Z","shell.execute_reply.started":"2022-04-22T16:07:27.796853Z","shell.execute_reply":"2022-04-22T16:07:27.963484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.to_csv('test.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:07:27.965584Z","iopub.execute_input":"2022-04-22T16:07:27.96587Z","iopub.status.idle":"2022-04-22T16:07:28.33834Z","shell.execute_reply.started":"2022-04-22T16:07:27.965824Z","shell.execute_reply":"2022-04-22T16:07:28.337368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:08:20.032045Z","iopub.execute_input":"2022-04-22T16:08:20.032345Z","iopub.status.idle":"2022-04-22T16:08:20.04875Z","shell.execute_reply.started":"2022-04-22T16:08:20.032295Z","shell.execute_reply":"2022-04-22T16:08:20.047662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data loaders\n\ntransform_train = Compose([CenterCrop(200, 200),\n                           #Resize(224, 224),\n                           HorizontalFlip(),\n                           RandomBrightnessContrast(),\n    ShiftScaleRotate(),\n    ToTensor()\n])\n\ntransform_test= Compose([CenterCrop(200, 200),\n                         #Resize(224, 224),\n    ToTensor()\n])\n\ntrain_dataset = IntracranialDataset(\n    csv_file='train.csv', path=dir_train_img, transform=transform_train, labels=True)\n\ntrain_dataset=torch.utils.data.Subset(train_dataset, range(0,25000))\n\ntest_dataset = IntracranialDataset(\n    csv_file='test.csv', path=dir_test_img, transform=transform_test, labels=False)\n\ntest_dataset=torch.utils.data.Subset(test_dataset, range(0,2000))\n\n#newtest_dataset=torch.utils.data.Subset(train_dataset,range(25000,27000))\n\ndata_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n\ndata_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n                                        \n#data_loader_newtest = torch.utils.data.DataLoader(newtest_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:10:38.418253Z","iopub.execute_input":"2022-04-22T16:10:38.418561Z","iopub.status.idle":"2022-04-22T16:10:38.997077Z","shell.execute_reply.started":"2022-04-22T16:10:38.418508Z","shell.execute_reply":"2022-04-22T16:10:38.996214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoaders","metadata":{}},{"cell_type":"code","source":"newtest_dataset = IntracranialDataset(\n    csv_file='train.csv', path=dir_train_img, transform=transform_train, labels=True)\nnewtest_dataset=torch.utils.data.Subset(newtest_dataset,range(25000,27000))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:10:42.078523Z","iopub.execute_input":"2022-04-22T16:10:42.078829Z","iopub.status.idle":"2022-04-22T16:10:42.557323Z","shell.execute_reply.started":"2022-04-22T16:10:42.078781Z","shell.execute_reply":"2022-04-22T16:10:42.556539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loader_newtest = torch.utils.data.DataLoader(newtest_dataset, batch_size=batch_size, shuffle=False, num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:10:44.02542Z","iopub.execute_input":"2022-04-22T16:10:44.026024Z","iopub.status.idle":"2022-04-22T16:10:44.03274Z","shell.execute_reply.started":"2022-04-22T16:10:44.025795Z","shell.execute_reply":"2022-04-22T16:10:44.032021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"device = torch.device(\"cuda:0\")\nfrom torchvision.models.resnet import ResNet, Bottleneck","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:10:46.601342Z","iopub.execute_input":"2022-04-22T16:10:46.601668Z","iopub.status.idle":"2022-04-22T16:10:46.605925Z","shell.execute_reply.started":"2022-04-22T16:10:46.601616Z","shell.execute_reply":"2022-04-22T16:10:46.605046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.hub import load_state_dict_from_url\nfrom torchvision.models.resnet import ResNet, Bottleneck\n\n\nmodel_urls = {\n    'resnext101_32x8d': 'https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth',\n    'resnext101_32x16d': 'https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth',\n    'resnext101_32x32d': 'https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth',\n    'resnext101_32x48d': 'https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth',\n}\n\n\ndef _resnext(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    #print('a')\n    state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n   # print('b')\n    model.load_state_dict(state_dict)\n    #print('c')\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:10:49.042283Z","iopub.execute_input":"2022-04-22T16:10:49.042983Z","iopub.status.idle":"2022-04-22T16:10:49.055269Z","shell.execute_reply.started":"2022-04-22T16:10:49.042911Z","shell.execute_reply":"2022-04-22T16:10:49.054311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resnext101_32x8d_wsl(progress=True, **kwargs):\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 8\n    return _resnext('resnext101_32x8d', Bottleneck, [3, 4, 23, 3], True, progress, **kwargs)\n","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:10:52.384655Z","iopub.execute_input":"2022-04-22T16:10:52.385036Z","iopub.status.idle":"2022-04-22T16:10:52.39054Z","shell.execute_reply.started":"2022-04-22T16:10:52.384906Z","shell.execute_reply":"2022-04-22T16:10:52.389472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnext101_32x8d_wsl()","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:10:54.515069Z","iopub.execute_input":"2022-04-22T16:10:54.515354Z","iopub.status.idle":"2022-04-22T16:11:09.119247Z","shell.execute_reply.started":"2022-04-22T16:10:54.515304Z","shell.execute_reply":"2022-04-22T16:11:09.118332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Model\n\n#device = torch.device(\"cuda:0\")\n#model = torch.hub.load('facebookresearch/WSL-Images', 'resnext101_32x8d_wsl')\nmodel.fc = torch.nn.Linear(2048, n_classes)\n\nmodel.to(device)\n\ncriterion = torch.nn.BCEWithLogitsLoss()\nplist = [{'params': model.parameters(), 'lr': 2e-5}]\noptimizer = optim.Adam(plist, lr=2e-5)\n\n#model, optimizer = amp.initialize(model, optimizer, opt_level=\"O1\")\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-22T16:11:13.252221Z","iopub.execute_input":"2022-04-22T16:11:13.252547Z","iopub.status.idle":"2022-04-22T16:11:18.127259Z","shell.execute_reply.started":"2022-04-22T16:11:13.252492Z","shell.execute_reply":"2022-04-22T16:11:18.126517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_state_dict(torch.load('../input/params/save.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:11:20.446892Z","iopub.execute_input":"2022-04-22T16:11:20.449742Z","iopub.status.idle":"2022-04-22T16:11:23.433149Z","shell.execute_reply.started":"2022-04-22T16:11:20.449685Z","shell.execute_reply":"2022-04-22T16:11:23.43245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"# Train\n\n\n#for epoch in range(n_epochs):\n    \n#    print('Epoch {}/{}'.format(epoch, n_epochs - 1))\n#    print('-' * 10)\n\n #   model.train()    \n  #  tr_loss = 0\n    \n  #  tk0 = tqdm(data_loader_train, desc=\"Iteration\")\n\n  #  for step, batch in enumerate(tk0):\n\n   #     inputs = batch[\"image\"]\n    #    labels = batch[\"labels\"]\n\n     #   inputs = inputs.to(device, dtype=torch.float)\n     #   labels = labels.to(device, dtype=torch.float)\n\n     #   outputs = model(inputs)\n     #  loss = criterion(outputs, labels)\n\n       # with amp.scale_loss(loss, optimizer) as scaled_loss:\n            #scaled_loss.backward()\n      #  loss.backward()\n      #  tr_loss += loss.item()\n\n       # optimizer.step()\n       # optimizer.zero_grad()\n        \n      #  if epoch == 1 and step > 6000:\n          #  epoch_loss = tr_loss / 6000\n          #  print('Training Loss: {:.4f}'.format(epoch_loss))\n           # break\n\n    #epoch_loss = tr_loss / len(data_loader_train)\n    #print('Training Loss: {:.4f}'.format(epoch_loss))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"#boi working final\nfor param in model.parameters():\n    param.requires_grad = False\njacc=[]\nacc=[]\nf1=[]\nmodel.eval()\nnew = []\ntest_pred = np.zeros((len(newtest_dataset) * n_classes, 1))\nfor i, x_batch in enumerate(tqdm(data_loader_newtest)):\n    \n    x_image = x_batch[\"image\"]\n    x_image = x_image.to(device, dtype=torch.float)\n    x_label = x_batch[\"labels\"]\n    x_label  = x_label.to(device,dtype=torch.float)\n    with torch.no_grad():\n        \n        pred = model(x_image)\n        #print(pred)\n        #print(pred.size())\n        #break\n        test_pred[(i * batch_size * n_classes):((i + 1) * batch_size * n_classes)] = torch.sigmoid(\n            pred).detach().cpu().reshape((len(x_image) * n_classes, 1))\n        new.append(torch.sigmoid(pred).detach().cpu())\n        new1=torch.sigmoid(pred).detach().cpu()>=0.5\n        #print(new1,x_label)\n        #ans = (new1.float()==x_label.cpu())\n        jacc.append(jaccard_similarity_score(new1.float(),x_label.cpu()))\n        acc.append(accuracy_score(new1.float(),x_label.cpu()))\n        #print(accuracy_score(new1.float(),x_label.cpu()))\n        f1.append(f1_score(new1.float(),x_label.cpu(),average='micro'))\n        #print(f1_score(new1.float(),x_label.cpu(),average='micro'))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:49:35.471473Z","iopub.execute_input":"2022-04-22T16:49:35.471781Z","iopub.status.idle":"2022-04-22T16:49:50.138986Z","shell.execute_reply.started":"2022-04-22T16:49:35.47173Z","shell.execute_reply":"2022-04-22T16:49:50.138097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jacc","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:49:54.202829Z","iopub.execute_input":"2022-04-22T16:49:54.203161Z","iopub.status.idle":"2022-04-22T16:49:54.210676Z","shell.execute_reply.started":"2022-04-22T16:49:54.203107Z","shell.execute_reply":"2022-04-22T16:49:54.209722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ans= sum(acc)/len(acc)\nans","metadata":{"execution":{"iopub.status.busy":"2022-04-22T16:51:04.140254Z","iopub.execute_input":"2022-04-22T16:51:04.140648Z","iopub.status.idle":"2022-04-22T16:51:04.148585Z","shell.execute_reply.started":"2022-04-22T16:51:04.140593Z","shell.execute_reply":"2022-04-22T16:51:04.147799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"JC final = 91.36\nACC final= 89.11","metadata":{},"execution_count":null,"outputs":[]}]}