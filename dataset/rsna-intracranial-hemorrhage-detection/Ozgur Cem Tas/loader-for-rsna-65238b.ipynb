{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pydicom\nimport os\nimport matplotlib.pyplot as plt\nimport collections\nfrom tqdm import tqdm_notebook as tqdm\nfrom datetime import datetime\n\nfrom math import ceil, floor, log\nimport cv2\n\nimport tensorflow as tf\nimport keras\nimport cupy as cp\nimport sys\n\n# from keras_applications.resnet import ResNet50\nfrom keras.applications import *\nfrom keras.layers import *\nfrom sklearn.model_selection import ShuffleSplit\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\nimport pathlib\nfrom tensorflow import keras\nfrom PIL import Image\nimport pandas as pd\nfrom glob import glob\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.applications import *\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.xception import Xception\nfrom keras.applications import DenseNet121, ResNet50V2, InceptionV3\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils import plot_model\nfrom keras.callbacks import TensorBoard\n#from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n#from sklearn.model_selection import train_test_split\n#from tqdm import tqdm\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.utils import Sequence\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nif 'checkpoint' not in os.listdir('./'):\n    os.mkdir('./checkpoint')\n\ninput_path = \"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/\"\ntest_images_dir = input_path + 'stage_2_test/'\ntrain_images_dir = input_path + 'stage_2_train/'","metadata":{"execution":{"iopub.status.busy":"2021-05-24T09:45:43.414684Z","iopub.execute_input":"2021-05-24T09:45:43.415061Z","iopub.status.idle":"2021-05-24T09:45:43.429004Z","shell.execute_reply.started":"2021-05-24T09:45:43.415022Z","shell.execute_reply":"2021-05-24T09:45:43.428166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/ID_000012eaf.dcm'\nimg = pydicom.dcmread(path)\nimg","metadata":{"execution":{"iopub.status.busy":"2021-05-23T06:41:07.749153Z","iopub.execute_input":"2021-05-23T06:41:07.749818Z","iopub.status.idle":"2021-05-23T06:41:07.786377Z","shell.execute_reply.started":"2021-05-23T06:41:07.749778Z","shell.execute_reply":"2021-05-23T06:41:07.785574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correct_dcm(dcm):\n    x = dcm.pixel_array + 1000\n    px_mode = 4096\n    x[x>=px_mode] = x[x>=px_mode] - px_mode\n    dcm.PixelData = x.tobytes()\n    dcm.RescaleIntercept = -1000\n\ndef window_image(dcm, window_center, window_width):\n    \n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    \n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n\n    return img\n\ndef bsb_window(dcm):\n    brain_img = window_image(dcm, 40, 80)\n    subdural_img = window_image(dcm, 80, 200)\n    soft_img = window_image(dcm, 40, 380)\n    \n    brain_img = (brain_img - 0) / 80\n    subdural_img = (subdural_img - (-20)) / 200\n    soft_img = (soft_img - (-150)) / 380\n    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n\n    return bsb_img\n\n# Sanity Check\n# Example dicoms: ID_2669954a7, ID_5c8b5d701, ID_52c9913b1\n\ndicom = pydicom.dcmread(train_images_dir + 'ID_5c8b5d701' + '.dcm')\n \n# 4045571               ID_5c8b5d701_any      1\nplt.imshow(bsb_window(dicom), cmap=plt.cm.bone);\n","metadata":{"execution":{"iopub.status.busy":"2021-05-23T06:41:07.788026Z","iopub.execute_input":"2021-05-23T06:41:07.788467Z","iopub.status.idle":"2021-05-23T06:41:08.035161Z","shell.execute_reply.started":"2021-05-23T06:41:07.788405Z","shell.execute_reply":"2021-05-23T06:41:08.034076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def window_with_correction(dcm, window_center, window_width):\n    if (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100):\n        correct_dcm(dcm)\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef window_without_correction(dcm, window_center, window_width):\n    img = dcm.pixel_array * dcm.RescaleSlope + dcm.RescaleIntercept\n    img_min = window_center - window_width // 2\n    img_max = window_center + window_width // 2\n    img = np.clip(img, img_min, img_max)\n    return img\n\ndef window_testing(img, window):\n    brain_img = window(img, 40, 80)\n    subdural_img = window(img, 80, 200)\n    soft_img = window(img, 40, 380)\n    \n    brain_img = (brain_img - 0) / 80\n    subdural_img = (subdural_img - (-20)) / 200\n    soft_img = (soft_img - (-150)) / 380\n    bsb_img = np.array([brain_img, subdural_img, soft_img]).transpose(1,2,0)\n\n    return bsb_img\n\n# example of a \"bad data point\" (i.e. (dcm.BitsStored == 12) and (dcm.PixelRepresentation == 0) and (int(dcm.RescaleIntercept) > -100) == True)\ndicom = pydicom.dcmread(train_images_dir + \"ID_036db39b7\" + \".dcm\")\n\nfig, ax = plt.subplots(1, 2)\n\nax[0].imshow(window_testing(dicom, window_without_correction), cmap=plt.cm.bone);\nax[0].set_title(\"original\")\nax[1].imshow(window_testing(dicom, window_with_correction), cmap=plt.cm.bone);\nax[1].set_title(\"corrected\");","metadata":{"execution":{"iopub.status.busy":"2021-05-23T06:41:08.036665Z","iopub.execute_input":"2021-05-23T06:41:08.037067Z","iopub.status.idle":"2021-05-23T06:41:08.393536Z","shell.execute_reply.started":"2021-05-23T06:41:08.037024Z","shell.execute_reply":"2021-05-23T06:41:08.392286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/rsna-csv-files/RSNA_DATA/DATA.csv')","metadata":{"execution":{"iopub.status.busy":"2021-05-24T09:46:58.43666Z","iopub.execute_input":"2021-05-24T09:46:58.437091Z","iopub.status.idle":"2021-05-24T09:47:00.750476Z","shell.execute_reply.started":"2021-05-24T09:46:58.437041Z","shell.execute_reply":"2021-05-24T09:47:00.749665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import trange\ndef get_partition_labels(df):\n    partition = dict()\n    labels = dict()\n    for i in trange(len(df)):\n        id_ = df.Image[i]\n        label = df.iloc[i,1:7].to_numpy(dtype = 'int32')\n        labels[id_] = label\n        \n    df = df.sample(frac = 0.1)\n    training = df.sample(frac = 0.7)\n    \n    validation = df.drop(training.index, axis = 0)\n    test = validation.sample(frac = 0.5)\n    validation = validation.drop(test.index, axis = 0) \n    \n    partition['train'] = list(training.Image)\n    partition['validation'] = list(validation.Image)\n    partition['test'] = list(test.Image)\n    return partition,labels","metadata":{"execution":{"iopub.status.busy":"2021-05-24T09:47:11.53749Z","iopub.execute_input":"2021-05-24T09:47:11.537801Z","iopub.status.idle":"2021-05-24T09:47:11.544369Z","shell.execute_reply.started":"2021-05-24T09:47:11.537771Z","shell.execute_reply":"2021-05-24T09:47:11.543386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"partition,labels = get_partition_labels(df)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T09:47:18.67499Z","iopub.execute_input":"2021-05-24T09:47:18.675301Z","iopub.status.idle":"2021-05-24T09:49:58.913046Z","shell.execute_reply.started":"2021-05-24T09:47:18.675271Z","shell.execute_reply":"2021-05-24T09:49:58.912254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(partition['train']))\nvalues_view = labels.values()\nvalue_iterator = iter(values_view)\nfirst_value = next(value_iterator)\nprint(next(iter(labels)))\nprint(first_value)\n\n\nvalues_view2 = partition.values()\nvalue_iterator2 = iter(values_view)\nfirst_value2 = next(value_iterator)\nprint(next(iter(partition['train'])))\nprint(first_value2)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T09:49:58.916531Z","iopub.execute_input":"2021-05-24T09:49:58.916792Z","iopub.status.idle":"2021-05-24T09:49:58.925344Z","shell.execute_reply.started":"2021-05-24T09:49:58.916767Z","shell.execute_reply":"2021-05-24T09:49:58.92419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def _read(path, desired_size):\n    \"\"\"Will be used in DataGenerator\"\"\"\n    \n    dcm = pydicom.dcmread(path)\n    \n    try:\n        img = bsb_window(dcm)\n    except:\n        img = np.zeros(desired_size)\n    \n    \n    img = cv2.resize(img, desired_size[:2], interpolation=cv2.INTER_LINEAR)\n    return img\n\n# Another sanity check \nplt.imshow(\n    _read(train_images_dir+'ID_5c8b5d701'+'.dcm', (256, 256,3)), cmap=plt.cm.bone\n);","metadata":{"execution":{"iopub.status.busy":"2021-05-23T06:44:01.755606Z","iopub.execute_input":"2021-05-23T06:44:01.757877Z","iopub.status.idle":"2021-05-23T06:44:01.978104Z","shell.execute_reply.started":"2021-05-23T06:44:01.757831Z","shell.execute_reply":"2021-05-23T06:44:01.977355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type(_read(train_images_dir+'ID_5c8b5d701'+'.dcm', (256, 256,3)))","metadata":{"execution":{"iopub.status.busy":"2021-05-23T06:44:01.981269Z","iopub.execute_input":"2021-05-23T06:44:01.981522Z","iopub.status.idle":"2021-05-23T06:44:01.999525Z","shell.execute_reply.started":"2021-05-23T06:44:01.981496Z","shell.execute_reply":"2021-05-23T06:44:01.998595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport keras\n\nclass DataGenerator(keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, list_IDs, labels, batch_size=64, dim=(32,32,32), n_channels=1,\n                 n_classes=10, shuffle=True):\n        'Initialization'\n        self.dim = dim\n        self.batch_size = batch_size\n        self.labels = labels\n        self.list_IDs = list_IDs\n        self.n_channels = n_channels\n        self.n_classes = n_classes\n        self.shuffle = shuffle\n        self.true_labels = []\n        self.on_epoch_end()\n\n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        return int(np.floor(len(self.list_IDs) / self.batch_size))\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        # Generate indexes of the batch\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n\n        # Find list of IDs\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n\n        # Generate data\n        X, y = self.__data_generation(list_IDs_temp)\n        \n        self.true_labels.append(y)\n\n        return X, y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange(len(self.list_IDs))\n        if self.shuffle == True:\n            np.random.shuffle(self.indexes)\n\n    def __data_generation(self, list_IDs_temp):\n        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n        # Initialization\n        X = np.empty((self.batch_size, *self.dim)) #,self.n_channels))\n        \n        y = np.empty((self.batch_size,6), dtype=int)\n        #print(y.shape)\n        #print(X.shape)\n\n        # Generate data\n        for i, ID in enumerate(list_IDs_temp):\n            # Store sample\n            image_dir = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/'\n            X[i,] = _read(image_dir+ID+'.dcm',self.dim)\n            #print(X)\n            # Store class\n            \n            y[i] = self.labels[ID]\n            #print(y[i])\n\n        return X,y","metadata":{"execution":{"iopub.status.busy":"2021-05-23T06:44:02.001415Z","iopub.execute_input":"2021-05-23T06:44:02.002018Z","iopub.status.idle":"2021-05-23T06:44:02.015852Z","shell.execute_reply.started":"2021-05-23T06:44:02.001969Z","shell.execute_reply":"2021-05-23T06:44:02.014897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"params = {'dim':(224,224,3),\n         'batch_size':64,\n         'n_classes':6,\n         'n_channels':0,\n         'shuffle':True}\n\nmy_callbacks = [\n    ModelCheckpoint(filepath='./checkpoint', monitor = 'val_weighted_loss' ,save_best_only=True,verbose = 3),\n    ReduceLROnPlateau(monitor= 'val_weighted_loss', factor=0.1, patience= 3, verbose=1,mode='auto', min_delta=0.0001)]\n\n# Generators\ntraining_generator = DataGenerator(partition['train'], labels, **params)\nvalidation_generator = DataGenerator(partition['validation'], labels, **params)\n\n# Design model\nmodel = Sequential([\n    tf.keras.applications.ResNet152V2(\n    include_top=False,\n    weights=\"imagenet\",\n    input_shape=params['dim'],\n    pooling='max'),\n    Flatten(),\n    Dense(30,activation = 'relu'),\n    Dense(6,activation = 'sigmoid') \n])\n\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=[keras.metrics.BinaryAccuracy()])\n#model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['ACC'])\n\n# Train model on dataset\nhistory = model.fit(training_generator,validation_data=validation_generator, workers = 4, use_multiprocessing= True, epochs=20, callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T10:17:49.385394Z","iopub.execute_input":"2021-05-24T10:17:49.385741Z","iopub.status.idle":"2021-05-24T10:18:14.905561Z","shell.execute_reply.started":"2021-05-24T10:17:49.38571Z","shell.execute_reply":"2021-05-24T10:18:14.902605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_history(history, desc = ''):\n    fig = plt.figure(figsize = (18 , 6))\n    if desc:\n        plt.title('{}'.format(desc), fontsize = 16, y = -0.1)\n\n    subplot = (1, 2, 1)\n    fig.add_subplot(*subplot)\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['train loss', 'valid loss'])\n    plt.grid(True)\n    plt.plot()\n    \n    subplot = (1, 2, 2)\n    fig.add_subplot(*subplot)\n    plt.plot(history.history['binary_accuracy'])\n    plt.plot(history.history['val_binary_accuracy'])\n    plt.title('model accuracy')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.legend(['train accuracy', 'valid accuracy'])\n    plt.grid(True)\n    plt.plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_history(history)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\ndef weighted_log_loss(y_true, y_pred):\n    \"\"\"\n    Can be used as the loss function in model.compile()\n    ---------------------------------------------------\n    \"\"\"\n    \n    class_weights =  tf.Variable([2., 1., 1., 1., 1., 1.])\n    \n    eps = K.epsilon()\n    \n    y_pred = K.clip(y_pred, eps, 1.0-eps)\n\n    out = -(         y_true  * K.log(      y_pred) * class_weights\n            + (1.0 - y_true) * K.log(1.0 - y_pred) * class_weights)\n    \n    return K.mean(out, axis=-1)\n####\ndef weighted_log_loss_V2(y_true, y_pred):\n    \"\"\"\n    Can be used as the loss function in model.compile()\n    ---------------------------------------------------\n    \"\"\"\n    \n    class_weights =  tf.constant([2., 1., 1., 1., 1., 1.])\n    \n    eps = tf.keras.backend.epsilon()\n    \n    \n    y_pred = tf.clip_by_value(y_pred, eps, 1.0-eps)\n\n    out = -(         y_true  * tf.math.log(      y_pred) * class_weights\n            + (1.0 - y_true) * tf.math.log(1.0 - y_pred) * class_weights)\n    \n    return tf.reduce_mean(out, axis=-1)\n####\n\ndef _normalized_weighted_average(arr, weights=None):\n    \"\"\"\n    A simple Keras implementation that mimics that of \n    numpy.average(), specifically for this competition\n    \"\"\"\n    \n    if weights is not None:\n        scl = K.sum(weights)\n        weights = K.expand_dims(weights, axis=1)\n        return K.sum(K.dot(arr, weights), axis=1) / scl\n    return K.mean(arr, axis=1)\n\n\ndef weighted_loss(y_true, y_pred):\n    \"\"\"\n    Will be used as the metric in model.compile()\n    ---------------------------------------------\n    \n    Similar to the custom loss function 'weighted_log_loss()' above\n    but with normalized weights, which should be very similar \n    to the official competition metric:\n        https://www.kaggle.com/kambarakun/lb-probe-weights-n-of-positives-scoring\n    and hence:\n        sklearn.metrics.log_loss with sample weights\n    \"\"\"\n    \n    class_weights = tf.constant([2., 1., 1., 1., 1., 1.])\n    \n    eps = tf.keras.backend.epsilon()\n    \n    y_pred = tf.clip_by_value(y_pred, eps, 1.0-eps)\n\n    loss = -(        y_true  * tf.math.log(      y_pred)\n            + (1.0 - y_true) * tf.math.log(1.0 - y_pred))\n    \n    loss_samples = _normalized_weighted_average(loss, class_weights)\n    \n    return tf.reduce_mean(loss_samples)\n\n\ndef weighted_log_loss_metric(trues, preds):\n    \"\"\"\n    Will be used to calculate the log loss \n    of the validation set in PredictionCheckpoint()\n    ------------------------------------------\n    \"\"\"\n    class_weights = [2., 1., 1., 1., 1., 1.]\n    \n    epsilon = 1e-7\n    \n    preds = np.clip(preds, epsilon, 1-epsilon)\n    loss = trues * np.log(preds) + (1 - trues) * np.log(1 - preds)\n    loss_samples = np.average(loss, axis=1, weights=class_weights)\n\n    return - loss_samples.mean()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluation\nparams_test = {'dim':(224,224,3),\n         'batch_size':1,\n         'n_classes':6,\n         'n_channels':0,\n         'shuffle':False}\n\ntest_generator = DataGenerator(partition['test'], labels, **params_test)\ntest_pred = model.predict(test_generator,verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import multilabel_confusion_matrix, classification_report\n\nprint(len(partition['test']))\nprediction_with_treshold = []\n\ntreshold = 0.1\n\nfor sample in test_pred:\n    prediction_with_treshold.append([1 if i>=treshold else 0 for i in sample ] )\nprediction_with_treshold = np.array(prediction_with_treshold)\nprint(len(prediction_with_treshold))\n\nprint(type(test_generator.true_labels[10]))\ntotal_list = np.concatenate(test_generator.true_labels)\ntotal_list = total_list[:-1, :]\nprint(len(total_list))\n\naccuracy_score(total_list, prediction_with_treshold)\nprint(multilabel_confusion_matrix(total_list, prediction_with_treshold))\nprint(classification_report(total_list, prediction_with_treshold, target_names = ['Any', 'Epidural', 'Intraparenychemal','Intraventricular','Subarachnoid','Subdural']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import average_precision_score\n\naverage_precision_score(total_list, test_pred, average='micro', pos_label=1, sample_weight=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import multilabel_confusion_matrix, classification_report\n\naccuracy_score(total_list, prediction_with_treshold)\nprint(multilabel_confusion_matrix(total_list, prediction_with_treshold))\nprint(classification_report(total_list, prediction_with_treshold, target_names = ['Any', 'Epidural', 'Intraparenychemal','Intraventricular','Subarachnoid','Subdural']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"test_generator.true_labels\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_img_array(img_path, size):\n    # `img` is a PIL image of size 299x299\n    img = keras.preprocessing.image.load_img(img_path, target_size=size)\n    # `array` is a float32 Numpy array of shape (299, 299, 3)\n    array = keras.preprocessing.image.img_to_array(img)\n    # We add a dimension to transform our array into a \"batch\"\n    # of size (1, 299, 299, 3)\n    array = np.expand_dims(array, axis=0)\n    return array\n\n\ndef make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n    # First, we create a model that maps the input image to the activations\n    # of the last conv layer as well as the output predictions\n    grad_model = tf.keras.models.Model(\n        [model.inputs], [model.get_layer(last_conv_layer_name).output, model.output]\n    )\n\n    # Then, we compute the gradient of the top predicted class for our input image\n    # with respect to the activations of the last conv layer\n    with tf.GradientTape() as tape:\n        last_conv_layer_output, preds = grad_model(img_array)\n        if pred_index is None:\n            pred_index = tf.argmax(preds[0])\n        class_channel = preds[:, pred_index]\n\n    # This is the gradient of the output neuron (top predicted or chosen)\n    # with regard to the output feature map of the last conv layer\n    grads = tape.gradient(class_channel, last_conv_layer_output)\n\n    # This is a vector where each entry is the mean intensity of the gradient\n    # over a specific feature map channel\n    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n\n    # We multiply each channel in the feature map array\n    # by \"how important this channel is\" with regard to the top predicted class\n    # then sum all the channels to obtain the heatmap class activation\n    last_conv_layer_output = last_conv_layer_output[0]\n    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n    heatmap = tf.squeeze(heatmap)\n\n    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n    return heatmap.numpy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"array1 = _read(train_images_dir+\"ID_29c9c2ee8\"+'.dcm',(224, 224,3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"last_conv_layer_name = \"conv5 x\"\n\n# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(array1, model, last_conv_layer_name)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subdural_img = 'ID_29c9c2ee8.dcm'\t\nintraventricular_img = 'ID_004780f8e.dcm'\nintraparenchymal_img = 'ID_000d69988.dcm'\nsubarachnoid_img = 'ID_00058bb06.dcm'\nepidural_img = 'ID_00f1e66e1.dcm'\nepidural_img2 = 'ID_ff0afaa64.dcm'\nsubdural_img2 = 'ID_47f130bfa.dcm'\t\nsubarachnoid_img2 = 'ID_526b45786.dcm'\n\ntype_list = [subdural_img, intraventricular_img, intraparenchymal_img, subarachnoid_img, epidural_img2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_id = subarachnoid_img2\nimg = hem_df.loc[hem_df.index == img_id].index[0]\nimage = _read(train_images_dir + img,(224, 224))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(img_array)\nprint(\"Predicted:\", decode_predictions(preds, top=1)[0])\n\n# Generate class activation heatmap\nheatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n\n# Display heatmap\nplt.matshow(heatmap)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#SUBMITTER UNIT\n\ntest_csv = \"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_sample_submission.csv\"\ntest_dir = \"../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_test\"\nTEST_DIR = \"stage_2_test/\"\ntest_df = pd.read_csv(test_csv)\ntest_df.head()\n\ntestdf = test_df.ID.str.rsplit(\"_\", n=1, expand=True)\ntestdf = testdf.rename({0: \"id\", 1: \"subtype\"}, axis=1)\ntestdf.loc[:, \"label\"] = 0\n\ntestdf = pd.pivot_table(testdf, index=\"id\", columns=\"subtype\", values=\"label\")\n\ndef preprocess(file,type=\"WINDOW\",DIR=test_images_dir):\n    dcm = pydicom.dcmread(test_images_dir+file+\".dcm\")\n    if type == \"WINDOW\":\n        window_center , window_width, intercept, slope = get_windowing(dcm)\n        w = window_image(dcm, window_center, window_width)\n        win_img = np.repeat(w[:, :, np.newaxis], 3, axis=2)\n        #return win_img\n    elif type == \"SIGMOID\":\n        window_center , window_width, intercept, slope = get_windowing(dcm)\n        test_img = dcm.pixel_array\n        w = sigmoid_window(dcm, window_center, window_width)\n        win_img = np.repeat(w[:, :, np.newaxis], 3, axis=2)\n        #return win_img\n    elif type == \"BSB\":\n        win_img = bsb_window(dcm)\n        #return win_img\n    elif type == \"SIGMOID_BSB\":\n        win_img = sigmoid_bsb_window(dcm)\n    elif type == \"GRADIENT\":\n        win_img = rainbow_window(dcm)\n        #return win_img\n    else:\n        win_img = dcm.pixel_array\n    resized = cv2.resize(win_img,(224,224))\n    return resized\n\nclass DataLoader(Sequence):\n    def __init__(self, dataframe,\n                 batch_size,\n                 shuffle,\n                 input_shape,\n                 num_classes=6,\n                 steps=None,\n                 prep=\"SIGMOID\"):\n        \n        self.data_ids = dataframe.index.values\n        self.dataframe = dataframe\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.input_shape = input_shape\n        self.num_classes = num_classes\n        self.current_epoch=0\n        self.prep = prep\n        self.steps=steps\n        if self.steps is not None:\n            self.steps = np.round(self.steps/3) * 3\n            self.undersample()\n        \n    def undersample(self):\n        part = np.int(self.steps/3 * self.batch_size)\n        zero_ids = np.random.choice(self.dataframe.loc[self.dataframe[\"any\"] == 0].index.values, size=5000, replace=False)\n        hot_ids = np.random.choice(self.dataframe.loc[self.dataframe[\"any\"] == 1].index.values, size=5000, replace=True)\n        self.data_ids = list(set(zero_ids).union(hot_ids))\n        np.random.shuffle(self.data_ids)\n        \n    # defines the number of steps per epoch\n    def __len__(self):\n        if self.steps is None:\n            return np.int(np.ceil(len(self.data_ids) / np.float(self.batch_size)))\n        else:\n            return 3*np.int(self.steps/3) \n    \n    # at the end of an epoch: \n    def on_epoch_end(self):\n        # if steps is None and shuffle is true:\n        if self.steps is None:\n            self.data_ids = self.dataframe.index.values\n            if self.shuffle:\n                np.random.shuffle(self.data_ids)\n        else:\n            self.undersample()\n        self.current_epoch += 1\n    \n    # should return a batch of images\n    def __getitem__(self, item):\n        # select the ids of the current batch\n        current_ids = self.data_ids[item*self.batch_size:(item+1)*self.batch_size]\n        X, y = self.__generate_batch(current_ids)\n        return X, y\n    \n    # collect the preprocessed images and targets of one batch\n    def __generate_batch(self, current_ids):\n        X = np.empty((self.batch_size, *self.input_shape, 3))\n        y = np.empty((self.batch_size, self.num_classes))\n        for idx, ident in enumerate(current_ids):\n            # Store sample\n            #image = self.preprocessor.preprocess(ident) \n            image = preprocess(ident,self.prep)\n            X[idx] = image\n            # Store class\n            y[idx] = self.__get_target(ident)\n        return X, y\n    \n    # extract the targets of one image id:\n    def __get_target(self, ident):\n        targets = self.dataframe.loc[ident].values\n        return targets\n    \ndef turn_pred_to_dataframe(data_df, pred):\n    df = pd.DataFrame(pred, columns=data_df.columns, index=data_df.index)\n    df = df.stack().reset_index()\n    df.loc[:, \"ID\"] = df.id.str.cat(df.subtype, sep=\"_\")\n    df = df.drop([\"id\", \"subtype\"], axis=1)\n    df = df.rename({0: \"Label\"}, axis=1)\n    return df\n\ndef weighted_loss(y_true, y_pred):\n    \"\"\"\n    Will be used as the metric in model.compile()\n    ---------------------------------------------\n    \n    Similar to the custom loss function 'weighted_log_loss()' above\n    but with normalized weights, which should be very similar \n    to the official competition metric:\n        https://www.kaggle.com/kambarakun/lb-probe-weights-n-of-positives-scoring\n    and hence:\n        sklearn.metrics.log_loss with sample weights\n    \"\"\"\n    \n    class_weights = tf.constant([2., 1., 1., 1., 1., 1.])\n    \n    eps = tf.keras.backend.epsilon()\n    \n    y_pred = tf.clip_by_value(y_pred, eps, 1.0-eps)\n\n    loss = -(        y_true  * tf.math.log(      y_pred)\n            + (1.0 - y_true) * tf.math.log(1.0 - y_pred))\n    \n    loss_samples = _normalized_weighted_average(loss, class_weights)\n    \n    return tf.reduce_mean(loss_samples)\n\nimport keras.losses\n\ntest_dataloader = DataLoader(testdf,32,shuffle=False,input_shape=(224,224),prep=\"SIGMOID\")\n\ntest_pred = model.predict(workers = 2, use_multiprocessing= True, test_dataloader,verbose=1)\n\npred = test_pred[0:testdf.shape[0]]\npred_df = turn_pred_to_dataframe(testdf,pred)\npred_df.to_csv(\"test4.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid_window(dcm, window_center, window_width, U=1.0, eps=(1.0 / 255.0)):\n    img = dcm.pixel_array\n    img = cp.array(np.array(img))\n    _, _, intercept, slope = get_windowing(dcm)\n    img = img * slope + intercept\n    ue = cp.log((U / eps) - 1.0)\n    W = (2 / window_width) * ue\n    b = ((-2 * window_center) / window_width) * ue\n    z = W * img + b\n    img = U / (1 + cp.power(np.e, -1.0 * z))\n    img = (img - cp.min(img)) / (cp.max(img) - cp.min(img))\n    return cp.asnumpy(img)\ndef get_first_of_dicom_field_as_int(x):\n    #get x[0] as in int is x is a 'pydicom.multival.MultiValue', otherwise get int(x)\n    if type(x) == pydicom.multival.MultiValue:\n        return int(x[0])\n    else:\n        return int(x)\n\ndef get_windowing(data):\n    dicom_fields = [data[('0028','1050')].value, #window center\n                    data[('0028','1051')].value, #window width\n                    data[('0028','1052')].value, #intercept\n                    data[('0028','1053')].value] #slope\n    return [get_first_of_dicom_field_as_int(x) for x in dicom_fields]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T10:17:38.151141Z","iopub.execute_input":"2021-05-24T10:17:38.15149Z","iopub.status.idle":"2021-05-24T10:17:38.161305Z","shell.execute_reply.started":"2021-05-24T10:17:38.151439Z","shell.execute_reply":"2021-05-24T10:17:38.160136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"score, acc = model.evaluate(x_test, y_test,\n                            batch_size=batch_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_generator = DataGenerator(partition['test'], labels, **params)\n\nprint(\"Test Accuracy: \", model.evaluate(test_generator))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds=test_generator\npredictions= model.predict(ds)\nprint(\"A sample output from the last layer (model) \", predictions[0])\ny=[]\nprint(\"10 Sample predictions:\")\nfor (pred,(a,b)) in zip(predictions,ds):\n  \n  pred[pred>0.5]=1\n  pred[pred<=0.5]=0\n  print(\"predicted: \" ,pred, str(covert_onehot_string_labels(LABELS, pred)),  \n        \"Actual Label: (\"+str(covert_onehot_string_labels(LABELS,b.numpy())) +\")\")\n  y.append(b.numpy())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds=test_generator\npredictions= model.predict(ds)\nprint(\"10 Sample predictions:\")\nfor (pred,(a,b)) in zip(predictions,ds):\n  \n  pred[pred>0.5]=1\n  pred[pred<=0.5]=0\n  print(\"predicted: \" ,pred, str( pred),  \n        \"Actual Label: (\"+str(b) +\")\")\n  y.append(b)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}