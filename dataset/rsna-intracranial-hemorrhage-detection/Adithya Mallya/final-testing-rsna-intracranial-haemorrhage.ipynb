{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#importing libraries\nimport os\nimport random\nimport glob\nimport pandas as pd\nimport numpy as np\nimport pydicom \nfrom torch.hub import load_state_dict_from_url\nfrom torchvision.models.resnet import ResNet, Bottleneck\nimport torch\nimport torch.optim as optim\nfrom albumentations import Compose, ShiftScaleRotate, Resize, Normalize, HorizontalFlip, RandomBrightnessContrast,CenterCrop\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset,Subset\nimport cv2\n#from sklearn.decomposition import PCA\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import roc_auc_score, classification_report, recall_score, f1_score, accuracy_score, precision_score, jaccard_score\nfrom tqdm import notebook as tqdm\n\nfrom matplotlib import pyplot as plt","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-06-26T20:52:18.167882Z","iopub.execute_input":"2022-06-26T20:52:18.168813Z","iopub.status.idle":"2022-06-26T20:52:22.100021Z","shell.execute_reply.started":"2022-06-26T20:52:18.168725Z","shell.execute_reply":"2022-06-26T20:52:22.09903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install opencv-python","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_csv = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection'\n\ntrain_images_dir = '../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\ntest_images_dir = '../input/rsna-test-stage-1-images-png-224x/stage_1_test_png_224x'\n# train_metadata_csv = '/home/navneeth/ICH_Code/input/train_metadata_noidx.csv'\n# test_metadata_csv = '/home/navneeth/ICH_Code/input/test_metadata_noidx.csv'","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:52:27.870143Z","iopub.execute_input":"2022-06-26T20:52:27.871555Z","iopub.status.idle":"2022-06-26T20:52:27.876685Z","shell.execute_reply.started":"2022-06-26T20:52:27.871507Z","shell.execute_reply":"2022-06-26T20:52:27.875389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PARAMS\nn_classes = 6\nn_epochs = 10\nbatch_size = 32\n\nCOLS = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:52:31.255606Z","iopub.execute_input":"2022-06-26T20:52:31.256041Z","iopub.status.idle":"2022-06-26T20:52:31.261913Z","shell.execute_reply.started":"2022-06-26T20:52:31.256Z","shell.execute_reply":"2022-06-26T20:52:31.260653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(os.path.join(dir_csv, 'stage_2_train.csv'))\ntest = pd.read_csv(os.path.join(dir_csv, 'stage_2_sample_submission.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:52:49.992831Z","iopub.execute_input":"2022-06-26T20:52:49.993201Z","iopub.status.idle":"2022-06-26T20:52:54.404834Z","shell.execute_reply.started":"2022-06-26T20:52:49.993162Z","shell.execute_reply":"2022-06-26T20:52:54.403879Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class IntracranialDataset(Dataset):\n\n    def __init__(self, csv_file, path, labels, transform=None):\n        \n        self.path = path\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n        self.labels = labels\n\n    def __len__(self):\n        \n        return len(self.data)\n\n    def __getitem__(self, idx):\n        \n        img_name = os.path.join(self.path, self.data.loc[idx, 'Image'] + '.png')\n        img = cv2.imread(img_name)\n        \n        if self.transform:       \n            \n            augmented = self.transform(image=img)\n            img = augmented['image']   \n            \n        if self.labels:\n            \n            labels = torch.tensor(\n                self.data.loc[idx, ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']])\n            return {'image': img, 'labels': labels}    \n        \n        else:      \n            \n            return {'image': img}\n    ","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:52:54.406588Z","iopub.execute_input":"2022-06-26T20:52:54.406962Z","iopub.status.idle":"2022-06-26T20:52:54.416545Z","shell.execute_reply.started":"2022-06-26T20:52:54.406925Z","shell.execute_reply":"2022-06-26T20:52:54.415521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Preparing data\ntrain[['ID', 'Image', 'Diagnosis']] = train['ID'].str.split('_', expand=True)\ntrain = train[['Image', 'Diagnosis', 'Label']]\ntrain.drop_duplicates(inplace=True)\ntrain = train.pivot(index='Image', columns='Diagnosis', values='Label').reset_index()\ntrain['Image'] = 'ID_' + train['Image']\n\n#remove images that are not saved properly as png \npng = glob.glob(os.path.join(train_images_dir, '*.png'))\npng = [os.path.basename(png)[:-4] for png in png]\npng = np.array(png)\n\n\ntrain = train[train['Image'].isin(png)]\ntrain.to_csv('train.csv',index=False)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T20:53:02.764572Z","iopub.execute_input":"2022-06-26T20:53:02.764941Z","iopub.status.idle":"2022-06-26T20:53:41.724324Z","shell.execute_reply.started":"2022-06-26T20:53:02.76491Z","shell.execute_reply":"2022-06-26T20:53:41.723212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['ID','Image','Diagnosis']] = test['ID'].str.split('_', expand=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['Image'] = 'ID_' + test['Image']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test[['Image', 'Label']]\ntest.drop_duplicates(inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"png = glob.glob(os.path.join(test_images_dir, '*.png'))\npng = [os.path.basename(png)[:-4] for png in png]\npng = np.array(png)\n\ntest = test[test['Image'].isin(png)]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()\nprint(len(test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"No instances of Image IDs in csv found in image dataset","metadata":{}},{"cell_type":"code","source":"# Prepare test table\ntest.to_csv('test1.csv', index=False)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test1 = pd.read_csv('../input/mydata/test.csv')\ntest1","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_train = Compose([CenterCrop(200,200),HorizontalFlip(),\n                           ShiftScaleRotate(),\n                           RandomBrightnessContrast(),\n                           ToTensorV2()])\n\ntransform_test = Compose([CenterCrop(200,200),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:54:18.556216Z","iopub.execute_input":"2022-06-26T20:54:18.556815Z","iopub.status.idle":"2022-06-26T20:54:18.562479Z","shell.execute_reply.started":"2022-06-26T20:54:18.556777Z","shell.execute_reply":"2022-06-26T20:54:18.561129Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = IntracranialDataset(\n    csv_file='train.csv', path=train_images_dir, transform=transform_train, labels=True)\n\nvalid_dataset = IntracranialDataset(\n    csv_file='train.csv', path=train_images_dir, transform=transform_train, labels=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:54:24.531478Z","iopub.execute_input":"2022-06-26T20:54:24.531829Z","iopub.status.idle":"2022-06-26T20:54:25.362394Z","shell.execute_reply.started":"2022-06-26T20:54:24.531791Z","shell.execute_reply":"2022-06-26T20:54:25.361367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_dataset = torch.utils.data.Subset(valid_dataset,range(0,134359))\nprint(len(valid_dataset))\n\ntrain_dataset = torch.utils.data.Subset(train_dataset,range(134359, len(train_dataset)-1))\nprint(len(train_dataset))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:54:28.991638Z","iopub.execute_input":"2022-06-26T20:54:28.991987Z","iopub.status.idle":"2022-06-26T20:54:28.998473Z","shell.execute_reply.started":"2022-06-26T20:54:28.991956Z","shell.execute_reply":"2022-06-26T20:54:28.997459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = IntracranialDataset(\n    csv_file='../input/mydata/test.csv', path=test_images_dir, transform=transform_test, labels=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(test_dataset))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loader_train = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\nprint(len(data_loader_train))\n\ndata_loader_valid = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\nprint(len(data_loader_valid))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T20:54:35.55957Z","iopub.execute_input":"2022-06-26T20:54:35.56043Z","iopub.status.idle":"2022-06-26T20:54:35.570449Z","shell.execute_reply.started":"2022-06-26T20:54:35.560376Z","shell.execute_reply":"2022-06-26T20:54:35.569297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_loader_test = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\nprint(len(data_loader_test))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot train example\n\nbatch = next(iter(data_loader_train))\nfig, axs = plt.subplots(1, 5, figsize=(30,15))\n\nfor i in np.arange(5):\n\n    axs[i].imshow(np.transpose(batch['image'][i].numpy(), (1,2,0))[:,:,0], cmap=plt.cm.bone)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T21:25:49.753417Z","iopub.execute_input":"2022-06-26T21:25:49.754351Z","iopub.status.idle":"2022-06-26T21:25:51.370947Z","shell.execute_reply.started":"2022-06-26T21:25:49.754292Z","shell.execute_reply":"2022-06-26T21:25:51.366319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"how_many_to_plot = 30","metadata":{"execution":{"iopub.status.busy":"2022-06-26T21:04:07.016017Z","iopub.execute_input":"2022-06-26T21:04:07.016606Z","iopub.status.idle":"2022-06-26T21:04:07.021256Z","shell.execute_reply.started":"2022-06-26T21:04:07.016567Z","shell.execute_reply":"2022-06-26T21:04:07.020047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(50,50))\nfor i, batch in enumerate(data_loader_train, start=1):\n    \n    plt.subplot(10,10,i)\n    plt.imshow(np.transpose(batch['image'][i].numpy(), (1,2,0))[:,:,0], cmap='bone')\n    plt.axis('off')\n#     plt.title(train_set.classes[label.item()], fontsize=28)\n    if (i >= how_many_to_plot): break\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T21:26:03.887224Z","iopub.execute_input":"2022-06-26T21:26:03.887593Z","iopub.status.idle":"2022-06-26T21:26:08.942377Z","shell.execute_reply.started":"2022-06-26T21:26:03.88756Z","shell.execute_reply":"2022-06-26T21:26:08.94146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the model\nmodel_urls = {\n    'resnext101_32x8d': 'https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth',\n    'resnext101_32x16d': 'https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth',\n    'resnext101_32x32d': 'https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth',\n    'resnext101_32x48d': 'https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth',\n}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T16:09:59.970484Z","iopub.execute_input":"2022-06-26T16:09:59.970835Z","iopub.status.idle":"2022-06-26T16:09:59.976274Z","shell.execute_reply.started":"2022-06-26T16:09:59.970805Z","shell.execute_reply":"2022-06-26T16:09:59.97502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting up the model\ndef _resnext(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n    model.load_state_dict(state_dict)\n    return model\n\ndef resnext101_32x8d_wsl(progress=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 8\n    return _resnext('resnext101_32x8d', Bottleneck, [3, 4, 23, 3], True, progress, **kwargs)\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T16:11:11.311443Z","iopub.execute_input":"2022-06-26T16:11:11.311988Z","iopub.status.idle":"2022-06-26T16:11:11.322461Z","shell.execute_reply.started":"2022-06-26T16:11:11.31194Z","shell.execute_reply":"2022-06-26T16:11:11.321446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:12:01.946766Z","iopub.execute_input":"2022-06-26T16:12:01.947112Z","iopub.status.idle":"2022-06-26T16:12:01.954631Z","shell.execute_reply.started":"2022-06-26T16:12:01.947083Z","shell.execute_reply":"2022-06-26T16:12:01.951346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnext101_32x8d_wsl()\nmodel.fc = torch.nn.Linear(2048,n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:11:41.458454Z","iopub.execute_input":"2022-06-26T16:11:41.459404Z","iopub.status.idle":"2022-06-26T16:11:45.336452Z","shell.execute_reply.started":"2022-06-26T16:11:41.459356Z","shell.execute_reply":"2022-06-26T16:11:45.335281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading state dictionaries\nmodel = torch.nn.DataParallel(model)\ncheckpoint = torch.load('../input/models/png_model_e10_final.pt')\nmodel.load_state_dict(checkpoint['model'])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:11:45.671498Z","iopub.execute_input":"2022-06-26T16:11:45.672462Z","iopub.status.idle":"2022-06-26T16:11:57.122056Z","shell.execute_reply.started":"2022-06-26T16:11:45.672417Z","shell.execute_reply":"2022-06-26T16:11:57.121111Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-26T16:12:05.449523Z","iopub.execute_input":"2022-06-26T16:12:05.44988Z","iopub.status.idle":"2022-06-26T16:12:05.467382Z","shell.execute_reply.started":"2022-06-26T16:12:05.449849Z","shell.execute_reply":"2022-06-26T16:12:05.466238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"next(iter(data_loader_test))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch = next(iter(data_loader_test))\nfig, axs = plt.subplots(1, 5, figsize=(15,5))\n\nfor i in np.arange(5):\n    \n    axs[i].imshow(np.transpose(batch['image'][i].numpy(), (1,2,0))[:,:,0], cmap=plt.cm.bone)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\nmodel.eval()\n\ntest_pred = np.zeros((len(test_dataset) * n_classes, 1))\n\nfor i, x_batch in enumerate(tqdm.tqdm(data_loader_test)):\n    \n    x_batch = x_batch[\"image\"]\n    x_batch = x_batch.to(device, dtype=torch.float)\n    \n    with torch.no_grad():\n        \n        pred = model(x_batch)\n        \n        test_pred[(i * batch_size * n_classes):((i + 1) * batch_size * n_classes)] = torch.sigmoid(\n            pred).detach().cpu().reshape((len(x_batch) * n_classes, 1))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Testing with single image","metadata":{}},{"cell_type":"code","source":"img1 = cv2.imread(\"../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x/ID_aec8e68b3.png\")\n# augmented = transform_test(image=img1)\nsample_img = transform_test(image=img1)['image'].unsqueeze(0)\nprint(sample_img.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-26T14:12:59.869419Z","iopub.execute_input":"2022-06-26T14:12:59.870213Z","iopub.status.idle":"2022-06-26T14:12:59.879944Z","shell.execute_reply.started":"2022-06-26T14:12:59.870175Z","shell.execute_reply":"2022-06-26T14:12:59.878503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_input = sample_img.to(device, dtype=torch.float)\nprint(test_input.shape)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-26T14:13:03.539674Z","iopub.execute_input":"2022-06-26T14:13:03.540264Z","iopub.status.idle":"2022-06-26T14:13:03.546949Z","shell.execute_reply.started":"2022-06-26T14:13:03.540231Z","shell.execute_reply":"2022-06-26T14:13:03.545592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = model(test_input)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"proba = torch.sigmoid(pred).detach().cpu()\nproba","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out_b = torch.round(proba)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_list = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:12:37.809575Z","iopub.execute_input":"2022-06-26T16:12:37.810692Z","iopub.status.idle":"2022-06-26T16:12:37.815185Z","shell.execute_reply.started":"2022-06-26T16:12:37.810647Z","shell.execute_reply":"2022-06-26T16:12:37.81428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_lbl = np.where(out_b.float() == 1)[1]\npred_lbl","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = []\nfor i in pred_lbl:\n    label.append(label_list[i])\n    \nlabel","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Custom functions(WIP)","metadata":{}},{"cell_type":"code","source":"def get_tensor(img):\n    tfms_img = Compose([CenterCrop(200,200),\n                           ToTensorV2()])\n    img = cv2.imread(img)\n    return tfms_img(image=img)['image'].unsqueeze(0)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:12:16.167283Z","iopub.execute_input":"2022-06-26T16:12:16.16765Z","iopub.status.idle":"2022-06-26T16:12:16.174344Z","shell.execute_reply.started":"2022-06-26T16:12:16.167618Z","shell.execute_reply":"2022-06-26T16:12:16.172337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def predict(img, model, label_list):\n    \n    input_tensor = get_tensor(img)\n    \n#     if device == \"cuda:0\":\n    input_tensor = input_tensor.to(device, dtype=torch.float)\n#     else:\n        #code for CPU device\n        \n    pred = model(input_tensor)\n    \n    #probabilities\n#     if device == \"cuda:0\":\n    proba = torch.sigmoid(pred).detach().cpu()\n#     else:\n        #code for CPU device\n    \n    #labels\n    out = torch.round(proba)\n    pred_lbl = np.where(out == 1)[1]\n    \n    label = []\n    for i in pred_lbl:\n        label.append(label_list[i])\n        \n    return proba, out, label","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:12:23.531461Z","iopub.execute_input":"2022-06-26T16:12:23.53204Z","iopub.status.idle":"2022-06-26T16:12:23.543004Z","shell.execute_reply.started":"2022-06-26T16:12:23.531994Z","shell.execute_reply":"2022-06-26T16:12:23.541953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Testing function on sample image\npredict('../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x/ID_ade010bbf.png', model, label_list)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:24:43.164136Z","iopub.execute_input":"2022-06-26T16:24:43.164808Z","iopub.status.idle":"2022-06-26T16:24:43.216376Z","shell.execute_reply.started":"2022-06-26T16:24:43.164772Z","shell.execute_reply":"2022-06-26T16:24:43.215417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual explanations using Grad-CAM","metadata":{}},{"cell_type":"code","source":"#importing libraries\nimport os\nimport random\nimport glob\nimport pandas as pd\nimport numpy as np\nimport pydicom \nfrom torch.hub import load_state_dict_from_url\nfrom torchvision.models.resnet import ResNet, Bottleneck\nimport torch\nimport torch.optim as optim\nfrom albumentations import Compose, ShiftScaleRotate, Resize, Normalize, HorizontalFlip, RandomBrightnessContrast,CenterCrop\nfrom albumentations.pytorch import ToTensorV2\nfrom torch.utils.data import Dataset,Subset\nimport cv2\n#from sklearn.decomposition import PCA\nfrom torch.utils.tensorboard import SummaryWriter\nfrom sklearn.metrics import roc_auc_score, classification_report, recall_score, f1_score, accuracy_score, precision_score, jaccard_score\nfrom tqdm import notebook as tqdm\n\nfrom matplotlib import pyplot as plt\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:54:51.622591Z","iopub.execute_input":"2022-06-26T08:54:51.623278Z","iopub.status.idle":"2022-06-26T08:54:51.635089Z","shell.execute_reply.started":"2022-06-26T08:54:51.623244Z","shell.execute_reply":"2022-06-26T08:54:51.633666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dir_csv = '../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection'\n\ntrain_images_dir = '../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x'\ntest_images_dir = '../input/rsna-test-stage-1-images-png-224x/stage_1_test_png_224x'","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:55:27.115134Z","iopub.execute_input":"2022-06-26T08:55:27.115518Z","iopub.status.idle":"2022-06-26T08:55:27.121292Z","shell.execute_reply.started":"2022-06-26T08:55:27.115484Z","shell.execute_reply":"2022-06-26T08:55:27.120191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#PARAMS\nn_classes = 6\nn_epochs = 10\nbatch_size = 32\n\nCOLS = ['epidural', 'intraparenchymal', 'intraventricular', 'subarachnoid', 'subdural', 'any']","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:55:51.352512Z","iopub.execute_input":"2022-06-26T08:55:51.352921Z","iopub.status.idle":"2022-06-26T08:55:51.36097Z","shell.execute_reply.started":"2022-06-26T08:55:51.352889Z","shell.execute_reply":"2022-06-26T08:55:51.358679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transform_test = Compose([CenterCrop(200,200),\n                           ToTensorV2()])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:55:54.512995Z","iopub.execute_input":"2022-06-26T08:55:54.51386Z","iopub.status.idle":"2022-06-26T08:55:54.525632Z","shell.execute_reply.started":"2022-06-26T08:55:54.513792Z","shell.execute_reply":"2022-06-26T08:55:54.524037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Importing the model\nmodel_urls = {\n    'resnext101_32x8d': 'https://download.pytorch.org/models/ig_resnext101_32x8-c38310e5.pth',\n    'resnext101_32x16d': 'https://download.pytorch.org/models/ig_resnext101_32x16-c6f796b0.pth',\n    'resnext101_32x32d': 'https://download.pytorch.org/models/ig_resnext101_32x32-e4b90b00.pth',\n    'resnext101_32x48d': 'https://download.pytorch.org/models/ig_resnext101_32x48-3e41cc8a.pth',\n}","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:55:57.833878Z","iopub.execute_input":"2022-06-26T08:55:57.834265Z","iopub.status.idle":"2022-06-26T08:55:57.841153Z","shell.execute_reply.started":"2022-06-26T08:55:57.834235Z","shell.execute_reply":"2022-06-26T08:55:57.839253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Setting up the model\ndef _resnext(arch, block, layers, pretrained, progress, **kwargs):\n    model = ResNet(block, layers, **kwargs)\n    state_dict = load_state_dict_from_url(model_urls[arch], progress=progress)\n    model.load_state_dict(state_dict)\n    return model\n\ndef resnext101_32x8d_wsl(progress=True, **kwargs):\n    \"\"\"Constructs a ResNeXt-101 32x8 model pre-trained on weakly-supervised data\n    and finetuned on ImageNet from Figure 5 in\n    `\"Exploring the Limits of Weakly Supervised Pretraining\" <https://arxiv.org/abs/1805.00932>`_\n    Args:\n        progress (bool): If True, displays a progress bar of the download to stderr.\n    \"\"\"\n    kwargs['groups'] = 32\n    kwargs['width_per_group'] = 8\n    return _resnext('resnext101_32x8d', Bottleneck, [3, 4, 23, 3], True, progress, **kwargs)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:56:13.700881Z","iopub.execute_input":"2022-06-26T08:56:13.701373Z","iopub.status.idle":"2022-06-26T08:56:13.7105Z","shell.execute_reply.started":"2022-06-26T08:56:13.701284Z","shell.execute_reply":"2022-06-26T08:56:13.709123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:56:17.992281Z","iopub.execute_input":"2022-06-26T08:56:17.992894Z","iopub.status.idle":"2022-06-26T08:56:18.093562Z","shell.execute_reply.started":"2022-06-26T08:56:17.992805Z","shell.execute_reply":"2022-06-26T08:56:18.092362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = resnext101_32x8d_wsl()\nmodel.fc = torch.nn.Linear(2048,n_classes)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:56:27.844631Z","iopub.execute_input":"2022-06-26T08:56:27.845157Z","iopub.status.idle":"2022-06-26T08:56:40.622841Z","shell.execute_reply.started":"2022-06-26T08:56:27.845126Z","shell.execute_reply":"2022-06-26T08:56:40.621446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Loading state dictionaries\nmodel = torch.nn.DataParallel(model)\ncheckpoint = torch.load('../input/models/png_model_e10_final.pt')\nmodel.load_state_dict(checkpoint['model'])","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:56:47.206099Z","iopub.execute_input":"2022-06-26T08:56:47.206488Z","iopub.status.idle":"2022-06-26T08:56:59.31343Z","shell.execute_reply.started":"2022-06-26T08:56:47.206459Z","shell.execute_reply":"2022-06-26T08:56:59.312234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:58:23.273073Z","iopub.execute_input":"2022-06-26T08:58:23.273456Z","iopub.status.idle":"2022-06-26T08:58:23.295985Z","shell.execute_reply.started":"2022-06-26T08:58:23.273425Z","shell.execute_reply":"2022-06-26T08:58:23.294837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install grad-cam","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T08:58:34.797768Z","iopub.execute_input":"2022-06-26T08:58:34.798236Z","iopub.status.idle":"2022-06-26T08:59:14.903991Z","shell.execute_reply.started":"2022-06-26T08:58:34.798206Z","shell.execute_reply":"2022-06-26T08:59:14.902509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_grad_cam import GradCAM\nfrom pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\nfrom pytorch_grad_cam.utils.image import show_cam_on_image","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:59:32.180806Z","iopub.execute_input":"2022-06-26T08:59:32.181402Z","iopub.status.idle":"2022-06-26T08:59:32.204243Z","shell.execute_reply.started":"2022-06-26T08:59:32.18135Z","shell.execute_reply":"2022-06-26T08:59:32.202663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_layers = [model.module.layer4[-1]]","metadata":{"execution":{"iopub.status.busy":"2022-06-26T08:59:42.468311Z","iopub.execute_input":"2022-06-26T08:59:42.468717Z","iopub.status.idle":"2022-06-26T08:59:42.475401Z","shell.execute_reply.started":"2022-06-26T08:59:42.468683Z","shell.execute_reply":"2022-06-26T08:59:42.473923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1 = cv2.imread(\"../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x/ID_9b7d000a2.png\")\n# img1 = Image.open(\"../input/rsna-train-stage-1-images-png-224x/stage_1_train_png_224x/ID_aec8e68b3.png\")\nprint(img1.shape)\naug_img1 = transform_test(image=img1)\ntest_img = aug_img1['image'].unsqueeze(0)\nprint(test_img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:09:05.435558Z","iopub.execute_input":"2022-06-26T16:09:05.435978Z","iopub.status.idle":"2022-06-26T16:09:05.523415Z","shell.execute_reply.started":"2022-06-26T16:09:05.435893Z","shell.execute_reply":"2022-06-26T16:09:05.522246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# img2 = np.array(test_img)\n# img2 = Image.fromarray((img2 * 255).astype(np.uint8))\n# img2","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:13:54.031599Z","iopub.execute_input":"2022-06-26T09:13:54.032043Z","iopub.status.idle":"2022-06-26T09:13:54.038468Z","shell.execute_reply.started":"2022-06-26T09:13:54.032012Z","shell.execute_reply":"2022-06-26T09:13:54.037191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img2.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:14:23.084153Z","iopub.execute_input":"2022-06-26T09:14:23.08501Z","iopub.status.idle":"2022-06-26T09:14:23.092772Z","shell.execute_reply.started":"2022-06-26T09:14:23.084975Z","shell.execute_reply":"2022-06-26T09:14:23.09138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img2 = test_img.to(device, dtype=torch.float)\nprint(img2.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:16:48.618766Z","iopub.execute_input":"2022-06-26T09:16:48.619439Z","iopub.status.idle":"2022-06-26T09:16:48.636238Z","shell.execute_reply.started":"2022-06-26T09:16:48.619391Z","shell.execute_reply":"2022-06-26T09:16:48.634787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Construct the CAM object once, and then re-use it on many images:\ncam = GradCAM(model=model, target_layers=target_layers, use_cuda=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:16:52.465476Z","iopub.execute_input":"2022-06-26T09:16:52.465963Z","iopub.status.idle":"2022-06-26T09:16:52.473971Z","shell.execute_reply.started":"2022-06-26T09:16:52.46593Z","shell.execute_reply":"2022-06-26T09:16:52.472566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grayscale_cam = cam(input_tensor=img2, targets=None)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:16:57.854662Z","iopub.execute_input":"2022-06-26T09:16:57.855096Z","iopub.status.idle":"2022-06-26T09:17:04.818047Z","shell.execute_reply.started":"2022-06-26T09:16:57.855065Z","shell.execute_reply":"2022-06-26T09:17:04.816705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(type(img1))\nprint(type(np.array(grayscale_cam)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cv2.imshow('CAM',grayscale_cam)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T09:17:10.783548Z","iopub.execute_input":"2022-06-26T09:17:10.784276Z","iopub.status.idle":"2022-06-26T09:17:10.842126Z","shell.execute_reply.started":"2022-06-26T09:17:10.784233Z","shell.execute_reply":"2022-06-26T09:17:10.839843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grayscale_cam_np = np.array(grayscale_cam)\ngrayscale_cam_np.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:52.417603Z","iopub.execute_input":"2022-06-25T16:33:52.417977Z","iopub.status.idle":"2022-06-25T16:33:52.425433Z","shell.execute_reply.started":"2022-06-25T16:33:52.41794Z","shell.execute_reply":"2022-06-25T16:33:52.424374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(grayscale_cam_np.reshape(200, 200, 1))","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:55.578739Z","iopub.execute_input":"2022-06-25T16:33:55.579124Z","iopub.status.idle":"2022-06-25T16:33:55.778988Z","shell.execute_reply.started":"2022-06-25T16:33:55.579093Z","shell.execute_reply":"2022-06-25T16:33:55.777875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cam = np.maximum(cam, 0)\ncam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam))  # Normalize between 0-1\ncam = np.uint8(cam * 255)  # Scale between 0-255 to visualize","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cam2 = Image.from_array(cam.traspose(1,2,0))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"alpha = 0.7","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"overlay_img = Image.fromarray((alpha * np.asarray(img2) + (1 - alpha) * cam2).astype(np.uint8))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(overlay_img)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"grayscale_cam","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall opencv-python-headless -y","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:29:32.367214Z","iopub.execute_input":"2022-06-25T16:29:32.367578Z","iopub.status.idle":"2022-06-25T16:29:34.000332Z","shell.execute_reply.started":"2022-06-25T16:29:32.367547Z","shell.execute_reply":"2022-06-25T16:29:33.999211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install opencv-python --upgrade\n","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:33:00.856698Z","iopub.execute_input":"2022-06-25T16:33:00.857096Z","iopub.status.idle":"2022-06-25T16:33:10.632465Z","shell.execute_reply.started":"2022-06-25T16:33:00.857062Z","shell.execute_reply":"2022-06-25T16:33:10.631309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:46:20.48511Z","iopub.execute_input":"2022-06-25T16:46:20.486126Z","iopub.status.idle":"2022-06-25T16:46:20.522991Z","shell.execute_reply.started":"2022-06-25T16:46:20.48609Z","shell.execute_reply":"2022-06-25T16:46:20.522055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"heatmap = cv2.applyColorMap(np.uint8(255 * grayscale_cam_np), cv2.COLOR_BG2RGB)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:48:33.723192Z","iopub.execute_input":"2022-06-25T16:48:33.724094Z","iopub.status.idle":"2022-06-25T16:48:33.74341Z","shell.execute_reply.started":"2022-06-25T16:48:33.724058Z","shell.execute_reply":"2022-06-25T16:48:33.741977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" if use_rgb:\n        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n    heatmap = np.float32(heatmap) / 255\n\n    if np.max(img) > 1:\n        raise Exception(\n            \"The input image should np.float32 in the range [0, 1]\")\n\n    cam = heatmap + img\n    cam = cam / np.max(cam)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualization = show_cam_on_image(img1, grayscale_cam_np, use_rgb=True)","metadata":{"execution":{"iopub.status.busy":"2022-06-25T16:34:06.323085Z","iopub.execute_input":"2022-06-25T16:34:06.323451Z","iopub.status.idle":"2022-06-25T16:34:06.357189Z","shell.execute_reply.started":"2022-06-25T16:34:06.323421Z","shell.execute_reply":"2022-06-25T16:34:06.355886Z"},"trusted":true},"execution_count":null,"outputs":[]}]}