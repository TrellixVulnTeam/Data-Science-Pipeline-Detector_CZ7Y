{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"raw","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport pydicom \nfrom pydicom import dcmread\nimport matplotlib.pyplot as plt\nfrom cv2 import cv2\nfrom PIL import Image\nimport os\nimport pandas as pd\n# import time\nimport zipfile\nfrom tqdm import tqdm\n\ndata_zip = zipfile.ZipFile('data.zip', 'w')\n# os.mkdir('teste')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def return_transform_img(ds, window_center, window_width):\n    img = ds.pixel_array\n    ds.pixel_array\n#     print(img.shape)\n    intercept = ds[('0028','1052')].value\n    slope = ds[('0028','1053')].value\n\n    img = (img*slope +intercept)\n    img_min = window_center - window_width//2\n    img_max = window_center + window_width//2\n    img[img<img_min] = img_min\n    img[img>img_max] = img_max\n\n    # img[img<img_min] = 0\n    # img[img>img_max] = 255\n\n    img = (img - img_min) / (img_max - img_min)\n\n    return img\n\ntrain_folder = 'train'\n\ndicom_names = pd.read_csv('../input/testinho/train_dicom_names.csv').values\n\nif not os.path.exists(train_folder):\n    os.mkdir(train_folder)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for name in tqdm(dicom_names[350000:380000]):\n#     print(name[0])\n#     time.sleep(.300)\n#     os.system('kaggle competitions download -c rsna-intracranial-hemorrhage-detection -f rsna-intracranial-hemorrhage-detection/stage_2_train/' + str(name[0]) + '.dcm')\n    # kaggle competitions download -c rsna-intracranial-hemorrhage-detection -f rsna-intracranial-hemorrhage-detection/stage_2_train/ID_0000f1657.dcm\n\n    fileName = name[0]\n    ds = pydicom.read_file('../input/rsna-intracranial-hemorrhage-detection/rsna-intracranial-hemorrhage-detection/stage_2_train/' + fileName + \".dcm\") # read dicom image\n\n    img_subdural = return_transform_img(ds, 80, 200)\n    img_brain = return_transform_img(ds, 40, 80)\n    img_bone = return_transform_img(ds, 600, 2800)\n\n    cmap = plt.cm.gray\n\n    if not os.path.exists(train_folder + '/' +fileName):\n        os.mkdir(train_folder + '/' +fileName)\n\n    # norm = plt.Normalize(vmin=data.min(), vmax=data.max())\n    image = cmap(img_subdural)\n    plt.imsave('test.jpg', image)\n    img_pil = Image.open('test.jpg')\n    img = img_pil.resize((224,224), Image.ANTIALIAS)\n    img.save(train_folder + '/' +fileName + '/subdural.jpg')\n    data_zip.write(train_folder + '/' +fileName + '/subdural.jpg', compress_type=zipfile.ZIP_DEFLATED)\n\n    image = cmap(img_brain)\n    plt.imsave('test.jpg', image)\n    img_pil = Image.open('test.jpg')\n    img = img_pil.resize((224,224), Image.ANTIALIAS)\n    img.save(train_folder + '/' + fileName + '/brain.jpg')\n    data_zip.write(train_folder + '/' +fileName + '/brain.jpg', compress_type=zipfile.ZIP_DEFLATED)\n    \n\n    image = cmap(img_bone)\n    plt.imsave('test.jpg', image)\n    img_pil = Image.open('test.jpg')\n    img = img_pil.resize((224,224), Image.ANTIALIAS)\n    img.save(train_folder + '/' +fileName + '/bone.jpg')\n    data_zip.write(train_folder + '/' + fileName + '/bone.jpg', compress_type=zipfile.ZIP_DEFLATED)\n    \n    os.system('rm ' + fileName + '.dcm')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_zip.close()\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nos.chdir(r'/kaggle/working')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'data.zip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import requests\nr = requests.get(FileLink(r'data.zip'), allow_redirects=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"open('data.zip', 'wb').write(r.content)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display(FileLink(r'data.zip'))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}