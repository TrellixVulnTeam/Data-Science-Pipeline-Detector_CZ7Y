{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow import keras\n\nimport os\nimport pandas as pd\nimport numpy as np\nfrom skimage.io import imread_collection\nimport skimage.io\nimport skimage.color\nimport skimage.transform\nfrom platform import python_version\nimport matplotlib.pyplot as plt\n\nprint(tf.__version__)\nprint(python_version())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract filenames from the folder of images\n#filenames = []\n#for root, dirs, files in os.walk('../input/rsna-hemorrhage-jpg/train_jpg/train_jpg'):\n#    for file in files:\n#        if file.endswith('.jpg'):\n#            filenames.append(file)\n#should be the same as the images imported\n#len(filenames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#col_dir = '../input/rsna-hemorrhage-jpg/train_jpg/train_jpg/*.jpg'\n\n# Create a collection with the available images\n#images = imread_collection(col_dir)\n#we could also try what is below,\n#this should load the images in the order that we expect, \n#but if automatically alphabetical this isn't necessary:\n#images = imread_collection(col_dir, load_pattern = filenames)\n\n#make sure this is equivalent with the number of filenames\n#len(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select only the first 5000 images\n#images = images[:5000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the first image\n#plt.figure()\n#plt.imshow(images[0])\n#plt.colorbar()\n#plt.grid(False)\n#plt.show()\n\n#print(images[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check shape\n#print(images[0].shape)\n#print(images[1].shape)\n#print(images[2].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform data into array\n#images_arr = skimage.io.collection.concatenate_images(images)\n#images_arr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import labels and selct only first 5000 labels without any additional columns\n#labels = pd.read_feather('../input/rsna-hemorrhage-jpg/meta/meta/labels.fth')\n#labels = labels.iloc[:5000, 1]\n#print(labels)\n#print(type(labels))\n#print(labels.sum())\n\n#manipulate the filenames list, stripping the .jpg at the end\n#idstosearch = [item.rstrip(\".jpg\") for item in filenames]\n\n#now search the \"ID\" column for ids that correspond to our filenames\n#made the reduced dataframe \"labels2\" for now\n#labels2 = labels[labels['ID'].isin(idstosearch)]\n#labels2.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transform labels into array\n#labels_final = pd.Series.to_numpy(labels)\n#len(labels_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build the model\n#model = keras.Sequential([\n#    keras.layers.Flatten(input_shape=(256, 256, 3)),\n#    keras.layers.Dense(128, activation='relu'),\n#    keras.layers.Dense(23, activation='softmax')\n#])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Compile the model\n#model.compile(optimizer='adam',\n#              loss='sparse_categorical_crossentropy',\n#              metrics=['accuracy'])\n\n# data = train_images.reshape(2000,75,100,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train model\n#model.fit(images_arr, labels_final, epochs=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ToDos:\n# 1. Assign labels correctly\n# 2. Train / Validation / Test split\n# 3. Increase data size\n# 4. Use pretrained model to compare","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_comb = pd.read_feather('../input/rsna-hemorrhage-jpg/meta/meta/comb.fth').set_index('SOPInstanceUID')   \n#print(df_comb.shape)\n\n#df_tst = pd.read_feather('../input/rsna-hemorrhage-jpg/meta/meta/df_tst.fth').set_index('SOPInstanceUID')\n#print(df_tst.shape)\n\n#df_samp = pd.read_feather('../input/rsna-hemorrhage-jpg/meta/meta/wgt_sample.fth').set_index('SOPInstanceUID')\n#print(df_samp.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from PIL import Image\n#import glob\n\n#image_list = []\n\n#for filename in glob.glob('../input/rsna-hemorrhage-jpg/train_jpg/train_jpg/*.jpg'):\n#    im=Image.open(filename)\n#    image_list.append(im)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":1}