{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Grad-CAM Evrişimsel Sinir Ağları tekniğinin aptos datalarına uygulanması\n\n***TEZ İÇİN ÖNEMLİ -> ALTTA YER ALAN FLOW CHART İŞLENECEK!\n\n!(http://gradcam.cloudcv.org/static/images/network.png)","metadata":{}},{"cell_type":"markdown","source":"Grad-CAM görselleştirme şu şekilde özetlenebilir:\n\n**Amaç** Modelin nihai öngörülen sınıf (burada, diyabetik retinopati şiddet düzeyi) hakkında karar vermesini sağlayan piksel bölgelerini (uzaysal bilgi) vurgulanması şeklindedir. Bu bölgeleri **ısı haritası** kullanarak görselleştiriyoruz (yukarıdaki şekilde gösterildiği gibi).\n\n**Yöntem Sezgisi**\n* En önemli uzamsal bilginin, son FC katmanına akan en yakın uzamsal bilgi olan *son evrişim katmanının* ('GlobalPooling katmanı'ndan hemen önce) 3B tensöründen geldiği görülmekte.\n\n* Bu 3D tensörün her kanalı için, etkinleştirilmiş her piksel bölgesi, giriş görüntüsünün önemli özelliklerini (örneğin kan damarı / kabuk / cotton noktası vbb.) temsil eder. Bazı özelliklerin sınıf 0'ı (mükemmel ince kan damarı) belirlemek için önemli olduğunu, bazı özelliklerin sınıf 4'ü (büyük ebatlı cotton noktaları) belirlemek için önemli olduğunu unutmayın. Normalde, her kanalın farklı özellikler dizisi yakalamasını bekleriz.\n\n* Nihai tahmini etkileyen özellikleri vurgulamak için, **son tahmin edilen sınıfın her bir özelliğe göre gradyanını hesaplarız.** Bu özellik bu sınıf için önemliyse, yüksek eğime sahip olmalıdır (yani değerini artırın). bu özellik, prediction'ın yani kestirimin güvenini arttırır)\n\n* Bu nedenle, her kanal için görselleştirilmiş ısı haritasını elde etmek için bu 3B tensörün etkinleştirilmiş değerlerini ve gradyanları birlikte çarpıyoruz. Çoklu kanallarımız olduğunu ve her kanalın genellikle çoklu özellikleri olduğunu unutmayın.\n\n* Son olarak, basit bir ortalama kullanarak tüm kanalların ısı haritalarını birleştirir ve nihai ısı haritasını elde etmek için negatif değeri (yukarıdaki resimde 'ReLu' adımı) kaldırılmaktadır. \n\n","metadata":{}},{"cell_type":"code","source":"import json\nimport math\nimport os\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm\n\n%matplotlib inline","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T11:28:55.105171Z","iopub.execute_input":"2021-12-24T11:28:55.105471Z","iopub.status.idle":"2021-12-24T11:28:55.115932Z","shell.execute_reply.started":"2021-12-24T11:28:55.105416Z","shell.execute_reply":"2021-12-24T11:28:55.114964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Model çıktısını Grad-CAM kullanarak görselleştirmek için modeli yeniden yüklenmesine gerek bulunmamakta, zira depo içeriisnde aptos datalarını bir önceki ŞY-1 noktasından çekmekteyiz. \n\n**Orijinal modülün 224x224 görüntü kullandığını ve aşağıdaki preprocess_image işlevini kullandığını unutmayın.\n\nYine de, model ağırlıklarını doğru yüklediğimizden emin olmak için test verilerini önceden işleyeceğim ve orijinal çekirdekle tam olarak aynı tahminleri elde ettiğimizden emin oluyoruz.","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ntest_df.head()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T11:29:00.357404Z","iopub.execute_input":"2021-12-24T11:29:00.357704Z","iopub.status.idle":"2021-12-24T11:29:00.40461Z","shell.execute_reply.started":"2021-12-24T11:29:00.357643Z","shell.execute_reply":"2021-12-24T11:29:00.403977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\ndef preprocess_image(image_path, desired_size=224):\n    im = Image.open(image_path)\n    im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n#     im = im.resize((desired_size, )*2)\n    \n    return im","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T11:32:13.813589Z","iopub.execute_input":"2021-12-24T11:32:13.8139Z","iopub.status.idle":"2021-12-24T11:32:13.822792Z","shell.execute_reply.started":"2021-12-24T11:32:13.81385Z","shell.execute_reply":"2021-12-24T11:32:13.822004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test datalarının sisteme yüklenmesi, png verileri daha nitelikli olduğundan dolayı sisteme yüklüyoruz!\n\nN = test_df.shape[0]\nx_test = np.empty((N, 224, 224, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(test_df['id_code'])):\n    x_test[i, :, :, :] = preprocess_image(\n        f'../input/aptos2019-blindness-detection/test_images/{image_id}.png'\n    )","metadata":{"execution":{"iopub.status.busy":"2021-12-24T11:32:17.773251Z","iopub.execute_input":"2021-12-24T11:32:17.773551Z","iopub.status.idle":"2021-12-24T11:34:21.821551Z","shell.execute_reply.started":"2021-12-24T11:32:17.773493Z","shell.execute_reply":"2021-12-24T11:34:21.820777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Bazı orijinal test görüntülerini görüntüleme\n\nSadece bir fikir olması için, test setindeki ilk 10 gözü görselleştirelim. Burada az sayıda gözün iyi göründüğünü gözlenmekte (tez içerisinde önemli olduğu vurgulanacak). tıp uygulamaları için anormal noktaları daha kolay göreceğimiz ve daha sonra göz resmini ısı haritası ile birleştirdiğimizde daha temiz olacağı için ŞY-1 uygulamasında yer alan önişlemeleri çağırıyoruz ","metadata":{}},{"cell_type":"code","source":"# model.summary()\ndef load_image_ben_orig(path,resize=True,crop=False,norm255=True,keras=False):\n    image = cv2.imread(path)\n    \n#     if crop:\n#         image = crop_image(image)\n    \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n#     if resize:\n#         image = cv2.resize(image,(SIZE,SIZE))\n        \n    image=cv2.addWeighted( image,4, cv2.GaussianBlur( image , (0,0) ,  10) ,-4 ,128)\n#     image=cv2.addWeighted( image,4, cv2.medianBlur( image , 10) ,-4 ,128)\n    \n    # NOTE plt.imshow can accept both int (0-255) or float (0-1), but deep net requires (0-1)\n    if norm255:\n        return image/255\n    elif keras:\n        #see https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py for mode\n        #see https://github.com/keras-team/keras-applications/blob/master/keras_applications/xception.py for inception,xception mode\n        #the use of tf based preprocessing (- and / by 127 respectively) will results in [-1,1] so it will not visualize correctly (directly)\n        image = np.expand_dims(image, axis=0)\n        return preprocess_input(image)[0]\n    else:\n        return image.astype(np.int16)\n    \n    return image\n\ndef transform_image_ben(img,resize=True,crop=False,norm255=True,keras=False):  \n    image=cv2.addWeighted( img,4, cv2.GaussianBlur( img , (0,0) ,  10) ,-4 ,128)\n    \n    # NOTE plt.imshow can accept both int (0-255) or float (0-1), but deep net requires (0-1)\n    if norm255:\n        return image/255\n    elif keras:\n        image = np.expand_dims(image, axis=0)\n        return preprocess_input(image)[0]\n    else:\n        return image.astype(np.int16)\n    \n    return image","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T11:34:36.211399Z","iopub.execute_input":"2021-12-24T11:34:36.211706Z","iopub.status.idle":"2021-12-24T11:34:36.222509Z","shell.execute_reply.started":"2021-12-24T11:34:36.211644Z","shell.execute_reply":"2021-12-24T11:34:36.221664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_samples(df, columns=5, rows=2, Ben=True):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n#         image_id = df.loc[i,'diagnosis']\n        path = f'../input/aptos2019-blindness-detection/test_images/{image_path}.png'\n        if Ben:\n            img = load_image_ben_orig(path)\n        else:\n            img = cv2.imread(path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n#         plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(test_df, Ben=False)\ndisplay_samples(test_df, Ben=True)","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T11:34:40.495464Z","iopub.execute_input":"2021-12-24T11:34:40.495974Z","iopub.status.idle":"2021-12-24T11:34:48.83198Z","shell.execute_reply.started":"2021-12-24T11:34:40.495712Z","shell.execute_reply":"2021-12-24T11:34:48.831059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Modeli oluşturma konulu gradyan çıktı modülü\n\nKavramsal olarak, sadece önceden eğitilmiş modeli yükleyebilir ve istenen gradyanı hesaplayabiliriz ve bu, ısı haritasına sahip olmak için yeterlidir! Ancak, teknik olarak konuşursak, orijinal çekirdek Keras'ın 'İşlevsel yöntemi' yerine ince ayarlı bir DenseNet modeli oluşturmak için Keras'ın 'Sıralı yöntemini' kullanır.Paylaşılan katmanları kullanarak bir model oluşturmak için 'Sıralı yöntemi' kullanmak ve ardından önceden eğitilmiş ağırlıklar uygulamaktır. Bundan sonra, `Fonksiyonel yöntem` kullanarak ancak aynı paylaşılan katmanları kullanarak başka bir model oluşturuyoruz. Tüm katmanlar paylaşıldığından, iki model tamamen aynıdır, aynı ağırlıklara sahiptir.\n\n\nkeras ile derin öğrenme modeli -> https://medium.com/@tuncerergin/keras-ile-derin-ogrenme-modeli-olusturma-4b4ffdc35323","metadata":{}},{"cell_type":"code","source":"from keras import layers\nfrom keras.models import Model\nimport keras.backend as K","metadata":{"execution":{"iopub.status.busy":"2021-12-24T11:46:11.215022Z","iopub.execute_input":"2021-12-24T11:46:11.215652Z","iopub.status.idle":"2021-12-24T11:46:11.22347Z","shell.execute_reply.started":"2021-12-24T11:46:11.215324Z","shell.execute_reply":"2021-12-24T11:46:11.222746Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"K.clear_session()\ndensenet = DenseNet121(\n    weights=None,\n    include_top=False,\n    input_shape=(None,None,3)\n)","metadata":{"execution":{"iopub.status.busy":"2021-12-24T11:45:57.683988Z","iopub.execute_input":"2021-12-24T11:45:57.684273Z","iopub.status.idle":"2021-12-24T11:46:11.198229Z","shell.execute_reply.started":"2021-12-24T11:45:57.684225Z","shell.execute_reply":"2021-12-24T11:46:11.197451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Daha sonra, orijinal çekirdekte kullanılanla tamamen aynı türde 3 paylaşılan kafa katmanı tanımlıyoruz. Ardından, orijinal çekirdekle aynı işlemi `Sequential()` modülünü kullanarak oluşturun. Aşağıdaki `model.summary()`den `Sequential()` modülünü kullanarak omurganın katman detaylarının gizlendiğini ve doğrudan kullanamadığımızı görebilirsiniz. **tezde belirtilecek ayrı bir detay.","metadata":{}},{"cell_type":"code","source":"GAP_layer = layers.GlobalAveragePooling2D()\ndrop_layer = layers.Dropout(0.5)\ndense_layer = layers.Dense(5, activation='sigmoid', name='final_output')","metadata":{"execution":{"iopub.status.busy":"2021-12-24T11:46:41.38137Z","iopub.execute_input":"2021-12-24T11:46:41.381668Z","iopub.status.idle":"2021-12-24T11:46:41.386985Z","shell.execute_reply.started":"2021-12-24T11:46:41.381618Z","shell.execute_reply":"2021-12-24T11:46:41.386213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model_sequential():\n    model = Sequential()\n    model.add(densenet)\n    model.add(GAP_layer)\n    model.add(drop_layer)\n    model.add(dense_layer)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-12-24T11:46:43.660212Z","iopub.execute_input":"2021-12-24T11:46:43.660504Z","iopub.status.idle":"2021-12-24T11:46:43.665989Z","shell.execute_reply.started":"2021-12-24T11:46:43.660454Z","shell.execute_reply":"2021-12-24T11:46:43.66519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"modelA = build_model_sequential()\nmodelA.load_weights('../input/aptos-data/dense_xhlulu_731.h5')\n\nmodelA.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below, we construct another model using exactly the same (shared) layers. When pretrained weights are loaded into the first model, the second model also get the same weights (since all layers are shared)","metadata":{}},{"cell_type":"code","source":"def build_model_functional():\n    base_model = densenet\n    \n    x = GAP_layer(base_model.layers[-1].output)\n    x = drop_layer(x)\n    final_output = dense_layer(x)\n    model = Model(base_model.layers[0].input, final_output)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Artık fonksiyonel modülü kullanarak, `model.summary()` çalıştırıldığında görünen tüm katmanlara erişebiliriz. Çıktı çok uzun olduğu için arasıra bu arayüz kitlenebilir, tekrardan deneyiniz !","metadata":{}},{"cell_type":"code","source":"model = build_model_functional() \nmodel.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T11:47:21.101349Z","iopub.execute_input":"2021-12-24T11:47:21.101641Z","iopub.status.idle":"2021-12-24T11:47:21.34578Z","shell.execute_reply.started":"2021-12-24T11:47:21.101589Z","shell.execute_reply":"2021-12-24T11:47:21.34474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu nedenle, son evrişim katmanına buradan erişebiliriz. \"conv5_block16_concat\"ın düzeltilmiş ve toplu normalleştirilmiş sürümü olan \"conv5_block16_concat\" veya \"relu\" kullanabileceğimizi unutmayın.","metadata":{}},{"cell_type":"markdown","source":"## 3.1 Sadece doğru ağırlıklara sahip olduğumuzdan emin olmak için\n\nBu bölümün amacının, zaten doğru ağırlıkları yüklediğimizden emin olmak olduğunu unutmayın. ÖLB puanı ile kanıtlandığı için bu sürümde yorumlamak mümkündür.","metadata":{}},{"cell_type":"code","source":"# y_test = model.predict(x_test) > 0.5\n# y_test = y_test.astype(int).sum(axis=1) - 1\n\n# test_df['diagnosis'] = y_test\n# test_df.to_csv('submission.csv',index=False)\n# y_test.shape, x_test.shape","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import seaborn as sns\n# import cv2\n\n# SIZE=224\n# def create_pred_hist(pred_level_y,title='NoTitle'):\n#     results = pd.DataFrame({'diagnosis':pred_level_y})\n\n#     f, ax = plt.subplots(figsize=(7, 4))\n#     ax = sns.countplot(x=\"diagnosis\", data=results, palette=\"GnBu_d\")\n#     sns.despine()\n#     plt.title(title)\n#     plt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create_pred_hist(y_test,title='predicted level distribution in test set')   #-> kestirim seviyesinin belirlenmesi ","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4. Gerçek veya Sanal Anomalilerin tespiti\n\nÖnce bir ısı haritası hesaplama fonksiyonu tanımlayalım. Giriş bölümünde belirtildiği gibi, kodlar [bu makaleden](http://www.hackevolve.com/where-cnn-is-look-grad-cam/) uyarlanmıştır ve bu da F.Chollet'in kitabından uyarlanmıştır.\n\nBu fonksiyon girdi olarak 4 argüman alacaktır. (1) bir tahmin/görselleştirme yapmak için görüntü, buraya doğru önceden işlenmiş versiyonu eklemeyi unutmayın (2) model (3) gradyanları elde etmek için bir katman ve (4) sadece ısı haritası ile birleştirmek ve nihai sonucu görselleştirmek için bir yardımcı görüntü ; Resimlerdeki yıldırım koşullarını ortadan kaldırdığı ve nihai sonucu görselleştirmemiz amacıyla ŞY_1 scriptinde yer alan işlenmiş görüntüleri kullanmaktayız.","metadata":{}},{"cell_type":"code","source":"def gen_heatmap_img(img, model0, layer_name='last_conv_layer',viz_img=None,orig_img=None):\n    preds_raw = model0.predict(img[np.newaxis])\n    preds = preds_raw > 0.5 \n    class_idx = (preds.astype(int).sum(axis=1) - 1)[0]\n#     print(class_idx, class_idx.shape)\n    class_output_tensor = model0.output[:, class_idx]\n    \n    viz_layer = model0.get_layer(layer_name)\n    grads = K.gradients(\n                        class_output_tensor ,\n                        viz_layer.output\n                        )[0] \n    \n    pooled_grads=K.mean(grads,axis=(0,1,2))\n    iterate=K.function([model0.input],[pooled_grads, viz_layer.output[0]])\n    \n    pooled_grad_value, viz_layer_out_value = iterate([img[np.newaxis]])\n    \n    for i in range(pooled_grad_value.shape[0]):\n        viz_layer_out_value[:,:,i] *= pooled_grad_value[i]\n    \n    heatmap = np.mean(viz_layer_out_value, axis=-1)\n    heatmap = np.maximum(heatmap,0)\n    heatmap /= np.max(heatmap)\n\n    viz_img=cv2.resize(viz_img,(img.shape[1],img.shape[0]))\n    heatmap=cv2.resize(heatmap,(viz_img.shape[1],viz_img.shape[0]))\n    \n    heatmap_color = cv2.applyColorMap(np.uint8(heatmap*255), cv2.COLORMAP_SPRING)/255\n    heated_img = heatmap_color*0.5 + viz_img*0.5\n    \n    print('raw output from model : ')\n    print_pred(preds_raw)\n    \n    if orig_img is None:\n        show_Nimages([img,viz_img,heatmap_color,heated_img])\n    else:\n        show_Nimages([orig_img,img,viz_img,heatmap_color,heated_img])\n    \n    plt.show()\n    return heated_img","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_image(image,figsize=None,title=None):\n    \n    if figsize is not None:\n        fig = plt.figure(figsize=figsize)\n#     else: # crash!!\n#         fig = plt.figure()\n        \n    if image.ndim == 2:\n        plt.imshow(image,cmap='gray')\n    else:\n        plt.imshow(image)\n        \n    if title is not None:\n        plt.title(title)\n\ndef show_Nimages(imgs,scale=1):\n\n    N=len(imgs)\n    fig = plt.figure(figsize=(25/scale, 16/scale))\n    for i, img in enumerate(imgs):\n        ax = fig.add_subplot(1, N, i + 1, xticks=[], yticks=[])\n        show_image(img)\n        \ndef print_pred(array_of_classes):\n    xx = array_of_classes\n    s1,s2 = xx.shape\n    for i in range(s1):\n        for j in range(s2):\n            print('%.3f ' % xx[i,j],end='')\n        print('')","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_SAMP=10\nSEED=77\nlayer_name = 'relu' #'conv5_block16_concat'\nfor i, (idx, row) in enumerate(test_df[:NUM_SAMP].iterrows()):\n    path=f\"../input/aptos2019-blindness-detection/test_images/{row['id_code']}.png\"\n    ben_img = load_image_ben_orig(path)\n    input_img = np.empty((1,224, 224, 3), dtype=np.uint8)\n    input_img[0,:,:,:] = preprocess_image(path)\n        \n    print('test pic no.%d' % (i+1))\n    _ = gen_heatmap_img(input_img[0],\n                        model, layer_name=layer_name,viz_img=ben_img)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Burada birçok ilginç gözlem var. Birkaç isim,\n\n* 1., 4., 5., 6. tahminler harika görünüyor\n* 2. tahmin, ortadaki tüm büyük noktaları kaçırır\n* 3. ve 7. tahminler de önemli noktaları kaçırıyor\n* 9. görselde kanlı noktalar her yerde doğru tespitler bulunmakta.","metadata":{}},{"cell_type":"markdown","source":"# 5. Sağlamlık Testi\n\n","metadata":{}},{"cell_type":"code","source":"from albumentations import *\nimport time\n\nIMG_SIZE = (224,224)\n\n\ndef albaugment(aug0, img):\n    return aug0(image=img)['image']\nidx=8\nimage1=x_test[idx]\n\n'''1. Rotate or Flip'''\naug1 = OneOf([\n    Rotate(p=0.99, limit=160, border_mode=0,value=0), \n    Flip(p=0.5)\n    ],p=1)\n\n'''2. Adjust Brightness or Contrast'''\naug2 = RandomBrightnessContrast(brightness_limit=0.45, contrast_limit=0.45,p=1)\nh_min=np.round(IMG_SIZE[1]*0.72).astype(int)\nh_max= np.round(IMG_SIZE[1]*0.9).astype(int)\nprint(h_min,h_max)\n\n'''3. Random Crop and then Resize'''\n#w2h_ratio = aspect ratio of cropping\naug3 = RandomSizedCrop((h_min, h_max),IMG_SIZE[1],IMG_SIZE[0], w2h_ratio=IMG_SIZE[0]/IMG_SIZE[1],p=1)\n\n'''4. CutOut Augmentation'''\nmax_hole_size = int(IMG_SIZE[1]/10)\naug4 = Cutout(p=1,max_h_size=max_hole_size,max_w_size=max_hole_size,num_holes=8 )#default num_holes=8\n\n'''5. SunFlare Augmentation'''\naug5 = RandomSunFlare(src_radius=max_hole_size,\n                      num_flare_circles_lower=10,\n                      num_flare_circles_upper=20,\n                      p=1)#default flare_roi=(0,0,1,0.5),\n\n'''6. Ultimate Augmentation -- combine everything'''\nfinal_aug = Compose([\n    aug1,aug2,aug3,aug4,aug5\n],p=1)\n\n\nimg1 = albaugment(aug1,image1)\nimg2 = albaugment(aug1,image1)\nprint('Rotate or Flip')\nshow_Nimages([image1,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(aug2,image1)\nimg2 = albaugment(aug2,image1)\nimg3 = albaugment(aug2,image1)\nprint('Brightness or Contrast')\nshow_Nimages([img3,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(aug3,image1)\nimg2 = albaugment(aug3,image1)\nimg3 = albaugment(aug3,image1)\nprint('Rotate and Resize')\nshow_Nimages([img3,img1,img2],scale=2)\nprint(img1.shape,img2.shape)\n# time.sleep(1)\n\nimg1 = albaugment(aug4,image1)\nimg2 = albaugment(aug4,image1)\nimg3 = albaugment(aug4,image1)\nprint('CutOut')\nshow_Nimages([img3,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(aug5,image1)\nimg2 = albaugment(aug5,image1)\nimg3 = albaugment(aug5,image1)\nprint('Sun Flare')\nshow_Nimages([img3,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(final_aug,image1)\nimg2 = albaugment(final_aug,image1)\nimg3 = albaugment(final_aug,image1)\nprint('All above combined')\nshow_Nimages([img3,img1,img2],scale=2)\nprint(img1.shape,img2.shape)\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Büyütme rastgele olduğu için, bu çekirdeği yazdığımdan farklı sonuçlar göreceksiniz. Denememde, model oldukça sağlam çünkü bazen kafa karıştırıcı bir şekilde seviye 4 olarak tahmin ettiği nihai (her şey) büyütme dışında neredeyse aynı seviyeyi tahmin ediyor. Algılanan özellikler de oldukça tutarlı.\n\n","metadata":{}},{"cell_type":"code","source":"aug_list = [aug5, aug2, aug3, aug4, aug1, final_aug]\naug_name = ['SunFlare', 'brightness or contrast', 'crop and resized', 'CutOut', 'rotate or flip', 'Everything Combined']\n\nidx=8\nlayer_name = 'relu' #'conv5_block16_concat'\nfor i in range(len(aug_list)):\n    path=f\"../input/aptos2019-blindness-detection/test_images/{test_df.iloc[idx]['id_code']}.png\"\n    input_img = np.empty((1,224, 224, 3), dtype=np.uint8)\n    input_img[0,:,:,:] = preprocess_image(path)\n    aug_img = albaugment(aug_list[i],input_img[0,:,:,:])\n    ben_img = transform_image_ben(aug_img)\n    \n    print('test pic no.%d -- augmentation: %s' % (i+1, aug_name[i]))\n    _ = gen_heatmap_img(aug_img,\n                        model, layer_name=layer_name,viz_img=ben_img,orig_img=input_img[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gelecekte güncelleyeceğim bu ısı haritası görselleştirmesinin daha birçok olası yaratıcı kullanımı var.\n\n* Artırılmış görüntüleri görselleştirin ve modelimizin yeterince sağlam olup olmadığına (aynı şeyi tahmin ediyor) veya büyütmemizin anlamlı olup olmadığına (önemli bilgileri koruyor mu?) tez içerisinde bakılmalı\n\n* Modelimizin her bir önem derecesini belirlemek için hangi özellikleri kullandığı hakkında bir fikir edinmek için 0'dan 4'e kadar her seviye için görselleştirin\n","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}