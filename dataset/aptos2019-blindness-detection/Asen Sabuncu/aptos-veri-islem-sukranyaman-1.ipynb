{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # numpy numerik py komutu ile kümülastif işlem modülü açılır\nimport pandas as pd # aynı şekilde pandas modülü ile katlı layerlı işlemler modülü açılır \n\nimport os\nprint(os.listdir(\"../input\"))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:34:18.731722Z","iopub.execute_input":"2021-12-24T10:34:18.732638Z","iopub.status.idle":"2021-12-24T10:34:18.74155Z","shell.execute_reply.started":"2021-12-24T10:34:18.732572Z","shell.execute_reply":"2021-12-24T10:34:18.740152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image, ImageOps\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy\nfrom keras.applications.resnet50 import preprocess_input\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score\nfrom keras.utils import Sequence\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nIMG_SIZE = 512\nNUM_CLASSES = 5\nSEED = 77\nTRAIN_NUM = 1000 # APTOS verisetine ait tüm  standart importlar sisteme bu aşamada dahil edilir, plotlama içinse iki adet işlemciyi bu aşamada çağırıyoruz.","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:34:18.744746Z","iopub.execute_input":"2021-12-24T10:34:18.745488Z","iopub.status.idle":"2021-12-24T10:34:22.142952Z","shell.execute_reply.started":"2021-12-24T10:34:18.745426Z","shell.execute_reply":"2021-12-24T10:34:22.141775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ndf_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n\nx = df_train['id_code']\ny = df_train['diagnosis']\n\nx, y = shuffle(x, y, random_state=SEED)\n\n# verilere ait ilk kategorize işlemi bu aşamada yapılmakta, train ve test csv dosyalarında hastalar ait temel ayrımlar yapılmakta, (cinsiyet, yaş vb.)\n# ardından stuffle komutu ile olası bir otokorelasyonda verilerin tekrarlı döngüye girmesi engellenir.\n","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:34:22.14505Z","iopub.execute_input":"2021-12-24T10:34:22.145592Z","iopub.status.idle":"2021-12-24T10:34:22.181605Z","shell.execute_reply.started":"2021-12-24T10:34:22.145521Z","shell.execute_reply":"2021-12-24T10:34:22.180894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n                                                      stratify=y, random_state=SEED)\nprint(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\ntrain_y.hist()\nvalid_y.hist()\n\n# ardından histogramı alınarak veri üzerinde sınır uç değerlerinde gözlenen yüksek gürültü var ise (olası) bunların silinme işlemleri yapılır.","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:34:22.185176Z","iopub.execute_input":"2021-12-24T10:34:22.185417Z","iopub.status.idle":"2021-12-24T10:34:22.60282Z","shell.execute_reply.started":"2021-12-24T10:34:22.185367Z","shell.execute_reply":"2021-12-24T10:34:22.601654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Diyabetik Retinopartiyi oluşturan elemanların adlandırılması Retinopathy\n\n![credit : https://www.eyeops.com/](https://sa1s3optim.patientpop.com/assets/images/provider/photos/1947516.jpeg)","metadata":{}},{"cell_type":"markdown","source":"Burada sistem öncesinde verilerin yorumlanmasına yönelik hangi kısmın ne olarak adlandılacağı verilmekte.","metadata":{}},{"cell_type":"markdown","source":"# Veri Girişleri\n\nİlk olarak, orjinal işlenmemiş verilere bakıldığında, retinonun çapı her bir önem düzeyini gösterir. Örneğin, bazı görüntüler nesnelerin tespit edilemeyeceği kadar çok karanlık [pic(0,2) ve pic(4,4) ] olabilmekte veya farklı renk tayfına sahip olabilmekte [pic (3,3)]. İkinci olarak, bazı resimler için bilgi vermeyen karanlık alanları elde edebiliriz [pic(0,1), pic(0,3)]. Bilgilendirici alanlar çok küçüldüğü için resim boyutunu küçülttüğümüzde bu önemlidir. Bu nedenle, ikinci durumda bilgi vermeyen alanları kırpmak modelleme başlangıcı için önem teşkil eder.","metadata":{}},{"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\n# kesilen figürlerin 5x5 gösterimi\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\n        plt.imshow(image)\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )\n        \n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:34:22.611327Z","iopub.execute_input":"2021-12-24T10:34:22.614248Z","iopub.status.idle":"2021-12-24T10:34:29.634712Z","shell.execute_reply.started":"2021-12-24T10:34:22.611627Z","shell.execute_reply":"2021-12-24T10:34:29.633656Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Gri tonlamayı deneyebilir ve renk dağılması ortadan kalktığı için bazı resimler için daha iyi anladığımızı hissedebiliriz. Örneğin pic(4,4)'ün şiddet seviyesi 4 olan üst kısmında damar yolunun daha net bir şekilde gözlendiğini görebiliriz.","metadata":{}},{"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image=cv2.addWeighted ( image, 0 , cv2.GaussianBlur( image , (0 ,0 ) , 10) ,-4 ,128)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:34:29.637539Z","iopub.execute_input":"2021-12-24T10:34:29.637916Z","iopub.status.idle":"2021-12-24T10:34:34.603577Z","shell.execute_reply.started":"2021-12-24T10:34:29.63786Z","shell.execute_reply":"2021-12-24T10:34:34.602622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Bu kısımda iki renk tayfına ait örneğin fark edilmesinin zor olduğunu görmekteyiz; pic(4,1) ve pic(4,4). Ayrıntıları görmek için yakınlaştırmaya çalıştığımızda (gerçek boyutlu bir resim içerisinde), bu gözlerde bazı anormallikler (şekilde verilen cotton leak. veya hard exutades olarak adlandırılan görebiliriz (gözün sağ alt kısmına dikkatli bir şekilde bakıldığında). Bu nedenle, `IMG_SIZE` bu problem için kesinlikle önemlidir. ","metadata":{}},{"cell_type":"code","source":"dpi = 80 #inch\n\n# path=f\"../input/aptos2019-blindness-detection/train_images/5c7ab966a3ee.png\" # notice upper part\npath=f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\" # lower-right, this still looks not so severe, can be class3\nimage = cv2.imread(path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nheight, width = image.shape\nprint(height, width)\n\nSCALE=2\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image, cmap='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:34:34.605117Z","iopub.execute_input":"2021-12-24T10:34:34.605595Z","iopub.status.idle":"2021-12-24T10:34:35.778387Z","shell.execute_reply.started":"2021-12-24T10:34:34.605526Z","shell.execute_reply":"2021-12-24T10:34:35.776393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. gaussian filtre eliminasyonu\n\nbu aşamada gri olarak elde edilen veriseti üzerine gaussian filtresi oluşturularak daha net ve gürültülerden arındırılmış figürler görmekteyiz.","metadata":{}},{"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128) # bu aşamada getirilen gaussian filtresi\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:34:35.779952Z","iopub.execute_input":"2021-12-24T10:34:35.780519Z","iopub.status.idle":"2021-12-24T10:34:47.442115Z","shell.execute_reply.started":"2021-12-24T10:34:35.78045Z","shell.execute_reply":"2021-12-24T10:34:47.440934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. otomatik kesim ile tek ölçekte çizim\n\notomatik kesim (autocrop) için github dan bir kodlamayı buraya uyarladık, bu aşamada her bir verinin tek bir ölçekte çizdirilmesi amaçlanmaktadır.\n","metadata":{}},{"cell_type":"code","source":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:34:47.44351Z","iopub.execute_input":"2021-12-24T10:34:47.443862Z","iopub.status.idle":"2021-12-24T10:34:47.477135Z","shell.execute_reply.started":"2021-12-24T10:34:47.443783Z","shell.execute_reply":"2021-12-24T10:34:47.475781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# OLD version of image color cropping, use crop_image_from_gray instead\n# The above code work only for 1-channel. Here is my simple extension for 3-channels image\ndef crop_image(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        h,w,_=img.shape\n#         print(h,w)\n        img1=cv2.resize(crop_image1(img[:,:,0]),(w,h))\n        img2=cv2.resize(crop_image1(img[:,:,1]),(w,h))\n        img3=cv2.resize(crop_image1(img[:,:,2]),(w,h))\n        \n#         print(img1.shape,img2.shape,img3.shape)\n        img[:,:,0]=img1\n        img[:,:,1]=img2\n        img[:,:,2]=img3\n        return img\n\n'''all of these do not work'''\n\ndef crop_image2(image,threshold=5):\n    if len(image.shape) == 3:\n        flatImage = np.max(image, 2)\n    else:\n        flatImage = image\n    assert len(flatImage.shape) == 2\n\n    rows = np.where(np.max(flatImage, 0) > threshold)[0]\n    if rows.size:\n        cols = np.where(np.max(flatImage, 1) > threshold)[0]\n        image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n    else:\n        image = image[:1, :1]\n\n    return image\n\ndef crop_image3(image):\n    mask = image > 0\n\n    # Coordinates of non-black pixels.\n    coords = np.argwhere(mask)\n\n    # Bounding box of non-black pixels.\n    x0, y0 = coords.min(axis=0)\n    x1, y1 = coords.max(axis=0) + 1   # slices are exclusive at the top\n    \n    # Get the contents of the bounding box.\n    cropped = image[x0:x1, y0:y1]\n    return cropped\n\ndef crop_image4(image):\n    _,thresh = cv2.threshold(image,1,255,cv2.THRESH_BINARY)\n    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n    cnt = contours[0]\n    x,y,w,h = cv2.boundingRect(cnt)\n    crop = image[y:y+h,x:x+w]\n    return crop\n\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T10:34:47.479339Z","iopub.execute_input":"2021-12-24T10:34:47.48017Z","iopub.status.idle":"2021-12-24T10:34:47.511286Z","shell.execute_reply.started":"2021-12-24T10:34:47.480105Z","shell.execute_reply":"2021-12-24T10:34:47.510125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n","metadata":{}},{"cell_type":"markdown","source":"# sigmaX komut paradigması ile yeniden renklendirme ****tez için önemli bir kısım ****\n\nburada gri renk paletine sahip her bir yoğunluk değerinin skaler ölçüsüne göre bir renk ataması yapılmaktadır. Son satırda ise tekrardan resize yapılmakta(renklerin taşmasından dolayı filtre) ve gaussian filtre bir kez daha renkli yapı üzerine uygulanmaktadır. \n\n\nalt kısımlarda ise farklı sigma ağırlık değerleri denenerek hem optimum değer aranmış, hem de daha sonra işlenecek olan jpeg, png vb. uzantılı dosya formlarında hangi sigmanın daha efektif çalıştığı irdelenmiştir. ","metadata":{}},{"cell_type":"code","source":"def load_ben_color(path, sigmaX=10 ):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:34:47.513233Z","iopub.execute_input":"2021-12-24T10:34:47.513884Z","iopub.status.idle":"2021-12-24T10:34:47.525127Z","shell.execute_reply.started":"2021-12-24T10:34:47.513821Z","shell.execute_reply":"2021-12-24T10:34:47.523681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Alt kısmında tekrardan sigma denemeleri yapılmakta.","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"%%time\n\nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:34:47.527109Z","iopub.execute_input":"2021-12-24T10:34:47.527831Z","iopub.status.idle":"2021-12-24T10:35:04.473264Z","shell.execute_reply.started":"2021-12-24T10:34:47.527722Z","shell.execute_reply":"2021-12-24T10:35:04.472319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dpi = 80 #inch\n\n# path=f\"../input/aptos2019-blindness-detection/train_images/5c7ab966a3ee.png\" \npath=f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\" \nimage = load_ben_color(path,sigmaX=10)\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image, cmap='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:35:04.474865Z","iopub.execute_input":"2021-12-24T10:35:04.475401Z","iopub.status.idle":"2021-12-24T10:35:05.276918Z","shell.execute_reply.started":"2021-12-24T10:35:04.475319Z","shell.execute_reply":"2021-12-24T10:35:05.275807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nNUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor jj in range(5):\n    for i, (idx, row) in enumerate(df_test.sample(NUM_SAMP,random_state=SEED+jj).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, jj * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/test_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=30)\n        \n        plt.imshow(image)\n        ax.set_title('%d-%s' % (idx, row['id_code']) )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:35:05.278714Z","iopub.execute_input":"2021-12-24T10:35:05.27925Z","iopub.status.idle":"2021-12-24T10:35:22.986641Z","shell.execute_reply.started":"2021-12-24T10:35:05.279191Z","shell.execute_reply":"2021-12-24T10:35:22.985783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n'''Bonus : sigmaX=50'''\nNUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor jj in range(5):\n    for i, (idx, row) in enumerate(df_test.sample(NUM_SAMP,random_state=SEED+jj).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, jj * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/test_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=50)\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('%d-%s' % (idx, row['id_code']) )","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T10:35:22.988313Z","iopub.execute_input":"2021-12-24T10:35:22.989038Z","iopub.status.idle":"2021-12-24T10:35:52.370246Z","shell.execute_reply.started":"2021-12-24T10:35:22.988944Z","shell.execute_reply":"2021-12-24T10:35:52.369124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n# This is the old imperfect 'by-channel' color cropping code\n# this code can cause different crop among 3 channels\n\n# try cropping color image with the fixed function\n# path=f\"../input/aptos2019-blindness-detection/train_images/5c7ab966a3ee.png\"\npath=f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\"\nimage = cv2.imread(path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage = crop_image(image)\n# image = crop_image_from_gray(image)\nimage = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\nimage=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 10) ,-4 ,128)\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image)\n'''","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-12-24T11:02:00.519341Z","iopub.execute_input":"2021-12-24T11:02:00.519737Z","iopub.status.idle":"2021-12-24T11:02:00.52866Z","shell.execute_reply.started":"2021-12-24T11:02:00.519641Z","shell.execute_reply":"2021-12-24T11:02:00.526686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/diabetic-retinopathy-resized/","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:35:52.393577Z","iopub.execute_input":"2021-12-24T10:35:52.394171Z","iopub.status.idle":"2021-12-24T10:35:53.513137Z","shell.execute_reply.started":"2021-12-24T10:35:52.394114Z","shell.execute_reply":"2021-12-24T10:35:53.511734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/diabetic-retinopathy-resized/resized_train/resized_train | head","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:35:53.519008Z","iopub.execute_input":"2021-12-24T10:35:53.521838Z","iopub.status.idle":"2021-12-24T10:35:55.003127Z","shell.execute_reply.started":"2021-12-24T10:35:53.521742Z","shell.execute_reply":"2021-12-24T10:35:55.002208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_old = pd.read_csv('../input/diabetic-retinopathy-resized/trainLabels.csv')\n\ndf_old.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-24T10:35:55.006236Z","iopub.execute_input":"2021-12-24T10:35:55.006798Z","iopub.status.idle":"2021-12-24T10:35:55.065738Z","shell.execute_reply.started":"2021-12-24T10:35:55.006722Z","shell.execute_reply":"2021-12-24T10:35:55.064917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_old.loc[df_old['level'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/{row['image']}.jpeg\"\n        image = load_ben_color(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['image']) )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:35:55.06764Z","iopub.execute_input":"2021-12-24T10:35:55.068298Z","iopub.status.idle":"2021-12-24T10:36:08.88165Z","shell.execute_reply.started":"2021-12-24T10:35:55.067986Z","shell.execute_reply":"2021-12-24T10:36:08.880822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_old.loc[df_old['level'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/{row['image']}.jpeg\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n#         image = crop_image_from_gray(image)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n#         image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128)\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['image']) )","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:36:08.883306Z","iopub.execute_input":"2021-12-24T10:36:08.883866Z","iopub.status.idle":"2021-12-24T10:36:14.074364Z","shell.execute_reply.started":"2021-12-24T10:36:08.883788Z","shell.execute_reply":"2021-12-24T10:36:14.071887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ön işleme yöntemleri bu kapsamda iyi sonuç vermekte, ancak [yukarıda yaptığımız çizimdeki resim(4,1)] çok şiddetli renk tayf odaklı farklı görünmüyor. (Ya da bu çok fazla kan damarı örneği olması durumu araştırılacak).","metadata":{}},{"cell_type":"code","source":"dpi = 80 #inch\n\npath=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/31590_right.jpeg\" # fazla damar çapı vs\n# path=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/18017_left.jpeg\" \nimage = load_ben_color(path,sigmaX=30)\n# image = cv2.imread(path)\n# image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# image = crop_image1(image)\n# image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n# image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128)\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image, cmap='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:36:14.076191Z","iopub.execute_input":"2021-12-24T10:36:14.07677Z","iopub.status.idle":"2021-12-24T10:36:14.734918Z","shell.execute_reply.started":"2021-12-24T10:36:14.076715Z","shell.execute_reply":"2021-12-24T10:36:14.733921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":".## .png görüntülerin karşılaştırılması\n\nBazı resimler (örneğin, resimler (4,5-8)) ayrıntıları kaybetmiş görünüyor, .png versiyonlarında ise bu ayrıntılar gözlenmekte.","metadata":{}},{"cell_type":"code","source":"!ls ../input/retinopathy-train-2015/rescaled_train_896/rescaled_train_896/ | head","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:36:14.736736Z","iopub.execute_input":"2021-12-24T10:36:14.737294Z","iopub.status.idle":"2021-12-24T10:36:16.259061Z","shell.execute_reply.started":"2021-12-24T10:36:14.737226Z","shell.execute_reply":"2021-12-24T10:36:16.258044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dpi = 80 #inch\n\npath_jpg=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/18017_left.jpeg\" \npath_png=f\"../input/retinopathy-train-2015/rescaled_train_896/rescaled_train_896/18017_left.png\" \nimage = cv2.imread(path_png)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage = crop_image(image)\nimage = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\nimage2 =  cv2.imread(path_jpg)\nimage2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\nimage2 = crop_image(image2)\nimage2 = cv2.resize(image2, (IMG_SIZE, IMG_SIZE))\n\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1/4\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nax = fig.add_subplot(2, 2, 1, xticks=[], yticks=[])\nax.set_title('png format original' )\nplt.imshow(image, cmap='gray')\nax = fig.add_subplot(2, 2, 2, xticks=[], yticks=[])\nax.set_title('jpg format original' )\nplt.imshow(image2, cmap='gray')\n\nimage = load_ben_color(path_png,sigmaX=30)\nimage2 = load_ben_color(path_jpg,sigmaX=30)\nax = fig.add_subplot(2, 2, 3, xticks=[], yticks=[])\nax.set_title('png format transformed' )\nplt.imshow(image, cmap='gray')\nax = fig.add_subplot(2, 2, 4, xticks=[], yticks=[])\nax.set_title('jpg format transformed' )\nplt.imshow(image2, cmap='gray')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-12-24T10:36:16.262724Z","iopub.execute_input":"2021-12-24T10:36:16.263091Z","iopub.status.idle":"2021-12-24T10:36:18.814848Z","shell.execute_reply.started":"2021-12-24T10:36:16.263027Z","shell.execute_reply":"2021-12-24T10:36:18.813923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Önemli EK - RENK TAYFININ DEĞERLENDİRİLMESİ ÖNCESİ BİLGİ VERİLMELİ\n\n\n![inconsistent  estimation in diabetic retinophaty](https://i.ibb.co/6rQ2sFG/inconsistent-estimation.png)\n\nBu sorunun doğasının gürültülü olmasına dikkat edin. Bir Doktor bir gözü şiddet seviyesi 3 olarak tahmin edebilir, ancak bir diğeri seviye 1 diyebilir. Hatta bazı doktorlar seviye 5 bile diyebilir! Aşağıdaki Tensorflow zirvesindeki kanıtlara bakın. Daha fazla bilgi için bkz. https://youtu.be/oOeZ7IgEN4o?t=156 .","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}