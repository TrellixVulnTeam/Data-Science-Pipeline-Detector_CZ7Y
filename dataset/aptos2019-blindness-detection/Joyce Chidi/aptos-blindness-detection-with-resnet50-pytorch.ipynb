{"cells":[{"metadata":{},"cell_type":"markdown","source":"This is my very first Kaggle competition. Working with this very important dataset is an opportunity for me to use the skills I have learned from many different areas of Deep Learning and Python to find a solution that will be beneficial to people. \n\nFramework: PyTorch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install torchvision","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing\n\nimport os\nimport glob\nimport sys\nsys.setrecursionlimit(100000)  #this will increase the capacity of the stack \n\nimport torch\nimport torchvision\nfrom torch import nn, optim\nimport torch.nn.functional as F\n\nfrom PIL import Image, ImageFile\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n#from torch.utils.data import datasets\nfrom torchvision import models\n\nimport imageio\n\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%config IPCompleter.greedy=True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(torch.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('../input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"USE_GPU = True","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"****Loading Training Dataset****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"traindata_dir = '../input/aptos2019-blindness-detection/train_images/'\ntrain_label = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n\ntrain_label.head(10)\n#print(traindata_dir)\n\n#print(os.listdir(traindata_dir))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label[\"diagnosis\"].value_counts().plot(kind=\"pie\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_label = pd.read_csv('../input/aptos2019-blindness-detection/train.csv', header=0).iloc[:,2:4]\n#train_label.head(20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Loading Test Dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"testdata_dir = '../input/aptos2019-blindness-detection/test_images'\ntest_label = pd.read_csv(\"../input/aptos2019-blindness-detection/test.csv\", encoding='latin-1')\n\n#print(os.listdir(testdata_dir))\ntest_label.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Visualizing The Training Dataset**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=[15,15])\ni = 1\nfor img_name in train_label['id_code'][:12]:\n    img = mpimg.imread(traindata_dir + img_name + '.png')\n    plt.subplot(6,4,i)\n    plt.imshow(img)\n    i += 1\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Processing The Dataset (Train and Test data)****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class DRTrainDataset(Dataset):\n    def __init__(self, data_label, data_dir, transform):\n        super().__init__()\n        self.data_label = data_label\n        self.data_dir = data_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data_label)\n    \n    def __getitem__(self, index):       \n        img_name = self.data_label.id_code[index] + '.png'\n        label = self.data_label.diagnosis[index]          \n        img_path = os.path.join(self.data_dir, img_name)   \n            \n        image = mpimg.imread(img_path)\n        image = (image + 1) * 127.5\n        image = image.astype(np.uint8)\n        \n        image = self.transform(image)\n        \n        \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's manually view 5 random images from the train_image dataset.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import Image\n\nlistOfImageNames = ['../input/aptos2019-blindness-detection/train_images/000c1434d8d7.png',\n                    '../input/aptos2019-blindness-detection/train_images/001639a390f0.png',\n                   '../input/aptos2019-blindness-detection/train_images/002c21358ce6.png',\n                    '..//input/aptos2019-blindness-detection/train_images/005b95c28852.png',\n                    '../input/aptos2019-blindness-detection/train_images/005b95c28852.png'\n                   ]\n\nfor imageName in listOfImageNames:\n    display(Image(filename=imageName))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Data Processing***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_transform = transforms.Compose([transforms.ToPILImage(mode='RGB'),\n                                  transforms.RandomHorizontalFlip(),\n                                  transforms.Resize(265),\n                                  transforms.CenterCrop(224),\n                                  transforms.ToTensor(),\n                                     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntest_transform = transforms.Compose([transforms.ToPILImage(mode='RGB'), \n                                  transforms.Resize(265),\n                                  transforms.CenterCrop(224),\n                                  transforms.ToTensor(),\n                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrain_data = DRTrainDataset(data_label = train_label, data_dir = traindata_dir, transform = train_transform)\ntest_data = DRTrainDataset(data_label = test_label, data_dir = testdata_dir, transform = test_transform)\n\n\ntrain_loader = DataLoader(dataset = train_data, batch_size=64, shuffle=True)\n\ntest_loader = DataLoader(dataset = test_data, batch_size=64)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*****Definition of Model Architecture*****","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torchvision import datasets, transforms\n\n# Use GPU if it's available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodel = torchvision.models.resnet50()\n\nmodel.load_state_dict(torch.load(\"../input/resnet50/resnet50.pth\"))\n\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build a feed-forward network\n#I'll freeze the parameters so I don't back-propagate through them\n\nfor param in model.parameters():\n    param.requires_grad = False\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\n\nmodel.fc = nn.Linear(2048, 5)\nmodel.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.01)\nloss_func = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> **Training The Model**","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # number of epochs to train the model\n# num_epochs = 20\n\n# valid_loss_min = np.Inf # track change in validation loss\n\n# for epoch in range(1, num_epochs+1):\n\n#     # keep track of training and validation loss\n#     train_loss = 0.0\n    \n    \n#     ###################\n#     # train the model #\n#     ###################\n#     model.train()\n#     for inputs, label in train_loader:\n#         # move tensors to GPU if CUDA is available\n#         inputs, label = inputs.to(device), label.to(device)\n#         # clear the gradients of all optimized variables\n#         optimizer.zero_grad()\n#         # forward pass: compute predicted outputs by passing inputs to the model\n#         output = model(inputs)\n#         # calculate the batch loss\n#         loss = loss_func(output, label)\n#         # backward pass: compute gradient of the loss with respect to model parameters\n#         loss.backward()\n#         # perform a single optimization step (parameter update)\n#         optimizer.step()\n#         # update training loss\n#         train_loss += loss.item()*inputs.size(0)\n    \n    \n#     # print training/validation statistics \n#     print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(epoch, train_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 15\nsteps = 0\nrunning_loss = 0\nprint_every = 5\n\nloss_log=[] \n\nfor epoch in range(epochs):\n    model.train()\n        \n    for ii, (inputs, labels) in enumerate(train_loader):\n        inputs, labels = inputs.cuda(), labels.cuda()\n             \n        optimizer.zero_grad()\n        output = model(inputs)                    \n        loss = loss_func(output, labels)\n        loss.backward()\n        optimizer.step()\n        \n        if ii % 1000 == 0:\n            loss_log.append(loss.item())\n        # inside the for-loop:\n        if epoch % 10 == 9:\n          torch.save(model.state_dict(), 'train_valid_exp4-epoch{}.pth'.format(epoch+1))\n    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))\n\n      ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Model Testing and Validation***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_submission = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\ntest_data = DRTrainDataset(data_label = initial_submission, data_dir = testdata_dir, transform = test_transform)\ntest_loader = DataLoader(dataset = test_data, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Prediction\npredict = []\nmodel.eval()\n\nwith torch.no_grad():\n    for i, (inputs, _) in enumerate(test_loader):\n        inputs = inputs.cuda()\n        output = model(inputs)\n        output = output.cpu().detach().numpy()\n        predict.append(output[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_submission['diagnosis'] = np.argmax(predict, axis=1)\ninitial_submission.head(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Creating The Submission File Containing The Predictions***","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}