{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport sys\nimport random\nimport math\nimport subprocess\nfrom glob import glob\nfrom collections import OrderedDict\nimport numpy as np\nimport cv2\nfrom skimage import measure\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom matplotlib import pyplot as plt\nimport scipy.ndimage as ndi\nfrom PIL import Image\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.linear_model import LinearRegression\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nimport torch.backends.cudnn as cudnn\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.optim.optimizer import Optimizer, required\nsys.path.append(\"../input/pretrained-models/pretrained-models.pytorch-master/\")\nimport pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def scale_radius(src, img_size, padding=False):\n    x = src[src.shape[0] // 2, ...].sum(axis=1)\n    r = (x > x.mean() / 10).sum() // 2\n    yx = src.sum(axis=2)\n    region_props = measure.regionprops((yx > yx.mean() / 10).astype('uint8'))\n    yc, xc = np.round(region_props[0].centroid).astype('int')\n    x1 = max(xc - r, 0)\n    x2 = min(xc + r, src.shape[1] - 1)\n    y1 = max(yc - r, 0)\n    y2 = min(yc + r, src.shape[0] - 1)\n    dst = src[y1:y2, x1:x2]\n    dst = cv2.resize(dst, dsize=None, fx=img_size/(2*r), fy=img_size/(2*r))\n    if padding:\n        pad_x = (img_size - dst.shape[1]) // 2\n        pad_y = (img_size - dst.shape[0]) // 2\n        dst = np.pad(dst, ((pad_y, pad_y), (pad_x, pad_x), (0, 0)), 'constant')\n    return dst\n\n    \nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, img_paths, labels, transform=None, img_size=576, save_img=True):\n        self.img_paths = img_paths\n        self.labels = labels\n        self.transform = transform\n        self.img_size = img_size\n        self.save_img = save_img\n\n    def __getitem__(self, index):\n        img_path, label = self.img_paths[index], self.labels[index]\n        \n        if 'train' in img_path:\n            img = cv2.imread('../input/aptos2019-dataset/images_288_scaled/images_288_scaled/%s' %os.path.basename(img_path))\n        \n        else:\n            if os.path.exists('processed/%s' %os.path.basename(img_path)):\n                img = cv2.imread('processed/%s' %os.path.basename(img_path))\n\n            else:\n                img = cv2.imread(img_path)\n                try:\n                    img = scale_radius(img, img_size=self.img_size, padding=False)\n                except Exception as e:\n                    img = img\n                if self.save_img:\n                    cv2.imwrite('processed/%s' %os.path.basename(img_path), img)\n        \n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = Image.fromarray(img)\n\n        if self.transform is not None:\n            img = self.transform(img)\n\n        return img, label\n\n\n    def __len__(self):\n        return len(self.img_paths)\n\n\ndef get_model(model_name='resnet18', num_outputs=None, pretrained=True,\n              freeze_bn=False, dropout_p=0, **kwargs):\n\n    pretrained = 'imagenet' if pretrained else None\n    model = pretrainedmodels.__dict__[model_name](num_classes=1000,\n                                                  pretrained=pretrained)\n\n    if 'dpn' in model_name:\n        in_channels = model.last_linear.in_channels\n        model.last_linear = nn.Conv2d(in_channels, num_outputs,\n                                      kernel_size=1, bias=True)\n    else:\n        if 'resnet' in model_name:\n            model.avgpool = nn.AdaptiveAvgPool2d(1)\n        else:\n            model.avg_pool = nn.AdaptiveAvgPool2d(1)\n        in_features = model.last_linear.in_features\n        if dropout_p == 0:\n            model.last_linear = nn.Linear(in_features, num_outputs)\n        else:\n            model.last_linear = nn.Sequential(\n                nn.Dropout(p=dropout_p),\n                nn.Linear(in_features, num_outputs),\n            )\n\n    if freeze_bn:\n        for m in model.modules():\n            if isinstance(m, nn.BatchNorm2d):\n                m.weight.requires_grad = False\n                m.bias.requires_grad = False\n\n    return model\n\n\nclass RAdam(Optimizer):\n    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8, weight_decay=0):\n        defaults = dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)\n        self.buffer = [[None, None, None] for ind in range(10)]\n        super(RAdam, self).__init__(params, defaults)\n\n    def __setstate__(self, state):\n        super(RAdam, self).__setstate__(state)\n\n    def step(self, closure=None):\n\n        loss = None\n        if closure is not None:\n            loss = closure()\n\n        for group in self.param_groups:\n\n            for p in group['params']:\n                if p.grad is None:\n                    continue\n                grad = p.grad.data.float()\n                if grad.is_sparse:\n                    raise RuntimeError('RAdam does not support sparse gradients')\n\n                p_data_fp32 = p.data.float()\n\n                state = self.state[p]\n\n                if len(state) == 0:\n                    state['step'] = 0\n                    state['exp_avg'] = torch.zeros_like(p_data_fp32)\n                    state['exp_avg_sq'] = torch.zeros_like(p_data_fp32)\n                else:\n                    state['exp_avg'] = state['exp_avg'].type_as(p_data_fp32)\n                    state['exp_avg_sq'] = state['exp_avg_sq'].type_as(p_data_fp32)\n\n                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n                beta1, beta2 = group['betas']\n\n                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n\n                state['step'] += 1\n                buffered = self.buffer[int(state['step'] % 10)]\n                if state['step'] == buffered[0]:\n                    N_sma, step_size = buffered[1], buffered[2]\n                else:\n                    buffered[0] = state['step']\n                    beta2_t = beta2 ** state['step']\n                    N_sma_max = 2 / (1 - beta2) - 1\n                    N_sma = N_sma_max - 2 * state['step'] * beta2_t / (1 - beta2_t)\n                    buffered[1] = N_sma\n\n                    # more conservative since it's an approximated value\n                    if N_sma >= 5:\n                        step_size = group['lr'] * math.sqrt((1 - beta2_t) * (N_sma - 4) / (N_sma_max - 4) * (N_sma - 2) / N_sma * N_sma_max / (N_sma_max - 2)) / (1 - beta1 ** state['step'])\n                    else:\n                        step_size = group['lr'] / (1 - beta1 ** state['step'])\n                    buffered[2] = step_size\n\n                if group['weight_decay'] != 0:\n                    p_data_fp32.add_(-group['weight_decay'] * group['lr'], p_data_fp32)\n\n                # more conservative since it's an approximated value\n                if N_sma >= 5:\n                    denom = exp_avg_sq.sqrt().add_(group['eps'])\n                    p_data_fp32.addcdiv_(-step_size, exp_avg, denom)\n                else:\n                    p_data_fp32.add_(-step_size, exp_avg)\n\n                p.data.copy_(p_data_fp32)\n\n        return loss\n\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count\n\n\ndef quadratic_weighted_kappa(y_pred, y_true):\n    if torch.is_tensor(y_pred):\n        y_pred = y_pred.data.cpu().numpy()\n    if torch.is_tensor(y_true):\n        y_true = y_true.data.cpu().numpy()\n    if y_pred.shape[1] == 1:\n        y_pred = y_pred[:, 0]\n    else:\n        y_pred = np.argmax(y_pred, axis=1)\n    return metrics.cohen_kappa_score(y_pred, y_true, weights='quadratic')\n\n\ndef train(train_loader, model, criterion, optimizer, epoch):\n    losses = AverageMeter()\n    scores = AverageMeter()\n\n    model.train()\n\n    for i, (input, target) in tqdm(enumerate(train_loader), total=len(train_loader)):\n        input = input.cuda()\n        target = target.cuda()\n\n        output = model(input)\n        loss = criterion(output.view(-1), target.float())\n\n        # compute gradient and do optimizing step\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        thrs = [0.5, 1.5, 2.5, 3.5]\n        output[output < thrs[0]] = 0\n        output[(output >= thrs[0]) & (output < thrs[1])] = 1\n        output[(output >= thrs[1]) & (output < thrs[2])] = 2\n        output[(output >= thrs[2]) & (output < thrs[3])] = 3\n        output[output >= thrs[3]] = 4\n        \n        target[target < thrs[0]] = 0\n        target[(target >= thrs[0]) & (target < thrs[1])] = 1\n        target[(target >= thrs[1]) & (target < thrs[2])] = 2\n        target[(target >= thrs[2]) & (target < thrs[3])] = 3\n        target[target >= thrs[3]] = 4\n        \n        score = quadratic_weighted_kappa(output, target)\n\n        losses.update(loss.item(), input.size(0))\n        scores.update(score, input.size(0))\n\n    return losses.avg, scores.avg\n\n\ndef validate(val_loader, model, criterion):\n    losses = AverageMeter()\n    scores = AverageMeter()\n\n    # switch to evaluate mode\n    model.eval()\n\n    with torch.no_grad():\n        for i, (input, target) in tqdm(enumerate(val_loader), total=len(val_loader)):\n            input = input.cuda()\n            target = target.cuda()\n\n            output = model(input)\n            loss = criterion(output.view(-1), target.float())\n        \n            thrs = [0.5, 1.5, 2.5, 3.5]\n            output[output < thrs[0]] = 0\n            output[(output >= thrs[0]) & (output < thrs[1])] = 1\n            output[(output >= thrs[1]) & (output < thrs[2])] = 2\n            output[(output >= thrs[2]) & (output < thrs[3])] = 3\n            output[output >= thrs[3]] = 4\n            score = quadratic_weighted_kappa(output, target)\n\n            losses.update(loss.item(), input.size(0))\n            scores.update(score, input.size(0))\n\n    return losses.avg, scores.avg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs('processed', exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pseudo Labeling"},{"metadata":{"trusted":true},"cell_type":"code","source":"pseudo_probs = {}\n\naptos2019_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\naptos2019_img_paths = '../input/aptos2019-blindness-detection/train_images/' + aptos2019_df['id_code'].values + '.png'\naptos2019_labels = aptos2019_df['diagnosis'].values\n\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ndir_name = '../input/aptos2019-blindness-detection/test_images'\ntest_img_paths = dir_name + '/' + test_df['id_code'].values + '.png'\ntest_labels = np.zeros(len(test_img_paths))\n\ntest_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n\ntest_set = Dataset(\n    test_img_paths,\n    test_labels,\n    transform=test_transform)\ntest_loader = torch.utils.data.DataLoader(\n    test_set,\n    batch_size=16,\n    shuffle=False,\n    num_workers=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SE-ResNeXt50_32x4d"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel = get_model(model_name='se_resnext50_32x4d',\n                  num_outputs=1,\n                  pretrained=False,\n                  freeze_bn=True,\n                  dropout_p=0)\nmodel = model.cuda()\nmodel.eval()\n\nprobs = []\nfor fold in range(5):\n    print('Fold [%d/%d]' %(fold+1, 5))\n\n    model.load_state_dict(torch.load('../input/se-resnext50-32x4d-080922/model_%d.pth' % (fold+1)))\n    probs_fold = []\n    with torch.no_grad():\n        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            input = input.cuda()\n            output = model(input)\n\n            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n    probs_fold = np.array(probs_fold)\n    probs.append(probs_fold)\n\nprobs = np.mean(probs, axis=0)\npseudo_probs['se_resnext50_32x4d'] = probs\n\ndel model\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SE-ResNeXt101_32x4d"},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel = get_model(model_name='se_resnext101_32x4d',\n                  num_outputs=1,\n                  pretrained=False,\n                  freeze_bn=True,\n                  dropout_p=0,\n                  )\nmodel = model.cuda()\nmodel.eval()\n\nprobs = []\nfor fold in range(5):\n    print('Fold [%d/%d]' %(fold+1, 5))\n\n    model.load_state_dict(torch.load('../input/se-resnext101-32x4d-081208/model_%d.pth' % (fold+1)))\n\n    probs_fold = []\n    with torch.no_grad():\n        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            input = input.cuda()\n            output = model(input)\n\n            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n    probs_fold = np.array(probs_fold)\n    probs.append(probs_fold)\n\nprobs = np.mean(probs, axis=0)\npseudo_probs['se_resnext101_32x4d'] = probs\n\ndel model\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SENet154"},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# create model\nmodel = get_model(model_name='senet154',\n                  num_outputs=1,\n                  pretrained=False,\n                  freeze_bn=True,\n                  dropout_p=0)\nmodel = model.cuda()\nmodel.eval()\n\nprobs = []\nfor fold in range(5):\n    print('Fold [%d/%d]' %(fold+1, 5))\n\n    model.load_state_dict(torch.load('../input/senet154-082510/model_%d.pth' % (fold+1)))\n\n    probs_fold = []\n    with torch.no_grad():\n        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            input = input.cuda()\n            output = model(input)\n\n            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n    probs_fold = np.array(probs_fold)\n    probs.append(probs_fold)\n\nprobs = np.mean(probs, axis=0)\npseudo_probs['senet154'] = probs\n\ndel model\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train & Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"l1_probs = {}\n\ntrain_transform = []\ntrain_transform = transforms.Compose([\n    transforms.Resize((576, 576)),\n    transforms.RandomAffine(\n        degrees=(-180, 180),\n        scale=(0.8889, 1.0),\n        shear=(-36, 36),\n    ),\n    transforms.CenterCrop(512),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomVerticalFlip(p=0.5),\n    transforms.ColorJitter(\n        brightness=0,\n        contrast=(0.9, 1.1),\n        saturation=0,\n        hue=0),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## SE-ResNeXt50_32x4d"},{"metadata":{},"cell_type":"markdown","source":"### Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"aptos2019_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\naptos2019_img_paths = '../input/aptos2019-blindness-detection/train_images/' + aptos2019_df['id_code'].values + '.png'\naptos2019_labels = aptos2019_df['diagnosis'].values\n\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ntest_img_paths = '../input/aptos2019-blindness-detection/test_images/' + test_df['id_code'].values + '.png'\ntest_labels = 0.4 * pseudo_probs['se_resnext50_32x4d'] + 0.3 * pseudo_probs['se_resnext101_32x4d'] + 0.3 * pseudo_probs['senet154']\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\nkf = KFold(n_splits=5, shuffle=True, random_state=41)\nimg_paths = []\nlabels = []\nfor (train_idx1, val_idx1), (train_idx2, val_idx2) in zip(skf.split(aptos2019_img_paths, aptos2019_labels), kf.split(test_img_paths)):\n    img_paths.append((np.hstack((aptos2019_img_paths[train_idx1], test_img_paths[val_idx2])), aptos2019_img_paths[val_idx1]))\n    labels.append((np.hstack((aptos2019_labels[train_idx1], test_labels[val_idx2])), aptos2019_labels[val_idx1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel = get_model(model_name='se_resnext50_32x4d',\n                  num_outputs=1,\n                  pretrained=False,\n                  freeze_bn=True,\n                  dropout_p=0,\n                  )\nmodel = model.cuda()\n\ncriterion = nn.MSELoss().cuda()\n\nbest_losses = []\nbest_scores = []\n\nfor fold, ((train_img_paths, val_img_paths), (train_labels, val_labels)) in enumerate(zip(img_paths, labels)):\n    print('Fold [%d/%d]' %(fold+1, len(img_paths)))\n\n    # train\n    train_set = Dataset(\n        train_img_paths,\n        train_labels,\n        transform=train_transform,\n        img_size=576,\n        save_img=True)\n    train_loader = torch.utils.data.DataLoader(\n        train_set,\n        batch_size=16,\n        shuffle=True,\n        num_workers=2,\n    )\n\n    val_set = Dataset(\n        val_img_paths,\n        val_labels,\n        transform=val_transform,\n        save_img=True)\n    val_loader = torch.utils.data.DataLoader(\n        val_set,\n        batch_size=16,\n        shuffle=False,\n        num_workers=2)\n\n    model.load_state_dict(torch.load('../input/se-resnext50-32x4d-080922/model_%d.pth' % (fold+1)))\n\n    optimizer = RAdam(\n        filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n\n    scheduler = lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=10, eta_min=1e-5)\n    \n    os.makedirs('se_resnext50_32x4d', exist_ok=True)\n\n    best_loss = float('inf')\n    best_score = 0\n    for epoch in range(10):\n        print('Epoch [%d/%d]' % (epoch + 1, 10))\n\n        # train for one epoch\n        train_loss, train_score = train(\n            train_loader, model, criterion, optimizer, epoch)\n        # evaluate on validation set\n        val_loss, val_score = validate(val_loader, model, criterion)\n\n        scheduler.step()\n\n        print('loss %.4f - score %.4f - val_loss %.4f - val_score %.4f'\n              % (train_loss, train_score, val_loss, val_score))\n\n        if val_loss < best_loss:\n            torch.save(model.state_dict(), 'se_resnext50_32x4d/model_%d.pth' %(fold+1))\n            best_loss = val_loss\n            best_score = val_score\n            print(\"=> saved best model\")\n\n    print('val_loss:  %f' % best_loss)\n    print('val_score: %f' % best_score)\n    \ndel model\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ndir_name = '../input/aptos2019-blindness-detection/test_images'\ntest_img_paths = dir_name + '/' + test_df['id_code'].values + '.png'\ntest_labels = np.zeros(len(test_img_paths))\n\ntest_transform = transforms.Compose([\n    transforms.Resize((512, 512)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n\ntest_set = Dataset(\n    test_img_paths,\n    test_labels,\n    transform=test_transform)\ntest_loader = torch.utils.data.DataLoader(\n    test_set,\n    batch_size=16,\n    shuffle=False,\n    num_workers=2)\n\n# create model\nmodel = get_model(model_name='se_resnext50_32x4d',\n                  num_outputs=1,\n                  pretrained=False,\n                  freeze_bn=True,\n                  dropout_p=0)\nmodel = model.cuda()\nmodel.eval()\n\nprobs = []\nfor fold in range(5):\n    print('Fold [%d/%d]' %(fold+1, 5))\n\n    model.load_state_dict(torch.load('se_resnext50_32x4d/model_%d.pth' % (fold+1)))\n\n    probs_fold = []\n    with torch.no_grad():\n        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            input = input.cuda()\n            output = model(input)\n\n            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n    probs_fold = np.array(probs_fold)\n    probs.append(probs_fold)\n\nprobs = np.mean(probs, axis=0)\nl1_probs['se_resnext50_32x4d'] = probs\n\ndel model\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## SE-ResNeXt101_32x4d"},{"metadata":{},"cell_type":"markdown","source":"### Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"aptos2019_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\naptos2019_img_paths = '../input/aptos2019-blindness-detection/train_images/' + aptos2019_df['id_code'].values + '.png'\naptos2019_labels = aptos2019_df['diagnosis'].values\n\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ntest_img_paths = '../input/aptos2019-blindness-detection/test_images/' + test_df['id_code'].values + '.png'\ntest_labels = 0.4 * pseudo_probs['se_resnext50_32x4d'] + 0.3 * pseudo_probs['se_resnext101_32x4d'] + 0.3 * pseudo_probs['senet154']\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=41)\nkf = KFold(n_splits=5, shuffle=True, random_state=42)\nimg_paths = []\nlabels = []\nfor (train_idx1, val_idx1), (train_idx2, val_idx2) in zip(skf.split(aptos2019_img_paths, aptos2019_labels), kf.split(test_img_paths)):\n    img_paths.append((np.hstack((aptos2019_img_paths[train_idx1], test_img_paths[val_idx2])), aptos2019_img_paths[val_idx1]))\n    labels.append((np.hstack((aptos2019_labels[train_idx1], test_labels[val_idx2])), aptos2019_labels[val_idx1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create model\nmodel = get_model(model_name='se_resnext101_32x4d',\n                  num_outputs=1,\n                  pretrained=False,\n                  freeze_bn=True,\n                  dropout_p=0)\nmodel = model.cuda()\n\ncriterion = nn.MSELoss().cuda()\n\nbest_losses = []\nbest_scores = []\n\nfor fold, ((train_img_paths, val_img_paths), (train_labels, val_labels)) in enumerate(zip(img_paths, labels)):\n    print('Fold [%d/%d]' %(fold+1, len(img_paths)))\n\n    # train\n    train_set = Dataset(\n        train_img_paths,\n        train_labels,\n        transform=train_transform,\n        img_size=576,\n        save_img=True)\n\n    train_loader = torch.utils.data.DataLoader(\n        train_set,\n        batch_size=16,\n        shuffle=True,\n        num_workers=2)\n\n    val_set = Dataset(\n        val_img_paths,\n        val_labels,\n        transform=val_transform,\n        save_img=True)\n    val_loader = torch.utils.data.DataLoader(\n        val_set,\n        batch_size=16,\n        shuffle=False,\n        num_workers=2)\n\n    model.load_state_dict(torch.load('../input/se-resnext101-32x4d-081208/model_%d.pth' % (fold+1)))\n\n    optimizer = RAdam(\n        filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n\n    scheduler = lr_scheduler.CosineAnnealingLR(\n        optimizer, T_max=10, eta_min=1e-5)\n    \n    os.makedirs('se_resnext101_32x4d', exist_ok=True)\n\n    best_loss = float('inf')\n    best_score = 0\n    for epoch in range(10):\n        print('Epoch [%d/%d]' % (epoch + 1, 10))\n\n        # train for one epoch\n        train_loss, train_score = train(\n            train_loader, model, criterion, optimizer, epoch)\n        # evaluate on validation set\n        val_loss, val_score = validate(val_loader, model, criterion)\n\n        scheduler.step()\n\n        print('loss %.4f - score %.4f - val_loss %.4f - val_score %.4f'\n              % (train_loss, train_score, val_loss, val_score))\n\n        if val_loss < best_loss:\n            torch.save(model.state_dict(), 'se_resnext101_32x4d/model_%d.pth' %(fold+1))\n            best_loss = val_loss\n            best_score = val_score\n            print(\"=> saved best model\")\n\n    print('val_loss:  %f' % best_loss)\n    print('val_score: %f' % best_score)\n    \ndel model\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Inference"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ndir_name = '../input/aptos2019-blindness-detection/test_images'\ntest_img_paths = dir_name + '/' + test_df['id_code'].values + '.png'\ntest_labels = np.zeros(len(test_img_paths))\n\ntest_transform = transforms.Compose([\n    transforms.Resize((512,512)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n])\n\ntest_set = Dataset(\n    test_img_paths,\n    test_labels,\n    transform=test_transform)\ntest_loader = torch.utils.data.DataLoader(\n    test_set,\n    batch_size=16,\n    shuffle=False,\n    num_workers=2)\n\n# create model\nmodel = get_model(model_name='se_resnext101_32x4d',\n                  num_outputs=1,\n                  pretrained=False,\n                  freeze_bn=True,\n                  dropout_p=0)\nmodel = model.cuda()\nmodel.eval()\n\nprobs = []\nfor fold in range(5):\n    print('Fold [%d/%d]' %(fold+1, 5))\n\n    model.load_state_dict(torch.load('se_resnext101_32x4d/model_%d.pth' % (fold+1)))\n\n    probs_fold = []\n    with torch.no_grad():\n        for i, (input, _) in tqdm(enumerate(test_loader), total=len(test_loader)):\n            input = input.cuda()\n            output = model(input)\n\n            probs_fold.extend(output.data.cpu().numpy()[:, 0])\n    probs_fold = np.array(probs_fold)\n    probs.append(probs_fold)\n\nprobs = np.mean(probs, axis=0)\nl1_probs['se_resnext101_32x4d'] = probs\n\ndel model\ntorch.cuda.empty_cache()\n!nvidia-smi","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = 0.0 * l1_probs['se_resnext50_32x4d'] + 1.0 * l1_probs['se_resnext101_32x4d']\npreds2 = 0.5 * l1_probs['se_resnext50_32x4d'] + 0.5 * l1_probs['se_resnext101_32x4d']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"thrs = [0.5, 1.5, 2.5, 3.5]\npreds1[preds1 < thrs[0]] = 0\npreds1[(preds1 >= thrs[0]) & (preds1 < thrs[1])] = 1\npreds1[(preds1 >= thrs[1]) & (preds1 < thrs[2])] = 2\npreds1[(preds1 >= thrs[2]) & (preds1 < thrs[3])] = 3\npreds1[preds1 >= thrs[3]] = 4\npreds1 = preds1.astype('int')\npreds2[preds2 < thrs[0]] = 0\npreds2[(preds2 >= thrs[0]) & (preds2 < thrs[1])] = 1\npreds2[(preds2 >= thrs[1]) & (preds2 < thrs[2])] = 2\npreds2[(preds2 >= thrs[2]) & (preds2 < thrs[3])] = 3\npreds2[preds2 >= thrs[3]] = 4\npreds2 = preds2.astype('int')\n\ntest_df['diagnosis'] = preds1\ntest_df.to_csv('submission.csv', index=False)\ntest_df['diagnosis'] = preds2\ntest_df.to_csv('submission2.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm processed/*","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}