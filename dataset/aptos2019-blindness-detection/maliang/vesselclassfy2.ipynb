{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\nimport numpy as np\nimport os\nimport glob\nimport cv2\nimport csv\nimport pandas as pd\nfrom math import ceil\nfrom PIL import Image, ImageFilter\n#from scipy.misc import imresize, imsave\nimport gc\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss, confusion_matrix\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\n#from PIL import Image, ImageChops, ImageOps\n\nimport matplotlib.pyplot as plt\nfrom tensorflow.python.keras.optimizers import Adam, SGD\nfrom tensorflow.python.keras.models import Model, Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.python.keras.utils import np_utils\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\nfrom tensorflow.python.keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\nfrom tensorflow.python.keras.applications import DenseNet121, DenseNet201, DenseNet169\nfrom tensorflow.python.keras.applications.nasnet import NASNetLarge, NASNetMobile\n#from tensorflow.python.keras.models import Sequential, model_from_json\nfrom tensorflow.python.keras import layers\nfrom tensorflow.python.keras.applications.resnet50 import ResNet50\nfrom tensorflow.python.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.python.keras.layers import Flatten, Dense, Dropout, GlobalAveragePooling2D, Input\nfrom tensorflow.python.keras.utils import to_categorical\n#from keras.layers import Input, Dense, GlobalAveragePooling2D, Dropout\n#from deepaugment.deepaugment import DeepAugment\n\nval_split = .15  # if not using kfold cv\nclasses = [\"No DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferative DR\"]\nNUM_CLASSES = len(classes)\nFREEZE_LAYERS = 2\nglobal img_width\nglobal img_height\nimg_width=312\nimg_height=312\n\n\n \ndef crop(fname):\n    #img = Image.open(fname)\n    img = cv2.imread(fname) #直接读为灰度图像\n    #img = cv2.normalize(img, None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n    # 合并每一个通道\n    cropped = False\n    #img = cv2.equalizeHist(img)\n    #blurred = img.filter(ImageFilter.BLUR) 这里学长用了blur后的，可能可以更均匀的识别背景？ 我没有很明白\n    #ba = np.array(blurred)\n    if cropped:\n        ba = np.array(img)\n        h, w,_ = ba.shape\n    #这里的1.2, 32, 5, 0.8都是后续可以调整的参数。 只是暂时觉得用这个来提取背景不错。\n        left=0\n        right=0\n        uper=0\n        low=0\n        hor = ba[h//2, : ,1]\n        vect = ba[:,w//2,1]\n        for num1 in range(1,w):\n            if hor[num1]>4:\n                left = num1\n                break\n        for num2 in range(1,w):\n            if hor[w-num2]>4:\n                right = w-num2\n                break\n        for num3 in range(1,h):\n            if vect[num3]>4:\n                uper = num3\n                break\n        for num4 in range(1,h):\n            if vect[h-num4]>4:\n                low = h-num4\n                break\n        img = img[left:right,uper:low]\n    #resized = cropped.resize([img_width, img_height])\n    img = cv2.resize(img,(img_width,img_height),interpolation=cv2.INTER_CUBIC)\n    return img\n\ndef load_train():\n    n=3662\n    X_train = np.zeros((n, img_width, img_height, 3), dtype=np.float32)\n    y_train = np.zeros((n, 1), dtype=np.float32)\n    #X_train = []\n    #y_train = []\n    i=0\n    csvFile = open(\"../input/train.csv\", \"r\")\n    dict_reader = csv.DictReader(csvFile)\n    print('Loading training images...')\n    train_path='../input/train_images/'\n    for row in dict_reader:\n        flname = row['id_code'][0:12]\n        path = os.path.join(train_path,flname+'.png')\n        #print('path',path)\n        #img_obj = crop(path)\n        img = cv2.imread(path) #直接读为灰度图像\n        img = cv2.resize(img,(img_width,img_height),interpolation=cv2.INTER_CUBIC)   \n        #X_train[i] = img_array[sp[0]]\n        X_train[i] = np.array(img) \n        y_train[i] = row['diagnosis']\n        ## 图像预处理\n        #dataset_normalized\n        #clahe_equalized\n        del img\n        #adjust_gamma\n        #读入图片 + 转成RGB + resize\n        i = i+1\n        #if i>=2500:\n        #    break\n        print('sp',i)\n        #gc.collect()\n        #print('y_train',y_train)\n    gc.collect()\n    #print('Training data load time: {} seconds'.format(round(time.time() - start_time, 2)))\n    #print('y_train',y_train)\n    #imgs_std = np.std(X_train)\n    #imgs_mean = np.mean(X_train)\n    #imgs_normalized = (X_train-imgs_mean)/imgs_std\n    #for i in range(X_train.shape[0]):\n    #    X_train[i] = ((imgs_normalized[i] - np.min(imgs_normalized[i])) / (np.max(imgs_normalized[i])-np.min(imgs_normalized[i])))*255\n    #return imgs_normalized\n    return X_train, y_train\n\n\ndef build_model1():\n    densenet = DenseNet169(\n    #densenet = DenseNet121(\n    weights='imagenet',\n    #weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    #pretrained=True,\n    input_shape=(img_width,img_height,3)\n    )\n    model = Sequential()\n    model.add(densenet)\n    model.add(Dropout(0.25))\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.00001),\n        #optimizer=SGD(),\n        metrics=['accuracy']\n    )\n    \n    return model\n\ndef build_model3():\n    densenet = InceptionV3(\n    weights='imagenet',\n    #densenet = DenseNet121(\n    #weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    #pretrained=True,\n    input_shape=(img_width,img_height,3)\n    )\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.00005),\n        #optimizer=SGD(),\n        metrics=['accuracy']\n    )\n    \n    return model\n\ndef build_model4():\n    densenet = NASNetMobile(\n    weights='imagenet',\n    #densenet = DenseNet121(\n    #weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    #pretrained=True,\n    input_shape=(img_width,img_height,3)\n    )\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation='sigmoid'))\n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.0001),\n        #optimizer=SGD(),\n        metrics=['accuracy']\n    )\n    \n    return model\n\ndef build_model5():\n    densenet = ResNet50(\n    weights='imagenet',\n    #densenet = DenseNet121(\n    #weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    #pretrained=True,\n    input_shape=(img_width,img_height,3)\n    )\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation='softmax'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.0005),\n        #optimizer=SGD(),\n        metrics=['accuracy']\n    )\n    \n    return model\n\ndef build_model2():\n    net = InceptionResNetV2(include_top=False,\n                        weights='imagenet',\n                        input_tensor=None,\n                        input_shape=(img_width,img_height,3))\n    x = net.output\n    x = layers.GlobalAveragePooling2D()(x)\n    #x = Dense(1024, activation='relu')(x)\n    x = layers.Dropout(0.5)(x)\n    output_layer = layers.Dense(NUM_CLASSES, activation='softmax', name='softmax')(x)\n    net_final = Model(inputs=net.input, outputs=output_layer)\n    #for layer in net_final.layers[:FREEZE_LAYERS]:\n    #    layer.trainable = False\n    #for layer in net_final.layers[FREEZE_LAYERS:]:\n    #    layer.trainable = True\n    net_final.compile(optimizer=Adam(lr=0.0005),\n                  loss='binary_crossentropy', metrics=['accuracy'])\n    return net_final\n#print(net_final.summary())\nnet_final=build_model1()\n#print('train_target',train_target)\n#net_final=build_model1()\ntrain_data, train_target = load_train()\n\nmy_config = {\n    \"child_epochs\":10,\n    \"opt_samples\":5\n}\ntrain_target = to_categorical(train_target)\n#deepaug = DeepAugment(images=train_data, labels=train_target, config=my_config)\nprint(train_target.shape)\n\nX_train, X_valid, Y_train, Y_valid = train_test_split(train_data, train_target, test_size=val_split, random_state=8)\n#print('X_train',X_train.shape())\n#dataAugmentaion = ImageDataGenerator(rotation_range = 60, zoom_range = 0.1,featurewise_center=True,featurewise_std_normalization=True,\n#                  horizontal_flip=True,vertical_flip=True,fill_mode = \"reflect\", shear_range = 0.1,zca_whitening=True,\n#                  brightness_range=[0.8, 1.2])\ndataAugmentaion = ImageDataGenerator(\n        featurewise_std_normalization=True,\n        zoom_range=0.15,  # set range for random zoom\n        #shear_range = 0.1,\n        height_shift_range = 0.05,\n        width_shift_range = 0.1,\n        #rotation_range = 10,\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True  # randomly flip images\n    )\n\n\nearlyStopping = EarlyStopping(\n    monitor='val_loss',\n    patience=15,\n    verbose=1,\n    mode='min'\n)\n\nreduceLROnPlateau = ReduceLROnPlateau(\n    monitor='val_loss',\n    factor=0.1,\n    patience=5,\n    min_lr=0.000001,\n    verbose=1,\n    mode='min'\n)\n# training the model\n#dataAugmentaion.fit(X_train)\n\nnet_final.fit_generator(dataAugmentaion.flow(X_train, Y_train, batch_size = 16),\nvalidation_data = (X_valid, Y_valid), steps_per_epoch=ceil(3662/16),callbacks=[earlyStopping, reduceLROnPlateau],\nvalidation_steps = 0.2,epochs = 100, verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ndel X_train\ndel X_valid\ndel Y_train\ndel Y_valid\ndel train_data\ndel train_target\ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_test():\n    n=1928\n    X_test = np.zeros((n, img_width, img_height, 3), dtype=np.float32)\n    #y_test = np.zeros((n, 1), dtype=np.float32)\n    i=0\n    csvFile = open(\"../input/test.csv\", \"r\")\n    dict_reader = csv.DictReader(csvFile)\n    print('Loading testing images...')\n    train_path='../input/test_images/'\n    for row in dict_reader:\n        flname = row['id_code'][0:12]\n        path = os.path.join(train_path,flname+'.png')\n        #print('path',path)\n        #img_obj = crop(path)\n        img = cv2.imread(path) #直接读为灰度图像\n        img = cv2.resize(img,(img_width,img_height),interpolation=cv2.INTER_CUBIC)   \n        #X_train[i] = img_array[sp[0]]\n        X_test[i] = np.array(img) \n        #y_train[i] = row['diagnosis']\n        del img\n        #adjust_gamma\n        #读入图片 + 转成RGB + resize\n        i = i+1\n        #if i>=2500:\n        #    break\n        print('sp',i)\n        #gc.collect()\n        #print('y_train',y_train)\n    gc.collect()\n    return X_test\n\ntest_data = load_test()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result = net_final.predict(test_data)\nprint(test_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = np.zeros((1928, 1), dtype=np.int32)\nfor i in range(0,1928):\n    label_predict = np.argmax(test_result[i,:])\n    y_test[i] = label_predict\n\nprint(y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/sample_submission.csv')\nsubmit['diagnosis'] = y_test\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}