{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint(len(filenames))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Import Packages and Libraries**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nfrom PIL import Image\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom torchvision import transforms","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**CSV Files Pasing and Visualisation-**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"file_path1 ='../input/test.csv'\nfile_path2 ='../input/train.csv'\nfile_path3 ='../input/sample_submission.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(file_path1)\ntrain = pd.read_csv(file_path2)\nsample_submission=pd.read_csv(file_path3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape[0], test.shape[0]) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Visualisation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport matplotlib.pyplot as plt\nwith open('/kaggle/input/test_images/b16787f65d49.png', 'rb') as file:\n    img=Image.open(file)\n    plt.axis('off')\n    plt.imshow(img)\n    #print(img.size)\n\n#print(img.format)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dataset Class**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, csv_file, root_dir, transform = None, train = True):\n        self.label_frame = pd.read_csv(csv_file)\n        self.root_dir = root_dir\n        self.transform = transform\n        self.train = train\n        \n    def __len__(self):\n        return len(self.label_frame)\n    \n    def __getitem__(self, indx):\n        img_name = os.path.join(self.root_dir, self.label_frame.iloc[indx, 0] + '.png')\n        img = Image.open(img_name)\n        if self.transform:\n            img = self.transform(img)\n            \n        if self.train == True:\n            label = self.label_frame.iloc[indx, 1]\n            label = np.array([label])\n            return img, label\n        else:\n            return img, img_name           \n            ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data Preprocessing and Loading**"},{"metadata":{"trusted":true},"cell_type":"code","source":"transform = transforms.Compose([transforms.Resize((224, 224)),\n                                transforms.Grayscale(3),\n                                transforms.ToTensor(), \n                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])                                               ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = ImageDataset(\"../input/train.csv\", \"../input/train_images\", transform = transform, train = True)\ntest_data = ImageDataset(\"../input/test.csv\", \"../input/test_images\", transform = transform, train = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_loader), len(test_loader)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in train_loader:\n    img, lab = data\n    print(lab[0].shape)\n    print(img[0].shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\nfrom tqdm import tqdm_notebook","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.resnet18(pretrained=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fc = nn.Linear(512, 5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda:0\" if torch.cuda.is_available else 'cpu')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.to(device)\nloss_fn = nn.CrossEntropyLoss()\nopt = optim.Adam(model.parameters())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(lab[0].shape)\nprint(lab[9,:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in tqdm_notebook(range(5)):\n    for data in tqdm_notebook(train_loader):\n        image, label = data\n        label = label.squeeze(1)\n        image, label = image.to(device), label.to(device)\n        \n        opt.zero_grad()\n        out = model(image)\n        loss = loss_fn(out, label)\n        loss.backward()\n        opt.step()\n        torch.save(model.state_dict(), \"best_model.pth\")\n        del image, label, out\n        torch.cuda.empty_cache()\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_state_dict(torch.load(\"best_model.pth\"))\nmodel.to(device)\nmodel.eval()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"outputs = []\nfor test_img, test_filename in tqdm_notebook(test_loader):\n        test_img = test_img.to(device)\n        output = model(test_img)\n        num, ind = torch.max(output, 1)\n        output =  ind.squeeze().cpu().numpy()\n        outputs.extend(output)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test\nsubmission['diagnosis'] = outputs\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv( 'submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}