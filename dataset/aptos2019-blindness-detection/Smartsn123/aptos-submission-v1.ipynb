{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport random\nfrom scipy import ndarray\nimport skimage as sk\nfrom skimage import transform\nfrom skimage import util\nfrom copy import deepcopy\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nfrom keras import backend as K\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport cv2  # for image processing\nimport scipy.io\nimport os\n#import keras_utils\n#from keras_utils import reset_tf_session \nprint(tf.__version__)\nprint(keras.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'axes.titlesize': 'small'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 128","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import glob, pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/aptos2019-blindness-detection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv(\"../input/aptos2019-blindness-detection/train.csv\").head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_df = pd.read_csv(\"../input/aptos2019-blindness-detection/train.csv\").set_index('id_code')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(labels_df.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels_df['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images = [f for f in glob.glob(\"../input/aptos2019-blindness-detection/train_images/\" + \"*.png\")]\nlabels = [ labels_df.loc[f.split('/')[-1].split('.')[0].strip()].diagnosis for f in  images]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_ixs = set(random.choices(range(len(images)), k=6000))\ntrain_images = []\ntrain_labels = []\ntest_images = []\ntest_labels = []\nfor i in range(len(labels)):\n    if i in train_images_ixs:\n        train_images.append(images[i])\n        train_labels.append(labels[i])\n    else:\n        test_images.append(images[i])\n        test_labels.append(labels[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print (train_images_ixs)\nprint (len(train_labels), len(train_images))\nprint (len(test_labels), len(test_images))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test_labels_df = pd.read_csv(\"../input/test.csv\").set_index('id_code')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for img,lb in zip(images[:5], labels[:5]):\n    print (img, lb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom matplotlib import pyplot as plt\nimport random","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_text = ['No DR', 'Mild', 'Moderate', 'Severe', 'Proliferative DR']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images_to_display = []\nfor lb in range(5):\n    images_to_display += random.choices([ (images[ix], labels[ix]) for ix in range(len(images)) if labels[ix] == lb ] , k=10)\n\nfig = plt.figure(figsize=(25, 16))\nfor ii, (img,label) in enumerate(images_to_display):\n    ax = fig.add_subplot(5, 10, ii + 1, xticks=[], yticks=[])\n    img = cv2.imread(img)\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #img = Image.open(img_byte)\n    plt.imshow(img)\n    plt.text(0, img.shape[0], label_text[label], bbox=dict(facecolor='red', alpha=0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def adjust_gamma(image, gamma=1.0):\n    # build a lookup table mapping the pixel values [0, 255] to\n    # their adjusted gamma values\n    invGamma = 1.0 / gamma\n    table = np.array([((i / 255.0) ** invGamma) * 255 for i in np.arange(0, 256)]).astype(\"uint8\")\n    # apply gamma correction using the lookup table\n    return cv2.LUT(image, table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_contrast(img, contrast):\n        buf = img.copy()\n        f = float(131 * (contrast + 127)) / (127 * (131 - contrast))\n        alpha_c = f\n        gamma_c = 127*(1-f)\n        buf = cv2.addWeighted(buf, alpha_c, buf, 0, gamma_c)\n        return buf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preproces_image(img):\n    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    img = adjust_gamma(img, 1.5)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = add_contrast(img, 20)\n    #laplacian = cv2.Laplacian(img,cv2.CV_64F)\n    #sobelx = cv2.Sobel(img,cv2.CV_64F,1,0,ksize=5)\n    #sobely = cv2.Sobel(img,cv2.CV_64F,0,1,ksize=5)\n    return img\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(25, 16))\nfor ii, (img,label) in enumerate(images_to_display):\n    ax = fig.add_subplot(5, 10, ii + 1, xticks=[], yticks=[])\n    img = cv2.imread(img)\n    img_new = preproces_image(img)\n    #print (img.shape)\n    #img = Image.open(img_byte)\n    plt.imshow(img_new)\n    plt.text(0, img_new.shape[0], label_text[label], bbox=dict(facecolor='red', alpha=0.5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_rotation(image_array: ndarray):\n    # pick a random degree of rotation between 25% on the left and 25% on the right\n    random_degree = random.uniform(-180, 180)\n    return sk.transform.rotate(image_array, random_degree)\n\ndef random_noise(image_array: ndarray):\n    # add random noise to the image\n    return sk.util.random_noise(image_array)\n\ndef horizontal_flip(image_array: ndarray):\n    # horizontal flip doesn't need skimage, it's easy as flipping the image array of pixels !\n    return image_array[:, ::-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wts = [0.1, 0.4, 0.2 , 0.90, 0.60]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = cv2.imread(train_images[0])\nimg = preproces_image(img)\nimg = cv2.resize(img, (IMG_SIZE, IMG_SIZE) )\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_of_class = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_training_images(cur_images, cur_tags, batch_size=500):\n    while True:\n        cur_batch = []\n        cur_labels = []\n        cur_wts = []\n        for ix,image in enumerate(cur_images):\n            #print (ix,len(cur_labels))\n            label = cur_tags[ix]\n            wt = wts[label]\n            img = cv2.imread(image)\n            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n            img = adjust_gamma(img, 1.5)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = add_contrast(img, 20)\n            #img = preproces_image(img)\n            #img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n\n            new_img = deepcopy(img)\n            #new_img += cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY) \n            cur_batch.append(new_img)\n            cur_labels.append(label)\n            cur_wts.append(wt)\n            if len(cur_batch) == batch_size:\n                batch_imgs = np.stack(cur_batch, axis=0)\n                batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class )\n                yield batch_imgs,batch_targets, np.array(cur_wts)\n                cur_batch = []\n                cur_labels = []\n                cur_wts = []\n\n\n            new_img = adjust_gamma(deepcopy(img), random.uniform(0.8, 1.8))\n            #new_img += cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY) \n            cur_batch.append(new_img)\n            cur_labels.append(label)\n            cur_wts.append(wt)\n            if len(cur_batch) == batch_size:\n                batch_imgs = np.stack(cur_batch, axis=0)\n                batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class)\n                yield batch_imgs,batch_targets, np.array(cur_wts)\n                cur_batch = []\n                cur_labels = []\n                cur_wts = []\n\n            new_img = horizontal_flip(deepcopy(img))\n            #new_img += cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY) \n            cur_batch.append(new_img)\n            cur_labels.append(label)\n            cur_wts.append(wt)\n            if len(cur_batch) == batch_size:\n                batch_imgs = np.stack(cur_batch, axis=0)\n                batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class)\n                yield batch_imgs,batch_targets, np.array(cur_wts)\n                cur_batch = []\n                cur_labels = []\n                cur_wts = []\n        batch_imgs = np.stack(cur_batch, axis=0)\n        batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class )\n        yield batch_imgs,batch_targets,  np.array(cur_wts)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_testing_images(cur_images, cur_tags, batch_size=500):\n    while True:\n        cur_batch = []\n        cur_labels = []\n        cur_wts = []\n        for ix,image in enumerate(cur_images):\n            #print (ix,len(cur_labels))\n            label = cur_tags[ix]\n            wt = wts[label]\n            img = cv2.imread(image)\n            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n            img = adjust_gamma(img, 1.5)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = add_contrast(img, 20)\n            #img = preproces_image(img)\n            #img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n\n            new_img = deepcopy(img)\n            #new_img += cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY) \n            cur_batch.append(new_img)\n            cur_labels.append(label)\n            cur_wts.append(wt)\n            if len(cur_batch) == batch_size:\n                batch_imgs = np.stack(cur_batch, axis=0)\n                batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class )\n                yield batch_imgs,batch_targets\n                cur_batch = []\n                cur_labels = []\n                cur_wts = []\n\n\n            new_img = adjust_gamma(deepcopy(img), random.uniform(0.8, 1.8))\n            #new_img += cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY) \n            cur_batch.append(new_img)\n            cur_labels.append(label)\n            cur_wts.append(wt)\n            if len(cur_batch) == batch_size:\n                batch_imgs = np.stack(cur_batch, axis=0)\n                batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class)\n                yield batch_imgs,batch_targets\n                cur_batch = []\n                cur_labels = []\n                cur_wts = []\n\n            new_img = horizontal_flip(deepcopy(img))\n            #new_img += cv2.cvtColor(new_img, cv2.COLOR_BGR2GRAY) \n            cur_batch.append(new_img)\n            cur_labels.append(label)\n            cur_wts.append(wt)\n            if len(cur_batch) == batch_size:\n                batch_imgs = np.stack(cur_batch, axis=0)\n                batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class)\n                yield batch_imgs,batch_targets\n                cur_batch = []\n                cur_labels = []\n                cur_wts = []\n        batch_imgs = np.stack(cur_batch, axis=0)\n        batch_targets = keras.utils.np_utils.to_categorical(cur_labels, num_of_class )\n        yield batch_imgs,batch_targets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (len(train_images), len(train_labels))\ntrain_labels[:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for batch in generate_training_images(train_images, train_labels, 100):\n    tmp_images, labels, wts  = batch\n    print (tmp_images[0].shape, len(labels) )\n    plt.imshow(tmp_images[10])\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.densenet import DenseNet121\nfrom keras.layers import Input\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.models import load_model\nfrom IPython.display import clear_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def reset_tf_session():\n    curr_session = tf.get_default_session()\n    # close current session\n    if curr_session is not None:\n        curr_session.close()\n    # reset graph\n    K.clear_session()\n    # create new session\n    config = tf.ConfigProto()\n    config.gpu_options.allow_growth = True\n    s = tf.InteractiveSession(config=config)\n    K.set_session(s)\n    return s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_shape = (IMG_SIZE, IMG_SIZE, 3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s = reset_tf_session()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# img_in = Input(input_shape)              #input of model \n# model = DenseNet121(include_top= False , # remove  the 3 fully-connected layers at the top of the network\n#                 weights='imagenet',      # pre train weight \n#                 input_tensor= img_in, \n#                 input_shape= input_shape,\n#                 pooling ='avg') \n\n# x = model.output  \n# predictions = Dense(num_of_class, activation=\"sigmoid\", name=\"predictions\")(x)    # fuly connected layer for predict class \n# model = Model(inputs=img_in, outputs=predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INIT_LR = 5e-3  # initial learning rate\nBATCH_SIZE = 200\nEPOCHS = 200\ndef lr_scheduler(epoch):\n    return min(INIT_LR * 0.9 ** epoch, 0.00001)\n\n# callback for printing of actual learning rate used by optimizer\nclass LrHistory(keras.callbacks.Callback):\n    def on_epoch_begin(self, epoch, logs={}):\n        print(\"Learning rate:\", K.get_value(model.optimizer.lr))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_images)\nlen(test_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class PlotLearning(keras.callbacks.Callback):\n    def on_train_begin(self, logs={}):\n        self.i = 0\n        self.x = []\n        self.losses = []\n        self.val_losses = []\n        self.acc = []\n        self.val_acc = []\n        self.fig = plt.figure()\n        \n        self.logs = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch%10 == 0 and epoch > 0:\n            self.logs.append(logs)\n            self.x.append(self.i)\n            self.losses.append(logs.get('loss'))\n            self.val_losses.append(logs.get('val_loss'))\n            self.acc.append(logs.get('acc'))\n            self.val_acc.append(logs.get('val_acc'))\n            self.i += 1\n            f, (ax1, ax2) = plt.subplots(1, 2, sharex=True)\n\n            clear_output(wait=True)\n\n            ax1.set_yscale('log')\n            ax1.plot(self.x, self.losses, label=\"loss\")\n            ax1.plot(self.x, self.val_losses, label=\"val_loss\")\n            ax1.legend()\n\n            ax2.plot(self.x, self.acc, label=\"accuracy\")\n            ax2.plot(self.x, self.val_acc, label=\"validation accuracy\")\n            ax2.legend()\n\n            plt.show();\n        \nplot_losses = PlotLearning()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.compile(\n#     loss='categorical_crossentropy',  # we train 10-way classification\n#     optimizer=keras.optimizers.adamax(lr=INIT_LR),  # for SGD\n#     metrics=['accuracy']  # report accuracy during training\n# )\n\n\n#model = load_model('../input/aptos/iris_trained_model_v2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = None\nimport os\nmodel = load_model('../input/aptosv4/iris_trained_model_v3')\nprint (\"loaded existing model weights\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prepare model for fitting (loss, optimizer, etc)\n\n# model.fit_generator(epochs=EPOCHS,\n#                     generator=generate_training_images(train_images, train_labels, BATCH_SIZE),\n#                     steps_per_epoch = len(train_images) // BATCH_SIZE // 8,\n#                      validation_steps = 40,\n#                     callbacks=[keras.callbacks.LearningRateScheduler(lr_scheduler), \n#                                LrHistory(),\n#                                plot_losses],\n#                     validation_data=generate_testing_images(test_images, test_labels, BATCH_SIZE),\n#                     use_multiprocessing=True,\n#                     workers = 4,\n#                     initial_epoch=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model.save(\"./iris_trained_model_v3\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!ls ../input/aptos2019-blindness-detection","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_images = [f for f in glob.glob(\"../input/aptos2019-blindness-detection/test_images/\" + \"*.png\")]\n#labels = [ labels_df.loc[f.split('/')[-1].split('.')[0].strip()].diagnosis for f in  images]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(predict_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_predict_images(cur_images):\n    cur_batch = []\n    cur_labels = []\n    cur_wts = []\n    for ix,image in enumerate(cur_images):\n        img = cv2.imread(image)\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = adjust_gamma(img, 1.5)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = add_contrast(img, 20)\n        cur_batch.append(img)\n        cur_labels.append(image.split('/')[-1].split('.')[0])\n    return cur_batch, cur_labels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_batch, names = generate_predict_images(predict_images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(np.array(pred_batch) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fl = open('submission.csv', 'w')\nfl.write(\"id_code,diagnosis\\n\")\nfor ix, row in enumerate(predictions):\n    row = list(row)\n    fl.write(\"{},{}\\n\".format(str(names[ix]), str(row.index(max(row ))) ))\nfl.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!head -100 submission.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}