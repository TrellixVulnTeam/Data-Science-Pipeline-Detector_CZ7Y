{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-15T17:11:35.28784Z","iopub.execute_input":"2021-06-15T17:11:35.288212Z","iopub.status.idle":"2021-06-15T17:11:38.069161Z","shell.execute_reply.started":"2021-06-15T17:11:35.288134Z","shell.execute_reply":"2021-06-15T17:11:38.067236Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# To have reproducible results (Tekrarlanabilir sonuÃ§lara sahip olmak)\nseed = 5 \nimport numpy as np \nnp.random.seed(seed)\nimport tensorflow as tf\n#tf.set_random_seed(seed)\ntf.random.set_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:11:38.07152Z","iopub.execute_input":"2021-06-15T17:11:38.071874Z","iopub.status.idle":"2021-06-15T17:11:43.514793Z","shell.execute_reply.started":"2021-06-15T17:11:38.071835Z","shell.execute_reply":"2021-06-15T17:11:43.513851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"/kaggle/input/aptos2019-blindness-detection/\"","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:11:43.516578Z","iopub.execute_input":"2021-06-15T17:11:43.516877Z","iopub.status.idle":"2021-06-15T17:11:43.523769Z","shell.execute_reply.started":"2021-06-15T17:11:43.51685Z","shell.execute_reply":"2021-06-15T17:11:43.522909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path + 'train.csv', sep = ',')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:11:43.525407Z","iopub.execute_input":"2021-06-15T17:11:43.525772Z","iopub.status.idle":"2021-06-15T17:11:43.57098Z","shell.execute_reply.started":"2021-06-15T17:11:43.525735Z","shell.execute_reply":"2021-06-15T17:11:43.569886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['diagnosis'].hist()\ndf['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:11:43.572337Z","iopub.execute_input":"2021-06-15T17:11:43.572688Z","iopub.status.idle":"2021-06-15T17:11:43.761169Z","shell.execute_reply.started":"2021-06-15T17:11:43.572654Z","shell.execute_reply":"2021-06-15T17:11:43.760365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\nimport matplotlib.pyplot as plt\nimport cv2\ndef display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.axis('off')\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(df)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:11:43.763782Z","iopub.execute_input":"2021-06-15T17:11:43.764026Z","iopub.status.idle":"2021-06-15T17:11:43.769037Z","shell.execute_reply.started":"2021-06-15T17:11:43.764002Z","shell.execute_reply":"2021-06-15T17:11:43.768254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfiles = os.listdir(path + 'train_images')\n# files\nlen(files)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:11:43.770351Z","iopub.execute_input":"2021-06-15T17:11:43.771022Z","iopub.status.idle":"2021-06-15T17:11:43.783297Z","shell.execute_reply.started":"2021-06-15T17:11:43.770982Z","shell.execute_reply":"2021-06-15T17:11:43.782456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = []\nimport cv2\nfrom tqdm import tqdm_notebook as tqdm\n\nfor i in tqdm(files):\n    image = cv2.imread(path + 'train_images/' + i)\n    image = cv2.resize(image,(400,400))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    kopya = image.copy()\n    kopya = cv2.cvtColor(kopya, cv2.COLOR_RGB2GRAY)\n    blur = cv2.GaussianBlur(kopya,(5,5),0)\n    thresh = cv2.threshold(blur,10,255, cv2.THRESH_BINARY)[1]\n    kontur = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    kontur = kontur[0][0]\n    kontur = kontur[:,0,:]\n    x1 = tuple(kontur[kontur[:,0].argmin()])[0]\n    y1 = tuple(kontur[kontur[:,1].argmin()])[1]\n    x2 = tuple(kontur[kontur[:,0].argmax()])[0]\n    y2 = tuple(kontur[kontur[:,1].argmax()])[1]\n    x = int(x2-x1)*4//50\n    y = int(y2-y1)*5//50\n    kopya2 = image.copy()\n    if x2-x1 >100 and y2-y1> 100:\n        kopya2 = kopya2[y1+y : y2-y , x1+x : x2-x]\n        kopya2 = cv2.resize(kopya2,(400,400))\n    lab = cv2.cvtColor(kopya2, cv2.COLOR_RGB2LAB)\n    l,a,b = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=5.0,tileGridSize=((8,8)))\n    cl = clahe.apply(l)\n    limg = cv2.merge((cl,a,b))\n    son = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n    med_son = cv2.medianBlur(son, 3)\n    arka_plan = cv2.medianBlur(son, 37)\n    maske = cv2.addWeighted(med_son,1,arka_plan,-1,255)\n    son_img = cv2.bitwise_and(maske,med_son)\n    img_list.append(son_img)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:11:43.786163Z","iopub.execute_input":"2021-06-15T17:11:43.786514Z","iopub.status.idle":"2021-06-15T17:19:21.450277Z","shell.execute_reply.started":"2021-06-15T17:11:43.786466Z","shell.execute_reply":"2021-06-15T17:19:21.44946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_list[6])","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:21.452325Z","iopub.execute_input":"2021-06-15T17:19:21.452835Z","iopub.status.idle":"2021-06-15T17:19:21.638738Z","shell.execute_reply.started":"2021-06-15T17:19:21.452792Z","shell.execute_reply":"2021-06-15T17:19:21.637784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,12))\n\nfor i in range(12):\n    img = img_list[i]\n    fig.add_subplot(3,4,i+1)\n    plt.imshow(img)\n\nplt.tight_layout()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:21.640026Z","iopub.execute_input":"2021-06-15T17:19:21.640362Z","iopub.status.idle":"2021-06-15T17:19:23.918874Z","shell.execute_reply.started":"2021-06-15T17:19:21.640325Z","shell.execute_reply":"2021-06-15T17:19:23.917941Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd.get_dummies(df['diagnosis']).values\ny_train","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.92013Z","iopub.execute_input":"2021-06-15T17:19:23.920605Z","iopub.status.idle":"2021-06-15T17:19:23.927678Z","shell.execute_reply.started":"2021-06-15T17:19:23.920563Z","shell.execute_reply":"2021-06-15T17:19:23.926901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['diagnosis'][1]","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.928939Z","iopub.execute_input":"2021-06-15T17:19:23.929545Z","iopub.status.idle":"2021-06-15T17:19:23.938253Z","shell.execute_reply.started":"2021-06-15T17:19:23.929506Z","shell.execute_reply":"2021-06-15T17:19:23.93738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[1]","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.939644Z","iopub.execute_input":"2021-06-15T17:19:23.94024Z","iopub.status.idle":"2021-06-15T17:19:23.947784Z","shell.execute_reply.started":"2021-06-15T17:19:23.940202Z","shell.execute_reply":"2021-06-15T17:19:23.94698Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_son = np.ones(y_train.shape, dtype='uint8')\n#y_train_son = np.ones(y_train.shape, dtype=y_train.dtype)\ny_train_son","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.949265Z","iopub.execute_input":"2021-06-15T17:19:23.949876Z","iopub.status.idle":"2021-06-15T17:19:23.958886Z","shell.execute_reply.started":"2021-06-15T17:19:23.949815Z","shell.execute_reply":"2021-06-15T17:19:23.958022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny_train_son[:,4] = y_train[:,4]\ny_train_son","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.960059Z","iopub.execute_input":"2021-06-15T17:19:23.960683Z","iopub.status.idle":"2021-06-15T17:19:23.967204Z","shell.execute_reply.started":"2021-06-15T17:19:23.960647Z","shell.execute_reply":"2021-06-15T17:19:23.966098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3,-1,-1):\n    y_train_son[:,i] = np.logical_or(y_train[:,i], y_train_son[:,i+1])\n    \ny_train_son\ny_train","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.968694Z","iopub.execute_input":"2021-06-15T17:19:23.969199Z","iopub.status.idle":"2021-06-15T17:19:23.97722Z","shell.execute_reply.started":"2021-06-15T17:19:23.969165Z","shell.execute_reply":"2021-06-15T17:19:23.976216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#print(\"Original y_train:\", y_train.sum(axis=0))\n#print(\"Multilabel version:\", y_train_son.sum(axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.978563Z","iopub.execute_input":"2021-06-15T17:19:23.97911Z","iopub.status.idle":"2021-06-15T17:19:23.98264Z","shell.execute_reply.started":"2021-06-15T17:19:23.979074Z","shell.execute_reply":"2021-06-15T17:19:23.981811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.array(img_list)\nx_train.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:23.984035Z","iopub.execute_input":"2021-06-15T17:19:23.984596Z","iopub.status.idle":"2021-06-15T17:19:24.658664Z","shell.execute_reply.started":"2021-06-15T17:19:23.984554Z","shell.execute_reply":"2021-06-15T17:19:24.657681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_son.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:24.660035Z","iopub.execute_input":"2021-06-15T17:19:24.66038Z","iopub.status.idle":"2021-06-15T17:19:24.666598Z","shell.execute_reply.started":"2021-06-15T17:19:24.660344Z","shell.execute_reply":"2021-06-15T17:19:24.665709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_val , y_train, y_val = train_test_split(x_train,\n                                                   y_train_son,\n                                                   test_size=0.20,\n                                                   random_state=2019,\n                                                   shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:24.668292Z","iopub.execute_input":"2021-06-15T17:19:24.668763Z","iopub.status.idle":"2021-06-15T17:19:26.382029Z","shell.execute_reply.started":"2021-06-15T17:19:24.668721Z","shell.execute_reply":"2021-06-15T17:19:26.381146Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_val=x_val/255","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:26.383475Z","iopub.execute_input":"2021-06-15T17:19:26.383907Z","iopub.status.idle":"2021-06-15T17:19:27.791631Z","shell.execute_reply.started":"2021-06-15T17:19:26.383862Z","shell.execute_reply":"2021-06-15T17:19:27.790684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, x_val.shape , y_train.shape, y_val.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:27.795906Z","iopub.execute_input":"2021-06-15T17:19:27.797873Z","iopub.status.idle":"2021-06-15T17:19:27.807236Z","shell.execute_reply.started":"2021-06-15T17:19:27.797831Z","shell.execute_reply":"2021-06-15T17:19:27.806461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\ndata_generator = datagen.flow(x_train,y_train,batch_size=2,seed=2019)\n#data_generator = datagen.flow(x_train,y_train,batch_size=2,seed=2020)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:27.813891Z","iopub.execute_input":"2021-06-15T17:19:27.816009Z","iopub.status.idle":"2021-06-15T17:19:32.054796Z","shell.execute_reply.started":"2021-06-15T17:19:27.815967Z","shell.execute_reply":"2021-06-15T17:19:32.053818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x, y = data_generator.next()\n#y","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:32.056378Z","iopub.execute_input":"2021-06-15T17:19:32.056732Z","iopub.status.idle":"2021-06-15T17:19:32.061356Z","shell.execute_reply.started":"2021-06-15T17:19:32.056698Z","shell.execute_reply":"2021-06-15T17:19:32.059893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x.shape,y.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:19:32.062945Z","iopub.execute_input":"2021-06-15T17:19:32.063299Z","iopub.status.idle":"2021-06-15T17:19:32.070769Z","shell.execute_reply.started":"2021-06-15T17:19:32.063263Z","shell.execute_reply":"2021-06-15T17:19:32.070022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:43:22.165158Z","iopub.execute_input":"2021-06-15T17:43:22.165478Z","iopub.status.idle":"2021-06-15T17:43:30.315277Z","shell.execute_reply.started":"2021-06-15T17:43:22.165447Z","shell.execute_reply":"2021-06-15T17:43:30.314125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' ## Credits\nAll credits are due to https://github.com/qubvel/efficientnet\nThanks so much for your contribution!\n\n## Usage:\nAdding this utility script to your kernel, and you will be able to \nuse all models just like standard Keras pretrained model. For details see\nhttps://www.kaggle.com/c/aptos2019-blindness-detection/discussion/100186\n\n## Pretrained Weights\nhttps://www.kaggle.com/ratthachat/efficientnet-keras-weights-b0b5/\n'''\n\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport numpy as np\nfrom skimage.transform import resize\nimport tensorflow as tf\nimport keras.backend as K\nimport keras.layers as KL\nfrom keras.initializers import Initializer\nfrom keras.utils.generic_utils import get_custom_objects\n\nimport os\nimport re\nimport collections\nimport math\nimport six\nfrom six.moves import xrange  # pylint: disable=redefined-builtin\n\nimport keras.models as KM\nfrom keras.utils import get_file\n\nMEAN_RGB = [0.485 * 255, 0.456 * 255, 0.406 * 255]\nSTDDEV_RGB = [0.229 * 255, 0.224 * 255, 0.225 * 255]\n\nMAP_INTERPOLATION_TO_ORDER = {\n    \"nearest\": 0,\n    \"bilinear\": 1,\n    \"biquadratic\": 2,\n    \"bicubic\": 3,\n}\n\n\ndef center_crop_and_resize(image, image_size, crop_padding=32, interpolation=\"bicubic\"):\n    assert image.ndim in {2, 3}\n    assert interpolation in MAP_INTERPOLATION_TO_ORDER.keys()\n\n    h, w = image.shape[:2]\n\n    padded_center_crop_size = int(\n        (image_size / (image_size + crop_padding)) * min(h, w)\n    )\n    offset_height = ((h - padded_center_crop_size) + 1) // 2\n    offset_width = ((w - padded_center_crop_size) + 1) // 2\n\n    image_crop = image[\n        offset_height : padded_center_crop_size + offset_height,\n        offset_width : padded_center_crop_size + offset_width,\n    ]\n    resized_image = resize(\n        image_crop,\n        (image_size, image_size),\n        order=MAP_INTERPOLATION_TO_ORDER[interpolation],\n        preserve_range=True,\n    )\n\n    return resized_image\n\n\ndef preprocess_input(x):\n    assert x.ndim in (3, 4)\n    assert x.shape[-1] == 3\n\n    x = x - np.array(MEAN_RGB)\n    x = x / np.array(STDDEV_RGB)\n\n    return x\n\nclass EfficientConv2DKernelInitializer(Initializer):\n    \"\"\"Initialization for convolutional kernels.\n    The main difference with tf.variance_scaling_initializer is that\n    tf.variance_scaling_initializer uses a truncated normal with an uncorrected\n    standard deviation, whereas here we use a normal distribution. Similarly,\n    tf.contrib.layers.variance_scaling_initializer uses a truncated normal with\n    a corrected standard deviation.\n    Args:\n      shape: shape of variable\n      dtype: dtype of variable\n      partition_info: unused\n    Returns:\n      an initialization for the variable\n    \"\"\"\n\n    def __call__(self, shape, dtype=K.floatx(), **kwargs):\n        kernel_height, kernel_width, _, out_filters = shape\n        fan_out = int(kernel_height * kernel_width * out_filters)\n        return tf.random.normal(\n            shape, mean=0.0, stddev=np.sqrt(2.0 / fan_out), dtype=dtype\n        )\n\n\nclass EfficientDenseKernelInitializer(Initializer):\n    \"\"\"Initialization for dense kernels.\n    This initialization is equal to\n      tf.variance_scaling_initializer(scale=1.0/3.0, mode='fan_out',\n                                      distribution='uniform').\n    It is written out explicitly here for clarity.\n    Args:\n      shape: shape of variable\n      dtype: dtype of variable\n    Returns:\n      an initialization for the variable\n    \"\"\"\n\n    def __call__(self, shape, dtype=K.floatx(), **kwargs):\n        \"\"\"Initialization for dense kernels.\n        This initialization is equal to\n          tf.variance_scaling_initializer(scale=1.0/3.0, mode='fan_out',\n                                          distribution='uniform').\n        It is written out explicitly here for clarity.\n        Args:\n          shape: shape of variable\n          dtype: dtype of variable\n        Returns:\n          an initialization for the variable\n        \"\"\"\n        init_range = 1.0 / np.sqrt(shape[1])\n        return tf.random_uniform(shape, -init_range, init_range, dtype=dtype)\n\n\nconv_kernel_initializer = EfficientConv2DKernelInitializer()\ndense_kernel_initializer = EfficientDenseKernelInitializer()\n\n\nget_custom_objects().update(\n    {\n        \"EfficientDenseKernelInitializer\": EfficientDenseKernelInitializer,\n        \"EfficientConv2DKernelInitializer\": EfficientConv2DKernelInitializer,\n    }\n)\n\nclass Swish(KL.Layer):\n    def call(self, inputs):\n        return tf.nn.swish(inputs)\n\n\nclass DropConnect(KL.Layer):\n    def __init__(self, drop_connect_rate=0.0, **kwargs):\n        super().__init__(**kwargs)\n        self.drop_connect_rate = drop_connect_rate\n\n    def call(self, inputs, training=None):\n        def drop_connect():\n            keep_prob = 1.0 - self.drop_connect_rate\n\n            # Compute drop_connect tensor\n            batch_size = tf.shape(inputs)[0]\n            random_tensor = keep_prob\n            random_tensor += tf.random_uniform(\n                [batch_size, 1, 1, 1], dtype=inputs.dtype\n            )\n            binary_tensor = tf.floor(random_tensor)\n            output = tf.div(inputs, keep_prob) * binary_tensor\n            return output\n\n        return K.in_train_phase(drop_connect, inputs, training=training)\n\n    def get_config(self):\n        config = super().get_config()\n        config[\"drop_connect_rate\"] = self.drop_connect_rate\n        return config\n\n\nget_custom_objects().update({\"DropConnect\": DropConnect, \"Swish\": Swish})\n\n\nIMAGENET_WEIGHTS = {\n    \"efficientnet-b0\": {\n        \"name\": \"efficientnet-b0_imagenet_1000.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000.h5\",\n        \"md5\": \"bca04d16b1b8a7c607b1152fe9261af7\",\n    },\n    \"efficientnet-b0-notop\": {\n        \"name\": \"efficientnet-b0_imagenet_1000_notop.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b0_imagenet_1000_notop.h5\",\n        \"md5\": \"45d2f3b6330c2401ef66da3961cad769\",\n    },\n    \"efficientnet-b1\": {\n        \"name\": \"efficientnet-b1_imagenet_1000.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b1_imagenet_1000.h5\",\n        \"md5\": \"bd4a2b82f6f6bada74fc754553c464fc\",\n    },\n    \"efficientnet-b1-notop\": {\n        \"name\": \"efficientnet-b1_imagenet_1000_notop.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b1_imagenet_1000_notop.h5\",\n        \"md5\": \"884aed586c2d8ca8dd15a605ec42f564\",\n    },\n    \"efficientnet-b2\": {\n        \"name\": \"efficientnet-b2_imagenet_1000.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b2_imagenet_1000.h5\",\n        \"md5\": \"45b28b26f15958bac270ab527a376999\",\n    },\n    \"efficientnet-b2-notop\": {\n        \"name\": \"efficientnet-b2_imagenet_1000_notop.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b2_imagenet_1000_notop.h5\",\n        \"md5\": \"42fb9f2d9243d461d62b4555d3a53b7b\",\n    },\n    \"efficientnet-b3\": {\n        \"name\": \"efficientnet-b3_imagenet_1000.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_imagenet_1000.h5\",\n        \"md5\": \"decd2c8a23971734f9d3f6b4053bf424\",\n    },\n    \"efficientnet-b3-notop\": {\n        \"name\": \"efficientnet-b3_imagenet_1000_notop.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b3_imagenet_1000_notop.h5\",\n        \"md5\": \"1f7d9a8c2469d2e3d3b97680d45df1e1\",\n    },\n    \"efficientnet-b4\": {\n        \"name\": \"efficientnet-b4_imagenet_1000.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_imagenet_1000.h5\",\n        \"md5\": \"01df77157a86609530aeb4f1f9527949\",\n    },\n    \"efficientnet-b4-notop\": {\n        \"name\": \"efficientnet-b4_imagenet_1000_notop.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b4_imagenet_1000_notop.h5\",\n        \"md5\": \"e7c3b780f050f8f49c800f23703f285c\",\n    },\n    \"efficientnet-b5\": {\n        \"name\": \"efficientnet-b5_imagenet_1000.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b5_imagenet_1000.h5\",\n        \"md5\": \"c31311a1a38b5111e14457145fccdf32\",\n    },\n    \"efficientnet-b5-notop\": {\n        \"name\": \"efficientnet-b5_imagenet_1000_notop.h5\",\n        \"url\": \"https://github.com/qubvel/efficientnet/releases/download/v0.0.1/efficientnet-b5_imagenet_1000_notop.h5\",\n        \"md5\": \"a09b36129b41196e0bb659fd84fbdd5f\",\n    },\n}\n\n\nGlobalParams = collections.namedtuple(\n    \"GlobalParams\",\n    [\n        \"batch_norm_momentum\",\n        \"batch_norm_epsilon\",\n        \"dropout_rate\",\n        \"data_format\",\n        \"num_classes\",\n        \"width_coefficient\",\n        \"depth_coefficient\",\n        \"depth_divisor\",\n        \"min_depth\",\n        \"drop_connect_rate\",\n    ],\n)\nGlobalParams.__new__.__defaults__ = (None,) * len(GlobalParams._fields)\n\nBlockArgs = collections.namedtuple(\n    \"BlockArgs\",\n    [\n        \"kernel_size\",\n        \"num_repeat\",\n        \"input_filters\",\n        \"output_filters\",\n        \"expand_ratio\",\n        \"id_skip\",\n        \"strides\",\n        \"se_ratio\",\n    ],\n)\n# defaults will be a public argument for namedtuple in Python 3.7\n# https://docs.python.org/3/library/collections.html#collections.namedtuple\nBlockArgs.__new__.__defaults__ = (None,) * len(BlockArgs._fields)\n\n\ndef efficientnet_params(model_name):\n    \"\"\"Get efficientnet params based on model name.\"\"\"\n    params_dict = {\n        # (width_coefficient, depth_coefficient, resolution, dropout_rate)\n        \"efficientnet-b0\": (1.0, 1.0, 224, 0.2),\n        \"efficientnet-b1\": (1.0, 1.1, 240, 0.2),\n        \"efficientnet-b2\": (1.1, 1.2, 260, 0.3),\n        \"efficientnet-b3\": (1.2, 1.4, 300, 0.3),\n        \"efficientnet-b4\": (1.4, 1.8, 380, 0.4),\n        \"efficientnet-b5\": (1.6, 2.2, 456, 0.4),\n        \"efficientnet-b6\": (1.8, 2.6, 528, 0.5),\n        \"efficientnet-b7\": (2.0, 3.1, 600, 0.5),\n    }\n    return params_dict[model_name]\n\n\nclass BlockDecoder(object):\n    \"\"\"Block Decoder for readability.\"\"\"\n\n    def _decode_block_string(self, block_string):\n        \"\"\"Gets a block through a string notation of arguments.\"\"\"\n        assert isinstance(block_string, str)\n        ops = block_string.split(\"_\")\n        options = {}\n        for op in ops:\n            splits = re.split(r\"(\\d.*)\", op)\n            if len(splits) >= 2:\n                key, value = splits[:2]\n                options[key] = value\n\n        if \"s\" not in options or len(options[\"s\"]) != 2:\n            raise ValueError(\"Strides options should be a pair of integers.\")\n\n        return BlockArgs(\n            kernel_size=int(options[\"k\"]),\n            num_repeat=int(options[\"r\"]),\n            input_filters=int(options[\"i\"]),\n            output_filters=int(options[\"o\"]),\n            expand_ratio=int(options[\"e\"]),\n            id_skip=(\"noskip\" not in block_string),\n            se_ratio=float(options[\"se\"]) if \"se\" in options else None,\n            strides=[int(options[\"s\"][0]), int(options[\"s\"][1])],\n        )\n\n    def _encode_block_string(self, block):\n        \"\"\"Encodes a block to a string.\"\"\"\n        args = [\n            \"r%d\" % block.num_repeat,\n            \"k%d\" % block.kernel_size,\n            \"s%d%d\" % (block.strides[0], block.strides[1]),\n            \"e%s\" % block.expand_ratio,\n            \"i%d\" % block.input_filters,\n            \"o%d\" % block.output_filters,\n        ]\n        if block.se_ratio > 0 and block.se_ratio <= 1:\n            args.append(\"se%s\" % block.se_ratio)\n        if block.id_skip is False:\n            args.append(\"noskip\")\n        return \"_\".join(args)\n\n    def decode(self, string_list):\n        \"\"\"Decodes a list of string notations to specify blocks inside the network.\n    Args:\n      string_list: a list of strings, each string is a notation of block.\n    Returns:\n      A list of namedtuples to represent blocks arguments.\n    \"\"\"\n        assert isinstance(string_list, list)\n        blocks_args = []\n        for block_string in string_list:\n            blocks_args.append(self._decode_block_string(block_string))\n        return blocks_args\n\n    def encode(self, blocks_args):\n        \"\"\"Encodes a list of Blocks to a list of strings.\n    Args:\n      blocks_args: A list of namedtuples to represent blocks arguments.\n    Returns:\n      a list of strings, each string is a notation of block.\n    \"\"\"\n        block_strings = []\n        for block in blocks_args:\n            block_strings.append(self._encode_block_string(block))\n        return block_strings\n\n\ndef efficientnet(\n    width_coefficient=None,\n    depth_coefficient=None,\n    dropout_rate=0.2,\n    drop_connect_rate=0.2,\n):\n    \"\"\"Creates a efficientnet model.\"\"\"\n    blocks_args = [\n        \"r1_k3_s11_e1_i32_o16_se0.25\",\n        \"r2_k3_s22_e6_i16_o24_se0.25\",\n        \"r2_k5_s22_e6_i24_o40_se0.25\",\n        \"r3_k3_s22_e6_i40_o80_se0.25\",\n        \"r3_k5_s11_e6_i80_o112_se0.25\",\n        \"r4_k5_s22_e6_i112_o192_se0.25\",\n        \"r1_k3_s11_e6_i192_o320_se0.25\",\n    ]\n    global_params = GlobalParams(\n        batch_norm_momentum=0.99,\n        batch_norm_epsilon=1e-3,\n        dropout_rate=dropout_rate,\n        drop_connect_rate=drop_connect_rate,\n        data_format=\"channels_last\",\n        num_classes=1000,\n        width_coefficient=width_coefficient,\n        depth_coefficient=depth_coefficient,\n        depth_divisor=8,\n        min_depth=None,\n    )\n    decoder = BlockDecoder()\n    return decoder.decode(blocks_args), global_params\n\n\ndef get_model_params(model_name, override_params=None):\n    \"\"\"Get the block args and global params for a given model.\"\"\"\n    if model_name.startswith(\"efficientnet\"):\n        width_coefficient, depth_coefficient, input_shape, dropout_rate = efficientnet_params(\n            model_name\n        )\n        blocks_args, global_params = efficientnet(\n            width_coefficient, depth_coefficient, dropout_rate\n        )\n    else:\n        raise NotImplementedError(\"model name is not pre-defined: %s\" % model_name)\n\n    if override_params:\n        # ValueError will be raised here if override_params has fields not included\n        # in global_params.\n        global_params = global_params._replace(**override_params)\n\n    # print('global_params= %s', global_params)\n    # print('blocks_args= %s', blocks_args)\n    return blocks_args, global_params, input_shape\n\n\n\n__all__ = [\n    \"EfficientNet\",\n    \"EfficientNetB0\",\n    \"EfficientNetB1\",\n    \"EfficientNetB2\",\n    \"EfficientNetB3\",\n    \"EfficientNetB4\",\n    \"EfficientNetB5\",\n    \"EfficientNetB6\",\n    \"EfficientNetB7\",\n]\n\n\ndef round_filters(filters, global_params):\n    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n    orig_f = filters\n    multiplier = global_params.width_coefficient\n    divisor = global_params.depth_divisor\n    min_depth = global_params.min_depth\n    if not multiplier:\n        return filters\n\n    filters *= multiplier\n    min_depth = min_depth or divisor\n    new_filters = max(min_depth, int(filters + divisor / 2) // divisor * divisor)\n    # Make sure that round down does not go down by more than 10%.\n    if new_filters < 0.9 * filters:\n        new_filters += divisor\n    # print('round_filter input={} output={}'.format(orig_f, new_filters))\n    return int(new_filters)\n\n\ndef round_repeats(repeats, global_params):\n    \"\"\"Round number of filters based on depth multiplier.\"\"\"\n    multiplier = global_params.depth_coefficient\n    if not multiplier:\n        return repeats\n    return int(math.ceil(multiplier * repeats))\n\n\ndef SEBlock(block_args, global_params):\n    num_reduced_filters = max(1, int(block_args.input_filters * block_args.se_ratio))\n    filters = block_args.input_filters * block_args.expand_ratio\n    if global_params.data_format == \"channels_first\":\n        channel_axis = 1\n        spatial_dims = [2, 3]\n    else:\n        channel_axis = -1\n        spatial_dims = [1, 2]\n\n    def block(inputs):\n        x = inputs\n        x = KL.Lambda(lambda a: K.mean(a, axis=spatial_dims, keepdims=True))(x)\n        x = KL.Conv2D(\n            num_reduced_filters,\n            kernel_size=[1, 1],\n            strides=[1, 1],\n            kernel_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=True,\n        )(x)\n        x = Swish()(x)\n        # Excite\n        x = KL.Conv2D(\n            filters,\n            kernel_size=[1, 1],\n            strides=[1, 1],\n            kernel_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=True,\n        )(x)\n        x = KL.Activation(\"sigmoid\")(x)\n        out = KL.Multiply()([x, inputs])\n        return out\n\n    return block\n\n\ndef MBConvBlock(block_args, global_params, drop_connect_rate=None):\n    batch_norm_momentum = global_params.batch_norm_momentum\n    batch_norm_epsilon = global_params.batch_norm_epsilon\n\n    if global_params.data_format == \"channels_first\":\n        channel_axis = 1\n        spatial_dims = [2, 3]\n    else:\n        channel_axis = -1\n        spatial_dims = [1, 2]\n\n    has_se = (\n        (block_args.se_ratio is not None)\n        and (block_args.se_ratio > 0)\n        and (block_args.se_ratio <= 1)\n    )\n\n    filters = block_args.input_filters * block_args.expand_ratio\n    kernel_size = block_args.kernel_size\n\n    def block(inputs):\n\n        if block_args.expand_ratio != 1:\n            x = KL.Conv2D(\n                filters,\n                kernel_size=[1, 1],\n                strides=[1, 1],\n                kernel_initializer=conv_kernel_initializer,\n                padding=\"same\",\n                use_bias=False,\n            )(inputs)\n            x = KL.BatchNormalization(\n                axis=channel_axis,\n                momentum=batch_norm_momentum,\n                epsilon=batch_norm_epsilon,\n            )(x)\n            x = Swish()(x)\n        else:\n            x = inputs\n\n        x = KL.DepthwiseConv2D(\n            [kernel_size, kernel_size],\n            strides=block_args.strides,\n            depthwise_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=False,\n        )(x)\n        x = KL.BatchNormalization(\n            axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n        )(x)\n        x = Swish()(x)\n\n        if has_se:\n            x = SEBlock(block_args, global_params)(x)\n\n        # output phase\n\n        x = KL.Conv2D(\n            block_args.output_filters,\n            kernel_size=[1, 1],\n            strides=[1, 1],\n            kernel_initializer=conv_kernel_initializer,\n            padding=\"same\",\n            use_bias=False,\n        )(x)\n        x = KL.BatchNormalization(\n            axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n        )(x)\n\n        if block_args.id_skip:\n            if (\n                all(s == 1 for s in block_args.strides)\n                and block_args.input_filters == block_args.output_filters\n            ):\n                # only apply drop_connect if skip presents.\n                if drop_connect_rate:\n                    x = DropConnect(drop_connect_rate)(x)\n                x = KL.Add()([x, inputs])\n        return x\n\n    return block\n\n\ndef EfficientNet(\n    input_shape, block_args_list, global_params, input_tensor=None, include_top=True, pooling=None\n):\n    batch_norm_momentum = global_params.batch_norm_momentum\n    batch_norm_epsilon = global_params.batch_norm_epsilon\n    if global_params.data_format == \"channels_first\":\n        channel_axis = 1\n    else:\n        channel_axis = -1\n\n    # Stem part\n    if input_tensor is None:\n        inputs = KL.Input(shape=input_shape)\n    else:\n        if not K.is_keras_tensor(input_tensor):\n            inputs = KL.Input(tensor=input_tensor, shape=input_shape)\n        else:\n            inputs = input_tensor\n    x = inputs\n    x = KL.Conv2D(\n        filters=round_filters(32, global_params),\n        kernel_size=[3, 3],\n        strides=[2, 2],\n        kernel_initializer=conv_kernel_initializer,\n        padding=\"same\",\n        use_bias=False,\n    )(x)\n    x = KL.BatchNormalization(\n        axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n    )(x)\n    x = Swish()(x)\n\n    # Blocks part\n    block_idx = 1\n    n_blocks = sum([block_args.num_repeat for block_args in block_args_list])\n    drop_rate = global_params.drop_connect_rate or 0\n    drop_rate_dx = drop_rate / n_blocks\n\n    for block_args in block_args_list:\n        assert block_args.num_repeat > 0\n        # Update block input and output filters based on depth multiplier.\n        block_args = block_args._replace(\n            input_filters=round_filters(block_args.input_filters, global_params),\n            output_filters=round_filters(block_args.output_filters, global_params),\n            num_repeat=round_repeats(block_args.num_repeat, global_params),\n        )\n\n        # The first block needs to take care of stride and filter size increase.\n        x = MBConvBlock(\n            block_args, global_params, drop_connect_rate=drop_rate_dx * block_idx\n        )(x)\n        block_idx += 1\n\n        if block_args.num_repeat > 1:\n            block_args = block_args._replace(\n                input_filters=block_args.output_filters, strides=[1, 1]\n            )\n\n        for _ in xrange(block_args.num_repeat - 1):\n            x = MBConvBlock(\n                block_args, global_params, drop_connect_rate=drop_rate_dx * block_idx\n            )(x)\n            block_idx += 1\n\n    # Head part\n    x = KL.Conv2D(\n        filters=round_filters(1280, global_params),\n        kernel_size=[1, 1],\n        strides=[1, 1],\n        kernel_initializer=conv_kernel_initializer,\n        padding=\"same\",\n        use_bias=False,\n    )(x)\n    x = KL.BatchNormalization(\n        axis=channel_axis, momentum=batch_norm_momentum, epsilon=batch_norm_epsilon\n    )(x)\n    x = Swish()(x)\n\n    if include_top:\n        x = KL.GlobalAveragePooling2D(data_format=global_params.data_format)(x)\n        if global_params.dropout_rate > 0:\n            x = KL.Dropout(global_params.dropout_rate)(x)\n        x = KL.Dense(\n            global_params.num_classes, kernel_initializer=dense_kernel_initializer\n        )(x)\n        x = KL.Activation(\"softmax\")(x)\n    else:\n        if pooling == \"avg\":\n            x = KL.GlobalAveragePooling2D(data_format=global_params.data_format)(x)\n        elif pooling == \"max\":\n            x = KL.GlobalMaxPooling2D(data_format=global_params.data_format)(x)\n\n    outputs = x\n    model = KM.Model(inputs, outputs)\n\n    return model\n\n\ndef _get_model_by_name(\n    model_name, \n    input_shape=None, \n    input_tensor=None, \n    include_top=True, \n    weights=None, \n    classes=1000, \n    pooling=None\n):\n    \"\"\"Re-Implementation of EfficientNet for Keras\n    Reference:\n        https://arxiv.org/abs/1807.11626\n    Args:\n        input_shape: optional, if ``None`` default_input_shape is used\n            EfficientNetB0 - (224, 224, 3)\n            EfficientNetB1 - (240, 240, 3)\n            EfficientNetB2 - (260, 260, 3)\n            EfficientNetB3 - (300, 300, 3)\n            EfficientNetB4 - (380, 380, 3)\n            EfficientNetB5 - (456, 456, 3)\n            EfficientNetB6 - (528, 528, 3)\n            EfficientNetB7 - (600, 600, 3)\n        input_tensor: optional, if ``None`` default_input_tensor is used\n        include_top: whether to include the fully-connected\n            layer at the top of the network.\n        weights: one of `None` (random initialization),\n              'imagenet' (pre-training on ImageNet).\n        classes: optional number of classes to classify images\n            into, only to be specified if `include_top` is True, and\n            if no `weights` argument is specified.\n        pooling: optional [None, 'avg', 'max'], if ``include_top=False``\n            add global pooling on top of the network\n            - avg: GlobalAveragePooling2D\n            - max: GlobalMaxPooling2D\n    Returns:\n        A Keras model instance.\n    \"\"\"\n    if weights not in {None, \"imagenet\"}:\n        raise ValueError('Parameter `weights` should be one of [None, \"imagenet\"]')\n\n    if weights == \"imagenet\" and model_name not in IMAGENET_WEIGHTS:\n        raise ValueError(\n            \"There are not pretrained weights for {} model.\".format(model_name)\n        )\n\n    if weights == \"imagenet\" and include_top and classes != 1000:\n        raise ValueError(\n            \"If using `weights` and `include_top`\" \" `classes` should be 1000\"\n        )\n\n    block_agrs_list, global_params, default_input_shape = get_model_params(\n        model_name, override_params={\"num_classes\": classes}\n    )\n\n    if input_shape is None:\n        input_shape = (default_input_shape, default_input_shape, 3)\n        \n    model = EfficientNet(\n        input_shape,\n        block_agrs_list,\n        global_params,\n        input_tensor=input_tensor,\n        include_top=include_top,\n        pooling=pooling,\n    )\n\n    model.name = model_name\n\n    if weights:\n        if not include_top:\n            weights_name = model_name + \"-notop\"\n        else:\n            weights_name = model_name\n        weights = IMAGENET_WEIGHTS[weights_name]\n        weights_path = get_file(\n            weights[\"name\"],\n            weights[\"url\"],\n            cache_subdir=\"models\",\n            md5_hash=weights[\"md5\"],\n        )\n        model.load_weights(weights_path)\n\n    return model\n\n\ndef EfficientNetB0(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b0\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB1(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b1\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB2(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b2\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB3(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b3\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB4(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b4\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB5(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b5\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB6(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b6\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\ndef EfficientNetB7(\n    include_top=True, input_shape=None, input_tensor=None, weights=None, classes=1000, pooling=None\n):\n    return _get_model_by_name(\n        \"efficientnet-b7\",\n        include_top=include_top,\n        input_shape=input_shape,\n        input_tensor=input_tensor,\n        weights=weights,\n        classes=classes,\n        pooling=pooling,\n    )\n\n\nEfficientNetB0.__doc__ = _get_model_by_name.__doc__\nEfficientNetB1.__doc__ = _get_model_by_name.__doc__\nEfficientNetB2.__doc__ = _get_model_by_name.__doc__\nEfficientNetB3.__doc__ = _get_model_by_name.__doc__\nEfficientNetB4.__doc__ = _get_model_by_name.__doc__\nEfficientNetB5.__doc__ = _get_model_by_name.__doc__\nEfficientNetB6.__doc__ = _get_model_by_name.__doc__\nEfficientNetB7.__doc__ = _get_model_by_name.__doc__","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:42:24.789799Z","iopub.execute_input":"2021-06-15T17:42:24.790168Z","iopub.status.idle":"2021-06-15T17:42:24.880359Z","shell.execute_reply.started":"2021-06-15T17:42:24.790134Z","shell.execute_reply":"2021-06-15T17:42:24.879277Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"from efficientnet.keras import EfficientNetB5\n\nfrom keras.models import Sequential\nfrom keras import layers\n\nmodel = Sequential()\nmodel.add(EfficientNetB5(weights='imagenet',include_top=False, input_shape=(400,400,3)))\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5,activation = 'sigmoid'))\n\n\"\"\"\nefn_wg_root   = '/kaggle/input/efficientnet-keras-noisystudent-weights-b0b7/'\n\nfrom efficientnet.keras import EfficientNetB5\nfrom keras.models import Sequential\nfrom keras import layers\n\nmodel = Sequential()\neff=EfficientNetB5(include_top=False,weights=None, input_shape=(400,400,3))\neff.load_weights(efn_wg_root + 'efficientnet-b5_noisy-student_notop.h5')\nmodel.add(eff)\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5,activation = 'sigmoid'))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:43:34.903054Z","iopub.execute_input":"2021-06-15T17:43:34.903404Z","iopub.status.idle":"2021-06-15T17:43:43.020433Z","shell.execute_reply.started":"2021-06-15T17:43:34.903368Z","shell.execute_reply":"2021-06-15T17:43:43.019608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam\nmodel.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.00005),\n        metrics=['accuracy']\n    )\n#model.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.00005),metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:43:43.021931Z","iopub.execute_input":"2021-06-15T17:43:43.022256Z","iopub.status.idle":"2021-06-15T17:43:43.046109Z","shell.execute_reply.started":"2021-06-15T17:43:43.022223Z","shell.execute_reply":"2021-06-15T17:43:43.0453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\n\nlr = ReduceLROnPlateau(monitor = 'val_loss',\n                      patience = 3,\n                      verbose = 1,\n                      mode='auto',\n                      factor=0.25,\n                      min_lr=0.000001)","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:43:46.174519Z","iopub.execute_input":"2021-06-15T17:43:46.174851Z","iopub.status.idle":"2021-06-15T17:43:46.1795Z","shell.execute_reply.started":"2021-06-15T17:43:46.174816Z","shell.execute_reply":"2021-06-15T17:43:46.178338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.callbacks import (ModelCheckpoint, LearningRateScheduler,\n                                        EarlyStopping, ReduceLROnPlateau, \n                                        TensorBoard, CSVLogger)\n# defining some callbacks\ndef Call_Back():\n    # model check point\n    checkpoint = ModelCheckpoint('effB5.h5', \n                                 monitor = 'val_loss', \n                                 verbose = 0, save_best_only=True, \n                                 mode = 'min',\n                                 save_weights_only = True)\n    \n    csv_logger = CSVLogger('effB5.csv')\n\n    # reduce learning rate plateau\n    rlr = ReduceLROnPlateau(monitor = 'val_loss',\n                      patience = 3,\n                      verbose = 1,\n                      mode='auto',\n                      factor=0.25,\n                      min_lr=0.000001)\n    \n    est=EarlyStopping(monitor='val_loss',patience=5, min_delta=0.005)\n    return [checkpoint, rlr, csv_logger, est]\n    #return [checkpoint, rlr]\n\n# calling all callbacks \ncallbacks = Call_Back()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T16:57:33.935369Z","iopub.execute_input":"2021-06-15T16:57:33.935927Z","iopub.status.idle":"2021-06-15T16:57:33.943993Z","shell.execute_reply.started":"2021-06-15T16:57:33.935887Z","shell.execute_reply":"2021-06-15T16:57:33.943103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(data_generator,\n                             steps_per_epoch = 1000,\n                             epochs = 2,\n                             validation_data = (x_val,y_val),\n                             callbacks = [lr])","metadata":{"execution":{"iopub.status.busy":"2021-06-15T17:46:24.140561Z","iopub.execute_input":"2021-06-15T17:46:24.140925Z","iopub.status.idle":"2021-06-15T17:50:37.196853Z","shell.execute_reply.started":"2021-06-15T17:46:24.140893Z","shell.execute_reply":"2021-06-15T17:50:37.190707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.save('my_history.npy',history.history)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:24:13.531383Z","iopub.execute_input":"2021-06-14T12:24:13.53176Z","iopub.status.idle":"2021-06-14T12:24:13.537992Z","shell.execute_reply.started":"2021-06-14T12:24:13.531726Z","shell.execute_reply":"2021-06-14T12:24:13.53716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history=np.load('my_history.npy',allow_pickle='TRUE').item()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# convert the history.history dict to a pandas DataFrame:     \nhist_df = pd.DataFrame(history.history) \n\n# save to json:  \nhist_json_file = 'history.json' \nwith open(hist_json_file, mode='w') as f:\n    hist_df.to_json(f)\n\n# or save to csv: \nhist_csv_file = 'history.csv'\nwith open(hist_csv_file, mode='w') as f:\n    hist_df.to_csv(f)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n# plt\nfrom tensorflow.keras.utils import plot_model\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn\")\n\ndef plot_log(filename, show=True):\n\n    data = filename\n\n    fig = plt.figure(figsize=(8,10))\n    fig.subplots_adjust(top=0.95, bottom=0.05, right=0.95)\n    fig.add_subplot(211)\n    \n    for key in data.keys():\n        if key.find('loss') >= 0:  # loss\n            plt.plot(data['epoch'].values, data[key].values, label=key)\n    plt.legend()\n    plt.title('Training and Validtion Loss')\n\n    fig.add_subplot(212)\n    for key in data.keys():\n        if key.find('acc') >= 0:  # acc\n            plt.plot(data['epoch'].values, data[key].values, label=key)\n    plt.legend()\n    plt.title('Training and Validation Accuracy')\n\n    if show:\n        plt.show()\n        \n# plt\nplot_log(history)\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-13T16:08:33.180579Z","iopub.execute_input":"2021-06-13T16:08:33.18091Z","iopub.status.idle":"2021-06-13T16:08:33.320849Z","shell.execute_reply.started":"2021-06-13T16:08:33.180881Z","shell.execute_reply":"2021-06-13T16:08:33.319089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}