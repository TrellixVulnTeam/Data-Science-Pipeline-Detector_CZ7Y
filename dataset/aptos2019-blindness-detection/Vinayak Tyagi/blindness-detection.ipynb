{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Importing Libraries"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport keras\nimport cv2\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.metrics import categorical_crossentropy\nfrom keras.optimizers import Adam\nfrom keras import models\nfrom keras.layers.core import Dense , Flatten , Dropout \nfrom keras.models import Sequential\nfrom keras.layers import Activation , Conv2D , MaxPooling2D, Lambda, ZeroPadding2D, Convolution2D\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras import backend as K\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames[:2]:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"submission_names = '/kaggle/input/aptos2019-blindness-detection/sample_submission.csv'\ntrain_names = \"/kaggle/input/aptos2019-blindness-detection/train.csv\"\ntest_names = \"/kaggle/input/aptos2019-blindness-detection/test.csv\"\n\ntest_images_path = \"/kaggle/input/aptos2019-blindness-detection/test_images/\"\ntrain_images_path = \"/kaggle/input/aptos2019-blindness-detection/train_images/\"\n\ntrain_data = pd.read_csv(train_names)\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX , testX , trainY , testY = train_test_split(train_data['id_code'], train_data['diagnosis'], test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Image Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SHAPE = (120, 120, 3)\nIMAGE_SIZE = (120, 120)\n\ndef preprocess_image(image):\n    \n    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), 30), -4, 128)\n    \n    height, width, _ = image.shape\n    center_x = int(width / 2)\n    center_y = int(height / 2)\n    radius = min(center_x, center_y)\n    \n    circle_mask = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_mask, (center_x, center_y), radius, color=1, thickness=-1)\n    image = cv2.resize(cv2.bitwise_and(image, image, mask=circle_mask)[center_y - radius:center_y + radius, center_x - radius:center_x + radius], IMAGE_SIZE)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getting_image_from_path(img_id, common_path):\n    img_url = common_path + str(img_id + \".png\")\n    img = cv2.imread(img_url) # 1 = color && 0 = black&white\n    imgs =  preprocess_image(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n#     imgs = cv2.resize(img, (260, 260)) # (height, width) pixels for img resolution try 480, 640\n    return imgs\n\ndef data_maker(img_ids , labels, common_train_test_path, size):\n    img_lst = []\n    for i in img_ids[:int(size)]:\n        image = getting_image_from_path(str(i), common_train_test_path)\n        img_lst.append(image)\n        \n    return np.array(img_lst), np.array(labels[:int(size)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_imgs, train_labels = data_maker(trainX, trainY, train_images_path, len(trainY))\ntest_imgs, test_labels = data_maker(testX, testY, train_images_path, len(testY))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the Images Graph\n\nfor i in range(10):\n        if (i % 5) == 0:\n            fig, ax = plt.subplots(1,5,figsize=(25,5)) \n        else:\n            k = i\n            for j in range(5):\n                ax[j].imshow(train_imgs[k])\n                k = k + 1\n                \nprint(train_labels[:10])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## One Hot Encoding"},{"metadata":{"trusted":true},"cell_type":"code","source":"def one_hot_encoding(list_of_target):\n    one_hot_lst = []\n    lst = pd.get_dummies(np.unique(list_of_target))\n#     print(lst)\n    for i in list_of_target:\n        a = np.array(lst[i]).tolist()\n        one_hot_lst.append(a)\n    return np.array(one_hot_lst) , len(lst)\n\n# print(one_hot_encoding(train_labels))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Code for saving & loading back the training model****"},{"metadata":{"trusted":true},"cell_type":"code","source":"def saving_model(model_instance,model_name):\n    model_instance.save(str(model_name))\n    print(\"Model Saved\")\n    \ndef loading_model(model_name):\n    model = models.load_model(str(model_name))\n    print(\"Model Loaded\")\n    return model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Making the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"SHAPE = (120, 120,3)\n###################################\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape= SHAPE))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(5, activation='softmax'))\n\n####################################\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy']) # try optimizer sgd with vgg16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization=True,\n        rotation_range=20,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=True)\n\ndatagen.fit(train_imgs)\nhistory = model.fit_generator(datagen.flow(train_imgs, one_hot_encoding(train_labels)[0], batch_size=32),\n                        steps_per_epoch=len(train_imgs) / 32,\n                        validation_data=datagen.flow(test_imgs, one_hot_encoding(test_labels)[0], batch_size=32),\n                        validation_steps=len(test_imgs) / 32,\n                        epochs=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"1. 1. ## Plotting accuracy & loss graph"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Accuracy Graph\nplt.plot(history.epoch, history.history['acc'] , label=\"acc\")\nplt.plot(history.epoch, history.history['val_acc'] , label = \"val_acc\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loss Graph\nplt.plot(history.epoch, history.history['loss'] , label = \"loss\")\nplt.plot(history.epoch, history.history['val_loss'] , label = \"val_loss\")\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now Making the Prediction and Evaluating the model\n\nscore = model.evaluate(test_imgs, one_hot_encoding(test_labels)[0], verbose = 0)\nprint(\"%s: %.2f%%\" % (\"acc\", score[1]*100))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicting the model and Saving in CSV"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_file = pd.read_csv(submission_names)\nsub_file.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length = len(sub_file['diagnosis'])\n#####################\n\nval = data_maker(sub_file[\"id_code\"], sub_file['diagnosis'], test_images_path, length)[0]\npred = model.predict_classes(val)\nprint(pred[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(data = {\"id_code\": sub_file[\"id_code\"], \"diagnosis\": pred })\ndf.to_csv(\"submission.csv\", sep = \",\", index = False)\nprint(\"Done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Can do TTA (test time Augmentation) and blending of model for better accuracy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}