{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1><center>APTOS 2019 Blindness Detection</center></h1>\n<h2><center>Detect diabetic retinopathy to stop blindness before it's too late</center></h2>\n<center><img src=\"https://raw.githubusercontent.com/dimitreOliveira/MachineLearning/master/Kaggle/APTOS%202019%20Blindness%20Detection/aux_img.png\"></center>\n\nIn this synchronous Kernels-only competition, you'll build a machine learning model to speed up disease detection. Youâ€™ll work with thousands of images collected in rural areas to help identify diabetic retinopathy automatically. If successful, you will not only help to prevent lifelong blindness, but these models may be used to detect other sorts of diseases in the future, like glaucoma and macular degeneration.\n\nIn this notebook, I will be using basic deep learning and transfer learning (ResNet50) to create a baseline.\n##### Image source: http://cceyemd.com/diabetes-and-eye-exams/"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # showing and rendering figures\nfrom skimage.io import imread\nfrom glob import glob\n#from IPython.display import Image as Image1 # show image real-time\nfrom PIL import Image as Image # convert image to numpy array\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\nimport sys\n\n%matplotlib inline\n# Any results you write to the current directory are saved as output.\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input, Dense, Activation, Conv2D, BatchNormalization\nfrom keras.layers import Flatten, MaxPooling2D, Dropout, Conv2DTranspose\nfrom keras.layers import Concatenate, Lambda\nfrom keras.models import Model\nfrom keras.utils import to_categorical\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nimport os\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read data\nIMG_SIZE = 512\n\n\ntrain_data = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\nprint('{} samples'.format(len(train_data)))\n\ntest_data = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nprint('{} tests'.format(len(test_data)))\n\ntrain_ids = train_data['id_code'].values\ntrain_labels = train_data['diagnosis'].values\n\ntest_ids = test_data['id_code'].values\n\n\n\nTRAIN_PATH = '../input/aptos2019-blindness-detection/train_images'\nTEST_PATH = '../input/aptos2019-blindness-detection/test_images'\n\n\"\"\"\nArguments:\n    num_batch: start from 1\n\"\"\"\ndef batch_read(num_batch, batch_size=100):\n    x_train, y_train = [], []\n    for i in tqdm(range(batch_size)):\n        img_file = os.path.join(TRAIN_PATH, train_ids[i+batch_size*(num_batch-1)]+'.png')\n        img = cv2.imread(img_file)\n        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        img = img.astype('float32')/255\n        x_train.append(img)\n        \n        label = train_labels[i+batch_size*(num_batch-1)]\n        label = to_categorical(label, num_classes=5)\n        y_train.append(label)\n        \n    return np.array(x_train), np.array(y_train)\n\nx_train, y_train = batch_read(1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# randomly show 15 images\n\nplt.figure(figsize=(20, 15))\nidx = np.random.randint(0, len(x_train), size=15)\n\nfor i in range(15):\n    plt.subplot(3, 5, i+1)\n    im = x_train[idx[i]][..., [2, 1, 0]] # tranverse RGB to \n    im = plt.imshow(im)\n    plt.title('image %s label %s' % (i+1, np.argmax(y_train[idx[i]])))\nplt.show()\nprint(im.get_cmap().name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# show label distrubtion\nimport seaborn as sns\nplt.figure(figsize=(20, 10))\nsns.set(style='darkgrid')\nax= sns.countplot(x='diagnosis', data=train_data, palette=\"GnBu_d\") # accept pd.DataFrame\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##### Legend\n- 0 - No DR\n- 1 - Mild\n- 2 - Moderate\n- 3 - Severe\n- 4 - Proliferative DR "},{"metadata":{"trusted":true},"cell_type":"code","source":"# get ground truth \nfile = os.path.join(TRAIN_PATH, train_ids[0]+'.png')\nimg = cv2.imread(file, 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# customized metric.accuracy\ndef mean_iou(y_true, y_pred):\n    prec = []\n    for t in np.arange(0.5, 1.0, 0.05):\n        y_pred_ = tf.to_int32(y_pred > t) # tensor 1 / 0\n        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n        K.get_session().run(tf.local_variables_initializer())\n        with tf.control_dependencies([up_opt]):\n            score = tf.identity(score) # no change\n        prec.append(score)\n    return K.mean(K.stack(prec), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use mnist to test model\nmnist = pd.read_csv('../input/digit-recognizer/train.csv')\nlabels = mnist['label'].values\nm_images = mnist.drop(['label'], axis=1).values.reshape(-1, 28, 28, 1)\nm_labels = to_categorical(labels, num_classes=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"(imageSize - kernel_size) / strides + 1"},{"metadata":{},"cell_type":"markdown","source":"# Build and train our neural network\nNext we build our U-Net model, loosely based on [U-Net: Convolutional Networks for Biomedical Image Segmentation](https://arxiv.org/pdf/1505.04597.pdf) and very similar to [this repo](https://github.com/jocicmarko/ultrasound-nerve-segmentation) from the Kaggle Ultrasound Nerve Segmentation competition.\n\n![](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unet in paper\n# dimension needs to be resized by tf.image.resize_images\n'''\ninput = Input(shape=(image_size, image_size, 3))\ninput = cv2.resize(a_images[0], (image_size, image_size))\ninput = input.reshape(1, image_size, image_size, 3)\ninput = tf.Variable(input)\n\n## Contracting\n# 1 - 64\nconv1 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1))(input) # (?, 570, 570, 64)\nconv1 = BatchNormalization()(conv1)\nconv1 = Activation('relu')(conv1)\n\nconv1 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1))(conv1) # (?, 568, 568, 64)\nconv1 = BatchNormalization()(conv1)\nconv1 = Activation('relu')(conv1)\n\npool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv1) # (?, 284, 284, 64)\n\n\n# 2 - 128\nconv2 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1))(pool1) # (?, 282, 282, 128)\nconv2 = BatchNormalization()(conv2)\nconv2 = Activation('relu')(conv2)\n\nconv2 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1))(conv2) # (?, 280, 280, 128)\nconv2 = BatchNormalization()(conv2)\nconv2 = Activation('relu')(conv2)\n\npool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv2) # (?, 140, 140, 128)\n\n\n# 3 - 256\nconv3 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1))(pool2) # (?, 138, 138, 256)\nconv3 = BatchNormalization()(conv3)\nconv3 = Activation('relu')(conv3)\n\nconv3 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1))(conv3) # (?, 136, 136, 256)\nconv3 = BatchNormalization()(conv3)\nconv3 = Activation('relu')(conv3)\n\npool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv3) # (?, 68, 68, 256)\n\n\n# 4 - 512\nconv4 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1))(pool3) # (?, 66, 66, 512)\nconv4 = BatchNormalization()(conv4)\nconv4 = Activation('relu')(conv4)\n\nconv4 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1))(conv4) # (?, 64, 64, 512)\nconv4 = BatchNormalization()(conv4)\nconv4 = Activation('relu')(conv4)\n\npool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv4) # (?, 32, 32, 512)\n\n\n# 5 - 1024\nconv5 = Conv2D(filters=1024, kernel_size=(3, 3), strides=(1, 1))(pool4) # (?, 30, 30, 1024)\nconv5 = BatchNormalization()(conv5)\nconv5 = Activation('relu')(conv5)\n\nconv5 = Conv2D(filters=1024, kernel_size=(3, 3), strides=(1, 1))(conv5) # (?, 28, 28, 1024)\nconv5 = BatchNormalization()(conv5)\nconv5 = Activation('relu')(conv5)\n\n\n## Expansive\n# 1 - 512\ndconv1 = Conv2DTranspose(filters=512, kernel_size=(2, 2), strides=(2, 2))(conv5)  #(56, 56, 512)\ndconv1 = BatchNormalization()(dconv1)\ndconv1 = Activation('relu')(dconv1)\n\ncat1 = Concatenate(axis=3)([conv4, dconv1]) # (56, 56, 1024)\n\nconv6 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1))(cat1) # (54, 54, 512)\nconv6 = BatchNormalization()(conv6)\nconv6 = Activation('relu')(conv6)\n\nconv6 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1))(conv6) # (52, 52, 512)\nconv6 = BatchNormalization()(conv6)\nconv6 = Activation('relu')(conv6)\n\nse=tf.Session()\nse.run(tf.global_variables_initializer())\nresult = se.run(dconv1)\nprint(result.shape)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Unet in paper (revised)\n# 1) image_size should be 32n(5 layers)\n# 2) Conv2D use padding='same' to avoid concatenate problem\n\nimage_size = 512\n\ninput = Input(shape=(image_size, image_size, 3))\n\n## Contracting\n# 1 - 64\nconv1 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same')(input) # (?, 512, 512, 64)\nconv1 = BatchNormalization()(conv1)\nconv1 = Activation('relu')(conv1)\n\nconv1 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv1) # (?, 512, 512, 64)\nconv1 = BatchNormalization()(conv1)\nconv1 = Activation('relu')(conv1)\n\npool1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv1) # (?, 256, 256, 64)\n\n\n# 2 - 128\nconv2 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same')(pool1) # (?, 256, 256, 128)\nconv2 = BatchNormalization()(conv2)\nconv2 = Activation('relu')(conv2)\n\nconv2 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv2) # (?, 256, 256, 128)\nconv2 = BatchNormalization()(conv2)\nconv2 = Activation('relu')(conv2)\n\npool2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv2) # (?, 128, 128, 128)\n\n\n# 3 - 256\nconv3 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same')(pool2) # (?, 128, 128, 256)\nconv3 = BatchNormalization()(conv3)\nconv3 = Activation('relu')(conv3)\n\nconv3 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv3) # (?, 128, 128, 256)\nconv3 = BatchNormalization()(conv3)\nconv3 = Activation('relu')(conv3)\n\npool3 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv3) # (?, 64, 64, 256)\n\n\n# 4 - 512\nconv4 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same')(pool3) # (?, 64, 64, 512)\nconv4 = BatchNormalization()(conv4)\nconv4 = Activation('relu')(conv4)\n\nconv4 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv4) # (?, 64, 64, 512)\nconv4 = BatchNormalization()(conv4)\nconv4 = Activation('relu')(conv4)\n\npool4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='same')(conv4) # (?, 32, 32, 512)\n\n\n# 5 - 1024\nconv5 = Conv2D(filters=1024, kernel_size=(3, 3), strides=(1, 1), padding='same')(pool4) # (?, 32, 32, 1024)\nconv5 = BatchNormalization()(conv5)\nconv5 = Activation('relu')(conv5)\n\nconv5 = Conv2D(filters=1024, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv5) # (?, 32, 32, 1024)\nconv5 = BatchNormalization()(conv5)\nconv5 = Activation('relu')(conv5)\n\n\n## Expansive\n# 1 - 512\ndconv1 = Conv2DTranspose(filters=512, kernel_size=(2, 2), strides=(2, 2))(conv5)  #(64, 64, 512)\ndconv1 = BatchNormalization()(dconv1)\ndconv1 = Activation('relu')(dconv1)\n\ncat1 = Concatenate(axis=3)([conv4, dconv1]) # (64, 64, 1024)\n\nconv6 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same')(cat1) # (64, 64, 512)\nconv6 = BatchNormalization()(conv6)\nconv6 = Activation('relu')(conv6)\n\nconv6 = Conv2D(filters=512, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv6) # (64, 64, 512)\nconv6 = BatchNormalization()(conv6)\nconv6 = Activation('relu')(conv6)\n\n\n# 2 - 256\ndconv2 = Conv2DTranspose(filters=256, kernel_size=(2, 2), strides=(2, 2))(conv6) # (128, 128, 256)\ndconv2 = BatchNormalization()(dconv2)\ndconv2 = Activation('relu')(dconv2)\n\ncat2 = Concatenate(axis=3)([conv3, dconv2]) # (128, 128, 512)\n\nconv7 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same')(cat2) # (128, 128, 256)\nconv7 = BatchNormalization()(conv7)\nconv7 = Activation('relu')(conv7)\n\nconv7 = Conv2D(filters=256, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv7) # (128, 128, 256)\nconv7 = BatchNormalization()(conv7)\nconv7 = Activation('relu')(conv7)\n\n\n# 3 - 128\ndconv3= Conv2DTranspose(filters=128, kernel_size=(2, 2), strides=(2, 2))(conv7) # (256, 256, 128)\ndconv3 = BatchNormalization()(dconv3)\ndconv3 = Activation('relu')(dconv3)\n\ncat3 = Concatenate(axis=3)([conv2, dconv3]) # (256, 256, 256)\n\nconv8 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same')(cat3) # (256, 256, 128)\nconv8 = BatchNormalization()(conv8)\nconv8 = Activation('relu')(conv8)\n\nconv9 = Conv2D(filters=128, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv8) # (256, 256, 128)\nconv9 = BatchNormalization()(conv9)\nconv9 = Activation('relu')(conv9)\n\n\n# 4 - 64\ndconv4 = Conv2DTranspose(filters=64, kernel_size=(2, 2), strides=(2, 2))(conv9) # (512, 512, 64)\ndconv4 = BatchNormalization()(dconv4)\ndconv4 = Activation('relu')(dconv4)\n\ncat4 = Concatenate(axis=3)([conv1, dconv4]) # (512, 512, 128)\n\nconv10 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same')(cat4) # (512, 512, 64)\nconv10 = BatchNormalization()(conv10)\nconv10 = Activation('relu')(conv10)\n\nconv11 = Conv2D(filters=64, kernel_size=(3, 3), strides=(1, 1), padding='same')(conv10) # (512, 512, 64)\nconv11 = BatchNormalization()(conv11)\nconv11 = Activation('relu')(conv11)\n\noutput = Conv2D(filters=1, kernel_size=(1, 1), activation='sigmoid')(conv11) # (512, 512, 1)\n\nprint(output)\n\nmodel  = Model(input, output)\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam',\n              metrics=mean_iou)\nmodel.summary()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n\nearlystopping = EarlyStopping(patience=5, verbose=1)\ncheckpoint = ModelCheckpoint('model-aptos.h5', verbose=1, save_best_only=True)\n\nhistory = model.fit(a_images, a_labels, epochs=30, batch_size=2, validation_split=0.1, callbacks=[earlystopping, checkpoint])\n\nplt.plot(history.history['acc'])\nplt.title('Accuracy')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.title('Loss')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## IoU(Intersection Over Union)\n<center>\n    <figure>\n        <img src=\"https://www.pyimagesearch.com/wp-content/uploads/2016/09/iou_equation.png\" />\n        <figcaption>Source: https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/</figcaption>\n    </figure>\n</center>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tnrange, tqdm_notebook\nfrom time import sleep\n\nfor i in tnrange(10, desc='1st loop'):\n    sleep(1)\n    \nfor j in tqdm_notebook(range(100), desc='2nd loop'):\n    sleep(0.01)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}