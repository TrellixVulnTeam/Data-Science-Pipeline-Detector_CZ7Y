{"cells":[{"metadata":{},"cell_type":"markdown","source":"Just vote from these models below:\n- **EfficientNet v1 by pytorch:**  \n  Eye -- EfficientNet Pytorch[LB 0.777] written by Chanhu  \n  https://www.kaggle.com/chanhu/eye-efficientnet-pytorch-lb-0-777\n    \n- **EfficientNet v2 by fastai: **   \n  Starter kernel for > 0.79  \n  https://www.kaggle.com/drhabib/starter-kernel-for-0-79\n\n- **Resnet101 by pytorch:**  \n  very simple pytorch training [0.59+] written by Abhishek Thakur  \n  https://www.kaggle.com/abhishek/very-simple-pytorch-training-0-59\n\n- **DenseNet by keras: **   \n  APTOS 2019: DenseNet Keras Starter  \n  https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter\n    \n- **Resnet50 by fastai:  **  \n  fast.ai starter with ResNet 50 written by Anna Novikova  \n  https://www.kaggle.com/demonplus/fast-ai-starter-with-resnet-50\n\n\nAnd about the voting code, I learned it from here and did some changes:  \n- **aptos_Vote**    \nhttps://www.kaggle.com/ahoukang/aptos-vote"},{"metadata":{},"cell_type":"markdown","source":"# EfficientNet_v2"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\nimport torch\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n%matplotlib inline  \nfrom sklearn.model_selection import StratifiedKFold\nfrom joblib import load, dump\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom torchvision import models as md\nfrom torch import nn\nfrom torch.nn import functional as F\nimport re\nimport math\nimport collections\nfrom functools import partial\nfrom torch.utils import model_zoo\nfrom sklearn import metrics\nfrom collections import Counter\nimport json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"package_path = '../input/efficientnet/efficientnet-pytorch/EfficientNet-PyTorch/'\nsys.path.append(package_path)\n\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making model\n# md_ef = EfficientNet.from_pretrained('efficientnet-b5', num_classes=1)\n\nnum_classes = 1\n\nmd_ef = EfficientNet.from_name('efficientnet-b5')\nmd_ef.load_state_dict(torch.load('../input/efficientnet-pytorch/efficientnet-b5-586e6cc6.pth'))\nin_features = md_ef._fc.in_features\nmd_ef._fc = nn.Linear(in_features, num_classes)\nmd_ef.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#copying weighst to the local directory \n!mkdir models\n!cp '../input/kaggle-public/abcdef.pth' 'models'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_df():\n    base_image_dir = os.path.join('..', 'input/aptos2019-blindness-detection/')\n    train_dir = os.path.join(base_image_dir,'train_images/')\n    df = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\n    df['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\n    df = df.drop(columns=['id_code'])\n    df = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n    test_df = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n    return df, test_df\n\ndf, test_df = get_df()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#you can play around with tfms and image sizes\nbs = 64\nsz = 224\ntfms = get_transforms(do_flip=True,flip_vert=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_df(df=df,path='./',cols='path') \n        .split_by_rand_pct(0.2) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .transform(tfms,size=sz,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=bs,num_workers=4) \n        .normalize(imagenet_stats)  \n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def qk(y_pred, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_pred), y, weights='quadratic'), device='cuda:0')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                model_dir=\"models\").to_fp16()\n\nlearn.data.add_test(ImageList.from_df(test_df,\n                                      '../input/aptos2019-blindness-detection',\n                                      folder='test_images',\n                                      suffix='.png'))\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Try to fit model here:\n> learn.fit_one_cycle(10, 1e-3)"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('abcdef');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://www.kaggle.com/abhishek/optimizer-for-quadratic-weighted-kappa\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_subm(learn=learn, coefficients=[0.5, 1.5, 2.5, 3.5]):\n    opt = OptimizedRounder()\n    preds,y = learn.get_preds(DatasetType.Test)\n    tst_pred = opt.predict(preds, coefficients)\n    tst_pred = tst_pred.astype(int)\n    return tst_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = run_subm()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resnet101"},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\npackage_dir = \"../input/pretrained-models/pretrained-models/pretrained-models.pytorch-master/\"\nsys.path.insert(0, package_dir)\nimport numpy as np\nimport pandas as pd\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nfrom torchvision import transforms\nimport os\nimport pretrainedmodels\n\ndevice = torch.device(\"cuda:0\")\nImageFile.LOAD_TRUNCATED_IMAGES = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTest(Dataset):\n    def __init__(self, csv_file, transform):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join('../input/aptos2019-blindness-detection/test_images', self.data.loc[idx, 'id_code'] + '.png')\n        image = Image.open(img_name)\n        image = self.transform(image)\n        return {'image': image}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = pretrainedmodels.__dict__['resnet101'](pretrained=None)\n\nmodel.avg_pool = nn.AdaptiveAvgPool2d(1)\nmodel.last_linear = nn.Sequential(\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.25),\n                          nn.Linear(in_features=2048, out_features=2048, bias=True),\n                          nn.ReLU(),\n                          nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n                          nn.Dropout(p=0.5),\n                          nn.Linear(in_features=2048, out_features=1, bias=True),\n                         )\nmodel.load_state_dict(torch.load(\"../input/mmmodel/model.bin\"))\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\nmodel.eval()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\ntest_dataset = RetinopathyDatasetTest(csv_file='../input/aptos2019-blindness-detection/sample_submission.csv',\n                                      transform=test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tta(test_dataset, batch_size=32, shuffle=False, num_workers=4):\n    test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=num_workers)\n    test_preds = np.zeros((len(test_dataset), 1))\n    tk = tqdm(test_data_loader)\n    \n    for i, x_batch in enumerate(tk):\n        x_batch = x_batch['image']\n        pred = model(x_batch.to(device))\n        test_preds[i*32:(i+1)*32] = pred.detach().cpu().squeeze().numpy().ravel().reshape(-1, 1)\n    \n    return test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1, 6):\n    locals()['test_preds{}'.format(i)] = tta(test_dataset) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds2 = (test_preds1 + test_preds2 + test_preds3 + test_preds4 + test_preds5) / 5.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(preds2):\n    if pred < coef[0]:\n        preds2[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        preds2[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        preds2[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        preds2[i] = 3\n    else:\n        preds2[i] = 4","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# EfficientNet v1"},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\nfrom os.path import isfile\n# import torch.nn.init as init\nimport torch\nimport torch.nn as nn\nimport numpy as np\nimport pandas as pd \nimport os\nfrom PIL import Image\n# from PIL import ImageFilter\n# print(os.listdir(\"../input\"))\n# from sklearn.model_selection import train_test_split, StratifiedKFold\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\n# from torch.optim import Adam, SGD, RMSprop\nimport time\n# from torch.autograd import Variable\n# import torch.functional as F\nfrom tqdm import tqdm\n# from sklearn import metrics\n# import urllib\n# import pickle\n# from torchvision import models\n# import seaborn as sns\nimport random\nimport sys","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"package_path = '../input/efficientnet/efficientnet-pytorch/EfficientNet-PyTorch/'\nsys.path.append(package_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## EfficientNet是谷歌开源的新模型。\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seed_everything(1234)\nTTA         = 5\nnum_classes = 1\nIMG_SIZE    = 384","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = '../input/aptos2019-blindness-detection/test_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def expand_path(p):\n    p = str(p)\n    if isfile(test + p + \".png\"):\n        return test + (p + \".png\")\n    return p","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(Dataset):\n    \n    def __init__(self, dataframe, transform=None):\n        self.df = dataframe\n        self.transform = transform\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):\n        \n        label = self.df.diagnosis.values[idx]\n        label = np.expand_dims(label, -1)\n        \n        p = self.df.id_code.values[idx]\n        p_path = expand_path(p)\n        image = cv2.imread(p_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = crop_image_from_gray(image)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 30) ,-4 ,128)\n        image = transforms.ToPILImage()(image)\n        \n        if self.transform:\n            image = self.transform(image)\n        \n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transform = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation((-120, 120)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n\ntestset        = MyDataset(pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv'), \n                 transform=test_transform)\ntest_loader    = torch.utils.data.DataLoader(testset, batch_size=16, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = EfficientNet.from_name('efficientnet-b0')\nin_features = model._fc.in_features\nmodel._fc = nn.Linear(in_features, num_classes)\nmodel.load_state_dict(torch.load('../input/enet0802/weight_best_0802.pt'))\nmodel.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntest_pred = np.zeros((len(sample), 1))\nmodel.eval()\n\nfor _ in range(TTA):\n    with torch.no_grad():\n        for i, data in tqdm(enumerate(test_loader)):\n            images, _ = data\n            images = images.cuda()\n            pred = model(images)\n            test_pred[i * 16:(i + 1) * 16] += pred.detach().cpu().squeeze().numpy().reshape(-1, 1)\n        \noutput = test_pred / TTA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef = [0.57, 1.37, 2.57, 3.57]\n\nfor i, pred in enumerate(output):\n    if pred < coef[0]:\n        output[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        output[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        output[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        output[i] = 3\n    else:\n        output[i] = 4\n        \npreds3 = output","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DesNet v2"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, load_model\nfrom keras.layers import (Activation, Dropout, Flatten, Dense, GlobalMaxPooling2D,\n                          BatchNormalization, Input, Conv2D, GlobalAveragePooling2D,concatenate,Concatenate)\nfrom keras.callbacks import ModelCheckpoint\nfrom keras import metrics\nfrom keras.optimizers import Adam \nfrom keras import backend as K\nfrom keras.models import load_model\nimport keras\nfrom keras.models import Model\n\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image, ImageOps\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\n#from keras.applications.resnet50 import preprocess_input\nfrom keras.applications.densenet import DenseNet121,DenseNet169\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score, cohen_kappa_score\nfrom keras.utils import Sequence\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nimport imgaug as ia\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"../input\"))\n\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nSIZE = 300\nNUM_CLASSES = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model(input_shape, n_out):\n    input_tensor = Input(shape=input_shape)\n    base_model = DenseNet121(include_top=False,\n                   weights=None,\n                   input_tensor=input_tensor)\n    base_model.load_weights(\"../input/densenet-keras/DenseNet-BC-121-32-no-top.h5\")\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n    x = Dense(1024, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    final_output = Dense(n_out, activation='softmax', name='final_output')(x)\n    model = Model(input_tensor, final_output) \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n\nmodel = load_model('../input/densenet_v2_0817_2/densenet_v2_0817_2.h5')\npreds4 = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reference:https://www.kaggle.com/CVxTz/cnn-starter-nasnet-mobile-0-9709-lb \nfor i, name in tqdm(enumerate(submit['id_code']), total=len(submit)):\n    path = os.path.join('../input/aptos2019-blindness-detection/test_images/', name+'.png')\n    image = cv2.imread(path)\n    image = cv2.resize(image, (SIZE, SIZE))\n    X = np.array((image[np.newaxis])/255)\n    score_predict=((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist()\n    label_predict = np.argmax(score_predict)\n    preds4.append(label_predict)\n\npreds4 = np.array(preds4) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ResNet50"},{"metadata":{"trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport scipy as sp\n\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nfrom fastai.callbacks import *\n\nimport PIL\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Set seed for all\ndef seed_everything(seed=1358):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_everything()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = Path('../input/aptos2019-blindness-detection')\n\ndf = pd.read_csv(PATH/'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/resnet50/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# copy pretrained weights for resnet50 to the folder fastai will search by default\nPath('/tmp/.cache/torch/checkpoints/').mkdir(exist_ok=True, parents=True)\n!cp '../input/resnet50/resnet50.pth' '/tmp/.cache/torch/checkpoints/resnet50-19c8e357.pth'\n\n#copying weighst to the local directory \n!mkdir kaggle\n!cp '../input/resnet50-0823/resnet50_0823.pth' '/kaggle/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 512\n\ndef _load_format(path, convert_mode, after_open)->Image:\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0), 10) ,-4 ,128)\n                    \n    return Image(pil2tensor(image, np.float32).div_(255)) #return fastai Image format\n\nvision.data.open_image = _load_format\n    \nsrc = (\n    ImageList.from_df(df,PATH,folder='train_images',suffix='.png')\n        .split_by_rand_pct(0.2, seed=42)\n        .label_from_df(cols='diagnosis',label_cls=FloatList)    \n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=0.10, max_zoom=1.3, max_warp=0.0, max_lighting=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv(PATH/'sample_submission.csv')\nsample_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Definition of Quadratic Kappa\nfrom sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')\n\ndata = (\n    src.transform(tfms,size=224)\n    .databunch()\n    .normalize(imagenet_stats)\n)\n\nlearn = cnn_learner(data, base_arch=models.resnet50 ,metrics=[quadratic_kappa],model_dir='/kaggle',pretrained=True)\nlearn.data.add_test(ImageList.from_df(sample_df,PATH,folder='test_images',suffix='.png'))\nlearn.load('resnet50_0823')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds,y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optR = OptimizedRounder()\n\ncoefficients = [0.563203, 1.400153, 2.43412,  3.439786]\ntest_predictions = optR.predict(preds, coefficients)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds5 = test_predictions.astype(int)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ensemble"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds1 = preds1.flatten()\npreds2 = preds2.flatten()\npreds3 = preds3.flatten()\npreds4 = preds4.flatten()\npreds5 = preds5.flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = [0.783, 0.750, 0.783, 0.741, 0.738]\nweight = [0.23, 0.195, 0.23, 0.175, 0.170]\npredsData = weight[0]*preds1 + weight[1]*preds2 + weight[2]*preds3 + weight[3]*preds4 + weight[4]*preds5\n\ncoef = [0.5, 1.5, 2.5, 3.5]\nfor i, pred in enumerate(predsData):\n    if pred < coef[0]:\n        predsData[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        predsData[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        predsData[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        predsData[i] = 3\n    else:\n        predsData[i] = 4\nsubmission = pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\nsubmission.diagnosis = predsData.astype(int)\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}