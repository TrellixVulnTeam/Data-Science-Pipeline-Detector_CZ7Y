{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom PIL import Image\nimport glob\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport cv2\nimport csv\nimport os\nimport tensorflow as tf\nimport scipy.misc\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.applications.resnet_v2 import preprocess_input, decode_predictions\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom tensorflow.keras.models import Model, load_model\n# from resnets_utils import *\nfrom tensorflow.keras.initializers import random_uniform, glorot_uniform, constant, identity\nfrom tensorflow.python.framework.ops import EagerTensor\nfrom matplotlib.pyplot import imshow\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n# from test_utils import summary, comparator\n# import public_tests\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n#path='/kaggle/input/aptos2019-blindness-detection/train_images'\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-30T00:08:35.493771Z","iopub.execute_input":"2021-09-30T00:08:35.494444Z","iopub.status.idle":"2021-09-30T00:08:40.172734Z","shell.execute_reply.started":"2021-09-30T00:08:35.494346Z","shell.execute_reply":"2021-09-30T00:08:40.171875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Read_training_data():\n    path_training_imgs='/kaggle/input/aptos2019-blindness-detection/train_images'\n    path_training_lbls='/kaggle/input/aptos2019-blindness-detection/train.csv'\n    train_image_list=np.zeros((3662,256,256,3))\n    train_lbls_list=np.zeros((1,3662))\n    i=0\n    j=0\n\n    with open(path_training_lbls, 'r') as file:\n                reader = csv.reader(file)\n                for row in reader:\n                    if(row[1]=='diagnosis'):\n                        continue\n                    train_lbls_list[0][j]=int(row[1])\n                    j=j+1\n    Y_train =tf.keras.utils.to_categorical(train_lbls_list, num_classes=5, dtype=\"float32\")\n    print(Y_train.shape)\n    for dirname, _, filenames in os.walk(path_training_imgs):\n        for filename in filenames:\n            image_path=os.path.join(dirname, filename)\n            img = cv2.imread(image_path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img,(256,256))\n#             img=np.asarray(img)\n#             img=img.reshape(224,224,3)\n            train_image_list[i]=img\n            i=i+1\n\n#     print(training_image_list.shape)\n#     for dirname, _, filenames in os.walk(path_training_lbls):\n    return train_image_list , Y_train","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:08:40.174594Z","iopub.execute_input":"2021-09-30T00:08:40.174899Z","iopub.status.idle":"2021-09-30T00:08:40.186893Z","shell.execute_reply.started":"2021-09-30T00:08:40.174832Z","shell.execute_reply":"2021-09-30T00:08:40.185722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, X_lbls=Read_training_data()\nprint(X.shape, X_lbls.shape)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:08:40.188318Z","iopub.execute_input":"2021-09-30T00:08:40.188724Z","iopub.status.idle":"2021-09-30T00:15:02.479511Z","shell.execute_reply.started":"2021-09-30T00:08:40.188683Z","shell.execute_reply":"2021-09-30T00:15:02.477754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D , GaussianDropout\nfrom tensorflow.keras import regularizers, optimizers\nk=4\ns=2\nmodel = Sequential()\nmodel.add(Conv2D(input_shape=(256,256,3),filters=16,kernel_size=(k,k),padding=\"valid\"))\nmodel.add(Conv2D(filters = 16,kernel_size=(k,k),strides=(s,s),padding = 'valid', activation ='relu', input_shape = (224,224,3)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2),strides=(s,s)))\nmodel.add(Conv2D(filters = 64, kernel_size=(k,k),strides=(s,s),padding = 'Same'))\nmodel.add(Conv2D(filters = 64, kernel_size=(k,k),strides=(s,s),padding = 'Same' ))\nmodel.add(Conv2D(filters = 64, kernel_size=(k,k),strides=(s,s),padding = 'Same', activation ='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2,2), strides=(s,s)))\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu', kernel_initializer='he_normal'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(5, activation = \"softmax\"))","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:15:02.481814Z","iopub.execute_input":"2021-09-30T00:15:02.482199Z","iopub.status.idle":"2021-09-30T00:15:04.677163Z","shell.execute_reply.started":"2021-09-30T00:15:02.482156Z","shell.execute_reply":"2021-09-30T00:15:04.676416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.optimizers import RMSprop,Adam\noptimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999,amsgrad=True,clipnorm=1.,clipvalue=0.5)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:15:04.678503Z","iopub.execute_input":"2021-09-30T00:15:04.678763Z","iopub.status.idle":"2021-09-30T00:15:04.685232Z","shell.execute_reply.started":"2021-09-30T00:15:04.678729Z","shell.execute_reply":"2021-09-30T00:15:04.684366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = optimizer , loss = \"categorical_crossentropy\", metrics=[\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:15:04.686811Z","iopub.execute_input":"2021-09-30T00:15:04.687095Z","iopub.status.idle":"2021-09-30T00:15:04.703488Z","shell.execute_reply.started":"2021-09-30T00:15:04.687061Z","shell.execute_reply":"2021-09-30T00:15:04.70265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:15:04.706299Z","iopub.execute_input":"2021-09-30T00:15:04.706585Z","iopub.status.idle":"2021-09-30T00:15:04.720103Z","shell.execute_reply.started":"2021-09-30T00:15:04.706549Z","shell.execute_reply":"2021-09-30T00:15:04.71896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 20  # for better result increase the epochs\nbatch_size = 20","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:15:04.721875Z","iopub.execute_input":"2021-09-30T00:15:04.722369Z","iopub.status.idle":"2021-09-30T00:15:04.730264Z","shell.execute_reply.started":"2021-09-30T00:15:04.722157Z","shell.execute_reply":"2021-09-30T00:15:04.728713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X,X_lbls[0],batch_size=20, epochs=50)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:15:04.731311Z","iopub.execute_input":"2021-09-30T00:15:04.731532Z","iopub.status.idle":"2021-09-30T00:19:19.590148Z","shell.execute_reply.started":"2021-09-30T00:15:04.73151Z","shell.execute_reply":"2021-09-30T00:19:19.588209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit = pd.read_csv('/kaggle/input/aptos2019-blindness-detection/sample_submission.csv')\npredicted = []","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:19:19.596207Z","iopub.execute_input":"2021-09-30T00:19:19.598332Z","iopub.status.idle":"2021-09-30T00:19:19.63334Z","shell.execute_reply.started":"2021-09-30T00:19:19.598286Z","shell.execute_reply":"2021-09-30T00:19:19.632542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\nfor i, name in tqdm(enumerate(submit['id_code'])):\n    path = os.path.join('/kaggle/input/aptos2019-blindness-detection/test_images/', name+'.png')\n    image = cv2.imread(path)\n    #print(path)\n    image = cv2.resize(image, (256, 256))\n    X = np.array((image[np.newaxis])/255)\n   # print(X[0][150])\n   # print(((model.predict(X).ravel()*model.predict(X[:, ::-1, :, :]).ravel()*model.predict(X[:, ::-1, ::-1, :]).ravel()*model.predict(X[:, :, ::-1, :]).ravel())**0.25).tolist())\n    score_predict=model.predict(X)\n    print(score_predict)\n    label_predict = np.argmax(score_predict)\n    predicted.append(str(label_predict))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.idle":"2021-09-30T00:22:29.702567Z","shell.execute_reply.started":"2021-09-30T00:19:57.780992Z","shell.execute_reply":"2021-09-30T00:22:29.700646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submit['diagnosis'] = predicted\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:22:36.696901Z","iopub.execute_input":"2021-09-30T00:22:36.69748Z","iopub.status.idle":"2021-09-30T00:22:36.726121Z","shell.execute_reply.started":"2021-09-30T00:22:36.697434Z","shell.execute_reply":"2021-09-30T00:22:36.725386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(predicted)","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:19:20.313059Z","iopub.status.idle":"2021-09-30T00:19:20.31392Z","shell.execute_reply.started":"2021-09-30T00:19:20.313603Z","shell.execute_reply":"2021-09-30T00:19:20.313629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2021-09-30T00:19:20.315033Z","iopub.status.idle":"2021-09-30T00:19:20.315897Z","shell.execute_reply.started":"2021-09-30T00:19:20.315543Z","shell.execute_reply":"2021-09-30T00:19:20.315567Z"},"trusted":true},"execution_count":null,"outputs":[]}]}