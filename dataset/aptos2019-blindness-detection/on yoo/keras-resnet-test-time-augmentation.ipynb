{"cells":[{"metadata":{},"cell_type":"markdown","source":"**라이브러리 임포트**\n\nStages Of Diabetic Retinopathy\n\nNO DR\nMild\nModerate\nServere\nProliferative DR"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\n\nimport cv2\nimport PIL\nimport gc\nimport psutil\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow import set_random_seed\nfrom tqdm import tqdm\nfrom math import ceil\nimport math\nimport sys\n\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator, load_img, array_to_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.applications.resnet50 import ResNet50, preprocess_input\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Input\nfrom keras.layers import Dropout, Flatten, Dense\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.activations import softmax, relu, elu\nfrom keras.optimizers import Adam, rmsprop, RMSprop,SGD\nfrom keras.layers import BatchNormalization\nfrom tqdm import tqdm\ngc.enable()\n\nprint(os.listdir(\"../input/\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**변수 설정**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"SEED = 7\nnp.random.seed(SEED)\nset_random_seed(SEED)\ndir_path = \"../input/aptos2019-blindness-detection/\"\nIMG_DIM = 299  # 224\nBATCH_SIZE = 12\nCHANNEL_SIZE = 3\nNUM_EPOCHS = 60\nTRAIN_DIR = 'train_images'\nTEST_DIR = 'test_images'\nFREEZE_LAYERS = 2  # freeze the first this many layers for training\nCLASSS = {0: \"No DR\", 1: \"Mild\", 2: \"Moderate\", 3: \"Severe\", 4: \"Proliferative DR\"}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**데이터 가져오기**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(os.path.join(dir_path, \"train.csv\"))\ndf_test = pd.read_csv(os.path.join(dir_path, \"test.csv\"))\nNUM_CLASSES = df_train['diagnosis'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training set has {} samples and {} classes.\".format(df_train.shape[0], df_train.shape[1]))\nprint(\"Testing set has {} samples and {} classes.\".format(df_test.shape[0], df_test.shape[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**증상별로 데이터 분산**\n\n데이터 셋이 상당히 불균형한걸로 보임."},{"metadata":{"trusted":true},"cell_type":"code","source":"chat_data = df_train.diagnosis.value_counts()\nchat_data.plot(kind='bar');\nplt.title('Samples Per Class');\nplt.show()\nplt.pie(chat_data, autopct='%1.1f%%', shadow=True, labels=[\"No DR\", \"Mild\", \"Moderate\", \"Severe\", \"Proliferative DR\"])\nplt.title('Per class sample Percentage');\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No DR에 비해 Severe의 수가 상당히 차이나는것을 볼수 있다.\n데이터 집합의 균형을 맞추기 위해 데이터를 증가시킬 필요가 있다."},{"metadata":{},"cell_type":"markdown","source":"데이터 셋의 크기를 보여주는 파이 차트"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Train & Test samples ratio\n# Plot Data\nlabels = 'Train', 'Test'\nsizes = df_train.shape[0], df_test.shape[0]\ncolors = 'lightskyblue', 'lightcoral'\n# Plot\nplt.figure(figsize=(7, 5))\nplt.pie(sizes, labels=labels, autopct='%1.1f%%', shadow=True)\nplt.axis('equal')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(df_train.id_code, df_train.diagnosis, test_size=0.2,\n                                                    random_state=SEED, stratify=df_train.diagnosis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def draw_img(imgs, target_dir, class_label='0'):\n    fig, axis = plt.subplots(2, 6, figsize=(15, 6))\n    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n        imgPath = os.path.join(dir_path, f\"{target_dir}/{row['id_code']}.png\")\n        img = cv2.imread(imgPath)\n        row = idnx // 6\n        col = idnx % 6\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axis[row, col].imshow(img)\n    plt.suptitle(class_label)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"증상별로 자료 표시\n데이터 셋의 샘플 이미지\n\n이미지 크기 조정 필요\n표준 이미지 크기 정하기\n이미지 밝기 조정 필요"},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_ID = 0\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_ID = 1\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_ID = 2\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_ID = 3\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_ID = 4\ndraw_img(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_ID = 'Test DataSet'\ndraw_img(df_test.sample(12, random_state=SEED), 'test_images', CLASS_ID)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"train / test 셋 이미지 높이/너비 가져오기"},{"metadata":{"trusted":true},"cell_type":"code","source":"def check_max_min_img_height_width(df, img_dir):\n    max_Height , max_Width =0 ,0\n    min_Height , min_Width =sys.maxsize ,sys.maxsize \n    for idx, row in df.iterrows():\n        imgPath=os.path.join(dir_path,f\"{img_dir}/{row['id_code']}.png\") \n        img=cv2.imread(imgPath)\n        H,W=img.shape[:2]\n        max_Height=max(H,max_Height)\n        max_Width =max(W,max_Width)\n        min_Height=min(H,min_Height)\n        min_Width =min(W,min_Width)\n    return max_Height, max_Width, min_Height, min_Width","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_max_min_img_height_width(df_train, TRAIN_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"check_max_min_img_height_width(df_test, TEST_DIR)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'regin'을 견디기 위해 GrayScale 적용(??)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display some random images from Data Set with class categories ing gray\nfigure = plt.figure(figsize=(20, 16))\nfor target_class in (y_train.unique()):\n    for i, (idx, row) in enumerate(\n            df_train.loc[df_train.diagnosis == target_class].sample(5, random_state=SEED).iterrows()):\n        ax = figure.add_subplot(5, 5, target_class * 5 + i + 1)\n        imagefile = f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        img = cv2.imread(imagefile)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        plt.imshow(img, cmap='gray')\n        ax.set_title(CLASSS[target_class])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"눈 주위의 검은 부분을 제거 해줘야함."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Add Lighting to the images for improving the visibility \n\ndef draw_img_light(imgs, target_dir, class_label='0'):\n    fig, axis = plt.subplots(2, 6, figsize=(15, 6))\n    for idnx, (idx, row) in enumerate(imgs.iterrows()):\n        imgPath = os.path.join(dir_path, f\"{target_dir}/{row['id_code']}.png\")\n        img = cv2.imread(imgPath)\n        row = idnx // 6\n        col = idnx % 6\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , IMG_DIM/10) ,-4 ,128) # the trick is to add this line\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        axis[row, col].imshow(img, cmap='gray')\n    plt.suptitle(class_label)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASS_ID = 3\ndraw_img_light(df_train[df_train.diagnosis == CLASS_ID].head(12), 'train_images', CLASSS[CLASS_ID])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image Croping\ndef crop_image1(img, tol=7) :\n    # img is image data\n    # tol is tolerance\n    mask = img>tol\n    return img[np.ix_(mask.any(1,),mask.any(0))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim== 2:\n        mask=img>tol\n    elif img.ndim==3:\n        gray_img=cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)\n        mask=gray_img>tol\n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n#         check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if check_shape ==0: # Image was full dark and may be cropout everything.\n            return img # Return original Image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            print(img1.shape,img2.shape,img3.shape)            \n            img=np.stack([img1,img2,img3],axis=1)\n            print(img.shape)\n            return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n#     image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)S\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_DIM, IMG_DIM))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"크기를 조정하기 위해 임의로 이미지를 자름."},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image(img,tol=7):\n    w, h = img.shape[1],img.shape[0]\n    gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    gray_img = cv2.blur(gray_img,(5,5))\n    shape = gray_img.shape \n    gray_img = gray_img.reshape(-1,1)\n    quant = quantile_transform(gray_img, n_quantiles=256, random_state=0, copy=True)\n    quant = (quant*256).astype(int)\n    gray_img = quant.reshape(shape)\n    xp = (gray_img.mean(axis=0)>tol)\n    yp = (gray_img.mean(axis=1)>tol)\n    x1, x2 = np.argmax(xp), w-np.argmax(np.flip(xp))\n    y1, y2 = np.argmax(yp), h-np.argmax(np.flip(yp))\n    if x1 >= x2 or y1 >= y2 : # something wrong with the crop\n        return img # return original image\n    else:\n        img1=img[y1:y2,x1:x2,0]\n        img2=img[y1:y2,x1:x2,1]\n        img3=img[y1:y2,x1:x2,2]\n        img = np.stack([img1,img2,img3],axis=-1)\n    return img\n\ndef process_image(image, size=512):\n    image = cv2.resize(image, (size,int(size*image.shape[0]/image.shape[1])))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    try:\n        image = crop_image(image, tol=15)\n    except Exception as e:\n        image = image\n        print( str(e) )\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Display some random images from Data Set with class categories. showig Gray image removing other channel and adding lighting to image.\nfigure = plt.figure(figsize=(20, 16))\nfor target_class in (y_train.unique()):\n    #     print(CLASSS[target_class],target_class)\n    for i, (idx, row) in enumerate(\n            df_train.loc[df_train.diagnosis == target_class].sample(5, random_state=SEED).iterrows()):\n        ax = figure.add_subplot(5, 5, target_class * 5 + i + 1)\n        imagefile = f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        img = cv2.imread(imagefile)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.resize(img, (IMG_DIM, IMG_DIM))\n        img = cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), IMG_DIM / 10), -4, 128)\n        plt.imshow(img, cmap='gray')\n        ax.set_title('%s-%d-%s' % (CLASSS[target_class], idx, row['id_code']))\n#         print(row['id_code'])\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgPath = f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\"\nimg = cv2.imread(imgPath)\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n_, thresh = cv2.threshold(gray, 1, 255, cv2.THRESH_BINARY)\ncontours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnt = contours[0]\nx, y, w, h = cv2.boundingRect(cnt)\nimg = img[y:y + h, x:x + w]\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_crop(img, random_crop_size):\n    # Note: image_data_format is 'channel_last'\n    assert img.shape[2] == 3\n    height, width = img.shape[0], img.shape[1]\n    dy, dx = random_crop_size\n    x = np.random.randint(0, width - dx + 1)\n    y = np.random.randint(0, height - dy + 1)\n    img = img[y:(y + dy), x:(x + dx), :]\n    return img\n\n\n\"\"\"Take as input a Keras ImageGen (Iterator) and generate random\n    crops from the image batches generated by the original iterator.\n    \"\"\"\n\n\ndef crop_generator(batches, crop_length):\n    while True:\n        batch_x, batch_y = next(batches)\n        batch_crops = np.zeros((batch_x.shape[0], crop_length, 3))\n        for i in range(batch_x.shape[0]):\n            batch_crops[0] = random_crop(batch_x[i], (crop_length, crop_length))\n        yield (batch_crops, batch_y)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"데이터 프레임에 이미지와 함께 이미지 유형 추가"},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(\"available RAM:\", psutil.virtual_memory())\ngc.collect()\n#print(\"available RAM:\", psutil.virtual_memory())\n\ndf_train.id_code = df_train.id_code.apply(lambda x: x + \".png\")\ndf_test.id_code = df_test.id_code.apply(lambda x: x + \".png\")\ndf_train['diagnosis'] = df_train['diagnosis'].astype('str')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**데이터 생성기**\nKeras 모델에 대한 데이터 생성을 위한 Keras ImageDataGenerator 클래스 사용 shear_range, zoom_range 추가"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating the imageDatagenerator Instance \ndatagenerator=ImageDataGenerator(#rescale=1./255,\n#                                       validation_split=0.15, \n                                         horizontal_flip=True,\n                                         vertical_flip=True, \n                                         rotation_range=40, \n                                         zoom_range=0.2, \n                                         shear_range=0.1,\n                                        fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgPath = f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\"\n# Loading image\nimg = load_img(imgPath)\ndata = img_to_array(img)\nsamples =np.expand_dims(data, 0)\ni=5\nit=datagenerator.flow(samples , batch_size=1)\nfor i in range(5):\n    plt.subplot(230 + 1 + i)\n    batch = it.next()\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.15, horizontal_flip=True,\n                                         vertical_flip=True, rotation_range=40, zoom_range=0.2, shear_range=0.1, fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory=\"../input/aptos2019-blindness-detection/train_images/\",\n                                                    x_col=\"id_code\",\n                                                    y_col=\"diagnosis\",\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode=\"categorical\",\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='training',\n                                                    shaffle=True,\n                                                    seed=SEED,\n                                                    )\nvalid_generator = train_datagen.flow_from_dataframe(dataframe=df_train,\n                                                    directory=\"../input/aptos2019-blindness-detection/train_images/\",\n                                                    x_col=\"id_code\",\n                                                    y_col=\"diagnosis\",\n                                                    batch_size=BATCH_SIZE,\n                                                    class_mode=\"categorical\",\n                                                    target_size=(IMG_DIM, IMG_DIM),\n                                                    subset='validation',\n                                                    shaffle=True,\n                                                    seed=SEED\n                                                    )\ndel x_train\n# # del x_test\ndel y_train\n# del y_test\ngc.collect()\n#  color_mode= \"grayscale\",","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"모델 아키텍처 설계"},{"metadata":{"trusted":true},"cell_type":"code","source":"def design_model():\n    model = Sequential()\n    model.add(Conv2D(filters=16, kernel_size=(2, 2), input_shape=[IMG_DIM, IMG_DIM, CHANNEL_SIZE], activation='elu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(filters=32, kernel_size=(2, 2), activation='elu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(filters=64, kernel_size=(2, 2), activation='elu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(units=1000, activation=elu))\n    model.add(Dropout(rate=0.2))\n    model.add(Dense(units=1000, activation=elu))\n    model.add(Dropout(rate=0.2))\n    model.add(Dense(5, activation='softmax'))\n    return model\n\n\nmodel = design_model()\n# model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=RMSprop(), loss='categorical_crossentropy', metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"콜백 기능(?)\nEraly Stoping and Learning Rate Reducing"},{"metadata":{"trusted":true},"cell_type":"code","source":"eraly_stop = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=3, verbose=1, mode='auto')\n# Reducing the Learning Rate if result is not improving. \nreduce_lr = ReduceLROnPlateau(monitor='val_loss', min_delta=0.0004, patience=2, factor=0.1, min_lr=1e-6, mode='auto',\n                              verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUB_TRAIN_STEPS = train_generator.n // train_generator.batch_size\nNUB_VALID_STEPS = valid_generator.n // valid_generator.batch_size\n\nNUB_TRAIN_STEPS, NUB_VALID_STEPS","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**RestNet50을 사용한 전송 학습 사용**"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U '../input/install/efficientnet-0.0.3-py2.py3-none-any.whl'\nfrom efficientnet import EfficientNetB5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_resnet(img_dim, CHANNEL, n_class):\n    input_tensor = Input(shape=(img_dim, img_dim, CHANNEL))\n\n    base_model = EfficientNetB5(weights=None,\n    input_shape=(IMG_DIM, IMG_DIM, CHANNEL_SIZE),\n    include_top=False\n                   )\n    base_model.load_weights(\"../input/efficientnet-keras-weights-b0b5/efficientnet-b5_imagenet_1000_notop.h5\")\n    #base_model = ResNet50(weights=None, include_top=False, input_tensor=input_tensor)\n    #base_model.load_weights('../input/resnet50weightsfile/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    \n    #x = GlobalAveragePooling2D()(base_model.output)\n    #x = Dropout(0.3)(x)\n    #x = Dense(1024, activation=elu)(x)\n    #x = Dropout(0.3)(x)\n    #x = Dense(1024, activation=elu)(x)\n    #x = Dropout(0.3)(x)\n    #x = Dense(512, activation=elu)(x)\n    #x = Dropout(0.3)(x)\n    #x = BatchNormalization()(x)\n    #output_layer = Dense(n_class, activation='softmax', name=\"Output_Layer\")(x)\n    #model_resnet = Model(input_tensor, output_layer)\n    \n    x = base_model.output\n    x = Flatten()(x)\n    x = Dense(1024, activation=\"relu\")(x)\n    x = Dropout(0.5)(x)\n    predictions = Dense(n_class, activation=\"softmax\")(x)\n    model_resnet = Model(input = base_model.input, output = predictions)\n    \n    return model_resnet\n\n\nmodel_resnet = create_resnet(IMG_DIM, CHANNEL_SIZE, NUM_CLASSES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for layers in model_resnet.layers:\n    layers.trainable = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-3\noptimizer =SGD(lr=lr, decay=1e-6, momentum=0.9, nesterov=True)# Adam(lr=lr, decay=0.1)\nmodel_resnet.compile(optimizer=optimizer, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n# model.summary()\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model_resnet.fit_generator(generator=train_generator,\n                                     steps_per_epoch=NUB_TRAIN_STEPS,\n                                     validation_data=valid_generator,\n                                     validation_steps=NUB_VALID_STEPS,\n                                     epochs=NUM_EPOCHS,\n                                     callbacks=[eraly_stop, reduce_lr])\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accu = history.history['acc']\nval_acc = history.history['val_acc']\n\nplt.plot(accu, label=\"Accuracy\")\nplt.plot(val_acc)\nplt.xlabel(\"Epoch\")\nplt.ylabel(\"Accuracy\")\nplt.legend(['Acc', 'val_acc'])\nplt.plot(np.argmax(history.history[\"val_acc\"]), np.max(history.history[\"val_acc\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8, 8))\nplt.title(\"Learning curve\")\nplt.plot(history.history[\"loss\"], label=\"loss\")\nplt.plot(history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.argmin(history.history[\"val_loss\"]), np.min(history.history[\"val_loss\"]), marker=\"x\", color=\"r\",\n         label=\"best model\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"log_loss\")\nplt.legend();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"(eval_loss, eval_accuracy) = tqdm(\n    model_resnet.evaluate_generator(generator=valid_generator, steps=NUB_VALID_STEPS, pickle_safe=False))\nprint(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\nprint(\"[INFO] Loss: {}\".format(eval_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen = ImageDataGenerator(rescale=1. / 255, validation_split=0.2, horizontal_flip=True)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe=df_test,\n                                                  directory=\"../input/aptos2019-blindness-detection/test_images/\",\n                                                  x_col=\"id_code\",\n                                                  target_size=(IMG_DIM, IMG_DIM),\n                                                  batch_size=1,\n                                                  shuffle=False,\n                                                  class_mode=None,\n                                                  seed=SEED)\n# del df_test\nprint(df_test.shape[0])\n# del train_datagen\n# del traabsin_generator\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Test-Time Augmentation**\n\n아래 섹션에서 우리는 TTA에 예측 정확도를 부여합니다. 그것은 이미지를 변형시키고 예측할 것이다."},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_steps = 5\npreds_tta = []\nfor i in tqdm(range(tta_steps)):\n    test_generator.reset()\n    preds = model_resnet.predict_generator(generator=test_generator, steps=ceil(df_test.shape[0]))\n    #     print('Before ', preds.shape)\n    preds_tta.append(preds)\n#     print(i,  len(preds_tta))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = np.mean(preds_tta, axis=0)\npredicted_class_indices = np.argmax(final_pred, axis=1)\nlen(predicted_class_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({\"id_code\": test_generator.filenames, \"diagnosis\": predicted_class_indices})\nresults.id_code = results.id_code.apply(lambda x: x[:-4])  # results.head()\nresults.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results['diagnosis'].value_counts().plot(kind='bar')\nplt.title('Test Samples Per Class')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}