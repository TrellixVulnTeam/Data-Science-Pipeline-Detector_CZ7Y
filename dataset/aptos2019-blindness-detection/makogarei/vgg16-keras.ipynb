{"cells":[{"metadata":{},"cell_type":"markdown","source":"## for the first time vgg16\n### Please let me know if you have any advice"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport random as rn\nfrom sklearn.preprocessing import LabelEncoder\n\n# dl libraries\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam, SGD, Adagrad, Adadelta, RMSprop\nfrom keras.utils import to_categorical\nfrom keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping\n\n \n# specifically for cnn\nfrom keras.layers import Dropout, Flatten, Activation, Lambda\nfrom keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization\n\n# preprocess\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf\n\nimport cv2\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Load data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/train.csv')\ndf_test = pd.read_csv('../input/test.csv')\ntrain_image_path = '../input/train_images/'\ntest_image_path = '../input/test_images/'\ndf_submission = pd.read_csv('../input/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['diagnosis'].hist(bins=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check images"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(\"../input/train_images/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(os.listdir(\"../input/test_images/\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_images_name_list = os.listdir(\"../input/train_images/\")\ntest_images_name_list = os.listdir(\"../input/test_images/\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## sample 15 train images"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set_style(\"white\")\ncount = 1\nplt.figure(figsize=[20, 20])\nfor img_name in df_train['id_code'][:15]:\n    img = cv2.imread(\"../input/train_images/%s.png\" % img_name)[...,[2, 1, 0]]\n    plt.subplot(5, 5, count)\n    plt.imshow(img)\n    plt.title(\"diagnosis %s\" % df_train[df_train['id_code']==img_name]['diagnosis'])\n    count += 1\n    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=[]\nZ=[]\nIMG_SIZE=150\nＴＲＡＩＮ_ＩＭＡＧＥ_DIR='../input/train_images/'\n\ndef assign_label(img, diagnosis):\n    return diagnosis\n\ndef make_train_data(df_train, DIR):\n    for img in tqdm(os.listdir(DIR)):\n        #print(img)\n        label = assign_label(img, df_train[df_train['id_code']==img.strip('.png')]['diagnosis'].values)\n        path = os.path.join(DIR, img)\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n        if not img is None:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        else:\n            print('None image file : ', path)\n            continue\n\n        X.append(np.array(img))\n        Z.append(str(label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_train_data(df_train, ＴＲＡＩＮ_ＩＭＡＧＥ_DIR)\nprint(\"total images: \", len(X))\nprint(\"image size: \", X[0].shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(5,2)\nfig.set_size_inches(15, 15)\nfor i in range(5):\n    for j in range(2):\n        l = rn.randint(0, len(Z))\n        ax[i, j].imshow(X[l])\n        ax[i, j].set_title('diagnosis: '+Z[l][1])\n\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 5\n# Label encoding\nle = LabelEncoder()\nY = le.fit_transform(Z)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# one hot vector\nY = to_categorical(Y)\n# normalize\nX = np.array(X)\nX = X/255","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\n\ndatagen.fit(X)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### make model"},{"metadata":{"trusted":true},"cell_type":"code","source":"_input = Input(shape=(150, 150, 3))\nx = Lambda(lambda image: tf.image.resize_images(image, (224, 224)))(_input)\nconv1 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(x)\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(conv1)\npool1 = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='block1_pool')(conv2)\n\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(pool1)\nconv4 = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(conv3)\npool2 = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='block2_pool')(conv4)\n\nconv5 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(pool2)\nconv6 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(conv5)\nconv7 = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(conv6)\npool3 = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='block3_pool')(conv7)\n\nconv8 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(pool3)\nconv9 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(conv8)\nconv10 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(conv9)\npool4 = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='block4_pool')(conv10)\n\nconv11 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(pool4)\nconv12 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(conv11)\nconv13 = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(conv12)\npool5 = MaxPooling2D((2, 2), strides=(2, 2), padding='same', name='block5_pool')(conv13)\n\nflat = Flatten(name='flatten')(pool5)\ndense1 = Dense(4096, activation='relu', name='fc1')(flat)\ndropout1 = Dropout(0.5, name='dropout1')(dense1)\ndense2 = Dense(4096, activation='relu', name='fc2')(dropout1)\ndropout2 = Dropout(0.5, name='dropout2')(dense2)\noutput = Dense(num_classes, activation='softmax', name='output')(dropout2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nred_lr = ReduceLROnPlateau(monitor='val_acc',\n                           factor=0.1,\n                           patience=5,\n                           verbose=1,\n                           mode='auto',\n                           min_delta=0.0001,\n                           cooldown=0,\n                           min_lr=0.00001)\n\nearlyStopping = EarlyStopping(\n    monitor='val_loss',\n    patience=20,\n    verbose=1\n)\n\nLOG_DIR = './logs'\nif not os.path.isdir(LOG_DIR):\n    os.mkdir(LOG_DIR)\nelse:\n    pass\nCKPT_PATH = LOG_DIR + '/checkpoint-{epoch:02d}-{val_loss:.4f}.hdf5'\n\ntensorBoard = TensorBoard(\n    log_dir=LOG_DIR,\n    write_images=True\n)\n\nif not os.path.isdir('./logs/saved_medel'):\n    os.mkdir('./logs/saved_medel')\n\nmc = ModelCheckpoint('./logs/saved_medel/model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nopt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n\nmodel  = Model(inputs=_input, outputs=output)\n\nmodel.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(x_train,y_train,validation_data=[x_test,y_test],batch_size=54,epochs=500,verbose=1,callbacks=[red_lr,earlyStopping,mc])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## History visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\n \nplt.plot(acc)\nplt.plot(val_acc)\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.plot(loss)\nplt.plot(val_loss)\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## prepare test images data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_X=[]\ntest_Z=[]\nIMG_SIZE=150\nＴEST_ＩＭＡＧＥ_DIR='../input/test_images/'\n\ndef make_test_data(DIR):\n    for img in tqdm(os.listdir(DIR)):\n        #print(img)\n        #label = assign_label(img, df_train[df_train['id_code']==img.strip('.png')]['diagnosis'].values)\n        path = os.path.join(DIR, img)\n        img = cv2.imread(path, cv2.IMREAD_COLOR)\n        if not img is None:\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n            img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n        else:\n            print('None image file : ', path)\n            continue\n\n        test_X.append(np.array(img))\n        #test_Z.append(str(label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"make_test_data(ＴEST_ＩＭＡＧＥ_DIR)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# normalize\ntest_X = np.array(test_X)\ntest_X = test_X/255","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_max = np.argmax(preds,axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['diagnosis']= preds_max","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['diagnosis'].hist(bins = 10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}