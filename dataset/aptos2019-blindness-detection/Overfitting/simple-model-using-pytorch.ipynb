{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input/aptos2019-blindness-detection/\"))\n\n\n# Any results you write to the current directory are saved as output.\nfrom tqdm import tqdm\nimport pathlib\nimport matplotlib\nimport torch.nn as nn\nimport torch.optim as optim \nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom PIL import Image, ImageFile","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ndf_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ndf_sample = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\ndf_train.shape, df_test.shape, df_sample.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_image_path = '../input/aptos2019-blindness-detection/train_images/'\ntest_image_path = '../input/aptos2019-blindness-detection/test_images/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adding another column to contain the image path\ndf_train['image_file'] = train_image_path + df_train['id_code']+'.png' \ndf_test['image_file'] = test_image_path + df_test['id_code']+'.png' ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['diagnosis'] = 999","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image(filepath):\n#     return io.imread(filepath)\n#     return cv2.imread(filepath, cv2.COLOR_BGR2RGB)\n    return Image.open(filepath)\n\ndef normalize(x, m, s): \n    return (x-m)/s\n\ndef apply_transform(image):\n    transform_fn = transforms.Compose([transforms.Resize((480,480)),\n#                                        transforms.CenterCrop((480,480)),                                       \n                                      ])\n    unnorm_img = transform_fn(image)\n    norm_tf = transforms.Compose([transforms.ToTensor(), \n                                  transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n                                 ])\n    \n    \n    return norm_tf(unnorm_img), unnorm_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = load_image(df_train['image_file'][0])\nnp.array(img).shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Setting up gpu parameter and batch_size\nclasses = 5\nper_device_batch_size = 16\n\nnum_gpus = torch.cuda.device_count()\nnum_workers = num_gpus\nctx = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nbatch_size = per_device_batch_size * max(num_gpus, 1)\nprint(ctx,batch_size, num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Example of images \nplt.figure(figsize=[15,15])\ni = 1\nfor img_name in df_train['image_file'][:10]:\n    img = load_image(img_name)\n    plt.subplot(6,5,i)\n    plt.imshow(img)\n    i += 1\nplt.title('Raw image without transformation')    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Image after transformation\nplt.figure(figsize=[15,15])\ni = 1\nfor img_name in df_train['image_file'][:10]:\n    _, img = apply_transform(load_image(img_name))\n    print(np.array(img).shape)\n    plt.subplot(6,5,i)\n    plt.imshow(img)\n    i += 1\n# plt.title('Images after applying transformation')    \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self, df, is_test= False):\n        super().__init__()\n        self.df = df\n        self.is_test = is_test\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx):                \n        if not self.is_test:\n            label = self.df.diagnosis[idx]\n        else:\n            label = None\n            \n        img_path = self.df.image_file[idx]\n        img = load_image(df_train['image_file'][idx])\n        image, _ = apply_transform(img)                    \n        \n        return image, label        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from sklearn.model_selection import train_test_split\n\n# X_train, X_test, y_train, y_test = train_test_split(df_train[['id_code','image_file']], df_train['diagnosis'],test_size=0.25, random_state=42, stratify=df_train['diagnosis'] )\n# X_train = pd.concat([X_train, y_train], axis=1).reset_index(drop=True)\n# X_test = pd.concat([X_test, y_test], axis=1).reset_index(drop=True)\n# X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train.diagnosis.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  X_test.diagnosis.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = CustomDataset(df=df_train)\n# valid_dataset = CustomDataset(df=X_test)\nlen(train_dataset)\n# len(valid_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers = num_workers)\n# valid_dl = torch.utils.data.DataLoader(valid_dataset, batch_size=batch_size, shuffle=False, num_workers = num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Unit test dataloader block\nfor data, label in train_dl:\n    print(data.shape, label.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ctx, batch_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net =  torchvision.models.resnet50(pretrained=False)\n\n# Freeze model weights\nfor param in net.parameters():\n    param.requires_grad = False\n    \nnet.fc = nn.Linear(in_features=2048, out_features=classes)\n    \n# nn.init()    \n# net.initialize(init=init.Xavier(), ctx=ctx)\n# net.collect_params().reset_ctx(ctx)\n# net.hybridize()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Transfer execution to device\nmodel = net.to(ctx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = optim.Adam(model.parameters())\nloss_func = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Train model\nloss_log=[]\nloss_values = []\nfor epoch in range(15):\n    running_loss = 0.0\n    model.train()\n    dl = tqdm(train_dl, total=int(len(train_dl)))\n    for ii, (data, target) in enumerate(dl):        \n        data, target = data.to(ctx), target.to(ctx)\n        optimizer.zero_grad()\n        output = model(data)                    \n        loss = loss_func(output, target)\n        loss.backward()\n        optimizer.step()          \n        if ii % 1000 == 0:\n            loss_log.append(loss.item())\n        running_loss =+ loss.item() * data.size(0)\n        \n    loss_values.append(running_loss / len(train_dataset))\n    \n    print('Epoch: {} - Loss: {:.6f}'.format(epoch + 1, loss.item()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"torch.save(net.state_dict(), \"model.bin\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(loss_values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_sample\ntest_dataset = CustomDataset(df_test, is_test=False)\ntest_dl = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Unit test dataloader block\nfor data, label in test_dl:\n    print(data.shape, label.shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Prediction\npredict = []\nnet.eval()\ndl = tqdm(test_dl, total=int(len(test_dl)))\nfor i, (data, _) in enumerate(dl):\n    data = data.cuda()\n    output = net(data)  \n    output = output.cpu().detach().numpy()    \n    predict.append(output[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sample['diagnosis'] = np.argmax(predict, axis=1)\ndf_sample.head()\n\ndf_sample.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}