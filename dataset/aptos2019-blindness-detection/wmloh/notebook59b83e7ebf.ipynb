{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.utils import plot_model\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.models import load_model\n\nDATA_PATH = '../input/aptos2019-blindness-detection/'\n\nDIM_X = 256\nDIM_Y = 256\nBATCH_SIZE = 32\n\n\nimport cv2\nimport keras.backend as K\n\n\ndef crop_image_from_gray(img, tol=7):\n    # If for some reason we only have two channels\n    if img.ndim == 2:\n        mask = img > tol\n        return img[np.ix_(mask.any(1), mask.any(0))]\n    # If we have a normal RGB images\n    elif img.ndim == 3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img > tol\n\n        check_shape = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))].shape[0]\n        if (check_shape == 0):  # image is too dark so that we crop out everything,\n            return img  # return original image\n        else:\n            img1 = img[:, :, 0][np.ix_(mask.any(1), mask.any(0))]\n            img2 = img[:, :, 1][np.ix_(mask.any(1), mask.any(0))]\n            img3 = img[:, :, 2][np.ix_(mask.any(1), mask.any(0))]\n            img = np.stack([img1, img2, img3], axis=-1)\n        return img\n\n\ndef circle_crop_v2(img):\n    height, width, depth = img.shape\n    largest_side = np.max((height, width))\n    img = cv2.resize(img, (largest_side, largest_side))\n\n    height, width, depth = img.shape\n\n    x = int(width / 2)\n    y = int(height / 2)\n    r = np.amin((x, y))\n\n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n\n    return img\n\n\ndef preprocess_image(image, sigmaX=25, DIM_X=256, DIM_Y=256):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = circle_crop_v2(image)\n    image = cv2.resize(image, (DIM_X, DIM_Y))\n    image = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0, 0), sigmaX), -4, 128)\n    return image\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class FixedDropout(tf.keras.layers.Dropout):\n    def _get_noise_shape(self, inputs):\n        if self.noise_shape is None:\n            return self.noise_shape\n\n        symbolic_shape = K.shape(inputs)\n        noise_shape = [symbolic_shape[axis] if shape is None else shape\n                       for axis, shape in enumerate(self.noise_shape)]\n        return tuple(noise_shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model = load_model('../input/resnet/resnet_06-12.h5', custom_objects={'kappa_keras': kappa_keras, 'kappa_loss': KAPPA_LOSS})\n# model = load_model('../input/effnet/effnet_06-12.h5', custom_objects={'kappa_keras': kappa_keras, 'kappa_loss': KAPPA_LOSS, 'FixedDropout': FixedDropout})\nmodel = load_model('../input/effnet-8/effnet_09-12_2.h5', custom_objects={'FixedDropout': FixedDropout})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import os\n# import numpy as np\n# import pandas as pd\n# from PIL import Image\n# from tqdm import tqdm\n\n# import os\n# from PIL import Image\n# import cv2\n# import numpy as np\n# import matplotlib.pyplot as plt\n\n# STANDARDIZE_CROP_RATIO = 0.792\n# OVERCROP_THRESHOLD = 25\n# ZERO_TOLERANCE = 2\n# BLUE_LAYER_IDX = 2\n# RED_LAYER_IDX = 0\n\n\n# def autocrop_scale(path, IMG_DIM=(512, 512), EPSILON=7, standardize_crop=False, return_crop_only=False):\n#     '''\n#     Loads the image file and automatically crops based on dark regions and rescales\n#         to a specified dimension ignoring aspect ratio\n\n#     :param path: str - path to file\n#     :param IMG_DIM: tuple(int,int)/None - final dimension of image (no rescale if None)\n#     :param EPSILON: int - minimum threshold for mean row/col pixel value\n#     :param standardize_crop: bool - if True, intentionally over-crop perfect circles to standardize to\n#                                     the images that are not perfect circles\n#     :param return_crop_only: bool - if True, does not resize and return numpy array\n#     :return: PIL.Image/np.ndarray\n#     '''\n\n#     # loads and convert images\n# #     img = Image.open(path)\n# #     data = np.asarray(img)\n#     data = path\n#     gray_data = data.mean(axis=2)\n\n#     # dynamically determine non-dark regions based on grayscale mean of row/col values\n#     limit_h = np.where(gray_data.mean(axis=0) >= EPSILON)[0]\n#     horizontal = (limit_h[0], limit_h[-1])\n#     limit_v = np.where(gray_data.mean(axis=1) >= EPSILON)[0]\n\n#     # over-cropping\n#     if standardize_crop and (abs((limit_h[-1] - limit_h[0]) - (limit_v[-1] - limit_v[0])) <= OVERCROP_THRESHOLD):\n#         # executes only if the limits are approximately square\n#         crop_v = STANDARDIZE_CROP_RATIO * (limit_v[-1] - limit_v[0]) / 2\n#         center = (limit_v[-1] + limit_v[0]) / 2\n#         vertical = (int(center - crop_v), int(center + crop_v))\n#     else:\n#         vertical = (limit_v[0], limit_v[-1])\n\n#     # crops array representation\n#     new_data = data[vertical[0]:vertical[1] + 1, horizontal[0]:horizontal[1] + 1, :]\n\n#     # reverts to original if too much cropped\n#     if new_data.shape[0] < 100 or new_data.shape[1] < 100:\n#         new_data = data\n\n#     if return_crop_only:\n#         return new_data\n\n#     # converts and resize to PIL image\n#     processed_img = Image.fromarray(new_data)\n#     if IMG_DIM is not None:\n#         processed_img = processed_img.resize(IMG_DIM)\n\n#     return processed_img\n\n\n# def standard_crop(path, IMG_DIM=(512, 512), ratio=4 / 3, cratio=592 / 386, contrast_fnc=None, **kwargs):\n#     '''\n#     Crops an image to an approximate form found in majority of the images in the test dataset.\n\n#     The values found here is derived from manual measurements with trigonometry.\n\n#     :param path: str - path of image\n#     :param IMG_DIM: tuple(int, int)/None - final dimension of image (no rescale if None)\n#     :param ratio: float - final aspect ratio of output image\n#     :param cratio: flaot - ratio of chord at the bottom to the radius\n#     :param contrast_fnc: None/function - contrast function\n#     :return: PIL.Image\n#     '''\n# #     data = autocrop_scale(path, return_crop_only=True)  # crops away all excess background\n#     data = crop_image_from_gray(path, tol=7)\n# #     data = circle_crop_v2(path)\n    \n#     h, l = data.shape[0], data.shape[1]\n\n#     # dynamically determine the radius of the circle\n#     sample_column = data[:, 1, :]  # second column of data\n#     # first non-background pixel\n#     edge = np.where((data.mean(axis=2)[:, 0] > sample_column.mean() + 5 / sample_column.mean(axis=1).std()))\n#     edge = edge[0][edge[0] > h / 8]  # accepts if not near the corner\n#     if len(edge) > 0:\n#         r = np.sqrt((edge[0] - h / 2) ** 2 + (l / 2) ** 2)\n#     else:\n#         r = l / 2  # assumes length is the diameter\n\n#     delta_h = r - np.sqrt(r ** 2 - (cratio * r / 2) ** 2)  # height to be cropped away at both the top and bottom\n#     # max(..., 0) is needed to handle the cases when the specified image is a perfect circle and cropped circle\n#     data = data[max(int(delta_h - (2 * r - h) / 2), 0):h - max(int(delta_h - (2 * r - h) / 2), 0), ...]\n\n#     h, l = data.shape[0], data.shape[1]\n#     delta_l = l - h * ratio  # length to be cropped away at both the left and right\n\n#     data = data[:, int(delta_l / 2):l - int(delta_l / 2), :]\n\n#     data = cv2.resize(data, dsize=IMG_DIM, interpolation=cv2.INTER_AREA)\n\n#     if contrast_fnc is not None:\n#         data = contrast_fnc(data, **kwargs)\n\n# #     processed_img = Image.fromarray(data)\n\n#     return data.reshape(*data.shape)\n\n# def contrast_enhance(img, sigma=10, gray=False):\n#     '''\n#     Contrast technique based on Kaggle notebook\n\n#     :param img: np.ndarray - image\n#     :param sigma: int - degree of contrast (affects efficiency of code)\n#     :param gray: bool - returns grayscale (i.e. 1 channel)\n#     :return: nd.ndarray\n#     '''\n#     if gray:\n#         img = img.mean(axis=2)\n#         img = np.dstack((img, img, img)).astype(np.uint8)\n\n#     return cv2.addWeighted(img, 4, cv2.GaussianBlur(img, (0, 0), sigma), -4, 128)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv(DATA_PATH + '/test.csv')\nsubmission_df['filename'] = submission_df['id_code'].astype(str)+'.png'\n\nsubmission = ImageDataGenerator(preprocessing_function=preprocess_image, rescale=1/255.)\n# submission = ImageDataGenerator(preprocessing_function=lambda x: standard_crop(x,IMG_DIM=(256,256), contrast_fnc=contrast_enhance, gray=False), rescale=1/255.)\ngen = submission.flow_from_dataframe(dataframe = submission_df,\n                                       directory= DATA_PATH + \"test_images\",\n                                       x_col=\"filename\", \n                                       batch_size = 64,\n                                       shuffle=False,\n                                       class_mode=None, \n                                       target_size=(256, 256), validate_filenames=False)\n\npred = model.predict_generator(gen, verbose=1)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = np.argmax(pred, axis=1)\n\nresults = dict(zip(gen.filenames, pred))\nlabels = list(map(lambda x: results[x], submission_df['filename']))\n\nsubmission_df.drop(columns=['filename'], inplace= True)\nsubmission_df['diagnosis'] = labels\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ncnt = Counter(labels)\ncnt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}