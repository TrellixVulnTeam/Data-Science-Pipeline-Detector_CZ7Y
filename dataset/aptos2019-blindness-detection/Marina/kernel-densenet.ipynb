{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport keras\nfrom sklearn.model_selection import train_test_split\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom PIL import Image\nimport os\nimport glob\nimport cv2\nfrom keras.models import Sequential\nfrom keras.layers import Activation, Dropout, Flatten, Dense,Convolution2D,MaxPooling2D,AveragePooling2D,BatchNormalization, SeparableConv2D, GlobalAveragePooling2D\nfrom sklearn.metrics import confusion_matrix,classification_report,roc_auc_score\nimport seaborn as sns\n\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/labels/labels_new.csv')\ntest = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nprint(train.shape, test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_img = []\ntitle_font = {'fontname':'Arial', 'size':'14'}\nIMG_FOLDER_PREFIX_i = \"../input/optos-all/optos_all/optos_all/\"\nIMG_EXTENSION = \".png\"\nNUM_IMAGES = 8\n\nfor i in range(NUM_IMAGES):\n    image_path = IMG_FOLDER_PREFIX_i + str(train['id_code'][i])\n    n = cv2.imread(image_path)\n    cv_img.append(n)\n\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(20, 20))\nfor i in range(NUM_IMAGES):\n    plt.subplot(4,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.text(0.0, 0.0, 'diagnosis'+str(train['diagnosis'][i]), **title_font)\n    plt.imshow(cv_img[i], cmap=plt.cm.binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_png(fn):\n    return fn+\".png\"\n'''train[\"id_code\"]=train[\"id_code\"].apply(append_png)\ntrain.head()'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new_width  = 224\nnew_height = 224\n        \ndef preprocess_img(img):\n    img = cv2.morphologyEx(img, cv2.MORPH_CLOSE, (3,3))\n    img = np.uint8(img)\n    for c in range(0, 2):\n        img[:,:,c] = cv2.equalizeHist(img[:,:,c])\n    \n     # convert image to LAB color model\n    image_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n\n    # split the image into L, A, and B channels\n    l_channel, a_channel, b_channel = cv2.split(image_lab)\n\n    # apply CLAHE to lightness channel\n    clahe = cv2.createCLAHE(clipLimit=7.0, tileGridSize=(8, 8))\n    cl = clahe.apply(l_channel)\n\n    # merge the CLAHE enhanced L channel with the original A and B channel\n    merged_channels = cv2.merge((cl, a_channel, b_channel))\n\n    # convert iamge from LAB color model back to RGB color model\n    final_image = cv2.cvtColor(merged_channels, cv2.COLOR_LAB2BGR) \n    img = cv2.resize(final_image, (new_width,new_height), interpolation = cv2.INTER_AREA)\n    return img  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_img(img):\n    #img = cv2.cvtColor(img, cv2 . COLOR_BGR2RGB)\n    img = cv2.GaussianBlur ( img , ( 5 , 5 ), 0 )\n    img = np.uint8(img)\n    r, g, b = cv2.split(img)\n    clahe = cv2.createCLAHE(clipLimit=5.0, tileGridSize=(8, 8))\n    red = clahe.apply(r)\n    gr = clahe.apply(g)\n    bl = clahe.apply(b)\n    merged_channels = cv2.merge((red, gr, bl))\n    merged_channels = cv2.resize(merged_channels , (new_width,new_height), interpolation = cv2.INTER_AREA)\n    \n    bits_per_channel = 8\n    assert merged_channels.dtype == np.uint8\n\n    shift = 8-bits_per_channel\n    halfbin = (1 << shift) >> 1\n\n    return ((merged_channels.astype(int) >> shift) << shift) + halfbin    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nvalid=0.25\ntrain_datagen = ImageDataGenerator(preprocessing_function= process_img, validation_split=valid,\n                                   width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_img = []\ntitle_font = {'fontname':'Arial', 'size':'14'}\nIMG_FOLDER_PREFIX_i = \"../input/optos-all/optos_all/optos_all/\"\n#IMG_EXTENSION = \".png\"\nNUM_IMAGES = 8\n\nfor i in range(NUM_IMAGES):\n    image_path = IMG_FOLDER_PREFIX_i + str(train['id_code'][i])\n    n = cv2.imread(image_path)\n    n = process_img(n)\n    cv_img.append(n)\n    \nplt.figure(figsize=(20, 20))\nfor i in range(NUM_IMAGES):\n    plt.subplot(4,4,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.text(0.0, 0.0, 'diagnosis'+str(train['diagnosis'][i]), **title_font)\n    plt.imshow(cv_img[i], cmap=plt.cm.binary)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nrun_opts = tf.RunOptions(report_tensor_allocations_upon_oom = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['diagnosis']=train['diagnosis'].apply(str)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train, data_test, labels_train, labels_test = train_test_split(train, train['diagnosis'], \n                                                                    test_size=0.25)\nprint(len(data_train), len(data_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = '../input/optos-all/optos_all/optos_all/'\ntrain_generator = train_datagen.flow_from_dataframe(dataframe=data_train,  directory=path, \n    x_col='id_code', y_col=\"diagnosis\", target_size=(new_width,new_height), batch_size=50, class_mode='categorical',\n                                                    subset='training',seed=42, drop_duplicates=True)\n\nvalidation_generator = train_datagen.flow_from_dataframe(dataframe=data_train, directory=path,  \n  x_col='id_code', y_col=\"diagnosis\",target_size=(new_width,new_height), batch_size=50, class_mode='categorical',\n                                                         subset='validation',seed=42, drop_duplicates=True) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#filepath = '\\\\kaggle\\\\working\\\\'\n#mc = ModelCheckpoint(filepath, monitor='val_loss', verbose=0,save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly_stopping_callback = EarlyStopping(monitor='val_acc', patience=3, restore_best_weights=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.layers import Input\ninput_tensor = Input(shape=(new_width,new_height,3)) \nbase_n=keras.applications.vgg19.VGG19(include_top=False,\n     weights='../input/keraspretrainedmodel/keras-pretrain-model/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5',\n                                      input_tensor=input_tensor)\nmodel_i = Sequential()\nmodel_i.add(base_n)\n\nmodel_i.add(Flatten())\nmodel_i.add(Dense(512))\nmodel_i.add(Activation('relu'))\nmodel_i.add(Dropout(0.5))\nmodel_i.add(Dense(5))\nmodel_i.add(Activation('softmax'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.optimizers import Adam\nmodel_i.compile(loss='categorical_crossentropy',  optimizer=Adam(lr=1e-5), metrics=['accuracy'], options = run_opts)\n#model_i.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epoch=25\nbatch_size_train=50\nsteps_per_epoch = (len(train)*(1-valid)//batch_size_train)    \nprint(steps_per_epoch)\nvalidation_steps=len(train)*valid// batch_size_train\nprint(validation_steps)\nmodel_i.fit_generator(generator=train_generator,steps_per_epoch=steps_per_epoch, validation_data=validation_generator,\n                    validation_steps=validation_steps,epochs=nb_epoch, \n                      callbacks=[early_stopping_callback])\n\nprint(\"Обучение остановлено на эпохе\", early_stopping_callback.stopped_epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.eval(model_i.optimizer.lr.assign(0.000001))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epoch=25\nbatch_size_train=32\nsteps_per_epoch = (len(train)*(1-valid)//batch_size_train)    \nprint(steps_per_epoch)\nvalidation_steps=len(train)*valid// batch_size_train\nprint(validation_steps)\nmodel_i.fit_generator(generator=train_generator,steps_per_epoch=steps_per_epoch, validation_data=validation_generator,\n                    validation_steps=validation_steps,epochs=nb_epoch, \n                      callbacks=[early_stopping_callback])\n\nprint(\"Обучение остановлено на эпохе\", early_stopping_callback.stopped_epoch)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=ImageDataGenerator(preprocessing_function= process_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\ndata_test_generator = test_data.flow_from_dataframe(dataframe=data_test,  directory=path, \n    x_col='id_code', y_col=\"diagnosis\", target_size=(new_width,new_height), batch_size= batch_size, class_mode=None, \n                                                    seed=42, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_test_generator.reset()\npred_i = model_i.predict_generator (data_test_generator, steps = (len(data_test)//batch_size+1), verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict=np.argmax(pred_i,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = labels_test\nmy_list = labels.values\nmy_list= [int(item) for item in my_list]\nprint(my_list[:20])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix\nmulticlass = confusion_matrix(my_list, predict)\nclass_names = ['0', '1', '2', '3', '4']\n\nfig, ax = plot_confusion_matrix(conf_mat=multiclass,\n                                colorbar=True,\n                                show_absolute=True,\n                                show_normed=True,\n                                class_names=class_names)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import r2_score\nr2_score(my_list, predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(my_list, predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"id_code\"]=test[\"id_code\"].apply(append_png)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_datagen=ImageDataGenerator(preprocessing_function= process_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator=test_datagen.flow_from_dataframe(dataframe=test, \n        directory='../input/aptos2019-blindness-detection/test_images', \n        x_col=\"id_code\", y_col=\"diagnosis\", target_size=(new_width,new_height), batch_size=batch_size, seed=42, \n                                                class_mode=None, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\ni_test = model_i.predict_generator (test_generator, steps = (len(test)//batch_size+1), verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i_test=np.argmax(i_test,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission[\"diagnosis\"] = i_test\nsample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":1}