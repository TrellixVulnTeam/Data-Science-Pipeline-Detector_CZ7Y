{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport time\nimport torchvision\nimport torch.nn as nn\nfrom tqdm import tqdm_notebook as tqdm\nfrom PIL import Image, ImageFile\nfrom torch.utils.data import Dataset\nimport torch\nimport torch.optim as optim\nfrom torchvision import transforms\nfrom torch.optim import lr_scheduler\nimport os\n\ndevice = torch.device('cuda:0')\nImageFile.LOAD_TRUNCATED_IMAGES = True\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTrain(Dataset):\n    def __init__(self, csv_file):\n        self.data = pd.read_csv(csv_file)\n    \n    def __len__(self):\n        return len(self.data)\n    \n    def __getitem__(self, idx):\n        img_name = os.path.join(\"../input/aptos2019-blindness-detection/train_images\",\n                                self.data.loc[idx,'id_code']+'.png')\n        image = Image.open(img_name)\n        image = image.resize((256,256), resample = Image.BILINEAR)\n        label = torch.tensor(self.data.loc[idx, 'diagnosis'])\n        return {'image': transforms.ToTensor()(image),\n               'labels' : label\n               }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Get the model\nmodel = torchvision.models.resnet101(pretrained = False)\nmodel.load_state_dict(torch.load(\"../input/pytorch-pretrained-models/resnet101-5d3b4d8f.pth\")) # Loads a modelâ€™s parameter dictionary using a deserialized state_dict.\nnum_features = model.fc.in_features # in_feature is the number of inputs for your linear layer:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fc = nn.Linear(2048,1)\nmodel = model.to(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Create dataset + optimizer\n\ntrain_dataset  = RetinopathyDatasetTrain(csv_file= '../input/aptos2019-blindness-detection/train.csv')\ndata_loader = torch.utils.data.DataLoader(train_dataset, batch_size= 16, shuffle = True, num_workers = 4)\n\nplist = [\n    {\n        'params' : model.layer4.parameters(), 'lr':1e-4, 'weight' : 0.001\n    },\n    {\n        'params': model.fc.parameters(), 'lr': 1e-3\n    }\n]\n\noptimizer= optim.Adam(plist, lr = 0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size = 10) # Sets the learning rate of each parameter group to the initial lr decayed by gamma every step_size epochs. When last_epoch=-1, sets initial lr as lr\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Training loop\n\nsince = time.time()\ncriterion = nn.MSELoss()\nnum_epochs = 15\nfor epoch in range(num_epochs):\n    print('Epoch {}/{}'.format(epoch, num_epochs-1))\n    print('-'*10)\n    scheduler.step() # for every 10 steps,(step_size =10), lr will be changed. But step() should be called on each epoch to get this behaviour\n    model.train()\n    running_loss = 0.0\n    tk0 = tqdm(data_loader, total =int(len(data_loader)))\n    counter =0\n    for bi, d in enumerate(tk0):\n        inputs = d['image']\n        labels = d['labels'].view(-1,1)\n        inputs = inputs.to(device, dtype = torch.float)\n        labels = labels.to(device, dtype = torch.float)\n        optimizer.zero_grad()\n        with torch.set_grad_enabled(True):\n            outputs =model(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n        running_loss += loss.item() * inputs.size(0)\n        counter +=1\n        tk0.set_postfix(loss = (running_loss/(counter*data_loader.batch_size)))   #Set/modify postfix (additional stats) with automatic formatting based on datatype.\n    epoch_loss = running_loss/len(data_loader)\n    print('Training loss: {:.4f}'.format(epoch_loss))\n\ntime_elapsed = time.time() - since\nprint('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed//60, time_elapsed %60))\ntorch.save(model.state_dict(),'model.bin') #torch can read either .bin or .pt or .anything so it's probably convention employed by the creators of that repository.\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reference: https://www.kaggle.com/abhishek/very-simple-pytorch-training-0-59\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}