{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport random\nprint(os.listdir(\"../input\"))\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nimport torch.optim as optim\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.metrics import accuracy_score\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\ntorch.manual_seed(11)\nnp.random.seed(13)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/train.csv\")\ntrain_data.head()\n\ntrain, test = train_test_split(train_data, test_size=0.1)\nprint(\"Training size : \" + str(len(train)))\nprint(\"Testing size : \" + str(len(test)))\nROOT_DIR = \"../input/train_images/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(Dataset):\n    def __init__(self, root_dir, csv_file, transforms = None):\n        self.root_dir = root_dir\n        self.transform = transforms\n        self.csvfile = csv_file\n        \n    def __len__(self):\n        return len(self.csvfile)\n    \n    def __getitem__(self, idx):\n        label = self.csvfile.iloc[idx, 1]\n        label = to_categorical(label, num_classes=5)\n        \n        img = cv2.imread(self.root_dir + self.csvfile.iloc[idx, 0] + \".png\")\n        img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_NEAREST)\n        if self.transform:\n            img = self.transform(img)\n        \n        return (img, torch.FloatTensor(label))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = MyDataset(root_dir=ROOT_DIR, csv_file = train,\n                                transforms = transforms.Compose([\n                                    transforms.ToPILImage(),\n                                    transforms.RandomApply([\n                                        transforms.RandomAffine(10.0, shear=15.0),\n                                        transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3)\n                                    ]),\n                                    transforms.ToTensor()\n                                ]))\n\ntesting_data = MyDataset(root_dir=ROOT_DIR, csv_file = test,\n                                transforms = transforms.Compose([\n                                    transforms.ToPILImage(),\n                                    transforms.RandomApply([\n                                        transforms.RandomAffine(19.0, shear=15.0),\n                                        transforms.RandomPerspective(distortion_scale=0.5, p=0.5, interpolation=3)\n                                    ]),\n                                    transforms.ToTensor()\n                                ]))\n\nnloader = DataLoader(training_data, batch_size=32)\nploader = DataLoader(testing_data, batch_size=32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\nclass VGG11(nn.Module):\n    def __init__(self, inchannels = 3):\n        super(VGG11, self).__init__()\n        self.network = nn.Sequential(\n            nn.Conv2d(inchannels, 64, 7, stride=2, padding = 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(64, 128, 3, stride=2, padding = 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(128, 256, 3, stride=1, padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(256, 256, 3, stride=2, padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(256, 256, 3, stride=2, padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(256, 256, 3, stride=2, padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(256, 256, 3, stride=2, padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(256, 256, 3, stride=2, padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Conv2d(256, 256, 3, stride=2, padding = 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.AvgPool2d(2),\n            Flatten(),\n            nn.Linear(256, 128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.5),\n            nn.Linear(128, 5),\n            nn.Softmax(dim=1)\n        )\n\n    def forward(self, x):\n        return self.network(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = VGG11()\nmodel.cuda()\n\nopt = optim.Adam(model.parameters())\nloss = nn.BCELoss()\n\ntrain_loss_epoch = []\ntrain_acc_epoch = []\n\nloss_epoch = []\nacc_epoch = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for j in tqdm(range(10), desc=\"Epoch : \"):\n    losses = 0\n    accuracy = 0\n    with tqdm(total = len(nloader)) as ibar:\n        model = model.train()\n        for i, batch in enumerate(nloader):\n            pred = model(batch[0].cuda())\n            l = loss(pred, batch[1].cuda())\n            l.backward()\n            opt.step()\n            accuracy += accuracy_score(np.argmax(batch[1].numpy(), axis=1), np.argmax(pred.detach().cpu().numpy(), axis=1))\n            losses += l.item()\n            ibar.set_description(\"TRAINING Loss:{:.4f},Acc:{:.3f}\".format(\n                losses/(i+1), (accuracy/(i+1)) * 100.0\n            ))\n            ibar.update(1)\n        train_loss_epoch.append(losses/(i+1))\n        train_acc_epoch.append(accuracy/(i+1))\n        \n    losses = 0\n    accuracy = 0\n    with tqdm(total = len(ploader)) as kbar:\n        model = model.eval()\n        for k, batch in enumerate(ploader):\n            pred = model(batch[0].cuda())\n            l = loss(pred, batch[1].cuda())\n            accuracy += accuracy_score(np.argmax(batch[1].numpy(), axis=1), np.argmax(pred.detach().cpu().numpy(), axis=1))\n            losses += l.item()\n            kbar.set_description(\"TESTING Loss:{:.4f},Acc:{:.3f}\".format(\n                losses/(k+1), (accuracy/(k+1)) * 100.0\n            ))\n            kbar.update(1)\n        loss_epoch.append(losses/(k+1))\n        acc_epoch.append(accuracy/(k+1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = (15,10)\n\nplt.subplot(221)\nplt.title(\"Training Accuracy\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Accuracy\")\nplt.plot(list(range(len(train_acc_epoch))), train_acc_epoch)\n\nplt.subplot(222)\nplt.title(\"Training Loss\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Loss\")\nplt.plot(list(range(len(train_loss_epoch))), train_loss_epoch)\n\nplt.subplot(223)\nplt.title(\"Testing Accuracy\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Accuracy\")\nplt.plot(list(range(len(acc_epoch))), acc_epoch)\n\nplt.subplot(224)\nplt.title(\"Testing Loss\")\nplt.xlabel(\"Iteration\")\nplt.ylabel(\"Loss\")\nplt.plot(list(range(len(loss_epoch))), loss_epoch)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = os.listdir(\"../input/test_images/\")\n\nmodel = model.eval()\nans = {}\nfor i in range(len(test)):\n    img = cv2.imread(\"../input/test_images/\" + test[i])\n    img = cv2.resize(img, (512, 512), interpolation = cv2.INTER_NEAREST)\n    img = img.transpose((2, 0, 1))\n    img = np.expand_dims(img, axis=0) / 255.0\n    img = torch.FloatTensor(img)\n    pred = model(img.cuda())\n    ans[test[i]] = np.argmax(pred.detach().cpu().numpy()[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {'id_code' : list(ans.keys()), 'diagnosis' : list(ans.values())}\ndata = pd.DataFrame.from_dict(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}