{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n\nimport os\nprint(os.listdir(\"../input/aptos2019-blindness-detection/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 属性配置"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import sys\n# package_dir = \"../input/pretrainedmodels/pretrained-models/pretrained-models.pytorch-master/\"\n# sys.path.insert(0, package_dir)\n\n# import pretrainedmodels","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch.nn as nn\n# import torch\n# model = pretrainedmodels.__dict__['vgg16'](pretrained=None)\n# model.last_linear = nn.Sequential( nn.Linear(in_features=4096, out_features=5),\n#                                     nn.Softmax()\n#                                   )\n# model\n\n# model.load_state_dict(torch.load(\"../input/mymodel/vgg_stact_dict.pt\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from PIL import Image\n# import matplotlib.pyplot as plt \n# train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\n# c = 0\n# imgs = []\n# plt.figure(figsize=(15, 10/5*3))\n# for i in range(10):\n#     f = os.path.join('../input/aptos2019-blindness-detection/train_images/{0}.png'.format(train['id_code'][i]))\n#     img = Image.open(f)\n#     plt.subplot(2 ,5, i+1)\n#     plt.imshow(img)  \n# plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import unicode_literals\nfrom PIL import Image\nimport os\nimport torch\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt \n# %matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import transforms as tfs\nfrom torch.utils.data import DataLoader,Dataset\nclass Config:\n    data_dir = '../input/aptos2019-blindness-detection/'\n    crop_size = 224\n    train_batch_size = 64\n    test_batch_size = 1\n    lr = 1e-3\n    momentum = 0.9\n    epochs = 20\n    print_every = 5\n    \nopt = Config()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 数据加载"},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_file(data_dir, split = 'train'):\n    file = os.path.join(data_dir + ('test.csv' if split is 'test' else 'train.csv' ))\n    dataset = pd.read_csv(file)\n    if split is 'test':\n        data = [os.path.join(data_dir, 'test_images/{0}.png' .format(dataset.iloc[i].values[0]) )\n                for i in range(len(dataset))]\n        label = 0\n        return data, label\n    else :\n        data =[os.path.join(data_dir, 'train_images/{0}.png'.format(dataset.iloc[i].values[0])) \n               for i in range(len(dataset))]\n        label = dataset.iloc[:,1].values \n        train_data, eval_data, train_label, eval_label = train_test_split(data, label)\n        if split is 'eval':\n            return eval_data, eval_label\n        else:\n            return train_data, train_label\n\ndef transforms(img, crop_size):\n    img_tfs = tfs.Compose([\n        tfs.RandomResizedCrop(crop_size),\n        tfs.RandomHorizontalFlip(p=0.2),\n#         tfs.RandomRotation(degrees = (30,90)),\n        tfs.ToTensor(),\n        tfs.Normalize([0.5, 0.5 ,0.5],[0.5, 0.5, 0.5])\n        \n    ])\n    img = img_tfs(img)\n    return img\n\nclass APTOSSet(Dataset):\n    def __init__(self, transform , split = 'train',\n        data_dir=opt.data_dir,crop_size=opt.crop_size):\n        data_list, label = read_file(data_dir, split = split)\n        self.transform = transform\n        self.data_list = data_list\n        self.label = label\n        self.crop_size = crop_size\n        self.split = split\n    def __getitem__(self, idx):\n        img = self.data_list[idx]\n        img = Image.open(img) \n        img = transforms(img, self.crop_size)\n        if self.split is 'test' :\n            return img\n        else:\n            label = self.label[idx]\n            return img , label\n\n    def __len__(self):\n        return len(self.data_list)\n\ntrain_set = APTOSSet(split='train', transform=transforms)\neval_set  = APTOSSet(split='eval', transform= transforms)\ntest_set = APTOSSet(split='test',transform= transforms)\nAPT_train = DataLoader(train_set, opt.train_batch_size, shuffle=True,num_workers= 0)\nAPT_eval = DataLoader(eval_set, opt.train_batch_size, shuffle=True,num_workers= 0)\nAPT_test = DataLoader(test_set, opt.test_batch_size, shuffle=False,num_workers= False)\n# for inputs, labels in APT_train:\n#     print(inputs)\n\n#可视化\n# vis_trains = []\n# for i in range(10):\n#     img, _ = train_set[i]\n#     vis_trains.append(img)\n# plt.figure(figsize=(15,len(vis_trains)/5*3))\n# for c in range(len(vis_trains)):\n#     plt.subplot(len(vis_trains)/5, 5, c+1)\n#     plt.imshow(vis_trains[c])\n# plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 模型搭建\n>使用迁移学习，利用 vgg16 googlenet   res-net三个模型作比较"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import  torchvision.models  as models\n# import torch.nn as nn\n# model = pretrainedmodels.__dict__['vgg16'](pretrained=None)\nmodel = torch.load('../input/mymodel/vgg16_model.pt')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for params in model.parameters():\n    params.requires_grad = False\nmodel.eval()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from torch import optim\n# import torch\n# criterion = nn.NLLLoss()\n# optimizer = optim.SGD(model.parameters(), lr = opt.lr, momentum = opt.momentum)\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\ndevice\nmodel.to(device)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# train\n\n采用一次训练一次测试速度慢，运算代价大？多次训练一次测试明显能减少 运算量"},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.to(device)\n\n# step = 0\n# run_loss = 0\n# lst_tloss = []\n# ac_train = []\n# for epoch in range(opt.epochs):\n#     train_correct = 0\n#     for inputs, labels in APT_train:\n#         step +=1\n#         inputs = inputs.to(device)\n#         labels = labels.to(device)\n#         optimizer.zero_grad()\n#         outputs = model.forward(inputs)\n#         loss = criterion(outputs, labels)\n#         pred = outputs.data.max(1, keepdim=True)[1]\n#         loss.backward()\n#         optimizer.step()\n#         train_correct += pred.eq(labels.data.view_as(pred)).cpu().sum().item()\n#         train_accuracy = train_correct/len(APT_train.dataset)\n#         run_loss += loss.item()\n#     lst_tloss.append(run_loss)\n#     ac_train.append(train_accuracy)\n     \n#     test_loss = 0\n#     accuracy = 0\n#     model.eval()\n#     with torch.no_grad():\n#         for inputs, labels in APT_eval:\n#             inputs, labels = inputs.to(device), labels.to(device)\n#             outputs = model.forward(inputs)\n#             pred = outputs.data.max(1, keepdim=True)[1]\n#             batch_loss = criterion(outputs, labels)\n#             test_loss += batch_loss\n#             accuracy += pred.eq(labels.data.view_as(pred)).cpu().sum().item()\n#     print(f\"Epoch {epoch+1}/{opt.epochs}.. \"\n#           f\"Train loss: {run_loss/len(APT_train):.3f}.. \"\n#           f\"Train accuracy: {train_correct/len(APT_train.dataset):.3f}..\"\n#           f\"Test loss: {test_loss/len(APT_eval):.3f}.. \"\n#           f\"Test accuracy: {accuracy/len(APT_eval.dataset):.3f}\")\n#     run_loss = 0\n#     model.train()\n                    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import matplotlib.pyplot as plt\n# a=[2,6,5,4,3]\n# plt.plot(np.arange(1, 6), a, color= 'b')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.to(device)\n\n# step = 0\n# run_loss = 0\n# lst_tloss = []\n# ac_train = []\n# test_losses = []\n# test_acces = []\n# for epoch in range(opt.epochs):\n#     train_correct = 0\n#     for inputs, labels in APT_train:\n#         step +=1\n#         inputs = inputs.to(device)\n#         labels = labels.to(device)\n#         optimizer.zero_grad()\n#         outputs = model.forward(inputs)\n#         pred = outputs.data.max(1, keepdim=True)[1]\n#         loss = criterion(outputs, labels)\n#         loss.backward()\n#         optimizer.step()\n#         train_correct += pred.eq(labels.data.view_as(pred)).cpu().sum().item()\n#         run_loss += loss.item()\n       \n#         if step % opt.print_every ==0:\n#             test_loss = 0\n#             correct = 0\n#             model.eval()\n#             with torch.no_grad():\n#                 for inputs, labels in APT_eval:\n#                     inputs, labels = inputs.to(device), labels.to(device)\n#                     outputs = model.forward(inputs)\n#                     pred = outputs.data.max(1, keepdim=True)[1]\n#                     batch_loss = criterion(outputs, labels)\n#                     test_loss += batch_loss\n#                     correct += pred.eq(labels.data.view_as(pred)).cpu().sum().item()\n#             accuracy = float(correct)/ len(APT_eval.dataset)\n#             test_losses.append(test_loss/ len(APT_eval))  \n#             test_acces.append(accuracy)\n            \n#             lst_tloss.append(run_loss/opt.print_every)\n#             ac_train.append(train_correct/(opt.print_every*opt.train_batch_size))\n#             print(f\"Epoch {epoch+1}/{opt.epochs}.. \"\n#                   f\"Train loss: {run_loss/opt.print_every:.3f}.. \"\n#                   f\"Train accuracy: {train_correct/(opt.print_every*opt.train_batch_size):.3f}..\"\n#                   f\"Test loss: {test_loss/len(APT_eval):.3f}.. \"\n#                   f\"Test accuracy: {accuracy:.3f}\")\n#             run_loss = 0\n#             train_correct = 0\n#             model.train()\n#             torch.save(model.state_dict(),'vgg_stact_dict.bin')\n#             torch.save(model, 'vgg16_model.bin')\n            \n# import matplotlib.pyplot as plt\n# # % inline matplotlib\n# plt.subplot(211)\n# plt.title('loss')\n# plt.plot(np.arange(1, len(lst_tloss)+1), lst_tloss, color= 'b')\n# plt.plot(np.arange(1, len(test_losses)+1), test_losses, color='r')\n\n# plt.subplot(212)\n# plt.title('acc')\n# plt.plot(np.arange(1, len(ac_train)+1), ac_train, color ='b')\n# plt.plot(np.arange(1, len(test_acces)+1), test_acces, color = 'r')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"def test_predict(model):\n    model.eval()\n    prediction = []\n    for data in APT_test:\n        data = data.to(device)\n        outputs = model(data)\n        pred = outputs.data.max(1, keepdim=True)[1]\n        prediction.append(int(pred))\n    return prediction\n\nsub = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nsub['diagnosis'] = test_predict(model)\nsub.to_csv('submission.csv', index= False)\nsub.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}