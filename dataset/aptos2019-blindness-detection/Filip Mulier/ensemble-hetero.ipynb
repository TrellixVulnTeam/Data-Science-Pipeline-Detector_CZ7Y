{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\ndef walkdir(path='/kaggle/input'):\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\nos.listdir('/kaggle/input')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\npackage_path = '../input/efficientnetpytorchpackage/EfficientNet-PyTorch-master'\nsys.path.append(package_path)\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai.vision import *\nimport cv2\nimport fastai\n\n\nprint(torch.__version__)\nprint(fastai.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function Definitions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndef get_prob(arr):\n    #print(arr.shape)\n    \n    probs=torch.zeros(arr.size(0)+1,dtype=arr.dtype)\n    probs[4]=arr[3]\n    probs[3]=(arr[2]-arr[3]).relu()\n    probs[2]=(arr[1]-arr[2]).relu()\n    probs[1]=(arr[0]-arr[1]).relu()\n    probs[0]=1-arr[0]\n\n    return probs\n\ndef get_pred(probs):\n    #print(arr.shape)\n    return probs.argmax(0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_image_dir = os.path.join('..', 'input/aptos2019-blindness-detection/')\ntrain_dir = os.path.join(base_image_dir,'train_images/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_prob_s1(arr):\n    #convert stage 1 preds to full model for all 5 levels\n    # counts are from training set to calc naive bayes\n    probs=torch.zeros(arr.size(0)+3,dtype=arr.dtype)\n    probs[4]=arr[1]*295/1857\n    probs[3]=arr[1]*193/1857\n    probs[2]=arr[1]*999/1857\n    probs[1]=arr[1]*370/1857\n    probs[0]=arr[0]\n    \n    return probs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clahe(img):\n    \n    clahe = cv2.createCLAHE(clipLimit=2 , tileGridSize=(8,8))\n    img_new_1 = clahe.apply(img[:,:,0])\n    img_new_2 = clahe.apply(img[:,:,1])\n    img_new_3 = clahe.apply(img[:,:,2])\n    img_merge = cv2.merge([img_new_1,img_new_2,img_new_3])\n    \n    return img_merge\n\ndef clahel(img):\n    \n    image = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n    clahe = cv2.createCLAHE(clipLimit=2 , tileGridSize=(8,8))\n    img_new_1 = clahe.apply(image[:,:,0])\n    img_merge = cv2.merge([img_new_1,image[:,:,1],image[:,:,2]])\n    \n    return cv2.cvtColor(img_merge,cv2.COLOR_LAB2RGB)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def img_load(p,IMG_SIZE=512):\n    image = cv2.imread(p)\n    image = crop_image_from_gray(image)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    height, width = image.shape[:2]\n    m=max(height,width)\n    \n    f=IMG_SIZE/m\n    image = cv2.resize(image, None,fx=f, fy=f)\n    \n    return image\n\n\ndef img_proc(image,blur_rad=10,use_clahel=False,use_clahe=False):\n    \n    if(use_clahel==True):\n        image = clahel(image)\n    if(use_clahe==True):\n        image = clahe(image)\n    \n    if (blur_rad>0):\n        image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0), blur_rad) ,-4 ,128)\n    return Image(pil2tensor(image, np.float32).div_(255))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Models"},{"metadata":{"trusted":true},"cell_type":"code","source":"walkdir('/kaggle/input/aptos-models')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path='/kaggle/input/aptos-models/'\n#No Processing\nlearn1=load_learner(model_path,'finalresnet34-all_train_images_512.pkl')\nlearn2=load_learner(model_path,'finalefficientnet-b6-all_train_images_512.pkl')\nlearn3=load_learner(model_path,'final-rn50-nz-nip.pkl')\n#learn4=load_learner(model_path,'final-rn34-nz-nip.pkl')\n\n\n#Blur=10\nlearn_b10_1=load_learner(model_path,'final-rn34-nonzero.pkl')\nlearn_b10_2=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_blur.pkl')\nlearn_b10_3=load_learner(model_path,'finalresnet34-all_train_images_512_blur.pkl')\n\n#Clahe\nlearn_clahe_1=load_learner(model_path,'finalresnet34-all_train_images_512_clahe.pkl')\nlearn_clahe_2=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_clahe.pkl')\n\n#Clahel\n#learn_clahel_1=load_learner(model_path,'final-rn34-nz-clahel.pkl')\n#learn_clahel_2=load_learner(model_path,'final-rn50-nz-clahel.pkl')\nlearn_clahel_3=load_learner(model_path,'finalresnet34-all_train_images_512_clahel.pkl')\nlearn_clahel_4=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_clahel.pkl')\n\n#Blur=50\n#learn_blur_50_1=load_learner(model_path,'finalresnet34-all_train_images_512_blur_50.pkl')\n#learn_blur_50_2=load_learner(model_path,'finalefficientnet-b6-all_train_images_512_blur_50.pkl')\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"walkdir('/kaggle/input/aptos_2_stage')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path='/kaggle/input/aptos_2_stage/'\n#Stage 2 No Processing\nlearn5=load_learner(model_path,'final-s2resnet34-all_train_images_512.pkl')\nlearn6=load_learner(model_path,'final-s2-efficientnet-b6-all_train_images_512.pkl')\n\n#Stage 2 Blur=10\nlearn_b10_4=load_learner(model_path,'final-s2-resnet34-all_train_images_512_blur.pkl')\n\n\n#Stage 2 Clahe\nlearn_clahe_3=load_learner(model_path,'final-s2-resnet34-all_train_images_512_clahe.pkl')\nlearn_clahe_4=load_learner(model_path,'final-s2-efficientnet-b6-all_train_images_512_clahe.pkl')\n\n#Stage 2 Clahel\nlearn_clahel_5=load_learner(model_path,'final-s2-resnet34-all_train_images_512_clahel.pkl')\n\n#stage 1 model\nlearn_s1=load_learner('/kaggle/input/aptos_2_stage/','final-s1resnet34-all_train_images_512_clahe.pkl')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict Test Set"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"sample_df = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nsample_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE=512\n\n\ntest_path='/kaggle/input/aptos2019-blindness-detection/test_images/'\nfor it in progress_bar(sample_df.index):\n    fns=str(sample_df.id_code[it])+'.png'\n\n    p=test_path + fns\n\n    image = cv2.imread(p)\n    image = crop_image_from_gray(image)\n    height, width = image.shape[:2]    \n    m=max(height,width)            \n    f=IMG_SIZE/m\n    image_no_proc = cv2.resize(image, None,fx=f, fy=f)\n    image_no_proc = cv2.cvtColor(image_no_proc, cv2.COLOR_BGR2RGB)\n    image_blur_10=cv2.addWeighted ( image_no_proc,4, cv2.GaussianBlur( image_no_proc , (0,0), 10) ,-4 ,128)\n    image_clahe = clahe(image_no_proc)\n    image_clahel = clahel(image_no_proc)\n    #image_blur_50 = cv2.addWeighted ( image_no_proc,4, cv2.GaussianBlur( image_no_proc , (0,0), 50) ,-4 ,128)\n\n    \n    \n\n    probs=0\n    \n    \n\n    #no processing\n    imagef=Image(pil2tensor(image_no_proc, np.float32).div_(255))  \n\n    pred_class,pred_idx,outputs = learn1.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n    pred_class,pred_idx,outputs = learn2.predict(imagef)\n    probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn3.predict(imagef)\n    probs=probs+get_prob(outputs)\n    \n    #pred_class,pred_idx,outputs = learn4.predict(imagef)\n    #probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn5.predict(imagef)\n    probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn6.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n    #blur=10\n    imagef=Image(pil2tensor(image_blur_10, np.float32).div_(255))\n\n    pred_class,pred_idx,outputs = learn_b10_1.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n    pred_class,pred_idx,outputs = learn_b10_2.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n    pred_class,pred_idx,outputs = learn_b10_3.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n    pred_class,pred_idx,outputs = learn_b10_4.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n\n\n    #clahe\n    imagef=Image(pil2tensor(image_clahe, np.float32).div_(255))\n    \n    # stage 1\n    pred_class,pred_idx,outputs = learn_s1.predict(imagef)\n    probs=probs+get_prob_s1(outputs)\n    \n    pred_class,pred_idx,outputs = learn_clahe_1.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n    pred_class,pred_idx,outputs = learn_clahe_2.predict(imagef)\n    probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn_clahe_3.predict(imagef)\n    probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn_clahe_4.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n\n    #clahel\n    imagef=Image(pil2tensor(image_clahel, np.float32).div_(255))\n    #pred_class,pred_idx,outputs = learn_clahel_1.predict(imagef)\n    #probs=probs+get_prob(outputs)\n\n    #pred_class,pred_idx,outputs = learn_clahel_2.predict(imagef)\n    #probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn_clahel_3.predict(imagef)\n    probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn_clahel_4.predict(imagef)\n    probs=probs+get_prob(outputs)\n    \n    pred_class,pred_idx,outputs = learn_clahel_5.predict(imagef)\n    probs=probs+get_prob(outputs)\n\n    #blur=50\n\n    #imagef=Image(pil2tensor(image_blur_50, np.float32).div_(255))\n    #pred_class,pred_idx,outputs = learn_blur_50_1.predict(imagef)\n    #probs=probs+get_prob(outputs)\n\n    #pred_class,pred_idx,outputs = learn_blur_50_2.predict(imagef)\n    #probs=probs+get_prob(outputs)\n\n    preds2=get_pred(probs).numpy()\n    #print(pred_class, pred_idx,outputs[pred_idx])\n    #sample_df.diagnosis[it]=preds2.numpy()\n    \n    \n    sample_df.loc[it,'diagnosis']=preds2\n    #print(sample_df.loc[it,'diagnosis'])\nsample_df[0:20]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}