{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n - This model is mainly for my own learning of Autoencoders\n - You could use this model to score each image with the encoder, flatten, and use features in an XGB model"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Resources:\n\nhttps://blog.keras.io/building-autoencoders-in-keras.html"},{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Import some packages to use\nimport cv2\nimport numpy as np\nimport pandas as pd\n# matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline \n#To see our directory\nimport os\nimport random\nimport gc   #Gabage collector for cleaning deleted data from memory\n# sklearn\nfrom sklearn.model_selection import train_test_split\n# keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import img_to_array, load_img\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dropout, MaxPooling2D\nfrom keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.utils import to_categorical\nfrom keras.callbacks import EarlyStopping, LearningRateScheduler\nfrom keras.applications import DenseNet121\n# math\nimport math","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Data & Targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\nids_and_target = train_df[['id_code','diagnosis']]\nonehottarget = pd.get_dummies(ids_and_target['diagnosis'])\nids_and_target = ids_and_target.join(onehottarget)\nprint(ids_and_target.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#densenet = DenseNet121(\n#    weights='../input/densenet-keras/DenseNet-BC-121-32-no-top.h5',\n#    include_top=False,\n#    input_shape=(280,280,3)\n#)","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"input_img = Input(shape=(280, 280, 3))  # adapt this if using `channels_first` image data format\n\n#x = densenet(input_img)\n\nx = Conv2D(40, kernel_size=3, activation='tanh', padding='same')(input_img)\nx = MaxPooling2D(pool_size=2, padding='same')(x)\nx = Conv2D(20, kernel_size=3, activation='tanh', padding='same')(x)\nx = MaxPooling2D(pool_size=2, padding='same')(x)\nx = Conv2D(8, kernel_size=3, activation='tanh', padding='same')(x)\nencoded = MaxPooling2D(pool_size=2, padding='same')(x)\n\nx = Conv2D(8, kernel_size=3, activation='tanh', padding='same')(encoded)\nx = UpSampling2D(size=2)(x)\nx = Conv2D(20, kernel_size=3, activation='tanh', padding='same')(x)\nx = UpSampling2D(size=2)(x)\nx = Conv2D(40, kernel_size=3, activation='tanh', padding='same')(x)\nx = UpSampling2D(size=2)(x)\ndecoded = Conv2D(3, kernel_size=3, activation='sigmoid', padding='same')(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this model maps an input to it's encoded represenations\nencoder = Model(input_img, encoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# full autoencoder model\nautoencoder = Model(input_img, decoded)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create a placeholder for an encoded input\nencoded_input = Input(shape=(35,35,8))\n# retrieve the last layer of the autoencoder model\ndecoder_layer = autoencoder.layers[-6]\n# create the decoder model\ndecoder = Model(encoded_input, decoder_layer(encoded_input))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\nautoencoder.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Images"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/aptos2019-blindness-detection/train_images'\ntest_dir = '../input/aptos2019-blindness-detection/test_images'\n\ntrain_imgs = ['../input/aptos2019-blindness-detection/train_images/{}'.format(i) for i in os.listdir(train_dir)]  #get images\ntest_imgs = ['../input/aptos2019-blindness-detection/test_images/{}'.format(i) for i in os.listdir(test_dir)] #get test images\n\nX_train, X_val = train_test_split(train_imgs, test_size=0.20, random_state=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function to Load Images\n\n- Will be used in our image generator\n- Technially this can load the targets as well, but here the target is just the image, so we'll just pass the image as the target here instead of the targets for the competition"},{"metadata":{"trusted":true},"cell_type":"code","source":"def LoadImagesAndTarget(files, lookup_table, shape):\n    # Initialize variables\n    i = 0\n    w = shape[0]\n    h = shape[1]\n    batch_images = np.zeros(((len(files)),w,h,3))\n    #print(\"batch image shape:\",batch_images.shape)\n    targetvals = np.zeros(((len(files)),5))\n    #print(\"target val shape: \",targetvals.shape)\n    for file in files:\n        # read in image\n        img = cv2.imread(file)\n        # resize\n        newimage = cv2.resize(img, shape) / 255\n        # add image to training set\n        batch_images[i] = newimage\n        #print(\"batch_images[i]\",batch_images[i])\n        # get the filename without extension\n        filename = os.path.splitext(os.path.basename(file))[0]\n        #print(\"filename: \",filename)\n        # only keep the row from the lookup table that matches our id\n        getrow = lookup_table.loc[lookup_table['id_code'] == filename]\n        # change the format to one-hot encoded, and save to target dataset\n        targetvals[i] = np.asmatrix(getrow[[0,1,2,3,4]].values[0], dtype=np.float32)\n        # get target based on filename\n        i += 1\n    #print(\"returning batches ...\")\n    #print(\"batch image shape:\",batch_images.shape)\n    return batch_images, batch_images","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create Image Generators"},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_generator(IMGDATA, batchsize, lookup_table, shape):\n    # needed for generator to work\n    while True:\n        # loop over all batches\n        for i in range(math.ceil(len(IMGDATA)/batchsize)):\n            # find the start and end index of the batch\n            window_slide = batchsize*i\n            start = min(0+window_slide,len(IMGDATA))\n            end = min(batchsize+window_slide,len(IMGDATA))\n            #print(\"Start: \",start)\n            #print(\"End: \",end)\n            # get images\n            Xtrain, Xtrain = LoadImagesAndTarget(IMGDATA[start:end], lookup_table, shape)\n            #print(\"batch \",i,\" completed!\")\n            yield [Xtrain, Xtrain]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_generator_val(IMGDATA, batchsize, lookup_table, shape):\n    # needed for generator to work\n    while True:\n        # loop over all batches\n        for i in range(math.ceil(len(IMGDATA)/batchsize)):\n            # find the start and end index of the batch\n            window_slide = batchsize*i\n            start = min(0+window_slide,len(IMGDATA))\n            end = min(batchsize+window_slide,len(IMGDATA))\n            # get images\n            Xval, Xval = LoadImagesAndTarget(IMGDATA[start:end], lookup_table, shape)\n            yield [Xval, Xval]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_epoch = 50\nbatch_size = 32\nn_steps = (len(X_train)) // batch_size\nautoencoder.fit_generator(image_generator(X_train, batch_size, ids_and_target, (280, 280)),\n                    steps_per_epoch=n_steps, \n                    epochs=nb_epoch, \n                    validation_data=image_generator_val(X_val, batch_size, ids_and_target, (280, 280)),\n                    validation_steps=(len(X_val) // batch_size),\n                    callbacks=[LearningRateScheduler(lambda _: 1.95)])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test Model Works\n\n- First we'll show the performance of the image reconstruction from the encoded image\n- Then we'll show we can score an image using the encoder model "},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir('../input/aptos2019-blindness-detection/train_images')\ni = 0\nfor file in files[0:2]:\n    batch_images = np.zeros((1,280,280,3))\n    # read in image\n    img = cv2.imread('../input/aptos2019-blindness-detection/train_images/' + file)\n    # resize\n    imgp = cv2.resize(img, (280,280))\n    # normalize\n    imgp = np.array(imgp) / 255.0\n    # reformat img\n    batch_images[0] = imgp\n    # score image\n    decoded_img = autoencoder.predict(batch_images, verbose=0)\n    # show image\n    #f, axarr = plt.subplots(1,2)\n    #axarr[0].imshow(img)\n    #axarr[1].imshow(np.squeeze(decoded_img, axis=0))\n    fig = plt.figure()\n    a=fig.add_subplot(1,2,1)\n    imgplot = plt.imshow(imgp)\n    a.set_title('Original')\n    a=fig.add_subplot(1,2,2)\n    imgplot = plt.imshow(np.squeeze(decoded_img, axis=0))\n    a.set_title('Decoded')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"files = os.listdir('../input/aptos2019-blindness-detection/train_images')\ni = 0\nfor file in files[0:2]:\n    batch_images = np.zeros((1,280,280,3))\n    # read in image\n    img = cv2.imread('../input/aptos2019-blindness-detection/train_images/' + file)\n    # resize\n    imgp = cv2.resize(img, (280,280))\n    # normalize\n    imgp = np.array(imgp) / 255.0\n    # reformat img\n    batch_images[0] = imgp\n    # score image\n    decoded_img = autoencoder.predict(batch_images, verbose=0)\n    # show image\n    #f, axarr = plt.subplots(1,2)\n    #axarr[0].imshow(img)\n    #axarr[1].imshow(np.squeeze(decoded_img, axis=0))\n    #fig = plt.figure()\n    #a=fig.add_subplot(1,2,1)\n    #imgplot = plt.imshow(imgp)\n    #a.set_title('Original')\n    #a=fig.add_subplot(1,2,2)\n    #imgplot = plt.imshow(np.squeeze(decoded_img, axis=0))\n    #a.set_title('Decoded')\n    print(\"Encoded Image:\")\n    print(encoder.predict(batch_images, verbose=0).shape)\n    print(encoder.predict(batch_images, verbose=0).flatten())\n    print(encoder.predict(batch_images, verbose=0).flatten().shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}