{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing required libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom matplotlib import patches\n#import matplotlib.pyplot.axis(*args, **kwargs)\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# read the csv file using read_csv function of pandas\ntrain_df = pd.read_csv('../input/train.csv')\n\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading single image using imread function of matplotlib\n#im_0 = Image(filename ='../input/train_images/002c21358ce6.png')\n\nimage0 = plt.imread('../input/train_images/000c1434d8d7.png')\nimage1 = plt.imread('../input/train_images/001639a390f0.png')\nimage2 = plt.imread('../input/train_images/0024cdab0c1e.png')\nimage3 = plt.imread('../input/train_images/002c21358ce6.png')\nimage4 = plt.imread('../input/train_images/005b95c28852.png')\nplt.imshow(image0)\nxmin, xmax, ymin, ymax = plt.axis()\nprint(xmin,xmax,ymin,ymax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(image4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of unique training images\ntrain_df['id_code'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Number of classes\ntrain_df['diagnosis'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntrain_df['diagnosis'] = train_df['diagnosis'].astype('str')\ntrain_df['id_code'] = train_df['id_code'].astype(str)+'.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen=ImageDataGenerator(\n    rescale=1./255, \n    validation_split=0.2)\n\nbatch_size = 32\n\ntrain_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(96,96),\n    subset='training')\n\ntest_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\", \n    target_size=(96,96),\n    subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Extract target column from training data\n* Convert target column to categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_df['diagnosis']\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train)\nnum_classes = y_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" CNN with good optimizer Adamax and using K folds:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, GaussianNoise, GaussianDropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, SeparableConv2D\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras import regularizers, optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    # create model\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), input_shape=[96,96,3], activation='relu'))\n    model.add(GaussianDropout(0.3))\n    model.add(Conv2D(32, (5, 5), activation='relu', kernel_constraint=maxnorm(3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(64, (5, 5), activation='relu'))\n    model.add(Conv2D(128, (7, 7), activation='relu'))\n    \n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n                   ,activity_regularizer=regularizers.l1(0.01)))\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.Adamax(lr=0.002), metrics=['accuracy'])\n    print('compiling model with optimizer Adamax and using filters 32,64,128')\n    return model\n#Adamax(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0)\n#keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n#original\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n#model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, Adamax=True), metrics=['accuracy'])\n#model.compile(optimizer='rmsprop',              loss='categorical_crossentropy',              metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To prevent overfitting,\n* monitoring the loss on validation/test set for minimum value\n* run epochs for 20 times when there is no decrease in val_loss. here it is done for epochs 3\n* save the best model that has low validation loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes= EarlyStopping(monitor='val_loss', mode ='min', verbose = 0, patience = 2)\nmc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Num_folds=3\nfor i in range(Num_folds):\n    print(\"Training on Fold: \",i+1)\n\n    model.fit_generator(generator=train_gen,              \n                                    steps_per_epoch=len(train_gen),\n                                    validation_data=test_gen,                    \n                                    validation_steps=len(test_gen),\n                                    epochs=3,\n                                    callbacks = [es, mc], \n                                    use_multiprocessing = True,\n                                    verbose=1)\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Due to the timeconstraints here for implementation we have limited epoch =3,(use epoch=20) folds=3(use fold more than this) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run predictions for given test data and submit the output file in required format (submission.csv)"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/sample_submission.csv')\n\nsubmission_df['id_code'] = submission_df['id_code'].astype(str)+'.png'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing test images:"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_datagen=ImageDataGenerator(rescale=1./255)\nsubmission_gen=submission_datagen.flow_from_dataframe(\n    dataframe=submission_df,\n    directory=\"../input/test_images\",\n    x_col=\"id_code\",    \n    batch_size=batch_size,\n    shuffle=False,\n    class_mode=None, \n    target_size=(96,96)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict_generator(submission_gen, steps = len(submission_gen))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_probability = np.argmax(predictions,axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['diagnosis'] = max_probability\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}