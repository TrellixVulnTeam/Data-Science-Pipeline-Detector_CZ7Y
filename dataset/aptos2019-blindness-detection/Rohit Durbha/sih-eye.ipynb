{"cells":[{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ntrainLabels = pd.read_csv(\"../input/diabetic-retinopathy-resized/trainLabels.csv\")\ntrainLabels_cropped = pd.read_csv(\"../input/diabetic-retinopathy-resized/trainLabels_cropped.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"","_uuid":"","trusted":true},"cell_type":"code","source":"import pandas as pd\ntrainLabels = pd.read_csv(\"../input/retinopathy-train-2015/trainLabels.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image, ImageOps\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\nfrom keras.losses import binary_crossentropy\nfrom keras.applications.resnet50 import preprocess_input\nimport keras.backend as K\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score\nfrom keras.utils import Sequence\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nIMG_SIZE = 512\nNUM_CLASSES = 5\nSEED = 77\nTRAIN_NUM = 1000 # use 1000 when you just want to explore new idea, use -1 for full train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ndf_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n\nx = df_train['id_code']\ny = df_train['diagnosis']\n\nx, y = shuffle(x, y, random_state=SEED)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n                                                      stratify=y, random_state=SEED)\nprint(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\ntrain_y.hist()\nvalid_y.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\n# display 10 images from each class\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\n        plt.imshow(image)\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image=cv2.addWeighted ( image, 0 , cv2.GaussianBlur( image , (0 ,0 ) , 10) ,-4 ,128)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dpi = 80 #inch\n\n# path=f\"../input/aptos2019-blindness-detection/train_images/5c7ab966a3ee.png\" # notice upper part\npath=f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\" # lower-right, this still looks not so severe, can be class3\nimage = cv2.imread(path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nheight, width = image.shape\nprint(height, width)\n\nSCALE=2\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128) # the trick is to add this line\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# OLD version of image color cropping, use crop_image_from_gray instead\n# The above code work only for 1-channel. Here is my simple extension for 3-channels image\ndef crop_image(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        h,w,_=img.shape\n#         print(h,w)\n        img1=cv2.resize(crop_image1(img[:,:,0]),(w,h))\n        img2=cv2.resize(crop_image1(img[:,:,1]),(w,h))\n        img3=cv2.resize(crop_image1(img[:,:,2]),(w,h))\n        \n#         print(img1.shape,img2.shape,img3.shape)\n        img[:,:,0]=img1\n        img[:,:,1]=img2\n        img[:,:,2]=img3\n        return img\n\n'''all of these do not work'''\n\ndef crop_image2(image,threshold=5):\n    if len(image.shape) == 3:\n        flatImage = np.max(image, 2)\n    else:\n        flatImage = image\n    assert len(flatImage.shape) == 2\n\n    rows = np.where(np.max(flatImage, 0) > threshold)[0]\n    if rows.size:\n        cols = np.where(np.max(flatImage, 1) > threshold)[0]\n        image = image[cols[0]: cols[-1] + 1, rows[0]: rows[-1] + 1]\n    else:\n        image = image[:1, :1]\n\n    return image\n\ndef crop_image3(image):\n    mask = image > 0\n\n    # Coordinates of non-black pixels.\n    coords = np.argwhere(mask)\n\n    # Bounding box of non-black pixels.\n    x0, y0 = coords.min(axis=0)\n    x1, y1 = coords.max(axis=0) + 1   # slices are exclusive at the top\n    \n    # Get the contents of the bounding box.\n    cropped = image[x0:x1, y0:y1]\n    return cropped\n\ndef crop_image4(image):\n    _,thresh = cv2.threshold(image,1,255,cv2.THRESH_BINARY)\n    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n    cnt = contours[0]\n    x,y,w,h = cv2.boundingRect(cnt)\n    crop = image[y:y+h,x:x+w]\n    return crop","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def circle_crop(img, sigmaX=10):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    return img \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n## try circle crop\nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = circle_crop(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dpi = 80 #inch\n\n# path=f\"../input/aptos2019-blindness-detection/train_images/5c7ab966a3ee.png\" # notice upper part\npath=f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\" # lower-right, can be class3\nimage = load_ben_color(path,sigmaX=10)\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nNUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor jj in range(5):\n    for i, (idx, row) in enumerate(df_test.sample(NUM_SAMP,random_state=SEED+jj).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, jj * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/test_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=30)\n        \n        plt.imshow(image)\n        ax.set_title('%d-%s' % (idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n'''Bonus : sigmaX=50'''\nNUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor jj in range(5):\n    for i, (idx, row) in enumerate(df_test.sample(NUM_SAMP,random_state=SEED+jj).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, jj * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/test_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=50)\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('%d-%s' % (idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# This is the old imperfect 'by-channel' color cropping code\n# this code can cause different crop among 3 channels\n\n# try cropping color image with the fixed function\n# path=f\"../input/aptos2019-blindness-detection/train_images/5c7ab966a3ee.png\"\npath=f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\"\nimage = cv2.imread(path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage = crop_image(image)\n# image = crop_image_from_gray(image)\nimage = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\nimage=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 10) ,-4 ,128)\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image)\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/diabetic-retinopathy-resized/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/diabetic-retinopathy-resized/resized_train/resized_train | head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_old = pd.read_csv('../input/diabetic-retinopathy-resized/trainLabels.csv')\n\ndf_old.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_old.loc[df_old['level'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/{row['image']}.jpeg\"\n        image = load_ben_color(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['image']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_SAMP=10\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_old.loc[df_old['level'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/{row['image']}.jpeg\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n\n#         image = crop_image_from_gray(image)\n        image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n#         image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128)\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['image']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dpi = 80 #inch\n\npath=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/31590_right.jpeg\" # too many vessels?\n# path=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/18017_left.jpeg\" # details are lost\nimage = load_ben_color(path,sigmaX=30)\n# image = cv2.imread(path)\n# image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n# image = crop_image1(image)\n# image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n# image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , IMG_SIZE/10) ,-4 ,128)\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/retinopathy-train-2015/rescaled_train_896/rescaled_train_896/ | head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dpi = 80 #inch\n\npath_jpg=f\"../input/diabetic-retinopathy-resized/resized_train/resized_train/18017_left.jpeg\" # too many vessels?\npath_png=f\"../input/retinopathy-train-2015/rescaled_train_896/rescaled_train_896/18017_left.png\" # details are lost\nimage = cv2.imread(path_png)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\nimage = crop_image(image)\nimage = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n\nimage2 =  cv2.imread(path_jpg)\nimage2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)\nimage2 = crop_image(image2)\nimage2 = cv2.resize(image2, (IMG_SIZE, IMG_SIZE))\n\n\nheight, width = IMG_SIZE, IMG_SIZE\nprint(height, width)\n\nSCALE=1/4\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nax = fig.add_subplot(2, 2, 1, xticks=[], yticks=[])\nax.set_title('png format original' )\nplt.imshow(image, cmap='gray')\nax = fig.add_subplot(2, 2, 2, xticks=[], yticks=[])\nax.set_title('jpg format original' )\nplt.imshow(image2, cmap='gray')\n\nimage = load_ben_color(path_png,sigmaX=30)\nimage2 = load_ben_color(path_jpg,sigmaX=30)\nax = fig.add_subplot(2, 2, 3, xticks=[], yticks=[])\nax.set_title('png format transformed' )\nplt.imshow(image, cmap='gray')\nax = fig.add_subplot(2, 2, 4, xticks=[], yticks=[])\nax.set_title('jpg format transformed' )\nplt.imshow(image2, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nimport math\nimport os\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\ndef preprocess_image(image_path, desired_size=224):\n    im = Image.open(image_path)\n    im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n#     im = im.resize((desired_size, )*2)\n    \n    return im","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = test_df.shape[0]\nx_test = np.empty((N, 224, 224, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(test_df['id_code'])):\n    x_test[i, :, :, :] = preprocess_image(\n        f'../input/aptos2019-blindness-detection/test_images/{image_id}.png'\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_image_ben_orig(path,resize=True,crop=False,norm255=True,keras=False):\n    image = cv2.imread(path)\n    \n#     if crop:\n#         image = crop_image(image)\n    \n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n#     if resize:\n#         image = cv2.resize(image,(SIZE,SIZE))\n        \n    image=cv2.addWeighted( image,4, cv2.GaussianBlur( image , (0,0) ,  10) ,-4 ,128)\n#     image=cv2.addWeighted( image,4, cv2.medianBlur( image , 10) ,-4 ,128)\n    \n    # NOTE plt.imshow can accept both int (0-255) or float (0-1), but deep net requires (0-1)\n    if norm255:\n        return image/255\n    elif keras:\n        #see https://github.com/keras-team/keras-applications/blob/master/keras_applications/imagenet_utils.py for mode\n        #see https://github.com/keras-team/keras-applications/blob/master/keras_applications/xception.py for inception,xception mode\n        #the use of tf based preprocessing (- and / by 127 respectively) will results in [-1,1] so it will not visualize correctly (directly)\n        image = np.expand_dims(image, axis=0)\n        return preprocess_input(image)[0]\n    else:\n        return image.astype(np.int16)\n    \n    return image\n\ndef transform_image_ben(img,resize=True,crop=False,norm255=True,keras=False):  \n    image=cv2.addWeighted( img,4, cv2.GaussianBlur( img , (0,0) ,  10) ,-4 ,128)\n    \n    # NOTE plt.imshow can accept both int (0-255) or float (0-1), but deep net requires (0-1)\n    if norm255:\n        return image/255\n    elif keras:\n        image = np.expand_dims(image, axis=0)\n        return preprocess_input(image)[0]\n    else:\n        return image.astype(np.int16)\n    \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_samples(df, columns=5, rows=2, Ben=True):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n#         image_id = df.loc[i,'diagnosis']\n        path = f'../input/aptos2019-blindness-detection/test_images/{image_path}.png'\n        if Ben:\n            img = load_image_ben_orig(path)\n        else:\n            img = cv2.imread(path)\n            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n#         plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(test_df, Ben=False)\ndisplay_samples(test_df, Ben=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras import layers\nfrom keras.models import Model\nimport keras.backend as K","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"K.clear_session()\ndensenet = DenseNet121(\n    weights=None,\n    include_top=False,\n    input_shape=(None,None,3)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GAP_layer = layers.GlobalAveragePooling2D()\ndrop_layer = layers.Dropout(0.5)\ndense_layer = layers.Dense(5, activation='sigmoid', name='final_output')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model_sequential():\n    model = Sequential()\n    model.add(densenet)\n    model.add(GAP_layer)\n    model.add(drop_layer)\n    model.add(dense_layer)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"modelA = build_model_sequential()\nmodelA.load_weights('../input/aptos-data/dense_xhlulu_731.h5')\n\nmodelA.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model_functional():\n    base_model = densenet\n    \n    x = GAP_layer(base_model.layers[-1].output)\n    x = drop_layer(x)\n    final_output = dense_layer(x)\n    model = Model(base_model.layers[0].input, final_output)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model_functional() # with pretrained weights, and layers we want\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_test = model.predict(x_test) > 0.5\n# y_test = y_test.astype(int).sum(axis=1) - 1\n\n# test_df['diagnosis'] = y_test\n# test_df.to_csv('submission.csv',index=False)\n# y_test.shape, x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import seaborn as sns\n# import cv2\n\n# SIZE=224\n# def create_pred_hist(pred_level_y,title='NoTitle'):\n#     results = pd.DataFrame({'diagnosis':pred_level_y})\n\n#     f, ax = plt.subplots(figsize=(7, 4))\n#     ax = sns.countplot(x=\"diagnosis\", data=results, palette=\"GnBu_d\")\n#     sns.despine()\n#     plt.title(title)\n#     plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# create_pred_hist(y_test,title='predicted level distribution in test set')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_heatmap_img(img, model0, layer_name='last_conv_layer',viz_img=None,orig_img=None):\n    preds_raw = model0.predict(img[np.newaxis])\n    preds = preds_raw > 0.5 # use the same threshold as @xhlulu original kernel\n    class_idx = (preds.astype(int).sum(axis=1) - 1)[0]\n#     print(class_idx, class_idx.shape)\n    class_output_tensor = model0.output[:, class_idx]\n    \n    viz_layer = model0.get_layer(layer_name)\n    grads = K.gradients(\n                        class_output_tensor ,\n                        viz_layer.output\n                        )[0] # gradients of viz_layer wrt output_tensor of predicted class\n    \n    pooled_grads=K.mean(grads,axis=(0,1,2))\n    iterate=K.function([model0.input],[pooled_grads, viz_layer.output[0]])\n    \n    pooled_grad_value, viz_layer_out_value = iterate([img[np.newaxis]])\n    \n    for i in range(pooled_grad_value.shape[0]):\n        viz_layer_out_value[:,:,i] *= pooled_grad_value[i]\n    \n    heatmap = np.mean(viz_layer_out_value, axis=-1)\n    heatmap = np.maximum(heatmap,0)\n    heatmap /= np.max(heatmap)\n\n    viz_img=cv2.resize(viz_img,(img.shape[1],img.shape[0]))\n    heatmap=cv2.resize(heatmap,(viz_img.shape[1],viz_img.shape[0]))\n    \n    heatmap_color = cv2.applyColorMap(np.uint8(heatmap*255), cv2.COLORMAP_SPRING)/255\n    heated_img = heatmap_color*0.5 + viz_img*0.5\n    \n    print('raw output from model : ')\n    print_pred(preds_raw)\n    \n    if orig_img is None:\n        show_Nimages([img,viz_img,heatmap_color,heated_img])\n    else:\n        show_Nimages([orig_img,img,viz_img,heatmap_color,heated_img])\n    \n    plt.show()\n    return heated_img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_image(image,figsize=None,title=None):\n    \n    if figsize is not None:\n        fig = plt.figure(figsize=figsize)\n#     else: # crash!!\n#         fig = plt.figure()\n        \n    if image.ndim == 2:\n        plt.imshow(image,cmap='gray')\n    else:\n        plt.imshow(image)\n        \n    if title is not None:\n        plt.title(title)\n\ndef show_Nimages(imgs,scale=1):\n\n    N=len(imgs)\n    fig = plt.figure(figsize=(25/scale, 16/scale))\n    for i, img in enumerate(imgs):\n        ax = fig.add_subplot(1, N, i + 1, xticks=[], yticks=[])\n        show_image(img)\n        \ndef print_pred(array_of_classes):\n    xx = array_of_classes\n    s1,s2 = xx.shape\n    for i in range(s1):\n        for j in range(s2):\n            print('%.3f ' % xx[i,j],end='')\n        print('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_SAMP=10\nSEED=77\nlayer_name = 'relu' #'conv5_block16_concat'\nfor i, (idx, row) in enumerate(test_df[:NUM_SAMP].iterrows()):\n    path=f\"../input/aptos2019-blindness-detection/test_images/{row['id_code']}.png\"\n    ben_img = load_image_ben_orig(path)\n    input_img = np.empty((1,224, 224, 3), dtype=np.uint8)\n    input_img[0,:,:,:] = preprocess_image(path)\n        \n    print('test pic no.%d' % (i+1))\n    _ = gen_heatmap_img(input_img[0],\n                        model, layer_name=layer_name,viz_img=ben_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from albumentations import *\nimport time\n\nIMG_SIZE = (224,224)\n\n'''Use case from https://www.kaggle.com/alexanderliao/image-augmentation-demo-with-albumentation/'''\ndef albaugment(aug0, img):\n    return aug0(image=img)['image']\nidx=8\nimage1=x_test[idx]\n\n'''1. Rotate or Flip'''\naug1 = OneOf([\n    Rotate(p=0.99, limit=160, border_mode=0,value=0), # value=black\n    Flip(p=0.5)\n    ],p=1)\n\n'''2. Adjust Brightness or Contrast'''\naug2 = RandomBrightnessContrast(brightness_limit=0.45, contrast_limit=0.45,p=1)\nh_min=np.round(IMG_SIZE[1]*0.72).astype(int)\nh_max= np.round(IMG_SIZE[1]*0.9).astype(int)\nprint(h_min,h_max)\n\n'''3. Random Crop and then Resize'''\n#w2h_ratio = aspect ratio of cropping\naug3 = RandomSizedCrop((h_min, h_max),IMG_SIZE[1],IMG_SIZE[0], w2h_ratio=IMG_SIZE[0]/IMG_SIZE[1],p=1)\n\n'''4. CutOut Augmentation'''\nmax_hole_size = int(IMG_SIZE[1]/10)\naug4 = Cutout(p=1,max_h_size=max_hole_size,max_w_size=max_hole_size,num_holes=8 )#default num_holes=8\n\n'''5. SunFlare Augmentation'''\naug5 = RandomSunFlare(src_radius=max_hole_size,\n                      num_flare_circles_lower=10,\n                      num_flare_circles_upper=20,\n                      p=1)#default flare_roi=(0,0,1,0.5),\n\n'''6. Ultimate Augmentation -- combine everything'''\nfinal_aug = Compose([\n    aug1,aug2,aug3,aug4,aug5\n],p=1)\n\n\nimg1 = albaugment(aug1,image1)\nimg2 = albaugment(aug1,image1)\nprint('Rotate or Flip')\nshow_Nimages([image1,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(aug2,image1)\nimg2 = albaugment(aug2,image1)\nimg3 = albaugment(aug2,image1)\nprint('Brightness or Contrast')\nshow_Nimages([img3,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(aug3,image1)\nimg2 = albaugment(aug3,image1)\nimg3 = albaugment(aug3,image1)\nprint('Rotate and Resize')\nshow_Nimages([img3,img1,img2],scale=2)\nprint(img1.shape,img2.shape)\n# time.sleep(1)\n\nimg1 = albaugment(aug4,image1)\nimg2 = albaugment(aug4,image1)\nimg3 = albaugment(aug4,image1)\nprint('CutOut')\nshow_Nimages([img3,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(aug5,image1)\nimg2 = albaugment(aug5,image1)\nimg3 = albaugment(aug5,image1)\nprint('Sun Flare')\nshow_Nimages([img3,img1,img2],scale=2)\n# time.sleep(1)\n\nimg1 = albaugment(final_aug,image1)\nimg2 = albaugment(final_aug,image1)\nimg3 = albaugment(final_aug,image1)\nprint('All above combined')\nshow_Nimages([img3,img1,img2],scale=2)\nprint(img1.shape,img2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"aug_list = [aug5, aug2, aug3, aug4, aug1, final_aug]\naug_name = ['SunFlare', 'brightness or contrast', 'crop and resized', 'CutOut', 'rotate or flip', 'Everything Combined']\n\nidx=8\nlayer_name = 'relu' #'conv5_block16_concat'\nfor i in range(len(aug_list)):\n    path=f\"../input/aptos2019-blindness-detection/test_images/{test_df.iloc[idx]['id_code']}.png\"\n    input_img = np.empty((1,224, 224, 3), dtype=np.uint8)\n    input_img[0,:,:,:] = preprocess_image(path)\n    aug_img = albaugment(aug_list[i],input_img[0,:,:,:])\n    ben_img = transform_image_ben(aug_img)\n    \n    print('test pic no.%d -- augmentation: %s' % (i+1, aug_name[i]))\n    _ = gen_heatmap_img(aug_img,\n                        model, layer_name=layer_name,viz_img=ben_img,orig_img=input_img[0])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}