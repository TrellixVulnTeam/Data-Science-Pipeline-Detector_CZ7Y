{"cells":[{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport os, shutil\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nfrom keras import models, layers\nfrom keras.utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg19 import VGG19","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/aptos2019-blindness-detection'\n# for f in os.listdir(base_dir):\n#     print(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"csv_path = os.path.join(base_dir, 'train.csv')\ndf = pd.read_csv(csv_path)\ndf = df.sort_values(by='id_code')\ndf['id_code'] = df['id_code'].values + '.png' ## needed for flow_from_dataframe\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels, counts = np.unique(df['diagnosis'], return_counts=True)\n# plt.bar(labels, counts)\n# plt.title('Bar chart of labels')\n# plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_IMG_PATH = os.path.join(base_dir, 'train_images')\nIMG_WIDTH = 256\nIMG_HEIGHT = 256","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def crop_image_from_gray(img, tol=7):\n#     \"\"\"\n#     Applies masks to the orignal image and \n#     returns the a preprocessed image with \n#     3 channels\n    \n#     :param img: A NumPy Array that will be cropped\n#     :param tol: The tolerance used for masking\n    \n#     :return: A NumPy array containing the cropped image\n#     \"\"\"\n#     # If for some reason we only have two channels\n#     if img.ndim == 2:\n#         mask = img > tol\n#         return img[np.ix_(mask.any(1),mask.any(0))]\n#     # If we have a normal RGB images\n#     elif img.ndim == 3:\n#         gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n#         mask = gray_img > tol\n        \n#         check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n#         if (check_shape == 0): # image is too dark so that we crop out everything,\n#             return img # return original image\n#         else:\n#             img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n#             img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n#             img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n#             img = np.stack([img1,img2,img3],axis=-1)\n#         return img\n\ndef preprocess_image(image, sigmaX=10):\n    \"\"\"\n    The whole preprocessing pipeline:\n    1. Read in image\n    2. Apply masks\n    3. Resize image to desired size\n    4. Add Gaussian noise to increase Robustness\n    \n    :param img: A NumPy Array that will be cropped\n    :param sigmaX: Value used for add GaussianBlur to the image\n    \n    :return: A NumPy array containing the preprocessed image\n    \"\"\"\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n#     image = crop_image_from_gray(image)\n    image = cv2.resize(image, (IMG_WIDTH, IMG_HEIGHT))\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(rescale=1/128., horizontal_flip=True,\n                                   vertical_flip=True, validation_split=0.1, preprocessing_function=preprocess_image)\ntrain_generator = train_datagen.flow_from_dataframe(df, x_col='id_code', y_col='diagnosis'\n                                                    , directory=TRAIN_IMG_PATH, class_mode='raw' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base = VGG19(weights='imagenet',\n                        include_top=False,\n                        input_shape=(IMG_WIDTH, IMG_HEIGHT, 3))\nconv_base.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.Sequential([\n    conv_base,\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(1, activation='linear')\n])\nmodel.compile(loss='mse', optimizer='adam', metrics=['mse', 'acc'])\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(train_generator, steps_per_epoch=train_generator.samples // BATCH_SIZE,\n                              epochs=30, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}