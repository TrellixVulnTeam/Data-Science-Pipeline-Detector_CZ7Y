{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install tensorflow-addons\nimport tensorflow_addons as tfa\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Flatten, Dense\nfrom keras.callbacks import ReduceLROnPlateau, Callback, ModelCheckpoint\nfrom sklearn.metrics import cohen_kappa_score\nfrom tensorflow.keras.utils import to_categorical\nfrom keras import backend as K\nfrom keras import regularizers\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.utils import to_categorical\nimport os\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model\nfrom tensorflow.keras.applications import DenseNet121\nfrom tqdm import tqdm\nfrom sklearn.utils import class_weight\n\n\nimport keras\nfrom keras import Input\nfrom keras.models import Model\nfrom keras.utils import *\nfrom keras.layers import *\n\n\nimport matplotlib.pyplot as plt\n\nimport gc","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:19:31.874443Z","iopub.execute_input":"2022-04-10T15:19:31.874707Z","iopub.status.idle":"2022-04-10T15:20:06.533265Z","shell.execute_reply.started":"2022-04-10T15:19:31.874677Z","shell.execute_reply":"2022-04-10T15:20:06.532533Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n    Config\n'''\nIMG_SIZE = 224\nBATCH_SIZE = 16\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): \n            return img \n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n    \ndef load_ben_color(image, sigmaX=10):\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image).astype('uint8')\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image = cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image\n\n'''\n    Preprocessing for ImageDataGenerator since ImageDataGenerator reads images in rgb mode, while opencv in bgr\n'''\ndef preprocessing(image, sigmaX=10):\n    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n    image = crop_image_from_gray(image).astype('uint8')\n    image = cv2.resize(image, (IMG_SIZE, IMG_SIZE))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image.astype('float32') / 255.","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:20:06.534837Z","iopub.execute_input":"2022-04-10T15:20:06.535108Z","iopub.status.idle":"2022-04-10T15:20:06.550275Z","shell.execute_reply.started":"2022-04-10T15:20:06.535055Z","shell.execute_reply":"2022-04-10T15:20:06.549667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## load train and test image ","metadata":{}},{"cell_type":"code","source":"base_model = tf.keras.applications.efficientnet.EfficientNetB0(include_top=False,weights=None,input_shape=(IMG_SIZE,IMG_SIZE,3))","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:20:06.552819Z","iopub.execute_input":"2022-04-10T15:20:06.553639Z","iopub.status.idle":"2022-04-10T15:20:09.899152Z","shell.execute_reply.started":"2022-04-10T15:20:06.553576Z","shell.execute_reply":"2022-04-10T15:20:09.895353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"flatten_layer = tf.keras.layers.Flatten()\ndense_layer_1 = tf.keras.layers.Dense(4096, activation='relu')\nDropout_1 = tf.keras.layers.Dropout(0.6)\ndense_layer_2 = tf.keras.layers.Dense(2048, activation='relu')\nDropout_2 = tf.keras.layers.Dropout(0.5)\ndense_layer_3 = tf.keras.layers.Dense(1024, activation='relu')\nDropout_3 = tf.keras.layers.Dropout(0.3)\ndense_layer_4 = tf.keras.layers.Dense(512, activation='relu')\nprediction_layer = tf.keras.layers.Dense(5, activation='softmax')\n\n\nmodel = tf.keras.models.Sequential([\n      base_model,\n      flatten_layer,\n      dense_layer_1,\n      Dropout_1,\n      dense_layer_2,\n      Dropout_2,\n      dense_layer_3,\n      Dropout_3,\n      dense_layer_4,\n      prediction_layer\n  ])","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:20:09.9044Z","iopub.execute_input":"2022-04-10T15:20:09.905099Z","iopub.status.idle":"2022-04-10T15:20:10.843497Z","shell.execute_reply.started":"2022-04-10T15:20:09.905031Z","shell.execute_reply":"2022-04-10T15:20:10.842763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('../input/eff-b0-model/eff_b0_model_224.h5')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T15:20:31.069998Z","iopub.execute_input":"2022-04-10T15:20:31.070592Z","iopub.status.idle":"2022-04-10T15:20:39.848332Z","shell.execute_reply.started":"2022-04-10T15:20:31.070555Z","shell.execute_reply":"2022-04-10T15:20:39.847521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = keras.models.load_model('../input/eff-b2-model/eff_b2_model')","metadata":{"execution":{"iopub.status.busy":"2022-04-10T04:01:26.835962Z","iopub.execute_input":"2022-04-10T04:01:26.836223Z","iopub.status.idle":"2022-04-10T04:02:16.622223Z","shell.execute_reply.started":"2022-04-10T04:01:26.83619Z","shell.execute_reply":"2022-04-10T04:02:16.621462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_csv = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nid_code = test_csv['id_code']\ntest_prediction = np.empty(len(id_code), dtype='float32')\nfor i in range(len(id_code)):\n    img = cv2.imread('../input/aptos2019-blindness-detection/test_images/{}.png'.format(id_code[i]))\n    \n#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n#     img = crop_image_from_gray(img).astype('uint8')\n#     img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n    \n    img = load_ben_color(img)\n    X = np.array([img])\n    pred = model.predict(X)\n    test_prediction[i] = np.argmax(pred).astype('int64')\ntest_prediction = test_prediction.astype('int64')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:36:34.414705Z","iopub.execute_input":"2022-03-29T09:36:34.414973Z","iopub.status.idle":"2022-03-29T09:40:46.11513Z","shell.execute_reply.started":"2022-03-29T09:36:34.414938Z","shell.execute_reply":"2022-03-29T09:40:46.114344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# prediction = predict(test_prediction).astype('uint8')\ntest_csv['diagnosis'] = test_prediction\ntest_csv.to_csv(\"submission.csv\", index=False)\nunique, counts = np.unique(test_prediction, return_counts=True)\ntmp = dict(zip(unique, counts))\nprint(tmp)\nprint('Done!')","metadata":{"execution":{"iopub.status.busy":"2022-03-29T09:40:46.116535Z","iopub.execute_input":"2022-03-29T09:40:46.116807Z","iopub.status.idle":"2022-03-29T09:40:46.130722Z","shell.execute_reply.started":"2022-03-29T09:40:46.116774Z","shell.execute_reply":"2022-03-29T09:40:46.129691Z"},"trusted":true},"execution_count":null,"outputs":[]}]}