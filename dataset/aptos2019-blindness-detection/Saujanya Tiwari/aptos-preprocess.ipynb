{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IM_DIM = 224","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]/2), math.ceil(pad_diff[0]/2)\n    l, r = math.floor(pad_diff[1]/2), math.ceil(pad_diff[1]/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n      \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n\ndef clahe_green(img):\n    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n    lab_planes = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=0.5)\n    lab_planes[1] = clahe.apply(lab_planes[1])\n    lab = cv2.merge(lab_planes)\n    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n    image = cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n    return image\n\ndef reshape_img(image, im_dim):\n    image = cv2.resize(image, (im_dim,)*2)\n    return image\n\ndef load_ben_color(image, sigmaX):\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n    return image\n\ndef preprocess(image):\n    image = crop_image_from_gray(image)\n    image = clahe_green(image)\n    image = reshape_img(image, im_dim = IM_DIM)\n    image = load_ben_color(image, sigmaX=30)\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocess 1:\n1. image = crop_image_from_gray(image)\n2. image = clahe_green(image)\n3. image = reshape_img(image, im_dim=512)\n4. image = load_ben_color(image, sigmaX=30)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"NUM_SAMP=5\nSEED = 7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_df['diagnosis'].unique()):\n    for i, (idx, row) in enumerate(train_df.loc[train_df['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = preprocess(image)\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def img_arr(df, im_dim, path):\n    N = df.shape[0]\n    arr = np.empty((N, im_dim, im_dim, 3), dtype = np.uint8)\n    for i, image_id in enumerate(tqdm(df['id_code'])):\n        image = cv2.imread(f'{path}/{image_id}.png')\n        arr[i,:,:,:] = preprocess(image)\n    return arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = img_arr(train_df, im_dim = IM_DIM, path = '../input/aptos2019-blindness-detection/train_images/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = img_arr(test_df, im_dim = IM_DIM, path = '../input/aptos2019-blindness-detection/test_images/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.save('train_all_four',x_train)\nnp.save('test_all_four',x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}