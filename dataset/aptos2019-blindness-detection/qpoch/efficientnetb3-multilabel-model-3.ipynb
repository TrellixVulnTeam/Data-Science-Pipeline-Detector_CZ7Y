{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# EfficientNetB3Trained with Old and New Data\n\n\n---","metadata":{}},{"cell_type":"markdown","source":"The Inference kernel of this notebook can be found here: https://www.kaggle.com/fanconic/efficientnetb3-inference-keras?scriptVersionId=18596729\n\n - LB Score: 0.786\n - Private Score: 0.910","metadata":{}},{"cell_type":"code","source":"# To have reproducible results and compare them\nnr_seed = 11\nimport numpy as np \nnp.random.seed(nr_seed)\nimport tensorflow as tf\ntf.set_random_seed(nr_seed)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:52:50.390119Z","iopub.execute_input":"2022-06-26T15:52:50.390452Z","iopub.status.idle":"2022-06-26T15:52:52.748883Z","shell.execute_reply.started":"2022-06-26T15:52:50.390407Z","shell.execute_reply":"2022-06-26T15:52:52.746898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import libraries\n!pip install -U '../input/install/efficientnet-0.0.3-py2.py3-none-any.whl'\nimport json\nimport math\nfrom tqdm import tqdm, tqdm_notebook\nimport gc\nimport warnings\nimport os\n\nimport cv2\nfrom PIL import Image\n\nimport pandas as pd\nimport scipy\nimport matplotlib.pyplot as plt\n\nfrom keras import backend as K\nfrom keras import layers\nfrom efficientnet import EfficientNetB3\nfrom keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.losses import binary_crossentropy, categorical_crossentropy\nfrom skimage.color import rgb2hsv, lab2lch\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\n\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T15:52:52.750941Z","iopub.execute_input":"2022-06-26T15:52:52.75125Z","iopub.status.idle":"2022-06-26T15:53:19.855172Z","shell.execute_reply.started":"2022-06-26T15:52:52.7512Z","shell.execute_reply":"2022-06-26T15:53:19.854361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image size\nWIDTH= 320\nHEIGHT = 320\n# Batch size\nBATCH_SIZE = 32","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:53:19.856729Z","iopub.execute_input":"2022-06-26T15:53:19.857019Z","iopub.status.idle":"2022-06-26T15:53:19.868187Z","shell.execute_reply.started":"2022-06-26T15:53:19.856971Z","shell.execute_reply":"2022-06-26T15:53:19.867419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading & Merging","metadata":{}},{"cell_type":"code","source":"new_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\nold_train = pd.read_csv('../input/diabetic-retinopathy-resized/trainLabels_cropped.csv')\nduplicates = pd.read_csv('../input/aptos-trained-weights/inconsistent.csv')\nprint(new_train.shape)\nprint(old_train.shape)\nprint(duplicates.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:53:19.869452Z","iopub.execute_input":"2022-06-26T15:53:19.869891Z","iopub.status.idle":"2022-06-26T15:53:19.949568Z","shell.execute_reply.started":"2022-06-26T15:53:19.869839Z","shell.execute_reply":"2022-06-26T15:53:19.948815Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for img_name in duplicates['id_code'].values:\n    new_train = new_train[new_train['id_code'] != img_name]\nprint(new_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:53:19.953179Z","iopub.execute_input":"2022-06-26T15:53:19.953483Z","iopub.status.idle":"2022-06-26T15:53:20.055493Z","shell.execute_reply.started":"2022-06-26T15:53:19.953422Z","shell.execute_reply":"2022-06-26T15:53:20.054691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"old_train = old_train[['image','level']]\nold_train.columns = new_train.columns\nold_train.diagnosis.value_counts()\n\n# path columns\nnew_train['id_code'] = '../input/aptos2019-blindness-detection/train_images/' + new_train['id_code'].astype(str) + '.png'\nold_train['id_code'] = '../input/diabetic-retinopathy-resized/resized_train/resized_train/' + old_train['id_code'].astype(str) + '.jpeg'\n\ntrain_df = old_train.copy()\nval_df = new_train.copy()\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:53:20.058108Z","iopub.execute_input":"2022-06-26T15:53:20.05874Z","iopub.status.idle":"2022-06-26T15:53:20.121106Z","shell.execute_reply.started":"2022-06-26T15:53:20.058678Z","shell.execute_reply":"2022-06-26T15:53:20.120348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train - Valid split\nUse new Data for validation and Old data for trainingÂ£","metadata":{}},{"cell_type":"code","source":"# Let's shuffle the datasets\ntrain_df = train_df.sample(frac=1).reset_index(drop=True)\nval_df = val_df.sample(frac=1).reset_index(drop=True)\nprint(train_df.shape)\nprint(val_df.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:53:20.124167Z","iopub.execute_input":"2022-06-26T15:53:20.124403Z","iopub.status.idle":"2022-06-26T15:53:20.137979Z","shell.execute_reply.started":"2022-06-26T15:53:20.124359Z","shell.execute_reply":"2022-06-26T15:53:20.137205Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Process Images","metadata":{}},{"cell_type":"markdown","source":"Crop function: https://www.kaggle.com/ratthachat/aptos-updated-preprocessing-ben-s-cropping ","metadata":{}},{"cell_type":"code","source":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n   \n        return img\n\n\n# Make all images circular (possible data loss)\ndef circle_crop(img):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = crop_image_from_gray(img)    \n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    \n    return img \n\ndef preprocess_image(image_path, width=320, height=320, new_data=False):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)    \n    if new_data:\n        img = crop_image_from_gray(img)\n    img = cv2.resize(img, (width,height))\n    #img = cv2.addWeighted(img,4,cv2.GaussianBlur(img, (0,0), 20) ,-4 ,128)\n\n    return img","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:53:20.140824Z","iopub.execute_input":"2022-06-26T15:53:20.141047Z","iopub.status.idle":"2022-06-26T15:53:20.159999Z","shell.execute_reply.started":"2022-06-26T15:53:20.141004Z","shell.execute_reply":"2022-06-26T15:53:20.159284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = preprocess_image(f'{image_path}', width=WIDTH, height=HEIGHT)\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(train_df)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-06-26T15:53:20.161485Z","iopub.execute_input":"2022-06-26T15:53:20.161811Z","iopub.status.idle":"2022-06-26T15:53:24.082591Z","shell.execute_reply.started":"2022-06-26T15:53:20.161764Z","shell.execute_reply":"2022-06-26T15:53:24.080215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Processing Images","metadata":{}},{"cell_type":"markdown","source":"__UPDATE:__ Here we are reading just the validation set. In order to use 320x320 images, we are going to load one bucket at a time only when needed. This will let our code run without memory-related errors.","metadata":{}},{"cell_type":"code","source":"# validation set\nN = val_df.shape[0]\nx_val = np.empty((N, HEIGHT, WIDTH, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm_notebook(val_df['id_code'])):\n    x_val[i, :, :, :] = preprocess_image(\n        f'{image_id}',\n        height=HEIGHT, width=WIDTH, new_data=True\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-26T15:53:24.083717Z","iopub.execute_input":"2022-06-26T15:53:24.08401Z","iopub.status.idle":"2022-06-26T16:04:37.017863Z","shell.execute_reply.started":"2022-06-26T15:53:24.083961Z","shell.execute_reply":"2022-06-26T16:04:37.017048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd.get_dummies(train_df['diagnosis']).values\ny_val = pd.get_dummies(val_df['diagnosis']).values\n\nprint(y_train.shape)\nprint(x_val.shape)\nprint(y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:37.019184Z","iopub.execute_input":"2022-06-26T16:04:37.019617Z","iopub.status.idle":"2022-06-26T16:04:37.030894Z","shell.execute_reply.started":"2022-06-26T16:04:37.019432Z","shell.execute_reply":"2022-06-26T16:04:37.030253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating multilabels\n\nInstead of predicting a single label, we will change our target to be a multilabel problem; i.e., if the target is a certain class, then it encompasses all the classes before it. E.g. encoding a class 4 retinopathy would usually be `[0, 0, 0, 1]`, but in our case we will predict `[1, 1, 1, 1]`. For more details, please check out [Lex's kernel](https://www.kaggle.com/lextoumbourou/blindness-detection-resnet34-ordinal-targets).","metadata":{}},{"cell_type":"code","source":"y_train_multi = np.empty(y_train.shape, dtype=y_train.dtype)\ny_train_multi[:, 4] = y_train[:, 4]\n\nfor i in range(3, -1, -1):\n    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i+1])\n\ny_val_multi = np.empty(y_val.shape, dtype=y_val.dtype)\ny_val_multi[:, 4] = y_val[:, 4]\n\nfor i in range(3, -1, -1):\n    y_val_multi[:, i] = np.logical_or(y_val[:, i], y_val_multi[:, i+1])\n\nprint(\"Y_train multi: {}\".format(y_train_multi.shape))\nprint(\"Y_val multi: {}\".format(y_val_multi.shape))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:37.032517Z","iopub.execute_input":"2022-06-26T16:04:37.032767Z","iopub.status.idle":"2022-06-26T16:04:37.046261Z","shell.execute_reply.started":"2022-06-26T16:04:37.032716Z","shell.execute_reply":"2022-06-26T16:04:37.04518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = y_train_multi\ny_val = y_val_multi","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:37.04791Z","iopub.execute_input":"2022-06-26T16:04:37.048447Z","iopub.status.idle":"2022-06-26T16:04:37.053332Z","shell.execute_reply.started":"2022-06-26T16:04:37.048246Z","shell.execute_reply":"2022-06-26T16:04:37.052392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# delete the uneeded df\ndel new_train\ndel old_train\ndel val_df\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:37.054957Z","iopub.execute_input":"2022-06-26T16:04:37.055391Z","iopub.status.idle":"2022-06-26T16:04:37.192222Z","shell.execute_reply.started":"2022-06-26T16:04:37.055223Z","shell.execute_reply":"2022-06-26T16:04:37.191101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating keras callback for QWK\n\n---\n\nI had to change this function, in order to consider the best kappa score among all the buckets.","metadata":{}},{"cell_type":"code","source":"class Metrics(Callback):\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val, y_val = self.validation_data[:2]\n        y_val = y_val.sum(axis=1) - 1\n        \n        y_pred = self.model.predict(X_val) > 0.5\n        y_pred = y_pred.astype(int).sum(axis=1) - 1\n\n        _val_kappa = cohen_kappa_score(\n            y_val,\n            y_pred, \n            weights='quadratic'\n        )\n\n        self.val_kappas.append(_val_kappa)\n\n        print(f\"val_kappa: {_val_kappa:.4f}\")\n        \n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save('model.h5')\n\n        return","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:37.195307Z","iopub.execute_input":"2022-06-26T16:04:37.195747Z","iopub.status.idle":"2022-06-26T16:04:37.204004Z","shell.execute_reply.started":"2022-06-26T16:04:37.195662Z","shell.execute_reply":"2022-06-26T16:04:37.203368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Generator","metadata":{}},{"cell_type":"code","source":"def create_datagen():\n    return ImageDataGenerator(\n        horizontal_flip=True,\n        vertical_flip=True,\n        zoom_range= 0.3,\n        brightness_range=(0.5, 2),\n        fill_mode='constant',\n        cval=0\n    )","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:37.205606Z","iopub.execute_input":"2022-06-26T16:04:37.206037Z","iopub.status.idle":"2022-06-26T16:04:37.216254Z","shell.execute_reply.started":"2022-06-26T16:04:37.205869Z","shell.execute_reply":"2022-06-26T16:04:37.215667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Check the differenct kinds of augmentations on the pictures.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 10, figsize=(20, 10))\nax = ax.ravel()\n\nimg = x_val[0].reshape(1,x_val[0].shape[0],x_val[0].shape[1], x_val[0].shape[2])\n\nax[0].imshow(img[0].astype('uint8'))\nax[1].imshow(next(ImageDataGenerator().flow(img))[0].astype('uint8'))\nax[2].imshow(next(ImageDataGenerator(horizontal_flip=True, fill_mode='constant', cval=0).flow(img))[0].astype('uint8'))\nax[3].imshow(next(ImageDataGenerator(vertical_flip=True,fill_mode='constant', cval=0).flow(img))[0].astype('uint8'))\nax[4].imshow(next(ImageDataGenerator(rotation_range=360, fill_mode='constant', cval=0).flow(img))[0].astype('uint8'))\nax[5].imshow(next(ImageDataGenerator(zoom_range= (0.65,1), fill_mode='constant', cval=0).flow(img))[0].astype('uint8'))\nax[6].imshow(next(ImageDataGenerator(height_shift_range=0.15, fill_mode='constant', cval=0).flow(img))[0].astype('uint8'))\nax[7].imshow(next(ImageDataGenerator(width_shift_range=0.15, fill_mode='constant', cval=0).flow(img))[0].astype('uint8'))\nax[8].imshow(next(ImageDataGenerator(brightness_range=(0.5, 2), fill_mode='constant', cval=0).flow(img))[0].astype('uint8'))\nax[9].imshow(next(ImageDataGenerator(horizontal_flip=True,\n                                     vertical_flip=True,\n                                     rotation_range=360,zoom_range= (0.65,1),\n                                     brightness_range=(0.5, 2),\n                                     fill_mode='constant',cval=0).flow(img))[0].astype('uint8'))\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:37.217472Z","iopub.execute_input":"2022-06-26T16:04:37.218174Z","iopub.status.idle":"2022-06-26T16:04:38.720477Z","shell.execute_reply.started":"2022-06-26T16:04:37.217916Z","shell.execute_reply":"2022-06-26T16:04:38.719635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model: EfficientNetB3","metadata":{}},{"cell_type":"code","source":"efficientnetb3 = EfficientNetB3(\n        weights=None,\n        input_shape=(HEIGHT,WIDTH,3),\n        include_top=False\n                   )\n\nefficientnetb3.load_weights(\"../input/efficientnet-keras-weights-b0b5/efficientnet-b3_imagenet_1000_notop.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:38.72501Z","iopub.execute_input":"2022-06-26T16:04:38.725592Z","iopub.status.idle":"2022-06-26T16:04:56.869447Z","shell.execute_reply.started":"2022-06-26T16:04:38.725534Z","shell.execute_reply":"2022-06-26T16:04:56.868575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(efficientnetb3)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.BatchNormalization())\n    model.add(layers.Dense(5, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        #loss=kappa_loss,\n        optimizer=Adam(lr=1e-4,decay=1e-6),\n        metrics=['accuracy']\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:56.871932Z","iopub.execute_input":"2022-06-26T16:04:56.872213Z","iopub.status.idle":"2022-06-26T16:04:56.879769Z","shell.execute_reply.started":"2022-06-26T16:04:56.872168Z","shell.execute_reply":"2022-06-26T16:04:56.879028Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:04:56.881018Z","iopub.execute_input":"2022-06-26T16:04:56.881456Z","iopub.status.idle":"2022-06-26T16:05:03.342491Z","shell.execute_reply.started":"2022-06-26T16:04:56.881404Z","shell.execute_reply":"2022-06-26T16:05:03.340901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pretraining with old Data","metadata":{}},{"cell_type":"code","source":"bucket_num = 8\ndiv = round(train_df.shape[0]/bucket_num)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:05:03.345925Z","iopub.execute_input":"2022-06-26T16:05:03.346174Z","iopub.status.idle":"2022-06-26T16:05:03.352199Z","shell.execute_reply.started":"2022-06-26T16:05:03.346128Z","shell.execute_reply":"2022-06-26T16:05:03.350929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_init = {\n    'val_loss': [0.0],\n    'val_acc': [0.0],\n    'loss': [0.0], \n    'acc': [0.0],\n    'bucket': [0.0]\n}\nresults = pd.DataFrame(df_init)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:05:03.353461Z","iopub.execute_input":"2022-06-26T16:05:03.353724Z","iopub.status.idle":"2022-06-26T16:05:03.362623Z","shell.execute_reply.started":"2022-06-26T16:05:03.353678Z","shell.execute_reply":"2022-06-26T16:05:03.361822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# I found that changing the nr. of epochs for each bucket helped in terms of performances\nepochs = [5,5,5,5,5,5,5,5]\nkappa_metrics = Metrics()\nkappa_metrics.val_kappas = []\n\nlearn_control = ReduceLROnPlateau(monitor='val_acc', patience=5,\n                                  verbose=1,factor=.2, min_lr=1e-7)\n\ncheckpoint = ModelCheckpoint('val_model.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:05:03.364813Z","iopub.execute_input":"2022-06-26T16:05:03.365042Z","iopub.status.idle":"2022-06-26T16:05:03.372537Z","shell.execute_reply.started":"2022-06-26T16:05:03.365001Z","shell.execute_reply":"2022-06-26T16:05:03.371684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,bucket_num):\n    if i != (bucket_num-1):\n        print(\"Bucket Nr: {}\".format(i))\n        \n        N = train_df.iloc[i*div:(1+i)*div].shape[0]\n        x_train = np.empty((N, HEIGHT, WIDTH, 3), dtype=np.uint8)\n        for j, image_id in enumerate(tqdm_notebook(train_df.iloc[i*div:(1+i)*div,0])):\n            x_train[j, :, :, :] = preprocess_image(f'{image_id}', height=HEIGHT, width=WIDTH)\n\n        data_generator = create_datagen().flow(x_train, y_train[i*div:(1+i)*div,:], batch_size=BATCH_SIZE, shuffle=False)\n        history = model.fit_generator(\n                        data_generator,\n                        steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n                        epochs=epochs[i],\n                        validation_data=(x_val, y_val),\n                        callbacks=[kappa_metrics, learn_control, checkpoint]\n                        )\n        \n        dic = history.history\n        df_model = pd.DataFrame(dic)\n        df_model['bucket'] = i\n    else:\n        print(\"Bucket Nr: {}\".format(i))\n        \n        N = train_df.iloc[i*div:].shape[0]\n        x_train = np.empty((N, HEIGHT, WIDTH, 3), dtype=np.uint8)\n        for j, image_id in enumerate(tqdm_notebook(train_df.iloc[i*div:,0])):\n            x_train[j, :, :, :] = preprocess_image(f'{image_id}', height=HEIGHT, width=WIDTH)\n        data_generator = create_datagen().flow(x_train, y_train[i*div:,:], batch_size=BATCH_SIZE, shuffle=False)\n        \n        history = model.fit_generator(\n                        data_generator,\n                        steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n                        epochs=epochs[i],\n                        validation_data=(x_val, y_val),\n                        callbacks=[kappa_metrics, learn_control, checkpoint]\n                        )\n        \n        dic = history.history\n        df_model = pd.DataFrame(dic)\n        df_model['bucket'] = i\n\n    results = results.append(df_model)\n    \n    del data_generator\n    del x_train\n    gc.collect()\n    \n    print('-'*40)\n","metadata":{"execution":{"iopub.status.busy":"2022-06-26T16:05:03.374045Z","iopub.execute_input":"2022-06-26T16:05:03.374632Z","iopub.status.idle":"2022-06-26T18:34:20.19779Z","shell.execute_reply.started":"2022-06-26T16:05:03.374578Z","shell.execute_reply":"2022-06-26T18:34:20.196872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = results.iloc[1:]\nresults['kappa'] = kappa_metrics.val_kappas\nresults = results.reset_index()\nresults = results.rename(index=str, columns={\"index\": \"epoch\"})\nresults","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:34:20.200473Z","iopub.execute_input":"2022-06-26T18:34:20.200771Z","iopub.status.idle":"2022-06-26T18:34:20.239313Z","shell.execute_reply.started":"2022-06-26T18:34:20.200723Z","shell.execute_reply":"2022-06-26T18:34:20.238183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results[['loss', 'val_loss']].plot()\nresults[['acc', 'val_acc']].plot()\nresults[['kappa']].plot()\nresults.to_csv('model_results.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:34:20.24127Z","iopub.execute_input":"2022-06-26T18:34:20.24194Z","iopub.status.idle":"2022-06-26T18:34:21.315272Z","shell.execute_reply.started":"2022-06-26T18:34:20.241889Z","shell.execute_reply":"2022-06-26T18:34:21.314327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fine Tune with new Data\nCreate New Train and Validation Set to finetune our model","metadata":{}},{"cell_type":"code","source":"model.load_weights('val_model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:38:42.080429Z","iopub.execute_input":"2022-06-26T18:38:42.080769Z","iopub.status.idle":"2022-06-26T18:38:45.049491Z","shell.execute_reply.started":"2022-06-26T18:38:42.08071Z","shell.execute_reply":"2022-06-26T18:38:45.048466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(\n    x_val, y_val, \n    test_size=0.2, \n    random_state=nr_seed\n)\n\ngc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:38:45.053214Z","iopub.execute_input":"2022-06-26T18:38:45.053458Z","iopub.status.idle":"2022-06-26T18:38:46.301555Z","shell.execute_reply.started":"2022-06-26T18:38:45.053412Z","shell.execute_reply":"2022-06-26T18:38:46.300783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:38:46.303418Z","iopub.execute_input":"2022-06-26T18:38:46.303689Z","iopub.status.idle":"2022-06-26T18:38:48.371179Z","shell.execute_reply.started":"2022-06-26T18:38:46.303644Z","shell.execute_reply":"2022-06-26T18:38:48.370191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(\n                data_generator,\n                steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n                epochs=20,\n                validation_data=(x_val, y_val),\n                callbacks=[kappa_metrics,learn_control,checkpoint]\n                )","metadata":{"execution":{"iopub.status.busy":"2022-06-26T18:38:48.374608Z","iopub.execute_input":"2022-06-26T18:38:48.374857Z","iopub.status.idle":"2022-06-26T19:16:57.575602Z","shell.execute_reply.started":"2022-06-26T18:38:48.374812Z","shell.execute_reply":"2022-06-26T19:16:57.574046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('val_model.h5')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = model.evaluate(x_val, y_val)\nprint(\"Testing accuracy : \" + str(res[1]))\nprint(\"Testing loss : \" + str(res[0]))","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:31:02.5651Z","iopub.execute_input":"2022-06-26T19:31:02.565374Z","iopub.status.idle":"2022-06-26T19:31:07.356461Z","shell.execute_reply.started":"2022-06-26T19:31:02.565326Z","shell.execute_reply":"2022-06-26T19:31:07.355606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_val = model.predict(x_val)","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:16:57.577508Z","iopub.execute_input":"2022-06-26T19:16:57.577833Z","iopub.status.idle":"2022-06-26T19:17:02.556713Z","shell.execute_reply.started":"2022-06-26T19:16:57.577786Z","shell.execute_reply":"2022-06-26T19:17:02.555849Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_val","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:17:02.558818Z","iopub.execute_input":"2022-06-26T19:17:02.559108Z","iopub.status.idle":"2022-06-26T19:17:02.565934Z","shell.execute_reply.started":"2022-06-26T19:17:02.559047Z","shell.execute_reply":"2022-06-26T19:17:02.565127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1 = pred_val > 0.4\ny1 = y1.astype(int).sum(axis=1) - 1","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:24:34.265844Z","iopub.execute_input":"2022-06-26T19:24:34.266165Z","iopub.status.idle":"2022-06-26T19:24:34.271044Z","shell.execute_reply.started":"2022-06-26T19:24:34.266107Z","shell.execute_reply":"2022-06-26T19:24:34.269984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1.shape","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:22:29.372572Z","iopub.execute_input":"2022-06-26T19:22:29.372854Z","iopub.status.idle":"2022-06-26T19:22:29.378492Z","shell.execute_reply.started":"2022-06-26T19:22:29.372808Z","shell.execute_reply":"2022-06-26T19:22:29.377666Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y2 = y_val.sum(axis=1) - 1","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:20:36.003794Z","iopub.execute_input":"2022-06-26T19:20:36.004098Z","iopub.status.idle":"2022-06-26T19:20:36.014106Z","shell.execute_reply.started":"2022-06-26T19:20:36.004035Z","shell.execute_reply":"2022-06-26T19:20:36.013144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y1","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:24:40.527705Z","iopub.execute_input":"2022-06-26T19:24:40.527997Z","iopub.status.idle":"2022-06-26T19:24:40.53543Z","shell.execute_reply.started":"2022-06-26T19:24:40.527945Z","shell.execute_reply":"2022-06-26T19:24:40.534542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y2","metadata":{"execution":{"iopub.status.busy":"2022-06-26T19:22:36.774895Z","iopub.execute_input":"2022-06-26T19:22:36.775448Z","iopub.status.idle":"2022-06-26T19:22:36.784954Z","shell.execute_reply.started":"2022-06-26T19:22:36.775199Z","shell.execute_reply":"2022-06-26T19:22:36.784003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import classification_report\nprint(classification_report(y1, y2))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nimport seaborn as sns\n\ncf_matrix = confusion_matrix(y1, y2)\nsns.heatmap(cf_matrix, annot=True)","metadata":{},"execution_count":null,"outputs":[]}]}