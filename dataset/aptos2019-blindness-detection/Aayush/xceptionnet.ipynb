{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nprint(os.listdir(\"../input/resnet50-image-weights/\"))\nprint(os.listdir(\"../input/xception-weights/\"))\nprint(os.listdir(\"../input/aptos2019-blindness-detection/\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_csv = '../input/aptos2019-blindness-detection/train.csv'\nimage_dataset = '../input/aptos2019-blindness-detection/train_images'\nsample_csv = '../input/aptos2019-blindness-detection/sample_submission.csv'\ntest_dataset = '../input/aptos2019-blindness-detection/test_images'\nresnet_weights = '../input/resnet50-image-weights/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\nxception_weights = '../input/xception-weights/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'\nimport tensorflow as tf\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport numpy\nimport csv\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\n\ndef display_images_sample(df,columns=4,rows=3):\n    fig = plt.figure(figsize=(2*columns,2*rows))\n\n    for i in range(columns*rows):\n        image_name = df.loc[i,'id_code']\n        image_id  = df.loc[i,'diagnosis']\n        image_path = os.path.join(image_dataset,image_name)\n        image_path = image_path + '.png'\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n        fig.add_subplot(rows,columns,i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    plt.tight_layout()\n    plt.show()\n\ndef data_dist(df_train):\n    x = df_train['id_code']\n    y = df_train['diagnosis']\n    x,y = shuffle(x,y,random_state = 8)\n    y.hist()\n    plt.show()\n\ndf_train = pd.read_csv(train_csv)\ndisplay_images_sample(df_train)\ndata_dist(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cohens_kappa(y_true, y_pred):\n    y_true_classes = tf.argmax(y_true, 1)\n    y_pred_classes = tf.argmax(y_pred, 1)\n    return tf.contrib.metrics.cohen_kappa(y_true_classes, y_pred_classes, 5)[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\nmodel\nResNet\n'''\n\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import Callback\nfrom tensorflow.keras.backend import clear_session\nfrom tensorflow.keras.models import Model , load_model\nfrom tensorflow.keras.layers import Dense , Input , Flatten , Dropout ,BatchNormalization\nfrom tensorflow.keras.applications import ResNet50 \nfrom tensorflow.keras.applications import Xception\n\nimg = Input(shape=(224,224,3))\n\nbase_model = Xception(include_top = False,\n                        weights=xception_weights,\n                        input_tensor=img,\n                        pooling='avg',\n                        input_shape = None)\n# base_model = ResNet50(include_top = False,\n#                      weights = resnet_weights,\n#                      input_tensor = img,\n#                      pooling = 'avg',\n#                      input_shape = None)\n\nfinal_layer = base_model.layers[-1].output\nfinal_layer = Dropout(0.2)(final_layer)\ndense_layer1 = Dense(512, activation='relu')(final_layer)\ndense_layer1 = Dropout(0.3)(dense_layer1)\n# dense_layer1 = BatchNormalization()(dense_layer1)\ndense_layer2 = Dense(128,activation= 'relu')(dense_layer1)\ndense_layer2 = Dropout(0.3)(dense_layer2)\noutput_layer = Dense(5,activation='softmax')(dense_layer2)\n\nmodel = Model(img,output_layer)\nfor layer in base_model.layers:\n  layer.trainable = True\n\nmodel.compile(optimizer = 'adam',loss = 'categorical_crossentropy',metrics = ['accuracy'])\nmodel.summary() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"size = 224,224\ndef get_cropped_image(image):\n    img = cv2.blur(image,(2,2))\n    slice1Copy = np.uint8(img)\n    canny = cv2.Canny(slice1Copy, 0, 50)\n    pts = np.argwhere(canny>0)\n    y1,x1 = pts.min(axis=0)\n    y2,x2 = pts.max(axis=0)\n    cropped_img = img[y1:y2, x1:x2]\n    cropped_img = cv2.resize(cropped_img, size)\n    cropped_img = cropped_img.astype(\"float32\")*(1.)/255\n    return np.array(cropped_img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image preprocessing Ben's preprocessing\ndef crop_image_from_gray(img, tol=7):\n    \"\"\"\n    Applies masks to the orignal image and \n    returns the a preprocessed image with \n    3 channels\n    \"\"\"\n    # If for some reason we only have two channels\n    if img.ndim == 2:\n        mask = img > tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    # If we have a normal RGB images\n    elif img.ndim == 3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img > tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n    \ndef preprocess_image(image, sigmaX=10):\n    \"\"\"\n    The whole preprocessing pipeline:\n    1. Read in image\n    2. Apply masks\n    3. Resize image to desired size\n    4. Add Gaussian noise to increase Robustness\n    \"\"\"\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (224, 224))\n    image = cv2.addWeighted (image,4, cv2.GaussianBlur(image, (0,0) ,sigmaX), -4, 128)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              min_delta=0.0004,\n                              patience=5,\n                              factor=0.5,\n                              min_lr=1e-6,\n                              mode='auto',\n                              verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import EarlyStopping\nearly_stop = EarlyStopping(monitor='val_loss',\n                           min_delta=0.0001, \n                           patience=10, \n                           verbose=1,\n                           mode='auto')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.optimizers import Adam \n#load train and test data\ndf_train = pd.read_csv(train_csv)\ndf_train[\"id_code\"] = df_train[\"id_code\"].apply(lambda x:x+\".png\")\ndf_train[\"diagnosis\"] = df_train['diagnosis'].astype('str')\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1/255.,\n                                  horizontal_flip = True,\n                                  vertical_flip = False,\n                                  width_shift_range = 0.1,\n                                  height_shift_range = 0.1,\n                                  fill_mode = 'nearest',\n                                  validation_split = 0.15,\n                                  zoom_range = 0.2,\n                                  preprocessing_function=preprocess_image,\n                                  rotation_range = 10)\n      \ntrain_generator = train_datagen.flow_from_dataframe(\n    dataframe = df_train,\n    directory = image_dataset,\n    validation_split = 0.2,\n    x_col = 'id_code',\n    y_col = 'diagnosis',\n    target_size = (224,224),\n    class_mode = 'categorical',\n    batch_size = 64,\n    shaffle=True,\n    subset = 'training'\n)\n\nval_generator = train_datagen.flow_from_dataframe(\n    dataframe = df_train,\n    x_col = 'id_code',\n    y_col = 'diagnosis',\n    directory = image_dataset,\n    class_mode = \"categorical\",\n    batch_size = 64,\n    shaffle=True,\n    target_size = (224,224),\n    subset = \"validation\"\n    )\noptimizer = Adam(lr=0.0005)\nsave_callback = ModelCheckpoint(filepath='Blindness-detection.h5', monitor='val_loss', save_best_only=True)\nmodel.compile(loss = 'categorical_crossentropy',optimizer = 'adam',metrics = ['accuracy'])\n\n\nhistory = model.fit_generator(\n    train_generator,\n    epochs = 70,\n    steps_per_epoch = 20,\n    validation_data = val_generator,\n    validation_steps = 7,\n    callbacks = [reduce_lr,early_stop,save_callback]\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plotting accuracies and losses\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nprint('kappa loss',history)\n\nepochs = range(1,len(acc) + 1)\n\nplt.plot(epochs,acc,'bo',label = 'Training Accuracy')\nplt.plot(epochs,val_acc,'b',label = 'Validation Accuracy')\nplt.title('Training and Validation Accuracy')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs,loss,'bo',label = 'Training loss')\nplt.plot(epochs,val_loss,'b',label = 'Validation Loss')\nplt.title('Training and Validation Loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#make predictions on test images\n\ntest_datagen = ImageDataGenerator(rescale=1./255,\n                                 preprocessing_function=preprocess_image)\n\n\nsample_df = pd.read_csv(sample_csv)\n\nsample_df[\"id_code\"]=sample_df[\"id_code\"].apply(lambda x:x+\".png\")\n\ntest_generator = test_datagen.flow_from_dataframe(  \n        dataframe=sample_df,\n        directory = test_dataset,    \n        x_col=\"id_code\",\n        target_size = (224,224),\n        batch_size = 1,\n        shuffle = False,\n        class_mode = None\n        )\npreds = model.predict_generator(\n    test_generator,\n    steps=len(test_generator.filenames)\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#sklearn confusion matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\ny_true = val_generator.classes\ny_pred = np.argmax(model.predict_generator(val_generator),axis=1)\nprint(confusion_matrix(y_true,y_pred))\n\n#classification report\ntarget_names = ['0','1','2','3','4']\nprint(classification_report(val_generator.classes, y_pred, target_names=target_names))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #submission formatting\nfilenames= test_generator.filenames\nresults=pd.DataFrame({\"id_code\":filenames,\n                      \"diagnosis\":np.argmax(preds,axis = 1)})\nresults['id_code'] = results['id_code'].map(lambda x: str(x)[:-4])\nresults.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results['diagnosis'].value_counts().plot(kind='bar')\nplt.title('Test Samples Per Class')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}