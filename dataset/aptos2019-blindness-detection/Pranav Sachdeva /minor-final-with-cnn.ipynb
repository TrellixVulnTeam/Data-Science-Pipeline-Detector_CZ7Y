{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"\nimport numpy as np \nimport pandas as pd \n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os, sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport skimage.io\nfrom skimage.transform import resize\nfrom imgaug import augmenters as iaa\nfrom tqdm import tqdm\nimport PIL\nfrom PIL import Image, ImageOps\nimport cv2\nfrom sklearn.utils import class_weight, shuffle\n#from keras.losses import binary_crossentropy\n#from keras.applications.resnet50 import preprocess_input\n#import keras.backend as K\n#import tensorflow as tf\nfrom sklearn.metrics import f1_score, fbeta_score\n#from keras.utils import Sequence\n#from keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\n\nWORKERS = 2\nCHANNEL = 3\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nIMG_SIZE = 512\nNUM_CLASSES = 5\nSEED = 77\nTRAIN_NUM = 1000 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ndf_test = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n\nx = df_train['id_code']\ny = df_train['diagnosis']\n\n\ny.hist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* > ****CROSS VALIDATION TECHNIQUE****"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_x, valid_x, train_y, valid_y = train_test_split(x, y, test_size=0.15,\n                                                      stratify=y, random_state=SEED)\nprint(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape)\ntrain_y.hist()\n\nvalid_y.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.plotting import scatter_matrix\ndf = pd.DataFrame(np.random.randn(1000, 4), columns = ['train_x', 'train_y', 'valid_x', 'valid-y'])\nscatter_matrix(df, alpha = 0.2, figsize = (6, 6), diagonal = 'kde')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***ORIGINAL INPUT***"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_dataset(path):\n    eye_files = os.listdir(path)\n    return eye_files","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_a = load_dataset('../input/aptos2019-blindness-detection/train_images')\ntest_b = load_dataset('../input/aptos2019-blindness-detection/test_images')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom glob import glob\n\ntrain_a = np.array(glob(\"../input/aptos2019-blindness-detection/train_images/*\"))\ntrain_b = np.array(glob(\"../input/aptos2019-blindness-detection/test_images/*\"))\nimg = cv2.imread(train_a[3])\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nfor i in range(10):\n    plt.figure(figsize=(10,10))\n    i = random.choice(os.listdir('../input/aptos2019-blindness-detection/train_images'))\n    i_c = i.split('.')[0]\n    img = cv2.imread(os.path.join('../input/aptos2019-blindness-detection/train_images', i))\n    \n    plt.imshow(img)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***RGB PREPROCESSING TO INPUTS***"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n%%time\nimport random\nfig = plt.figure(figsize=(25, 16))\n# display 10 images from each clasS\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (100, 100))\n\n        plt.imshow(image)\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***GRAY SCALE PRE PROCESSING***"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n\n        image = cv2.resize(image, (100, 100))\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***ZOOMING THE DETAILS ***\n***PRE PROCESSING***"},{"metadata":{"trusted":true},"cell_type":"code","source":"dpi = 80 #inch\n\n# path=f\"../input/aptos2019-blindness-detection/train_images/5c7ab966a3ee.png\" # notice upper part\npath=f\"../input/aptos2019-blindness-detection/train_images/cd54d022e37d.png\" # lower-right, this still looks not so severe, can be class3\nimage = cv2.imread(path)\nimage = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\nheight, width = image.shape\nprint(height, width)\n\nSCALE=2\nfigsize = (width / float(dpi))/SCALE, (height / float(dpi))/SCALE\n\nfig = plt.figure(figsize=figsize)\nplt.imshow(image, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***BEN GRAMS PRE PROCESSING METHOD***"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n#         image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (100, 100))\n        image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , 100/10) ,-4 ,128) # the trick is to add this line\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***AUTO CROPPING PRE PROCESSING***"},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n    plt.imshow(image, cmap='gray')\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_ben_color(path, sigmaX=10):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (100,100))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = load_ben_color(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***CIRCULAR CROP PRE PROCESSING***"},{"metadata":{"trusted":true},"cell_type":"code","source":"def circle_crop(img, sigmaX=10):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted ( img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    return img ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n## try circle crop\nNUM_SAMP=7\nfig = plt.figure(figsize=(25, 16))\nfor class_id in sorted(train_y.unique()):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(NUM_SAMP, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, NUM_SAMP, class_id * NUM_SAMP + i + 1, xticks=[], yticks=[])\n        path=f\"../input/aptos2019-blindness-detection/train_images/{row['id_code']}.png\"\n        image = circle_crop(path,sigmaX=30)\n\n        plt.imshow(image)\n        ax.set_title('%d-%d-%s' % (class_id, idx, row['id_code']) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, GaussianNoise, GaussianDropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, SeparableConv2D\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras import regularizers, optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntrain_df['diagnosis'] = train_df['diagnosis'].astype('str')\ntrain_df['id_code'] = train_df['id_code'].astype(str)+'.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen=ImageDataGenerator(\n    rescale=1./255, \n    validation_split=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nbatch_size = 16\nimage_size = 96\n\n\n\ntrain_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/aptos2019-blindness-detection/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(image_size,image_size),\n    subset='training')\n\ntest_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/aptos2019-blindness-detection/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\", \n    target_size=(image_size,image_size),\n    subset='validation')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_df['diagnosis']\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train)\nnum_classes = y_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    # create model\n    model = Sequential()\n    #model.add(Reshape((x_train.shape[0],),))\n    #model.add(GaussianDropout(0.3,input_shape=[96,96,3]))\n    model.add(Conv2D(15, (3, 3), input_shape=[96,96,3], activation='relu'))\n    model.add(GaussianDropout(0.3))\n    model.add(Conv2D(30, (5, 5), activation='relu', kernel_constraint=maxnorm(3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(30, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(50, (5, 5), activation='relu'))\n    model.add(Conv2D(50, (7, 7), activation='relu'))\n    \n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n                   ,activity_regularizer=regularizers.l1(0.01)))\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 20)\nmc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator=train_gen,              \n                                    steps_per_epoch=len(train_gen),\n                                    validation_data=test_gen,                    \n                                    validation_steps=len(test_gen),\n                                    epochs=1,\n                                    callbacks = [es, mc], \n                                    use_multiprocessing = True,\n                                    verbose=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n#submission_df['diagnosis'] = submission_df['diagnosis'].astype('str')\nsubmission_df['filename'] = submission_df['id_code'].astype(str)+'.png'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_datagen=ImageDataGenerator(rescale=1./255)\nsubmission_gen=submission_datagen.flow_from_dataframe(\n    dataframe=submission_df,\n    directory=\"../input/aptos2019-blindness-detection/test_images\",\n    x_col=\"filename\",    \n    batch_size=batch_size,\n    shuffle=False,\n    class_mode=None, \n    target_size=(image_size,image_size)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict_generator(submission_gen, steps = len(submission_gen))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_probability = np.argmax(predictions,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.drop(columns=['filename'], inplace= True)\nsubmission_df['diagnosis'] = max_probability\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**random forest**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport os\nimport time\n\n#model selection\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\n# specifically for manipulating zipped images and getting numpy arrays of pixel values of images.\nimport cv2                  \n\n# to make this notebook's output stable across runs\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 128\nDATA_DIR = os.path.join(r'/kaggle/input/', 'aptos2019-blindness-detection')\nTRAIN_DIR = os.path.join(DATA_DIR,'train_images')\nTEST_DIR = os.path.join(DATA_DIR, 'test_images')\n\ndef searchCircle(img):\n    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    gray = cv2.medianBlur(gray, 5)\n    rows = gray.shape[0]\n    circles = cv2.HoughCircles(gray, cv2.HOUGH_GRADIENT, 1, rows / 8,\n                               param1=100, param2=30,\n                               minRadius=int(img.shape[1]/4), maxRadius=int(img.shape[1]/2))\n    \n    if circles is not None:\n        circles = np.int32(np.around(circles))\n        return circles[0,0]\n    \n    cx = int(img.shape[1]/2)\n    cy = int(img.shape[0]/2)\n    r = max(cx, cy)\n    return np.array([cx, cy, r])\n\ndef circle_crop(img, cx, cy, r):\n    mask = np.zeros((img.shape[1], img.shape[0]), np.uint8)\n    cv2.circle(mask, (cx, cy), r, (255,255,255), thickness=-1)\n    return cv2.bitwise_and(img, img, mask=mask)\n\ndef rect_crop(img, x0, y0, x1, y1):\n    mask = np.zeros((img.shape[1], img.shape[0]), np.uint8)\n    cv2.rectangle(mask, (x0, y0), (x1, y1), (255,255,255), thickness=-1)\n    return cv2.bitwise_and(img, img, mask=mask)\n\ndef processImg(img):\n    # find the circle and resize\n    cir = searchCircle(img)     \n    scale = (float(IMG_SIZE)) / (cir[2] * 2)\n    img = cv2.resize(img,(0,0),fx=scale, fy=scale)\n    \n    cir = np.int32(np.around(cir * scale))\n    \n    # crop the circle\n    x0 = max(cir[0]-cir[2], 0)\n    x1 = min(cir[0]+cir[2], img.shape[1])\n    y0 = max(cir[1]-cir[2], 0)\n    y1 = min(cir[1]+cir[2], img.shape[0])\n    img = img[y0:y1, x0:x1,:]\n    \n    # copy the circle to the center of square\n    img1 = np.zeros([cir[2] * 2, cir[2] * 2, img.shape[2]])\n    dx = max(cir[2] - cir[0], 0)\n    dy = max(cir[2] - cir[1], 0)\n    img1[dy:dy+y1-y0,dx:dx+x1-x0,:] = img\n    \n    # crop the cirle\n    r = int(IMG_SIZE/2)\n    img1 = circle_crop(img1, r, r, r)\n    img1 = rect_crop(img1, dx, dy, dx+x1-x0, dy+y1-y0)\n\n    img1 = np.array(img1)/255 # normalize the image\n    return img1\n\ndef getImageData(path):\n    img = cv2.imread(path, cv2.IMREAD_COLOR)\n\n    if img is not None:\n        return processImg(img)\n    \n    return None\n\ndef idcode2Path(imgDir, idCode):\n    return os.path.join(imgDir, '{}.png'.format(idCode))\n\ndef getImgArray(idList, imgDir):\n    imgs = []\n    for i, idCode in enumerate(idList):\n        img = getImageData(idcode2Path(imgDir, idCode))\n        if img is None:\n            print(idCode , \" is none\")\n        imgs.append(img)\n        \n    return np.array(imgs)\n\ndef showOne(ax, imgs, index):\n    if(index >= len(imgs)): \n        return False\n    \n    img1 = imgs[index].reshape(IMG_SIZE, IMG_SIZE, 3)\n    ax.imshow(img1)\n    ax.axis(\"off\")\n    \n    return True\n\ndef plotMatrix(funcOne, paramList, row=1, col=3, figsize=None):\n    if figsize is None:\n        figsize=(col * 5, row * 4)\n    fig, axes = plt.subplots(row, col,figsize=figsize)\n    if((row > 1) | (col > 1)):\n        axes = axes.ravel()\n    else:\n        axes = [axes]\n        \n    for i, ax in enumerate(axes):\n        if(not funcOne(ax, paramList, i)): \n            break\n   \n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t0 = time.time()\nX = getImgArray(df['id_code'], TRAIN_DIR)\nX = X.reshape(X.shape[0], X.shape[1]*X.shape[2]*X.shape[3])\nY = df['diagnosis']\n\nprint(\"getImgArray elapsed time:\", time.time() - t0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_valid,y_train,y_valid = train_test_split(X,Y,test_size=0.2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestClassifier(random_state=42, bootstrap=False, criterion='entropy', \n           max_features=10,min_samples_split=10, max_depth=38, n_estimators=27)\n\nmodel.fit(x_train, y_train)\n\ny_valid_pred = model.predict(x_valid)\n\nscore = accuracy_score(y_valid, y_valid_pred)\nprint(\"Valid Score = {0:.4f}\".format(score))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))\nx_test = getImgArray(test_df['id_code'], TEST_DIR)\n\nprint(x_test.shape)\nx_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]*x_test.shape[3])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X, np.array(Y))\npred = model.predict(x_test)\n\ntest_df['diagnosis'] = pred\ntest_df.to_csv('submission2.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**KNN BEGINS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix \nfrom sklearn.metrics import cohen_kappa_score\nfrom imblearn.over_sampling import SMOTE\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\n\n#Ensures consistency across runs\nfrom numpy.random import seed\nseed(1)\n\n#Imports to view data\nimport cv2\nfrom glob import glob\nimport matplotlib.pyplot as plt\nfrom numpy import floor\nimport random\n\n#others\nimport os\nprint(os.listdir('../input/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df=pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest_df=pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nprint('Size of train dataset',train_df.shape)\nprint('Size of test dataset',test_df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_labels=train_df['diagnosis']\ndisplay(train_labels.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"target_classes=['No DR','Mild','Moderate','Sever','Proliferative DR']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\nid_code=train_df['id_code']\ndiagnosis=train_df['diagnosis']\nid_code,diagnosis=shuffle(id_code,diagnosis,random_state=42)\nplt.figure(figsize=(15,8))\nplt.xlabel('diagnosis')\nplt.ylabel('count')\ndiagnosis.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_image(path,id_code,size):\n    img_path=os.path.join(path,id_code+'.png')\n    image=cv2.imread(img_path)\n    image=cv2.resize(image,(size,size))\n    #Normalizing pixel data (0-255)\n    image=image.reshape(size,size,3).astype('float32')/255  \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Build train images data as a numpy array\ntrain_images=[]\ntrain_images.append(train_df['id_code'].apply(lambda x:read_image\n                                              ('../input/aptos2019-blindness-detection/train_images',x,128)))\ndf_train=np.array(train_images)\ndf_train=df_train.reshape(df_train.shape[1],128,128,3).astype('float32')\nprint(df_train.shape)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df=pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\ntest_images=[]\ntest_images.append(test_df['id_code'].apply(lambda x:read_image\n                                              ('../input/aptos2019-blindness-detection/test_images',x,128)))\nX_test=np.array(test_images)\nX_test=X_test.reshape(X_test.shape[1],128,128,3).astype('float32')\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_2d = len(df_train)\ndf_train= df_train.reshape(df_train_2d,-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Before sampling...')\nprint('Size of the train dataset:',len(df_train))\nprint(\"Before sampling,counts of label '0':{}\".format(sum(train_labels==0)))\nprint(\"Before sampling,counts of label '1':{}\".format(sum(train_labels==1)))\nprint(\"Before sampling,counts of label '2':{}\".format(sum(train_labels==2)))\nprint(\"Before sampling,counts of label '3':{}\".format(sum(train_labels==3)))\nprint(\"Before sampling,counts of label '4':{}\".format(sum(train_labels==4)))\n#Apply SMOTE technique\nsm=SMOTE(random_state=42,k_neighbors=3)\nX_train_res,Y_train_res=sm.fit_sample(df_train,train_labels.ravel())\n\n#After sampling\nprint('After sampling...')\nprint('Size of the train dataset:',len(X_train_res))\nprint(\"Before sampling,counts of label '0':{}\".format(sum(Y_train_res==0)))\nprint(\"Before sampling,counts of label '1':{}\".format(sum(Y_train_res==1)))\nprint(\"Before sampling,counts of label '2':{}\".format(sum(Y_train_res==2)))\nprint(\"Before sampling,counts of label '3':{}\".format(sum(Y_train_res==3)))\nprint(\"Before sampling,counts of label '4':{}\".format(sum(Y_train_res==4)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train1,X_valid,Y_train1,Y_valid=train_test_split(X_train_res,Y_train_res,\n                                                 test_size=0.1,\n                                                 random_state=42)\nprint(len(X_train1),len(X_valid))\nprint(len(Y_train1),len(Y_valid))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert 3d array to 1d array\nX_test_2d = len(X_test)\nX_test= X_test.reshape(X_test_2d,-1)\nprint(X_train1.shape,X_valid.shape,X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Evaluating the KNN Classifier...')\nmodel=KNeighborsClassifier(n_neighbors=3,n_jobs=-1)\nmodel.fit(X_train1,Y_train1)\nY_pred=model.predict(X_valid)\nclassification_report=classification_report(Y_valid,Y_pred,target_names=target_classes)\ndisplay(classification_report)\nconfusion_matrix=confusion_matrix(Y_valid,Y_pred)\ndisplay(confusion_matrix)\nkappa_score=cohen_kappa_score(Y_valid,Y_pred,weights='quadratic')\nprint('Quadratic Kappa Score:')\ndisplay(kappa_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#prediction on unseen data (test data)\nKNN=pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\nY_predict=model.predict(X_test)\nKNN['diagnosis']=Y_predict\nKNN.to_csv('submission3.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}