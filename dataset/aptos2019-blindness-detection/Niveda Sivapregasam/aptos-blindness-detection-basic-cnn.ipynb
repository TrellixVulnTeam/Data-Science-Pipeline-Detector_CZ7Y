{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load train data:"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/train.csv')\ntrain_df['diagnosis'] = train_df['diagnosis'].astype('str')\ntrain_df['id_code'] = train_df['id_code'].astype(str)+'.png'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Function \n* to get image from respective directory(train_images, test_images)\n* to resize the large image\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen=ImageDataGenerator(\n    rescale=1./255, \n    validation_split=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\nbatch_size = 16\nimage_size = 96\n\n\n\ntrain_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    target_size=(image_size,image_size),\n    subset='training')\n\ntest_gen=datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"../input/train_images\",\n    x_col=\"id_code\",\n    y_col=\"diagnosis\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\", \n    target_size=(image_size,image_size),\n    subset='validation')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Extract target column from training data\n* Convert target column to categorical"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = train_df['diagnosis']\nfrom keras.utils import np_utils\ny_train = np_utils.to_categorical(y_train)\nnum_classes = y_train.shape[1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Traditional CNN:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, GaussianNoise, GaussianDropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, SeparableConv2D\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras import regularizers, optimizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    # create model\n    model = Sequential()\n    #model.add(Reshape((x_train.shape[0],),))\n    #model.add(GaussianDropout(0.3,input_shape=[96,96,3]))\n    model.add(Conv2D(15, (3, 3), input_shape=[96,96,3], activation='relu'))\n    model.add(GaussianDropout(0.3))\n    model.add(Conv2D(30, (5, 5), activation='relu', kernel_constraint=maxnorm(3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(30, (3, 3), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Conv2D(50, (5, 5), activation='relu'))\n    model.add(Conv2D(50, (7, 7), activation='relu'))\n    \n    model.add(Dropout(0.2))\n    model.add(Flatten())\n    model.add(Dense(256, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(128, activation='relu'))\n    model.add(Dense(50, activation='relu'))\n    model.add(Dense(num_classes, activation='softmax', kernel_regularizer=regularizers.l2(0.0001)\n                   ,activity_regularizer=regularizers.l1(0.01)))\n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"To prevent overfitting,\n* monitoring the loss on validation/test set for minimum value\n* run epochs for 20 times when there is no decrease in val_loss\n* save the best model that has low validation loss"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nes= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 20)\nmc = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit_generator(generator=train_gen,              \n                                    steps_per_epoch=len(train_gen),\n                                    validation_data=test_gen,                    \n                                    validation_steps=len(test_gen),\n                                    epochs=50,\n                                    callbacks = [es, mc], \n                                    use_multiprocessing = True,\n                                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\nmodel = load_model('model.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Run predictions for given test data and submit the output file in required format (submission.csv)"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/sample_submission.csv')\n#submission_df['diagnosis'] = submission_df['diagnosis'].astype('str')\nsubmission_df['filename'] = submission_df['id_code'].astype(str)+'.png'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Preprocessing test images:"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_datagen=ImageDataGenerator(rescale=1./255)\nsubmission_gen=submission_datagen.flow_from_dataframe(\n    dataframe=submission_df,\n    directory=\"../input/test_images\",\n    x_col=\"filename\",    \n    batch_size=batch_size,\n    shuffle=False,\n    class_mode=None, \n    target_size=(image_size,image_size)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict_generator(submission_gen, steps = len(submission_gen))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_probability = np.argmax(predictions,axis=1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.drop(columns=['filename'], inplace= True)\nsubmission_df['diagnosis'] = max_probability\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}