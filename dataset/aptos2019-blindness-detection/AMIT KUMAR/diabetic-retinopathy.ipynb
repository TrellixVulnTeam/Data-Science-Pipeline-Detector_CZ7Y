{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-21T14:48:03.433155Z","iopub.execute_input":"2021-08-21T14:48:03.433487Z","iopub.status.idle":"2021-08-21T14:48:09.927721Z","shell.execute_reply.started":"2021-08-21T14:48:03.43346Z","shell.execute_reply":"2021-08-21T14:48:09.920829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras import Model\nfrom tensorflow.keras import layers\nimport os\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport cv2\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input,InceptionV3\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\nfrom tensorflow.keras.optimizers import RMSprop,Adam","metadata":{"execution":{"iopub.status.busy":"2021-08-21T14:48:09.929727Z","iopub.execute_input":"2021-08-21T14:48:09.93015Z","iopub.status.idle":"2021-08-21T14:48:15.990687Z","shell.execute_reply.started":"2021-08-21T14:48:09.930107Z","shell.execute_reply":"2021-08-21T14:48:15.989913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#2019 data\n'''import cv2\nimport glob\nfrom tqdm import tqdm\nfiles= glob.glob(\"../input/aptos2019-blindness-detection/train_images/*.png\")\nfor i in tqdm(range(len(files))):\n    img = cv2.imread(files[i])\n    green=img[:,:,1]\n    clache= cv2.createCLAHE(clipLimit=3.0)\n    clache_img= clache.apply(green) \n    median_img= cv2.medianBlur(clache_img,5)\n    \n\n    resize_img=cv2.resize(median_img,(256,256))\n    \n\n    #canny_img= cv2.Canny(resize_img,75,200)\n\n    \n    cv2.imwrite(\"./\"+os.path.basename(files[i]), resize_img)'''","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:07:02.779178Z","iopub.execute_input":"2021-08-19T10:07:02.779717Z","iopub.status.idle":"2021-08-19T10:15:42.811515Z","shell.execute_reply.started":"2021-08-19T10:07:02.779674Z","shell.execute_reply":"2021-08-19T10:15:42.809704Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"base_image_dir= os.path.join(\"..\",\"input\", \"aptos2019-blindness-detection\")\nprint(base_image_dir)\nretina_df2019 = pd.read_csv(os.path.join(base_image_dir, \"train.csv\"))\n#retina_df[\"PatientId\"]= retina_df[\"id_code\"].map(lambda x: x.split(\"_\")[0])\nretina_df2019['path'] = retina_df2019['id_code'].map(lambda x: os.path.join(\"../input/aptos2019-blindness-detection/train_images\",'{}.png'.format(x)))\nretina_df2019[\"exists\"]= retina_df2019[\"path\"].map(os.path.exists)\nprint(retina_df2019[\"exists\"].sum(),\"found of\",retina_df2019.shape[0], \"total\")\nretina_df2019.dropna(inplace= True)\nretina_df2019= retina_df2019[retina_df2019[\"exists\"]]\nretina_df=retina_df2019","metadata":{"execution":{"iopub.status.busy":"2021-08-20T11:06:13.650337Z","iopub.execute_input":"2021-08-20T11:06:13.650941Z","iopub.status.idle":"2021-08-20T11:06:13.673915Z","shell.execute_reply.started":"2021-08-20T11:06:13.650892Z","shell.execute_reply":"2021-08-20T11:06:13.672356Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm\ndef load_raw_images_df(data_frame,filenamecol,labelcol,img_size,n_classes):\n    n_images = len(data_frame)\n    X = np.empty((n_images,img_size,img_size,3))\n    Y = np.zeros((n_images,n_classes))\n    for index,entry in tqdm(data_frame.iterrows()):  \n        Y[index,entry[labelcol]] = 1\n        img = cv2.imread(entry[filenamecol])\n        green=img[:,:,1]\n        clache= cv2.createCLAHE(clipLimit=3.0)\n        clache_img= clache.apply(green) \n        median_img= cv2.medianBlur(clache_img,5)\n\n\n        resize_img=cv2.resize(median_img,(256,256))\n        layer=cv2.merge((resize_img,resize_img,resize_img))\n        X[index,:] =layer\n        X[index,:] = X[index,:] /255.0\n    return X,Y","metadata":{"execution":{"iopub.status.busy":"2021-08-20T11:10:27.960341Z","iopub.execute_input":"2021-08-20T11:10:27.960858Z","iopub.status.idle":"2021-08-20T11:10:27.972588Z","shell.execute_reply.started":"2021-08-20T11:10:27.960811Z","shell.execute_reply":"2021-08-20T11:10:27.971311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_df,val_df= train_test_split(retina_df,\n                                    random_state = 42,\n                                    shuffle= True,\n                                    test_size=0.2)\ntrain_df.reset_index(drop=True,inplace=True)\nval_df.reset_index(drop=True,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:15:42.947764Z","iopub.execute_input":"2021-08-19T10:15:42.948194Z","iopub.status.idle":"2021-08-19T10:15:43.623479Z","shell.execute_reply.started":"2021-08-19T10:15:42.948152Z","shell.execute_reply":"2021-08-19T10:15:43.622446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nimg_size = 256\nX_train,Y_train = load_raw_images_df(train_df,\"path\",\"diagnosis\",img_size,5)\nX_val,Y_val = load_raw_images_df(val_df,\"path\",\"diagnosis\",img_size,5)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T10:15:43.65554Z","iopub.execute_input":"2021-08-19T10:15:43.6558Z","iopub.status.idle":"2021-08-19T10:15:53.251103Z","shell.execute_reply.started":"2021-08-19T10:15:43.655775Z","shell.execute_reply":"2021-08-19T10:15:53.250422Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path= \"../input/d/madmaxliu/inceptionv3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\npre_trained_model=InceptionV3(weights=path,input_shape=(256,256,3),include_top=False)\nfor layer in pre_trained_model.layers:\n    layer.trainable=False\nlast_layer=pre_trained_model.get_layer(\"mixed7\")\nlast_output= last_layer.output\nx= layers.Flatten()(last_output)\nx=layers.Dense(1024,activation=\"relu\")(x)\nx=layers.Dropout(0.2)(x)\nx= layers.Dense(5,activation=\"softmax\")(x)\nmodel= Model(pre_trained_model.input,x)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T14:48:15.991886Z","iopub.execute_input":"2021-08-21T14:48:15.992273Z","iopub.status.idle":"2021-08-21T14:48:22.000558Z","shell.execute_reply.started":"2021-08-21T14:48:15.992246Z","shell.execute_reply":"2021-08-21T14:48:21.999554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer=Adam(lr=0.00005),loss = \"categorical_crossentropy\" ,metrics = [\"accuracy\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:55:39.299119Z","iopub.execute_input":"2021-08-20T08:55:39.300386Z","iopub.status.idle":"2021-08-20T08:55:40.532249Z","shell.execute_reply.started":"2021-08-20T08:55:39.300329Z","shell.execute_reply":"2021-08-20T08:55:40.531401Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n            rotation_range=40,\n            width_shift_range=0.2,\n            shear_range=0.2,\n            zoom_range=0.2,  \n            fill_mode='constant', \n            cval=0.,  \n            horizontal_flip=True,  \n            vertical_flip=True)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:55:44.218803Z","iopub.execute_input":"2021-08-20T08:55:44.219126Z","iopub.status.idle":"2021-08-20T08:55:44.223968Z","shell.execute_reply.started":"2021-08-20T08:55:44.219098Z","shell.execute_reply":"2021-08-20T08:55:44.223322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom tensorflow.keras.callbacks import ModelCheckpoint,EarlyStopping\nmc= ModelCheckpoint(filepath= \"./best_model.h5\",\n                    monitor=\"accuracy\",\n                    verbose=1,\n                    save_best_only=True)\nes=EarlyStopping(monitor=\"accuracy\",\n                 min_delta=0.01,\n                 patience=8,\n                 verbose=1)\ncb=[mc,es]","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:55:46.028855Z","iopub.execute_input":"2021-08-20T08:55:46.029184Z","iopub.status.idle":"2021-08-20T08:55:46.034202Z","shell.execute_reply.started":"2021-08-20T08:55:46.029155Z","shell.execute_reply":"2021-08-20T08:55:46.033492Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EPOCHS = 10\nhistory=model.fit_generator(datagen.flow(X_train, Y_train, batch_size=32), \n                        validation_data=(X_val, Y_val), steps_per_epoch=X_train.shape[0]/32,\n                            callbacks=cb, epochs=EPOCHS)\n","metadata":{"execution":{"iopub.status.busy":"2021-08-20T08:55:47.389203Z","iopub.execute_input":"2021-08-20T08:55:47.389732Z","iopub.status.idle":"2021-08-20T08:55:47.415488Z","shell.execute_reply.started":"2021-08-20T08:55:47.389698Z","shell.execute_reply":"2021-08-20T08:55:47.41435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\nmodel= load_model(\"./best_model.h5\")\nh= history.history\nh.keys()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T11:06:19.863002Z","iopub.execute_input":"2021-08-19T11:06:19.863492Z","iopub.status.idle":"2021-08-19T11:06:29.216413Z","shell.execute_reply.started":"2021-08-19T11:06:19.863434Z","shell.execute_reply":"2021-08-19T11:06:29.215494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(h[\"accuracy\"],c=\"blue\")\nplt.plot(h[\"val_accuracy\"],c=\"red\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T11:06:29.217734Z","iopub.execute_input":"2021-08-19T11:06:29.217993Z","iopub.status.idle":"2021-08-19T11:06:29.416505Z","shell.execute_reply.started":"2021-08-19T11:06:29.217967Z","shell.execute_reply":"2021-08-19T11:06:29.415582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.plot(h[\"loss\"],c=\"blue\")\nplt.plot(h[\"val_loss\"],c=\"red\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-19T11:06:29.419731Z","iopub.execute_input":"2021-08-19T11:06:29.420012Z","iopub.status.idle":"2021-08-19T11:06:29.542085Z","shell.execute_reply.started":"2021-08-19T11:06:29.419976Z","shell.execute_reply":"2021-08-19T11:06:29.541148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_data=pd.read_csv(\"../input/aptos2019-blindness-detection/test.csv\")\n\n","metadata":{"execution":{"iopub.status.busy":"2021-08-19T11:08:07.553934Z","iopub.execute_input":"2021-08-19T11:08:07.554316Z","iopub.status.idle":"2021-08-19T11:08:07.57278Z","shell.execute_reply.started":"2021-08-19T11:08:07.554285Z","shell.execute_reply":"2021-08-19T11:08:07.571938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntest_data['filename'] = test_data['id_code'].map(lambda x: x+\".png\")","metadata":{"execution":{"iopub.status.busy":"2021-08-19T11:09:02.819494Z","iopub.execute_input":"2021-08-19T11:09:02.819886Z","iopub.status.idle":"2021-08-19T11:09:02.826572Z","shell.execute_reply.started":"2021-08-19T11:09:02.819854Z","shell.execute_reply":"2021-08-19T11:09:02.825481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_gen=ImageDataGenerator(rescale=1./255)\ntest_generator=test_gen.flow_from_dataframe(\n\n                                dataframe=test_data,\n                                directory=\"../input/aptos2019-blindness-detection/test_images\",\n                                x_col=\"filename\",\n                                y_col=None,\n                                \n                                target_size=(256,256),\n                                color_mode=\"rgb\",\n                                batch_size=1,\n                                shuffle=False,\n                                class_mode=None)","metadata":{"execution":{"iopub.status.busy":"2021-08-19T11:09:04.219679Z","iopub.execute_input":"2021-08-19T11:09:04.220031Z","iopub.status.idle":"2021-08-19T11:09:05.434018Z","shell.execute_reply.started":"2021-08-19T11:09:04.219999Z","shell.execute_reply":"2021-08-19T11:09:05.432925Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions=model.predict_generator(test_generator,steps=len(test_generator.filenames))","metadata":{"execution":{"iopub.status.busy":"2021-08-19T11:10:36.978546Z","iopub.execute_input":"2021-08-19T11:10:36.978903Z","iopub.status.idle":"2021-08-19T11:15:16.75986Z","shell.execute_reply.started":"2021-08-19T11:10:36.978867Z","shell.execute_reply":"2021-08-19T11:15:16.75861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"filenames=test_generator.filenames\nresults=pd.DataFrame(\n{\"id_code\":filenames,\n\"diagnosis\":np.argmax(predictions,axis=1),\n})\nresults['id_code'] = results['id_code'].map(lambda x: str(x)[:-4])\nresults.to_csv(\"submission.csv\",index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output= pd.read_csv(\"./submission.csv\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output","metadata":{"execution":{"iopub.status.busy":"2021-08-20T10:33:59.405116Z","iopub.execute_input":"2021-08-20T10:33:59.405751Z","iopub.status.idle":"2021-08-20T10:33:59.427464Z","shell.execute_reply.started":"2021-08-20T10:33:59.405703Z","shell.execute_reply":"2021-08-20T10:33:59.42595Z"},"trusted":true},"execution_count":null,"outputs":[]}]}