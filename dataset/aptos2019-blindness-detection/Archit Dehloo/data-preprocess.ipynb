{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nfrom keras.preprocessing import image\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.utils import to_categorical\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nimport tensorflow as tf\n\nfrom sklearn.metrics import confusion_matrix\nimport seaborn as sn; sn.set(font_scale=1.4)\nfrom sklearn.utils import shuffle                      \nimport cv2                                               \nimport tensorflow.keras.models as Models\nimport tensorflow.keras.layers as Layers\nimport tensorflow.keras.layers as layers\nimport tensorflow.keras.activations as Actications\nimport tensorflow.keras.models as Models\nimport tensorflow.keras.optimizers as Optimizer\nimport tensorflow.keras.metrics as Metrics\nimport tensorflow.keras.utils as Utils\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.preprocessing.image import ImageDataGenerator\n\nfrom scipy import ndimage","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-11T14:30:21.932189Z","iopub.execute_input":"2021-07-11T14:30:21.932732Z","iopub.status.idle":"2021-07-11T14:30:21.947004Z","shell.execute_reply.started":"2021-07-11T14:30:21.932666Z","shell.execute_reply":"2021-07-11T14:30:21.945572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Add all the paths to variables","metadata":{}},{"cell_type":"code","source":"train_path = \"/kaggle/input/aptos2019-blindness-detection/train_images/\"\ntest_path = \"/kaggle/input/aptos2019-blindness-detection/test_images\"\ntrain_data = pd.read_csv(\"../input/aptos2019-blindness-detection/train.csv\")\ntest_data = pd.read_csv(\"../input/aptos2019-blindness-detection/test.csv\")\ntrain_data.head(10)\ntest_data.head(10)\ntrain_data['diagnosis'][1]","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:21.949246Z","iopub.execute_input":"2021-07-11T14:30:21.949842Z","iopub.status.idle":"2021-07-11T14:30:21.980624Z","shell.execute_reply.started":"2021-07-11T14:30:21.949797Z","shell.execute_reply":"2021-07-11T14:30:21.979744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train_data))","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:21.982584Z","iopub.execute_input":"2021-07-11T14:30:21.982925Z","iopub.status.idle":"2021-07-11T14:30:21.988366Z","shell.execute_reply.started":"2021-07-11T14:30:21.982893Z","shell.execute_reply":"2021-07-11T14:30:21.987369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Running the above stpes on all images as per input size","metadata":{}},{"cell_type":"code","source":"def rgb2red(rgb): \n     #rgb = image.img_to_array(rgb)\n     r, g, b = rgb[:,:,0], rgb[:,:,1], rgb[:,:,2] \n     red = 25 * r + 0 * g + 0 * b\n     return red","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:21.989967Z","iopub.execute_input":"2021-07-11T14:30:21.990266Z","iopub.status.idle":"2021-07-11T14:30:22.001068Z","shell.execute_reply.started":"2021-07-11T14:30:21.990236Z","shell.execute_reply":"2021-07-11T14:30:22.000108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train_data['diagnosis'][236])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:22.002254Z","iopub.execute_input":"2021-07-11T14:30:22.00293Z","iopub.status.idle":"2021-07-11T14:30:22.017582Z","shell.execute_reply.started":"2021-07-11T14:30:22.002689Z","shell.execute_reply":"2021-07-11T14:30:22.016538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_image = []\ntrain_org=[]\nsize = 20#len(train_data)\n# label_image=[]\n# img = image.load_img(train_path +'/' + train_data['id_code'][0] +'.png',target_size=(400,400,3))\n# plt.imshow(img)\nimg_size=224\nkernel = np.ones((3,3), np.uint8)\nfor i in tqdm(range(size)):\n    img = cv2.imread(train_path +'/' + train_data['id_code'][i] +'.png')\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    img = cv2.resize(img, (img_size, img_size))\n    img_opt=cv2.addWeighted (img, -5, cv2.GaussianBlur(img, (0,0), img_size/10), 5, 128)\n    img_opt1=cv2.addWeighted (img, 5, cv2.GaussianBlur(img, (0,0), img_size/10), -5, 128)\n    test=img_opt+img_opt1\n    test = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n    test = rgb2red(test)\n    test = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n    if i==37:\n        plt.imshow(train_image[i-1])\n    #test = cv2.dilate(test, kernel, iterations=1)\n    #test = cv2.erode(test, kernel, iterations=1)\n    # test = cv2.bitwise_not(test)\n    #test=np.array(test)\n    # test=image.img_to_array(test)\n#     test = image.img_to_array(test).flatten()\n#     test_gray = cv2.cvtColor(test, cv2.COLOR_BGR2GRAY)\n#     img_opt = cv2.cvtColor(img_opt, cv2.COLOR_BGR2GRAY)\n#     img_opt = image.img_to_array(img_opt)\n    #img=np.array(test)\n    train_image.append(test)\n#     label_image.append(train_data['diagnosis'][i])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:22.020892Z","iopub.execute_input":"2021-07-11T14:30:22.021228Z","iopub.status.idle":"2021-07-11T14:30:26.050052Z","shell.execute_reply.started":"2021-07-11T14:30:22.021197Z","shell.execute_reply":"2021-07-11T14:30:26.048963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(train_image[6])","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:26.051576Z","iopub.execute_input":"2021-07-11T14:30:26.052008Z","iopub.status.idle":"2021-07-11T14:30:26.425291Z","shell.execute_reply.started":"2021-07-11T14:30:26.051963Z","shell.execute_reply":"2021-07-11T14:30:26.424257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_save_path = \"./kaggle/working/train_images2/\"\n#test_save_path = \"./kaggle/working/test_images2/\"\nos.makedirs(train_save_path)\n#os.makedirs(test_save_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:26.426568Z","iopub.execute_input":"2021-07-11T14:30:26.426892Z","iopub.status.idle":"2021-07-11T14:30:26.43125Z","shell.execute_reply.started":"2021-07-11T14:30:26.426862Z","shell.execute_reply":"2021-07-11T14:30:26.430206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.chdir(train_save_path)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:26.433099Z","iopub.execute_input":"2021-07-11T14:30:26.433378Z","iopub.status.idle":"2021-07-11T14:30:26.453211Z","shell.execute_reply.started":"2021-07-11T14:30:26.433344Z","shell.execute_reply":"2021-07-11T14:30:26.452376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count=0\nfor i in range(len(train_image)):\n    name=str(train_data['id_code'][i]+'.jpg')\n    count+=1\n    plt.imsave(name, train_image[i])\nprint(count)","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:30:26.454405Z","iopub.execute_input":"2021-07-11T14:30:26.454687Z","iopub.status.idle":"2021-07-11T14:30:26.521141Z","shell.execute_reply.started":"2021-07-11T14:30:26.45466Z","shell.execute_reply":"2021-07-11T14:30:26.519968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#os.chdir('./kaggle/working')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:33:23.35685Z","iopub.execute_input":"2021-07-11T14:33:23.357226Z","iopub.status.idle":"2021-07-11T14:33:23.36297Z","shell.execute_reply.started":"2021-07-11T14:33:23.357195Z","shell.execute_reply":"2021-07-11T14:33:23.361561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir()","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:33:25.88856Z","iopub.execute_input":"2021-07-11T14:33:25.888914Z","iopub.status.idle":"2021-07-11T14:33:25.895013Z","shell.execute_reply.started":"2021-07-11T14:33:25.888885Z","shell.execute_reply":"2021-07-11T14:33:25.894062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLinks\nFileLinks(r'train_images2')","metadata":{"execution":{"iopub.status.busy":"2021-07-11T14:34:20.373264Z","iopub.execute_input":"2021-07-11T14:34:20.373616Z","iopub.status.idle":"2021-07-11T14:34:20.380421Z","shell.execute_reply.started":"2021-07-11T14:34:20.373583Z","shell.execute_reply":"2021-07-11T14:34:20.379413Z"},"trusted":true},"execution_count":null,"outputs":[]}]}