{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nimport math\nimport os\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nimport tensorflow as tf\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau,LearningRateScheduler\nfrom tqdm import tqdm_notebook as tqdm\n\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:30:43.036564Z","iopub.execute_input":"2021-07-03T07:30:43.037038Z","iopub.status.idle":"2021-07-03T07:30:50.111542Z","shell.execute_reply.started":"2021-07-03T07:30:43.036953Z","shell.execute_reply":"2021-07-03T07:30:50.110463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport timeit\n\ndevice_name = tf.test.gpu_device_name()\nprint(device_name)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:08.232198Z","iopub.execute_input":"2021-07-03T07:31:08.232563Z","iopub.status.idle":"2021-07-03T07:31:10.403539Z","shell.execute_reply.started":"2021-07-03T07:31:08.232533Z","shell.execute_reply":"2021-07-03T07:31:10.401632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.random.seed(2020)\ntf.random.set_seed(2020)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:12.491471Z","iopub.execute_input":"2021-07-03T07:31:12.492038Z","iopub.status.idle":"2021-07-03T07:31:12.497127Z","shell.execute_reply.started":"2021-07-03T07:31:12.49196Z","shell.execute_reply":"2021-07-03T07:31:12.495935Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntest_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:14.881671Z","iopub.execute_input":"2021-07-03T07:31:14.882197Z","iopub.status.idle":"2021-07-03T07:31:14.93623Z","shell.execute_reply.started":"2021-07-03T07:31:14.882164Z","shell.execute_reply":"2021-07-03T07:31:14.934776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['diagnosis'].hist()\ntrain_df['diagnosis'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:17.302794Z","iopub.execute_input":"2021-07-03T07:31:17.30317Z","iopub.status.idle":"2021-07-03T07:31:17.555404Z","shell.execute_reply.started":"2021-07-03T07:31:17.303139Z","shell.execute_reply":"2021-07-03T07:31:17.554137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 4*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'id_code']\n        image_id = df.loc[i,'diagnosis']\n        img = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{image_path}.png')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n    \n    plt.tight_layout()\n\ndisplay_samples(train_df)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:19.96733Z","iopub.execute_input":"2021-07-03T07:31:19.96777Z","iopub.status.idle":"2021-07-03T07:31:30.52226Z","shell.execute_reply.started":"2021-07-03T07:31:19.967738Z","shell.execute_reply":"2021-07-03T07:31:30.519165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_ht = 256\nimg_wd = 256","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:35.717197Z","iopub.execute_input":"2021-07-03T07:31:35.717601Z","iopub.status.idle":"2021-07-03T07:31:35.724184Z","shell.execute_reply.started":"2021-07-03T07:31:35.717525Z","shell.execute_reply":"2021-07-03T07:31:35.722847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n    \n    \ndef circle_crop(img, sigmaX):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    img = crop_image_from_gray(img)    \n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img=cv2.addWeighted(img,4, cv2.GaussianBlur( img , (0,0) , sigmaX) ,-4 ,128)\n    return img ","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:38.621712Z","iopub.execute_input":"2021-07-03T07:31:38.622093Z","iopub.status.idle":"2021-07-03T07:31:38.639476Z","shell.execute_reply.started":"2021-07-03T07:31:38.622062Z","shell.execute_reply":"2021-07-03T07:31:38.638164Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''Perform Image Processing on a sample image'''\n\ni = np.random.randint(low = 0,high = len(train_df) - 1)\n\n#img = img_t\nimage_path = train_df.loc[i,'id_code']\nimage_id = train_df.loc[i,'diagnosis']\nimg = cv2.imread(f'../input/aptos2019-blindness-detection/train_images/{image_path}.png')\n#img = cv2.imread(train_df.file_path.iloc[rn])\nimg_t = circle_crop(img,sigmaX = 30)\n\nf, axarr = plt.subplots(1,2,figsize = (11,11))\naxarr[0].imshow(cv2.resize(cv2.cvtColor(img, cv2.COLOR_BGR2RGB),(256,256)))\naxarr[1].imshow(img_t)\nplt.title('After applying Circular Crop and Gaussian Blur')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:38.816398Z","iopub.execute_input":"2021-07-03T07:31:38.816769Z","iopub.status.idle":"2021-07-03T07:31:40.962704Z","shell.execute_reply.started":"2021-07-03T07:31:38.816719Z","shell.execute_reply":"2021-07-03T07:31:40.961701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_image(image_path):\n    img = cv2.imread(image_path)\n    img_t = circle_crop(img,sigmaX = 30)\n    img_blue_channel=cv2.resize(cv2.cvtColor(img_t, cv2.COLOR_BGR2RGB),(256,256))\n    #f, axarr = plt.subplots(1,2,figsize = (11,11))\n    #axarr[0].imshow(img_t)\n    #axarr[1].imshow(img_r)\n    #plt.title('After applying Circular Crop and Gaussian Blur')\n    #plt.show()\n    return img_blue_channel","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:31:45.392405Z","iopub.execute_input":"2021-07-03T07:31:45.392947Z","iopub.status.idle":"2021-07-03T07:31:45.400624Z","shell.execute_reply.started":"2021-07-03T07:31:45.392901Z","shell.execute_reply":"2021-07-03T07:31:45.398467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"N = train_df.shape[0]\nx_train = np.empty((N, img_ht, img_wd, 3), dtype=np.uint8)\n\n\nfor i, image_id in enumerate(tqdm(train_df['id_code'])):\n    x_train[i, :, :, :] = preprocess_image( f'../input/aptos2019-blindness-detection/train_images/{image_id}.png')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T07:41:12.115953Z","iopub.execute_input":"2021-07-03T07:41:12.116361Z","iopub.status.idle":"2021-07-03T08:39:55.854721Z","shell.execute_reply.started":"2021-07-03T07:41:12.116328Z","shell.execute_reply":"2021-07-03T08:39:55.853646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd.get_dummies(train_df['diagnosis']).values\n\nprint(x_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:00.286628Z","iopub.execute_input":"2021-07-03T08:40:00.287031Z","iopub.status.idle":"2021-07-03T08:40:00.296994Z","shell.execute_reply.started":"2021-07-03T08:40:00.286992Z","shell.execute_reply":"2021-07-03T08:40:00.295535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_multi = np.empty(y_train.shape, dtype=y_train.dtype)\ny_train_multi[:, 4] = y_train[:, 4]\n\nfor i in range(3, -1, -1):\n    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i+1])\n\nprint(\"Original y_train:\", y_train.sum(axis=0))\nprint(\"Multilabel version:\", y_train_multi.sum(axis=0))","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:02.686597Z","iopub.execute_input":"2021-07-03T08:40:02.686964Z","iopub.status.idle":"2021-07-03T08:40:02.697715Z","shell.execute_reply.started":"2021-07-03T08:40:02.686933Z","shell.execute_reply":"2021-07-03T08:40:02.696115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train_multi, \n    test_size=0.15, \n    random_state=2019\n)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:04.776467Z","iopub.execute_input":"2021-07-03T08:40:04.776855Z","iopub.status.idle":"2021-07-03T08:40:05.062404Z","shell.execute_reply.started":"2021-07-03T08:40:04.776824Z","shell.execute_reply":"2021-07-03T08:40:05.061089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 4\n\ndef create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.15,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n        width_shift_range = 0.3,\n        height_shift_range=0.3\n    )\n\n# Using original generator\ndata_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE, seed=2020)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:07.027195Z","iopub.execute_input":"2021-07-03T08:40:07.027623Z","iopub.status.idle":"2021-07-03T08:40:08.114899Z","shell.execute_reply.started":"2021-07-03T08:40:07.027581Z","shell.execute_reply":"2021-07-03T08:40:08.113737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(effnet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.00005),\n        metrics=['accuracy']\n    )\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:10.437377Z","iopub.execute_input":"2021-07-03T08:40:10.437892Z","iopub.status.idle":"2021-07-03T08:40:10.444645Z","shell.execute_reply.started":"2021-07-03T08:40:10.437859Z","shell.execute_reply":"2021-07-03T08:40:10.443075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet==1.1.0","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:12.796525Z","iopub.execute_input":"2021-07-03T08:40:12.796971Z","iopub.status.idle":"2021-07-03T08:40:22.654393Z","shell.execute_reply.started":"2021-07-03T08:40:12.796939Z","shell.execute_reply":"2021-07-03T08:40:22.653276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import efficientnet.tfkeras as efn","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:22.656907Z","iopub.execute_input":"2021-07-03T08:40:22.657383Z","iopub.status.idle":"2021-07-03T08:40:23.001876Z","shell.execute_reply.started":"2021-07-03T08:40:22.657337Z","shell.execute_reply":"2021-07-03T08:40:23.000808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_ht = 256\nimg_wd = 256","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:24.307309Z","iopub.execute_input":"2021-07-03T08:40:24.307653Z","iopub.status.idle":"2021-07-03T08:40:24.313385Z","shell.execute_reply.started":"2021-07-03T08:40:24.307623Z","shell.execute_reply":"2021-07-03T08:40:24.312003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"effnet = efn.EfficientNetB3(weights=None,\n                        include_top=False,\n                        input_shape=(img_wd, img_ht, 3))\neffnet.load_weights('../input/efficientnet/efficientnet-b3_imagenet_1000_notop.h5/efficientnet-b3_imagenet_1000_notop.h5')","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:28.226936Z","iopub.execute_input":"2021-07-03T08:40:28.227293Z","iopub.status.idle":"2021-07-03T08:40:32.913447Z","shell.execute_reply.started":"2021-07-03T08:40:28.227263Z","shell.execute_reply":"2021-07-03T08:40:32.912292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:34.487192Z","iopub.execute_input":"2021-07-03T08:40:34.487536Z","iopub.status.idle":"2021-07-03T08:40:35.867931Z","shell.execute_reply.started":"2021-07-03T08:40:34.487506Z","shell.execute_reply":"2021-07-03T08:40:35.866803Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Metrics(Callback):\n    def on_train_begin(self, logs={}):\n        self.val_kappas = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val, Y_val = x_val, y_val\n        Y_val = Y_val.sum(axis=1) - 1\n        \n        y_pred = self.model.predict(X_val) > 0.5\n        y_pred = y_pred.astype(int).sum(axis=1) - 1\n\n        _val_kappa = cohen_kappa_score(\n            Y_val,\n            y_pred, \n            weights='quadratic'\n        )\n\n        self.val_kappas.append(_val_kappa)\n\n        print(f\"val_kappa: {_val_kappa:.4f}\")\n        \n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save('model.h5')\n\n        return","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:37.8871Z","iopub.execute_input":"2021-07-03T08:40:37.887496Z","iopub.status.idle":"2021-07-03T08:40:37.895615Z","shell.execute_reply.started":"2021-07-03T08:40:37.887465Z","shell.execute_reply":"2021-07-03T08:40:37.894124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"es = EarlyStopping(monitor='val_loss',\n                                      mode='auto',\n                                      verbose=1,\n                                      patience=10)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_loss',\n                                            patience=3,\n                                            verbose=1,\n                                            mode = 'auto',\n                                            factor=0.25,\n                                            min_lr=0.000001)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:39.981979Z","iopub.execute_input":"2021-07-03T08:40:39.982387Z","iopub.status.idle":"2021-07-03T08:40:39.990239Z","shell.execute_reply.started":"2021-07-03T08:40:39.982358Z","shell.execute_reply":"2021-07-03T08:40:39.988551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with tf.device('/gpu:0'):\n    kappa_metrics = Metrics()\n    history = model.fit_generator(\n        data_generator,\n        steps_per_epoch=x_train.shape[0] / BATCH_SIZE,\n        #steps_per_epoch=5,\n        epochs=15,\n        validation_data=(x_val, y_val),\n        callbacks=[kappa_metrics,es, learning_rate_reduction]\n    )","metadata":{"execution":{"iopub.status.busy":"2021-07-03T08:40:43.496803Z","iopub.execute_input":"2021-07-03T08:40:43.497214Z","iopub.status.idle":"2021-07-03T09:08:09.757149Z","shell.execute_reply.started":"2021-07-03T08:40:43.497182Z","shell.execute_reply":"2021-07-03T09:08:09.755971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('history.json', 'w') as f:\n    try:\n        json.dump(history.history, f)\n    except:\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:16:59.947739Z","iopub.execute_input":"2021-07-03T09:16:59.948145Z","iopub.status.idle":"2021-07-03T09:16:59.954071Z","shell.execute_reply.started":"2021-07-03T09:16:59.948113Z","shell.execute_reply":"2021-07-03T09:16:59.9528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(kappa_metrics.val_kappas)","metadata":{"execution":{"iopub.status.busy":"2021-07-03T09:17:02.755576Z","iopub.execute_input":"2021-07-03T09:17:02.755977Z","iopub.status.idle":"2021-07-03T09:17:02.966538Z","shell.execute_reply.started":"2021-07-03T09:17:02.755944Z","shell.execute_reply":"2021-07-03T09:17:02.964891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}