{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fast AI setup"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *\nimport torch","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### First look at the Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/aptos2019-blindness-detection')\npath_train = path/'train_images'\npath_test = path/'test_images'\npath, path_train, path_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = pd.read_csv(path/'train.csv')\nlabels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = open_image(path_train/'000c1434d8d7.png')\nimg.show(figsize = (7,7))\nprint(img.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Distribution of the 5 diagnosis categories\nlabels['diagnosis'].value_counts().plot(kind = 'bar', title='Distribution of diagnosis categories')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The non-uniform distribution of data in our training set can be easily observed"},{"metadata":{},"cell_type":"markdown","source":"### Creating a DataBunch"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Apply data augmentation to the images\ntfms = get_transforms(\n    do_flip=True,\n    flip_vert=True,\n    max_warp=0.1,\n    max_rotate=360.,\n    max_zoom=1.1,\n    max_lighting=0.1,\n    p_lighting=0.5\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Applying aptos19 normalization and standard deviation stats, from a pre-trained model found on a kaggle kernel\naptos19_stats = ([0.42, 0.22, 0.075], [0.27, 0.15, 0.081])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_labels = pd.read_csv(path/'sample_submission.csv')\ntest = ImageList.from_df(test_labels, path = path_test, suffix = '.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"src = (ImageList.from_df(labels, path = path_train, suffix = '.png')\n       .split_by_rand_pct(seed = 42)\n       .label_from_df(cols = 'diagnosis')\n       .add_test(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (\n    src.transform(\n        tfms,\n        size = 512, \n        resize_method=ResizeMethod.SQUISH,\n        padding_mode='zeros'\n    )\n    .databunch(bs=8)\n    .normalize(aptos19_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(3, figsize = (7,7))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(data.classes)\nprint(len(data.train_ds))\nprint(len(data.valid_ds))\nprint(len(data.test_ds))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Setting up the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p /tmp/.cache/torch/checkpoints\n!cp ../input/resnet34/resnet34.pth /tmp/.cache/torch/checkpoints/resnet34-333f7ec4.pth\n!cp ../input/resnet152/resnet152.pth /tmp/.cache/torch/checkpoints/resnet152-b121ed2d.pth","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kappa = KappaScore()\nkappa.weights = \"quadratic\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = cnn_learner(\n    data, \n    models.resnet152, \n    metrics = [accuracy, kappa], \n    model_dir = Path('../kaggle/working'),\n    path = Path(\".\")\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('resnet152-1')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Unfreeze and Learn some more"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('resnet152-1');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(3, slice(1e-6,1e-5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('resnet152-2')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('resnet152-2');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# learn.export()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Double the size of images"},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (\n    src.transform(\n        tfms,\n        size = 1024, \n        resize_method=ResizeMethod.SQUISH,\n        padding_mode='zeros'\n    )\n    .databunch(bs=4)\n    .normalize(aptos19_stats))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.data = data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.freeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(4, 2e-4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('resnet152-3')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('resnet152-3');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.unfreeze()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit_one_cycle(6, 2e-5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('resnet152-4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('resnet152-4');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Get Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.load('resnet152-4');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds, _ = learn.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preparing Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(path/'sample_submission.csv')\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.array(preds.argmax(1)).astype(int).tolist()\npreds[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission['diagnosis'] = preds\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}