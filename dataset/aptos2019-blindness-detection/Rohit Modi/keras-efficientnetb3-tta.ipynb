{"cells":[{"metadata":{},"cell_type":"markdown","source":"**I would like to share a notebook that i used to train a model which i used in ensembling which resulted in the final score of 0.810 on the public LB, also i would like to share the TTA i used which gave me an lb boost of about 0.02-0.03**"},{"metadata":{},"cell_type":"markdown","source":"Configurations :\n* MODEL - EfficientNetB3\n* IMAGE SIZE - 300x300\n* OPTIMIZER - Adam\n* LEARNING RATE - 5e-5\n* EPOCHS - 6\n* BATCH SIZE - 8"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport gc\nimport h5py\nimport keras\nimport matplotlib.pyplot as plt\nimport cv2\nfrom keras.optimizers import Adam\nfrom tqdm import tqdm_notebook\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nimport random\nfrom statistics import mode","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Defining paths to directories"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"model_path = '../input/size300-v1-old-data-aptos/old_data_effnet.h5'\ntrain_csv = \"../input/aptos2019-blindness-detection/train.csv\"\ntest_csv = \"../input/aptos2019-blindness-detection/test.csv\"\ntrain_dir = \"../input/aptos2019-blindness-detection/train_images/\"\ntest_dir = \"../input/aptos2019-blindness-detection/test_images/\"\nsize = 300,300 # input image size","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading Model : "},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install -U '../input/install/efficientnet-0.0.3-py2.py3-none-any.whl'\nfrom efficientnet import EfficientNetB3\n\nmodel = keras.models.load_model(model_path)\n\noptimizer=Adam(lr = 5e-5)\nloss = \"binary_crossentropy\"\nmodel.compile(loss = loss, optimizer = optimizer, metrics = [\"accuracy\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_image(path):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, size)\n    return image","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Below code converts the labels into multilabel, this code is taken from the kernel [APTOS 2019: DenseNet Keras Starter](https://www.kaggle.com/xhlulu/aptos-2019-densenet-keras-starter)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(train_csv)\n\ntrain_paths = [train_dir + str(x) + str(\".png\") for x in df[\"id_code\"]]\n\nlabels = pd.get_dummies(df[\"diagnosis\"]).values\ny_train_multi = np.empty(labels.shape, dtype=labels.dtype)\ny_train_multi[:, 4] = labels[:, 4]\nfor i in range(3, -1, -1):\n    y_train_multi[:, i] = np.logical_or(labels[:, i], y_train_multi[:, i+1])\ntrain_labels = y_train_multi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading images\nimages = np.empty((len(df),300,300,3), dtype = np.uint8)\nfor i, im in tqdm_notebook(enumerate(train_paths)):\n    images[i,:,:,:] = get_image(im)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"images, x_val, train_labels, y_val = train_test_split(images, train_labels, test_size = 0.15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### TRAINING : "},{"metadata":{"trusted":true},"cell_type":"code","source":"train_aug = ImageDataGenerator(\n        zoom_range=0.25,\n        rotation_range = 360,\n        vertical_flip=True,\n        horizontal_flip=True)\n\ntrain_generator = train_aug.flow(images, train_labels, batch_size = 8)\n\nmodel.fit_generator(train_generator, epochs = 6, steps_per_epoch = len(train_generator), validation_data = (x_val, y_val))\n\n#training process is same for the old data as well.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_generator, images, x_val\ngc.collect","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"PREDICTIONS AND TTA :"},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_predictions(test, model):\n    predictions = model.predict(test) > 0.5\n    predictions = predictions.astype(int).sum(axis=1) - 1\n    return predictions\n\ndef rotate_image(image, degree):\n    height, width = image.shape[:2]\n    rotation_matrix = cv2.getRotationMatrix2D((width/2,height/2), degree, 1)\n    image_transformed = cv2.warpAffine(image, rotation_matrix, (width, height))\n    return image_transformed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading test images\n\ntest_df = pd.read_csv(test_csv)\ntest_paths = [test_dir + str(x) + str(\".png\") for x in test_df[\"id_code\"]]\n\nimages = np.empty((len(test_df),300,300,3), dtype = np.uint8)\nfor i, im in tqdm_notebook(enumerate(test_paths)):\n    images[i,:,:,:] = get_image(im)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### TTA"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions1 = get_predictions(images, model)\n\n# rotate image and then make predictions\ntemp_images = np.empty((len(images), 300,300,3), dtype = np.uint8)\nfor i in range(len(images)):\n    temp_images[i,:,:,:] = rotate_image(images[i], random.randint(1,6))\npredictions2 = get_predictions(temp_images, model)\n\n# rotate image and make predictions\ntemp_images = np.empty((len(images), 300,300,3), dtype = np.uint8)\nfor i in range(len(images)):\n    temp_images[i,:,:,:] = rotate_image(images[i], random.randint(7,12))\n\npredictions3 = get_predictions(temp_images, model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# stack all predictions for images and then find the mode of prediction.\nfinal_predictions = []\nfor i in range(len(predictions1)):\n    temp = [predictions1[i], predictions2[i], predictions3[i]]\n    curr_mode = None\n    if len(set(temp)) == 3:\n        curr_mode = temp[0]\n    else:\n        curr_mode = mode(temp)\n    final_predictions.append(curr_mode)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_code = test_df[\"id_code\"].values.tolist()\nsubfile = pd.DataFrame({\"id_code\":id_code, \"diagnosis\":final_predictions})\nsubfile.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}