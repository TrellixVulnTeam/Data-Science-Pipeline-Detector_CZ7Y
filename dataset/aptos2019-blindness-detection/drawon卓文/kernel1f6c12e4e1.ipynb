{"cells":[{"metadata":{},"cell_type":"markdown","source":"**Install package**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom keras import layers,models\nfrom keras.preprocessing.image import img_to_array\nimport warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\nimport os,shutil\nfrom sklearn.model_selection import train_test_split\nfrom keras.applications import VGG16\nfrom keras.preprocessing.image import image\nfrom keras import layers,models,optimizers\nimport math","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dataset dir "},{"metadata":{"trusted":true},"cell_type":"code","source":"#base_dir=\"../input\"/\ntrain_images_dir=\"../input/train_images\"\ntest_images_dir=\"../input/test_images\"\ntrain_df=pd.read_csv(\"../input/train.csv\")\ntest_df=pd.read_csv(\"../input/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.diagnosis.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_base=VGG16(weights='imagenet',\n               include_top=False,\n               input_shape=(728,728,3))\nconv_base.trainable=False\n\nmodel=models.Sequential()\nmodel.add(conv_base)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256,activation='relu',input_dim=22*22*512))\nmodel.add(layers.Dropout(0.4))\nmodel.add(layers.Dense(5,activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size=32\nseed=666\n\ntrain_df.id_code=train_df.id_code.apply(lambda x :x+'.png')\ntest_df.id_code=test_df.id_code.apply(lambda x :x+'.png')\ntrain_df['diagnosis']=train_df['diagnosis'].astype(str)\nx_train,x_val=train_test_split(train_df,test_size=0.2,random_state=seed)\ntrain_datagen=image.ImageDataGenerator(rescale=1./255,\n                                       horizontal_flip=True,rotation_range=40,\n                                       width_shift_range=0.2,shear_range=0.2,\n                                      zoom_range=0.2,fill_mode='nearest')\n\nval_datagen=image.ImageDataGenerator(rescale=1./255)\n    \ntest_datagen=image.ImageDataGenerator(rescale=1./255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow_from_dataframe(\n    dataframe=x_train, \n    directory=train_images_dir,\n    x_col='id_code',\n    y_col='diagnosis',\n    target_size=(728,728),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batch_size,\n    seed=seed)\nvalidation_generator = val_datagen.flow_from_dataframe(\n    dataframe=x_val, \n    directory=train_images_dir,\n    x_col='id_code',\n    y_col='diagnosis',\n    target_size=(728,728),\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batch_size,\n    shuffle=False,\n    seed=seed)\ntest_generator=test_datagen.flow_from_dataframe(\n    dataframe=test_df,\n    directory=test_images_dir,\n    x_col='id_code',\n    y_col=None,\n    target_size=(728,728),\n    color_mode='rgb',\n    class_mode=None,\n    batch_size=batch_size,\n    shuffle=False,\n    seed=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer=optimizers.RMSprop(lr=2e-4),\n             loss='categorical_crossentropy',\n             metrics=['acc'])\nhistory=model.fit_generator(train_generator,  \n                steps_per_epoch=math.ceil(len(x_train)/batch_size),\n                 epochs=20,\n                 validation_data=validation_generator,\n                 validation_steps=32\n                         )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(1,len(acc)+1)\n\nplt.plot(epochs,acc,'bo',label='training acc')\nplt.plot(epochs,val_acc,'r',label='val acc')\nplt.title('training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs,loss,'bo',label='training loss')\nplt.plot(epochs,val_loss,'r',label='val loss')\nplt.title('training and validation loss')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"step=math.ceil(len(test_df)/batch_size)\ntest_generator.reset()\ntest_pre=model.predict_generator(test_generator,steps=step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predicted_class_indices = np.argmax(test_pre_array, axis=1)\n# labels = (train_generator.class_indices)\n# label = dict((v,k) for k,v in labels.items())\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"because of my this part no work,i found [this kernel](http://www.kaggle.com/bharatsingh213/keras-resnet-test-time-augmentation) to test my predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\ntta_steps = 10\nstep=math.ceil(len(test_df)/batch_size)\npreds_tta=[]\nfor i in tqdm(range(tta_steps)):\n    test_generator.reset()\n    preds = model.predict_generator(generator=test_generator,steps =step)\n#     print('Before ', preds.shape)\n    preds_tta.append(preds)\n#     print(i,  len(preds_tta))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_tta","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_pred = np.mean(preds_tta, axis=0)\npredicted_class_indices = np.argmax(final_pred, axis=1)\nlen(predicted_class_indices)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['diagnosis']=predicted_class_indices.astype(int)\ntest_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.diagnosis.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"when i saw [this kernel](http://www.kaggle.com/c/aptos2019-blindness-detection/discussion/101366#584009),i decided to use MixUp loss training my model.i wonder if its magical."},{"metadata":{"trusted":true},"cell_type":"code","source":"# import torch.nn as nn\n# class MixUpSoftmaxLoss(nn.Module):\n\n#     def __init__(self, crit, reduction='mean'):\n#         super().__init__()\n#         self.crit = crit\n#         setattr(self.crit, 'reduction', 'none')\n#         self.reduction = reduction\n\n#     def forward(self, output, target):\n#         if len(target.size()) == 2:\n#             loss1 = self.crit(output, target[:, 0].long())\n#             loss2 = self.crit(output, target[:, 1].long())\n#             lambda_ = target[:, 2]\n#             d = (loss1 * lambda_ + loss2 * (1-lambda_)).mean()\n#         else:\n#             # This handles the cases without MixUp for backward compatibility\n#             d = self.crit(output, target)\n#         if self.reduction == 'mean':\n#             return d.mean()\n#         elif self.reduction == 'sum':\n#             return d.sum()\n#         return d`","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}