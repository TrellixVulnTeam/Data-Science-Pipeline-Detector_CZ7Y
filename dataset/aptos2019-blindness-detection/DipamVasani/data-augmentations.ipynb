{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Data augmentations\n\nSince the images are of different sizes, we need to resize and augment them well. In this notebook we look at the various augmentations available and decide the best values for our dataset"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from fastai import *\nfrom fastai.vision import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(max_rotate=25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_ex(): return open_image('../input/b-images/b_image.png')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# default transforms\ndef plots_f(rows, cols, width, height, **kwargs):\n    [get_ex().apply_tfms(tfms[0], **kwargs).show(ax=ax) for i,ax in enumerate(plt.subplots(\n        rows,cols,figsize=(width,height))[1].flatten())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_f(2, 4, 12, 6, size=224)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random zoom and crop\ntfms = zoom_crop(scale=(0.75,2), do_rand=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plots_f(2, 4, 12, 6, size=224)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# random resize and crop\ntfms = [rand_resize_crop(224)]\nplots_f(2, 4, 12, 6, size=224)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rotation using probability\ntfm = [rotate(degrees=30, p=0.5)]\nfig, axs = plt.subplots(1,5,figsize=(12,4))\nfor ax in axs:\n    img = get_ex().apply_tfms(tfm)\n    title = 'Done' if tfm[0].do_run else 'Not done'\n    img.show(ax=ax, title=title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rotation using degree range\ntfm = [rotate(degrees=(0,180))]\nfig, axs = plt.subplots(1,5,figsize=(12,4))\nfor ax in axs:\n    img = get_ex().apply_tfms(tfm)\n    title = f\"deg={tfm[0].resolved['degrees']:.1f}\"\n    img.show(ax=ax, title=title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# brightness\nfig, axs = plt.subplots(1,5,figsize=(14,8))\nfor change, ax in zip(np.linspace(0.1,0.9,5), axs):\n    brightness(get_ex(), change).show(ax=ax, title=f'change={change:.1f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# contrast\nfig, axs = plt.subplots(1,5,figsize=(12,4))\nfor scale, ax in zip(np.exp(np.linspace(log(0.5),log(2),5)), axs):\n    contrast(get_ex(), scale).show(ax=ax, title=f'scale={scale:.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# flips\nfig, axs = plt.subplots(1,2,figsize=(10,8))\nget_ex().show(ax=axs[0], title=f'no flip')\nflip_lr(get_ex()).show(ax=axs[1], title=f'flip')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# squinch, this will be used for resizing so that we don't\n# lose the original image\nfig, axs = plt.subplots(1,5,figsize=(12,4))\nfor scale, ax in zip(np.linspace(0.66,1.33,5), axs):\n    get_ex().squish(scale=scale).show(ax=ax, title=f'scale={scale:.2f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/aptos2019-blindness-detection/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path.ls()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(path/'train.csv')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ??get_transforms","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"src = (\n    ImageList.from_df(df,path,folder='train_images',suffix='.png')\n        .split_by_rand_pct(0.1, seed=42)\n        .label_from_df()\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfms = get_transforms(max_warp=0, max_zoom=1.1, max_lighting=0.1, p_lighting=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (\n    src.transform(tfms,size=128, resize_method=ResizeMethod.SQUISH,padding_mode='zeros')\n    .databunch()\n    .normalize(imagenet_stats)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.show_batch(rows=3, figsize=(5,7))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}