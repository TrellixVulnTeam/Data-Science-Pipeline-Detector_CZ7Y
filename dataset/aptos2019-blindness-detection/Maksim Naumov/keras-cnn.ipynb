{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Resources\n* [Preprocessing & Cropping](https://www.kaggle.com/ratthachat/aptos-updated-preprocessing-ben-s-cropping) "},{"metadata":{},"cell_type":"markdown","source":"# Constants"},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 300","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# Importing libraries"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport cv2\nimport os\n\nprint('Tensorflow version:', tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/aptos2019-blindness-detection/train.csv\")\ntest = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\n#train_x = np.array([cv2.resize(np.array(cv2.imread(\"../input/aptos2019-blindness-detection/train_images/\"+i+\".png\")),(IMG_SIZE,IMG_SIZE)) for i in train.id_code])\n#train_y = np.array(train.diagnosis)\n#test_x = np.array([cv2.resize(np.array(cv2.imread(\"../input/aptos2019-blindness-detection/test_images/\"+i+\".png\")),(IMG_SIZE,IMG_SIZE)) for i in test.id_code])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"Images before preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nn = 10\ncols = 5\nrows = np.ceil(n/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(test_x[i])\n  #plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Auto-cropping"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndef crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\"\"\"\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Ben Graham's preprocessing method"},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_ben_color(data, img_size, sigmaX=10):\n    if data.ndim == 4:  # array of images\n        for i in range(len(data)):\n            image = cv2.cvtColor(data[i], cv2.COLOR_BGR2RGB)\n            image = crop_image_from_gray(image)\n            image = cv2.resize(image, (img_size, img_size))\n            data[i] = cv2.addWeighted(image, 4, cv2.GaussianBlur(image, (0,0), sigmaX), -4 ,128)\n    elif data.ndim == 3:  # just a single image\n        data = cv2.cvtColor(data, cv2.COLOR_BGR2RGB)\n        data = crop_image_from_gray(data)\n        data = cv2.resize(data, (img_size, img_size))\n        data = cv2.addWeighted(data, 4, cv2.GaussianBlur(data, (0,0), sigmaX), -4 , 128)\n    else: \n        return 0\n    \n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def image_preprocessing(data, img_size, sigmaX=10):\n    # cropping & Ben Graham's preprocessing method\n    data = load_ben_color(data, img_size, sigmaX)\n    \n    # normalization (rescaling between 0 and 1)\n    data = data.astype('float32')\n    for i in range(len(data)):\n        cv2.normalize(data[i],  data[i], 0, 1, cv2.NORM_MINMAX)\n        \n    return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"normalization\nhttps://docs.opencv.org/2.4/modules/core/doc/operations_on_arrays.html#cv2.normalize\nhttps://stackoverflow.com/questions/40645985/opencv-python-normalize-image/42164670"},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_x = image_preprocessing(train_x, IMG_SIZE, sigmaX=10)\n#test_x = image_preprocessing(test_x, IMG_SIZE, sigmaX=10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Images after preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nn = 10\ncols = 5\nrows = np.ceil(n/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(test_x[i])\n  #plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Pickle\nyou don't want to rebuild your dataset everytime!"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\"\"\"\n# pickle out\npickle_out_train_x = open('train_x_aptos2019.pickle', 'wb')\npickle.dump(train_x, pickle_out_train_x)\npickle_out_train_x.close()\n\npickle_out_train_y = open('train_y_aptos2019-blindness-detection.pickle', 'wb')\npickle.dump(train_y, pickle_out_train_y)\npickle_out_train_y.close()\n\npickle_out_test_x = open('test_x_aptos2019-blindness-detection.pickle', 'wb')\npickle.dump(test_x, pickle_out_test_x)\npickle_out_test_x.close()\n\"\"\"\n\n#\"\"\"\n# pickle in\npickle_in_train_x = open('../input/preprocessed-data-aptos2019blindnessdetection/train_x_aptos2019.pickle', 'rb')\npickle_in_train_y = open('../input/preprocessed-data-aptos2019blindnessdetection/train_y_aptos2019.pickle', 'rb')\npickle_in_test_x = open('../input/preprocessed-data-aptos2019blindnessdetection/test_x_aptos2019.pickle', 'rb')\n\ntrain_x = pickle.load(pickle_in_train_x)\ntrain_y = pickle.load(pickle_in_train_y)\ntest_x = pickle.load(pickle_in_test_x)\n\nprint(train_x.shape, train_y.shape, test_x.shape)\n#\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 5\ncols = 5\nrows = np.ceil(n/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(train_x[i])\n  plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 5\ncols = 5\nrows = np.ceil(n/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n  plt.subplot(rows, cols, i+1)\n  plt.imshow(test_x[i])\n  #plt.title(train['diagnosis'][i], fontsize=40)\n  plt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model_1"},{"metadata":{"trusted":true},"cell_type":"code","source":"#\"\"\"\ndef create_model_1():\n    layers_1 = [\n        tf.keras.layers.Conv2D(filters=16, kernel_size=(3,3), padding='same', activation=tf.nn.relu, input_shape=train_x.shape[1:]),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=32, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=64, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=128, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Conv2D(filters=256, kernel_size=(3,3), padding='same', activation=tf.nn.relu),\n        tf.keras.layers.MaxPool2D(pool_size=(2,2), strides=(2,2)),\n        tf.keras.layers.Flatten(),  \n        tf.keras.layers.Dense(units=512, activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=256, activation=tf.nn.relu),\n        tf.keras.layers.Dense(units=len(np.unique(train_y)), activation=tf.nn.softmax),\n    ] \n\n    model_1 = tf.keras.Sequential(layers_1)\n    model_1.compile(optimizer=tf.keras.optimizers.Adam(), #tf.optimizers.Adam(),\n                 loss=tf.keras.losses.sparse_categorical_crossentropy, #tf.losses.SparseCategoricalCrossentropy(),\n                 metrics=['accuracy'])\n    \n    return model_1\n#\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\"\"\"\nmodel_1 = create_model_1()\nmodel_1.summary()\n#\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Train the model"},{"metadata":{},"cell_type":"markdown","source":"Simple_1 with no augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"#\"\"\"\n# https://www.youtube.com/watch?v=HxtBIwfy0kM\ncheckpoint_path = 'cp_model_1_aptos2019-blindness-detection.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\n# Create checkpoint callback\ncp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                 save_weights_only=True,\n                                                 verbose=1)\n\nmodel_1 = create_model_1()\n\nmodel_1.fit(train_x, train_y, epochs=5, batch_size=32, \n            callbacks=[cp_callback])  # pass calback to training\n#\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#\"\"\"\ntrain_predicted = model_1.predict(train_x)\ntrain_predicted = [np.argmax(i) for i in train_predicted]\n\nfrom sklearn.metrics import cohen_kappa_score\ncohen_kappa_score(train_predicted, train_y, weights='quadratic')\n#\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model_1 with augmentation"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" Memory error here\n# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=30,\n    brightness_range=[0.5, 1.5],\n    zoom_range=[0.8, 1.2],\n    horizontal_flip=True,\n    vertical_flip=False)\n\ndatagen.fit(train_x)\n\ncheckpoint_path = 'cp_model_1_aptos2019-blindness-detection.ckpt'\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n# Create checkpoint callback\ncp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n                                                save_weights_only=True,\n                                                verbose=1)\n\nmodel_1 = create_model_1()\n\n# fits the model on batches with real-time data augmentation:\nmodel_1.fit_generator(datagen.flow(train_x, train_y, batch_size=32),\n                      steps_per_epoch=len(train_x) / 32, epochs=5,\n                      callbacks=[cp_callback])\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import model"},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_1 = create_model_1()\n\n#loss, acc = model_1.evaluate(x, y)\n#print(\"Untrained model, accuracy: {:5.2f}%\".format(100*acc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#model_1.load_weights('../input/blindness-1/cp_model_1_aptos2019-blindness-detection.ckpt')\n#loss, acc = model_1.evaluate(x, y)\n#print(\"Restored model, accuracy: {:5.2f}%\".format(100*acc))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"#\"\"\"\ntest_predicted = model_1.predict(test_x)\ntest_predicted = [np.argmax(i) for i in test_predicted]\ntest_result = pd.DataFrame({\"id_code\": test[\"id_code\"].values, \"diagnosis\": test_predicted})\ntest_result.head()\n#\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_result.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 5\ncols = 5\nrows = np.ceil(n/cols)\nfig = plt.gcf()\nfig.set_size_inches(cols * n, rows * n)\nfor i in range(n):\n    plt.subplot(rows, cols, i+1)\n    plt.imshow(test_x[i])\n    plt.title(test_predicted[i], fontsize=40)\n    plt.axis('off') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# How to count the occurrence of certain item in an ndarray (from numpy) in Python? \n# https://stackoverflow.com/questions/28663856/how-to-count-the-occurrence-of-certain-item-in-an-ndarray-in-python\nunique, counts = np.unique(test_predicted, return_counts=True)\nmydict = dict(zip(unique, counts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(unique, counts)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}