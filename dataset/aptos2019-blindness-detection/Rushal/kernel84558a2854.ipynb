{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2 as cv\nimport os\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn.functional as F\nimport torch.utils.data.dataloader as DataLoader\nimport torch.utils.data.sampler as sampler\nimport torchvision.transforms as transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom PIL import Image\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Target Column label\n#0 - No DR(Diabetic Retinopathy)\n#1 - Mild\n#2 - Moderate\n#3 - Severe\n#4 - Proliferative DR(Diabetic Retinopathy)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntest_df = pd.read_csv(\"../input/test.csv\")\ntarget_dict = {0:\"No DR(Diabetic Retinopathy)\",\n               1:\"Mild\",\n               2:\"Moderate\",\n               3:\"Severe\",\n               4:\"Proliferative DR(Diabetic Retinopathy)\" }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MyDataset(torch.utils.data.Dataset):\n    def __init__(self,dir_img_path=None,dir_csv_path=None,Usage=None,transform=None):\n        super().__init__()\n        \"\"\"\n        Usage:\n        \"\"\"\n        self.DIR_PATH = \"../input\"\n        self.df = pd.read_csv(dir_csv_path)\n        self.dir_img_path = dir_img_path\n        self.images = self.loadImage(self.dir_img_path)\n        self.Usage = Usage\n        self.transform = transform\n        print(\"{} Data length of image {}:\".format(Usage,len(self.images)))\n        print(\"{} Data length of csv file {}:\".format(Usage,len(self.df)))\n        \n    def loadImage(self,path):\n        return os.listdir(path) \n    \n    def __getitem__(self,pos):\n        obj = self.df.loc[pos]\n        img_id = obj[\"id_code\"]\n        if self.Usage ==\"Training\":\n            label = obj[\"diagnosis\"]\n            \n        img_id =\"{}.png\".format(img_id)\n         \n        img = cv.imread(os.path.join(self.dir_img_path,img_id))\n        #img = np.moveaxis(img, -1, 0) # for shifting column in Tensor\n        #print(img.shape)\n        img = Image.fromarray(img)\n        \n        #sample = {'image': img, 'label': label}\n        if self.transform:\n            img = self.transform(img)\n        #print(img.shape)\n        if self.Usage == \"Training\":\n            return img,label\n        return img,obj[\"id_code\"]\n    def change_type(self,img,label):\n        return img.astype(np.float32),label.astype(np.long)\n    \n    def read(self,image):\n        return cv.imread(image)\n    \n    def reshape(self,image):\n        return cv.resize(image,(244,244))\n    \n    def __len__(self):\n        return len(self.df)\n       \ntransformation  = transforms.Compose([transforms.Resize((224,224)),\n                                     #transforms.Grayscale(num_output_channels=1),\n                                     transforms.ColorJitter(0.1),\n                                     transforms.RandomHorizontalFlip(),\n                                     transforms.RandomVerticalFlip(),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize([0.5,0.5,0.5], [0.5,0.5,0.5])])\n\nmyDataset = MyDataset(\"../input/train_images\",\"../input/train.csv\",transform=transformation,Usage=\"Training\")\n#trainingLoader = torch.utils.data.DataLoader(myDataset,batch_size=32,shuffle=True)\n#myDataset[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size= 0.2\nsamples = len(myDataset)\nindices = list(range(samples))\nnp.random.shuffle(indices)\ntrain_len  =  int(np.floor(samples * (test_size)))\ntrain_idx, valid_idx = indices[train_len:], indices[:train_len]\ntrain_sampler = sampler.SubsetRandomSampler(train_idx)\nvalid_sampler = sampler.SubsetRandomSampler(valid_idx)\nprint(len(train_sampler),len(valid_sampler))\n\ntrain_loader = torch.utils.data.DataLoader(myDataset,sampler= train_sampler\n                                           ,batch_size = 32,shuffle=False)\ntest_loader = torch.utils.data.DataLoader(myDataset, sampler= valid_sampler,\n                                          batch_size = 32,shuffle=False)\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device(\"cuda\" if use_cuda else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net,self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=3,out_channels=32,kernel_size=7,padding=3)\n        self.conv1_1 = nn.Conv2d(in_channels=32,out_channels=32,kernel_size=7,padding=3)\n        \n        self.conv2 = nn.Conv2d(in_channels=32,out_channels=64,kernel_size=7,padding=3)\n        self.conv2_1 = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=7,padding=3)\n        \n        self.conv3 = nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,padding=2)\n        self.conv3_1 = nn.Conv2d(in_channels=128,out_channels=128,kernel_size=5,padding=2)\n        \n        self.conv4 = nn.Conv2d(in_channels=128,out_channels=256,kernel_size=5,padding=2)\n        self.conv4_1 = nn.Conv2d(in_channels=256,out_channels=256,kernel_size=5,padding=2)\n        \n        self.conv5 = nn.Conv2d(in_channels=256,out_channels=512,kernel_size=5,padding=2)\n        self.conv5_1 = nn.Conv2d(in_channels=512,out_channels=512,kernel_size=5,padding=2)\n        \n        self.fc1 = nn.Linear(in_features=512*7*7,out_features=1024)\n        self.fc2 = nn.Linear(in_features=1024,out_features=1024)\n        self.fc3 = nn.Linear(in_features=1024,out_features=512)\n        self.out = nn.Linear(in_features=1024,out_features=5)\n        \n        self.dropout = nn.Dropout(0.5)\n        \n    def forward(self,x):\n        x = F.relu(self.conv1(x))\n        x = F.relu(self.conv1_1(x))\n        x = F.max_pool2d(x,kernel_size=2,stride=2)\n        #print(x.shape)\n        x = self.dropout(x)\n        \n        x = F.relu(self.conv2(x))\n        x = F.relu(self.conv2_1(x))\n        x = F.max_pool2d(x,kernel_size=2,stride=2)\n        #print(x.shape)\n        x = self.dropout(x)\n        \n        x = F.relu(self.conv3(x))\n        x = F.relu(self.conv3_1(x))\n        x = F.max_pool2d(x,kernel_size=2,stride=2)\n        #print(x.shape)\n        x = self.dropout(x)\n        \n        x = F.relu(self.conv4(x))\n        x = F.relu(self.conv4_1(x))\n        x = F.max_pool2d(x,kernel_size=2,stride=2)\n        #print(x.shape)\n        x = self.dropout(x)\n        \n        x = F.relu(self.conv5(x))\n        x = F.relu(self.conv5_1(x))\n        x = F.max_pool2d(x,kernel_size=2,stride=2)\n        x = self.dropout(x)\n        #print(x.shape)\n        x = x.reshape(-1,512*7*7)\n        #print(x.shape)\n        x = F.relu(self.fc1(x))\n        \n        x = self.dropout(x)\n        #x = F.relu(self.fc2(x))\n        #x = F.relu(self.fc3(x))\n        #print(x.shape)\n        x = F.log_softmax(self.out(x),dim=1)\n        #print(x.shape)\n        return x\nnet = Net().to(device)\n#net.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"criterion = torch.nn.NLLLoss()\noptimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\nlr_step = torch.optim.lr_scheduler.StepLR(optimizer,step_size=2,gamma=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(20):\n    running_loss = 0.0 \n    valid_loss = []\n    valid_auc = []\n    train_loss = []\n    train_auc = []\n    #lr_step.step()\n    net.train()\n    for i,(image,label) in enumerate(train_loader): \n            image,label = image.to(device),label.to(device)\n            optimizer.zero_grad()\n            output = net(image)\n            loss = criterion(output,label)\n            _,output = torch.max(output,1)             \n            loss.backward()\n            optimizer.step()\n            running_loss +=loss.item() \n            train_loss.append(loss.item())\n            train_auc.append(accuracy_score(torch.Tensor.cpu(output),torch.Tensor.cpu(label)))\n            if i % 10 == 9: # print every 10 mini-batches\n                print('[%d, %5d] loss: %.5f Accuracy:%.5f' %(epoch + 1, i + 1,running_loss / 100,\naccuracy_score(torch.Tensor.cpu(output),torch.Tensor.cpu(label))))\n                running_loss = 0.0\n    net.eval()  \n    for i,(image,label) in enumerate(test_loader):\n        image,label = image.to(device),label.to(device)\n        output = net(image)\n        loss = criterion(output,label)\n        _,output = torch.max(output,1)   \n        valid_loss.append(loss.item())\n        valid_auc.append(accuracy_score(output.cpu().detach().numpy(),label.cpu().detach().numpy()))\n    print('Epoch {}, train loss: {}, train accuracy: {}\\tvalid loss: {}, valid accuracy: {}'.format(epoch+1,np.mean(train_loss),np.mean(train_auc),np.mean(valid_loss),np.mean(valid_auc)))\n    #break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"The state dict keys: \\n\\n\", net.state_dict().keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = {'model': Net(),\n              'state_dict': net.state_dict(),\n              'optimizer' : optimizer.state_dict()}\ntorch.save(checkpoint, 'checkpoint.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_model(filepath):\n    checkpoint = torch.load(filepath)\n    model = checkpoint['model']\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    for parameter in model.parameters():\n        parameter.require_grad = False\n    model.eval()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = load_model(\"checkpoint.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData = MyDataset(\"../input/test_images\",\"../input/test.csv\",transform=transformation,Usage=\"Testing\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_dict = {}\nlabel_dict['id_code'] = list()\nlabel_dict[\"diagnosis\"] = list()\nfor image,tag in testData:\n    image = image.unsqueeze(0)\n    output = model(image)\n    _,output = torch.max(output,1)\n    label_dict[\"id_code\"].append(tag)\n    label_dict[\"diagnosis\"].append(int(output))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame(label_dict)\ndf.to_csv(\"submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}