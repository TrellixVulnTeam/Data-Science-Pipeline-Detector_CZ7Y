{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport cv2\nimport random\nimport warnings\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, cohen_kappa_score\nfrom keras.models import Model\nfrom keras import optimizers, applications\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom keras.layers import Dense, Dropout, GlobalAveragePooling2D, Input\nimport tensorflow as tf\n\nfrom keras.applications import inception_v3\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.inception_v3 import preprocess_input as inception_v3_preprocessor\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    #set_random_seed(0)\nseed_everything()\n\n%matplotlib inline\nsns.set(style=\"whitegrid\")\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" #This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# # You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation,Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import regularizers, optimizers\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input')\n!ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.getcwd()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('blindness/extra_info.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diagnosis'] = df['diagnosis'].astype('str')\ndf.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.sample(frac=1).reset_index(drop=True)\ndf.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_col=\"id_code\"\ny_col=\"diagnosis\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_col=\"id_code\"\ny_col=\"diagnosis\"\n\ndatagen=ImageDataGenerator(rescale=1./255,validation_split=0.15)\ntrain_generator=datagen.flow_from_dataframe(dataframe=df,directory=\"/kaggle/input/blindness/dataset/\",x_col=x_col,y_col=y_col,\n                                subset=\"training\",batch_size=16,seed=42,shuffle=True,class_mode=\"categorical\",target_size=(300,300))\nvalid_generator=datagen.flow_from_dataframe(dataframe=df,directory=\"/kaggle/input/blindness/dataset/\",x_col=x_col,y_col=y_col,\n                                subset=\"validation\",batch_size=16,seed=42,shuffle=True,class_mode=\"categorical\",target_size=(300,300))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdf=pd.read_csv('../input/aptos2019-blindness-detection/test.csv',dtype=str)\ntestdf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def append_ext(fn):\n    return fn+\".png\"\ntestdf[\"id_code\"]=testdf[\"id_code\"].apply(append_ext)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testdf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/input/aptos2019-blindness-detection/test_images/')\ntest_datagen=ImageDataGenerator(rescale=1./255.)\ntest_generator=test_datagen.flow_from_dataframe(\ndataframe=testdf,\ndirectory=\"/kaggle/input/aptos2019-blindness-detection/test_images/\",\nx_col=\"id_code\",\ny_col=None,\nbatch_size=32,\nseed=42,\nshuffle=False,\nclass_mode=None,\ntarget_size=(300, 300))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nfrom keras import layers\nfrom keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\nfrom keras.models import Model, load_model\nfrom keras.preprocessing import image\nfrom keras.utils import layer_utils\nfrom keras.utils.data_utils import get_file\nfrom keras.applications.imagenet_utils import preprocess_input\nimport pydot\nfrom IPython.display import SVG\nfrom keras.utils.vis_utils import model_to_dot\nfrom keras.utils import plot_model\nimport keras\nfrom keras.initializers import glorot_uniform\nimport scipy.misc\nfrom matplotlib.pyplot import imshow\n%matplotlib inline\nimport tensorflow as tf\nimport keras.backend as K\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def kappa_loss(y_pred, y_true, y_pow=2, eps=1e-10, N=5, bsize=16, name='kappa'):\n    \"\"\"A continuous differentiable approximation of discrete kappa loss.\n        Args:\n            y_pred: 2D tensor or array, [batch_size, num_classes]\n            y_true: 2D tensor or array,[batch_size, num_classes]\n            y_pow: int,  e.g. y_pow=2\n            N: typically num_classes of the model\n            bsize: batch_size of the training or validation ops\n            eps: a float, prevents divide by zero\n            name: Optional scope/name for op_scope.\n        Returns:\n            A tensor with the kappa loss.\"\"\"\n\n \n\n    with tf.name_scope(name):\n        y_true = tf.cast(y_true,dtype=tf.float32)\n        repeat_op = tf.cast(tf.tile(tf.reshape(tf.range(0, N), [N, 1]), [1, N]),dtype=tf.float32)\n        repeat_op_sq = tf.square((repeat_op - tf.transpose(repeat_op)))\n        weights = repeat_op_sq / tf.cast((N - 1) ** 2,dtype=tf.float32)\n    \n        pred_ = y_pred ** y_pow\n        try:\n            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [-1, 1]))\n        except Exception:\n            pred_norm = pred_ / (eps + tf.reshape(tf.reduce_sum(pred_, 1), [bsize, 1]))\n    \n        hist_rater_a = tf.reduce_sum(pred_norm, 0)\n        hist_rater_b = tf.reduce_sum(y_true, 0)\n    \n        conf_mat = tf.matmul(tf.transpose(pred_norm), y_true)\n    \n        nom = tf.reduce_sum(weights * conf_mat)\n        denom = tf.reduce_sum(weights * tf.matmul(\n            tf.reshape(hist_rater_a, [N, 1]), tf.reshape(hist_rater_b, [1, N])) /\n                              tf.cast(bsize,dtype=tf.float32))\n    \n        return nom / (denom + eps)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# example of tending the vgg16 model\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\n# load model without classifier layers\nbase_model = InceptionV3(weights = 'imagenet', include_top = False, input_shape=(300, 300, 3))\n\nbase_model.trainable = False\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import model_from_json","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"os.chdir('/kaggle/working')\nmodel_json = base_model.to_json()\nwith open(\"model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nbase_model.save_weights(\"model.h5\")\nprint(\"Saved model to disk\")\n \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nos.chdir('/kaggle/working')\njson_file = open('/kaggle/working/model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\nloaded_model.load_weights(\"model.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# add new classifier layers\nflat1 =  GlobalAveragePooling2D()(loaded_model.output)\n\nclass2=Dense(64, activation='relu')(flat1)\noutput = Dense(5, activation='softmax')(class2)\n# define new model\nmodel = Model(inputs=loaded_model.inputs, outputs=output)\n# summarize\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# instantiating the model in the strategy scope creates the model on the TPU\n\nmodel.compile(optimizer=keras.optimizers.Adam(),\n                  loss=keras.losses.CategoricalCrossentropy(),\n                  metrics=[kappa_loss,keras.metrics.CategoricalAccuracy()])\nmodel.fit_generator(train_generator,steps_per_epoch=3000/20  ,epochs=15,\n                                  validation_data=valid_generator)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc \ngc.collect()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_generator.reset()\npred=loaded_model.predict_generator(test_generator)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_class_indices=np.argmax(pred,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"id_code\":filenames,\n                      \"diagnosis\":predictions})\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.chdir('/kaggle/working')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"import numpy as np\nfrom sklearn.metrics import cohen_kappa_score\n\nimport keras.backend as K\nimport tensorflow as tf\n\n\ndef kappa_keras(y_true, y_pred):\n\n    y_true = K.cast(K.argmax(y_true, axis=-1), dtype='int32')\n    y_pred = K.cast(K.argmax(y_pred, axis=-1), dtype='int32')\n\n    # Figure out normalized expected values\n    min_rating = K.minimum(K.min(y_true), K.min(y_pred))\n    max_rating = K.maximum(K.max(y_true), K.max(y_pred))\n\n    # shift the values so that the lowest value is 0\n    # (to support scales that include negative values)\n    y_true = K.map_fn(lambda y: y - min_rating, y_true, dtype='int32')\n    y_pred = K.map_fn(lambda y: y - min_rating, y_pred, dtype='int32')\n\n    # Build the observed/confusion matrix\n    num_ratings = max_rating - min_rating + 1\n    observed = tf.confusion_matrix(y_true, y_pred,\n                                num_classes=num_ratings)\n    num_scored_items = K.shape(y_true)[0]\n\n    weights = K.expand_dims(K.arange(num_ratings), axis=-1) - K.expand_dims(K.arange(num_ratings), axis=0)\n    weights = K.cast(K.pow(weights, 2), dtype='float64')\n\n    hist_true = tf.math.bincount(y_true, minlength=num_ratings)\n    hist_true = hist_true[:num_ratings] / num_scored_items\n    hist_pred = tf.math.bincount(y_pred, minlength=num_ratings)\n    hist_pred = hist_pred[:num_ratings] / num_scored_items\n    expected = K.dot(K.expand_dims(hist_true, axis=-1), K.expand_dims(hist_pred, axis=0))\n\n    # Normalize observed array\n    observed = observed / num_scored_items\n\n    # If all weights are zero, that means no disagreements matter.\n    score = tf.where(K.any(K.not_equal(weights, 0)), \n                     K.sum(weights * observed) / K.sum(weights * expected), \n                     0)\n    \n    return 1. - score\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"def quadratic_weighted_kappa(rater_a, rater_b, min_rating=None, max_rating=None):\n    \"\"\"\n    Calculates the quadratic weighted kappa\n    quadratic_weighted_kappa calculates the quadratic weighted kappa\n    value, which is a measure of inter-rater agreement between two raters\n    that provide discrete numeric ratings.  Potential values range from -1\n    (representing complete disagreement) to 1 (representing complete\n    agreement).  A kappa value of 0 is expected if all agreement is due to\n    chance.\n    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n    each correspond to a list of integer ratings.  These lists must have the\n    same length.\n    The ratings should be integers, and it is assumed that they contain\n    the complete range of possible ratings.\n    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n    is the minimum possible rating, and max_rating is the maximum possible\n    rating\n    \"\"\"\n    rater_a = np.array(rater_a, dtype=int)\n    rater_b = np.array(rater_b, dtype=int)\n    assert(len(rater_a) == len(rater_b))\n    if min_rating is None:\n        min_rating = min(min(rater_a), min(rater_b))\n    if max_rating is None:\n        max_rating = max(max(rater_a), max(rater_b))\n    conf_mat = confusion_matrix(rater_a, rater_b,\n                                min_rating, max_rating)\n    num_ratings = len(conf_mat)\n    num_scored_items = float(len(rater_a))\n\n    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n\n    numerator = 0.0\n    denominator = 0.0\n\n    for i in range(num_ratings):\n        for j in range(num_ratings):\n            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n                              / num_scored_items)\n            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n            numerator += d * conf_mat[i][j] / num_scored_items\n            denominator += d * expected_count / num_scored_items\n\n    return 1.0 - numerator / denominator\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"optR = OptimizedRounder()\noptR.fit(valid_predictions, targets)\ncoefficients = optR.coefficients()\nvalid_predictions = optR.predict(valid_predictions, coefficients)\ntest_predictions = optR.predict(test_predictions, coefficients)\n","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}