{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n!ls ../input\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import Subset\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.nn import CosineSimilarity\nfrom torchvision.transforms import ToTensor\nfrom torchvision import transforms\nimport torchvision.models as models\nfrom pathlib import Path\nimport PIL.Image\nimport random\nimport math\nfrom tqdm import tqdm_notebook as tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom torch.optim.lr_scheduler import ExponentialLR\nimport os\nimport glob\nimport cv2\nimport numpy as np\nimport PIL\nfrom sklearn.metrics import cohen_kappa_score","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Path('/tmp/.cache/torch/checkpoints/').mkdir(exist_ok=True, parents=True)\n!cp /kaggle/input/fastai-pretrained-models/* /tmp/.cache/torch/checkpoints/\n!cp /kaggle/input/pretrained-pytorch-models/* /tmp/.cache/torch/checkpoints/\n!cp /kaggle/input/resnet152/* /tmp/.cache/torch/checkpoints/\n!mv /tmp/.cache/torch/checkpoints/resnet152.pth /tmp/.cache/torch/checkpoints/resnet152-b121ed2d.pth\n!ls -lh /tmp/.cache/torch/checkpoints/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random.seed(42)\ntorch.manual_seed(42)\nnp.random.seed(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path = Path('../input/aptos2019-blindness-detection')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CircleCrop:\n    def __init__(self, radius):\n        self.radius = radius\n        circle_img = np.zeros((2 * radius, 2 * radius), np.uint8)\n        cv2.circle(circle_img, (radius, radius), int(radius), 1, thickness=-1)\n        self.mask = torch.tensor(circle_img, dtype=torch.float32)\n        \n    def __call__(self, img):\n#         assert(img.shape[1] == 2 * self.radius)\n#         assert(img.shape[2] == 2 * self.radius)\n        return torch.mul(img, self.mask)\n    \n    def __repr__(self):\n        return self.__class__.__name__ + '(radius={0})'.format(self.radius)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class APTOSDataset(Dataset):\n    def __init__(self, path, df, labels=None, augmentation=False, img_size=480):\n        self.len = len(df)\n        self.path = path\n        self.labels = labels\n        self.images = list(map(lambda f: path/(f + '.png'), df['id_code']))\n        self.trfms = transforms.Compose([\n            transforms.Resize(img_size),\n            transforms.CenterCrop(img_size),\n            transforms.RandomApply((\n                transforms.RandomHorizontalFlip(p=0.5),\n                transforms.RandomVerticalFlip(p=0.5),\n                transforms.ColorJitter(\n                    saturation=(1.0, 1.0),\n                    brightness=(1.0, 1.5), \n                    contrast=(1.5, 2.5),\n                ),\n                transforms.RandomAffine(degrees=180, scale=(1.0, 1.0)),\n                ), p = 1 if augmentation else 0  \n            ),\n            transforms.ToTensor(),\n#             transforms.Normalize(mean=[0.485, 0.456, 0.406],\n#                                  std=[0.229, 0.224, 0.225]),\n            CircleCrop(img_size // 2),\n            ])\n        \n    def __getitem__(self, index):\n        if self.labels is not None:\n            label = self.labels[index]\n        else:\n            label = 0\n        path = self.images[index]\n        img = PIL.Image.open(path)\n        return self.trfms(img), label\n    \n    def __len__(self):\n        return self.len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_df = pd.read_csv(path/'train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_ds = APTOSDataset(path/'train_images', tr_df, tr_df['diagnosis'].values, augmentation=True, img_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te_df = pd.read_csv(path/'test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te_ds = APTOSDataset(path/'test_images', te_df, te_df['id_code'], augmentation=True, img_size=256)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tr_ds), len(te_ds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = tr_ds[random.randint(0, len(tr_ds) - 1)]\nplt.imshow(transforms.ToPILImage()(img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img, label = te_ds[random.randint(0, len(te_ds) - 1)]\nplt.imshow(transforms.ToPILImage()(img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bs = 50\nnw = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_dl = DataLoader(tr_ds, batch_size=bs, num_workers=nw, drop_last=False, pin_memory=True, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"te_dl = DataLoader(te_ds, batch_size=bs, num_workers=nw, drop_last=False, pin_memory=True, shuffle=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Flatten(nn.Module):\n    def forward(self, x):\n        return x.view(x.size()[0], -1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Bias(nn.Module):\n    def __init__(self, num_out):\n        super(Bias, self).__init__()\n        self.bias = nn.Parameter(torch.zeros(num_out).float())\n        \n    def forward(self, x):\n        return x + self.bias","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_classes = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = models.densenet201(pretrained=True)\nfor param in model.parameters():\n    param.requires_grad = False\nmodel.classifier = nn.Sequential(\n    nn.BatchNorm1d(1920),\n    nn.Dropout(p=0.5, inplace=False),\n    nn.Linear(in_features=1920, out_features=512),\n    nn.ReLU(inplace=True),\n    nn.BatchNorm1d(512),\n    nn.Dropout(p=0.5, inplace=False),\n    nn.Linear(in_features=512, out_features=num_classes),\n    nn.Linear(in_features=num_classes, out_features=1, bias=False),\n    Bias(num_classes - 1)\n#     nn.Hardtanh(min_val=0.0, max_val=4.0)\n)\n# model.fc = nn.Linear(in_features=2048, out_features=num_classes)\n# model.classifier.requires_grad = True\nmodel = model.cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = torch.load('../input/aptos-pytorch/checkpoint.tar')\nmodel.load_state_dict(checkpoint['model'])\n# optimizer.load_state_dict(checkpoint['optimizer'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tta_count = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\ndiagnoses = defaultdict(list)\nwith torch.no_grad():\n    for i in tqdm(range(tta_count)):\n        id_code = []\n        diagnosis = []\n        for inputs, id_codes in tqdm(te_dl):\n            inputs = inputs.cuda()\n#             preds = model(inputs).argmax(1).tolist()\n            preds = model(inputs).tolist()\n            diagnosis.extend(preds)\n            id_code.extend(id_codes)\n        for id_c, diag in zip(id_code, diagnosis):\n            diagnoses[id_c].append(diag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def coral_out_to_class(out):\n    out = torch.sigmoid(torch.tensor(out))\n#     print(out)\n    out = out > 0.5\n    return torch.sum(out, dim=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_code = []\ndiagnosis = []\nfor k, v in diagnoses.items():\n#     print(k, np.array(v).mean(axis=0), np.array(v).argmax(axis=1), np.array(v))\n    id_code.append(k)\n#     print(k, v)\n#     print(np.bincount(coral_out_to_class(v).numpy()))\n#     print(np.argmax(np.bincount(coral_out_to_class(v).numpy())))\n#     break\n    # mean\n#     diagnosis.append((np.array(v).mean(axis=0).argmax()))\n#     diagnosis.append(np.minimum(np.array(v).mean(axis=0).round(), 4.0).astype(int)[0])\n    # voting\n#     diagnosis.append((np.argmax(np.bincount(np.array(v).argmax(axis=1)))))\n    diagnosis.append(np.argmax(np.bincount(coral_out_to_class(v).numpy())))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.DataFrame({'id_code':id_code, 'diagnosis':diagnosis})\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}