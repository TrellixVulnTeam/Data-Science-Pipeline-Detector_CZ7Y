{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch import nn\nfrom fastai.vision import *\nimport torchvision\n\ndf = pd.read_csv('../input/train.csv')\npath = '../input'\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nmodel = torchvision.models.resnext101_32x8d(pretrained=True)\niB = ImageDataBunch.from_df(path=path,\n                   df=df,\n                   folder = 'train_images',\n                   seed = 42,\n                   suffix = '.png',\n                   test = 'test_images',\n                   size=224,\n                    bs=32,\n                   ds_tfms=get_transforms(do_flip=True,\n                                      max_warp=0,\n                                      max_rotate=0,\n                                      max_lighting=0,\n                                      p_affine=0,\n                                      xtra_tfms=[crop_pad()]))\n\n#Ensembling ResNeXt101_32x8d, Densenet201, Resnet152 and VGG16(with BatchNorm)\nmodel1 = torchvision.models.resnext101_32x8d(pretrained=True)\nmodel1.fc = nn.Sequential(nn.BatchNorm1d(2048),\n                          nn.Dropout(p=0.25),\n                          nn.Linear(2048,512),\n                          nn.ReLU(),\n                          nn.BatchNorm1d(512),\n                          nn.Dropout(p=0.5),\n                          nn.Linear(512,5))\nmodel1.to(device)\nlearn1 = Learner(data=iB,model=model1,model_dir='/tmp/models',metrics=[accuracy])\nlearn2 = cnn_learner(data=iB,base_arch=models.resnet152,model_dir='/tmp/models',metrics=[accuracy])\nlearn3 = cnn_learner(data=iB,base_arch=models.densenet201,model_dir='/tmp/models',metrics=[accuracy])\nlearn4 = cnn_learner(data=iB,base_arch=models.vgg16_bn,model_dir='/tmp/models',metrics=[accuracy])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Training ResNeXt101_32x8d....\")\nlearn1.fit_one_cycle(7,slice(8e-04))\nmodel1 = learn1.model\nprint(\"Training Resnet152....\")\nlearn2.unfreeze()\nlearn2.fit_one_cycle(7,slice(3e-03))\nmodel2 = learn2.model\nprint(\"Traning Densenet201....\")\nlearn3.unfreeze()\nlearn3.fit_one_cycle(7,slice(3e-03))\nmodel3 = learn3.model\nprint(\"Training VGG16......\")\nlearn4.unfreeze()\nlearn4.fit_one_cycle(7,slice(3e-03))\nmodel4 = learn4.model\ntorch.save(model1, './model1.pth')\ntorch.save(model2, './model2.pth')\ntorch.save(model3, './model3.pth')\ntorch.save(model4, './model4.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff = pd.read_csv(\"../input/test.csv\")\nsrc = (ImageList.from_df(dff, path='../input', folder='test_images', suffix='.png')\n               .split_none()\n               .label_empty())\nmodel1.eval()\nmodel2.eval()\nmodel3.eval()\nmodel4.eval()\niB = ImageDataBunch.create_from_ll(src,size=224,bs=32,\n                                  ds_tfms=get_transforms(do_flip=True,\n                                      max_warp=0,\n                                      max_rotate=0,\n                                      max_lighting=0,\n                                      p_affine=0.2,\n                                      xtra_tfms=[crop_pad()]))\npredictor1 = Learner(data=iB,model=model1,model_dir='/')\npreds1 = predictor1.get_preds(ds_type=DatasetType.Fix)\npredictor2 = Learner(data=iB,model=model2,model_dir='/')\npreds2 = predictor2.get_preds(ds_type=DatasetType.Fix)\npredictor3 = Learner(data=iB,model=model3,model_dir='/')\npreds3 = predictor3.get_preds(ds_type=DatasetType.Fix)\npredictor4 = Learner(data=iB,model=model4,model_dir='/')\npreds4 = predictor4.get_preds(ds_type=DatasetType.Fix)\nlabels1,labels2,labels3,labels4 = [],[],[],[]\nprint(\"Predicting from model1....\")\nfor pr in preds1[0]:\n    p = pr.tolist()\n    labels1.append(np.argmax(p))\nprint(\"Predicting from model2....\")\nfor pr in preds2[0]:\n    p = pr.tolist()\n    labels2.append(np.argmax(p))\nprint(\"Predicting from model3....\")\nfor pr in preds3[0]:\n    p = pr.tolist()\n    labels3.append(np.argmax(p))\nprint(\"Predicting from model4....\")\nfor pr in preds4[0]:\n    p = pr.tolist()\n    labels4.append(np.argmax(p))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finalPreds = []\nfor i in range(len(labels1)):\n    predd = (labels1[i]+labels2[i]+labels3[i]+labels4[i])/4.0\n    predd = np.floor(predd)\n    predd = int(predd)\n    finalPreds.append(predd)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids = list(dff[\"id_code\"])\nsubmit = pd.DataFrame(data={'id_code':ids,'diagnosis':finalPreds})\nsubmit.to_csv('./submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}