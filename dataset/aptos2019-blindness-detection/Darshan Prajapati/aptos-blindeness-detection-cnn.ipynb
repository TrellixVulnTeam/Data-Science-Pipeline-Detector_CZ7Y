{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nos.listdir('../input/aptos2019-blindness-detection/')\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_DIR = '../input/aptos2019-blindness-detection'\nTRAIN_IMG_DIR = '../input/aptos2019-blindness-detection/train_images'\nTEST_IMG_DIR = \"../input/aptos2019-blindness-detection/test_images\"\nBATCH_SIZE = 8\nEPOCHES = 30\nIMAGE_SIZE = 512","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')\ntrain_df['diagnosis'] = train_df['diagnosis'].astype('str')\ntrain_df['id_code'] = train_df['id_code'].astype(str)+'.png'\ntrain_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\ntest_df['id_code'] = test_df['id_code'].astype(str)+'.png'\ntest_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n    rescale = 1./255,\n    horizontal_flip=True,\n    vertical_flip=True,\n    zoom_range=0.2,\n    validation_split = 0.2\n)\ntrain_gen = datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = TRAIN_IMG_DIR,\n    class_mode ='categorical',\n    x_col = 'id_code',\n    y_col = 'diagnosis',\n    batch_size = BATCH_SIZE,\n    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n    subset = 'training',\n    shuffle = True,\n)\ntest_gen = datagen.flow_from_dataframe(\n    dataframe = train_df,\n    directory = TRAIN_IMG_DIR,\n    class_mode= 'categorical',\n    x_col = 'id_code',\n    y_col = 'diagnosis',\n    batch_size = BATCH_SIZE,\n    target_size = (IMAGE_SIZE,IMAGE_SIZE),\n    subset = 'validation',\n    shuffle = True,\n)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# y_train = train_df['diagnosis']\n# from keras.utils import np_utils\n# y_train = np_utils.to_categorical(y_train)\n# num_classes = y_train.shape[1]\n# print(y_train.shape)\nfrom sklearn.preprocessing import OneHotEncoder\nonehot_encoder = OneHotEncoder(sparse=False)\nencoded_diagnosis = onehot_encoder.fit_transform(train_df[['diagnosis']])\nprint(encoded_diagnosis)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout, GaussianNoise, GaussianDropout\nfrom keras.layers import Flatten, BatchNormalization\nfrom keras.layers.convolutional import Conv2D, SeparableConv2D\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.utils import np_utils\nfrom keras import backend as K\nfrom keras import regularizers, optimizers\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications.densenet import DenseNet201\nfrom keras.layers import LeakyReLU","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    model = Sequential()\n    model.add(Conv2D(filters=16, kernel_size=(5, 5), activation=\"relu\", input_shape=(512,512,3)))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters=32, kernel_size=(5, 5), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Conv2D(filters=64, kernel_size=(5, 5), activation='relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    model.add(Flatten())\n    model.add(Dense(128, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(64, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation='sigmoid'))\n    \n    # Compile model\n    model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model\n\ndef build_inception():\n    model = Sequential()\n    model.add(InceptionResNetV2(include_top=False, weights=None, input_shape=(512,512,3)))\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.1))\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model\n\ndef build_densent():\n    model = Sequential()\n    model.add(DenseNet201(include_top=False, weights=None, input_shape=(512,512,3), pooling=None))\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dense(128))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.5))\n    model.add(Dense(64))\n    model.add(LeakyReLU(alpha=0.2))\n    model.add(Dropout(0.5))\n    model.add(Dense(5, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=optimizers.adam(lr=0.0001, amsgrad=True), metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_inception()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ModelCheckpoint\nearly_stop= EarlyStopping(monitor='val_loss', mode ='min', verbose = 1, patience = 20)\n# model_checkpoint = ModelCheckpoint('model.h5', monitor='val_loss', save_best_only = True, mode ='min', verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit_generator(generator=train_gen,              \n                                    steps_per_epoch=len(train_gen)//BATCH_SIZE,\n                                    validation_data=test_gen,                    \n                                    validation_steps=len(test_gen)//BATCH_SIZE,\n                                    epochs=50,\n                                    callbacks = [early_stop],\n                                    use_multiprocessing = True,\n                                    verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_loss, test_acc = model.evaluate_generator(\n    test_gen,\n    steps=len(test_gen)\n)\n\nprint(\"Test accuracy : {}\".format(test_acc * 100))\nprint(\"Test loss/error : {}\".format(test_loss))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\n#submission_df['diagnosis'] = submission_df['diagnosis'].astype('str')\nsubmission_df['id_code'] = submission_df['id_code'].astype(str)+'.png'\nprint(submission_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_datagen=ImageDataGenerator(rescale=1./255)\nsubmission_gen=submission_datagen.flow_from_dataframe(\n    dataframe=submission_df,\n    directory=TEST_IMG_DIR,\n    x_col=\"id_code\",    \n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    class_mode=None, \n    target_size=(IMAGE_SIZE,IMAGE_SIZE)\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions=model.predict_generator(submission_gen, steps = len(submission_gen))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_probability = np.argmax(predictions,axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['id_code'] = submission_df['id_code'].str.replace('.png','')\nsubmission_df['diagnosis'] = max_probability\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('submission.csv')\nsubmission.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}