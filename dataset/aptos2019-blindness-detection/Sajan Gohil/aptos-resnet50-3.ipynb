{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport cv2\nimport math \nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport sys\nfrom tensorflow.keras import layers,models\nimport gc\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.DataFrame(columns = ['id','class'])#","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf ../working/pics_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir pics_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = np.array(pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop(img):\n    img = cv2.resize(img,(img.shape[1]//4,img.shape[0]//4), interpolation =  cv2.INTER_AREA )\n    img2 = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    _,img3 = cv2.threshold(img2,10,255,cv2.THRESH_BINARY)\n    contours,hierarchy = cv2.findContours(img2,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n    cnt = contours[0]\n    x,y,w,h = cv2.boundingRect(cnt)\n    if x>5 and h>5:\n        img = img[y:y+h,x:x+w,:]\n    img = cv2.resize(img,(256,256),interpolation =  cv2.INTER_AREA)\n#     cv2.imshow(img)\n#     plt.show()\n    return img\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef Krish(crop):\n    Input=crop[:,:,2]\n    a,b=Input.shape\n    Kernel=np.zeros((3,3,8))#windows declearations(8 windows)\n    Kernel[:,:,0]=np.array([[5,5,5],[-3,0,-3],[-3,-3,-3]])\n    Kernel[:,:,1]=np.array([[-3,5,5],[-3,0,5],[-3,-3,-3]])\n    Kernel[:,:,2]=np.array([[-3,-3,5],[-3,0,5],[-3,-3,5]])\n    Kernel[:,:,3]=np.array([[-3,-3,-3],[-3,0,5],[-3,5,5]])\n    Kernel[:,:,4]=np.array([[-3,-3,-3],[-3,0,-3],[5,5,5]])\n    Kernel[:,:,5]=np.array([[-3,-3,-3],[5,0,-3],[5,5,-3]])\n    Kernel[:,:,6]=np.array([[5,-3,-3],[5,0,-3],[5,-3,-3]])\n    Kernel[:,:,7]=np.array([[5,5,-3],[5,0,-3],[-3,-3,-3]])\n    #Kernel=(1/float(15))*Kernel\n    #Convolution output\n    dst=np.zeros((a,b,8))\n    for x in range(0,8):\n        dst[:,:,x] = cv2.filter2D(Input,-1,Kernel[:,:,x])\n    Out=np.zeros((a,b))\n    for y in range(0,a-1):\n        for z in range(0,b-1):\n            Out[y,z]=max(dst[y,z,:])\n    Out=np.uint8(Out)\n    return Out\n\n\ndef crop_image_from_gray(img,tol=7):\n    \"\"\"\n    Crop out black borders\n    https://www.kaggle.com/ratthachat/aptos-updated-preprocessing-ben-s-cropping\n    \"\"\"\n\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        mask = gray_img>tol\n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0):\n            return img\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n            img = np.stack([img1,img2,img3],axis=-1)\n        return img\n\ndef Cos_inv(crop):    \n    blu=crop[:,:,0].astype(np.float64)    \n    gre=crop[:,:,1].astype(np.float64)    \n    red=crop[:,:,2].astype(np.float64)     \n    l=((blu**2)+(gre**2)+(red**2))**0.5    \n    l=l.astype(np.float64)    \n    l[l==0]=0.0000000001    \n    m=blu/l    \n    Max=np.max(m)    \n    Min=np.min(m)    \n    j=((m-float(Min)/(float(Max)-float(Min)))*2)-1    \n    n=((np.arccos(j))*255)/3.14    \n    nm=n.astype(np.uint8)    \n    equ1 = cv2.equalizeHist(nm)    \n    return equ1\n\n\ndef circle_crop_v2(img):\n    \"\"\"\n    Create circular crop around image centre\n    \"\"\"\n    img = cv2.imread(img)\n    img = crop_image_from_gray(img)\n    img = cv2.resize(img,(img.shape[1]//4,img.shape[0]//4), interpolation = cv2.INTER_AREA)\n    height, width, depth = img.shape\n    largest_side = np.max((height, width))\n    img = cv2.resize(img, (largest_side, largest_side))\n\n    height, width, depth = img.shape\n\n    x = int(width / 2)\n    y = int(height / 2)\n    r = np.amin((x, y))\n\n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    img = Krish(img)\n#     print(img.shape)\n    img = cv2.resize(img, (256,256), cv2.INTER_AREA)\n#     plt.imshow(img, cmap = 'gray')\n#     plt.show()\n    #_,img = cv2.threshold(img,80,255,cv2.THRESH_BINARY)\n    return img\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform(img):\n    arr = []\n#     return arr\n    for i in range(4,7,2):\n        new_image = np.zeros(img.shape, img.dtype)\n#         new_image2 = np.zeros(img.shape, img.dtype)\n#         new_image3 = np.zeros(img.shape, img.dtype)\n        alpha = i # Simple contrast control\n        beta1 = -35*i    # Simple brightness control\n#         beta2 = -40*i\n#         beta3 = -45*i#\n        for y in range(img.shape[0]):\n            for x in range(img.shape[1]):\n        #        new_image[y,x] = np.clip(alpha*image[y,x] + beta, 0, 255)\n                new_image[y,x] = np.clip(alpha*img[y,x] + beta1, 0, 255)\n#                 new_image2[y,x] = np.clip(alpha*img[y,x] + beta2, 0, 255)\n#                 new_image3[y,x] = np.clip(alpha*img[y,x] + beta3, 0, 255)\n        arr.extend([new_image])#,new_image2])#,new_image3])\n    return arr","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = '../input/aptos2019-blindness-detection/train_images/'\n# diag = []\ntrain_arr = []\nif test.shape[0]>1928:\n    for index,value in train.iterrows():\n        id_code = value[0]\n        diagnosis = str(value[1])\n    #     img = cv2.imread(directory+id_code+'.png')\n        img = circle_crop_v2(directory+id_code+'.png')\n    #     arr = [img]#transform(img)\n    #     arr.append(img)\n        train_arr.append(img/255)\n\n        #for image in range(len(arr)):\n         #   df = df.append({'id':id_code+str(image),'class':diagnosis}, ignore_index = True)\n    #         cv2.imwrite('../working/pics_all/'+id_code+str(image)+'.png', arr[image])    \n          #  train_arr.append(arr[image]/255)\ndf = train\n    \n#         diag.append(diagnosis)\n#     if index%100==0:\n#         plt.imshow(img,'gray')\n#         print(img.shape)\n#         plt.show()\n    #df = df.append({'id':id_code,'x_len':img.shape[0], 'y_len': img.shape[1], 'aspect_ratio': img.shape[0]/img.shape[1], 'class':diagnosis}, ignore_index=True)\n    #print(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shape_arr = 14648","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shape_arr = df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"work_dir = '../working/pics_all/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"# train_arr = []\n# for index,value in df.iterrows():\n#     id_code = value[0]\n#     img = cv2.imread(work_dir+id_code+'.png',0)\n#     train_arr.append(img/255)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop('id_code',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.get_dummies(df.astype(str))\ndiag = np.array(df)\ndel df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_arr = np.reshape(np.array(train_arr, dtype = 'float32'), (shape_arr,256,256,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_arr = tf.convert_to_tensor(np.reshape(np.array(train_arr),(3662,64,64,1)), dtype = 'float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(diag))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diag = np.reshape(diag,(shape_arr,5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import (Input,\n                                            GlobalAveragePooling2D,\n                                            Dense,\n                                            Dropout,\n                                            BatchNormalization,\n                                            Conv2D,\n                                            MaxPooling2D)\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import (CSVLogger,\n                                        ModelCheckpoint,\n                                        EarlyStopping)\n# from tensorflow.keras.metrics import Metric\nfrom tensorflow.keras.applications.resnet50 import ResNet50\nfrom tensorflow.keras.applications.densenet import DenseNet121\n\nfrom sklearn.metrics import cohen_kappa_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cnn_model():\n    input_shape = ((256,256,1))\n    inputs = layers.Input(shape=input_shape)\n\n    base_model = ResNet50(weights=None, include_top=False, input_tensor=inputs)\n\n    x = GlobalAveragePooling2D()(base_model.output)\n    x = Dropout(0.5)(x)\n\n    x = Dense(1024, activation='relu')(x)\n\n    output = Dense(5, activation='sigmoid')(x)\n\n    model = Model(inputs, output)\n    model.compile(optimizer = Adam(lr=0.00005), loss='categorical_crossentropy', metrics= [\"accuracy\"] )\n    print(model.summary())\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model = tf.keras.models.load_model(\"../input/aptos2019blindnessdetection-resnet50model/saved_mode500l.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_arr = train_arr[0:100]\n# diag = diag[0:100]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_datagen = ImageDataGenerator(#rescale=1. / 255, \n                                         #validation_split=0.15, \n                                         horizontal_flip=True,\n                                         vertical_flip=True, \n                                         rotation_range=20, \n                                         zoom_range=0.1, \n                                         shear_range=0.1,\n                                        fill_mode='nearest')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_generator = train_datagen.flow(x=train_arr,\n                                     y = diag,\n                                        batch_size=12,\n                                        seed=5000\n                                        )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator():\n    while(1):\n        for _i in range(0,shape_arr,32):\n            yield(train_datagen.flow(train_arr[_i:_i+32],diag[_i:_i+32], batch_size=12,\n                                        shuffle=True,\n                                        seed=40))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if test.shape[0]<=1928:\n    train_model.fit_generator(train_generator, epochs=1, steps_per_epoch=shape_arr//10, verbose=2)\nelse:\n    train_model.fit_generator(train_generator, epochs=100, steps_per_epoch=shape_arr//10, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_model.save('saved_model_dense.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del train_arr\ndel diag","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"directory = '../input/aptos2019-blindness-detection/test_images/'\ntrain_arr = []\nfor index,value in df.iterrows():\n    id_code = value[0]\n#     img = cv2.imread(directory+id_code+'.png')\n    img = circle_crop_v2(directory+id_code+'.png')\n#     arr = transform(img)\n    arr = []\n    train_arr.append(img/255)\n#     train_arr.extend(arr)\n        #df = df.append({'id':id_code+str(image),'class':diagnosis}, ignore_index = True)\n#         cv2.imwrite('../working/pics_all/'+id_code+str(image)+'.png', arr[image])    \n        \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_arr = np.reshape(np.array(train_arr),(len(train_arr),256,256,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_arr.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generator_2():\n    while(1):\n        for _i in range(0,len(train_arr),128):\n            yield((train_arr[_i:_i+128]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(random.choice([0,1,2,3,4]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diag = []\n\n\nfor image in train_arr:\n    pred = train_model.predict(np.reshape(image,(1,256,256,1)))\n    diag.append(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diag = np.array(diag)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = []\nif test.shape[0]<=1928:\n    l = [random.choice([0,1,2,3,4]) for i in range(df.shape[0])]\nelse:\n    for r in diag:\n            l.append(np.where(r[0]==np.max(r[0]))[0][0]) \n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['diagnosis'] = l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm -rf pics_all","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}