{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install efficientnet\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/aptos2019-blindness-detection/'\ndf = pd.read_csv(path + 'train.csv', sep = ',')\ndf.head()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['diagnosis'].hist()\ndf['diagnosis'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['diagnosis'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# burada amaç train_images deki resimlerin isimlerini liste halinde bulmak bunu yapmassak resimleri okuyamayız.\nimport os\nfiles = os.listdir(path + 'train_images')\nlen(files)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2\nimg_list = []\n\nfor i in files[0:20]:\n    image = cv2.imread(path + 'train_images/'+i)\n    image = cv2.resize(image,(400,400))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    img_list.append(image)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_list[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_list[4])\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kopya = img_list[4].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kopya = cv2.cvtColor(kopya, cv2.COLOR_RGB2GRAY)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(kopya, cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kopya.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"blur = cv2.GaussianBlur(kopya,(5,5),0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(blur,cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thresh = cv2.threshold(blur,10,255, cv2.THRESH_BINARY)[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(thresh, cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nkontur = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kontur = kontur[0][0]\nkontur.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kontur = kontur[:,0,:]\nkontur.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kontur[:,0].argmax()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kontur[335]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kontur[:,0].argmin()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kontur[111]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsol = tuple(kontur[kontur[:,0].argmin()])\nsağ = tuple(kontur[kontur[:,0].argmax()])\nüst = tuple(kontur[kontur[:,1].argmin()])\nalt = tuple(kontur[kontur[:,1].argmax()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sol, sağ, üst, alt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    x1 = sol[0]\n    y1 = üst[1]\n    x2 = sağ[0]\n    y2 = alt[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x1, x2, y1, y2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"orijinal = img_list[4].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(orijinal)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crop_ilk = orijinal[y1:y2 , x1:x2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(crop_ilk)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crop_ilk.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crop_ilk = cv2.resize(crop_ilk,(400,400))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(crop_ilk)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = int(x2-x1)*4//100\ny = int(y2-y1)*5//100","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x,y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crop_son = orijinal[y1+y : y2-y , x1+x : x2-x]\nplt.imshow(crop_son)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"crop_son = cv2.resize(crop_son,(400,400))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(crop_son)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lab = cv2.cvtColor(crop_son, cv2.COLOR_RGB2LAB)\nlab.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l,a,b = cv2.split(lab)\nplt.imshow(l, cmap='gray')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"l.shape\ndüz = l.flatten()\ndüz.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(düz,25,[0,256], color = 'r')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"clahe = cv2.createCLAHE(clipLimit=7.0,tileGridSize=((8,8)))\ncl = clahe.apply(l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.hist(cl.flatten(),25,[0,256], color = 'r')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(cl)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"limg = cv2.merge((cl,a,b))\nson = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\nplt.imshow(son)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(crop_son)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"med_son = cv2.medianBlur(son, 3)\nplt.imshow(med_son)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"arka_plan = cv2.medianBlur(son, 37)\nplt.imshow(arka_plan)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"maske = cv2.addWeighted(med_son,1,arka_plan,-1,255)\nplt.imshow(maske)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"son_img = cv2.bitwise_and(maske,med_son)\nplt.imshow(son_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(med_son)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_list = []\n\nfrom tqdm import tqdm_notebook as tqdm\n\nfor i in tqdm(files):\n    image = cv2.imread(path + 'train_images/'+i)\n    image = cv2.resize(image,(400,400))\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    kopya = image.copy()\n    kopya = cv2.cvtColor(kopya, cv2.COLOR_RGB2GRAY)\n    blur = cv2.GaussianBlur(kopya,(5,5),0)\n    thresh = cv2.threshold(blur,10,255, cv2.THRESH_BINARY)[1]\n    kontur = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n    kontur = kontur[0][0]\n    kontur = kontur[:,0,:]\n    x1 = tuple(kontur[kontur[:,0].argmin()])[0]\n    y1 = tuple(kontur[kontur[:,1].argmin()])[1]\n    x2 = tuple(kontur[kontur[:,0].argmax()])[0]\n    y2 = tuple(kontur[kontur[:,1].argmax()])[1]\n    x = int(x2-x1)*4//50\n    y = int(y2-y1)*5//50\n    kopya2 = image.copy()\n    if x2-x1 >100 and y2-y1> 100:\n        kopya2 = kopya2[y1+y : y2-y , x1+x : x2-x]\n        kopya2 = cv2.resize(kopya2,(400,400))\n    lab = cv2.cvtColor(kopya2, cv2.COLOR_RGB2LAB)\n    l,a,b = cv2.split(lab)\n    clahe = cv2.createCLAHE(clipLimit=5.0,tileGridSize=((8,8)))\n    cl = clahe.apply(l)\n    limg = cv2.merge((cl,a,b))\n    son = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)\n    med_son = cv2.medianBlur(son, 3)\n    arka_plan = cv2.medianBlur(son, 37)\n    maske = cv2.addWeighted(med_son,1,arka_plan,-1,255)\n    son_img = cv2.bitwise_and(maske,med_son)\n    img_list.append(son_img)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(img_list[6])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=(20,12))\n\nfor i in range(12):\n    img = img_list[i]\n    fig.add_subplot(3,4,i+1)\n    plt.imshow(img)\n\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train = pd.get_dummies(df['diagnosis']).values\ndf['diagnosis'][1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_son = np.ones(y_train.shape, dtype='uint8')\ny_train_son[:,4] = y_train[:,4]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.logical_or(0,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.logical_or(1,0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(3,-1,-1):\n    y_train_son[:,i] = np.logical_or(y_train[:,i], y_train_son[:,i+1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_son","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = np.array(img_list)\nx_train.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_son.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_val , y_train, y_val = train_test_split(x_train,\n                                                   y_train_son,\n                                                   test_size=0.15,\n                                                   random_state=2019,\n                                                   shuffle=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train.shape, x_val.shape , y_train.shape, y_val.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(horizontal_flip=True,vertical_flip=True)\ndata_generator = datagen.flow(x_train,y_train,batch_size=2,seed=2020)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from efficientnet.keras import EfficientNetB5","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"örnek_model = EfficientNetB5()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# örnek_model.summary()\nörnek_model2 = EfficientNetB5(include_top=False)\n# örnek_model2.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom keras.models import Sequential\nfrom keras import layers\n\nmodel = Sequential()\nmodel.add(EfficientNetB5(weights='imagenet',include_top=False, input_shape=(400,400,3)))\nmodel.add(layers.GlobalAveragePooling2D())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(5,activation = 'sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.optimizers import Adam\nmodel.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.00005),metrics=['accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\n\nlr = ReduceLROnPlateau(monitor = 'val_loss',\n                      patience = 3,\n                      verbose = 1,\n                      mode='auto',\n                      factor=0.25,\n                      min_lr=0.000001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(data_generator,\n                             steps_per_epoch = 1000,\n                             epochs = 1,\n                             validation_data = (x_val,y_val),\n                             callbacks = [lr])","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}