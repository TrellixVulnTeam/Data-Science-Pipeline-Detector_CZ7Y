{"cells":[{"metadata":{},"cell_type":"markdown","source":"This kernel is based on DrHabib's starter kernel: - Great starter and lots of thanks!\nhttps://www.kaggle.com/drhabib/starter-kernel-for-0-79\nAlso codes from Mendonca's EfficientNetB4 -\nhttps://www.kaggle.com/hmendonca/efficientnetb4-fastai-blindness-detection\nPreprocessing methods (circle_crop/ben's cropping) from -\nhttps://www.kaggle.com/ratthachat/aptos-updatedv14-preprocessing-ben-s-cropping"},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# directly from pretrained:\nk = 0\npreds = ['','','','','']\nfor image_size in [224,232,240,248,256]:\n    test = ImageList.from_df(test_df,\n                             '../input/aptos2019-blindness-detection',\n                             folder='test_images',\n                             suffix='.png')\n    data = (ImageList.from_df(df=train_df,path='./',cols='path')\n            .split_by_rand_pct(0.2) \n            .label_from_df(cols='diagnosis',label_cls=FloatList)\n            .add_test(test)\n            .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n            .databunch(bs=batch_size,num_workers=4) \n            .normalize(imagenet_stats)  \n           )\n    learn = Learner(data, \n                    model_b5, \n                    metrics = [quadratic_kappa], \n                    model_dir=\"models\").to_fp16()\n    learn.load('abcdef');\n    opt = OptimizedRounder()\n    preds[k],y = learn.get_preds(DatasetType.Test)\n    k = k + 1\npreds_1 = preds[0] * 0.2 + preds[1] * 0.20 + preds[2] * 0.2 + preds[3] * 0.2 + preds[4] * 0.2\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\n# directly from pretrained:\nk = 0\npreds = ['','','','','']\nfor image_size in [224,232,240,248,256]:\n    test = ImageList.from_df(test_df,\n                             '../input/aptos2019-blindness-detection',\n                             folder='test_images',\n                             suffix='.png')\n    data = (ImageList.from_df(df=train_df,path='./',cols='path')\n            .split_by_rand_pct(0.2) \n            .label_from_df(cols='diagnosis',label_cls=FloatList)\n            .add_test(test)\n            .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n            .databunch(bs=batch_size,num_workers=4) \n            .normalize(imagenet_stats)  \n           )\n    learn = Learner(data, \n                    model_b5, \n                    metrics = [quadratic_kappa], \n                    model_dir=\"models\").to_fp16()\n    learn.load('best_kappa');\n    opt = OptimizedRounder()\n    preds[k],y = learn.get_preds(DatasetType.Test)\n    k = k + 1\npreds_2 = preds[0] * 0.2 + preds[1] * 0.20 + preds[2] * 0.2 + preds[3] * 0.2 + preds[4] * 0.2\n'''","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n%reload_ext autoreload\n%autoreload 2\n%matplotlib inline\n# data visualisation and manipulation\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n%matplotlib inline\n\n#\nfrom joblib import load, dump\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\nfrom sklearn.metrics import confusion_matrix\nimport torch\nfrom torchvision import models as md\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils import model_zoo\nimport re\nimport math\nimport json\nimport os\nimport sys\nimport cv2\nimport collections\nfrom functools import partial\nfrom collections import Counter\n\n# ignore warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# loading fastai\nimport fastai\nfrom fastai import *\nfrom fastai.vision import *\nfrom fastai.callbacks import *\nfrom fastai.basic_train import *\nfrom fastai.vision.learner import *\n\n# set directory\ndir_19_name = os.path.join('..', 'input/aptos2019-blindness-detection/')\ndir_15_name = os.path.join('..', 'input/diabetic-retinopathy-resized/')\n# loading EfficientNet\n# Repository source: https://github.com/qubvel/efficientnet\nsys.path.append(os.path.abspath('../input/efficientnet-pytorch/efficientnet-pytorch/EfficientNet-PyTorch-master'))\nfrom efficientnet_pytorch import EfficientNet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#making model\nmd_ef = EfficientNet.from_name('efficientnet-b5',override_params={'num_classes':1})\n#copying weighst to the local directory \n!mkdir models\n!cp '../input/kaggle-public/abcdef.pth' 'models'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_df(dir_15_name,dir_19_name):\n    valid_dir = os.path.join(dir_19_name,'train_images/')\n    valid_df = pd.read_csv(os.path.join(dir_19_name,'train.csv'))\n    valid_df['path'] = valid_df['id_code'].map(lambda x: os.path.join(valid_dir,'{}.png'.format(x)))\n    #valid_df = valid_df.drop(columns=['id_code'])\n    valid_df['is_valid'] = [True] * len(valid_df)\n    valid_df = valid_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n    test_df = pd.read_csv(os.path.join(dir_19_name,'sample_submission.csv'))\n    train_dir = os.path.join(dir_15_name,'resized_train_cropped/resized_train_cropped/')\n    train_df = pd.read_csv(os.path.join(dir_15_name,'trainLabels_cropped.csv'))\n    train_df['path'] = train_df['image'].map(lambda x: os.path.join(train_dir,'{}.jpeg'.format(x)))\n    train_df['diagnosis'] = train_df['level']\n    train_df['id_code'] = train_df['image']\n    train_df['is_valid'] = [False] * len(train_df)\n    train_df1 = train_df[train_df['diagnosis'] == 0]\n    train_df2 = train_df[train_df['diagnosis'] != 0]\n    train_df1 = train_df1.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n    #train_df1 = train_df1[:5000]\n    train_df = pd.concat([train_df1,train_df2],axis=0,ignore_index=True)\n    train_df = train_df.drop(columns = ['Unnamed: 0.1','Unnamed: 0','level','image'])\n    train_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n    return train_df, valid_df, test_df\ntrain_df, valid_df, test_df = get_df(dir_15_name,dir_19_name)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%% train_test_split using Stratified K-folds:\nSEED = 42\ndef skfold_split(x, y, n_folds=5, random_seed = SEED):  \n    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=random_seed)\n    split_index = [(train,valid) for train, valid in skf.split(x, y)]\n    return split_index\ndf = pd.concat([train_df,valid_df],axis = 0,ignore_index = True)\nsplit_idx = skfold_split(df['id_code'],df['diagnosis'])\ntrain_df0 = df[df.index.isin(split_idx[0][0])]\nvalid_df0 = df[df.index.isin(split_idx[0][1])]\ntrain_df1 = df[df.index.isin(split_idx[1][0])]\nvalid_df1 = df[df.index.isin(split_idx[1][1])]\ntrain_df2 = df[df.index.isin(split_idx[2][0])]\nvalid_df2 = df[df.index.isin(split_idx[2][1])]\ntrain_df3 = df[df.index.isin(split_idx[3][0])]\nvalid_df3 = df[df.index.isin(split_idx[3][1])]\ntrain_df4 = df[df.index.isin(split_idx[4][0])]\nvalid_df4 = df[df.index.isin(split_idx[4][1])]\nprint('train_df.shape:', train_df3.shape)\nprint('valid_df.shape:', valid_df3.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"train_df1 = train_df[:4000]\ntrain_df2 = train_df[4000:8000]\ntrain_df3 = train_df[8000:12000]\ntrain_df4 = train_df[12000:]\nvalid_df1 = valid_df[:1000]\nvalid_df2 = valid_df[1000:2000]\nvalid_df3 = valid_df[2000:3000]\nvalid_df4 = valid_df[3000:]\nres1 = pd.concat([train_df1,valid_df1],axis=0,ignore_index=True)\nres2 = pd.concat([train_df2,valid_df2],axis=0,ignore_index=True)\nres3 = pd.concat([train_df3,valid_df3],axis=0,ignore_index=True)\nres4 = pd.concat([train_df4,valid_df4],axis=0,ignore_index=True)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n    \ndef circle_crop(img):   \n    \"\"\"\n    Create circular crop around image centre    \n    \"\"\"    \n    \n    #img = cv2.imread(img)\n    img = crop_image_from_gray(img)    \n    \n    height, width, depth = img.shape    \n    \n    x = int(width/2)\n    y = int(height/2)\n    r = np.amin((x,y))\n    \n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x,y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n    \n    return img \n\ndef circle_crop_v2(img):\n    \"\"\"\n    Create circular crop around image centre\n    \"\"\"\n    #img = cv2.imread(img)\n    img = crop_image_from_gray(img)\n\n    height, width, depth = img.shape\n    largest_side = np.max((height, width))\n    img = cv2.resize(img, (largest_side, largest_side))\n\n    height, width, depth = img.shape\n\n    x = int(width / 2)\n    y = int(height / 2)\n    r = np.amin((x, y))\n\n    circle_img = np.zeros((height, width), np.uint8)\n    cv2.circle(circle_img, (x, y), int(r), 1, thickness=-1)\n    img = cv2.bitwise_and(img, img, mask=circle_img)\n    img = crop_image_from_gray(img)\n\n    return img\n\ndef qk(y_pred, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_pred), y, weights='quadratic'), device='cuda:0')\n#https://www.kaggle.com/abhishek/optimizer-for-quadratic-weighted-kappa\n\nclass OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']\ndef _load_format(path, convert_mode, after_open)->Image:\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = circle_crop(image)\n    image = cv2.resize(image, (image_size, image_size))\n    image = cv2.addWeighted(image,4,cv2.GaussianBlur(image,(0,0),10),-4,128)\n    return Image(pil2tensor(image, np.float32).div_(255)) #return fastai Image format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nimage_size = 256\ntransforms = get_transforms(do_flip=True,flip_vert=True,max_rotate=360, max_zoom=1.35, max_lighting=0.1,p_affine = 0.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = ['','','','','','','','','','']\ni = 0\n#for sz in [264,232,240,248,256,264,232,240,248,256]:\ntest = (ImageList.from_df(test_df,\n                          '../input/aptos2019-blindness-detection',\n                          folder='test_images',\n                          suffix='.png'))\ndata = (ImageList.from_df(df=valid_df,path='./',cols='path') \n        .split_by_rand_pct(0.2) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .add_test(test)\n        .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=batch_size,num_workers=4) \n        .normalize(imagenet_stats)  \n        )\nlearn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                model_dir=\"models\").to_fp16()\nlearn.load('abcdef');\npreds_A,y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nimage_size = 224\n!cp '../input/aptosdataset/19model2.pth' 'models'\nvision.data.open_image = _load_format","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_df(df=df,path='./',cols='path') \n        .split_by_idxs(split_idx[0][0],split_idx[0][1]) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=batch_size,num_workers=6) \n        .normalize(imagenet_stats)  \n        )\nlearn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                callback_fns=[BnFreeze,\n                              partial(SaveModelCallback, monitor='valid_loss', name='model0')],\n                model_dir=\"models\").to_fp16()\n\nlearn.data.add_test(ImageList.from_df(test_df,\n                                      '../input/aptos2019-blindness-detection',\n                                      folder='test_images',\n                                      suffix='.png'))\nlearn.load('19model2')\nlearn.fit_one_cycle(20,1e-3,wd = 1e-2)\nlearn.load('model0')\npreds0,y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_df(df=df,path='./',cols='path') \n        .split_by_idxs(split_idx[1][0],split_idx[1][1]) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=batch_size,num_workers=6) \n        .normalize(imagenet_stats)  \n        )\nlearn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                callback_fns=[BnFreeze,\n                              partial(SaveModelCallback, monitor='valid_loss', name='model1')],\n                model_dir=\"models\").to_fp16()\n\nlearn.data.add_test(ImageList.from_df(test_df,\n                                      '../input/aptos2019-blindness-detection',\n                                      folder='test_images',\n                                      suffix='.png'))\nlearn.load('19model2')\nlearn.fit_one_cycle(20,1e-3,wd = 1e-2)\nlearn.load('model1')\npreds1,y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_df(df=df,path='./',cols='path') \n        .split_by_idxs(split_idx[2][0],split_idx[2][1]) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=batch_size,num_workers=6) \n        .normalize(imagenet_stats)  \n        )\nlearn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                callback_fns=[BnFreeze,\n                              partial(SaveModelCallback, monitor='valid_loss', name='model2')],\n                model_dir=\"models\").to_fp16()\n\nlearn.data.add_test(ImageList.from_df(test_df,\n                                      '../input/aptos2019-blindness-detection',\n                                      folder='test_images',\n                                      suffix='.png'))\nlearn.load('19model2')\nlearn.fit_one_cycle(20,1e-3,wd = 1e-2)\nlearn.load('model2')\npreds2,y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_df(df=df,path='./',cols='path') \n        .split_by_idxs(split_idx[3][0],split_idx[3][1]) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=batch_size,num_workers=6) \n        .normalize(imagenet_stats)  \n        )\nlearn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                callback_fns=[BnFreeze,\n                              partial(SaveModelCallback, monitor='valid_loss', name='model3')],\n                model_dir=\"models\").to_fp16()\n\nlearn.data.add_test(ImageList.from_df(test_df,\n                                      '../input/aptos2019-blindness-detection',\n                                      folder='test_images',\n                                      suffix='.png'))\nlearn.load('19model2')\nlearn.fit_one_cycle(20,1e-3,wd = 1e-2)\nlearn.load('model3')\npreds3,y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = (ImageList.from_df(df=df,path='./',cols='path') \n        .split_by_idxs(split_idx[4][0],split_idx[4][1]) \n        .label_from_df(cols='diagnosis',label_cls=FloatList) \n        .transform(transforms,size=image_size,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n        .databunch(bs=batch_size,num_workers=4) \n        .normalize(imagenet_stats)  \n        )\nlearn = Learner(data, \n                md_ef, \n                metrics = [qk], \n                callback_fns=[BnFreeze,\n                              partial(SaveModelCallback, monitor='valid_loss', name='model4')],\n                model_dir=\"models\").to_fp16()\n\nlearn.data.add_test(ImageList.from_df(test_df,\n                                      '../input/aptos2019-blindness-detection',\n                                      folder='test_images',\n                                      suffix='.png'))\nlearn.load('19model2')\nlearn.fit_one_cycle(20,1e-3,wd = 1e-2)\nlearn.load('model4')\npreds4,y = learn.get_preds(DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"'''\npreds = ['','','','','','','','','','']\ni = 0\nopt = OptimizedRounder()\nfor sz in [264,232,240,248,256,264,232,240,248,256]:\n    test = (ImageList.from_df(test_df,\n                              '../input/aptos2019-blindness-detection',\n                              folder='test_images',\n                              suffix='.png'))\n    data = (ImageList.from_df(df=valid_df,path='./',cols='path') \n            .split_by_rand_pct(0.2) \n            .label_from_df(cols='diagnosis',label_cls=FloatList) \n            .add_test(test)\n            .transform(transforms,size=sz,resize_method=ResizeMethod.SQUISH,padding_mode='zeros') \n            .databunch(bs=batch_size,num_workers=4) \n            .normalize(imagenet_stats)  \n           )\n    learn = Learner(data, \n                    md_ef, \n                    metrics = [quadratic_kappa], \n                    model_dir=\"models\").to_fp16()\n    learn.load('19_kappa');\n    preds[i],y = learn.get_preds(DatasetType.Test)\n    i = i + 1\npreds_B = (preds[0] + preds[1] + preds[2] + preds[3] + preds[4] + preds[5] + preds[6] + preds[7] + preds[8] + preds[9])/10\n'''\npred_final = preds_A * 0.3 + preds0 * 0.14 + preds1 * 0.14 + preds2 * 0.14 + preds3 * 0.14 + preds5 * 0.14","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#learn.load('final_kappa')\nopt = OptimizedRounder()\ntst_pred = opt.predict(pred_final,coef=[0.5, 1.5, 2.5, 3.5])\ntest_df.diagnosis = tst_pred.astype(int)\ntest_df.to_csv('submission.csv',index=False)\nprint ('done')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}