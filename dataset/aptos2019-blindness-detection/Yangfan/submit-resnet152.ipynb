{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input/223333/resnet152/resnet152\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# import os\nimport cv2\nimport time\nimport shutil\nimport matplotlib.pyplot as plt\nfrom tqdm import *\nfrom sklearn.model_selection import train_test_split\n\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.backends.cudnn as cudnn\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\nimport torchvision.models as models\nimport torch.optim as optim\nimport torch.nn as nn\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_size = 224\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resnet_cls = models.resnet152()\nresnet_weights_path = \"../input/resnet152/resnet152.pth\"\nresnet_cls.load_state_dict(torch.load(resnet_weights_path))\n\nclass AvgPool(nn.Module):\n    def forward(self, x):\n        return F.avg_pool2d(x, x.shape[2:])\n    \nclass ResNet152(nn.Module):\n    def __init__(self,num_outputs):\n        super(ResNet152,self).__init__()\n        self.resnet = resnet_cls\n        layer4 = self.resnet.layer4\n        self.resnet.layer4 = nn.Sequential(\n                                    nn.Dropout(0.5),\n                                    layer4\n                                    )\n        self.resnet.avgpool = AvgPool()\n        self.resnet.fc = nn.Linear(2048, num_outputs)\n        for param in self.resnet.parameters():\n            param.requires_grad = False\n\n        for param in self.resnet.layer4.parameters():\n            param.requires_grad = True\n\n        for param in self.resnet.fc.parameters():\n            param.requires_grad = True\n            \n    def forward(self,x):\n        out = self.resnet(x)\n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# resnet_cls = models.resnet152()\n# resnet_weights_path = \"../input/resnet152/resnet152.pth\"\n# resnet_cls.load_state_dict(torch.load(resnet_weights_path))\n\n# class AvgPool(nn.Module):\n#     def forward(self, x):\n#         return F.avg_pool2d(x, x.shape[2:])\n    \n# class ResNet152(nn.Module):\n#     def __init__(self,num_outputs):\n#         super(ResNet152,self).__init__()\n#         self.resnet = resnet_cls\n#         layer4 = self.resnet.layer4\n#         self.resnet.layer4 = nn.Sequential(\n#                                     nn.Dropout(0.5),\n#                                     layer4\n#                                     )\n#         self.resnet.avgpool = AvgPool()\n#         self.resnet.fc = nn.Sequential(\n#                           nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n#                           nn.Dropout(p=0.25),\n#                           nn.Linear(in_features=2048, out_features=2048, bias=True),\n#                           nn.ReLU(),\n#                           nn.BatchNorm1d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n#                           nn.Dropout(p=0.5),\n#                           nn.Linear(in_features=2048, out_features=num_outputs, bias=True),\n#                          )\n#         for param in self.resnet.parameters():\n#             param.requires_grad = False\n\n#         for param in self.resnet.layer4.parameters():\n#             param.requires_grad = True\n\n#         for param in self.resnet.fc.parameters():\n#             param.requires_grad = True\n            \n#     def forward(self,x):\n#         out = self.resnet(x)\n#         return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RetinopathyDatasetTest(Dataset):\n    def __init__(self, csv_file, transform):\n        self.data = pd.read_csv(csv_file)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name = os.path.join('../input/aptos2019-blindness-detection/test_images', self.data.loc[idx, 'id_code'] + '.png')\n#         image = cv2.imread(img_name)\n#         image = cv2.resize(image,(512,512))\n        image = load_ben_color(img_name)\n        image = self.transform(image)\n        return {'image': image}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def crop_image1(img,tol=7):\n    # img is image data\n    # tol  is tolerance\n        \n    mask = img>tol\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef crop_image_from_gray(img,tol=7):\n    if img.ndim ==2:\n        mask = img>tol\n        return img[np.ix_(mask.any(1),mask.any(0))]\n    elif img.ndim==3:\n        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n        mask = gray_img>tol\n        \n        check_shape = img[:,:,0][np.ix_(mask.any(1),mask.any(0))].shape[0]\n        if (check_shape == 0): # image is too dark so that we crop out everything,\n            return img # return original image\n        else:\n            img1=img[:,:,0][np.ix_(mask.any(1),mask.any(0))]\n            img2=img[:,:,1][np.ix_(mask.any(1),mask.any(0))]\n            img3=img[:,:,2][np.ix_(mask.any(1),mask.any(0))]\n    #         print(img1.shape,img2.shape,img3.shape)\n            img = np.stack([img1,img2,img3],axis=-1)\n    #         print(img.shape)\n        return img\n    \ndef load_ben_color(path, sigmaX=10 ):\n    image = cv2.imread(path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = crop_image_from_gray(image)\n    image = cv2.resize(image, (img_size, img_size))\n    image=cv2.addWeighted ( image,4, cv2.GaussianBlur( image , (0,0) , sigmaX) ,-4 ,128)\n        \n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checkpoint = torch.load('../input/aptos7-12-224/aptosresnet101_224/model_best.pth.tar')\n# checkpoint = torch.load('../input/152-512/aptosresnet152_512/model_best.pth.tar')\n# print(checkpoint['best_prec1'])\n# print(checkpoint['epoch'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = pd.read_csv('../input/aptos2019-blindness-detection/sample_submission.csv')\ncheckpoint = torch.load('../input/223333/resnet152/resnet152/model_best.pth.tar')\n#checkpoint = torch.load(\"../input/blindmodel-resnet152up/resnet152up/model_best.pth.tar\")\n#creat model\nNeuralNet = ResNet152(num_outputs = 5).to(device)\n#NeuralNet = torch.nn.DataParallel(NeuralNet).cuda()\n#cudnn.benchmark = True\nNeuralNet.load_state_dict(checkpoint['state_dict'])\nNeuralNet.eval()\npredicted = []\n\ntest_transform = transforms.Compose([transforms.ToPILImage(),\n                               #transforms.Pad(64,padding_mode='reflect'),\n                               transforms.RandomHorizontalFlip(),\n                               #transforms.RandomVerticalFlip(),\n                               transforms.ToTensor(),\n                               transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n\ntest_dataset = RetinopathyDatasetTest(csv_file='../input/aptos2019-blindness-detection/sample_submission.csv',\n                                  transform=test_transform)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds1 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds1[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds2 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds2[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds3 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds3[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds4 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds4[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds5 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds5[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds6 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds6[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds7 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds7[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds8 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds8[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds9 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds9[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\ntest_preds10 = np.zeros((len(test_dataset), 1))\ntk0 = tqdm(test_data_loader)\nfor i, x_batch in enumerate(tk0):\n    x_batch = x_batch[\"image\"].to(device)\n    pred = NeuralNet(x_batch)\n    pred_np = np.argmax(pred.data.cpu().numpy(),axis=1)\n    test_preds10[i * 32:(i + 1) * 32] = pred_np.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = (test_preds1 + test_preds2 + test_preds3 + test_preds4 + test_preds5\n             + test_preds6 + test_preds7 + test_preds8 + test_preds9 + test_preds10) / 10.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"coef = [0.5, 1.5, 2.5, 3.5]\n\nfor i, pred in enumerate(test_preds):\n    if pred < coef[0]:\n        test_preds[i] = 0\n    elif pred >= coef[0] and pred < coef[1]:\n        test_preds[i] = 1\n    elif pred >= coef[1] and pred < coef[2]:\n        test_preds[i] = 2\n    elif pred >= coef[2] and pred < coef[3]:\n        test_preds[i] = 3\n    else:\n        test_preds[i] = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/aptos2019-blindness-detection/sample_submission.csv\")\nsample.diagnosis = test_preds.astype(int)\nsample.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}