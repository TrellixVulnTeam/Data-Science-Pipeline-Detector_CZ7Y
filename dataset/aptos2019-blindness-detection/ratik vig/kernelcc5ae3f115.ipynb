{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\"\"\"\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATADIR = \"../input/aptos2019-blindness-detection/train_images/\"\ndf = pd.read_csv('../input/aptos2019-blindness-detection/train.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntraining_data = []\n\"\"\"\"for img in df['id_code']:\n    path = os.path.join(DATADIR,img)\n    path = path+\".png\"\n    image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n   \n    #image = image.resize(1024,1024)\n    image = cv2.resize(image,(1024,1024))\n    print(type(image))\n    img_arr.append(image)\n    i+=1\n    break\"\"\"\nfor _,row in df.iterrows():\n    print (row['id_code'],' ',row['diagnosis'])\n    path = os.path.join(DATADIR,row['id_code']+\".png\")\n    image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image,(224,224))\n    training_data.append([image,row['diagnosis']])\n    \ndel df\n\n    \ndf = pd.read_csv('../input/resized-2015-2019-blindness-detection-images/labels/trainLabels15.csv')\nDATADIR2 = '../input/resized-2015-2019-blindness-detection-images/resized train 15/'\nfor _,row in df.iterrows():\n    print (row['image'],' ',row['level'])\n    path = os.path.join(DATADIR2,row['image']+\".jpg\")\n    image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image,(224,224))\n    training_data.append([image,row['level']])\n   \n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count=0\nfor i in range(35126):\n    if(df['level'][i] == 0):\n        count +=1\nprint(count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df\nimport gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf = pd.read_csv('../input/resized-2015-2019-blindness-detection-images/labels/testLabels15.csv')\nDATADIR2 = '../input/resized-2015-2019-blindness-detection-images/resized test 15/'\nfor _,row in df.iterrows():\n    print (row['image'],' ',row['level'])\n    path = os.path.join(DATADIR2,row['image']+\".jpg\")\n    image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image,(224,224))\n    training_data.append([image,row['level']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df\nprint(len(training_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"img_arr = np.array(img_arr)\nplt.imshow(img_arr[0])\nplt.show()\nprint(img_arr.shape)\"\"\"\n\nimport keras\nx_train=[]\ny_train=[]\nfor features,labels in training_data:\n    x_train.append(features)\n    y_train.append(labels)\nx_train = np.array(x_train).reshape(-1,224,224,1)\n\ny_train = np.array(y_train)\ny_train = keras.utils.to_categorical(y_train)\n\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Activation, Dropout, Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D,AveragePooling2D,BatchNormalization\nimport tensorflow as tf\n\ninput_shape = (224, 224, 1)\nmodel = Sequential([\nConv2D(64, (3, 3), input_shape=(224, 224, 1), activation='relu',padding='same'),\nConv2D(64, (3, 3), activation='relu',padding='same'),\nMaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\nConv2D(128, (3, 3), activation='relu',padding='same'),\nConv2D(128, (3, 3), activation='relu',padding='same'),\nMaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\nConv2D(256, (3, 3), activation='relu',padding='same'),\nConv2D(256, (3, 3), activation='relu',padding='same'),\nConv2D(256, (3, 3), activation='relu',padding='same'),\nMaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\nConv2D(512, (3, 3), activation='relu',padding='same'),\nConv2D(512, (3, 3), activation='relu',padding='same'),\nConv2D(512, (3, 3), activation='relu',padding='same'),\nMaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\nConv2D(512, (3, 3), activation='relu',padding='same'),\nConv2D(512, (3, 3), activation='relu',padding='same'),\nConv2D(512, (3, 3), activation='relu',padding='same'),\nMaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\nFlatten(),\nDense(4096, activation='relu'),\nDense(4096, activation='relu'),\nDense(5, activation='softmax')\n])\nmodel.summary()\n\"\"\"\nmodel = keras.Sequential()\n\nmodel.add(Conv2D(filters=6, kernel_size=(3, 3), activation='relu', input_shape=(224,224,1)))\nmodel.add(AveragePooling2D())\n\nmodel.add(Conv2D(filters=16, kernel_size=(3, 3), activation='relu'))\nmodel.add(AveragePooling2D())\n\nmodel.add(Flatten())\n\nmodel.add(Dense(units=120, activation='relu'))\n\nmodel.add(Dense(units=84, activation='relu'))\n\nmodel.add(Dense(units=5, activation = 'softmax'))\nmodel.summary()\n\n\n\nmodel = Sequential()\n\n\nmodel.add(Conv2D(filters=96, input_shape=(224,224,1), kernel_size=(11,11),\\\n strides=(4,4), padding='valid'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(1024, input_shape=(224*224*1,)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(BatchNormalization())\n\n\nmodel.add(Dense(5))\nmodel.add(Activation('softmax'))\n\nmodel.summary()\"\"\"\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nopt = keras.optimizers.Adam(lr=0.00001)\nclass_weights = {0:1.,1:9.,2:4.,3:26.,4:26.}\nmodel.compile(optimizer=opt, loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.fit(x_train,y_train,epochs=1,validation_split=0.1,class_weight = class_weights)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('my_model.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = []\nTEST_DIR = \"../input/aptos2019-blindness-detection/test_images/\"\ndf = pd.read_csv('../input/aptos2019-blindness-detection/test.csv')\nfor _,row in df.iterrows():\n    print (row['id_code'])\n    path = os.path.join(TEST_DIR,row['id_code']+\".png\")\n    image = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n    image = cv2.resize(image,(224,224))\n    test_data.append(image)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = np.array(test_data).reshape(-1,224,224,1)\nres = model.predict(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"diagnosis = np.argmax(res,axis=1)\nmy_submission = pd.DataFrame({'id_code': df.id_code, 'diagnosis': diagnosis})\n\nmy_submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}