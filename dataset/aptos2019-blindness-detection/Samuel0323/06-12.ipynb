{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-12T12:18:15.820027Z","iopub.execute_input":"2021-06-12T12:18:15.820526Z","iopub.status.idle":"2021-06-12T12:18:20.033428Z","shell.execute_reply.started":"2021-06-12T12:18:15.820413Z","shell.execute_reply":"2021-06-12T12:18:20.032737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n%matplotlib inline\nimport torch\nimport torchvision\nimport numpy as np\nfrom PIL import Image\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import ShuffleSplit\nimport torchvision.models.inception\nfrom torchvision import transforms\nimport matplotlib.pyplot as plt","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:20.034909Z","iopub.execute_input":"2021-06-12T12:18:20.03523Z","iopub.status.idle":"2021-06-12T12:18:22.407368Z","shell.execute_reply.started":"2021-06-12T12:18:20.035199Z","shell.execute_reply":"2021-06-12T12:18:22.406639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# training\nnum_epochs = 20\nbatch_size = 32\nnum_workers = 6\nlr = 0.001\n\n# data sources\nsample_submission = '../input/aptos2019-blindness-detection/sample_submission.csv'\nroot = '../input/aptos2019-blindness-detection/test_images/'\ntraining_file = '../input/aptos2019-blindness-detection/train.csv'\ntrainroot = '../input/aptos2019-blindness-detection/train_images/'\npretrained = '../input/pretrained-pytorch-models/inception_v3_google-1a9a5a14.pth'\ntest_size = 0.2\n\n# data preprocessing from imagenet\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\n# device checker, use GPU if available\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(\"Using device\", device)\n\n# fixing random seed (for reproducibility)\nseed = 555\ntorch.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\nnp.random.seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:22.408604Z","iopub.execute_input":"2021-06-12T12:18:22.408947Z","iopub.status.idle":"2021-06-12T12:18:22.477724Z","shell.execute_reply.started":"2021-06-12T12:18:22.408915Z","shell.execute_reply":"2021-06-12T12:18:22.476729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Loading the pretrained inception v3\nnet = torchvision.models.inception_v3()\nnet.load_state_dict(torch.load(pretrained, map_location='cpu'))\n\n\nnet.fc = torch.nn.Linear(in_features=2048, out_features=5)\nnet.AuxLogits = torchvision.models.inception.InceptionAux(in_channels=768, num_classes=5)\nnet = net.to(device)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:22.479083Z","iopub.execute_input":"2021-06-12T12:18:22.479684Z","iopub.status.idle":"2021-06-12T12:18:30.596363Z","shell.execute_reply.started":"2021-06-12T12:18:22.479648Z","shell.execute_reply":"2021-06-12T12:18:30.59545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optim = torch.optim.Adam(lr=lr, params=net.parameters())\ncrit = torch.nn.BCEWithLogitsLoss()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:30.59869Z","iopub.execute_input":"2021-06-12T12:18:30.598951Z","iopub.status.idle":"2021-06-12T12:18:30.607343Z","shell.execute_reply.started":"2021-06-12T12:18:30.598926Z","shell.execute_reply":"2021-06-12T12:18:30.606383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntransform = torchvision.transforms.Compose([\n    transforms.Resize(299),\n    transforms.CenterCrop(299),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std)\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:30.60869Z","iopub.execute_input":"2021-06-12T12:18:30.609198Z","iopub.status.idle":"2021-06-12T12:18:30.620542Z","shell.execute_reply.started":"2021-06-12T12:18:30.609161Z","shell.execute_reply":"2021-06-12T12:18:30.619514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass SimpleDataset():\n    def __init__(self, data, root, transform):\n        self.files = list(root + data['id_code'] + '.png')\n\n        # LabelBinarizer takes numerical labels and returns a one-hot label\n        binarizer = LabelBinarizer()\n        self.targets = binarizer.fit_transform(data['diagnosis'].values)\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.files)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.files[idx])\n        x = self.transform(img)\n        y = torch.tensor(self.targets[idx,:]).float()\n        return x, y","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:30.621881Z","iopub.execute_input":"2021-06-12T12:18:30.622415Z","iopub.status.idle":"2021-06-12T12:18:30.629741Z","shell.execute_reply.started":"2021-06-12T12:18:30.622379Z","shell.execute_reply":"2021-06-12T12:18:30.628875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndata = pd.read_csv(training_file)\nssplit = ShuffleSplit(n_splits=1, test_size=test_size, random_state=seed)\n\ntrain_index, test_index = next(ssplit.split(data['id_code']))\n\ndataset = SimpleDataset(data.iloc[train_index], trainroot, transform)\nvalidationset = SimpleDataset(data.iloc[test_index], trainroot, transform)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:30.630878Z","iopub.execute_input":"2021-06-12T12:18:30.631403Z","iopub.status.idle":"2021-06-12T12:18:30.675432Z","shell.execute_reply.started":"2021-06-12T12:18:30.631365Z","shell.execute_reply":"2021-06-12T12:18:30.674699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n# # Training model\n# total_step = len(train_loader)\n# for epoch in range(num_epochs):\n#     for batch_i, (data, target) in enumerate(train_loader):\n#         data, target = data.to(device), target.to(device)\n\n#         # Forward pass\n#         outputs, hidden = net(data)\n#         loss = crit(outputs, target)\n\n#         # Backward and optimizer\n#         optim.zero_grad()\n#         loss.backward()\n#         optim.step()\n\n#         if (batch_i+1) % 100 == 0:\n#             print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n#                  .format(epoch+1, num_epochs, batch_i+1, total_step, loss.item()))\n\n# PATH = \"./results/inception_V3_0611.pth\"\n# torch.save(net.state_dict(), PATH)","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:30.677356Z","iopub.execute_input":"2021-06-12T12:18:30.677841Z","iopub.status.idle":"2021-06-12T12:18:30.681817Z","shell.execute_reply.started":"2021-06-12T12:18:30.677808Z","shell.execute_reply":"2021-06-12T12:18:30.68085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = \"../input/inception-v3-0609/inception_V3_0611.pth\"\n# Evaluation\nnet.load_state_dict(torch.load(PATH))\nnet = net.to(device)\nsubmit = pd.read_csv(sample_submission)\nnet.eval()\n\nwith torch.no_grad():\n    for name in tqdm(submit['id_code']):\n        img = Image.open(root+name+'.png')\n        x = transform(img).to(device).unsqueeze(0)\n        y = net(x).cpu().numpy()\n        diag = int(np.argmax(y[:5]))\n        submit.loc[submit['id_code']==name, 'diagnosis'] = diag","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:18:30.683101Z","iopub.execute_input":"2021-06-12T12:18:30.683446Z","iopub.status.idle":"2021-06-12T12:21:24.863311Z","shell.execute_reply.started":"2021-06-12T12:18:30.683413Z","shell.execute_reply":"2021-06-12T12:21:24.86244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsubmit.to_csv('submission.csv', index=False)\nsubmit.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-06-12T12:21:24.864689Z","iopub.execute_input":"2021-06-12T12:21:24.865251Z","iopub.status.idle":"2021-06-12T12:21:25.141131Z","shell.execute_reply.started":"2021-06-12T12:21:24.865213Z","shell.execute_reply":"2021-06-12T12:21:25.140481Z"},"trusted":true},"execution_count":null,"outputs":[]}]}