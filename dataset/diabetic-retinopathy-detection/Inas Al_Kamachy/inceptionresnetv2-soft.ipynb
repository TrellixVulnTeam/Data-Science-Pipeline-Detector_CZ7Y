{"cells":[{"metadata":{"_uuid":"274d4623b344b4fdcf50eeb474ef569645e2c1a8","trusted":true},"cell_type":"code","source":"from multiprocessing.pool import ThreadPool\nimport numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense,Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import *\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n%matplotlib inline\nimport os\nimport random\nimport glob\nimport itertools\nfrom keras.utils import to_categorical\nimport seaborn as sns\nimport tensorflow as tf\nfrom keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"946870e405af53584fb663ed332855045c207c62","trusted":true},"cell_type":"code","source":"import pandas as pd\nrandom.seed(10)\ntrainLabels = pd.read_csv('/kaggle/working/../input/trainLabels.csv')\ntrainLabels.head()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2bc773a897609017b0e5ccf9f779f50b6135e8dc"},"cell_type":"code","source":"from PIL import Image\nfrom keras.preprocessing import image\nimport os\nimport numpy as np\n\n# resize the image to 300x300\nimg_rows, img_cols = 350,350\nBatch_size = 16\n\nlisting = os.listdir(\"/kaggle/working/../input\") \nlisting.remove(\"trainLabels.csv\")\n\nimmatrix = []\nimlabel = []\n\nfor file in listing:\n    base = os.path.basename(\"/kaggle/working/../input/\" + file)\n    fileName = os.path.splitext(base)[0]\n    imlabel.append(trainLabels.loc[trainLabels.image==fileName, 'level'].values[0])\n    im = Image.open(\"/kaggle/working/../input/\" + file)\n    img = np.array(im.resize((img_rows,img_cols)))\n    immatrix.append(np.array(img))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c0adb91ecf64b5f6a45d13ae9510add2efed1a0"},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]\n\nimport matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"86ac18c452a812d30cf285b192bf325242471100"},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_data[0], train_data[1], test_size = 0.1, random_state = 42)\n\n\nprint(np.array(x_train).shape)\nprint(np.array(y_train).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5e5fcec3519fb71785de17861b84923e41c80145"},"cell_type":"code","source":"from keras.utils import np_utils\n\ny_train = np_utils.to_categorical(np.array(y_train), 5)\ny_test = np_utils.to_categorical(np.array(y_test), 5)\n\n\nx_train = np.array(x_train).astype(\"float32\")/255.\nx_test = np.array(x_test).astype(\"float32\")/255.\n\n\nprint(np.array(y_train).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2df0b4630f6771b09ca0a2e29cd682a7d412f42b"},"cell_type":"code","source":"im = Image.fromarray(immatrix[1],'RGB')\nprint(\"level:\",imlabel[1])\nim\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c9b5b703ab626fd8395913c340076568d2b24727"},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bb2823b2e27eb711cc985375d31b55a59f463016"},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_MODEL='InceptionResNetV2' # ['VGG16', 'RESNET52', 'InceptionV3', 'Xception', 'DenseNet169', 'DenseNet121','InceptionResNetV2']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8d48d7dc31233aff3ced166e5ea59f297ebf0177"},"cell_type":"code","source":"\nfrom keras.preprocessing.image import ImageDataGenerator\nif BASE_MODEL=='VGG16':\n    from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\nelif BASE_MODEL=='InceptionResNetV2':\n    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\nelif BASE_MODEL=='InceptionV3':\n    from keras.applications.inception_v3 import InceptionV3 as PTModel, preprocess_input\nelif BASE_MODEL=='Xception':\n    from keras.applications.xception import Xception as PTModel, preprocess_input\nelif BASE_MODEL=='DenseNet169': \n    from keras.applications.densenet import DenseNet169 as PTModel, preprocess_input\nelif BASE_MODEL=='DenseNet121':\n    from keras.applications.densenet import DenseNet121 as PTModel, preprocess_input\nelif BASE_MODEL=='MobileNet':\n    from keras.applications.resnet50 import ResNet50 as PTModel, preprocess_input\nelse:\n    raise ValueError('Unknown model: {}'.format(BASE_MODEL))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications import InceptionResNetV2\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Input\nfrom keras.applications import VGG16\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import MobileNet\nfrom keras.applications import InceptionResNetV2\n\ndef create_model(input_shape, n_out):\n    pretrain_model = PTModel(\n        include_top=False, \n        weights='imagenet', \n        input_shape=input_shape)    \n    input_tensor = Input(shape=input_shape)\n    bn = BatchNormalization()(input_tensor)\n    x = pretrain_model(bn)\n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_out, activation='softmax')(x)\n    model = Model(input_tensor, output)\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def f1(y_true, y_pred):\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('f1')\n    ax[1].plot(history.epoch, history.history[\"f1\"], label=\"Train f1\")\n    ax[1].plot(history.epoch, history.history[\"val_f1\"], label=\"Validation f1\")\n    ax[2].set_title('acc')\n    ax[2].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[2].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keras.backend.clear_session()\nLEARN_RATE = 1e-4\nmodel = create_model(\n    input_shape=x_train[0].shape, \n    n_out=5)\nhistory_InceptionResNetV2  = model.compile(optimizer = Adam(lr=LEARN_RATE), \n                   loss = 'categorical_crossentropy',\n                   metrics = ['acc',f1])\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('boat_detector')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nreduceLROnPlat = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=10, verbose=1, mode='auto', epsilon=0.0001, cooldown=5, min_lr=0.0001)\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=15) # probably needs to be more patient, but kaggle time is limited\ncallbacks_list = [checkpoint, early, reduceLROnPlat]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def brightness_adjustment(img):\n\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    ratio = .5 + np.random.uniform()\n    hsv[:,:,2] =  np.clip(hsv[:,:,2].astype(np.int32) * ratio, 0, 255).astype(np.uint8)\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nimport numpy\nX_train = numpy.array(x_train, copy=True) \nY_train = numpy.array(y_train, copy=True) \nshift = 0.2\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=360,\n   preprocessing_function=brightness_adjustment,\n                                   width_shift_range=shift,\n                                   height_shift_range=shift, shear_range=0.2,\n                                   zoom_range=0.2, channel_shift_range=4.,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rescale=1. /255,\n                                \nfill_mode='nearest') \n\ndatagen.fit(x_train)\n\n\n\n# Concatenating the old data with the augmented data\ntrain_x  = numpy.concatenate((x_train, X_train), axis=0)\ntrain_y  = numpy.concatenate((y_train, Y_train), axis=0)\nprint(train_x.shape)\nprint(train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Batch_size = 16","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_InceptionResNetV2 =model.fit(train_x, train_y, batch_size = Batch_size, epochs=150,validation_split=0.1, verbose=1,\n                          callbacks=callbacks_list   ,  shuffle=True)\n#,callbacks=callbacks_list","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights(weight_path)\nmodel.save('history_InceptionResNetV2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_history(history_InceptionResNetV2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"score = model.evaluate(x_test, y_test,  verbose=0)\nprint('Test score:', score[0])\nprint('Test accuracy:', score[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\npred_Y = model.predict(x_test, batch_size = 16, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)\ntest_Y_cat = np.argmax(y_test, -1)\nprint('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y_pred = model.predict(x_test)\n#print(Y_pred)\ny_pred = np.argmax(Y_pred, axis=1)\n#print(y_pred)\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nsns.heatmap\ntarget_names = ['class 0(BIKES)', 'class 1(CARS)', 'class 2(HORSES)', 'class 3(normal)', 'class 4(dfdd)']\nprint(classification_report(np.argmax(y_test,axis=1), y_pred,target_names=target_names))\nsns.heatmap(confusion_matrix(np.argmax(y_test,axis=1), y_pred), annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = x_test.shape[0]//16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nsick_vec = test_Y_cat>0\nsick_score = np.sum(pred_Y[:,1:],1)\nfpr, tpr, _ = roc_curve(sick_vec, sick_score)\nfig, ax1 = plt.subplots(1,1, figsize = (6, 6), dpi = 150)\nax1.plot(fpr, tpr, 'b.-', label = 'Model Prediction (AUC: %2.2f)' % roc_auc_score(sick_vec, sick_score))\nax1.plot(fpr, fpr, 'g-', label = 'Random Guessing')\nax1.legend()\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = pd.DataFrame({'ImageId': pd.Series(range(1, len(test_Y_cat) + 1)), 'Label': pd.Series(pred_Y_cat)})\nresults.to_csv('results.csv', index=False)\nresults.head(400)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}