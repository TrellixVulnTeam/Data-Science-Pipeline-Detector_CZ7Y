{"cells":[{"metadata":{"_uuid":"274d4623b344b4fdcf50eeb474ef569645e2c1a8","trusted":true},"cell_type":"code","source":"#we used cnn architecture with sigmoid and binary-crossentropy, and 10 epochs and 256 * 256 \nfrom multiprocessing.pool import ThreadPool\nimport numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense,Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import *\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n%matplotlib inline\nimport os\nimport random\nimport glob\nimport itertools\nfrom keras.utils import to_categorical\nimport seaborn as sns\nimport tensorflow as tf\nfrom keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"946870e405af53584fb663ed332855045c207c62","trusted":true},"cell_type":"code","source":"import pandas as pd\nrandom.seed(10)\ntrainLabels = pd.read_csv(\"../input/diabetic-retinopathy-detection/trainLabels.csv\")\ntrainLabels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom keras import backend as K\nfrom keras.applications.inception_v3 import preprocess_input\nimport numpy as np\nIMG_SIZE = (512, 512) # slightly smaller than vgg16 normally expects\ndef tf_image_loader(out_size, \n                      horizontal_flip = True, \n                      vertical_flip = False, \n                     random_brightness = True,\n                     random_contrast = True,\n                    random_saturation = True,\n                    random_hue = True,\n                      color_mode = 'rgb',\n                       preproc_func = preprocess_input,\n                       on_batch = False):\n    def _func(X):\n        with tf.name_scope('image_augmentation'):\n            with tf.name_scope('input'):\n                X = tf.image.decode_png(tf.read_file(X), channels = 3 if color_mode == 'rgb' else 0)\n                X = tf.image.resize_images(X, out_size)\n            with tf.name_scope('augmentation'):\n                if horizontal_flip:\n                    X = tf.image.random_flip_left_right(X)\n                if vertical_flip:\n                    X = tf.image.random_flip_up_down(X)\n                if random_brightness:\n                    X = tf.image.random_brightness(X, max_delta = 0.1)\n                if random_saturation:\n                    X = tf.image.random_saturation(X, lower = 0.75, upper = 1.5)\n                if random_hue:\n                    X = tf.image.random_hue(X, max_delta = 0.15)\n                if random_contrast:\n                    X = tf.image.random_contrast(X, lower = 0.75, upper = 1.5)\n                return preproc_func(X)\n    if on_batch: \n        # we are meant to use it on a batch\n        def _batch_func(X, y):\n            return tf.map_fn(_func, X), y\n        return _batch_func\n    else:\n        # we apply it to everything\n        def _all_func(X, y):\n            return _func(X), y         \n        return _all_func\n    \ndef tf_augmentor(out_size,\n                intermediate_size = (640, 640),\n                 intermediate_trans = 'crop',\n                 batch_size = 16,\n                   horizontal_flip = True, \n                  vertical_flip = False, \n                 random_brightness = True,\n                 random_contrast = True,\n                 random_saturation = True,\n                    random_hue = True,\n                  color_mode = 'rgb',\n                   preproc_func = preprocess_input,\n                   min_crop_percent = 0.001,\n                   max_crop_percent = 0.005,\n                   crop_probability = 0.5,\n                   rotation_range = 10):\n    \n    load_ops = tf_image_loader(out_size = intermediate_size, \n                               horizontal_flip=horizontal_flip, \n                               vertical_flip=vertical_flip, \n                               random_brightness = random_brightness,\n                               random_contrast = random_contrast,\n                               random_saturation = random_saturation,\n                               random_hue = random_hue,\n                               color_mode = color_mode,\n                               preproc_func = preproc_func,\n                               on_batch=False)\n    def batch_ops(X, y):\n        batch_size = tf.shape(X)[0]\n        with tf.name_scope('transformation'):\n            # code borrowed from https://becominghuman.ai/data-augmentation-on-gpu-in-tensorflow-13d14ecf2b19\n            # The list of affine transformations that our image will go under.\n            # Every element is Nx8 tensor, where N is a batch size.\n            transforms = []\n            identity = tf.constant([1, 0, 0, 0, 1, 0, 0, 0], dtype=tf.float32)\n            if rotation_range > 0:\n                angle_rad = rotation_range / 180 * np.pi\n                angles = tf.random_uniform([batch_size], -angle_rad, angle_rad)\n                transforms += [tf.contrib.image.angles_to_projective_transforms(angles, intermediate_size[0], intermediate_size[1])]\n\n            if crop_probability > 0:\n                crop_pct = tf.random_uniform([batch_size], min_crop_percent, max_crop_percent)\n                left = tf.random_uniform([batch_size], 0, intermediate_size[0] * (1.0 - crop_pct))\n                top = tf.random_uniform([batch_size], 0, intermediate_size[1] * (1.0 - crop_pct))\n                crop_transform = tf.stack([\n                      crop_pct,\n                      tf.zeros([batch_size]), top,\n                      tf.zeros([batch_size]), crop_pct, left,\n                      tf.zeros([batch_size]),\n                      tf.zeros([batch_size])\n                  ], 1)\n                coin = tf.less(tf.random_uniform([batch_size], 0, 1.0), crop_probability)\n                transforms += [tf.where(coin, crop_transform, tf.tile(tf.expand_dims(identity, 0), [batch_size, 1]))]\n            if len(transforms)>0:\n                X = tf.contrib.image.transform(X,\n                      tf.contrib.image.compose_transforms(*transforms),\n                      interpolation='BILINEAR') # or 'NEAREST'\n            if intermediate_trans=='scale':\n                X = tf.image.resize_images(X, out_size)\n            elif intermediate_trans=='crop':\n                X = tf.image.resize_image_with_crop_or_pad(X, out_size[0], out_size[1])\n            else:\n                raise ValueError('Invalid Operation {}'.format(intermediate_trans))\n            return X, y\n    def _create_pipeline(in_ds):\n        batch_ds = in_ds.map(load_ops, num_parallel_calls=4).batch(batch_size)\n        return batch_ds.map(batch_ops)\n    return _create_pipeline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"803eb8881bbc0b7211523853964714bdced4da78","trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom keras.preprocessing import image\nimport os\nimport numpy as np\n\n# resize the image to 300x300\n\n\nlisting = os.listdir(\"../input/diabetic-retinopathy-detection\") \nlisting.remove(\"trainLabels.csv\")\n\nimmatrix = []\nimlabel = []\n\nfor file in listing:\n    base = os.path.basename(\"../input/diabetic-retinopathy-detection/\" + file)\n    fileName = os.path.splitext(base)[0]\n    imlabel.append(trainLabels.loc[trainLabels.image==fileName, 'level'].values[0])\n    im = Image.open(\"../input/diabetic-retinopathy-detection/\" + file)\n    img = np.array(im.resize((512,512)))\n    immatrix.append(np.array(img))\n \n","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_uuid":"bc0a0bfdc775a33e93fce40346d82db2a056d7ec","trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]\n\nimport matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43d952ea1aa319b0a6100e4d87e23b5370fbfc54"},"cell_type":"code","source":"#split the dataset into 60% training , 20% test, 20% validation dataset \nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_data[0], train_data[1], test_size = 0.1, random_state = 42)\n\n\nprint(np.array(x_train).shape)\nprint(np.array(y_train).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf1a5df820b49e3448e1662425e3771f1532e640"},"cell_type":"code","source":"from keras.utils import np_utils\n\ny_train = np_utils.to_categorical(np.array(y_train), 5)\ny_test = np_utils.to_categorical(np.array(y_test), 5)\n\n\nx_train = np.array(x_train).astype(\"float32\")/255.\nx_test = np.array(x_test).astype(\"float32\")/255.\n\n\nprint(np.array(y_train).shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42bc0cbf4319d3d94e1f5449f52de04fc6073521","trusted":true},"cell_type":"code","source":"#specify the green channel of the images..\nim = Image.fromarray(immatrix[1],'RGB')\nprint(\"level:\",imlabel[1])\nim","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_uuid":"d9937da7d4e8adc07c9eb02274bb0f5cec6a4964","trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6fb15532a08d21e42038e698a0e6a7a3fa96e4d","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c98367b6448554a929992cdf58dcd2c0f24bbd9d","trusted":true},"cell_type":"code","source":"from keras.applications import InceptionResNetV2\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Input\nfrom keras.applications import VGG16\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import MobileNet\nfrom keras.applications import InceptionResNetV2\n\ndef create_model(input_shape, n_out):\n    pretrain_model = InceptionResNetV2(\n        include_top=False, \n        weights='imagenet', \n        input_shape=input_shape)    \n    input_tensor = Input(shape=input_shape)\n    bn = BatchNormalization()(input_tensor)\n    x = pretrain_model(bn)\n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_out, activation='softmax')(x)\n    model = Model(input_tensor, output)\n    \n    return model\n#x = GlobalAveragePooling2D()(backbone.output)\n#outputs = Dense(5, activation=\"softmax\")(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e6d5093be00ebe79a7cef68ffb0aa691317d8a2"},"cell_type":"code","source":"keras.backend.clear_session()\n\nmodel = create_model(\n    input_shape=x_train[0].shape, \n    n_out=5)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('inceptionResNetv2_model_wieghts.h5')\nmodel.save('inceptionResNetv2_model_keras.h5')\nmodel_json=model.to_json()\nwith open(\"model.json\", \"w\")as json_file:\n    json_file.write(model_json)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c69af0b5ae2ef1f1412783872cb5483b390e6fac","trusted":true},"cell_type":"code","source":"def f1(y_true, y_pred):\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('f1')\n    ax[1].plot(history.epoch, history.history[\"f1\"], label=\"Train f1\")\n    ax[1].plot(history.epoch, history.history[\"val_f1\"], label=\"Validation f1\")\n    ax[2].set_title('acc')\n    ax[2].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[2].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdb13671dd26fcf286f7119e58b401a92c778975"},"cell_type":"code","source":"#from keras.optimizers import SGD\n#from tensorflow.keras.optimizers import RMSprop\nimport torchvision\nfrom numpy import *\nhistory_InceptionResNetV2 =  model.compile(optimizer=Adam(1e-3)\n\n                    , loss='categorical_crossentropy'\n                    , metrics=['acc',f1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93324097fb68be60e1a41a4ca369343276162904","trusted":true},"cell_type":"code","source":"def brightness_adjustment(img):\n    # turn the image into the HSV space\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    # creates a random bright\n    ratio = .5 + np.random.uniform()\n    # convert to int32, so you don't get uint8 overflow\n    # multiply the HSV Value channel by the ratio\n    # clips the result between 0 and 255\n    # convert again to uint8\n    hsv[:,:,2] =  np.clip(hsv[:,:,2].astype(np.int32) * ratio, 0, 255).astype(np.uint8)\n    # return the image int the BGR color space\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use augmentation to increase the number of dataset and solve overfitting problems..\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy\nX_train = numpy.array(x_train, copy=True) \nY_train = numpy.array(y_train, copy=True) \nshift = 0.2\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=360,\n   preprocessing_function=brightness_adjustment,\n                                   width_shift_range=shift,\n                                   height_shift_range=shift, shear_range=0.2,\n                                   zoom_range=0.2, channel_shift_range=4.,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rescale=1. /255,\n#zca_whitening = True                                 \nfill_mode='nearest') \n\ndatagen.fit(x_train)\n\n#print(type(X_train2))\n#print(type(x_train))\n\n# Concatenating the old data with the augmented data\ntrain_x  = numpy.concatenate((x_train, X_train), axis=0)\ntrain_y  = numpy.concatenate((y_train, Y_train), axis=0)\nprint(train_x.shape)\nprint(train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"273d13131a9cc2f7267b945e8797051b2d47e6ca","trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nbest_save_model_file = '../working/inception_model.h5'\ncallbacks = [EarlyStopping(monitor='val_loss',\n                           patience=20,\n                           verbose=1,\n                           min_delta=0.00001,\n                           mode='min'),\n             ReduceLROnPlateau(monitor='val_loss',\n                               factor=0.1,\n                               patience=2,\n                               verbose=1,\n                               min_delta=0.0001,\n                               mode='min'),\n             ModelCheckpoint(monitor='val_loss',save_weights_only=True,\n                             filepath=best_save_model_file,\n                             save_best_only=True,\n                             mode='min') ,\n             ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_InceptionResNetV2 =model.fit(train_x, train_y, batch_size = 16, epochs=100,validation_split=0.1, verbose=1,\n                               shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eca9db197986d17a821c972617e870e820b38f69","trusted":true},"cell_type":"code","source":"#history_inceptionv3= model.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(lr=0.0001), metrics=['acc', f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use augmentation to increase the number of dataset and solve overfitting problems..\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy\nX_test = numpy.array(x_test, copy=True) \nY_test = numpy.array(y_test, copy=True) \nshift = 0.2\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=360,\n   preprocessing_function=brightness_adjustment,\n                                   width_shift_range=shift,\n                                   height_shift_range=shift, shear_range=0.2,\n                                   zoom_range=0.2, channel_shift_range=4.,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rescale=1. /255,\n#zca_whitening = True                                 \nfill_mode='nearest') \n\ndatagen.fit(x_test)\n\n#print(type(X_train2))\n#print(type(x_train))\n\n# Concatenating the old data with the augmented data\ntest_x  = numpy.concatenate((x_test, X_test), axis=0)\ntest_y  = numpy.concatenate((y_test, Y_test), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fb2d7ecc6752621fbbceafc9d1d72778560b1de"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\npred_Y = model.predict(test_x, batch_size = 16, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)\ntest_Y_cat = np.argmax(test_y, -1)\nprint('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))\nprint(classification_report(test_Y_cat, pred_Y_cat))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48ba44d9d73e8882d01bae2a2dc6219e31bee490"},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(test_Y_cat, pred_Y_cat), \n            annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = test_x.shape[0]//16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_history(history_InceptionResNetV2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=80\ntest=test_x[t].reshape(-1,512,512,3)\narr=model.predict(test)\narr=arr.flatten()\n\nmaxm=arr[0]\nfor i in range(0,5):\n    if(arr[i]>=maxm):\n        predicted_label=i+1\n        maxm=arr[i]\nfor i in range(0,5):\n    if(int(test_y[t][i])==1):\n        actual_label=i+1\n        break\nname={1:\"NO level of Diabetic Retinopathy\",2:\"MILD level of Diabetic Retinopathy\",3:\"MODERATE level of Diabetic Retinopathy\",4:\"SEVERE level of Diabetic Retinopathy\",5:\"PROLIFERATIVE level of Diabetic Retinopathy\"\n}\n\nimport matplotlib.pyplot as plt\nplt.imshow(x_test[t])\nplt.show\n\nprint(\"Predicted  : The patient is having \" + name[predicted_label])\nprint(\"Expected   : The patient should have \"+name[actual_label])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37d61472d0217bc4ac64b405dd7ddd4f35675c03","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\npred_Y = model.predict(test_x, batch_size = 16, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)\ntest_Y_cat = np.argmax(test_y, -1)\nprint('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))\nprint(classification_report(test_Y_cat, pred_Y_cat))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71baa2c3f66a204c4c39870ea01f8f43c56a2a91","trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(test_Y_cat, pred_Y_cat), \n            annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = test_x.shape[0]//16)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f28170f51950ba901454524daae772003b8aaf7","trusted":true},"cell_type":"code","source":"score = model.evaluate(test_x,test_y, verbose=0)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d304380df8352b3d4602b91165a9751c87cc9e97","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nsick_vec = test_Y_cat>0\nsick_score = np.sum(pred_Y[:,1:],1)\nfpr, tpr, _ = roc_curve(sick_vec, sick_score)\nfig, ax1 = plt.subplots(1,1, figsize = (6, 6), dpi = 150)\nax1.plot(fpr, tpr, 'b.-', label = 'Model Prediction (AUC: %2.2f)' % roc_auc_score(sick_vec, sick_score))\nax1.plot(fpr, fpr, 'g-', label = 'Random Guessing')\nax1.legend()\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26fb8f44205c4e4a2e34731da1e74d5a8a0dbca0"},"cell_type":"code","source":"score = model.evaluate(test_x, test_y , verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5724a155d3eebd3293b34bcaa97d9a2b3116197"},"cell_type":"code","source":"show_history(history_inceptionvResNetV2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a44e495a61613676761bfba836801fa7d0b10626","trusted":true},"cell_type":"code","source":"results = pd.DataFrame({'ImageId': pd.Series(range(1, len(test_Y_cat) + 1)), 'Label': pd.Series(pred_Y_cat)})\nresults.to_csv('results.csv', index=False)\nresults.head(200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3f271206ac3a2ca71771105641018f083448962a"},"cell_type":"markdown","source":"#Specificity: When the actual value is negative, how often is the prediction correct?\n\n#How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n\nprint(TN / float(TN + FP))\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\n#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n\n\nprint(FP / float(TN + FP))"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}