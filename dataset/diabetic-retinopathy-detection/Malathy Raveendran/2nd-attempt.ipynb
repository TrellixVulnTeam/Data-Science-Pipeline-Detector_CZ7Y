{"cells":[{"metadata":{"_uuid":"274d4623b344b4fdcf50eeb474ef569645e2c1a8","trusted":true},"cell_type":"code","source":"#we used cnn architecture with sigmoid and binary-crossentropy, and 10 epochs and 256 * 256 \nfrom multiprocessing.pool import ThreadPool\nimport numpy as np\nimport keras\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Activation\nfrom keras.layers.core import Dense,Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.convolutional import *\nfrom matplotlib import pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport itertools\nimport matplotlib.pyplot as plt\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten\n%matplotlib inline\nimport os\nimport random\nimport glob\nimport itertools\nfrom keras.utils import to_categorical\nimport seaborn as sns\nimport tensorflow as tf\nfrom keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"946870e405af53584fb663ed332855045c207c62","trusted":true},"cell_type":"code","source":"import pandas as pd\nrandom.seed(10)\ntrainLabels = pd.read_csv(\"../input/diabetic-retinopathy-detection/trainLabels.csv.zip\")\ntrainLabels.head()\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"803eb8881bbc0b7211523853964714bdced4da78","trusted":true},"cell_type":"code","source":"from PIL import Image\nfrom keras.preprocessing import image\nimport os\nimport numpy as np\nimport zipfile \n# resize the image to 300x300\nimg_rows, img_cols = 350,350\n\nlisting = os.listdir(\"../input/diabetic-retinopathy-detection\") \nlisting.remove(\"trainLabels.csv.zip\")\nlisting.remove(\"sampleSubmission.csv.zip\")\n\n\nimmatrix = []\nimlabel = []\n\n    \nfor file in listing:\n    print(file)\n    zf = zipfile.ZipFile(\"../input/diabetic-retinopathy-detection/\" + file)\n    print(zf.filename)\n    #zf.extractall()\n    imageslist = zf.namelist()\n    \n    \n    for imagefile in imageslist: \n        fileName = os.path.splitext(imagefile)[0]\n        print(fileName)\n        print(trainLabels.loc[image==fileName][level])\n        imlabel.append(str(trainLabels.loc[image==fileName][level]))\n        im = Image.open(imagefile)\n        img = np.array(im.resize((img_rows,img_cols)))\n        immatrix.append(np.array(img))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_uuid":"bc0a0bfdc775a33e93fce40346d82db2a056d7ec","trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]\n\nimport matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"43d952ea1aa319b0a6100e4d87e23b5370fbfc54"},"cell_type":"code","source":"#split the dataset into 60% training , 20% test, 20% validation dataset \nfrom sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(train_data[0], train_data[1], test_size = 0.1, random_state = 42)\n\n\nprint(np.array(x_train).shape)\nprint(np.array(y_train).shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cf1a5df820b49e3448e1662425e3771f1532e640"},"cell_type":"code","source":"from keras.utils import np_utils\n\ny_train = np_utils.to_categorical(np.array(y_train), 5)\ny_test = np_utils.to_categorical(np.array(y_test), 5)\n\n\nx_train = np.array(x_train).astype(\"float32\")/255.\nx_test = np.array(x_test).astype(\"float32\")/255.\n\n\nprint(np.array(y_train).shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"42bc0cbf4319d3d94e1f5449f52de04fc6073521","trusted":true},"cell_type":"code","source":"#specify the green channel of the images..\nim = Image.fromarray(immatrix[1],'RGB')\nprint(\"level:\",imlabel[1])\nim","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"_uuid":"d9937da7d4e8adc07c9eb02274bb0f5cec6a4964","trusted":true},"cell_type":"code","source":"from sklearn.utils import shuffle\n\ndata,label = shuffle(immatrix, imlabel, random_state=42)\ntrain_data = [data,label]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a6fb15532a08d21e42038e698a0e6a7a3fa96e4d","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.hist(label)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c98367b6448554a929992cdf58dcd2c0f24bbd9d","trusted":true},"cell_type":"code","source":"from keras.applications import InceptionResNetV2\nfrom keras.preprocessing import image\nfrom keras.models import Model\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.layers import Input\nfrom keras.applications import VGG16\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications import MobileNet\nfrom keras.applications import InceptionResNetV2\n\ndef create_model(input_shape, n_out):\n    pretrain_model = InceptionResNetV2(\n        include_top=False, \n        weights='imagenet', \n        input_shape=input_shape)    \n    input_tensor = Input(shape=input_shape)\n    bn = BatchNormalization()(input_tensor)\n    x = pretrain_model(bn)\n    x = Conv2D(128, kernel_size=(1,1), activation='relu')(x)\n    x = Flatten()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.5)(x)\n    output = Dense(n_out, activation='sigmoid')(x)\n    model = Model(input_tensor, output)\n    \n    return model\n#x = GlobalAveragePooling2D()(backbone.output)\n#outputs = Dense(5, activation=\"softmax\")(x)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6e6d5093be00ebe79a7cef68ffb0aa691317d8a2"},"cell_type":"code","source":"keras.backend.clear_session()\n\nmodel = create_model(\n    input_shape=x_train[0].shape, \n    n_out=5)\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save_weights('inceptionResNetv2_model_wieghts.h5')\nmodel.save('inceptionResNetv2_model_keras.h5')\nmodel_json=model.to_json()\nwith open(\"model.json\", \"w\")as json_file:\n    json_file.write(model_json)\n\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c69af0b5ae2ef1f1412783872cb5483b390e6fac","trusted":true},"cell_type":"code","source":"def f1(y_true, y_pred):\n    tp = K.sum(K.cast(y_true*y_pred, 'float'), axis=0)\n    fp = K.sum(K.cast((1-y_true)*y_pred, 'float'), axis=0)\n    fn = K.sum(K.cast(y_true*(1-y_pred), 'float'), axis=0)\n\n    p = tp / (tp + fp + K.epsilon())\n    r = tp / (tp + fn + K.epsilon())\n\n    f1 = 2*p*r / (p+r+K.epsilon())\n    f1 = tf.where(tf.is_nan(f1), tf.zeros_like(f1), f1)\n    return K.mean(f1)\n\ndef show_history(history):\n    fig, ax = plt.subplots(1, 3, figsize=(15,5))\n    ax[0].set_title('loss')\n    ax[0].plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n    ax[0].plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n    ax[1].set_title('f1')\n    ax[1].plot(history.epoch, history.history[\"f1\"], label=\"Train f1\")\n    ax[1].plot(history.epoch, history.history[\"val_f1\"], label=\"Validation f1\")\n    ax[2].set_title('acc')\n    ax[2].plot(history.epoch, history.history[\"acc\"], label=\"Train acc\")\n    ax[2].plot(history.epoch, history.history[\"val_acc\"], label=\"Validation acc\")\n    ax[0].legend()\n    ax[1].legend()\n    ax[2].legend()\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fdb13671dd26fcf286f7119e58b401a92c778975"},"cell_type":"code","source":"#from keras.optimizers import SGD\n#from tensorflow.keras.optimizers import RMSprop\nimport torchvision\nfrom numpy import *\nhistory_InceptionResNetV2 =  model.compile(optimizer=Adam(1e-3)\n\n                    , loss='binary_crossentropy'\n                    , metrics=['acc',f1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"93324097fb68be60e1a41a4ca369343276162904","trusted":true},"cell_type":"code","source":"def brightness_adjustment(img):\n    # turn the image into the HSV space\n    hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n    # creates a random bright\n    ratio = .5 + np.random.uniform()\n    # convert to int32, so you don't get uint8 overflow\n    # multiply the HSV Value channel by the ratio\n    # clips the result between 0 and 255\n    # convert again to uint8\n    hsv[:,:,2] =  np.clip(hsv[:,:,2].astype(np.int32) * ratio, 0, 255).astype(np.uint8)\n    # return the image int the BGR color space\n    return cv2.cvtColor(hsv, cv2.COLOR_HSV)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use augmentation to increase the number of dataset and solve overfitting problems..\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy\nX_train = numpy.array(x_train, copy=True) \nY_train = numpy.array(y_train, copy=True) \nshift = 0.2\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=360,\n   preprocessing_function=brightness_adjustment,\n                                   width_shift_range=shift,\n                                   height_shift_range=shift, shear_range=0.2,\n                                   zoom_range=0.2, channel_shift_range=4.,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rescale=1. /255,\n#zca_whitening = True                                 \nfill_mode='nearest') \n\ndatagen.fit(x_train)\n\n#print(type(X_train2))\n#print(type(x_train))\n\n# Concatenating the old data with the augmented data\ntrain_x  = numpy.concatenate((x_train, X_train), axis=0)\ntrain_y  = numpy.concatenate((y_train, Y_train), axis=0)\nprint(train_x.shape)\nprint(train_y.shape)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"273d13131a9cc2f7267b945e8797051b2d47e6ca","trusted":true},"cell_type":"code","source":"from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n\nbest_save_model_file = '../working/inception_model.h5'\ncallbacks = [EarlyStopping(monitor='val_loss',\n                           patience=20,\n                           verbose=1,\n                           min_delta=0.00001,\n                           mode='min'),\n             ReduceLROnPlateau(monitor='val_loss',\n                               factor=0.1,\n                               patience=2,\n                               verbose=1,\n                               min_delta=0.0001,\n                               mode='min'),\n             ModelCheckpoint(monitor='val_loss',save_weights_only=True,\n                             filepath=best_save_model_file,\n                             save_best_only=True,\n                             mode='min') ,\n             ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history_InceptionResNetV2 =model.fit(train_x, train_y, batch_size = 32, epochs=100,validation_split=0.1, verbose=1,\n                               shuffle=True)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"eca9db197986d17a821c972617e870e820b38f69","trusted":true},"cell_type":"code","source":"#history_inceptionv3= model.compile(loss='binary_crossentropy', optimizer = keras.optimizers.Adam(lr=0.0001), metrics=['acc', f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#use augmentation to increase the number of dataset and solve overfitting problems..\nfrom keras.preprocessing.image import ImageDataGenerator\nimport numpy\nX_test = numpy.array(x_test, copy=True) \nY_test = numpy.array(y_test, copy=True) \nshift = 0.2\ndatagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=360,\n   preprocessing_function=brightness_adjustment,\n                                   width_shift_range=shift,\n                                   height_shift_range=shift, shear_range=0.2,\n                                   zoom_range=0.2, channel_shift_range=4.,\n                                   horizontal_flip=True, vertical_flip=True,\n                                   rescale=1. /255,\n#zca_whitening = True                                 \nfill_mode='nearest') \n\ndatagen.fit(x_test)\n\n#print(type(X_train2))\n#print(type(x_train))\n\n# Concatenating the old data with the augmented data\ntest_x  = numpy.concatenate((x_test, X_test), axis=0)\ntest_y  = numpy.concatenate((y_test, Y_test), axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5fb2d7ecc6752621fbbceafc9d1d72778560b1de"},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\npred_Y = model.predict(test_x, batch_size = 16, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)\ntest_Y_cat = np.argmax(test_y, -1)\nprint('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))\nprint(classification_report(test_Y_cat, pred_Y_cat))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"48ba44d9d73e8882d01bae2a2dc6219e31bee490"},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(test_Y_cat, pred_Y_cat), \n            annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = test_x.shape[0]//16)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_history(history_InceptionResNetV2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t=154\ntest=test_x[t].reshape(-1,350,350,3)\narr=model.predict(test)\narr=arr.flatten()\n\nmaxm=arr[0]\nfor i in range(0,5):\n    if(arr[i]>=maxm):\n        predicted_label=i+1\n        maxm=arr[i]\nfor i in range(0,5):\n    if(int(test_y[t][i])==1):\n        actual_label=i+1\n        break\nname={1:\"NO level of Diabetic Retinopathy\",2:\"MILD level of Diabetic Retinopathy\",3:\"MODERATE level of Diabetic Retinopathy\",4:\"SEVERE level of Diabetic Retinopathy\",5:\"PROLIFERATIVE level of Diabetic Retinopathy\"\n}\n\nimport matplotlib.pyplot as plt\nplt.imshow(x_test[t])\nplt.show\n\nprint(\"Predicted  : The patient is having \" + name[predicted_label])\nprint(\"Expected   : The patient should have \"+name[actual_label])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"37d61472d0217bc4ac64b405dd7ddd4f35675c03","trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score, classification_report\npred_Y = model.predict(test_x, batch_size = 16, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)\ntest_Y_cat = np.argmax(test_y, -1)\nprint('Accuracy on Test Data: %2.2f%%' % (accuracy_score(test_Y_cat, pred_Y_cat)))\nprint(classification_report(test_Y_cat, pred_Y_cat))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"71baa2c3f66a204c4c39870ea01f8f43c56a2a91","trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\nsns.heatmap(confusion_matrix(test_Y_cat, pred_Y_cat), \n            annot=True, fmt=\"d\", cbar = False, cmap = plt.cm.Blues, vmax = test_x.shape[0]//16)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3f28170f51950ba901454524daae772003b8aaf7","trusted":true},"cell_type":"code","source":"score = model.evaluate(test_x,test_y, verbose=0)\nprint(score)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d304380df8352b3d4602b91165a9751c87cc9e97","trusted":true,"scrolled":true},"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\nsick_vec = test_Y_cat>0\nsick_score = np.sum(pred_Y[:,1:],1)\nfpr, tpr, _ = roc_curve(sick_vec, sick_score)\nfig, ax1 = plt.subplots(1,1, figsize = (6, 6), dpi = 150)\nax1.plot(fpr, tpr, 'b.-', label = 'Model Prediction (AUC: %2.2f)' % roc_auc_score(sick_vec, sick_score))\nax1.plot(fpr, fpr, 'g-', label = 'Random Guessing')\nax1.legend()\nax1.set_xlabel('False Positive Rate')\nax1.set_ylabel('True Positive Rate');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"26fb8f44205c4e4a2e34731da1e74d5a8a0dbca0"},"cell_type":"code","source":"score = model.evaluate(test_x, test_y , verbose=0)\nprint(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f5724a155d3eebd3293b34bcaa97d9a2b3116197"},"cell_type":"code","source":"show_history(history_inceptionvResNetV2)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a44e495a61613676761bfba836801fa7d0b10626","trusted":true},"cell_type":"code","source":"results = pd.DataFrame({'ImageId': pd.Series(range(1, len(test_Y_cat) + 1)), 'Label': pd.Series(pred_Y_cat)})\nresults.to_csv('results.csv', index=False)\nresults.head(200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c3f2befccba5609621e82782a24cc8c6d09ecfb"},"cell_type":"markdown","source":"from sklearn import metrics\nprint(metrics.accuracy_score(test_Y_cat, pred_Y_cat))\nconfusion = metrics.confusion_matrix(test_Y_cat, pred_Y_cat)\nTP = confusion[1, 1]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]"},{"metadata":{"trusted":true,"_uuid":"5a0311978f57512d93d433b6d53d4772d8aea339"},"cell_type":"markdown","source":"\n#Also known as \"Misclassification Rate\"\n\nprint((FP + FN) / float(TP + TN + FP + FN))\nprint(1 - metrics.accuracy_score(test_Y_cat, pred_Y_cat))"},{"metadata":{"trusted":true,"_uuid":"cdc99f999c6c13d7602d921773679c1cd1ac41f8"},"cell_type":"markdown","source":"#Sensitivity: When the actual value is positive, how often is the prediction correct?\n\n###How \"sensitive\" is the classifier to detecting positive instances?\n#Also known as \"True Positive Rate\" or \"Recall\"\n\nprint(TP / float(TP + FN))\nprint(metrics.recall_score(test_Y_cat, pred_Y_cat))"},{"metadata":{"trusted":true,"_uuid":"3f271206ac3a2ca71771105641018f083448962a"},"cell_type":"markdown","source":"#Specificity: When the actual value is negative, how often is the prediction correct?\n\n#How \"specific\" (or \"selective\") is the classifier in predicting positive instances?\n\nprint(TN / float(TN + FP))\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"\n#False Positive Rate: When the actual value is negative, how often is the prediction incorrect?\n\n\nprint(FP / float(TN + FP))"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}