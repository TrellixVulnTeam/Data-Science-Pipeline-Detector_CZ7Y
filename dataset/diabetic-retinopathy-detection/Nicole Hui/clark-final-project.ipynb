{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"!pip install tensorflow-gpu\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \nfrom tensorflow.keras import *\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import  Dense, Activation, Flatten, Dropout, BatchNormalization\n# import keras\n# from keras import models\n# from keras import layers \nfrom tensorflow.keras.models import Sequential \n# from keras_preprocessing.image import ImageDataGenerator\n# from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n# from keras.layers import Conv2D, MaxPooling2D\n# from keras import regularizers, optimizers\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nfrom skimage.io import imread\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# import os\n# # data_train_file = pd.read_csv('train.zip.001/input')\n# print(os.listdir(\"../input/\"))\n# # shows specific image\n# img = mpimg.imread('../input/diabetic-retinopathy-detection/36_right.jpeg')\n# # plt.imshow(img)\n# # data_train_file = 'train.zip.001'\n# # df_train = pd.read_csv(data_train_file)\n# # Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\n# data_train_file = pd.read_csv('train.zip.001/input')\nprint(os.listdir(\"../input/\"))\n# shows specific image\nimg = mpimg.imread('../input/diabetic-retinopathy-detection/627_right.jpeg')\nplt.imshow(img)\n# data_train_file = 'train.zip.001'\n# df_train = pd.read_csv(data_train_file)\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/retinopathy-solution/retinopathy_solution.csv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df = pd.trainLabels(np.random.randn(100, 2))\n\n# msk = np.random.rand(len(df)) < 0.8\n\n# train = df[msk]\n\n# In [14]: test = df[~msk]\n\ntrainLabels = pd.read_csv('../input/diabetic-retinopathy-detection/trainLabels.csv')\n\nprint(len(trainLabels))\n\n# converts elements in \"level\" column to string so we can use sparse as a parameter flow_rom_dataframe \ntrainLabels.level = trainLabels.level.map(lambda x: str(x))\n\n# edits the trainLabels datafram so that elements of the \"image\" column match case with names of unzipped file\ntrainLabels.image = trainLabels.image.map(lambda f: f + '.jpeg')\ntrainLabels\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../lib/kaggle","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating new dataframe of only unzipped files (had to merge two dataframes together)\nfrom sklearn.model_selection import train_test_split\n\ndf_list = os.listdir(\"../input/diabetic-retinopathy-detection\")\ndf = pd.DataFrame(df_list, columns = [\"image\"])\ndf = pd.merge(df, trainLabels, on=['image'], how='inner')\n# df['level'].value_counts()\ntrain, test = train_test_split(df, test_size=0.1)\ntrain, validation = train_test_split(train, test_size = 0.2222)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train\ntrain['level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation\nvalidation['level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test\ntest['level'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.4,\n    height_shift_range=0.4,\n    shear_range=0.4,\n    zoom_range=0.4,\n    horizontal_flip=True,\n    validation_split = .222222)\n\ntest_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=40,\n    width_shift_range=0.4,\n    height_shift_range=0.4,\n    shear_range=0.4,\n    zoom_range=0.4,\n    horizontal_flip=True)\n# creating batches of augumented and normalized data\n\ntrain_generator = datagen.flow_from_dataframe(\ndataframe = train,\ndirectory = \"../input/diabetic-retinopathy-detection\",\nx_col = \"image\",\ny_col = \"level\",\nsubset = 'training',\nbatch_size = 32,\nseed = None,\nshuffle = True,\ncolor_mode='rgb',\nclass_mode = 'sparse',\ndrop_duplicates = True,\nsave_prefix = '',\ntarget_size = (28, 28))\n\nvalidation_generator = datagen.flow_from_dataframe(\ndataframe = train,\ndirectory = '../input/diabetic-retinopathy-detection',\nx_col = \"image\",\ny_col = \"level\",\nsubset = 'validation',\nbatch_size = 32,\nseed = None,\nshuffle = True,\ncolor_mode='rgb',\nclass_mode = 'sparse',\ndrop_duplicates = True,\nsave_prefix = '',\ntarget_size = (28, 28))\n\ntest_generator = test_datagen.flow_from_dataframe(\ndataframe = test,\ndirectory = '../input/diabetic-retinopathy-detection',\nx_col = \"image\",\ny_col = \"level\",\nsubset = None,\nbatch_size = 32,\nseed = None,\nshuffle = True,\ncolor_mode='rgb',\nclass_mode = 'sparse',\ndrop_duplicates = True,\nsave_prefix = '',\ntarget_size = (28, 28))\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = Sequential()\n\nmodel.add(layers.Conv2D(32, (3, 3), input_shape=(28, 28, 3)))\nmodel.add(BatchNormalization(axis=-1))\nconvLayer01 = layers.Activation('relu')                    \nmodel.add(convLayer01)\n\nmodel.add(layers.Conv2D(32, (3, 3)))\nmodel.add(BatchNormalization(axis=-1))\nmodel.add(Activation('relu'))                    \nconvLayer02 = layers.MaxPooling2D(pool_size=(2,2)) \nmodel.add(convLayer02)\nmodel.add(Dropout(0.25))\n\n\nmodel.add(layers.Conv2D(64,(3, 3)))                         # 64 different 3x3 kernels -- so 64 feature maps\nmodel.add(BatchNormalization(axis=-1))               # normalize each feature map before activation\nconvLayer03 = Activation('relu')                     # activation\nmodel.add(convLayer03)\n\nmodel.add(layers.Conv2D(64, (3, 3)))\nmodel.add(BatchNormalization(axis=-1))    \nmodel.add(Activation('relu'))  \nconvLayer04 = layers.MaxPooling2D(pool_size=(2,2)) \nmodel.add(convLayer04)\nmodel.add(Dropout(0.25))\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(512, kernel_regularizer=regularizers.l2(0.003)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))  \nmodel.add(Dropout(0.5)) \nmodel.add(layers.Dense(5))\nmodel.add(Activation('softmax')) \nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# from keras.utils import to_categorical\n# y_binary = to_categorical(train_generator ,num_classes=None, dtype = 'float32') \nmodel.compile(loss = \"sparse_categorical_crossentropy\", optimizer = keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n              metrics =['acc'])\n\nhistory = model.fit_generator(\n    train_generator,\n    callbacks=[keras.callbacks.TensorBoard(log_dir='../logs/')],\n    validation_data=validation_generator,\n    #       steps_per_epoch=100,\n      epochs=30)\n\n# model.save('model.h5')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'b', label='Training acc')\nplt.plot(epochs, val_acc, 'r', label='Validation acc')\nplt.title('Training and validation accuracy')\nplt.legend()\nplt.figure\nplt.show()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.figure()\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.evaluate_generator(generator=test_generator)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# The predict_classes function outputs the highest probability class\n# according to the trained classifier for each input example.\npredicted_classes = model.predict_generator(generator = test_generator)\nprint(predicted_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ig, m_axs = plt.subplots(2, 4, figsize = (32, 20))\n# for (idx, c_ax) in enumerate(m_axs.flatten()):\n#     c_ax.imshow(np.clip(test_X[idx]*127+127,0 , 255).astype(np.uint8), cmap = 'bone')\n#     c_ax.set_title('Actual Severity: {}\\n{}'.format(test_Y_cat[idx], \n#                                                            '\\n'.join(['Predicted %02d (%04.1f%%): %s' % (k, 100*v, '*'*int(10*v)) for k, v in sorted(enumerate(pred_Y[idx]), key = lambda x: -1*x[1])])), loc='left')\n#     c_ax.axis('off')\n# fig.savefig('trained_img_predictions.png', dpi = 300)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!tar -czvf logs.tar ../logs","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}