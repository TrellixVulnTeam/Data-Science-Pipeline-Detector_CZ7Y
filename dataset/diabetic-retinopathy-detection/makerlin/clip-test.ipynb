{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-20T04:15:42.095819Z","iopub.execute_input":"2021-09-20T04:15:42.096874Z","iopub.status.idle":"2021-09-20T04:15:42.106187Z","shell.execute_reply.started":"2021-09-20T04:15:42.096803Z","shell.execute_reply":"2021-09-20T04:15:42.105322Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ftfy regex tqdm\n!pip install git+https://github.com/openai/CLIP.git\n!git clone https://gitee.com/oscarlin/clip-cross-domain-test.git","metadata":{"execution":{"iopub.status.busy":"2021-09-20T04:15:44.651196Z","iopub.execute_input":"2021-09-20T04:15:44.651454Z","iopub.status.idle":"2021-09-20T04:16:01.452656Z","shell.execute_reply.started":"2021-09-20T04:15:44.651426Z","shell.execute_reply":"2021-09-20T04:16:01.451852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%cd ./clip-cross-domain-test","metadata":{"execution":{"iopub.status.busy":"2021-09-20T04:16:07.253674Z","iopub.execute_input":"2021-09-20T04:16:07.254249Z","iopub.status.idle":"2021-09-20T04:16:07.260776Z","shell.execute_reply.started":"2021-09-20T04:16:07.25421Z","shell.execute_reply":"2021-09-20T04:16:07.26005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport pandas as pd\nfrom PIL import Image\nclass RetinopathyDataset(Dataset):\n    def __init__(self, path, csv_path, transform):\n        self.transform = transform\n        self.img_folder_path = path\n        df = pd.read_csv(csv_path)\n        self.classes = ['no','mild','moderate','severe','proliferative']\n        data = {}\n        for k,v in df.groupby('level'):\n            if len(v) < 1000:\n                data[k] = v\n            else:\n                data[k] = v.iloc[:len(v),:]\n        self.data = pd.concat([data[i] for i in range(5)],axis=0)\n    def __len__(self):\n        return len(self.data)\n    def __getitem__(self, index):\n        img_name,label = self.data.iloc[index,:].values\n        img_path = os.path.join(self.img_folder_path, img_name)\n        img_path += '.jpeg'\n        img = Image.open(img_path)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, label   ","metadata":{"execution":{"iopub.status.busy":"2021-09-20T04:16:10.676818Z","iopub.execute_input":"2021-09-20T04:16:10.67759Z","iopub.status.idle":"2021-09-20T04:16:11.392893Z","shell.execute_reply.started":"2021-09-20T04:16:10.677531Z","shell.execute_reply":"2021-09-20T04:16:11.392185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import clip\nimport torch\nfrom dataset import *\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader\nfrom utils import Metric\n#parser = argparse.ArgumentParser()\n#parser.add_argument(\"--vb\", help=\"visual backbone\", default='ViT-B-32.pt')\n#parser.add_argument(\"--n\", help=\"dataset name\", default='NICO')\n#parser.add_argument(\"--p\", help=\"folder path\", default='.')\n\n#args = parser.parse_args()\n\n# Load the model\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"use {} to inference\".format(device))\nmodel, preprocess = clip.load(\"RN50\", device)\n\nimage_folder_path = \"/kaggle/input/diabetic-retinopathy-resized/resized_train/resized_train\"\ncsv_path = '/kaggle/input/diabetic-retinopathy-resized/trainLabels.csv'\ndataset = RetinopathyDataset(image_folder_path,csv_path,preprocess)\nBATCH_SIZE = 8\n\nmetric = Metric(dataset.classes)\nmetric.clear()\nloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, drop_last=False)\ntexts = torch.cat([clip.tokenize(f\"There is {c} diabetic retinopathy in this image\") for c in dataset.classes]).to(device)\nwith torch.no_grad():\n    for imgs, labels in tqdm(loader):\n        image_features = model.encode_image(imgs.to(device))\n        text_features = model.encode_text(texts)\n        # Pick the top 5 most similar labels for the image\n        image_features /= image_features.norm(dim=-1, keepdim=True)\n        text_features /= text_features.norm(dim=-1, keepdim=True)\n        similarity = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n        metric.update(similarity.cpu().type(torch.float32), labels)\n    metric.report()","metadata":{"execution":{"iopub.status.busy":"2021-09-20T04:16:12.964216Z","iopub.execute_input":"2021-09-20T04:16:12.96478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}