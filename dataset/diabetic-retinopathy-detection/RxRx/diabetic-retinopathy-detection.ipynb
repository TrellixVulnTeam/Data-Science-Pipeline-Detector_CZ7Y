{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Diabetic retinopathy detection**\n## **Author: [Dr. Rahul Remanan](https://www.linkedin.com/in/rahulremanan/)**\n## **CEO, [Moad Computer](http://www.moad.computer/)**","metadata":{"papermill":{"duration":0.056508,"end_time":"2022-06-19T15:03:15.677773","exception":false,"start_time":"2022-06-19T15:03:15.621265","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"# Configuration","metadata":{"papermill":{"duration":0.068802,"end_time":"2022-06-19T15:03:15.833693","exception":false,"start_time":"2022-06-19T15:03:15.764891","status":"completed"},"tags":[]}},{"cell_type":"code","source":"ROOT_DIR = '/kaggle/input'","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:03:15.955011Z","iopub.status.busy":"2022-06-19T15:03:15.954216Z","iopub.status.idle":"2022-06-19T15:03:15.957827Z","shell.execute_reply":"2022-06-19T15:03:15.957306Z","shell.execute_reply.started":"2022-06-19T12:38:43.584353Z"},"papermill":{"duration":0.067245,"end_time":"2022-06-19T15:03:15.957966","exception":false,"start_time":"2022-06-19T15:03:15.890721","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CONFIG():\n  NOTEBOOK_ID = 'diabetic-retinopathy-detection'\n  TRAIN_CSV = 'trainLabels.csv'\n\n  ENABLE_TRAINING = False\n  \n  BACKBONE = 'EfficientNetB0'\n\n  PRE_TRAINED_WEIGHTS = 'imagenet'\n\n  IMAGE_SIZE = (256, 256) # (512, 512)\n\n  EPOCHS = 1 # 20 #\n  \n  HORIZONTAL_FLIP = True\n  VERTICAL_FLIP = True\n  RANDOM_BRIGHTNESS = True\n  RANDOM_SATURATION = True\n  RANDOM_GAMMA = False\n  RANDOM_HUE = True\n  RANDOM_CONTRAST = True\n\n  TRAIN_ATTN_CONV = True\n    \n  BATCH_SIZE = 24 # 16 #\n    \n  SHUFFLE_BUFFER = max(BATCH_SIZE*25, 500) #\n\n  DROPOUT = 0.35\n\n  MODEL_SUMMARY = 'summary' # 'plot' #\n    \n  SAVED_WEIGHTS_DIR = f'{ROOT_DIR}/diabetic-retinopathy-detection-weights'\n  SAVED_WEIGHTS = 'output'\n  SAVED_ATTN_WEIGHTS = 'output_attn'  \n    \n  OUT_WEIGHTS = 'output.h5'  \n  OUT_ATTN_WEIGHTS = 'output_attn.h5'\n  \n  VERBOSE = True","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:03:16.111177Z","iopub.status.busy":"2022-06-19T15:03:16.109822Z","iopub.status.idle":"2022-06-19T15:03:16.112079Z","shell.execute_reply":"2022-06-19T15:03:16.110429Z","shell.execute_reply.started":"2022-06-19T12:38:43.66753Z"},"papermill":{"duration":0.100813,"end_time":"2022-06-19T15:03:16.112291","exception":false,"start_time":"2022-06-19T15:03:16.011478","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Imports","metadata":{"papermill":{"duration":0.054567,"end_time":"2022-06-19T15:03:16.223798","exception":false,"start_time":"2022-06-19T15:03:16.169231","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import os, gc, cv2, numpy as np, pandas as pd, tensorflow as tf, \\\n       tensorflow_addons as tfa,matplotlib.pyplot as plt\n\nfrom glob import glob\nfrom skimage.io import imread\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import backend as K\nfrom keras.applications.inception_v3 import preprocess_input\n\n%matplotlib inline ","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2022-06-19T15:03:16.339475Z","iopub.status.busy":"2022-06-19T15:03:16.338791Z","iopub.status.idle":"2022-06-19T15:03:22.844365Z","shell.execute_reply":"2022-06-19T15:03:22.84331Z","shell.execute_reply.started":"2022-06-19T12:38:43.745706Z"},"papermill":{"duration":6.566077,"end_time":"2022-06-19T15:03:22.844574","exception":false,"start_time":"2022-06-19T15:03:16.278497","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Manage training data","metadata":{"papermill":{"duration":0.053665,"end_time":"2022-06-19T15:03:22.952571","exception":false,"start_time":"2022-06-19T15:03:22.898906","status":"completed"},"tags":[]}},{"cell_type":"code","source":"zip_dir = os.path.join(ROOT_DIR, CONFIG.NOTEBOOK_ID)\ntrain_images_dir = '/tmp/train/'\ntrain_csv_dir = './'\nbase_image_dir = os.path.join(train_images_dir, 'train')","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:03:23.065542Z","iopub.status.busy":"2022-06-19T15:03:23.064626Z","iopub.status.idle":"2022-06-19T15:03:23.066443Z","shell.execute_reply":"2022-06-19T15:03:23.066927Z","shell.execute_reply.started":"2022-06-19T12:38:50.529671Z"},"papermill":{"duration":0.060632,"end_time":"2022-06-19T15:03:23.067055","exception":false,"start_time":"2022-06-19T15:03:23.006423","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper function to run OS commands from within Python","metadata":{"papermill":{"duration":0.054193,"end_time":"2022-06-19T15:03:23.174663","exception":false,"start_time":"2022-06-19T15:03:23.12047","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def linux_shell(cmd):\n  os.system(cmd)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:03:23.289563Z","iopub.status.busy":"2022-06-19T15:03:23.287644Z","iopub.status.idle":"2022-06-19T15:03:23.290216Z","shell.execute_reply":"2022-06-19T15:03:23.290622Z","shell.execute_reply.started":"2022-06-19T12:38:50.536489Z"},"papermill":{"duration":0.061264,"end_time":"2022-06-19T15:03:23.290751","exception":false,"start_time":"2022-06-19T15:03:23.229487","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Unzip the training data","metadata":{"papermill":{"duration":0.053637,"end_time":"2022-06-19T15:03:23.398554","exception":false,"start_time":"2022-06-19T15:03:23.344917","status":"completed"},"tags":[]}},{"cell_type":"code","source":"%%capture\nif len(glob(f'{base_image_dir}/*.jpeg')) != 35126:\n  cmds= ['apt-get install -y p7zip-full',\n         f'mkdir {train_images_dir}',\n         f'7z x {zip_dir}/train.zip.001 -o{train_images_dir}',\n         f'7z x {zip_dir}/trainLabels.csv.zip -o{train_csv_dir}',]\n  for c in cmds:\n    linux_shell(c)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:03:23.513049Z","iopub.status.busy":"2022-06-19T15:03:23.512271Z","iopub.status.idle":"2022-06-19T15:17:56.092709Z","shell.execute_reply":"2022-06-19T15:17:56.09338Z","shell.execute_reply.started":"2022-06-19T12:38:50.556025Z"},"papermill":{"duration":872.640801,"end_time":"2022-06-19T15:17:56.093578","exception":false,"start_time":"2022-06-19T15:03:23.452777","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create and process the training dataframe","metadata":{"papermill":{"duration":0.093999,"end_time":"2022-06-19T15:17:56.281879","exception":false,"start_time":"2022-06-19T15:17:56.18788","status":"completed"},"tags":[]}},{"cell_type":"code","source":"retina_df = pd.read_csv(os.path.join(train_csv_dir, CONFIG.TRAIN_CSV))","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:17:56.479894Z","iopub.status.busy":"2022-06-19T15:17:56.479063Z","iopub.status.idle":"2022-06-19T15:17:56.519565Z","shell.execute_reply":"2022-06-19T15:17:56.518954Z","shell.execute_reply.started":"2022-06-19T12:55:02.647383Z"},"papermill":{"duration":0.143746,"end_time":"2022-06-19T15:17:56.519735","exception":false,"start_time":"2022-06-19T15:17:56.375989","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(glob(f'{train_images_dir}/train/*.jpeg')))\nprint(len(retina_df))","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:17:56.639496Z","iopub.status.busy":"2022-06-19T15:17:56.638772Z","iopub.status.idle":"2022-06-19T15:17:56.756217Z","shell.execute_reply":"2022-06-19T15:17:56.755745Z","shell.execute_reply.started":"2022-06-19T12:55:02.690118Z"},"papermill":{"duration":0.178785,"end_time":"2022-06-19T15:17:56.75634","exception":false,"start_time":"2022-06-19T15:17:56.577555","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retina_df['PatientId'] = retina_df['image'].map(lambda x: x.split('_')[0])\nretina_df['path'] = retina_df['image'].map(\n                      lambda x: os.path.join(base_image_dir,\n                                             '{}.jpeg'.format(x))\n                      )\nretina_df['exists'] = retina_df['path'].map(os.path.exists)\nretina_df['eye'] = retina_df['image'].map(\n                     lambda x: 1 if x.split('_')[-1]=='left' else 0\n                     )\n\nretina_df['level_cat'] = retina_df['level'].map(\n                           lambda x: to_categorical(x, 1+retina_df['level'].max())\n                           )\n\nretina_df.dropna(inplace = True)\nretina_df = retina_df[retina_df['exists']]","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:17:56.884867Z","iopub.status.busy":"2022-06-19T15:17:56.88432Z","iopub.status.idle":"2022-06-19T15:17:59.85664Z","shell.execute_reply":"2022-06-19T15:17:59.856058Z","shell.execute_reply.started":"2022-06-19T12:55:02.816981Z"},"papermill":{"duration":3.040712,"end_time":"2022-06-19T15:17:59.856787","exception":false,"start_time":"2022-06-19T15:17:56.816075","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(retina_df['exists'].sum(), 'images found of', retina_df.shape[0], 'total')","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:17:59.994014Z","iopub.status.busy":"2022-06-19T15:17:59.99331Z","iopub.status.idle":"2022-06-19T15:17:59.996244Z","shell.execute_reply":"2022-06-19T15:17:59.996689Z","shell.execute_reply.started":"2022-06-19T12:55:05.842392Z"},"papermill":{"duration":0.073104,"end_time":"2022-06-19T15:17:59.99683","exception":false,"start_time":"2022-06-19T15:17:59.923726","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(retina_df.sample(3))","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:00.127998Z","iopub.status.busy":"2022-06-19T15:18:00.12727Z","iopub.status.idle":"2022-06-19T15:18:00.14061Z","shell.execute_reply":"2022-06-19T15:18:00.141029Z","shell.execute_reply.started":"2022-06-19T12:55:05.851073Z"},"papermill":{"duration":0.079787,"end_time":"2022-06-19T15:18:00.141177","exception":false,"start_time":"2022-06-19T15:18:00.06139","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Histogram summary of the training dataset","metadata":{"papermill":{"duration":0.058188,"end_time":"2022-06-19T15:18:00.259407","exception":false,"start_time":"2022-06-19T15:18:00.201219","status":"completed"},"tags":[]}},{"cell_type":"code","source":"retina_df[['level', 'eye']].hist(figsize = (10, 5))","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:00.386872Z","iopub.status.busy":"2022-06-19T15:18:00.386229Z","iopub.status.idle":"2022-06-19T15:18:00.773273Z","shell.execute_reply":"2022-06-19T15:18:00.772583Z","shell.execute_reply.started":"2022-06-19T12:55:07.161752Z"},"papermill":{"duration":0.453809,"end_time":"2022-06-19T15:18:00.773402","exception":false,"start_time":"2022-06-19T15:18:00.319593","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-validation split","metadata":{"papermill":{"duration":0.060904,"end_time":"2022-06-19T15:18:00.895087","exception":false,"start_time":"2022-06-19T15:18:00.834183","status":"completed"},"tags":[]}},{"cell_type":"code","source":"rr_df = retina_df[['PatientId', 'level']].drop_duplicates()\ntrain_ids, valid_ids = train_test_split(\n                         rr_df['PatientId'], \n                         test_size = 0.25, \n                         random_state = 2018, \n                         stratify = rr_df['level']\n                         )\nraw_train_df = retina_df[retina_df['PatientId'].isin(train_ids)]\nval_df = retina_df[retina_df['PatientId'].isin(valid_ids)]","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:01.027818Z","iopub.status.busy":"2022-06-19T15:18:01.02687Z","iopub.status.idle":"2022-06-19T15:18:01.05619Z","shell.execute_reply":"2022-06-19T15:18:01.055713Z","shell.execute_reply.started":"2022-06-19T12:55:07.569314Z"},"papermill":{"duration":0.100612,"end_time":"2022-06-19T15:18:01.056314","exception":false,"start_time":"2022-06-19T15:18:00.955702","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('train', raw_train_df.shape[0], 'validation', val_df.shape[0])","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:01.182662Z","iopub.status.busy":"2022-06-19T15:18:01.181984Z","iopub.status.idle":"2022-06-19T15:18:01.184815Z","shell.execute_reply":"2022-06-19T15:18:01.185394Z","shell.execute_reply.started":"2022-06-19T12:55:07.607604Z"},"papermill":{"duration":0.068347,"end_time":"2022-06-19T15:18:01.185546","exception":false,"start_time":"2022-06-19T15:18:01.117199","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Balance the training data","metadata":{"papermill":{"duration":0.059486,"end_time":"2022-06-19T15:18:01.30508","exception":false,"start_time":"2022-06-19T15:18:01.245594","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_df = raw_train_df.groupby(['level', 'eye']).apply(\n             lambda x: x.sample(75, replace = True)\n             ).reset_index(drop = True)\ntrain_df[['level', 'eye']].hist(figsize = (10, 5))","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:01.433266Z","iopub.status.busy":"2022-06-19T15:18:01.432224Z","iopub.status.idle":"2022-06-19T15:18:01.810787Z","shell.execute_reply":"2022-06-19T15:18:01.811201Z","shell.execute_reply.started":"2022-06-19T12:55:07.615785Z"},"papermill":{"duration":0.445261,"end_time":"2022-06-19T15:18:01.811356","exception":false,"start_time":"2022-06-19T15:18:01.366095","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('New data size:', train_df.shape[0], 'Old Size:', raw_train_df.shape[0])","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:01.940587Z","iopub.status.busy":"2022-06-19T15:18:01.93989Z","iopub.status.idle":"2022-06-19T15:18:01.942636Z","shell.execute_reply":"2022-06-19T15:18:01.943027Z","shell.execute_reply.started":"2022-06-19T12:55:08.003853Z"},"papermill":{"duration":0.069808,"end_time":"2022-06-19T15:18:01.943177","exception":false,"start_time":"2022-06-19T15:18:01.873369","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train-validation data generators","metadata":{"papermill":{"duration":0.061558,"end_time":"2022-06-19T15:18:02.065607","exception":false,"start_time":"2022-06-19T15:18:02.004049","status":"completed"},"tags":[]}},{"cell_type":"code","source":"@tf.function\ndef tf_load_image(path)->tf.Tensor:\n  \"\"\" Load an image with the correct shape using only TF\n    \n  Args:\n      path (tf.string): Path to the image to be loaded\n      resize_to (tuple, optional): Size to reshape image\n    \n  Returns:\n      3 channel tf.Constant image ready for training/inference\n  \"\"\"\n  img_bytes = tf.io.read_file(path)\n  img = tf.image.decode_jpeg(img_bytes, channels=3)\n  img = 255.*((img-tf.reduce_min(img))/(tf.reduce_max(img) - tf.reduce_min(img)))\n  img = tf.image.resize(img, (tf.constant(CONFIG.IMAGE_SIZE[0]), \n                              tf.constant(CONFIG.IMAGE_SIZE[1])))\n  return img\n\n@tf.function\ndef tf_labels(y:tf.Tensor)->tf.Tensor:  \n  return tf.convert_to_tensor([y], tf.float32)\n\n@tf.function\ndef tf_img(img:tf.Tensor)->tf.Tensor:\n  return img\n\n@tf.function\ndef tf_pair_cond(img, true_fn, false_fn)->tf.Tensor:\n  p = tf.random.uniform([])<=tf.constant(0.5)   \n  img = tf.cond(\n           p, \n           lambda: tf.image.flip_left_right(img), \n           lambda: tf_img(img)\n           )\n  return img\n\n@tf.function\ndef tf_augment_batch(img:tf.Tensor, y:tf.Tensor)->tf.Tensor: \n  if CONFIG.HORIZONTAL_FLIP:\n    img = tf_pair_cond(img, tf.image.flip_left_right, tf_img)\n  if CONFIG.VERTICAL_FLIP:\n    img = tf_pair_cond(img, tf.image.flip_up_down, tf_img)\n  if CONFIG.RANDOM_BRIGHTNESS:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_brightness(img, 0.1), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_CONTRAST:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_contrast(img, 0.1, 0.125), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_GAMMA:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.adjust_gamma(img, 1e-6), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_HUE:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_hue(img, 0.1), \n           lambda: tf_img(img)\n           )\n  if CONFIG.RANDOM_SATURATION:\n    img = tf.cond(\n           tf.random.uniform([])<=tf.constant(0.5), \n           lambda: tf.image.random_saturation(img, 0.475, 0.525), \n           lambda: tf_img(img)\n           )\n  return img, y\n\n@tf.function\ndef tf_model_preprocessing_train(img:tf.Tensor, y:tf.Tensor)->tf.Tensor:\n  img = img/tf.constant(127.5)-tf.constant(1.0)\n  return img, y\n\n@tf.function\ndef tf_model_preprocessing_test(img:tf.Tensor, y:tf.Tensor)->tf.Tensor:\n  img = img/tf.constant(127.5)-tf.constant(1.0)\n  return img, y","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:02.209839Z","iopub.status.busy":"2022-06-19T15:18:02.208863Z","iopub.status.idle":"2022-06-19T15:18:02.210875Z","shell.execute_reply":"2022-06-19T15:18:02.211306Z","shell.execute_reply.started":"2022-06-19T12:55:08.012125Z"},"papermill":{"duration":0.084075,"end_time":"2022-06-19T15:18:02.211436","exception":false,"start_time":"2022-06-19T15:18:02.127361","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def df_make_dataset(df, autotune=None):\n  ds = tf.data.Dataset.from_tensor_slices((df.path, df.level_cat.to_list()))\n  ds = ds.map(lambda x,y: (tf_load_image(x), tf_labels(y)), num_parallel_calls=autotune)\n  return ds","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:02.341941Z","iopub.status.busy":"2022-06-19T15:18:02.34124Z","iopub.status.idle":"2022-06-19T15:18:02.343281Z","shell.execute_reply":"2022-06-19T15:18:02.343789Z","shell.execute_reply.started":"2022-06-19T12:55:08.035341Z"},"papermill":{"duration":0.071111,"end_time":"2022-06-19T15:18:02.343927","exception":false,"start_time":"2022-06-19T15:18:02.272816","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:02.47503Z","iopub.status.busy":"2022-06-19T15:18:02.474326Z","iopub.status.idle":"2022-06-19T15:18:02.47643Z","shell.execute_reply":"2022-06-19T15:18:02.47687Z","shell.execute_reply.started":"2022-06-19T12:55:08.050528Z"},"papermill":{"duration":0.070101,"end_time":"2022-06-19T15:18:02.477003","exception":false,"start_time":"2022-06-19T15:18:02.406902","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create train data generator","metadata":{"papermill":{"duration":0.061624,"end_time":"2022-06-19T15:18:02.60123","exception":false,"start_time":"2022-06-19T15:18:02.539606","status":"completed"},"tags":[]}},{"cell_type":"code","source":"train_ds = df_make_dataset(train_df, autotune=AUTOTUNE)\n\ntrain_ds = train_ds.shuffle(len(train_df))           \\\n                   .batch(CONFIG.BATCH_SIZE, \n                          drop_remainder=True)       \\\n                   .map(tf_augment_batch, \n                        num_parallel_calls=AUTOTUNE) \\\n                   .map(tf_model_preprocessing_train, \n                        num_parallel_calls=AUTOTUNE) \\\n                   .prefetch(AUTOTUNE)\ndel train_df","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:05.491111Z","iopub.status.busy":"2022-06-19T15:18:05.140702Z","iopub.status.idle":"2022-06-19T15:18:06.408847Z","shell.execute_reply":"2022-06-19T15:18:06.407979Z","shell.execute_reply.started":"2022-06-19T12:55:08.059354Z"},"papermill":{"duration":3.744704,"end_time":"2022-06-19T15:18:06.408998","exception":false,"start_time":"2022-06-19T15:18:02.664294","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Create validation data generator","metadata":{"papermill":{"duration":0.060682,"end_time":"2022-06-19T15:18:06.53431","exception":false,"start_time":"2022-06-19T15:18:06.473628","status":"completed"},"tags":[]}},{"cell_type":"code","source":"val_ds = df_make_dataset(val_df, autotune=AUTOTUNE)\nval_ds = val_ds.shuffle(len(val_df)//5)               \\\n               .batch(CONFIG.BATCH_SIZE//2, \n                      drop_remainder=True)            \\\n               .map(tf_model_preprocessing_train, \n                    num_parallel_calls=AUTOTUNE)      \\\n               .prefetch(AUTOTUNE)\ndel val_df","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:06.702618Z","iopub.status.busy":"2022-06-19T15:18:06.692418Z","iopub.status.idle":"2022-06-19T15:18:06.891806Z","shell.execute_reply":"2022-06-19T15:18:06.890912Z","shell.execute_reply.started":"2022-06-19T12:55:11.321755Z"},"papermill":{"duration":0.293744,"end_time":"2022-06-19T15:18:06.89195","exception":false,"start_time":"2022-06-19T15:18:06.598206","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize the data generator outputs","metadata":{"papermill":{"duration":0.062037,"end_time":"2022-06-19T15:18:07.016235","exception":false,"start_time":"2022-06-19T15:18:06.954198","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def plot_data(x, y, fig_size=(16, 8)):\n  fig, m_axs = plt.subplots(2, 4, figsize=fig_size)\n  for (c_x, c_y, c_ax) in zip(x, y, m_axs.flatten()):\n    c_ax.imshow(np.clip(c_x*127+127, 0, 255).astype(np.uint8))\n    c_ax.set_title('Severity {}'.format(np.argmax(c_y, -1)))\n    c_ax.axis('off')","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:07.146039Z","iopub.status.busy":"2022-06-19T15:18:07.145235Z","iopub.status.idle":"2022-06-19T15:18:07.147776Z","shell.execute_reply":"2022-06-19T15:18:07.14735Z","shell.execute_reply.started":"2022-06-19T12:55:11.729731Z"},"papermill":{"duration":0.070174,"end_time":"2022-06-19T15:18:07.147885","exception":false,"start_time":"2022-06-19T15:18:07.077711","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize train data generator","metadata":{"papermill":{"duration":0.06127,"end_time":"2022-06-19T15:18:07.270818","exception":false,"start_time":"2022-06-19T15:18:07.209548","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for t_x, t_y in train_ds.take(1):\n  plot_data(t_x, t_y)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:18:07.401859Z","iopub.status.busy":"2022-06-19T15:18:07.401325Z","iopub.status.idle":"2022-06-19T15:20:17.054281Z","shell.execute_reply":"2022-06-19T15:20:17.054902Z","shell.execute_reply.started":"2022-06-19T12:55:11.739017Z"},"papermill":{"duration":129.722494,"end_time":"2022-06-19T15:20:17.055146","exception":false,"start_time":"2022-06-19T15:18:07.332652","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize validation data generator","metadata":{"papermill":{"duration":0.069541,"end_time":"2022-06-19T15:20:17.198589","exception":false,"start_time":"2022-06-19T15:20:17.129048","status":"completed"},"tags":[]}},{"cell_type":"code","source":"for v_x, v_y in val_ds.take(1):\n  plot_data(v_x, v_y)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:20:17.345455Z","iopub.status.busy":"2022-06-19T15:20:17.344637Z","iopub.status.idle":"2022-06-19T15:25:46.05039Z","shell.execute_reply":"2022-06-19T15:25:46.050807Z","shell.execute_reply.started":"2022-06-19T12:57:23.860988Z"},"papermill":{"duration":328.781811,"end_time":"2022-06-19T15:25:46.050959","exception":false,"start_time":"2022-06-19T15:20:17.269148","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Input shape: ', t_x.shape[1:], '\\nNumber of classes:', t_y.shape[-1])","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:46.242575Z","iopub.status.busy":"2022-06-19T15:25:46.241525Z","iopub.status.idle":"2022-06-19T15:25:46.244677Z","shell.execute_reply":"2022-06-19T15:25:46.245079Z","shell.execute_reply.started":"2022-06-19T13:03:02.261313Z"},"papermill":{"duration":0.101708,"end_time":"2022-06-19T15:25:46.245244","exception":false,"start_time":"2022-06-19T15:25:46.143536","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Attention mechanism","metadata":{"papermill":{"duration":0.09077,"end_time":"2022-06-19T15:25:46.427283","exception":false,"start_time":"2022-06-19T15:25:46.336513","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def conv_attention(x:tf.Tensor, \n                   base_model, \n                   filter_dim:int=8, \n                   batch_size:int=8, \n                   dropout:int=0.2, \n                   padding:str='same', \n                   name:str='conv_attn', \n                   activation:str='relu',\n                   train_output_conv:bool=False, \n                   eager_execution:bool=True)->tf.Tensor:\n  attn = tf.keras.layers.Dropout(dropout, name=f'{name}_attn_dropout_in')(x)\n  for i, ff in enumerate([8, 2, 1]):\n    attn = tf.keras.layers.Conv2D(ff*filter_dim, \n                                  kernel_size=(1,1), \n                                  padding=padding, \n                                  activation=activation,\n                                  name=f'{name}_attn_conv2D_{ff*filter_dim}')(attn)\n    attn = tf.keras.layers.Dropout(dropout, name=f'{name}_attn_dropout_{i}')(attn) \n  attn = tf.keras.layers.Conv2D(1, kernel_size=(1,1), \n                                padding='valid', \n                                activation='sigmoid',\n                                name=f'{name}_attn_conv2D_1')(attn)\n  attn = tf.keras.layers.Dropout(dropout, name=f'{name}_attn_dropout_4')(attn)  \n  \n  base_depth = base_model.get_output_shape_at(0)[-1]\n  if eager_execution:\n    up_conv_wt = tf.ones((1, 1, 1, base_depth))\n  else:\n    up_conv_wt = np.ones((1, 1, 1, base_depth))\n\n  up_conv_2D = tf.keras.layers.Conv2D(base_depth, kernel_size=(1,1), padding='same', \n                                      activation='linear', use_bias=False, \n                                      weights=[up_conv_wt], name=f'{name}_attn_final')\n  up_conv_2D.trainable = train_output_conv\n  attn = up_conv_2D(attn)\n  out_feat = tf.keras.layers.multiply([attn, x], name=f'{name}_attn_out')\n  return out_feat, attn","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:46.624824Z","iopub.status.busy":"2022-06-19T15:25:46.623934Z","iopub.status.idle":"2022-06-19T15:25:46.625961Z","shell.execute_reply":"2022-06-19T15:25:46.626353Z","shell.execute_reply.started":"2022-06-19T13:03:02.270005Z"},"papermill":{"duration":0.106534,"end_time":"2022-06-19T15:25:46.62649","exception":false,"start_time":"2022-06-19T15:25:46.519956","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dense_attention(x:tf.Tensor, \n                    dropout:int=0.2, \n                    activation:str='relu', \n                    name:str='dense_attn',\n                    train_output_conv:bool=False, \n                    eager_execution:bool=True)->tf.Tensor:\n  x = tf.keras.layers.Dropout(dropout, name=f'{name}_attn_dropout_in')(x) \n  attn = tf.keras.layers.Dense(x.shape[1]*x.shape[2]*x.shape[3], \n                               activation=activation, name=f'{name}_attn_dense')(x)\n  attn = tf.keras.layers.Reshape((x.shape[1], x.shape[2], x.shape[3]),\n                                 name=f'{name}_attn_reshape')(x)\n  out_feat = tf.keras.layers.multiply([attn, x], name=f'{name}_attn_out')\n  return out_feat, attn","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:46.818482Z","iopub.status.busy":"2022-06-19T15:25:46.817734Z","iopub.status.idle":"2022-06-19T15:25:46.820376Z","shell.execute_reply":"2022-06-19T15:25:46.819906Z","shell.execute_reply.started":"2022-06-19T13:03:02.287918Z"},"papermill":{"duration":0.102982,"end_time":"2022-06-19T15:25:46.820488","exception":false,"start_time":"2022-06-19T15:25:46.717506","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Diabetic retinopathy classifier","metadata":{"papermill":{"duration":0.091625,"end_time":"2022-06-19T15:25:47.002434","exception":false,"start_time":"2022-06-19T15:25:46.910809","status":"completed"},"tags":[]}},{"cell_type":"markdown","source":"## Diabetic retinopathy classifier without the attention mechanism","metadata":{"papermill":{"duration":0.091202,"end_time":"2022-06-19T15:25:47.186879","exception":false,"start_time":"2022-06-19T15:25:47.095677","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def DiabeticRetinopathyClassifier(input_shape, \n                                  num_classes, \n                                  model, \n                                  fc_size=128, \n                                  batch_size=8,\n                                  dropout=0.25, \n                                  pre_trained_weights=None, \n                                  activation='relu', \n                                  name='retina_model', \n                                  train_all:bool=True, \n                                  train_output_conv:bool=False, \n                                  eager_execution:bool=True,\n                                  feature_dense:bool=True):\n  base_model = model(input_shape=input_shape, include_top=False, weights=pre_trained_weights)\n  base_model.trainable = False if (pre_trained_weights is not None or train_all) else True\n  inp = tf.keras.layers.Input(input_shape)\n  x = base_model(inp)\n  x = tf.keras.layers.Dropout(dropout, name=f'{name}_enc_dropout')(x) \n  x = tf.keras.layers.BatchNormalization(name=f'{name}_bn_inp')(x) \n  x = tf.keras.layers.Dropout(dropout, name=f'{name}_bn_dropout')(x)\n  gap = tf.keras.layers.GlobalAveragePooling2D(name=f'{name}_gap_')(x)\n  x = tf.keras.layers.Dropout(dropout, name=f'{name}_gap_dropout')(gap)\n  if feature_dense:\n    ft = tf.keras.layers.Dense(num_classes, activation=activation, name=f'{name}_feat')(gap)\n    x = tf.keras.layers.Dropout(dropout, name=f'{name}_feat_dropout')(ft)\n  if x.shape[1]==num_classes:  \n    x = tf.expand_dims(x, axis=1, name=f'{name}_reshape')  \n  out = tf.keras.layers.Dense(num_classes, activation='softmax', name=f'{name}_output')(x)\n  return tf.keras.Model(inputs=[inp], outputs=[out])","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:47.3813Z","iopub.status.busy":"2022-06-19T15:25:47.380406Z","iopub.status.idle":"2022-06-19T15:25:47.38295Z","shell.execute_reply":"2022-06-19T15:25:47.382519Z","shell.execute_reply.started":"2022-06-19T13:03:02.29871Z"},"papermill":{"duration":0.105118,"end_time":"2022-06-19T15:25:47.383059","exception":false,"start_time":"2022-06-19T15:25:47.277941","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Diabetic retinopathy classifier with attention mechanism","metadata":{"papermill":{"duration":0.092359,"end_time":"2022-06-19T15:25:47.565916","exception":false,"start_time":"2022-06-19T15:25:47.473557","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def DiabeticRetinopathyAttnClassifier(input_shape, \n                                      num_classes, \n                                      model, \n                                      fc_size=128,\n                                      batch_size=8, \n                                      dropout=0.25, \n                                      pre_trained_weights=None, \n                                      activation='relu', \n                                      name='retina_model', \n                                      train_all=True,\n                                      train_output_conv=False, \n                                      eager_execution=True):\n  base_model = model(input_shape=input_shape, include_top=False, weights=pre_trained_weights)\n  base_model.trainable = False if (pre_trained_weights is not None or train_all) else True\n  inp = tf.keras.layers.Input(input_shape)\n  x = base_model(inp)\n  x = tf.keras.layers.BatchNormalization(name=f'{name}_bn_inp')(x)\n  a, o = conv_attention(x, base_model, filter_dim=8, batch_size=batch_size,\n                        padding='same', name=name, activation=activation,\n                        dropout=dropout, train_output_conv=train_output_conv,\n                        eager_execution=eager_execution)\n  gap_feat = tf.keras.layers.GlobalAveragePooling2D(name=f'{name}_gap_feat')(o)\n  gap_mask = tf.keras.layers.GlobalAveragePooling2D(name=f'{name}_gap_mask')(a)\n  gap_feat = tf.keras.layers.Reshape((1,gap_mask.shape[1]),\n                                     name=f'{name}_reshape_feat')(gap_feat)   \n  gap_mask = tf.keras.layers.Reshape((1,gap_mask.shape[1]),\n                                     name=f'{name}_reshape_mask')(gap_mask) \n  gap = tf.keras.layers.Lambda(lambda x: x[0]/x[1], \n                               name=f'{name}_gap_rescale')([gap_feat, gap_mask])\n  gap = tf.keras.layers.Dropout(dropout, name=f'{name}_gap_dropout')(gap)\n  fc = tf.keras.layers.Dense(fc_size, activation=activation,\n                             name=f'{name}_fc_dense_{fc_size}')(gap)\n  fc = tf.keras.layers.Dropout(dropout, name=f'{name}_fc_dropout')(fc)\n  out = tf.keras.layers.Dense(num_classes, activation='softmax', name=f'{name}_output')(fc)\n  return tf.keras.Model(inputs=[inp], outputs=[out])","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:47.762751Z","iopub.status.busy":"2022-06-19T15:25:47.760932Z","iopub.status.idle":"2022-06-19T15:25:47.763353Z","shell.execute_reply":"2022-06-19T15:25:47.763803Z","shell.execute_reply.started":"2022-06-19T13:03:02.31363Z"},"papermill":{"duration":0.106294,"end_time":"2022-06-19T15:25:47.763945","exception":false,"start_time":"2022-06-19T15:25:47.657651","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"encoder = getattr(tf.keras.applications, CONFIG.BACKBONE)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:47.954992Z","iopub.status.busy":"2022-06-19T15:25:47.953949Z","iopub.status.idle":"2022-06-19T15:25:47.956037Z","shell.execute_reply":"2022-06-19T15:25:47.956547Z","shell.execute_reply.started":"2022-06-19T13:03:02.334691Z"},"papermill":{"duration":0.102554,"end_time":"2022-06-19T15:25:47.956704","exception":false,"start_time":"2022-06-19T15:25:47.85415","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_shape, num_classes = t_x.shape[1:], t_y.shape[-1]\n# input_shape, num_classes = (512, 512, 3), 5\nprint(input_shape, num_classes)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:48.18048Z","iopub.status.busy":"2022-06-19T15:25:48.17865Z","iopub.status.idle":"2022-06-19T15:25:48.183217Z","shell.execute_reply":"2022-06-19T15:25:48.182495Z","shell.execute_reply.started":"2022-06-19T13:03:02.343889Z"},"papermill":{"duration":0.119271,"end_time":"2022-06-19T15:25:48.183347","exception":false,"start_time":"2022-06-19T15:25:48.064076","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_retina_model(eager_execution:bool=True):\n  return DiabeticRetinopathyClassifier(\n           input_shape, num_classes, encoder,\n             batch_size=CONFIG.BATCH_SIZE, \n               train_output_conv=CONFIG.TRAIN_ATTN_CONV,\n                 pre_trained_weights=CONFIG.PRE_TRAINED_WEIGHTS, \n                   eager_execution=eager_execution\n           )\n\nretina_model = get_retina_model()","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:48.376048Z","iopub.status.busy":"2022-06-19T15:25:48.375435Z","iopub.status.idle":"2022-06-19T15:25:51.257628Z","shell.execute_reply":"2022-06-19T15:25:51.258446Z","shell.execute_reply.started":"2022-06-19T13:03:02.352769Z"},"papermill":{"duration":2.982405,"end_time":"2022-06-19T15:25:51.258625","exception":false,"start_time":"2022-06-19T15:25:48.27622","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_retina_attn_model(eager_execution:bool=True):\n  return DiabeticRetinopathyAttnClassifier(\n           input_shape, num_classes, encoder,\n             batch_size=CONFIG.BATCH_SIZE, \n               train_output_conv=CONFIG.TRAIN_ATTN_CONV,\n                 pre_trained_weights=CONFIG.PRE_TRAINED_WEIGHTS, \n                   name='retina_attn_model', \n                     eager_execution=eager_execution\n           )\n\nretina_attn_model = get_retina_attn_model()","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:51.456654Z","iopub.status.busy":"2022-06-19T15:25:51.456067Z","iopub.status.idle":"2022-06-19T15:25:53.542483Z","shell.execute_reply":"2022-06-19T15:25:53.542973Z","shell.execute_reply.started":"2022-06-19T13:03:05.071807Z"},"papermill":{"duration":2.19072,"end_time":"2022-06-19T15:25:53.543159","exception":false,"start_time":"2022-06-19T15:25:51.352439","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model summary","metadata":{"papermill":{"duration":0.092763,"end_time":"2022-06-19T15:25:53.729546","exception":false,"start_time":"2022-06-19T15:25:53.636783","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if CONFIG.MODEL_SUMMARY=='plot':\n  display(tf.keras.utils.plot_model(retina_model))\nelif CONFIG.MODEL_SUMMARY=='summary' and CONFIG.VERBOSE:\n  print(retina_model.summary())","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:53.924659Z","iopub.status.busy":"2022-06-19T15:25:53.92366Z","iopub.status.idle":"2022-06-19T15:25:53.943652Z","shell.execute_reply":"2022-06-19T15:25:53.943235Z","shell.execute_reply.started":"2022-06-19T13:03:07.501558Z"},"papermill":{"duration":0.120122,"end_time":"2022-06-19T15:25:53.943768","exception":false,"start_time":"2022-06-19T15:25:53.823646","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.MODEL_SUMMARY=='plot':\n  display(tf.keras.utils.plot_model(retina_attn_model))\nelif CONFIG.MODEL_SUMMARY=='summary' and CONFIG.VERBOSE:\n  print(retina_attn_model.summary())","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:54.151098Z","iopub.status.busy":"2022-06-19T15:25:54.149646Z","iopub.status.idle":"2022-06-19T15:25:54.159234Z","shell.execute_reply":"2022-06-19T15:25:54.158801Z","shell.execute_reply.started":"2022-06-19T13:03:07.526212Z"},"papermill":{"duration":0.122142,"end_time":"2022-06-19T15:25:54.159356","exception":false,"start_time":"2022-06-19T15:25:54.037214","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del retina_model, retina_attn_model; tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:54.352931Z","iopub.status.busy":"2022-06-19T15:25:54.352384Z","iopub.status.idle":"2022-06-19T15:25:54.359189Z","shell.execute_reply":"2022-06-19T15:25:54.358748Z","shell.execute_reply.started":"2022-06-19T13:03:07.555136Z"},"papermill":{"duration":0.106423,"end_time":"2022-06-19T15:25:54.359315","exception":false,"start_time":"2022-06-19T15:25:54.252892","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Custom callbacks for training","metadata":{"papermill":{"duration":0.094344,"end_time":"2022-06-19T15:25:54.548661","exception":false,"start_time":"2022-06-19T15:25:54.454317","status":"completed"},"tags":[]}},{"cell_type":"code","source":"class GarbageCollectorCallback(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    _ =  gc.collect()\n    tf.keras.backend.clear_session()","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:54.743471Z","iopub.status.busy":"2022-06-19T15:25:54.742834Z","iopub.status.idle":"2022-06-19T15:25:54.746237Z","shell.execute_reply":"2022-06-19T15:25:54.746609Z","shell.execute_reply.started":"2022-06-19T13:03:07.565599Z"},"papermill":{"duration":0.103272,"end_time":"2022-06-19T15:25:54.746757","exception":false,"start_time":"2022-06-19T15:25:54.643485","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train model","metadata":{"papermill":{"duration":0.095735,"end_time":"2022-06-19T15:25:54.936935","exception":false,"start_time":"2022-06-19T15:25:54.8412","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def train_model(train_ds, \n                val_ds, \n                epochs=1, \n                model=None, \n                fold=None,  \n                custom_objects=None, \n                opt='Adam', \n                metrics=['categorical_accuracy'], \n                saved_weights_dir='./', \n                saved_weights='output.h5', \n                out_dir='./',\n                dropout=0.25, \n                out_weights_file='output.h5', \n                learning_rate=1e-4):\n  opt = getattr(tf.keras.optimizers, opt)(learning_rate)\n\n  loss = 'categorical_crossentropy'\n\n  lr_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.75, \n                                               patience=2, verbose=1, mode='min')\n  es_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=4, mode='min',\n                                           verbose=1, restore_best_weights=True)\n  ckpt_file = f'./{out_weights_file}_{fold}.h5' if fold is not None else \\\n              f'./{out_weights_file}.h5'\n  ckpt_cb = tf.keras.callbacks.ModelCheckpoint(ckpt_file, monitor='val_loss', \n                                               mode='min', save_best_only=True)\n  gc_cb = GarbageCollectorCallback()\n  cb = [es_cb, ckpt_cb, lr_cb, #gc_cb\n       ]\n\n  model.compile(optimizer=opt, loss=loss, metrics=metrics)\n\n  if os.path.exists(os.path.join(saved_weights_dir, saved_weights)):\n    model.load_weights(os.path.join(saved_weights_dir, saved_weights))\n    print('Loaded weights: ', os.path.join(saved_weights_dir, saved_weights))\n    \n  model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=cb)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:55.140414Z","iopub.status.busy":"2022-06-19T15:25:55.138734Z","iopub.status.idle":"2022-06-19T15:25:55.14097Z","shell.execute_reply":"2022-06-19T15:25:55.141409Z","shell.execute_reply.started":"2022-06-19T13:03:07.573269Z"},"papermill":{"duration":0.107928,"end_time":"2022-06-19T15:25:55.141549","exception":false,"start_time":"2022-06-19T15:25:55.033621","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CONFIG.ENABLE_TRAINING:\n  retina_model = get_retina_model()  \n  train_model(train_ds, val_ds, model=retina_model, \n              epochs=CONFIG.EPOCHS, dropout=CONFIG.DROPOUT,\n              saved_weights_dir=CONFIG.SAVED_WEIGHTS_DIR, \n              saved_weights=CONFIG.SAVED_WEIGHTS, \n              out_weights_file=CONFIG.OUT_WEIGHTS)\n  del retina_model; tf.keras.backend.clear_session()\n  \n  retina_attn_model = get_retina_attn_model()  \n  train_model(train_ds, val_ds, model=retina_attn_model, \n              epochs=CONFIG.EPOCHS, dropout=CONFIG.DROPOUT,\n              saved_weights_dir=CONFIG.SAVED_WEIGHTS_DIR, \n              saved_weights=CONFIG.SAVED_ATTN_WEIGHTS, \n              out_weights_file=CONFIG.OUT_ATTN_WEIGHTS)","metadata":{"execution":{"iopub.execute_input":"2022-06-19T15:25:55.33961Z","iopub.status.busy":"2022-06-19T15:25:55.339015Z","iopub.status.idle":"2022-06-19T15:25:59.086159Z","shell.execute_reply":"2022-06-19T15:25:59.085585Z"},"papermill":{"duration":3.849911,"end_time":"2022-06-19T15:25:59.086427","exception":true,"start_time":"2022-06-19T15:25:55.236516","status":"failed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize attention mechanism","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"sample_img, sample_label = v_x[0].numpy(), v_y[0].numpy()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.774094Z","iopub.status.idle":"2022-06-19T13:34:37.774693Z","shell.execute_reply":"2022-06-19T13:34:37.774465Z","shell.execute_reply.started":"2022-06-19T13:34:37.77444Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Disable eager execution","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"tf.compat.v1.disable_eager_execution()\ntf.keras.backend.clear_session()","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.775959Z","iopub.status.idle":"2022-06-19T13:34:37.776541Z","shell.execute_reply":"2022-06-19T13:34:37.776321Z","shell.execute_reply.started":"2022-06-19T13:34:37.776293Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"retina_attn_model = get_retina_attn_model(eager_execution=False)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.77776Z","iopub.status.idle":"2022-06-19T13:34:37.778311Z","shell.execute_reply":"2022-06-19T13:34:37.77809Z","shell.execute_reply.started":"2022-06-19T13:34:37.778065Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_weights = os.path.join('./', CONFIG.SAVED_WEIGHTS)\nsaved_weights = os.path.join(CONFIG.SAVED_WEIGHTS_DIR, CONFIG.SAVED_WEIGHTS)\nif os.path.exists(trained_weights):\n  retina_attn_model.load_weights(trained_weights)\n  print('Loaded weights: ', trained_weights)\nelif os.path.exists(saved_weights):\n  retina_attn_model.load_weights(saved_weights)\n  print('Loaded weights: ', saved_weights)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.779395Z","iopub.status.idle":"2022-06-19T13:34:37.779943Z","shell.execute_reply":"2022-06-19T13:34:37.779737Z","shell.execute_reply.started":"2022-06-19T13:34:37.779711Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_attention_layer(attn_model, attn_layer=None):\n  if attn_layer is not None:\n    return attn_model.get_layer(attn_layer)\n  else:  \n    for i, _layer in enumerate(retina_model.layers):\n      _shape = _layer.get_output_shape_at(0)\n      if len(_shape)==4:\n        if _shape[-1]==1:\n          print(_layer)\n          print(_layer.name)\n          return _layer\n\nattn_layer = get_attention_layer(\n               retina_attn_model, attn_layer='retina_attn_model_attn_conv2D_1'\n               )","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.781018Z","iopub.status.idle":"2022-06-19T13:34:37.781565Z","shell.execute_reply":"2022-06-19T13:34:37.781362Z","shell.execute_reply.started":"2022-06-19T13:34:37.781336Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_attention(x, attn_model, attn_layer):\n  attn_inp = attn_model.input  \n  attn_fn = K.function(\n              inputs=[attn_model.input, K.learning_phase()],\n              outputs=[attn_layer.output]\n              )\n  return attn_fn([x, 0])","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.782646Z","iopub.status.idle":"2022-06-19T13:34:37.783176Z","shell.execute_reply":"2022-06-19T13:34:37.782973Z","shell.execute_reply.started":"2022-06-19T13:34:37.782947Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def heatmap_overlay(img, heatmap, threshold=0.8, read_file=False):\n  if read_file:\n    img = cv2.imread(img)\n  heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n  heatmap = np.uint8(255 * heatmap)\n  heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n  hif = threshold\n  superimposed_img = cv2.addWeighted(img,threshold,heatmap,1-threshold,0)\n  return superimposed_img, heatmap","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.78428Z","iopub.status.idle":"2022-06-19T13:34:37.784825Z","shell.execute_reply":"2022-06-19T13:34:37.784612Z","shell.execute_reply.started":"2022-06-19T13:34:37.784586Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the predictions and the attention map","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"def normalize_arr(arr):\n  return (arr - np.min(arr))/(np.max(arr) - np.min(arr))","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.785929Z","iopub.status.idle":"2022-06-19T13:34:37.78651Z","shell.execute_reply":"2022-06-19T13:34:37.786292Z","shell.execute_reply.started":"2022-06-19T13:34:37.786267Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_preds(img, label, model, attn_layer):\n  attn_img = np.array(get_attention(img, model, attn_layer))\n  img = np.clip(img[:,:,:]*127+127, 0, 255).astype(np.uint8)\n  attn_img = normalize_arr(attn_img[0, 0, :])\n  [out_img, attn_img] = heatmap_overlay(img, attn_img)\n  fig, m_axs = plt.subplots(1, 3, figsize = (8, 4))\n  [c_ax.axis('off') for c_ax in m_axs.flatten()]\n  for (img_ax, over_ax, attn_ax)  in [m_axs]:\n    img_ax.imshow(img)\n    over_ax.imshow(out_img)\n    attn_ax.imshow(attn_img, cmap='viridis', vmin=0, vmax=1, interpolation='lanczos')\n    real_cat = np.argmax(label)\n    img_ax.set_title(\n        'Eye image\\nCat:%2d' % (real_cat))\n    pred_cat = model.predict(np.expand_dims(img, axis=0))[0]\n    over_ax.set_title(\n        'Overlay of attention map\\nCat (Pred):%2d (%1d)' % (\n            real_cat,np.argmax(pred_cat)\n        )\n          )  \n    attn_ax.set_title('Attention map\\nProb:%2.2f%%' % (\n        np.max(100*pred_cat[0,real_cat])\n        )\n          )","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.787615Z","iopub.status.idle":"2022-06-19T13:34:37.788168Z","shell.execute_reply":"2022-06-19T13:34:37.787956Z","shell.execute_reply.started":"2022-06-19T13:34:37.787932Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = sample_img, sample_label\nfor i in range(3):\n  plot_preds(img, label, retina_attn_model, attn_layer)","metadata":{"execution":{"iopub.status.busy":"2022-06-19T13:34:37.78924Z","iopub.status.idle":"2022-06-19T13:34:37.789779Z","shell.execute_reply":"2022-06-19T13:34:37.789567Z","shell.execute_reply.started":"2022-06-19T13:34:37.789544Z"},"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References:\n**1. [This notebook is forked and modified from the diabetic retinopathy detection notebook authored by @manifoldix](https://www.kaggle.com/code/manifoldix/inceptionv3-for-retinopathy-gpu-hr)**\n\n**2. [Kaggle diabetic retinopathy dataset](https://www.kaggle.com/competitions/diabetic-retinopathy-detection)**","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]}},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}