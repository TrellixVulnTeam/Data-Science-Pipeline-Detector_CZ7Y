{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np \nimport xgboost as xgb\nfrom scipy.optimize import fmin_powell\nfrom ml_metrics import quadratic_weighted_kappa\n\ndef eval_wrapper(yhat, y):  \n    y = np.array(y)\n    y = y.astype(int)\n    yhat = np.array(yhat)\n    yhat = np.clip(np.round(yhat), np.min(y), np.max(y)).astype(int)   \n    return quadratic_weighted_kappa(yhat, y)\n    \ndef get_params():\n    \n    params = {}\n    params[\"objective\"] = \"reg:linear\"     \n    params[\"eta\"] = 0.05\n    params[\"min_child_weight\"] = 360\n    params[\"subsample\"] = 0.85\n    params[\"colsample_bytree\"] = 0.3\n    params[\"silent\"] = 1\n    params[\"max_depth\"] = 7\n    plst = list(params.items())\n\n    return plst\n    \ndef score_offset(data, bin_offset, sv, scorer=eval_wrapper):\n    # data has the format of pred=0, offset_pred=1, labels=2 in the first dim\n    data[1, data[0].astype(int)==sv] = data[0, data[0].astype(int)==sv] + bin_offset\n    score = scorer(data[1], data[2])\n    return score\n    \ndef apply_offsets(data, offsets):\n    for j in range(num_classes):\n        data[1, data[0].astype(int)==j] = data[0, data[0].astype(int)==j] + offsets[j]\n    return data\n\n# global variables\ncolumns_to_drop = ['Id', 'Response'] #, 'Medical_History_10','Medical_History_24']\nxgb_num_rounds = 720\nnum_classes = 8\nmissing_indicator = -1000\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Load the data using pandas\")\ntrain = pd.read_csv(\"../input/prudential-life-insurance-assessment/test.csv.zip\")\ntest = pd.read_csv(\"../input/prudential-life-insurance-assessment/train.csv.zip\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine train and test\nall_data = train.append(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Found at https://www.kaggle.com/marcellonegro/prudential-life-insurance-assessment/xgb-offset0501/run/137585/code\n# create any new variables    \nall_data['Product_Info_2_char'] = all_data.Product_Info_2.str[0]\nall_data['Product_Info_2_num'] = all_data.Product_Info_2.str[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# factorize categorical variables\nall_data['Product_Info_2'] = pd.factorize(all_data['Product_Info_2'])[0]\nall_data['Product_Info_2_char'] = pd.factorize(all_data['Product_Info_2_char'])[0]\nall_data['Product_Info_2_num'] = pd.factorize(all_data['Product_Info_2_num'])[0]\n\nall_data['BMI_Age'] = all_data['BMI'] * all_data['Ins_Age']\n\nmed_keyword_columns = all_data.columns[all_data.columns.str.startswith('Medical_Keyword_')]\nall_data['Med_Keywords_Count'] = all_data[med_keyword_columns].sum(axis=1)\n\nprint('Eliminate missing values')    \nall_data.fillna(missing_indicator, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix the dtype on the label column\nall_data['Response'] = all_data['Response'].astype(int)\n\n# split train and test\ntrain = all_data[all_data['Response']>0].copy()\ntest = all_data[all_data['Response']<1].copy()\n\n# convert data to xgb data structure\nxgtrain = xgb.DMatrix(train.drop(columns_to_drop, axis=1), train['Response'].values, \n                        missing=missing_indicator)\nxgtest = xgb.DMatrix(test.drop(columns_to_drop, axis=1), label=test['Response'].values, \n                        missing=missing_indicator) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get the parameters for xgboost\nplst = get_params()\nprint(plst)      \n\n# train model\nmodel = xgb.train(plst, xgtrain, xgb_num_rounds) \n\n# get preds\ntrain_preds = model.predict(xgtrain, ntree_limit=model.best_iteration)\nprint('Train score is:', eval_wrapper(train_preds, train['Response'])) \ntest_preds = model.predict(xgtest, ntree_limit=model.best_iteration)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train offsets \noffsets = np.array([0.1, -1, -2, -1, -0.8, 0.02, 0.8, 1])\noffset_preds = np.vstack((train_preds, train_preds, train['Response'].values))\noffset_preds = apply_offsets(offset_preds, offsets)\nopt_order = [6,4,5,3]\nfor j in opt_order:\n    train_offset = lambda x: -score_offset(offset_preds, x, j) * 100\n    offsets[j] = fmin_powell(train_offset, offsets[j], disp=False)\n\nprint('Offset Train score is:', eval_wrapper(offset_preds[1], train['Response']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# apply offsets to test\ndata = np.vstack((test_preds, test_preds, test['Response'].values))\ndata = apply_offsets(data, offsets)\n\nfinal_test_preds = np.round(np.clip(data[1], 1, 8)).astype(int)\n\npreds_out = pd.DataFrame({\"Id\": test['Id'].values, \"Response\": final_test_preds})\npreds_out = preds_out.set_index('Id')\npreds_out.to_csv('xgb_offset_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('sampleSubmission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}