{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(style='darkgrid')\n\nfrom sklearn.feature_selection import RFECV, VarianceThreshold\nfrom sklearn.model_selection import train_test_split, StratifiedShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom ml_metrics import quadratic_weighted_kappa\nrandom_state = 42\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/prudential-life-insurance-assessment/train.csv.zip')\ntrain_df.set_index('Id', inplace=True)\ndisplay(train_df.head())\nX_train, y_train = train_df.iloc[:, :-1], train_df.iloc[:, -1]\nprint(X_train.shape)\nprint(y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple data cleansing"},{"metadata":{"trusted":true},"cell_type":"code","source":"ordinal_y_mean_dict = {}\n\n#transform the categorial columns into numeric\nfor col in X_train.select_dtypes(include='object').columns:\n    ordinal_y_mean_dict[col]  = {index:i for i, index in enumerate(train_df.groupby(col)['Response'].mean().sort_values().index)}\n    print(ordinal_y_mean_dict[col])\n    X_train[col] = X_train[col].map(ordinal_y_mean_dict[col])\n    \n#check missing data\nfor col in X_train:\n    if pd.isnull(X_train[col]).any():\n        print('containing NA values:', col)\n\nimputer = SimpleImputer(strategy='mean')\nX_train2 = pd.DataFrame(imputer.fit_transform(X_train), columns=X_train.columns, index=X_train.index)\n#check missing data\nfor col in X_train2:\n    if pd.isnull(X_train2[col]).any():\n        print('containing NA values:', col)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Unsupervised approach\nReference:\nhttps://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection****"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2_unsup  = X_train2.copy() #deep copy","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop by the missing rate"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Suppose you data now contains some missing data, you want to filter the data with very high missing rate.\nX_train2_unsup['dump'] = np.nan\nX_train2_unsup2 = X_train2_unsup.dropna(axis=1, thresh=0.8) #drop the columns with missing rate > 80%\nprint(X_train2_unsup.shape)\nprint(X_train2_unsup2.shape) #drop the demp column","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Drop by the variance"},{"metadata":{"trusted":true},"cell_type":"code","source":"selector = VarianceThreshold(0.7)\nselector.fit(X_train2_unsup2)\nX_train2_unsup3 = X_train2_unsup2[X_train2_unsup2.columns[selector.get_support(indices=True)]]\nprint('number of columns after dropping by variance threshold:', X_train2_unsup3.shape[1])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. supervised approach"},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train2_sup = X_train2.copy() #deep copy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nX_model, X_valid, y_model, y_valid = train_test_split(X_train2_sup, y_train, stratify=y_train, random_state=random_state, test_size=.8)\n\nmodel_dict = {'LogisticRegression': LogisticRegression(penalty='l1', solver='saga', C=2, multi_class='multinomial', n_jobs=-1, random_state=random_state)\n             , 'ExtraTreesClassifier': ExtraTreesClassifier(n_estimators=200, max_depth=3, min_samples_leaf=.06, n_jobs=-1, random_state=random_state)\n              , 'RandomForestClassifier': RandomForestClassifier(n_estimators=20, max_depth=2, min_samples_leaf=.1, random_state=random_state, n_jobs=-1)\n             }\nestimator_dict = {}\nimportance_fatures_sorted_all = pd.DataFrame()\nfor model_name, model in model_dict.items():\n    print('='*10, model_name, '='*10)\n    model.fit(X_model, y_model)\n    print('Accuracy in training:', accuracy_score(model.predict(X_model), y_model))\n    print('Accuracy in valid:', accuracy_score(model.predict(X_valid), y_valid))\n    importance_values = np.absolute(model.coef_) if model_name == 'LogisticRegression' else model.feature_importances_\n    importance_fatures_sorted = pd.DataFrame(importance_values.reshape([-1, len(X_train2_sup.columns)]), columns=X_train2_sup.columns).mean(axis=0).sort_values(ascending=False).to_frame()\n    importance_fatures_sorted.rename(columns={0: 'feature_importance'}, inplace=True)\n    importance_fatures_sorted['ranking']= importance_fatures_sorted['feature_importance'].rank(ascending=False)\n    importance_fatures_sorted['model'] = model_name\n    print('Show top 10 important features:')\n    display(importance_fatures_sorted.drop('model', axis=1).head(10))\n    importance_fatures_sorted_all = importance_fatures_sorted_all.append(importance_fatures_sorted)\n    estimator_dict[model_name] = model\n\nplt.title('Feature importance ranked by number of features by model')\nsns.lineplot(data=importance_fatures_sorted_all, x='ranking', y='feature_importance', hue='model')\nplt.xlabel(\"Number of features selected\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_model = 'LogisticRegression'\nnumber_of_features = 60\nselect_features_by_model = importance_fatures_sorted_all[importance_fatures_sorted_all['model'] == selected_model].index[:number_of_features].tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#it takes much more time comparing \nrfecv = RFECV(estimator=model_dict['LogisticRegression'].set_params(max_iter=150, C=1), step=1, cv=StratifiedShuffleSplit(1, test_size=.2, random_state=random_state), scoring='accuracy', n_jobs=-1)\nrfecv.fit(X_train2_sup[select_features_by_model], y_train)\nplt.figure()\nplt.title('Feature importance ranked by number of features by model')\nplt.xlabel(\"Number of features selected\")\nplt.ylabel(\"Cross validation score (nb of correct classifications)\")\nplt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\nplt.plot(rfecv.n_features_, rfecv.grid_scores_[rfecv.n_features_-1], marker='o', label='Optimal number of feature')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rfecv_df = pd.DataFrame({'col': select_features_by_model})\nrfecv_df['rank'] = np.nan\nfor index, support in enumerate(rfecv.get_support(indices=True)):\n    rfecv_df.loc[support, 'rank'] = index\nfor index, rank in enumerate(rfecv.ranking_ -2):\n    if rank >= 0:\n        rfecv_df.loc[index, 'rank'] = rfecv.n_features_ + rank\nrfecv_df","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}