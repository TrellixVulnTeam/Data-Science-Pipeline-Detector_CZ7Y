{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# Read data\nimport pandas as pd\nimport pandas_profiling as pdp\ntrain = pd.read_csv(\"../input/prudential-life-insurance-assessment/train.csv\")\ntest = pd.read_csv(\"../input/prudential-life-insurance-assessment/test.csv\")\nprint(\"train:\", train.shape)\nprint(\"test:\", test.shape)\n\n# Check data\nprint(train.columns.to_numpy())\n#pdp.ProfileReport(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split x and y\nx = train.iloc[:,1:-1]\ny = train['Response']\nprint(y.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One-hot encode categorical data \nx = pd.get_dummies(x)\nx.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Normalize\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nx = pd.DataFrame(scaler.fit_transform(x), columns=x.columns)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Complete missing values\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(strategy='mean')\nx = pd.DataFrame(imputer.fit_transform(x), columns=x.columns)\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocess test data\nz = test.iloc[:,1:]\nz = pd.get_dummies(z)\nz = pd.DataFrame(scaler.transform(z), columns=z.columns)\nz = pd.DataFrame(imputer.transform(z), columns=z.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split train data and test data\nfrom sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(x, y, random_state=0)\nprint(x_train.shape, x_val.shape, y_train.shape, y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM (grid search)\nfrom sklearn.svm import LinearSVC\nfrom sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n\nparam = {'C': [5, 10, 20], 'dual': [False], 'penalty': ['l1', 'l2']}\ngscv = GridSearchCV(LinearSVC(), param, cv=4, verbose=2)\ngscv.fit(x, y)\n\nresult = pd.DataFrame.from_dict(gscv.cv_results_)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM (train)\nfrom sklearn.svm import LinearSVC\nsvm_clf = LinearSVC(C=10, penalty='l1', dual=False)\nsvm_clf.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\n# Save model\nfilename = 'svm_clf.bin'\npickle.dump(svm_clf, open(filename, 'wb'))\n\n# Load model\n#model = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest (grid search)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n\nparam = {\n    \"n_estimators\":[50,75,100],\n    \"criterion\":[\"gini\",\"entropy\"],\n    \"max_depth\":[15,20,25],\n    \"random_state\":[0],\n}\ngscv = GridSearchCV(RandomForestClassifier(), param, cv=4, verbose=2)\ngscv.fit(x, y)\n\nresult = pd.DataFrame.from_dict(gscv.cv_results_)\nresult","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Random forest (train)\nfrom sklearn.ensemble import RandomForestClassifier\nrf_clf = RandomForestClassifier(n_estimators=100, criterion='gini', max_depth=25)\nrf_clf.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\n\n# Save model\nfilename = 'rf_clf.bin'\npickle.dump(rf_clf, open(filename, 'wb'))\n\n# Load model\n#model = pickle.load(open(filename, 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inference\nresult = rf_clf.predict(z)\nsubmission = pd.DataFrame({'Id': test['Id'].astype('int').values, 'Response': result})\nsubmission.to_csv('submission_rf.csv', index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DNN\nfrom tensorflow import keras\ndef get_model():\n    model = keras.Sequential([\n        keras.layers.Flatten(input_shape=[x.shape[-1]]),\n        keras.layers.Dense(512, activation='relu'),\n        keras.layers.Dense(256, activation='relu'),\n        keras.layers.Dense(128, activation='relu'),\n        keras.layers.Dense(64, activation='relu'),\n        keras.layers.Dense(32, activation='relu'),\n        keras.layers.Dropout(0.5),\n        keras.layers.Dense(9, activation='softmax')\n    ])\n    model.compile(optimizer='adam', \n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DNN (fit and validation)\nimport tensorflow as tf\n\nbatch_size = 512\ntrain_ds = tf.data.Dataset.from_tensor_slices((x_train.values, y_train.values)).shuffle(len(x_train)).batch(batch_size)\nval_ds = tf.data.Dataset.from_tensor_slices((x_val.values, y_val.values)).batch(batch_size)\n\nmodel = get_model()\nfit = model.fit(train_ds, validation_data=val_ds, epochs=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# DNN (accuracy by epoch)\nimport matplotlib.pyplot as plt\n\nplt.plot(fit.history['accuracy'])\nplt.plot(fit.history['val_accuracy'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 512\ntrain_ds = tf.data.Dataset.from_tensor_slices((x.values, y.values)).shuffle(len(x_train)).batch(batch_size)\ntest_ds = tf.data.Dataset.from_tensor_slices((z.values)).batch(batch_size)\n\n# Train\nmodel = get_model()\nmodel.fit(train_ds, epochs=5)\n\n# Inference\nresult = model.predict(test_ds)\nresult = [pd.np.argmax(res) for res in result]\nsubmission = pd.DataFrame({'Id': test['Id'].astype('int').values, 'Response': result})\nsubmission.to_csv('submission_dnn.csv', index=False)\nsubmission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"dnn_clf = tf.estimator.DNNClassifier(\n    feature_columns=x_train.columns,\n    hidden_units=[512, 256, 128, 64, 32],\n    n_classes=8)\ndef input_fn(features, )\ndnn_clf.train(input_fn=input_fn)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}