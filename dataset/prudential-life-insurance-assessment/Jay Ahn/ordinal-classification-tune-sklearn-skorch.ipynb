{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Before begins\n\nThis notebook is written in google colab.\n\nTo see some interactive plots, please enter the colab link Below.\n\n<a href=\"https://colab.research.google.com/drive/1WPxPqsUsWxgZcmeHRsXn-jYR6aJLdegO?usp=sharing\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/></a>","metadata":{"id":"G2LMbV2w1gmU"}},{"cell_type":"markdown","source":"There are many notebooks similar to this for various competitions, so check the github address below\n\n<img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=50 align='left' alt=\"Open in Colab\" /></a>\n&nbsp; <font size=\"5\">[Github: Kaggle-Notebook](https://github.com/JayAhn0104/Kaggle-Notebook)</font>","metadata":{}},{"cell_type":"markdown","source":"# Overview\n\n<br>\n\n## Competition description\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/4699/logos/thumb76_76.png\" width=40 align='left' alt=\"Open in Colab\"/></a>\n&nbsp; \n<font size=\"5\">[Prudential Life Insurance Assessment](https://www.kaggle.com/c/prudential-life-insurance-assessment)</font>\n\n- Problem type: (Ordinal) classification\n  - Predicting the risk (8 classes) of individual in terms of life insurance\n- Evaluation metric: [quadratic weighted kappa](https://www.kaggle.com/c/prudential-life-insurance-assessment/overview/evaluation)\n\n<br>\n\n## Notebook description\n\nThis notebook provides the '**proper workflow**' for kaggle submission.\n\nThe workflow is divided into three main steps.\n1. Data preprocessing\n2. Model selection (hyper parameter tuning, model combination, model comparison)\n3. Training final model & Prediction on Test-set\n\nAt each stage, detailed descriptions of the work and an appropriate procedure will be provided.\n\nThrough this notebook, readers can learn the 'proper workflow' to be done for kaggle submission, \nand using this as a basic structure, someone will be able to apply this to other competitions easily with some adjustments\n\n**Warnings**:\n- The purpose of this notebook\n  - This notebook focuses on the 'procedure' rather than the 'result'. \n  - Thus this notebook does not guide you on how to achieve the top score. Since I personally think that any result can only have a meaning through an appropriate procedure.\n\n- The readers this notebook is intended for\n  - Who are aware of the basic usage of data processing tools (e.g., numpy, pandas)\n  - Who are aware of the basic concepts of machine learning models \n","metadata":{"id":"b46-DXk41pak"}},{"cell_type":"markdown","source":"# 0. Preliminaries","metadata":{"id":"nMmwylL27LPe"}},{"cell_type":"markdown","source":"### > Set Configurations \n\n- Set the configurations for this notebook","metadata":{"id":"9Dgu8su0VYOs"}},{"cell_type":"code","source":"config = {\n    'data_name': 'prudential-life-insurance-assessment',\n    'random_state': 2022\n}","metadata":{"id":"pWBOheYU7MX0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Install Libraries","metadata":{"id":"iG5yEKpVVfLI"}},{"cell_type":"code","source":"!pip install tune_sklearn skorch","metadata":{"id":"8vzQzPvOVjlq","outputId":"d5e59d50-77ec-4a57-edb4-ecc94ffa9504"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Data preprocessing\n\nThe data preprocessing works are divided into 8 steps here.\n\nSome of these steps are mandatory and some are optional.\n\nOptional steps are marked separately.\n\nIt is important to go through each step in order.\nBe careful not to reverse the order.","metadata":{"id":"gH2oJD3ezQD6"}},{"cell_type":"markdown","source":"## 1-1. Load Dataset\n\nLoad train-set and test-set on working environment\n","metadata":{"id":"b2CoDRXg7O8m"}},{"cell_type":"code","source":"%%bash \n\n(\ncd config['data_name']\nunzip train.csv\nunzip test.csv\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/{}/train.csv'.format(config['data_name']))\ntest = pd.read_csv('/kaggle/input/{}/test.csv'.format(config['data_name']))","metadata":{"id":"OmHiIN8l4HrR"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ### Concatenate the 'train' and 'test' data for preprocessing\n\nData preprocessing work should be applied equally for train-set and test-set.\n\nIn order to work at once, exclude the response variable 'Response' from 'train' and combine it with 'test'.","metadata":{"id":"pA9El-m57VoY"}},{"cell_type":"code","source":"all_features = pd.concat((train.drop(['Id','Response'], axis=1), test.drop(['Id'], axis=1)), axis=0)","metadata":{"id":"Ex45yF7FM5sI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-2. Missing Value Treatment\n\nMissing (NA) values in Data must be treated properly before model training.\n\nThere are three main treatment methods:\n1. Remove the variables which have NA values\n2. Remove the rows (observations) which have NA values\n3. Impute the NA values with other values\n\nWhich of the above methods is chosen is at the analyst's discretion.\nIt is important to choose the appropriate method for the situation.","metadata":{"id":"Fia79Yb4YfnR"}},{"cell_type":"markdown","source":"### > Check missing values in each variable\n","metadata":{"id":"rb9w50287ZT0"}},{"cell_type":"code","source":"import missingno as msno\nmsno.bar(all_features)","metadata":{"id":"K80IQwu2NvMm","outputId":"28860a17-0899-4a97-a14c-46075d5ca91e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Remove highly proportioned nan variables (nan proportion > 30%)","metadata":{"id":"_4LkY0Q2N4gD"}},{"cell_type":"code","source":"condition_col_idx = ((all_features.isnull().sum() / all_features.shape[0]) > 0.3).values\n\nprint(all_features.iloc[:,condition_col_idx].isnull().sum()/ all_features.shape[0])\n\nall_features = all_features.iloc[:, ~condition_col_idx]","metadata":{"id":"q2r37cmeOJzn","outputId":"b7f4fd0b-4dfd-4290-9212-1ff3631278d9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Impute the NA values properly\n\nThere are 4 variables that have NA values left.\n\nAnd these are all numeric (interger, float) variables","metadata":{"id":"1lm0gUQgQB_n"}},{"cell_type":"code","source":"all_features.iloc[:,all_features.isnull().any().values].head()","metadata":{"id":"y9Ga1lgsQBH1","outputId":"3b140d17-cd52-4c1c-f6e6-b15a31947feb"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### >> Replace NA by 'median value' of the variable grouped by another (relevant) categorical variable\n\n\nThe figures below show that the distribution of y-axis variable is different depending on the x-axis variable values.\n\n(ANOVA test is used to determine whether the differences between groups are significant.)\n","metadata":{"id":"xPjqyNNMWdQ9"}},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\nby_var_list = ['Employment_Info_2', 'Employment_Info_3', 'Employment_Info_5']\ntarget_list = ['Employment_Info_1', 'Employment_Info_4', 'Employment_Info_6']\n\nanova_res_list = []\nfor target in target_list:\n  for by_var in by_var_list:\n    formula = target + '~' + by_var\n    model = ols(formula, data=all_features).fit()\n    anova_table = sm.stats.anova_lm(model, typ=2)\n    anova_res_list.append([target, by_var, anova_table['F'][0]])\n\nanova_res = pd.DataFrame(np.vstack((anova_res_list)), columns=['target', 'by_var', 'F-statistic'])    \nanova_res['F-statistic'] = anova_res['F-statistic'].astype(np.float32)\n\nimport plotly.express as px\nfig = px.bar(anova_res, x='target', y='F-statistic', color='by_var', width=800, height=400, barmode='group')\nfig.show()","metadata":{"id":"ShfUx7xbRKFO","outputId":"49d93ca7-3789-40d4-e0fc-cf9526e48ca3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import statsmodels.api as sm\nfrom statsmodels.formula.api import ols\n\nby_var_list = all_features.iloc[:,all_features.columns.str.startswith('Medical')].select_dtypes(exclude=np.float64).columns\ntarget_list = ['Medical_History_1']\n\nanova_res_list = []\nfor target in target_list:\n  for by_var in by_var_list:\n    formula = target + '~' + by_var\n    model = ols(formula, data=all_features).fit()\n    anova_table = sm.stats.anova_lm(model, typ=2)\n    anova_res_list.append([target, by_var, anova_table['F'][0]])\n\nanova_res = pd.DataFrame(np.vstack((anova_res_list)), columns=['target', 'by_var', 'F-statistic'])    \nanova_res['F-statistic'] = anova_res['F-statistic'].astype(np.float32)\n\nimport plotly.express as px\nfig = px.bar(anova_res, x='target', y='F-statistic', color='by_var', width=800, height=400, barmode='group')\nfig.show()","metadata":{"id":"b89kxb2_YRzt","outputId":"5bf2be2d-b9ba-4833-afa6-b765a4161e48"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"method = 'median'\n\nall_features.loc[:,'Employment_Info_1'] = all_features.loc[:,'Employment_Info_3'].fillna(all_features.groupby('Employment_Info_3')['Employment_Info_1'].transform(method))\nall_features.loc[:,'Employment_Info_4'] = all_features.loc[:,'Employment_Info_3'].fillna(all_features.groupby('Employment_Info_5')['Employment_Info_4'].transform(method))\nall_features.loc[:,'Employment_Info_6'] = all_features.loc[:,'Employment_Info_3'].fillna(all_features.groupby('Employment_Info_3')['Employment_Info_6'].transform(method))\n\nall_features.loc[:,'Medical_History_1'] = all_features.loc[:,'Medical_History_23'].fillna(all_features.groupby('Medical_History_23')['Medical_History_1'].transform(method))","metadata":{"id":"YBSvW6ayVrDt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"assert not all_features.isnull().sum().any()","metadata":{"id":"UwmDT03ZZ3HQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-3. Categorical variable consideration","metadata":{"id":"n44VK2jscV4d"}},{"cell_type":"markdown","source":"### > 'Medical_Keyword_[1-48]' variables\n\n'Medical_Keyword_[1-48]' variables have only {0, 1} values","metadata":{"id":"HoSFJHUgepwt"}},{"cell_type":"code","source":"var_idx = all_features.columns.str.startswith('Medical_Keyword')\nnp.unique(all_features.iloc[:,var_idx].values)","metadata":{"id":"Vzh5PKFRcfkF","outputId":"1659dbc2-f0a2-4a2d-cd72-3b2415672184"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"But sum of values through axis=1 has values > 1.\n\nSo, we can think that these variables are set of one-hot encoded (dummified) variables,\nNOT one-hot encoded on 'ONE' variable.\n\nThus we should change the data type from 'int64' to 'uint8' to prevent additional one-hot encoding","metadata":{"id":"uUf4OslmdHSP"}},{"cell_type":"code","source":"all_features.iloc[:,var_idx].sum(axis=1).value_counts()","metadata":{"id":"lLeknE0ybogK","outputId":"aad6d2ea-61f4-415d-8ed2-b9f6e3ff9aae"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"var_idx = all_features.columns.str.startswith('Medical_Keyword')\nall_features.iloc[:,var_idx] = all_features.iloc[:,var_idx].astype(np.uint8)","metadata":{"id":"XcsMRtMJdzxg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-4. Dummify categorical variables\n\nIn the case of linear modeling without regularization, the first or last column should be dropped (to prevent linear dependency), but here, for the convenience of using the factorization model, one-hot encoding method is used that does not drop any columns.","metadata":{"id":"hJayzx_-Nzck"}},{"cell_type":"code","source":"data_set = pd.get_dummies(all_features, drop_first=False)","metadata":{"id":"CsctjSYSQClH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-5. Scaling continuous variables\n\nMinMaxScaling maps all variables from 0 to 1 in order to consider only relative information, not absolute magnitudes of the values.\n\nBesides, it is known that scaling is often more stable in parameter optimization when training a model.","metadata":{"id":"Yo_M-blKP1pP"}},{"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\ndata_set = scaler.fit_transform(data_set)","metadata":{"id":"W-F7cdreP1ZV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-6. Split Train & Test set","metadata":{"id":"3Bds2C0rQb_c"}},{"cell_type":"code","source":"n_train = train.shape[0]\nX_train = data_set[:n_train].astype(np.float32)\nX_test = data_set[n_train:].astype(np.float32)\ny_train = train['Response'].values.astype(np.int64)","metadata":{"id":"AZj86aMgaBrp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-7. Outlier Detection on Training data (*optional*)\n\nDetect and remove outlier observations that exist in the train-set.\n\n- Methodology: [Isolation Forest](https://ieeexplore.ieee.org/abstract/document/4781136/?casa_token=V7U3M1UIykoAAAAA:kww9pojtMeJtXaBcNmw0eVlJaXEGGICi1ogmeHUFMpgJ2h_XCbSd2yBU5mRgd7zEJrXZ01z2)\n  - How it works\n    - Isolation Forest applies a decision tree that repeats splits based on the 'random criterion' for the given data unitl only one observation remains in every terminal node (this is defined as 'isolation').\n    - Based on the number of splits used for isolation, 'normality' is defined. A smaller value means a higher degree of outlierness.\n    - By applying this decision tree several times, the average of the measured 'normality' values ​​is derived as the final 'normality' value.\n  - Assumptions\n    - Outliers require relatively few splits to be isolated.\n    - For normal data, the number of splits required to be isolated is relatively large.\n  - Outlier determination\n    - Determines whether it is an outlier or not based on the measured 'normality' value.\n      - sklearn's IsolationForest package determines based on '0' \n      - I, personally, think it is better to set the discriminant criterion by considering the 'distribution' of the 'normality' values.\n      - The details of the method is given below.","metadata":{"id":"xXpd4YS_Rooe"}},{"cell_type":"code","source":"from sklearn.ensemble import IsolationForest\nclf = IsolationForest(\n    n_estimators=100,\n    max_samples='auto',\n    n_jobs=-1,\n    random_state=config['random_state'])\n\nclf.fit(X_train)\nnormality_df = pd.DataFrame(clf.decision_function(X_train), columns=['normality'])","metadata":{"id":"CT4-2FOcRnkM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The dicriminant value \n  - The discriminant value (threshold) is defined by calculating the 1st quartile ($q_1$) and 3rd quartile ($q_3$) on the distribution of the measured normality values.\n    - with $k=1.5$\n\n$$threshold = q_1 - k*(q_3 - q_1)$$\n\n\n- Motivation\n  - This discriminant method is adapted from Tukey's boxplot idea.\nIn the distribution of any continuous variable, Tukey designates observations smaller than that value or larger than q_3 + k*(q_3 - q_1) as outliers.\n\n- How we do \n  - Our methodology does not apply the above method to a specific variable, but applies the method to the obtained normality.\n\n  - That is, it is based on the assumption that an outlier will be far left from the other observations in the measured normality distribution.","metadata":{"id":"xWtuNCQs7zra"}},{"cell_type":"code","source":"def outlier_threshold(normality, k=1.5):\n  q1 = np.quantile(normality, 0.25)\n  q3 = np.quantile(normality, 0.75)  \n  threshold = q1 - k*(q3-q1)\n  return threshold\n\nthreshold = outlier_threshold(normality_df['normality'].values, k=1.5)\n\nimport plotly.express as px\nfig = px.histogram(normality_df, x='normality', width=400, height=400)\nfig.add_vline(x=threshold, line_width=3, line_dash=\"dash\", line_color=\"red\")\nfig.show()","metadata":{"id":"fnuzws26Sm_7","outputId":"3777475e-70c9-4400-af1c-0bcf3a120796"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\npx.box(normality_df, x='normality', orientation='h', width=400, height=400)","metadata":{"id":"HFc_y-fSUp4Y","outputId":"2d2955a7-9ecb-4801-e918-936f1b656098"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train = X_train[normality_df['normality'].values>=threshold]\ny_train = y_train[normality_df['normality'].values>=threshold]\n\nprint('{} out of {} observations are removed from train_set'.format(train.shape[0] - X_train.shape[0], train.shape[0]))","metadata":{"id":"sTVOUiyma73J","outputId":"f9055eb8-0307-4180-bd2c-b13d3b7c11b6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1-8. Output variable transformation","metadata":{"id":"TWG_V9p_hq6P"}},{"cell_type":"code","source":"print('Before transformation:', np.unique(y_train))\n\ny_train_trans = y_train - 1\n\nprint('After transformation:', np.unique(y_train_trans))","metadata":{"id":"tkSL1ap_h0Fm","outputId":"ae888ee1-e01d-4c23-9156-87a3bc4a50f2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# 2. Model Selection\n\n\n## > Modeling Strategy\nOur goal is to build a model that predicts the type of risk in terms of life insurance for individuals given some informations. The formula can be expressed as:\n\n$\\hat{y} = \\underset{k \\in \\{1,\\cdots,K\\}}{\\operatorname{argmax}}f_{k}(x)$\n\nwhere,\n  - $y \\in \\{1,\\cdots,K\\} $: labels \n    - $ 1 < \\cdots < K$\n  - $x$: an input observation\n  - $f_{k}(x)$: a function of $x$ that outputs predicted value for each $k$\n\nThis can be formulated as a \"**ordinal** classification\" problem whose output variable has a ordinal characteristic.\n\n\n- Problem \n  - Standard classification models can not consider the ordinal relationship of output variable\n\n- Solution \n  - According to [A Simple Approach to Ordinal Classification](https://www.cs.waikato.ac.nz/~eibe/pubs/ordinal_tech_report.pdf), by applying some simple methods, we can formulate the ordinal classification while using standard (binary) classification methods.\n  > We can take advantage of the ordered class value by transforming a k-class ordinal regression problem to a k-1 binary classification problem, we convert an ordinal attribute A* with ordinal value V1, V2, V3, … Vk into k-1 binary attributes, one for each of the original attribute’s first k − 1 values. The ith binary attribute represents the test A* > Vi\n\n  - How it works\n    1. Convert an ordinal output variable Y into k-1 binary attributes ($Y_{1}, \\cdots Y_{K-1}$). The i-th binary attributes $Y_{i} \\in \\\\{0, 1\\\\}$ represents $Y > i$\n    2. Estimate the probabilities $Pr(Y_{1} = 1), \\cdots, Pr(Y_{K-1}=1)$ by training each model on data which are same as $Pr(Y > 1), \\cdots, Pr(Y > K-1)$\n    3. Get the probabilities $Pr(Y=k)$ by using estimated $Pr(Y > 1), \\cdots, Pr(Y > K-1)$. i.e.,\n      - $Pr(Y=1) = 1 - Pr(Y>1) $\n      - $Pr(Y=i) = Pr(Y>i-1) - Pr(Y>i)$\n      - $Pr(Y=K) = Pr(Y>K-1)$\n\nBelow figure shows the overall procedure, when $Y \\in \\{1, 2, 3, 4\\}$\n\n<center><img src='https://drive.google.com/uc?export=view&id=1ImlHhVUuBXAfHwEBfg0RS6NXXkDNJk3H' width = 1000></center>\n","metadata":{"id":"3UbJJrv6i3kM"}},{"cell_type":"markdown","source":"## > Model Selection method\n\nTo estimate the probabilities for each binary classification model, we uses the following models.\n- Logistic regression\n- Random forest\n- Xgboost\n- Multi-layer perceptron\n\nHowever, we have to \"choose\" one final methodology to make predictions on the test set.\nTo do this, a “fair evaluation” of the models is essential. \"Fair evaluation\" must satisfy the following two conditions.\n\n1. Select optimal hyperparameters for each model\n  - If hyperparameter search is not performed, the difference in model performance may occur due to incorrect hyperparameter values.\n2. same evaluation method\n  - If the same evaluation method is not applied, comparison between models itself is impossible.\n\nWhen comparing models through an evaluation method that satisfies the above two conditions,\nOnly then can the final model be selected.\n\n\n","metadata":{"id":"qHMrducqSjBL"}},{"cell_type":"markdown","source":"### > Define a scoring function for hyper parameter tuning\n","metadata":{"id":"CiWZvUqiz3dA"}},{"cell_type":"code","source":"from sklearn.metrics import make_scorer\nfrom sklearn.metrics import cohen_kappa_score\n\ndef weighted_kappa(y_true, y_pred):\n  try:\n    score = cohen_kappa_score(y_true, y_pred, weights='quadratic')\n  except:\n    score = np.nan\n  return score\n\ntarget_metric = make_scorer(weighted_kappa, greater_is_better=True)","metadata":{"id":"uj_KeaLgz6EH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-1. Define a Ordinal Classificatier class\n\nThis class enables the ordinal classification formulation by using the standard binary classification models\n","metadata":{"id":"_oe8y0_9QMiV"}},{"cell_type":"code","source":"from sklearn.base import BaseEstimator\nfrom sklearn.base import clone\nfrom sklearn.metrics import accuracy_score\nclass OrdinalClassifier(BaseEstimator):\n\n    def __init__(self, clf):\n        self.clf = clf\n        self.clfs = {}\n\n    def fit(self, X, y):\n        self.unique_class = np.sort(np.unique(y))\n        if self.unique_class.shape[0] > 2:\n            for i in range(self.unique_class.shape[0]-1):\n                # for each k - 1 ordinal value we fit a binary classification problem\n                binary_y = (y > self.unique_class[i]).astype(np.uint8)\n                clf = clone(self.clf)\n                try:\n                  clf.module\n                except: # For others\n                  clf.fit(X, binary_y)\n                else: # For MLP\n                  binary_y_reshape = binary_y.astype('float32').reshape(-1,1)\n                  clf.fit(X, binary_y_reshape)\n                self.clfs[i] = clf\n\n    def predict_proba(self, X):\n        clfs_predict = {k: self.clfs[k].predict_proba(X) for k in self.clfs}\n        predicted = []\n        for i, y in enumerate(self.unique_class):\n            if i == 0:\n                # V1 = 1 - Pr(y > V1)\n                predicted.append(1 - clfs_predict[i][:,1])\n            elif i in clfs_predict:\n                # Vi = Pr(y > Vi-1) - Pr(y > Vi)\n                 predicted.append(clfs_predict[i-1][:,1] - clfs_predict[i][:,1])\n            else:\n                # Vk = Pr(y > Vk-1)\n                predicted.append(clfs_predict[i-1][:,1])\n        try:\n          self.clf.module\n        except: # For others\n          pred_proba = np.vstack(predicted).T      \n        else: # For MLP\n          pred_proba = np.hstack((predicted))\n        \n        return pred_proba\n\n    def predict(self, X):\n        return np.argmax(self.predict_proba(X), axis=1)\n\n    def score(self, X, y, sample_weight=None):\n        _, indexed_y = np.unique(y, return_inverse=True)\n        return accuracy_score(indexed_y, self.predict(X), sample_weight=sample_weight)","metadata":{"id":"LeVtqLJmQL4G"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-2. Hyper parameter tuning by using Tune_SKlearn (Ray Tune)\n\n- Package: tune_sklearn\n  - This package makes it easy to apply [Ray Tune](https://docs.ray.io/en/latest/tune/index.html) to sklearn models.\n  - Ray Tune is a python package that provides various hyperparameter tuning algorithms (HyperOpt, BayesianOptimization, ...).\n- Tuning procedure\n  - Define an appropriate search space for each model's hyperparameters.\n  - 5-fold CV (Cross Validation) is performed for each specific hyper-parameter value combination of the search space by using the hyper-parameter tuning algorithm (HyperOpt)\n    - Training: Training by using Scikit-Learn and Skorch packages\n    - Validation: Evaluate the model using an appropriate evaluation metric\n  - The hyperparameter with the highest average score of the CV result is designated as the optimal hyperparameter of the model.\n    - Save this CV result and use for model comparison\n\n","metadata":{"id":"TpffTJyuKCip"}},{"cell_type":"markdown","source":"### > Make a dataframe for containing CV results","metadata":{"id":"CG_uUxGt8dk9"}},{"cell_type":"code","source":"model_list = []\nfor name in ['linear', 'rf', 'xgb', 'mlp']:\n  model_list.append(np.full(5, name))\n  \nbest_cv_df = pd.DataFrame({'model': np.hstack((model_list)), 'accuracy':None, 'kappa':None, 'best_hyper_param': None})","metadata":{"id":"yecAASyT5ljV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Logistic regression","metadata":{"id":"2MZsMccOKY2B"}},{"cell_type":"code","source":"from tune_sklearn import TuneSearchCV\nfrom sklearn.linear_model import SGDClassifier\n\n# Define a search space\nparameters = {\n    'clf__alpha': list(np.geomspace(1e-5, 1e-2, 4)),\n    'clf__max_iter': [1000],\n    'clf__tol': [1e-4, 1e-3, 1e-2],\n    'clf__loss': ['log'],\n    'clf__penalty': ['l2'],\n    'clf__random_state': [config['random_state']],\n}\n\n# Define a Ordinal classifier\nclf = SGDClassifier()\nordinal_clf = OrdinalClassifier(clf)\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    ordinal_clf,\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=6,\n    n_jobs=-1,\n    scoring={'accuracy':'accuracy', 'kappa':target_metric},\n    cv=5,\n    refit='kappa',\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n# Run hyper parameter tuning\nX = X_train\ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'linear'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'kappa'] = cv_values[5:]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_kappa')\nfig.show()","metadata":{"id":"eZKESznQ-tNf","outputId":"14324075-81da-415e-d844-354b071c7ae0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Random forest","metadata":{"id":"TZV1XLbAKffy"}},{"cell_type":"code","source":"from tune_sklearn import TuneSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Define a search space\nparameters = {\n    'clf__n_estimators': [50, 100],\n    'clf__criterion': ['gini', 'entropy'],\n    'clf__max_depth': [20, 25, 30],\n    'clf__max_features': ['auto'],\n    'clf__random_state': [config['random_state']]\n}\n\n# Define a Ordinal classifier\nclf = RandomForestClassifier()\nordinal_clf = OrdinalClassifier(clf)\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    ordinal_clf,\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=4,\n    n_jobs=-1,\n    scoring={'accuracy':'accuracy', 'kappa':target_metric},\n    cv=5,\n    refit='kappa',\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n# Run hyper parameter tuning\nX = X_train\ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'rf'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'kappa'] = cv_values[5:]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.get_dummies(pd.DataFrame(tune_search.cv_results_['params']), drop_first=False), \n                            cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\ntune_result_df = tune_result_df.astype({'clf__criterion_entropy':'int64', 'clf__criterion_gini':'int64'})\nimport plotly.express as px\npx.parallel_coordinates(tune_result_df, color='mean_test_kappa')","metadata":{"id":"Ro5m_OKISh3P","outputId":"02bc3942-3809-49c0-d842-e9161c451ccc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### XGBoost","metadata":{"id":"NGiWtM5NKhA-"}},{"cell_type":"code","source":"from tune_sklearn import TuneSearchCV\nfrom xgboost import XGBClassifier\n\n# Define a search space\nparameters = {\n    'clf__n_estimators': [10, 50],\n    'clf__learning_rate': list(np.geomspace(1e-2, 1, 3)),\n    'clf__min_child_weight': [5, 10, 15],\n    'clf__gamma': [0.5, 2],\n    'clf__subsample': [0.6, 1.0],\n    'clf__colsample_bytree': [0.6, 1.0],\n    'clf__max_depth': [5, 10, 15],\n    'clf__lambda': [1],\n    'clf__objective': ['binary:logistic'],\n    'clf__random_state': [config['random_state']]\n}\n\n# Define a Ordinal classifier\nclf = XGBClassifier()\nordinal_clf = OrdinalClassifier(clf)\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    ordinal_clf,\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=4,\n    n_jobs=-1,\n    scoring={'accuracy':'accuracy', 'kappa':target_metric},\n    cv=5,\n    refit='kappa',\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n# Run hyper parameter tuning\nX = X_train\ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'xgb'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'kappa'] = cv_values[5:]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\nimport plotly.express as px\nfig = px.parallel_coordinates(tune_result_df, color='mean_test_kappa')\nfig.show()","metadata":{"id":"YtJ5wlpu9j21","outputId":"f26b3c55-856c-434a-8009-56a8214dbd9a"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multi-layer perceptron","metadata":{"id":"eMEkfLDXKmtD"}},{"cell_type":"code","source":"import torch\nfrom torch import nn\nfrom skorch import NeuralNetClassifier\nfrom skorch.callbacks import EarlyStopping\nfrom skorch.callbacks import EpochScoring\nfrom skorch.callbacks import Checkpoint\nfrom tune_sklearn import TuneSearchCV\n\n# Define a model structure\nclass MLP(nn.Module):\n    def __init__(self, num_inputs=X_train.shape[1], num_outputs=1, layer1=512, layer2=256, dropout1=0, dropout2=0):\n        super(MLP, self).__init__()\n\n        self.linear_relu_stack = nn.Sequential(\n            nn.Linear(num_inputs, layer1),\n            nn.LeakyReLU(),\n            nn.Dropout(dropout1),\n            nn.Linear(layer1, layer2),\n            nn.LeakyReLU(),\n            nn.Dropout(dropout2),\n            nn.Linear(layer2, num_outputs)\n            )\n    def forward(self, x):\n        x = self.linear_relu_stack(x)\n        return x  \n\ndef try_gpu(i=0): \n    return f'cuda:{i}' if torch.cuda.device_count() >= i + 1 else 'cpu'\n\n# Set model configurations\nmlp = NeuralNetClassifier(\n    MLP(num_inputs=X_train.shape[1], num_outputs=1),\n    criterion=nn.BCEWithLogitsLoss(),\n    optimizer=torch.optim.Adam,\n    device=try_gpu(),\n    verbose=0,\n    callbacks=[EarlyStopping(monitor='valid_loss', patience=5,\n                             threshold=1e-3, lower_is_better=False)]\n                          )\n# Define a search space\nparameters = {\n    'clf__lr': list(np.geomspace(1e-4, 1e-1, 4)),\n    'clf__module__layer1': [128, 256, 512],\n    'clf__module__layer2': [128, 256, 512],\n    'clf__module__dropout1': [0, 0.1],\n    'clf__module__dropout2': [0, 0.1],\n    'clf__batch_size': [128, 256],\n    'clf__optimizer__weight_decay': list(np.geomspace(1e-5, 1e-1, 5)),\n    'clf__max_epochs': [2000],\n    'clf__iterator_train__shuffle': [True],\n    'clf__callbacks__EarlyStopping__threshold': [1e-4, 1e-3]\n    }\n\ndef use_gpu(device):\n    return True if not device == 'cpu' else False \n\n# Define a Ordinal classifier\nclf = mlp\nordinal_clf = OrdinalClassifier(clf)\n\n# Specify the hyper parameter tuning algorithm\ntune_search = TuneSearchCV(\n    ordinal_clf,\n    parameters,\n    search_optimization='hyperopt',\n    n_trials=10,\n    n_jobs=-1,\n    scoring={'accuracy':'accuracy', 'kappa':target_metric},\n    cv=5,\n    refit='kappa',\n    verbose=1,\n    random_state=config['random_state']\n    )\n\n# Run hyper parameter tuning\nX = X_train\ny = y_train_trans\ntune_search.fit(X, y)\n\n# Save the tuning results \nmodel_name = 'mlp'\n\n## Save the optimal hyper parmater values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'best_hyper_param'] = str(tune_search.best_params_)\n\n## Save the CV results\ncv_df = pd.DataFrame(tune_search.cv_results_)\ncv_values = cv_df.loc[tune_search.best_index_, cv_df.columns.str.startswith('split')].values\nbest_cv_df.loc[best_cv_df['model']==model_name, 'accuracy'] = cv_values[:5]\nbest_cv_df.loc[best_cv_df['model']==model_name, 'kappa'] = cv_values[5:]\n\n# Visualize the tuning results with parallel coordinate plot\ntune_result_df = pd.concat([pd.DataFrame(tune_search.cv_results_['params']), cv_df.loc[:,cv_df.columns.str.startswith('mean')] ], axis=1)\ntune_result_df.rename({\n    'clf__callbacks__EarlyStopping__threshold':'Earlystoping_threshold',\n    'clf__optimizer__weight_decay': 'weight_decay'\n    }, axis=1, inplace=True)\nimport plotly.express as px\npx.parallel_coordinates(tune_result_df, color='mean_test_kappa')","metadata":{"id":"sADua7CoPz3Z","outputId":"dfb5e7c4-2df9-41da-c879-a936b875021d"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Save CV results","metadata":{"id":"kq87ZglH8uIS"}},{"cell_type":"markdown","source":"## 2-3. Model Comparison based on CV results\n\nCompare the CV results (measured using the optimal hyper parameter values).\n\nThe figure below shows that \n\nxgb > linear > mlp > rf\n\n\n","metadata":{"id":"v4BlrQ6XK0ol"}},{"cell_type":"code","source":"fig = px.box(best_cv_df, x='model', y='kappa', color='model', width=800)\nfig.show()","metadata":{"id":"0V_rMg7WzxDo","outputId":"0e167164-71d3-4541-be46-dd0a3ba988b2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-4. Model Combination\n\nAlthough it is possible to select a final model based on the above results, it has been observed that in many cases the combination of predicted values ​​from multiple models leads to improve prediction performance. ([Can multi-model combination really enhance the prediction skill of probabilistic ensemble forecasts?](https://rmets.onlinelibrary.wiley.com/doi/abs/10.1002/qj.210?casa_token=OwyF2RbEywAAAAAA:gahpwGRdOWzLXyafYQQt_voHOF8MedTBLd1SBv4vkdT3ZTLVoKZQj3zl-KbrhSkX5x8CndeCxwBoL_-S))\n\nFor classification problems, the final probabilities are derived by combining the predicted 'probabilities' for each class in a 'proper way'.\n\nThis notebook uses following two model combination methods.\n\n1. Simple Average\n2. Stacked Generalization (Stacking)\n\n\nModel comparison needs to be done with single models (e.g., rf, xgb,...).\nSo model performance are measured by applying the same CV method as above.\n\nBased on the CV results, we select (linear, xgb, mlp) as the base estimators for model combination.","metadata":{"id":"4n8Ah9ahKDDZ"}},{"cell_type":"markdown","source":"### > Simple Average\n\nThe simple average method derives the final probability value by 'averaging' the predicted probability values ​​for each class of multiple models.\n\nThe top 3 models (linear, xgb, mlp) of the above CV results are selected as base estimators used for the combination of predicted values.\n\nFor example,\n- Base Estimations\n  - $P_{linear}(Y=1|X=x)$ = 0.80\n  - $P_{xgb}(Y=1|X=x)$ = 0.80\n  - $P_{mlp}(Y=1|X=x)$ = 0.85\n- Final Estimation\n  - $P_{average}(Y=1|X=x)$  = 0.817 (= 0.80 + 0.80 + 0.85 / 3)\n","metadata":{"id":"Sf4wsWU4EHW-"}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom tqdm import notebook\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import log_loss\nfrom sklearn.metrics import roc_auc_score\n\ndef CV_ensemble(ensemble_name, ensemble_func, estimators, X_train, y_train, n_folds=5, shuffle=True, random_state=2022):\n  kf = KFold(n_splits=5, random_state=random_state, shuffle=True)\n\n  res_list = []\n  for train_idx, valid_idx in notebook.tqdm(kf.split(X_train), total=kf.get_n_splits(), desc='Eval_CV'):\n    X_train_train, X_valid = X_train[train_idx], X_train[valid_idx]\n    y_train_train, y_valid = y_train[train_idx], y_train[valid_idx]\n\n    ensemble_pred_proba = ensemble_func(estimators, X_train_train, y_train_train, X_valid)\n    accuracy = accuracy_score(y_valid, ensemble_pred_proba.argmax(axis=1))\n    kappa = weighted_kappa(y_valid, ensemble_pred_proba.argmax(axis=1))\n\n    res_list.append([ensemble_name, accuracy, kappa])\n  res_df = pd.DataFrame(np.vstack((res_list)))\n  res_df.columns = ['model', 'accuracy', 'kappa']\n  return res_df\n\ndef ensemble_average(estimators, X_train, y_train, X_test):\n  preds = []\n  num_estimators = len(estimators)\n  num_class = len(np.unique(y_train))\n  for iter in range(num_estimators):\n    estimators[iter].fit(X_train, y_train)\n    preds.append(estimators[iter].predict_proba(X_test))\n  \n  preds_stack = np.hstack((preds))\n  preds_mean = []\n  for iter in range(num_class):\n    col_idx = np.arange(iter, num_estimators * num_class, num_class)\n    preds_mean.append(np.mean(preds_stack[:,col_idx], axis=1))\n\n  pred_fin = np.vstack((preds_mean)).transpose()\n  return pred_fin","metadata":{"id":"BJ6YHo9Bfl2Q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\n\nlinear_ordinal = OrdinalClassifier(SGDClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='linear', 'best_hyper_param'].values[0]))\nrf_ordinal = OrdinalClassifier(RandomForestClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='rf', 'best_hyper_param'].values[0]))\nxgb_ordinal = OrdinalClassifier(XGBClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='xgb', 'best_hyper_param'].values[0]))\nmlp_ordinal = OrdinalClassifier(mlp).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='mlp', 'best_hyper_param'].values[0]))\n\nestimators = [linear_ordinal, xgb_ordinal, mlp_ordinal]\nestimators_name = 'linear_xgb_mlp'\nensemble_name = 'average' + '_' + estimators_name\n\nX = X_train\ny = y_train_trans\n\nres_df = CV_ensemble(ensemble_name, ensemble_average, estimators, X, y, n_folds=5, shuffle=True, random_state=config['random_state'])\nbest_cv_df = best_cv_df.append(res_df).reset_index(drop=True)","metadata":{"id":"JEDSzMQTX48i","outputId":"2379fd51-0fcd-463c-97a4-d89c4a1bc929"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.box(best_cv_df, x='model', y='kappa', color='model', width=800)\nfig.show()","metadata":{"id":"FLZOgZ7j82Xt","outputId":"2da41630-1685-43ca-f2f9-6b21bab70162"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### > Stacked generalization (Stacking)\n\nIn the [Stacked generalization](https://www.jair.org/index.php/jair/article/view/10228), the predicted probabilities of base estimators are treated as the 'input data', and y (Cover_Type) of each row is treated as the 'output variable'. \nThe 'Meta Learner' is learned with these data and the predicted probablities of this model are derived as the final prediction probabilities.\n\n- The 'Meta Learner' can be optained among any of the classification models. However, this notebook uses a ridge model (logistic regression with ridge penalty) to prevent overfitting.\n\n- As input data for 'Meta Learner', prediction probabilities for validation data in cv of base estimators are obtained.\n\n- Trained meta-learner predicts the final predicted probabilities for the test-set by using the predicted probabilites of baes estimators for the test-set as input data.\n\nThe total process, in order, is as follows:\n1. (Base estimators) Run CV on Train-set\n2. (Meta Learner) Train on CV predictions (predicted probabilities on validation data of CV) with corresponding y values\n3. (Base estimators) Train on Train-set\n4. (Base estimators) Predict on Test-set\n5. (Meta Learner) Predict on predictions on Test-set\n\n<img align='top' src='https://drive.google.com/uc?export=view&id=1uDxSIIFt8rUJkuIwRYU4lALvOPqlXPG5' width='600' height='400'>\n\n\nFor example,\n- Assume that \n  - $Y \\in \\{0, 1, 2\\}$\n- Base Estimatiors\n  - rf\n    - $P_{rf}(Y=0|X=x)$ = 0.75\n    - $P_{rf}(Y=1|X=x)$ = 0.10\n    - $P_{rf}(Y=2|X=x)$ = 0.15\n  - xgb\n    - $P_{xgb}(Y=0|X=x)$ = 0.80\n    - $P_{xgb}(Y=1|X=x)$ = 0.10\n    - $P_{xgb}(Y=2|X=x)$ = 0.10\n- Meta Learner (logistic regression with ridge (l2) penalty)\n  - when Y=0:\n    - intercept = 0.1\n    - coefficient = [0.8, 0.1, -0.1, 0.9, 0.2, -0.05]\n  - predicted probabilities\n    - $P_{stack}(Y=0|X=x)$ = 0.8069 = sigmoid(0.1 + 0.8*0.75 + 0.1*0.1 -0.1*0.15 + 0.9*0.8 + 0.2*0.1 - 0.05*0.1)$\n\n\n**Warnings**:\n\n- the set of predicted probabilities $[P_{rf}(Y=1|X=x), \\cdots, P_{xgb}(Y=2|X=x)]$ is a **linearly dependent ** matrix.\n- Thus, as a final estimator, linear model with penalty or not a linear model is recommended.\n- If you want to apply plain linear model with no penalty, please remove the first or last class probabilities of each base estimators (e.g., remove $P_{rf}(Y=2|X=x)$ and $P_{xgb}(Y=2|X=x)$)","metadata":{"id":"5eKbDaOmEPVc"}},{"cell_type":"code","source":"from sklearn.model_selection import KFold\nfrom tqdm import notebook\n\n\ndef stack_clf(estimators, X_train, y_train, X_test, n_folds=5, shuffle=True, random_state=2022):\n  final_estimator = estimators[-1]\n  num_estimators = len(estimators)-1\n\n  kf = KFold(n_splits=n_folds, random_state=random_state, shuffle=shuffle)\n  preds = []\n  y_valid_list = []\n  # Get CV predictions\n  for train_idx, valid_idx in notebook.tqdm(kf.split(X_train), total=kf.get_n_splits(), desc='Stack_CV'):\n    X_train_train, X_valid = X_train[train_idx], X_train[valid_idx]\n    y_train_train, y_valid = y_train[train_idx], y_train[valid_idx]\n    \n    valid_preds = []\n    for iter in range(num_estimators):\n        estimators[iter].fit(X_train_train, y_train_train)\n        valid_preds.append(estimators[iter].predict_proba(X_valid)) # warning: this matrix is linearly dependent. If you want to ge linearly independent matrix, drop first column\n    \n    preds.append(np.hstack((valid_preds)))\n    y_valid_list.append(y_valid)\n\n  cv_preds = np.vstack((preds))\n  cv_y = np.hstack((y_valid_list))\n\n  # Get test predictions\n  test_preds =[]\n  for iter in range(num_estimators):\n      estimators[iter].fit(X_train, y_train)\n      test_preds.append(estimators[iter].predict_proba(X_test)) # warning: this matrix is linearly dependent. If you want to ge linearly independent matrix, drop first column\n\n  test_preds_mat = np.hstack((test_preds))\n\n  # Fit the final estimator on cv prediction values \n  # And make a prediction on test predictoin values\n  final_estimator.fit(cv_preds, cv_y)\n  print('Training score: {}'.format(target_metric(final_estimator, cv_preds, cv_y)))\n  print(' Estimated coefficients: {} \\n intercept: {}'.format(final_estimator.coef_, final_estimator.intercept_))\n  \n  pred_fin = final_estimator.predict_proba(test_preds_mat)\n  return pred_fin","metadata":{"id":"ixki1gq_3Wwk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Base estimators\nlinear_ordinal = OrdinalClassifier(SGDClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='linear', 'best_hyper_param'].values[0]))\nrf_ordinal = OrdinalClassifier(RandomForestClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='rf', 'best_hyper_param'].values[0]))\nxgb_ordinal = OrdinalClassifier(XGBClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='xgb', 'best_hyper_param'].values[0]))\nmlp_ordinal = OrdinalClassifier(mlp).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='mlp', 'best_hyper_param'].values[0]))\n\nestimators = [linear_ordinal, xgb_ordinal, mlp_ordinal]\nestimators_name = 'linear_xgb_mlp'\n\n# Final estimator\nclf = LogisticRegression(penalty='l2', max_iter=1000, random_state=config['random_state'])\n\nestimators.append(clf)\nensemble_func = stack_clf\nensemble_name = 'stack_ridge' + '_by_' + estimators_name\n\n# Run CV \nX = X_train\ny = y_train_trans\n\nres_df = CV_ensemble(ensemble_name, ensemble_func, estimators, X, y, n_folds=5, shuffle=True, random_state=config['random_state'])\nbest_cv_df = best_cv_df.append(res_df)","metadata":{"id":"c0h_Vp91oze7","outputId":"9f20979c-7d71-4a05-d64f-1ae3fb70f866"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2-5. Model Comparison based on CV results including model combination methods\n\nFrom the figure below, 'stack_ridge_by_linear_xgb_mlp' shows the best performance.","metadata":{"id":"pPbUEOsj84xw"}},{"cell_type":"code","source":"fig = px.box(best_cv_df, x='model', y='kappa', color='model', width=800)\nfig.show()","metadata":{"id":"O2h5NM8vH1Vf","outputId":"a2632f57-b3b0-475a-9ed1-f27eac33fc00"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"best_cv_df.to_csv('best_cv_results.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Make a prediction with the best model\n","metadata":{"id":"mqxwLjTU6jWq"}},{"cell_type":"code","source":"from sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Base estimators\nlinear_ordinal = OrdinalClassifier(SGDClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='linear', 'best_hyper_param'].values[0]))\nrf_ordinal = OrdinalClassifier(RandomForestClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='rf', 'best_hyper_param'].values[0]))\nxgb_ordinal = OrdinalClassifier(XGBClassifier()).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='xgb', 'best_hyper_param'].values[0]))\nmlp_ordinal = OrdinalClassifier(mlp).set_params(**eval(best_cv_df.loc[best_cv_df['model']=='mlp', 'best_hyper_param'].values[0]))\n\nestimators = [linear_ordinal, xgb_ordinal, mlp_ordinal]\nestimators_name = 'linear_xgb_mlp'\n\n# Final estimator\nclf = LogisticRegression(penalty='l2', max_iter=1000, random_state=config['random_state'])\n\nestimators.append(clf)\nensemble_func = stack_clf\nensemble_name = 'stack_ridge' + '_by_' + estimators_name\n\n# Run CV \nX = X_train\ny = y_train_trans\n\npred_proba = stack_clf(estimators, X, y,  X_test, n_folds=5, shuffle=True, random_state=config['random_state'])\npred = pred_proba.argmax(axis=1)\npred_trans = pred + 1\n\nres_df = pd.DataFrame({'Id': test['Id'], 'Response': pred_trans})\nres_df.to_csv('submission.csv', index=False)\nprint(ensemble_name)","metadata":{"id":"_fnE-46Q6ix1","outputId":"bc9b84e5-788f-45ee-ac18-0d9c03cddcfd"},"execution_count":null,"outputs":[]}]}