{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"effa9f0f-625c-4140-89f4-5a0073bb5f42"},"outputs":[],"source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or \n# pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input/train_2\"]).decode(\"utf8\"))"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2ca0ef40-b003-4811-b74d-1cab5be0c444"},"outputs":[],"source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom PIL import Image, ImageFilter\nimport random\nimport cv2\nimport os, glob\n\n#t = pd.read_csv('../input/train_info.csv'); t.head()\n#s = pd.read_csv('../input/submission_info.csv'); s.head()\ntrain_files = [f for f in glob.glob(\"../input/train_2/*\")]\ni_ = 0\nplt.rcParams['figure.figsize'] = (10.0, 10.0)\nplt.subplots_adjust(wspace=0, hspace=0)\nfor l in train_files[:100]:\n    im = cv2.imread(l)\n    im = cv2.resize(im, (50, 50)) \n    plt.subplot(10, 10, i_+1) #.set_title(l)\n    plt.imshow(cv2.cvtColor(im, cv2.COLOR_BGR2RGB)); plt.axis('off')\n    i_ += 1"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2144ee52-8235-4c02-bb99-a6cc54448599"},"outputs":[],"source":"import tensorflow as tf\nfrom scipy import ndimage"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"719c51dd-5d97-b885-fc19-5495c0adfee8"},"outputs":[],"source":"def load_images(folder, min_num_images):\n    \"\"\"Load the data for a single letter label.\"\"\"\n    image_files = os.listdir(folder)\n    dataset = np.ndarray(shape=(len(image_files), image_size, image_size), dtype=np.float32)\n    print(folder)\n    num_images = 0\n    for image in image_files:\n        image_file = os.path.join(folder, image)\n    try:\n        image_data = (ndimage.imread(image_file).astype(float) - pixel_depth / 2) / pixel_depth\n        dataset[num_images, :, :] = image_data\n        num_images = num_images + 1\n    except IOError as e:\n        print('Could not read:', image_file, ':', e, '- it\\'s ok, skipping.')\n    \n    dataset = dataset[0:num_images, :, :]\n    print('Full dataset tensor:', dataset.shape)\n    print('Mean:', np.mean(dataset))\n    print('Standard deviation:', np.std(dataset))\n    return dataset"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"cd9f4c1c-cab0-7afc-73b5-0bee3bfc692c"},"outputs":[],"source":"datset = load_images(\"../input/train_2\", 1)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"da70ad32-2d61-efd9-a4af-8094d1195ae1"},"outputs":[],"source":"import glob\nimage_list = []\nfor filename in glob.glob('../input/train_2/*.jpg'): #assuming gif\n    im=Image.open(filename)\n    image_list.append(im)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"2a1d474a-1710-84b8-2afb-4a578b2898dc"},"outputs":[],"source":"\nlen(image_list)"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f09220a5-4dc3-4def-6203-b93a5503be11"},"outputs":[],"source":""},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"f10b302f-57b5-ead4-226b-33c4be983f53"},"outputs":[],"source":"t = pd.read_csv('../input/train_info.csv'); t.head()"},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"07d09922-a58d-e086-e338-19d8a50fdb4b"},"outputs":[],"source":""}],"metadata":{"_change_revision":0,"_is_fork":false,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.2"}},"nbformat":4,"nbformat_minor":0}