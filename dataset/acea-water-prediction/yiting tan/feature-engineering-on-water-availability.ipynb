{"cells":[{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The Acea Group is one of the leading Italian multiutility operators. Listed on the Italian Stock Exchange since 1999, the company manages and develops water and electricity networks and environmental services. Acea is the foremost Italian operator in the water services sector supplying 9 million inhabitants in Lazio, Tuscany, Umbria, Molise, Campania.\n\nIn this competition we will focus only on the water sector to help Acea Group preserve precious waterbodies. As it is easy to imagine, a water supply company struggles with the need to forecast the water level in a waterbody (water spring, lake, river, or aquifer) to handle daily consumption. During fall and winter waterbodies are refilled, but during spring and summer they start to drain. To help preserve the health of these waterbodies it is important to predict the most efficient water availability, in terms of level and water flow for each day of the year."},{"metadata":{},"cell_type":"markdown","source":"**Executive Summary **\n* "},{"metadata":{},"cell_type":"markdown","source":"**Data**"},{"metadata":{},"cell_type":"markdown","source":"**Data Preprocessing**\n* Many values are missing, espeicially data in the distant past. We delete the first one or two years of data that is largely missing; for other missing points we use interpolation to fill the data \n* There are a few unlikely zero values - we convert them to nan and interpolate \n* We take absolute value of the flow rate, as told in the discussion section\n* We convert float to int, for easier computation \n* Date: we convert the date into date and take month out. We downsample the data to each month using averages. We use one-hot encoding for the month. "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Feature Engineering**\n* We are dealing with a timeseries with seasonal influences, and past data will affect the next one. We use past value as a feature - at least attempting to. For some datasets, this value does not seem to be of relevance. \n* There is definitely a lagging effect on the level of rainfall and temperature on the water level. We augment the dataset with the past three and past month data - sum of rainfall in the past one and three months and weather averages for the past one and three months, and also the (averaged) target value of the past month and past three months.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Selection**\n* We use simple baseline - value at t to infer value at t+1\n* Baseline leanring model is a SVM with rbf kernel and a linear model with basic features\n* We experiement with different and combined version of augmented features and select factors of relevance \n* We use LSTM and GRU (seq2seq) model to predict the next value given past data"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np \ndf = pd.read_csv(\"/kaggle/input/acea-water-prediction/Aquifer_Auser.csv\") #River_Arno.csv\ndf = df[3000:]\nimport scipy\ndf = df.interpolate(method=\"pchip\")\nfrom datetime import datetime\ndf['date'] = df['Date'].apply(lambda x: datetime.strptime(x, \"%d/%m/%Y\"))\ndf['month'] = df['date'].apply(lambda x: int(x.month))\n# Get one hot encoding of columns B\none_hot = pd.get_dummies(df['month'])\n# Drop column B as it is now encoded\ndf = df.drop('month',axis = 1)\n# Join the encoded df\ndf = df.join(one_hot)\ndf.set_index('date',inplace=True)\ndf = df.resample('M').mean()\ndf = df.dropna().reset_index()\nprint(list(df.columns))\nprint(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\ncorrMatrix = df.corr()\nsns.heatmap(corrMatrix, annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"train = df[:102]\ntest = df[102:]\n\nx_train = train[['Rainfall_Gallicano', 'Rainfall_Pontetetto', 'Rainfall_Monte_Serra', 'Rainfall_Orentano', 'Rainfall_Borgo_a_Mozzano', 'Rainfall_Piaggione', 'Rainfall_Calavorno', 'Rainfall_Croce_Arcana', 'Rainfall_Tereglio_Coreglia_Antelminelli', 'Rainfall_Fabbriche_di_Vallico', 'Temperature_Orentano', 'Temperature_Monte_Serra', 'Temperature_Ponte_a_Moriano', 'Temperature_Lucca_Orto_Botanico', 'Volume_POL', 'Volume_CC1', 'Volume_CC2', 'Volume_CSA', 'Volume_CSAL', 'Hydrometry_Monte_S_Quirico', 'Hydrometry_Piaggione', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]].to_numpy().astype(int)\n#y=  df['Depth_to_Groundwater_SAL'].astype(int) \ny_train=  train['Depth_to_Groundwater_LT2'].astype(int) \nx_test = test[['Rainfall_Gallicano', 'Rainfall_Pontetetto', 'Rainfall_Monte_Serra', 'Rainfall_Orentano', 'Rainfall_Borgo_a_Mozzano', 'Rainfall_Piaggione', 'Rainfall_Calavorno', 'Rainfall_Croce_Arcana', 'Rainfall_Tereglio_Coreglia_Antelminelli', 'Rainfall_Fabbriche_di_Vallico', 'Temperature_Orentano', 'Temperature_Monte_Serra', 'Temperature_Ponte_a_Moriano', 'Temperature_Lucca_Orto_Botanico', 'Volume_POL', 'Volume_CC1', 'Volume_CC2', 'Volume_CSA', 'Volume_CSAL', 'Hydrometry_Monte_S_Quirico', 'Hydrometry_Piaggione', 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]].to_numpy().astype(int)\n#y=  df['Depth_to_Groundwater_SAL'].astype(int) \ny_test =  test['Depth_to_Groundwater_LT2'].astype(int) \n#y=  df['Depth_to_Groundwater_SAL'].astype(int) \n#y=  df['Depth_to_Groundwater_PAG'].astype(int) \n#y=  df['Depth_to_Groundwater_CoS'].astype(int) \n#y=  df['Depth_to_Groundwater_DIEC'].astype(int) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#from sklearn.model_selection import train_test_split\n#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)\n\nfrom sklearn.svm import SVR\nrf = SVR(kernel = 'rbf')\nrf.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = rf.predict(x_test)\nfrom sklearn import metrics\nerrors = metrics.mean_absolute_error(y_test, predictions)\n# Print out the mean absolute error (mae)\nprint('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\nerrors2 = np.sqrt(metrics.mean_squared_error(y_test, predictions))\n# Print out the rooted mse\nprint('rMSE:', round(np.mean(errors2), 2), 'degrees.')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}