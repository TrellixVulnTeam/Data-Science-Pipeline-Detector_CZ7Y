{"cells":[{"metadata":{},"cell_type":"markdown","source":"# EDA of the aquifers datasets\n\n## Encyclopedic knowlege\nThe aquifers (literaly a water-carriers) are underground water sources. The water is stored in porous rock layers (e.g. sand), where the is an underlying bed of low-permeability rock (e.g. clay). Sometimes the low-permeability rock layer can also be above the porous layer, then it forms a confined aquifer, that can carry water at considerable overpressure. Auquifers can be stacker on top of each other, with unconfined aquifer above a confined aquifer:\n\nhttps://www.canada.ca/en/environment-climate-change/services/water-overview/sources/groundwater/_jcr_content/par/img_305/image.img.gif/1506365092299.gif\n\nThe water table is the upper surface of the water that is contained in the ground. At some places, this height can be above the ground level. In such cases, the well would spill (even spout).\n\nThe height of the water table should be equal at each place of a given aquifer in quazi-static conditions, due to gravity. From this one might think that the depth to groundwater (DTG) depends on additional parameter of surface of land elevation. However under condition of rapid water extraction and low flowrates of the water through the porous rocks, the conditions are strongly non-equilibrium.\n\n## water ballance\n\nhttps://www.canada.ca/en/environment-climate-change/services/water-overview/sources/groundwater/_jcr_content/par/img_48812/image.img.gif/1506362514201.gif\n\nWater turnover in the aquifer can vary dramaticaly. Estimated water storage times ranges form 2 weeks to 10000 years. Some aquifers contain water from the melted snow/ice from the last glacial period. Some contain residual prehistoric seawater.\n\n### discharge\n* The water from an aquifer is extracted by means of a well (Pozzo). This extraction is metered by water plant in volume quantities.\n* The opoen aquifers may be extracted by plants, that drain water with their roots and cause water evaporation form leafs.\n* Discharge to the surface can be caused by a water spring.\n* Discharge by seepage into the sea. In this case, contamination by sea salt can occur.\n\nDischarge of water leads to lowering of the water table (the top surface of the water filling the aquifer). This leads to an decrease of the \"depth to ground\" parameter of the well.\n\n### recharge\n\n* The water in acquifer is replenished by precipitation (called also meteoric water). Especially in the case of confined aquifers, the area where the rainfall seeps into the aqfer can be away from the well that is used for its extraction. \n* Seepage form the river/stream bed.\n* from the sea (salty).\n\nRecharge of water leads to rising of the water table. This leads to an increase of the \"depth to ground\" parameter of the well.\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install networkx tigramite","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport sklearn\nimport tigramite\n\nfrom tigramite import data_processing as pp\nfrom tigramite import plotting as tp\nfrom tigramite.pcmci import PCMCI\nfrom tigramite.independence_tests import ParCorr, GPDC, CMIknn, CMIsymb\nfrom tigramite.models import LinearMediation, Prediction","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"aqfs = dict()\nbasename = 'Aquifer_'\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if basename in filename:\n            link = os.path.join(dirname, filename)\n            aqf_name = filename.split('_')[-1].split('.')[0]\n            aqfs[aqf_name] = pd.read_csv(link, index_col=0, parse_dates=True,dtype=np.float32)\n            #print(aqfs[aqf_name].describe())\n            \n        ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Auser aquifer\nInfor from the competition documents: This water body consists of two subsystems, that we call NORH and SOUTH, where the former partly influences the behaviour of the latter.\n* The levels of the NORTH sector are represented by the values of the SAL, PAG, CoS and DIEC wells, \n* the levels of the SOUTH sector by the LT2 well.\n\nTargets: Depth_to_Groundwater_SAL, Depth_to_Groundwater_COS, Depth_to_Groundwater_LT2\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = aqfs['Auser']\n\ndt = df.index\ntimestamp_s = dt.map(datetime.timestamp)\n\nday = 24*60*60\nyear = (365.2425)*day # number of days in a year\n\ndf['year_sin'] = np.sin( timestamp_s * (2 * np.pi / year))\ndf['year_cos'] = np.cos(timestamp_s * (2 * np.pi / year))\n\ndf['month'] = dt.month\ndf['week_of_year'] = dt.isocalendar().week\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feats = ['Depth_to_Groundwater_LT2', 'Depth_to_Groundwater_SAL', 'Depth_to_Groundwater_CoS']\nrain_feats = ['Rainfall_Gallicano', 'Rainfall_Pontetetto', 'Rainfall_Monte_Serra',\n       'Rainfall_Orentano', 'Rainfall_Borgo_a_Mozzano', 'Rainfall_Piaggione',\n       'Rainfall_Calavorno', 'Rainfall_Croce_Arcana',\n       'Rainfall_Tereglio_Coreglia_Antelminelli',\n       'Rainfall_Fabbriche_di_Vallico']\ntemp_feats = ['Temperature_Orentano', 'Temperature_Monte_Serra',\n       'Temperature_Ponte_a_Moriano', 'Temperature_Lucca_Orto_Botanico']\nhydrometry = ['Hydrometry_Monte_S_Quirico', 'Hydrometry_Piaggione']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[feats].plot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data on Depth_to_Ground_X features are somehow burried in periodic up-and downs that occur every month. There are strange year-to-year jumps in the oscillations, as if the actual levels were set by water supply management authority (Acea).\n\nIt is tempting to use the top-most water level as the water table height. The water in the well cannot rise above the water table height. \nOn the other hand, the jumps of the upmost depth level seems to jump unnaturally at the end of every year. Instead, we will consider the abrupt changes an artifact of water level measurements, and smoothen the evolutions of the DTG paramter by taking the median value foe every month, or week interval. "},{"metadata":{},"cell_type":"markdown","source":"### Calculate the weekly and monthly medians"},{"metadata":{"trusted":true},"cell_type":"code","source":"timeslice = slice('01-01-2006',None) # check the whole time interval in the dataset\nfeats_diff = [feat+'_diff' for feat in feats]\n\n\nmonthly = df.loc[timeslice,feats].resample('1M').median()\nmonthly_dev = monthly[feats].diff()\nmonthly_dev['month'] = monthly_dev.index.month\nweekly = df.loc[timeslice,feats].resample('1w').median()\n\nweekly_dev=  weekly[feats] - monthly[feats].resample('1w').ffill()\n#df.loc[timeslice,['Depth_to_Groundwater_Podere_Casetta',]].plot()\n\n# restore the lost feature weak_of_year\nweekly_dev['week_of_year'] = weekly_dev.index.isocalendar().week\nweekly_dev['month'] = weekly_dev.index.month\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"years = slice('2006','2009')\nax = plt.axes()\ndf.loc[years,feats].plot(label=feats,ax=ax,alpha=0.3)\nmonthly.loc[years,feats].plot(ax=ax)\nplt.legend(loc=[1,0])\n\nplt.figure()\nax = plt.axes()\ndf.loc[timeslice,feats].plot(label=feats,ax=ax,alpha=0.3)\nmonthly[feats].plot(ax=ax)\nplt.legend(loc=[1,0])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The monthly medians represents the Depth values pretty shoothly. The strange up-and-downs are elliminated. In the case of CoS and SAL data, there are quite large monthly variations, with abrupt changes in depths. The data in  2020 contain zero values simultaneously in LT2 and CoS (maybe in SAL too), SAL reaches zero half a year later. Maybe a lack of senzor maintenance due to COVID-19 effects? This is candidate for removal.\n\nThe monthly medians of CoS and SAL follow similar patterns, with CoS showing larger variations.\nThe LT2 and SAL are also pretty correlated."},{"metadata":{},"cell_type":"markdown","source":"## how the DTG changes ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"for site in feats:\n    monthly_dev.boxplot(column=[site],by='month')\n    plt.ylabel('changes in monthly DTG averages')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# When it rains on Auser?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[timeslice,rain_feats].plot(subplots=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" The dataset shows almost complete history of rain records since 2006. There is a year of gap for year 2009 from Piaggione."},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('month').describe().loc[:,(rain_feats,'mean')].plot()\n#pp.ylim(0,8)\nplt.legend('',title='locations')\nplt.ylabel('mean daily rainfall (mm)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# What is the air temperature?"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[timeslice,temp_feats].plot(subplots=True)\nplt.figure()\ndf.groupby('month').describe().loc[:,(temp_feats,'mean')].plot()\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The temperature records are missing in 'Ponte_a_Moriano'."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Feature engineering ideas\n* The Features of Water extraction volumes (WEVs), Rainfall (RFL), Temperature and DTG should be related by some relation, that is stable in time.\n\n* DTG has meaning of state parameter (total remaining volume in the well), but in fact, we want to predict ist change with respect to its previous state (differential). Its actual value should be considered more as conditional parameter.\n* The WEV has meaning of a rate parameter (volume per day). \n* Rainfall parameter (RFL) has meaning of rate parameter (volume, per day).\n* Temperature has meaning of conditional parameter, that does not represent water quantity, but can influence how RFL increases DTG.\n\n* The oscillations of DTG parameter of Pozzos  within each year probably occurs due to extraction/replenishing cycle of the well. The fact that the amplitude of the oscillations are more or less constant suggests that the target boundary levels of DTG are set by a hydrological authority (presumably Acea itself). The Acea representative (Louisa) claims that POC well in fact is not used for water extraction, just metering. In that case the origin of the DTG oscillations are unclear. It may mean that the POC well is located near some of the other Pozzos that are used for extraction, and thus its levels are sychronized.\n* For predictions the monthly jumps of the DTG parameter is probably worthy to filter out."},{"metadata":{},"cell_type":"markdown","source":"# Causality discovery\n\nFor the purose of efficient causality discovery, we will utilize dedicated python package called Tigramite. It allows to efficiently reconstruct causal graphs from high-dimensional time series datasets and model the obtained causal dependencies for causal mediation and prediction analyses. Causal discovery is based on linear as well as non-parametric conditional independence tests applicable to discrete or continuously-valued time series.\n\n\nMore info can be found in the recent conference paper: J. Runge (2020): Discovering contemporaneous and lagged causal relations in autocorrelated nonlinear time series datasets. Proceedings of the 36th Conference on Uncertainty in Artificial Intelligence, UAI 2020,Toronto, Canada, 2019, AUAI Press, 2020. http://auai.org/uai2020/proceedings/579_main_paper.pdf\n\nFeatures\n\n*    high detection power even for large-scale time series datasets\n*    flexible conditional independence test statistics adapted to continuously-valued or discrete data, and different assumptions about linear or nonlinear dependencies\n*    automatic hyperparameter optimization for most tests\n*    prediction class based on sklearn models including causal feature selection\n"},{"metadata":{},"cell_type":"markdown","source":"## Weekly time scale\n\n### preprocessing of the data\nResampling the data and removal of the artifacts. We can filter the depth data, taking only the data that are close to the monthly averages:"},{"metadata":{"trusted":true},"cell_type":"code","source":"# selecting features according to their completeness\n\nfeats = ['Depth_to_Groundwater_LT2',\n       'Depth_to_Groundwater_SAL',\n       'Depth_to_Groundwater_CoS']\n\nrain_feats = ['Rainfall_Gallicano', 'Rainfall_Pontetetto', 'Rainfall_Monte_Serra',\n       'Rainfall_Orentano', 'Rainfall_Borgo_a_Mozzano', \n       'Rainfall_Calavorno', 'Rainfall_Croce_Arcana',\n       'Rainfall_Tereglio_Coreglia_Antelminelli',\n       'Rainfall_Fabbriche_di_Vallico']\ntemp_feats = ['Temperature_Orentano']\nvolumes = ['Volume_POL', 'Volume_CC1', 'Volume_CC2', 'Volume_CSA', 'Volume_CSAL']\nhydrometries = ['Hydrometry_Monte_S_Quirico', 'Hydrometry_Piaggione']\n\nselected_feats =[]\ntimeslice = slice('2007','03-2020')\nfor feat_list in [feats,temp_feats,rain_feats]:\n    selected_feats.extend(feat_list)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"timeslice = slice('2008','03-2020') # check this time interval in the dataset\n\ninterval = '1M' # new_sampling_interval_code\n\nmonthly = df.loc[timeslice,:].resample(interval).median().ffill() # resample whole dataset\n\ninterval = '1d' # new_sampling_interval_code\nmonthly_upsampled = monthly.resample(interval).interpolate('linear')\n\n# filter the data:\nmax_dev = {'Depth_to_Groundwater_CoS':0.3, \n                 'Depth_to_Groundwater_SAL':0.2,\n                 'Depth_to_Groundwater_LT2':0.2}\nfilterred = df.loc[timeslice,:] \n\ndfdiff = df.loc[timeslice,feats] - monthly_upsampled.loc[timeslice,feats]\nfor feat in feats:\n    dfdiff_idxs = dfdiff[feat].where(abs(dfdiff[feat]) > max_dev[feat]).dropna().index # indices of data out of maxdev bounds\n    filterred.loc[dfdiff_idxs,feat] = np.nan\n    filterred.loc[timeslice,feat] = filterred.loc[timeslice,feat].resample(interval).interpolate('linear')\n\n#compare the traces \nfig,ax = plt.subplots(ncols=1,nrows=1,figsize=(10,10))\ndf.loc[:,feats].plot(ax=ax)\nmonthly.loc[:,feats].plot(ax=ax)\nax.legend(loc=(1,0))\n\nfig,ax2 = plt.subplots(ncols=1,nrows=1,figsize=(10,10))\n#filterred.loc[timeslice,feats].resample(interval).interpolate('linear').plot(ax=ax2)\nfilterred[feats].plot(ax=ax2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removal of the non-nubmers\nfilterred=filterred.where(filterred.notna(), 0).loc[:,selected_feats]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## resample the filterred data into weekly intervals:"},{"metadata":{"trusted":true},"cell_type":"code","source":"interval = '1w' # new_sampling_interval_code\n\nweekly = filterred.resample(interval).mean() # resample whole dataset\n\nfig,ax = plt.subplots(ncols=1,nrows=1,figsize=(10,10))\nfilterred.loc[:,feats].plot(ax=ax)\nweekly.loc[:,feats].plot(ax=ax)\nax.legend(loc=(1,0))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## calculate the differential from the weekly data"},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly[feats] = weekly[feats].diff() # differentiate\nweekly = weekly.iloc[1:,:] # throw away the first line\nweekly[feats].boxplot()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## filter the differentials according to quartiles"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nquart = weekly[feats].describe().T\ncutoffs = 2*(-quart[r'25%'] + quart[r'75%']).abs() \n\nfeats_thrshld = cutoffs.to_dict()\n\nfor feat in feats:\n    weekly[feat] = weekly[feat].where(abs(weekly[feat]) < feats_thrshld[feat] , np.nan).fillna(value=0)\n    \nweekly[feats].boxplot()\nweekly[feats].plot(subplots=True,figsize=(15,12))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## add features based on datetime"},{"metadata":{"trusted":true},"cell_type":"code","source":"dt = weekly.index\ntimestamp_s = dt.map(datetime.timestamp)\n\nday = 24*60*60\nyear = (365.2425)*day # number of days in a year\n\nweekly['year_sin'] = np.sin( timestamp_s * (2 * np.pi / year))\nweekly['year_cos'] = np.cos(timestamp_s * (2 * np.pi / year))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## causality discovery on weekly data"},{"metadata":{"trusted":true},"cell_type":"code","source":"parcorr = ParCorr(significance='analytic')\n# select the data\ndataset = weekly\nvar_names = [col_name.split('_')[0][0]+col_name.split('_')[-1][0:2] for col_name in dataset.columns] # abbreviate the names\ndataframe = pp.DataFrame(data=dataset.values,var_names = var_names)\npcmci = PCMCI(\n    dataframe=dataframe, \n    cond_ind_test=parcorr,\n    verbosity=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"correlations = pcmci.get_lagged_dependencies(tau_max=15, val_only=True)['val_matrix']\n\n#plt.figure(figsize=(10,10))\nlag_func_matrix = tp.plot_lagfuncs(val_matrix=correlations, setup_args={'var_names':var_names, 'figsize':(18,10),\n                                    'x_base':2, 'y_base':1}); \nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rainfall featrues are loosing effect after max 7 weeks. Let us restrict the causality search to this number of past time steps."},{"metadata":{},"cell_type":"markdown","source":"## calculate the lagged causal effect\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"tau_max = 7\npc_alpha = 0.05\npcmci.verbosity = 1\n\nresults = pcmci.run_pcmciplus(tau_min=0, tau_max=tau_max, pc_alpha=pc_alpha)\n\nprint(\"Graph\")\nprint (results['graph'])\nprint(\"Adjacency MCI partial correlations\")\nprint (results['val_matrix'].round(2))\nprint(\"Adjacency p-values\")\nprint (results['p_matrix'].round(3))\n\nq_matrix = pcmci.get_corrected_pvalues(p_matrix=results['p_matrix'], fdr_method='fdr_bh',\n                                                  exclude_contemporaneous=False)\n\nlink_matrix = results['graph']\n\ntp.plot_graph(\n    val_matrix=results['val_matrix'],\n    link_matrix=link_matrix,\n    var_names=var_names,\n    link_colorbar_label='cross-MCI (edges)',\n    node_colorbar_label='auto-MCI (nodes)',\n    ); plt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"In the weekly time scale, the algorithm found the following causality pathways: \n* the Rain feature \"RAn\" directly influences Depth \"DSA\" with lag1 week\n* and RPo in 7 weeks influences DLT.\n* there seems to be communication between the DCo and DSA istantly, and with DLT in 5 or 4 weeks."},{"metadata":{},"cell_type":"markdown","source":"# Make the predictions based on the obtained causalities information\nFor this predictions we will use the linar regression model, together with the data processed by the tigramite package that reflect the causal dependency graph."},{"metadata":{"trusted":true},"cell_type":"code","source":"T=weekly.shape[0]\nN=weekly.shape[1]\npred = Prediction(dataframe=dataframe,\n        cond_ind_test=ParCorr(),   #CMIknn ParCorr\n        prediction_model = sklearn.linear_model.LinearRegression(),\n#         prediction_model = sklearn.gaussian_process.GaussianProcessRegressor(),\n        # prediction_model = sklearn.neighbors.KNeighborsRegressor(),\n#    data_transform=sklearn.preprocessing.StandardScaler(),\n    train_indices= range(int(0.8*T)),\n    test_indices= range(int(0.8*T), T),\n    verbosity=1\n    )\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## predict target 2 (Depth_to_ground_CoS, DCo)\n"},{"metadata":{},"cell_type":"markdown","source":"Now, we estimate causal predictors using get_predictors for the target variable 2 (DCo) taking into account a maximum past lag of tau_max. Note that the predictors are different for each prediction horizon. For example, at a prediction horizon of steps_ahead=1 we get the causal parents from the model plus some others:\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"target = 2\ntau_max = 7\npc_alpha = 0.05\npredictors = pred.get_predictors(\n                  selected_targets=[target],\n                  steps_ahead=1,\n                  tau_max=tau_max,\n                  pc_alpha=pc_alpha\n                  )\nlink_matrix = np.zeros((N, N, tau_max+1), dtype='bool')\nfor j in [target]:\n    for p in predictors[j]:\n        link_matrix[p[0], j, abs(p[1])] = 1\n\n# Plot time series graph\ntp.plot_time_series_graph(\n    figsize=(6, 3),\n    val_matrix=np.ones(link_matrix.shape),\n    link_matrix=link_matrix,\n    var_names=var_names,\n    link_colorbar_label='',\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred.fit(target_predictors=predictors, \n                selected_targets=[target],\n                    tau_max=tau_max)\n\npredicted = pred.predict(target)\ntrue_data = pred.get_test_array()[0]\n\nplt.scatter(true_data, predicted,alpha=0.3)\nplt.title(r\"NRMSE = %.2f\" % (np.abs(true_data - predicted).mean()/true_data.std()))\nplt.plot(true_data, true_data, 'k-')\nplt.xlabel('True test data')\nplt.ylabel('Predicted test data')\n\nfig, ax = plt.subplots(1,figsize=(10,10))\nax.plot(true_data)\nax.plot(predicted)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}