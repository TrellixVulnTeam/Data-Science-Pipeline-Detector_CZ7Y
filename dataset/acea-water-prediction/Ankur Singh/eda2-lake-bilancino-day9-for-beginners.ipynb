{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we have 10 different csv files for use , we would examine each of our csv files , let's do some EDA for all our csv files"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"We would start our EDA with River Arno\n\nThe Arno is a river in the Tuscany region of Italy. It is the most important river of central Italy after the Tiber"},{"metadata":{"trusted":true},"cell_type":"code","source":"arno = pd.read_csv('/kaggle/input/acea-water-prediction/River_Arno.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us see the null data first"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nsns.heatmap(arno.isnull())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"white part is the missing data"},{"metadata":{},"cell_type":"markdown","source":"LET US KNOW WHAT EACH COLUMN REPRESENT :\n1.Each Columns starting with Rainfall_X , here X is region , it tells us rainfall in region X in mm\n\n2.Temperature_Firenze represents temprature recorded by thermometric station Firenze (Temp in Celsius)\n\n3.Hydrometry_Nave_di_Rosano represents River Level recorder by hydrometric station at Rosano"},{"metadata":{},"cell_type":"markdown","source":"# EDA "},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('first date of observation :',arno['Date'][0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('last date of observation :',arno['Date'][8216])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.corr()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The high co relation between rain fall of different regions can be because of closer distance"},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(arno.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let Us Find Out Avg Level of River For Each Year\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1 = arno.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1['Day'] = arno_1['Date'].str.split('/').str[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1['Month'] = arno_1['Date'].str.split('/').str[1]\narno_1['Year'] = arno_1['Date'].str.split('/').str[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.bar(arno_1['Month'],arno_1['Hydrometry_Nave_di_Rosano'])\nplt.xlabel('Month')\nplt.ylabel('Water Level in Metre')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This clearly indicates that during June , July and August Water Level is at its lowest and during Nov , Dec  and Jan level at its peak "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,6))\nplt.bar(arno_1['Year'],arno_1['Hydrometry_Nave_di_Rosano'])\nplt.xlabel('Year')\nplt.ylabel('River Level')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no uniformity in the river level in the years , it seems to be quite radom "},{"metadata":{"trusted":true},"cell_type":"code","source":"#For Further EDA , I would drop missing values to keep things simple\narno_1.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that a huge amount of data has been lost after i dropped missing values but since it is for EDA , let's carry on EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Month'],arno_1['Temperature_Firenze'])\nplt.xlabel('Month')\nplt.ylabel('Temp of River')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Quite obvious thing That Temprature of river is highest in JULY and AUGUST but , temprature of river in July too ranges between 20 to 35"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\nplt.scatter(arno_1['Year'],arno_1['Temperature_Firenze'])\nplt.xlabel('Year')\nplt.ylabel('Temp of River')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As Years proceed highest temprature of river is also increasing , especially after 2014 , maximum temp has increased drastically"},{"metadata":{},"cell_type":"markdown","source":"# TEMPRATURE AND RIVER DEPTH RELATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Temperature_Firenze'],arno_1['Hydrometry_Nave_di_Rosano'])\nplt.xlabel('Temprature of River')\nplt.ylabel('River Level')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is again a Gaussian Curve , Maximum River Level Reaches at an optimal temprature of 10C to 20C \nexcept some outliers(exceptions) which would be studied furthur"},{"metadata":{},"cell_type":"markdown","source":"# RAINFALLS AND RIVER LEVEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Rainfall_Bibbiena'],arno_1['Hydrometry_Nave_di_Rosano'])\nplt.xlabel('Rainfall at BIBBIENA(mm)')\nplt.ylabel('River Level')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Rainfall_Camaldoli'],arno_1['Hydrometry_Nave_di_Rosano'])\nplt.xlabel('Rainfall at CAMALDOLI(mm)')\nplt.ylabel('River Level') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Rainfall_Cavallina'],arno_1['Hydrometry_Nave_di_Rosano'])\nplt.xlabel('Rainfall at CAVALLINA(mm)')\nplt.ylabel('River Level')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"ALL THESE TRENDS POINT AT SAME THING : MORE RAINFALL means MORE RIVER LEVEL"},{"metadata":{},"cell_type":"markdown","source":"*** END OF DAY 1 EDA ***"},{"metadata":{},"cell_type":"markdown","source":"# DAY 2 EDA"},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1.dropna()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# IS RAINFALL AFFECTING RIVER TEMPRATURE ?"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Rainfall_Bibbiena'],arno_1['Temperature_Firenze'])\nplt.xlabel('Rainfall at BIBBIENA')\nplt.ylabel('Temprature of River')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Rainfall_Camaldoli'],arno_1['Temperature_Firenze'])\nplt.xlabel('Rainfall at Camaldoli(mm)')\nplt.ylabel('Temprature of River(C)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(arno_1['Rainfall_Mangona'],arno_1['Temperature_Firenze'])\nplt.xlabel('Rainfall at Magona(mm)')\nplt.ylabel('Temprature of River(C)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Trends are same , More The Rainfall , Lesser the temprature of River and This trend is true for almost every Region "},{"metadata":{},"cell_type":"markdown","source":"INDEPTH ANALYSIS OF WATER LEVEL IN SUMMERS AND WINTERS"},{"metadata":{},"cell_type":"markdown","source":"we have seen water level of River is at lowest in JUNE AND JULY and highest in NOVEMBER AND JANURAY , let's see those trends more in depth"},{"metadata":{},"cell_type":"markdown","source":"# Analysis of JUNE"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.title('Water Level in June throughout Years')\narno_june = arno_1[arno_1['Month']=='06']\nsns.lineplot(x='Year',y='Hydrometry_Nave_di_Rosano',data=arno_june)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.title('Temprature of River in June throughout Years')\nsns.lineplot(x='Year',y='Temperature_Firenze',data=arno_june)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"CONCLUSION : Direct relationship between level of water and temprature of river exists water level was lowest in 2017 and temprature was also higest in 2017 even though low water level of 2009 can not be explained by this pattern"},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.title('Rainfall in different regions v/s River Water Level')\nsns.lineplot(x='Rainfall_Le_Croci',y='Hydrometry_Nave_di_Rosano',data=arno_june)\nsns.lineplot(x='Rainfall_Cavallina',y='Hydrometry_Nave_di_Rosano',data=arno_june)\nsns.lineplot(x='Rainfall_Vernio',y='Hydrometry_Nave_di_Rosano',data=arno_june)\nsns.lineplot(x='Rainfall_Camaldoli',y='Hydrometry_Nave_di_Rosano',data=arno_june)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I was trying to find some pattern in Water level and Rainfall at different regions in month of June and to find some pattern that must be common but there was not any similar pattern except that River Level is highlt unstable when Rainfall is below 30mm and after that River Level becomes almost constant in month of June"},{"metadata":{},"cell_type":"markdown","source":"# ANAYLYSIS OF NOVEMBER"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.title('Water Level in November throughout Years')\narno_nov = arno_1[arno_1['Month']=='11']\nsns.lineplot(x='Year',y='Hydrometry_Nave_di_Rosano',data=arno_nov)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Water Level is considerably high but there is no pattern throughout the years , 2008 is outlier when water level were very low even in November "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.title('Temprature of River in November throughout Years')\nsns.lineplot(x='Year',y='Temperature_Firenze',data=arno_nov)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.title('Rainfall in different regions v/s River Water Level')\nsns.lineplot(x='Rainfall_Le_Croci',y='Hydrometry_Nave_di_Rosano',data=arno_nov)\nsns.lineplot(x='Rainfall_Cavallina',y='Hydrometry_Nave_di_Rosano',data=arno_nov)\nsns.lineplot(x='Rainfall_Vernio',y='Hydrometry_Nave_di_Rosano',data=arno_nov)\nsns.lineplot(x='Rainfall_Camaldoli',y='Hydrometry_Nave_di_Rosano',data=arno_nov)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There is no regular pattern from which we can deduce any conclusion between Water Level and Rainfall at Different Regions"},{"metadata":{},"cell_type":"markdown","source":"# PREDICTIVE MODEL"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"We would make two models to predict LEVEL OF WATER IN RIVER , one would be Regression Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_1 =  arno_1.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = arno_1[[ 'Rainfall_Le_Croci', 'Rainfall_Cavallina', 'Rainfall_S_Agata',\n       'Rainfall_Mangona', 'Rainfall_S_Piero', 'Rainfall_Vernio',\n       'Rainfall_Stia', 'Rainfall_Consuma', 'Rainfall_Incisa',\n       'Rainfall_Montevarchi', 'Rainfall_S_Savino', 'Rainfall_Laterina',\n       'Rainfall_Bibbiena', 'Rainfall_Camaldoli', 'Temperature_Firenze',\n        'Month', 'Year']]\ny = arno_1['Hydrometry_Nave_di_Rosano']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train ,x_test ,y_train ,y_test = train_test_split(x,y,test_size=0.1,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nlin = LinearRegression()\nlin.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lin.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = lin.predict(x_test)\nfrom sklearn.metrics import mean_absolute_error,mean_squared_error\nimport math\nmean_abs_err = mean_absolute_error(y_pred,y_test)\nrmse = math.sqrt(mean_squared_error(y_test,y_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error',mean_abs_err)\nprint('Root Mean Square Error',rmse)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(y_test,y_pred)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is just a Trial Model which ic very poor"},{"metadata":{},"cell_type":"markdown","source":"**DAY 2 ends**"},{"metadata":{},"cell_type":"markdown","source":"# DAY 3 : MODEL BUILDING AND OPTIMIZATION\n today on day 3 , we would focus on how to select best algorithm and get best result for river level prediction , and what factors are influencing it how much !"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('linear regression score on train set is :',lin.score(x_train,y_train))\nprint('linear regression score on test set is : ',lin.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well there is a little over-fitting but model on the whole is performing very poor"},{"metadata":{},"cell_type":"markdown","source":"# LASSO REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Lasso\nlas = Lasso(alpha=0.1)\nlas.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('linear regression score on train set is :',las.score(x_train,y_train))\nprint('linear regression score on test set is :',las.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# now we would try to optimize our LASSO model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import GridSearchCV\nparam_grid = {'alpha':[0.1,0.2,0.3,0.4,0.45,0.5,0.55,0.6,0.65,0.7,0.9,0.005,1,5,10,0.001,0.0001]}\nserch = GridSearchCV(las,param_grid,cv=3,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = serch.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So basically the  alpha=-.005  is the most optimized param was  all the way , and so our lasso model is also not working good and 50 percent accuracy is way too ppor"},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = result.predict(x_test)\nprint('MAE',mean_absolute_error(y_pred,y_test))\nprint('RSME',math.sqrt(mean_squared_error(y_pred,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# KNN REGRESSION"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.neighbors import KNeighborsRegressor\nknn = KNeighborsRegressor()\nknn.fit(x_train,y_train)\nknn.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Optimising KNN model"},{"metadata":{"trusted":true},"cell_type":"code","source":"grid_parms = {\n    'n_neighbors':[3,4,5,6,10,15,20,25,30,35,40,45,50,55,90,105,110,150],\n    'weights' : ['uniform','distance'],\n    'metric' : ['eucledian','manhattan']\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs = GridSearchCV(knn,grid_parms,cv=5,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_k = gs.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Mean Absolute Error',mean_absolute_error(y_pred_k,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RMSE',math.sqrt(mean_squared_error(y_pred_k,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"EVEN AFTER ALL THE TUING WE JUST GOT ACCURACY OF 47 percent\n\nDAY 3 ends !!"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"DAY 4 : Trying more regression models\n\n\n"},{"metadata":{},"cell_type":"markdown","source":"DECISION TREES REGRESSOR"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\ntree = DecisionTreeRegressor()\ntree.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Testing Accuracy is : ',tree.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"WE WILL NOT CONSIDER DECISION TREE BECAUSE IT IS GIVING VERY POOR ACCURACY"},{"metadata":{},"cell_type":"markdown","source":"# RANDOM FOREST REGRESSOR"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nforest = RandomForestRegressor()\nforest.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy on Random Forest is :',forest.score(x_test,y_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model has relatively good model so we can futhur optimize it "},{"metadata":{},"cell_type":"markdown","source":"# OPTIMIZING RANDOM FOREST MODEL"},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'max_depth' : [10,20,30,40,50,60,70,80,90,100],\n    \n}\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fore = GridSearchCV(forest,param_grid,cv=5,verbose=1)\nfore.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fore.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'min_samples_split' : [100,500,1000,2000,4000,5000],\n    \n}\nfore = GridSearchCV(forest,param_grid,cv=5,verbose=1)\nfore.fit(x_train,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fore.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"param_grid = {\n    'n_estimators' : [100,200,300,400,500,600],\n    \n}\nfore = GridSearchCV(forest,param_grid,cv=5,verbose=1)\nfore.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fore.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fore = RandomForestRegressor(n_estimators=200,min_samples_split=100,max_depth=20)\nfore.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fore.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_rf = forest.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('MAE is : ',mean_absolute_error(y_pred_rf,y_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('RSME is : ',math.sqrt(mean_squared_error(y_pred_rf,y_test)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Random Forest MODEL has more accuracy without optimising "},{"metadata":{},"cell_type":"markdown","source":"# GRADIENT BOOSTING"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingRegressor\nboost = GradientBoostingRegressor()\nboost.fit(x_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boost.score(x_test,y_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"SO accuracy on testing dataset is 67 percent , which is a major improvement on previous models"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_importance =  boost.feature_importances_.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is a feature importance array , we would explore more about this tommorow !\n\nDAY 4 ends!!"},{"metadata":{},"cell_type":"markdown","source":"DAY 5\n\nlet us look at some Feature importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_list = x_train.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimportance = pd.DataFrame(list(zip(feature_list, feature_importance)), \n               columns =['Feature', 'Importance']) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"importance","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is feature importance as per gradeint boosting"},{"metadata":{},"cell_type":"markdown","source":"We would reduce features and wo select top 10 most important feature and would then check the accuracy "},{"metadata":{"trusted":true},"cell_type":"code","source":"x_opt = arno_1[['Temperature_Firenze','Rainfall_Consuma','Rainfall_Bibbiena','Month','Year','Rainfall_S_Savino',\n                      'Rainfall_Montevarchi','Rainfall_Camaldoli','Rainfall_Le_Croci','Rainfall_S_Agata']]\ny_opt = arno_1['Hydrometry_Nave_di_Rosano']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train_opt,x_test_opt,y_train_opt,y_test_opt = train_test_split(x_opt,y_opt,test_size=0.15,random_state=101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"boost.fit(x_train_opt,y_train_opt)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Accuracy on fewer columns testing data with gradient boosting : ',boost.score(x_test_opt,y_test_opt))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest.fit(x_train_opt,y_train_opt)\nprint('accuracy on fewer columns testing data with Random Forest : ',forest.score(x_test_opt,y_test_opt))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM CODE FOR RIVER LEVEL PREDICTION"},{"metadata":{},"cell_type":"markdown","source":"we would be using Long Short Term Memory to predict River Water Level , we would consider it as a time series and fed it in the same way in LSTM model"},{"metadata":{"trusted":true},"cell_type":"code","source":"arno_lstm = arno_1.copy()\ndf = arno_lstm.reset_index()['Hydrometry_Nave_di_Rosano']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so basically here we created a data for all The Hydrometry(River Level) as a time series format"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Pattern of Falling and rising of Water Level through out time"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Scaling our data to pass into LSTM as it is sensitive to scaling\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range=(0,1))\ndf = scaler.fit_transform(np.array(df).reshape(-1,1))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so we basically converted our DataFrame into one dimensional array and also scaled it between 0 and 1 before feeding it to LSTM\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"#separating traing and testing data\ntraining_size = int(len(df)*0.70)\ntest_size = len(df) - training_size\ntrain_data,test_data = df[0:training_size,:],df[training_size:len(df),:1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_size","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert an arrays of value into dataset matrix\ndef create_dataset(dataset,timestep=1):\n    dataX,dataY = [],[]\n    for i in range(len(dataset)-timestep-1):\n        a = dataset[i:(i+timestep),0]\n        dataX.append(a)\n        dataY.append(dataset[i+timestep,0])\n    return np.array(dataX),np.array(dataY)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reshape our dataset into 100 time steps\ntime_step=50\nx_train,y_train = create_dataset(train_data,time_step)\nx_test,y_test = create_dataset(test_data,time_step)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#As LSTM model expexts 3D input so we would reshape our input data\nx_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\nx_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so basically we have 842 data points and taking a time stamp of 50 at a time , it means 50 points would be taken at a time"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Creating LSTM Model\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nmodel = Sequential()\nmodel.add(LSTM(50,return_sequences=True,input_shape=(50,1)))\nmodel.add(LSTM(50,return_sequences=True))\nmodel.add(LSTM(50))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error',optimizer='adam')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=80,batch_size=64,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_predict = model.predict(x_train)\ntest_predict = model.predict(x_test)\ntrain_predict = scaler.inverse_transform(train_predict)\ntest_predict = scaler.inverse_transform(test_predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"math.sqrt(mean_squared_error(y_train,train_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"math.sqrt(mean_squared_error(y_test,test_predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# shift train predictions for plotting\nlook_back=50\ntrainPredictPlot = np.empty_like(df)\ntrainPredictPlot[:, :] = np.nan\ntrainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n# shift test predictions for plotting\ntestPredictPlot = np.empty_like(df)\ntestPredictPlot[:, :] = np.nan\ntestPredictPlot[len(train_predict)+(look_back*2)+1:len(df)-1, :] = test_predict\n# plot baseline and predictions\nplt.plot(scaler.inverse_transform(df))\nplt.plot(trainPredictPlot)\nplt.plot(testPredictPlot)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So basically blue lines are the trends in our real data , orange lines are how our training data is fitting and green points are how our testing data is fitting which is doing quite good barring some outliers"},{"metadata":{},"cell_type":"markdown","source":"# PREDICTING FUTURE VALUES"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"383-50","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_input=test_data[333:].reshape(1,-1)\nx_input.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_input=list(x_input)\ntemp_input=temp_input[0].tolist()\ntemp_input","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting values for next 10 days\nfrom numpy import array\n\nlst_output=[]\nn_steps=50\ni=0\nwhile(i<10):\n    \n    if(len(temp_input)>100):\n        #print(temp_input)\n        x_input=np.array(temp_input[1:])\n        print(\"{} day input {}\".format(i,x_input))\n        x_input=x_input.reshape(1,-1)\n        x_input = x_input.reshape((1, n_steps, 1))\n        #print(x_input)\n        yhat = model.predict(x_input, verbose=0)\n        print(\"{} day output {}\".format(i,yhat))\n        temp_input.extend(yhat[0].tolist())\n        temp_input=temp_input[1:]\n        #print(temp_input)\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    else:\n        x_input = x_input.reshape((1, n_steps,1))\n        yhat = model.predict(x_input, verbose=0)\n        print(yhat[0])\n        temp_input.extend(yhat[0].tolist())\n        print(len(temp_input))\n        lst_output.extend(yhat.tolist())\n        i=i+1\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"day_new=np.arange(1,101)\nday_pred=np.arange(101,111)\nplt.plot(day_new,scaler.inverse_transform(df[1176:]))\nplt.plot(day_pred,scaler.inverse_transform(lst_output))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So blue line is trend in river level for last 100 days and then orange is river level prediction for next 10 days !"},{"metadata":{},"cell_type":"markdown","source":"DAY 6 ends\n"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"DAY 7 \n# LAKE BILANCINO"},{"metadata":{},"cell_type":"markdown","source":"Lago di Bilancino is an artificial lake near Barberino di Mugello in the Metropolitan City of Florence, Tuscany, Italy, made with a dam on the river Sieve. At an elevation of 252 m, the lake surface area is approximately 5 km²"},{"metadata":{"trusted":true},"cell_type":"code","source":"lake = pd.read_csv('/kaggle/input/acea-water-prediction/Lake_Bilancino.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lake.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lake.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Understanding DATA : \n    Rainfall_X : It indicates the quantity of rain falling, expressed in millimeters (mm), in the area X\n    \n    Flow_Rate : It indicates the lake's flow rate, expressed in cubic meters per seconds (mc/s)\n    \n    Lake_Level : It indicates the lake level, expressed in meters (m)\n    \n    Temperature_Y : It indicates the temperature, expressed in °C, detected by the thermometric station Y\n\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(lake.isnull())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"White Portion Represents Missing Data "},{"metadata":{},"cell_type":"markdown","source":"Let's see how much missing data is in each column"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport missingno as msno ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"msno.bar(lake)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All Rainfall DATA is majorly missing , so for our furthur EDA purpose , we can remove missing data"},{"metadata":{"trusted":true},"cell_type":"code","source":"lake_1 = lake.dropna()\nprint('original data shape',lake.shape)\nprint('missing values removed data shape',lake_1.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"almost 600 entries were removed from 6000 which is almost 10 percent , we would deal with it later !"},{"metadata":{},"cell_type":"markdown","source":"# CO RELATION"},{"metadata":{"trusted":true},"cell_type":"code","source":"lake_1.corr()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = lake_1.corr()\nsns.heatmap(lake_1.corr(),xticklabels=corr.columns,\n        yticklabels=corr.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"There are some intersting observatons which we discuss ahead....."},{"metadata":{},"cell_type":"markdown","source":"1. Rainfall and Lake Level has negative co relation which means Negative correlation is a relationship between two variables in which one variable increases as the other decreases, and vice versa\n\n2.Flow Rate and Lake Level has positive co relation\n\n3.Rainfall and Temprature has negative co relation"},{"metadata":{},"cell_type":"markdown","source":"# LAKE LEVEL AND FLOW RATE "},{"metadata":{"trusted":true},"cell_type":"markdown","source":"let us see how both are related or un related or how are both affecting each other"},{"metadata":{},"cell_type":"markdown","source":"let us see how both are related or un related or how are both affecting each other"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(lake_1['Flow_Rate'],lake_1['Lake_Level'])\nplt.xlabel('FLOW RATE mc/s')\nplt.ylabel('Water LEVEL (m)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so baically most of flow rate is between 0 and 10 and usually water level stays highest at 252 around"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.bar(lake_1['Flow_Rate'],lake_1['Lake_Level'])\nplt.xlabel('FLOW RATE mc/s')\nplt.ylabel('Water LEVEL (m)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so basically this is telling us that most of the flow rate of water is between 0 to 30 mc/s"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.lineplot(x='Flow_Rate',y='Lake_Level',data=lake_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This gives us a idea that When Flow Rate is more there is a higher probability that Lake Level would be higher and as Flow Rate increases we have a higher probability of having a higher Lake Level"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist2d(lake_1['Flow_Rate'],lake_1['Lake_Level'])\nplt.xlabel('FLOW RATE mc/s')\nplt.ylabel('Water LEVEL (m)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"so the most probable situation in lake is when flow rate is between 0 and 10 and water level is between 250 and 252"},{"metadata":{},"cell_type":"markdown","source":"we will discuss trends based on different period of time ahead..."},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# Relation Between WATER LEVEL and TEMPRATURE"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(lake_1['Temperature_Le_Croci'],lake_1['Lake_Level'])\nplt.xlabel('Temprature in degree celsius')\nplt.ylabel('Water LEVEL (m)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So This is also a gaussian distribution and as it is evident that mostly during temprature 10 to 20 degree water level at it's most with around 252m "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist2d(lake_1['Temperature_Le_Croci'],lake_1['Lake_Level'])\nplt.xlabel('Temprature in degree celsius')\nplt.ylabel('Water LEVEL (m)')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"as we said earlier that most probably temprature is between 15 and 20 degree celsius and water level is around 251m and if try to predict flow rate at this situation , it would most probably be between 0 and 10 mc/s"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\nsns.lineplot(x='Temperature_Le_Croci',y='Lake_Level',data=lake_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"there is too much variance in the level and temprature but one this is quite evident that water level is maximum and least varying between 10 and 20 degree celsius temprature which again proves the point raised previously\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(lake_1['Temperature_Le_Croci'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" tempratures are scattered between -10 to 40 degree celsius peaking at around 10 degree celsius "},{"metadata":{},"cell_type":"markdown","source":"Now let us dive more into Temprature , Level and Flow rate and let us visualise all three at same time and deduce what we can...!"},{"metadata":{},"cell_type":"markdown","source":"# Temprature , Flow Rate and Level"},{"metadata":{},"cell_type":"markdown","source":"first let us break timestamp into months , days and years"},{"metadata":{"trusted":true},"cell_type":"code","source":"lake_1['Day'] = lake_1['Date'].str.split('/').str[0]\nlake_1['Month'] = lake_1['Date'].str.split('/').str[1]\nlake_1['Year'] = lake_1['Date'].str.split('/').str[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lake_1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,6))\nsns.lineplot(x='Year',y='Temperature_Le_Croci',data=lake_1)\nsns.lineplot(x='Year',y='Lake_Level',data=lake_1)\nsns.lineplot(x='Year',y='Flow_Rate',data=lake_1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"we will discuss about it and will do more EDA ahead"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}