{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"The Acea Group is one of the leading Italian multiutility operators. Listed on the Italian Stock Exchange since 1999, the company manages and develops water and electricity networks and environmental services. Acea is the foremost Italian operator in the water services sector supplying 9 million inhabitants in Lazio, Tuscany, Umbria, Molise, Campania.\n\nIn this competition Kagglers were asked to focus on the water sector to help Acea Group preserve precious waterbodies such as water springs, lakes, rivers, and aquifers. To help preserve the health of these waterbodies it is important to predict the water availability in terms of level and water flow for each day/month of the year.\n\nIn the following sections, I would like to show my work on the prediction of water availabilities and its accuracies in terms of mean absolute error, mean squared error, and R^2 beween obervation and prediction values.","metadata":{}},{"cell_type":"markdown","source":"# Content:\n\n1. Loading Data\n2. Visulization of Data\n3. Data imputation\n4. Exploratory Analysis and Feature Engineering\n5. Prediction","metadata":{}},{"cell_type":"code","source":"# import libraries that will be used in the analysis\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Loading Data","metadata":{}},{"cell_type":"code","source":"# loading all data into a list structure\nfiles=os.listdir('../input/acea-water-prediction')\nprint(files)\n# read cvs data files\nAquifer_Doganella=pd.read_csv('../input/acea-water-prediction/'+'Aquifer_Doganella.csv')\nAquifer_Auser=pd.read_csv('../input/acea-water-prediction/'+'Aquifer_Auser.csv')\nWater_Spring_Amiata=pd.read_csv('../input/acea-water-prediction/'+'Water_Spring_Amiata.csv')\nLake_Bilancino=pd.read_csv('../input/acea-water-prediction/'+'Lake_Bilancino.csv')\nWater_Spring_Madonna_di_Canneto=pd.read_csv('../input/acea-water-prediction/'+'Water_Spring_Madonna_di_Canneto.csv')\nAquifer_Luco=pd.read_csv('../input/acea-water-prediction/'+'Aquifer_Luco.csv')\nAquifer_Petrignano=pd.read_csv('../input/acea-water-prediction/'+'Aquifer_Petrignano.csv')\nWater_Spring_Lupa=pd.read_csv('../input/acea-water-prediction/'+'Water_Spring_Lupa.csv')\nRiver_Arno=pd.read_csv('../input/acea-water-prediction/'+'River_Arno.csv')\n# combine data into datasets\ndatasets = [Aquifer_Doganella,Aquifer_Auser,Water_Spring_Amiata,Lake_Bilancino,Water_Spring_Madonna_di_Canneto,\n           Aquifer_Luco,Aquifer_Petrignano,Water_Spring_Lupa,River_Arno]\ndatasets_names=['Aquifer_Doganella.csv', 'Aquifer_Auser.csv', 'Water_Spring_Amiata.csv', 'Lake_Bilancino.csv', 'Water_Spring_Madonna_di_Canneto.csv', 'Aquifer_Luco.csv', 'Aquifer_Petrignano.csv', 'Water_Spring_Lupa.csv', 'River_Arno.csv']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Visulization of Data \n","metadata":{}},{"cell_type":"code","source":"#boxplot of all variables in each file to examine data range and distribution\nfig,ax1 = plt.subplots(3,3,figsize=(15,15))\nfor i in range(len(datasets)):\n    ax1.flatten()[i].set_title(datasets_names[i][:-4])\n    datasets[i][datasets[i].columns[1:]].boxplot(ax=ax1.flatten()[i],rot=90)\nplt.tight_layout()\n    ","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation 1ï¼š**Data visulization using boxplot tells what variables are included in each data file and how responsive varibles and predictive variables are distributed. However, variable values are not at same scale (e.g. rainfall in mm, flow rate in cubic meter per sencond, and volume in cubic meter) which make it hard to fully view the distributions. Further data analysis including correlation, exploratory factor, and feature engineering are necessary. ","metadata":{}},{"cell_type":"markdown","source":"# 3.Data imputation and missing value treatment \nThere are a lot of missing values in the daily time series. for example the water use vollumes are mostly missing and they are hard to be replaced with meaningful values. In this analysis, monthly data were firstly grouped by from daily values and then monthly means were used to replace mising values","metadata":{}},{"cell_type":"code","source":"# define a function to plot features vs. target variables\ndef plot1(inputdata,features,target_var,ylabel1,ylabel2):\n    fig, ax1= plt.subplots(figsize=(15,5))\n    #inputdata['Year-mon']=pd.to_datetime(inputdata['Year-mon'])\n    ax1.bar(inputdata['Year-mon'],inputdata[features])\n    ax1.spines['left'].set_color('blue')\n    ax1.spines['left'].set_linewidth(3)\n    ax1.legend([features],loc=2)\n    ax2 =ax1.twinx()\n    ax2.plot(inputdata['Year-mon'],inputdata[target_var],color='red')\n    ax2.spines['right'].set_color('red')\n    ax2.spines['right'].set_linewidth(3)\n    ax1.set_ylabel(ylabel1)\n    ax1.set_xticks(range(0,len(inputdata),10))\n    ax1.set_xticklabels(inputdata['Year-mon'][range(0,len(inputdata),10)],rotation=90)\n    ax2.set_ylabel(ylabel2)\n    ax2.set_xticks(range(0,len(inputdata),10))\n    ax2.set_xticklabels(inputdata['Year-mon'][range(0,len(inputdata),10)],rotation=90)\n    ax2.legend([target_var[0]],loc=1)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# transform daily data into montly data using groupby\nfor i in range(len(datasets)): \n  datasets[i].drop(datasets[i][datasets[i].Date.isnull()].index,inplace = True,axis=0)\n  datasets[i]['Year-mon']=pd.to_datetime(datasets[i].Date).apply(lambda x: x.strftime('%Y-%m'))\ndatasets_monthly = [datasets[i].groupby('Year-mon').mean().reset_index() for i in range(len(datasets))]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_var=['Depth_to_Groundwater_Pozzo_1', 'Depth_to_Groundwater_Pozzo_2',\n       'Depth_to_Groundwater_Pozzo_3', 'Depth_to_Groundwater_Pozzo_4',\n       'Depth_to_Groundwater_Pozzo_5', 'Depth_to_Groundwater_Pozzo_6',\n       'Depth_to_Groundwater_Pozzo_7', 'Depth_to_Groundwater_Pozzo_8',\n       'Depth_to_Groundwater_Pozzo_9', ]\nplot1(datasets_monthly[0],'Rainfall_Monteporzio',target_var,'Rainfall, mm','Groundwater Level, m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot1(datasets_monthly[0],'Volume_Pozzo_9',['Depth_to_Groundwater_Pozzo_9'],'Volume cm','Groundwater Level, m')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Observation 2:** Relative dry years (less rainfall) appeared in 2015-2017, which seems to cause well water depth droped, especially at wells Pozzo_1 and Pozzo_9. While water usage seems not to be very important in water depth drops as there is some cooccurence between less water usage and greater water depth drop at the well Pozzo_9. Of course, these are just observation for occasion wells at their occasion times. More important info about important features can be seen later in prediction and feature importance analysis.","metadata":{}},{"cell_type":"markdown","source":"# 4. Exploratory Analysis and Feature Engineering","metadata":{}},{"cell_type":"code","source":"# create a season variable to see if it can help improve prediction\nfor i in range(len(datasets_monthly)):\n    datasets_monthly[i].loc[datasets_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('12|01|02'),'season']=1\n    datasets_monthly[i].loc[datasets_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('03|04|05'),'season']=2\n    datasets_monthly[i].loc[datasets_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('06|07|08'),'season']=3\n    datasets_monthly[i].loc[datasets_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('09|10|11'),'season']=4\n# create a dryness variable based on rainfall amount\nfor i in range(len(datasets_monthly)):\n    datasets_monthly[i].loc[datasets_monthly[i].iloc[:,1]>(datasets_monthly[i].iloc[:,1].mean()+datasets_monthly[i].iloc[:,1].std()),'dryness']=4\n    datasets_monthly[i].loc[(datasets_monthly[i].iloc[:,1]<=(datasets_monthly[i].iloc[:,1].mean()+datasets_monthly[i].iloc[:,1].std())) & (datasets_monthly[i].iloc[:,1]>datasets_monthly[i].iloc[:,1].mean()),'dryness']=3\n    datasets_monthly[i].loc[(datasets_monthly[i].iloc[:,1]>=(datasets_monthly[i].iloc[:,1].mean()-datasets_monthly[i].iloc[:,1].std())) & (datasets_monthly[i].iloc[:,1]<=datasets_monthly[i].iloc[:,1].mean()),'dryness']=2\n    datasets_monthly[i].loc[datasets_monthly[i].iloc[:,1]<(datasets_monthly[i].iloc[:,1].mean()-datasets_monthly[i].iloc[:,1].std()),'dryness']=1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Predictive Accuracy and Feature Importance**","metadata":{}},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\nf,ax3 = plt.subplots(9,2,figsize=(10,50))\n# setup target variabe list\ntarget_var = [[col for col in datasets_monthly[0].columns if 'Depth' in col]]\ntarget_var.append([col for col in datasets_monthly[1].columns if 'Depth' in col])\ntarget_var.append([col for col in datasets_monthly[2].columns if 'Flow_Rate' in col])\ntarget_var.append([col for col in datasets_monthly[3].columns if 'Lake' in col])\ntarget_var.append([col for col in datasets_monthly[4].columns if 'Flow_Rate' in col])\ntarget_var.append([col for col in datasets_monthly[5].columns if 'Depth' in col])\ntarget_var.append([col for col in datasets_monthly[6].columns if 'Depth' in col])\ntarget_var.append([col for col in datasets_monthly[7].columns if 'Flow_Rate' in col])\ntarget_var.append([col for col in datasets_monthly[8].columns if 'Hydrometry' in col])\n# create a dataframe to store prediction results\nstats_index=[datasets_names[j][:-4]+': '+item for j, sublist in enumerate(target_var) for item in sublist]\nstats = pd.DataFrame(columns=['MSE','MAE','R-Squared','Top 3 important features'],index=stats_index)\nfor j in range(len(target_var)):\n    for i,target in enumerate(target_var[j]):\n        #select non-null values of responsive variable and imputing nan values of predictive variables by mean\n        idx1 = datasets_monthly[j][target].notnull()\n        data = datasets_monthly[j][idx1].fillna(datasets_monthly[j][idx1].mean())\n        x = data.drop(target_var[j],axis=1)\n        x = x.drop('Year-mon',axis=1)\n        y = data[target]\n        x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n        np.random.seed(1234)\n        RFG = RandomForestRegressor(n_estimators=20,random_state=0)\n        RFG.fit(x_train,y_train)\n        importance = RFG.feature_importances_\n        # output statistics of prediction\n        stats.loc[f'{datasets_names[j][:-4]}: {target}','MSE']=f'{mean_squared_error(y_test,RFG.predict(x_test)):.3f}'\n        stats.loc[f'{datasets_names[j][:-4]}: {target}','MAE']=f'{mean_absolute_error(y_test,RFG.predict(x_test)):.3f}' \n        stats.loc[f'{datasets_names[j][:-4]}: {target}','R-Squared']=f'{r2_score(y_test,RFG.predict(x_test)):.3f}'\n        stats.loc[f'{datasets_names[j][:-4]}: {target}','Top 3 important features']= [list(x.columns[np.argsort(importance)[::-1][:3]])]\n        # give an example of prediction in visulization\n        if j == 0:\n            ax3[i,0].plot(y_test,RFG.predict(x_test),'.')\n            ax3[i,0].plot(np.linspace(np.amin(y_test),np.amax(y_test),100),np.linspace(np.amin(y_test),np.amax(y_test),100),'k')\n            ax3[i,0].set_ylabel('Predicted')\n            ax3[i,0].set_xlabel('Observed')\n            ax3[i,0].text(np.min(y_test),np.max(y_test)-1,f'MSE: {mean_squared_error(y_test,RFG.predict(x_test)):.3f}')\n            ax3[i,0].text(np.min(y_test),np.max(y_test)-2,f'MAE: {mean_absolute_error(y_test,RFG.predict(x_test)):.3f}')\n            ax3[i,0].text(np.min(y_test),np.max(y_test)-3,f'R-Squared: {r2_score(y_test,RFG.predict(x_test)):.3f}' )\n            ax3[i,0].set_title(f'{target}, meter')   \n            ax3[i,1].bar(range(len(importance)),importance)\n            ax3[i,1].set_xticks(range(len(importance)))\n            ax3[i,1].set_xticklabels(x.columns,rotation=90)\n            ax3[i,1].set_ylabel('Importance')\n    plt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 6. Statistics of prediction","metadata":{}},{"cell_type":"code","source":"stats\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"stats.to_csv('final_stats.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}