{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport math\n\nAquiferDoganella=pd.read_csv('Aquifer_Doganella.csv')\nAquiferAuser=pd.read_csv('Aquifer_Auser.csv')\nWaterSpringAmiata=pd.read_csv('Water_Spring_Amiata.csv')\nLakeBilancino=pd.read_csv('Lake_Bilancino.csv')\nWaterSpringMadonna=pd.read_csv('Water_Spring_Madonna_di_Canneto.csv')\nAquiferLuco=pd.read_csv('Aquifer_Luco.csv')\nAquiferPetrignano=pd.read_csv('Aquifer_Petrignano.csv')\nWaterSpringLupa=pd.read_csv('Water_Spring_Lupa.csv')\nRiverArno=pd.read_csv('River_Arno.csv')\n\n# juntando todos os dataset em um (join all dataset in just one called 'dados')\ndados = [AquiferDoganella,AquiferAuser,WaterSpringAmiata,LakeBilancino,WaterSpringMadonna,\n           AquiferLuco,AquiferPetrignano,WaterSpringLupa,RiverArno]\ndados_arquivos=['Aquifer_Doganella.csv', 'Aquifer_Auser.csv', 'Water_Spring_Amiata.csv', 'Lake_Bilancino.csv', 'Water_Spring_Madonna_di_Canneto.csv', 'Aquifer_Luco.csv', 'Aquifer_Petrignano.csv', 'Water_Spring_Lupa.csv', 'River_Arno.csv']\n\ndef plot1(inputdata,features,target_var,ylabel1,ylabel2):\n    fig, ax1= plt.subplots(figsize=(15,5))\n    ax1.bar(inputdata['Year-mon'],inputdata[features])\n    ax1.spines['left'].set_color('black')\n    ax1.spines['left'].set_linewidth(3)\n    ax1.legend([features],loc=2)\n    ax2 =ax1.twinx()\n    ax2.plot(inputdata['Year-mon'],inputdata[target_var],color='grey')\n    ax2.spines['right'].set_color('blue')\n    ax2.spines['right'].set_linewidth(3)\n    ax1.set_ylabel(ylabel1)\n    ax1.set_xticks(range(0,len(inputdata),10))\n    ax1.set_xticklabels(inputdata['Year-mon'][range(0,len(inputdata),10)],rotation=90)\n    ax2.set_ylabel(ylabel2)\n    ax2.set_xticks(range(0,len(inputdata),10))\n    ax2.set_xticklabels(inputdata['Year-mon'][range(0,len(inputdata),10)],rotation=90)\n    ax2.legend([target_var[0]],loc=1)\n    \n# converting dates\nfor i in range(len(dados)): \n  dados[i].drop(dados[i][dados[i].Date.isnull()].index,inplace = True,axis=0)\n  dados[i]['Year-mon']=pd.to_datetime(dados[i].Date).apply(lambda x: x.strftime('%Y-%m'))\ndados_monthly = [dados[i].groupby('Year-mon').mean().reset_index() for i in range(len(dados))]\n\ndadosSelect=['Depth_to_Groundwater_Pozzo_1', 'Depth_to_Groundwater_Pozzo_2',\n       'Depth_to_Groundwater_Pozzo_3', 'Depth_to_Groundwater_Pozzo_4',\n       'Depth_to_Groundwater_Pozzo_5', 'Depth_to_Groundwater_Pozzo_6',\n       'Depth_to_Groundwater_Pozzo_7', 'Depth_to_Groundwater_Pozzo_8',\n       'Depth_to_Groundwater_Pozzo_9', ]\nplot1(dados_monthly[0],'Rainfall_Monteporzio',dadosSelect,'Rainfall, mm','Groundwater Level, m')\n\n# setup a variavel aim\naim = [[col for col in dados_monthly[0].columns if 'Depth' in col]]\naim.append([col for col in dados_monthly[1].columns if 'Depth' in col])\naim.append([col for col in dados_monthly[2].columns if 'Flow_Rate' in col])\naim.append([col for col in dados_monthly[3].columns if 'Lake' in col])\naim.append([col for col in dados_monthly[4].columns if 'Flow_Rate' in col])\naim.append([col for col in dados_monthly[5].columns if 'Depth' in col])\naim.append([col for col in dados_monthly[6].columns if 'Depth' in col])\naim.append([col for col in dados_monthly[7].columns if 'Flow_Rate' in col])\naim.append([col for col in dados_monthly[8].columns if 'Hydrometry' in col])\n\nfor i in range(len(dados_monthly)):\n    dados_monthly[i].loc[dados_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('12|01|02'),'season']=1\n    dados_monthly[i].loc[dados_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('03|04|05'),'season']=2\n    dados_monthly[i].loc[dados_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('06|07|08'),'season']=3\n    dados_monthly[i].loc[dados_monthly[i]['Year-mon'].str.split('-').str[1].str.contains('09|10|11'),'season']=4\n    \n    \nfor i in range(len(dados_monthly)):\n    dados_monthly[i].loc[dados_monthly[i].iloc[:,1]>(dados_monthly[i].iloc[:,1].mean()+dados_monthly[i].iloc[:,1].std()),'dryness']=4\n    dados_monthly[i].loc[(dados_monthly[i].iloc[:,1]<=(dados_monthly[i].iloc[:,1].mean()+dados_monthly[i].iloc[:,1].std())) & (dados_monthly[i].iloc[:,1]>dados_monthly[i].iloc[:,1].mean()),'dryness']=3\n    dados_monthly[i].loc[(dados_monthly[i].iloc[:,1]>=(dados_monthly[i].iloc[:,1].mean()-dados_monthly[i].iloc[:,1].std())) & (dados_monthly[i].iloc[:,1]<=dados_monthly[i].iloc[:,1].mean()),'dryness']=2\n    dados_monthly[i].loc[dados_monthly[i].iloc[:,1]<(dados_monthly[i].iloc[:,1].mean()-dados_monthly[i].iloc[:,1].std()),'dryness']=1\n\n# create features of previous month for analyzes \nfor i in range(len(dados_monthly)):\n    newDado =[newDado for newDado in dados_monthly[i].columns if newDado not in aim[i]][1:]\n    for j in range(len(newDado)):\n        dados_monthly[i][f'{newDado[j]}_previous_month1']=np.append([np.nan],dados_monthly[i].iloc[:-1][f'{newDado[j]}'].values)\n\n        #Accuracy\n\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score\nf,ax3 = plt.subplots(9,2,figsize=(10,50))\n# dataframe\nindex=[dados_arquivos[j][:-4]+': '+item for j, sublist in enumerate(aim) for item in sublist]\nstart = pd.DataFrame(columns=['MSE','MAE','R-Squared','Top 3 important features'],index=index)\nfor j in range(len(aim)):\n    for i,target in enumerate(aim[j]):\n        #select non-null values\n        idx1 = dados_monthly[j][target].notnull()\n        data = dados_monthly[j][idx1].fillna(dados_monthly[j][idx1].mean())\n        x = data.drop(aim[j],axis=1)\n        x = x.drop('Year-mon',axis=1)\n        y = data[target]\n        x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.3)\n        np.random.seed(1234)\n        RFG = RandomForestRegressor(n_estimators=40,random_state=0)\n        RFG.fit(x_train,y_train)\n        importance = RFG.feature_importances_\n        \n\n        # output statistics\n        start.loc[f'{dados_arquivos[j][:-4]}: {target}','MSE']=f'{mean_squared_error(y_test,RFG.predict(x_test)):.3f}'\n        start.loc[f'{dados_arquivos[j][:-4]}: {target}','MAE']=f'{mean_absolute_error(y_test,RFG.predict(x_test)):.3f}' \n        start.loc[f'{dados_arquivos[j][:-4]}: {target}','R-Squared']=f'{r2_score(y_test,RFG.predict(x_test)):.3f}'\n        start.loc[f'{dados_arquivos[j][:-4]}: {target}','Top 3 important features']= [list(x.columns[np.argsort(importance)[::-1][:3]])]\n        \n        # an example of prediction in visulization\n        if j == 0:\n            ax3[i,0].plot(y_test,RFG.predict(x_test),'.')\n            ax3[i,0].plot(np.linspace(np.amin(y_test),np.amax(y_test),100),np.linspace(np.amin(y_test),np.amax(y_test),100),'k')\n            ax3[i,0].set_ylabel('Predicted')\n            ax3[i,0].set_xlabel('Observed')\n            ax3[i,0].text(np.min(y_test),np.max(y_test)-1,f'MSE: {mean_squared_error(y_test,RFG.predict(x_test)):.3f}')\n            ax3[i,0].text(np.min(y_test),np.max(y_test)-2,f'MAE: {mean_absolute_error(y_test,RFG.predict(x_test)):.3f}')\n            ax3[i,0].text(np.min(y_test),np.max(y_test)-3,f'R-Squared: {r2_score(y_test,RFG.predict(x_test)):.3f}' )\n            ax3[i,0].set_title(f'{target}, meter')   \n            ax3[i,1].bar(range(len(importance)),importance)\n            ax3[i,1].set_xticks(range(len(importance)))\n            ax3[i,1].set_xticklabels(x.columns,rotation=90)\n            ax3[i,1].set_ylabel('Importance')\n    plt.tight_layout()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}