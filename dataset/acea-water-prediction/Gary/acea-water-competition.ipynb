{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Lake Bilancino\nIn this section random forests are used to determine the Lake Level and Flow Rate, which outperform SVR according to the following tables\n\n#### Lake Level Difference\n|      ML Method     |       MAE      |       RMSE     | $R^2$       |\n|:------------------:|:--------------:|:--------------:|:-----------:|\n| **Random Forests** | 0.025 ± 0.0037 | 0.042 ± 0.0091 | 0.50 ± 0.12 |\n|       **SVR**      | 0.039 ± 0.0058 | 0.052 ± 0.0084 | 0.25 ± 0.32 |\n\n---\n\n#### Flow Rate\n|      ML Method     |     MAE    |    RMSE    |   $R^2$      |\n|:------------------:|:----------:|:----------:|:------------:|\n| **Random Forests** | 1.3 ± 0.16 | 2.0 ± 0.38 |  0.64 ± 0.09 |\n|       **SVR**      | 2.0 ± 0.29 | 3.6 ± 0.73 | -0.04 ± 0.06 |\n\nThese values are the result of randomly selecting 50 train/test data combinations and fitting a random forest and SVR model to each data set. It should be noted that the values presented are of the form $\\mu \\pm 2\\sigma$, where $\\mu$ is the mean, and $\\sigma$ is the associated standard deviation.\n\nThe key data processing operations that lead to the values from the tables above come from averaging the rainfall columns into one feature, which is possible due to the high correlation among the different regions. Then, the lake level from the previous day is used as a feature in predicting the *difference* in lake level from day to day. This assumes it is arbitrary or inexpensive to measure the lake level each day, or even weekly. Finally, averaging the values of 7 consecutive rows into one reduces the number of zero values in the data enough to accurately predict the weekly difference in lake level.\n\nThe resulting lake level model, while trained on a weekly average, can be expected to perform on daily lake level differences, so long as the rainfall regions are averaged. The resulting statistics for 10 random forest models trained on the weekly data (7 consecutive row averages) and tested on the original daily data is shown below.\n\n#### RF Models Tested on Daily Data\n|          Target           |      MAE      |      RMSE     |    $R^2$    |\n|:-------------------------:|:-------------:|:-------------:|:-----------:|\n| **Lake Level Difference** | 0.042 ± 0.001 | 0.098 ± 0.001 | 0.10 ± 0.01 |\n|       **Flow Rate**       | 1.3 ± 0.18    | 2.0 ± 0.42    | 0.65 ± 0.11 |"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/acea-water-prediction/Lake_Bilancino.csv')\ndf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Bilancino Missing Data"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', df.shape[0], '\\n',\n      35*'=')\ndf.isna().sum()/(df.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(df.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"578 rows are missing *feature* information.  \nAfter a quick check, we find that the data is simply missing rainfall measurements for the first 577 rows, and that it is not spread throughout the data. We will drop these two years of missing feature data.\n\nThe 578th row begins to record rainfall data, but is missing temperature. We could try to substitute that information, but it won't hurt to drop it, as it is the last missing data point from our dataset.\n\nWe can see that `Flow_Rate` is also missing some information. It turns out that those missing data points are all within this same block. So we can safely remove `[0:578]`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(subset=['Rainfall_S_Piero','Rainfall_Mangona','Rainfall_Cavallina',\n                     'Rainfall_Le_Croci','Temperature_Le_Croci'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"df.reset_index(drop=True,inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', df.shape[0], '\\n',\n      35*'=')\ndf.isna().sum()/(df.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"All entries are now non-null."},{"metadata":{},"cell_type":"markdown","source":"### Feature Correlation\nNow we should explore how correlated rainfall is in these different areas."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr = df.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We might have expected that the rainfall features are all highly correlated with each other, so then we might want to create a single feature column based on all the features. This could be an average, or a sum.\n\nWe will use an average in this case. The reasoning is that it should increase bias within the feature data, and smooth out the events where an isolated region of rainfall might be one that carries *more* or *less* \"weight\" than other regions when determining our result."},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"df['Mean_Rainfall'] = df[['Rainfall_S_Piero','Rainfall_Mangona','Rainfall_S_Agata','Rainfall_Cavallina','Rainfall_Le_Croci']].mean(axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Before we deconstruct the `Date`, let's get a compiled graph that shows how other features change over just the first 5 years and see if cycles are approximately lined up or if we can distinguish some sort of \"phase shift\""},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"years = df[:1825]\n\nfig = plt.figure(figsize=(11,4))\nax1 = fig.add_axes([0,0,1,0.5])\nax2 = fig.add_axes([0,-0.7,1,0.5])\nax3 = fig.add_axes([0,-1.4,1,0.5])\nax4 = fig.add_axes([0,-2.1,1,0.5])\n\nax1.set_title('Lake Level')\nax1.set_xlabel('Time')\nax1.set_ylabel('meters')\n\nax2.set_title('Flow Rate')\nax2.set_xlabel('Time')\nax2.set_ylabel('mc/s')\n\nax3.set_title('Temperature')\nax3.set_xlabel('Time')\nax3.set_ylabel('celsius')\n\nax4.set_title('Mean Region Rainfall')\nax4.set_xlabel('Time')\nax4.set_ylabel('mm')\n\nax1.tick_params(axis='x', bottom=False, labelbottom=False)\nax2.tick_params(axis='x', bottom=False, labelbottom=False)\nax3.tick_params(axis='x', bottom=False, labelbottom=False)\nax4.tick_params(axis='x', bottom=False, labelbottom=False)\n\nax1.plot(years['Date'], years['Lake_Level'], label='Lake Level', color='g')\nax2.plot(years['Date'], years['Flow_Rate'], label='Flow Rate', color='y')\nax3.plot(years['Date'], years['Temperature_Le_Croci'], label='Temperature', color='r')\nax4.plot(years['Date'], years['Mean_Rainfall'], label='Rainfall', color='b')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> In the figure above, we can see that `Lake Level` drops shortly after `Temperature` rises. `Rainfall` however does not appear to have significant shift. Presumably because evaporation is a slower process to affect water levels than precipitation."},{"metadata":{},"cell_type":"markdown","source":"Let's do some clean up of our data and break down `Date` as more insight into the cyclical nature of these features might be found when considering the month of the particular date."},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Month'] = df['Date'].apply(lambda x: x.split('/')[1]) # Strip the month\nmonths = pd.get_dummies(df['Month'], drop_first=True) # One-hot encoding of month\n\nclean = pd.DataFrame()\n\nclean['Mean_Rainfall'] = df['Mean_Rainfall']\nclean['Temperature'] = df['Temperature_Le_Croci']\nclean['Lake_Level'] = df['Lake_Level']\nclean['Flow_Rate'] = df['Flow_Rate']\nclean = pd.concat([clean,months],axis=1) # Add the months to the end\nclean.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Bilancino Visualization\n### Mean Rainfall Visualization\nIt is apparent this relationship is highly non-linear. The data here has a distribution that is reminiscent of a regression tree problem."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=df['Mean_Rainfall'], y=df['Lake_Level'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=df['Mean_Rainfall'], y=df['Flow_Rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Temperature Visualization\nMore highly non-linear data. We probably won't want to use lasso or ridge regression with these features/predictors."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=df['Temperature_Le_Croci'], y=df['Lake_Level'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=df['Temperature_Le_Croci'], y=df['Flow_Rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Month Visualization\nIt is apparent that the month contains some information about the level of the lake."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.boxplot(x='Month',y='Lake_Level',data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Each month does not appear to contain enough non-zero information on flow rate for a non-zero mean."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.boxplot(x='Month', y='Flow_Rate', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We see that the same is true for the rainfall, but we also see that the month shares information with temperature."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.boxplot(x='Month', y='Mean_Rainfall', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.boxplot(x='Month', y='Temperature_Le_Croci', data=df)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lake Level vs Flow Rate\nIt does appear that Flow Rate is dependant on lake level, as the flow rate doesn't appear to go over 10 until the lake level goes over 250. Lake Level could be a good predictor of Flow Rate, when used with other information."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=df['Lake_Level'], y=df['Flow_Rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Modeling\nWe briefly discuss the models we should consider for this problem so far.  \nThe fact that this is a non-linear regression problem with ~6000 samples suggest we can start with considering SVR or Regression Trees.\n\nIn this case, I want to start with SVR as performance should be a good benchmark without any optimizations.\n\n#### Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = clean.drop(['Lake_Level','Flow_Rate'],axis=1)\nyLL = clean['Lake_Level']\nyFR = clean['Flow_Rate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XLL_train, XLL_test, yLL_train, yLL_test = train_test_split(X, yLL, test_size=0.3)\nXFR_train, XFR_test, yFR_train, yFR_test = train_test_split(X, yFR, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LLmodel = SVR(kernel='rbf')\nFRmodel = SVR(kernel='poly')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LLmodel.fit(XLL_train, yLL_train)\nFRmodel.fit(XFR_train, yFR_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LLpredictions = LLmodel.predict(XLL_test)\nFRpredictions = FRmodel.predict(XFR_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Evaluation"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yLL_test<LLpredictions,'indigo','peru')\n\nax.scatter(x=yLL_test, y=LLpredictions, c=col)\nax.plot(yLL_test,yLL_test, color='r') # Line of accurate predictions\nax.set_xlabel('Lake Level')\nax.set_ylabel('Predicted Lake Level')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yFR_test<FRpredictions,'indigo','peru')\n\nax.scatter(x=yFR_test, y=FRpredictions, c=col)\nax.plot(yFR_test,yFR_test, color='r') # Line of accurate predictions\nax.set_xlabel('Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Lake Level\",\"\\nMAE:\\t\", metrics.mean_absolute_error(yLL_test,LLpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yLL_test,LLpredictions)))\nprint(30*\"=\",\"\\nFlow Rate\")\nprint(\"MAE:\\t\", metrics.mean_absolute_error(yFR_test,FRpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yFR_test,FRpredictions)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Lake Level R^2:\\t\", metrics.r2_score(yLL_test,LLpredictions))\nprint(\"Flow Rate R^2:\\t\", metrics.r2_score(yFR_test,FRpredictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is obvious here that more feature engineering should be done to improve the prediction power of this model.\n\nAfter thinking about the problem, it seems that it would be equally useful to simply predict the daily difference ($\\pm$) in water level. This will effectively abstract the date or \"seasonal\" aspect from the lake level. Our model will then only require a rainfall amount and a temperature and you should receive an increase or a decrease in lake level. This relieves the burden of the temperature/month features from having to predict the level of the lake, which should be readily available information from the previous day.\n\nFor that same reason, it may be worth while to include the previous day's lake level as a feature of the data. We've already seen in the visualization that lake level would be a good predictor of flow rate. This would be a powerful addition to the feature set.\n\n---\n\n## Further feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"clean.drop(['02','03','04','05','06','07','08','09','10','11','12'], axis=1, inplace=True)\nclean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reform = pd.DataFrame()\n\n# Predictors\nreform['Mean_Rainfall'] = df['Mean_Rainfall']\nreform['Temperature'] = df['Temperature_Le_Croci']\nreform['Previous_Level'] = df['Lake_Level'].shift(periods=1,fill_value=251.14) # Fill value is for 01/01/2004\n\n# Response\nreform['Lake_Level'] = df['Lake_Level'] # Our model won't directly predict this value anymore\nreform['Diff'] = df['Lake_Level'].subtract(reform['Previous_Level'])\nreform['Flow_Rate'] = df['Flow_Rate']\n\nreform.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## More Visualizations\nNow that we're looking to predict different values, we should visualize them to see if we have more machine learning techniques available."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr = reform.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Mean Rainfall"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=reform['Mean_Rainfall'], y=reform['Diff'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Temperature"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=reform['Temperature'], y=reform['Diff'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Previous Level"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=reform['Previous_Level'], y=reform['Diff'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=reform['Previous_Level'], y=reform['Flow_Rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Modeling the Modified Target\n### Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = reform.drop(['Lake_Level','Diff','Flow_Rate'],axis=1)\nyDiff = reform['Diff']\nyFR = reform['Flow_Rate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XDiff_train, XDiff_test, yDiff_train, yDiff_test = train_test_split(X, yDiff, test_size=0.3)\nXFR_train, XFR_test, yFR_train, yFR_test = train_test_split(X, yFR, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n### SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"Diffmodel = SVR()\nFRmodel = SVR()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Diffmodel.fit(XDiff_train, yDiff_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FRmodel.fit(XFR_train, yFR_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Diffpredictions = Diffmodel.predict(XDiff_test)\nFRpredictions = FRmodel.predict(XFR_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Evaluation"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yDiff_test<Diffpredictions,'indigo','peru')\n\nax.scatter(x=yDiff_test, y=Diffpredictions, c=col)\nax.plot(yDiff_test,yDiff_test, color='r') # Line of accurate predictions\nax.set_xlabel('Lake Level Difference')\nax.set_ylabel('Predicted Difference')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This may not seem impressive, and indeed it isn't when you realize that the model is effectively just guessing that there is approximately zero meter increase/decrease in lake level from the previous day.\n\nHowever, it is obvious that when you use the difference as an adjustment to lake level from the previous day, we see that there has been a major improvement. But hopefully it makes sense to the reader that this is an artifical improvement, simply from the way we've constructed our solution. Regardless, we will add a visualization of what those lake level predictions would now look like for reference."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yDiff_test + XDiff_test['Previous_Level']<Diffpredictions + XDiff_test['Previous_Level'],\n               'indigo','peru')\n\nax.scatter(x=yDiff_test + XDiff_test['Previous_Level'], y=Diffpredictions + XDiff_test['Previous_Level'], c=col)\nax.plot(yDiff_test+XDiff_test['Previous_Level'],\n        yDiff_test+XDiff_test['Previous_Level'], color='r') # Line of accurate predictions\nax.set_xlabel('Lake Level')\nax.set_ylabel('Predicted Lake Level')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"As for the flow rate, there is still not much improvement, as the model is still just guessing the most common flow rate $(0\\ m^3/s)$ for each value."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yFR_test<FRpredictions,'indigo','peru')\n\nax.scatter(x=yFR_test, y=FRpredictions, c=col)\nax.plot(yFR_test,yFR_test, color='r') # Line of accurate predictions\nax.set_xlabel('Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Lake Level\",\"\\nMAE:\\t\", metrics.mean_absolute_error(yDiff_test,Diffpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yDiff_test,Diffpredictions)))\nprint(30*\"=\",\"\\nFlow Rate\")\nprint(\"MAE:\\t\", metrics.mean_absolute_error(yFR_test,FRpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yFR_test,FRpredictions)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(\"Lake Level R^2:\\t\", metrics.r2_score(yDiff_test,Diffpredictions))\nprint(\"Flow Rate R^2:\\t\", metrics.r2_score(yFR_test,FRpredictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Improvement Ideas\nIt is apparent that the data is still heavily skewed around zero rainfall events. This is causing the model to struggle to make predictions other than zero.\n\nWe can visualize how many days have a mean rainfall of zero to see how problematic this can be."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.histplot(data=reform, x='Mean_Rainfall', bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reform['Mean_Rainfall'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will need to flatten this data so that it is a bit more even and the affect of outliers will be more apparent in our models.\n\nWe can accomplish this by averaging out the days of zero rain by grouping the data into weeks."},{"metadata":{"trusted":true},"cell_type":"code","source":"reform['Mean_Rainfall'].groupby(reform.index // 7).mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note the drop in the size of our data; we've divided it by 7.  \nHowever, we can see that the rainfall feature distribution has been spread out by this process."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.histplot(reform['Mean_Rainfall'].groupby(reform.index // 7).mean(), bins=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weekly Refactor\nLet's refactor the most recent dataframe into a weekly one."},{"metadata":{"trusted":true},"cell_type":"code","source":"weekly = pd.DataFrame()\n\n# Predictors\nweekly['Mean_Rainfall'] = reform['Mean_Rainfall'].groupby(reform.index // 7).mean()\nweekly['Mean_Temperature'] = reform['Temperature'].groupby(reform.index // 7).mean()\nweekly['Mean_Previous_Level'] = reform['Previous_Level'].groupby(reform.index // 7).mean()\n\n# Response\nweekly['Mean_Lake_Level'] = reform['Lake_Level'].groupby(reform.index // 7).mean()\nweekly['Mean_Diff'] = reform['Diff'].groupby(reform.index // 7).mean()\nweekly['Mean_Flow_Rate'] = reform['Flow_Rate'].groupby(reform.index // 7).mean()\n\nweekly.head(10)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"weekly.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=weekly['Mean_Rainfall'], y=weekly['Mean_Diff'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=weekly['Mean_Rainfall'], y=weekly['Mean_Flow_Rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=weekly['Mean_Temperature'], y=weekly['Mean_Diff'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=weekly['Mean_Temperature'], y=weekly['Mean_Flow_Rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=weekly['Mean_Previous_Level'], y=weekly['Mean_Diff'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=weekly['Mean_Previous_Level'], y=weekly['Mean_Flow_Rate'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"corr = weekly.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Models Revisited\n### SVR\nTo see if we have improved we will want to fit with SVR once more for a comparison to our previous models."},{"metadata":{"trusted":true},"cell_type":"code","source":"X = weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1)\nyDiff = weekly['Mean_Diff']\nyFR = weekly['Mean_Flow_Rate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"XDiff_train, XDiff_test, yDiff_train, yDiff_test = train_test_split(X, yDiff, test_size=0.3)\nXFR_train, XFR_test, yFR_train, yFR_test = train_test_split(X, yFR, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Diffmodel_weekly = SVR(kernel='poly')\nFRmodel_weekly = SVR(kernel='poly')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Diffmodel_weekly.fit(XDiff_train, yDiff_train)\nFRmodel_weekly.fit(XFR_train, yFR_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Diffpredictions = Diffmodel_weekly.predict(XDiff_test)\nFRpredictions = FRmodel_weekly.predict(XFR_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n### Evaluation"},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yDiff_test<Diffpredictions,'indigo','peru')\n\nax.scatter(x=yDiff_test, y=Diffpredictions, c=col)\nax.plot(yDiff_test,yDiff_test, color='r') # Line of accurate predictions\nax.set_xlabel('Lake Level Difference')\nax.set_ylabel('Predicted Difference')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This is an improvement to our previous model. Again, to emphasize what our prediction for Lake Level looks like based on this difference prediction, we can show that below. However, we can no longer measure our model's performance by the lake level metric, rather we measure based on the difference predicted."},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yDiff_test + XDiff_test['Mean_Previous_Level']<Diffpredictions + XDiff_test['Mean_Previous_Level'],\n               'indigo','peru')\n\nax.scatter(x=yDiff_test + XDiff_test['Mean_Previous_Level'], y=Diffpredictions + XDiff_test['Mean_Previous_Level'], c=col)\nax.plot(yDiff_test+XDiff_test['Mean_Previous_Level'],\n        yDiff_test+XDiff_test['Mean_Previous_Level'], color='r') # Line of accurate predictions\nax.set_xlabel('Lake Level')\nax.set_ylabel('Predicted Lake Level')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that the flow rate has not improved. We will require a different regression method."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yFR_test<FRpredictions,'indigo','peru')\n\nax.scatter(x=yFR_test, y=FRpredictions, c=col)\nax.plot(yFR_test,yFR_test, color='r') # Line of accurate predictions\nax.set_xlabel('Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Difference in Lake Level\",\"\\nMAE:\\t\", metrics.mean_absolute_error(yDiff_test,Diffpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yDiff_test,Diffpredictions)))\nprint(30*\"=\",\"\\nFlow Rate\")\nprint(\"MAE:\\t\", metrics.mean_absolute_error(yFR_test,FRpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yFR_test,FRpredictions)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(\"Difference in Lake Level R^2:\\t\", metrics.r2_score(yDiff_test,Diffpredictions))\nprint(\"Flow Rate R^2:\\t\", metrics.r2_score(yFR_test,FRpredictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"### Decision Trees\nDue to the shape of the data related to the flow rate, we will try to model the data using regression trees. Hopefully we will see some improvement, which will then encourage us to seek optimization and improve the predictive power of decision trees."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FRmodel_weekly = DecisionTreeRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FRmodel_weekly.fit(XFR_train, yFR_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FRpredictions = FRmodel_weekly.predict(XFR_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yFR_test<FRpredictions,'indigo','peru')\n\nax.scatter(x=yFR_test, y=FRpredictions, c=col)\nax.plot(yFR_test,yFR_test, color='r') # Line of accurate predictions\nax.set_xlabel('Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Flow Rate\")\nprint(\"MAE:\\t\", metrics.mean_absolute_error(yFR_test,FRpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yFR_test,FRpredictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Flow Rate R^2:\\t\", metrics.r2_score(yFR_test,FRpredictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Since a simple decision tree performed better on this target, let's try to improve performance by using **AdaBoost**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import AdaBoostRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"booster = AdaBoostRegressor(DecisionTreeRegressor(max_depth=3),\n                          n_estimators=2000, learning_rate=0.01)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"booster.fit(XFR_train, yFR_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FRpredictions = booster.predict(XFR_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yFR_test<FRpredictions,'indigo','peru')\n\nax.scatter(x=yFR_test, y=FRpredictions, c=col)\nax.plot(yFR_test,yFR_test, color='r') # Line of accurate predictions\nax.set_xlabel('Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Flow Rate\")\nprint(\"MAE:\\t\", metrics.mean_absolute_error(yFR_test,FRpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yFR_test,FRpredictions)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Flow Rate R^2:\\t\", metrics.r2_score(yFR_test,FRpredictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest = RandomForestRegressor(n_estimators=500, max_features='sqrt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest.fit(XFR_train, yFR_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FRpredictions = forest.predict(XFR_test)","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[0],"scrolled":false,"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yFR_test<FRpredictions,'indigo','peru')\n\nax.scatter(x=yFR_test, y=FRpredictions, c=col)\nax.plot(yFR_test,yFR_test, color='r') # Line of accurate predictions\nax.set_xlabel('Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Flow Rate\")\nprint(\"MAE:\\t\", metrics.mean_absolute_error(yFR_test,FRpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yFR_test,FRpredictions)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"print(\"Flow Rate R^2:\\t\", metrics.r2_score(yFR_test,FRpredictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lake Level with Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest = RandomForestRegressor(n_estimators=500, max_features='sqrt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forest.fit(XDiff_train, yDiff_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Diffpredictions = forest.predict(XDiff_test)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(yDiff_test<Diffpredictions,'indigo','peru')\n\nax.scatter(x=yDiff_test, y=Diffpredictions, c=col)\nax.plot(yDiff_test,yDiff_test, color='r') # Line of accurate predictions\nax.set_xlabel('Lake Level Difference')\nax.set_ylabel('Predicted Difference')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Difference in Lake Level\",\"\\nMAE:\\t\", metrics.mean_absolute_error(yDiff_test,Diffpredictions),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(yDiff_test,Diffpredictions)))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"print(\"Difference in Lake Level R^2:\\t\", metrics.r2_score(yDiff_test,Diffpredictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## SVR vs Random Forest\nWe now want to show that Random Forests will consistently out-perform SVR.  \nTo do this, we compare the mean of the $\\text{MAE}$, $\\text{RMSE}$, and $R^2$ statistics of 50 respective models of each method."},{"metadata":{"code_folding":[0],"trusted":true},"cell_type":"code","source":"def fit_method(X_train,Y_train,X_test,Y_test,method,**kwargs):\n    #Fit random forest model and return RMSE and R squared values\n    try:\n        model_k = method(**kwargs)\n    except TypeError:\n        model_k = method # This will handle AdaBoost\n    model_k.fit(X_train,Y_train)\n    predictions = model_k.predict(X_test)\n    \n    MAE = metrics.mean_absolute_error(Y_test,predictions)\n    RMSE = np.sqrt(metrics.mean_squared_error(Y_test,predictions))\n    R_squared = metrics.r2_score(Y_test,predictions)\n    return MAE, RMSE, R_squared","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[0],"trusted":true},"cell_type":"code","source":"def run_method(X, y, n=20, method=RandomForestRegressor, **kwargs):\n    # Initialization variables\n    MAE_list, RMSE_list, R_squared_list = [],[],[]\n\n    for k in range(1,n):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n        tmp_result = fit_method(X_train, y_train, X_test, y_test, method, **kwargs)   #Store temp result \n        MAE_list.append(tmp_result[0])    #Append lists\n        RMSE_list.append(tmp_result[1])\n        R_squared_list.append(tmp_result[2])\n    \n    table = pd.DataFrame({'MAE': MAE_list, 'RMSE': RMSE_list, 'R_squared':R_squared_list})\n    return table","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[0],"trusted":true},"cell_type":"code","source":"def print_method_results(title):\n    print(title,\n          \"\\nMean MAE:\", np.round(table['MAE'].mean(),3), \"±\" , np.round(2*table['MAE'].std(),4),\n          \"\\nMean RMSE:\", np.round(table['RMSE'].mean(),3), \"±\" , np.round(2*table['RMSE'].std(),4),\n          \"\\nMean R2:\", np.round(table['R_squared'].mean(),3), \"±\" , np.round(2*table['R_squared'].std(),4), \n          \"\\n\")\n    print(25*\"=\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lake Level Difference with Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1), weekly['Mean_Diff'],\n                   n=50,method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Lake Level with Random Forests\")","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[],"scrolled":true,"trusted":true},"cell_type":"code","source":"# Initialization variables\nMAE_list, RMSE_list, R_squared_list = [],[],[]\nX_test = reform.drop(['Lake_Level','Diff','Flow_Rate'],axis=1)\ny_test = reform['Diff']\n\nX_train = weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1)\ny_train = weekly['Mean_Diff']\nn = 10\n\n# Fitting 10 models to 10 different training subset of the data\nfor k in range(1,n):\n    tmp_result = fit_method(X_train, y_train, X_test, y_test, \n                            RandomForestRegressor,n_estimators=500, max_features='sqrt')   #Store temp result \n    MAE_list.append(tmp_result[0])    #Append lists\n    RMSE_list.append(tmp_result[1])\n    R_squared_list.append(tmp_result[2])\n        \ntable = pd.DataFrame({'MAE': MAE_list, 'RMSE': RMSE_list, 'R_squared': R_squared_list})\nprint(\"Difference in Lake Level tested on Daily Data\",\n      \"\\nMean MAE:\", np.round(table['MAE'].mean(),4), \"±\" , np.round(2*table['MAE'].std(),5),\n      \"\\nMean RMSE:\", np.round(table['RMSE'].mean(),4), \"±\" , np.round(2*table['RMSE'].std(),5),\n      \"\\nMean R2:\", np.round(table['R_squared'].mean(),4), \"±\" , np.round(2*table['R_squared'].std(),4))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Flow Rate Difference with Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1),weekly['Mean_Flow_Rate'],\n                   n=50,method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Flow Rate with Random Forests\")","execution_count":null,"outputs":[]},{"metadata":{"code_folding":[],"trusted":true},"cell_type":"code","source":"# Initialization variables\nMAE_list, RMSE_list, R_squared_list = [],[],[]\nX_test = reform.drop(['Lake_Level','Diff','Flow_Rate'],axis=1)\ny_test = reform['Flow_Rate']\n\nX_train = weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1)\ny_train = weekly['Mean_Flow_Rate']\nn = 10\n# Fitting 50 models to 50 different training subset of the data\nfor k in range(1,n):\n    tmp_result = fit_method(X_train, y_train, X_test, y_test,\n                           RandomForestRegressor,n_estimators=500, max_features='sqrt')   #Store temp result \n    MAE_list.append(tmp_result[0])    #Append lists\n    RMSE_list.append(tmp_result[1])\n    R_squared_list.append(tmp_result[2])\n    \ntable = pd.DataFrame({'MAE': MAE_list, 'RMSE': RMSE_list, 'R_squared': R_squared_list})\nprint(\"Flow Rate tested on Daily Data\",\n      \"\\nMean MAE:\", np.round(table['MAE'].mean(),3), \"±\" , np.round(2*table['MAE'].std(),4),\n      \"\\nMean RMSE:\", np.round(table['RMSE'].mean(),3), \"±\" , np.round(2*table['RMSE'].std(),4),\n      \"\\nMean R2:\", np.round(table['R_squared'].mean(),3), \"±\" , np.round(2*table['R_squared'].std(),4))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1),weekly['Mean_Flow_Rate'],\n                   n=50,method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Flow Rate with Random Forests\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lake Level Difference with SVR"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1),weekly['Mean_Diff'],\n                   n=50,method=SVR,kernel='poly')\nprint_method_results(\"Difference in Lake Level with SVR\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Flow Rate Difference with SVR"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"table = run_method(weekly.drop(['Mean_Lake_Level','Mean_Diff','Mean_Flow_Rate'],axis=1),weekly['Mean_Flow_Rate'],\n                   n=50,method=SVR,kernel='poly')\nprint_method_results(\"Flow Rate with Random Forests\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n# Arno River\n\nIn this section random forests and regression trees with AdaBoost are used to predict the target value of `Hydrometry_Nave_di_Rosano`. The performance of the respective methods are as follows.\n\n|      ML Method     |       MAE      |       RMSE     | $R^2$       |\n|:------------------:|:--------------:|:--------------:|:-----------:|\n| **Random Forests** | 0.375 ± 0.0212 | 0.572 ± 0.0375 | 0.28 ± 0.07 |\n|    **AdaBoost**    | 0.356 ± 0.0203 | 0.547 ± 0.0370 | 0.34 ± 0.07 |\n\nThese values are the result of randomly selecting 50 train/test data combinations and fitting a random forest and AdaBoost model to each data set. This is the same algorithm for generating the mean MAE, RMSE, and $R^2$ statistics as was used with the lake.\n\nThe key data processing operations that lead to the values from the tables above come from averaging the rainfall columns into two groups. This was again motivated by the desire to lower the variance of the resulting models and from the high correlation among the two groups of regions. No time aggregation was necessary on this data, as the volatility of the target data is more apparent on the daily time-scale for a river than for a lake. In any case, it wasn't necessary to get within half meter in absolute error and doing so will only reduce the training data size and increase bias with low variance trade-off."},{"metadata":{"trusted":true},"cell_type":"code","source":"arno = pd.read_csv('../input/acea-water-prediction/River_Arno.csv')\narno","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.describe().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', arno.shape[0], '\\n',\n      35*'=')\narno.isna().sum()/(arno.isna().sum() + arno.notna().sum()) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It is obvious that there is more data for some regions than others.  \nWe see the percentages, let's see *how* and *where* those missing values are spread."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.heatmap(arno.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = arno.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The rainfall in the first 6 regions are correlated with each other, while the rainfall in the last 8 regions are correlated with themselves. Furthermore, it seems that the response variable is more responsive to those last 8 regions, as rainfall in those regions have higher correlation with the response.\n\nThis means that it might be a good idea to average the 6 and 8 regions respectively and build a model off that. This will help reduce the number of missing data, but it cannot be ignored that the amount of missing data is very large for the second group of rainfall.\n\nThe plan might be to first drop any row where there are more than 7 regions of missing rainfall data. That would look like this."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.heatmap(arno.dropna(subset=['Rainfall_Le_Croci', 'Rainfall_Cavallina','Rainfall_S_Agata','Rainfall_Mangona',\n                  'Rainfall_S_Piero','Rainfall_Vernio','Rainfall_Stia','Rainfall_Consuma',\n                 'Rainfall_Incisa','Rainfall_Montevarchi','Rainfall_S_Savino','Rainfall_Laterina',\n                 'Rainfall_Bibbiena','Rainfall_Camaldoli'],thresh=7).isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.dropna(subset=['Rainfall_Le_Croci', 'Rainfall_Cavallina','Rainfall_S_Agata','Rainfall_Mangona',\n                  'Rainfall_S_Piero','Rainfall_Vernio','Rainfall_Stia','Rainfall_Consuma',\n                 'Rainfall_Incisa','Rainfall_Montevarchi','Rainfall_S_Savino','Rainfall_Laterina',\n                 'Rainfall_Bibbiena','Rainfall_Camaldoli'],thresh=7, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', arno.shape[0], '\\n',\n      35*'=')\narno.isna().sum()/(arno.isna().sum() + arno.notna().sum()) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The first 6 regions, which are all correlated, now have no missing data. This challenge is solved for that first group of regions. We managed to keep as much of the data as possible this way, preserving as much of the variability of the data as possible.\n\nNow we have 6 out of 8 regions in the second group that are missing more than 60% of the data.\n\nTo make up for the missing information, as well as remove some of the \"weight of importance\" of some regions over others, we will take a daily rainfall average of the two correlated region groups."},{"metadata":{"trusted":true},"cell_type":"code","source":"arno['Mean_Rainfall_Group1'] = arno[['Rainfall_Le_Croci','Rainfall_Cavallina','Rainfall_S_Agata',\n                                 'Rainfall_Mangona','Rainfall_S_Piero','Rainfall_Vernio']].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno['Mean_Rainfall_Group2'] = arno[['Rainfall_Stia','Rainfall_Consuma', 'Rainfall_Incisa','Rainfall_Montevarchi','Rainfall_S_Savino',\n           'Rainfall_Laterina','Rainfall_Bibbiena','Rainfall_Camaldoli']].mean(axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.drop(['Rainfall_Le_Croci','Rainfall_Cavallina','Rainfall_S_Agata','Rainfall_Mangona',\n                     'Rainfall_S_Piero','Rainfall_Vernio','Rainfall_Stia','Rainfall_Consuma', 'Rainfall_Incisa',\n                     'Rainfall_Montevarchi','Rainfall_S_Savino','Rainfall_Laterina','Rainfall_Bibbiena',\n                     'Rainfall_Camaldoli'], axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno = arno[['Date','Mean_Rainfall_Group1','Mean_Rainfall_Group2','Temperature_Firenze','Hydrometry_Nave_di_Rosano']]\narno.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = arno.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', arno.shape[0], '\\n',\n      35*'=')\narno.isna().sum()/(arno.isna().sum() + arno.notna().sum()) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"arno.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Visualizations\n\nOne thing we will have to recognize before moving forward is that our data will be very \"patchy.\"  \nThere was some attempt to maintain the continuous time-series aspect of the data, however not all of the data could be preserved while maintaining that continuous chronological order. That is to say, we will not be able to use the \"hydrometry value of the previous day\" to inform our model in some way, and that our data may spike more than expected."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(11,4))\nax1 = fig.add_axes([0,0,1,0.5])\nax2 = fig.add_axes([0,-0.7,1,0.5])\nax3 = fig.add_axes([0,-1.4,1,0.5])\nax4 = fig.add_axes([0,-2.1,1,0.5])\n\nax1.set_title('Hydrometry Nave di Rosano')\nax1.set_xlabel('Time')\nax1.set_ylabel('m')\n\nax2.set_title('Mean Rainfall Group 1')\nax2.set_xlabel('Time')\nax2.set_ylabel('mm')\n\nax3.set_title('Mean Rainfall Group 2')\nax3.set_xlabel('Time')\nax3.set_ylabel('mm')\n\nax4.set_title('Temperature')\nax4.set_xlabel('Time')\nax4.set_ylabel('celsius')\n\nax1.tick_params(axis='x', bottom=False, labelbottom=False)\nax2.tick_params(axis='x', bottom=False, labelbottom=False)\nax3.tick_params(axis='x', bottom=False, labelbottom=False)\nax4.tick_params(axis='x', bottom=False, labelbottom=False)\n\nax1.plot(arno['Date'], arno['Hydrometry_Nave_di_Rosano'], label='Hydrometry Level', color='g')\nax2.plot(arno['Date'], arno['Mean_Rainfall_Group1'], label='Mean Rainfall Group 1', color='b')\nax3.plot(arno['Date'], arno['Mean_Rainfall_Group2'], label='Mean Rainfall Group 2', color='c')\nax4.plot(arno['Date'], arno['Temperature_Firenze'], label='Temperature', color='r')\n\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x='Mean_Rainfall_Group1', y='Hydrometry_Nave_di_Rosano', data=arno)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.histplot(data=arno, x='Mean_Rainfall_Group1', bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x='Mean_Rainfall_Group2', y='Hydrometry_Nave_di_Rosano', data=arno)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.histplot(data=arno, x='Mean_Rainfall_Group2', bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.jointplot(x='Temperature_Firenze', y='Hydrometry_Nave_di_Rosano', data=arno)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.histplot(data=arno, x='Hydrometry_Nave_di_Rosano', bins=30)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This data is again highly non-linear. The rainfall data values are heavily centered around 0, as with the lake. Random Forests handled that data well, so we can try that first. We can also add a model with AdaBoost to compete.\n\n---\n## Modeling\n### Train/Test Split"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = arno.drop(['Date','Hydrometry_Nave_di_Rosano'],axis=1)\ny = arno['Hydrometry_Nave_di_Rosano']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest = RandomForestRegressor(n_estimators=500, max_features='sqrt')\nforest.fit(X_train, y_train)\n\npredictions_forest = forest.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol1 = np.where(y_test<predictions_forest,'indigo','peru')\n\nax.scatter(x=y_test, y=predictions_forest, c=col1)\nax.plot(y_test,y_test, color='r') # Line of accurate predictions\nax.set_xlabel('Hydrometry Nave di Rosano')\nax.set_ylabel('Predicted Hydrometry Nave di Rosano')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## AdaBoost"},{"metadata":{"trusted":true},"cell_type":"code","source":"model_boost = AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=500, learning_rate=0.01)\nmodel_boost.fit(X_train,y_train)\npredictions_boost = model_boost.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol1 = np.where(y_test<predictions_boost,'indigo','peru')\n\nax.scatter(x=y_test, y=predictions_boost, c=col1)\nax.plot(y_test,y_test, color='r') # Line of accurate predictions\nax.set_xlabel('Hydrometry Nave di Rosano')\nax.set_ylabel('Predicted Hydrometry Nave di Rosano')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Hydrometry Nave di Rosano\")\nprint(\"FOREST MODEL\",\n      \"\\nMAE:\\t\", metrics.mean_absolute_error(y_test,predictions_forest),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(y_test,predictions_forest)),\n      \"\\tR^2:\\t\", metrics.r2_score(y_test,predictions_forest))\n\nprint(65*\"=\")\n\nprint(\"\\nBOOST MODEL\",\n      \"\\nMAE:\\t\", metrics.mean_absolute_error(y_test,predictions_boost),\n      \"\\nRMSE:\\t\", np.sqrt(metrics.mean_squared_error(y_test,predictions_boost)),\n      \"\\tR^2:\\t\", metrics.r2_score(y_test,predictions_boost))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Boost vs Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(arno.drop(['Date','Hydrometry_Nave_di_Rosano'],axis=1),\n                   arno['Hydrometry_Nave_di_Rosano'], n=50,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Hydrometry Nave di Rosano with Random Forests\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(arno.drop(['Date','Hydrometry_Nave_di_Rosano'],axis=1),\n                   arno['Hydrometry_Nave_di_Rosano'], n=50,\n                   method=AdaBoostRegressor(DecisionTreeRegressor(max_depth=4), n_estimators=500, learning_rate=0.01))\nprint_method_results(\"Hydrometry Nave di Rosano with Boosted Regression Trees\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Water Springs\nEach water spring had varying amounts of data fill. Handling missing data was more important for some data sets than others as data sizes also varied across water springs. As with the models we've seen so far, the majority of the work was done on data preprocessing with the goal of improving either accuracy of the resulting models, or their consistency, or both.\n\n## Amiata Overview\nWater spring amiata has 4 targets it wishes to predict. Each target, one must assume, is located in a different region of the spring. Therefore, the multiple regions of rainfall is decidedly not combined into one or two feature. Instead, we allow for each model to attempt to decide their optimal features by employing machine learning methods that use only a subset of the total features.\n\nUp until now, we've used random forests as a reliably appropriate method to start with. This is still the case for this data, except now we will compare random forests against decision trees. The following values were computed over 20 random fits of each respective ML method for each respective target as before.\n\n\n#### Flow Rate Bugnano\n|      ML Method     |       MAE      |       RMSE     |  $R^2$       |\n|:------------------:|:--------------:|:--------------:|:------------:|\n| **Decision Trees** | 0.010 ± 0.0052 | 0.038 ± 0.0209 | 0.91 ± 0.098 |\n| **Random Forests** | 0.017 ± 0.0029 | 0.037 ± 0.0067 | 0.92 ± 0.028 |\n\n\n#### Flow Rate Arbure\n|      ML Method     |       MAE      |       RMSE     | $R^2$       |\n|:------------------:|:--------------:|:--------------:|:-----------:|\n| **Decision Trees** | 0.102 ± 0.0534 | 0.380 ± 0.1856 | 0.86 ± 0.12 |\n| **Random Forests** | 0.162 ± 0.0217 | 0.342 ± 0.0624 | 0.90 ± 0.04 |\n\n#### Flow Rate Ermicciolo\n|      ML Method     |       MAE      |       RMSE     | $R^2$       |\n|:------------------:|:--------------:|:--------------:|:-----------:|\n| **Decision Trees** | 0.152 ± 0.0580 | 0.535 ± 0.2524 | 0.86 ± 0.13 |\n| **Random Forests** | 0.215 ± 0.0473 | 0.459 ± 0.1251 | 0.90 ± 0.05 |\n\n#### Flow Rate Alta \n|      ML Method     |       MAE      |       RMSE     | $R^2$       |\n|:------------------:|:--------------:|:--------------:|:-----------:|\n| **Decision Trees** | 0.433 ± 0.0664 | 0.795 ± 0.1239 | 0.85 ± 0.04 |\n| **Random Forests** | 0.413 ± 0.0398 | 0.609 ± 0.0623 | 0.91 ± 0.02 |\n\n## Madonna di Canneto Overview\nThis water spring contains only one rainfall feature, one temperature feature, and the date. The temperature carries some seasonal information regarding the flow rate, but since there are no other predictors in this dataset, a one-hot encoding of the month is added as a categorical feature.\n\nThe resulting statistics are calculated by fitting 20 random training/test set combinations of the original data to the three respective models. In the case of this spring, SVR was included to show how it arbitrarily predicts a mean value for the flow rate, regardless of the input values. Random forests perform within one standard deviation of SVR, and Decision trees performs arbitrarily worse than random forests. Modeling this spring can use further improvement.\n\n#### Flow Rate Madonna di Canneto\n|      ML Method     |    MAE     |     RMSE   |  $R^2$       |\n|:------------------:|:----------:|:----------:|:------------:|\n| **Decision Trees** | 16.2 ± 4.0 | 28.7 ± 5.4 | -0.50 ± 0.52 |\n| **Random Forests** | 14.4 ± 2.2 | 23.6 ± 3.1 | -0.03 ± 0.27 |\n|       **SVR**      | 13.6 ± 2.4 | 23.5 ± 3.9 | -0.08 ± 0.06 |\n\n\n## Lupa Overview\nThis spring is missing any temperature data, so the month was added as a categorical feature in the same way as with the Madonna di Canneto dataset.\n\nThe resulting statistics are calculated by fitting 20 random training/test set combinations of the original data to the two respective models.\n\n#### Flow Rate Lupa\n|      ML Method     |       MAE      |       RMSE     | $R^2$       |\n|:------------------:|:--------------:|:--------------:|:-----------:|\n| **Decision Trees** | 0.549 ± 0.2452 | 2.878 ± 2.7529 | 0.96 ± 0.09 |\n| **Random Forests** | 0.480 ± 0.1589 | 1.996 ± 1.3736 | 0.98 ± 0.03 |"},{"metadata":{"trusted":true},"cell_type":"code","source":"amiata = pd.read_csv('../input/acea-water-prediction/Water_Spring_Amiata.csv')\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', amiata.shape[0], '\\n',\n      35*'=')\namiata.isna().sum()/(amiata.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lupa = pd.read_csv('../input/acea-water-prediction/Water_Spring_Lupa.csv')\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', lupa.shape[0], '\\n',\n      35*'=')\nlupa.isna().sum()/(lupa.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mdc = pd.read_csv('../input/acea-water-prediction/Water_Spring_Madonna_di_Canneto.csv')\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', mdc.shape[0], '\\n',\n      35*'=')\nmdc.isna().sum()/(mdc.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"These bodies of water all have independent datasets and thus may require different algorithms for fitting.\nIt appears that water spring Lupa is perhaps ready for EDA, with no missing values. However, the lack of temperature suggest we might want to add a month feature into our model to assist the loss of some sort of seasonal information.\n\nWater spring Madonna di Canneto is missing half of its target values, which only leaves about 1700 supervised data points, and that's assuming we don't need to further reduce the data. We may require an algorithm such as SVR to make up for the potential lack of training data.\n\nWater spring Amiata appears to have very sparse data. Missing data might be a serious issue in this dataset, so we will tackle that problem before moving on.\n\n---\n\n## Amiata Missing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(amiata.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data seems to be mostly missing from the earliest dates. We could remove most of them with a simple threshold drop. However, we're interested in prediction. Prediction requires observed data. So we will need to remove any data that is missing any of the target data."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(amiata.dropna(subset=['Flow_Rate_Bugnano','Flow_Rate_Arbure',\n                                  'Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta']).isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amiata.dropna(subset=['Flow_Rate_Bugnano','Flow_Rate_Arbure','Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta'],\n              how='all', inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', amiata.shape[0], '\\n',\n      35*'=')\namiata.isna().sum()/(amiata.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have near complete rainfall data. With 18% missing data and high rainfall correlation (see below) we can use an average from the other rainfall features to estimate the missing data. However, the question is whether or not to combine the rainfall data.\n\nIn this case, we are predicting 4 different flow rates. Each with a different model, but more importantly; each of which is affected differently by the rainfall of different regions. An example of this is how `Flow_Rate_Bugnano` is negatively correlated with `Rainfall_Castel_del_Piano`, but positively correlated with `Flow_Rate_Ermicciolo` and how `Rainfall_Vetta_Amiata` is positively correlated with `Rainfall_Castel_del_Piano`, but negatively correlated with `Flow_Rate_Ermicciolo`.\n\nSo we will maintain the individual rainfall data of each region separate, and use some subset selection method or a model such as the lasso that has feature selection. This way, the flow rate of each region can attempt to find the features that best suit its prediction.\n\nThe same goes for Depth to Groundwater, except the motivations for doing so are more apparent.\n\nUltimately though, we can use other {rainfall / depth to ground water / temperature} data to predict a missing {rainfall / depth to ground water / temperature} data point."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = amiata.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,8))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a_rain_mean = amiata.loc[:,'Rainfall_Castel_del_Piano':'Rainfall_Vetta_Amiata'].mean(axis=1)\n\n# We have to check each column independently to fill null values with this row-wise mean.\namiata['Rainfall_Castel_del_Piano'].fillna(value=a_rain_mean, inplace=True)\namiata['Rainfall_Abbadia_S_Salvatore'].fillna(value=a_rain_mean, inplace=True)\namiata['Rainfall_S_Fiora'].fillna(value=a_rain_mean, inplace=True)\namiata['Rainfall_Laghetto_Verde'].fillna(value=a_rain_mean, inplace=True)\namiata['Rainfall_Vetta_Amiata'].fillna(value=a_rain_mean, inplace=True)\n\nfig = plt.figure(figsize=(6,3))\nsns.heatmap(amiata.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"According to the correlation between these rows, we *can* use the mean of the depth to groundwater of each row to substitute missing values for any particular column. We *cannot* average them into one column, as each region might affect some models differently."},{"metadata":{"trusted":true},"cell_type":"code","source":"a_depth_mean = amiata.loc[:,\n                          'Depth_to_Groundwater_S_Fiora_8':'Depth_to_Groundwater_David_Lazzaretti'\n                         ].mean(axis=1)\n\n# We have to check each column independently to fill null values with this row-wise mean.\namiata['Depth_to_Groundwater_S_Fiora_8'].fillna(value=a_depth_mean, inplace=True)\namiata['Depth_to_Groundwater_S_Fiora_11bis'].fillna(value=a_depth_mean, inplace=True)\namiata['Depth_to_Groundwater_David_Lazzaretti'].fillna(value=a_depth_mean, inplace=True)\n\nfig = plt.figure(figsize=(6,3))\nsns.heatmap(amiata.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Lastly, we do the same for the temperature, with the same argument as the rainfall and depth to groundwater."},{"metadata":{"trusted":true},"cell_type":"code","source":"a_depth_mean = amiata.loc[:,\n                          'Temperature_Abbadia_S_Salvatore':'Temperature_Laghetto_Verde'\n                         ].mean(axis=1)\n\n# We have to check each column independently to fill null values with this row-wise mean.\namiata['Temperature_Abbadia_S_Salvatore'].fillna(value=a_depth_mean, inplace=True)\namiata['Temperature_S_Fiora'].fillna(value=a_depth_mean, inplace=True)\namiata['Temperature_Laghetto_Verde'].fillna(value=a_depth_mean, inplace=True)\n\nfig = plt.figure(figsize=(6,3))\nsns.heatmap(amiata.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"amiata.dropna(subset=['Flow_Rate_Bugnano','Flow_Rate_Arbure','Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta'],\n              how='all', inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', amiata.shape[0], '\\n',\n      35*'=')\namiata.isna().sum()/(amiata.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Madonna di Canneto Missing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(mdc.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Unfortunately the data for this spring is missing a lot of target values. Again, we have to cut those and the data will no longer be sequential. We'll keep this in mind when choosing a model."},{"metadata":{"trusted":true},"cell_type":"code","source":"mdc.dropna(inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', mdc.shape[0], '\\n',\n      35*'=')\nmdc.isna().sum()/(mdc.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point, the temperature data is having to express a lot of seasonal information inherent in the flow rate. So in an effort to aid this feature, we will encode the month of each data point for our model."},{"metadata":{"trusted":true},"cell_type":"code","source":"mdc['Month'] = mdc['Date'].apply(lambda x: x.split('/')[1]) # Strip the month\nmonths = pd.get_dummies(mdc['Month'], drop_first=True) # One-hot encoding of month\n\nmdc = pd.concat([mdc,months],axis=1) # Add the months to the end","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Lupa Missing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(lupa.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The spread of missing data here would be ideal for imputation of missing feature data.  \nHowever, in an effort to not influence the resulting model, we will simply remove those missing data points."},{"metadata":{"trusted":true},"cell_type":"code","source":"lupa.dropna(inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', lupa.shape[0], '\\n',\n      35*'=')\nlupa.isna().sum()/(lupa.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Recall that Lupa doesn't have any temperature information. We can use the month to give some seasonal variation in the data."},{"metadata":{"trusted":true},"cell_type":"code","source":"lupa['Month'] = lupa['Date'].apply(lambda x: x.split('/')[1]) # Strip the month\nmonths = pd.get_dummies(lupa['Month'], drop_first=True) # One-hot encoding of month\n\nlupa = pd.concat([lupa,months],axis=1) # Add the months to the end","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Visualizations\n\n### Amiata Features Vs Targets"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=amiata,\n             x_vars=[\n                 'Rainfall_Castel_del_Piano','Rainfall_Abbadia_S_Salvatore',\n                 'Rainfall_S_Fiora','Rainfall_Laghetto_Verde','Rainfall_Vetta_Amiata'\n             ],\n            y_vars=[\n                'Flow_Rate_Bugnano', 'Flow_Rate_Arbure',\n                'Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta'\n            ])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=amiata,\n             x_vars=[\n                 'Depth_to_Groundwater_S_Fiora_8','Depth_to_Groundwater_S_Fiora_11bis',\n                 'Depth_to_Groundwater_David_Lazzaretti'\n             ],\n            y_vars=[\n                'Flow_Rate_Bugnano', 'Flow_Rate_Arbure',\n                'Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta'\n            ],\n            aspect=1.5)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=amiata,\n             x_vars=[\n                 'Temperature_Abbadia_S_Salvatore','Temperature_S_Fiora',\n                 'Temperature_Laghetto_Verde'\n             ],\n            y_vars=[\n                'Flow_Rate_Bugnano', 'Flow_Rate_Arbure',\n                'Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta'\n            ],\n            aspect=1.5)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Madonna di Canneto Features Vs Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x='Rainfall_Settefrati', y='Flow_Rate_Madonna_di_Canneto', data=mdc)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x='Temperature_Settefrati', y='Flow_Rate_Madonna_di_Canneto', data=mdc)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.boxplot(x='Month',y='Flow_Rate_Madonna_di_Canneto',data=mdc)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lupa Features Vs Target"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.scatterplot(x='Rainfall_Terni', y='Flow_Rate_Lupa', data=lupa)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.boxplot(x='Month', y='Flow_Rate_Lupa', data=lupa)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So it seems like these springs, or at least this spring, flows very consistently throughout the year. The spread of the data for this is generally contained within -75 and -125, with the exception of a few outliers in about 6 of the months.\n\nOur model might have a difficult time predicting any value that is not just the training mean.\n\nLet's model without any further speculation and see how well it does.\n\n---\n\n## Building the Models\n\n### Amiata Modeling\nAmiata has about 2000 data points and will require 4 resulting models. Because certain rainfall features seem to affect the flow rates differently, we will need to use a model that does some sort of feature selection. \n\nFor this, I had in mind the elastic-net and regression tree methods. However, we should not expect elastic-net to perform well on data that is this non-linear, so we can skip to regression trees. Regression trees have some feature selection properties, which will be ideal since there is high-correlation between rainfall of different regions, we just don't know which ones might be relevant."},{"metadata":{"trusted":true},"cell_type":"code","source":"aX = amiata.drop(['Date','Flow_Rate_Bugnano','Flow_Rate_Arbure',\n                  'Flow_Rate_Ermicciolo','Flow_Rate_Galleria_Alta'],axis=1)\nbugnano = amiata['Flow_Rate_Bugnano']\narbure = amiata['Flow_Rate_Arbure']\nermicciolo = amiata['Flow_Rate_Ermicciolo']\nalta = amiata['Flow_Rate_Galleria_Alta']\n\nX_bug_train, X_bug_test, bugnano_train, bugnano_test = train_test_split(aX, bugnano, test_size=0.2)\nX_arb_train, X_arb_test, arbure_train, arbure_test = train_test_split(aX, arbure, test_size=0.2)\nX_erm_train, X_erm_test, ermicciolo_train, ermicciolo_test = train_test_split(aX, ermicciolo, test_size=0.2)\nX_alt_train, X_alt_test, alta_train, alta_test = train_test_split(aX, alta, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Trees on Amiata"},{"metadata":{"trusted":true},"cell_type":"code","source":"tree_bugnano = DecisionTreeRegressor()\ntree_arbure = DecisionTreeRegressor()\ntree_ermicciolo = DecisionTreeRegressor()\ntree_alta = DecisionTreeRegressor()\n\ntree_bugnano.fit(X_bug_train, bugnano_train)\ntree_arbure.fit(X_arb_train, arbure_train)\ntree_ermicciolo.fit(X_erm_train, ermicciolo_train)\ntree_alta.fit(X_alt_train, alta_train)\n\nbug_predictions = tree_bugnano.predict(X_bug_test)\narb_predictions = tree_arbure.predict(X_arb_test)\nerm_predictions = tree_ermicciolo.predict(X_erm_test)\nalt_predictions = tree_alta.predict(X_alt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(6,5))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\n\ncol1 = np.where(bugnano_test<bug_predictions,'indigo','peru')\ncol2 = np.where(arbure_test<arb_predictions,'indigo','peru')\n\nax.scatter(x=bugnano_test, y=bug_predictions, c=col1)\nax.plot(bugnano_test,bugnano_test, color='r') # Line of accurate predictions\nax.set_xlabel('Bugnano Flow Rate')\nax.set_ylabel('Predicted Bugnano Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=arbure_test, y=arb_predictions, c=col2)\nax2.plot(arbure_test,arbure_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Arbure Flow Rate')\nax2.set_ylabel('Predicted Arbure Flow Rate')\nax2.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(6,5))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\n\ncol1 = np.where(ermicciolo_test<erm_predictions,'indigo','peru')\ncol2 = np.where(alta_test<alt_predictions,'indigo','peru')\n\nax.scatter(x=ermicciolo_test, y=erm_predictions, c=col1)\nax.plot(ermicciolo_test,ermicciolo_test, color='r') # Line of accurate predictions\nax.set_xlabel('Ermicciolo Flow Rate')\nax.set_ylabel('Predicted Ermicciolo Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=alta_test, y=alt_predictions, c=col2)\nax2.plot(alta_test,alta_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Alta Flow Rate')\nax2.set_ylabel('Predicted Alta Flow Rate')\nax2.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluations\nprint(\"Bugnano Flow Rate\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(bugnano_test,bug_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(bugnano_test,bug_predictions))\n\nprint(65*\"=\",\"\\nArbure Flow Rate\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(arbure_test,arb_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(arbure_test,arb_predictions))\n\nprint(65*\"=\",\"\\nErmicciolo Flow Rate\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(ermicciolo_test,erm_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(ermicciolo_test,erm_predictions))\n\nprint(65*\"=\",\"\\nAlta Flow Rate\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(alta_test,alt_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(alta_test,alt_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest on Amiata"},{"metadata":{"trusted":true},"cell_type":"code","source":"forest_bugnano = RandomForestRegressor(n_estimators=500, max_features='sqrt')\nforest_arbure = RandomForestRegressor(n_estimators=500, max_features='sqrt')\nforest_ermicciolo = RandomForestRegressor(n_estimators=500, max_features='sqrt')\nforest_alta = RandomForestRegressor(n_estimators=500, max_features='sqrt')\n\nforest_bugnano.fit(X_bug_train, bugnano_train)\nforest_arbure.fit(X_arb_train, arbure_train)\nforest_ermicciolo.fit(X_erm_train, ermicciolo_train)\nforest_alta.fit(X_alt_train, alta_train)\n\nbug_predictions = forest_bugnano.predict(X_bug_test)\narb_predictions = forest_arbure.predict(X_arb_test)\nerm_predictions = forest_ermicciolo.predict(X_erm_test)\nalt_predictions = forest_alta.predict(X_alt_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(6,5))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\n\ncol1 = np.where(bugnano_test<bug_predictions,'indigo','peru')\ncol2 = np.where(arbure_test<arb_predictions,'indigo','peru')\n\nax.scatter(x=bugnano_test, y=bug_predictions, c=col1)\nax.plot(bugnano_test,bugnano_test, color='r') # Line of accurate predictions\nax.set_xlabel('Bugnano Flow Rate')\nax.set_ylabel('Predicted Bugnano Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=arbure_test, y=arb_predictions, c=col2)\nax2.plot(arbure_test,arbure_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Arbure Flow Rate')\nax2.set_ylabel('Predicted Arbure Flow Rate')\nax2.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(6,5))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\n\ncol1 = np.where(ermicciolo_test<erm_predictions,'indigo','peru')\ncol2 = np.where(alta_test<alt_predictions,'indigo','peru')\n\nax.scatter(x=ermicciolo_test, y=erm_predictions, c=col1)\nax.plot(ermicciolo_test,ermicciolo_test, color='r') # Line of accurate predictions\nax.set_xlabel('Ermicciolo Flow Rate')\nax.set_ylabel('Predicted Ermicciolo Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=alta_test, y=alt_predictions, c=col2)\nax2.plot(alta_test,alta_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Alta Flow Rate')\nax2.set_ylabel('Predicted Alta Flow Rate')\nax2.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluations\nprint(\"Bugnano Flow Rate\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(bugnano_test,bug_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(bugnano_test,bug_predictions))\n\nprint(65*\"=\",\"\\nArbure Flow Rate\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(arbure_test,arb_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(arbure_test,arb_predictions))\n\nprint(65*\"=\",\"\\nErmicciolo Flow Rate\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(ermicciolo_test,erm_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(ermicciolo_test,erm_predictions))\n\nprint(65*\"=\",\"\\nAlta Flow Rate\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(alta_test,alt_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(alta_test,alt_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Madonna di Canneto Modeling\n\nMadonna di Canneto has only 879 points of data and merely 3 predictors (Rainfall, Temperature, and Month).\nFor these reasons we might choose decision trees or SVR with a radial basis kernel, as the visualization suggests some circular symmetry in the temperature data. "},{"metadata":{"trusted":true},"cell_type":"code","source":"mdX = mdc.drop(['Date','Flow_Rate_Madonna_di_Canneto','Month'],axis=1)\nmdy = mdc['Flow_Rate_Madonna_di_Canneto']\n\nmdX_train, mdX_test, mdy_train, mdy_test = train_test_split(mdX, mdy, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"md_model = SVR(kernel='rbf')\nmd_model.fit(mdX_train,mdy_train)\nmd_pre = md_model.predict(mdX_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(mdy_test<md_pre,'indigo','peru')\n\nax.scatter(x=mdy_test, y=md_pre, c=col)\nax.plot(mdy_test,mdy_test, color='r') # Line of accurate predictions\nax.set_xlabel('Madonna di Canneto Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Madonna di Canneto Flow Rate\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(mdy_test,md_pre)),\n     \"\\tR^2:\\t\", metrics.r2_score(mdy_test,md_pre))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Decision Trees on Madonna di Canneto"},{"metadata":{"trusted":true},"cell_type":"code","source":"md_tree = DecisionTreeRegressor()\nmd_tree.fit(mdX_train,mdy_train)\nmd_tree_pre = md_tree.predict(mdX_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(mdy_test<md_tree_pre,'indigo','peru')\n\nax.scatter(x=mdy_test, y=md_tree_pre, c=col)\nax.plot(mdy_test,mdy_test, color='r') # Line of accurate predictions\nax.set_xlabel('Madonna di Canneto Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Madonna di Canneto Flow Rate\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(mdy_test,md_tree_pre)),\n     \"\\tR^2:\\t\", metrics.r2_score(mdy_test,md_tree_pre))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forests on Madonna di Canneto"},{"metadata":{"trusted":true},"cell_type":"code","source":"md_forest = RandomForestRegressor(n_estimators=500, max_features='sqrt',\n                                  min_samples_leaf=2, min_samples_split=5)\nmd_forest.fit(mdX_train,mdy_train)\nmd_forest_pre = md_forest.predict(mdX_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(mdy_test<md_forest_pre,'indigo','peru')\n\nax.scatter(x=mdy_test, y=md_forest_pre, c=col)\nax.plot(mdy_test,mdy_test, color='r') # Line of accurate predictions\nax.set_xlabel('Madonna di Canneto Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Madonna di Canneto Flow Rate\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(mdy_test,md_forest_pre)),\n     \"\\tR^2:\\t\", metrics.r2_score(mdy_test,md_forest_pre))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Lupa Modeling\n\nBecause Lupa only has rainfall and a month feature, but still a healthy amount of data, we have the ideal situation for decision trees. So we will use that here."},{"metadata":{"trusted":true},"cell_type":"code","source":"lupX = lupa.drop(['Date','Flow_Rate_Lupa'],axis=1)\nlupy = lupa['Flow_Rate_Lupa']\n\nlupX_train, lupX_test, lupy_train, lupy_test = train_test_split(lupX, lupy, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lup_tree = DecisionTreeRegressor()\nlup_tree.fit(lupX_train,lupy_train)\nlup_pre = lup_tree.predict(lupX_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(lupy_test<lup_pre,'indigo','peru')\n\nax.scatter(x=lupy_test, y=lup_pre, c=col)\nax.plot(lupy_test,lupy_test, color='r') # Line of accurate predictions\nax.set_xlabel('Lupa Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Lupa Flow Rate\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(lupy_test,lup_pre)),\n     \"\\tR^2:\\t\", metrics.r2_score(lupy_test,lup_pre))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Random Forest on Lupa"},{"metadata":{"trusted":true},"cell_type":"code","source":"lup_forest = RandomForestRegressor(n_estimators=100, max_features='sqrt')\nlup_forest.fit(lupX_train,lupy_train)\nlup_pre = lup_forest.predict(lupX_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predictions\nfig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(lupy_test<lup_pre,'indigo','peru')\n\nax.scatter(x=lupy_test, y=lup_pre, c=col)\nax.plot(lupy_test,lupy_test, color='r') # Line of accurate predictions\nax.set_xlabel('Lupa Flow Rate')\nax.set_ylabel('Predicted Flow Rate')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Lupa Flow Rate\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(lupy_test,lup_pre)),\n     \"\\tR^2:\\t\", metrics.r2_score(lupy_test,lup_pre))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Decision Trees Vs Random Forests"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(aX, bugnano,method=DecisionTreeRegressor, n=20)\nprint_method_results(\"Bugnano Flow Rate with Decision trees\")\n\ntable = run_method(aX, arbure,method=DecisionTreeRegressor, n=20)\nprint_method_results(\"Arbure Flow Rate with Decision trees\")\n\ntable = run_method(aX, ermicciolo,method=DecisionTreeRegressor, n=20)\nprint_method_results(\"Ermicciolo Flow Rate with Decision trees\")\n\ntable = run_method(aX, alta,method=DecisionTreeRegressor, n=20)\nprint_method_results(\"Alta Flow Rate with Decision trees\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(aX, bugnano, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Bugnano Flow Rate with Random Forests\")\n\ntable = run_method(aX, arbure, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Arbure Flow Rate with Random Forests\")\n\ntable = run_method(aX, ermicciolo, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Ermicciolo Flow Rate with Random Forests\")\n\ntable = run_method(aX, alta, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Alta Flow Rate with Random Forests\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(mdX, mdy,n=20, method=DecisionTreeRegressor)\nprint_method_results(\"Madonna di Canneto Flow Rate with Decision trees\")\n\ntable = run_method(mdX, mdy, n=20, method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Madonna di Canneto Flow Rate with Random forests\")\n\ntable = run_method(mdX, mdy,n=20, method=SVR)\nprint_method_results(\"Madonna di Canneto Flow Rate with SVR\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(lupX, lupy,n=20, method=DecisionTreeRegressor)\nprint_method_results(\"Lupa Flow Rate with Decision trees\")\n\ntable = run_method(lupX, lupy, n=20, method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Lupa Flow Rate with Random forests\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Aquifers\n\n## Doganella Overview\nThis aquifer has 9 targets, each one modeled with random forests. Each target was fit with 20 random train/test splits of the original data to achieve the following statistics.\n\n#### Random Forests \n|              Target              |       MAE      |       RMSE     | $R^2$       |\n|:--------------------------------:|:--------------:|:--------------:|:-----------:|\n| **Depth to Groundwater Pozzo 1** | 1.401 ± 0.3904 | 2.264 ± 0.7389 | 0.89 ± 0.07 |\n| **Depth to Groundwater Pozzo 2** | 0.239 ± 0.0766 | 0.387 ± 0.1519 | 0.91 ± 0.06 |\n| **Depth to Groundwater Pozzo 3** | 0.699 ± 0.2849 | 1.369 ± 0.8608 | 0.86 ± 0.14 |\n| **Depth to Groundwater Pozzo 4** | 0.175 ± 0.0463 | 0.277 ± 0.0887 | 0.92 ± 0.06 |\n| **Depth to Groundwater Pozzo 5** | 0.090 ± 0.0392 | 0.184 ± 0.0913 | 0.94 ± 0.05 |\n| **Depth to Groundwater Pozzo 6** | 0.450 ± 0.1641 | 0.902 ± 0.3928 | 0.77 ± 0.17 |\n| **Depth to Groundwater Pozzo 7** | 0.400 ± 0.0667 | 0.633 ± 0.1459 | 0.47 ± 0.12 |\n| **Depth to Groundwater Pozzo 8** | 0.322 ± 0.0901 | 0.517 ± 0.2240 | 0.82 ± 0.12 |\n| **Depth to Groundwater Pozzo 9** | 0.646 ± 0.1918 | 1.196 ± 0.5841 | 0.92 ± 0.07 |\n\nThe key data processing operations that lead to the values from the tables above come from the result of attempting to save missing data by averaging the two rainfall regions data and using that average value any time there was missing data. There was also some use of forward fill strategies for any other missing rainfall days. However, it should be noted that the two regions were kept as separate columns. This is again consistent with the strategy used on other water bodies with multiple targets. \n\nThe missing temperature data is handled in a new way for this case. For each missing temperature data point, the historical temperature data is used to give the average temperature for that month. \n\nAny row missing volume data is dropped. This limited the available data to 421 data points. However, this decision was shown to be an improvement over dropping the volume columns of data.\n\nFinally, the month of a particular data point is added to each row."},{"metadata":{"trusted":true},"cell_type":"code","source":"dog = pd.read_csv('../input/acea-water-prediction/Aquifer_Doganella.csv')\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', dog.shape[0], '\\n',\n      35*'=')\ndog.isna().sum()/(dog.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Quick re-order of the columns to put the targets at the end\ndog = dog[['Date','Rainfall_Monteporzio','Rainfall_Velletri','Temperature_Monteporzio','Temperature_Velletri',\n           'Volume_Pozzo_1','Volume_Pozzo_2','Volume_Pozzo_3','Volume_Pozzo_4','Volume_Pozzo_5+6',\n           'Volume_Pozzo_7','Volume_Pozzo_8','Volume_Pozzo_9','Depth_to_Groundwater_Pozzo_1',\n           'Depth_to_Groundwater_Pozzo_2','Depth_to_Groundwater_Pozzo_3','Depth_to_Groundwater_Pozzo_4',\n           'Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6','Depth_to_Groundwater_Pozzo_7',\n           'Depth_to_Groundwater_Pozzo_8','Depth_to_Groundwater_Pozzo_9']]\ndog.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(dog.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Missing a lot of Volume_**K** data. This information indicates the volume of water, expressed in cubic meters (**mc**), taken from the drinking water treatment plant **K**.\n\nLet's see how the predictors are correlated so that we may strategize how to go about dealing with this missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = dog.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two rainfall features are correlated with a coefficient of 0.82. The two temperature features are correlated with a coefficient of 0.99.\n\nThe strategy here will be to average the two rainfall regions together. This will keep as much of the rainfall information, with the cost of some variability in the different regions. It should be noted that this is possible because each target shares an approximate correlation with the two regions. This has not been the case in some of the previous datasets with multiple targets.\n\nThe strategy for the temperatures will be slightly different. We have two options.\n1. We have lots of temperature data from previous years. We should be able to average a temperature for each month based on those previous years, and fill missing temperature information with this computed average for the month.\n2. Remove the temperature feature entirely and add a month feature as a category.\n\nThe first option would preserve the most variability in the data.\n\nThe volume feature is mostly missing from the top of the data set, so we will have to remove the top as there isn't much to do about it. But before we do that, we need to determine the average temperature for each month."},{"metadata":{"trusted":true},"cell_type":"code","source":"dog['Month'] = dog['Date'].apply(lambda x: x.split('/')[1]) # Strip the month\ntemp_means = dog.groupby(['Month']).mean()[['Temperature_Monteporzio','Temperature_Velletri']] # Print monthly temp average \ntemp_means","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\n\ndef fillin(x,col='No value passed'):   \n    # x is a series of an individual row with axis=1\n    if math.isnan(x[col]):\n        # check the value for temp_means\n        # Give mean temp value for the respective month\n        return temp_means.loc[x['Month'],col]\n    else:\n        return x[col]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog['Temperature_Monteporzio'] = dog[['Month','Temperature_Monteporzio']].apply(fillin,axis=1,col='Temperature_Monteporzio')\ndog['Temperature_Velletri'] = dog[['Month','Temperature_Velletri']].apply(fillin,axis=1,col='Temperature_Velletri')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(dog.dropna(subset=['Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2',\n                               'Depth_to_Groundwater_Pozzo_3','Depth_to_Groundwater_Pozzo_4',\n                               'Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n                               'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8',\n                               'Depth_to_Groundwater_Pozzo_9']).isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog.dropna(subset=['Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2',\n                   'Depth_to_Groundwater_Pozzo_3','Depth_to_Groundwater_Pozzo_4',\n                   'Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n                   'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8',\n                   'Depth_to_Groundwater_Pozzo_9'],\n          inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(dog.fillna(method='ffill',limit=2).isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog.fillna(method='ffill',limit=2, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The remaining missing data from one column of rainfall data can be filled by the value of the other rainfall column, assuming it is not also missing data for that day.\n\nIf we do take an average across the two columns, we find that there are only 14 days where no rainfall is recorded in either column."},{"metadata":{"trusted":true},"cell_type":"code","source":"rain_mean = dog.loc[:,'Rainfall_Monteporzio':'Rainfall_Velletri'].mean(axis=1)\nrain_mean.value_counts(dropna=False).head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Monteporzio has 75 missing values. With the `rain_mean` data, we can reduce that to 14."},{"metadata":{"trusted":true},"cell_type":"code","source":"dog['Rainfall_Monteporzio'].value_counts(dropna=False).head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog['Rainfall_Monteporzio'] = dog['Rainfall_Monteporzio'].fillna(rain_mean)\ndog['Rainfall_Monteporzio'].value_counts(dropna=False).head(6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will also reduce the missing rainfall data to 14 for the Velletri column.\n\nThis will result in 14 days where no rainfall data exists."},{"metadata":{"trusted":true},"cell_type":"code","source":"dog['Rainfall_Velletri'] = dog['Rainfall_Velletri'].fillna(rain_mean)\ndog['Rainfall_Velletri'].value_counts(dropna=False).head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(dog.fillna(rain_mean).isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog.fillna(rain_mean,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"At this point, we might consider dropping the remaining 14 rows with no rainfall data.\n\nBut while we're at it, we might want to split our data into two sets.  \n\nOne where we keep the volume data and drop the remaining missing data.  \nAnother where we drop all volume columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"dog_no_vol = dog.drop(labels=['Volume_Pozzo_1','Volume_Pozzo_2','Volume_Pozzo_3','Volume_Pozzo_4',\n                           'Volume_Pozzo_5+6','Volume_Pozzo_7','Volume_Pozzo_8','Volume_Pozzo_9'], axis=1)\ndog_no_vol.dropna(inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', dog_no_vol.shape[0], '\\n',\n      35*'=')\ndog_no_vol.isna().sum()/(dog_no_vol.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dog.dropna(inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', dog.shape[0], '\\n',\n      35*'=')\ndog.isna().sum()/(dog.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n## Doganella Visualizations\nAt this point, we can't do any more feature engineering without actually looking at the data.\nSo let's visualize it."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=dog_no_vol,\n             x_vars=[\n                 'Rainfall_Monteporzio','Rainfall_Velletri',\n                 'Temperature_Monteporzio','Temperature_Velletri', 'Month'\n             ],\n            y_vars=[\n                'Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2','Depth_to_Groundwater_Pozzo_3',\n                'Depth_to_Groundwater_Pozzo_4','Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n                'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8','Depth_to_Groundwater_Pozzo_9'\n            ])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"months = pd.get_dummies(dog_no_vol['Month'], drop_first=True) # One-hot encoding of month\n\ndog_no_vol = pd.concat([dog_no_vol,months],axis=1) # Add the months to the end","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There appears to be enough of a trend in the month feature to merit a one-hot encoding of the month."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=dog,\n             x_vars=[\n                 'Rainfall_Monteporzio','Rainfall_Velletri',\n                 'Temperature_Monteporzio','Temperature_Velletri', 'Month'\n                 \n             ],\n            y_vars=[\n                'Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2','Depth_to_Groundwater_Pozzo_3',\n                'Depth_to_Groundwater_Pozzo_4','Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n                'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8','Depth_to_Groundwater_Pozzo_9'\n            ])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=dog,\n             x_vars=[\n                 'Volume_Pozzo_1','Volume_Pozzo_2','Volume_Pozzo_3','Volume_Pozzo_4',\n                 'Volume_Pozzo_5+6','Volume_Pozzo_7','Volume_Pozzo_8','Volume_Pozzo_9'\n                 \n             ],\n            y_vars=[\n                'Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2','Depth_to_Groundwater_Pozzo_3',\n                'Depth_to_Groundwater_Pozzo_4','Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n                'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8','Depth_to_Groundwater_Pozzo_9'\n            ])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"months = pd.get_dummies(dog['Month'], drop_first=True) # One-hot encoding of month\n\ndog = pd.concat([dog,months],axis=1) # Add the months to the end","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Building the Models\nA good choice of model appears again to be decision trees, as seen from similar structures in the data in other bodies of water.\n\nWe will have to build two sets of 9 models. One for each target of the two data sets."},{"metadata":{"trusted":true},"cell_type":"code","source":"nvX = dog_no_vol.drop(['Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2',\n                       'Depth_to_Groundwater_Pozzo_3','Depth_to_Groundwater_Pozzo_4',\n                       'Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n                       'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8',\n                       'Depth_to_Groundwater_Pozzo_9','Date','Month'],axis=1)\n\nnv_p1 = dog_no_vol['Depth_to_Groundwater_Pozzo_1']\nnv_p2 = dog_no_vol['Depth_to_Groundwater_Pozzo_2']\nnv_p3 = dog_no_vol['Depth_to_Groundwater_Pozzo_3']\nnv_p4 = dog_no_vol['Depth_to_Groundwater_Pozzo_4']\nnv_p5 = dog_no_vol['Depth_to_Groundwater_Pozzo_5']\nnv_p6 = dog_no_vol['Depth_to_Groundwater_Pozzo_6']\nnv_p7 = dog_no_vol['Depth_to_Groundwater_Pozzo_7']\nnv_p8 = dog_no_vol['Depth_to_Groundwater_Pozzo_8']\nnv_p9 = dog_no_vol['Depth_to_Groundwater_Pozzo_9']\n\nnvX_p1_train, nvX_p1_test, nv_p1_train, nv_p1_test = train_test_split(nvX, nv_p1, test_size=0.2)\nnvX_p2_train, nvX_p2_test, nv_p2_train, nv_p2_test = train_test_split(nvX, nv_p2, test_size=0.2)\nnvX_p3_train, nvX_p3_test, nv_p3_train, nv_p3_test = train_test_split(nvX, nv_p3, test_size=0.2)\nnvX_p4_train, nvX_p4_test, nv_p4_train, nv_p4_test = train_test_split(nvX, nv_p4, test_size=0.2)\nnvX_p5_train, nvX_p5_test, nv_p5_train, nv_p5_test = train_test_split(nvX, nv_p5, test_size=0.2)\nnvX_p6_train, nvX_p6_test, nv_p6_train, nv_p6_test = train_test_split(nvX, nv_p6, test_size=0.2)\nnvX_p7_train, nvX_p7_test, nv_p7_train, nv_p7_test = train_test_split(nvX, nv_p7, test_size=0.2)\nnvX_p8_train, nvX_p8_test, nv_p8_train, nv_p8_test = train_test_split(nvX, nv_p8, test_size=0.2)\nnvX_p9_train, nvX_p9_test, nv_p9_train, nv_p9_test = train_test_split(nvX, nv_p9, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nv_p1_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p2_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p3_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p4_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p5_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p6_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p7_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p8_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nnv_p9_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nv_p1_model.fit(nvX_p1_train,nv_p1_train)\nnv_p2_model.fit(nvX_p2_train,nv_p2_train)\nnv_p3_model.fit(nvX_p3_train,nv_p3_train)\nnv_p4_model.fit(nvX_p4_train,nv_p4_train)\nnv_p5_model.fit(nvX_p5_train,nv_p5_train)\nnv_p6_model.fit(nvX_p6_train,nv_p6_train)\nnv_p7_model.fit(nvX_p7_train,nv_p7_train)\nnv_p8_model.fit(nvX_p8_train,nv_p8_train)\nnv_p9_model.fit(nvX_p9_train,nv_p9_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nv_predictions1 = nv_p1_model.predict(nvX_p1_test)\nnv_predictions2 = nv_p2_model.predict(nvX_p2_test)\nnv_predictions3 = nv_p3_model.predict(nvX_p3_test)\nnv_predictions4 = nv_p4_model.predict(nvX_p4_test)\nnv_predictions5 = nv_p5_model.predict(nvX_p5_test)\nnv_predictions6 = nv_p6_model.predict(nvX_p6_test)\nnv_predictions7 = nv_p7_model.predict(nvX_p7_test)\nnv_predictions8 = nv_p8_model.predict(nvX_p8_test)\nnv_predictions9 = nv_p9_model.predict(nvX_p9_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pozzo 1 - 4\nfig = plt.figure(figsize=(4,3))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\nax3 = fig.add_axes([0,-1.3,1,1])\nax4 = fig.add_axes([1.2,-1.3,1,1])\n\ncol1 = np.where(nv_p1_test<nv_predictions1,'indigo','peru')\ncol2 = np.where(nv_p2_test<nv_predictions2,'indigo','peru')\ncol3 = np.where(nv_p3_test<nv_predictions3,'indigo','peru')                      \ncol4 = np.where(nv_p4_test<nv_predictions4,'indigo','peru')                      \n\nax.scatter(x=nv_p1_test, y=nv_predictions1, c=col1)\nax.plot(nv_p1_test,nv_p1_test, color='r') # Line of accurate predictions\nax.set_xlabel('Depth to Groundwater Pozzo 1')\nax.set_ylabel('Predicted Depth to Groundwater Pozzo 1')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=nv_p2_test, y=nv_predictions2, c=col2)\nax2.plot(nv_p2_test,nv_p2_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Depth to Groundwater Pozzo 2')\nax2.set_ylabel('Predicted Depth to Groundwater Pozzo 2')\nax2.set_title('Predicted and true values on the test set')\n\nax3.scatter(x=nv_p3_test, y=nv_predictions3, c=col3)\nax3.plot(nv_p3_test,nv_p3_test, color='r') # Line of accurate predictions\nax3.set_xlabel('Depth to Groundwater Pozzo 3')\nax3.set_ylabel('Predicted Depth to Groundwater Pozzo 3')\nax3.set_title('Predicted and true values on the test set')\n\nax4.scatter(x=nv_p4_test, y=nv_predictions4, c=col4)\nax4.plot(nv_p4_test,nv_p4_test, color='r') # Line of accurate predictions\nax4.set_xlabel('Depth to Groundwater Pozzo 4')\nax4.set_ylabel('Predicted Depth to Groundwater Pozzo 4')\nax4.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pozzo 5-9\nfig = plt.figure(figsize=(4,3))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\nax3 = fig.add_axes([0,-1.3,1,1])\nax4 = fig.add_axes([1.2,-1.3,1,1])\nax5 = fig.add_axes([0,-2.6,1,1])\n\ncol1 = np.where(nv_p5_test<nv_predictions5,'indigo','peru')\ncol2 = np.where(nv_p6_test<nv_predictions6,'indigo','peru')\ncol3 = np.where(nv_p7_test<nv_predictions7,'indigo','peru')\ncol4 = np.where(nv_p8_test<nv_predictions8,'indigo','peru')\ncol5 = np.where(nv_p9_test<nv_predictions9,'indigo','peru')\n\nax.scatter(x=nv_p5_test, y=nv_predictions5, c=col1)\nax.plot(nv_p5_test,nv_p5_test, color='r') # Line of accurate predictions\nax.set_xlabel('Depth to Groundwater Pozzo 5')\nax.set_ylabel('Predicted Depth to Groundwater Pozzo 5')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=nv_p6_test, y=nv_predictions6, c=col2)\nax2.plot(nv_p6_test,nv_p6_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Depth to Groundwater Pozzo 6')\nax2.set_ylabel('Predicted Depth to Groundwater Pozzo 6')\nax2.set_title('Predicted and true values on the test set')\n\nax3.scatter(x=nv_p7_test, y=nv_predictions7, c=col3)\nax3.plot(nv_p7_test,nv_p7_test, color='r') # Line of accurate predictions\nax3.set_xlabel('Depth to Groundwater Pozzo 7')\nax3.set_ylabel('Predicted Depth to Groundwater Pozzo 7')\nax3.set_title('Predicted and true values on the test set')\n\nax4.scatter(x=nv_p8_test, y=nv_predictions8, c=col4)\nax4.plot(nv_p8_test,nv_p8_test, color='r') # Line of accurate predictions\nax4.set_xlabel('Depth to Groundwater Pozzo 8')\nax4.set_ylabel('Predicted Depth to Groundwater Pozzo 8')\nax4.set_title('Predicted and true values on the test set')\n\nax5.scatter(x=nv_p9_test, y=nv_predictions9, c=col5)\nax5.plot(nv_p9_test,nv_p9_test, color='r') # Line of accurate predictions\nax5.set_xlabel('Depth to Groundwater Pozzo 9')\nax5.set_ylabel('Predicted Depth to Groundwater Pozzo 9')\nax5.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation\nprint(\"Depth to Groundwater Pozzo 1\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p1_test,nv_predictions1)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p1_test,nv_predictions1))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 2\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p2_test,nv_predictions2)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p2_test,nv_predictions2))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 3\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p3_test,nv_predictions3)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p3_test,nv_predictions3))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 4\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p4_test,nv_predictions4)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p4_test,nv_predictions4))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 5\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p5_test,nv_predictions5)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p5_test,nv_predictions5))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 6\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p6_test,nv_predictions6)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p6_test,nv_predictions6))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 7\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p7_test,nv_predictions7)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p7_test,nv_predictions7))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 8\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p8_test,nv_predictions8)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p8_test,nv_predictions8))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 9\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(nv_p9_test,nv_predictions9)),\n     \"\\tR^2:\\t\", metrics.r2_score(nv_p9_test,nv_predictions9))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## The Volume Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = dog.drop(['Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_2','Depth_to_Groundwater_Pozzo_3',\n              'Depth_to_Groundwater_Pozzo_4','Depth_to_Groundwater_Pozzo_5','Depth_to_Groundwater_Pozzo_6',\n              'Depth_to_Groundwater_Pozzo_7','Depth_to_Groundwater_Pozzo_8','Depth_to_Groundwater_Pozzo_9',\n              'Date','Month'],axis=1)\n\np1 = dog['Depth_to_Groundwater_Pozzo_1']\np2 = dog['Depth_to_Groundwater_Pozzo_2']\np3 = dog['Depth_to_Groundwater_Pozzo_3']\np4 = dog['Depth_to_Groundwater_Pozzo_4']\np5 = dog['Depth_to_Groundwater_Pozzo_5']\np6 = dog['Depth_to_Groundwater_Pozzo_6']\np7 = dog['Depth_to_Groundwater_Pozzo_7']\np8 = dog['Depth_to_Groundwater_Pozzo_8']\np9 = dog['Depth_to_Groundwater_Pozzo_9']\n\nX_p1_train, X_p1_test, p1_train, p1_test = train_test_split(X, p1, test_size=0.1)\nX_p2_train, X_p2_test, p2_train, p2_test = train_test_split(X, p2, test_size=0.1)\nX_p3_train, X_p3_test, p3_train, p3_test = train_test_split(X, p3, test_size=0.1)\nX_p4_train, X_p4_test, p4_train, p4_test = train_test_split(X, p4, test_size=0.1)\nX_p5_train, X_p5_test, p5_train, p5_test = train_test_split(X, p5, test_size=0.1)\nX_p6_train, X_p6_test, p6_train, p6_test = train_test_split(X, p6, test_size=0.1)\nX_p7_train, X_p7_test, p7_train, p7_test = train_test_split(X, p7, test_size=0.1)\nX_p8_train, X_p8_test, p8_train, p8_test = train_test_split(X, p8, test_size=0.1)\nX_p9_train, X_p9_test, p9_train, p9_test = train_test_split(X, p9, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np2_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np3_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np4_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np5_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np6_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np7_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np8_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')\np9_model = RandomForestRegressor(n_estimators=200, max_features='sqrt')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p1_model.fit(X_p1_train,p1_train)\np2_model.fit(X_p2_train,p2_train)\np3_model.fit(X_p3_train,p3_train)\np4_model.fit(X_p4_train,p4_train)\np5_model.fit(X_p5_train,p5_train)\np6_model.fit(X_p6_train,p6_train)\np7_model.fit(X_p7_train,p7_train)\np8_model.fit(X_p8_train,p8_train)\np9_model.fit(X_p9_train,p9_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions1 = p1_model.predict(X_p1_test)\npredictions2 = p2_model.predict(X_p2_test)\npredictions3 = p3_model.predict(X_p3_test)\npredictions4 = p4_model.predict(X_p4_test)\npredictions5 = p5_model.predict(X_p5_test)\npredictions6 = p6_model.predict(X_p6_test)\npredictions7 = p7_model.predict(X_p7_test)\npredictions8 = p8_model.predict(X_p8_test)\npredictions9 = p9_model.predict(X_p9_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pozzo 1 - 4\nfig = plt.figure(figsize=(4,3))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\nax3 = fig.add_axes([0,-1.3,1,1])\nax4 = fig.add_axes([1.2,-1.3,1,1])\n\ncol1 = np.where(p1_test<predictions1,'indigo','peru')\ncol2 = np.where(p2_test<predictions2,'indigo','peru')\ncol3 = np.where(p3_test<predictions3,'indigo','peru')                      \ncol4 = np.where(p4_test<predictions4,'indigo','peru')                      \n\nax.scatter(x=p1_test, y=predictions1, c=col1)\nax.plot(p1_test,p1_test, color='r') # Line of accurate predictions\nax.set_xlabel('Depth to Groundwater Pozzo 1')\nax.set_ylabel('Predicted Depth to Groundwater Pozzo 1')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=p2_test, y=predictions2, c=col2)\nax2.plot(p2_test,p2_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Depth to Groundwater Pozzo 2')\nax2.set_ylabel('Predicted Depth to Groundwater Pozzo 2')\nax2.set_title('Predicted and true values on the test set')\n\nax3.scatter(x=p3_test, y=predictions3, c=col3)\nax3.plot(p3_test,p3_test, color='r') # Line of accurate predictions\nax3.set_xlabel('Depth to Groundwater Pozzo 3')\nax3.set_ylabel('Predicted Depth to Groundwater Pozzo 3')\nax3.set_title('Predicted and true values on the test set')\n\nax4.scatter(x=p4_test, y=predictions4, c=col4)\nax4.plot(p4_test,p4_test, color='r') # Line of accurate predictions\nax4.set_xlabel('Depth to Groundwater Pozzo 4')\nax4.set_ylabel('Predicted Depth to Groundwater Pozzo 4')\nax4.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Pozzo 5-9\nfig = plt.figure(figsize=(4,3))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\nax3 = fig.add_axes([0,-1.3,1,1])\nax4 = fig.add_axes([1.2,-1.3,1,1])\nax5 = fig.add_axes([0,-2.6,1,1])\n\ncol1 = np.where(p5_test<predictions5,'indigo','peru')\ncol2 = np.where(p6_test<predictions6,'indigo','peru')\ncol3 = np.where(p7_test<predictions7,'indigo','peru')\ncol4 = np.where(p8_test<predictions8,'indigo','peru')\ncol5 = np.where(p9_test<predictions9,'indigo','peru')\n\nax.scatter(x=p5_test, y=predictions5, c=col1)\nax.plot(p5_test,p5_test, color='r') # Line of accurate predictions\nax.set_xlabel('Depth to Groundwater Pozzo 5')\nax.set_ylabel('Predicted Depth to Groundwater Pozzo 5')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=p6_test, y=predictions6, c=col2)\nax2.plot(p6_test,p6_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Depth to Groundwater Pozzo 6')\nax2.set_ylabel('Predicted Depth to Groundwater Pozzo 6')\nax2.set_title('Predicted and true values on the test set')\n\nax3.scatter(x=p7_test, y=predictions7, c=col3)\nax3.plot(p7_test,p7_test, color='r') # Line of accurate predictions\nax3.set_xlabel('Depth to Groundwater Pozzo 7')\nax3.set_ylabel('Predicted Depth to Groundwater Pozzo 7')\nax3.set_title('Predicted and true values on the test set')\n\nax4.scatter(x=p8_test, y=predictions8, c=col4)\nax4.plot(p8_test,p8_test, color='r') # Line of accurate predictions\nax4.set_xlabel('Depth to Groundwater Pozzo 8')\nax4.set_ylabel('Predicted Depth to Groundwater Pozzo 8')\nax4.set_title('Predicted and true values on the test set')\n\nax5.scatter(x=p9_test, y=predictions9, c=col5)\nax5.plot(p9_test,p9_test, color='r') # Line of accurate predictions\nax5.set_xlabel('Depth to Groundwater Pozzo 9')\nax5.set_ylabel('Predicted Depth to Groundwater Pozzo 9')\nax5.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation\nprint(\"Depth to Groundwater Pozzo 1\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p1_test,predictions1)),\n     \"\\tR^2:\\t\", metrics.r2_score(p1_test,predictions1))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 2\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p2_test,predictions2)),\n     \"\\tR^2:\\t\", metrics.r2_score(p2_test,predictions2))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 3\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p3_test,predictions3)),\n     \"\\tR^2:\\t\", metrics.r2_score(p3_test,predictions3))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 4\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p4_test,predictions4)),\n     \"\\tR^2:\\t\", metrics.r2_score(p4_test,predictions4))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 5\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p5_test,predictions5)),\n     \"\\tR^2:\\t\", metrics.r2_score(p5_test,predictions5))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 6\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p6_test,predictions6)),\n     \"\\tR^2:\\t\", metrics.r2_score(p6_test,predictions6))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 7\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p7_test,predictions7)),\n     \"\\tR^2:\\t\", metrics.r2_score(p7_test,predictions7))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 8\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p8_test,predictions8)),\n     \"\\tR^2:\\t\", metrics.r2_score(p8_test,predictions8))\n\nprint(65*\"=\",\"\\nDepth to Groundwater Pozzo 9\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p9_test,predictions9)),\n     \"\\tR^2:\\t\", metrics.r2_score(p9_test,predictions9))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Clearly, the volume data are very strong predictors of the depth to groundwater of each region. This is because, despite the loss in hundreds of data points to include only those days where volume data was recorded, the volume data results in better performance.\n\n---\n\n## MAE, RMSE, and $R^2$"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(X, p1, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 1\")\n\ntable = run_method(X, p2, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 2\")\n\ntable = run_method(X, p3, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 3\")\n\ntable = run_method(X, p4, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 4\")\n\ntable = run_method(X, p5, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 5\")\n\ntable = run_method(X, p6, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 6\")\n\ntable = run_method(X, p7, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 7\")\n\ntable = run_method(X, p8, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 8\")\n\ntable = run_method(X, p9, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Pozzo 9\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Luco Overview\nThis aquifer has one target, which has been modeled with random forests. Each target was fit with 20 random train/test splits of the original data to achieve the following statistics.\n\n#### Depth to Groundwater Podere Casetta \n|     ML Method      |       MAE      |       RMSE     | $R^2$       |\n|:------------------:|:--------------:|:--------------:|:-----------:|\n| **Random Forests** | 0.031 ± 0.0077 | 0.046 ± 0.0109 | 0.98 ± 0.01 |\n\n\nThe rainfall and temperature features in this dataset are averaged into one column to reduce variance of the resulting model. Any missing data after these two operations are dropped row-wise for the targets and the features."},{"metadata":{"trusted":true},"cell_type":"code","source":"luco = pd.read_csv('../input/acea-water-prediction/Aquifer_Luco.csv')\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', luco.shape[0], '\\n',\n      35*'=')\nluco.isna().sum()/(luco.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(luco.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Because we are trying to predict only one output, we can average rainfall data to make up for missing information.\n\nThere is no missing temperature data, but that can be averaged into a single column for simplification, since local temperatures are likely to all be correlated and are also not likely to affect an aquifer through evaporation in the same way a lake would be affected.\n\nThere is a lot of missing information missing from the Pozzo regions. In the Doganella aquifer data, it was worth the loss of years of data to include the volume data in the model, so we will attempt to keep that data, but the target data is very spotty around those later dates."},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = luco.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"luco['Mean_Rainfall'] = luco.loc[:,'Rainfall_Simignano':'Rainfall_Monteroni_Arbia_Biena'].mean(axis=1)\n\nluco.drop(labels=['Rainfall_Simignano','Rainfall_Siena_Poggio_al_Vento','Rainfall_Mensano',\n                  'Rainfall_Montalcinello','Rainfall_Monticiano_la_Pineta','Rainfall_Sovicille',\n                  'Rainfall_Ponte_Orgia','Rainfall_Scorgiano','Rainfall_Pentolina',\n                  'Rainfall_Monteroni_Arbia_Biena'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(luco.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will remove any missing rows from the target data."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(luco.dropna(subset=['Depth_to_Groundwater_Podere_Casetta']).isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"luco.dropna(subset=['Depth_to_Groundwater_Podere_Casetta'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = luco.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are only a few hundred data points for the other depth variables, which we can use as predictors in this challenge. Pozzo 1 and 3 have a high negative correlation with the response variable, so it is probably justified in keeping those data points. Let's see exactly how many non-null values there are for those columns.\n\nFortunately, those non-null depth to groundwater features overlap with the non-null volume data, so we don't have to concern ourselves as much with the volume data."},{"metadata":{"trusted":true},"cell_type":"code","source":"luco.dropna(subset=[\n    'Depth_to_Groundwater_Pozzo_1',\n    'Depth_to_Groundwater_Pozzo_3',\n    'Depth_to_Groundwater_Pozzo_4'], inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', luco.shape[0], '\\n',\n      35*'=')\nluco.isna().sum()/(luco.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"445 data points should be enough to work with, considering the benefit from keeping the depth to groundwater columns.\n\nWe can now simplify the temperature data and begin visualization."},{"metadata":{"trusted":true},"cell_type":"code","source":"luco['Mean_Temperature'] = luco.loc[:,'Temperature_Siena_Poggio_al_Vento':'Temperature_Monteroni_Arbia_Biena'].mean(axis=1)\n\nluco.drop(labels=['Temperature_Siena_Poggio_al_Vento','Temperature_Mensano','Temperature_Pentolina',\n                  'Temperature_Monteroni_Arbia_Biena'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = [\n    'Date','Mean_Rainfall','Mean_Temperature',\n    'Volume_Pozzo_1','Volume_Pozzo_3','Volume_Pozzo_4',\n    'Depth_to_Groundwater_Pozzo_1','Depth_to_Groundwater_Pozzo_3','Depth_to_Groundwater_Pozzo_4',\n    'Depth_to_Groundwater_Podere_Casetta'\n       ]\n\nluco = luco[cols]\nluco.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = luco.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"An interesting observation; the individual temperatures each had low correlation $( |\\text{ corr }| < 0.2 )$ with our target. But with the averaging of each region, we now have a stronger correlation between temperature and our target.\n\n---\n\n##  Luco Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(11,4))\nax1 = fig.add_axes([0,0,1,0.5])\nax2 = fig.add_axes([0,-0.7,1,0.5])\nax3 = fig.add_axes([0,-1.4,1,0.5])\nax4 = fig.add_axes([0,-2.1,1,0.5])\n\nax1.set_title('Depth to Groundwater Podere Casetta')\nax1.set_xlabel('Time')\nax1.set_ylabel('meters')\n\nax2.set_title('Mean Volume')\nax2.set_xlabel('Time')\nax2.set_ylabel('mc')\n\nax3.set_title('Temperature')\nax3.set_xlabel('Time')\nax3.set_ylabel('celsius')\n\nax4.set_title('Mean Region Rainfall')\nax4.set_xlabel('Time')\nax4.set_ylabel('mm')\n\nax1.tick_params(axis='x', bottom=False, labelbottom=False)\nax2.tick_params(axis='x', bottom=False, labelbottom=False)\nax3.tick_params(axis='x', bottom=False, labelbottom=False)\nax4.tick_params(axis='x', bottom=False, labelbottom=False)\n\nax1.plot(luco['Date'], luco['Depth_to_Groundwater_Podere_Casetta'], label='Depth to Groundwater', color='g')\nax2.plot(luco['Date'], luco[['Volume_Pozzo_1','Volume_Pozzo_3','Volume_Pozzo_4']].mean(axis=1), label='Volume', color='y')\nax3.plot(luco['Date'], luco['Mean_Temperature'], label='Temperature', color='r')\nax4.plot(luco['Date'], luco['Mean_Rainfall'], label='Rainfall', color='b')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(11,4))\nax1 = fig.add_axes([0,0,1,0.5])\nax2 = fig.add_axes([0,-0.7,1,0.5])\nax3 = fig.add_axes([0,-1.4,1,0.5])\nax4 = fig.add_axes([0,-2.1,1,0.5])\n\nax1.set_title('Depth to Groundwater Podere Casetta')\nax1.set_xlabel('Time')\nax1.set_ylabel('meters')\n\nax2.set_title('Depth to Groundwater Pozzo 1')\nax2.set_xlabel('Time')\nax2.set_ylabel('meters')\n\nax3.set_title('Depth to Groundwater Pozzo 3')\nax3.set_xlabel('Time')\nax3.set_ylabel('meters')\n\nax4.set_title('Depth to Groundwater Pozzo 4')\nax4.set_xlabel('Time')\nax4.set_ylabel('meters')\n\nax1.tick_params(axis='x', bottom=False, labelbottom=False)\nax2.tick_params(axis='x', bottom=False, labelbottom=False)\nax3.tick_params(axis='x', bottom=False, labelbottom=False)\nax4.tick_params(axis='x', bottom=False, labelbottom=False)\n\nax1.plot(luco['Date'], luco['Depth_to_Groundwater_Podere_Casetta'], label='Depth to Groundwater', color='g')\nax2.plot(luco['Date'], luco['Depth_to_Groundwater_Pozzo_1'], label='Depth Pozzo 1', color='y')\nax3.plot(luco['Date'], luco['Depth_to_Groundwater_Pozzo_3'], label='Depth Pozzo 3', color='r')\nax4.plot(luco['Date'], luco['Depth_to_Groundwater_Pozzo_4'], label='Depth Pozzo 4', color='b')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Mean_Rainfall'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Mean_Temperature'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Volume_Pozzo_1'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Volume_Pozzo_3'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Volume_Pozzo_4'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Depth_to_Groundwater_Pozzo_1'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Depth_to_Groundwater_Pozzo_3'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\nsns.scatterplot(x=luco['Depth_to_Groundwater_Pozzo_4'], y=luco['Depth_to_Groundwater_Podere_Casetta'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The data looks like it would be fit well with decision trees yet again. So we can jump to using random forest to begin.\n\n---\n\n## Modeling Luco"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = luco.drop(['Date','Depth_to_Groundwater_Podere_Casetta'], axis=1)\ny = luco['Depth_to_Groundwater_Podere_Casetta']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=5)\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,6))\n\nax = fig.add_axes([0,0,1,1])\n\ncol = np.where(y_test<predictions,'indigo','peru')\n\nax.scatter(x=y_test, y=predictions, c=col)\nax.plot(y_test,y_test, color='r') # Line of accurate predictions\nax.set_xlabel('Depth to Groundwater Podere Casetta')\nax.set_ylabel('Predicted Depth to Groundwater')\nax.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Depth to Groundwater Podere Casetta \\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(y_test,predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(y_test,predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n## MAE, RMSE, and $R^2$"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(X, y, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater Podere Casetta\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"##  Auser Overview\n\nThis aquifer has five targets, each modeled with random forests. Each target was fit with 20 random train/test splits of the original data to achieve the following statistics.\n\n#### Random Forests \n|             Target           |       MAE      |       RMSE     | $R^2$       |\n|:----------------------------:|:--------------:|:--------------:|:-----------:|\n| **Depth to Groundwater LT2** | 0.020 ± 0.0121 | 0.160 ± 0.2050 | 0.92 ± 0.13 |\n| **Depth to Groundwater SAL** | 0.017 ± 0.0089 | 0.060 ± 0.0702 | 0.98 ± 0.02 |\n| **Depth to Groundwater PAG** | 0.016 ± 0.0025 | 0.032 ± 0.0107 | 0.99 ± 0.01 |\n| **Depth to Groundwater CoS** | 0.029 ± 0.0119 | 0.090 ± 0.1274 | 0.99 ± 0.01 |\n| **Depth to Groundwater DIEC** | 0.016 ± 0.0045  | 0.041 ± 0.0243 | 0.99 ± 0.01 |\n\n#### Procedure\nThe rainfall and temperature features in this dataset are averaged into one column to reduce variance of the resulting model. After dropping rows with missing target data, there were only about 13 missing rows remaining. Linear interpolation was used to fill those gaps."},{"metadata":{"trusted":true},"cell_type":"code","source":"auser = pd.read_csv('../input/acea-water-prediction/Aquifer_Auser.csv')\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', auser.shape[0], '\\n',\n      35*'=')\nauser.isna().sum()/(auser.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(auser.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Auser Missing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = auser.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rainfall and Temperature are highly correlated and can be averaged as before. This would just be for simplification purposes and to lower the variance of our resulting model as there isn't much missing data, except from the targets. Of course, we typically just remove rows with missing target data.\n\nWe can see that if we remove those data points, we have only a few days remaining with missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(auser.dropna(subset=['Depth_to_Groundwater_LT2','Depth_to_Groundwater_SAL',\n                                 'Depth_to_Groundwater_PAG','Depth_to_Groundwater_CoS',\n                                 'Depth_to_Groundwater_DIEC']).isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auser.dropna(subset=['Depth_to_Groundwater_LT2','Depth_to_Groundwater_SAL','Depth_to_Groundwater_PAG',\n                     'Depth_to_Groundwater_CoS','Depth_to_Groundwater_DIEC'], inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', auser.shape[0], '\\n',\n      35*'=')\nauser.isna().sum()/(auser.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at those rows where there are some missing data for the two hydrometry columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"auser[auser['Hydrometry_Monte_S_Quirico'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auser[auser['Hydrometry_Piaggione'].isnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The two options for filling this data is a linear interpolation and the other option is a simple back fill."},{"metadata":{"trusted":true},"cell_type":"code","source":"auser.interpolate(inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', auser.shape[0], '\\n',\n      35*'=')\nauser.isna().sum()/(auser.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"auser['Mean_Rainfall'] = auser.loc[:,'Rainfall_Gallicano':'Rainfall_Fabbriche_di_Vallico'].mean(axis=1)\nauser['Mean_Temperature'] = auser.loc[:,'Temperature_Orentano':'Temperature_Lucca_Orto_Botanico'].mean(axis=1)\n\ncols = ['Mean_Rainfall','Mean_Temperature', 'Volume_POL','Volume_CC1','Volume_CC2','Volume_CSA','Volume_CSAL',\n        'Hydrometry_Monte_S_Quirico','Hydrometry_Piaggione','Depth_to_Groundwater_LT2','Depth_to_Groundwater_SAL',\n        'Depth_to_Groundwater_PAG','Depth_to_Groundwater_CoS','Depth_to_Groundwater_DIEC']\n\nauser = auser[cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = auser.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Auser Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=auser,\n             x_vars=[\n                 'Mean_Rainfall','Mean_Temperature', 'Volume_POL','Volume_CC1','Volume_CC2',\n                 'Volume_CSA','Volume_CSAL','Hydrometry_Monte_S_Quirico','Hydrometry_Piaggione'\n             ],\n            y_vars=[\n                'Depth_to_Groundwater_LT2','Depth_to_Groundwater_SAL','Depth_to_Groundwater_PAG',\n                'Depth_to_Groundwater_CoS','Depth_to_Groundwater_DIEC'\n            ])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Auser Modeling\n### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = auser.drop(['Mean_Rainfall','Mean_Temperature', 'Volume_POL','Volume_CC1','Volume_CC2',\n                 'Volume_CSA','Volume_CSAL','Hydrometry_Monte_S_Quirico','Hydrometry_Piaggione'],axis=1)\n\nLT2 = auser['Depth_to_Groundwater_LT2']\nSAL = auser['Depth_to_Groundwater_SAL']\nPAG = auser['Depth_to_Groundwater_PAG']\nCoS = auser['Depth_to_Groundwater_CoS']\nDIEC = auser['Depth_to_Groundwater_DIEC']\n\nX_LT2_train, X_LT2_test, LT2_train, LT2_test = train_test_split(X, LT2, test_size=0.2)\nX_SAL_train, X_SAL_test, SAL_train, SAL_test = train_test_split(X, SAL, test_size=0.2)\nX_PAG_train, X_PAG_test, PAG_train, PAG_test = train_test_split(X, PAG, test_size=0.2)\nX_CoS_train, X_CoS_test, CoS_train, CoS_test = train_test_split(X, CoS, test_size=0.2)\nX_DIEC_train, X_DIEC_test, DIEC_train, DIEC_test = train_test_split(X, DIEC, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LT2_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nLT2_model.fit(X_LT2_train,LT2_train)\n\nSAL_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nSAL_model.fit(X_SAL_train,SAL_train)\n\nPAG_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nPAG_model.fit(X_PAG_train,PAG_train)\n\nCoS_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nCoS_model.fit(X_CoS_train,CoS_train)\n\nDIEC_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=10)\nDIEC_model.fit(X_DIEC_train,DIEC_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LT2_predictions = LT2_model.predict(X_LT2_test)\nSAL_predictions = SAL_model.predict(X_SAL_test)\nPAG_predictions = PAG_model.predict(X_PAG_test)\nCoS_predictions = CoS_model.predict(X_CoS_test)\nDIEC_predictions = DIEC_model.predict(X_DIEC_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Auser Results\nfig = plt.figure(figsize=(4,3))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\nax3 = fig.add_axes([0,-1.3,1,1])\nax4 = fig.add_axes([1.2,-1.3,1,1])\nax5 = fig.add_axes([0,-2.6,1,1])\n\ncol1 = np.where(LT2_test<LT2_predictions,'indigo','peru')\ncol2 = np.where(SAL_test<SAL_predictions,'indigo','peru')\ncol3 = np.where(PAG_test<PAG_predictions,'indigo','peru')\ncol4 = np.where(CoS_test<CoS_predictions,'indigo','peru')\ncol5 = np.where(DIEC_test<DIEC_predictions,'indigo','peru')\n\nax.scatter(x=LT2_test, y=LT2_predictions, c=col1)\nax.plot(LT2_test,LT2_test, color='r') # Line of accurate predictions\nax.set_xlabel('Depth to Groundwater LT2')\nax.set_ylabel('Predicted Depth to Groundwater LT2')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=SAL_test, y=SAL_predictions, c=col2)\nax2.plot(SAL_test,SAL_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Depth to Groundwater SAL')\nax2.set_ylabel('Predicted Depth to Groundwater SAL')\nax2.set_title('Predicted and true values on the test set')\n\nax3.scatter(x=PAG_test, y=PAG_predictions, c=col3)\nax3.plot(PAG_test,PAG_test, color='r') # Line of accurate predictions\nax3.set_xlabel('Depth to Groundwater PAG')\nax3.set_ylabel('Predicted Depth to Groundwater PAG')\nax3.set_title('Predicted and true values on the test set')\n\nax4.scatter(x=CoS_test, y=CoS_predictions, c=col4)\nax4.plot(CoS_test,CoS_test, color='r') # Line of accurate predictions\nax4.set_xlabel('Depth to Groundwater CoS')\nax4.set_ylabel('Predicted Depth to Groundwater CoS')\nax4.set_title('Predicted and true values on the test set')\n\nax5.scatter(x=DIEC_test, y=DIEC_predictions, c=col5)\nax5.plot(DIEC_test,DIEC_test, color='r') # Line of accurate predictions\nax5.set_xlabel('Depth to Groundwater DIEC')\nax5.set_ylabel('Predicted Depth to Groundwater DIEC')\nax5.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation\nprint(\"Depth to Groundwater LT2\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(LT2_test,LT2_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(LT2_test,LT2_predictions))\n\nprint(65*\"=\",\"\\nDepth to Groundwater SAL\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(SAL_test,SAL_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(SAL_test,SAL_predictions))\n\nprint(65*\"=\",\"\\nDepth to Groundwater PAG\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(PAG_test,PAG_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(PAG_test,PAG_predictions))\n\nprint(65*\"=\",\"\\nDepth to Groundwater CoS\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(CoS_test,CoS_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(CoS_test,CoS_predictions))\n\nprint(65*\"=\",\"\\nDepth to Groundwater DIEC\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(DIEC_test,DIEC_predictions)),\n     \"\\tR^2:\\t\", metrics.r2_score(DIEC_test,DIEC_predictions))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## MAE, RMSE, and $R^2$"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(X, LT2, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater LT2\")\n\ntable = run_method(X, SAL, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater SAL\")\n\ntable = run_method(X, PAG, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater PAG\")\n\ntable = run_method(X, CoS, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater CoS\")\n\ntable = run_method(X, DIEC, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater DIEC\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Petrignano Overview\nThis aquifer has two targets, each modeled with random forests. Each model was fit with 20 random train/test splits of the original data to achieve the following statistics.\n\n#### Random Forests \n|             Target           |       MAE      |       RMSE     | $R^2$       |\n|:----------------------------:|:--------------:|:--------------:|:-----------:|\n| **Depth to Groundwater P24** | 1.761 ± 0.0954 | 2.357 ± 0.1257 | 0.40 ± 0.07 |\n| **Depth to Groundwater P25** | 1.738 ± 0.0730 | 2.345 ± 0.0777 | 0.37 ± 0.07 |\n\n#### Procedure\nThis procedure simply involved removing all rows with missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"pet = pd.read_csv('../input/acea-water-prediction/Aquifer_Petrignano.csv')\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', pet.shape[0], '\\n',\n      35*'=')\npet.isna().sum()/(pet.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(8,5))\nsns.heatmap(pet.isnull(), cbar=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = pet.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There's plenty of data here that we can simply remove any of the few rows with missing data."},{"metadata":{"trusted":true},"cell_type":"code","source":"pet['Mean_Temperature'] = pet.loc[:,'Temperature_Bastia_Umbra':'Temperature_Petrignano'].mean(axis=1)\n\ncols = ['Date','Rainfall_Bastia_Umbra','Mean_Temperature','Volume_C10_Petrignano',\n        'Hydrometry_Fiume_Chiascio_Petrignano','Depth_to_Groundwater_P24','Depth_to_Groundwater_P25']\n\npet = pet[cols]\n\npet.dropna(inplace=True)\n\nprint('\\t% Null Values by Column','\\n',\n      '\\tDataFrame Size:', pet.shape[0], '\\n',\n      35*'=')\npet.isna().sum()/(pet.shape[0]) *100","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr = pet.corr()\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\n\nwith sns.axes_style(\"white\"):\n    fig,ax = plt.subplots(figsize=(12,10))\n    ax = sns.heatmap(corr, mask=mask, annot=True, vmin=-1, vmax=1, cmap='viridis')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## Petrignano Visualization"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data=pet,\n             x_vars=[\n                 'Rainfall_Bastia_Umbra','Mean_Temperature','Volume_C10_Petrignano',\n                 'Hydrometry_Fiume_Chiascio_Petrignano'\n             ],\n            y_vars=[\n                'Depth_to_Groundwater_P24','Depth_to_Groundwater_P25'\n            ])\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n\n## Modeling Petrignano\n### Random Forest"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pet.drop(['Date','Depth_to_Groundwater_P24','Depth_to_Groundwater_P25'],axis=1)\np24 = pet['Depth_to_Groundwater_P24']\np25 = pet['Depth_to_Groundwater_P25']\n\nX_p24_train, X_p24_test, p24_train, p24_test = train_test_split(X, p24, test_size=0.2)\nX_p25_train, X_p25_test, p25_train, p25_test = train_test_split(X, p25, test_size=0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p24_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=15)\np25_model = RandomForestRegressor(n_estimators=200, max_features='sqrt', min_samples_split=15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"p24_model.fit(X_p24_train,p24_train)\np25_model.fit(X_p25_train,p25_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions1 = p24_model.predict(X_p24_test)\npredictions2 = p25_model.predict(X_p25_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Results\nfig = plt.figure(figsize=(4,3))\n\nax = fig.add_axes([0,0,1,1])\nax2 = fig.add_axes([1.2,0,1,1])\n\ncol1 = np.where(p24_test<predictions1,'indigo','peru')\ncol2 = np.where(p25_test<predictions2,'indigo','peru')\n\nax.scatter(x=p24_test, y=predictions1, c=col1)\nax.plot(p24_test,p24_test, color='r') # Line of accurate predictions\nax.set_xlabel('Depth to Groundwater P24')\nax.set_ylabel('Predicted Depth to Groundwater P24')\nax.set_title('Predicted and true values on the test set')\n\nax2.scatter(x=p25_test, y=predictions2, c=col2)\nax2.plot(p25_test,p25_test, color='r') # Line of accurate predictions\nax2.set_xlabel('Depth to Groundwater P25')\nax2.set_ylabel('Predicted Depth to Groundwater P25')\nax2.set_title('Predicted and true values on the test set')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluation\nprint(\"Depth to Groundwater P24\\n\")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p24_test,predictions1)),\n     \"\\tR^2:\\t\", metrics.r2_score(p24_test,predictions1))\n\nprint(65*\"=\",\"\\nDepth to Groundwater P25\\n \")\nprint(\"RMSE:\\t\", np.sqrt(metrics.mean_squared_error(p25_test,predictions2)),\n     \"\\tR^2:\\t\", metrics.r2_score(p25_test,predictions2))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---\n\n## MAE, RMSE, and $R^2$"},{"metadata":{"trusted":true},"cell_type":"code","source":"table = run_method(X, p24, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater P24\")\n\ntable = run_method(X, p25, n=20,\n                   method=RandomForestRegressor,n_estimators=500, max_features='sqrt')\nprint_method_results(\"Depth to Groundwater P25\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}