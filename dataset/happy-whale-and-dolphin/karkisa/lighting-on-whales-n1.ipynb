{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import party!!","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torchvision\nimport matplotlib.pyplot as plt\nfrom glob import glob\nimport torchvision.transforms.functional as F\nfrom torchvision.utils import draw_bounding_boxes\nimport pytorch_lightning as pl\nfrom torch.utils.data import Dataset , DataLoader\nfrom sklearn.model_selection import train_test_split","metadata":{"_uuid":"969722e7-8be1-4465-abb4-e35ba27538cb","_cell_guid":"55c51f07-2a54-483c-8a3f-624aab1002b0","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2022-03-24T05:15:48.916152Z","iopub.execute_input":"2022-03-24T05:15:48.916451Z","iopub.status.idle":"2022-03-24T05:15:48.922447Z","shell.execute_reply.started":"2022-03-24T05:15:48.916418Z","shell.execute_reply":"2022-03-24T05:15:48.921487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Simple and basic file visualisation","metadata":{}},{"cell_type":"code","source":"def read_img(path):\n    img= torchvision.io.read_image(path)\n    return img\n\n\ndef plot(df,r=8,c=8,figsize=(20,20),train_files=True):\n    \n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    \n    for n, ax in enumerate(axs):\n        \n        img= read_img(df.image[n])\n        \n        if train_files:\n            label=df.species[n] \n            ax.set_title(label)\n        \n        ax.imshow(F.to_pil_image(img))\n        ax.axis('off')\n        \n    plt.show()\n    plt.tight_layout()\n    \n    \ndef display_(path,base_folder_path):\n    df=pd.read_csv(path)\n    df.image=base_folder_path+'/'+df.image\n    display(df)\n    print(df.info())\n    for col in df.columns:\n        print(col ,'         ' , df[col].nunique())\n    \n        \n    return df\n\n    \n    \ndef main():\n    train_folder_path='../input/happy-whale-and-dolphin/train_images'\n    test_folder_path='../input/happy-whale-and-dolphin/test_images'\n\n    train_df_path='../input/happy-whale-and-dolphin/train.csv'\n    submission_df_path='../input/happy-whale-and-dolphin/sample_submission.csv'\n    \n    print('training files ')\n    train_df=display_(train_df_path,train_folder_path)\n    plot(train_df)\n    \n    print('test files ')\n    submission_df=display_(submission_df_path,test_folder_path)\n    plot(submission_df,train_files=False)\n    \n    \n    \nmain()","metadata":{"execution":{"iopub.status.busy":"2022-03-24T05:09:51.74071Z","iopub.execute_input":"2022-03-24T05:09:51.741009Z","iopub.status.idle":"2022-03-24T05:10:38.93563Z","shell.execute_reply.started":"2022-03-24T05:09:51.740962Z","shell.execute_reply":"2022-03-24T05:10:38.934679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Pipeline ","metadata":{}},{"cell_type":"code","source":"class pipeline_basic(Dataset):\n    \n    def __init__(self,df):\n        self.df=df\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def read_img(self,path):\n        \n        img= torchvision.io.read_image(path)\n        img=img/255.0\n        \n        return img\n        \n    def __getitem__(self,idx):\n        \n        x=self.read_img(self.df.image[idx])\n        y=self.df.species[idx]\n        \n        return x,y\n\n    \nclass PL_dataset(pl.LightningDataModule):\n    \n    def __init__(\n                    self,\n                    df,\n                    test_df,\n                    Dataset,\n                    batch_size=32,\n                    num_workers=1\n                ):\n        self.Dataset=Dataset\n        self.df=df\n        self.test_df=test_df\n        self.batch_size=batch_size\n        self.num_workers=num_workers\n        \n    def setup(self):\n        \n        self.train_df,self.val_df=train_test_split(self.df)    \n        \n    def training_dataloader(self):\n        \n        return Dataloader(Dataset(self.train_df),batch_size=self.batch_size)\n    \n    def validation_dataloader(self):\n        \n        return Dataloader(Dataset(self.val_df),batch_size=self.batch_size)\n    \n    def test_dataloader(self):\n        \n        return Dataloader(Dataset(self.test_df),batch_size=self.batch_size)\n\n        \ndef display_(path,base_folder_path):\n    df=pd.read_csv(path)\n    df.image=base_folder_path+'/'+df.image\n    return df\n\n\ndef plot_pipeline(dataset,r=8,c=8,figsize=(20,20)):\n    \n    _,axs=plt.subplots(r,c,figsize=figsize)\n    axs=axs.flatten()\n    \n    for n, ax in enumerate(axs):\n        \n        img,label= dataset[n]\n        ax.set_title(label)\n        ax.imshow(F.to_pil_image(img))\n        ax.axis('off')\n        \n    plt.show()\n    plt.tight_layout()\n\ndef main():\n    \n    train_folder_path='../input/happy-whale-and-dolphin/train_images'\n    test_folder_path='../input/happy-whale-and-dolphin/test_images'\n\n    train_df_path='../input/happy-whale-and-dolphin/train.csv'\n    submission_df_path='../input/happy-whale-and-dolphin/sample_submission.csv'\n    \n    train_df=display_(train_df_path,train_folder_path)\n    \n    submission_df=display_(submission_df_path,test_folder_path)\n    \n    print('testing basic pipeline')\n    Da=pipeline_basic(train_df)\n    plot_pipeline(Da)\n    \n\n    \nmain()    ","metadata":{"execution":{"iopub.status.busy":"2022-03-24T06:41:01.497271Z","iopub.execute_input":"2022-03-24T06:41:01.497592Z","iopub.status.idle":"2022-03-24T06:41:32.124133Z","shell.execute_reply.started":"2022-03-24T06:41:01.497561Z","shell.execute_reply":"2022-03-24T06:41:32.123303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# good scope to improve with different type of heads, backbones , 2 optimizer method etc.\n# basic model\nclass Model(pl.LightningModule):\n    def __init__(\n                 self,\n                 model,\n#                  img_size,\n    ):\n        super().__init__()\n        self.base_model=model()\n        self.linear_head=torch.nn.Linear(in_features=1000,out_features=30)\n        self.relu=torch.nn.Softmax(dim=1)\n        \n        \n    def forward(self,x):\n        out=self.base_model(x)\n        out=self.linear_head(out)\n        out=self.relu(out)\n        \n        return out\n    \n\n# testing if model works. Easy pisy unit test\ndef main():\n    \n    train_folder_path='../input/happy-whale-and-dolphin/train_images'\n    test_folder_path='../input/happy-whale-and-dolphin/test_images'\n\n    train_df_path='../input/happy-whale-and-dolphin/train.csv'\n    submission_df_path='../input/happy-whale-and-dolphin/sample_submission.csv'\n    \n    train_df=display_(train_df_path,train_folder_path)\n    \n    submission_df=display_(submission_df_path,test_folder_path)\n    \n    Da=pipeline_basic(train_df)\n    model=Model(torchvision.models.resnet18)\n    img,label=Da[3]\n    preds=model(img[None,:])                          # model demands 4 D tensor (B,C,H,W)\n    print(len(preds[0]),preds)\n    \n\n    \nmain()    \n        \n        ","metadata":{"execution":{"iopub.status.busy":"2022-03-24T07:08:20.82356Z","iopub.execute_input":"2022-03-24T07:08:20.824252Z","iopub.status.idle":"2022-03-24T07:08:29.498286Z","shell.execute_reply.started":"2022-03-24T07:08:20.824208Z","shell.execute_reply":"2022-03-24T07:08:29.49715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}