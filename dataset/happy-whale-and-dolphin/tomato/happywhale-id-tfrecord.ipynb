{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Happywhale - Whale and Dolphin Identification](https://www.kaggle.com/c/happy-whale-and-dolphin/overview)\n## Identify whales and dolphins by unique characteristics\n\n<img src=\"https://storage.googleapis.com/kaggle-competitions/kaggle/22962/logos/header.png?t=2021-03-17-22-44-0\">","metadata":{}},{"cell_type":"markdown","source":"If you like this work, please upvote!\n\nPlease also this!\n\n[Happywhale - üêã & üê¨ ID [EDA] | Kaggle](https://www.kaggle.com/tomato0813/happywhale-identification-eda)\n\n[Happywhale - üêã & üê¨ ID [TensorFlow Tutorial] | Kaggle](https://www.kaggle.com/tomato0813/happywhale-id-tensorflow-tutorial)\n\n## References for this notebook:\n\n### Code\n[1] [HappyWhale TFRecords | Kaggle](https://www.kaggle.com/ks2019/happywhale-tfrecords/data)\n\n### Discussions\nNone\n\nPlease Upvote these work too!\n\n### Others\n[TFRecord and tf.train.Example &nbsp;|&nbsp; TensorFlow Core](https://www.tensorflow.org/tutorials/load_data/tfrecord#write_the_tfrecord_file)\n\nThanks guys!","metadata":{}},{"cell_type":"code","source":"import os\nimport json\nfrom tqdm import tqdm\nimport pandas as pd\nfrom sklearn.model_selection import KFold\nimport tensorflow as tf\nimport IPython.display as display","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-05T11:37:58.798461Z","iopub.execute_input":"2022-02-05T11:37:58.79944Z","iopub.status.idle":"2022-02-05T11:37:58.803958Z","shell.execute_reply.started":"2022-02-05T11:37:58.799388Z","shell.execute_reply":"2022-02-05T11:37:58.80326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DATASET_NAME = f'happywhale-tfrecords-5743-v0'\nFOLD = 1\nN_FOLD = 5\n\n\ntrain_filenams = [f'/tmp/{DATASET_NAME}/happywhale-train-{fold}.tfrecord' for fold in range(N_FOLD)]\ntest_filenames = [f'/tmp/{DATASET_NAME}/happywhale-test-{fold}.tfrecord' for fold in range(N_FOLD)]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:35:51.762818Z","iopub.execute_input":"2022-02-05T11:35:51.763014Z","iopub.status.idle":"2022-02-05T11:35:51.772175Z","shell.execute_reply.started":"2022-02-05T11:35:51.76299Z","shell.execute_reply":"2022-02-05T11:35:51.771284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_filenams","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_filenames","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r /tmp/{DATASET_NAME}\n\nos.makedirs(f'/tmp/{DATASET_NAME}', exist_ok=True)\n\nwith open('../input/kaggle-api-creds/kaggle.json') as f:\n    kaggle_creds = json.load(f)\n    \nos.environ['KAGGLE_USERNAME'] = kaggle_creds['username']\nos.environ['KAGGLE_KEY'] = kaggle_creds['key']\n\n!kaggle datasets init -p /tmp/{DATASET_NAME}\n\n\nwith open(f'/tmp/{DATASET_NAME}/dataset-metadata.json') as f:\n    dataset_meta = json.load(f)\ndataset_meta['id'] = f'tomato0813/{DATASET_NAME}'\ndataset_meta['title'] = DATASET_NAME\nwith open(f'/tmp/{DATASET_NAME}/dataset-metadata.json', \"w\") as outfile:\n    json.dump(dataset_meta, outfile)\nprint(dataset_meta)\n\n!ls /tmp/{DATASET_NAME}\n\n!kaggle datasets create -u -p /tmp/{DATASET_NAME} ","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:36:53.318106Z","iopub.execute_input":"2022-02-05T11:36:53.318823Z","iopub.status.idle":"2022-02-05T11:36:57.406788Z","shell.execute_reply.started":"2022-02-05T11:36:53.318766Z","shell.execute_reply":"2022-02-05T11:36:57.40567Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:12.615906Z","iopub.execute_input":"2022-02-05T11:37:12.616298Z","iopub.status.idle":"2022-02-05T11:37:12.746767Z","shell.execute_reply.started":"2022-02-05T11:37:12.616252Z","shell.execute_reply":"2022-02-05T11:37:12.745853Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['image_path'] = ['../input/happy-whale-and-dolphin/train_images/' + img for img in train_df['image']]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:14.39102Z","iopub.execute_input":"2022-02-05T11:37:14.391881Z","iopub.status.idle":"2022-02-05T11:37:14.427199Z","shell.execute_reply.started":"2022-02-05T11:37:14.391818Z","shell.execute_reply":"2022-02-05T11:37:14.426298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"id_to_label = dict((i_id, index) for index, i_id in enumerate(train_df['individual_id'].unique()))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:16.220834Z","iopub.execute_input":"2022-02-05T11:37:16.221917Z","iopub.status.idle":"2022-02-05T11:37:16.240059Z","shell.execute_reply.started":"2022-02-05T11:37:16.221863Z","shell.execute_reply":"2022-02-05T11:37:16.238694Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = [id_to_label[i_id] for i_id in train_df['individual_id']]\nlabels[:20]","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:17.733189Z","iopub.execute_input":"2022-02-05T11:37:17.734086Z","iopub.status.idle":"2022-02-05T11:37:17.758824Z","shell.execute_reply.started":"2022-02-05T11:37:17.734037Z","shell.execute_reply":"2022-02-05T11:37:17.757987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['label'] = labels\ntrain_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:19.311646Z","iopub.execute_input":"2022-02-05T11:37:19.311979Z","iopub.status.idle":"2022-02-05T11:37:19.34254Z","shell.execute_reply.started":"2022-02-05T11:37:19.311944Z","shell.execute_reply":"2022-02-05T11:37:19.341619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['fold'] = None\n\nkf = KFold(n_splits=N_FOLD)\nfor i, (train_index, test_index) in enumerate(kf.split(train_df)):\n    train_df['fold'].iloc[test_index] = i\n\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:21.716151Z","iopub.execute_input":"2022-02-05T11:37:21.716526Z","iopub.status.idle":"2022-02-05T11:37:21.74414Z","shell.execute_reply.started":"2022-02-05T11:37:21.716486Z","shell.execute_reply":"2022-02-05T11:37:21.74328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# The following functions can be used to convert a value to a type compatible\n# with tf.train.Example.\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:27.15812Z","iopub.execute_input":"2022-02-05T11:37:27.158938Z","iopub.status.idle":"2022-02-05T11:37:27.167744Z","shell.execute_reply.started":"2022-02-05T11:37:27.158887Z","shell.execute_reply":"2022-02-05T11:37:27.166577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def image_example(image_string, label):\n    \"\"\"\n    Creates a tf.train.Example message ready to be written to a file.\n    \"\"\"\n    # Create a dictionary mapping the feature name to the tf.train.Example-compatible\n    # data type.\n    feature = {\n        'image_raw': _bytes_feature(image_string),\n        'label': _int64_feature(label),\n    }\n\n    # Create a Features message using tf.train.Example.\n    return tf.train.Example(features=tf.train.Features(feature=feature))","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:29.019174Z","iopub.execute_input":"2022-02-05T11:37:29.019551Z","iopub.status.idle":"2022-02-05T11:37:29.025427Z","shell.execute_reply.started":"2022-02-05T11:37:29.019511Z","shell.execute_reply":"2022-02-05T11:37:29.024367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_train_tf_record(fold):\n    record_file = train_filenams[fold]\n    df = train_df[train_df.fold == fold]\n    with tf.io.TFRecordWriter(record_file) as writer:\n        for i, row in df.iterrows():\n            image_string = tf.io.read_file(row.image_path)\n            label = row.label\n            tf_example = image_example(image_string, label)\n            writer.write(tf_example.SerializeToString())","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:37:30.793227Z","iopub.execute_input":"2022-02-05T11:37:30.793616Z","iopub.status.idle":"2022-02-05T11:37:30.799812Z","shell.execute_reply.started":"2022-02-05T11:37:30.793579Z","shell.execute_reply":"2022-02-05T11:37:30.798791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\n_ = joblib.Parallel(n_jobs=8)(\n        joblib.delayed(create_train_tf_record)(fold) for fold in tqdm(range(N_FOLD))\n    )","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:38:37.656173Z","iopub.execute_input":"2022-02-05T11:38:37.65658Z","iopub.status.idle":"2022-02-05T11:48:19.623196Z","shell.execute_reply.started":"2022-02-05T11:38:37.656543Z","shell.execute_reply":"2022-02-05T11:48:19.621498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/happy-whale-and-dolphin/sample_submission.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:48:19.628809Z","iopub.execute_input":"2022-02-05T11:48:19.632595Z","iopub.status.idle":"2022-02-05T11:48:19.733256Z","shell.execute_reply.started":"2022-02-05T11:48:19.632537Z","shell.execute_reply":"2022-02-05T11:48:19.732524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['image_path'] = ['../input/happy-whale-and-dolphin/test_images/' + img for img in test_df['image']]\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:48:19.73419Z","iopub.execute_input":"2022-02-05T11:48:19.734884Z","iopub.status.idle":"2022-02-05T11:48:33.549017Z","shell.execute_reply.started":"2022-02-05T11:48:19.734848Z","shell.execute_reply":"2022-02-05T11:48:33.54814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df['fold'] = None\n\nkf = KFold(n_splits=N_FOLD)\nfor i, (train_index, test_index) in enumerate(kf.split(test_df)):\n    test_df['fold'].iloc[test_index] = i\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:48:33.551352Z","iopub.execute_input":"2022-02-05T11:48:33.551623Z","iopub.status.idle":"2022-02-05T11:48:33.837009Z","shell.execute_reply.started":"2022-02-05T11:48:33.551591Z","shell.execute_reply":"2022-02-05T11:48:33.836196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_test_tf_record(fold):\n    record_file = test_filenames[fold]\n    df = test_df[test_df.fold == fold]\n    with tf.io.TFRecordWriter(record_file) as writer:\n        for i, row in df.iterrows():\n            image_string = tf.io.read_file(row.image_path)\n            label = -1\n            tf_example = image_example(image_string, label)\n            writer.write(tf_example.SerializeToString())","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:48:33.838498Z","iopub.execute_input":"2022-02-05T11:48:33.838793Z","iopub.status.idle":"2022-02-05T11:48:34.208652Z","shell.execute_reply.started":"2022-02-05T11:48:33.838755Z","shell.execute_reply":"2022-02-05T11:48:34.207775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\n_ = joblib.Parallel(n_jobs=8)(\n        joblib.delayed(create_test_tf_record)(fold) for fold in tqdm(range(N_FOLD))\n    )","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:48:34.213373Z","iopub.execute_input":"2022-02-05T11:48:34.213745Z","iopub.status.idle":"2022-02-05T11:54:01.494816Z","shell.execute_reply.started":"2022-02-05T11:48:34.213691Z","shell.execute_reply":"2022-02-05T11:54:01.493453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from datetime import datetime\nversion_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\nprint(version_name)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:54:01.49853Z","iopub.execute_input":"2022-02-05T11:54:01.49891Z","iopub.status.idle":"2022-02-05T11:54:01.50748Z","shell.execute_reply.started":"2022-02-05T11:54:01.498868Z","shell.execute_reply":"2022-02-05T11:54:01.50647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!kaggle datasets version -m {version_name} -p /tmp/{DATASET_NAME} -r zip -q","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:54:01.509237Z","iopub.execute_input":"2022-02-05T11:54:01.510369Z","iopub.status.idle":"2022-02-05T12:10:32.148392Z","shell.execute_reply.started":"2022-02-05T11:54:01.510312Z","shell.execute_reply":"2022-02-05T12:10:32.146846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"raw_image_dataset = tf.data.TFRecordDataset(test_filenames[FOLD])\nraw_image_dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:30:12.457322Z","iopub.status.idle":"2022-02-05T11:30:12.457762Z","shell.execute_reply.started":"2022-02-05T11:30:12.457523Z","shell.execute_reply":"2022-02-05T11:30:12.457546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a description of the features.\nimage_feature_description = {\n    'image_raw': tf.io.FixedLenFeature([], tf.string),\n    'label': tf.io.FixedLenFeature([], tf.int64),\n}\n\ndef _parse_image_function(example_proto):\n    # Parse the input `tf.train.Example` proto using the dictionary above.\n    return tf.io.parse_single_example(example_proto, image_feature_description)","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:30:12.459436Z","iopub.status.idle":"2022-02-05T11:30:12.460616Z","shell.execute_reply.started":"2022-02-05T11:30:12.460346Z","shell.execute_reply":"2022-02-05T11:30:12.460374Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\nparsed_image_dataset","metadata":{"execution":{"iopub.status.busy":"2022-02-05T11:30:12.461663Z","iopub.status.idle":"2022-02-05T11:30:12.46253Z","shell.execute_reply.started":"2022-02-05T11:30:12.462268Z","shell.execute_reply":"2022-02-05T11:30:12.462295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}