{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Use this notebook to finetune a ConvNeXt-tiny model on this competition dataset. The [official ConvNeXt repository](https://github.com/facebookresearch/ConvNeXt) is instrumented with [Weights and Biases](https://wandb.ai/site). You can now easily log your train/test metrics and version control your model checkpoints to Weigths and Biases.\n\n**The trained model checkpoint can be used to extract image embeddings.** ","metadata":{"id":"LniKjqdogsrH"}},{"cell_type":"markdown","source":"# ‚öΩÔ∏è Installation and Setup\n\nThe following installation instruction is based on [INSTALL.md](https://github.com/facebookresearch/ConvNeXt/blob/main/INSTALL.md) provided by the official ConvNeXt repository. ","metadata":{"id":"1JS4ffXFRnRr"}},{"cell_type":"code","source":"!pip install -qq torch==1.8.0+cu111 torchvision==0.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n!pip install -qq --upgrade wandb timm==0.3.2 six tensorboardX","metadata":{"id":"5YbEGpKrDKC5","execution":{"iopub.status.busy":"2022-02-02T10:24:16.261671Z","iopub.execute_input":"2022-02-02T10:24:16.262038Z","iopub.status.idle":"2022-02-02T10:28:11.000484Z","shell.execute_reply.started":"2022-02-02T10:24:16.261946Z","shell.execute_reply":"2022-02-02T10:28:10.999339Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Download the official ConvNeXt respository. ","metadata":{"id":"kDXQ-EpX9fsB"}},{"cell_type":"code","source":"!git clone https://github.com/facebookresearch/ConvNeXt","metadata":{"id":"zmmHO1Cp4E90","execution":{"iopub.status.busy":"2022-02-02T10:29:48.88706Z","iopub.execute_input":"2022-02-02T10:29:48.887413Z","iopub.status.idle":"2022-02-02T10:29:50.730074Z","shell.execute_reply.started":"2022-02-02T10:29:48.887341Z","shell.execute_reply":"2022-02-02T10:29:50.72887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Install Weights and Biases for experiment tracking. ","metadata":{}},{"cell_type":"code","source":"import wandb\n\ntry:\n    from kaggle_secrets import UserSecretsClient\n    user_secrets = UserSecretsClient()\n    secret_value_0 = user_secrets.get_secret(\"WANDB_KEY\")\n    wandb.login(key=secret_value_0)\nexcept:\n    print('To use your W&B account, go to Add-ons -> Secrets and provide your W&B access token. Use the Label name as wandb_api. \\nGet your W&B access token from here: https://wandb.ai/authorize')","metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:42:00.787708Z","iopub.execute_input":"2022-02-02T10:42:00.78804Z","iopub.status.idle":"2022-02-02T10:42:11.946815Z","shell.execute_reply.started":"2022-02-02T10:42:00.788004Z","shell.execute_reply":"2022-02-02T10:42:11.945653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üèÄ Download the Dataset\n\nTo finetune on any custom dataset the format of the dataset should be as shown below:\n\n```\n/path/to/dataset/\n  train/\n    class1/\n      img1.jpeg\n    class2/\n      img2.jpeg\n  val/\n    class1/\n      img3.jpeg\n    class2/\n      img4.jpeg\n```\n\nI have created the dataset for you all: https://www.kaggle.com/ayuraj/happywhale-train-by-class","metadata":{"id":"yoVwkQ0v80KW"}},{"cell_type":"code","source":"path_to_dataset = '../../input/happywhale-train-by-class/train_images_by_class'","metadata":{"execution":{"iopub.status.busy":"2022-02-02T10:32:42.581481Z","iopub.execute_input":"2022-02-02T10:32:42.581962Z","iopub.status.idle":"2022-02-02T10:32:42.587626Z","shell.execute_reply.started":"2022-02-02T10:32:42.58191Z","shell.execute_reply":"2022-02-02T10:32:42.586575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> Note: We ain't using any validation set in this example. We will thus finetune only for 10 epochs. You can use this notebook and train with a validation set as well.","metadata":{}},{"cell_type":"markdown","source":"# üèà Download Pretrained Weights\n\nWe will be finetuning the ConvNeXt Tiny model pretrained on ImageNet 1K dataset.","metadata":{"id":"J6qUVfL29tH1"}},{"cell_type":"code","source":"%cd ConvNeXt/\n!wget https://dl.fbaipublicfiles.com/convnext/convnext_tiny_1k_224_ema.pth","metadata":{"id":"TYPDl5bT8LZ5","execution":{"iopub.status.busy":"2022-02-02T10:29:58.789055Z","iopub.execute_input":"2022-02-02T10:29:58.78984Z","iopub.status.idle":"2022-02-02T10:30:06.711279Z","shell.execute_reply.started":"2022-02-02T10:29:58.789762Z","shell.execute_reply":"2022-02-02T10:30:06.710337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üéæ Train with Weights and Biases\n\nIf you want to log the train and evaluation metrics using Weights and Biases pass `--enable_wandb true`. \n\nYou can also save the finetuned checkpoints as version controlled W&B [Artifacts](https://docs.wandb.ai/guides/artifacts) if you pass `--wandb_ckpt true`.\n\nIf you want to pass a directory of validation images use the argument `--eval_data_path`. \n","metadata":{"id":"pSPgPCjp-Lro"}},{"cell_type":"code","source":"!python main.py --epochs 10 \\\n                --model convnext_tiny \\\n                --data_set image_folder \\\n                --data_path ../../input/happywhale-train-by-class/train_images_by_class/ \\\n                --disable_eval true \\\n                --nb_classes 30 \\\n                --num_workers 8 \\\n                --warmup_epochs 0 \\\n                --save_ckpt true \\\n                --output_dir model_ckpt \\\n                --finetune convnext_tiny_1k_224_ema.pth \\\n                --cutmix 0 \\\n                --mixup 0 --lr 4e-4 \\\n                --enable_wandb true --wandb_ckpt true --project happywhale_convnext","metadata":{"id":"_8sNl2Mb6x8_","execution":{"iopub.status.busy":"2022-02-02T10:48:40.509352Z","iopub.execute_input":"2022-02-02T10:48:40.510772Z","iopub.status.idle":"2022-02-02T10:48:40.517106Z","shell.execute_reply.started":"2022-02-02T10:48:40.510708Z","shell.execute_reply":"2022-02-02T10:48:40.516166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# üèê Conclusion\n\n* The ConvNeXt repository comes with modern training regimes and is easy to finetune on any dataset. \n* The finetune model should learn good image features.. \n\nI have also created this [colab notebook](https://colab.research.google.com/drive/1ijAxGthE9RENJJQRO17v9A7PTd1Tei9F?usp=sharing) to finetune on CIFAR-10 dataset.","metadata":{"id":"350MmZgtBVWy"}}]}