{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Hi Kagglers !","metadata":{}},{"cell_type":"markdown","source":"Original notebook : https://www.kaggle.com/code/seabutterfly95/ensemble-of-public-and-beluga-fullbody","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"Here is a simple ensemble method for submissions.\nThis idea can be easily referenced from previous competitions\n\nIf you think this kernel is good, please upvote the following people who provided the original kernel instead.\n\n*  https://www.kaggle.com/aikhmelnytskyy/happywhale-arcface-baseline-eff7-tpu-768-inference\n\n* https://www.kaggle.com/code/nghiahoangtrung/swin-tranform-submission/notebook#Configuration\n\n* https://www.kaggle.com/code/gtownfoster/effv2-l-backfin-embeddings-ensemble\n\n\nI added my own result training (best82) on fullbody annotation dataset with beluga only\nand was able to achieve significant lb boost. \n\nI use the pytorch notebook by clemchris to train my model with some adjustment such as fine\ntuning the margin \n\n\nhttps://www.kaggle.com/code/clemchris/pytorch-backfin-convnext-arcface","metadata":{}},{"cell_type":"code","source":"import csv\nimport pandas as pd \n\nsub_files = [\n                 '../input/effv2-l-backfin-embeddings-ensemble/submission.csv',\n                 '../input/swin-tranform-submission/submission.csv',\n                 '../input/happywhale-arcface-baseline-eff7-tpu-768-inference/submission.csv',\n                '../input/best82/submission.csv'\n]\n\n# Weights of the individual subs\nsub_weight = [\n                0.768**2.4,\n                0.830**2.3,\n                0.650**6,\n                0.650**1.2,\n    \n            ]\n","metadata":{"execution":{"iopub.status.busy":"2022-04-16T06:48:36.453074Z","iopub.execute_input":"2022-04-16T06:48:36.455168Z","iopub.status.idle":"2022-04-16T06:48:36.485634Z","shell.execute_reply.started":"2022-04-16T06:48:36.455037Z","shell.execute_reply":"2022-04-16T06:48:36.48475Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Hlabel = 'image' \nHtarget = 'predictions'\nnpt = 6\nplace_weights = {}\nfor i in range(npt):\n    place_weights[i] = (1 / (i + 1))\n\nprint(place_weights)\n\nlg = len(sub_files)\nsub = [None]*lg\nfor i, file in enumerate( sub_files ):   \n    print(\"Reading {}: w={} - {}\". format(i, sub_weight[i], file))\n    reader = csv.DictReader(open(file,\"r\"))\n    sub[i] = sorted(reader, key=lambda d: str(d[Hlabel]))\n\nout = open(\"submission.csv\", \"w\", newline='')\nwriter = csv.writer(out)\nwriter.writerow([Hlabel,Htarget])\n\nfor p, row in enumerate(sub[0]):\n    target_weight = {}\n    for s in range(lg):\n        row1 = sub[s][p]\n        for ind, trgt in enumerate(row1[Htarget].split(' ')):\n            target_weight[trgt] = target_weight.get(trgt,0) + (place_weights[ind]*sub_weight[s])\n    tops_trgt = sorted(target_weight, key=target_weight.get, reverse=True)[:npt]\n    writer.writerow([row1[Hlabel], \" \".join(tops_trgt)])\nout.close()","metadata":{"execution":{"iopub.status.busy":"2022-04-16T06:48:36.513495Z","iopub.execute_input":"2022-04-16T06:48:36.514132Z","iopub.status.idle":"2022-04-16T06:48:39.202839Z","shell.execute_reply.started":"2022-04-16T06:48:36.514084Z","shell.execute_reply":"2022-04-16T06:48:39.201678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<center>\n    <h1 style='color: #f13658'> Thanks for reading üëç <h1>","metadata":{}}]}