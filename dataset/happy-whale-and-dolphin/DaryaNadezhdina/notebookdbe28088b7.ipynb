{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install timm faiss-gpu","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:36.669407Z","iopub.execute_input":"2022-05-22T15:59:36.66972Z","iopub.status.idle":"2022-05-22T15:59:51.032412Z","shell.execute_reply.started":"2022-05-22T15:59:36.669642Z","shell.execute_reply":"2022-05-22T15:59:51.03147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nfrom typing import Callable\nfrom typing import Dict\nfrom typing import Optional\nfrom typing import Tuple\nfrom pathlib import Path\n\nimport faiss\nimport numpy as np\nimport pandas as pd\nimport pytorch_lightning as pl\nimport timm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchmetrics\nfrom PIL import Image\nfrom timm.data.transforms_factory import create_transform\nfrom timm.optim import create_optimizer_v2\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import normalize\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:51.034432Z","iopub.execute_input":"2022-05-22T15:59:51.035513Z","iopub.status.idle":"2022-05-22T15:59:55.991982Z","shell.execute_reply.started":"2022-05-22T15:59:51.035478Z","shell.execute_reply":"2022-05-22T15:59:55.99122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INPUT_DIR = Path(\"..\") / \"input\"\nOUTPUT_DIR = Path(\"/\") / \"kaggle\" / \"working\"\n\nDATA_ROOT_DIR = INPUT_DIR / \"happy-whale-and-dolphin\"\nCROPPED_DATA_ROOT_DIR = INPUT_DIR / \"whale2-cropped-dataset\"\n\nTRAIN_DIR = CROPPED_DATA_ROOT_DIR / \"cropped_train_images\" / \"cropped_train_images\"\nTEST_DIR = CROPPED_DATA_ROOT_DIR / \"cropped_test_images\" / \"cropped_test_images\"\nTRAIN_CSV_PATH = DATA_ROOT_DIR / \"train.csv\"\nSAMPLE_SUBMISSION_CSV_PATH = DATA_ROOT_DIR / \"sample_submission.csv\"\n\nN_SPLITS = 5\n\nENCODER_CLASSES_PATH = OUTPUT_DIR / \"encoder_classes.npy\"\nTEST_CSV_PATH = OUTPUT_DIR / \"test.csv\"\nTRAIN_CSV_ENCODED_FOLDED_PATH = OUTPUT_DIR / \"train_encoded_folded.csv\"\nSUBMISSION_CSV_PATH = OUTPUT_DIR / \"submission.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:55.993372Z","iopub.execute_input":"2022-05-22T15:59:55.993849Z","iopub.status.idle":"2022-05-22T15:59:56.000808Z","shell.execute_reply.started":"2022-05-22T15:59:55.993814Z","shell.execute_reply":"2022-05-22T15:59:55.999736Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_image_path(id: str, dir: Path) -> str:\n    return f\"{dir / id}\"","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:56.002111Z","iopub.execute_input":"2022-05-22T15:59:56.002649Z","iopub.status.idle":"2022-05-22T15:59:56.012488Z","shell.execute_reply.started":"2022-05-22T15:59:56.00261Z","shell.execute_reply":"2022-05-22T15:59:56.0118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(TRAIN_CSV_PATH)\n\n# Fix all known species column problems\n# From https://www.kaggle.com/c/happy-whale-and-dolphin/discussion/305574\ntrain_df.species.replace(\n    {\n        \"globis\": \"short_finned_pilot_whale\",\n        \"pilot_whale\": \"short_finned_pilot_whale\",\n        \"kiler_whale\": \"killer_whale\",\n        \"bottlenose_dolpin\": \"bottlenose_dolphin\",\n    },\n    inplace=True,\n)\n\ntrain_df[\"image_path\"] = train_df[\"image\"].apply(get_image_path, dir=TRAIN_DIR)\n\nencoder = LabelEncoder()\ntrain_df[\"individual_id\"] = encoder.fit_transform(train_df[\"individual_id\"])\nnp.save(ENCODER_CLASSES_PATH, encoder.classes_)\n\nskf = StratifiedKFold(n_splits=N_SPLITS)\nfor fold, (_, val_) in enumerate(skf.split(X=train_df, y=train_df.individual_id)):\n    train_df.loc[val_, \"kfold\"] = fold\n    \ntrain_df.to_csv(TRAIN_CSV_ENCODED_FOLDED_PATH, index=False)\n    \ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:56.015122Z","iopub.execute_input":"2022-05-22T15:59:56.016063Z","iopub.status.idle":"2022-05-22T15:59:57.298711Z","shell.execute_reply.started":"2022-05-22T15:59:56.016024Z","shell.execute_reply":"2022-05-22T15:59:57.298055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(SAMPLE_SUBMISSION_CSV_PATH)\ntest_df[\"image_path\"] = test_df[\"image\"].apply(get_image_path, dir=TEST_DIR)\n\ntest_df.drop(columns=[\"predictions\"], inplace=True)\n\n# Dummy id\ntest_df[\"individual_id\"] = 0\n\ntest_df.to_csv(TEST_CSV_PATH, index=False)\n\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:57.299975Z","iopub.execute_input":"2022-05-22T15:59:57.300346Z","iopub.status.idle":"2022-05-22T15:59:57.684027Z","shell.execute_reply.started":"2022-05-22T15:59:57.300312Z","shell.execute_reply":"2022-05-22T15:59:57.683357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class HappyWhaleDataset(Dataset):\n    def __init__(self, df: pd.DataFrame, transform: Optional[Callable] = None):\n        self.df = df\n        self.transform = transform\n\n        self.image_names = self.df[\"image\"].values\n        self.image_paths = self.df[\"image_path\"].values\n        self.targets = self.df[\"individual_id\"].values\n\n    def __getitem__(self, index: int) -> Dict[str, torch.Tensor]:\n        image_name = self.image_names[index]\n\n        image_path = self.image_paths[index]\n\n        image = Image.open(image_path)\n        \n        if self.transform:\n            image = self.transform(image)\n\n        target = self.targets[index]\n        target = torch.tensor(target, dtype=torch.long)\n\n        return {\"image_name\": image_name, \"image\": image, \"target\": target}\n\n    def __len__(self) -> int:\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:57.6854Z","iopub.execute_input":"2022-05-22T15:59:57.685659Z","iopub.status.idle":"2022-05-22T15:59:57.695221Z","shell.execute_reply.started":"2022-05-22T15:59:57.685625Z","shell.execute_reply":"2022-05-22T15:59:57.694438Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitDataModule(pl.LightningDataModule):\n    def __init__(\n        self,\n        train_csv_encoded_folded: str,\n        test_csv: str,\n        val_fold: float = 0.0,\n        image_size: int = 256,\n        batch_size: int = 64,\n        num_workers: int = 2,\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.train_df = pd.read_csv(train_csv_encoded_folded)\n        self.test_df = pd.read_csv(test_csv)\n\n        self.transform = create_transform(\n            input_size=(self.hparams.image_size, self.hparams.image_size),\n            crop_pct=1.0,\n        )\n        \n    def setup(self, stage: Optional[str] = None):\n        if stage == \"fit\" or stage is None:\n            # Split train df using fold\n            train_df = self.train_df[self.train_df.kfold != self.hparams.val_fold].reset_index(drop=True)\n            val_df = self.train_df[self.train_df.kfold == self.hparams.val_fold].reset_index(drop=True)\n\n            self.train_dataset = HappyWhaleDataset(train_df, transform=self.transform)\n            self.val_dataset = HappyWhaleDataset(val_df, transform=self.transform)\n\n        if stage == \"test\" or stage is None:\n            self.test_dataset = HappyWhaleDataset(self.test_df, transform=self.transform)\n\n    def train_dataloader(self) -> DataLoader:\n        return self._dataloader(self.train_dataset, train=True)\n\n    def val_dataloader(self) -> DataLoader:\n        return self._dataloader(self.val_dataset)\n\n    def test_dataloader(self) -> DataLoader:\n        return self._dataloader(self.test_dataset)\n\n    def _dataloader(self, dataset: HappyWhaleDataset, train: bool = False) -> DataLoader:\n        return DataLoader(\n            dataset,\n            batch_size=self.hparams.batch_size,\n            shuffle=train,\n            num_workers=self.hparams.num_workers,\n            pin_memory=True,\n            drop_last=train,\n        )","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:57.69672Z","iopub.execute_input":"2022-05-22T15:59:57.696974Z","iopub.status.idle":"2022-05-22T15:59:57.710615Z","shell.execute_reply.started":"2022-05-22T15:59:57.696939Z","shell.execute_reply":"2022-05-22T15:59:57.709149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# From https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/blob/master/src/modeling/metric_learning.py # noqa E501\n# Added type annotations, device, and 16bit support\nclass ArcMarginProduct(nn.Module):\n    r\"\"\"Implement of large margin arc distance: :\n    Args:\n        in_features: size of each input sample\n        out_features: size of each output sample\n        s: norm of input feature\n        m: margin\n        cos(theta + m)\n    \"\"\"\n\n    def __init__(\n        self,\n        in_features: int,\n        out_features: int,\n        s: float = 30.0,\n        m: float = 0.50,\n        easy_margin: bool = False,\n        ls_eps: float = 0.0,\n    ):\n        super(ArcMarginProduct, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps  # label smoothing\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n        self.easy_margin = easy_margin\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = math.cos(math.pi - m)\n        self.mm = math.sin(math.pi - m) * m\n\n    def forward(self, input: torch.Tensor, label: torch.Tensor, device: str = \"cuda\") -> torch.Tensor:\n        # --------------------------- cos(theta) & phi(theta) ---------------------\n        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n        # Enable 16 bit precision\n        cosine = cosine.to(torch.float32)\n\n        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = torch.where(cosine > 0, phi, cosine)\n        else:\n            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n        # --------------------------- convert label to one-hot ---------------------\n        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n        one_hot = torch.zeros(cosine.size(), device=device)\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n        # -------------torch.where(out_i = {x_i if condition_i else y_i) ------------\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:57.712071Z","iopub.execute_input":"2022-05-22T15:59:57.713028Z","iopub.status.idle":"2022-05-22T15:59:57.728513Z","shell.execute_reply.started":"2022-05-22T15:59:57.71299Z","shell.execute_reply":"2022-05-22T15:59:57.727832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LitModule(pl.LightningModule):\n    def __init__(\n        self,\n        model_name: str = \"tf_efficientnet_b2\",\n        pretrained: bool = True,\n        drop_rate: float = 0.0,\n        embedding_size: int = 512,\n        num_classes: int = 15587,\n        arc_s: float = 30.0,\n        arc_m: float = 0.5,\n        arc_easy_margin: bool = False,\n        arc_ls_eps: float = 0.0,\n        optimizer: str = \"adam\",\n        learning_rate: float = 1e-4,\n        weight_decay: float = 1e-6,\n    ):\n        super().__init__()\n\n        self.save_hyperparameters()\n\n        self.model = timm.create_model(model_name, pretrained=pretrained, drop_rate=drop_rate)\n        self.embedding = nn.Linear(self.model.get_classifier().in_features, embedding_size)\n        self.model.reset_classifier(num_classes=0, global_pool=\"avg\")\n\n        self.arc = ArcMarginProduct(\n            in_features=embedding_size,\n            out_features=num_classes,\n            s=arc_s,\n            m=arc_m,\n            easy_margin=arc_easy_margin,\n            ls_eps=arc_ls_eps,\n        )\n\n        self.loss_fn = F.cross_entropy\n\n        self.metrics = torch.nn.ModuleDict(\n            {\"train_acc\": torchmetrics.Accuracy(top_k=5), \"val_acc\": torchmetrics.Accuracy(top_k=5)}\n        )\n\n    def forward(self, images: torch.Tensor) -> torch.Tensor:\n        features = self.model(images)\n        embeddings = self.embedding(features)\n\n        return embeddings\n\n    def configure_optimizers(self):\n        optimizer = create_optimizer_v2(\n            self.parameters(),\n            opt=self.hparams.optimizer,\n            lr=self.hparams.learning_rate,\n            weight_decay=self.hparams.weight_decay,\n        )\n\n        return optimizer\n\n    def training_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self._step(batch, \"train\")\n\n    def validation_step(self, batch: Dict[str, torch.Tensor], batch_idx: int) -> torch.Tensor:\n        return self._step(batch, \"val\")\n\n    def _step(self, batch: Dict[str, torch.Tensor], step: str) -> torch.Tensor:\n        images, targets = batch[\"image\"], batch[\"target\"]\n\n        embeddings = self(images)\n        outputs = self.arc(embeddings, targets, self.device)\n\n        loss = self.loss_fn(outputs, targets)\n        self.log(f\"{step}_loss\", loss)\n\n        acc_key = f\"{step}_acc\"\n        acc = self.metrics[acc_key](outputs, targets)\n        self.log(acc_key, acc, prog_bar=True, on_step=False, on_epoch=True)\n\n        return loss","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:57.73004Z","iopub.execute_input":"2022-05-22T15:59:57.730529Z","iopub.status.idle":"2022-05-22T15:59:57.748299Z","shell.execute_reply.started":"2022-05-22T15:59:57.73049Z","shell.execute_reply":"2022-05-22T15:59:57.747518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(\n    train_csv_encoded_folded: str = str(TRAIN_CSV_ENCODED_FOLDED_PATH),\n    test_csv: str = str(TEST_CSV_PATH),\n    val_fold: float = 0.0,\n    image_size: int = 256,\n    batch_size: int = 128,\n    num_workers: int = 2,\n    model_name: str = \"tf_efficientnet_b2\",\n    pretrained: bool = True,\n    drop_rate: float = 0.0,\n    embedding_size: int = 512,\n    num_classes: int = 15587,\n    arc_s: float = 30.0,\n    arc_m: float = 0.5,\n    arc_easy_margin: bool = False,\n    arc_ls_eps: float = 0.0,\n    optimizer: str = \"adam\",\n    learning_rate: float = 3e-4,\n    weight_decay: float = 1e-6,\n    project: str = \"kaggle-happywhale\",\n    accumulate_grad_batches=1,\n    auto_lr_find: bool = False,\n    auto_scale_batch_size: bool = False,\n    fast_dev_run: bool = False,\n    gpus: int = 1,\n    max_epochs: int = 10,\n    precision: int = 16,\n    stochastic_weight_avg=False,\n):\n    pl.seed_everything(42)\n\n    datamodule = LitDataModule(\n        train_csv_encoded_folded=train_csv_encoded_folded,\n        test_csv=test_csv,\n        val_fold=val_fold,\n        image_size=image_size,\n        batch_size=batch_size,\n        num_workers=num_workers,\n    )\n\n    module = LitModule(\n        model_name=model_name,\n        pretrained=pretrained,\n        drop_rate=drop_rate,\n        embedding_size=embedding_size,\n        num_classes=num_classes,\n        arc_s=arc_s,\n        arc_m=arc_m,\n        arc_easy_margin=arc_easy_margin,\n        arc_ls_eps=arc_ls_eps,\n        optimizer=optimizer,\n        learning_rate=learning_rate,\n        weight_decay=weight_decay,\n    )\n\n    trainer = pl.Trainer(\n        accumulate_grad_batches=accumulate_grad_batches,\n        benchmark=True,\n        auto_lr_find=auto_lr_find,\n        auto_scale_batch_size=auto_scale_batch_size,\n        deterministic=True,\n        fast_dev_run=fast_dev_run,\n        gpus=gpus,\n        max_epochs=max_epochs,\n        precision=precision,\n        stochastic_weight_avg=stochastic_weight_avg,\n    )\n\n    trainer.tune(module, datamodule=datamodule)\n\n    trainer.fit(module, datamodule=datamodule)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:57.751175Z","iopub.execute_input":"2022-05-22T15:59:57.751414Z","iopub.status.idle":"2022-05-22T15:59:57.765426Z","shell.execute_reply.started":"2022-05-22T15:59:57.751388Z","shell.execute_reply":"2022-05-22T15:59:57.764708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T15:59:57.766541Z","iopub.execute_input":"2022-05-22T15:59:57.766864Z","iopub.status.idle":"2022-05-22T17:16:03.819654Z","shell.execute_reply.started":"2022-05-22T15:59:57.766827Z","shell.execute_reply":"2022-05-22T17:16:03.818868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ls /kaggle/working/lightning_logs/version_0/checkpoints","metadata":{"execution":{"iopub.status.busy":"2022-05-22T17:16:03.82145Z","iopub.execute_input":"2022-05-22T17:16:03.821692Z","iopub.status.idle":"2022-05-22T17:16:04.681627Z","shell.execute_reply.started":"2022-05-22T17:16:03.821666Z","shell.execute_reply":"2022-05-22T17:16:04.680634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_eval_module(checkpoint_path: str, device: torch.device) -> LitModule:\n    module = LitModule.load_from_checkpoint(checkpoint_path)\n    module.to(device)\n    module.eval()\n\n    return module\n\ndef load_dataloaders(\n    train_csv_encoded_folded: str,\n    test_csv: str,\n    val_fold: float,\n    image_size: int,\n    batch_size: int,\n    num_workers: int,\n) -> Tuple[DataLoader, DataLoader, DataLoader]:\n\n    datamodule = LitDataModule(\n        train_csv_encoded_folded=train_csv_encoded_folded,\n        test_csv=test_csv,\n        val_fold=val_fold,\n        image_size=image_size,\n        batch_size=batch_size,\n        num_workers=num_workers,\n    )\n\n    datamodule.setup()\n\n    train_dl = datamodule.train_dataloader()\n    val_dl = datamodule.val_dataloader()\n    test_dl = datamodule.test_dataloader()\n\n    return train_dl, val_dl, test_dl\n\n\ndef load_encoder() -> LabelEncoder:\n    encoder = LabelEncoder()\n    encoder.classes_ = np.load(ENCODER_CLASSES_PATH, allow_pickle=True)\n\n    return encoder\n\n\n@torch.inference_mode()\ndef get_embeddings(\n    module: pl.LightningModule, dataloader: DataLoader, encoder: LabelEncoder, stage: str\n) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n\n    all_image_names = []\n    all_embeddings = []\n    all_targets = []\n\n    for batch in tqdm(dataloader, desc=f\"Creating {stage} embeddings\"):\n        image_names = batch[\"image_name\"]\n        images = batch[\"image\"].to(module.device)\n        targets = batch[\"target\"].to(module.device)\n\n        embeddings = module(images)\n\n        all_image_names.append(image_names)\n        all_embeddings.append(embeddings.cpu().numpy())\n        all_targets.append(targets.cpu().numpy())\n\n    all_image_names = np.concatenate(all_image_names)\n    all_embeddings = np.vstack(all_embeddings)\n    all_targets = np.concatenate(all_targets)\n\n    all_embeddings = normalize(all_embeddings, axis=1, norm=\"l2\")\n    all_targets = encoder.inverse_transform(all_targets)\n\n    return all_image_names, all_embeddings, all_targets\n\n\ndef create_and_search_index(embedding_size: int, train_embeddings: np.ndarray, val_embeddings: np.ndarray, k: int):\n    index = faiss.IndexFlatIP(embedding_size)\n    index.add(train_embeddings)\n    D, I = index.search(val_embeddings, k=k)  # noqa: E741\n\n    return D, I\n\n\ndef create_val_targets_df(\n    train_targets: np.ndarray, val_image_names: np.ndarray, val_targets: np.ndarray\n) -> pd.DataFrame:\n\n    allowed_targets = np.unique(train_targets)\n    val_targets_df = pd.DataFrame(np.stack([val_image_names, val_targets], axis=1), columns=[\"image\", \"target\"])\n    val_targets_df.loc[~val_targets_df.target.isin(allowed_targets), \"target\"] = \"new_individual\"\n\n    return val_targets_df\n\n\ndef create_distances_df(\n    image_names: np.ndarray, targets: np.ndarray, D: np.ndarray, I: np.ndarray, stage: str  # noqa: E741\n) -> pd.DataFrame:\n\n    distances_df = []\n    for i, image_name in tqdm(enumerate(image_names), desc=f\"Creating {stage}_df\"):\n        target = targets[I[i]]\n        distances = D[i]\n        subset_preds = pd.DataFrame(np.stack([target, distances], axis=1), columns=[\"target\", \"distances\"])\n        subset_preds[\"image\"] = image_name\n        distances_df.append(subset_preds)\n\n    distances_df = pd.concat(distances_df).reset_index(drop=True)\n    distances_df = distances_df.groupby([\"image\", \"target\"]).distances.max().reset_index()\n    distances_df = distances_df.sort_values(\"distances\", ascending=False).reset_index(drop=True)\n\n    return distances_df\n\n\ndef get_best_threshold(val_targets_df: pd.DataFrame, valid_df: pd.DataFrame) -> Tuple[float, float]:\n    best_th = 0\n    best_cv = 0\n    for th in [0.1 * x for x in range(11)]:\n        all_preds = get_predictions(valid_df, threshold=th)\n\n        cv = 0\n        for i, row in val_targets_df.iterrows():\n            target = row.target\n            preds = all_preds[row.image]\n            val_targets_df.loc[i, th] = map_per_image(target, preds)\n\n        cv = val_targets_df[th].mean()\n\n        print(f\"th={th} cv={cv}\")\n\n        if cv > best_cv:\n            best_th = th\n            best_cv = cv\n\n    print(f\"best_th={best_th}\")\n    print(f\"best_cv={best_cv}\")\n\n    # Adjustment: Since Public lb has nearly 10% 'new_individual' (Be Careful for private LB)\n    val_targets_df[\"is_new_individual\"] = val_targets_df.target == \"new_individual\"\n    val_scores = val_targets_df.groupby(\"is_new_individual\").mean().T\n    val_scores[\"adjusted_cv\"] = val_scores[True] * 0.1 + val_scores[False] * 0.9\n    best_th = val_scores[\"adjusted_cv\"].idxmax()\n    print(f\"best_th_adjusted={best_th}\")\n\n    return best_th, best_cv\n\n\ndef get_predictions(df: pd.DataFrame, threshold: float = 0.2):\n    sample_list = [\"938b7e931166\", \"5bf17305f073\", \"7593d2aee842\", \"7362d7a01d00\", \"956562ff2888\"]\n\n    predictions = {}\n    for i, row in tqdm(df.iterrows(), total=len(df), desc=f\"Creating predictions for threshold={threshold}\"):\n        if row.image in predictions:\n            if len(predictions[row.image]) == 5:\n                continue\n            predictions[row.image].append(row.target)\n        elif row.distances > threshold:\n            predictions[row.image] = [row.target, \"new_individual\"]\n        else:\n            predictions[row.image] = [\"new_individual\", row.target]\n\n    for x in tqdm(predictions):\n        if len(predictions[x]) < 5:\n            remaining = [y for y in sample_list if y not in predictions]\n            predictions[x] = predictions[x] + remaining\n            predictions[x] = predictions[x][:5]\n\n    return predictions\n\n\n# TODO: add types\ndef map_per_image(label, predictions):\n    \"\"\"Computes the precision score of one image.\n\n    Parameters\n    ----------\n    label : string\n            The true label of the image\n    predictions : list\n            A list of predicted elements (order does matter, 5 predictions allowed per image)\n\n    Returns\n    -------\n    score : double\n    \"\"\"\n    try:\n        return 1 / (predictions[:5].index(label) + 1)\n    except ValueError:\n        return 0.0\n\n\ndef create_predictions_df(test_df: pd.DataFrame, best_th: float) -> pd.DataFrame:\n    predictions = get_predictions(test_df, best_th)\n\n    predictions = pd.Series(predictions).reset_index()\n    predictions.columns = [\"image\", \"predictions\"]\n    predictions[\"predictions\"] = predictions[\"predictions\"].apply(lambda x: \" \".join(x))\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2022-05-22T17:32:45.068269Z","iopub.execute_input":"2022-05-22T17:32:45.068533Z","iopub.status.idle":"2022-05-22T17:32:45.123592Z","shell.execute_reply.started":"2022-05-22T17:32:45.068496Z","shell.execute_reply":"2022-05-22T17:32:45.122658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def infer(\n    train_csv_encoded_folded: str = str(TRAIN_CSV_ENCODED_FOLDED_PATH),\n    test_csv: str = str(TEST_CSV_PATH),\n    val_fold: float = 0.0,\n    image_size: int = 256,\n    batch_size: int = 64,\n    num_workers: int = 2,\n    k: int = 50,\n    submit: bool = False,\n):\n    checkpoint_path = \"/kaggle/working/lightning_logs/version_0/checkpoints/epoch=9-step=3179.ckpt\"\n\n    module = load_eval_module(checkpoint_path, torch.device(\"cuda\"))\n\n    train_dl, val_dl, test_dl = load_dataloaders(\n        train_csv_encoded_folded=train_csv_encoded_folded,\n        test_csv=test_csv,\n        val_fold=val_fold,\n        image_size=image_size,\n        batch_size=batch_size,\n        num_workers=num_workers,\n    )\n\n    encoder = load_encoder()\n\n    train_image_names, train_embeddings, train_targets = get_embeddings(module, train_dl, encoder, stage=\"train\")\n    val_image_names, val_embeddings, val_targets = get_embeddings(module, val_dl, encoder, stage=\"val\")\n    test_image_names, test_embeddings, test_targets = get_embeddings(module, test_dl, encoder, stage=\"test\")\n\n    D, I = create_and_search_index(module.hparams.embedding_size, train_embeddings, val_embeddings, k)  # noqa: E741\n    print(\"Created index with train_embeddings\")\n\n    val_targets_df = create_val_targets_df(train_targets, val_image_names, val_targets)\n    print(f\"val_targets_df=\\n{val_targets_df.head()}\")\n\n    val_df = create_distances_df(val_image_names, train_targets, D, I, \"val\")\n    print(f\"val_df=\\n{val_df.head()}\")\n\n    best_th, best_cv = get_best_threshold(val_targets_df, val_df)\n    print(f\"val_targets_df=\\n{val_targets_df.describe()}\")\n\n    train_embeddings = np.concatenate([train_embeddings, val_embeddings])\n    train_targets = np.concatenate([train_targets, val_targets])\n    print(\"Updated train_embeddings and train_targets with val data\")\n\n    D, I = create_and_search_index(module.hparams.embedding_size, train_embeddings, test_embeddings, k)  # noqa: E741\n    print(\"Created index with train_embeddings\")\n\n    test_df = create_distances_df(test_image_names, train_targets, D, I, \"test\")\n    print(f\"test_df=\\n{test_df.head()}\")\n\n    predictions = create_predictions_df(test_df, best_th)\n    print(f\"predictions.head()={predictions.head()}\")\n    predictions.to_csv(SUBMISSION_CSV_PATH, index=False)","metadata":{"execution":{"iopub.status.busy":"2022-05-22T17:16:04.728014Z","iopub.execute_input":"2022-05-22T17:16:04.72835Z","iopub.status.idle":"2022-05-22T17:16:04.743064Z","shell.execute_reply.started":"2022-05-22T17:16:04.728312Z","shell.execute_reply":"2022-05-22T17:16:04.742124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"infer()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T17:16:04.744434Z","iopub.execute_input":"2022-05-22T17:16:04.7449Z","iopub.status.idle":"2022-05-22T17:32:45.003128Z","shell.execute_reply.started":"2022-05-22T17:16:04.744864Z","shell.execute_reply":"2022-05-22T17:32:45.002285Z"},"trusted":true},"execution_count":null,"outputs":[]}]}