{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\"\"\"First of all this is not my code. I created this model by the help of the guy named tomoto. And I'm sharing the original post here: https://www.kaggle.com/tomato0813/happywhale-id-tensorflow-tutorial/notebook . first i think i can create the model by using the opencv but from this tutorial i understand this method is very helpful and from this i can learn lot of new technique or his approach to the mdoel\"\"\"","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:26.249778Z","iopub.execute_input":"2022-02-16T13:22:26.250095Z","iopub.status.idle":"2022-02-16T13:22:26.258435Z","shell.execute_reply.started":"2022-02-16T13:22:26.250064Z","shell.execute_reply":"2022-02-16T13:22:26.257705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We all know that we need to use some pipeline for creating model. Pipeline I used here is\n\n1. Import Libraries\n1. Fetch Data\n1. EDA\n1. Feautre Engineering\n1. Model creation\n    1. Create Functions\n    1. Create Training Dataset\n    1. Create Validation Dataset    \n1. Testing model\n1. Submission\n","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nAUTO = tf.data.experimental.AUTOTUNE\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:26.260046Z","iopub.execute_input":"2022-02-16T13:22:26.260403Z","iopub.status.idle":"2022-02-16T13:22:31.963482Z","shell.execute_reply.started":"2022-02-16T13:22:26.260375Z","shell.execute_reply":"2022-02-16T13:22:31.962575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 1. Import Libraries","metadata":{}},{"cell_type":"markdown","source":"Import the required libraries we actually going to work. If the library package are missing,Use **!pip install package_name**","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:31.964968Z","iopub.execute_input":"2022-02-16T13:22:31.965307Z","iopub.status.idle":"2022-02-16T13:22:31.970341Z","shell.execute_reply.started":"2022-02-16T13:22:31.965267Z","shell.execute_reply":"2022-02-16T13:22:31.969464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet\nimport re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, train_test_split\nfrom tensorflow.keras import backend as K\nimport tensorflow_addons as tfa\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport pickle\nimport json\nimport tensorflow_hub as tfhub\nfrom datetime import datetime\nfrom kaggle_datasets import KaggleDatasets","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:31.972843Z","iopub.execute_input":"2022-02-16T13:22:31.973647Z","iopub.status.idle":"2022-02-16T13:22:39.968316Z","shell.execute_reply.started":"2022-02-16T13:22:31.973591Z","shell.execute_reply":"2022-02-16T13:22:39.966932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"''' import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename)) '''\n","metadata":{"_kg_hide-output":true,"scrolled":true,"execution":{"iopub.status.busy":"2022-02-16T13:22:39.969946Z","iopub.execute_input":"2022-02-16T13:22:39.970226Z","iopub.status.idle":"2022-02-16T13:22:39.976121Z","shell.execute_reply.started":"2022-02-16T13:22:39.970194Z","shell.execute_reply":"2022-02-16T13:22:39.975436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Fetch Data","metadata":{"execution":{"iopub.status.busy":"2022-02-14T13:12:37.912329Z","iopub.execute_input":"2022-02-14T13:12:37.912671Z","iopub.status.idle":"2022-02-14T13:12:37.916693Z","shell.execute_reply.started":"2022-02-14T13:12:37.912638Z","shell.execute_reply":"2022-02-14T13:12:37.915964Z"}}},{"cell_type":"code","source":"### read all the required files\n\ntrain_df = pd.read_csv(\"../input/happy-whale-and-dolphin/train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:39.977459Z","iopub.execute_input":"2022-02-16T13:22:39.977687Z","iopub.status.idle":"2022-02-16T13:22:40.078166Z","shell.execute_reply.started":"2022-02-16T13:22:39.977661Z","shell.execute_reply":"2022-02-16T13:22:40.077237Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv('../input/happy-whale-and-dolphin/sample_submission.csv')\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.07964Z","iopub.execute_input":"2022-02-16T13:22:40.079874Z","iopub.status.idle":"2022-02-16T13:22:40.127444Z","shell.execute_reply.started":"2022-02-16T13:22:40.079845Z","shell.execute_reply":"2022-02-16T13:22:40.126433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_df = pd.concat([train_df['image'], test_df['image']])\nconcat_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.128841Z","iopub.execute_input":"2022-02-16T13:22:40.129145Z","iopub.status.idle":"2022-02-16T13:22:40.142113Z","shell.execute_reply.started":"2022-02-16T13:22:40.129103Z","shell.execute_reply":"2022-02-16T13:22:40.141316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Exploratory data analysis","metadata":{"execution":{"iopub.status.busy":"2022-02-14T13:12:02.941539Z","iopub.execute_input":"2022-02-14T13:12:02.941834Z","iopub.status.idle":"2022-02-14T13:12:02.947726Z","shell.execute_reply.started":"2022-02-14T13:12:02.941802Z","shell.execute_reply":"2022-02-14T13:12:02.945822Z"}}},{"cell_type":"code","source":"## lets find, How many  species are availble in the dataset and their counts\ntrain_df.species.value_counts()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.144625Z","iopub.execute_input":"2022-02-16T13:22:40.145627Z","iopub.status.idle":"2022-02-16T13:22:40.160414Z","shell.execute_reply.started":"2022-02-16T13:22:40.145581Z","shell.execute_reply":"2022-02-16T13:22:40.159497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"both pilot_whale and globis are short_finned_pilot_whale and can be merge as per the confirmation from the host and also found duplicate names in the species.Let's merge all!!!","metadata":{}},{"cell_type":"code","source":"## Find the duplicactes and merge\n\nprint(\"Total species before finding duplicates :\",len(train_df.species.unique()))\ntrain_df.species = train_df.species.str.replace('kiler_whale','killer_whale')\ntrain_df.species = train_df.species.str.replace('bottlenose_dolpin','bottlenose_dolphin')\ntrain_df['species'][(train_df['species'] ==\"pilot_whale\") | (train_df['species'] ==\"globis\" )]='short_finned_pilot_whale'\nprint(\"Total species after :\",len(train_df.species.unique()))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.161709Z","iopub.execute_input":"2022-02-16T13:22:40.162324Z","iopub.status.idle":"2022-02-16T13:22:40.293728Z","shell.execute_reply.started":"2022-02-16T13:22:40.162288Z","shell.execute_reply":"2022-02-16T13:22:40.292802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"The available species are:\",train_df['species'].unique())","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.295129Z","iopub.execute_input":"2022-02-16T13:22:40.29599Z","iopub.status.idle":"2022-02-16T13:22:40.306895Z","shell.execute_reply.started":"2022-02-16T13:22:40.295947Z","shell.execute_reply":"2022-02-16T13:22:40.305971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## lets check speiceis in visually\nplt.figure(figsize=(16, 12))\nplt.rcParams[\"font.size\"] = 16\nplt.barh(train_df[\"species\"].value_counts().sort_values(ascending=True).index,train_df[\"species\"].value_counts().sort_values(ascending=True),tick_label = train_df[\"species\"].value_counts().sort_values(ascending=True).index)\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.308211Z","iopub.execute_input":"2022-02-16T13:22:40.309221Z","iopub.status.idle":"2022-02-16T13:22:40.74262Z","shell.execute_reply.started":"2022-02-16T13:22:40.309173Z","shell.execute_reply":"2022-02-16T13:22:40.741749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This data set is imbalanced, lets check the specices less than 1000 images","metadata":{}},{"cell_type":"code","source":"train_df.species.value_counts()[train_df.species.value_counts()<=1000]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.743912Z","iopub.execute_input":"2022-02-16T13:22:40.744798Z","iopub.status.idle":"2022-02-16T13:22:40.770603Z","shell.execute_reply.started":"2022-02-16T13:22:40.744748Z","shell.execute_reply":"2022-02-16T13:22:40.769676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.771848Z","iopub.execute_input":"2022-02-16T13:22:40.772124Z","iopub.status.idle":"2022-02-16T13:22:40.866133Z","shell.execute_reply.started":"2022-02-16T13:22:40.772096Z","shell.execute_reply":"2022-02-16T13:22:40.865131Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"concat_df = pd.concat([train_df['image'], test_df['image']])\nconcat_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.867242Z","iopub.execute_input":"2022-02-16T13:22:40.867461Z","iopub.status.idle":"2022-02-16T13:22:40.87736Z","shell.execute_reply.started":"2022-02-16T13:22:40.867435Z","shell.execute_reply":"2022-02-16T13:22:40.876451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Feautre Engineering","metadata":{}},{"cell_type":"code","source":"## Set the path for train image\nIMG_PATH = \"/kaggle/input/happy-whale-and-dolphin/train_images/\"\nIMG_PATH_TEST = \"/kaggle/input/happy-whale-and-dolphin/test_images/\"\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.879749Z","iopub.execute_input":"2022-02-16T13:22:40.880598Z","iopub.status.idle":"2022-02-16T13:22:40.884765Z","shell.execute_reply.started":"2022-02-16T13:22:40.880563Z","shell.execute_reply":"2022-02-16T13:22:40.884144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nimage_name_to_image_id = dict((image_name, index) for index, image_name in enumerate(concat_df.unique()))\n#image_id_to_image_name = {v: k for k, v in image_name_to_image_id.items()}\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:40.88619Z","iopub.execute_input":"2022-02-16T13:22:40.88669Z","iopub.status.idle":"2022-02-16T13:22:40.942107Z","shell.execute_reply.started":"2022-02-16T13:22:40.886659Z","shell.execute_reply":"2022-02-16T13:22:40.941395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_dict = dict((image,index) for index,image in enumerate(concat_df.unique()))\nimg_dict_inverse = {ind:img for img,ind in img_dict.items()}\n","metadata":{"_kg_hide-output":true,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-16T13:22:40.943476Z","iopub.execute_input":"2022-02-16T13:22:40.943925Z","iopub.status.idle":"2022-02-16T13:22:41.001628Z","shell.execute_reply.started":"2022-02-16T13:22:40.943893Z","shell.execute_reply":"2022-02-16T13:22:41.000734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"image_id\"]=[img_dict[i] for i in train_df['image']]\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.00288Z","iopub.execute_input":"2022-02-16T13:22:41.003163Z","iopub.status.idle":"2022-02-16T13:22:41.055339Z","shell.execute_reply.started":"2022-02-16T13:22:41.003127Z","shell.execute_reply":"2022-02-16T13:22:41.054338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## lets create for individual id \n\nid_dict = dict((a,b) for b,a in enumerate(train_df.individual_id.unique()))\nid_dict_inverse={(c,d) for d,c in id_dict.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.05662Z","iopub.execute_input":"2022-02-16T13:22:41.057218Z","iopub.status.idle":"2022-02-16T13:22:41.079906Z","shell.execute_reply.started":"2022-02-16T13:22:41.057181Z","shell.execute_reply":"2022-02-16T13:22:41.079145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"label\"]=[id_dict[i] for i in train_df.individual_id]\ntrain_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.081085Z","iopub.execute_input":"2022-02-16T13:22:41.081444Z","iopub.status.idle":"2022-02-16T13:22:41.132211Z","shell.execute_reply.started":"2022-02-16T13:22:41.081416Z","shell.execute_reply":"2022-02-16T13:22:41.131565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## lets create for species\n\nspid_dict = dict((a,b) for b,a in enumerate(train_df.species.unique()))\nspid_dict_inverse={(c,d) for d,c in spid_dict.items()}","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.133177Z","iopub.execute_input":"2022-02-16T13:22:41.133717Z","iopub.status.idle":"2022-02-16T13:22:41.143605Z","shell.execute_reply.started":"2022-02-16T13:22:41.133688Z","shell.execute_reply":"2022-02-16T13:22:41.142587Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"label\"]=[id_dict[i] for i in train_df.individual_id]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.145102Z","iopub.execute_input":"2022-02-16T13:22:41.145374Z","iopub.status.idle":"2022-02-16T13:22:41.194975Z","shell.execute_reply.started":"2022-02-16T13:22:41.145344Z","shell.execute_reply":"2022-02-16T13:22:41.19408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[\"species\"] = [spid_dict[i] for i in train_df.species]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.199463Z","iopub.execute_input":"2022-02-16T13:22:41.199807Z","iopub.status.idle":"2022-02-16T13:22:41.239229Z","shell.execute_reply.started":"2022-02-16T13:22:41.19977Z","shell.execute_reply":"2022-02-16T13:22:41.238226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import model_selection","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.240753Z","iopub.execute_input":"2022-02-16T13:22:41.241002Z","iopub.status.idle":"2022-02-16T13:22:41.245111Z","shell.execute_reply.started":"2022-02-16T13:22:41.240974Z","shell.execute_reply":"2022-02-16T13:22:41.244265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_folds(data,target,num_splits):\n    # we create a new column called kfold and fill it with -1\n    data[\"kfold\"] = -1\n    \n    # the next step is to randomize the rows of the data\n    data = data.sample(frac=1).reset_index(drop=True)\n\n    # calculate number of bins by Sturge's rule\n    # I take the floor of the value, you can also\n    # just round it\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[target], bins=num_bins, labels=False\n    )\n    \n    # initiate the kfold class from model_selection module\n    kf = model_selection.StratifiedKFold(n_splits=num_splits)\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins!\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n    \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n\n    # return dataframe with folds\n    return data","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.246512Z","iopub.execute_input":"2022-02-16T13:22:41.246761Z","iopub.status.idle":"2022-02-16T13:22:41.259263Z","shell.execute_reply.started":"2022-02-16T13:22:41.246722Z","shell.execute_reply":"2022-02-16T13:22:41.258337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Model Creation","metadata":{}},{"cell_type":"markdown","source":"### A. Function","metadata":{}},{"cell_type":"code","source":"# image to array\ndef decode_image(image_raw):\n    image = tf.image.decode_jpeg(image_raw, channels=3)\n    image = tf.image.resize(image, [IMAGE_SIZE, IMAGE_SIZE])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.260889Z","iopub.execute_input":"2022-02-16T13:22:41.262045Z","iopub.status.idle":"2022-02-16T13:22:41.272398Z","shell.execute_reply.started":"2022-02-16T13:22:41.261939Z","shell.execute_reply":"2022-02-16T13:22:41.271611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef read_tfrecord(raw_image_dataset):\n    feature_description = {\n        \"image_id\": tf.io.FixedLenFeature([], tf.int64),\n        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n        \"label\": tf.io.FixedLenFeature([], tf.int64),\n    }\n\n    parsed_image_dataset = tf.io.parse_single_example(raw_image_dataset, feature_description)\n    image_id = tf.cast(parsed_image_dataset['image_id'], tf.int32)\n    image = decode_image(parsed_image_dataset['image_raw'])\n    label = tf.cast(parsed_image_dataset['label'], tf.int32)\n    \n    return image_id, image, label\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.273876Z","iopub.execute_input":"2022-02-16T13:22:41.274149Z","iopub.status.idle":"2022-02-16T13:22:41.284498Z","shell.execute_reply.started":"2022-02-16T13:22:41.27412Z","shell.execute_reply":"2022-02-16T13:22:41.28369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nsave_dir = '.'\nEXPERIMENT = 0\nrun_ts = datetime.now().strftime('%Y%m%d-%H%M%S')\nprint(run_ts)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.285915Z","iopub.execute_input":"2022-02-16T13:22:41.286451Z","iopub.status.idle":"2022-02-16T13:22:41.302046Z","shell.execute_reply.started":"2022-02-16T13:22:41.286409Z","shell.execute_reply":"2022-02-16T13:22:41.301336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class config:\n    \n    \n    SEED = 42\n    FOLD_TO_RUN = 0\n    FOLDS = 5\n    DEBUG = False\n    EVALUATE = True\n    RESUME = False\n    RESUME_EPOCH = None\n    \n    \n    ### Dataset\n    BATCH_SIZE = 32 * strategy.num_replicas_in_sync\n    IMAGE_SIZE = 512\n    N_CLASSES = 15587\n    \n    ### Model\n    model_type = 'effnetv1'  \n    EFF_NET = 5\n    EFF_NETV2 = 's-21k-ft1k'\n    FREEZE_BATCH_NORM = False\n    head = 'arcface' \n    EPOCHS = 20\n    LR = 0.001\n    message='baseline'\n    \n    ### Augmentations\n    CUTOUT = False\n    \n    ### Save-Directory\n    save_dir = save_dir\n    \n    ### Inference\n    KNN = 50\n    \ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n         for filename in filenames]\n    return np.sum(n)\n\n# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \ndef is_interactive():\n    return 'runtime'    in get_ipython().config.IPKernelApp.connection_file\nIS_INTERACTIVE = is_interactive()\nprint(IS_INTERACTIVE)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.303255Z","iopub.execute_input":"2022-02-16T13:22:41.303646Z","iopub.status.idle":"2022-02-16T13:22:41.316369Z","shell.execute_reply.started":"2022-02-16T13:22:41.303616Z","shell.execute_reply":"2022-02-16T13:22:41.315524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MODEL_NAME = None\nif config.model_type == 'effnetv1':\n    MODEL_NAME = f'effnetv1_b{config.EFF_NET}'\nelif config.model_type == 'effnetv2':\n    MODEL_NAME = f'effnetv2_{config.EFF_NETV2}'\n\nconfig.MODEL_NAME = MODEL_NAME\nprint(MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.31752Z","iopub.execute_input":"2022-02-16T13:22:41.318373Z","iopub.status.idle":"2022-02-16T13:22:41.328397Z","shell.execute_reply.started":"2022-02-16T13:22:41.318338Z","shell.execute_reply":"2022-02-16T13:22:41.327395Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open(config.save_dir+'/config.json', 'w') as fp:\n    json.dump({x:dict(config.__dict__)[x] for x in dict(config.__dict__) if not x.startswith('_')}, fp)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.330089Z","iopub.execute_input":"2022-02-16T13:22:41.330564Z","iopub.status.idle":"2022-02-16T13:22:41.341265Z","shell.execute_reply.started":"2022-02-16T13:22:41.33053Z","shell.execute_reply":"2022-02-16T13:22:41.340248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('happywhale-tfrecords-v1')\n    \ntrain_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-train*.tfrec')))\ntest_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-test*.tfrec')))\nprint(GCS_PATH)\nprint(len(train_files),len(test_files),count_data_items(train_files),count_data_items(test_files))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:22:41.342823Z","iopub.execute_input":"2022-02-16T13:22:41.343133Z","iopub.status.idle":"2022-02-16T13:25:38.773568Z","shell.execute_reply.started":"2022-02-16T13:22:41.343098Z","shell.execute_reply":"2022-02-16T13:25:38.772793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def arcface_format(posting_id, image, label_group, matches):\n    return posting_id, {'inp1': image, 'inp2': label_group}, label_group, matches\n\ndef arcface_inference_format(posting_id, image, label_group, matches):\n    return image,posting_id\n\ndef arcface_eval_format(posting_id, image, label_group, matches):\n    return image,label_group\n\n# Data augmentation function\ndef data_augment(posting_id, image, label_group, matches):\n\n    ### CUTOUT\n    if tf.random.uniform([])>0.5 and config.CUTOUT:\n      N_CUTOUT = 6\n      for cutouts in range(N_CUTOUT):\n        if tf.random.uniform([])>0.5:\n           DIM = config.IMAGE_SIZE\n           CUTOUT_LENGTH = DIM//8\n           x1 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)\n           x2 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)\n           filter_ = tf.concat([tf.zeros((x1,CUTOUT_LENGTH)),tf.ones((CUTOUT_LENGTH,CUTOUT_LENGTH)),tf.zeros((DIM-x1-CUTOUT_LENGTH,CUTOUT_LENGTH))],axis=0)\n           filter_ = tf.concat([tf.zeros((DIM,x2)),filter_,tf.zeros((DIM,DIM-x2-CUTOUT_LENGTH))],axis=1)\n           cutout = tf.reshape(1-filter_,(DIM,DIM,1))\n           image = cutout*image\n\n    image = tf.image.random_flip_left_right(image)\n    # image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\n    return posting_id, image, label_group, matches\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, [config.IMAGE_SIZE,config.IMAGE_SIZE])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# This function parse our images and also get the target variable\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),\n#         \"matches\": tf.io.FixedLenFeature([], tf.string)\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    posting_id = example['image_name']\n    image = decode_image(example['image'])\n#     label_group = tf.one_hot(tf.cast(example['label_group'], tf.int32), depth = N_CLASSES)\n    label_group = tf.cast(example['target'], tf.int32)\n#     matches = example['matches']\n    matches = 1\n    return posting_id, image, label_group, matches\n\n# This function loads TF Records and parse them into tensors\ndef load_dataset(filenames, ordered = False):\n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n#     dataset = dataset.cache()\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n    return dataset\n\n# This function is to get our training tensors\ndef get_training_dataset(filenames):\n    dataset = load_dataset(filenames, ordered = False)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our training tensors\ndef get_val_dataset(filenames):\n    dataset = load_dataset(filenames, ordered = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our training tensors\ndef get_eval_dataset(filenames, get_targets = True):\n    dataset = load_dataset(filenames, ordered = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_eval_format, num_parallel_calls = AUTO)\n    if not get_targets:\n        dataset = dataset.map(lambda image, target: image)\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our training tensors\ndef get_test_dataset(filenames, get_names = True):\n    dataset = load_dataset(filenames, ordered = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_inference_format, num_parallel_calls = AUTO)\n    if not get_names:\n        dataset = dataset.map(lambda image, posting_id: image)\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\nrow = 10; col = 8;\nrow = min(row,config.BATCH_SIZE//col)\nN_TRAIN = count_data_items(train_files)\nprint(N_TRAIN)\nds = get_training_dataset(train_files)\n\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:25:38.77523Z","iopub.execute_input":"2022-02-16T13:25:38.77588Z","iopub.status.idle":"2022-02-16T13:25:39.763834Z","shell.execute_reply.started":"2022-02-16T13:25:38.775832Z","shell.execute_reply":"2022-02-16T13:25:39.762769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for (sample,label) in ds:\n    img = sample['inp1']\n    plt.figure(figsize=(25,int(25*row/col)))\n    for j in range(row*col):\n        plt.subplot(row,col,j+1)\n        plt.title(label[j].numpy())\n        plt.axis('off')\n        plt.imshow(img[j,])\n    plt.show()\n    break","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:25:39.765635Z","iopub.execute_input":"2022-02-16T13:25:39.76599Z","iopub.status.idle":"2022-02-16T13:26:01.938063Z","shell.execute_reply.started":"2022-02-16T13:25:39.765945Z","shell.execute_reply":"2022-02-16T13:26:01.935956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(img.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:01.93937Z","iopub.execute_input":"2022-02-16T13:26:01.939641Z","iopub.status.idle":"2022-02-16T13:26:01.945531Z","shell.execute_reply.started":"2022-02-16T13:26:01.939611Z","shell.execute_reply":"2022-02-16T13:26:01.944491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arcmarginproduct class keras layer\nclass ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:01.947083Z","iopub.execute_input":"2022-02-16T13:26:01.947362Z","iopub.status.idle":"2022-02-16T13:26:01.966044Z","shell.execute_reply.started":"2022-02-16T13:26:01.947332Z","shell.execute_reply":"2022-02-16T13:26:01.964934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n\ndef freeze_BN(model):\n    # Unfreeze layers while leaving BatchNorm layers frozen\n    for layer in model.layers:\n        if not isinstance(layer, tf.keras.layers.BatchNormalization):\n            layer.trainable = True\n        else:\n            layer.trainable = False\n\n# Function to create our EfficientNetB3 model\ndef get_model():\n\n    if config.head=='arcface':\n        head = ArcMarginProduct\n    else:\n        assert 1==2, \"INVALID HEAD\"\n    \n    with strategy.scope():\n        \n        margin = head(\n            n_classes = config.N_CLASSES, \n            s = 30, \n            m = 0.3, \n            name=f'head/{config.head}', \n            dtype='float32'\n            )\n\n        inp = tf.keras.layers.Input(shape = [config.IMAGE_SIZE, config.IMAGE_SIZE, 3], name = 'inp1')\n        label = tf.keras.layers.Input(shape = (), name = 'inp2')\n        \n        if config.model_type == 'effnetv1':\n            x = EFNS[config.EFF_NET](weights = 'noisy-student', include_top = False)(inp)\n            embed = tf.keras.layers.GlobalAveragePooling2D()(x)\n        elif config.model_type == 'effnetv2':\n            FEATURE_VECTOR = f'{EFFNETV2_ROOT}/tfhub_models/efficientnetv2-{config.EFF_NETV2}/feature_vector'\n            embed = tfhub.KerasLayer(FEATURE_VECTOR, trainable=True)(inp)\n            \n        embed = tf.keras.layers.Dropout(0.2)(embed)\n        embed = tf.keras.layers.Dense(512)(embed)\n        x = margin([embed, label])\n        \n        output = tf.keras.layers.Softmax(dtype='float32')(x)\n        \n        model = tf.keras.models.Model(inputs = [inp, label], outputs = [output])\n        embed_model = tf.keras.models.Model(inputs = inp, outputs = embed)  \n        \n        opt = tf.keras.optimizers.Adam(learning_rate = config.LR)\n        if config.FREEZE_BATCH_NORM:\n            freeze_BN(model)\n\n        model.compile(\n            optimizer = opt,\n            loss = [tf.keras.losses.SparseCategoricalCrossentropy()],\n            metrics = [tf.keras.metrics.SparseCategoricalAccuracy(),tf.keras.metrics.SparseTopKCategoricalAccuracy(k=5)]\n            ) \n        \n        return model,embed_model","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:01.967435Z","iopub.execute_input":"2022-02-16T13:26:01.967702Z","iopub.status.idle":"2022-02-16T13:26:01.987698Z","shell.execute_reply.started":"2022-02-16T13:26:01.967671Z","shell.execute_reply":"2022-02-16T13:26:01.986602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_callback(plot=False):\n    lr_start   = 0.000001\n    lr_max     = 0.000005 * config.BATCH_SIZE  \n    lr_min     = 0.000001\n    lr_ramp_ep = 4\n    lr_sus_ep  = 0\n    lr_decay   = 0.9\n   \n    def lrfn(epoch):\n        if config.RESUME:\n            epoch = epoch + config.RESUME_EPOCH\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n        \n    if plot:\n        epochs = list(range(config.EPOCHS))\n        learning_rates = [lrfn(x) for x in epochs]\n        plt.scatter(epochs,learning_rates)\n        plt.show()\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\nget_lr_callback(plot=True)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:01.989108Z","iopub.execute_input":"2022-02-16T13:26:01.989614Z","iopub.status.idle":"2022-02-16T13:26:02.216949Z","shell.execute_reply.started":"2022-02-16T13:26:01.989581Z","shell.execute_reply":"2022-02-16T13:26:02.216281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Snapshot(tf.keras.callbacks.Callback):\n    \n    def __init__(self,fold,snapshot_epochs=[]):\n        super(Snapshot, self).__init__()\n        self.snapshot_epochs = snapshot_epochs\n        self.fold = fold\n        \n        \n    def on_epoch_end(self, epoch, logs=None):\n        # logs is a dictionary\n#         print(f\"epoch: {epoch}, train_acc: {logs['acc']}, valid_acc: {logs['val_acc']}\")\n        if epoch in self.snapshot_epochs: # your custom condition         \n            self.model.save_weights(config.save_dir+f\"/EF{config.MODEL_NAME}_epoch{epoch}.h5\")\n        self.model.save_weights(config.save_dir+f\"/{config.MODEL_NAME}_last.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:02.218261Z","iopub.execute_input":"2022-02-16T13:26:02.219155Z","iopub.status.idle":"2022-02-16T13:26:02.227091Z","shell.execute_reply.started":"2022-02-16T13:26:02.21911Z","shell.execute_reply":"2022-02-16T13:26:02.226341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAINING_FILENAMES = [x for i,x in enumerate(train_files) if i%config.FOLDS!=config.FOLD_TO_RUN]\nVALIDATION_FILENAMES = [x for i,x in enumerate(train_files) if i%config.FOLDS==config.FOLD_TO_RUN]\nprint(len(TRAINING_FILENAMES),len(VALIDATION_FILENAMES),count_data_items(TRAINING_FILENAMES),count_data_items(VALIDATION_FILENAMES))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:02.228767Z","iopub.execute_input":"2022-02-16T13:26:02.229146Z","iopub.status.idle":"2022-02-16T13:26:02.24633Z","shell.execute_reply.started":"2022-02-16T13:26:02.229102Z","shell.execute_reply":"2022-02-16T13:26:02.245551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if config.DEBUG:\n    TRAINING_FILENAMES = [TRAINING_FILENAMES[0]]\n    VALIDATION_FILENAMES = [VALIDATION_FILENAMES[0]]\n    print(len(TRAINING_FILENAMES),len(VALIDATION_FILENAMES),count_data_items(TRAINING_FILENAMES),count_data_items(VALIDATION_FILENAMES))\n    test_files = [test_files[0]]","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:02.247601Z","iopub.execute_input":"2022-02-16T13:26:02.248318Z","iopub.status.idle":"2022-02-16T13:26:02.260553Z","shell.execute_reply.started":"2022-02-16T13:26:02.248279Z","shell.execute_reply":"2022-02-16T13:26:02.25944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed_everything(config.SEED)\nVERBOSE = 1\ntrain_dataset = get_training_dataset(TRAINING_FILENAMES)\nval_dataset = get_val_dataset(VALIDATION_FILENAMES)\nSTEPS_PER_EPOCH = count_data_items(TRAINING_FILENAMES) // config.BATCH_SIZE\ntrain_logger = tf.keras.callbacks.CSVLogger(config.save_dir+'/training-log-fold-%i.h5.csv'%config.FOLD_TO_RUN)\n# SAVE BEST MODEL EACH FOLD        \nsv_loss = tf.keras.callbacks.ModelCheckpoint(\n    config.save_dir+f\"/{config.MODEL_NAME}_loss.h5\", monitor='val_loss', verbose=0, save_best_only=True,\n    save_weights_only=True, mode='min', save_freq='epoch')\n# BUILD MODEL\nK.clear_session()\nmodel,embed_model = get_model()\nsnap = Snapshot(fold=config.FOLD_TO_RUN,snapshot_epochs=[5,8])\nmodel.summary()\n\nif config.RESUME:   \n    model.load_weights(config.resume_model_wts)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:02.261964Z","iopub.execute_input":"2022-02-16T13:26:02.262257Z","iopub.status.idle":"2022-02-16T13:26:51.850694Z","shell.execute_reply.started":"2022-02-16T13:26:02.262225Z","shell.execute_reply":"2022-02-16T13:26:51.849653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nprint('#### Image Size %i with EfficientNet B%i and batch_size %i'%\n      (config.IMAGE_SIZE,config.EFF_NET,config.BATCH_SIZE))\n\nhistory = model.fit(train_dataset,\n                validation_data = val_dataset,\n                steps_per_epoch = STEPS_PER_EPOCH,\n                epochs = config.EPOCHS,\n                callbacks = [snap,get_lr_callback(),train_logger,sv_loss], \n                verbose = VERBOSE)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:26:51.851982Z","iopub.execute_input":"2022-02-16T13:26:51.852285Z","iopub.status.idle":"2022-02-16T13:27:17.785641Z","shell.execute_reply.started":"2022-02-16T13:26:51.852253Z","shell.execute_reply":"2022-02-16T13:27:17.783144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights(config.save_dir+f\"/{config.MODEL_NAME}_loss.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.786836Z","iopub.status.idle":"2022-02-16T13:27:17.787302Z","shell.execute_reply.started":"2022-02-16T13:27:17.787074Z","shell.execute_reply":"2022-02-16T13:27:17.787103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_ids(filename):\n    ds = get_test_dataset([filename],get_names=True).map(lambda image, image_name: image_name).unbatch()\n    NUM_IMAGES = count_data_items([filename])\n    ids = next(iter(ds.batch(NUM_IMAGES))).numpy().astype('U')\n    return ids\n\ndef get_targets(filename):\n    ds = get_eval_dataset([filename],get_targets=True).map(lambda image, target: target).unbatch()\n    NUM_IMAGES = count_data_items([filename])\n    ids = next(iter(ds.batch(NUM_IMAGES))).numpy()\n    return ids\n\ndef get_embeddings(filename):\n    ds = get_test_dataset([filename],get_names=False)\n    embeddings = embed_model.predict(ds,verbose=0)\n    return embeddings\n\ndef get_predictions(test_df,threshold=0.2):\n    predictions = {}\n    for i,row in tqdm(test_df.iterrows()):\n        if row.image in predictions:\n            if len(predictions[row.image])==5:\n                continue\n            predictions[row.image].append(row.target)\n        elif row.confidence>threshold:\n            predictions[row.image] = [row.target,'new_individual']\n        else:\n            predictions[row.image] = ['new_individual',row.target]\n\n    for x in tqdm(predictions):\n        if len(predictions[x])<5:\n            remaining = [y for y in sample_list if y not in predictions]\n            predictions[x] = predictions[x]+remaining\n            predictions[x] = predictions[x][:5]\n        \n    return predictions\n\ndef map_per_image(label, predictions):\n    \"\"\"Computes the precision score of one image.\n\n    Parameters\n    ----------\n    label : string\n            The true label of the image\n    predictions : list\n            A list of predicted elements (order does matter, 5 predictions allowed per image)\n\n    Returns\n    -------\n    score : double\n    \"\"\"    \n    try:\n        return 1 / (predictions[:5].index(label) + 1)\n    except ValueError:\n        return 0.0\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:34.294226Z","iopub.execute_input":"2022-02-16T13:27:34.294503Z","iopub.status.idle":"2022-02-16T13:27:34.311245Z","shell.execute_reply.started":"2022-02-16T13:27:34.294475Z","shell.execute_reply":"2022-02-16T13:27:34.310329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"    \n\"\"\"f = open ('../input/happywhale-splits/individual_ids.json', \"r\")\ntarget_encodings = json.loads(f.read())\ntarget_encodings = {target_encodings[x]:x for x in target_encodings}\"\"\"\ntarget_encodings = id_dict\ntarget_encodings = {target_encodings[x]:x for x in target_encodings}\nsample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888']\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:37.033148Z","iopub.execute_input":"2022-02-16T13:27:37.033672Z","iopub.status.idle":"2022-02-16T13:27:37.041675Z","shell.execute_reply.started":"2022-02-16T13:27:37.033635Z","shell.execute_reply":"2022-02-16T13:27:37.040589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_targets = []\ntrain_embeddings = []\nfor filename in tqdm(TRAINING_FILENAMES):\n    embeddings = get_embeddings(filename)\n    targets = get_targets(filename)\n    train_embeddings.append(embeddings)\n    train_targets.append(targets)\ntrain_embeddings = np.concatenate(train_embeddings)\ntrain_targets = np.concatenate(train_targets)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:38.90915Z","iopub.execute_input":"2022-02-16T13:27:38.909423Z","iopub.status.idle":"2022-02-16T13:33:34.362154Z","shell.execute_reply.started":"2022-02-16T13:27:38.909396Z","shell.execute_reply":"2022-02-16T13:33:34.361281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_targets","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:33:34.363842Z","iopub.execute_input":"2022-02-16T13:33:34.36419Z","iopub.status.idle":"2022-02-16T13:33:34.371667Z","shell.execute_reply.started":"2022-02-16T13:33:34.364147Z","shell.execute_reply":"2022-02-16T13:33:34.370671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nfrom sklearn.neighbors import NearestNeighbors\nneigh = NearestNeighbors(n_neighbors=config.KNN,metric='cosine')\nneigh.fit(train_embeddings)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.794319Z","iopub.status.idle":"2022-02-16T13:27:17.795135Z","shell.execute_reply.started":"2022-02-16T13:27:17.794812Z","shell.execute_reply":"2022-02-16T13:27:17.794842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = []\ntest_nn_distances = []\ntest_nn_idxs = []\nval_targets = []\nval_embeddings = []\nfor filename in tqdm(VALIDATION_FILENAMES):\n    embeddings = get_embeddings(filename)\n    targets = get_targets(filename)\n    ids = get_ids(filename)\n    distances,idxs = neigh.kneighbors(embeddings, config.KNN, return_distance=True)\n    test_ids.append(ids)\n    test_nn_idxs.append(idxs)\n    test_nn_distances.append(distances)\n    val_embeddings.append(embeddings)\n    val_targets.append(targets)\ntest_nn_distances = np.concatenate(test_nn_distances)\ntest_nn_idxs = np.concatenate(test_nn_idxs)\ntest_ids = np.concatenate(test_ids)\nval_embeddings = np.concatenate(val_embeddings)\nval_targets = np.concatenate(val_targets)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.796666Z","iopub.status.idle":"2022-02-16T13:27:17.797667Z","shell.execute_reply.started":"2022-02-16T13:27:17.797262Z","shell.execute_reply":"2022-02-16T13:27:17.797293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"allowed_targets = set([target_encodings[x] for x in np.unique(train_targets)])\nval_targets_df = pd.DataFrame(np.stack([test_ids,val_targets],axis=1),columns=['image','target'])\nval_targets_df['target'] = val_targets_df['target'].astype(int).map(target_encodings)\nval_targets_df.loc[~val_targets_df.target.isin(allowed_targets),'target'] = 'new_individual'\nval_targets_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.799416Z","iopub.status.idle":"2022-02-16T13:27:17.800289Z","shell.execute_reply.started":"2022-02-16T13:27:17.79996Z","shell.execute_reply":"2022-02-16T13:27:17.79999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = []\nfor i in tqdm(range(len(test_ids))):\n    id_ = test_ids[i]\n    targets = train_targets[test_nn_idxs[i]]\n    distances = test_nn_distances[i]\n    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n    subset_preds['image'] = id_\n    test_df.append(subset_preds)\ntest_df = pd.concat(test_df).reset_index(drop=True)\ntest_df['confidence'] = 1-test_df['distances']\ntest_df = test_df.groupby(['image','target']).confidence.max().reset_index()\ntest_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\ntest_df['target'] = test_df['target'].map(target_encodings)\ntest_df.to_csv('val_neighbors.csv')\ntest_df.image.value_counts().value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.801946Z","iopub.status.idle":"2022-02-16T13:27:17.802494Z","shell.execute_reply.started":"2022-02-16T13:27:17.802231Z","shell.execute_reply":"2022-02-16T13:27:17.802258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n## Compute CV\nbest_th = 0\nbest_cv = 0\nfor th in [0.1*x for x in range(11)]:\n    all_preds = get_predictions(test_df,threshold=th)\n    cv = 0\n    for i,row in val_targets_df.iterrows():\n        target = row.target\n        preds = all_preds[row.image]\n        val_targets_df.loc[i,th] = map_per_image(target,preds)\n    cv = val_targets_df[th].mean()\n    print(f\"CV at threshold {th}: {cv}\")\n    if cv>best_cv:\n        best_th = th\n        best_cv = cv\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.804941Z","iopub.status.idle":"2022-02-16T13:27:17.805747Z","shell.execute_reply.started":"2022-02-16T13:27:17.805499Z","shell.execute_reply":"2022-02-16T13:27:17.805525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Best threshold\",best_th)\nprint(\"Best cv\",best_cv)\nval_targets_df.describe()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.806894Z","iopub.status.idle":"2022-02-16T13:27:17.807668Z","shell.execute_reply.started":"2022-02-16T13:27:17.807457Z","shell.execute_reply":"2022-02-16T13:27:17.80748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Adjustment: Since Public lb has nearly 10% 'new_individual' (Be Careful for private LB)\nval_targets_df['is_new_individual'] = val_targets_df.target=='new_individual'\nprint(val_targets_df.is_new_individual.value_counts().to_dict())\nval_scores = val_targets_df.groupby('is_new_individual').mean().T\nval_scores['adjusted_cv'] = val_scores[True]*0.1+val_scores[False]*0.9\nbest_threshold_adjusted = val_scores['adjusted_cv'].idxmax()\nprint(\"best_threshold\",best_threshold_adjusted)\nval_scores","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.809157Z","iopub.status.idle":"2022-02-16T13:27:17.809503Z","shell.execute_reply.started":"2022-02-16T13:27:17.809325Z","shell.execute_reply":"2022-02-16T13:27:17.809342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ntrain_embeddings = np.concatenate([train_embeddings,val_embeddings])\ntrain_targets = np.concatenate([train_targets,val_targets])\nprint(train_embeddings.shape,train_targets.shape)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.810388Z","iopub.status.idle":"2022-02-16T13:27:17.811076Z","shell.execute_reply.started":"2022-02-16T13:27:17.810852Z","shell.execute_reply":"2022-02-16T13:27:17.810874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import NearestNeighbors\nneigh = NearestNeighbors(n_neighbors=config.KNN,metric='cosine')\nneigh.fit(train_embeddings)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.81227Z","iopub.status.idle":"2022-02-16T13:27:17.813954Z","shell.execute_reply.started":"2022-02-16T13:27:17.813639Z","shell.execute_reply":"2022-02-16T13:27:17.813673Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = []\ntest_nn_distances = []\ntest_nn_idxs = []\nfor filename in tqdm(test_files):\n    embeddings = get_embeddings(filename)\n    ids = get_ids(filename)\n    distances,idxs = neigh.kneighbors(embeddings, config.KNN, return_distance=True)\n    test_ids.append(ids)\n    test_nn_idxs.append(idxs)\n    test_nn_distances.append(distances)\ntest_nn_distances = np.concatenate(test_nn_distances)\ntest_nn_idxs = np.concatenate(test_nn_idxs)\ntest_ids = np.concatenate(test_ids)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.815875Z","iopub.status.idle":"2022-02-16T13:27:17.816446Z","shell.execute_reply.started":"2022-02-16T13:27:17.816154Z","shell.execute_reply":"2022-02-16T13:27:17.816189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/happy-whale-and-dolphin/sample_submission.csv',index_col='image')\nprint(len(test_ids),len(sample_submission))\ntest_df = []\nfor i in tqdm(range(len(test_ids))):\n    id_ = test_ids[i]\n    targets = train_targets[test_nn_idxs[i]]\n    distances = test_nn_distances[i]\n    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n    subset_preds['image'] = id_\n    test_df.append(subset_preds)\ntest_df = pd.concat(test_df).reset_index(drop=True)\ntest_df['confidence'] = 1-test_df['distances']\ntest_df = test_df.groupby(['image','target']).confidence.max().reset_index()\ntest_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\ntest_df['target'] = test_df['target'].map(target_encodings)\ntest_df.to_csv('test_neighbors.csv')\ntest_df.image.value_counts().value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.817958Z","iopub.status.idle":"2022-02-16T13:27:17.818496Z","shell.execute_reply.started":"2022-02-16T13:27:17.818214Z","shell.execute_reply":"2022-02-16T13:27:17.81824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\nsample_list = ['938b7e931166', '5bf17305f073', '7593d2aee842', '7362d7a01d00','956562ff2888']\n\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.821086Z","iopub.status.idle":"2022-02-16T13:27:17.822263Z","shell.execute_reply.started":"2022-02-16T13:27:17.821909Z","shell.execute_reply":"2022-02-16T13:27:17.821942Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = {}\nfor i,row in tqdm(test_df.iterrows()):\n    if row.image in predictions:\n        if len(predictions[row.image])==5:\n            continue\n        predictions[row.image].append(row.target)\n    elif row.confidence>best_threshold_adjusted:\n        predictions[row.image] = [row.target,'new_individual']\n    else:\n        predictions[row.image] = ['new_individual',row.target]\n        \nfor x in tqdm(predictions):\n    if len(predictions[x])<5:\n        remaining = [y for y in sample_list if y not in predictions]\n        predictions[x] = predictions[x]+remaining\n        predictions[x] = predictions[x][:5]\n    predictions[x] = ' '.join(predictions[x])\n    \npredictions = pd.Series(predictions).reset_index()\npredictions.columns = ['image','predictions']\npredictions.to_csv('submission.csv',index=False)\npredictions.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-02-16T13:27:17.823998Z","iopub.status.idle":"2022-02-16T13:27:17.825088Z","shell.execute_reply.started":"2022-02-16T13:27:17.824709Z","shell.execute_reply":"2022-02-16T13:27:17.824744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}