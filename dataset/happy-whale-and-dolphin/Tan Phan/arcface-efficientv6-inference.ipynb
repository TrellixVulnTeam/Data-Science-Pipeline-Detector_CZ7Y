{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\n!pip install -q tensorflow_addons","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:55:24.41686Z","iopub.execute_input":"2022-03-30T14:55:24.417165Z","iopub.status.idle":"2022-03-30T14:55:40.812445Z","shell.execute_reply.started":"2022-03-30T14:55:24.41713Z","shell.execute_reply":"2022-03-30T14:55:40.811595Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Introduction</p></div>\n****\nIn this kernels, \n\nEfficientV1_B6 \n\nCropped TFRecords Dataset : \nI created a [dataset](https://www.kaggle.com/datasets/phanttan/happywhale-cropped-tfrecords-v1) with notebook in here https://www.kaggle.com/code/phanttan/happywhale-cropped-tfrecords\n\nPrediction with Weighted model: https://www.kaggle.com/datasets/librauee/eff-b6-5fold","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Import</p></div>","metadata":{}},{"cell_type":"code","source":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom sklearn import metrics\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.neighbors import NearestNeighbors\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.layers import BatchNormalization, Input, GlobalAveragePooling2D, Dropout, Dense, Softmax\nfrom tensorflow.keras.losses import SparseCategoricalCrossentropy\nfrom tensorflow.keras.metrics import SparseCategoricalAccuracy, SparseTopKCategoricalAccuracy\nfrom tensorflow.keras.callbacks import LearningRateScheduler, CSVLogger, ModelCheckpoint\nfrom tensorflow.keras.utils import plot_model\nimport tensorflow_addons as tfa\nfrom tqdm.auto import tqdm\nimport matplotlib.pyplot as plt\nimport pickle\nimport json\nimport tensorflow_hub as tfhub\nfrom datetime import datetime\n\nfrom kaggle_datasets import KaggleDatasets","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-03-30T14:55:40.814061Z","iopub.execute_input":"2022-03-30T14:55:40.81433Z","iopub.status.idle":"2022-03-30T14:55:40.824197Z","shell.execute_reply.started":"2022-03-30T14:55:40.8143Z","shell.execute_reply":"2022-03-30T14:55:40.823194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"\\n... ACCELERATOR SETUP STARTING ...\\n\")\n\n# Detect hardware, return appropriate distribution strategy\ntry:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    TPU = tf.distribute.cluster_resolver.TPUClusterResolver()  \nexcept ValueError:\n    TPU = None\n\nif TPU:\n    print(f\"\\n... RUNNING ON TPU - {TPU.master()}...\")\n    tf.config.experimental_connect_to_cluster(TPU)\n    tf.tpu.experimental.initialize_tpu_system(TPU)\n    strategy = tf.distribute.experimental.TPUStrategy(TPU)\nelse:\n    print(f\"\\n... RUNNING ON CPU/GPU ...\")\n    # Yield the default distribution strategy in Tensorflow\n    #   --> Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy() \n\n# What Is a Replica?\n#    --> A single Cloud TPU device consists of FOUR chips, each of which has TWO TPU cores. \n#    --> Therefore, for efficient utilization of Cloud TPU, a program should make use of each of the EIGHT (4x2) cores. \n#    --> Each replica is essentially a copy of the training graph that is run on each core and \n#        trains a mini-batch containing 1/8th of the overall batch size\nN_REPLICAS = strategy.num_replicas_in_sync\n    \nprint(f\"... # OF REPLICAS: {N_REPLICAS} ...\\n\")\n\nAUTO = tf.data.experimental.AUTOTUNE\n\nprint(f\"\\n... ACCELERATOR SETUP COMPLTED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:55:40.825492Z","iopub.execute_input":"2022-03-30T14:55:40.825809Z","iopub.status.idle":"2022-03-30T14:55:48.284619Z","shell.execute_reply.started":"2022-03-30T14:55:40.825771Z","shell.execute_reply":"2022-03-30T14:55:48.283606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Configuration and Versions</p></div>","metadata":{}},{"cell_type":"code","source":"class config:\n    \n    SEED = 319\n    FOLD_TO_RUN = 0   # To seperate train/validation dataset\n    FOLDS = 5\n    DEBUG = False  # If True, get out some data to run model\n    EVALUATE = True\n    \n    ### Dataset\n    BATCH_SIZE = 32 * N_REPLICAS\n    IMAGE_SIZE = 768\n    N_CLASSES = 15587\n    \n    ### Model\n    EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n            efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n    EFF_NET = 6 # choose Efficient V6 \n    MODEL_NAME = \"effnetv1_b6\"\n    FREEZE_BATCH_NORM = False # Choose inference or \n    head = 'arcface' # head layer in model\n    EPOCHS = 20\n    LR = 0.001\n    message='baseline'\n    RESUME = False\n    \n    ### Augmentations\n    CUTOUT = False\n    N_CUTOUT = 6\n    ### Inference\n    KNN = 100\n    \n    ###Learning Rate Scheduler\n    RESUME_EPOCH = None\n    LR_START   = 0.000001\n    LR_MAX     = 0.000005 * BATCH_SIZE  \n    LR_MIN     = 0.000001\n    LR_RAMP_EP = 4\n    LR_SUB_EP  = 0\n    LR_DECAY  = 0.9\n    \ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) \n         for filename in filenames]\n    return np.sum(n)\n    \n# Function to seed everything\ndef seed_everything(seed):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:55:48.2877Z","iopub.execute_input":"2022-03-30T14:55:48.288004Z","iopub.status.idle":"2022-03-30T14:55:48.300207Z","shell.execute_reply.started":"2022-03-30T14:55:48.287975Z","shell.execute_reply":"2022-03-30T14:55:48.299031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n... DATA ACCESS SETUP STARTED ...\\n\")\n\nGCS_PATH = KaggleDatasets().get_gcs_path('happywhale-cropped-tfrecords-v1')\ntrain_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-train*.tfrec')))\ntest_files = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/happywhale-2022-test*.tfrec')))\n\nprint(count_data_items(train_files),count_data_items(test_files))\n    \nprint(\"\\n\\n... DATA ACCESS SETUP COMPLETED ...\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:55:48.301674Z","iopub.execute_input":"2022-03-30T14:55:48.301923Z","iopub.status.idle":"2022-03-30T14:56:00.523219Z","shell.execute_reply.started":"2022-03-30T14:55:48.301893Z","shell.execute_reply":"2022-03-30T14:56:00.522162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Version 1: [TFRecords](https://www.kaggle.com/datasets/ks2019/happywhale-tfrecords-v1) and threshold = 0.52\n### Version 2: [TFRecords](https://www.kaggle.com/datasets/ks2019/happywhale-tfrecords-v1) and threshold = 0.6\n### Version 3: [TFRecords](https://www.kaggle.com/datasets/phanttan/happywhale-cropped-tfrecords-v1) and threshold = 0.52","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">Dataset</p></div>","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:70%;text-align:left\">EXTRA DATASET</p></div>\n****\n## 1. happywhale-splits\nThis dataset is created by @ks2019 with code:\n```\ntrain_df = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\ntrain_df.species.replace({\"globis\": \"short_finned_pilot_whale\",\n                          \"pilot_whale\": \"short_finned_pilot_whale\",\n                          \"kiler_whale\": \"killer_whale\",\n                          \"bottlenose_dolpin\": \"bottlenose_dolphin\"}, inplace=True)\ntrain_df.to_csv('train_fixed.csv',index=False)\n\ntrain_df = pd.read_csv('train_fixed.csv')\ntrain_df['individual_id'] = train_df['individual_id'].map(individual_ids)\ntrain_df['species'] = train_df['species'].map(species)\nskf = StratifiedKFold(n_splits=5,random_state=123)\nfor fold,(train_index, test_index) in enumerate(skf.split(train_df, train_df.species)):\n    train_df.loc[test_index,'fold'] = fold\nprint(train_df.groupby('fold').individual_id.nunique().to_dict())\nprint(train_df.groupby('fold').species.nunique().to_dict())\nprint(train_df.groupby('fold').image.nunique().to_dict())\ntrain_df.to_csv('skf_species_5folds.csv',index=False)\n```\n## 2. happywhale-tfrecords\nThis dataset is created by @ks2019 in kernel\n\nhttps://www.kaggle.com/code/ks2019/happywhale-tfrecords/\n\n## 3. TFRecords \n\nhttps://www.kaggle.com/code/phanttan/happywhale-cropped-tfrecords\n","metadata":{}},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">HELPER FUNCTIONS</p></div>","metadata":{}},{"cell_type":"markdown","source":"## ArcFace","metadata":{}},{"cell_type":"code","source":"def arcface_format(posting_id, image, label_group, matches):\n    return posting_id, {'Input1': image, 'Input2': label_group}, label_group, matches\n\ndef arcface_inference_format(posting_id, image, label_group, matches):\n    return image,posting_id\n\ndef arcface_eval_format(posting_id, image, label_group, matches):\n    return image,label_group","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.524367Z","iopub.execute_input":"2022-03-30T14:56:00.524751Z","iopub.status.idle":"2022-03-30T14:56:00.53145Z","shell.execute_reply.started":"2022-03-30T14:56:00.524714Z","shell.execute_reply":"2022-03-30T14:56:00.530484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Augmentation ","metadata":{}},{"cell_type":"code","source":"def data_augment(posting_id, image, label_group, matches):\n    ### CUTOUT\n    if tf.random.uniform([])>0.5 and config.CUTOUT:\n        N_CUTOUT = 6\n        for cutouts in range(N_CUTOUT):\n            if tf.random.uniform([])>0.5:\n               DIM = config.IMAGE_SIZE\n               CUTOUT_LENGTH = DIM//8\n               x1 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)\n               x2 = tf.cast( tf.random.uniform([],0,DIM-CUTOUT_LENGTH),tf.int32)\n               filter_ = tf.concat([tf.zeros((x1,CUTOUT_LENGTH)),tf.ones((CUTOUT_LENGTH,CUTOUT_LENGTH)),tf.zeros((DIM-x1-CUTOUT_LENGTH,CUTOUT_LENGTH))],axis=0)\n               filter_ = tf.concat([tf.zeros((DIM,x2)),filter_,tf.zeros((DIM,DIM-x2-CUTOUT_LENGTH))],axis=1)\n               cutout = tf.reshape(1-filter_,(DIM,DIM,1))\n               image = cutout*image\n\n    image = tf.image.random_flip_left_right(image)\n    # image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_hue(image, 0.01)\n    image = tf.image.random_saturation(image, 0.70, 1.30)\n    image = tf.image.random_contrast(image, 0.80, 1.20)\n    image = tf.image.random_brightness(image, 0.10)\n    return posting_id, image, label_group, matches\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, [config.IMAGE_SIZE,config.IMAGE_SIZE])\n    image = tf.cast(image, tf.float32) / 255.0\n    return image\n\n# This function parse our images and also get the target variable\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"image\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),\n#         \"matches\": tf.io.FixedLenFeature([], tf.string)\n    }\n\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    posting_id = example['image_name']\n    image = decode_image(example['image'])\n#     label_group = tf.one_hot(tf.cast(example['label_group'], tf.int32), depth = N_CLASSES)\n    label_group = tf.cast(example['target'], tf.int32)\n#     matches = example['matches']\n    matches = 1\n    return posting_id, image, label_group, matches","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.533723Z","iopub.execute_input":"2022-03-30T14:56:00.534387Z","iopub.status.idle":"2022-03-30T14:56:00.555044Z","shell.execute_reply.started":"2022-03-30T14:56:00.534327Z","shell.execute_reply":"2022-03-30T14:56:00.554244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TF Records to Tensors Functions","metadata":{}},{"cell_type":"code","source":"def load_dataset(filenames, ordered = False):\n    \"\"\"Loading Dataset from dataset: happywhale-tfrecords-v1.\n\n    Parameters\n    ----------\n    label : string\n            The true label of the image\n    predictions : list\n            A list of predicted elements (order does matter, 5 predictions allowed per image)\n\n    Returns\n    -------\n    score : double\n    \"\"\"    \n    \n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False \n        \n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads = AUTO)\n#     dataset = dataset.cache()\n    dataset = dataset.with_options(ignore_order)\n    dataset = dataset.map(read_labeled_tfrecord, num_parallel_calls = AUTO) \n    return dataset\n\n# Get Dataset with some configurations for Training\ndef get_training_dataset(filenames):\n    dataset = load_dataset(filenames, ordered = False)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# Get Dataset with some configurations for Validation\ndef get_val_dataset(filenames):\n    dataset = load_dataset(filenames, ordered = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_format, num_parallel_calls = AUTO)\n    dataset = dataset.map(lambda posting_id, image, label_group, matches: (image, label_group))\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# This function is to get our training tensors\ndef get_eval_dataset(filenames, get_targets = True):\n    dataset = load_dataset(filenames, ordered = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_eval_format, num_parallel_calls = AUTO)\n    if not get_targets:\n        dataset = dataset.map(lambda image, target: image)\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n# Get Dataset with some configurations for Prediction\ndef get_test_dataset(filenames, get_names = True):\n    dataset = load_dataset(filenames, ordered = True)\n    dataset = dataset.map(data_augment, num_parallel_calls = AUTO)\n    dataset = dataset.map(arcface_inference_format, num_parallel_calls = AUTO)\n    if not get_names:\n        dataset = dataset.map(lambda image, posting_id: image)\n    dataset = dataset.batch(config.BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.556858Z","iopub.execute_input":"2022-03-30T14:56:00.557372Z","iopub.status.idle":"2022-03-30T14:56:00.577182Z","shell.execute_reply.started":"2022-03-30T14:56:00.557331Z","shell.execute_reply":"2022-03-30T14:56:00.57643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Arcmarginproduct class keras layer\nclass ArcMarginProduct(tf.keras.layers.Layer):\n    '''\n    Implements large margin arc distance.\n\n    Reference:\n        https://arxiv.org/pdf/1801.07698.pdf\n        https://github.com/lyakaap/Landmark2019-1st-and-3rd-Place-Solution/\n            blob/master/src/modeling/metric_learning.py\n    '''\n    def __init__(self, n_classes, s=30, m=0.50, easy_margin=False,\n                 ls_eps=0.0, **kwargs):\n\n        super(ArcMarginProduct, self).__init__(**kwargs)\n\n        self.n_classes = n_classes\n        self.s = s\n        self.m = m\n        self.ls_eps = ls_eps\n        self.easy_margin = easy_margin\n        self.cos_m = tf.math.cos(m)\n        self.sin_m = tf.math.sin(m)\n        self.th = tf.math.cos(math.pi - m)\n        self.mm = tf.math.sin(math.pi - m) * m\n\n    def get_config(self):\n        config = super().get_config().copy()\n        config.update({\n            'n_classes': self.n_classes,\n            's': self.s,\n            'm': self.m,\n            'ls_eps': self.ls_eps,\n            'easy_margin': self.easy_margin,\n        })\n        return config\n\n    def build(self, input_shape):\n        super(ArcMarginProduct, self).build(input_shape[0])\n        self.W = self.add_weight(\n            name='W',\n            shape=(int(input_shape[0][-1]), self.n_classes),\n            initializer='glorot_uniform',\n            dtype='float32',\n            trainable=True,\n            regularizer=None)\n\n    def call(self, inputs):\n        X, y = inputs\n        y = tf.cast(y, dtype=tf.int32)\n        cosine = tf.matmul(\n            tf.math.l2_normalize(X, axis=1),\n            tf.math.l2_normalize(self.W, axis=0)\n        )\n        sine = tf.math.sqrt(1.0 - tf.math.pow(cosine, 2))\n        phi = cosine * self.cos_m - sine * self.sin_m\n        if self.easy_margin:\n            phi = tf.where(cosine > 0, phi, cosine)\n        else:\n            phi = tf.where(cosine > self.th, phi, cosine - self.mm)\n        one_hot = tf.cast(\n            tf.one_hot(y, depth=self.n_classes),\n            dtype=cosine.dtype\n        )\n        if self.ls_eps > 0:\n            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.n_classes\n\n        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n        output *= self.s\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.578576Z","iopub.execute_input":"2022-03-30T14:56:00.579198Z","iopub.status.idle":"2022-03-30T14:56:00.597451Z","shell.execute_reply.started":"2022-03-30T14:56:00.579152Z","shell.execute_reply":"2022-03-30T14:56:00.596544Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# BatchNormalization Mode Function\ndef freeze_BatchNorm(model):\n    # Unfreeze all Layers except for Batch Norm\n    for layer in model.layers:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = True \n        else:\n            layer.trainable = False # in inference mode\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.600139Z","iopub.execute_input":"2022-03-30T14:56:00.600672Z","iopub.status.idle":"2022-03-30T14:56:00.615382Z","shell.execute_reply.started":"2022-03-30T14:56:00.600634Z","shell.execute_reply":"2022-03-30T14:56:00.614659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## For Evaluation ","metadata":{}},{"cell_type":"code","source":"## Find the name of image in each filename. Exp : 00021adfb725ed.jpg \ndef get_id(filename):\n    ds = get_test_dataset([filename],get_names=True).map(lambda image, image_name: image_name).unbatch()\n    NUM_IMAGES = count_data_items([filename])\n    ids = next(iter(ds.batch(NUM_IMAGES))).numpy().astype('U')\n    return ids\n## Find the Target Encoding (defined in happywhale-splits/individual_ids.json)\ndef get_target(filename):\n    ds = get_eval_dataset([filename],get_targets=True).map(lambda image, target: target).unbatch()\n    NUM_IMAGES = count_data_items([filename])\n    ids = next(iter(ds.batch(NUM_IMAGES))).numpy()\n    return ids\n## Find the average of predictions in the best 5-model in data : eff-b6-5fold \ndef get_embedding(filename):\n    ds = get_test_dataset([filename],get_names=False)\n    embedding = np.mean(np.stack([embed_models[x][1].predict(ds,verbose=0) for x in range(len(embed_models))]), axis=0)\n    return embedding\n\ndef get_prediction(test_df,threshold=0.2):\n    predictions = {}\n    for i,row in tqdm(test_df.iterrows()):\n        if row.image in predictions:\n            if len(predictions[row.image])==5:\n                continue\n            predictions[row.image].append(row.target)\n        elif row.confidence>threshold:\n            predictions[row.image] = [row.target,'new_individual']\n        else:\n            predictions[row.image] = ['new_individual',row.target]\n\n    return predictions\n\ndef map_per_image(label, predictions):\n    \"\"\"Computes the precision score of one image.\n\n    Parameters\n    ----------\n    label : string\n            The true label of the image\n    predictions : list\n            A list of predicted elements (order does matter, 5 predictions allowed per image)\n\n    Returns\n    -------\n    score : double\n    \"\"\"    \n    try:\n        return 1 / (predictions[:5].index(label) + 1)\n    except ValueError:\n        return 0.0","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.616654Z","iopub.execute_input":"2022-03-30T14:56:00.617007Z","iopub.status.idle":"2022-03-30T14:56:00.63181Z","shell.execute_reply.started":"2022-03-30T14:56:00.61698Z","shell.execute_reply":"2022-03-30T14:56:00.630753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">BUILD MODEL</p></div>","metadata":{}},{"cell_type":"code","source":"# Create EfficientNetB6 Model\ndef create_model():\n    if config.head == \"arcface\":\n        head = ArcMarginProduct\n    else:\n        assert 2021==2022 , \"INVALID HEAD IN MODEL\"\n        \n    with strategy.scope():\n        margin = head(n_classes=config.N_CLASSES, \n                      s=30, \n                      m=0.3, \n                      name=f'head/{config.head}', \n                      dtype='float32'\n                     )\n        # Define Input\n        inp = Input(shape=[config.IMAGE_SIZE, config.IMAGE_SIZE, 3], name='Input1')\n        label = Input(shape=(), name='Input2')\n        x = config.EFNS[config.EFF_NET](weights=\"noisy-student\", include_top=False)(inp)\n        embed = GlobalAveragePooling2D()(x)\n        embed = Dropout(0.2)(embed)\n        embed = Dense(512)(embed)\n        x = margin([embed, label])\n        # Define Output\n        output = Softmax(dtype='float32')(x)\n        # Create model to Training\n        model = tf.keras.models.Model(inputs=[inp, label], outputs=[output])\n        # Create embed_model to Prediction (Inference) \n        embed_model = tf.keras.models.Model(inputs=inp, outputs=embed)\n        # Use Adam Optimization\n        opt = tf.keras.optimizers.Adam(learning_rate=config.LR)\n        \n        if config.FREEZE_BATCH_NORM:\n            freeze_BN(model)\n            \n        model.compile(optimizer=opt, \n                      loss=[SparseCategoricalCrossentropy()], \n                      metrics=[SparseCategoricalAccuracy(), SparseTopKCategoricalAccuracy(k=5)])\n        return model,embed_model","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.632928Z","iopub.execute_input":"2022-03-30T14:56:00.63358Z","iopub.status.idle":"2022-03-30T14:56:00.648924Z","shell.execute_reply.started":"2022-03-30T14:56:00.633545Z","shell.execute_reply":"2022-03-30T14:56:00.648116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_callbacks(plot=False):\n    # Learning Rate Scheduler function\n    def lr_fnc(epoch):\n        if config.RESUME:\n            epoch = epoch + config.RESUME_EPOCH\n        if epoch < config.LR_RAMP_EP: \n            # Linear\n            lr = (config.LR_MAX - config.LR_START)/config.LR_RAMP_EP*epoch + config.LR_START\n        elif epoch < config.LR_RAMP_EP + config.LR_SUB_EP:\n            lr = config.LR_MAX\n        else:\n            # Exponential\n            lr = (config.LR_MAX - config.LR_MIN)*config.LR_DECAY**(epoch - config.LR_RAMP_EP - config.LR_SUB_EP) + config.LR_MIN\n        return lr\n    \n    # Display the Learning Rate Scheduler\n    if plot:\n        lr_list = [lr_fnc(x) for x in list(range(config.EPOCHS))]\n        plt.scatter(range(config.EPOCHS), lr_list)\n        plt.show()\n    lr_callback = LearningRateScheduler(lr_fnc, verbose=False)\n    return lr_callback","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.650084Z","iopub.execute_input":"2022-03-30T14:56:00.650444Z","iopub.status.idle":"2022-03-30T14:56:00.666795Z","shell.execute_reply.started":"2022-03-30T14:56:00.650417Z","shell.execute_reply":"2022-03-30T14:56:00.665841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Snapshot(tf.keras.callbacks.Callback):\n    \n    def __init__(self,fold,snapshot_epochs=[]):\n        super(Snapshot, self).__init__()\n        self.snapshot_epochs = snapshot_epochs\n        self.fold = fold\n        \n        \n    def on_epoch_end(self, epoch, logs=None):\n        if epoch in self.snapshot_epochs: # your custom condition         \n            self.model.save_weights(f\"./EF{config.MODEL_NAME}_epoch{epoch}.h5\")\n        self.model.save_weights(f\"./{config.MODEL_NAME}_last.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.668219Z","iopub.execute_input":"2022-03-30T14:56:00.668466Z","iopub.status.idle":"2022-03-30T14:56:00.685374Z","shell.execute_reply.started":"2022-03-30T14:56:00.668437Z","shell.execute_reply":"2022-03-30T14:56:00.683822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TRAINING","metadata":{}},{"cell_type":"code","source":"training_filenames = [x for i,x in enumerate(train_files) if i%config.FOLDS!=config.FOLD_TO_RUN]\nvalidation_filenames = [x for i,x in enumerate(train_files) if i%config.FOLDS==config.FOLD_TO_RUN]\nprint(len(training_filenames),len(validation_filenames))\ndel train_files","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.686952Z","iopub.execute_input":"2022-03-30T14:56:00.687588Z","iopub.status.idle":"2022-03-30T14:56:00.700772Z","shell.execute_reply.started":"2022-03-30T14:56:00.687538Z","shell.execute_reply":"2022-03-30T14:56:00.699916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Callbacks","metadata":{}},{"cell_type":"code","source":"seed_everything(config.SEED)\ntrain_dataset = get_training_dataset(training_filenames)\nval_dataset = get_training_dataset(validation_filenames)\nSTEPS_PER_EPOCH = count_data_items(training_filenames)//config.BATCH_SIZE\n\n## Logging\ntrain_logger = CSVLogger('./training-log-fold-%i.h5.csv'%config.FOLD_TO_RUN)\n\n# SAVE BEST MODEL EACH FOLD\nsv_loss = ModelCheckpoint(f\"./{config.MODEL_NAME}_loss_{config.FOLD_TO_RUN}.h5\", \n                          monitor='val_loss', \n                          verbose=0, \n                          save_best_only=True, \n                          save_weight_only=True, mode='min', save_freq='epoch')\n# Snapshot\nsnap = Snapshot(fold=config.FOLD_TO_RUN,snapshot_epochs=[5,8])\n# Learning Rate Scheduler\nget_lr_callbacks(plot=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:00.702103Z","iopub.execute_input":"2022-03-30T14:56:00.702354Z","iopub.status.idle":"2022-03-30T14:56:02.368937Z","shell.execute_reply.started":"2022-03-30T14:56:00.702327Z","shell.execute_reply":"2022-03-30T14:56:02.368002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Build Model\nK.clear_session()\nmodel, embed_model = create_model()\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:02.370264Z","iopub.execute_input":"2022-03-30T14:56:02.370854Z","iopub.status.idle":"2022-03-30T14:56:51.293176Z","shell.execute_reply.started":"2022-03-30T14:56:02.370817Z","shell.execute_reply":"2022-03-30T14:56:51.292051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embed_model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:51.295113Z","iopub.execute_input":"2022-03-30T14:56:51.295372Z","iopub.status.idle":"2022-03-30T14:56:51.352125Z","shell.execute_reply.started":"2022-03-30T14:56:51.295344Z","shell.execute_reply":"2022-03-30T14:56:51.351392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"--- Size Image %i with EfficientNet B%i and Batchsize %i ---\"%(config.IMAGE_SIZE, config.EFF_NET, config.BATCH_SIZE))\n####-------------In the last, we trained model and save the log data in Server---------- ###\n# history = model.fit(train_dataset, \n#                     validation_data=val_dataset, \n#                     steps_per_epoch=STEPS_PER_EPOCH, \n#                     epochs=config.EPOCHS, \n#                     callbacks=[snap,get_lr_callbacks(), train_logger, sv_loss], \n#                     verbose=1)\n###-------------Loading the previous results----------------###\nembed_models = []\nfor i in range(5):\n    model, embed_model = create_model()\n    embed_models.append((model.load_weights(f\"../input/eff-b6-5fold/effnetv1_b6_loss_{i}.h5\"),embed_model))","metadata":{"execution":{"iopub.status.busy":"2022-03-30T14:56:51.353269Z","iopub.execute_input":"2022-03-30T14:56:51.353499Z","iopub.status.idle":"2022-03-30T15:01:25.066254Z","shell.execute_reply.started":"2022-03-30T14:56:51.353475Z","shell.execute_reply":"2022-03-30T15:01:25.06505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(model)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:25.068262Z","iopub.execute_input":"2022-03-30T15:01:25.06858Z","iopub.status.idle":"2022-03-30T15:01:26.433608Z","shell.execute_reply.started":"2022-03-30T15:01:25.068539Z","shell.execute_reply":"2022-03-30T15:01:26.432579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_model(embed_model)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:26.435776Z","iopub.execute_input":"2022-03-30T15:01:26.436331Z","iopub.status.idle":"2022-03-30T15:01:26.579228Z","shell.execute_reply.started":"2022-03-30T15:01:26.436283Z","shell.execute_reply":"2022-03-30T15:01:26.578147Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"f = open ('../input/happywhale-splits/individual_ids.json', \"r\")\ntarget_encodings = json.loads(f.read())\ntarget_encodings = {target_encodings[x]:x for x in target_encodings}","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:26.581042Z","iopub.execute_input":"2022-03-30T15:01:26.581306Z","iopub.status.idle":"2022-03-30T15:01:26.612706Z","shell.execute_reply.started":"2022-03-30T15:01:26.581276Z","shell.execute_reply":"2022-03-30T15:01:26.611812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prediction from emdedding model\ntrain_embeddings = []\ntrain_targets = []\nfor file in tqdm(training_filenames):\n    train_embeddings.append(get_embedding(file))\n    train_targets.append(get_target(file))\n# Change dtype/shape of data \ntrain_embeddings = np.concatenate(train_embeddings)\ntrain_targets = np.concatenate(train_targets)","metadata":{"execution":{"iopub.status.busy":"2022-03-30T15:01:26.613861Z","iopub.execute_input":"2022-03-30T15:01:26.614108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">KNN</p></div>","metadata":{}},{"cell_type":"code","source":"# Using KNN with Train Dataset to predict the target in Valid Dataset\nneigh = NearestNeighbors(n_neighbors=config.KNN, metric='cosine')\nneigh.fit(train_embeddings)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_ids = []\nval_knn_distances = []\nval_knn_idxs = []\nval_targets = []\nval_embeddings = []\nfor file in tqdm(validation_filenames):\n    embedding = get_embedding(file)\n    distances,idxs = neigh.kneighbors(embedding, config.KNN, return_distance=True)\n    val_knn_idxs.append(idxs)\n    val_knn_distances.append(distances)\n    val_ids.append(get_id(file))\n    val_embeddings.append(get_embedding(file))\n    val_targets.append(get_target(file))\nval_knn_distances = np.concatenate(val_knn_distances)\nval_knn_idxs = np.concatenate(val_knn_idxs)\nval_ids = np.concatenate(val_ids)\nval_embeddings = np.concatenate(val_embeddings)\nval_targets = np.concatenate(val_targets)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set label for new Individual target\nexist_targets = set([target_encodings[x] for x in np.unique(train_targets)])\nval_targets_df = pd.DataFrame(np.stack([val_ids, val_targets], axis=1), columns=['image','target'])\nval_targets_df['target'] = val_targets_df['target'].astype(int).map(target_encodings)\nval_targets_df.loc[~val_targets_df.target.isin(exist_targets),'target'] = 'new_individual'\nval_targets_df.target.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"val_df = []\nfor i in tqdm(range(len(val_ids))):\n    id_ = val_ids[i]\n    targets = train_targets[val_knn_idxs[i]]\n    distances = val_knn_distances[i]\n    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n    subset_preds['image'] = id_\n    val_df.append(subset_preds)\nval_df = pd.concat(val_df).reset_index(drop=True)\n# Create Confidence columns to pick up Top individual_id based on max confidence\nval_df['confidence'] = 1- val_df['distances']\nval_df = val_df.groupby(['image','target']).confidence.max().reset_index()\nval_df = val_df.sort_values('confidence',ascending=False).reset_index(drop=True)\nval_df['target'] = val_df['target'].map(target_encodings)\nval_df.to_csv('val_neighbors.csv')\nval_df.image.value_counts().value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">PREDICTION</p></div>","metadata":{}},{"cell_type":"code","source":"train_embeddings_infer = np.concatenate([train_embeddings,val_embeddings])\ntrain_targets_infer = np.concatenate([train_targets,val_targets])\nprint(train_embeddings_infer.shape,train_targets_infer.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# KNN\nneigh = NearestNeighbors(n_neighbors=config.KNN,metric='cosine')\nneigh.fit(train_embeddings_infer)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_ids = []\ntest_knn_distances = []\ntest_knn_idxs = []\nfor file in tqdm(test_files):\n    embeddings = get_embedding(file)\n    distances,idxs = neigh.kneighbors(embeddings, config.KNN, return_distance=True)\n    test_ids.append(get_id(file))\n    test_knn_idxs.append(idxs)\n    test_knn_distances.append(distances)\ntest_knn_distances = np.concatenate(test_knn_distances)\ntest_knn_idxs = np.concatenate(test_knn_idxs)\ntest_ids = np.concatenate(test_ids)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/happy-whale-and-dolphin/sample_submission.csv',index_col='image')\nprint(len(test_ids),len(sample_submission))\ntest_df = []\nfor i in tqdm(range(len(test_ids))):\n    id_ = test_ids[i]\n    targets = train_targets_infer[test_knn_idxs[i]]\n    distances = test_knn_distances[i]\n    subset_preds = pd.DataFrame(np.stack([targets,distances],axis=1),columns=['target','distances'])\n    subset_preds['image'] = id_\n    test_df.append(subset_preds)\ntest_df = pd.concat(test_df).reset_index(drop=True)\ntest_df['confidence'] = 1 - test_df['distances']\ntest_df = test_df.groupby(['image','target']).confidence.max().reset_index()\ntest_df = test_df.sort_values('confidence',ascending=False).reset_index(drop=True)\ntest_df['target'] = test_df['target'].map(target_encodings)\ntest_df.to_csv('test_neighbors.csv')\ntest_df.image.value_counts().value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# <div style=\"color:white;display:fill;border-radius:5px;background-color:#75B7BF;letter-spacing:0.1px;overflow:hidden\"><p style=\"padding:20px;color:white;overflow:hidden;margin:0;font-size:100%;text-align:center\">SUBMISSION</p></div>","metadata":{}},{"cell_type":"code","source":"best_threshold_adjusted = 0.52\npredictions = {}\nfor i,row in tqdm(test_df.iterrows()):\n    if row.image in predictions:\n        if len(predictions[row.image])==5:\n            continue\n        predictions[row.image].append(row.target)\n    elif row.confidence>best_threshold_adjusted:\n        predictions[row.image] = [row.target,'new_individual']\n    else:\n        predictions[row.image] = ['new_individual',row.target]\n        \nfor x in tqdm(predictions):\n    predictions[x] = ' '.join(predictions[x])\n    \npredictions = pd.Series(predictions).reset_index()\npredictions.columns = ['image','predictions']\npredictions.to_csv('submission.csv',index=False)\npredictions.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}