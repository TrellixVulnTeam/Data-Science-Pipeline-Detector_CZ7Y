{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [Happywhale - Whale and Dolphin Identification](https://www.kaggle.com/c/happy-whale-and-dolphin)\n> Identify whales üê≥ and dolphins üê¨ by unique characteristic\n\n<h4> Hi There</h4>\n<p>In this notebook I have analyzed and explored the dataset, fixing some of the problems and implemented some image augmentation techniques. I will continue to update this. I hope you will find this notebook useful. If you do please support with an upvote.<p>","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://i.imgur.com/VWojFpo.png\">","metadata":{}},{"cell_type":"markdown","source":"## Notebook Contents\n1. [Introduction](#introduction)\n2. [Submission Format](#submission-format)\n3. [Evaluation Metric Explained](#evaluation-metric-explained)\n4. [Loading Dataset](#loading-dataset)\n5. [Data Cleaning](#data-cleaning)\n6. [Dataset Visualization](#visualization)<br/>\n     6.1 [Visualize Train and Test Images](#visualization)<br/>\n     6.2 [Visualize Class Distribution](#class-distribution-analysis)<br/>\n     6.3 [Observations](#observation-regarding-class-distribution)<br/>\n7. [Getting Image Resolutions](#image-resolutions)\n8. [Color Analysis](#color-analysis)<br/>\n    8.1 [Check Gray Scale Images](#color-analysis)<br/>\n    8.2 [Visualize Mean Intensity for RGB Channels](#get-mean-intensity-for-each-channel-RGB)<br/>\n    8.3 [Observations](#observation-regarding-color-distribution)<br/>\n9. [Data Augmentation](#data-augmentation)\n10. [Preprocessing Dataset](#preprocessing)\n\n<br>\n\n<a id=\"introduction\"></a>\n# Introduction\nThis training data contains thousands of images of whales and dolphins. Individual whales and dolphins have been identified by researchers and given an `Id`. The challenge is to predict the `Id` of images in the test set by unique‚Äîbut often subtle‚Äîcharacteristics of their natural markings. The best submissions will suggest photo-`Id` solutions that are fast and accurate.\n\n<br>\n\n### If you find this notebook useful,  <font color='red'>please support with an upvote</font> üôè","metadata":{}},{"cell_type":"markdown","source":"# Importing Libraries","metadata":{}},{"cell_type":"code","source":"import os\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\n\nfrom keras import layers\nfrom keras.models import Sequential\nfrom keras.preprocessing import image\nfrom keras.layers import Input, Dense, Activation, Dropout\nfrom keras.layers import Flatten, BatchNormalization, Conv2D\nfrom keras.layers import MaxPooling2D, AveragePooling2D\nfrom keras.applications.imagenet_utils import preprocess_input\n\nfrom PIL import Image\nfrom tqdm import tqdm\nimport random as rnd\nimport cv2\n\n!pip install livelossplot\nfrom livelossplot import PlotLossesKeras\n\n%matplotlib inline","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-06T00:34:09.190616Z","iopub.execute_input":"2022-03-06T00:34:09.190982Z","iopub.status.idle":"2022-03-06T00:34:27.63129Z","shell.execute_reply.started":"2022-03-06T00:34:09.190883Z","shell.execute_reply":"2022-03-06T00:34:27.630418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"submission-format\"></a>\n# Submission Format\n\n### We need to predict 5 labels for each of the image.\nFor each image in the test set, we can predict up to 5 individual_id labels. There are individuals in the test set that are not seen in the training data; these should be predicted as new_individual. The file should contain a header and have the following format:\n\n```\nimage,predictions \n000188a72f2562.jpg,37c7aba965a5 114207cab555 a6e325d8e924 19fbb960f07d new_individual \n000ba09273d6f3.jpg,37c7aba965a5 114207cab555 a6e325d8e924 19fbb960f07d new_individual \n...\n```","metadata":{}},{"cell_type":"markdown","source":"<br>\n\n<a id=\"evaluation-metric-explained\"></a>\n# Evaluation Metric Explained\n\nThe evaluation metric in the competition's description is Mean Average Precision @ 5 (MAP@5):\n$$MAP@5 = {1 \\over U} \\sum_{u=1}^{U} \\sum_{k=1}^{min(n,5)}P(k)  √ó rel(k)$$\n\nwhere `U` is the number of images, `P(k)` is the precision at cutoff `k`, rel(k)  is an indicator function equaling 1 if the item at rank k is a relevant (correct) label, zero otherwise and `n` is the number of predictions per image.\n\n> the calculation would stop after the first occurrence of the correct whale, so `P(1) = 1`. So, a prediction that is `correct` `incorrect` `incorrect` `incorrect` `incorrect` also scores `1`.\n\nSo we don't have to sum up to 5, only up to the first correct answer. In this competition there is only one correct (`TP`) answer per image, so the possible precision scores per image are either `0` or `P(k)=1/k`.\n\n| true  | predicted   | k  | Image score |\n|:-:|:-:|:-:|:-:|:-:|\n| [x]  | [x, ?, ?, ?, ?]   | 1  | 1.0  |\n| [x]  | [?, x, ?, ?, ?]   | 2  | 0 + 1/2 = 0.5 |\n| [x]  | [?, ?, x, ?, ?]   | 3  | 0/1 + 0/2 + 1/3  = 0.33 |\n| [x]  | [?, ?, ?, x, ?]   | 4  | 0/1 + 0/2 + 0/3 + 1/4  = 0.25 |\n| [x]  | [?, ?, ?, ?, x]   | 5  | 0/1 + 0/2 + 0/3 + 0/4 + 1/5  = 0.2 |\n| [x]  | [?, ?, ?, ?, ?]   | 5  | 0/1 + 0/2 + 0/3 + 0/4 + 0/5  = 0.0 |\n\nwhere `x` is the correct and `?` is incorrect prediction. \n\n### The final score is simply the average over the scores of the images.","metadata":{}},{"cell_type":"markdown","source":"<br>\n\n<a id=\"loading-dataset\"></a>\n# Loading Dataset\nWe'll use here the [Pandas](https://pandas.pydata.org/pandas-docs/stable/) to load the dataset into memory","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv('../input/happy-whale-and-dolphin/train.csv')\ntrain_df['path'] = '../input/happy-whale-and-dolphin/train_images/' + train_df['image']\n\npred_df = pd.read_csv('../input/happy-whale-and-dolphin/sample_submission.csv')\npred_df['path'] = '../input/happy-whale-and-dolphin/test_images/' + pred_df['image']","metadata":{"execution":{"iopub.status.busy":"2022-03-06T00:34:27.633173Z","iopub.execute_input":"2022-03-06T00:34:27.633407Z","iopub.status.idle":"2022-03-06T00:34:27.815891Z","shell.execute_reply.started":"2022-03-06T00:34:27.633379Z","shell.execute_reply":"2022-03-06T00:34:27.815133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Having two csv files\n* train.csv - contain image name,species and individual_id\n*  sample_submission.csv - contain image name, dummy label for the images in the test folder\n\n#### And two folders contain the images\n* train - having 51033 images of different type of whales and dolphins. There Labels have provided in the train.csv file\n* test - having 27956 images of different type of whales and dolphins. We need to predict their labels","metadata":{}},{"cell_type":"code","source":"train_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:01:18.805278Z","iopub.execute_input":"2022-02-18T17:01:18.805624Z","iopub.status.idle":"2022-02-18T17:01:18.824788Z","shell.execute_reply.started":"2022-02-18T17:01:18.80558Z","shell.execute_reply":"2022-02-18T17:01:18.823992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Train samples count: ', len(train_df))\ntrain_df.columns","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:01:18.826264Z","iopub.execute_input":"2022-02-18T17:01:18.826504Z","iopub.status.idle":"2022-02-18T17:01:18.833743Z","shell.execute_reply.started":"2022-02-18T17:01:18.826453Z","shell.execute_reply":"2022-02-18T17:01:18.833014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Species Count: ',len(train_df['species'].value_counts()))\ntrain_df['species'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:01:18.835923Z","iopub.execute_input":"2022-02-18T17:01:18.836383Z","iopub.status.idle":"2022-02-18T17:01:18.856722Z","shell.execute_reply.started":"2022-02-18T17:01:18.836352Z","shell.execute_reply":"2022-02-18T17:01:18.856035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"data-cleaning\"></a>\n# Data Cleaning\n### Fixing Duplicate Labels\n* `bottlenose_dolpin` -> `bottlenose_dolphin`\n* `kiler_whale` -> `killer_whale`\n* `beluga` -> `beluga_whale`\n\n### Changing Label due to extreme similarities\n* `globis` & `pilot_whale` -> `short_finned_pilot_whale`","metadata":{}},{"cell_type":"code","source":"print('Before fixing duplicate labels : ')\nprint(\"Number of unique species : \", train_df['species'].nunique())\n\ntrain_df['species'].replace({\n    'bottlenose_dolpin' : 'bottlenose_dolphin',\n    'kiler_whale' : 'killer_whale',\n    'beluga' : 'beluga_whale',\n    'globis' : 'short_finned_pilot_whale',\n    'pilot_whale' : 'short_finned_pilot_whale'\n},inplace =True)\n\nprint('\\nAfter fixing duplicate labels : ')\nprint(\"Number of unique species : \", train_df['species'].nunique())\n\n\ntrain_df['class'] = train_df['species'].apply(lambda x: x.split('_')[-1])\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T00:34:27.817312Z","iopub.execute_input":"2022-03-06T00:34:27.817848Z","iopub.status.idle":"2022-03-06T00:34:27.896508Z","shell.execute_reply.started":"2022-03-06T00:34:27.817813Z","shell.execute_reply":"2022-03-06T00:34:27.895685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Checking missing data\nLets check if there is any missing values in our dataset","metadata":{}},{"cell_type":"code","source":"train_df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:01:18.918009Z","iopub.execute_input":"2022-02-18T17:01:18.918426Z","iopub.status.idle":"2022-02-18T17:01:18.950069Z","shell.execute_reply.started":"2022-02-18T17:01:18.918378Z","shell.execute_reply":"2022-02-18T17:01:18.948859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check for missing image\nNow lets see if there is any missing image","metadata":{}},{"cell_type":"code","source":"len(os.listdir('../input/happy-whale-and-dolphin/train_images'))","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:01:18.952028Z","iopub.execute_input":"2022-02-18T17:01:18.952393Z","iopub.status.idle":"2022-02-18T17:01:19.689139Z","shell.execute_reply.started":"2022-02-18T17:01:18.952343Z","shell.execute_reply":"2022-02-18T17:01:19.688372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"visualization\"></a>\n# Visualization\n### Looking at some random beauties  <a class=\"anchor\" id=\"third-bullet\"></a>\nIt's a great deal of fun to explore the data and play around with *matplotlib*\n\n```\nThe below code does not work some time. If you get any error run the cell again. If you found the bug please let me know in the comments.\n```","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (15,12))\nfor idx,i in enumerate(train_df.species.unique()):\n    plt.subplot(4,7,idx+1)\n    df = train_df[train_df['species'] ==i].reset_index(drop = True)\n    image_path = df.loc[rnd.randint(0, len(df))-1,'path']\n    img = Image.open(image_path)\n    img = img.resize((224,224))\n    plt.imshow(img)\n    plt.axis('off')\n    plt.title(i)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:01:19.690552Z","iopub.execute_input":"2022-02-18T17:01:19.691132Z","iopub.status.idle":"2022-02-18T17:01:25.785852Z","shell.execute_reply.started":"2022-02-18T17:01:19.691088Z","shell.execute_reply":"2022-02-18T17:01:25.784814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_species(df,species_name):\n    plt.figure(figsize = (12,12))\n    species_df = df[df['species'] ==species_name].reset_index(drop = True)\n    plt.suptitle(species_name)\n    for idx,i in enumerate(np.random.choice(species_df['path'],32)):\n        plt.subplot(8,8,idx+1)\n        image_path = i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:39:04.83769Z","iopub.execute_input":"2022-02-18T16:39:04.838201Z","iopub.status.idle":"2022-02-18T16:39:04.848211Z","shell.execute_reply.started":"2022-02-18T16:39:04.838161Z","shell.execute_reply":"2022-02-18T16:39:04.847081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plotting more images from each species","metadata":{}},{"cell_type":"code","source":"for species in train_df['species'].unique():\n    #print('\\n\\n')\n    plot_species(train_df , species)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:39:04.849922Z","iopub.execute_input":"2022-02-18T16:39:04.850825Z","iopub.status.idle":"2022-02-18T16:41:28.828882Z","shell.execute_reply.started":"2022-02-18T16:39:04.850773Z","shell.execute_reply":"2022-02-18T16:41:28.827942Z"},"_kg_hide-output":false,"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets see some image by individual_id\n\nWe have to predict individual_id from image. So lets see how each individual looks like.","metadata":{}},{"cell_type":"code","source":"def plot_individual(df,individual_id):\n    plt.figure(figsize = (12,12))\n    species_df = df[df['individual_id'] ==individual_id].reset_index(drop = True)\n    plt.suptitle(individual_id)\n    for idx,i in enumerate(np.random.choice(species_df['path'],24)):\n        plt.subplot(8,8,idx+1)\n        image_path = i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T15:56:21.215221Z","iopub.execute_input":"2022-03-05T15:56:21.215485Z","iopub.status.idle":"2022-03-05T15:56:21.225271Z","shell.execute_reply.started":"2022-03-05T15:56:21.215457Z","shell.execute_reply":"2022-03-05T15:56:21.224435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Top 5 most frequent individual","metadata":{}},{"cell_type":"code","source":"top_5_ids = train_df.individual_id.value_counts().head(5)\nfor i in top_5_ids.index:\n    #print('\\n\\n')\n    plot_individual(train_df , i)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:41:28.839135Z","iopub.execute_input":"2022-02-18T16:41:28.839413Z","iopub.status.idle":"2022-02-18T16:42:00.365643Z","shell.execute_reply.started":"2022-02-18T16:41:28.839379Z","shell.execute_reply":"2022-02-18T16:42:00.364536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Top 5 least frequent individual\n\nWe will get duplicate images because many individual has only one training image.","metadata":{}},{"cell_type":"code","source":"last_5_ids = train_df.individual_id.value_counts().tail(5)\nfor i in last_5_ids.index:\n    #print('\\n\\n')\n    plot_individual(train_df , i)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:42:00.369003Z","iopub.execute_input":"2022-02-18T16:42:00.369271Z","iopub.status.idle":"2022-02-18T16:42:19.884373Z","shell.execute_reply.started":"2022-02-18T16:42:00.369236Z","shell.execute_reply":"2022-02-18T16:42:19.883309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets see some test images","metadata":{}},{"cell_type":"code","source":"t_df = pd.read_csv('../input/happy-whale-and-dolphin/sample_submission.csv')\nt_df['path'] = '../input/happy-whale-and-dolphin/test_images/' + t_df['image']\n\ndef plot_testimages(df):\n    plt.figure(figsize = (12,12))\n    plt.suptitle('Test Images')\n    for idx,i in enumerate(np.random.choice(df['path'],48)):\n        plt.subplot(8,8,idx+1)\n        image_path = i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n\nplot_testimages(t_df)\ndel t_df","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:42:19.885661Z","iopub.execute_input":"2022-02-18T16:42:19.88591Z","iopub.status.idle":"2022-02-18T16:42:28.943766Z","shell.execute_reply.started":"2022-02-18T16:42:19.88588Z","shell.execute_reply":"2022-02-18T16:42:28.942527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Some hand picked Training Images\nI have manually looked up the dataset and found some weared train and test images. We must process those images before feeding to our model. This is required in order to improve model performance. I have also collected some images from <a href=\"https://www.kaggle.com/andradaolteanu\">@andradaolteanu</a>'s notebook","metadata":{}},{"cell_type":"code","source":"def plot_sometrainimages(image_ids, rows, cols):\n    images = []\n    \n    plt.figure(figsize = (12,36))\n    for idx,i in enumerate(image_ids):\n        plt.subplot(rows,cols,idx+1)\n        image_path = '../input/happy-whale-and-dolphin/train_images/' + i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.title(i.split('.')[0])\n        images.append(i)\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()\n    \nsome_train_images = [\n'ba870b9e693201.jpg','7b0fb782fd9288.jpg','b642b895fc7138.jpg','d5a39578f273f3.jpg','6461d14e8348dc.jpg','e8f26d80ec48a2.jpg',\n'db9097bd9d8cc1.jpg','5109dfc3b3e104.jpg','13fd25f2e6f344.jpg','7b8a44f8851f07.jpg','5227f5db439364.jpg','a50cd3d93457b1.jpg', \n'381a58bed2fbc1.jpg','1392531bb34c9a.jpg','9867c0f54ff77d.jpg','d4d8ac80cb3a4b.jpg','d3ed54248b6681.jpg','7617259953a75c.jpg',\n'186f85fd38a70a.jpg','93e0f73bb86f70.jpg','21b3ad2437152f.jpg','67f0cd56a4a2c5.jpg','3a8c7e5429df52.jpg','e63956125e34b1.jpg',\n'd20de23fe239b2.jpg','79be96e5d8674c.jpg','2a6a8d51f1cf49.jpg','5d6ca9ba43d567.jpg','0c03feec795ed0.jpg','061761cee5d501.jpg',\n'cc666d76135ec0.jpg','70cad7ea5587d6.jpg','2bff7fb335a178.jpg','f76609dff2c3c6.jpg','090d7f9228a6bc.jpg','58fda080bd639d.jpg',\n'1922f6641653d4.jpg','48196cd0f04a9b.jpg','78d7b40e183021.jpg','e7f43942481868.jpg','bb3fd5ca8db073.jpg','13a25d81619913.jpg',\n'35d677992a4f2e.jpg','0246806606bc80.jpg','b4fd6577002028.jpg','c0a5ad1aece888.jpg','67ad9cb0769536.jpg','5e1f489ea57e10.jpg',\n'63acaed950eab8.jpg','014f6d1c690aff.jpg','097fb940db8b2c.jpg','4edf5f49a062eb.jpg','9a236360f50155.jpg','4fdcfcd6660edd.jpg',\n'0b1bd9850ad8a3.jpg','3cfa63a3bbebb7.jpg','31f99c519f55c9.jpg','898559919d173c.jpg','ce7695de81f1fe.jpg','911dd92c244d93.jpg',\n'bec33fe0de0384.jpg','5bb81354d55397.jpg','8f8335a84b89fb.jpg','8022b7a61a1f39.jpg','931854aa0b59b6.jpg','07d4d07aa31141.jpg',\n'53eca7a79fbf3d.jpg','3d045073aa762d.jpg','cd5fe465c60cb9.jpg','77908aab4bb24b.jpg','abf6f48044116d.jpg','4f43555e842ade.jpg',\n'3c15e996c183aa.jpg','726582ee59e000.jpg','9cadc38ade64ac.jpg','402d2e6df3ca51.jpg','05b9a41635a275.jpg','fd7e858f16fb3f.jpg',\n'f461e90a1a0909.jpg','5f220b77007ecd.jpg','269a6830d8b3c4.jpg'\n]\n","metadata":{"_kg_hide-input":true,"_kg_hide-output":false,"execution":{"iopub.status.busy":"2022-03-05T16:12:02.370163Z","iopub.execute_input":"2022-03-05T16:12:02.37088Z","iopub.status.idle":"2022-03-05T16:12:02.382325Z","shell.execute_reply.started":"2022-03-05T16:12:02.370841Z","shell.execute_reply":"2022-03-05T16:12:02.381668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_sometrainimages(some_train_images, 14, 6)","metadata":{"_kg_hide-output":false,"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-02-20T15:53:03.390813Z","iopub.execute_input":"2022-02-20T15:53:03.391439Z","iopub.status.idle":"2022-02-20T15:53:19.0502Z","shell.execute_reply.started":"2022-02-20T15:53:03.3914Z","shell.execute_reply":"2022-02-20T15:53:19.048873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Some hand picked Test Images","metadata":{}},{"cell_type":"code","source":"def plot_sometestimages(image_ids, rows, cols):\n    images = []\n    \n    plt.figure(figsize = (12,6))\n    for idx,i in enumerate(image_ids):\n        plt.subplot(rows,cols,idx+1)\n        image_path = '../input/happy-whale-and-dolphin/test_images/' + i\n        img = Image.open(image_path)\n        img = img.resize((224,224))\n        plt.title(i.split('.')[0])\n        images.append(i)\n        plt.imshow(img)\n        plt.axis('off')\n    plt.tight_layout()\n    plt.show()","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2022-03-05T16:11:50.163032Z","iopub.execute_input":"2022-03-05T16:11:50.163348Z","iopub.status.idle":"2022-03-05T16:11:50.171584Z","shell.execute_reply.started":"2022-03-05T16:11:50.163317Z","shell.execute_reply":"2022-03-05T16:11:50.1709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"some_test_images = [\n'5bf1396d350169.jpg','5e4a1ef591f291.jpg','6caa20cf5526cb.jpg','9b0b44b19ba412.jpg','43f1e346be1ddd.jpg','67e5fb9a6110b0.jpg',\n'e4acbbdc2feb58.jpg','fbc03b809b4fb0.jpg','844631d5b8c2f0.jpg','65def7ff6151f6.jpg','efbebaa3d40a48.jpg','2ba1913c52463b.jpg',\n]\nplot_sometestimages(some_test_images, 2, 6)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:38:24.412744Z","iopub.execute_input":"2022-02-20T04:38:24.413236Z","iopub.status.idle":"2022-02-20T04:38:27.613351Z","shell.execute_reply.started":"2022-02-20T04:38:24.413202Z","shell.execute_reply":"2022-02-20T04:38:27.612163Z"},"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Observations regarding handpicked images\n\n1. There are some abnormal images in both train and test dataset\n2. Some training images contains people, boats, birds, penguins etc\n3. Many training images are cropped but some are not.\n4. The uncropped images must be taken care of.\n5. There are some images take from under water","metadata":{}},{"cell_type":"markdown","source":"<a id=\"class-distribution-analysis\"></a>\n# Class Distribution Analysis\nIn this section we will be analyzing the number of training and test samples in each class. It will give us a better understanding of our dataset and provide us the necessary information to preprocess our dataset before the training phase. ","metadata":{}},{"cell_type":"code","source":"plot = sns.countplot(x = train_df['class'], color = '#2596be')\nsns.despine()\nplot.set_title('Class Distribution\\n', font = 'serif', x = 0.1, y=1, fontsize = 16);\nplot.set_ylabel(\"Count\", x = 0.02, font = 'serif', fontsize = 12)\nplot.set_xlabel(\"Specie\", fontsize = 12, font = 'serif')\n\nfor p in plot.patches:\n    plot.annotate(format(p.get_height(), '.0f'), (p.get_x() + p.get_width() / 2, p.get_height()), \n       ha = 'center', va = 'center', xytext = (0, -20),font = 'serif', textcoords = 'offset points', size = 15)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:30.750436Z","iopub.execute_input":"2022-02-20T04:45:30.751288Z","iopub.status.idle":"2022-02-20T04:45:31.012298Z","shell.execute_reply.started":"2022-02-20T04:45:30.751228Z","shell.execute_reply":"2022-02-20T04:45:31.0114Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Percentage of images of whale and dolphin in the dataset","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(5,5))\nclass_cnt = train_df.groupby(['class']).size().reset_index(name = 'counts')\ncolors = sns.color_palette('Paired')[0:9]\nplt.pie(class_cnt['counts'], labels=class_cnt['class'], colors=colors, autopct='%1.1f%%')\nplt.legend(loc='upper left')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:33.591438Z","iopub.execute_input":"2022-02-20T04:45:33.591745Z","iopub.status.idle":"2022-02-20T04:45:33.709102Z","shell.execute_reply.started":"2022-02-20T04:45:33.591714Z","shell.execute_reply":"2022-02-20T04:45:33.708104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Number of training images of each species","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(8,8))\nsns.countplot(data=train_df, y = 'species',  palette='crest', dodge=False)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:36.128167Z","iopub.execute_input":"2022-02-20T04:45:36.12897Z","iopub.status.idle":"2022-02-20T04:45:36.537106Z","shell.execute_reply.started":"2022-02-20T04:45:36.12893Z","shell.execute_reply":"2022-02-20T04:45:36.53623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Number of training images of each species of whale and dolphin","metadata":{}},{"cell_type":"code","source":"fig,ax = plt.subplots(1,2,figsize=(10,5))\n\nwhales = train_df[train_df['class']=='whale']\ndolphins = train_df[train_df['class']!='whale']\n\nsns.countplot(y=\"species\", data=whales, order=whales.iloc[0:][\"species\"].value_counts().index, ax=ax[0], color = \"#0077b6\")\nax[0].set_title('Most frequent whales')\nax[0].set_ylabel(None)\n    \nsns.countplot(y=\"species\", data=dolphins,order=dolphins.iloc[0:][\"species\"].value_counts().index, ax=ax[1], color = \"#90e0ef\")\nax[1].set_title('Most frequent dolphins')\nax[1].set_ylabel(None)\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:38.825048Z","iopub.execute_input":"2022-02-20T04:45:38.825376Z","iopub.status.idle":"2022-02-20T04:45:39.466093Z","shell.execute_reply.started":"2022-02-20T04:45:38.825341Z","shell.execute_reply":"2022-02-20T04:45:39.465071Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Number of training images of top 10 individuals","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\ntop_ten_ids = train_df.individual_id.value_counts().head(24)\ntop_ten_ids = pd.DataFrame({'individual_id':top_ten_ids.index, 'frequency':top_ten_ids.values})\n\nplt.bar(top_ten_ids['individual_id'],top_ten_ids['frequency'],width = 0.8,color='c',zorder=4)\nplt.xticks(rotation=90)\nplt.ylabel(\"frequency\")\nplt.xlabel(\"Individual Ids\")\nplt.title(\"Top 10 Individual Ids used by frequency\")\nplt.grid(visible = True, color ='grey',linestyle ='-', linewidth = 0.9,alpha = 0.2, zorder=0)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:41.537573Z","iopub.execute_input":"2022-02-20T04:45:41.537853Z","iopub.status.idle":"2022-02-20T04:45:41.916369Z","shell.execute_reply.started":"2022-02-20T04:45:41.537824Z","shell.execute_reply":"2022-02-20T04:45:41.915304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Plot the value count graph of each individual","metadata":{}},{"cell_type":"code","source":"train_df['individual_id'].value_counts().plot()\nplt.xticks(rotation=90)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:44.251069Z","iopub.execute_input":"2022-02-20T04:45:44.25139Z","iopub.status.idle":"2022-02-20T04:45:45.082029Z","shell.execute_reply.started":"2022-02-20T04:45:44.251358Z","shell.execute_reply":"2022-02-20T04:45:45.081074Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Density estimation of each individuals","metadata":{}},{"cell_type":"code","source":"np.log(train_df['individual_id'].value_counts()).plot.kde()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:49.355555Z","iopub.execute_input":"2022-02-20T04:45:49.356406Z","iopub.status.idle":"2022-02-20T04:45:49.919152Z","shell.execute_reply.started":"2022-02-20T04:45:49.35635Z","shell.execute_reply":"2022-02-20T04:45:49.918349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Density estimation of individual by whale and dolphin","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize = (20, 10))\nsns.kdeplot(np.log(train_df.loc[train_df['class'] == 'whale']['individual_id'].value_counts()))\nsns.kdeplot(np.log(train_df.loc[train_df['class'] == 'dolphin']['individual_id'].value_counts()))\nplt.legend(labels = ['whale', 'dolphin'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:47.154551Z","iopub.execute_input":"2022-02-20T04:45:47.15484Z","iopub.status.idle":"2022-02-20T04:45:47.592091Z","shell.execute_reply.started":"2022-02-20T04:45:47.154809Z","shell.execute_reply":"2022-02-20T04:45:47.59112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Number of unique individuals in the dataset","metadata":{}},{"cell_type":"code","source":"len(train_df.individual_id.unique())","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:45:53.327035Z","iopub.execute_input":"2022-02-20T04:45:53.327359Z","iopub.status.idle":"2022-02-20T04:45:53.339565Z","shell.execute_reply.started":"2022-02-20T04:45:53.327325Z","shell.execute_reply":"2022-02-20T04:45:53.338467Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image count of individuals","metadata":{}},{"cell_type":"code","source":"train_df['count'] = train_df.groupby('individual_id',as_index=False)['individual_id'].transform(lambda x: x.count())\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:47:10.287127Z","iopub.execute_input":"2022-02-20T04:47:10.288091Z","iopub.status.idle":"2022-02-20T04:47:33.787772Z","shell.execute_reply.started":"2022-02-20T04:47:10.288045Z","shell.execute_reply":"2022-02-20T04:47:33.786867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Individuals with only one training image","metadata":{}},{"cell_type":"code","source":"train_df[train_df['count']==1]","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:47:33.789585Z","iopub.execute_input":"2022-02-20T04:47:33.789945Z","iopub.status.idle":"2022-02-20T04:47:33.81499Z","shell.execute_reply.started":"2022-02-20T04:47:33.789912Z","shell.execute_reply":"2022-02-20T04:47:33.814344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Percentage of Individuals with less then 5 images","metadata":{}},{"cell_type":"code","source":"tmp = train_df[train_df['count']<=4]\nlen(tmp)/len(train_df)","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:47:33.816255Z","iopub.execute_input":"2022-02-20T04:47:33.817148Z","iopub.status.idle":"2022-02-20T04:47:33.828606Z","shell.execute_reply.started":"2022-02-20T04:47:33.817102Z","shell.execute_reply":"2022-02-20T04:47:33.82748Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Percentage of Individuals with more then 4 and less then 21 images","metadata":{}},{"cell_type":"code","source":"count = 0\nfor i in train_df['count']:\n    if(i > 4 and i <= 20):\n        count += 1\nprint(count/len(train_df))","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:47:33.830947Z","iopub.execute_input":"2022-02-20T04:47:33.831669Z","iopub.status.idle":"2022-02-20T04:47:33.850769Z","shell.execute_reply.started":"2022-02-20T04:47:33.831635Z","shell.execute_reply":"2022-02-20T04:47:33.849845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"observation-regarding-class-distribution\"></a>\n## Observation Regarding Class Distribution\nThere is a huge disbalance in the data. There are many classes with only one or several samples:\n\n1. Total Number of individuals are 15587\n2. 9258 individuals have just one image\n3. Single whale with most images have 400 of them\n4. Images dsitribution:\n  1. almost 40% comes from whales with 4 or less images.\n  1. almost 23% comes from whales with 5-20 images.\n  1. rest 37% comes from individual with >20 images.","metadata":{}},{"cell_type":"markdown","source":"<a id=\"image-resolutions\"></a>\n# Image Resolutions","metadata":{}},{"cell_type":"code","source":"widths, heights = [], []\n\nfor path in tqdm(train_df[\"path\"]):\n    width, height = Image.open(path).size\n    widths.append(width)\n    heights.append(height)\n    \ntrain_df[\"width\"] = widths\ntrain_df[\"height\"] = heights\ntrain_df[\"dimension\"] = train_df[\"width\"] * train_df[\"height\"]","metadata":{"execution":{"iopub.status.busy":"2022-03-05T15:48:39.145568Z","iopub.execute_input":"2022-03-05T15:48:39.146067Z","iopub.status.idle":"2022-03-05T15:55:57.475848Z","shell.execute_reply.started":"2022-03-05T15:48:39.146033Z","shell.execute_reply":"2022-03-05T15:55:57.473962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets see some small images","metadata":{}},{"cell_type":"code","source":"train_df.sort_values('width').head(84)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T16:16:46.095404Z","iopub.execute_input":"2022-03-05T16:16:46.095717Z","iopub.status.idle":"2022-03-05T16:16:46.126348Z","shell.execute_reply.started":"2022-03-05T16:16:46.09568Z","shell.execute_reply":"2022-03-05T16:16:46.125447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"color-analysis\"></a>\n# Color Analysis\nWe need to do some color analysis to get an ida about the augmentation technique needed for this problem","metadata":{}},{"cell_type":"code","source":"def is_grey_scale(givenImage):\n    w,h = givenImage.size\n    for i in range(w):\n        for j in range(h):\n            r,g,b = givenImage.getpixel((i,j))\n            if r != g != b: return False\n    return True","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:05:25.144243Z","iopub.execute_input":"2022-02-18T17:05:25.144632Z","iopub.status.idle":"2022-02-18T17:05:25.151132Z","shell.execute_reply.started":"2022-02-18T17:05:25.144578Z","shell.execute_reply":"2022-02-18T17:05:25.150133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check color scale of Train images","metadata":{}},{"cell_type":"code","source":"sampleFrac = 0.1\n#get our sampled images\nisGreyList = []\nfor imageName in train_df['path'].sample(frac=sampleFrac):\n    val = Image.open(imageName).convert('RGB')\n    isGreyList.append(is_grey_scale(val))\nprint(np.sum(isGreyList) / len(isGreyList))\ndel isGreyList","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:05:40.467094Z","iopub.execute_input":"2022-02-18T17:05:40.467793Z","iopub.status.idle":"2022-02-18T17:17:34.005649Z","shell.execute_reply.started":"2022-02-18T17:05:40.467751Z","shell.execute_reply":"2022-02-18T17:17:34.004417Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check color scale of Test images","metadata":{}},{"cell_type":"code","source":"sampleFrac = 0.1\n#get our sampled images\nisGreyList_test = []\nfor imageName in pred_df['path'].sample(frac=sampleFrac):\n    val = Image.open(imageName).convert('RGB')\n    isGreyList_test.append(is_grey_scale(val))\nprint(np.sum(isGreyList_test) / len(isGreyList_test))\ndel isGreyList_test","metadata":{"execution":{"iopub.status.busy":"2022-02-18T17:24:24.758878Z","iopub.execute_input":"2022-02-18T17:24:24.759207Z","iopub.status.idle":"2022-02-18T17:29:21.19275Z","shell.execute_reply.started":"2022-02-18T17:24:24.759172Z","shell.execute_reply":"2022-02-18T17:29:21.191523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Get mean intensity for each channel RGB <a name=\"get-mean-intensity-for-each-channel-RGB\"></a>","metadata":{}},{"cell_type":"code","source":"def get_rgb_men(row):\n    img = cv2.imread(row['path'])\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return np.sum(img[:,:,0]), np.sum(img[:,:,1]), np.sum(img[:,:,2])\n\ntqdm.pandas()\ntrain_df['R'], train_df['G'], train_df['B'] = zip(*train_df.progress_apply(lambda row: get_rgb_men(row), axis=1) )","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:38:39.959444Z","iopub.status.idle":"2022-02-18T16:38:39.959915Z","shell.execute_reply.started":"2022-02-18T16:38:39.959668Z","shell.execute_reply":"2022-02-18T16:38:39.959692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_color_dist(df, count):\n    fig, axr = plt.subplots(count,2,figsize=(15,15))\n    for idx, i in enumerate(np.random.choice(df['path'], count)):\n        img = cv2.imread(i)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        axr[idx,0].imshow(img)\n        axr[idx,0].axis('off')\n        axr[idx,1].set_title('R={:.0f}, G={:.0f}, B={:.0f} '.format(np.mean(img[:,:,0]), np.mean(img[:,:,1]), np.mean(img[:,:,2]))) \n        x, y = np.histogram(img[:,:,0], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='R', alpha=0.8, color='red')\n        x, y = np.histogram(img[:,:,1], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='G', alpha=0.8, color='green')\n        x, y = np.histogram(img[:,:,2], bins=255)\n        axr[idx,1].bar(y[:-1], x, label='B', alpha=0.8, color='blue')\n        axr[idx,1].legend()\n        axr[idx,1].axis('off')","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:38:39.960992Z","iopub.status.idle":"2022-02-18T16:38:39.961455Z","shell.execute_reply.started":"2022-02-18T16:38:39.961199Z","shell.execute_reply":"2022-02-18T16:38:39.96123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Red images and their color distribution\nSince we are picking random images, some image may appear multiple times","metadata":{}},{"cell_type":"code","source":"df = train_df[((train_df['B']*1.05) < train_df['R']) & ((train_df['G']*1.05) < train_df['R'])]\nshow_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:38:39.963943Z","iopub.status.idle":"2022-02-18T16:38:39.964526Z","shell.execute_reply.started":"2022-02-18T16:38:39.964237Z","shell.execute_reply":"2022-02-18T16:38:39.964267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Blue images and their color distribution","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['B'] > 1.3*train_df['R']) & (train_df['B'] > 1.3*train_df['G'])]\nshow_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T16:38:39.966451Z","iopub.status.idle":"2022-02-18T16:38:39.96693Z","shell.execute_reply.started":"2022-02-18T16:38:39.966679Z","shell.execute_reply":"2022-02-18T16:38:39.966705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Green images and their color distribution","metadata":{}},{"cell_type":"code","source":"df = train_df[(train_df['G'] > 1.05*train_df['R']) & (train_df['G'] > 1.05*train_df['B'])]\nshow_color_dist(df, 8)","metadata":{"execution":{"iopub.status.busy":"2022-02-18T04:51:04.093705Z","iopub.execute_input":"2022-02-18T04:51:04.09428Z","iopub.status.idle":"2022-02-18T04:51:24.365796Z","shell.execute_reply.started":"2022-02-18T04:51:04.094216Z","shell.execute_reply":"2022-02-18T04:51:24.364858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"observation-regarding-color-distribution\"></a>\n### Observation Regarding Color Distribution\n1. We see that around 3% of the images in the training set are greyscale. While 1% in the Test set are greyscale.\n2. Some whales have yellow spots and some images are reddish.This can happened due to sunset.\n3. This suggests that we need to create image transformations that are very agnostic to the RGB spectrum (i.e. bump up the number of greyscaled images in the smaller classes).","metadata":{}},{"cell_type":"markdown","source":"## Please Upvote if you find this Notebook Useful üôè","metadata":{}},{"cell_type":"markdown","source":"<a id=\"data-augmentation\"></a>\n# Data Augmentation\n\nData augmentation technique is used to prevent the model from overfitting by showing same image multiple time with slight modification. We will be using keras's built in ImageDataGenerator to augment out training images","metadata":{}},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\nfrom numpy import expand_dims","metadata":{"execution":{"iopub.status.busy":"2022-03-06T00:34:37.857022Z","iopub.execute_input":"2022-03-06T00:34:37.857311Z","iopub.status.idle":"2022-03-06T00:34:37.861049Z","shell.execute_reply.started":"2022-03-06T00:34:37.857282Z","shell.execute_reply":"2022-03-06T00:34:37.860116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_augimages(paths, datagen):\n    plt.figure(figsize = (14,28))\n    plt.suptitle('Augmented Images')\n    \n    midx = 0\n    for path in paths:\n        data = Image.open(path)\n        data = data.resize((224,224))\n        samples = expand_dims(data, 0)\n        it = datagen.flow(samples, batch_size=1)\n    \n        # Show Original Image\n        plt.subplot(10,5, midx+1)\n        plt.imshow(data)\n        plt.axis('off')\n    \n        # Show Augmented Images\n        for idx, i in enumerate(range(4)):\n            midx += 1\n            plt.subplot(10,5, midx+1)\n            \n            batch = it.next()\n            image = batch[0].astype('uint8')\n            plt.imshow(image)\n            plt.axis('off')\n        midx += 1\n    \n    plt.tight_layout()\n    plt.show()\n\n    \ndatagen = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.10,\n    brightness_range=[0.6,1.4],\n    channel_shift_range=0.7,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode='nearest'\n) \nplot_augimages(np.random.choice(train_df['path'],10), datagen)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T00:34:40.976951Z","iopub.execute_input":"2022-03-06T00:34:40.977215Z","iopub.status.idle":"2022-03-06T00:34:47.670659Z","shell.execute_reply.started":"2022-03-06T00:34:40.977187Z","shell.execute_reply":"2022-03-06T00:34:47.669982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id=\"preprocessing\"></a>\n# Preprocessing\n### Encoding Labels","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\n\nX = train_df.iloc[:, 3].values\ny = train_df.iloc[:, 2].values\n\nlabel_encoder = LabelEncoder()\ny = label_encoder.fit_transform(y)\nonehot_encoder = OneHotEncoder(sparse=False)\ny = y.reshape(len(y), 1)\ny = onehot_encoder.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T00:35:01.075358Z","iopub.execute_input":"2022-03-06T00:35:01.075704Z","iopub.status.idle":"2022-03-06T00:35:01.561632Z","shell.execute_reply.started":"2022-03-06T00:35:01.075669Z","shell.execute_reply":"2022-03-06T00:35:01.560701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T00:35:06.483878Z","iopub.execute_input":"2022-03-06T00:35:06.484159Z","iopub.status.idle":"2022-03-06T00:35:06.490298Z","shell.execute_reply.started":"2022-03-06T00:35:06.48413Z","shell.execute_reply":"2022-03-06T00:35:06.489686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### If you find this notebook useful,  <font color='red'>please support with an upvote</font> üôè","metadata":{}},{"cell_type":"markdown","source":"# References\nI have used these awesome kernels for whole EDA. Do check them out if you have time.","metadata":{}},{"cell_type":"code","source":"##https://www.kaggle.com/andradaolteanu/whales-dolphins-effnet-embedding-cos-distance\n##https://www.kaggle.com/lextoumbourou/happy-whale-dolphin-q-a-style-eda\n##https://www.kaggle.com/andradaolteanu/whales-dolphins-effnet-embedding-cos-distance\n##https://www.kaggle.com/rednivrug/eda-for-whale-with-bounding-boxes/notebook\n##https://www.kaggle.com/andradaolteanu/whales-dolphins-effnet-embedding-cos-distance\n##https://www.kaggle.com/pestipeti/explanation-of-map5-scoring-metric","metadata":{"execution":{"iopub.status.busy":"2022-02-20T04:58:35.784203Z","iopub.execute_input":"2022-02-20T04:58:35.784555Z","iopub.status.idle":"2022-02-20T04:58:35.788764Z","shell.execute_reply.started":"2022-02-20T04:58:35.784523Z","shell.execute_reply":"2022-02-20T04:58:35.7881Z"},"trusted":true},"execution_count":null,"outputs":[]}]}