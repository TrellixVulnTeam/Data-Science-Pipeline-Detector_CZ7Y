{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torchvision import models \nimport torchvision.transforms as T\nfrom torchvision.transforms.functional import InterpolationMode\nfrom PIL import Image\nimport pandas as pd\nimport matplotlib.pylab as plt\nimport numpy as np\nimport numpy.ma as ma\nimport cv2\nfrom scipy.special import softmax\nimport os\nimport shutil\nimport time\nfcn = models.segmentation.fcn_resnet101(pretrained=True).eval()\ndlab = models.segmentation.deeplabv3_resnet101(pretrained=1).eval()\nmodel = torch.hub.load('pytorch/vision:v0.10.0', 'deeplabv3_resnet50', pretrained=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-05T19:08:47.661048Z","iopub.execute_input":"2022-03-05T19:08:47.66176Z","iopub.status.idle":"2022-03-05T19:09:14.324168Z","shell.execute_reply.started":"2022-03-05T19:08:47.661654Z","shell.execute_reply":"2022-03-05T19:09:14.323352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_FOLDER = \"/kaggle/input/happy-whale-and-dolphin/train_images/\"\nTEST_FOLDER = \"/kaggle/input/happy-whale-and-dolphin/test_images/\"\nHEIGHT = 244\nWIDTH = 244\nTHRESHOLD = 0.05\n# Import the training data\ntraindata = pd.read_csv(\"/kaggle/input/happy-whale-and-dolphin/train.csv\")\ntraindata.loc[:,'image'] = TRAIN_FOLDER + traindata['image']\n# Import the test data\ntestdata = pd.read_csv(\"/kaggle/input/happy-whale-and-dolphin/sample_submission.csv\")\ntestdata.loc[:,'image'] = TEST_FOLDER + testdata['image']\n\noutputdir = '/kaggle/working/'\n\nif not os.path.exists(outputdir+\"/train_images/\"):\n    os.makedirs(outputdir+\"/train_images/\")\n    \nif not os.path.exists(outputdir+\"/test_images/\"):\n    os.makedirs(outputdir+\"/test_images/\")\n    \n\noriginal = r'/kaggle/input/happy-whale-and-dolphin/train.csv'\ntarget = r'./train.csv'\nshutil.copyfile(original, target)\n\noriginal = r'/kaggle/input/happy-whale-and-dolphin/sample_submission.csv'\ntarget = r'./sample_submission.csv'\nshutil.copyfile(original, target)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T19:09:14.326127Z","iopub.execute_input":"2022-03-05T19:09:14.326633Z","iopub.status.idle":"2022-03-05T19:09:14.514575Z","shell.execute_reply.started":"2022-03-05T19:09:14.326583Z","shell.execute_reply":"2022-03-05T19:09:14.51371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the helper function\ndef decode_segmap(image, nc=2):\n  \n    label_colors = np.array([(0, 0, 0),  # 0=background\n               # 1=aeroplane, 2=bicycle, 3=bird, 4=boat, 5=bottle\n               (128, 0, 0), (0, 128, 0), (128, 128, 0), (0, 0, 128), (128, 0, 128),\n               # 6=bus, 7=car, 8=cat, 9=chair, 10=cow\n               (0, 128, 128), (128, 128, 128), (64, 0, 0), (192, 0, 0), (64, 128, 0),\n               # 11=dining table, 12=dog, 13=horse, 14=motorbike, 15=person\n               (192, 128, 0), (64, 0, 128), (192, 0, 128), (64, 128, 128), (192, 128, 128),\n               # 16=potted plant, 17=sheep, 18=sofa, 19=train, 20=tv/monitor\n               (0, 64, 0), (128, 64, 0), (0, 192, 0), (128, 192, 0), (0, 64, 128)])\n\n    label_colors = np.array([(1,1,1)]*2)\n    label_colors[0] = (0,0,0)\n    \n    r = np.zeros_like(image).astype(np.uint8)\n    g = np.zeros_like(image).astype(np.uint8)\n    b = np.zeros_like(image).astype(np.uint8)\n  \n    for l in range(0, nc):\n        idx = image == l\n        r[idx] = label_colors[l, 0]\n        g[idx] = label_colors[l, 1]\n        b[idx] = label_colors[l, 2]\n\n        rgb = np.stack([r, g, b], axis=2)\n    return rgb\n\ndef masked_image(net, path):\n    #img = crop(yolo, path)\n    #img = Image.fromarray(np.uint8(img))\n    img = Image.open(path)\n    # Comment the Resize and CenterCrop for better inference results\n    trf = T.Compose([T.Resize(105,interpolation=InterpolationMode.NEAREST),\n                   #T.CenterCrop(300),\n                   T.ToTensor(),\n                   T.Normalize(mean = [0.485, 0.456, 0.406],\n                               std = [0.229, 0.224, 0.225])])\n    try:\n        inp = trf(img).unsqueeze(0)\n    except RuntimeError:\n        return np.array(img)\n    out = dlab(inp)['out'].squeeze().detach().numpy() #Lag point.\n\n    out = softmax(out, axis=0)[0]  \n    out = 1-out\n    #img = cv2.resize(np.array(img), (HEIGHT,WIDTH), interpolation = cv2.INTER_AREA)\n    out = cv2.resize(out, img.size, interpolation = cv2.INTER_LINEAR)\n    out[out < THRESHOLD] = 0\n    out[out >= THRESHOLD] = 1\n    if np.sum(out)<1:\n        return np.array(img)\n    else:\n        out = np.reshape(out, (out.shape[0], out.shape[1], 1))\n        return (out*np.array(img)/255.0)\n    \ndef progress_bar(perc_comp):\n    '''\n    Takes float or int between 0 and 100. \n    '''\n    bar_width = 100\n    bar = '#' * int(perc_comp)\n    bar += '-' * (100-int(perc_comp)) + ' ' + str(int(perc_comp)) + '% complete'\n    if perc_comp < 100:\n        print (bar, end='\\r')\n    else:\n        print (bar)","metadata":{"execution":{"iopub.status.busy":"2022-03-05T19:15:27.806401Z","iopub.execute_input":"2022-03-05T19:15:27.80668Z","iopub.status.idle":"2022-03-05T19:15:27.836199Z","shell.execute_reply.started":"2022-03-05T19:15:27.806654Z","shell.execute_reply":"2022-03-05T19:15:27.835341Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(masked_image(dlab, traindata.image.values[0]))","metadata":{"execution":{"iopub.status.busy":"2022-03-05T19:15:29.193902Z","iopub.execute_input":"2022-03-05T19:15:29.194479Z","iopub.status.idle":"2022-03-05T19:15:30.775052Z","shell.execute_reply.started":"2022-03-05T19:15:29.194435Z","shell.execute_reply":"2022-03-05T19:15:30.774343Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in traindata.image.values[0:10]:\n    fig, ax = plt.subplots(1,2, figsize=(10,10))\n    mask = masked_image(dlab, i)\n    ax[0].imshow(mask)\n    ax[1].imshow(Image.open(i))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-05T19:15:31.097701Z","iopub.execute_input":"2022-03-05T19:15:31.098016Z","iopub.status.idle":"2022-03-05T19:15:49.082803Z","shell.execute_reply.started":"2022-03-05T19:15:31.097982Z","shell.execute_reply":"2022-03-05T19:15:49.081782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t1 = time.time()\nfor i in range(len(traindata.image.values)):\n    output = outputdir+\"/test_images/\"+traindata.image.values[i].split('/')[-1]\n    img = masked_image(dlab, traindata.image.values[i])*255.0\n    #im = cv2.resize(im, (244,244), interpolation = cv2.INTER_AREA)\n    cv2.imwrite(output, img)\n    progress_bar(i/(len(traindata.image.values)-1)*100)   \nt2 = time.time()\nprint(f'Executed in {(t2-t1):.4f}s')","metadata":{"execution":{"iopub.status.busy":"2022-03-05T19:15:49.084587Z","iopub.execute_input":"2022-03-05T19:15:49.084891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}