{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"raw","source":"# Do upvote if this notebook helps you. \n\n*I will be using tez library from Abhishek Thakur*","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-26T14:43:56.777377Z","iopub.execute_input":"2022-02-26T14:43:56.777732Z","iopub.status.idle":"2022-02-26T14:44:07.712792Z","shell.execute_reply.started":"2022-02-26T14:43:56.77765Z","shell.execute_reply":"2022-02-26T14:44:07.711735Z"}}},{"cell_type":"markdown","source":"Vision Transformer Model is imported from [ViT](https://www.kaggle.com/abhinand05/vit-base-models-pretrained-pytorch)\nFor details on ViT, visit my blog : [ViT For Begiiners](https://dev.to/rohitgupta24/vision-transformer-an-image-is-worth-1616-words-3o2g)","metadata":{}},{"cell_type":"code","source":"!pip install wtfml==0.0.2\n!pip install timm\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:16:49.692694Z","iopub.execute_input":"2022-03-06T19:16:49.693405Z","iopub.status.idle":"2022-03-06T19:17:05.913365Z","shell.execute_reply.started":"2022-03-06T19:16:49.693359Z","shell.execute_reply":"2022-03-06T19:17:05.912484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Do upvote if this notebook helps you.**\n**I will be using tez library from Abhishek Thakur**","metadata":{}},{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom PIL import Image\n\nfrom sklearn import model_selection\nfrom sklearn import metrics\n\nimport timm\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\n\nimport albumentations as A\n\nfrom wtfml.utils import EarlyStopping\nfrom wtfml.engine import Engine\nfrom wtfml.data_loaders.image import ClassificationLoader\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:05.916327Z","iopub.execute_input":"2022-03-06T19:17:05.916608Z","iopub.status.idle":"2022-03-06T19:17:05.92601Z","shell.execute_reply.started":"2022-03-06T19:17:05.916569Z","shell.execute_reply":"2022-03-06T19:17:05.925217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Read the data by loading all the input files and create folds.\ntrain_dir = '../input/happy-whale-and-dolphin/train_images'\ntest_dir = '../input/happy-whale-and-dolphin/test_images'\ndf = pd.read_csv(\"../input/testcsv/demo.csv\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:05.927826Z","iopub.execute_input":"2022-03-06T19:17:05.928101Z","iopub.status.idle":"2022-03-06T19:17:05.951032Z","shell.execute_reply.started":"2022-03-06T19:17:05.928063Z","shell.execute_reply":"2022-03-06T19:17:05.950209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# checking the number of files in train_dir and csv\nt = os.listdir(train_dir)\ny = len(df.species),len(t)\n\n#number of species in csv file\nx =len(pd.unique(df.species))\nprint(x,y)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:05.952359Z","iopub.execute_input":"2022-03-06T19:17:05.952647Z","iopub.status.idle":"2022-03-06T19:17:05.989934Z","shell.execute_reply.started":"2022-03-06T19:17:05.952605Z","shell.execute_reply":"2022-03-06T19:17:05.988959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.species.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:05.992646Z","iopub.execute_input":"2022-03-06T19:17:05.993147Z","iopub.status.idle":"2022-03-06T19:17:06.002599Z","shell.execute_reply.started":"2022-03-06T19:17:05.993102Z","shell.execute_reply":"2022-03-06T19:17:06.001488Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Data Cleaning\n#Found out some duplicate labels\n\nprint(\"Number of unique species before fixing : \", df['species'].nunique())\n\ndf['species'].replace({\n    'bottlenose_dolpin' : 'bottlenose_dolphin',\n    'kiler_whale' : 'killer_whale',\n},inplace =True)\n\nprint(\"Number of unique species after fixing : \", df['species'].nunique())\n\n\n#df['class'] = df['species'].apply(lambda x: x.split('_')[-1])\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.004683Z","iopub.execute_input":"2022-03-06T19:17:06.005675Z","iopub.status.idle":"2022-03-06T19:17:06.024303Z","shell.execute_reply.started":"2022-03-06T19:17:06.005631Z","shell.execute_reply":"2022-03-06T19:17:06.02354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''visualizing  the data count'''\n\n#visualization imports\n#to have better idea of eda, please visit : https://www.kaggle.com/awsaf49/happywhale-data-distribution#Dolphin-Species-6%EF%B8%8F%E2%83%A3\n\nimport plotly.express as px\n\ndata = df.species.value_counts().reset_index()\nfig = px.bar(data, x='index', y='species', color='species',title='Species Count')\nfig.update_traces(textfont_size=12, textangle=0, textposition=\"outside\", cliponaxis=False)\nfig.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.026532Z","iopub.execute_input":"2022-03-06T19:17:06.027138Z","iopub.status.idle":"2022-03-06T19:17:06.11474Z","shell.execute_reply.started":"2022-03-06T19:17:06.027094Z","shell.execute_reply":"2022-03-06T19:17:06.113914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Cross Validation #imbalanced dataset so stratifi\n\n'''\n# import pandas and model_selection module of scikit-learn\nimport pandas as pd\nfrom sklearn import model_selection\nif __name__ == \"__main__\":\n    # Training data is in a csv file called train.csv\n    df = pd.read_csv(\"train.csv\")\n    # we create a new column called kfold and fill it with -1\n    df[\"kfold\"] = -1\n    # the next step is to randomize the rows of the data\n    df = df.sample(frac=1).reset_index(drop=True)\n    # fetch targets\n    y = df.target.values\n    # initiate the kfold class from model_selection module\n    kf = model_selection.StratifiedKFold(n_splits=5)\n    # fill the new kfold column\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f\n# save the new csv with kfold column\ndf.to_csv(\"train_folds.csv\", index=False)\n\n'''\n#Not trying the above Stratified K Fold for now. Instead will be using train_test split from model_selection to make validation and training set\n\ndfx = pd.read_csv('../input/testcsv/demo.csv')\ndf_train, df_valid = model_selection.train_test_split(\n        dfx, test_size=0.1, random_state=42, stratify=dfx.species.values\n)\nlen(df_train),len(df_valid)\n\n# so we have not created folds inthe input, only divided the data into training and validation set.\ndf_train.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.116018Z","iopub.execute_input":"2022-03-06T19:17:06.116921Z","iopub.status.idle":"2022-03-06T19:17:06.137392Z","shell.execute_reply.started":"2022-03-06T19:17:06.116875Z","shell.execute_reply":"2022-03-06T19:17:06.136597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reset the index and than drop the index\ndf_train = df_train.reset_index(drop=True)\ndf_valid = df_valid.reset_index(drop=True)\ndf_train.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.138941Z","iopub.execute_input":"2022-03-06T19:17:06.139448Z","iopub.status.idle":"2022-03-06T19:17:06.147519Z","shell.execute_reply.started":"2022-03-06T19:17:06.139407Z","shell.execute_reply":"2022-03-06T19:17:06.146596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#join image name with path to make a list of training images\n\ntrain_images = [os.path.join(train_dir,x) for x in df_train.image.values]\ntrain_images[1]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.149041Z","iopub.execute_input":"2022-03-06T19:17:06.149759Z","iopub.status.idle":"2022-03-06T19:17:06.158487Z","shell.execute_reply.started":"2022-03-06T19:17:06.149713Z","shell.execute_reply":"2022-03-06T19:17:06.157648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_images = [os.path.join(train_dir,x) for x in df_valid.image.values]\nvalid_images[:5]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.15993Z","iopub.execute_input":"2022-03-06T19:17:06.160382Z","iopub.status.idle":"2022-03-06T19:17:06.172719Z","shell.execute_reply.started":"2022-03-06T19:17:06.16034Z","shell.execute_reply":"2022-03-06T19:17:06.171901Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_targets = df_train.species.values\nvalid_targets = df_valid.species.values\n\ntrain_targets[1]","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.174778Z","iopub.execute_input":"2022-03-06T19:17:06.175524Z","iopub.status.idle":"2022-03-06T19:17:06.183445Z","shell.execute_reply.started":"2022-03-06T19:17:06.175477Z","shell.execute_reply":"2022-03-06T19:17:06.182423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install tez\nimport tez\nfrom tez.datasets import ImageDataset\nfrom tez.callbacks import EarlyStopping","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:06.185168Z","iopub.execute_input":"2022-03-06T19:17:06.185784Z","iopub.status.idle":"2022-03-06T19:17:13.930735Z","shell.execute_reply.started":"2022-03-06T19:17:06.18574Z","shell.execute_reply":"2022-03-06T19:17:13.929743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations\n\ntrain_aug = albumentations.Compose([\n            albumentations.RandomResizedCrop(256, 256),\n            albumentations.Transpose(p=0.5),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.ShiftScaleRotate(p=0.5),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1,0.1), \n                contrast_limit=(-0.1, 0.1), \n                p=0.5\n            ),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            ),\n            albumentations.CoarseDropout(p=0.5),\n            albumentations.Cutout(p=0.5)], p=1.)\n  \n        \nvalid_aug = albumentations.Compose([\n            albumentations.CenterCrop(256, 256, p=1.),\n            albumentations.Resize(256, 256),\n            albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406], \n                std=[0.229, 0.224, 0.225], \n                max_pixel_value=255.0, \n                p=1.0\n            )], p=1.)\n\nprint(\"hello\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T19:17:56.367012Z","iopub.execute_input":"2022-03-06T19:17:56.367329Z","iopub.status.idle":"2022-03-06T19:17:56.379003Z","shell.execute_reply.started":"2022-03-06T19:17:56.367289Z","shell.execute_reply":"2022-03-06T19:17:56.378181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}