{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install visualkeras --upgrade\n!git clone https://github.com/shreyas-bk/U-2-Net-Keras ./u2-net\n!git clone https://github.com/ktjonsson/keras-ArcFace ./arcface","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from arcface.src.arcface_layer import ArcFace","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os, sys, glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport keras.backend as K\nfrom IPython.display import Image\nimport random\nimport tqdm\nfrom skimage import color, io, feature\nimport seaborn as sns\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimgdir = \"../input/happy-whale-and-dolphin/\"\ncropped = \"../input/whale2-cropped-dataset/\"\nu2net = \"./u2-net/\"\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style(\"white\")\nimport visualkeras as vk","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:26.043983Z","iopub.execute_input":"2022-04-29T23:08:26.044204Z","iopub.status.idle":"2022-04-29T23:08:26.389Z","shell.execute_reply.started":"2022-04-29T23:08:26.044176Z","shell.execute_reply":"2022-04-29T23:08:26.388196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(imgdir)\nfor file in glob.glob(os.path.join(imgdir, \"*\")): \n    print(f\" \\_ {file}\")\nprint(cropped)\nfor file in glob.glob(os.path.join(cropped, \"*\")): \n    print(f\" \\_ {file}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:26.390282Z","iopub.execute_input":"2022-04-29T23:08:26.390526Z","iopub.status.idle":"2022-04-29T23:08:26.411051Z","shell.execute_reply.started":"2022-04-29T23:08:26.390494Z","shell.execute_reply":"2022-04-29T23:08:26.41023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import train_test_split\n\nimport tensorflow as tf\nfrom keras.models import Sequential\nfrom keras import layers\n\nfrom keras.preprocessing import image\nfrom keras.applications.imagenet_utils import preprocess_input\nfrom keras.layers import Input, Dense, Activation, BatchNormalization, Flatten, Conv2D\nfrom keras.layers import AveragePooling2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom keras.models import Model\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import resnet\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.layers import Input","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:24:36.708269Z","iopub.execute_input":"2022-04-29T23:24:36.708538Z","iopub.status.idle":"2022-04-29T23:24:36.715867Z","shell.execute_reply.started":"2022-04-29T23:24:36.708505Z","shell.execute_reply":"2022-04-29T23:24:36.71468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = pd.read_csv(imgdir + \"train.csv\")\n# train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:26.57667Z","iopub.execute_input":"2022-04-29T23:08:26.577129Z","iopub.status.idle":"2022-04-29T23:08:26.580874Z","shell.execute_reply.started":"2022-04-29T23:08:26.577092Z","shell.execute_reply":"2022-04-29T23:08:26.580122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cropped = pd.read_csv(cropped + \"train2.csv\")\ntrain_cropped.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:24:39.447224Z","iopub.execute_input":"2022-04-29T23:24:39.447489Z","iopub.status.idle":"2022-04-29T23:24:39.533018Z","shell.execute_reply.started":"2022-04-29T23:24:39.447459Z","shell.execute_reply":"2022-04-29T23:24:39.532293Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# print(train.shape)\nprint(train_cropped.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:24:41.792181Z","iopub.execute_input":"2022-04-29T23:24:41.792779Z","iopub.status.idle":"2022-04-29T23:24:41.797775Z","shell.execute_reply.started":"2022-04-29T23:24:41.792741Z","shell.execute_reply":"2022-04-29T23:24:41.797009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are some species that are duplicates due to typos, or other misclassification errors. So there are actually 26 species total in the dataset.","metadata":{}},{"cell_type":"code","source":"def clean_labels(train):\n    encoder = LabelEncoder()\n    train['species'].replace('kiler_whale', 'killer_whale', inplace=True)\n    train['species'].replace('bottlenose_dolpin', 'bottlenose_dolphin', inplace=True)\n    train['species'].replace(('globis', 'pilot_whale'), 'short_finned_pilot_whale', \n                         inplace=True)\n    train['species_id'] = encoder.fit_transform(train['species'])\n    return train","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:24:43.441514Z","iopub.execute_input":"2022-04-29T23:24:43.441987Z","iopub.status.idle":"2022-04-29T23:24:43.448225Z","shell.execute_reply.started":"2022-04-29T23:24:43.44195Z","shell.execute_reply":"2022-04-29T23:24:43.447572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train = clean_labels(train)\ntrain_cropped = clean_labels(train_cropped)\ny = train_cropped['species_id']","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:24:45.68979Z","iopub.execute_input":"2022-04-29T23:24:45.690354Z","iopub.status.idle":"2022-04-29T23:24:45.723396Z","shell.execute_reply.started":"2022-04-29T23:24:45.690317Z","shell.execute_reply":"2022-04-29T23:24:45.722742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(dpi=150)\nsns.histplot(data=train_cropped, x='species', hue='species', stat='percent', \n             discrete=True)\nax.get_legend().remove()\nplt.xticks(rotation=90)\nplt.title(\"Distribution of different whale species\")\nsns.despine()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:26.764743Z","iopub.execute_input":"2022-04-29T23:08:26.765229Z","iopub.status.idle":"2022-04-29T23:08:28.819742Z","shell.execute_reply.started":"2022-04-29T23:08:26.765191Z","shell.execute_reply":"2022-04-29T23:08:28.819048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Image(filename= imgdir + \"train_images/\" + random.choice(train['image'])) ","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:28.820875Z","iopub.execute_input":"2022-04-29T23:08:28.821489Z","iopub.status.idle":"2022-04-29T23:08:28.825378Z","shell.execute_reply.started":"2022-04-29T23:08:28.821445Z","shell.execute_reply":"2022-04-29T23:08:28.82466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Image(filename=cropped + \"cropped_train_images/cropped_train_images/\" + random.choice(train_cropped['image'])) ","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:28.82648Z","iopub.execute_input":"2022-04-29T23:08:28.827227Z","iopub.status.idle":"2022-04-29T23:08:28.856271Z","shell.execute_reply.started":"2022-04-29T23:08:28.827191Z","shell.execute_reply":"2022-04-29T23:08:28.855593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_cropped[\"individual_id\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:28.857577Z","iopub.execute_input":"2022-04-29T23:08:28.85801Z","iopub.status.idle":"2022-04-29T23:08:28.880376Z","shell.execute_reply.started":"2022-04-29T23:08:28.857975Z","shell.execute_reply":"2022-04-29T23:08:28.879626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Processing the Images","metadata":{}},{"cell_type":"code","source":"pix_size = 128","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_imgs(train, stop=0, size=64, channels=1, resnet=False):\n    with tqdm.tqdm(desc=\"processing\", total=stop) as progress:\n        X = np.zeros((train.shape[0], size, size, channels))\n        for n, i in enumerate(train['image']):\n            img = image.load_img(imgdir + 'train_images/' + i, target_size=(size, size, 3))\n            if not resnet:\n                if channels == 1:\n                    img = color.rgb2gray(img)\n                # img = img.reshape((size, size, channels))\n            # else:\n            img = preprocess_input(image.img_to_array(img))\n                \n            X[n] = img\n            if n == stop:\n                break\n            progress.update(1)\n    X = X.astype('float32')\n    return X","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:28:40.042219Z","iopub.execute_input":"2022-04-29T23:28:40.04303Z","iopub.status.idle":"2022-04-29T23:28:40.051429Z","shell.execute_reply.started":"2022-04-29T23:28:40.042993Z","shell.execute_reply":"2022-04-29T23:28:40.050568Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_gray = process_imgs(train, 500)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:08:28.891349Z","iopub.execute_input":"2022-04-29T23:08:28.891794Z","iopub.status.idle":"2022-04-29T23:08:28.900163Z","shell.execute_reply.started":"2022-04-29T23:08:28.891759Z","shell.execute_reply":"2022-04-29T23:08:28.899421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_cropped = process_imgs(train_cropped, stop=500, size=pix_size, channels=3)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:28:43.764876Z","iopub.execute_input":"2022-04-29T23:28:43.765602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# plt.imshow(X_gray[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:11.468421Z","iopub.execute_input":"2022-04-29T23:09:11.468683Z","iopub.status.idle":"2022-04-29T23:09:11.473453Z","shell.execute_reply.started":"2022-04-29T23:09:11.468648Z","shell.execute_reply":"2022-04-29T23:09:11.472675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(X_cropped[0])","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:11.474731Z","iopub.execute_input":"2022-04-29T23:09:11.475558Z","iopub.status.idle":"2022-04-29T23:09:11.75234Z","shell.execute_reply.started":"2022-04-29T23:09:11.475521Z","shell.execute_reply":"2022-04-29T23:09:11.751689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I'm torn between using a sigma=3 or a sigma=2. Some of the pictures get pretty noisy, but other ones don't really have any dorsal fins that show up at all...","metadata":{}},{"cell_type":"code","source":"# edges0 = feature.canny(X_gray[0].reshape((64,64)), sigma=3)\n# plt.imshow(edges0)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:11.753766Z","iopub.execute_input":"2022-04-29T23:09:11.754253Z","iopub.status.idle":"2022-04-29T23:09:11.758099Z","shell.execute_reply.started":"2022-04-29T23:09:11.754214Z","shell.execute_reply":"2022-04-29T23:09:11.757321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# fig, axes = plt.subplots(1, 4, figsize=(20, 20))\n# for j in range(6 * 6):\n#     plt.subplot(6, 6, j+1)\n#     plt.axis('off')\n#     plt.imshow(X_gray[j])\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:11.760968Z","iopub.execute_input":"2022-04-29T23:09:11.761163Z","iopub.status.idle":"2022-04-29T23:09:11.766995Z","shell.execute_reply.started":"2022-04-29T23:09:11.761139Z","shell.execute_reply":"2022-04-29T23:09:11.766159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 4, figsize=(20, 20))\nfor j in range(6 * 6):\n    plt.subplot(6,6, j+1)\n    plt.axis('off')\n    plt.imshow(feature.canny(X_cropped[j].reshape((pix_size, pix_size)), sigma=2))\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_canny = np.zeros((X_gray.shape[0], 64, 64))\n# for i in range(1000):\n#     X_canny[i] = feature.canny(X_gray[i].reshape((64, 64)), sigma=2) ","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.683521Z","iopub.status.idle":"2022-04-29T23:09:12.684112Z","shell.execute_reply.started":"2022-04-29T23:09:12.68387Z","shell.execute_reply":"2022-04-29T23:09:12.683895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split(X, y, size=0.3, random=69):\n    return train_test_split(X, y, test_size=size, random_state=random)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:25:26.615961Z","iopub.execute_input":"2022-04-29T23:25:26.61625Z","iopub.status.idle":"2022-04-29T23:25:26.624239Z","shell.execute_reply.started":"2022-04-29T23:25:26.616212Z","shell.execute_reply":"2022-04-29T23:25:26.621355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X_train, X_test, y_train, y_test = split(X_gray, y)\n# X_train, X_val, y_train, y_val = split(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.687269Z","iopub.status.idle":"2022-04-29T23:09:12.68803Z","shell.execute_reply.started":"2022-04-29T23:09:12.687779Z","shell.execute_reply":"2022-04-29T23:09:12.687805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_crop_train, X_crop_test, y_crop_train, y_crop_test = split(X_cropped, y)\nX_crop_train, X_crop_val, y_crop_train, y_crop_val = split(X_crop_train, y_crop_train)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:25:28.415287Z","iopub.execute_input":"2022-04-29T23:25:28.417199Z","iopub.status.idle":"2022-04-29T23:25:30.296591Z","shell.execute_reply.started":"2022-04-29T23:25:28.417159Z","shell.execute_reply":"2022-04-29T23:25:30.295885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is the ArcFace implementation without any background removal. I am seeing how well the model performs after 500 epochs with a small dataset.","metadata":{}},{"cell_type":"code","source":"af = ArcFace(output_dim=26, class_num=26)\nmodel = Sequential([\n    layers.Conv2D(256, 3, padding='valid', activation='relu', input_shape=[pix_size, pix_size, 3]),\n    layers.MaxPooling2D(2),\n    layers.Conv2D(128, 3, padding='valid', activation='relu'),\n    layers.Conv2D(128, 3, padding='valid', activation='relu'),\n    layers.MaxPooling2D(2),\n    layers.Conv2D(64, 3, padding='valid'),\n    layers.Conv2D(64, 3, padding='valid', activation='leaky_relu'),\n    layers.Flatten(),\n    layers.Dropout(0.2),\n    layers.Dense(64, activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dense(256, activation='leaky_relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.2),\n    layers.Dense(256, activation='leaky_relu'),\n    layers.Dense(26, activation=af)\n])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vk.layered_view(model)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.693226Z","iopub.status.idle":"2022-04-29T23:09:12.69395Z","shell.execute_reply.started":"2022-04-29T23:09:12.69366Z","shell.execute_reply":"2022-04-29T23:09:12.693689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-3\nbest = \"best.hdf5\"\ncallbacks = [\n        ReduceLROnPlateau(monitor='val_accuracy', factor=0.2, patience=3, min_lr=1e-7),\n        EarlyStopping(monitor='val_accuracy', patience=5, min_delta=1e-5), \n        ModelCheckpoint(best, monitor='val_accuracy', verbose=1, save_best_only=True, mode='auto')\n    ]","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:25:36.212592Z","iopub.execute_input":"2022-04-29T23:25:36.212884Z","iopub.status.idle":"2022-04-29T23:25:36.218609Z","shell.execute_reply.started":"2022-04-29T23:25:36.212833Z","shell.execute_reply":"2022-04-29T23:25:36.217785Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# opt = Adam(learning_rate=lr)\n# model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n\n# model.fit(X_train, y_train, batch_size = 16, epochs = 20, validation_data = (X_val, y_val), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.69748Z","iopub.status.idle":"2022-04-29T23:09:12.698315Z","shell.execute_reply.started":"2022-04-29T23:09:12.698089Z","shell.execute_reply":"2022-04-29T23:09:12.698112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"opt = Adam(learning_rate=lr)\nmodel.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])\n\nmodel.fit(X_crop_train, y_crop_train, batch_size = 32, epochs = 500, validation_data = (X_crop_val, y_crop_val), callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_canny, y, test_size=0.4, random_state=69)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=69)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.701308Z","iopub.status.idle":"2022-04-29T23:09:12.702176Z","shell.execute_reply.started":"2022-04-29T23:09:12.701941Z","shell.execute_reply":"2022-04-29T23:09:12.701966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.fit(X_train, y_train, batch_size = 16, epochs = 50, validation_data = (X_val, y_val), callbacks=callbacks)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.703242Z","iopub.status.idle":"2022-04-29T23:09:12.70409Z","shell.execute_reply.started":"2022-04-29T23:09:12.703866Z","shell.execute_reply":"2022-04-29T23:09:12.70389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ResNet\nI think that maybe it might work better to use the ResNet model to find the whales in the image. But the results weren't as good as I hoped: in fact, they were worse than the previous model.","metadata":{}},{"cell_type":"code","source":"X_resnet = process_imgs(train_cropped, 500, channels=3, resnet=True)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.705144Z","iopub.status.idle":"2022-04-29T23:09:12.706008Z","shell.execute_reply.started":"2022-04-29T23:09:12.705762Z","shell.execute_reply":"2022-04-29T23:09:12.705787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_resnet, y, test_size=0.4, random_state=69)\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=69)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.707067Z","iopub.status.idle":"2022-04-29T23:09:12.70794Z","shell.execute_reply.started":"2022-04-29T23:09:12.707688Z","shell.execute_reply":"2022-04-29T23:09:12.707713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"resmodel = resnet.ResNet50(input_shape=(64, 64, 3), weights='imagenet', include_top=False, classes=26)\nmodel = tf.keras.Sequential([resmodel,\n                                 layers.MaxPooling2D(),\n                                 layers.Dense(3, activation=\"relu\"), \n                                 layers.Dropout(0.2),\n                                 layers.Dense(3, activation=\"relu\"),\n                                 layers.Dropout(0.2),\n                                 layers.Dense(2, activation=\"softmax\")                                     \n                                ])\n\nmodel.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n              loss='sparse_categorical_crossentropy',\n              metrics=['sparse_categorical_accuracy'])\n\nhistory = model.fit(X_train, y_train, epochs = 50 , validation_data = (X_val, y_val), callbacks=callbacks)\npreds = resmodel.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2022-04-29T23:09:12.70902Z","iopub.status.idle":"2022-04-29T23:09:12.709897Z","shell.execute_reply.started":"2022-04-29T23:09:12.709649Z","shell.execute_reply":"2022-04-29T23:09:12.709673Z"},"trusted":true},"execution_count":null,"outputs":[]}]}