{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom PIL import Image\nimport os, cv2, gc\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf \nfrom tensorflow import keras \nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import layers, losses, optimizers, metrics\nimport tensorflow_hub as hub\nfrom keras.applications import imagenet_utils\n\nimport tensorflow_addons as tfa\nfrom keras.layers.advanced_activations import LeakyReLU","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-10T11:30:05.04456Z","iopub.execute_input":"2022-04-10T11:30:05.045444Z","iopub.status.idle":"2022-04-10T11:30:14.173872Z","shell.execute_reply.started":"2022-04-10T11:30:05.045334Z","shell.execute_reply":"2022-04-10T11:30:14.172864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INP_SIZE      = (512, 512) \nTARGET_SIZE   = (224, 224) \nINTERPOLATION = \"bilinear\"\nN_CLASSES = 15587\n\nNUM_FOLDS  = 5\nBATCH_SIZE = 24\nSEED       = 42\n\nDATA_DIR  = '../input/happy-whale-and-dolphin/'\nTRAIN_DIR = DATA_DIR + 'train_images/'\nTEST_DIR  = DATA_DIR + 'test_images/'\n\n# SetAutoTune\nAUTOTUNE = tf.data.AUTOTUNE ","metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:30:17.679646Z","iopub.execute_input":"2022-04-10T11:30:17.680163Z","iopub.status.idle":"2022-04-10T11:30:17.687764Z","shell.execute_reply.started":"2022-04-10T11:30:17.680119Z","shell.execute_reply":"2022-04-10T11:30:17.686517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/ipythonx/tf-keras-learning-to-resize-image-for-vit-model/notebook\ndef build_augmenter(is_labelled):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.65, 1.05)\n        img = tf.image.random_brightness(img, 0.05)\n        img = tf.image.random_contrast(img, 0.75, 1.05)\n        img = tf.image.random_hue(img, 0.05)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    return augment_with_labels if is_labelled else augment\n\ndef build_decoder(is_labelled, size):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        img = tf.image.decode_jpeg(file_bytes, channels = 3)\n        img = tf.image.resize(img, (size[0], size[1]))\n        return tf.cast(tf.divide(img, 255.),tf.float32)\n    \n    def decode_with_labels(path, label):\n        label = tf.cast(label, tf.int32)\n        return decode(path),label\n    \n    return decode_with_labels if is_labelled else decode\n\ndef create_dataset(df, \n                   batch_size  = 32, \n                   is_labelled = False, \n                   augment     = False, \n                   repeat      = False, \n                   shuffle     = False,\n                   size        = INP_SIZE):\n    decode_fn    = build_decoder(is_labelled, size)\n    augmenter_fn = build_augmenter(is_labelled)\n    \n    # Create Dataset\n    if is_labelled:\n        dataset = tf.data.Dataset.from_tensor_slices((df['Id'].values, df['target_value'].values))\n    else:\n        dataset = tf.data.Dataset.from_tensor_slices((df['Id'].values))\n        \n    dataset = dataset.map(decode_fn, num_parallel_calls = AUTOTUNE)\n    dataset = dataset.map(augmenter_fn, num_parallel_calls = AUTOTUNE) if augment else dataset\n    dataset = dataset.repeat() if repeat else dataset\n    dataset = dataset.shuffle(1024, reshuffle_each_iteration = True) if shuffle else dataset\n    dataset = dataset.batch(batch_size)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset","metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:30:58.615605Z","iopub.execute_input":"2022-04-10T11:30:58.616116Z","iopub.status.idle":"2022-04-10T11:30:58.631895Z","shell.execute_reply.started":"2022-04-10T11:30:58.616071Z","shell.execute_reply":"2022-04-10T11:30:58.630658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_encoder = LabelEncoder()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:31:08.681791Z","iopub.execute_input":"2022-04-10T11:31:08.682132Z","iopub.status.idle":"2022-04-10T11:31:08.686851Z","shell.execute_reply.started":"2022-04-10T11:31:08.682095Z","shell.execute_reply":"2022-04-10T11:31:08.685962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv(f'{DATA_DIR}train.csv')\ntrain_df['Id'] = train_df['image'].apply(lambda x: f'{TRAIN_DIR}{x}')\n\n# Adjust typos in \"species\" column from Andrada's kernel\ntrain_df[\"species\"] = train_df[\"species\"].replace([\"bottlenose_dolpin\", \"kiler_whale\",\n                                             \"beluga\", \n                                             \"globis\", \"pilot_whale\"],\n                                            [\"bottlenose_dolphin\", \"killer_whale\",\n                                             \"beluga_whale\", \n                                             \"short_finned_pilot_whale\", \"short_finned_pilot_whale\"])\n\n\n# Set a specific label to be able to perform stratification\n#train_df['stratify_label'] = train_df['individual_id']\n\ntrain_df['target_value']  = label_encoder.fit_transform(train_df['individual_id'] )\n\n# Summary\nprint(f'train_df: {train_df.shape}')\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:31:25.647853Z","iopub.execute_input":"2022-04-10T11:31:25.648361Z","iopub.status.idle":"2022-04-10T11:31:25.889598Z","shell.execute_reply.started":"2022-04-10T11:31:25.648327Z","shell.execute_reply":"2022-04-10T11:31:25.888681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df[train_df['individual_id']=='19fbb960f07d']","metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:31:36.11369Z","iopub.execute_input":"2022-04-10T11:31:36.114005Z","iopub.status.idle":"2022-04-10T11:31:36.151662Z","shell.execute_reply.started":"2022-04-10T11:31:36.113966Z","shell.execute_reply":"2022-04-10T11:31:36.150696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.species.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:31:51.123161Z","iopub.execute_input":"2022-04-10T11:31:51.123706Z","iopub.status.idle":"2022-04-10T11:31:51.141444Z","shell.execute_reply.started":"2022-04-10T11:31:51.123672Z","shell.execute_reply":"2022-04-10T11:31:51.140777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2022-04-10T11:32:00.656253Z","iopub.execute_input":"2022-04-10T11:32:00.656571Z","iopub.status.idle":"2022-04-10T11:32:00.688674Z","shell.execute_reply.started":"2022-04-10T11:32:00.656542Z","shell.execute_reply":"2022-04-10T11:32:00.687766Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}