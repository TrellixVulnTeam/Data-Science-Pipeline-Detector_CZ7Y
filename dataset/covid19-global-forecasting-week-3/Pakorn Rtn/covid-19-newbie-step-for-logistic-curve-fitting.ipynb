{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom math import sqrt\nimport matplotlib.pyplot as plt\nimport datetime as dt\nimport numpy, scipy, matplotlib\nfrom scipy.optimize import curve_fit\nimport warnings\nfrom math import exp, e\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        pass\n        #print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Prepare Trian Data\ntrain_path = \"/kaggle/input/covid19-global-forecasting-week-3/train.csv\"\ntrain_data = pd.read_csv(train_path, parse_dates=['Date'])\n#train_data = pd.read_csv(train_path, index_col=\"Date\", parse_dates=True)\n\n# Check the Number of missing values in each column of training data\nmissing_val_count_by_column = (train_data.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prepare Test Data\ntest_path = \"/kaggle/input/covid19-global-forecasting-week-3/test.csv\"\ntest_data = pd.read_csv(test_path)\ntest_data1 = pd.read_csv(test_path, index_col=\"Date\", parse_dates=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Logistic Regression Mudule\ndef train_logistic(i):\n    #Prepare Train Data\n    train_data_1 = train_data.loc[train_data[\"Country_Region\"].isin([i])]\n    train_data_2 = train_data_1.sort_values(by=\"Date\")\n    train_data_3 = train_data_2.set_index('Date')\n    Date=[]\n    ConfirmedCases=[]\n    Fatalities=[]\n    X_1=[]\n    loop=1\n    Date = train_data_3.index.unique()\n    for a in Date:\n        if len(train_data_3.loc[a].index)>=8 or i=='Denmark' or i=='Netherlands':\n            daily_sum = train_data_3.loc[a].sum()\n        else:\n            daily_sum = train_data_3.loc[a]\n        ConfirmedCases.append(daily_sum.ConfirmedCases)\n        Fatalities.append(daily_sum.Fatalities)\n        X_1.append(loop)\n        loop=loop+1\n    train_data_final = pd.DataFrame({'ConfirmedCases':ConfirmedCases, 'Fatalities':Fatalities, 'X_1':X_1}, index=Date)\n    len_x = len(Date)+1\n    X_1 = np.array(list(range(1, len_x)))#.reshape(-1,1)\n    X_2 = np.array(list(range(1, len_x))).reshape(-1,1)\n    X_plot = Date\n    y_1 = train_data_final[\"ConfirmedCases\"].values#.reshape(-1,1)\n    y_plot = train_data_final[\"ConfirmedCases\"].values\n    y_2 = train_data_final[\"Fatalities\"].values.reshape(-1,1)\n    \n    #Prepare Test Data\n    test_data_1 = test_data.loc[test_data[\"Country_Region\"].isin([i])]\n    test_data_2 = test_data_1.sort_values(by=\"Date\")\n    test_data_3 = test_data_2.set_index('Date')\n    Date_test = test_data_1.Date.unique()\n    \n    X_test = test_data1.loc[test_data1[\"Country_Region\"].isin([i])]\n    X_train_map_index = X_test.index.values.min()\n    X_train_map_index = np.datetime_as_string(X_train_map_index, unit='D')\n    X_train_map_value = train_data_final.X_1.loc[X_train_map_index]\n    X_train_map_value\n    len_x_test = len(Date_test)\n    X_test_1 = np.array(list(range(X_train_map_value, len_x_test+X_train_map_value)))\n    X_test_2 = np.array(list(range(X_train_map_value, len_x_test+X_train_map_value))).reshape(-1,1)\n    X_test_0 = np.array(list(range(5, 100))).reshape(-1,1)\n    X_train_and_test = np.array(list(range(1, len_x_test+X_train_map_value))).reshape(-1,1)\n    ForecastID = X_test[\"ForecastId\"].values\n    \n    ####------ConfirmedCase-------> as y_1\n    \n    def func(x, a, b, c): # Logistic B equation \n        return a / (1.0 + numpy.power(x/b, c))\n \n        \n    # these are the same as the scipy defaults\n    initialParameters = numpy.array([1.0, 1.0, 1.0])\n\n    # curve fit the test data, ignoring warning due to initial parameter estimates\n    warnings.filterwarnings(\"ignore\")\n    fittedParameters, pcov = curve_fit(func, X_1, y_1, initialParameters, maxfev=10000)\n\n    modelPredictions = func(X_1, *fittedParameters) \n\n    absError = modelPredictions - y_1\n\n    SE = numpy.square(absError) # squared errors\n    MSE = numpy.mean(SE) # mean squared errors\n    RMSE = numpy.sqrt(MSE) # Root Mean Squared Error, RMSE\n    Rsquared = 1.0 - (numpy.var(absError) / numpy.var(y_1))\n\n    print('Parameters:', fittedParameters)\n    print('RMSE:', RMSE)\n    print('R-squared:', Rsquared)\n    \n    #Predict ConfirmedCases\n    y_1_pred = modelPredictions = func(X_test_1, *fittedParameters)\n    \n    ####------Fatalities-------> as y_2\n    \n    # Fitting Linear Regression to Fatalities\n    model = LinearRegression()\n    model.fit(X_2, y_2)\n\n    # Evaluate the testing error \n    score2 = model.score(X_2, y_2)\n    \n    #Predict ConfirmedCases\n    y_2_pred = model.predict(X_test_2)\n    \n    # Visualizing the Polymonial Regression results\n    def viz():\n        plt.scatter(X_1, y_1, color='red')\n        plt.plot(X_train_and_test, func(X_train_and_test, *fittedParameters), color='blue')\n        plt.title(i)\n        plt.xlabel('Date')\n        plt.ylabel('ConfirmedCases')\n        plt.show()\n        return\n    viz()\n    \n    #Prepare for Submission\n    y_1 = np.squeeze(y_1_pred.transpose()).round()\n    y_2 = np.squeeze(y_2_pred.transpose()).round()\n    #map y_1, y_2 to each case of the date\n    test_data_4 = test_data1.loc[test_data1[\"Country_Region\"].isin([i])]\n    test_data_4.ForecastId\n    data_prep0 =pd.DataFrame({'ConfirmedCases':y_1, 'Fatalities':y_2},index=Date_test)\n    data_prep1 = test_data_4.join(data_prep0)\n    data_prep2 = data_prep1.sort_values(by='ForecastId')\n    y_1_submit = data_prep2.ConfirmedCases.values    \n    y_2_submit = data_prep2.Fatalities.values\n    \n    submit = pd.DataFrame({'ForecastId': ForecastID, 'ConfirmedCases': y_1_submit, 'Fatalities': y_2_submit}, index=ForecastID)#list(range(1, len_x_test+1)) )\n    return submit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#i='Angola'\n#i='Antigua and Barbuda'\n#i='Australia'\ni='Afghanistan'\n#i='Netherlands'\nscore = train_logistic(i)\nprint(score) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train Model for all countries\nloop=0\ncountries = train_data[\"Country_Region\"].unique()\nfor i in countries:\n    print(i)\n    submit = train_logistic(i)\n    if loop ==0:\n        output = submit.copy()\n    else:\n        output = pd.concat([output,submit])\n    loop = loop +1\n    print(submit)\nprint(output)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get Submission Data File\noutput.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}