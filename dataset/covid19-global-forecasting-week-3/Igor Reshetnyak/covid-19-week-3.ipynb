{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.graph_objects as go\npy.init_notebook_mode()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DT=1\noptimize_model=False \n\noptimize_model_2=False\n\nMake_submission=True \n#n_estimators=450 #200 #400 #500  #1500\n#max_depth=4 #2 #4 #12  #8\n\n\n#{'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 800}\n\nmax_depth=7\nmin_child_weight=2\nn_estimators=600\nlearning_rate=0.1\n\n\n# {'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 500}\n\nmax_depth_2=5\nmin_child_weight_2=5\nn_estimators_2=600\nlearning_rate_2=0.1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/train.csv\")\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For some countries we also have data for individual regions"},{"metadata":{"trusted":true},"cell_type":"code","source":"have_states=train[train['Province_State'].notna()].groupby(['Country_Region'], sort=False)['Province_State'].nunique()\nprint(have_states)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Grouping country names and provinces into variable - location. Adding a true/false variable for Islands."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"def add_location(df_old):\n    df=df_old.copy()\n    df['Date']=pd.to_datetime(df['Date'])\n    df['Country_Region']=df['Country_Region'].fillna('')\n    df['Province_State']=df['Province_State'].fillna('')\n    df['location']=df['Province_State'].astype('str')+\" \"+df['Country_Region'].astype('str')\n    \n    df['Island']=False \n    df.loc[df['Province_State'].str.contains(\"Islan\"),'Island']=True\n    df.loc[df['Province_State'].isin(['French Polynesia',\n       'Guadeloupe', 'Martinique', 'Mayotte', 'New Caledonia', 'Reunion',\n       'Saint Barthelemy','Anguilla', 'Bermuda','Isle of Man', 'Montserrat','Aruba',\n       'Curacao']),'Island']=True \n    \n    df.loc[df['Country_Region'].isin(['Diamond Princess', 'MS Zaandam']),'Island']=True \n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=add_location(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['Province_State']!=\"\") & (train['Island']==False)]['Province_State'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Locations with less than 5 cases:"},{"metadata":{"trusted":true},"cell_type":"code","source":"max_cases_old=train[train['Date']<'2020-04-01'].groupby(['location'], sort=False)['ConfirmedCases'].max()\nmax_cases=train.groupby(['location'], sort=False)['ConfirmedCases'].max()\nprint(\"Now: {}\\r\\nSeven Days ago: {}\".format(len(max_cases[max_cases<5]),len(max_cases_old[max_cases_old<5])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_cases[max_cases<5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.set_index('location',inplace=True)\n\ntrain['day_of_year']=train['Date'].dt.dayofyear\ntrain['day_of_week']=train['Date'].dt.dayofweek\n\n\nfirst_day=train[(train['ConfirmedCases']>0)].groupby(['location'], sort=False)['day_of_year'].min()\nfirst_day.rename('first_day',inplace=True)\n\nday_ten=train[(train['ConfirmedCases']>10)].groupby(['location'], sort=False)['day_of_year'].min()\nday_ten.rename('day_ten',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_days_passed(df_old,first_day,day_ten):\n    df=df_old.copy()\n    df=pd.concat([df,first_day],axis=1,join='inner')\n    \n    df['days_passed']=df['day_of_year']-df['first_day']\n    df.drop(columns=['first_day'],inplace=True)\n    df.loc[df['days_passed']<0,'days_passed']=-1\n    \n    df=df.merge(day_ten,left_index=True,right_index=True,how=\"outer\")\n    \n    df['days_passed_10']=df['day_of_year']-df['day_ten']\n    df.loc[df['day_ten'].isna(),'days_passed_10']=-1\n    df.loc[df['days_passed_10']<0,'days_passed_10']=-1\n    df.drop(columns=['day_ten'],inplace=True)\n   \n    df['location']=df.index\n    \n    df.loc[df['location']=='Hubei China','days_passed']+=35\n    df.loc[df['location']=='Hubei China','days_passed_10']+=22\n    \n    df.set_index('Id',inplace=True)\n    df['Id']=df.index\n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=add_days_passed(train,first_day,day_ten)\n\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_stat=pd.read_csv('../input/countryinfo/covid19countryinfo.csv')\ncountry_stat = country_stat[country_stat['region'].isnull()] \n\nus_stat=pd.read_csv('../input/covid19-state-data/COVID19_state.csv')\nus_stat.rename(columns={'State':'location','Population':'pop','Pop Density':'density','Smoking Rate':'smokers'},inplace=True)\nus_stat['location']+=\" US\"\nus_stat.set_index('location',inplace=True)\n\ndef add_country_stat(old_df,country_stat,us_stat):\n    df=old_df.copy()\n    df=df.merge(country_stat[['country','pop','medianage','sex65plus','lung','smokers','density']],left_on=['Country_Region'],right_on=['country'],how='left')\n    df.drop(columns=['country'],inplace=True)\n    \n    df['pop']=df['pop'].fillna(1000)\n    df['pop']=df['pop'].apply(lambda x: int(str(x).replace(',', '')))\n    #df['gdp2019']=df['gdp2019'].fillna(0)\n    #df['gdp2019']=df['gdp2019'].apply(lambda x: int(str(x).replace(',', '')))\n    #df['gdp2019']=df['gdp2019']/df['pop']\n    \n    \n    df['density']=df['density'].fillna(0)\n    df['medianage']=df['medianage'].fillna(0)\n    #df['sexratio']=df['sexratio'].fillna(1)\n    df['sex65plus']=df['sex65plus'].fillna(1)\n    df['lung']=df['lung'].fillna(24)\n    df['smokers']=df['smokers'].fillna(24)\n    #df['lung']=df['lung']*df['pop']\n    \n    df.set_index('location',inplace=True)\n    df.update(us_stat[['pop','density','smokers']])\n    \n    df['location']=df.index\n    df.set_index('Id',inplace=True)\n    df['Id']=df.index\n    \n    \n    \n    return df\n    \n\ntrain=add_country_stat(train,country_stat,us_stat)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_stat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"us_stat.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weather_info=pd.read_csv(\"../input/climate-change-earth-surface-temperature-data/GlobalLandTemperaturesByCountry.csv\")\nweather_info['dt']=pd.to_datetime(weather_info['dt'])\nweather_info=weather_info[weather_info['dt']>'2000-12-30']\nweather_info['month']=weather_info['dt'].dt.month\nweather_info.drop(weather_info[weather_info['Country'].isin(\n    ['Denmark', 'France', 'Netherlands','United Kingdom'])].index,axis=0,inplace=True)\n\nweather_info.replace(\n   ['Denmark (Europe)', 'France (Europe)', 'Netherlands (Europe)', 'United Kingdom (Europe)'],\n   ['Denmark', 'France', 'Netherlands', 'United Kingdom'],inplace=True)\n\nweather_info.replace({\n    'Antigua And Barbuda':'Antigua and Barbuda',\n    'Bosnia And Herzegovina':'Bosnia and Herzegovina',\n    'Congo (Democratic Republic Of The)':'Congo (Kinshasa)',\n    'Congo':'Congo (Brazzaville)',\n    'Palestina':'West Bank and Gaza',\n    'Cape Verde':'Cabo Verde',\n    \"CÃ´te D'Ivoire\":\"Cote d'Ivoire\",\n    'Trinidad And Tobago':'Trinidad and Tobago',\n    'Saint Kitts And Nevis':'Saint Kitts and Nevis',\n    'Czech Republic':'Czechia',\n    'Swaziland':'Eswatini',\n    'Guinea Bissau':'Guinea-Bissau',\n    'South Korea':'Korea, South', \n    'Macedonia':'North Macedonia',\n    'Saint Vincent And The Grenadines':'Saint Vincent and the Grenadines',\n    'Taiwan':'Taiwan*', \n    'Timor Leste':'Timor-Leste',\n    'United States':'US'\n},inplace=True)\nweather_country=weather_info.groupby(['Country','month'])['AverageTemperature'].mean()\n\n\nstate_weather_info=pd.read_csv(\"../input/climate-change-earth-surface-temperature-data/GlobalLandTemperaturesByState.csv\")\nstate_weather_info.replace({'United States':'US','Georgia (State)':'Georgia','District Of Columbia':'District of Columbia'},inplace=True)\nstate_weather_info['dt']=pd.to_datetime(state_weather_info['dt'])\nstate_weather_info=state_weather_info[state_weather_info['dt']>'2000-12-30']\nstate_weather_info['month']=state_weather_info['dt'].dt.month\nweather_state=state_weather_info[state_weather_info['Country'].isin(have_states.index)].groupby(['Country','State','month'])['AverageTemperature'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def add_temperature(old_df,weather_country,weather_state):\n    df=old_df.copy()\n    df['Month']=df['Date'].dt.month\n    df=df.merge(weather_country,how=\"left\",left_on=['Country_Region','Month'],right_index=True)\n    df=df.merge(weather_state,how=\"left\",left_on=['Country_Region','Province_State','Month'],right_index=True)\n    df.loc[df['AverageTemperature_y'].notnull(),'AverageTemperature_x']=df['AverageTemperature_y']\n    df.drop(columns=['AverageTemperature_y','Month'],inplace=True)\n    df.rename(columns={'AverageTemperature_x':'AverageTemperature'},inplace=True)\n    \n    return df\n\ntrain=add_temperature(train,weather_country,weather_state)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['AverageTemperature'].isnull()]['Country_Region'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"border_info=pd.read_csv(\"../input/country-borders/border_info.csv\")\n#border_info.drop(columns=[\"country_code\",\"country_border_code\"],inplace=True)\nborder_info.replace({'United States of America':'US',\n                    'United Kingdom of Great Britain and Northern Ireland':'United Kingdom',\n                    'Bolivia (Plurinational State Of)':'Bolivia',\n                    'Brunei Darussalam':'Brunei',\n                    'Gambia (the)':'Gambia',\n                     'Congo (the Democratic Republic of the)':'Congo (Kinshasa)',\n                     'Cote dâIvoire':\"Cote d'Ivoire\",\n                     \"Iran (Islamic Republic of)\":'Iran',\n                     \"Korea (the Republic of)\":'Korea, South',\n                    \"Lao People's Democratic Republic\":'Laos',\n                     \"Moldova (the Republic of)\":'Moldova',\n                     'Myanmar':'Burma',\n                     'Palestine, State of':'West Bank and Gaza',\n                     \"Russian Federation\":'Russia',\n                    \"Syrian Arab Republic\":'Syria',\n                     \"Taiwan (Province of China)\":'Taiwan*',\n                    \"Tanzania (the United Republic of)\":'Tanzania',\n                     \"Venezuela (Bolivarian Republic of)\":'Venezuela',\n                     \"Viet Nam\":'Vietnam'},inplace=True)\nborder_info=border_info.fillna(\"\")\n#border_info.to_csv(\"border_info.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#set(border_info['country_name'].unique()).difference(set(train['Country_Region'].unique()))\nset(train['Country_Region'].unique()).difference(set(border_info['country_name'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from itertools import product as it_product\ndef expand_grid(data_dict):\n  rows = it_product(*data_dict.values())\n  return pd.DataFrame.from_records(rows, columns=data_dict.keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skel=expand_grid({'Index':border_info.index,'Date':train['Date'].unique()})\n\ncountry_info=train.groupby(['Date','Country_Region'])['ConfirmedCases'].sum()\n\nskel=skel.merge(border_info, how='inner', left_on=['Index'],right_index=True)\nskel=skel.merge(country_info, how='inner', \n                left_on=['Date','country_border_name'],right_on=['Date','Country_Region'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from datetime import timedelta\nskel['Date']=skel['Date']+timedelta(days=DT)\nborder_cases=skel.groupby(['country_name','Date'])['ConfirmedCases'].sum()\nlen(skel['country_name'].unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train=train.merge(border_cases, how='left', left_on=['Country_Region','Date'],right_on=['country_name','Date'])\ntrain['ConfirmedCases_y']=train['ConfirmedCases_y'].fillna(0)\ntrain.rename(columns={'ConfirmedCases_y':'ConfirmedCases_neighbors','ConfirmedCases_x':'ConfirmedCases'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train = pd.concat([train,pd.get_dummies(train['location'], prefix='loc')],axis=1)\nbig_train['ConfirmedCases_neighbors']=np.log1p(big_train['ConfirmedCases_neighbors'])\nbig_train.reset_index(inplace=True)\nbig_train.drop(columns=[\"Id\"],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def df_add_deltas(df_old):\n    df=df_old.copy()\n    df=df.sort_values(by=['location', 'Date'])\n    df['d_ConfirmedCases'] = df.groupby(['location'])['ConfirmedCases'].diff()\n    df['d_Fatalities'] = df.groupby(['location'])['Fatalities'].diff()\n    df.loc[df['d_Fatalities']<0,'d_Fatalities']=0\n    df.loc[df['d_ConfirmedCases']<0,'d_ConfirmedCases']=0\n    \n    df['prev_ConfirmedCases']=df['ConfirmedCases']-df['d_ConfirmedCases']\n    df['prev_Fatalities']=df['Fatalities']-df['d_Fatalities']\n    \n    #df['prev_ConfirmedCases']=np.log1p(df['prev_ConfirmedCases'])\n    #df['prev_Fatalities']=np.log1p(df['prev_Fatalities'])\n    \n    df['growth_ConfirmedCases']=df['d_ConfirmedCases']/(df['prev_ConfirmedCases']+1)\n    df['growth_Fatalities']=df['d_Fatalities']/(df['prev_Fatalities']+1)\n    \n    df['growth_ConfirmedCases']=np.log1p(df['growth_ConfirmedCases'])\n    df['growth_Fatalities']=np.log1p(df['growth_Fatalities'])\n    \n    df.drop(columns=['prev_ConfirmedCases','prev_Fatalities'], inplace=True)\n    \n    \n    first_day_stat=df[df['Date']=='2020-01-22']\n    df.drop(df[df['Date']=='2020-01-22'].index, inplace=True)\n    \n    return df,first_day_stat\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train,first_day_stat=df_add_deltas(big_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train.reset_index(inplace=True,drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=big_train.drop(columns=['Province_State','Country_Region','Date','ConfirmedCases','Fatalities','location',\n                          'd_ConfirmedCases','d_Fatalities','growth_ConfirmedCases','growth_Fatalities'])\n\ny=big_train['d_ConfirmedCases']\ny_2=big_train['d_Fatalities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_day=X['day_of_year'].max()\nmask_train=X['day_of_year']<max_day-DT+1\nmask_test=X['day_of_year']>=max_day-DT+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train=X[mask_train]\nX_test=X[mask_test]\n\n\ny_train=y[mask_train]\ny_test=y[mask_test]\n\ny_train_2=y_2[mask_train]\ny_test_2=y_2[mask_test]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test['day_of_year'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nfrom matplotlib import pyplot as plt\n\ncorr = big_train[['d_ConfirmedCases','d_Fatalities','days_passed','ConfirmedCases_neighbors','pop',\n                  'medianage','sex65plus','lung','smokers','density','Island','growth_ConfirmedCases',\n                  'growth_Fatalities','AverageTemperature','days_passed_10'#,'prev_ConfirmedCases','prev_Fatalities'\n                 ]].corr(\"spearman\")\nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(12,12))\n    ax = sns.heatmap(corr, annot=True,cmap=\"YlGnBu\",vmax=.3, square=True, linewidths=.3)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(big_train[(big_train['growth_ConfirmedCases']==0)]['growth_ConfirmedCases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(big_train[(big_train['growth_ConfirmedCases']>0)]['growth_ConfirmedCases'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train[(big_train['growth_ConfirmedCases']>0) & (big_train['growth_ConfirmedCases']<=1)]['growth_ConfirmedCases'].hist(bins=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train[(big_train['growth_ConfirmedCases']<2) & (big_train['Country_Region']=='Italy')],x='Date',y='growth_ConfirmedCases')\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig1 = px.scatter(big_train[(big_train['Country_Region']=='Italy')],x='Date',y='d_ConfirmedCases')\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.drop(columns=['day_of_year'],inplace=True)  #including day of year makes things worse RMLSE goes up from 0.49 to 0.7\nX_test.drop(columns=['day_of_year'],inplace=True)   #including day of year makes things worse RMLSE goes up from 0.49 to 0.7\n\nX_train.drop(columns=['day_of_week'],inplace=True)  #including day of week makes things worse RMLSE goes up from 0.49 to 0.57\nX_test.drop(columns=['day_of_week'],inplace=True)   #including day of week makes things worse RMLSE goes up from 0.49 to 0.57\n\nX.drop(columns=['day_of_year'],inplace=True)  \nX.drop(columns=['day_of_week'],inplace=True)   \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(columns=['index'],inplace=True)   \nX_train.drop(columns=['index'],inplace=True)\nX_test.drop(columns=['index'],inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best: -1.094395 using {'max_depth': 6, 'n_estimators': 400}\n\nimport xgboost as xgb\nfrom sklearn.model_selection import GridSearchCV\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42)\n    n_estimators_grid = [400,600,800,1000]\n    max_depth_grid = [6]\n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best: -1.039208 using {'max_depth': 6, 'n_estimators': 200}\n\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42)\n    n_estimators_grid = [100,200,300,400]\n    max_depth_grid = [6]\n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best: -0.968577 using {'max_depth': 7, 'min_child_weight': 5, 'n_estimators': 200}\n\n#Best: -0.944948 using {'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200}\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42)\n\n    max_depth_grid = [5,6,7]\n    min_child_weight_grid =[1,3,5,7]\n    n_estimators_grid=[200]\n    \n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid,min_child_weight=min_child_weight_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Best: -0.964721 using {'max_depth': 7, 'min_child_weight': 6, 'n_estimators': 200\n\n# Best: -0.944948 using {'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 200}\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42)\n\n    max_depth_grid = [7,8]\n    min_child_weight_grid =[2,3,4]\n    n_estimators_grid=[200]\n    \n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid,min_child_weight=min_child_weight_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best: -1.039208 using {'max_depth': 6, 'n_estimators': 200}\n\n#Best: -0.939250 using {'max_depth': 6, 'min_child_weight': 3, 'n_estimators': 800}\n\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42,learning_rate=0.1)\n    n_estimators_grid = [200,400,600,800]\n    max_depth_grid = [7]\n    min_child_weight_grid =[2]\n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid, min_child_weight=min_child_weight_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best: -0.944889 using {'max_depth': 8, 'min_child_weight': 7, 'n_estimators': 800}\n\n#Best: -0.926787 using {'max_depth': 5, 'min_child_weight': 4, 'n_estimators': 800}\n\nif optimize_model:\n\n    model = xgb.XGBRegressor(random_state=42,learning_rate=0.1)\n    n_estimators_grid = [600]\n    max_depth_grid = [6,7,8]\n    min_child_weight_grid =[1,2,3]\n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid, min_child_weight=min_child_weight_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['d_Confirmed']=np.log1p(y)\n\n#Best: -0.514411 using {'max_depth': 5, 'min_child_weight': 5, 'n_estimators': 400}\n\nif optimize_model_2:\n\n    model = xgb.XGBRegressor(random_state=42,learning_rate=0.1)\n    n_estimators_grid = [400,600,800,1000]\n    max_depth_grid = [5]\n    min_child_weight_grid = [5] \n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid,min_child_weight=min_child_weight_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y_2))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Best: -0.507334 using {'max_depth': 4, 'min_child_weight': 5, 'n_estimators': 400}\n\nif optimize_model_2:\n\n    model = xgb.XGBRegressor(random_state=42,learning_rate=0.1)\n    n_estimators_grid = [600]\n    max_depth_grid = [4,5]\n    min_child_weight_grid = [1,3,5,7] \n    param_grid = dict(max_depth=max_depth_grid, n_estimators=n_estimators_grid,min_child_weight=min_child_weight_grid)\n    grid_search = GridSearchCV(model, param_grid, scoring=\"neg_root_mean_squared_error\", n_jobs=-1, cv=[(X[mask_train].index,X[mask_test].index)], verbose=1)\n    grid_result = grid_search.fit(X,np.log1p(y_2))\n    # summarize results\n    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n    print(grid_result.cv_results_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = xgb.XGBRegressor(n_estimators=n_estimators,\n    max_depth=max_depth,\n    min_child_weight=min_child_weight,\n    learning_rate=learning_rate,\n    random_state=42)\nreg_2 = xgb.XGBRegressor(n_estimators=n_estimators_2,\n    max_depth=max_depth_2,\n    min_child_weight=min_child_weight_2,\n    learning_rate=learning_rate_2,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg.fit(X_train,np.log1p(y_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = xgb.plot_importance(reg, max_num_features=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = reg.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nnp.sqrt(mean_squared_error(y_pred,np.log1p(y_test)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_2=X_train.copy()\nX_train_2['d_confirmed']=np.log1p(y_train)  \nX_test_2=X_test.copy()\nX_test_2['d_confirmed']=y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg_2.fit(X_train_2,np.log1p(y_train_2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot = xgb.plot_importance(reg_2, max_num_features=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_2 = reg_2.predict(X_test_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.sqrt(mean_squared_error(y_pred_2,np.log1p(y_test_2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/test.csv\")\ntest.rename(columns={'ForecastId':'Id'},inplace=True)\ntest=add_location(test)\n\ntest.set_index('location',inplace=True)\n\ntest['day_of_year']=test['Date'].dt.dayofyear\ntest['day_of_week']=test['Date'].dt.dayofweek\ntest=add_days_passed(test,first_day,day_ten)\ntest=add_country_stat(test,country_stat,us_stat)\ntest=add_temperature(test,weather_country,weather_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_to_predict=test['Date'].unique()\ndays_to_predict.sort()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"big_train=big_train.drop(columns=[\"index\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"known=big_train['Date'].unique()\nprint(known)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    results=[]\n    full_results=[]\n\n    for d in days_to_predict:\n        print(\"Predicting {}\".format(d))\n        if d in known:\n            print(\"Data Known\")\n        \n            X=big_train.drop(columns=['Province_State','Country_Region','ConfirmedCases','Fatalities','location','Date',\n                                  'day_of_year','day_of_week','d_ConfirmedCases','d_Fatalities','growth_Fatalities',\n                                      'growth_ConfirmedCases'])\n\n            y=big_train['d_ConfirmedCases']\n            y_2=big_train['d_Fatalities']\n        \n            mask_train=big_train['Date']<d\n            mask_val=big_train['Date']==d\n        \n            X_train=X[mask_train]\n            y_train=y[mask_train]\n            y_train_2=y_2[mask_train]\n        \n            X_val=X[mask_val]\n            y_val=y[mask_val]\n            y_val_2=y_2[mask_val]\n        \n            reg = xgb.XGBRegressor(n_estimators=n_estimators,\n                                   max_depth=max_depth,\n                                   min_child_weight=min_child_weight,\n                                   learning_rate=learning_rate,random_state=42)\n            reg_2 = xgb.XGBRegressor(n_estimators=n_estimators_2,\n                                   max_depth=max_depth_2,\n                                   min_child_weight=min_child_weight_2,\n                                   learning_rate=learning_rate_2,random_state=42)\n        \n            reg.fit(X_train,np.log1p(y_train))\n        \n            y_pred = reg.predict(X_val)\n            print(\"MSLE {}\".format(mean_squared_error(y_pred,np.log1p(y_val))))\n        \n            X_train_2=X_train.copy()\n            X_train_2['d_ConfirmedCases']=np.log1p(y_train)  #0.4412899060661785 <- without , with - 0.4463  \n            X_val_2=X_val.copy()\n            X_val_2['d_ConfirmedCases']=y_pred\n        \n            reg_2.fit(X_train_2,np.log1p(y_train_2))\n        \n            y_pred_2 = reg_2.predict(X_val_2)\n        \n            print(\"MSLE {}\".format(mean_squared_error(y_pred_2,np.log1p(y_val_2))))\n        \n        #result=X_test[['']]\n        elif d-np.timedelta64(86400000000000,'ns') in known:\n            print(\"Data Known\")\n        \n            X=big_train.drop(columns=['Province_State','Country_Region','ConfirmedCases','Fatalities','location','Date',\n                                  'day_of_year','day_of_week','d_ConfirmedCases','d_Fatalities','growth_Fatalities',\n                                      'growth_ConfirmedCases'])\n\n            y=big_train['d_ConfirmedCases']\n            y_2=big_train['d_Fatalities']\n        \n            mask_train=big_train['Date']<d\n        \n            X_train=X[mask_train]\n            y_train=y[mask_train]\n            y_train_2=y_2[mask_train]\n        \n        \n            reg = xgb.XGBRegressor(n_estimators=n_estimators,\n                                   max_depth=max_depth,\n                                   min_child_weight=min_child_weight,\n                                   learning_rate=learning_rate,random_state=42)\n            reg_2 = xgb.XGBRegressor(n_estimators=n_estimators_2,\n                                   max_depth=max_depth_2,\n                                   min_child_weight=min_child_weight_2,\n                                   learning_rate=learning_rate_2,random_state=42)\n        \n            reg.fit(X_train,np.log1p(y_train))\n        \n            X_train_2=X_train.copy()\n            X_train_2['d_ConfirmedCases']=np.log1p(y_train)  #0.4412899060661785 <- without , with - 0.4463  \n            \n            reg_2.fit(X_train_2,np.log1p(y_train_2))\n        \n        \n        \n        X_test=test[test['Date']==d]\n    \n        day=X_test['day_of_year'].iloc[0]\n    \n        country_info=big_train[big_train['day_of_year']==day-1].groupby(['Country_Region'])['ConfirmedCases'].sum()\n    \n        border_cases=border_info.merge(country_info, how='inner', \n                left_on=['country_border_name'],right_on=['Country_Region'])\n    \n        border_cases=border_cases.groupby(['country_name'])['ConfirmedCases'].sum()\n        border_cases=border_cases.rename('ConfirmedCases_neighbors')\n    \n        X_test=X_test.merge(border_cases, how='left', left_on=['Country_Region'],right_on=['country_name'])\n        X_test['ConfirmedCases_neighbors']=X_test['ConfirmedCases_neighbors'].fillna(0)\n    \n        X_test = pd.concat([X_test,pd.get_dummies(X_test['location'], prefix='loc')],axis=1)\n        X_test['ConfirmedCases_neighbors']=np.log1p(X_test['ConfirmedCases_neighbors'])\n        \n        #X_test=X_test.merge(big_train[big_train['day_of_year']==day-1][['location','ConfirmedCases','Fatalities']], how='left', \n        #         left_on=['location'],right_on=['location'])\n        #X_test.rename(columns={'ConfirmedCases':'prev_ConfirmedCases','Fatalities':'prev_Fatalities'},inplace=True)\n        \n        #X_test['prev_ConfirmedCases']=np.log1p(X_test['prev_ConfirmedCases'])\n        #X_test['prev_Fatalities']=np.log1p(X_test['prev_Fatalities'])\n        \n    \n        X_test.set_index('Id',inplace=True)\n    \n    #print(X_test.head(5))\n    \n        y_test=reg.predict(X_test.drop(columns=['Province_State','Country_Region','location','Date','day_of_year','day_of_week']))\n    \n    #print(y_test)\n    \n        X_test['d_ConfirmedCases']=y_test\n    \n        y_test=reg_2.predict(X_test.drop(columns=['Province_State','Country_Region','location','Date',\n                                            'day_of_year','day_of_week']))\n    \n        X_test['d_Fatalities']=y_test\n    \n    #print(X_test.shape)\n    \n        X_test['Id']=X_test.index\n    \n        X_test=X_test.merge(big_train[big_train['day_of_year']==day-1][['location','ConfirmedCases','Fatalities']], how='left', \n                 left_on=['location'],right_on=['location'])\n    \n    #print(X_test.head(5))\n    \n    #X_test.set_index('Id',inplace=True)\n    \n    #print(X_test.shape)\n    \n        X_test.set_index('Id',inplace=True)\n    \n        #print(X_test.head(5))\n        \n        X_test['d_ConfirmedCases']=np.expm1(X_test['d_ConfirmedCases'])\n        X_test['d_Fatalities']=np.expm1(X_test['d_Fatalities'])\n    \n        X_test['ConfirmedCases']+=X_test['d_ConfirmedCases']\n        X_test['Fatalities']+=X_test['d_Fatalities']\n       \n    \n    \n        results.append(X_test[['ConfirmedCases','Fatalities']])\n        full_results.append(X_test)\n    \n        if not d in known: #Needed to correctly get data on neighbors         \n            big_train=pd.concat([big_train,X_test])\n    \n    \n    \n    \n    \n    \n    \n    \n        \n        \n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if Make_submission==True:\n    submission=pd.read_csv(\"../input/covid19-global-forecasting-week-3/submission.csv\")\n    submission.drop(columns=['ConfirmedCases','Fatalities'],inplace=True)\n    submission=submission.merge(pd.concat(results),left_on=['ForecastId'],right_index=True).clip(lower=0)\n    submission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"full_res=pd.concat(full_results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrained=big_train[(big_train['loc_ Ukraine']==1) & (big_train['Date']<'2020-04-02')][['Date','ConfirmedCases','Fatalities']]\nprediction=full_res[full_res['loc_ Ukraine']==1][['Date','ConfirmedCases','Fatalities']]\nfig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\nfig1.add_trace(go.Scatter(\n        x=prediction[\"Date\"],\n        y=prediction[\"ConfirmedCases\"],\n        mode=\"lines\",\n        line=go.scatter.Line(color=\"red\"),\n        showlegend=False))\n\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained=big_train[(big_train['loc_ Switzerland']==1) & (big_train['Date']<'2020-04-02')][['Date','ConfirmedCases','Fatalities']]\nprediction=full_res[full_res['loc_ Switzerland']==1][['Date','ConfirmedCases','Fatalities']]\nfig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\nfig1.add_trace(go.Scatter(\n        x=prediction[\"Date\"],\n        y=prediction[\"ConfirmedCases\"],\n        mode=\"lines\",\n        line=go.scatter.Line(color=\"red\"),\n        showlegend=False))\n\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained=big_train[(big_train['loc_ Italy']==1) & (big_train['Date']<'2020-04-02')][['Date','ConfirmedCases','Fatalities']]\nprediction=full_res[full_res['loc_ Italy']==1][['Date','ConfirmedCases','Fatalities']]\nfig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\nfig1.add_trace(go.Scatter(\n        x=prediction[\"Date\"],\n        y=prediction[\"ConfirmedCases\"],\n        mode=\"lines\",\n        line=go.scatter.Line(color=\"red\"),\n        showlegend=False))\n\nfig1.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trained=big_train[(big_train['loc_ France']==1) & (big_train['Date']<'2020-04-02')][['Date','ConfirmedCases','Fatalities']]\nprediction=full_res[full_res['loc_ France']==1][['Date','ConfirmedCases','Fatalities']]\nfig1 = px.scatter(trained, x=\"Date\", y=\"ConfirmedCases\")\n\nfig1.add_trace(go.Scatter(\n        x=prediction[\"Date\"],\n        y=prediction[\"ConfirmedCases\"],\n        mode=\"lines\",\n        line=go.scatter.Line(color=\"red\"),\n        showlegend=False))\n\nfig1.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}