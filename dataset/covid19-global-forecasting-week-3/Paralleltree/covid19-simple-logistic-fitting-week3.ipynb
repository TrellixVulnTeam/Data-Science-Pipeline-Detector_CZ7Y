{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this Notebook, we attempt to fit the number of confirmed and deceased cases by a logistic curve."},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import sys\nimport numpy as np\nimport pandas as pd\nfrom joblib import Parallel, delayed\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import GridSearchCV\nfrom scipy.optimize import curve_fit","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/train.csv', parse_dates=['Date'])\ndf_train = df_train.replace(np.nan, '', regex=True) # replace nan in Province_State with empty string\nagg_unit = ['Country_Region', 'Province_State'] # an argument of the groupby method\n\ndf_pops = pd.read_csv('/kaggle/input/population-by-country-2020/population_by_country_2020.csv')\npops = dict(zip(df_pops['Country (or dependency)'], df_pops['Population (2020)']))\npops['US'] = pops['United States']\npops['Korea, South'] = pops['South Korea']\npops['Congo (Brazzaville)'] = pops['DR Congo']\npops['Congo (Kinshasa)'] = pops['DR Congo']\npops['Taiwan*'] = pops['Taiwan']\npops['Saint Vincent and the Grenadines'] = pops['St. Vincent & Grenadines']\npops['Saint Kitts and Nevis'] = pops['Saint Kitts & Nevis']\npops['Czechia'] = pops['Czech Republic (Czechia)']\npops['Cote d\\'Ivoire'] = pops['CÃ´te d\\'Ivoire']\npops['Diamond Princess'] = 3000\npops['Burma'] = pops['Myanmar']\npops['West Bank and Gaza'] = pops['State of Palestine']\npops['Kosovo'] = 1847708\npops['MS Zaandam'] = 3000\n\nunmapped_countries = list(df_train['Country_Region'].unique()) - pops.keys()\nif len(unmapped_countries) > 0:\n    print('warn: There are unmapped population data: ', end='', file=sys.stderr)\n    print(*unmapped_countries, sep=', ', file=sys.stderr)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fix non-cumulative records\ndf_train[['ConfirmedCases', 'Fatalities']] = df_train.groupby(agg_unit)[['ConfirmedCases', 'Fatalities']].transform('cummax')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# set the first confirmed date to each rows\ndf_train['FirstConfirmedDateCountry'] = df_train.query('ConfirmedCases>0').groupby(agg_unit)['Date'].transform('min')\ndf_train['FirstDeceasedDateCountry'] = df_train.query('Fatalities>0').groupby(agg_unit)['Date'].transform('min')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['DaysSinceFirstConfirmed'] = (df_train['Date'] - df_train['FirstConfirmedDateCountry']).dt.days\ndf_train['DaysSinceFirstDeceased'] = (df_train['Date'] - df_train['FirstDeceasedDateCountry']).dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing an output dataframe\ndf_test = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/test.csv', parse_dates=['Date'])\ndf_test = df_test.replace(np.nan, '', regex=True)\ndf_test['ConfirmedCases'] = 0\ndf_test['Fatalities'] = 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Definition\n\nNow we use logistic curve as a model to fit.\n\nLogistic model can be defined the below equation:\n\n$$\n\\frac{\\mathrm{d}y}{\\mathrm{d}t} = k\\left(1 - \\frac{y}{c}\\right) y\n$$\n\nThe variable $c$ is called carrying capacity.\n\nBy solving this differential equation, we can get following equation as a logistic function.\n\n$$\ny = \\frac{c}{be^{-kt} + 1}\n$$\n\nWhat to do next is estimating the constants $k$, $b$, and $c$.\n\nThe below class is an estimator for these constants using `scipy.optimize.curve_fit` by specifing some parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"class LogisticCurve:\n    def __init__(self, k_init=1, c_init=1,\n                 k_lower=-np.inf, k_upper=np.inf,\n                 c_lower=-np.inf, c_upper=np.inf):\n        self.k_init = k_init\n        self.c_init = c_init\n        self.k_lower, self.k_upper = k_lower, k_upper\n        self.c_lower, self.c_upper = c_lower, c_upper\n        self.k = k_init\n        self.b = c_init\n        self.c = c_init\n\n\n    def logistic_func(self, x, k, b, c):\n        return c / (b * np.exp(-k * x) + 1)\n\n    def fit(self, xs, ys):\n        from scipy.optimize import curve_fit\n        p0 = [self.k_init, self.c_init, self.c_init]\n        bounds = [(self.k_lower, self.c_lower, self.c_lower), (self.k_upper, self.c_upper, self.c_upper)]\n        try:\n            params, pcov = curve_fit(self.logistic_func, xs, ys, p0=p0, bounds=bounds, maxfev=100000)\n            self.k, self.b, self.c = params\n        except RuntimeError:\n            pass\n        return self\n\n    def predict(self, xs):\n        return self.logistic_func(xs, self.k, self.b, self.c)\n\n    def get_params(self, deep=False):\n        return { \n            'k_init': self.k_init,\n            'c_init': self.c_init,\n            'k_lower': self.k_lower,\n            'k_upper': self.k_upper,\n            'c_lower': self.c_lower,\n            'c_upper': self.c_upper\n        }\n    \n    def set_params(self, **params):\n        for param, value in params.items():\n            setattr(self, param, value)\n        return self\n\n    def get_estimated_params(self):\n        return [self.k, self.b, self.c]\n\n    def set_curve_params(self, k, b, c):\n        self.k = k\n        self.b = b\n        self.c = c\n        return self","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fitting and Prediction\nLet us estimate constants of logistic curve for each regions.\n\nWe use joblib to parallelize the estimation process of each regions to make our code run fast!\n\nFirst, we define the estimating function to pass runner:"},{"metadata":{"trusted":true},"cell_type":"code","source":"def estimate_column_params(df, xcol, ycol, maximum):\n    try:\n        init_count = df[df[xcol] == 0][ycol].iloc[0]\n    except IndexError:\n        return None\n    \n    rows = df[df[xcol] >= 0]\n\n    mcv = LogisticCurve(c_lower=0, c_upper=maximum)\n    mcv.fit(rows[xcol], rows[ycol])\n    return mcv.get_estimated_params()\n\n    cv = [(list(range(len(train_data))), list(range(len(train_data), len(rows))))]\n    mcv = GridSearchCV(LogisticCurve(k_lower=1e-18, c_lower=0, c_upper=maximum), { 'k_init': [0.1, 1], 'k_upper': [1, 10], 'c_init': [0, init_count] }, cv=cv, scoring='neg_root_mean_squared_error')\n    mcv.fit(rows[xcol], rows[ycol])\n    return mcv.best_estimator_.get_estimated_params()\n    \ndef estimate_params(df, maximum):\n    return [estimate_column_params(df, 'DaysSinceFirstConfirmed', 'ConfirmedCases', maximum), estimate_column_params(df, 'DaysSinceFirstDeceased', 'Fatalities', maximum)]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By using above function, let us start estimation."},{"metadata":{"trusted":true},"cell_type":"code","source":"# estimate params with parallelism, then map result to corresponding region.\nestimated_params = dict(Parallel(n_jobs=-1, verbose=8)([delayed(lambda label, df, maximum: [label, estimate_params(df, maximum)])((country, state), df, pops[country]) for (country, state), df in df_train.groupby(agg_unit)]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"After parameter estimation, we predict the number of cases."},{"metadata":{"trusted":true},"cell_type":"code","source":"# make prediction with estimaed params\nfor (country, state), df in df_train.groupby(agg_unit):\n    cparams, fparams = estimated_params[(country, state)]\n    \n    try:\n        first_confirmed_on = df[df['DaysSinceFirstConfirmed'] == 0]['Date'].iloc[0]\n        df_test.loc[(df_test['Country_Region'] == country) & (df_test['Province_State'] == state), 'FirstConfirmedDate'] = first_confirmed_on\n        df_test['DaysSinceFirstConfirmed'] = (df_test['Date'] - df_test['FirstConfirmedDate']).dt.days\n        if cparams is not None:\n            mcv1 = LogisticCurve().set_curve_params(*cparams)\n            df_train.loc[(df_train['Country_Region'] == country) & (df_train['Province_State'] == state), 'PredictedConfirmedCases'] = mcv1.predict(df_train.loc[(df_train['Country_Region'] == country) & (df_train['Province_State'] == state), 'DaysSinceFirstConfirmed'])\n            df_test.loc[(df_test['Country_Region'] == country) & (df_test['Province_State'] == state), 'ConfirmedCases'] = mcv1.predict(df_test.loc[(df_test['Country_Region'] == country) & (df_test['Province_State'] == state), 'DaysSinceFirstConfirmed'])\n    except IndexError:\n        continue\n    \n    try:\n        first_deceased_on = df[df['DaysSinceFirstDeceased'] == 0]['Date'].iloc[0]\n        df_test.loc[(df_test['Country_Region'] == country) & (df_test['Province_State'] == state), 'FirstDeceasedDate'] = first_deceased_on\n        df_test['DaysSinceFirstDeceased'] = (df_test['Date'] - df_test['FirstDeceasedDate']).dt.days\n        if fparams is not None:\n            mcv2 = LogisticCurve().set_curve_params(*fparams)\n            df_train.loc[(df_train['Country_Region'] == country) & (df_train['Province_State'] == state), 'PredictedFatalities'] = mcv2.predict(df_train.loc[(df_train['Country_Region'] == country) & (df_train['Province_State'] == state), 'DaysSinceFirstDeceased'])\n            df_test.loc[(df_test['Country_Region'] == country) & (df_test['Province_State'] == state), 'Fatalities'] = mcv2.predict(df_test.loc[(df_test['Country_Region'] == country) & (df_test['Province_State'] == state), 'DaysSinceFirstDeceased'])\n    except IndexError:\n        continue","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, let us make some figures to check the estimated parameters."},{"metadata":{"trusted":true},"cell_type":"code","source":"# picking up countries to visualize\nfor (country, state), df in df_train.groupby(agg_unit):\n    if country not in ['Italy', 'Spain', 'Japan', 'Russia']:\n        continue\n    \n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 5))\n    fig.suptitle(f'{country} {state}')\n    \n    c = df.query('DaysSinceFirstConfirmed>=0').set_index('DaysSinceFirstConfirmed').sort_index()\n    if len(c) == 0:\n        continue\n    c['ConfirmedCases'].plot(label='Actual', ax=ax1)\n    c['PredictedConfirmedCases'].plot(label='Fitted', ax=ax1)\n    ax1.legend()\n    \n    c = df.query('DaysSinceFirstDeceased>=0').set_index('DaysSinceFirstDeceased').sort_index()\n    if len(c) == 0:\n        continue\n    c['Fatalities'].plot(label='Actual', ax=ax2)\n    c['PredictedFatalities'].plot(label='Fitted', ax=ax2)\n    ax1.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Evaluation and Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_eval = pd.merge(df_train.rename(columns={ 'ConfirmedCases': 'c1', 'Fatalities': 'f1' }), df_test.rename(columns={ 'ConfirmedCases': 'c2', 'Fatalities': 'f2' }), on=['Country_Region', 'Province_State', 'Date'])\n\nerror = 0\nfor (err, actual, pred) in [('cerr', 'c1', 'c2'), ('ferr', 'f1', 'f2')]:\n    df_eval[err] = np.square(np.log(df_eval[actual] + 1) - np.log(df_eval[pred] + 1))\n    colerr = np.sqrt(df_eval[err].sum() / len(df_eval))\n    error += colerr\n    print(f'RMSLE({err}):', colerr)\n\nprint('RMSLE:', error)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally, we write out the prediction into a file."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.to_csv('submission.csv', index=False, columns=['ForecastId', 'ConfirmedCases', 'Fatalities'])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}