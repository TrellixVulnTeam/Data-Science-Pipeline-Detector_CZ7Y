{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom itertools import count\nfrom random import shuffle\nimport time\nfrom copy import deepcopy\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dateToInt(date):\n    days = [0, 31, 29, 31, 30, 31, 30, 31, 31, 30, 31]\n    month, day = tuple(int(i) for i in date.split('-')[1:])\n    return sum(days[:month]) + day - 22\ndateToInt(\"2020-01-22\")\ndateToInt(\"2020-04-04\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def findDuplicates(l):\n    duplicates = list()\n    idxs = list()\n    seen = dict()\n    for i, element in enumerate(l):\n        if element in seen:\n            idx = seen[element]\n            duplicates.append(i)\n            idxs.append(idx)\n        seen.update({element: i})\n    return duplicates, idxs\nfindDuplicates([1, 2, 3, 4, 1, 2, 3, 4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Installs adabound\nimport sys\nfrom subprocess import call\ncall([sys.executable, '-m', 'pip', 'install', 'adabound'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testname = \"/kaggle/input/covid19-global-forecasting-week-3/test.csv\"\nptest = pd.read_csv(testname)\ntestnames = [p[1] if type(p[1]) is str else p[2] for p in ptest.to_numpy()]\nptest","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"trainname = \"/kaggle/input/covid19-global-forecasting-week-3/train.csv\"\nptrain = pd.read_csv(trainname)\nnptrain = ptrain.to_numpy()\nnames = set()\nprovinces = set()\npdatas = dict()\nfor data in nptrain:\n    name = data[2]\n    names.add(name)\nfor name in names:\n    pdatas.update({name: ptrain[ptrain[\"Country_Region\"] == name].to_numpy()})\nfor name, data in list(pdatas.items()):\n    for d in data:\n        state = d[1]\n        if type(state) is float or state in provinces:\n            continue\n        try:\n            if name not in (\"Canada\",) and name not in testnames:\n                del pdatas[name]\n                names.remove(name)\n        except:\n            pass\n        names.add(state)\n        provinces.add(state)\n        pdatas.update({state: ptrain[ptrain[\"Province_State\"] == state].to_numpy()})\ncounter = 0\nstuff = [0 for i in range(72)]\nfor i in pdatas[\"Illinois\"]:\n    stuff[counter % 72] += i[-2]\n    counter += 1\n# pdatas[\"California\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"oldxbycountry = dict()\noldybycountry = dict()\nxbycountry = dict()\nybycountry = dict()\nshufflexbycountry = dict()\nshuffleybycountry = dict()\n\nfor name in names:\n    data = pdatas[name]\n    countryx = [dateToInt(p[3]) for p in data]\n    countryy = [p[4:] for p in data]\n    oldxbycountry.update({name: countryx})\n    oldybycountry.update({name: countryy})\nl = len(oldxbycountry[\"Italy\"])\nfor name in names:\n    scheme = list(range(l))\n    shuffle(scheme)\n    newx = list(0 for i in range(l))\n    newy = list([0, 0] for i in range(l))\n    shufflex = list(0 for i in range(l))\n    shuffley = list([0,0] for i in range(l))\n    for i, x, y in zip(count(), oldxbycountry[name], oldybycountry[name]):\n        newx[i%l] = x\n        newy[i%l][0] += y[0]\n        newy[i%l][1] += y[1]\n        shufflex[scheme[i%l]] = x\n        shuffley[scheme[i%l]][0] += y[0]\n        shuffley[scheme[i%l]][1] += y[1]\n    xbycountry.update({name: np.array(newx)})\n    ybycountry.update({name: np.array(newy)})\n    shufflexbycountry.update({name: np.array(shufflex)})\n    shuffleybycountry.update({name: np.array(shuffley)})\nlen(ybycountry[\"California\"])\nxbycountry[\"California\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport adabound","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, criterion, optimizer, x, y, limit):\n    beg = time.time()\n    try:\n        for epoch in count():\n            model.train()\n            optimizer.zero_grad()\n            y_pred = model(x)\n            loss = criterion(y_pred, y)\n            if epoch % 5000 == 0:\n                print(\"Epoch:\", epoch + 0*120000, \"\\tLoss:\", loss.item())\n            loss.backward()\n            optimizer.step()\n            seconds = time.time() - beg\n            if seconds > limit:\n                break\n    except KeyboardInterrupt:\n        pass\n    return model, criterion, optimizer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Model(nn.Module):\n    def __init__(self, deg=1):\n        super(Model, self).__init__()\n        self.fc1 = nn.Linear(deg, 2)\n        self.sigmoid = nn.Sigmoid()\n        self.fc2 = nn.Linear(2, 2)\n    def forward(self, x):\n        return self.fc2(self.sigmoid(self.fc1(x/70)))\n\nloosex = torch.FloatTensor([[pow(i, p) for p in (2,1)] for i in shufflexbycountry[\"Canada\"]])\nloosey = torch.FloatTensor([[float(i[0]/1e4), float(i[1]/2e2)] for i in shuffleybycountry[\"Canada\"]])\n\nm = Model(2)\nloosemodel = train(\n    m,\n    nn.MSELoss(),\n    adabound.AdaBound(m.parameters(), lr=1e-3, final_lr=.1),\n    loosex,\n    loosey,\n    10\n)[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models = dict()\ncnames = names\n# cnames = (\"California\", \"Vietnam\")\n\nfor cname in cnames:\n    if cname == \"Canada\":\n        continue\n    cases = max(i[0] for i in ybycountry[cname])\n    small = cases < 30000\n    rllysmall = cases < 5000\n    xsmall = cases < 100\n    print(small, rllysmall, xsmall)\n    \n    casenorm = 100 if xsmall else cases + .0001\n    fatnorm = max(i[1] for i in ybycountry[cname]) + .001\n\n    powers = (2,1) if small else (1,)\n\n    beg = time.time()\n    \n#     train_limit = 100 if xsmall else 45 if rllysmall else 60 if small else 100\n    train_limit = 100 if rllysmall else 30 if small else 60\n#     train_limit = 3\n\n    model = deepcopy(loosemodel) if rllysmall else Model(2 if small else 1)\n    criterion = nn.MSELoss()\n    sgd = lambda model: torch.optim.SGD(model.parameters(), lr=.1)\n#     ada = lambda model: adabound.AdaBound(model.parameters(), lr=1e-2, final_lr=.1)\n    adam = lambda model: torch.optim.Adam(model.parameters())\n\n    x = torch.FloatTensor([[pow(i, p) for p in powers] for i in shufflexbycountry[cname]])\n    y = torch.FloatTensor([[float(i[0]/casenorm), float(i[1]/fatnorm)] for i in shuffleybycountry[cname]])\n\n    # Around 120000 epochs\n    newmodel = train(\n        model,\n        criterion,\n        adam(model),\n        x,\n        y,\n        train_limit\n    )[0]\n    \n    models.update({cname: (newmodel, powers, casenorm, fatnorm)})\n\n    seconds = time.time() - beg\n    print(cname, \"trained in\", seconds // 60, \"minutes\", seconds % 60, \"seconds\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fatality\nfor cname in cnames:\n    if cname == \"Canada\":\n        continue\n    model, powers, casenorm, fatnorm = deepcopy(models[cname])\n\n    import matplotlib.pyplot as plt\n\n    raw = model(torch.Tensor([[pow(xval, i) for i in powers] for xval in list(xbycountry[cname])])).detach()\n    predictions = np.array([j.numpy()[1]*fatnorm for j in raw])\n    plt.plot(np.array(list(range(150))), np.array([j.numpy()[1]*fatnorm for j in model(torch.Tensor([[pow(xval, i) for i in powers] for xval in list(range(150))])).detach()]), label=\"future\")\n    plt.plot(xbycountry[cname], [i[1] for i in ybycountry[cname]], label=\"actual\")\n    plt.plot(xbycountry[cname], predictions, label=\"model\")\n    # plt.plot(np.array([140 for i in range(200000)]), np.array(list(range(200000))), label=\"day 70\")\n    # plt.plot(np.array(list(range(200))), np.array([390000 for i in range(200)]), label=\"growth slows down\")\n    plt.xlabel = \"Days since 20-01-22\"\n    plt.ylabel = \"Cases\"\n    plt.legend()\n    plt.show()\n    # print(f\"Will max out at {model(torch.Tensor([[102, 102**2]])).detach().numpy()[0][1]*8e4} infected around May 26 2020\")\n    print(f\"{cname} average accuracy: {100*(1 - np.mean(abs(predictions - [i[1] for i in ybycountry[cname]]))/fatnorm):.3}%\")\n    del plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Cases\n\nfor cname in cnames:\n    if \"Canada\" == cname:\n        continue\n    model, powers, casenorm, fatnorm = deepcopy(models[cname])\n\n    \n    import matplotlib.pyplot as plt\n    \n    predictions = np.array([j.numpy()[0]*casenorm for j in model(torch.Tensor([[pow(xval, i) for i in powers] for xval in list(xbycountry[cname])])).detach()])\n    plt.plot(np.array(list(range(150))), np.array([j.numpy()[0]*casenorm for j in model(torch.Tensor([[pow(xval, i) for i in powers] for xval in list(range(150))])).detach()]), label=\"future\")\n    plt.plot(xbycountry[cname], [i[0] for i in ybycountry[cname]], label=\"actual\")\n    plt.plot(xbycountry[cname], predictions, label=\"model\")\n#     plt.plot(np.array([73 for i in range(int(casenorm) * 2)]), np.array(list(range(int(casenorm) * 2))), label=\"day 70\")\n    # plt.plot(np.array(list(range(200))), np.array([390000 for i in range(200)]), label=\"growth slows down\")\n    plt.xlabel = \"Days Since 2020-01-22\"\n    plt.ylabel = \"Cases\"\n    plt.legend()\n    plt.show()\n    # print(f\"Will max out at {model(torch.Tensor([[[102]]])).item()*8e4} infected around May 26 2020\")\n    print(f\"{cname} average accuracy: {100*(1-np.mean(abs(predictions - [i[0] for i in ybycountry[cname]]))/casenorm):.3}%\")\n    del plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!rm /kaggle/working/submission.csv\nstuff = []\nwith open(\"/kaggle/working/submission.csv\", 'a+') as fout:\n    fout.write(\"ForecastId,ConfirmedCases,Fatalities\\n\")\n    for i, p in enumerate(ptest.to_numpy()):\n        cname = p[1] if type(p[1]) is str else p[2]\n        model, powers, casenorm, fatnorm = deepcopy(models[cname])\n        date = dateToInt(p[3])\n        predictions = np.array([(j.numpy()[0]*casenorm, j.numpy()[1]*fatnorm) for j in model(torch.Tensor([[pow(xval, i) for i in powers] for xval in (date,)])).detach()])\n        print(i, cname, date, tuple(predictions[0]))\n        print(i + 1, int(round(predictions[0][0])), int(round(predictions[0][1])), sep=',', file=fout)\n        stuff.append((i+1, predictions[0]))\nprint(len(stuff))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}