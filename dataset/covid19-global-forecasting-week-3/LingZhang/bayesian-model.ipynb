{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd \nimport os\nfrom tqdm import tqdm\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])\ntrain[['ConfirmedCases', 'Fatalities']] = train.groupby(['Country_Region', 'Province_State'])[['ConfirmedCases', 'Fatalities']].transform('cummax') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression, BayesianRidge\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import make_pipeline\n\nfeature_day = [1,20,40,80,160,320,640]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,('Number day from ' + str(day) + ' case')] = 0\n        #data['Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n            df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n            df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n            X_train = CreateInput(df_train)\n            y_train_confirmed = df_train['ConfirmedCases'].ravel()\n            y_train_fatalities = df_train['Fatalities'].ravel()\n            X_pred = CreateInput(df_test)\n\n            # Define feature to use by X_pred\n            feature_use = X_pred.columns[0]\n            for i in range(X_pred.shape[1] - 1,0,-1):\n                if (X_pred.iloc[0,i] > 0):\n                    feature_use = X_pred.columns[i]\n                    break\n            idx = X_train[X_train[feature_use] == 0].shape[0]          \n            adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n            adjusted_y_train_confirmed = y_train_confirmed[idx:]\n            adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n\n            adjusted_X_pred = X_pred[feature_use].values.reshape(-1, 1)\n\n            model = make_pipeline(PolynomialFeatures(2), BayesianRidge())\n            model.fit(adjusted_X_train,adjusted_y_train_confirmed)                \n            y_hat_confirmed = model.predict(adjusted_X_pred)\n\n            model.fit(adjusted_X_train,adjusted_y_train_fatalities)                \n            y_hat_fatalities = model.predict(adjusted_X_pred)\n\n            pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n            pred_data['ConfirmedCases_hat'] = y_hat_confirmed\n            pred_data['Fatalities_hat'] = y_hat_fatalities\n            pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\n    \ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\ndf = df_val.copy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = df[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission = submission.round({'ConfirmedCases': 0, 'Fatalities': 0})\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}