{"cells":[{"metadata":{},"cell_type":"markdown","source":"# COVID-19 FORECASTING\n\nWe aim to predict the number of infections ($I_t$) and deaths ($D_t$) per country. For that, we account for the following variables:\n\n- Goverment response index ($G_t$): real number, time dependent.\n- Tracking and caring ($C_t$): binary time-dependent variable.\n- Number of tests ($T_t$)\n- Population ($\\rho$)\n- Density ($\\delta$)\n- Development ($\\Delta$)\n- Temperature ($\\theta$)\n\nOther variables:\n\n- Policy trends\n- Risk factors: smokers#\n- Cultural factors\n- Air pollution\n- Population age\n- Alcohol\n- Medical care"},{"metadata":{"trusted":true},"cell_type":"code","source":"#importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras.backend as keb\nfrom scipy.optimize import curve_fit\nfrom datetime import datetime as dtime\nfrom datetime import timedelta\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#loading data\npath = \"../input/input-covid/\"\n#path = \"\"\ndata = pd.read_csv(path+\"train2.csv\")\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"isCountry\"] = data.Province_State.isna()\ndata.Province_State[data.Province_State.isna()] = \"\"\ndata[\"Region\"]= data.Country_Region \ndata[\"Region\"][~data.isCountry]= data.Country_Region + \"-\" + data.Province_State\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"number_of_rows = data.shape[0]\nregisters_count_by_region = data[[\"Id\", \"Region\"]].groupby(\"Region\").count()\nregisters_count_by_region.columns = [\"Count\"]\nregisters_count_by_region.reset_index(inplace=True)#\ndays = np.unique(data.Date)\nn_days = len(days)\nregions = np.unique(data.Region)\n\nprint(\"Number of rows:\", number_of_rows)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"registers_count_by_region.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Days:\", days)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Countries:\", regions)\nprint(\"No. Countries:\", len(regions))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"No country - Regions:\", data.Region[~data.isCountry])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_confirmed_per_day_per_country = data[[ \"Region\", \"ConfirmedCases\" ]].groupby(\"Region\").max()\nmax_confirmed_per_day_per_country.head()","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"#new confirmed column\ndata[\"Id_by_Region\"] = data[[\"Region\", \"Id\"]].groupby(\"Region\").cumcount()\ndata[\"PreviousConfirmed\"] = data[\"ConfirmedCases\"].shift()\ndata.loc[ data.Id_by_Region==0, \"PreviousConfirmed\"] = 0\ndata[\"NewConfirmed\"]= data.ConfirmedCases - data.PreviousConfirmed\n\n#new fatalities column\ndata[\"Id_by_Region\"] = data[[\"Region\", \"Id\"]].groupby(\"Region\").cumcount()\ndata[\"PreviousFatalities\"] = data[\"Fatalities\"].shift()\ndata.loc[ data.Id_by_Region==0,\"PreviousFatalities\"] = 0\ndata[\"NewFatalities\"]= data.Fatalities - data.PreviousFatalities\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_countries = [\"Spain\", \"Italy\", \"Germany\", \"Singapore\", 'Korea, South']\n\nfig, ax = plt.subplots(1,2, figsize=(15,5))\n\nfor i, country in enumerate(selected_countries):\n    \n    confirmed_country = data[data.Region==country].ConfirmedCases\n    ax[0].plot(days, confirmed_country)\n    ax[0].set_xticks(np.arange(0, n_days,20 ))\n    \nax[0].legend(selected_countries)\nax[0].set_title(\"Confirmed cases\")\nax[0].grid()\n\nfor i, country in enumerate(selected_countries):\n    \n    fatalities_country = data[data.Region==country].Fatalities\n    ax[1].plot(days, fatalities_country)\n    ax[1].set_xticks(np.arange(0, n_days,20 ))\n    \nax[1].legend(selected_countries)\nax[1].set_title(\"Fatalities\")\nax[1].grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\n\nfig, ax = plt.subplots(1,2, figsize=(15,5))\n\nfor country in selected_countries:\n    \n    confirmed_country = np.log(data[data.Region==country].ConfirmedCases+1)\n    ax[0].plot(days, confirmed_country)\n    ax[0].set_xticks(np.arange(0, n_days,20 ))\nax[0].grid()\nax[0].legend(selected_countries)\nax[0].set_title(\"Confirmed cases (log)\")\n\nfor i, country in enumerate(selected_countries):\n    \n    fatalities_country = np.log(data[data.Region==country].Fatalities+1)\n    ax[1].plot(days, fatalities_country)\n    ax[1].set_xticks(np.arange(0, n_days,20 ))\n    \nax[1].legend(selected_countries)\nax[1].set_title(\"Fatalities (log)\")\nax[1].grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfig, ax = plt.subplots(1,2, figsize=(15,5))\n\nfor i, country in enumerate(selected_countries):\n    \n    confirmed_country = data[data.Region==country].NewConfirmed\n    ax[0].plot(days, confirmed_country)\n    ax[0].set_xticks(np.arange(0, n_days,20 ))\n    \nax[0].legend(selected_countries)\nax[0].set_title(\"Confirmed cases\")\nax[0].grid()\n\nfor i, country in enumerate(selected_countries):\n    \n    fatalities_country = data[data.Region==country].NewFatalities\n    ax[1].plot(days, fatalities_country)\n    ax[1].set_xticks(np.arange(0, n_days,20 ))\n    \nax[1].legend(selected_countries)\nax[1].set_title(\"Fatalities\")\nax[1].grid()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[\"FirstConfirmed\"] = data.apply(lambda x: x[\"ConfirmedCases\"]>0, axis=1)\ndata[\"FirstFatality\"] = data.apply(lambda x: x[\"Fatalities\"]>0, axis=1)\ndata[\"DayFromFirstConfirmed\"] = data[[\"FirstConfirmed\", \"Region\"]].groupby(\"Region\").cumsum()\ndata[\"DayFromFirstFatality\"] = data[[\"FirstFatality\", \"Region\"]].groupby(\"Region\").cumsum()\n\ndata[\"TenConfirmed\"] = data.apply(lambda x: x[\"ConfirmedCases\"]>10, axis=1)\ndata[\"TenFatality\"] = data.apply(lambda x: x[\"Fatalities\"]>10, axis=1)\ndata[\"DayFromTenConfirmed\"] = data[[\"TenConfirmed\", \"Region\"]].groupby(\"Region\").cumsum()\ndata[\"DayFromTenFatality\"] = data[[\"TenFatality\", \"Region\"]].groupby(\"Region\").cumsum()\n\ndata[\"LogNewConfirmed\"] = np.log(data[\"NewConfirmed\"]+1) \ndata[\"LogNewFatalities\"] = np.log(data[\"NewFatalities\"]+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_day_confirmed = data[data[\"DayFromTenConfirmed\"] == 1][[\"Region\", \"Date\"]]\nfirst_day_confirmed.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"first_day_fatality = data[data[\"DayFromTenFatality\"] == 1][[\"Region\", \"Date\"]]\nfirst_day_fatality.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged = pd.merge(first_day_confirmed, first_day_fatality, on='Region', how='left')\nprint(\"Number of unique regions:\", df_merged.shape[0])\ndf_merged.head()\n\ndef to_datetime(x):\n    try: \n        return dtime.strptime(x,  \"%Y-%m-%d\")\n    except: \n        return pd.NaT\n\ndf_merged.Date_x = df_merged.Date_x.apply(lambda x: dtime.strptime(x,  \"%Y-%m-%d\"))\ndf_merged.Date_y = df_merged.Date_y.apply(lambda x: to_datetime(x))\ndf_merged[\"DifferenceFirstConfirmedFatality\"] = df_merged.Date_y - df_merged.Date_x\ndf_merged.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple Models"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\nfig, ax = plt.subplots(len(selected_countries),1, figsize=(10,10))\nerror = []\nN = 5\n\ndef sigmoid(x, a, x0, k):\n    y = a / (1 + np.exp(-k*(x-x0)))\n    return y\n\ndef exponential(x, a, x0, k):\n    y = a*np.exp(-k*(x-x0))\n    return y\n\n    \nfor i, country in enumerate(selected_countries):\n    \n    data_region = data[data.Region == country][data.TenConfirmed==True]\n\n    y = data_region.NewConfirmed\n    x = data_region.DayFromTenConfirmed\n    ma = np.convolve(y, np.ones((N,))/N, mode='same')\n\n    popt, pcov = curve_fit(sigmoid, x, y)\n    confirmed_fitted_sigmoid = sigmoid(x, *popt)\n    \n    error.append(np.median((confirmed_fitted_sigmoid-ma)**2)/np.max(ma))\n\n    ax[i].plot(x, y)\n    ax[i].plot(x, confirmed_fitted_sigmoid)\n    ax[i].plot(x, ma)\n    ax[i].grid()\nerror","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_regions = []\nfor i, country in enumerate(regions):\n    \n    data_region = data[data.Region == country][data.TenConfirmed==True]\n\n\n\n    try:\n        y = data_region.NewConfirmed\n        x = data_region.DayFromTenConfirmed\n        ma = np.convolve(y, np.ones((N,))/N, mode='same')\n        popt, pcov = curve_fit(sigmoid, x, y)\n        confirmed_fitted_sigmoid = sigmoid(x, *popt)\n\n        error_regions.append(np.median((confirmed_fitted_sigmoid-ma)**2)/np.max(ma))\n    except:\n        error_regions.append(np.nan)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_index = pd.DataFrame({\"Region\": regions, \"state_index\": error_regions})\ndf_merged = pd.merge(df_merged, state_index, on='Region', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"interesting_regions = df_merged[df_merged.state_index>20].Region","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfor i, country in enumerate(interesting_regions):\n    \n    fig = plt.figure()\n    data_region = data[data.Region == country][data.TenConfirmed==True]\n\n    y = data_region.NewConfirmed\n    x = data_region.DayFromTenConfirmed\n    ma = np.convolve(y, np.ones((N,))/N, mode='same')\n\n    popt, pcov = curve_fit(exponential, x, y)\n    confirmed_fitted_sigmoid = exponential(x, *popt)\n    \n    error.append(np.median((confirmed_fitted_sigmoid-ma)**2)/np.max(ma))\n\n    plt.plot(x, y)\n    plt.plot(x, confirmed_fitted_sigmoid)\n    plt.plot(x, ma)\n    plt.grid()\n    plt.title(country)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_countries","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_region = data[data.Region == \"Korea, South\"][data.TenConfirmed==True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.median(data_region.NewConfirmed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"error_regions_exponential = []\nerror_regions_sigmoid = []\n\nfor i, country in enumerate(regions):\n    \n    data_region = data[data.Region == country][data.TenConfirmed==True]\n\n\n    try:\n        y = data_region.NewConfirmed\n        x = data_region.DayFromTenConfirmed\n        ma = np.convolve(y, np.ones((N,))/N, mode='same')\n        \n\n        popt, pcov = curve_fit(sigmoid, x, y)\n        confirmed_fitted_sigmoid = sigmoid(x, *popt)\n        \n        error_regions_sigmoid.append(np.median((confirmed_fitted_sigmoid-ma)**2)/np.max(ma))\n    except:\n        \n        error_regions_sigmoid.append(np.nan)\n        \n\n    try:\n        y = data_region.NewConfirmed\n        x = data_region.DayFromTenConfirmed\n        ma = np.convolve(y, np.ones((N,))/N, mode='same')\n        \n\n        popt, pcov = curve_fit(sigmoid, x, y)\n        confirmed_fitted_exponential = exponential(x, *popt)\n        \n        error_regions_exponential.append(np.median((confirmed_fitted_exponential-ma)**2)/np.max(ma))\n    except:\n        \n        error_regions_exponential.append(np.nan)\n        \n        \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"state_index = pd.DataFrame({\"Region\": regions, \"sigmoid_error\": error_regions_sigmoid, \n                            \"exponential_error\": error_regions_exponential})\n\ndf_merged2 = pd.merge(df_merged, state_index, on='Region', how='left')\ndf_merged2[\"state\"] = df_merged2[[\"sigmoid_error\", \"exponential_error\"]].apply(lambda x: int(x[0]< x[1]), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_merged2[df_merged2.Region==\"Colombia\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def simple_predictor(func, ts1, ts2, c1, c2, h):\n    \n    x_past1 = np.arange(len(ts1))\n    x_past2 = np.arange(len(ts2))\n    \n    x_fut = np.arange(c1,h+c1,1)\n    \n    popt, pcov = curve_fit(func, x_past1, ts1)\n    p1 = sigmoid(x_fut, *popt)\n\n    popt, pcov = curve_fit(func, x_past2, ts2)\n    p2 = sigmoid(x_fut, *popt)\n    \n    return p1, p2\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Simple RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"def multivariate_data(dataset, target, start_index, end_index, history_size,\n                      target_size, step, single_step=False):\n    data = []\n    labels = []\n\n    start_index = start_index + history_size\n    if end_index is None:\n        end_index = len(dataset) - target_size\n\n    for i in range(start_index, end_index):\n        indices = range(i-history_size, i, step)\n        data.append(dataset[indices])\n\n        if single_step:\n            labels.append(target[i+target_size])\n        else:\n            labels.append(target[i:i+target_size])\n\n    return np.array(data), np.array(labels)\n\n\ndef RMSLE (y_pred,  y_true):\n    \n    return keb.mean(keb.square(keb.log(y_pred+1)-keb.log(y_true+1)))\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datasets = []\nnorm_factor = 100\n\nfor region in regions:\n    datasets.append(np.array(data[[\"NewConfirmed\", \"NewFatalities\"]][data.TenConfirmed==1][data.Region==region]))\n    \nlen_data = len(datasets)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"past_history = 7\nfuture_target = 1\nSTEP = 1\n\nBATCH_SIZE = 10\nBUFFER_SIZE = 10\nEPOCHS = 0\nEVALUATION_INTERVAL = 1\nTHRESHOLD_REGION = 15\n\nx_train = []\ny_train = []\nx_val = []\ny_val = []\n\nfor dataset in datasets:\n    \n    if (dataset.shape[0]>THRESHOLD_REGION):\n        len_data= dataset.shape[0]\n        TRAIN_SPLIT = int(len_data*0.6)\n        x_train_temp, y_train_temp = multivariate_data(dataset, dataset[:,0], 0, TRAIN_SPLIT, past_history, future_target, STEP)\n\n        x_train.append(x_train_temp)\n        y_train.append(y_train_temp)\n        \n        x_val_temp, y_val_temp = multivariate_data(dataset, dataset[:,0], TRAIN_SPLIT, None, past_history, future_target, STEP)\n        \n        if(x_val_temp.shape[0]>0):\n            x_val.append(x_val_temp)\n            y_val.append(y_val_temp)\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train = np.concatenate(x_train, axis=0)\ny_train = np.vstack(y_train)\n\n\nprint(\"x_train shape:\", x_train.shape)\nprint(\"y_train shape:\", y_train.shape)\n\nx_val = np.concatenate(x_val, axis=0)\ny_val = np.vstack(y_val)\n\n\nprint(\"x_train shape:\", x_val.shape)\nprint(\"y_train shape:\", y_val.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\ntrain_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n\nval_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\nval_data = val_data.batch(BATCH_SIZE).repeat()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_step_model = tf.keras.models.Sequential()\nmulti_step_model.add(tf.keras.layers.LSTM(16,\n                                          return_sequences=True,\n                                          input_shape=x_train.shape[-2:]))\nmulti_step_model.add(tf.keras.layers.LSTM(8, activation='relu'))\nmulti_step_model.add(tf.keras.layers.Dense(future_target))\n\nmulti_step_model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.0001, clipvalue=1.0), loss=RMSLE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_step_history = multi_step_model.fit(train_data, epochs=EPOCHS,\n                                          steps_per_epoch=EVALUATION_INTERVAL,\n                                          validation_data=val_data,\n                                          validation_steps=10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred= multi_step_model.predict(x_val[1:100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(pred, y_val[1:100])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generating submission\n"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"path = \"../input/covid19-global-forecasting-week-3/\"\ntest_data = pd.read_csv(path+\"test.csv\")\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data[\"isCountry\"] = test_data.Province_State.isna()\ntest_data.Province_State[test_data.Province_State.isna()] = \"\"\ntest_data[\"Region\"]= test_data.Country_Region \ntest_data[\"Region\"][~test_data.isCountry]= test_data.Country_Region + \"-\" + test_data.Province_State\n\nnumber_of_rows = test_data.shape[0]\nregisters_count_by_region_test = test_data[[\"ForecastId\", \"Region\"]].groupby(\"Region\").count()\nregisters_count_by_region_test.columns = [\"Count\"]\nregisters_count_by_region_test.reset_index(inplace=True)#\ndays_test = np.unique(test_data.Date)\nn_days_test = len(days_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"days_to_predict = [dtime.strftime(dtime.strptime(days[-1],  \"%Y-%m-%d\")+timedelta(i), \"%Y-%m-%d\") for i in range(1,31)]\nn_days_to_predict = len(days_to_predict)\nconcat_df = pd.DataFrame()\n\nfor i, region in enumerate(regions):\n    \n    data_region = data[data.Region == region][data.TenConfirmed==True]\n    \n    if (data_region.shape[0]==0):\n        data_region = data[data.Region == region][data.FirstConfirmed==True]\n        \n    try:\n        state = df_merged2[df_merged2.Region==region].state.iloc[0]\n    except:\n        state = 0\n        \n    \n        \n    temp_df = pd.DataFrame({\"Date\":days_to_predict, \"Country_Region\": [data_region.Country_Region.iloc[0]]*n_days_to_predict, \n                            \"Province_State\": [data_region.Province_State.iloc[0]]*n_days_to_predict,\n                            \"isCountry\": [data_region.isCountry.iloc[0]]*n_days_to_predict})\n\n    temp_df[\"Region\"]= temp_df.Country_Region \n    temp_df[\"Region\"][~temp_df.isCountry] = temp_df.Country_Region + \"-\" + temp_df.Province_State\n    \n    ts_confirmed = data_region.NewConfirmed\n    ts_fatalities = data_region.NewFatalities\n    \n    ma_conf = np.convolve(ts_confirmed, np.ones((N,))/N, mode='same')\n    ma_fat = np.convolve(ts_fatalities, np.ones((N,))/N, mode='same')\n    \n    current_day_confirmed = data_region.DayFromTenConfirmed.iloc[-1]\n    current_day_fatalities = data_region.DayFromTenFatality.iloc[-1]\n    \n    current_confirmed = data_region.ConfirmedCases.iloc[-1]\n    current_fatalities = data_region.Fatalities.iloc[-1]\n        \n\n    func = sigmoid\n\n    \n    try:\n        predicted_confirmed, predicted_fatalities = simple_predictor(func, ma_conf, ma_fat, current_day_confirmed, current_day_fatalities, n_days_to_predict)\n        \n        predicted_confirmed[0] = predicted_confirmed[0] + current_confirmed\n        predicted_confirmed = np.cumsum(predicted_confirmed)\n        \n        predicted_fatalities[0] = predicted_fatalities[0] + current_fatalities\n        predicted_fatalities = np.cumsum(predicted_fatalities)\n    \n    except:\n        \n        predicted_confirmed = [0]*n_days_to_predict\n        predicted_fatalities = [0]*n_days_to_predict\n        predicted_confirmed[0], predicted_fatalities[0] = current_confirmed, current_fatalities\n        predicted_confirmed = np.cumsum(predicted_confirmed)\n        predicted_fatalities = np.cumsum(predicted_fatalities)\n    \n    temp_df[\"ConfirmedCases\"] = predicted_confirmed\n    temp_df[\"Fatalities\"] = predicted_fatalities\n    concat_df = pd.concat([concat_df, temp_df])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"current_data = data[[\"Date\", \"Country_Region\", \"Province_State\", \"ConfirmedCases\", \"Fatalities\", \"Region\"]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"concat_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission1 = test_data.merge(current_data, on=[\"Region\", \"Date\"] ,  how='left')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission1 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission2 = submission1.merge(concat_df, on= [\"Region\", \"Date\"], how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission2[submission2.Region==\"Spain\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission2[\"ConfirmedCases\"] = submission2[[\"ConfirmedCases_x\", \"ConfirmedCases_y\"]].apply(lambda x: x[0] if ~np.isnan(x[0]) else x[1], axis=1)\nsubmission2[\"Fatalities\"] = submission2[[\"Fatalities_x\", \"Fatalities_y\"]].apply(lambda x: x[0] if ~np.isnan(x[0]) else x[1], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = pd.read_csv(path+\"submission.csv\")#\nsubmission_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission3 = submission_data[[\"ForecastId\"]].merge(submission2[[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\" ]], on= \"ForecastId\", how=\"left\")\n\nsubmission3 = submission3.astype(\"int32\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission3.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Other data sources:\n\n- https://raw.githubusercontent.com/resbaz/r-novice-gapminder-files/master/data/gapminder-FiveYearData.csv\n- https://data.humdata.org/dataset/oxford-covid-19-government-response-tracker\n- Enriched data: https://www.kaggle.com/optimo/covid19-enriched-dataset\n- https://ourworldindata.org/coronavirus#all-charts-preview"},{"metadata":{},"cell_type":"markdown","source":"## Technical info:\n\n- https://www.tensorflow.org/tutorials/structured_data/time_series\n- https://www.tensorflow.org/api_docs/python/tf/keras/layers/Attention"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}