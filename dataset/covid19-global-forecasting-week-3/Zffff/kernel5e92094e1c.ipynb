{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"prepare data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train =  pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")\n\ntrain['Date'] = pd.to_datetime(train['Date'])\n\ntrain['day'] = train['Date'].apply(lambda x: x.dayofyear-21).astype(int)   #day of 1/21\nprint(train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_wc=train[train['Country_Region']!='China'].reset_index(drop=True)\nadd_data=pd.read_csv('../input/datadata/covid19countryinfo.csv')\nadd_data.rename(columns={'country':'Country_Region'},inplace = True)\nadd_data.rename(columns={'region':'Province_State'},inplace = True)\ntrain_wc=pd.merge(train_wc,add_data, on=['Country_Region','Province_State'], how='left')\ntrain_wc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_wc[pd.isnull(train_wc['hospibed'])]))\nprint(len(train_wc[pd.isnull(train_wc['pop'])]))\nprint(len(train_wc[pd.isnull(train_wc['medianage'])]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"use evaluate to fill null"},{"metadata":{"trusted":true},"cell_type":"code","source":"for column in ['hospibed','medianage','density','gdp2019','pop']:             #'hospibed','medianage','density'\n    mean_val = train_wc[column].mean()\n    train_wc[column].fillna(mean_val, inplace=True)\n\ntrain_wc.isnull().sum() > 0","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"add more detail"},{"metadata":{"trusted":true},"cell_type":"code","source":"for number in range(len(train_wc['day'])):\n\tif train_wc['day'][number]>6:\n\t\ttrain_wc.loc[number,'ConfirmedCases4']=train_wc['ConfirmedCases'][number-4].astype(int)\n\t\ttrain_wc.loc[number,'ConfirmedCases5']=train_wc['ConfirmedCases'][number-5].astype(int)\n\t\ttrain_wc.loc[number,'ConfirmedCases1']=train_wc['ConfirmedCases'][number-1].astype(int)\n\t\ttrain_wc.loc[number,'ConfirmedCases2']=train_wc['ConfirmedCases'][number-2].astype(int)\n\t\ttrain_wc.loc[number,'ConfirmedCases3']=train_wc['ConfirmedCases'][number-3].astype(int)\n\t\ttrain_wc.loc[number,'ConfirmedCases6']=train_wc['ConfirmedCases'][number-6].astype(int)\n\t\ttrain_wc.loc[number,'ConfirmedCases1-5']=(train_wc['ConfirmedCases'][number-1].astype(int)+\n                                                train_wc['ConfirmedCases'][number-2].astype(int)\n                                                +train_wc['ConfirmedCases'][number-3].astype(int)\n                                                +train_wc['ConfirmedCases'][number-4].astype(int)\n                                                +train_wc['ConfirmedCases'][number-5].astype(int) )                       \n\t\ttrain_wc.loc[number,'Fatalities1']=train_wc['Fatalities'][number-1].astype(int)\n\t\ttrain_wc.loc[number,'Fatalities2']=train_wc['Fatalities'][number-2].astype(int)\n\t\ttrain_wc.loc[number,'Fatalities3']=train_wc['Fatalities'][number-3].astype(int)\n\t\ttrain_wc.loc[number,'Fatalities1-5']=(train_wc['Fatalities'][number-1].astype(int)\n                                            +train_wc['Fatalities'][number-2].astype(int)\n                                            +train_wc['Fatalities'][number-3].astype(int)\n                                            +train_wc['Fatalities'][number-4].astype(int)\n                                            +train_wc['Fatalities'][number-5].astype(int))\n\telse:\n\t\ttrain_wc.loc[number,'ConfirmedCases1']=0\n\t\ttrain_wc.loc[number,'ConfirmedCases2']=0\n\t\ttrain_wc.loc[number,'ConfirmedCases3']=0\n\t\ttrain_wc.loc[number,'ConfirmedCases4']=0\n\t\ttrain_wc.loc[number,'ConfirmedCases5']=0\n\t\ttrain_wc.loc[number,'ConfirmedCases6']=0\n\t\ttrain_wc.loc[number,'ConfirmedCases1-5']=0\n\t\ttrain_wc.loc[number,'Fatalities1']=0\n\t\ttrain_wc.loc[number,'Fatalities2']=0\n\t\ttrain_wc.loc[number,'Fatalities3']=0\n\t\ttrain_wc.loc[number,'Fatalities1-5']=0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_wc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The time from case 1 to case 100 and The time from case 100 to case 1000\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def func(x):\n    try:\n        name = x['Country_Region'] + \"/\" + x['Province_State']\n    except:\n        name = x['Country_Region']\n    return name        \ntrain_wc['name'] = train_wc.apply(lambda x: func(x), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_wc.to_csv('train_wc1.csv',index=False)\ntrain_wc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_wc = pd.read_csv('train_wc1.csv')\ntemp = []\nnames = train_wc['name'].unique()\nfor name in names[:]:\n    df = train_wc[train_wc['name']==name].reset_index(drop=True)    \n    df['dayc1'] = (df['ConfirmedCases']<1).sum()\n    a=(df['ConfirmedCases']>=1).sum()-(df['ConfirmedCases']>=100).sum()\n    if (df['ConfirmedCases']<100).sum()==77:\n        df['dayc1_100'] = 50\n    else :\n        df['dayc1_100'] = a    \n    b=(df['ConfirmedCases']>=100).sum()-(df['ConfirmedCases']>=1000).sum()\n    if (df['ConfirmedCases']<1000).sum()==77:\n        df['dayc100_1000'] = 50\n    else :\n        df['dayc100_1000'] = b  \n        \n    df['dayf1']=(df['Fatalities']<1).sum()  \n    a=(df['Fatalities']>=1).sum()-(df['Fatalities']>=100).sum()\n    if (df['Fatalities']<100).sum()==77:\n        df['dayf1_100'] = 50\n    else:\n        df['dayf1_100'] = a    \n    b=df['dayf100_200'] = (df['Fatalities']>=100).sum()-(df['Fatalities']>=200).sum()\n    if (df['Fatalities']<200).sum()==77:\n        df['dayf100_200'] = 50\n    else:\n        df['dayc100_1000'] = b        \n    temp.append(df)     \ntemp=pd.concat(temp).reset_index(drop=True)\ntrain_wc=temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Start Training"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\")\ntest['Date'] = pd.to_datetime(test['Date'])\ntest['day'] = test['Date'].apply(lambda x: x.dayofyear-21).astype(int) \ntest['Date']=test['Date'].dt.date\ntest['name'] = test.apply(lambda x: func(x), axis=1)\ntt=pd.merge(train_wc,test, on=['Country_Region','Province_State','day'],how='left')\ntt.rename(columns={'Date_x':'Date'},inplace = True)\ntest=test[test['day']>=78]\ntt=tt.append(test).reset_index(drop=True)\ntt.to_csv(\"tt.csv\",index=False)\ntt.columns  \ntt = tt[tt['Country_Region']!='China'].reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# params\nimport lightgbm as lgb\nSEED = 42\nparams = {'num_leaves': 8,\n          'min_data_in_leaf': 5,  \n          'objective': 'regression',\n          'max_depth': 4,     # #最大的树深，设为-1时表示不限制树的深度\n          'learning_rate': 0.01,\n          'boosting': 'gbdt',\n          'bagging_freq': 5,  # 5\n          'bagging_fraction': 0.8,  # 0.5,\n          'feature_fraction': 0.8201,\n          'bagging_seed': SEED,\n          'reg_alpha': 1,  # 1.728910519108444,\n          'reg_lambda': 4.9847051755586085,\n          'random_state': SEED,\n          'metric': 'mse',   #mse\n          'verbosity': 100,\n          'min_gain_to_split': 0.02,  # 0.01077313523861969,\n          'min_child_weight': 5,  # 19.428902804238373,\n          'num_threads': 6,\n          }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_target='ConfirmedCases'\ncol_var = [\n           'ConfirmedCases1',\n           'ConfirmedCases1-5',\n     #  'ConfirmedCases2',\n      #     'ConfirmedCases3',\n     #      'ConfirmedCases4',\n     #  'ConfirmedCases5',\n     #      'ConfirmedCases6', \n     #      'Fatalities1',\n     #      'Fatalities1-5', \n     #      'Fatalities2',\n     #  'Fatalities3', \n       'day', \n           'dayc1',\n     #      'dayc100_1000', \n           'dayc1_100', \n           'dayf1',\n     #      'dayf100_200',\n     #  'dayf1_100',\n     #      'density', \n           'gdp2019',\n     #      'hospibed', \n     #      'medianage',\n    #   'pop'\n          ]\n\ndf_train = tt[tt['day']<=77]\ndf_valid = tt[(70<tt['day']) & (tt['day']<=77)]\ndf_test = tt[pd.isna(tt['ForecastId'])==False]\nX_train = df_train[col_var]\nX_valid = df_valid[col_var]\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\n\ntrain_data = lgb.Dataset(X_train,label=y_train)\nvalid_data = lgb.Dataset(X_valid,label=y_valid)\n\nnum_round = 100\nmodel = lgb.train(params,train_data,num_round,valid_sets=valid_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_target='Fatalities'\ncol_var2 = [\n           'ConfirmedCases',\n        #   'ConfirmedCases1',\n        #   'ConfirmedCases1-5',\n       #'ConfirmedCases2',\n       #    'ConfirmedCases3',\n       #    'ConfirmedCases4',\n       #'ConfirmedCases5',\n       #    'ConfirmedCases6', \n           'Fatalities1',\n       #    'Fatalities1-5', \n     #      'Fatalities2',\n      # 'Fatalities3', \n       'day', \n     #      'dayc100_1000', \n      #     'dayc1_100', \n           'dayf1',\n      #     'dayf100_200',\n  #     'dayf1_100',\n      #     'density', \n      #     'gdp2019',\n      #     'hospibed', \n      #     'medianage',\n   #'pop'\n          ]\n\ndf_train = tt[(tt['day']<=77) & (tt['day']>=10)]\ndf_valid = tt[(67<tt['day']) & (tt['day']<=77)]\nprint(df_train)\nX_train = df_train[col_var2]\nX_valid = df_valid[col_var2]\ny_train = df_train[col_target].values\ny_valid = df_valid[col_target].values\n\ny_train = np.log(df_train[col_target].values.clip(0, 1e10)+1)\ny_valid = np.log(df_valid[col_target].values.clip(0, 1e10)+1)\ntrain_data = lgb.Dataset(X_train,label=y_train)\nvalid_data = lgb.Dataset(X_valid,label=y_valid)\n\nnum_round = 500\nmodel2 = lgb.train(params,train_data,num_round,valid_sets=valid_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# display feature importance\ntmp = pd.DataFrame()\ntmp[\"feature\"] = col_var2\ntmp[\"importance\"] = model2.feature_importance()\ntmp = tmp.sort_values('importance', ascending=False)\ntmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt1 = pd.read_csv('../input/datadata/tt_1.csv')\ntt1 = tt1[tt1['Country_Region']!='China'].reset_index(drop=True)\ntt1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for number in range(len(tt1['Date'])):     #改108\n    if tt1.loc[number,'day']>=78:\n        tt1.loc[number,'ConfirmedCases4']=tt1['ConfirmedCases'][number-4].astype(int)\n        tt1.loc[number,'ConfirmedCases5']=tt1['ConfirmedCases'][number-5].astype(int)\n        tt1.loc[number,'ConfirmedCases1']=tt1['ConfirmedCases'][number-1].astype(int)\n        tt1.loc[number,'ConfirmedCases2']=tt1['ConfirmedCases'][number-2].astype(int)\n        tt1.loc[number,'ConfirmedCases3']=tt1['ConfirmedCases'][number-3].astype(int)\n        tt1.loc[number,'ConfirmedCases6']=tt1['ConfirmedCases'][number-6].astype(int)\n        tt1.loc[number,'ConfirmedCases1-5']=(tt1['ConfirmedCases'][number-1].astype(int)+\n                                                tt1['ConfirmedCases'][number-2].astype(int)\n                                                +tt1['ConfirmedCases'][number-3].astype(int)\n                                                +tt1['ConfirmedCases'][number-4].astype(int)\n                                                +tt1['ConfirmedCases'][number-5].astype(int))                       \n        tt1.loc[number,'Fatalities1']=tt1['Fatalities'][number-1].astype(int)\n        tt1.loc[number,'Fatalities2']=tt1['Fatalities'][number-2].astype(int)\n        tt1.loc[number,'Fatalities3']=tt1['Fatalities'][number-3].astype(int)\n        tt1.loc[number,'Fatalities1-5']=(tt1['Fatalities'][number-1].astype(int)\n                                            +tt1['Fatalities'][number-2].astype(int)\n                                            +tt1['Fatalities'][number-3].astype(int)\n                                            +tt1['Fatalities'][number-4].astype(int)\n                                            +tt1['Fatalities'][number-5].astype(int))\n        tt1.loc[number,'dayc1']=tt1['dayc1'][number-1].astype(int)\n        tt1.loc[number,'dayc100_1000']=tt1['dayc100_1000'][number-1].astype(int)\n        tt1.loc[number,'dayc1_100']=tt1['dayc1_100'][number-1].astype(int)\n        tt1.loc[number, 'dayf1']=tt1['dayf1'][number-1].astype(int)\n        tt1.loc[number,'dayf100_200']=tt1['dayf100_200'][number-1].astype(int)\n        tt1.loc[number,'dayf1_100']=tt1['dayf1_100'][number-1].astype(int)\n        tt1.loc[number,'density']=tt1['density'][number-1].astype(int)\n        tt1.loc[number, 'gdp2019'  ]=tt1['gdp2019'][number-1].astype(int)\n        tt1.loc[number, 'hospibed'  ]=tt1['hospibed'][number-1].astype(int)\n        tt1.loc[number,'medianage' ]=tt1['medianage'][number-1].astype(int)\n        tt1.loc[number,'pop']=tt1['pop'][number-1].astype(int)\n        #train\n        X_valid = tt1[col_var].iloc[number]\n        X_valid2 = tt1[col_var2].iloc[number]\n        pred_f = model.predict(X_valid)\n        pred_c = model2.predict(X_valid2)\n        a=(np.exp(pred_f)-1).clip(0, 1e10)\n        if a<=tt1.loc[number,'ConfirmedCases1']+1:\n            tt1.loc[number,'ConfirmedCases']= tt1.loc[number,'ConfirmedCases1']+1\n        else:\n            tt1.loc[number,'ConfirmedCases']= a\n        b=(np.exp(pred_c)-1).clip(0, 1e10)\n        \n        tt1.loc[number,'Fatalities']=3*tt1.loc[number,'Fatalities1']-tt1.loc[number-1,'Fatalities1']-b\n    print(number)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tt1.to_csv('hhhh.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"fill China data"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=pd.read_csv(\"../input/subsub/submission (1).csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Submit**"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}