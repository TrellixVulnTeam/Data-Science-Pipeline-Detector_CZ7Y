{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier,LGBMRegressor\n\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import mean_squared_log_error,make_scorer,r2_score  \nfrom sklearn import preprocessing\npd.set_option('display.max_rows',500)\npd.set_option('display.max_columns',900)\n# from pandas_profiling import ProfileReport\nimport plotly\nimport warnings\nwarnings.filterwarnings('ignore')\n\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ntrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/test.csv')\nsubmission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Use datetime functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"df= pd.concat([train, test])\n\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Create date columns\nle = preprocessing.LabelEncoder()\ndf['Day_num'] = le.fit_transform(df.Date)\ndf['Day'] = df['Date'].dt.day\ndf['Month'] = df['Date'].dt.month\ndf['Year'] = df['Date'].dt.year\n\ndf.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import iplot\nfrom plotly import tools\nimport plotly.graph_objects as go\nimport plotly.express as px\nimport plotly.offline as py\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nimport plotly.io as pio\npio.templates.default = \"plotly_dark\"\npy.init_notebook_mode(connected=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Plotly"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby(['Date', 'Country_Region'])['ConfirmedCases'].sum().reset_index()\ntemp['Date'] = pd.to_datetime(temp['Date']).dt.strftime('%m/%d/%Y')\ntemp['size'] = temp['ConfirmedCases'].pow(0.3) * 3.5\n\nfig = px.scatter_geo(temp, locations=\"Country_Region\", locationmode='country names', \n                     color=\"ConfirmedCases\", size='size', hover_name=\"Country_Region\", \n                     range_color=[1,100],\n                     projection=\"natural earth\", animation_frame=\"Date\", \n                     title='COVID-19: Cases Over Time', color_continuous_scale=\"greens\")\nfig.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = train.groupby('Date')['Date', 'ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nfig2 = px.line(grouped, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Worldwide Confirmed Cases Over Time\")\nfig2.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"groupedbr = train[train['Country_Region']=='Brazil'].groupby('Date')['Date', 'ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nfig2 = px.line(groupedbr, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Brazil Confirmed Cases Over Time\")\nfig2.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Country and Province State names treatment"},{"metadata":{"trusted":true},"cell_type":"code","source":"df['Province_State'].fillna('Vazio',inplace=True)\ndf['Local']=np.where(df['Province_State']== 'Vazio',df['Country_Region'],df['Country_Region']+'/'+df['Province_State'])\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test=df[df['ForecastId']>0]\ndf['Date']=df['Date'].astype('str')\ndf=df[df['Id']>0]\ndf['ConfirmedCases'].fillna(0,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(df.dtypes)\ndf.sample()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creation of dataframes with different time windows"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_f=df[df['Month']>2]\n\ndf0=df[(df['Day_num'].between(0,14))]\ndf1=df[(df['Day_num'].between(15,29))]\ndf2=df[(df['Day_num'].between(30,44))]\ndf3=df[(df['Day_num'].between(45,59))]\ndf4=df[(df['Day_num'].between(60,74))]\n\ndf5=df[(df['Day_num'].between(50,64))]\ndf6=df[(df['Day_num'].between(35,49))]\ndf7=df[(df['Day_num'].between(52,66))]\ndf8=df[(df['Day_num'].between(58,72))]\ndf9=df[(df['Day_num'].between(49,63))]\ndf10=df[(df['Day_num'].between(39,53))]\ndf11=df[(df['Day_num'].between(48,62))]\ndf12=df[(df['Day_num'].between(59,73))]\ndf13=df[(df['Day_num'].between(61,75))]\ndf14=df[(df['Day_num'].between(26,40))]\ndf15=df[(df['Day_num'].between(46,60))]\ndf16=df[(df['Day_num'].between(56,70))]\ndf17=df[(df['Day_num'].between(57,71))]\ndf18=df[(df['Day_num'].between(36,50))]\ndf19=df[(df['Day_num'].between(53,67))]\n\ndfr=df[(df['Day_num'].between(62,76))]\n\n\n#df6=df[((df['Month']==3)&(df['Day'].between(23,31)))|((df['Month']==4)&(df['Day'].between(1,6)))]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Function to aggregate datasets into the model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def make_decay(df):\n    \n\n    dft=df.pivot_table(index='Local',columns='Date',values='ConfirmedCases').reset_index()\n    Lista_colunas=['Local','dia_01','dia_02','dia_03','dia_04','dia_05','dia_06','dia_07',\n               'dia_08','dia_09','dia_10','dia_11','dia_12','dia_13','dia_14','dia_15']\n    dft_copy=dft.copy()\n    dft.columns=Lista_colunas\n    C1=np.where(\n        (dft.iloc[: , -15].values)==0,\n    (np.power(dft.iloc[: , -8].values/((dft.iloc[: , -15].values)+1),1/7)) -(1)\n    ,(np.power(dft.iloc[: , -8].values/((dft.iloc[: , -15].values)),1/7)) -(1)\n    )\n\n    C1=np.where(C1<0,0,C1)\n\n    C2=np.where(\n        (dft.iloc[: , -8].values)==0,\n    (np.power(dft.iloc[: , -1].values/((dft.iloc[: , -8].values)+1),1/7)) -(1)\n    ,(np.power(dft.iloc[: , -1].values/((dft.iloc[: , -8].values)),1/7)) -(1)\n    )\n\n    C2=np.where(C2<0,0,C2)\n\n    dft['Crescimento_1']=C1\n    dft['Crescimento_2']=C2\n    \n    #dataset adicionais\n    #gdp2020 = pd.read_csv('/kaggle/input/covidinformacoes/gdp.csv')\n#population2020 = pd.read_csv('/kaggle/input/population2020/population2020.csv')\n    \n\n    emprego_vul= pd.read_csv('/kaggle/input/covidinformacoes/Vulnerable employment ( of total employment).csv',skiprows=1)\n    diox_carb=pd.read_csv('/kaggle/input/covidinformacoes/Carbon dioxide emissions per capita (tonnes).csv',skiprows=1)\n    expec_vida=pd.read_csv('/kaggle/input/covidinformacoes/Life expectancy at birth.csv',skiprows=1)\n    gastos_saude=pd.read_csv('/kaggle/input/covidinformacoes/Current health expenditure ( of GDP).csv',skiprows=1)\n    idh=pd.read_csv('/kaggle/input/covidinformacoes/Human Development Index (HDI).csv',skiprows=1)\n    idade_mediana=pd.read_csv('/kaggle/input/covidinformacoes/Median age (years).csv',skiprows=1)\n    tuberculose=pd.read_csv('/kaggle/input/covidinformacoes/Tuberculosis incidence (per 100000 people).csv',skiprows=1)\n    desigualdade_exp_vida=pd.read_csv('/kaggle/input/covidinformacoes/Inequality in life expectancy ().csv',skiprows=1)\n    desigualdade_idh_ajustado=pd.read_csv('/kaggle/input/covidinformacoes/Inequality-adjusted HDI (IHDI).csv',skiprows=1)\n    desigualdade_ganhos=pd.read_csv('/kaggle/input/covidinformacoes/Inequality in income ().csv',skiprows=1)\n    desemprego=pd.read_csv('/kaggle/input/covidinformacoes/Unemployment total ( of labour force).csv',skiprows=1)\n    #idade_mediana=pd.read_csv('/kaggle/input/covidinformacoes/Median age (years).csv',skiprows=1)\n    #idade_mediana=pd.read_csv('/kaggle/input/covidinformacoes/Median age (years).csv',skiprows=1)\n    \n    #df_life=emprego_vul.copy()\n    \n    def func(x):\n        x_new = 0\n        try:\n            x_new = float(x.replace(\",\", \"\"))\n        except:\n    #         print(x)\n            x_new = np.nan\n        return x_new\n    \n    tmp = emprego_vul.iloc[:,1].values.tolist()\n    emprego_vul = emprego_vul[['Country', '2018']]\n    emprego_vul['2018'] = emprego_vul['2018'].apply(lambda x: func(x))\n    emprego_vul.columns = ['Country', 'Emprego_vulneravel']\n\n    tmp = diox_carb.iloc[:,1].values.tolist()\n    diox_carb = diox_carb[['Country', '2016']]\n    diox_carb['2016'] = diox_carb['2016'].apply(lambda x: func(x))\n    diox_carb.columns = ['Country', 'Dioxido_carbono']\n\n    tmp = expec_vida.iloc[:,1].values.tolist()\n    expec_vida = expec_vida[['Country', '2018']]\n    expec_vida['2018'] = expec_vida['2018'].apply(lambda x: func(x))\n    expec_vida.columns = ['Country', 'Expec_vida']\n    \n    tmp = gastos_saude.iloc[:,1].values.tolist()\n    gastos_saude = gastos_saude[['Country', '2016']]\n    gastos_saude['2016'] = gastos_saude['2016'].apply(lambda x: func(x))\n    gastos_saude.columns = ['Country', 'Gastos_saude']\n    \n    tmp = idh.iloc[:,1].values.tolist()\n    idh = idh[['Country', '2018']]\n    idh['2018'] = idh['2018'].apply(lambda x: func(x))\n    idh.columns = ['Country', 'IDH'] \n    \n    tmp= idade_mediana.iloc[:,1].values.tolist()\n    idade_mediana = idade_mediana[['Country', '2020']]\n    idade_mediana['2020'] = idade_mediana['2020'].apply(lambda x: func(x))\n    idade_mediana.columns = ['Country', 'Idade']\n    \n    tmp= tuberculose.iloc[:,1].values.tolist()\n    tuberculose = tuberculose[['Country', '2017']]\n    tuberculose['2017'] = tuberculose['2017'].apply(lambda x: func(x))\n    tuberculose.columns = ['Country', 'Tuberculose']\n    \n    tmp= desigualdade_exp_vida.iloc[:,1].values.tolist()\n    desigualdade_exp_vida = desigualdade_exp_vida[['Country', '2018']]\n    desigualdade_exp_vida['2018'] = desigualdade_exp_vida['2018'].apply(lambda x: func(x))\n    desigualdade_exp_vida.columns = ['Country', 'desigualdade_exp_vida']\n    \n    tmp= desigualdade_ganhos.iloc[:,1].values.tolist()\n    desigualdade_ganhos = desigualdade_ganhos[['Country', '2018']]\n    desigualdade_ganhos['2018'] = desigualdade_ganhos['2018'].apply(lambda x: func(x))\n    desigualdade_ganhos.columns = ['Country', 'desigualdade_ganhos']\n    \n    tmp= desigualdade_idh_ajustado.iloc[:,1].values.tolist()\n    desigualdade_idh_ajustado = desigualdade_idh_ajustado[['Country', '2018']]\n    desigualdade_idh_ajustado['2018'] = desigualdade_idh_ajustado['2018'].apply(lambda x: func(x))\n    desigualdade_idh_ajustado.columns = ['Country', 'desigualdade_idh_ajustado']\n    \n    tmp= desemprego.iloc[:,1].values.tolist()\n    desemprego = desemprego[['Country', '2018']]\n    desemprego['2018'] = desemprego['2018'].apply(lambda x: func(x))\n    desemprego.columns = ['Country', 'desemprego']\n    \n    # Merge\n    \n    dft['Country']=dft['Local'].str.split('/',expand=True)[0]\n    \n    #train = pd.merge(train, population2020, how='left', left_on = 'Country_Region', right_on = 'name')\n    train=dft.copy()\n    train = pd.merge(train, desemprego, how='left',on='Country')\n    train = pd.merge(train, idade_mediana, how='left', on='Country')\n    train = pd.merge(train, idh, how='left', on='Country')\n    train = pd.merge(train, emprego_vul, how='left', on='Country')\n    train = pd.merge(train, gastos_saude, how='left', on='Country')\n    train = pd.merge(train, expec_vida, how='left', on='Country')\n    train = pd.merge(train, diox_carb, how='left', on='Country')\n    train = pd.merge(train, tuberculose, how='left',on='Country')\n    train = pd.merge(train, desigualdade_exp_vida, how='left', on='Country')\n    train = pd.merge(train, desigualdade_ganhos, how='left',on='Country')\n    train = pd.merge(train, desigualdade_idh_ajustado, how='left', on='Country')\n    \n \n \n    \n    dft=train.copy()\n    \n    dft.rename({'Taiwan*':'Taiwan'}, axis=1)\n    Beta1_RM=-0.1692\n    dft['Decay']=np.where(((dft['Crescimento_1']==0)|(dft['Crescimento_2']==0)),\n                          Beta1_RM,np.power(dft['Crescimento_2']/(dft['Crescimento_1']),1/7) - 1)\n    dft['Decay']=np.where(((dft['Crescimento_1']==0) & (dft['Crescimento_2']==0)),\n                    0,dft['Decay'])\n    dft['Decay']=np.where(dft['Decay'].fillna('Vazio')=='Vazio',0,dft['Decay'])\n    dft['Decay']=np.where(((dft['Decay']>0.02)&(dft['Crescimento_2']>0.20)),(1.5*Beta1_RM),dft['Decay'])\n    dft['Decay']=np.where(((dft_copy.iloc[: ,1].values>100) & (dft['Crescimento_2']>0.1)),(Beta1_RM),dft['Decay'])\n    return (dft)\n\n\n\n\n# Aplicar funções nas diferentes janelas temporais\n\ndft0=make_decay(df0)\ndft1=make_decay(df1)\ndft2=make_decay(df2)\ndft3=make_decay(df3)\ndft4=make_decay(df4)\ndft5=make_decay(df5)\ndft6=make_decay(df6)\ndft7=make_decay(df7)\ndft8=make_decay(df8)\ndft9=make_decay(df9)\ndft10=make_decay(df10)\ndft11=make_decay(df11)\ndft12=make_decay(df12)\ndft13=make_decay(df13)\ndft14=make_decay(df14)\ndft15=make_decay(df15)\ndft16=make_decay(df16)\ndft17=make_decay(df17)\ndft18=make_decay(df18)\ndft19=make_decay(df19)\n\ndftr=make_decay(dfr)\n\n\ndfmodel=pd.concat([dft0,dft1,dft2,dft3,dft4,dft5,dft6\n                  ,dft7,dft8,dft9,dft10,dft11,dft12\n                  ,dft13,dft14,dft15,dft16,dft17\n                  ,dft18,dft19],ignore_index=True)\ndfmodel.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(dfmodel.shape)\nprint(dftr.shape)\ndftr.head(1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Regression with Lightgbm"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfmodel.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in dfmodel.columns]\ndftr.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in dftr.columns]\nresposta=dftr['Decay']\ndfteste= dftr.drop(columns=['Local','Crescimento_1','Crescimento_2','Country'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=dfmodel['Decay']\nvariaveis=dfmodel.drop(columns=['Local','Crescimento_1','Crescimento_2','Country'])\n\nX_train, X_test,y_train,y_test = train_test_split(variaveis, y,test_size=0.2)\n\n\n#Hyper Parameters\nparams= {'boosting_type' : 'dart',\n         'max_depth':-1,\n         'objective':'regression',\n         'nthread': 5,\n         'num_leaves':64,\n         'learning_rate':0.01,\n         'max_bin':256,\n         'subsample_for_bin':200,\n         'subsample':1,\n         'subsample_freq':1,\n         'colsample_bytree':0.8,\n         'reg_alpha':1.2,\n         'reg_lambda':1.2,\n         'min_split_gain':0.5,\n         'min_child_weight':1,\n         'min_child_samples':5,\n         'metric':'l2'    \n}\n\ngridParams = {'learning_rate': [0.001,0.01,0.03,0.05,0.07,0.09]\n              ,'num_leaves':[10,20,30,50,70,80]\n              ,'boosting_type': ['dart']\n              ,'objective': ['regression']\n              ,'random_state' : [13]\n              ,'min_split_gain': [0.01,0.03,0.05]\n              ,'drop_rate' : [0.015,0.02,0.04,0.05,0.07]\n              ,'max_bin': [64,128,256]\n              ,'reg_alpha':[0,1,2,3,5,7]\n              ,'reg_lambda':[0,1,2,3,5,7]\n              ,'colsample_bytree':[0.03,0.05,0.6,0.7,0.8,0.9]\n              ,'min_child_weight':[0.1,0.25,0.5,0.8,1,1.5,2,3]\n}\n\nmdl = lgb.LGBMRegressor(boosting_type='dart',\n                       objective='regression',\n                       n_jobs=-1,\n                       silent=True,\n                       max_depth=params['max_depth'],\n                       max_bin=params['max_bin'],\n                       subsample_for_bin= params['subsample_for_bin'],\n                       subsample=params['subsample'],\n                        subsample_freq=params['subsample_freq'],\n                        min_split_gain=params['min_split_gain'],\n                        min_child_weight=params['min_child_weight'],\n                        min_child_samples=params['min_child_samples'],\n                       )\n\nmdl.get_params().keys()\n\ngrid=RandomizedSearchCV(mdl, gridParams, scoring=make_scorer(score_func=r2_score, greater_is_better=True)\n                        ,n_iter=25,n_jobs=-1)\n\ngrid.fit(X_train,y_train)\n\nprint(grid.best_params_)\nprint(grid.best_score_)\n\n#Get from Grid/RandomizedSearch\n\nparams['min_split_gain']= grid.best_params_['min_split_gain']\nparams['learning_rate']= grid.best_params_['learning_rate']\nparams['max_bin']= grid.best_params_['max_bin']\nparams['num_leaves']= grid.best_params_['num_leaves']\nparams['drop_rate']= grid.best_params_['drop_rate']\nparams['reg_alpha']= grid.best_params_['reg_alpha']\nparams['reg_lambda']= grid.best_params_['reg_lambda']\nparams['colsample_bytree']= grid.best_params_['colsample_bytree']\nparams['min_child_weight']= grid.best_params_['min_child_weight']\n\n\ntrain_data=lgb.Dataset(X_train,label=y_train)\nlgbm_cases= lgb.train(params,\n               train_data,\n               600,\n               verbose_eval=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resp=lgbm_cases.predict(dfteste)\nprint(r2_score(resp,resposta))\ndftr['Previsto']=resp\ndftr.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# SHAP on Feature Importance"},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap\nshap_values = shap.TreeExplainer(lgbm_cases).shap_values(X_train)\nshap.summary_plot(shap_values, X_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Take a look at Brazil, New York and more"},{"metadata":{"trusted":true},"cell_type":"code","source":"dft=df_f.pivot_table(index='Local',columns='Date',values='ConfirmedCases').reset_index()\n\ndft_copy=dft.copy()\n#dft.columns=Lista_colunas\nC1=np.where(\n        (dft.iloc[: , -15].values)==0,\n    (np.power(dft.iloc[: , -8].values/((dft.iloc[: , -15].values)+1),1/7)) -(1)\n    ,(np.power(dft.iloc[: , -8].values/((dft.iloc[: , -15].values)),1/7)) -(1)\n    )\n\nC1=np.where(C1<0,0,C1)\n\nC2=np.where(\n        (dft.iloc[: , -8].values)==0,\n    (np.power(dft.iloc[: , -1].values/((dft.iloc[: , -8].values)+1),1/7)) -(1)\n    ,(np.power(dft.iloc[: , -1].values/((dft.iloc[: , -8].values)),1/7)) -(1)\n    )\n\nC2=np.where(C2<0,0,C2)\n\ndft['Crescimento_1']=C1\ndft['Crescimento_2']=C2\n\nBeta1_RM=-0.1692\ndft['Decay']=np.where(((dft['Crescimento_1']==0)|(dft['Crescimento_2']==0)),\n                          Beta1_RM,np.power(dft['Crescimento_2']/(dft['Crescimento_1']),1/7) - 1)\ndft['Decay']=np.where(((dft['Crescimento_1']==0) & (dft['Crescimento_2']==0)),\n                    0,dft['Decay'])\ndft['Decay']=np.where(dft['Decay'].fillna('Vazio')=='Vazio',0,dft['Decay'])\ndft['Decay']=np.where(((dft['Decay']>0.02)&(dft['Crescimento_2']>0.20)),(1.5*Beta1_RM),dft['Decay'])\ndft['Decay']=np.where(((dft_copy.iloc[: ,1].values>100) & (dft['Crescimento_2']>0.1)),(Beta1_RM),dft['Decay'])\n\ndft.head()\n\ndt=pd.merge(dft,dftr[['Local','Previsto']],on='Local',how='left')\ndt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dt[dt['Local'].isin(['Brazil','US/New York','US/New Jersey','US/Illinois','US/California','Italy','Spain','France','Germany'])]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"Beta0=0.941\n#Beta1=-0.1692\ndft=dt.copy()\ndft['Decay_Calculado']=dft['Decay']\ndft['Decay']=dft['Previsto']\nBeta1=dft['Decay']\n\n\n\n#dft['Cres_2020-04-01']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-02']=dft['Cres_2020-04-01']*((dft['Cres_2020-04-01']*(Beta1)+Beta0))\n#dft['Cres_2020-04-03']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-04']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-05']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-06']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\n#dft['Cres_2020-04-07']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\ndft['Cres_2020-04-08']=dft['Crescimento_2']*((dft['Crescimento_2']*(Beta1)+Beta0))\ndft['Cres_2020-04-09']=dft['Cres_2020-04-08']*((dft['Cres_2020-04-08']*(Beta1)+Beta0))\ndft['Cres_2020-04-10']=dft['Cres_2020-04-09']*((dft['Cres_2020-04-09']*(Beta1)+Beta0))\ndft['Cres_2020-04-11']=dft['Cres_2020-04-10']*((dft['Cres_2020-04-10']*(Beta1)+Beta0))\ndft['Cres_2020-04-12']=dft['Cres_2020-04-11']*((dft['Cres_2020-04-11']*(Beta1)+Beta0))\ndft['Cres_2020-04-13']=dft['Cres_2020-04-12']*((dft['Cres_2020-04-12']*(Beta1)+Beta0))\ndft['Cres_2020-04-14']=dft['Cres_2020-04-13']*((dft['Cres_2020-04-13']*(Beta1)+Beta0))\ndft['Cres_2020-04-15']=dft['Cres_2020-04-14']*((dft['Cres_2020-04-14']*(Beta1)+Beta0))\ndft['Cres_2020-04-16']=dft['Cres_2020-04-15']*((dft['Cres_2020-04-15']*(Beta1)+Beta0))\ndft['Cres_2020-04-17']=dft['Cres_2020-04-16']*((dft['Cres_2020-04-16']*(Beta1)+Beta0))\ndft['Cres_2020-04-18']=dft['Cres_2020-04-17']*((dft['Cres_2020-04-17']*(Beta1)+Beta0))\ndft['Cres_2020-04-19']=dft['Cres_2020-04-18']*((dft['Cres_2020-04-18']*(Beta1)+Beta0))\ndft['Cres_2020-04-20']=dft['Cres_2020-04-19']*((dft['Cres_2020-04-19']*(Beta1)+Beta0))\ndft['Cres_2020-04-21']=dft['Cres_2020-04-20']*((dft['Cres_2020-04-20']*(Beta1)+Beta0))\ndft['Cres_2020-04-22']=dft['Cres_2020-04-21']*((dft['Cres_2020-04-21']*(Beta1)+Beta0))\ndft['Cres_2020-04-23']=dft['Cres_2020-04-22']*((dft['Cres_2020-04-22']*(Beta1)+Beta0))\ndft['Cres_2020-04-24']=dft['Cres_2020-04-23']*((dft['Cres_2020-04-23']*(Beta1)+Beta0))\ndft['Cres_2020-04-25']=dft['Cres_2020-04-24']*((dft['Cres_2020-04-24']*(Beta1)+Beta0))\ndft['Cres_2020-04-26']=dft['Cres_2020-04-25']*((dft['Cres_2020-04-25']*(Beta1)+Beta0))\ndft['Cres_2020-04-27']=dft['Cres_2020-04-26']*((dft['Cres_2020-04-26']*(Beta1)+Beta0))\ndft['Cres_2020-04-28']=dft['Cres_2020-04-27']*((dft['Cres_2020-04-27']*(Beta1)+Beta0))\ndft['Cres_2020-04-29']=dft['Cres_2020-04-28']*((dft['Cres_2020-04-28']*(Beta1)+Beta0))\ndft['Cres_2020-04-30']=dft['Cres_2020-04-29']*((dft['Cres_2020-04-29']*(Beta1)+Beta0))\n\ndft['Cres_2020-05-01']=dft['Cres_2020-04-30']*((dft['Cres_2020-04-30']*(Beta1)+Beta0))\ndft['Cres_2020-05-02']=dft['Cres_2020-05-01']*((dft['Cres_2020-05-01']*(Beta1)+Beta0))\ndft['Cres_2020-05-03']=dft['Cres_2020-05-02']*((dft['Cres_2020-05-02']*(Beta1)+Beta0))\ndft['Cres_2020-05-04']=dft['Cres_2020-05-03']*((dft['Cres_2020-05-03']*(Beta1)+Beta0))\ndft['Cres_2020-05-05']=dft['Cres_2020-05-04']*((dft['Cres_2020-05-04']*(Beta1)+Beta0))\ndft['Cres_2020-05-06']=dft['Cres_2020-05-05']*((dft['Cres_2020-05-05']*(Beta1)+Beta0))\ndft['Cres_2020-05-07']=dft['Cres_2020-05-06']*((dft['Cres_2020-05-06']*(Beta1)+Beta0))\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dft['2020-04-01']=(1+dft['Cres_2020-04-01'])*dft['2020-03-31']\n#dft['2020-04-02']=(1+dft['Cres_2020-04-02'])*dft['2020-04-01']\n#dft['2020-04-03']=(1+dft['Cres_2020-04-03'])*dft['2020-04-02']\n#dft['2020-04-04']=(1+dft['Cres_2020-04-04'])*dft['2020-04-03']\n#dft['2020-04-05']=(1+dft['Cres_2020-04-05'])*dft['2020-04-04']\n#dft['2020-04-06']=(1+dft['Cres_2020-04-06'])*dft['2020-04-05']\n#dft['2020-04-07']=(1+dft['Cres_2020-04-07'])*dft['2020-04-06']\ndft['2020-04-08']=(1+dft['Cres_2020-04-08'])*dft['2020-04-07']\ndft['2020-04-09']=(1+dft['Cres_2020-04-09'])*dft['2020-04-08']\ndft['2020-04-10']=(1+dft['Cres_2020-04-10'])*dft['2020-04-09']\ndft['2020-04-11']=(1+dft['Cres_2020-04-11'])*dft['2020-04-10']\ndft['2020-04-12']=(1+dft['Cres_2020-04-12'])*dft['2020-04-11']\ndft['2020-04-13']=(1+dft['Cres_2020-04-13'])*dft['2020-04-12']\ndft['2020-04-14']=(1+dft['Cres_2020-04-14'])*dft['2020-04-13']\ndft['2020-04-15']=(1+dft['Cres_2020-04-15'])*dft['2020-04-14']\ndft['2020-04-16']=(1+dft['Cres_2020-04-16'])*dft['2020-04-15']\ndft['2020-04-17']=(1+dft['Cres_2020-04-17'])*dft['2020-04-16']\ndft['2020-04-18']=(1+dft['Cres_2020-04-18'])*dft['2020-04-17']\ndft['2020-04-19']=(1+dft['Cres_2020-04-19'])*dft['2020-04-18']\ndft['2020-04-20']=(1+dft['Cres_2020-04-20'])*dft['2020-04-19']\ndft['2020-04-21']=(1+dft['Cres_2020-04-21'])*dft['2020-04-20']\ndft['2020-04-22']=(1+dft['Cres_2020-04-22'])*dft['2020-04-21']\ndft['2020-04-23']=(1+dft['Cres_2020-04-23'])*dft['2020-04-22']\ndft['2020-04-24']=(1+dft['Cres_2020-04-24'])*dft['2020-04-23']\ndft['2020-04-25']=(1+dft['Cres_2020-04-25'])*dft['2020-04-24']\ndft['2020-04-26']=(1+dft['Cres_2020-04-26'])*dft['2020-04-25']\ndft['2020-04-27']=(1+dft['Cres_2020-04-27'])*dft['2020-04-26']\ndft['2020-04-28']=(1+dft['Cres_2020-04-28'])*dft['2020-04-27']\ndft['2020-04-29']=(1+dft['Cres_2020-04-29'])*dft['2020-04-28']\ndft['2020-04-30']=(1+dft['Cres_2020-04-30'])*dft['2020-04-29']\n\ndft['2020-05-01']=(1+dft['Cres_2020-05-01'])*dft['2020-04-30']\ndft['2020-05-02']=(1+dft['Cres_2020-05-02'])*dft['2020-05-01']\ndft['2020-05-03']=(1+dft['Cres_2020-05-03'])*dft['2020-05-02']\ndft['2020-05-04']=(1+dft['Cres_2020-05-04'])*dft['2020-05-03']\ndft['2020-05-05']=(1+dft['Cres_2020-05-05'])*dft['2020-05-04']\ndft['2020-05-06']=(1+dft['Cres_2020-05-06'])*dft['2020-05-05']\ndft['2020-05-07']=(1+dft['Cres_2020-05-07'])*dft['2020-05-06']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Adjust fatalities"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfm=df_f.pivot_table(index='Local',columns='Date',values='Fatalities').reset_index()\n#dft.iloc[: , -8].values/((dft.iloc[: , -15].values)\nmortes_adj=dfm.iloc[: , -1].values.sum() / dft_copy.iloc[: , -1].values.sum()\ndft['mortes']=dfm.iloc[: , -1].values / dft_copy.iloc[: , -1].values\n \nprint(mortes_adj)\ndft.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dft[dft['Local'].isin(['Brazil','US/New York','US/New Jersey','US/Illinois','Italy','Spain','France','Germany'])]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dft.loc(dft['mortes']>(2*mortes_adj),'mortes')=(2*mortes_adj)\n#dft.loc(dft['mortes']<(mortes_adj/2),'mortes')=(mortes_adj/2)\ndft['mortes']=np.where(dft['mortes']>(2*mortes_adj),(2*mortes_adj),np.where(dft['mortes']<(mortes_adj/2),(mortes_adj/2),dft['mortes']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfi=dft[['Local', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04',\n       '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09',\n       '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14',\n       '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19',\n       '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24',\n       '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29',\n       '2020-03-30', '2020-03-31',  '2020-04-01', '2020-04-02', '2020-04-03',\n       '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08',\n       '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13',\n       '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18',\n       '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23',\n       '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28',\n       '2020-04-29', '2020-04-30','2020-05-01','2020-05-02','2020-05-03','2020-05-04','2020-05-05','2020-05-06','2020-05-07']]\ndfi.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfi['2020-05-07'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = dfi.melt('Local', var_name='Date', value_name='ConfirmedCases')\n\n\ndf=pd.merge(df,dft[['Local','mortes']],on='Local',how='left')\ndf['Fatalities']=df['ConfirmedCases']*df['mortes']\ndf[df['Local']=='Brazil']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndf_test.head()\ndf_test=df_test.drop(columns=['ConfirmedCases','Fatalities'])\ndf_test['Date']=df_test['Date'].astype('str')\ndf_test=pd.merge(df_test,df[['Local','Date','ConfirmedCases','Fatalities']],on=['Local','Date'],how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dff=df_test.sort_values(by='ConfirmedCases',ascending=False)\ndff.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndfm = dfm.melt('Local', var_name='Date', value_name='Fatalities')\n\ndfat=pd.merge(df_test,dfm[['Local','Fatalities','Date']],on=['Local','Date'],how='left',suffixes=('_predicted','_real'))\ndfat['Fatalities_real'].fillna('Vazio',inplace=True)\ndfat['Fatalities']=np.where(dfat['Fatalities_real']=='Vazio',dfat['Fatalities_predicted'],dfat['Fatalities_real'])\ndfat[dfat['Local']=='Brazil']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dfat.to_csv('Regioes.csv',index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ngroupedbr = dfat[dfat['Country_Region']=='Brazil'].groupby('Date')['Date', 'ConfirmedCases', 'Fatalities'].sum().reset_index()\n\nfig2 = px.line(groupedbr, x=\"Date\", y=\"ConfirmedCases\", \n              title=\"Brazil Confirmed Cases + Predicted Over Time\")\nfig2.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission=dfat[['ForecastId','ConfirmedCases','Fatalities']]\nsubmission['ForecastId']=submission['ForecastId'].astype('int32')\nsubmission['Fatalities']=submission['Fatalities'].astype('float')\nprint(submission.dtypes)\nsubmission.sample(10)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[df_test['ConfirmedCases'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dftpronto=dfat.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index=None)\nsubmission.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}