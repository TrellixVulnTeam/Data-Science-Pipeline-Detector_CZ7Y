{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Pandas profiling is an open source Python module with which we can quickly do an exploratory data analysis with just a few lines of code. Besides, if this is not enough to convince us to use this tool, it also generates interactive reports in web format that can be presented to any person, even if they donâ€™t know programming.\n### In short, what pandas profiling does is save us all the work of visualizing and understanding the distribution of each variable. It generates a report with all the information easily available."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from pandas_profiling import ProfileReport","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Generates profile reports from a pandas DataFrame. The pandas df.describe() function is great but a little basic for serious exploratory data analysis. pandas_profiling extends the pandas DataFrame with df.profile_report() for quick data analysis.\n\n### For each column the following statistics - if relevant for the column type - are presented in an interactive HTML report:\n\n* Type inference: detect the types of columns in a dataframe.\n* Essentials: type, unique values, missing values\n* Quantile statistics like minimum value, Q1, median, Q3, maximum, range, interquartile range\n* Descriptive statistics like mean, mode, standard deviation, sum, median absolute deviation, coefficient of variation, kurtosis, skewness\n* Most frequent values\n* Histogram\n* Correlations highlighting of highly correlated variables, Spearman, Pearson and Kendall matrices\n* Missing values matrix, count, heatmap and dendrogram of missing values\n* Text analysis learn about categories (Uppercase, Space), scripts (Latin, Cyrillic) and blocks (ASCII) of text data."},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_profile = ProfileReport(xtrain, title='Pandas Profiling Report', html={'style':{'full_width':True}})\n# train_profile\n# Load Data\nxtrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/train.csv')\nxtest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/test.csv')\nxsubmission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/submission.csv')\nxtrain.rename(columns={'Country_Region':'Country'}, inplace=True)\nxtest.rename(columns={'Country_Region':'Country'}, inplace=True)\n\nxtrain.rename(columns={'Province_State':'State'}, inplace=True)\nxtest.rename(columns={'Province_State':'State'}, inplace=True)\nxtrain.State=xtrain.State.fillna('NA')\nxtest.State=xtest.State.fillna('NA')\nxtrain['Date'] = pd.to_datetime(xtrain['Date'], infer_datetime_format=True)\nxtest['Date'] = pd.to_datetime(xtest['Date'], infer_datetime_format=True)\n\nfor j in range(14):\n    train_lag=xtrain.groupby(['Country','State']).shift(periods=j+1)\n\n    xtrain['lag_'+str(j+1)+'_ConfirmedCases']=train_lag['ConfirmedCases'].fillna(0)\n    xtrain['lag_'+str(j+1)+'_Fatalities']=train_lag['Fatalities'].fillna(0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.ConfirmedCases","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain.rename(columns={'Country_Region':'Country'}, inplace=True)\nxtest.rename(columns={'Country_Region':'Country'}, inplace=True)\n\nxtrain.rename(columns={'Province_State':'State'}, inplace=True)\nxtest.rename(columns={'Province_State':'State'}, inplace=True)\n\nxtrain['Date'] = pd.to_datetime(xtrain['Date'], infer_datetime_format=True)\nxtest['Date'] = pd.to_datetime(xtest['Date'], infer_datetime_format=True)\n\nxtrain.info()\nxtest.info()\nfor_y=xtest.merge(xtrain,on=['State','Country','Date'],how='inner')\ny1_xTrain = xtrain.ConfirmedCases\ny1_xTrain.head()\ny1_xTest = for_y.ConfirmedCases\ny1_xTest.head()\ny2_xTrain = xtrain.Fatalities\ny2_xTrain.head()\ny2_xTest = for_y.Fatalities\ny2_xTest.head()\nEMPTY_VAL = \"NA\"\n\ndef fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2_xTest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_xTrain = xtrain.copy()\n\nX_xTrain['State'].fillna(EMPTY_VAL, inplace=True)\n\n\nX_xTrain['State'] = X_xTrain.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\nX_xTrain.loc[:, 'Date_ACT'] = X_xTrain.Date\nX_xTrain.loc[:, 'Date'] = X_xTrain.Date.dt.strftime(\"%m%d\")\nX_xTrain[\"Date\"]  = X_xTrain[\"Date\"].astype(int)\n\nprint(X_xTrain.head())\n\n#X_Test = df_test.loc[:, ['State', 'Country', 'Date']]\nX_xTest = for_y.copy()\n\nX_xTest['State'].fillna(EMPTY_VAL, inplace=True)\nX_xTest['State'] = X_xTest.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_xTest.loc[:, 'Date'] = X_xTest.Date.dt.strftime(\"%m%d\")\nX_xTest[\"Date\"]  = X_xTest[\"Date\"].astype(int)\n\nprint(X_xTest.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Fit Data with Model**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\nlec = preprocessing.LabelEncoder()\nles = preprocessing.LabelEncoder()\nX_xTrain.Country = lec.fit_transform(X_xTrain.Country)\nX_xTrain['State'] = les.fit_transform(X_xTrain['State'])\n\nprint(X_xTrain.head())\n\nX_xTest.Country = lec.transform(X_xTest.Country)\nX_xTest['State'] = les.transform(X_xTest['State'])\n\nprint(X_xTest.head())\n\n\nxtrain.loc[xtrain.Country == 'Afghanistan', :]\nprint(xtest.tail())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings('ignore')\n\nfrom sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n\nfrom xgboost import XGBRegressor\n\ncountries = X_xTrain.Country.unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_xTest","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict data and Create submission file from test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Predict data and Create submission file from test data\n# xout = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\n# from sklearn.model_selection import GridSearchCV, train_test_split\n# from xgboost import XGBRegressor\n# k_log_col=['lag_'+str(j+1)+'_ConfirmedCases' for j in range(14)]+['lag_'+str(j+1)+'_Fatalities' for j in range(14)]\n# from sklearn.metrics import r2_score\n# params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,8)],\n# 'colsample_bytree':[i/10.0 for i in range(6,8)], 'max_depth': [3,4,5],'n_estimators':[500,1000],'learning_rate': [.03, 0.05, .07],\n#      'objective':['reg:squaredlogerror']}\n# # params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,7)],\n# # 'colsample_bytree':[i/10.0 for i in range(6,10)], 'max_depth': [2,3,4],'n_estimators':[500,1000],\n# #      'objective':['reg:squaredlogerror']}\n# params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,4,5)],  'subsample':[i/10.0 for i in range(6,7)],\n# 'colsample_bytree':[i/10.0 for i in range(6,7)], 'max_depth': [2,3,4],'n_estimators':[1000],\n#      'objective':['reg:squaredlogerror']}\n# def RMSLE(pred,actual):\n#     return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))\n# import time\n# for country in countries[:1]:\n#     st_time=time.time()\n#     states = X_xTrain.loc[X_xTrain.Country == country, :].State.unique()\n#     #print(country, states)\n#     # check whether string is nan or not\n#     for state in states:\n#         print(lec.inverse_transform([country]), les.inverse_transform([state]) )\n#         X_xTrain_CS = X_xTrain.loc[(X_xTrain.Country == country) & (X_xTrain.State == state), ['State', 'Country', 'Date','Date_ACT', 'ConfirmedCases', 'Fatalities']+k_log_col]\n        \n#         #print(X_xTrain_CS.Country.unique())\n#         y1_xTrain_CS = X_xTrain_CS.loc[:, 'ConfirmedCases']\n#         y2_xTrain_CS = X_xTrain_CS.loc[:, 'Fatalities']\n        \n#         X_xTrain_CS1 = X_xTrain_CS.loc[:, ['State', 'Country']+k_log_col]\n#         le1=preprocessing.LabelEncoder().fit(X_xTrain_CS1.Country)\n#         le2=preprocessing.LabelEncoder().fit(X_xTrain_CS1['State'])\n#         X_xTrain_CS1.Country = le1.transform(X_xTrain_CS1.Country)\n#         X_xTrain_CS1['State'] = le2.transform(X_xTrain_CS1['State'])\n        \n#         X_xTest_CS = X_xTest.loc[(X_xTest.Country == country) & (X_xTest.State == state), ['State', 'Country', 'Date', 'ForecastId']+k_log_col]\n#         y1_xTest_CS = for_y[(X_xTest.Country == country) & (X_xTest.State == state)].iloc[:, -2]\n#         y2_xTest_CS = for_y[(X_xTest.Country == country) & (X_xTest.State == state)].iloc[:, -1]\n#         X_xTest_CS_Id = X_xTest_CS.loc[:, 'ForecastId']\n#         X_xTest_CS1 = X_xTest_CS.loc[:, ['State', 'Country']+k_log_col]\n        \n#         X_xTest_CS1.Country = le1.transform(X_xTest_CS.Country)\n#         X_xTest_CS1['State'] = le2.transform(X_xTest_CS['State'])\n        \n#         #models_C[country] = gridSearchCV(model, X_Train_CS, y1_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n#         #models_F[country] = gridSearchCV(model, X_Train_CS, y2_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n        \n\n#         xgb1 = XGBRegressor(nthread=-1) \n\n#         grid = GridSearchCV(xgb1, params)\n#         grid.fit(X_xTrain_CS1, y1_xTrain_CS)\n\n#         # Print the r2 score\n#         print(r2_score(y1_xTest_CS, grid.best_estimator_.predict(X_xTest_CS1))) \n#         print(RMSLE(y1_xTest_CS, grid.best_estimator_.predict(X_xTest_CS1))) \n\n#         # Save the file\n#         y1_xpred = grid.best_estimator_.predict(X_xTest_CS1)\n        \n# #         xmodel2 = XGBRegressor(n_estimators=1000)\n# #         xmodel2.fit(X_xTrain_CS, y2_xTrain_CS)\n# #         y2_xpred = xmodel2.predict(X_xTest_CS)\n#         xgb2 = XGBRegressor(nthread=-1)\n#         grid1 = GridSearchCV(xgb2, params)\n#         grid1.fit(X_xTrain_CS1, y2_xTrain_CS)\n\n#         # Print the r2 score\n#         print(r2_score(y2_xTest_CS, grid1.best_estimator_.predict(X_xTest_CS1))) \n#         print(RMSLE(y2_xTest_CS, grid1.best_estimator_.predict(X_xTest_CS1))) \n#         # Save the file\n#         y2_xpred = grid1.best_estimator_.predict(X_xTest_CS1)\n        \n#         xdata = pd.DataFrame({'ForecastId': X_xTest_CS_Id, 'ConfirmedCases': y1_xpred, 'Fatalities': y2_xpred})\n#         xout = pd.concat([xout, xdata], axis=0)\n#         print('Total time for 1 run ' + str(time.time()-st_time))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Predict data and Create submission file from test data\nxout = pd.DataFrame({'ForecastId': [], 'ConfirmedCases': [], 'Fatalities': []})\n\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom xgboost import XGBRegressor\nk_log_col=['lag_'+str(j+1)+'_ConfirmedCases' for j in range(14)]+['lag_'+str(j+1)+'_Fatalities' for j in range(14)]\nfrom sklearn.metrics import r2_score\nparams = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,8)],\n'colsample_bytree':[i/10.0 for i in range(6,8)], 'max_depth': [3,4,5],'n_estimators':[500,1000],'learning_rate': [.03, 0.05, .07],\n     'objective':['reg:squaredlogerror']}\n# params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,7)],\n# 'colsample_bytree':[i/10.0 for i in range(6,10)], 'max_depth': [2,3,4],'n_estimators':[500,1000],\n#      'objective':['reg:squaredlogerror']}\nparams = {'min_child_weight':[4,5],  'max_depth': [6],'n_estimators':[1000]}\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))\nimport time\n\nX_xTrain_CS = X_xTrain.loc[:, ['State', 'Country', 'Date','Date_ACT', 'ConfirmedCases', 'Fatalities']+k_log_col]\n\n#print(X_xTrain_CS.Country.unique())\ny1_xTrain_CS = X_xTrain_CS[X_xTrain_CS['ConfirmedCases'] - X_xTrain_CS['lag_1_ConfirmedCases'] >0]['ConfirmedCases']-X_xTrain_CS[X_xTrain_CS['ConfirmedCases'] - X_xTrain_CS['lag_1_ConfirmedCases'] >0]['lag_1_ConfirmedCases']\ny2_xTrain_CS = X_xTrain_CS[X_xTrain_CS['ConfirmedCases'] - X_xTrain_CS['lag_1_ConfirmedCases'] >0]['Fatalities']-X_xTrain_CS[X_xTrain_CS['ConfirmedCases'] - X_xTrain_CS['lag_1_ConfirmedCases'] >0]['lag_1_Fatalities']\n\n#X_xTrain_CS1 = X_xTrain_CS.loc[:, ['State', 'Country']+k_log_col]\nX_xTrain_CS1=X_xTrain_CS[(X_xTrain_CS['ConfirmedCases'] - X_xTrain_CS['lag_1_ConfirmedCases']) >0].loc[:, ['State', 'Country']+k_log_col].reset_index(drop=True)\noh1=preprocessing.OneHotEncoder(sparse=False).fit(X_xTrain_CS.Country.values.reshape(X_xTrain_CS.Country.shape[0],1))\noh2=preprocessing.OneHotEncoder(sparse=False).fit(X_xTrain_CS.State.values.reshape(X_xTrain_CS.Country.shape[0],1))\n\n\nall_val=oh1.transform(X_xTrain_CS1.Country.values.reshape(X_xTrain_CS1.Country.shape[0],1))\n\ncol=['cnty_'+str(k) for k in range(all_val.shape[1])]\nX_xTrain_CS1=pd.concat([X_xTrain_CS1,pd.DataFrame(all_val,columns=col)],axis=1)\n\n\nall_val_State=oh2.transform(X_xTrain_CS1.State.values.reshape(X_xTrain_CS1.State.shape[0],1))\n\ncol_State=['state_'+str(k) for k in range(all_val_State.shape[1])]\nX_xTrain_CS1=pd.concat([X_xTrain_CS1,pd.DataFrame(all_val_State,columns=col_State)],axis=1)\n# X_xTrain_CS1.Country = le1.transform(X_xTrain_CS1.Country)\n# X_xTrain_CS1['State'] = le2.transform(X_xTrain_CS1['State'])\n\nX_xTest_CS = X_xTest.loc[:, ['State', 'Country', 'Date', 'ForecastId']+k_log_col]\ny1_xTest_CS = for_y.loc[:, 'ConfirmedCases']-for_y.loc[:, 'lag_1_ConfirmedCases']\ny2_xTest_CS = for_y.loc[:, 'Fatalities']-for_y.loc[:, 'lag_1_Fatalities']\nX_xTest_CS_Id = X_xTest_CS.loc[:, 'ForecastId']\nX_xTest_CS1 = X_xTest_CS.loc[:, ['State', 'Country']+k_log_col]\nall_val=oh1.transform(X_xTest_CS1.Country.values.reshape(X_xTest_CS1.Country.shape[0],1))\n\ncol=['cnty_'+str(k) for k in range(all_val.shape[1])]\nX_xTest_CS1=pd.concat([X_xTest_CS1,pd.DataFrame(all_val,columns=col)],axis=1)\n\n\nall_val_State=oh2.transform(X_xTest_CS1.State.values.reshape(X_xTest_CS1.State.shape[0],1))\n\ncol_State=['state_'+str(k) for k in range(all_val_State.shape[1])]\nX_xTest_CS1=pd.concat([X_xTest_CS1,pd.DataFrame(all_val_State,columns=col_State)],axis=1)\n# # X_xTest_CS1.Country = le1.transform(X_xTest_CS.Country)\n# # X_xTest_CS1['State'] = le2.transform(X_xTest_CS['State'])\n\n# # #models_C[country] = gridSearchCV(model, X_Train_CS, y1_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n# # #models_F[country] = gridSearchCV(model, X_Train_CS, y2_Train_CS, param_grid, 10, 'neg_mean_squared_error')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y2_xTrain_CS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nxgb1 = XGBRegressor(nthread=-1,n_jobs=-1) \n\ngrid = GridSearchCV(xgb1, params)\ngrid.fit(X_xTrain_CS1, y1_xTrain_CS)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Print the r2 score\nprint(r2_score(y1_xTest_CS, np.where(grid.best_estimator_.predict(X_xTest_CS1)<0,0,grid.best_estimator_.predict(X_xTest_CS1)))) \nprint(RMSLE(np.where(y1_xTest_CS<=0,0.001,y1_xTest_CS), np.where(grid.best_estimator_.predict(X_xTest_CS1)<=0,0.001,grid.best_estimator_.predict(X_xTest_CS1))))\n\n# # Save the file\n# y1_xpred = grid.best_estimator_.predict(X_xTest_CS1)\n\n# #         xmodel2 = XGBRegressor(n_estimators=1000)\n# #         xmodel2.fit(X_xTrain_CS, y2_xTrain_CS)\n# #         y2_xpred = xmodel2.predict(X_xTest_CS)\nxgb2 = XGBRegressor(nthread=-1,n_jobs=-1)\ngrid1 = GridSearchCV(xgb2, params)\ngrid1.fit(X_xTrain_CS1, y2_xTrain_CS)\n\n# Print the r2 score\nprint(r2_score(y2_xTest_CS, np.where(grid1.best_estimator_.predict(X_xTest_CS1)<0,0,grid1.best_estimator_.predict(X_xTest_CS1)))) \nprint(RMSLE(np.where(y2_xTest_CS<=0,0.001,y2_xTest_CS), np.where(grid1.best_estimator_.predict(X_xTest_CS1)<=0,0.001,grid1.best_estimator_.predict(X_xTest_CS1))))\nprint(r2_score(y2_xTest_CS, grid1.best_estimator_.predict(X_xTest_CS1))) \nprint(RMSLE(y2_xTest_CS, grid1.best_estimator_.predict(X_xTest_CS1))) \n# Save the file\ny2_xpred = grid1.best_estimator_.predict(X_xTest_CS1)\n\n# xdata = pd.DataFrame({'ForecastId': X_xTest_CS_Id, 'ConfirmedCases': y1_xpred, 'Fatalities': y2_xpred})\n# xout = pd.concat([xout, xdata], axis=0)\n# print('Total time for 1 run ' + str(time.time()-st_time))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_xTrain_CS1_bk=X_xTrain_CS1.copy()\n\nX_xTrain_CS12=X_xTrain_CS.copy()\n\nall_val=oh1.transform(X_xTrain_CS12.Country.values.reshape(X_xTrain_CS12.Country.shape[0],1))\ncol=['cnty_'+str(k) for k in range(all_val.shape[1])]\nX_xTrain_CS12=pd.concat([X_xTrain_CS12,pd.DataFrame(all_val,columns=col)],axis=1)\n\n\nall_val_State=oh2.transform(X_xTrain_CS12.State.values.reshape(X_xTrain_CS12.State.shape[0],1))\ncol_State=['state_'+str(k) for k in range(all_val_State.shape[1])]\nX_xTrain_CS12=pd.concat([X_xTrain_CS12,pd.DataFrame(all_val_State,columns=col_State)],axis=1)\n\nX_xTrain_CS12=X_xTrain_CS12[X_xTrain_CS1.columns].copy()\n\nX_xTrain_CS12['Date_ACT']=X_xTrain_CS['Date_ACT']\nX_xTrain_CS12['Fatalities']=X_xTrain_CS['Fatalities']\nX_xTrain_CS12['ConfirmedCases']=X_xTrain_CS['ConfirmedCases']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for k in range(60):\n    X_xTrain_CS12\n    prev=X_xTrain_CS12[X_xTrain_CS12['Date_ACT']==X_xTrain_CS12.Date_ACT.max()]\n    lt=[ 'lag_1_ConfirmedCases','lag_2_ConfirmedCases', 'lag_3_ConfirmedCases',\n           'lag_4_ConfirmedCases', 'lag_5_ConfirmedCases', 'lag_6_ConfirmedCases',\n           'lag_7_ConfirmedCases', 'lag_8_ConfirmedCases', 'lag_9_ConfirmedCases',\n           'lag_10_ConfirmedCases', 'lag_11_ConfirmedCases',\n           'lag_12_ConfirmedCases', 'lag_13_ConfirmedCases',\n           'lag_14_ConfirmedCases', 'lag_1_Fatalities','lag_2_Fatalities',\n           'lag_3_Fatalities', 'lag_4_Fatalities', 'lag_5_Fatalities',\n           'lag_6_Fatalities', 'lag_7_Fatalities', 'lag_8_Fatalities',\n           'lag_9_Fatalities', 'lag_10_Fatalities', 'lag_11_Fatalities',\n           'lag_12_Fatalities', 'lag_13_Fatalities', 'lag_14_Fatalities']\n    #print(prev)\n    lt1=['ConfirmedCases','lag_1_ConfirmedCases', 'lag_2_ConfirmedCases', 'lag_3_ConfirmedCases',\n           'lag_4_ConfirmedCases', 'lag_5_ConfirmedCases', 'lag_6_ConfirmedCases',\n           'lag_7_ConfirmedCases', 'lag_8_ConfirmedCases', 'lag_9_ConfirmedCases',\n           'lag_10_ConfirmedCases', 'lag_11_ConfirmedCases',\n           'lag_12_ConfirmedCases', 'lag_13_ConfirmedCases',\n           'Fatalities', 'lag_1_Fatalities', 'lag_2_Fatalities',\n           'lag_3_Fatalities', 'lag_4_Fatalities', 'lag_5_Fatalities',\n           'lag_6_Fatalities', 'lag_7_Fatalities', 'lag_8_Fatalities',\n           'lag_9_Fatalities', 'lag_10_Fatalities', 'lag_11_Fatalities',\n           'lag_12_Fatalities', 'lag_13_Fatalities']\n    prev[lt]=X_xTrain_CS12[X_xTrain_CS12['Date_ACT']==X_xTrain_CS12.Date_ACT.max()][lt1]\n    #print(prev)\n    cc=grid.best_estimator_.predict(X_xTrain_CS12[X_xTrain_CS12['Date_ACT']==X_xTrain_CS12.Date_ACT.max()][ ['State', 'Country']+k_log_col+col+col_State])\n    prev['ConfirmedCases']=prev['lag_1_ConfirmedCases']+np.where(cc<=0,0.001,cc)\n    Fl=grid1.best_estimator_.predict(X_xTrain_CS12[X_xTrain_CS12['Date_ACT']==X_xTrain_CS12.Date_ACT.max()][ ['State', 'Country']+k_log_col+col+col_State])\n    prev['Fatalities']=prev['lag_1_Fatalities']+np.where(Fl<=0,0.001,Fl)\n    import datetime\n    prev['Date_ACT']=X_xTrain_CS12.Date_ACT.max()+  datetime.timedelta(days=1)\n    prev.index=prev.index+1\n    X_xTrain_CS12=X_xTrain_CS12.append(prev)\n    #print(prev)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_xTrain_CS2=X_xTrain_CS12.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_xTrain_CS2['Country_1']=lec.inverse_transform(X_xTrain_CS2['Country'])\nX_xTrain_CS2['State_1']=les.inverse_transform(X_xTrain_CS2['State'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_xTrain_CS2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/test.csv')\nxsubmission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/submission.csv')\n\nxtest.rename(columns={'Country_Region':'Country'}, inplace=True)\n\n\nxtest.rename(columns={'Province_State':'State'}, inplace=True)\n\n#xtest.State=xtest.State.fillna('NA')\nEMPTY_VAL = \"NA\"\n\ndef fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state\nxtest['Date'] = pd.to_datetime(xtest['Date'], infer_datetime_format=True)\nxtest['State'].fillna(EMPTY_VAL, inplace=True)\nxtest['State'] = xtest.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\nxtest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest1=xtest.merge(X_xTrain_CS2,left_on=['State','Country','Date'],right_on=['State_1','Country_1','Date_ACT'],how='inner')\nxtest1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest1[(xtest1['Country_x']=='US') & (xtest1['State_x']=='New York')][['Date','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest1[(xtest1['Country_x']=='India') & (xtest1['State_x']=='India')][['Date','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xtest1[['Fatalities','ConfirmedCases','ForecastId']].to_csv('submission.csv', index=False)\n# xtest.to_csv('submission.csv', index=False)\n# xout.ForecastId = xout.ForecastId.astype('int')\n# xout.tail()\n# xout.to_csv('submission.csv', index=False)\nprint(\"Submission file Created.....\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}