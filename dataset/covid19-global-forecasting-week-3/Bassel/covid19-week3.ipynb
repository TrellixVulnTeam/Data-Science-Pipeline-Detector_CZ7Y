{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_log_error\n\nmpl.rcParams['axes.grid']=True\npd.options.display.max_rows = 99\n\n\ntrain = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/train.csv')\ntest = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/test.csv')\nsubmission = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/submission.csv')\n\ntrain.Date = pd.to_datetime(train.Date)\ntest.Date = pd.to_datetime(test.Date)\n\ndef fill_province(row):\n    if pd.isna(row['Province_State']):\n        row['Province_State'] = '_PROVINCE_' + row['Country_Region']\n    return row\n\ntrain = train.apply(fill_province, axis = 1)\ntest = test.apply(fill_province, axis = 1)\n\ndef extract_time_features(df):\n    df['Day'] = df['Date'].dt.day\n    df['Day_of_Week'] = df['Date'].dt.dayofweek\n    df['Day_of_Year'] = df['Date'].dt.dayofyear\n    df['Week_of_Year'] = df['Date'].dt.weekofyear\n    df['Days_im_Month'] = df['Date'].dt.days_in_month\n\nextract_time_features(train)\nextract_time_features(test)\n\ntrain_col_to_delete = ['Id', 'ConfirmedCases', 'Fatalities', 'Country_Region', 'Province_State', 'Date' ]\ntest_col_to_delete = ['ForecastId', 'Date', 'Country_Region', 'Province_State']\nvalidation_duration = 2\nvalidation_duration = np.timedelta64(validation_duration - 1, 'D')\nprint(validation_duration)\n\ndef train_val_split(df, display = False):\n    split_thr = df['Date'].max() - validation_duration \n    df_train = df[df['Date'] < split_thr ]\n    X_train = df_train.drop(columns = train_col_to_delete)\n    y_cc_train = df_train[['ConfirmedCases']]\n    y_fa_train = df_train[['Fatalities']]\n\n    df_val= df[df['Date'] >= split_thr ]\n    X_val = df_val.drop(columns = train_col_to_delete)\n    y_cc_val = df_val[['ConfirmedCases']]\n    y_fa_val = df_val[['Fatalities']]\n\n    if display:\n        print('data shape:', df.shape)\n        print('train shape:', df_train.shape)\n        print('val shape:', df_val.shape)\n    return(X_train, y_cc_train, y_fa_train, X_val, y_cc_val, y_fa_val)\n\ndef plot_feature_importance(model, X):\n    feat_importance = pd.DataFrame(sorted(zip(model.feature_importance(importance_type = 'gain'), X.columns)), columns=['Score','Feature'])\n    feat_importance = feat_importance.sort_values(by = \"Score\", ascending = False)\n    plt.figure(figsize = (8, 8))\n    sns.barplot(x = \"Score\", y = \"Feature\", data = feat_importance)\n    plt.title('LightGBM Features')\n    plt.tight_layout()\n    plt.show()\n    return feat_importance.reset_index(drop = True)\n\ndef create_model(X_train, y_train, X_val, y_val, draw_metics = False):\n    n_estimators = 100\n    params = {\n  'metric': 'rmse',\n  'objective': 'mse',\n  'verbose': 0, \n  'learning_rate': 0.99,\n    }\n    d_train = lgb.Dataset(X_train, y_train)\n    d_valid = lgb.Dataset(X_val, y_val)\n    watchlist = [d_train, d_valid]\n    evals_result = {}\n    model = lgb.train(params,\n                    d_train, \n                    n_estimators,\n                    valid_sets = watchlist, \n                    evals_result = evals_result, \n                    early_stopping_rounds = 10,\n                    verbose_eval = 0,\n                    )\n    if draw_metics:\n        lgb.plot_metric(evals_result) \n    return model\n\ndef rmse(y, y_hat):\n    return np.sqrt(mean_squared_error(y, y_hat))\n\ndef rmsle(y, y_hat):\n    y_hat = np.where(y_hat < 0, 0, y_hat)\n    return 'rmsle', np.sqrt(mean_squared_log_error(y, y_hat))\n\ndef evaluate_model(model, X_train, y_train, X_val, y_val): \n    y_hat = model.predict(X_train)\n    print('Training error;', rmsle(y_train, y_hat))\n    y_val_hat = model.predict(X_val)\n    print('Validation error:', rmsle(y_val, y_val_hat))\n\n\n# Modeling for all country\n\nsubmission = pd.DataFrame(columns = submission.columns)\n\nfor country in train['Country_Region'].unique():\n    print('start modeling for ', country, '...')\n    provinces = train[train['Country_Region'] == country]['Province_State'].unique()\n    for province in provinces:\n        country_df = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n        X_train, y_cc_train, y_fa_train, X_val, y_cc_val, y_fa_val = train_val_split(country_df)\n        model_cc = create_model(X_train, y_cc_train, X_val, y_cc_val)\n        model_fa = create_model(X_train, y_fa_train, X_val, y_fa_val)\n\n        test_df = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n        forcast_id = test_df['ForecastId'].values.tolist()\n\n        X_test = test_df.drop(columns=test_col_to_delete)\n        y_cc_hat = model_cc.predict(X_test)\n        y_fa_hat = model_fa.predict(X_test)\n\n        test_res = pd.DataFrame(columns=submission.columns)\n        test_res['ForecastId'] = forcast_id\n        test_res['ConfirmedCases'] = y_cc_hat\n        test_res['Fatalities'] = y_fa_hat\n        submission = submission.append(test_res)\n\nfor col in ['ConfirmedCases', 'Fatalities']:\n    submission.loc[submission[col] < 0, col] = 0\n\nsubmission.to_csv('submission' + '.csv', index = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}