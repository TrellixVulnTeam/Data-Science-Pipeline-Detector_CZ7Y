{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\n\n\nimport matplotlib.pyplot as plt\n# import seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom wordcloud import WordCloud\nfrom plotly.subplots import make_subplots\n\n# predefine color pallette alias\ncnf = 'grey' # confirmed\ndth = 'red' # death\nrec = 'lightgreen' # recovered\nact = 'orange' # active\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/covid-forecasting-datasets/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('../input/covid19-global-forecasting-week-3/train.csv')\ntest_df = pd.read_csv('../input/covid19-global-forecasting-week-3/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lockdown = pd.read_csv(\"../input/covid-forecasting-datasets/countryLockdowndates.csv\")\nlockdown.columns = ['Country_Region', 'Province_State', 'Date_lockdown', 'Type', 'Reference']\nlowckdown_df = train_df.merge(lockdown, on=['Country_Region', 'Province_State'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measures = pd.read_csv(\"../input/covid-forecasting-datasets/acaps-covid-19-government-measures-dataset.csv\")\nmeasures.columns = ['id', 'Country_Region', 'iso', 'admin_level_name', 'pcode', 'region',\n       'category', 'measure', 'targeted_pop_group', 'comments',\n       'measures_date_implemented', 'source', 'source_type', 'link', 'entry_date',\n       'alternative_source']\n\nmeasures = measures[[\n    'id', 'Country_Region', 'category', 'measure', 'targeted_pop_group', 'comments', 'measures_date_implemented'\n    ]]\n\nmeasures[\"Country_Region\"].replace({\n    \"United States of America\": \"US\",\n    \"Russia\": \"Russian Federation\",\n    \"Viet Nam\": \"Vietnam\",\n    \"Korea Republic of\": \"Korea, South\",\n    \"Czech Republic\":\"Korea, South\"\n    }, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measures['category'] = measures.category.str.lower()\nmeasures['measure'] =  measures.measure.str.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"measures['measures_date_implemented'] = pd.to_datetime(measures[\"measures_date_implemented\"], errors='coerce')\n\nmeasures_country = measures.groupby(['Country_Region', 'measure']).agg({'measures_date_implemented': 'min'}).reset_index()\n\n\npivot_measures = pd.pivot_table(measures_country, values='measures_date_implemented', index=['Country_Region'],\n                    columns=['measure'], aggfunc='min')\npivot_measures = pivot_measures.reset_index()\npivot_measures\n\nlowckdown_df.Date = pd.to_datetime(lowckdown_df.Date)\nlockdown_measure_df = lowckdown_df.merge(\n    pivot_measures, left_on=['Country_Region'], right_on=['Country_Region'], how='left')\nlockdown_measure_df\n\n\nfor column in pivot_measures.columns.tolist():\n    if column in ['Country_Region', 'measures_date_implemented']:\n        continue\n    lockdown_measure_df.loc[lockdown_measure_df['Date'] >= pd.to_datetime(lockdown_measure_df[column]), column+'_flag'] = 1\n    lockdown_measure_df.drop(columns=[column], inplace=True)\n\nlockdown_measure_df.head()\n\nlockdown_measure_df.fillna(0.0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"location_global = pd.read_csv(\"../input/covid-forecasting-datasets/time_series_covid19_confirmed_global.csv\")[['Province/State', 'Country/Region', 'Lat', 'Long']\n                                                                  ].rename(columns={\n                    'Province/State': 'Province_State',\n                    'Country/Region': 'Country_Region'\n})\n\nlocation_us = pd.read_csv(\"../input/covid-forecasting-datasets/time_series_covid19_confirmed_US.csv\")[['Province_State', 'Country_Region', 'Lat', 'Long_']\n                                                                  ].rename(columns={\n                    'Long_': 'Long'\n})\n\nlocation = location_global.append(location_us)\n\n\nlocation = location[(location.Lat != 0) & (location.Long != 0)].drop_duplicates(\n    ['Province_State', 'Country_Region'])\n\nlocation\n\n\nlockdown_geo = lockdown_measure_df.merge(\n    location.fillna(0.0), on=['Country_Region', 'Province_State'], how='left')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Label Encode"},{"metadata":{"trusted":true},"cell_type":"code","source":"lockdown_geo['Location'] = lockdown_geo['Province_State'].astype(str) + '_' + lockdown_geo['Country_Region'].astype(str)\n\nfrom sklearn import preprocessing\n\ntypes = lockdown_geo.dtypes\ncat_columns = [t[0] for t in types.iteritems() if ((t[1] not in ['int64', 'float64']))]\n\nprint('Label encoding categorical columns:', cat_columns)\nencoders = {}\nLocations = []\nfor col in cat_columns:\n    lbl = preprocessing.LabelEncoder()\n    if col == 'Location':\n        Locations += lockdown_geo[col].unique().tolist()\n    if col == 'Date':\n        continue\n    lockdown_geo[col] = lbl.fit_transform(lockdown_geo[col].astype(str))\n    encoders[col] = lbl\n    \n","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"all_dates = list(set(train_df.Date.unique().tolist() + test_df.Date.unique().tolist()))\nlbl = preprocessing.LabelEncoder()\nlbl.fit(all_dates)\nlockdown_geo['Date'] = lbl.transform(lockdown_geo[['Date']].astype(str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train / Test"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"train_window_size = len(lockdown_geo.Date.unique())\nlookback_window_size = 14\nforecast_window_size = 33","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_set = []\nlabels_cases = []\nlabels_fatalities = []\n\nfrom tqdm import *\n\nfor i in tqdm(range(lookback_window_size, train_window_size - forecast_window_size)):\n\n    for location in lockdown_geo.Location.unique().tolist():\n        df = lockdown_geo[lockdown_geo.Location == location].reset_index()\n        features_set.append(df.iloc[i-lookback_window_size:i, 3:].values)\n        labels_cases.append(df.iloc[i:i+forecast_window_size, :]['ConfirmedCases'])\n        labels_fatalities.append(df.iloc[i:i+forecast_window_size, :]['Fatalities'])\n        \n# test_features_set = []\n# test_labels_cases = []\n# test_labels_fatalities = []\n \n# for i in tqdm(range(66, 67)):\n#     for location in lockdown_geo.Location.unique().tolist():#encoders['Location'].transform(['New York_US']).tolist():#l\n# #         print(location)\n#         df = lockdown_geo[lockdown_geo.Location == location].reset_index()\n#         test_features_set.append(df.iloc[i-7:i, 3:].values)\n#         test_labels_cases.append(df.iloc[i:i+7, :]['ConfirmedCases'])\n#         test_labels_fatalities(df.iloc[i:i+7, :]['Fatalities'])\n        \n# future_features_set = []\n# i=73\n# for location in lockdown_geo.Location.unique().tolist():#encoders['Location'].transform(['New York_US']).tolist():#l\n#     df = lockdown_geo[lockdown_geo.Location == location].reset_index()\n#     future_features_set.append(df.iloc[i-7:i, 3:].values)\n\n# future_features_set = pd.np.array(future_features_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future_features_set_1 = []\ni = train_window_size\nfor location in lockdown_geo.Location.unique().tolist():\n    df = lockdown_geo[lockdown_geo.Location == location].reset_index()\n    future_features_set_1.append(df.iloc[i-lookback_window_size:i, 3:].values)\n#         labels_cases.append(df.iloc[i:i+forecast_window_size, :]['ConfirmedCases'])\n#         labels_fatalities.append(df.iloc[i:i+forecast_window_size, :]['Fatalities'])\n\nfuture_features_set_1 = pd.np.array(future_features_set_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"future_features_set_2 = []\ni = lbl.transform([test_df.Date.min()])[0]\nfor location in lockdown_geo.Location.unique().tolist():\n    df = lockdown_geo[lockdown_geo.Location == location].reset_index()\n    future_features_set_2.append(df.iloc[i-lookback_window_size:i, 3:].values)\n#         labels_cases.append(df.iloc[i:i+forecast_window_size, :]['ConfirmedCases'])\n#         labels_fatalities.append(df.iloc[i:i+forecast_window_size, :]['Fatalities'])\n\nfuture_features_set_2 = pd.np.array(future_features_set_2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"test_df.fillna(0.0, inplace=True)\ntest_df['Location'] = test_df['Province_State'].astype(str) + '_' + test_df['Country_Region'].astype(str)\ntest_df['Location'] = encoders['Location'].transform(test_df['Location'])\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"features_set, labels_cases, labels_fatalities = pd.np.array(features_set), pd.np.array(labels_cases), pd.np.array(labels_fatalities)\n# test_features_set, test_labels = pd.np.array(test_features_set), pd.np.array(test_labels)\nsize = features_set.shape[0]\ngc.collect()\n\nsplit = int(size*(9/10))\nvalues = pd.np.nan_to_num(features_set)\nn_train_time = 365*24\n\ntrain = values[:split, :, :]\ntest = values[split:, :, :]\ntrain_y_cases = labels_cases[:split]\ntest_y_cases = labels_cases[split:]\n\ntrain_y_fatalities = labels_fatalities[:split]\ntest_y_fatalities = labels_fatalities[split:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\n\nmodel_cases = Sequential()\nmodel_cases.add(LSTM(units=100,input_shape=(features_set.shape[1], features_set.shape[2])))\nmodel_cases.add(Dropout(0.2))\nmodel_cases.add(Dense(units = 64, activation='relu'))\nmodel_cases.add(Dropout(0.2))\nmodel_cases.add(Dense(units = 32, activation='relu'))\nmodel_cases.add(Dropout(0.2))\nmodel_cases.add(Dense(units = forecast_window_size))\nmodel_cases.compile(optimizer = 'adam', loss = 'mean_squared_error')\nhistory_cases = model_cases.fit(train, train_y_cases, epochs = 10, batch_size = 32, validation_data=(test, test_y_cases))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"model_fatalities = Sequential()\nmodel_fatalities.add(LSTM(units=100,input_shape=(features_set.shape[1], features_set.shape[2])))\nmodel_fatalities.add(Dropout(0.2))\nmodel_fatalities.add(Dense(units = 64, activation='relu'))\nmodel_fatalities.add(Dropout(0.2))\nmodel_fatalities.add(Dense(units = 32, activation='relu'))\nmodel_fatalities.add(Dropout(0.2))\nmodel_fatalities.add(Dense(units = forecast_window_size))\nmodel_fatalities.compile(optimizer = 'adam', loss = 'mean_squared_error')\nhistory_fatalities = model_fatalities.fit(train, train_y_fatalities, epochs = 10, batch_size = 32, validation_data=(test, test_y_fatalities))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"forecast_cases_future_1 = model_cases.predict(future_features_set_1)\nforecast_fatalities_future_1 = model_fatalities.predict(future_features_set_1)\n\nforecast_cases_future_2 = model_cases.predict(future_features_set_2)\nforecast_fatalities_future_2 = model_fatalities.predict(future_features_set_2)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"date_1 = future_features_set_1[:,13,1]\ndate_2 = future_features_set_2[:,13,1]\nlocations_1 =  future_features_set_1[:,13,-1]\nlocations_2 =  future_features_set_2[:,13,-1]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"location_col = []\nDate_col = []\npredictions_col = []\nfatalities_col = []\n\nfor i,pred in enumerate(forecast_cases_future_1.tolist()):\n    location_col += [locations_1[i]]*33\n    Date_col += [date_1[i]+x+1 for x in range(33)]\n    predictions_col += pred\n    \nfor i,pred in enumerate(forecast_fatalities_future_1.tolist()):\n    fatalities_col += pred\n  \n    \ndf_1 = pd.DataFrame({'Location': location_col, 'Date': Date_col, 'predictions_1': predictions_col, 'fatalities_1': fatalities_col})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"location_col = []\nDate_col = []\npredictions_col = []\nfatalities_col = []\n\nfor i,pred in enumerate(forecast_cases_future_2.tolist()):\n    location_col += [locations_2[i]]*33\n    Date_col += [date_2[i]+x+1 for x in range(33)]\n    predictions_col += pred\n    \nfor i,pred in enumerate(forecast_fatalities_future_2.tolist()):\n#     location_col += [locations_1[i]]*33\n#     Date_col += [date_1[i]]*33\n    fatalities_col += pred\n      \ndf_2 = pd.DataFrame({'Location': location_col, 'Date': Date_col, 'predictions_2': predictions_col, 'fatalities_2': fatalities_col})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_1['Date'] = df_1['Date']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"encoders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['Date'] =lbl.transform(test_df['Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2.Location = df_2.Location.astype('int')\ndf_2.Date = df_2.Date.astype('int')\n\ndf_1.Location = df_1.Location.astype('int')\ndf_1.Date = df_1.Date.astype('int')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_1.loc[df_1.predictions_1 < 0, 'predictions_1'] = 0\ndf_1.loc[df_1.fatalities_1 < 0, 'fatalities_1'] = 0\ndf_2.loc[df_2.predictions_2 < 0, 'predictions_2'] = 0\ndf_2.loc[df_2.fatalities_2 < 0, 'fatalities_2'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_2","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"t = test_df.merge(\n    df_2, on=['Location', 'Date'], how='left'\n    ).merge(df_1, on=['Location', 'Date'], how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t['ConfirmedCases'] = t.predictions_1\nt['Fatalities'] = t.fatalities_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t.loc[t.ConfirmedCases.isnull(), 'ConfirmedCases'] = t[t.ConfirmedCases.isnull()].predictions_2\nt.loc[t.Fatalities.isnull(), 'Fatalities'] = t[t.Fatalities.isnull()].fatalities_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"4038 - 3126","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t.fillna(0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t['Date'] = lbl.inverse_transform(t['Date'])\nt.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"t['ConfirmedCases'] = t.ConfirmedCases.astype(int)\nt['Fatalities'] = t.Fatalities.astype(int)\nt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"t[['ForecastId', 'ConfirmedCases', 'Fatalities']].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"# dates1 = [i+1+date_1 for i in range(33)]\n# dates2 = [i+1+date_2 for i in range(33)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# dates = future_features_set_2[:,13,1]\n# locations =  future_features_set_1[:,13,-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# forecast_cases_future_1.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"forecast_cases_future\nforecast_cases_future[forecast_cases_future < 0] = 0\nforecast_fatalities_future[forecast_fatalities_future < 0] = 0","execution_count":null,"outputs":[]},{"metadata":{"collapsed":true,"trusted":false},"cell_type":"code","source":"# df.iloc[:,3:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# test_dates = []\n# for item in (test_features_set[:,:,1] + 7 ).tolist():\n#     test_dates+=item\n    \n# test_locations = []\n# for item in (test_features_set[:,:,-1]).tolist():\n#     test_locations+=item\n\n# len(test_locations)\n\n# test_forecast = []\n# for item in out.tolist():\n#     test_forecast+=item\n# len(test_forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# future_out = model.predict(future_features_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# for item in (future_features_set[:,:,1] + 7 ).tolist():\n#     test_dates+=item\n    \n# for item in (future_features_set[:,:,-1]).tolist():\n#     test_locations+=item\n\n# for item in future_out.tolist():\n#     test_forecast+=item\n# len(test_forecast)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# test_labels_list = []\n# for item in test_labels.tolist():\n#     test_labels_list+=item\n# len(test_labels_list)\n\n# test_labels_list += [pd.np.nan]*2142\n# len(test_labels_list)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# # test_locations = test_features_set[:,6,-1].tolist()\n# # test_dates = test_features_set[:,6,1].tolist()\n# locs = encoders['Location'].inverse_transform([int(i) for i in test_locations]).tolist()\n# # [loc for loc in locs if '_US' in loc]\n\n# dates = test_dates#encoders['Date'].inverse_transform([int(i) for i in test_dates]).tolist()\n# # [loc for loc in locs if '_US' in loc]\n\n# Forecast = pd.DataFrame({'Forecasted_cases': test_forecast, 'location': locs, 'Date': dates, 'True_cases': test_labels_list})\n\n# US_Forecast = Forecast[Forecast.location.astype(str).str.contains('_US')]\n\n\n\n# fig = go.Figure()\n# for location in ['0.0_Spain', 'Washington_US', 'Michigan_US', 'New York_US']:#US_Forecast.location.unique().tolist():\n#     location_df = Forecast[Forecast.location == location]\n# #     country_df = lockdown_geo[lockdown_geo.Country_Region == country].groupby(['Date']).agg({'Fatalities': 'sum'}).reset_index()\n#     fig.add_trace(go.Scatter(x=location_df.Date, y=location_df.True_cases,\n#                         mode='lines+markers',\n#                         name=location+' - True Cases'))\n\n#     fig.add_trace(go.Scatter(x=location_df.Date, y=location_df.Forecasted_cases,\n#                         mode='lines+markers',\n#                         name=location+' - Forecasted Cases'))\n\n\n#     # for business_id in ['e0CTLPxTnFEQSqQ1FJUqog', 'dWFUKB_HPBIE87AFBHEb_w', 'CMN3KmB5SEfONN00s2nEeQ', '7MNBIoGznDHhC1AfxGWOFw']:\n#     #     plot_df = bad_business_df[bad_business_df.business_id == business_id]\n#     #     plot_df = plot_df[['stars']].resample(\"M\").mean().reset_index()\n#     #     plot_df = plot_df[plot_df.date_time > \"2014-01-01\"]\n#     #     fig.add_trace(go.Scatter(x=plot_df.date_time, y=plot_df.stars,\n#     #                         mode='lines+markers',\n#     #                         name=bad_names_dict[business_id]))\n\n#     fig.update_layout(\n#         title={\n#             'text': \"Confirmed cases over time\"})\n\n# fig.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.5"}},"nbformat":4,"nbformat_minor":4}