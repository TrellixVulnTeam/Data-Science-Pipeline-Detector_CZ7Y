{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import math\nimport seaborn as sns\nfrom pmdarima.arima import auto_arima\nfrom datetime import datetime,date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/test.csv\")\nsubmission_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(train_data.shape)\nprint(test_data.shape)\nprint(train_data.info())\nprint(test_data.info())\nprint(train_data.isna().sum())\nprint(test_data.isna().sum())\ndisplay(train_data.head(5))\ndisplay(train_data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"display(train_data.head(5))\ndisplay(train_data.describe())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"### Gives count of each columns for Not Null values\ntrain_data.count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_data.Date = pd.to_datetime(train_data.Date)\ntest_data.Date = pd.to_datetime(test_data.Date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(\"train data range from \", min(train_data.Date) ,\"to\", max(train_data.Date))\nprint(\"test data range from \", min(test_data.Date) ,\"to\", max(test_data.Date))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"## train and test data manipulation\ntrain_data.Date = pd.to_datetime(train_data.Date)\ntrain_data['Province_State'] = train_data['Province_State'].astype(str)\ntrain_data['Province_State'] = train_data['Province_State'].str.replace(',','_').str.replace('nan','').str.lower()\ntrain_data['Country_Region'] = train_data['Country_Region'].astype(str).str.lower().str.replace(' ','_')\ntrain_data['province_state_country'] = train_data['Country_Region'].astype(str).str.lower().str.replace(' ','_') + ('_') + train_data['Province_State']\ntrain_data['province_state_country'] = train_data['province_state_country'].str.replace('_$','')\ntrain_data['DayWiseConfirmedCases'] = train_data['ConfirmedCases'] - train_data['ConfirmedCases'].shift(1)\ntrain_data['DayWiseConfirmedCases'] = train_data['DayWiseConfirmedCases'].fillna(0)\ntrain_data['DayWiseFatalities'] = train_data['Fatalities'] - train_data['Fatalities'].shift(1)\ntrain_data['DayWiseFatalities'] = train_data['DayWiseFatalities'].fillna(0)\n\n\n##3 test data manipulation\ntest_data.Date = pd.to_datetime(test_data.Date)\ntest_data['Province_State'] = test_data['Province_State'].astype(str)\ntest_data['Province_State'] = test_data['Province_State'].str.replace(',','_').str.replace('nan','').str.lower()\ntest_data['Country_Region'] = test_data['Country_Region'].astype(str).str.lower().str.replace(' ','_')\ntest_data['province_state_country'] = test_data['Country_Region'].astype(str).str.lower().str.replace(' ','_') + ('_') + test_data['Province_State']\ntest_data['province_state_country'] = test_data['province_state_country'].str.replace('_$','')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"### sort the data\ntrain_data = train_data.sort_values(['province_state_country','Date'])\ntest_data = test_data.sort_values(['province_state_country','Date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"### Dates\ntrain_data_start_date = pd.to_datetime(min(train_data.Date))\ntrain_data_end_date = max(train_data.Date)\ntest_data_start_date = min(test_data.Date)\ntest_data_end_date = max(test_data.Date)\npublic_test_data_start_date = test_data_start_date\npublic_test_data_end_date = datetime(2020,4,8)\nprivate_test_data_start_date = datetime(2020,4,9)\nprivate_test_data_end_date = test_data_end_date\nprint(type(train_data_start_date))\n# print(train_data_end_date)\n# print(test_data_start_date)\n# print(test_data_end_date)\n# print(public_test_data_start_date)\n# print(public_test_data_end_date)\n# print(private_test_data_start_date)\n# print(private_test_data_end_date)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# province_state_country_list = pd.concat([train_data['province_state_country'], test_data['province_state_country']]).unique()\n\n# # province_state_country_list = np.asarray(['china_xinjiang', 'china_yun'])\n\n# submission_df = pd.DataFrame(columns = ['ForecastId', 'Province_State', 'Country_Region', 'Date',\n#        'province_state_country','days','Confirmed_pred','Fatalities_Pred'])\n\n# validation_df = pd.DataFrame(columns = ['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n#        'Fatalities', 'province_state_country','days','Confirmed_pred','Fatalities_Pred'])\n# for s in province_state_country_list:\n#     print(s)\n    \n#     ### train data for public data\n# #     print(train_data.head(2))\n#     train_data_1 = train_data.loc[(train_data['province_state_country'] == s ) & (train_data['Date'] <test_data_start_date)]\n# #     print(train_data_1)\n# #     print(train_data_start_date)\n#     train_data_1['days'] =  (train_data.Date - train_data_start_date).dt.days\n#     train_data_1.index = pd.to_datetime(train_data_1.Date)\n#     train_data_exog_1 = np.array(train_data_1[['days']])\n    \n# #     print(train_data_1.head(1))\n# #     print(train_data_1.tail(1))\n    \n#     ### Validation data\n#     print(train_data)\n#     train_data_validation_1 = train_data.loc[(train_data['province_state_country'] == s ) & (train_data['Date'] >= test_data_start_date)]\n#     train_data_validation_1['days'] =  (train_data.Date - train_data_start_date).dt.days\n#     train_data_validation_exog_1 = np.array(train_data_validation_1[['days']])\n    \n# #     print(train_data_validation_1.head(1))\n# #     print(train_data_validation_1.tail(1))\n    \n#     ### test data for public board\n#     test_data_1 = test_data.loc[(test_data['province_state_country'] == s ) & (test_data['Date'] <= public_test_data_end_date)]\n#     test_data_1['days'] =  (test_data.Date - train_data_start_date).dt.days\n#     test_data_exog_1 = np.array(test_data_1[['days']])\n    \n# #     print(test_data_1.head(1))\n# #     print(test_data_1.tail(1))\n    \n#     ## train data for private board\n#     train_data_2 = train_data.loc[(train_data['province_state_country'] == s ) & (train_data['Date'] <=train_data_end_date)]\n#     train_data_2['days'] =  (train_data.Date - train_data_start_date).dt.days\n#     train_data_2.index = pd.to_datetime(train_data_2.Date)\n#     train_data_exog_2 = np.array(train_data_2[['days']])\n    \n# #     print(train_data_2.head(1))\n# #     print(train_data_2.tail(1))\n    \n#     ### test data for private board\n#     test_data_2 = test_data.loc[(test_data['province_state_country'] == s ) & (test_data['Date'] >= private_test_data_start_date)]\n#     test_data_2['days'] =  (test_data.Date - train_data_start_date).dt.days\n#     test_data_exog_2 = np.array(test_data_2[['days']])\n# #     print(test_data_2.head(1))\n# #     print(test_data_2.tail(1))\n    \n#     ### Set date as time index for train data before applying model\n    \n#     ##### For Public board\n#     ### Model Building for confirmed cases\n#     print(train_data_exog_1)\n#     trained_Model_Confirmed_1 = auto_arima(train_data_1['ConfirmedCases'],exogenous = train_data_exog_1 ,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n#     print((trained_Model_Confirmed_1))\n    \n#     prediction_confirmed_1 = trained_Model_Confirmed_1.predict(exogenous = train_data_validation_exog_1 ,n_periods = train_data_validation_1['days'].shape[0])\n    \n#     print(prediction_confirmed_1)\n#     prediction_confirmed_public_1 = trained_Model_Confirmed_1.predict(exogenous = test_data_exog_1 , n_periods = test_data_1['days'].shape[0])\n#     print(prediction_confirmed_public_1)\n    \n#     ### Model Building for Fatalities cases\n#     trained_Model_Fatalities_1 = auto_arima(train_data_1['Fatalities'],exogenous = train_data_exog_1,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n#     print((trained_Model_Fatalities_1))\n    \n#     prediction_Fatalities_1 = trained_Model_Fatalities_1.predict(exogenous = train_data_validation_exog_1,n_periods = train_data_validation_1['days'].shape[0])\n    \n#     print(prediction_Fatalities_1)\n#     prediction_Fatalities_public_1 = trained_Model_Fatalities_1.predict(exogenous = test_data_exog_1,n_periods = test_data_1['days'].shape[0])\n#     print(prediction_Fatalities_public_1)\n    \n#     ##### Model Building for Private board\n#     ### Model Building for confirmed cases\n    \n#     trained_Model_Confirmed_2 = auto_arima(train_data_2['ConfirmedCases'],exogenous = train_data_exog_2,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n#     print((trained_Model_Confirmed_2))\n    \n#     print(test_data_exog_2)\n#     prediction_confirmed_private_2 = trained_Model_Confirmed_2.predict(exogenous = test_data_exog_2 ,n_periods = test_data_2['days'].shape[0])\n#     print(prediction_confirmed_private_2)\n    \n#     ### Model Building for Fatalities cases\n#     trained_Model_Fatalities_2 = auto_arima(train_data_2['Fatalities'],exogenous = train_data_exog_2,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n#     print((trained_Model_Fatalities_2))\n    \n#     prediction_Fatalities_private_2 = trained_Model_Fatalities_2.predict(exogenous = test_data_exog_2,n_periods = test_data_2['days'].shape[0])\n#     print(prediction_Fatalities_private_2)\n    \n#     ### Public data prediction dataframe\n#     public_data_pred = test_data_1\n#     public_data_pred['Confirmed_pred'] =  prediction_confirmed_public_1\n#     public_data_pred['Fatalities_Pred'] =  prediction_Fatalities_public_1\n    \n#     ### Validation data\n#     validation_data = train_data_validation_1\n#     validation_data['Confirmed_pred'] =  prediction_confirmed_1\n#     validation_data['Fatalities_Pred'] =  prediction_Fatalities_1\n    \n#     ### Private data prediction dataframe\n#     private_data_pred = test_data_2\n#     private_data_pred['Confirmed_pred'] =  prediction_confirmed_private_2\n#     private_data_pred['Fatalities_Pred'] =  prediction_Fatalities_private_2\n    \n#     ##### Private data prediction filter(2020-04-09 to 2020-05-07)\n#     private_data_pred_till_date = private_data_pred.loc[private_data_pred.Date>= private_test_data_start_date]\n    \n#     Evaluation_df = public_data_pred\n    \n#     Evaluation_df= Evaluation_df.append(private_data_pred_till_date, ignore_index = True)\n    \n#     submission_df= submission_df.append(Evaluation_df, ignore_index = True)\n    \n#     validation_df= validation_df.append(validation_data, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.columns\n# train_data.iloc[-1][\"ConfirmedCases\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province_state_country_list = pd.concat([train_data['province_state_country'], test_data['province_state_country']]).unique()\nprovince_state_country_list[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"province_state_country_list = pd.concat([train_data['province_state_country'], test_data['province_state_country']]).unique()\n\n# province_state_country_list = np.asarray(['afghanistan', 'china_yun'])\n\nsubmission_df = pd.DataFrame(columns = ['ForecastId', 'Province_State', 'Country_Region', 'Date',\n       'province_state_country','days','Confirmed_pred','Fatalities_Pred','DayConfirmed_pred','DayFatalities_Pred'])\n\nvalidation_df = pd.DataFrame(columns = ['Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n       'Fatalities', 'province_state_country','days','Confirmed_pred','Fatalities_Pred','DayConfirmed_pred','DayFatalities_Pred'])\nfor s in province_state_country_list:\n    print(s)\n    \n    ### train data for public data\n#     print(train_data.head(2))\n    train_data_1 = train_data.loc[(train_data['province_state_country'] == s ) & (train_data['Date'] <test_data_start_date)]\n#     print(train_data_1)\n#     print(train_data_start_date)\n    train_data_1['days'] =  (train_data.Date - train_data_start_date).dt.days\n    train_data_1.index = pd.to_datetime(train_data_1.Date)\n    train_data_exog_1 = np.array(train_data_1[['days']])\n    train_data_1_ConfirmedCases = train_data_1.iloc[-1][\"ConfirmedCases\"]\n    train_data_1_Fatalities = train_data_1.iloc[-1][\"Fatalities\"]\n    \n#     print(train_data_1.head(1))\n#     print(train_data_1.tail(1))\n    \n    ### Validation data\n    print(train_data)\n    train_data_validation_1 = train_data.loc[(train_data['province_state_country'] == s ) & (train_data['Date'] >= test_data_start_date)]\n    train_data_validation_1['days'] =  (train_data.Date - train_data_start_date).dt.days\n    train_data_validation_exog_1 = np.array(train_data_validation_1[['days']])\n    \n#     print(train_data_validation_1.head(1))\n#     print(train_data_validation_1.tail(1))\n    \n    ### test data for public board\n    test_data_1 = test_data.loc[(test_data['province_state_country'] == s ) & (test_data['Date'] <= public_test_data_end_date)]\n    test_data_1['days'] =  (test_data.Date - train_data_start_date).dt.days\n    test_data_exog_1 = np.array(test_data_1[['days']])\n    \n#     print(test_data_1.head(1))\n#     print(test_data_1.tail(1))\n    \n    ## train data for private board\n    train_data_2 = train_data.loc[(train_data['province_state_country'] == s ) & (train_data['Date'] <=train_data_end_date)]\n    train_data_2['days'] =  (train_data.Date - train_data_start_date).dt.days\n    train_data_2.index = pd.to_datetime(train_data_2.Date)\n    train_data_exog_2 = np.array(train_data_2[['days']])\n    train_data_2_ConfirmedCases = train_data_2.iloc[-1][\"ConfirmedCases\"]\n    train_data_2_Fatalities = train_data_2.iloc[-1][\"Fatalities\"]\n    \n#     print(train_data_2.head(1))\n#     print(train_data_2.tail(1))\n    \n    ### test data for private board\n    test_data_2 = test_data.loc[(test_data['province_state_country'] == s ) & (test_data['Date'] >= private_test_data_start_date)]\n    test_data_2['days'] =  (test_data.Date - train_data_start_date).dt.days\n    test_data_exog_2 = np.array(test_data_2[['days']])\n#     print(test_data_2.head(1))\n#     print(test_data_2.tail(1))\n    \n    ### Set date as time index for train data before applying model\n    \n    ##### For Public board\n    \n#     'Id', 'Province_State', 'Country_Region', 'Date', 'ConfirmedCases',\n#        'Fatalities', 'province_state_country', 'DayWiseConfirmedCases',\n#        'DayWiseFatalities'],\n#       dtype='object')\n    ### Model Building for confirmed cases\n    \n    print(train_data_exog_1)\n    trained_Model_Confirmed_1 = auto_arima(train_data_1['DayWiseConfirmedCases'],exogenous = train_data_exog_1 ,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n    print((trained_Model_Confirmed_1))\n    \n    prediction_confirmed_1 = trained_Model_Confirmed_1.predict(exogenous = train_data_validation_exog_1 ,n_periods = train_data_validation_1['days'].shape[0])\n    \n    print(prediction_confirmed_1)\n    prediction_confirmed_public_1 = trained_Model_Confirmed_1.predict(exogenous = test_data_exog_1 , n_periods = test_data_1['days'].shape[0])\n    print(prediction_confirmed_public_1)\n    \n    ### Model Building for Fatalities cases\n    trained_Model_Fatalities_1 = auto_arima(train_data_1['DayWiseFatalities'],exogenous = train_data_exog_1,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n    print((trained_Model_Fatalities_1))\n    \n    prediction_Fatalities_1 = trained_Model_Fatalities_1.predict(exogenous = train_data_validation_exog_1,n_periods = train_data_validation_1['days'].shape[0])\n    \n    print(prediction_Fatalities_1)\n    prediction_Fatalities_public_1 = trained_Model_Fatalities_1.predict(exogenous = test_data_exog_1,n_periods = test_data_1['days'].shape[0])\n    print(prediction_Fatalities_public_1)\n    \n    ##### Model Building for Private board\n    ### Model Building for confirmed cases\n    \n    trained_Model_Confirmed_2 = auto_arima(train_data_2['DayWiseConfirmedCases'],exogenous = train_data_exog_2,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n    print((trained_Model_Confirmed_2))\n    \n    print(test_data_exog_2)\n    prediction_confirmed_private_2 = trained_Model_Confirmed_2.predict(exogenous = test_data_exog_2 ,n_periods = test_data_2['days'].shape[0])\n    print(prediction_confirmed_private_2)\n    \n    ### Model Building for Fatalities cases\n    trained_Model_Fatalities_2 = auto_arima(train_data_2['DayWiseFatalities'],exogenous = train_data_exog_2,supress_warnings = True,m= 1, stepwise = True,error_action = 'ignore',stationary = False)\n    print((trained_Model_Fatalities_2))\n    \n    prediction_Fatalities_private_2 = trained_Model_Fatalities_2.predict(exogenous = test_data_exog_2,n_periods = test_data_2['days'].shape[0])\n    print(prediction_Fatalities_private_2)\n    \n    ### Public data prediction dataframe\n    \n    public_data_pred = test_data_1\n    public_data_pred['Confirmed_pred'] =  prediction_confirmed_public_1\n    public_data_pred['Fatalities_Pred'] =  prediction_Fatalities_public_1\n    public_data_pred.loc[public_data_pred['Confirmed_pred'] <0,'Confirmed_pred'] =0\n    public_data_pred.loc[public_data_pred['Fatalities_Pred'] <0,'Fatalities_Pred'] =0\n    \n    public_data_pred['Confirmed_pred'].iloc[0]  = public_data_pred['Confirmed_pred'].iloc[0] + train_data_1_ConfirmedCases\n    \n    public_data_pred['Fatalities_Pred'].iloc[0]  = public_data_pred['Fatalities_Pred'].iloc[0] + train_data_1_Fatalities \n    \n    print(public_data_pred.head(5))\n    \n#     DayConfirmed_pred','DayFatalities_Pred\n#     public_data_pred['DayConfirmed_pred'].iloc[0]  = public_data_pred['Confirmed_pred'].iloc[0]\n#     public_data_pred['DayConfirmed_pred'] =  public_data_pred['Confirmed_pred'] + public_data_pred['DayConfirmed_pred'].shift(1) \n#     public_data_pred['DayFatalities_Pred'] =  public_data_pred['Fatalities_Pred'] + public_data_pred['DayFatalities_Pred'].shift(1) \n    public_data_pred['DayConfirmed_pred'] =  public_data_pred['Confirmed_pred'].cumsum()\n    public_data_pred['DayFatalities_Pred'] =  public_data_pred['Fatalities_Pred'].cumsum()\n#     public_data_pred['DayConfirmed_pred'].iloc[0]  = public_data_pred['Confirmed_pred'].iloc[0]\n    \n    ### Validation data\n    validation_data = train_data_validation_1\n    validation_data['Confirmed_pred'] =  prediction_confirmed_1\n    validation_data['Fatalities_Pred'] =  prediction_Fatalities_1\n    validation_data.loc[validation_data['Confirmed_pred'] <0,'Confirmed_pred'] =0\n    validation_data.loc[validation_data['Fatalities_Pred'] <0,'Fatalities_Pred'] =0\n    \n    validation_data['Confirmed_pred'].iloc[0]  = validation_data['Confirmed_pred'].iloc[0] + train_data_1_ConfirmedCases\n    \n    validation_data['Fatalities_Pred'].iloc[0]  = validation_data['Fatalities_Pred'].iloc[0] + train_data_1_Fatalities \n    \n    \n    print(validation_data.head(5))\n#     DayConfirmed_pred','DayFatalities_Pred\n#     validation_data['DayConfirmed_pred'].iloc[0]  = validation_data['Confirmed_pred'].iloc[0]\n#     validation_data['DayConfirmed_pred'] =  validation_data['Confirmed_pred'] + validation_data['DayConfirmed_pred'].shift(1) \n#     validation_data['DayFatalities_Pred'] =  validation_data['Fatalities_Pred'] + validation_data['DayFatalities_Pred'].shift(1)  \n    \n    \n    validation_data['DayConfirmed_pred'] =  validation_data['Confirmed_pred'].cumsum() \n    validation_data['DayFatalities_Pred'] =  validation_data['Fatalities_Pred'].cumsum()  \n    \n#     validation_data['DayConfirmed_pred'].iloc[0]  = validation_data['Confirmed_pred'].iloc[0]\n    \n    ### Private data prediction dataframe\n#     train_data_2_ConfirmedCases = train_data_2.iloc[-1][\"ConfirmedCases\"]\n#     train_data_2_Fatalities = train_data_2.iloc[-1][\"Fatalities\"]\n    private_data_pred = test_data_2\n    private_data_pred['Confirmed_pred'] =  prediction_confirmed_private_2\n    private_data_pred['Fatalities_Pred'] =  prediction_Fatalities_private_2\n    private_data_pred.loc[private_data_pred['Confirmed_pred'] <0,'Confirmed_pred'] =0\n    private_data_pred.loc[private_data_pred['Fatalities_Pred'] <0,'Fatalities_Pred'] =0\n    \n    private_data_pred['Confirmed_pred'].iloc[0]  = private_data_pred['Confirmed_pred'].iloc[0] + train_data_2_ConfirmedCases\n    \n    private_data_pred['Fatalities_Pred'].iloc[0]  = private_data_pred['Fatalities_Pred'].iloc[0] + train_data_2_Fatalities \n\n    print(private_data_pred.head(6))\n#     DayConfirmed_pred','DayFatalities_Pred\n    \n#     private_data_pred['DayConfirmed_pred'].iloc[0]  = private_data_pred['Confirmed_pred'].iloc[0]\n#     private_data_pred['DayConfirmed_pred'] =  private_data_pred['Confirmed_pred'] + private_data_pred['DayConfirmed_pred'].shift(1) \n#     private_data_pred['DayFatalities_Pred'] =  private_data_pred['Fatalities_Pred'] + private_data_pred['DayFatalities_Pred'].shift(1)   \n    \n    private_data_pred['DayConfirmed_pred'] =  private_data_pred['Confirmed_pred'].cumsum()\n    private_data_pred['DayFatalities_Pred'] =  private_data_pred['Fatalities_Pred'] .cumsum()   \n    \n    \n#     private_data_pred['DayConfirmed_pred'].iloc[0]  = private_data_pred['Confirmed_pred'].iloc[0]\n    ##### Private data prediction filter(2020-04-09 to 2020-05-07)\n    private_data_pred_till_date = private_data_pred.loc[private_data_pred.Date>= private_test_data_start_date]\n    \n    Evaluation_df = public_data_pred\n    \n    Evaluation_df= Evaluation_df.append(private_data_pred_till_date, ignore_index = True)\n    \n    submission_df= submission_df.append(Evaluation_df, ignore_index = True)\n    \n    validation_df= validation_df.append(validation_data, ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"###Make -ve prediction as 0\nsubmission_df.loc[submission_df['Confirmed_pred'] <0,'Confirmed_pred'] =0\nsubmission_df.loc[submission_df['Fatalities_Pred'] <0,'Fatalities_Pred'] =0\nvalidation_df.loc[validation_df['Confirmed_pred'] <0,'Confirmed_pred'] =0\nvalidation_df.loc[validation_df['Fatalities_Pred'] <0,'Fatalities_Pred'] =0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_df[:43]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = submission_df[['ForecastId','DayConfirmed_pred','DayFatalities_Pred']]\nprint(submission_data.columns)\n\n### renaming the columns\nsubmission_data.rename(columns = {\"DayConfirmed_pred\" :\"ConfirmedCases\",\"DayFatalities_Pred\": \"Fatalities\"},inplace = True)\nprint(submission_data.columns)\nsubmission_data['ConfirmedCases'] = submission_data['ConfirmedCases'].astype(int)\nsubmission_data['Fatalities'] = submission_data['Fatalities'].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data.to_csv('submission.csv', index = None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}