{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Reference: OsciiArt's notebook on this competition, the notebook is not accessible any more"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"scrolled":true},"cell_type":"code","source":"import os, gc, pickle, copy, datetime, warnings\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nimport pandas_profiling\npd.set_option('display.max_columns', 100)\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Loading"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")\nprint(df_train.shape)\nprint(df_train.Date.min(), df_train.Date.max())\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_min_date, train_max_date = df_train.Date.min(), df_train.Date.max()\ntrain_min_dayofyear, train_max_dayofyear = (pd.to_datetime(train_min_date)).dayofyear, (pd.to_datetime(train_max_date)).dayofyear\nprint(train_min_dayofyear, train_max_dayofyear)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train_valid_cutoff_dayofyear = train_min_dayofyear + ( train_max_dayofyear - train_min_dayofyear ) // 3 * 2\ntrain_valid_cutoff_dayofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\")\nprint(df_test.shape)\ntest_min_date, test_max_date = df_test.Date.min(), df_test.Date.max()\nprint(test_min_date, test_max_date)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# concat train and test\ndf_traintest = pd.concat([df_train, df_test])\nprint(df_train.shape, df_test.shape, df_traintest.shape)\ndf_traintest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# concat Country/Region and Province/State\ndef func(x):\n    try:\n        x_new = x['Country_Region'] + \"/\" + x['Province_State']\n    except:\n        x_new = x['Country_Region']\n    return x_new\n        \ndf_traintest['place_id'] = df_traintest.apply(lambda x: func(x), axis=1)\ntmp = np.sort(df_traintest['place_id'].unique())\nprint(\"num unique places: {}\".format(len(tmp)))\nprint(tmp[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# process date\n# df_traintest['Date'] = pd.to_datetime(df_traintest['Date'])\n# df_traintest['day'] = df_traintest['Date'].apply(lambda x: x.dayofyear).astype(np.int16)\n# df_traintest['dayofmonth'] = df_traintest['Date'].apply(lambda x: x.day).astype(np.int16)\n# df_traintest['dayofweek'] = df_traintest['Date'].apply(lambda x: x.dayofweek).astype(np.int16)\n# df_traintest.head()\n\n#     # time features\ndf_traintest['Date'] = pd.to_datetime(df_traintest['Date'])\ntime_cols = [\n#     \"year\", \"quarter\", \n    \"month\", \n    \"week\", \n    \"day\", \n    \"dayofyear\", \n    \"dayofweek\", \n#     \"is_year_end\", \"is_year_start\", \"is_quarter_end\", \"is_quarter_start\", \n#     \"is_month_end\",\"is_month_start\",\n]\n\nfor attr in time_cols:\n    dtype = np.int if attr == \"year\" else np.int8\n#     df_traintest[attr] = getattr(df_traintest['Date'].dt, attr).astype(dtype)\n    df_traintest[attr] = getattr(df_traintest['Date'].dt, attr)\n# df_traintest[\"is_weekend\"] = df_traintest[\"dayofweek\"].isin([5, 6]).astype(np.int8)\n# time_cols += [\"is_weekend\"]\nprint(time_cols)\ndf_traintest.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# calc cases and fatalities per day\ndf_traintest['cases/day'] = 0\ndf_traintest['fatal/day'] = 0\nplaces = np.sort(df_traintest['place_id'].unique())\nfor place in places:\n    tmp = df_traintest['ConfirmedCases'][df_traintest['place_id']==place].values\n    tmp[1:] -= tmp[:-1]\n    df_traintest['cases/day'][df_traintest['place_id']==place] = tmp\n    tmp = df_traintest['Fatalities'][df_traintest['place_id']==place].values\n    tmp[1:] -= tmp[:-1]\n    df_traintest['fatal/day'][df_traintest['place_id']==place] = tmp\n    \ndf_traintest[df_traintest['place_id']=='China/Hubei']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# aggregate cases and fatalities\ndef do_aggregation(df, col, mean_range, method='mean', val_cols=[]):\n    df_new = copy.deepcopy(df)\n    col_new = '{}_{}_({}-{})'.format(col, method, mean_range[0], mean_range[1])\n    val_cols.append(col_new)\n    df_new[col_new] = 0\n    if method=='mean':\n        tmp = df_new[col].rolling(mean_range[1]-mean_range[0]+1).mean()\n    elif method=='std':\n        tmp = df_new[col].rolling(mean_range[1]-mean_range[0]+1).std()\n    df_new[col_new][mean_range[0]:] = tmp[:-(mean_range[0])]\n    df_new[col_new][pd.isna(df_new[col_new])] = 0\n    return df_new[[col_new]].reset_index(drop=True)\n\n# def do_aggregations(df):\n#     for method in ['mean']:\n#         df = pd.concat([df, do_aggregation(df, 'cases/day', [1,1], method).reset_index(drop=True)], axis=1)\n#         df = pd.concat([df, do_aggregation(df, 'cases/day', [1,7], method).reset_index(drop=True)], axis=1)\n#         df = pd.concat([df, do_aggregation(df, 'cases/day', [8,14], method).reset_index(drop=True)], axis=1)\n#         df = pd.concat([df, do_aggregation(df, 'fatal/day', [1,1], method).reset_index(drop=True)], axis=1)\n#         df = pd.concat([df, do_aggregation(df, 'fatal/day', [1,7], method).reset_index(drop=True)], axis=1)\n#         df = pd.concat([df, do_aggregation(df, 'fatal/day', [8,14], method).reset_index(drop=True)], axis=1)\n#     return df\n\ndef do_aggregations(df, roll_ranges=[[1,1], [1,7], [8,14]], val_cols=[]):\n    for method in ['mean']:\n        for roll_range in roll_ranges:\n            df = pd.concat([df, do_aggregation(df, 'cases/day', roll_range, method, val_cols).reset_index(drop=True)], axis=1)\n            df = pd.concat([df, do_aggregation(df, 'fatal/day', roll_range, method, val_cols).reset_index(drop=True)], axis=1)\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest[df_traintest['dayofyear']<0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_traintest2 = []\nval_cols = []\nroll_ranges = [[i,i] for i in range(1,8)]\nroll_ranges += [[1,7], [8,14]]\n\nfor place in places[:]:\n    df_tmp = df_traintest[df_traintest['place_id']==place].reset_index(drop=True)\n    df_tmp = do_aggregations(df_tmp, roll_ranges=roll_ranges, val_cols=val_cols)\n    df_traintest2.append(df_tmp)\ndf_traintest2 = pd.concat(df_traintest2).reset_index(drop=True)\n\nval_cols = list(set(val_cols))\nprint(val_cols)\ndf_traintest2[df_traintest2['place_id']=='China/Hubei'].head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"roll_ranges","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Adding Smoking Rate Data"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# add Smoking rate per country\n# data of smoking rate is obtained from https://ourworldindata.org/smoking\ndf_smoking = pd.read_csv(\"../input/shareofadultswhosmoke/adults-smoking-2000-2016.csv\")\nprint(np.sort(df_smoking['Entity'].unique())[:10])\ndf_smoking.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# extract newest data\ndf_smoking_recent = df_smoking.sort_values('Year', ascending=False).reset_index(drop=True)\ndf_smoking_recent = df_smoking_recent[df_smoking_recent['Entity'].duplicated()==False]\ndf_smoking_recent['Country/Region'] = df_smoking_recent['Entity']\ndf_smoking_recent['SmokingRate'] = df_smoking_recent['Share of adults who smoke (%)']\ndf_smoking_recent.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# merge\ndf_traintest3 = pd.merge(df_traintest2, df_smoking_recent[['Country/Region', 'SmokingRate']], left_on='Country_Region', right_on='Country/Region', how='left')\ndf_traintest3.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"## fill na with world smoking rate\nSmokingRate = df_smoking_recent['SmokingRate'][df_smoking_recent['Entity']=='World'].values[0]\nprint(\"Smoking rate of the world: {:.6f}\".format(SmokingRate))\ndf_traintest3['SmokingRate'][pd.isna(df_traintest3['SmokingRate'])] = SmokingRate\ndf_traintest3.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add World Bank Dataset"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"world_happiness_index = pd.read_csv(\"../input/world-bank-datasets/World_Happiness_Index.csv\")\nworld_happiness_grouped = world_happiness_index.groupby('Country name').nth(-1)\nworld_happiness_grouped.head()\nworld_happiness_grouped.drop(\"Year\", axis=1, inplace=True)\n\ndf_traintest3 = pd.merge(left=df_traintest3, right=world_happiness_grouped, how='left', left_on='Country_Region', right_on='Country name')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"wh_cols = world_happiness_grouped.columns.to_list()\nprint(wh_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"malaria_world_health = pd.read_csv(\"../input/world-bank-datasets/Malaria_World_Health_Organization.csv\")\n\ndf_traintest3 = pd.merge(left=df_traintest3, right=malaria_world_health, how='left', left_on='Country_Region', right_on='Country')\ndf_traintest3.drop(\"Country\", axis=1, inplace=True)\n\nmwh_cols = [ col for col in malaria_world_health.columns.to_list() if col != \"Country\" ]\nprint(mwh_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"human_development_index = pd.read_csv(\"../input/world-bank-datasets/Human_Development_Index.csv\")\nhuman_development_index.drop([\"Gross national income (GNI) per capita 2018\"], axis=1, inplace=True)\n\ndf_traintest3 = pd.merge(left=df_traintest3, right=human_development_index, how='left', left_on='Country_Region', right_on='Country')\ndf_traintest3.drop(\"Country\", axis=1, inplace=True)\n\nhdi_cols = [ col for col in human_development_index.columns.to_list() if col != \"Country\" ]\nprint(hdi_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# df_lat_long = pd.concat( [ pd.read_csv(\"../input/covid19-global-forecasting-week-1/train.csv\"), pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\") ] )\n# df_lat_long = df_lat_long[['Country/Region', 'Province/State', 'Lat', 'Long']].drop_duplicates()\n# df_lat_long = df_lat_long.rename(columns={'Country/Region': 'Country_Region', 'Province/State': 'Province_State'})\n# df_lat_long['place_id'] = df_lat_long.apply(lambda x: func(x), axis=1)\n# df_lat_long.drop([\"Country_Region\", 'Province_State'], axis=1, inplace=True)\n\n# df_traintest3 = pd.merge(left=df_traintest3, right=df_lat_long, how='left', on='place_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# df_lat_long = pd.concat( [ pd.read_csv(\"../input/covid19-global-forecasting-week-1/train.csv\"), pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\") ] )\n# df_lat_long = df_lat_long[['Country/Region', 'Province/State', 'Lat', 'Long']].drop_duplicates()\n# df_lat_long = df_lat_long.rename(columns={'Country/Region': 'Country_Region', 'Province/State': 'Province_State'})\n# df_lat_long.to_csv(\"lat_long.csv\", index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_lat_long = pd.read_csv(\"../input/lat-long/lat_long.csv\")\ndf_lat_long['place_id'] = df_lat_long.apply(lambda x: func(x), axis=1)\ndf_lat_long.drop([\"Country_Region\", 'Province_State'], axis=1, inplace=True)\n\ndf_traintest3 = pd.merge(left=df_traintest3, right=df_lat_long, how='left', on='place_id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_lat_long.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = df_lat_long['place_id'].unique()\nprint(\"num unique places: {}\".format(len(tmp)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# df_tmp = pd.get_dummies(df_traintest3['Province_State'], prefix='ps')\n# ps_cols = df_tmp.columns.to_list()\n# print(ps_cols)\n# df_traintest3 = pd.concat([df_traintest3,df_tmp],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# df_tmp = pd.get_dummies(df_traintest3['Country_Region'], prefix='cr')\n# cr_cols = df_tmp.columns.to_list()\n# print(cr_cols)\n# df_traintest3 = pd.concat([df_traintest3,df_tmp],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_traintest3[df_traintest3['place_id']=='China/Hubei']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Model Training"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# params\nSEED = 42\nparams = {'num_leaves': 8,\n          'min_data_in_leaf': 5,  # 42,\n          'objective': 'regression',\n          'max_depth': 8,\n          'learning_rate': 0.02,\n          'boosting': 'gbdt',\n          'bagging_freq': 5,  # 5\n          'bagging_fraction': 0.8,  # 0.5,\n          'feature_fraction': 0.8201,\n          'bagging_seed': SEED,\n          'reg_alpha': 1,  # 1.728910519108444,\n          'reg_lambda': 4.9847051755586085,\n          'random_state': SEED,\n          'metric': 'mse',\n          'verbosity': 100,\n          'min_gain_to_split': 0.02,  # 0.01077313523861969,\n          'min_child_weight': 5,  # 19.428902804238373,\n          'num_threads': 6,\n          }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_traintest3[df_traintest3.dayofyear == 72]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_traintest3.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# train model to predict fatalities/day\ncol_target = 'fatal/day'\ncol_var = [\n    'Lat', 'Long',\n#    'cases/day_mean_(1-1)', 'cases/day_mean_(1-7)', 'cases/day_mean_(8-14)', \n#      'fatal/day_mean_(1-1)', 'fatal/day_mean_(1-7)', 'fatal/day_mean_(8-14)',\n#    'cases/day_std_(1-1)', 'cases/day_std_(1-7)', 'cases/day_std_(8-14)', \n#      'fatal/day_std_(1-1)', 'fatal/day_std_(1-7)', 'fatal/day_std_(8-14)',\n    'SmokingRate',\n#     'dayofyear',\n#     'day',\n#     'dayofweek',\n]\ncol_var += val_cols\ncol_var += time_cols\n# extra_cols = wh_cols + mwh_cols + hdi_cols + ps_cols + cr_cols\nextra_cols = wh_cols + mwh_cols + hdi_cols\ncol_var += extra_cols\n\ndf_train = df_traintest3[(pd.isna(df_traintest3['ForecastId'])) & (df_traintest3['dayofyear']<train_valid_cutoff_dayofyear)]\ndf_valid = df_traintest3[(pd.isna(df_traintest3['ForecastId'])) & (df_traintest3['dayofyear']>=train_valid_cutoff_dayofyear)]\ndf_test = df_traintest3[pd.isna(df_traintest3['ForecastId'])==False]\nX_train = df_train[col_var].values\nX_valid = df_valid[col_var].values\ny_train = df_train[col_target].values\ny_valid = df_valid[col_target].values\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid)\nnum_round = 15000\nmodel = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# display feature importance\ntmp = pd.DataFrame()\ntmp[\"feature\"] = col_var\ntmp[\"importance\"] = model.feature_importance()\ntmp = tmp.sort_values('importance', ascending=False)\n\nimportant_features = list(tmp[0:30]['feature'])\ncol_var = important_features\n\ntmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train_profile = df_train[col_var].profile_report(title='Pandas Profile Report:Train Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train_profile","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# rejected_var = df_train_profile.get_rejected_variables()\n# rejected_var","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"important_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X_train = df_train[col_var].values\nX_valid = df_valid[col_var].values\ny_train = df_train[col_target].values\ny_valid = df_valid[col_target].values\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid)\nnum_round = 15000\nmodel = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# model = xgb.XGBRegressor(n_estimators=1000)\n# eval_set = [(df_valid[col_var], df_valid[col_target])]\n# model.fit(df_train[col_var], df_train[col_target], eval_metric=\"rmse\", eval_set=eval_set, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# 19.30146**2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# plot = plot_importance(model, height=0.9, max_num_features=20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# train model to predict cases/day\ncol_target2 = 'cases/day'\ncol_var2 = [\n    'Lat', 'Long',\n#    'cases/day_mean_(1-1)', 'cases/day_mean_(1-7)', 'cases/day_mean_(8-14)', \n#      'fatal/day_mean_(1-1)', 'fatal/day_mean_(1-7)', 'fatal/day_mean_(8-14)',\n#    'cases/day_std_(1-1)', 'cases/day_std_(1-7)', 'cases/day_std_(8-14)', \n#      'fatal/day_std_(1-1)', 'fatal/day_std_(1-7)', 'fatal/day_std_(8-14)',\n    'SmokingRate',\n#     'day',\n#     'dayofmonth',\n#     'dayofweek'\n]\ncol_var2 += val_cols\ncol_var2 += time_cols\n# col_var2 += ps_cols\n# col_var2 += cr_cols\ncol_var2 += extra_cols\n\nX_train = df_train[col_var2].values\nX_valid = df_valid[col_var2].values\ny_train = df_train[col_target2].values\ny_valid = df_valid[col_target2].values\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid)\nnum_round = 15000\nmodel2 = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# display feature importance\ntmp = pd.DataFrame()\ntmp[\"feature\"] = col_var2\ntmp[\"importance\"] = model2.feature_importance()\ntmp = tmp.sort_values('importance', ascending=False)\n\nimportant_features = list(tmp[0:30]['feature'])\ncol_var2 = important_features\n\ntmp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"important_features","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"X_train = df_train[col_var2].values\nX_valid = df_valid[col_var2].values\ny_train = df_train[col_target2].values\ny_valid = df_valid[col_target2].values\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid)\nnum_round = 15000\nmodel2 = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data],\n                  verbose_eval=100,\n                  early_stopping_rounds=150,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# model2 = xgb.XGBRegressor(n_estimators=1000)\n# eval_set = [(df_valid[col_var2], df_valid[col_target2])]\n# model.fit(df_train[col_var2], df_train[col_target2], eval_metric=\"rmse\", eval_set=eval_set, verbose=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# 202.84695**2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Prediction"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# remove overlaps between train and test\ndf_traintest4 = copy.deepcopy(df_traintest3)\ndf_traintest4['unique'] = df_traintest4.apply(lambda x: x['place_id'] + str(x['dayofyear']), axis=1)\nprint(len(df_traintest4))\ndf_traintest4 = df_traintest4[df_traintest4['unique'].duplicated()==False]\nprint(len(df_traintest4))\ndf_traintest4[(df_traintest4['place_id']=='China/Hubei') & (df_traintest4['dayofyear']>75)].head() #2020-03-15","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# count the fatalities per place until Feb.\ndf_tmp = df_traintest[pd.isna(df_traintest['Fatalities'])==False]\ndf_tmp = df_tmp[df_tmp['dayofyear']<61]\ndf_agg = df_tmp.groupby('place_id')['Fatalities'].agg('max').reset_index()\ndf_agg = df_agg.sort_values('Fatalities', ascending=False)\ndf_agg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"print(len(col_var), len(col_var2))\ncol_var, col_var2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# Check the predictions of some hot areas.\nplace = 'China/Hubei'\n# place = 'Iran'\ndf_interest_base = df_traintest4[df_traintest4['place_id']==place].reset_index(drop=True)\ndf_interest = copy.deepcopy(df_interest_base)\ndf_interest['cases/day'] = df_interest['cases/day'].astype(np.float)\ndf_interest['fatal/day'] = df_interest['fatal/day'].astype(np.float)\ndf_interest['cases/day'][df_interest['dayofyear']>=train_valid_cutoff_dayofyear] = -1\ndf_interest['fatal/day'][df_interest['dayofyear']>=train_valid_cutoff_dayofyear] = -1\nlen_known = (df_interest['cases/day']!=-1).sum()\nlen_unknown = (df_interest['cases/day']==-1).sum()\nprint(\"len train: {}, len prediction: {}\".format(len_known, len_unknown))\nfor i in range(len_unknown): # use predicted cases and fatal for next days' prediction\n#     print(i)\n    X_valid = df_interest[col_var].iloc[i+len_known]\n    X_valid2 = df_interest[col_var2].iloc[i+len_known]\n#     print(X_valid.shape)\n    pred_f = model.predict(X_valid)\n    pred_c = model2.predict(X_valid2)\n    df_interest['fatal/day'][i+len_known] = pred_f\n    df_interest['cases/day'][i+len_known] = pred_c\n    df_interest = df_interest[['cases/day', 'fatal/day', 'Long', 'Lat', 'SmokingRate']+time_cols+extra_cols]\n    df_interest = do_aggregations(df_interest, roll_ranges=roll_ranges)\n\n# visualize\ntmp = df_interest_base['fatal/day'].values\ntmp = np.cumsum(tmp)\nsns.lineplot(x=df_interest_base['dayofyear'][pd.isna(df_interest_base['Fatalities'])==False],\n             y=tmp[pd.isna(df_interest_base['Fatalities'])==False], label='true')\ntmp = df_interest['fatal/day'].values\ntmp = np.cumsum(tmp)\nsns.lineplot(x=df_interest_base['dayofyear'], y=tmp, label='pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"place = 'Iran'\ndf_interest_base = df_traintest4[df_traintest4['place_id']==place].reset_index(drop=True)\ndf_interest = copy.deepcopy(df_interest_base)\ndf_interest['cases/day'] = df_interest['cases/day'].astype(np.float)\ndf_interest['fatal/day'] = df_interest['fatal/day'].astype(np.float)\ndf_interest['cases/day'][df_interest['dayofyear']>=train_valid_cutoff_dayofyear] = -1\ndf_interest['fatal/day'][df_interest['dayofyear']>=train_valid_cutoff_dayofyear] = -1\nlen_known = (df_interest['cases/day']!=-1).sum()\nlen_unknown = (df_interest['cases/day']==-1).sum()\nprint(\"len train: {}, len prediction: {}\".format(len_known, len_unknown))\nfor i in range(len_unknown): # use predicted cases and fatal for next days' prediction\n    X_valid = df_interest[col_var].iloc[i+len_known]\n    X_valid2 = df_interest[col_var2].iloc[i+len_known]\n#     print(X_valid.shape)\n    pred_f = model.predict(X_valid)\n    pred_c = model2.predict(X_valid2)\n    df_interest['fatal/day'][i+len_known] = pred_f\n    df_interest['cases/day'][i+len_known] = pred_c\n    df_interest = df_interest[['cases/day', 'fatal/day', 'Long', 'Lat', 'SmokingRate']+time_cols+extra_cols]\n    df_interest = do_aggregations(df_interest, roll_ranges=roll_ranges)\n\n# visualize\ntmp = df_interest_base['fatal/day'].values\ntmp = np.cumsum(tmp)\nsns.lineplot(x=df_interest_base['dayofyear'][pd.isna(df_interest_base['Fatalities'])==False],\n             y=tmp[pd.isna(df_interest_base['Fatalities'])==False], label='true')\ntmp = df_interest['fatal/day'].values\ntmp = np.cumsum(tmp)\nsns.lineplot(x=df_interest_base['dayofyear'], y=tmp, label='pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_traintest3[df_traintest3['dayofyear']<0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"place = 'Italy'\ndf_interest_base = df_traintest4[df_traintest4['place_id']==place].reset_index(drop=True)\ndf_interest = copy.deepcopy(df_interest_base)\ndf_interest['cases/day'] = df_interest['cases/day'].astype(np.float)\ndf_interest['fatal/day'] = df_interest['fatal/day'].astype(np.float)\ndf_interest['cases/day'][df_interest['dayofyear']>=train_valid_cutoff_dayofyear] = -1\ndf_interest['fatal/day'][df_interest['dayofyear']>=train_valid_cutoff_dayofyear] = -1\nlen_known = (df_interest['cases/day']!=-1).sum()\nlen_unknown = (df_interest['cases/day']==-1).sum()\nprint(\"len train: {}, len prediction: {}\".format(len_known, len_unknown))\nfor i in range(len_unknown): # use predicted cases and fatal for next days' prediction\n    X_valid = df_interest[col_var].iloc[i+len_known]\n    X_valid2 = df_interest[col_var2].iloc[i+len_known]\n#     print(X_valid.shape)\n    pred_f = model.predict(X_valid)\n    pred_c = model2.predict(X_valid2)\n    df_interest['fatal/day'][i+len_known] = pred_f\n    df_interest['cases/day'][i+len_known] = pred_c\n    df_interest = df_interest[['cases/day', 'fatal/day', 'Long', 'Lat', 'SmokingRate']+time_cols+extra_cols]\n    df_interest = do_aggregations(df_interest, roll_ranges=roll_ranges)\n\n# visualize\ntmp = df_interest_base['fatal/day'].values\ntmp = np.cumsum(tmp)\nsns.lineplot(x=df_interest_base['dayofyear'][pd.isna(df_interest_base['Fatalities'])==False],\n             y=tmp[pd.isna(df_interest_base['Fatalities'])==False], label='true')\ntmp = df_interest['fatal/day'].values\ntmp = np.cumsum(tmp)\nsns.lineplot(x=df_interest_base['dayofyear'], y=tmp, label='pred')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training With All Data"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# train model to predict fatalities/day\n# col_target = 'fatal/day'\n# col_var = [\n#     'Lat', 'Long',\n# #     'cases/day_(1-1)', 'cases/day_(1-7)', 'cases/day_(8-14)', \n#     'fatal/day_(1-1)', 'fatal/day_(1-7)', 'fatal/day_(8-14)',\n#     'SmokingRate',\n# #     'day'\n# ]\ndf_train = df_traintest3[(pd.isna(df_traintest3['ForecastId']))]\nX_train = df_train[col_var].values\nX_valid = df_train[col_var].values\ny_train = df_train[col_target].values\ny_valid = df_train[col_target].values\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid)\nnum_round = 575\nmodel = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data], verbose_eval=100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# train model to predict cases/day\ndf_train = df_traintest3[(pd.isna(df_traintest3['ForecastId']))]\nX_train = df_train[col_var2].values\nX_valid = df_train[col_var2].values\ny_train = df_train[col_target2].values\ny_valid = df_train[col_target2].values\ntrain_data = lgb.Dataset(X_train, label=y_train)\nvalid_data = lgb.Dataset(X_valid, label=y_valid)\nnum_round = 225\nmodel2 = lgb.train(params, train_data, num_round, valid_sets=[train_data, valid_data], verbose_eval=100,)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Make Submission"},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df_traintest4[(df_traintest4['place_id']=='China/Hubei') & (df_traintest4['dayofyear']>=72)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# predict test data\ndf_preds = []\nfor i, place in enumerate(places[:]):\n    df_interest = copy.deepcopy(df_traintest4[df_traintest4['place_id']==place].reset_index(drop=True))\n    df_interest['cases/day'] = df_interest['cases/day'].astype(np.float)\n    df_interest['fatal/day'] = df_interest['fatal/day'].astype(np.float)\n    df_interest['cases/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    df_interest['fatal/day'][(pd.isna(df_interest['ForecastId']))==False] = -1\n    len_known = (df_interest['cases/day']!=-1).sum()\n    len_unknown = (df_interest['cases/day']==-1).sum()\n    if (i+1)%10==0:\n        print(\"{:3d}/{}  {}, len known: {}, len unknown: {}\".format(i+1, len(places), place, len_known, len_unknown), df_interest.shape)\n    for j in range(len_unknown): # use predicted cases and fatal for next days' prediction\n        X_valid = df_interest[col_var].iloc[j+len_known]\n        X_valid2 = df_interest[col_var2].iloc[j+len_known]\n#         print(X_valid.shape)\n        pred_f = model.predict(X_valid)\n        pred_c = model2.predict(X_valid2)\n#         print(pred_f, pred_c)\n        df_interest['fatal/day'][j+len_known] = pred_f\n        df_interest['cases/day'][j+len_known] = pred_c\n        df_interest = df_interest[['cases/day', 'fatal/day', 'Long', 'Lat', 'SmokingRate', 'ForecastId', 'place_id']+time_cols+extra_cols]\n        df_interest = do_aggregations(df_interest, roll_ranges=roll_ranges)\n    df_interest['fatal_pred'] = np.cumsum(df_interest['fatal/day'].values)\n    df_interest['cases_pred'] = np.cumsum(df_interest['cases/day'].values)\n    df_preds.append(df_interest)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# concat prediction\ndf_preds= pd.concat(df_preds)\ndf_preds = df_preds.sort_values('dayofyear')\ncol_tmp = ['place_id', 'ForecastId', 'dayofyear', 'cases/day', 'cases_pred', 'fatal/day', 'fatal_pred',]\ndf_preds[col_tmp][(df_preds['place_id']=='Afghanistan') & (df_preds['dayofyear']>75)].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# load sample submission\ndf_sub = pd.read_csv(\"../input/covid19-global-forecasting-week-3/submission.csv\")\nprint(len(df_sub))\ndf_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# merge prediction with sub\ndf_sub = pd.merge(df_sub, df_traintest3[['ForecastId', 'place_id', 'dayofyear']])\ndf_sub = pd.merge(df_sub, df_preds[['place_id', 'dayofyear', 'cases_pred', 'fatal_pred']], on=['place_id', 'dayofyear',], how='left')\ndf_sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"# save\ndf_sub['ConfirmedCases'] = df_sub['cases_pred']\ndf_sub['Fatalities'] = df_sub['fatal_pred']\ndf_sub = df_sub[['ForecastId', 'ConfirmedCases', 'Fatalities']]\ndf_sub.to_csv(\"submission.csv\", index=None)\ndf_sub.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}