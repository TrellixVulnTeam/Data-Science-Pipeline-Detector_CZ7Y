{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from scipy.integrate import solve_ivp\nfrom scipy.optimize import minimize\n\nimport matplotlib.pyplot as plt\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from scipy.integrate import solve_ivp\nfrom scipy.optimize import minimize\n\nimport matplotlib.pyplot as plt\nimport csv\nimport math","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_values_from_csv():\n    location = []\n    trainset = pd.read_csv(root+'/train.csv', engine='python')\n    #groupby = trainset.groupby(['Province_State', 'Country_Region']).last()\n\n    groupby = trainset.drop_duplicates(['Province_State', 'Country_Region'], keep='last')\n    province = groupby.loc[:, 'Province_State'].values\n    country = groupby.loc[:, 'Country_Region'].values\n    for i in range(len(province)):\n        location.append((province[i], country[i]))\n    return location","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss(point, confirmed, deceased):\n    \"\"\"\n    RMSE between actual confirmed cases and the estimated infectious people with given beta and gamma.\n    \"\"\"\n    size = len(confirmed) #67\n    beta, gamma = point\n    def SID(t, y):\n        S = y[0]\n        I = y[1]\n        D = y[2]\n        return [-beta*S*I, beta*S*I-gamma*I, gamma*I]\n    solution = solve_ivp(SID, [0, size], [S_0,I_0,D_0], t_eval=np.arange(0, size, 1), vectorized=True)\n    l1 = np.sqrt(np.mean((solution.y[1] + solution.y[2] - confirmed.values)**2))\n    l2 = np.sqrt(np.mean((solution.y[2] - deceased.values)**2))\n\n    return l1 + l2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Learner(object):\n    def __init__(self, province, country, loss):\n        self.province = province\n        self.country = country\n        self.loss = loss\n\n    def load_confirmed(self):\n        trainset = pd.read_csv(root+'/train.csv', engine='python')\n        location_df = trainset[trainset['Country_Region'] == self.country]\n        if self.province is np.nan:\n            return location_df.iloc[:].loc[:, 'ConfirmedCases']\n        location_df = location_df[location_df['Province_State'] == self.province]\n        return location_df.iloc[:].loc[:, 'ConfirmedCases']\n    \n    def load_fatalities(self):\n        trainset = pd.read_csv(root+'/train.csv', engine='python')\n        location_df = trainset[trainset['Country_Region'] == self.country]\n        if self.province is np.nan:\n            return location_df.iloc[:].loc[:, 'Fatalities']\n        location_df = location_df[location_df['Province_State'] == self.province]\n        return location_df.iloc[:].loc[:, 'Fatalities']\n\n    def extend_index(self, index, new_size):\n        values = index.values\n        current = index[-1]\n        while len(values)<new_size:\n            current = current + 1\n            values = np.append(values, current)\n        return values\n        \n    def predict(self, beta, gamma, confirmed, deceased):\n        predict_range = 107\n        # data index : INT64Index([9782, ..., 9848])\n        new_index = self.extend_index(confirmed.index, predict_range)\n        #[9782, 9283, ..., 9881]\n        size = len(new_index)\n        def SID(t, y):\n            S = y[0]\n            I = y[1]\n            D = y[2]\n            return [-beta*S*I, beta*S*I-gamma*I, gamma*I]\n        extended_confirmed = np.concatenate((confirmed.values, [None] * (size - len(confirmed.values))))\n        extended_deceased = np.concatenate((deceased.values, [None] * (size - len(deceased.values))))\n        return new_index, extended_confirmed, extended_deceased, solve_ivp(SID, [0, size], [S_0,I_0,D_0], t_eval=np.arange(0, size, 1))\n\n    def test_results(self, new_index, extended_confirmed, extended_deceased, prediction):\n        S = prediction.y[0]\n        I = prediction.y[1]\n        D = prediction.y[2]\n        result = pd.read_csv(root+'/test.csv', engine='python')\n        country_df = result[result['Country_Region'] == self.country]\n        if self.province is np.nan:\n            forecast_ID = country_df.iloc[:].loc[:, 'ForecastId']\n        else:\n            location_df = country_df[result['Province_State']==self.province]\n            forecast_ID = location_df.iloc[:].loc[:, 'ForecastId']\n        index = forecast_ID.index\n        start = index.values[0] + 1\n\n        r = csv.reader(open(root+'/submission.csv')) # Here your csv file\n        lines = list(r)\n        for i in range(12):\n            lines[start+i][1] = extended_confirmed[64+i]\n            lines[start+i][2] = extended_deceased[64+i]\n        for j in range(31):\n            lines[start+12+j][1] = math.floor(I[76+j] + D[76+j])\n            lines[start+12+j][2] = math.floor(D[76+j])\n        writer = csv.writer(open('submission.csv', 'w'))\n        writer.writerows(lines)\n\n    def train(self):\n        confirmed = self.load_confirmed()\n        deceased = self.load_fatalities()\n        infected = confirmed-deceased\n        optimal = minimize(\n            loss,\n            [0.001, 0.001],\n            args=(confirmed, deceased),\n            method='L-BFGS-B',\n            bounds=[(0.00000001, 0.4), (0.00000001, 0.4)]\n        )\n        beta, gamma = optimal.x\n        print(self.country, 'beta:',beta, 'gamma:', gamma)\n        new_index, extended_infected, extended_deceased, prediction = self.predict(beta, gamma, infected, deceased)\n        self.test_results(new_index, extended_infected, extended_deceased, prediction)\n        '''\n        df = pd.DataFrame({\n            'confirmed': extended_infected,\n            'deceased' : extended_deceased,\n            'S': prediction.y[0],\n            'I': prediction.y[1],\n            'D': prediction.y[2]\n        }, index=new_index)\n        fig, ax = plt.subplots(figsize=(15, 10))\n        ax.set_title(self.country)\n        df.plot(ax=ax)\n        fig.savefig(f\"./plots_countries/{self.country}.png\")\n        '''\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if __name__ == \"__main__\":\n    root = '/kaggle/input/covid19-global-forecasting-week-3'\n\n    list_region = get_values_from_csv()\n    \n    for i in range(len(list_region)):\n        province = list_region[i][0]\n        country = list_region[i][1]\n        print(province, country)\n        S_0, I_0, R_0, D_0 = 100000, 1, 0, 0\n        SID_model = Learner(province, country, 0)\n    \n        SID_model.train()\n        \n        sub = pd.read_csv('submission.csv')\n        sub.to_csv('submission.csv', index=False)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}