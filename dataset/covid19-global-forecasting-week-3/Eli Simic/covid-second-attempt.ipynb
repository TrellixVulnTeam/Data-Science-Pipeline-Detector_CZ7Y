{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom datetime import date\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load Dataset"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"PATH_WEEK2 = './week2'\n\ndf_Train = pd.read_csv(f'/kaggle/input/covid19-global-forecasting-week-3/train.csv')\ndf_test = pd.read_csv(f'/kaggle/input/covid19-global-forecasting-week-3/test.csv')\n\ndf_Population = pd.read_csv(f'/kaggle/input/population-by-country-2020/population_by_country_2020.csv')\n\ndf_gdp = pd.read_excel(f'/kaggle/input/global-economic-monitor/gem-excel-zip-9-97-mb-/GDP at market prices, constant 2010 LCU, millions, seas. adj..xlsx')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Train['Date_Since'] = pd.to_datetime(date(2019, 12, 17)); df_Train['Date_Since']\ndf_Train['Days_Since'] = pd.to_datetime(df_Train['Date']) - df_Train['Date_Since']\n\ndf_Train['Days_Since'] = df_Train['Days_Since'].dt.days\ndf_Train = df_Train.drop(columns=['Date_Since'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_test['Date_Since'] = pd.to_datetime(date(2019, 12, 17)); df_test['Date_Since']\ndf_test['Days_Since'] = pd.to_datetime(df_test['Date']) - df_test['Date_Since']\n\ndf_test['Days_Since'] = df_test['Days_Since'].dt.days\ndf_test = df_test.drop(columns=['Date_Since'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# create new column with gdp\n# with the key of Country\n# we want to omit the countries that are not in gdp dataset\n# can we join?\n\n\n# select unique countries where gdp == Nan\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"## Rename the Columns of Train and Test Datasets"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Train.rename(columns={'Country_Region':'Country'}, inplace=True)\ndf_test.rename(columns={'Country_Region':'Country'}, inplace=True)\n\ndf_Train.rename(columns={'Province_State':'State'}, inplace=True)\ndf_test.rename(columns={'Province_State':'State'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Train.loc[: , ['Country', 'ConfirmedCases', 'Fatalities']].groupby(['Country']).max().sort_values(by='ConfirmedCases', ascending=False).reset_index()[:15].style.background_gradient(cmap='rainbow')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Population.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Population.rename(columns={'Country (or dependency)':'Country'}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train_countries = df_Train.Country.unique().tolist()\npop_countries = df_Population.Country.unique().tolist()\n\nfor country in train_countries:\n    if country not in pop_countries:\n        print (country)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"renameCountryNames = {\n    \"Congo (Brazzaville)\": \"Congo\",\n    \"Congo (Kinshasa)\": \"Congo\",\n    \"Cote d'Ivoire\": \"Côte d'Ivoire\",\n    \"Czechia\": \"Czech Republic (Czechia)\",\n    \"Korea, South\": \"South Korea\",\n    \"Saint Kitts and Nevis\": \"Saint Kitts & Nevis\",\n    \"Saint Vincent and the Grenadines\": \"St. Vincent & Grenadines\",\n    \"Taiwan*\": \"Taiwan\",\n    \"US\": \"United States\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_Train.loc[df_Train.Country in renameCountryNames.keys(), 'Country'] = df_Train.loc[df_Train.Country in renameCountryNames.keys(), 'Country'].map(country_map)\ndf_Train.replace({'Country': renameCountryNames}, inplace=True)\ndf_test.replace({'Country': renameCountryNames}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Population.loc[df_Population['Med. Age']=='N.A.', 'Med. Age'] = df_Population.loc[df_Population['Med. Age']!='N.A.', 'Med. Age'].mode()[0]\ndf_Population.loc[df_Population['Urban Pop %']=='N.A.', 'Urban Pop %'] = df_Population.loc[df_Population['Urban Pop %']!='N.A.', 'Urban Pop %'].mode()[0]\ndf_Population.loc[df_Population['Fert. Rate']=='N.A.', 'Fert. Rate'] = df_Population.loc[df_Population['Fert. Rate']!='N.A.', 'Fert. Rate'].mode()[0]\ndf_Population.loc[:, 'Migrants (net)'] = df_Population.loc[:, 'Migrants (net)'].fillna(0)\ndf_Population['Yearly Change'] = df_Population['Yearly Change'].str.rstrip('%')\ndf_Population['World Share'] = df_Population['World Share'].str.rstrip('%')\ndf_Population['Urban Pop %'] = df_Population['Urban Pop %'].str.rstrip('%')\ndf_Population = df_Population.astype({\"Net Change\": int,\"Density (P/Km²)\": int,\"Population (2020)\": int,\"Land Area (Km²)\": int,\"Yearly Change\": float,\"Urban Pop %\": int,\"Fert. Rate\": float,\"Med. Age\": int,\"World Share\": float, \"Migrants (net)\": float,})\n\n# As the Country value \"Diamond Princess\" is a CRUISE, we replace the population \ndf_Population = df_Population.append(pd.Series(['Diamond Princess', 3500, 0, 0, 0, 0, 0.0, 1, 30, 0, 0.0], index=df_Population.columns ), ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Train = df_Train.merge(df_Population, how='left', left_on='Country', right_on='Country')\ndf_test = df_test.merge(df_Population, how='left', left_on='Country', right_on='Country')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### GDP"},{"metadata":{"trusted":false},"cell_type":"code","source":"year18 = df_gdp[df_gdp['Unnamed: 0'] == 2018.0].drop(columns=['Unnamed: 0'])\n\npd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 100)\n\nyear18 = year18.T.reset_index()\nyear18.columns = year18.columns.astype(str)\nyear18.columns\nyear18 = year18.rename(columns={'index': 'Country', '29': 'GDP'})\n\ndf_Train = df_Train.merge(year18, how='left', on=['Country'])\ndf_Train['GDP'] = df_Train['GDP'].fillna(df_Train['GDP'].median())\n\ndf_test = df_test.merge(year18, how='left', on=['Country'])\ndf_test['GDP'] = df_test['GDP'].fillna(df_test['GDP'].median())\n\n# if gdp == Nan fill with median\n# if X_Train.loc[X_Train['Country'] == country]['GDP'].isnull().values.any():\n# X_Train = X_Train.loc[X_Train['Country'] == country].drop(columns=['GDP'])\n# X_Test = X_Test.loc[X_Test['Country'] == country].drop(columns=['GDP'])\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Transformation"},{"metadata":{},"cell_type":"markdown","source":"## Transform the Date to Pandas DataTime"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_Train['Date'] = pd.to_datetime(df_Train['Date'], infer_datetime_format=True)\ndf_test['Date'] = pd.to_datetime(df_test['Date'], infer_datetime_format=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Dataset for Model Training "},{"metadata":{},"cell_type":"markdown","source":"## Avoid Data Leakage\nAs the Train Dataset has records till 27th March 2020 and Test Dataset has partial intersection of records from 19th March 2020. Let us concise the Train Dataset to 18th March 2020."},{"metadata":{"trusted":false},"cell_type":"code","source":"MIN_TEST_DATE = df_test.Date.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train = df_Train.loc[df_Train.Date < MIN_TEST_DATE, :]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target#1 ConfirmedCases Series"},{"metadata":{"trusted":false},"cell_type":"code","source":"y1_Train = df_train.iloc[:, -2]\ny1_Train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target#1 Fatalities Series"},{"metadata":{"trusted":false},"cell_type":"code","source":"y2_Train = df_train.iloc[:, -1]\ny2_Train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Fill NaN from State feature"},{"metadata":{"trusted":false},"cell_type":"code","source":"EMPTY_VAL = \"EMPTY_VAL\"\n\ndef fillState(state, country):\n    if state == EMPTY_VAL: return country\n    return state","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#X_Train = df_train.loc[:, ['State', 'Country', 'Date']]\nX_Train = df_train.copy()\n\nX_Train['State'].fillna(EMPTY_VAL, inplace=True)\nX_Train['State'] = X_Train.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_Train['year'] = X_Train['Date'].dt.year\nX_Train['month'] = X_Train['Date'].dt.month\nX_Train['week'] = X_Train['Date'].dt.week\nX_Train['day'] = X_Train['Date'].dt.day\nX_Train['dayofweek'] = X_Train['Date'].dt.dayofweek\n\nX_Train.loc[:, 'Date'] = X_Train.Date.dt.strftime(\"%m%d\")\nX_Train[\"Date\"]  = X_Train[\"Date\"].astype(int)\n\n#X_Train.drop(columns=['Date'], axis=1, inplace=True)\n\n# X_Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#X_Test = df_test.loc[:, ['State', 'Country', 'Date']]\nX_Test = df_test.copy()\n\nX_Test['State'].fillna(EMPTY_VAL, inplace=True)\nX_Test['State'] = X_Test.loc[:, ['State', 'Country']].apply(lambda x : fillState(x['State'], x['Country']), axis=1)\n\nX_Test['year'] = X_Test['Date'].dt.year\nX_Test['month'] = X_Test['Date'].dt.month\nX_Test['week'] = X_Test['Date'].dt.week\nX_Test['day'] = X_Test['Date'].dt.day\nX_Test['dayofweek'] = X_Test['Date'].dt.dayofweek\n\nX_Test.loc[:, 'Date'] = X_Test.Date.dt.strftime(\"%m%d\")\nX_Test[\"Date\"]  = X_Test[\"Date\"].astype(int)\n\n#X_Test.drop(columns=['Date'], axis=1, inplace=True)\n\n# X_Test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Categorical Encoding using Label Encoder"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transforming the Country and State to Numerical values"},{"metadata":{"trusted":false},"cell_type":"code","source":"X_Train.Country = le.fit_transform(X_Train.Country)\nX_Train['State'] = le.fit_transform(X_Train['State'])\n\n# X_Train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_Test.Country = le.fit_transform(X_Test.Country)\nX_Test['State'] = le.fit_transform(X_Test['State'])\n\n# X_Test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from warnings import filterwarnings\nfilterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":false},"cell_type":"code","source":"from fastai.tabular import * ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"procs = [FillMissing, Categorify, Normalize]\n# get out of bad variable name\n\n# df_case.shape\nX_Train = X_Train.rename(columns={'Id': 'ForecastId'})","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_case = X_Train.copy()\ndf_case = df_case.drop(columns=['Fatalities'])\n\nvalid_idx = range(len(df_case)-4000, len(df_case))\n\ndep_var = 'ConfirmedCases'\n\ncat_names = ['State', 'Country', 'year', 'month', 'week', 'day', 'dayofweek']\n\ndata_cases = TabularDataBunch.from_df(path='.',df=df_case,\n                                      dep_var=dep_var, \n                                      valid_idx=valid_idx,\n                                      procs=procs,\n                                      cat_names=cat_names,\n                                      test_df=X_Test)\nlearn_c = tabular_learner(\n    data_cases, layers=[200,50], emb_szs={'native-country': 10}, metrics=mse)\n# learn.fit_one_cycle(1, 1e-2)\nlearn_c.fit(5, 1e-1)\n\npreds_c, _ = learn_c.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Fatalities"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_fatal = X_Train.copy()\ndf_fatal = df_fatal.drop(columns=['ConfirmedCases'])\n\nvalid_idx = range(len(df_fatal)-4000, len(df_fatal))\n\ndep_var = 'Fatalities'\n\ncat_names = ['State', 'Country', 'year', 'month', 'week', 'day', 'dayofweek']\n\ndata_fatal = TabularDataBunch.from_df(path='.',df=df_fatal,\n                                      dep_var=dep_var, \n                                      valid_idx=valid_idx,\n                                      procs=procs,\n                                      cat_names=cat_names,\n                                      test_df=X_Test)\nlearn_f = tabular_learner(\n    data_fatal, layers=[200,50], emb_szs={'native-country': 10}, metrics=mse)\n# learn.fit_one_cycle(1, 1e-2)\nlearn_f.fit(5, 1e-1)\n\npreds_f, _ = learn_c.get_preds(ds_type=DatasetType.Test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_out = pd.DataFrame({'ForecastId': X_Test['ForecastId'], 'ConfirmedCases': preds_c,\n                   'Fatalities': preds_f})\n\n# X_Test['ForecastId'].shape, preds_c.shape, preds_f.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data_cases.train_ds","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X_Test.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"preds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submit\n### Use pandas to_csv to create a submission.csv file"},{"metadata":{"trusted":false},"cell_type":"code","source":"df_out.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.4"}},"nbformat":4,"nbformat_minor":4}