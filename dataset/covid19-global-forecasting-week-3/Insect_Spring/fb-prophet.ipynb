{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Read input files\nfull_train_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/test.csv\")\nsubmission_data_orig = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/submission.csv\")\n\ntrain_data = full_train_data\ntrain_end_date = max(train_data.Date)\ntrain_data['Date'] = pd.to_datetime(train_data['Date'])\ntrain_data.head()\ntrain_end_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All imports\nimport matplotlib.pyplot as plt\nfrom fbprophet import Prophet\nfrom datetime import datetime\nfrom datetime import timedelta\nfrom sklearn.metrics import mean_squared_log_error\n\n# Constants\n\n# Total generated forecast\nFORECAST_COUNT = 50\n\n# Train data end date\nTRAIN_DATA_END = train_end_date\n# TODO Remove before final submission. PREDICTION_START_DATE is TRAIN_DATA_END + 1\n# It exists like this because train data end and prediction start date are two different things at the moment\n# Some places in the code filter data by train-data-end for understanding how much training data to read\n# Some places set the starting value of a cell based on first day too\nPREDICTION_START_DATE = '2020-03-26'\n\n# TODO: Calculate this as opposed to eye estimate\nAVRAGE_FATALITY_RATE_OF_INCREASE = 1.02\nAVERAGE_CONFIRMED_CASES_RATE_OF_INCREASE = 1.05","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# All Helper functions\ndef filter_train_data_for_public_leaderboard(data):\n    \"\"\"\n    Filters data by dates and only keeps samples on or before 03-25-2020\n    \"\"\"\n    data = data.loc[data.Date <= TRAIN_DATA_END]\n    return data\n\ndef filter_data_by_date_range(data, start_date, end_date):\n    \"\"\"\n    Filters data and keeps only those rows which lie in the date range left_date to right_date both inclusive\n    \"\"\"\n    data = data.loc[((data.Date >= start_date) & (data.Date <= end_date))]\n    return data\n\ndef remove_zero_cases(data, column_name):\n    \"\"\"\n    Remove rows which have column_name in data DF set to 0\n    \"\"\"\n    non_zero_columns_exp = data[column_name] != 0\n    non_zero_columns = data[non_zero_columns_exp]\n    return non_zero_columns\n\ndef filter_by_country(country, input_data):\n    \"\"\"\n    Filters and returns rows in the dataframe belonging to the country pointed to by the country parameter\n    \"\"\"\n    filtered_country_only = input_data[\"Country_Region\"] == country\n    return input_data[filtered_country_only]\n    \ndef filter_by_state(state, input_data):\n    \"\"\"\n    Call after filter_by_country since there is a slight possibility that two countries may have the same state\n    \"\"\"\n    filtered_state_only = input_data[\"Province_State\"] == state\n    return input_data[filtered_state_only]\n\ndef prepare_data_for_prophet(input_df):\n    \"\"\"\n    Prepare data for fitting into a Prophet forecasting model. That is timestamp (ds) and value (y) only.\n    Input DataFrame is expected to contain the 'Date' and 'ConfirmedCases column.'\n    \"\"\"\n    if 'ConfirmedCases' in input_df.columns:\n        base_column = \"ConfirmedCases\"\n    elif 'Fatalities' in input_df.columns:\n        base_column = \"Fatalities\"\n    else:\n        raise ValueError('Either ConfirmedCases or Fatalities is expected in the DF')\n        \n    data = input_df[[\"Date\", base_column]]\n    # data = data.assign(InterpolateQuadratic=data.ConfirmedCases.interpolate(method='quadratic'))\n    data_renamed = data.rename(columns = {'Date': 'ds', base_column: 'y'})\n    return data_renamed\n\ndef group_by_state(country_data):\n    \"\"\"\n    Returns a list of DF where one DF corresponds to one state.\n    \"\"\"\n    states_data = list()\n    for state in country_data.Province_State.unique():\n        filtered_by_state = filter_by_state(state, country_data)\n        if (len(filtered_by_state.index)) == 0:\n            print('The {} state does not have any data'.format(state))\n            continue\n        states_data.append(filtered_by_state)\n    return states_data\n\ndef rmsle(df1, df2):\n    \"\"\"\n    Pass two DFs containing only one column. Name of the columns doesn't need to match.\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(df1, df2))\n\ndef filter_by_state(state, input_data):\n    \"\"\"\n    Call after filter_by_country since there is a slight possibility that two countries may have the same state\n    \"\"\"\n    filtered_state_only = input_data[\"Province_State\"] == state\n    return input_data[filtered_state_only]\n\ndef get_next_day(input_date):\n    input_date = datetime.strptime(input_date, '%Y-%m-%d')\n    next_date = input_date + timedelta(days=1)\n    return datetime.strftime(next_date, format='%Y-%m-%d')\n\ndef get_previous_day(input_date):\n    input_date = datetime.strptime(input_date, '%Y-%m-%d')\n    next_date = input_date - timedelta(days=1)\n    return datetime.strftime(next_date, format='%Y-%m-%d')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Processing countries with states\n\ndef make_predictions_for_cc_and_f(state_data_relevant_cc_f, country, state):\n    \"\"\"\n    Makes predictions for ConfirmedCases and Fatalities.\n    Filters the training data state_data_relevant_cc_f to only include data until TRAIN_DATA_END.\n    Creates predictions only from TRAIN_DATA_END + 1.\n    \"\"\"\n    state_data_relevant_cc_f = state_data_relevant_cc_f[['Date', 'ConfirmedCases', 'Fatalities']]\n    # Remove rows with 0 ConfirmedCases\n    state_data_relevant_cc = remove_zero_cases(state_data_relevant_cc_f, 'ConfirmedCases')\n    forecast_cc = pd.DataFrame()\n    if len(state_data_relevant_cc) < 2:\n    # This loop should never enter because by private testing, all countries will have at least one case\n    # Writing it now since some countries still do not have data on 3-26\n        state_data_relevant_cc = pd.DataFrame({\n            'Date': [get_previous_day(get_previous_day(PREDICTION_START_DATE)), \n                     get_previous_day(PREDICTION_START_DATE)], \n            'ConfirmedCases': [0, 0],\n            # Setting a slow rate of increase of death\n            'Fatalities': [0.0, 0.0]\n        })\n\n    if len(state_data_relevant_cc) >= 2:\n        # Add IncrementalConfirmedCases since prophet fits better on stationary data based on above observations\n        state_data_relevant_stationary = state_data_relevant_cc[['ConfirmedCases']].diff()\n        state_data_relevant_stationary.rename(columns={'ConfirmedCases':'IncrementalConfirmedCases'}, inplace=True)\n        state_data_relevant_cc = state_data_relevant_cc.merge(\n            state_data_relevant_stationary, left_index=True, right_index=True)\n        state_data_relevant_cc[['IncrementalConfirmedCases']] = state_data_relevant_cc[[\n            'IncrementalConfirmedCases']].fillna(value=0)\n        # Renaming to ConfirmedCases since prepare_data_for_prophet function only understands ConfirmedCases or Fatalities\n        prophet_input = prepare_data_for_prophet(state_data_relevant_cc[['Date', 'IncrementalConfirmedCases']]\n                                     .rename(columns={'IncrementalConfirmedCases': 'ConfirmedCases'}))\n        m_cc = Prophet()\n        m_cc.fit(prophet_input)\n        future = m_cc.make_future_dataframe(FORECAST_COUNT, freq='D')\n        future = future.loc[future.ds >= PREDICTION_START_DATE]\n        forecast_cc = m_cc.predict(future)\n        forecast_cc = forecast_cc[['ds', 'yhat']]\n        state_data_relevant_cc['Date'] = pd.to_datetime(state_data_relevant_cc['Date'], format='%Y-%m-%d')\n        # Setting the first column value of yhat to be the count so far so that cumulative sum results in \n        # actual prediction\n        last_train_row = state_data_relevant_cc[\n            state_data_relevant_cc['Date'] == get_previous_day(PREDICTION_START_DATE)]\n        if last_train_row.shape[0] != 0:\n            last_cc = last_train_row.iloc[0]['ConfirmedCases']\n        else:\n            last_cc = 0\n        forecast_cc.at[0, 'yhat'] = last_cc + forecast_cc.iloc[0]['yhat']\n        # Removing all negative values, replacing with NaN and subsequently replacing NaNs with 0s\n        forecast_cc = forecast_cc.assign(yhat = forecast_cc.yhat.where(forecast_cc.yhat.ge(0)))\n        forecast_cc = forecast_cc.fillna(0)\n        # Aggregating incremental counts to generate predicted confirmed cases\n        forecast_cc['PredictedConfirmedCases'] = forecast_cc.yhat.cumsum()\n        # Applying ceiling since fractional cases have no meaning\n        forecast_cc['PredictedConfirmedCases'] = forecast_cc['PredictedConfirmedCases'].apply(np.rint)\n        # forecast_cc has the columns: ds, yhat (incremental prediction), PredictedConfirmedCases\n        # Renaming for better join output\n        forecast_cc = forecast_cc[['ds', 'PredictedConfirmedCases']]\n        forecast_cc.rename(columns={'ds': 'Date'}, inplace=True)\n\n    # Fatalities logic here. Exactly same as above but for the column Fatalities\n    state_data_relevant_f = remove_zero_cases(state_data_relevant_cc_f, 'Fatalities')\n    # Need this check since removing 0s could have removed all rows as there are lot more 0 Fatalities\n    forecast_f = pd.DataFrame()\n    if len(state_data_relevant_f) < 2:\n        # insert dummy row with linear increase. Since there are confirmed cases. This is going to do better than 0s\n        # if one row exists, double that and insert. \n        # Otherwise insert one row with 1 and another with 2\n        # We do not care about cc in this\n        if len(state_data_relevant_f) == 1:\n            f_value = state_data_relevant_f.iloc[0]['Fatalities']\n        else:\n            f_value = 0\n        state_data_relevant_f = pd.DataFrame({\n            'Date': [get_previous_day(get_previous_day(PREDICTION_START_DATE)), \n                     get_previous_day(PREDICTION_START_DATE)], \n            'ConfirmedCases': [0, 0],\n            'Fatalities': [f_value, f_value * AVRAGE_FATALITY_RATE_OF_INCREASE]\n        })\n    \n    state_data_relevant_stationary = state_data_relevant_f[['Fatalities']].diff()\n    state_data_relevant_stationary.rename(columns={'Fatalities':'IncrementalFatalities'}, inplace=True)\n    state_data_relevant_f = state_data_relevant_f.merge(state_data_relevant_stationary, left_index=True,\n                                                        right_index=True)\n    state_data_relevant_f[['IncrementalFatalities']] = state_data_relevant_f[[\n        'IncrementalFatalities']].fillna(value=0)\n    prophet_input = prepare_data_for_prophet(state_data_relevant_f[['Date', 'IncrementalFatalities']]\n                                 .rename(columns={'IncrementalFatalities': 'Fatalities'}))\n    m_f = Prophet()\n    m_f.fit(prophet_input)\n    future = m_f.make_future_dataframe(FORECAST_COUNT, freq='D')\n    future = future.loc[future.ds >= PREDICTION_START_DATE]\n    forecast_f = m_f.predict(future)\n    forecast_f = forecast_f[['ds', 'yhat']]\n    state_data_relevant_f['Date'] = pd.to_datetime(state_data_relevant_f['Date'], format='%Y-%m-%d')\n    last_train_row = state_data_relevant_f[state_data_relevant_f['Date'] == get_previous_day(PREDICTION_START_DATE)]\n    if last_train_row.shape[0] != 0:\n        last_f = last_train_row.iloc[0]['Fatalities']\n    else:\n        last_f = 0\n    forecast_f.at[0, 'yhat'] = last_f + forecast_f.iloc[0]['yhat']\n    forecast_f = forecast_f.assign(yhat = forecast_f.yhat.where(forecast_f.yhat.ge(0)))\n    forecast_f = forecast_f.fillna(0)\n    forecast_f['PredictedFatalities'] = forecast_f.yhat.cumsum()\n    forecast_f['PredictedFatalities'] = forecast_f['PredictedFatalities'].apply(np.rint)\n    forecast_f = forecast_f[['ds', 'PredictedFatalities']]\n    forecast_f.rename(columns={'ds': 'Date'}, inplace=True)\n\n    forecast_final = pd.DataFrame()\n    if forecast_f.empty and forecast_cc.count != 0:\n        # impossible that forecast_cc is empty and forecast_f is not\n        forecast_final = forecast_cc\n    else:\n        forecast_final = forecast_cc.merge(forecast_f, on='Date', how='left')\n    forecast_final['Country_Region'] = country\n    if state is not None:\n        forecast_final['Province_State'] = state\n    return forecast_final\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iterate over every country\n# For each country, prepare list of DF by state\n# For each state DF, make FB prophet prediction into the future\n# Create final DF of the form: Country, State, Date, Prediction\ndef make_predictions_for_countries_with_states(countries_with_state):\n    \"\"\"\n    Makes predictions for one state at a time. Returns a DF containing the following columns:\n    Country, State, Date, Prediction\n    Parameters\n    ----------\n    countries_with_state : DataFrame\n                           Containing all columns as pertaining in input_data but only those rows which have non \n                           NaN states\n    \"\"\"\n    output_df = pd.DataFrame(columns=['Date', 'Country_Region', \n                                      'Province_State', 'PredictedConfirmedCases', 'PredictedFatalities'])\n    for country in countries_with_state.Country_Region.unique():\n        country_data = filter_by_country(country, countries_with_state)\n        print('processing country {}'.format(country))\n        states_data = group_by_state(country_data)\n        for state_data in states_data:\n            state = state_data.iloc[0].Province_State\n            forecast_final = make_predictions_for_cc_and_f(state_data, country, state)\n            output_df = pd.concat([output_df, forecast_final])\n    print('finished processing all countries with state')        \n    return output_df\n\ndef make_prediction_for_countries(countries_data):\n    \"\"\"\n    Iterate over each country. Filter entries by country and perform prediction.\n    \"\"\"\n    output_df = pd.DataFrame(columns=['Date', 'Country_Region', \n                                      'Province_State', 'PredictedConfirmedCases', 'PredictedFatalities'])\n    for country in countries_data.Country_Region.unique():\n        country_data = filter_by_country(country, countries_data)\n        print('processing country {}'.format(country))\n        forecast_final = make_predictions_for_cc_and_f(country_data, country, None)\n        output_df = pd.concat([output_df, forecast_final])\n    print('finished processing all countries which are without state')\n    return output_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Run the predictions\n# TODO Remove tests\ntrain_data = filter_train_data_for_public_leaderboard(train_data)\ncountries_without_state = train_data[pd.isnull(train_data['Province_State'])]\n# countries_without_state = filter_by_country('India', countries_without_state)\nresult_countries_without_state = make_prediction_for_countries(countries_without_state)\ncountries_with_state = train_data.dropna(subset=['Province_State'])\n# countries_with_state = filter_by_country('Australia', countries_with_state)\nresult = make_predictions_for_countries_with_states(countries_with_state)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Filling all missing values with 0s\nresult['PredictedFatalities'].fillna(0, inplace=True)\nresult['PredictedConfirmedCases'].fillna(0, inplace=True)\nresult_countries_without_state['PredictedFatalities'].fillna(0, inplace=True)\nresult_countries_without_state['PredictedConfirmedCases'].fillna(0, inplace=True)\nfinal_result = pd.concat([result, result_countries_without_state])\nfinal_result.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"test_data.head()\n# test_data = filter_test_data_for_public_leaderboard(test_data)\n# max(test_data.Date) - 5/7\n# max(final_result.Date) - 5/24\n# state_data_relevant_cc['Date'] = pd.to_datetime(state_data_relevant_cc['Date'], format='%Y-%m-%d')\ntest_data['Date'] = pd.to_datetime(test_data['Date'], format='%Y-%m-%d')\n\n# Left join from test_data \nsubmission_data = test_data.merge(\n    final_result, \n    left_on=['Date', 'Country_Region', 'Province_State'],\n    right_on=['Date', 'Country_Region', 'Province_State'],\n    how='left'\n)\n\nsubmission_data = submission_data[['ForecastId', 'PredictedConfirmedCases', 'PredictedFatalities']]\nsubmission_data = submission_data.rename(columns={'PredictedConfirmedCases':'ConfirmedCases', \n                                                  'PredictedFatalities':'Fatalities'})\nsubmission_data['Fatalities'].fillna(0, inplace=True)\nsubmission_data['ConfirmedCases'].fillna(0, inplace=True)\nsubmission_data.head(50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Publishing output for commit\nsubmission_data.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation_data = pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/train.csv\")\n# validation_data['Date'] = pd.to_datetime(validation_data['Date'])\n# validation_data = filter_data_by_date_range(validation_data, '2020-03-26', '2020-04-08')\n\n# validation_data = filter_by_country('Australia', validation_data)\n# validation_data = filter_by_state('New South Wales', validation_data)\n\n# validation_data = validation_data.merge(\n#     final_result, \n#     left_on=['Date', 'Country_Region', 'Province_State'],\n#     right_on=['Date', 'Country_Region', 'Province_State'],\n#     how='left'\n# )\n# # print(validation_data.head())\n# validation_data.head(10)\n# # Filter by countries and do rmsle one at a time iterating over uniqueCountries.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# validation_data.fillna(0, inplace=True)\n# cc_score = rmsle(validation_data[['ConfirmedCases']], validation_data[['PredictedConfirmedCases']])\n# f_score = rmsle(validation_data[['Fatalities']], validation_data[['PredictedFatalities']])\n\n\n# print(cc_score)\n# print(f_score)\n# print((cc_score + f_score)/2)\n# # 0.6580012040905447\n# # 0.789636192992397\n# # 0.7238186985414709\n\n# # Australia with 0.4,0.45\n# # 0.19140066882712942\n# # 0.7522248023239893\n# # 0.47181273557555936\n\n# # Australia with 0, 0\n# # 0.19140066882712942\n# # 0.4371071402542409\n# # 0.31425390454068514\n\n# # Botswana with 0,0 \n# # 0.6965142403895137\n# # 0.543749384533382\n# # 0.6201318124614479\n\n# validation_data.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import statistics \n# validation_data.head()\n\n# # Iterate over all unique countries.\n# # filter data by country\n# # calculate rmsle for that country and keep adding two a DF containing the rows: Country, cc_score, f_score, combined\n# output_df = pd.DataFrame()\n# for country in validation_data.Country_Region.unique():\n#     country_data = filter_by_country(country, validation_data)\n#     cc_score = rmsle(country_data[['ConfirmedCases']], country_data[['PredictedConfirmedCases']])\n#     f_score = rmsle(country_data[['Fatalities']], country_data[['PredictedFatalities']])\n#     combined = statistics.median([cc_score, f_score])\n#     row = pd.DataFrame({'Country_region': [country], \n#                        'cc_score': [cc_score], \n#                        'f_score': [f_score], \n#                        'combined': [combined]})\n#     output_df = pd.concat([output_df, row], sort=False)\n# output_df.head(50)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# by_cc = output_df.sort_values(by=['cc_score'], ascending=False)\n# by_f = output_df.sort_values(by=['f_score'], ascending=False)\n# by_combined = output_df.sort_values(by=['combined'], ascending=False)\n\n# by_cc.to_csv('worst_cc_predicts_countries.csv', index=False)\n# by_f.to_csv('worst_f_predicts_countries.csv', index=False)\n# by_combined.to_csv('worst_combined_predict_countries.csv', index=False)\n\n# by_combined.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# countries = final_result.Country_Region.unique()\n# countries_data = train_data.loc[(\n#     (train_data['Date'] == '2020-03-25') & (train_data['ConfirmedCases'] == 0)\n# )]\n\n# countries = final_result.Country_Region.unique()\n# countries_data = full_train_data.loc[(\n#     (train_data['Date'] == '2020-04-06') & (train_data['Fatalities'] == 0)\n# )]\n\n\n# countries_data.head(50)\n\n# countries_data.shape\n# 134\n\n# countries_data for Fatalities = 0 on 3/25\n# 11 rows only\n\n\n# countries_data for ConfirmedCases = 0 on 3/25\n# 11 rows only\n# Resolution: Will be dealt with when full training data is available.\n\n# All these countries have data now so for private leaderboard, predictions should be much better. \n# Nothing to worry here.\n# Botswana\n# Burma\n# Burundi\n# Northwest Territories\tCanada\n# Yukon\tCanada\n# NaN\tKosovo\n# NaN\tMS Zaandam\n# NaN\tSierra Leone\n# Anguilla\tUnited Kingdom\n# British Virgin Islands\tUnited Kingdom\n# Turks and Caicos Islands\tUnited Kingdom","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # # Single country assessment\n# pd.plotting.register_matplotlib_converters()\n\n# # # Investigating how Niger can be improved\n\n# # Generate training data\n# country = 'Australia'\n# train_data = filter_train_data_for_public_leaderboard(train_data)\n\n# # For countries with state and country\n# # niger_data = niger_data[pd.isnull(niger_data['Province_State'])]\n# niger_data = filter_by_country(country, train_data)\n# niger_data = filter_by_state('New South Wales', niger_data)\n\n# # Make predictions\n# niger_result = make_prediction_for_countries(niger_data)\n# niger_result['Province_State'] = 'New South Wales'\n# niger_result[['PredictedFatalities']] = niger_result[['PredictedFatalities']].fillna(0)\n# niger_result[['PredictedConfirmedCases']] = niger_result[['PredictedConfirmedCases']].fillna(0)\n# # print(max(niger_result.Date))\n\n# # Generate validation data\n# niger_validation_data = filter_by_country(country, \n#                                           pd.read_csv(\"/kaggle/input/covid19-global-forecasting-week-3/train.csv\"))\n# # For countries with state and country\n# # niger_validation_data = niger_validation_data[pd.isnull(niger_validation_data['Province_State'])]\n# niger_validation_data = filter_by_state('New South Wales', niger_validation_data)\n\n# niger_validation_data['Date'] = pd.to_datetime(niger_validation_data['Date'])\n# after_26 = niger_validation_data.loc[niger_validation_data.Date >= '2020-03-26']\n\n# # after_26.head()\n# # Merge forecast and validation data for comparison\n# merged_result = after_26.merge(niger_result, how='left', on=['Date', 'Country_Region', 'Province_State'])\n# # after_26.plot(x='Date', y='ConfirmedCases', figsize=(6,6), grid=True)\n# # niger_result.plot(x='Date', y='PredictedConfirmedCases', figsize=(6,6), grid=True)\n# merged_result.plot(x='Date', y=['ConfirmedCases', 'PredictedConfirmedCases'], legend=True, figsize=(6,6), grid=True)\n# merged_result.plot(x='Date', y=['Fatalities', 'PredictedFatalities'], legend=True, figsize=(6,6), grid=True)\n# plt.show()\n# # print(rmsle(merged_result[['ConfirmedCases']], merged_result[['PredictedConfirmedCases']]))\n# print(merged_result.head())\n# merged_result.head()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}