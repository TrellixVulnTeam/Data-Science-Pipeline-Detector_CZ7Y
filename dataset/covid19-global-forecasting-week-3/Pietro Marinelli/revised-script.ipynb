{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport datetime\n\nimport lightgbm as lgb\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#RISCRIVI SCRIPT CELLA PER CELLA","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lat_long = pd.read_csv(\"../input/corona-virus-report/covid_19_clean_complete.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lat_long = lat_long[['Province/State','Country/Region','Lat','Long']].drop_duplicates() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lat_long.columns = ['Province_State', 'Country_Region', 'Lat', 'Long']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\")\nsub = pd.read_csv(\"../input/covid19-global-forecasting-week-3/submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat_col in ['Province_State', 'Country_Region']:\n    train[cat_col].fillna('no_value', inplace = True)\n    test[cat_col].fillna('no_value', inplace = True)\n    lat_long[cat_col].fillna('no_value', inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \n\ntrain['place'] = train['Province_State']+'_'+train['Country_Region']\ntest['place'] = test['Province_State']+'_'+test['Country_Region']\nlat_long['place'] = lat_long['Province_State']+'_'+lat_long['Country_Region']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sort_values(by='Date')\ntrain['Fatalities'] = train.groupby(['place'])['Fatalities'].cummax()\ntrain['ConfirmedCases'] = train.groupby(['place'])['ConfirmedCases'].cummax()\ntrain = train.sort_values(by='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train,lat_long[['place','Lat','Long']], on=['place'], how='left')\ntest = pd.merge(test,lat_long[['place','Lat','Long']], on=['place'],how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train))\nprint(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_date_pp = train['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_date_pp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_date = test['Date'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.loc[(train['Date']=='2020-03-24')&(train['Country_Region']=='France')&(train['Province_State']=='France'),'ConfirmedCases'] = 22654\n#train.loc[(train['Date']=='2020-03-24')&(train['Country_Region']=='France')&(train['Province_State']=='France'),'Fatalities'] = 1000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train.loc[(train['Date']=='2020-03-24')&(train['Country_Region']=='France')&(train['Province_State']=='France')]#,'ConfirmedCases']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train['Date']<lb_date].append(test[test['Date']<=lb_date_pp])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime \ntrain['Date'] = pd.to_datetime(train['Date'], format='%Y-%m-%d')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['day_dist'] = train['Date']-train['Date'].min()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['day_dist'] = train['day_dist'].dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Date'].max())\n#print(val['Date'].max())\nprint(test['Date'].min())\nprint(test['Date'].max())\n#print(test['Date'].max()-test['Date'].min())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = train.dtypes[train.dtypes=='object'].keys()\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_cols = train.dtypes[train.dtypes=='object'].keys()\ncat_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat_col in ['place']:\n    #train[cat_col].fillna('no_value', inplace = True) #train[cat_col].value_counts().idxmax()\n    le = preprocessing.LabelEncoder()\n    le.fit(train[cat_col])\n    train[cat_col]=le.transform(train[cat_col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols_cc = ['Id','ForecastId', 'ConfirmedCases','Date', 'Fatalities','day_dist', 'Province_State', 'Country_Region'] #,'day_dist','shift_22_ft','shift_23_ft','shift_24_ft','shift_25_ft','shift_26_ft']\ndrop_cols_ft = ['Id','ForecastId', 'ConfirmedCases','Date', 'Fatalities','day_dist', 'Province_State', 'Country_Region']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#val = train[(train['Id']).isnull()==True]\n#train = train[(train['Id']).isnull()==False]\nval = train[(train['Date']>lb_date)&(train['Id'].isnull()==False)]\n#test = train[(train['Date']>='2020-03-12')&(train['Id'].isnull()==True)]\n#train = train[(train['Date']<'2020-03-22')&(train['Id'].isnull()==False)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle (y_true, y_pred):\n    return np.sqrt(np.mean(np.power(np.log1p(y_pred) - np.log1p(y_true), 2)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def mape (y_true, y_pred):\n    return np.mean(np.abs(y_pred -y_true)*100/(y_true+1))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 12\nparams = {'num_leaves': 8,\n          'min_data_in_leaf': 5,  # 42,\n          'objective': 'regression',\n          'max_depth': 8,\n          'learning_rate': 0.02,\n          'boosting': 'gbdt',\n          'bagging_freq': 5,  # 5\n          'bagging_fraction': 0.8,  # 0.5,\n          'feature_fraction': 0.8201,\n          'bagging_seed': SEED,\n          'reg_alpha': 1,  # 1.728910519108444,\n          'reg_lambda': 4.9847051755586085,\n          'random_state': SEED,\n          'metric': 'mse',\n          'verbosity': 100,\n          'min_gain_to_split': 0.02,  # 0.01077313523861969,\n          'min_child_weight': 5,  # 19.428902804238373,\n          'num_threads': 6,\n          }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = test['Date'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates_pp = dates[dates>lb_date_pp]\ndates = dates[(dates<=lb_date_pp)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_date","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=5\ni = 0\nfold_n = 0\nfor date in dates:\n\n    fold_n = fold_n +1 \n    i =  i+1\n    if i==1:\n        nrounds = 200\n    else:\n        nrounds = 100\n    print(i)\n    print(nrounds)\n    #train['shift_0_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(1)\n    train['shift_1_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i)\n    train['shift_2_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+1)\n    train['shift_3_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+2)\n    train['shift_4_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+3)\n    train['shift_5_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+4)\n    train['shift_7_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+6)\n    train['shift_14_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*2)\n    train['shift_56_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*8)\n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=1), on=['Country_Region'], suffixes = ['', '_autoc_1']) \n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=10), on=['Country_Region'], suffixes = ['', '_autoc_10']) \n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=2), on=['Country_Region'], suffixes = ['', '_autoc_2']) \n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=5), on=['Country_Region'], suffixes = ['', '_autoc_5']) \n    print(nrounds)\n    #train['shift_22_ft'] = train.groupby(['place'])['Fatalities'].shift(i)\n    #train['shift_23_ft'] = train.groupby(['place'])['Fatalities'].shift(i+1)\n    #train['shift_24_ft'] = train.groupby(['place'])['Fatalities'].shift(i+2)\n    #train['shift_25_ft'] = train.groupby(['place'])['Fatalities'].shift(i+3)\n    #train['shift_26_ft'] = train.groupby(['place'])['Fatalities'].shift(i+4)\n    \n    #train['shift_22_ft'] = train['shift_22_ft']*100/train['shift_1_cc']\n    #train['shift_23_ft'] = train['shift_23_ft']*100/train['shift_2_cc']\n    #train['shift_24_ft'] = train['shift_24_ft']*100/train['shift_3_cc']\n    #train['shift_25_ft'] = train['shift_25_ft']*100/train['shift_4_cc']\n    #train['shift_26_ft'] = train['shift_26_ft']*100/train['shift_5_cc']\n\n    #train['diff_1_7_cc'] = (train['shift_1_cc']-train['shift_7_cc'])#/train['shift_1_cc']\n    #train['diff_1_14_cc'] = (train['shift_1_cc']-train['shift_14_cc'])#/train['shift_1_cc']\n    #train['diff_1_56_cc'] = (train['shift_1_cc']-train['shift_56_cc'])#/train['shift_1_cc']\n    train['diff_23_24_cc'] = (train['shift_3_cc']-train['shift_2_cc'])#/train['shift_2_cc']\n    train['diff_24_25_cc'] = (train['shift_5_cc']-train['shift_4_cc'])#/train['shift_4_cc']\n    train['diff_22_24_cc'] = (train['shift_4_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    train['diff_22_25_cc'] = (train['shift_5_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    print(nrounds)\n    #train['moving_avg_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].max().reset_index(0,drop=True)\n\n        \n    val2 = train[train['Date']==date]\n    train2 = train[(train['Date']<lb_date)] #date\n    y_cc = np.log1p(train2[\"ConfirmedCases\"])-np.log1p(train2['shift_1_cc'] )\n    #y_val_cc = val2[\"ConfirmedCases\"]\n    \n    train2.drop(drop_cols_cc, axis=1, inplace=True)\n    val2.drop(drop_cols_cc, axis=1, inplace=True)\n    print(\"check 1\")\n    #np.log1p(y)\n    #feature_importances = pd.DataFrame()\n    #feature_importances['feature'] = train.keys()\n    \n    #score = 0       \n    dtrain = lgb.Dataset(train2, label=y_cc)\n    #dvalid = lgb.Dataset(val2, label=y_val_cc)\n    print(\"check 2\")\n    model = lgb.train(params, dtrain, nrounds, \n                            #valid_sets = [dtrain, dvalid],\n                            categorical_feature = ['place'], #'Province/State', 'Country/Region'\n                            verbose_eval=False)#, early_stopping_rounds=50)\n\n    y_pred = model.predict(val2,num_iteration=nrounds)  #model.best_iteration\n    print(\"check 3\")\n    #y_pred = np.expm1( y_pred)\n    #vcheck.loc[vcheck['Date']==date,'cc_predict'] = y_pred\n    test.loc[test['Date']==date,'ConfirmedCases'] = np.expm1(y_pred+ np.log1p(train.loc[train['Date']==date,'shift_1_cc']))\n    #train.loc[train['Date']==date,'ConfirmedCases'] = np.expm1(y_pred+ np.log1p(train.loc[train['Date']==date,'shift_1_cc']))\n    print(\"check 4\")\n    #y_oof[valid_index] = y_pred\n\n    #rmsle_score = rmsle(y_val_cc, y_pred)\n    #mape_score = mape(y_val_cc, y_pred)\n    #score += rmsle_score\n    #print (f'fold: {date}, rmsle: {rmsle_score:.5f}' )\n    #print (f'fold: {date}, mape: {mape_score:.5f}' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.float_format', '{:.2f}'.format)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train = train.sort_values(by='Date')\n#train['Fatalities'] = train.groupby(['place'])['Fatalities'].cummax()\n#train['ConfirmedCases'] = train.groupby(['place'])['ConfirmedCases'].cummax()\n#train = train.sort_values(by='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test['Country_Region']=='Italy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred.mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfold_n = 0\nfor date in dates:\n\n    fold_n = fold_n +1 \n    i = i+1\n    if i==1:\n        nrounds = 200\n    else:\n        nrounds = 100\n    print(i)\n    print(nrounds)\n    #i =  i+1\n    train['shift_1_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i)\n    train['shift_2_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+1)\n    train['shift_3_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+2)\n    train['shift_4_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+3)\n    train['shift_5_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+4)\n    train['shift_7_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+6)\n    train['shift_14_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*2)\n    train['shift_56_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*8)\n    \n    #train['shift_0_ft'] = train.groupby(['place'])['Fatalities'].shift(1)\n    train['shift_1_ft'] = train.groupby(['place'])['Fatalities'].shift(i)\n    train['shift_2_ft'] = train.groupby(['place'])['Fatalities'].shift(i+1)\n    train['shift_3_ft'] = train.groupby(['place'])['Fatalities'].shift(i+2)\n    train['shift_4_ft'] = train.groupby(['place'])['Fatalities'].shift(i+3)\n    train['shift_5_ft'] = train.groupby(['place'])['Fatalities'].shift(i+4)\n    train['shift_7_ft'] = train.groupby(['place'])['Fatalities'].shift(i+6)\n    train['shift_14_ft'] = train.groupby(['place'])['Fatalities'].shift((i+6)*2)\n    train['shift_56_ft'] = train.groupby(['place'])['Fatalities'].shift((i+6)*8)\n    \n\n    \n\n    train['diff_1_7_cc'] = (train['shift_1_cc']-train['shift_7_cc'])#/train['shift_1_cc']\n    train['diff_1_14_cc'] = (train['shift_1_cc']-train['shift_14_cc'])#/train['shift_1_cc']\n    train['diff_1_56_cc'] = (train['shift_1_cc']-train['shift_56_cc'])#/train['shift_1_cc']\n    #train['diff_23_24_cc'] = (train['shift_3_cc']-train['shift_2_cc'])#/train['shift_2_cc']\n    #train['diff_24_25_cc'] = (train['shift_5_cc']-train['shift_4_cc'])#/train['shift_4_cc']\n    #train['diff_22_24_cc'] = (train['shift_4_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    #train['diff_22_25_cc'] = (train['shift_5_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    \n    train['diff_1_7_ft'] = (train['shift_1_ft']-train['shift_7_ft'])#/train['shift_1_ft']\n    train['diff_1_14_ft'] = (train['shift_1_ft']-train['shift_14_ft'])#/train['shift_1_ft']\n    train['diff_1_56_ft'] = (train['shift_1_ft']-train['shift_56_ft'])#/train['shift_1_ft']\n    train['diff_23_24_ft'] = (train['shift_3_ft']-train['shift_2_ft'])#/train['shift_2_ft']\n    train['diff_24_25_ft'] = (train['shift_5_ft']-train['shift_4_ft'])#/train['shift_4_ft']\n    train['diff_22_24_ft'] = (train['shift_4_ft']-train['shift_1_ft'])#/train['shift_1_ft']\n    train['diff_22_25_ft'] = (train['shift_5_ft']-train['shift_1_ft'])#/train['shift_1_ft']\n    \n    #train['moving_avg_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].max().reset_index(0,drop=True)\n    \n    #train['moving_avg_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].max().reset_index(0,drop=True)\n    \n    #train['moving_avg_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].max().reset_index(0,drop=True)\n \n        \n    val2 = train[train['Date']==date]\n    train2 = train[(train['Date']<lb_date)] #date\n    y_ft = np.log1p(train2[\"Fatalities\"])-np.log1p(train2['shift_1_ft'] )\n    #y_val_cc = val2[\"ConfirmedCases\"]\n    \n    train2.drop(drop_cols_ft, axis=1, inplace=True)\n    val2.drop(drop_cols_ft, axis=1, inplace=True)\n    \n    #np.log1p(y)\n    #feature_importances = pd.DataFrame()\n    #feature_importances['feature'] = train.keys()\n    \n    #score = 0       \n    dtrain = lgb.Dataset(train2, label=y_ft)\n    #dvalid = lgb.Dataset(val2, label=y_val_ft)\n\n    model = lgb.train(params, dtrain, nrounds, \n                            #valid_sets = [dtrain, dvalid],\n                            categorical_feature = ['place'], #'Province/State', 'Country/Region'\n                            verbose_eval=False)#, early_stopping_rounds=50)\n\n    y_pred = model.predict(val2,num_iteration=nrounds)  #model.best_iteration\n    #y_pred = np.expm1( y_pred)\n    #vcheck.loc[vcheck['Date']==date,'cc_predict'] = y_pred\n    test.loc[test['Date']==date,'Fatalities'] = np.expm1(y_pred + np.log1p(val2['shift_1_ft']))\n    #train.loc[train['Date']==date,'Fatalities'] = np.expm1(y_pred+ np.log1p(val2['shift_1_ft']))\n    #y_oof[valid_index] = y_pred\n\n    #rmsle_score = rmsle(y_val_cc, y_pred)\n    #mape_score = mape(y_val_cc, y_pred)\n    #score += rmsle_score\n    #print (f'fold: {date}, rmsle: {rmsle_score:.5f}' )\n    #print (f'fold: {date}, mape: {mape_score:.5f}' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test['Country_Region']=='Italy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")\n#test = pd.read_csv(\"../input/covid19-global-forecasting-week-2/test.csv\")\nsub = pd.read_csv(\"../input/covid19-global-forecasting-week-3/submission.csv\")\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for cat_col in ['Province_State', 'Country_Region']:\n    train[cat_col].fillna('no_value', inplace = True)\n\n\ntrain['place'] = train['Province_State']+'_'+train['Country_Region']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(train,lat_long[['place','Lat','Long']], on=['place'], how='left')\n#test = pd.merge(test,lat_long, on=['Province_State','Country_Region'],how='left')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.sort_values(by='Date')\ntrain['Fatalities'] = train.groupby(['place'])['Fatalities'].cummax()\ntrain['ConfirmedCases'] = train.groupby(['place'])['ConfirmedCases'].cummax()\ntrain = train.sort_values(by='Id')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_date_pp = train['Date'].max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lb_date_pp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.append(test[test['Date']>lb_date_pp])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime \ntrain['Date'] = pd.to_datetime(train['Date'], format='%Y-%m-%d')\ntrain['day_dist'] = train['Date']-train['Date'].min()\ntrain['day_dist'] = train['day_dist'].dt.days","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\ncat_cols = train.dtypes[train.dtypes=='object'].keys()\ncat_cols\nfor cat_col in ['place']:\n    #train[cat_col].fillna('no_value', inplace = True) #train[cat_col].value_counts().idxmax()\n    le = preprocessing.LabelEncoder()\n    le.fit(train[cat_col])\n    train[cat_col]=le.transform(train[cat_col])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates = test['Date'].unique()\ndates_pp = dates[dates>lb_date_pp]\ndates = dates[dates>lb_date]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dates_pp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['Country_Region']=='Italy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k=5\ni = 0\nfold_n = 0\nfor date in dates_pp:\n\n    fold_n = fold_n +1 \n    i = i+1\n    if i==1:\n        nrounds = 200\n    else:\n        nrounds = 100\n    print(i)\n    print(nrounds)\n    \n    #train['shift_0_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(1)\n    train['shift_1_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i)\n    train['shift_2_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+1)\n    train['shift_3_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+2)\n    train['shift_4_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+3)\n    train['shift_5_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+4)\n    train['shift_7_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+6)\n    train['shift_14_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*2)\n    train['shift_56_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*8)\n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=1), on=['Country_Region'], suffixes = ['', '_autoc_1']) \n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=10), on=['Country_Region'], suffixes = ['', '_autoc_10']) \n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=2), on=['Country_Region'], suffixes = ['', '_autoc_2']) \n    #train = train.merge(train.groupby(['Country_Region'])['ConfirmedCases'].apply(pd.Series.autocorr, lag=5), on=['Country_Region'], suffixes = ['', '_autoc_5']) \n    print(nrounds)\n    #train['shift_22_ft'] = train.groupby(['place'])['Fatalities'].shift(i)\n    #train['shift_23_ft'] = train.groupby(['place'])['Fatalities'].shift(i+1)\n    #train['shift_24_ft'] = train.groupby(['place'])['Fatalities'].shift(i+2)\n    #train['shift_25_ft'] = train.groupby(['place'])['Fatalities'].shift(i+3)\n    #train['shift_26_ft'] = train.groupby(['place'])['Fatalities'].shift(i+4)\n    \n    #train['shift_22_ft'] = train['shift_22_ft']*100/train['shift_1_cc']\n    #train['shift_23_ft'] = train['shift_23_ft']*100/train['shift_2_cc']\n    #train['shift_24_ft'] = train['shift_24_ft']*100/train['shift_3_cc']\n    #train['shift_25_ft'] = train['shift_25_ft']*100/train['shift_4_cc']\n    #train['shift_26_ft'] = train['shift_26_ft']*100/train['shift_5_cc']\n\n    #train['diff_1_7_cc'] = (train['shift_1_cc']-train['shift_7_cc'])#/train['shift_1_cc']\n    #train['diff_1_14_cc'] = (train['shift_1_cc']-train['shift_14_cc'])#/train['shift_1_cc']\n    #train['diff_1_56_cc'] = (train['shift_1_cc']-train['shift_56_cc'])#/train['shift_1_cc']\n    train['diff_23_24_cc'] = (train['shift_3_cc']-train['shift_2_cc'])#/train['shift_2_cc']\n    train['diff_24_25_cc'] = (train['shift_5_cc']-train['shift_4_cc'])#/train['shift_4_cc']\n    train['diff_22_24_cc'] = (train['shift_4_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    train['diff_22_25_cc'] = (train['shift_5_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    print(nrounds)\n    #train['moving_avg_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].max().reset_index(0,drop=True)\n    print(\"aoooo\")\n    #train['moving_avg_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].max().reset_index(0,drop=True)\n    print(\"aoooo\")\n        \n    val2 = train[train['Date']==date]\n    train2 = train[(train['Date']<date)]\n    y_cc = np.log1p(train2[\"ConfirmedCases\"])-np.log1p(train2['shift_1_cc'] )\n    #y_val_cc = val2[\"ConfirmedCases\"]\n    \n    train2.drop(drop_cols_cc, axis=1, inplace=True)\n    val2.drop(drop_cols_cc, axis=1, inplace=True)\n    \n    #np.log1p(y)\n    #feature_importances = pd.DataFrame()\n    #feature_importances['feature'] = train.keys()\n    \n    #score = 0       \n    dtrain = lgb.Dataset(train2, label=y_cc)\n    #dvalid = lgb.Dataset(val2, label=y_val_cc)\n\n    model = lgb.train(params, dtrain, nrounds, \n                            #valid_sets = [dtrain, dvalid],\n                            categorical_feature = ['place'], #'Province/State', 'Country/Region'\n                            verbose_eval=False)#, early_stopping_rounds=50)\n\n    y_pred = model.predict(val2,num_iteration=nrounds)  #model.best_iteration\n    #y_pred = np.expm1( y_pred)\n    #vcheck.loc[vcheck['Date']==date,'cc_predict'] = y_pred\n    test.loc[test['Date']==date,'ConfirmedCases'] = np.expm1(y_pred+ np.log1p(train.loc[train['Date']==date,'shift_1_cc']))\n    #train.loc[train['Date']==date,'ConfirmedCases'] = np.expm1(y_pred+ np.log1p(train.loc[train['Date']==date,'shift_1_cc']))\n    #y_oof[valid_index] = y_pred\n\n    #rmsle_score = rmsle(y_val_cc, y_pred)\n    #mape_score = mape(y_val_cc, y_pred)\n    #score += rmsle_score\n    #print (f'fold: {date}, rmsle: {rmsle_score:.5f}' )\n    #print (f'fold: {date}, mape: {mape_score:.5f}' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test['Country_Region']=='Italy']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"i = 0\nfold_n = 0\nfor date in dates_pp:\n\n    fold_n = fold_n +1 \n    i = i+1\n    if i==1:\n        nrounds = 200\n    else:\n        nrounds = 100\n    print(i)\n    print(nrounds)\n    \n    train['shift_1_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i)\n    train['shift_2_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+1)\n    train['shift_3_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+2)\n    train['shift_4_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+3)\n    train['shift_5_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+4)\n    train['shift_7_cc'] = train.groupby(['place'])['ConfirmedCases'].shift(i+6)\n    train['shift_14_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*2)\n    train['shift_56_cc'] = train.groupby(['place'])['ConfirmedCases'].shift((i+6)*8)\n    \n    #train['shift_0_ft'] = train.groupby(['place'])['Fatalities'].shift(1)\n    train['shift_1_ft'] = train.groupby(['place'])['Fatalities'].shift(i)\n    train['shift_2_ft'] = train.groupby(['place'])['Fatalities'].shift(i+1)\n    train['shift_3_ft'] = train.groupby(['place'])['Fatalities'].shift(i+2)\n    train['shift_4_ft'] = train.groupby(['place'])['Fatalities'].shift(i+3)\n    train['shift_5_ft'] = train.groupby(['place'])['Fatalities'].shift(i+4)\n    train['shift_7_ft'] = train.groupby(['place'])['Fatalities'].shift(i+6)\n    train['shift_14_ft'] = train.groupby(['place'])['Fatalities'].shift((i+6)*2)\n    train['shift_56_ft'] = train.groupby(['place'])['Fatalities'].shift((i+6)*8)\n    \n\n    \n\n    train['diff_1_7_cc'] = (train['shift_1_cc']-train['shift_7_cc'])#/train['shift_1_cc']\n    train['diff_1_14_cc'] = (train['shift_1_cc']-train['shift_14_cc'])#/train['shift_1_cc']\n    train['diff_1_56_cc'] = (train['shift_1_cc']-train['shift_56_cc'])#/train['shift_1_cc']\n    #train['diff_23_24_cc'] = (train['shift_3_cc']-train['shift_2_cc'])#/train['shift_2_cc']\n    #train['diff_24_25_cc'] = (train['shift_5_cc']-train['shift_4_cc'])#/train['shift_4_cc']\n    #train['diff_22_24_cc'] = (train['shift_4_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    #train['diff_22_25_cc'] = (train['shift_5_cc']-train['shift_1_cc'])#/train['shift_1_cc']\n    \n    train['diff_1_7_ft'] = (train['shift_1_ft']-train['shift_7_ft'])#/train['shift_1_ft']\n    train['diff_1_14_ft'] = (train['shift_1_ft']-train['shift_14_ft'])#/train['shift_1_ft']\n    train['diff_1_56_ft'] = (train['shift_1_ft']-train['shift_56_ft'])#/train['shift_1_ft']\n    train['diff_23_24_ft'] = (train['shift_3_ft']-train['shift_2_ft'])#/train['shift_2_ft']\n    train['diff_24_25_ft'] = (train['shift_5_ft']-train['shift_4_ft'])#/train['shift_4_ft']\n    train['diff_22_24_ft'] = (train['shift_4_ft']-train['shift_1_ft'])#/train['shift_1_ft']\n    train['diff_22_25_ft'] = (train['shift_5_ft']-train['shift_1_ft'])#/train['shift_1_ft']\n    \n    #train['moving_avg_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_22_cc'] = train.groupby(['place']).rolling(k)['shift_1_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_23_cc'] = train.groupby(['place']).rolling(k)['shift_2_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_24_cc'] = train.groupby(['place']).rolling(k)['shift_3_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_25_cc'] = train.groupby(['place']).rolling(k)['shift_14_cc'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].mean().reset_index(0,drop=True)\n    #train['moving_var_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].var().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].min().reset_index(0,drop=True)\n    #train['moving_min_26_cc'] = train.groupby(['place']).rolling(k)['shift_56_cc'].max().reset_index(0,drop=True)\n    \n    #train['moving_avg_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_22_ft'] = train.groupby(['place']).rolling(k)['shift_1_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_23_ft'] = train.groupby(['place']).rolling(k)['shift_2_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_24_ft'] = train.groupby(['place']).rolling(k)['shift_3_ft'].max().reset_index(0,drop=True)\n    \n    #train['moving_avg_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_7_ft'] = train.groupby(['place']).rolling(k)['shift_7_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_25_ft'] = train.groupby(['place']).rolling(k)['shift_14_ft'].max().reset_index(0,drop=True)\n\n    #train['moving_avg_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].mean().reset_index(0,drop=True)\n    #train['moving_var_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].var().reset_index(0,drop=True)\n    #train['moving_min_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].min().reset_index(0,drop=True)\n    #train['moving_min_26_ft'] = train.groupby(['place']).rolling(k)['shift_56_ft'].max().reset_index(0,drop=True)\n \n        \n    val2 = train[train['Date']==date]\n    train2 = train[(train['Date']<date)]\n    y_ft =  np.log1p(train2[\"Fatalities\"])-np.log1p(train2['shift_1_ft'] )\n    #y_val_cc = val2[\"ConfirmedCases\"]\n    \n    train2.drop(drop_cols_ft, axis=1, inplace=True)\n    val2.drop(drop_cols_ft, axis=1, inplace=True)\n    \n    #np.log1p(y)\n    #feature_importances = pd.DataFrame()\n    #feature_importances['feature'] = train.keys()\n    \n    #score = 0       \n    dtrain = lgb.Dataset(train2, label=y_ft)\n    #dvalid = lgb.Dataset(val2, label=y_val_ft)\n\n    model = lgb.train(params, dtrain, nrounds, \n                            #valid_sets = [dtrain, dvalid],\n                            categorical_feature = ['place'], #'Province/State', 'Country/Region'\n                            verbose_eval=False)#, early_stopping_rounds=50)\n\n    y_pred = model.predict(val2,num_iteration=nrounds)  #model.best_iteration\n    #y_pred = np.expm1( y_pred)\n    #vcheck.loc[vcheck['Date']==date,'cc_predict'] = y_pred\n    test.loc[test['Date']==date,'Fatalities'] = np.expm1(y_pred+ np.log1p(val2['shift_1_ft']))\n    #train.loc[train['Date']==date,'Fatalities'] = np.expm1(y_pred+ np.log1p(val2['shift_1_ft']))\n    #y_oof[valid_index] = y_pred\n\n    #rmsle_score = rmsle(y_val_cc, y_pred)\n    #mape_score = mape(y_val_cc, y_pred)\n    #score += rmsle_score\n    #print (f'fold: {date}, rmsle: {rmsle_score:.5f}' )\n    #print (f'fold: {date}, mape: {mape_score:.5f}' )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[(test['Country_Region']=='Italy')&(test['Date']>='2020-03-26')][['Date','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[(train['Country_Region']=='Spain')&(train['Date']>='2020-03-26')][['Date','ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = test[['ForecastId', 'ConfirmedCases','Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[sub['ConfirmedCases']<0, 'ConfirmedCases'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.loc[sub['Fatalities']<0, 'Fatalities'] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['Fatalities'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub['ConfirmedCases'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}