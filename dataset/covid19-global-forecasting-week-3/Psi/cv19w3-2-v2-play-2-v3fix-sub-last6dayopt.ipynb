{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import os\nimport datetime\nimport numpy as np\nimport pandas as pd\nimport time\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error\nfrom tqdm.notebook import tqdm\n\npath = '../input/covid19-global-forecasting-week-3/'\ntrain = pd.read_csv(path + 'train.csv')\ntest  = pd.read_csv(path + 'test.csv')\nsub   = pd.read_csv(path + 'submission.csv')\n\ntrain['Date'] = train['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))\ntest['Date'] = test['Date'].apply(lambda x: (datetime.datetime.strptime(x, '%Y-%m-%d')))\n#path_ext = '../input/novel-corona-virus-2019-dataset/'\n#ext_rec = pd.read_csv(path_ext + 'time_series_covid_19_recovered.csv').\\\n#        melt(id_vars=[\"Province/State\", \"Country/Region\", \"Lat\", \"Long\"], \n#            var_name=\"Date\", \n#            value_name=\"Recoveries\")\n#ext_rec['Date'] = ext_rec['Date'].apply(lambda x: (datetime.datetime.strptime(x+\"20\", '%m/%d/%Y')))\n#train = train.merge(ext_rec[['Province/State', 'Country/Region', 'Date', 'Recoveries']], how='left',\n#           left_on=['Province/State', 'Country/Region', 'Date'],\n#           right_on=['Province/State', 'Country/Region', 'Date'])\n\ntrain['days'] = (train['Date'].dt.date - train['Date'].dt.date.min()).dt.days\ntest['days'] = (test['Date'].dt.date - train['Date'].dt.date.min()).dt.days\n#train['isTest'] = train['Date'].dt.date >= datetime.date(2020, 3, 12)\n#train['isVal'] = np.logical_and(train['Date'].dt.date >= datetime.date(2020, 3, 11), train['Date'].dt.date <= datetime.date(9999, 3, 18))\ntrain.loc[train['Province_State'].isnull(), 'Province_State'] = 'N/A'\ntest.loc[test['Province_State'].isnull(), 'Province_State'] = 'N/A'\n\ntrain['Area'] = train['Country_Region'] + '_' + train['Province_State']\ntest['Area'] = test['Country_Region'] + '_' + test['Province_State']\n\nprint(train['Date'].max())\nprint(test['Date'].min())\nprint(train['days'].max())\nN_AREAS = train['Area'].nunique()\nAREAS = np.sort(train['Area'].unique())\n#TRAIN_N = 64\nTRAIN_N = 77\n\nprint(train[train['days'] < TRAIN_N]['Date'].max())\nprint(train[train['days'] >= TRAIN_N]['Date'].min())\nprint(train[train['days'] >= TRAIN_N]['Date'].max())\ntrain.head()\n\ntest_orig = test.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_p_c_raw = train.pivot(index='Area', columns='days', values='ConfirmedCases').sort_index()\ntrain_p_f_raw = train.pivot(index='Area', columns='days', values='Fatalities').sort_index()\n\ntrain_p_c = np.maximum.accumulate(train_p_c_raw, axis=1)\ntrain_p_f = np.maximum.accumulate(train_p_f_raw, axis=1)\n\nf_rate = (train_p_f / train_p_c).fillna(0)\n\nX_c = np.log(1+train_p_c.values)[:,:TRAIN_N]\nX_f = train_p_f.values[:,:TRAIN_N]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import mean_squared_error\n\ndef eval1(y, p):\n    val_len = y.shape[1] - TRAIN_N\n    return np.sqrt(mean_squared_error(y[:, TRAIN_N:TRAIN_N+val_len].flatten(), p[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n\ndef run_c(params, X, test_size=50):\n    \n    gr_base = []\n    gr_base_factor = []\n    \n    x_min = np.ma.MaskedArray(X, X<1)\n    x_min = x_min.argmin(axis=1) \n    \n    for i in range(X.shape[0]):\n        temp = X[i,:]\n        threshold = np.log(1+params['min cases for growth rate'])\n        num_days = params['last N days']\n        if (temp > threshold).sum() > num_days:\n            d = np.diff(temp[temp > threshold])[-num_days:]\n            w = np.arange(len(d))+1\n            w = w**5\n            w = w / np.sum(w)\n            gr_base.append(np.clip(np.average(d, weights=w), 0, params['growth rate max']))\n            d2 = np.diff(d)\n            w = np.arange(len(d2))+1\n            w = w**10\n            w = w / np.sum(w)\n            gr_base_factor.append(np.clip(np.average(d2, weights=w), -0.5, params[\"growth rate factor max\"]))\n        else:\n            gr_base.append(params['growth rate default'])\n            gr_base_factor.append(params['growth rate factor'])\n\n    gr_base = np.array(gr_base)\n    gr_base_factor = np.array(gr_base_factor)\n    #print(gr_base_factor)\n    #gr_base = np.clip(gr_base, 0.02, 0.8)\n    preds = X.copy()\n\n    for i in range(test_size):\n        delta = np.clip(preds[:, -1], np.log(2), None) + gr_base * (1 + params['growth rate factor']*(1 + params['growth rate factor factor'])**(i))**(np.log1p(i))\n        #delta = np.clip(preds[:, -1], np.log(2), None) + gr_base * (1 + gr_base_factor*(1 + params['growth rate factor factor'])**(i))**(i)\n        #delta = np.clip(preds[:, -1], np.log(2), None) + gr_base * (1 + params['growth rate factor']*(1 + params['growth rate factor factor'])**(i+X.shape[1]-x_min))**(i+X.shape[1]-x_min) \n        preds = np.hstack((preds, delta.reshape(-1,1)))\n\n    return preds\n\nparams = {\n    \"min cases for growth rate\": 0,\n    \"last N days\": 15,\n    \"growth rate default\": 0.10,\n    \"growth rate max\": 0.2,\n    \"growth rate factor max\": -0.1,\n    \"growth rate factor\": -0.3,\n    \"growth rate factor factor\": 0.01,\n}\n#x = train_p_c[train_p_c.index==\"Austria_N/A\"]\n\nx = train_p_c\n\npreds_c = run_c(params, np.log(1+x.values)[:,:TRAIN_N])\n#eval1(np.log(1+x).values, preds_c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor i in range(N_AREAS):\n    if 'China' in AREAS[i] and preds_c[i, TRAIN_N-1] < np.log(31):\n        preds_c[i, TRAIN_N:] = preds_c[i, TRAIN_N-1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def lin_w(sz):\n    res = np.linspace(0, 1, sz+1, endpoint=False)[1:]\n    return np.append(res, np.append([1], res[::-1]))\n\n\ndef run_f(params, X_c, X_f, X_f_r, test_size=50):\n  \n    X_f_r = np.array(np.ma.mean(np.ma.masked_outside(X_f_r, 0.03, 0.5)[:,:], axis=1))\n    X_f_r = np.clip(X_f_r, params['fatality_rate_lower'], params['fatality_rate_upper'])\n    #print(X_f_r)\n    \n    X_c = np.clip(np.exp(X_c)-1, 0, None)\n    preds = X_f.copy()\n    #print(preds.shape)\n    \n    train_size = X_f.shape[1] - 1\n    for i in range(test_size):\n        \n        t_lag = train_size+i-params['length']\n        t_wsize = 5\n        d = np.diff(X_c, axis=1)[:, t_lag-t_wsize:t_lag+1+t_wsize]\n#         w = np.arange(d.shape[1])[::-1]+1\n#         w = w**1\n#         w = w / np.sum(w)\n        delta = np.average(d, axis=1)\n        #delta = np.average(np.diff(X_c, axis=1)[:, t_lag-t_wsize:t_lag+1+t_wsize], axis=1, weights=lin_w(t_wsize))\n        \n        delta = params['absolute growth'] + delta * X_f_r\n        \n        preds = np.hstack((preds, preds[:, -1].reshape(-1,1) + delta.reshape(-1,1)))\n\n    return preds\n\nparams = {\n    \"length\": 7,\n    \"absolute growth\": 0.02,\n    \"fatality_rate_lower\": 0.02,\n    \"fatality_rate_upper\": 0.3,\n}\n\npreds_f_1 = run_f(params, preds_c, X_f, f_rate.values[:,:TRAIN_N])\npreds_f_1 = np.log(1+preds_f_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.nn import Parameter\nimport torch.nn as nn\nfrom torch.nn import init\nimport math \nimport torch\nimport time\n\nclass ZDatasetF(Dataset):\n    def __init__(self, X_c, X_f=None, hist_len=10):\n        self.X_c = X_c\n        self.X_f = X_f\n        self.hist_len = hist_len\n        self.is_test = X_f is None\n    def __len__(self):\n        return self.X_c.shape[1]\n    def __getitem__(self, idx):\n        if self.is_test:\n            return {'x_c':self.X_c[:, idx-self.hist_len:idx]}\n        else:\n            return {'x_c':self.X_c[:, idx-self.hist_len:idx],\n                    'x_f':self.X_f[:, idx-1],\n                    'y':np.log(1+self.X_f[:, idx])}\n\nclass PrLayer2(nn.Module):\n    def __init__(self, in_features1, in_features2):\n        super(PrLayer2, self).__init__()\n        self.weight0 = Parameter(torch.Tensor(1, 1, in_features2))\n        self.weight1 = Parameter(torch.Tensor(1, in_features1, in_features2))\n        self.reset_parameters()\n    def reset_parameters(self):\n        init.kaiming_uniform_(self.weight0, a=math.sqrt(5))\n        init.kaiming_uniform_(self.weight1, a=math.sqrt(5))\n    def forward(self, input):\n        return input * torch.sigmoid(self.weight0 + self.weight1)\n\n\n\nclass ZModelF(nn.Module):\n\n    def __init__(self, hist_len):\n        super(ZModelF, self).__init__()\n        self.l_conv = PrLayer2(len(X_c),hist_len-1)\n\n    def forward(self, x_c, x_f):\n        x = x_c[:,:,1:] - x_c[:,:,:-1]\n        res = torch.sum(self.l_conv(x), 2)\n        return {'preds': torch.log(1 + x_f + res)}        \n        \n\nclass DummySampler(torch.utils.data.sampler.Sampler):\n    def __init__(self, idx):\n        self.idx = idx\n    def __iter__(self):\n        return iter(self.idx)\n    def __len__(self):\n        return len(self.idx)\n    \n    \ndef _smooth_l1_loss(target):\n    t = torch.abs(target)\n    t = torch.where(t < 1, 0.5 * t ** 2, t - 0.5)\n    return torch.mean(t)\n\n\nn_epochs = 5000\nlr = 0.18\nbag_size = 4\ndevice = 'cpu'\nhist_len = 14\nloss_func = torch.nn.MSELoss()\nreg_loss_func = _smooth_l1_loss\nreg_factor = 0.035\n\n\ntrain_dataset = ZDatasetF(np.exp(X_c)-1, X_f, hist_len=hist_len)\ntest_dataset = ZDatasetF(np.exp(preds_c)-1, hist_len=hist_len)\n\n#trn_idx = np.arange(hist_len+1, len(train_dataset))\ntrn_idx = np.arange(hist_len+1, len(train_dataset))\ntrain_sampler = torch.utils.data.sampler.SubsetRandomSampler(trn_idx)\n#train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, sampler=train_sampler, num_workers=0, pin_memory=True)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=len(trn_idx), sampler=train_sampler, num_workers=0, pin_memory=True)\n\ntest_idx = np.arange(TRAIN_N, len(test_dataset))\ntest_sampler = DummySampler(test_idx)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, sampler=test_sampler, num_workers=0, pin_memory=True)\n\n\n#gradient_accumulation = len(trn_idx)\ngradient_accumulation = 1\n\npreds_f = 0\n\nfor m_i in range(bag_size):\n    model_f = ZModelF(hist_len=hist_len).to(device)\n    optimizer_f = torch.optim.Adam(model_f.parameters(), lr=lr)\n    model_f.train()\n\n    start_time = time.time()\n    for epoch in range(n_epochs):\n\n        s = time.time()\n        avg_train_loss = 0\n        \n        optimizer_f.zero_grad()\n        for idx, data in enumerate(train_loader):\n\n            X1 = data['x_c'].to(device).float()\n            X2 = data['x_f'].to(device).float()\n            y = data['y'].to(device).float()\n            \n            preds = model_f(X1, X2)['preds'].float()\n\n            cond = X2 > np.log(10)\n            preds = preds[cond]\n            y = y[cond]\n            \n            loss = loss_func(preds, y)\n            \n            loss += reg_factor * reg_loss_func(model_f.l_conv.weight1)\n            \n            avg_train_loss += loss  / len(train_loader)\n            \n            loss.backward()\n            if (idx+1) % gradient_accumulation == 0 or idx == len(train_loader) - 1: \n                optimizer_f.step()\n                optimizer_f.zero_grad()\n                \n        #if epoch % 1000 == 0:\n        if False:\n        \n            model_f.eval()\n            preds_f_delta = train_p_f.values[:,:TRAIN_N]\n\n            for idx, data in enumerate(test_loader):\n                X1 = data['x_c'].to(device).float()\n                temp = model_f(X1, torch.Tensor(preds_f_delta[:,-1]).unsqueeze(0))['preds']\n                temp = np.exp(temp.detach().cpu().numpy().reshape(-1,1)) - 1\n                preds_f_delta = np.hstack((preds_f_delta, temp))\n\n            preds_f_delta = np.log(1 + preds_f_delta)\n            val_len = train_p_c.values.shape[1] - TRAIN_N\n\n            m2 = np.sqrt(mean_squared_error(np.log(1 + train_p_f_raw.values[:, TRAIN_N:TRAIN_N+val_len]).flatten(), \\\n                                            preds_f_delta[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n            print(f\"{epoch:2} train_loss {avg_train_loss:<8.4f} val_loss {m2:8.5f} {time.time()-s:<2.2f}\")\n                \n            model_f.train()\n        \n    model_f.eval()\n    preds_f_delta = train_p_f.values[:,:TRAIN_N]\n    \n    for idx, data in enumerate(test_loader):\n        X1 = data['x_c'].to(device).float()\n        temp = model_f(X1, torch.Tensor(preds_f_delta[:,-1]).unsqueeze(0))['preds']\n        temp = np.exp(temp.detach().cpu().numpy().reshape(-1,1)) - 1\n        preds_f_delta = np.hstack((preds_f_delta, temp))\n    preds_f += preds_f_delta / bag_size\n\npreds_f_2 = np.log(1 + preds_f)\n\nprint(\"Done\")\n\n#eval1(np.log(1+train_p_f).values, preds_f_2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds_f = np.average([preds_f_1, preds_f_2], axis=0, weights=[1,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\n\nif False:\n    val_len = train_p_c.values.shape[1] - TRAIN_N\n\n    for i in range(val_len):\n        d = i + TRAIN_N\n        m1 = np.sqrt(mean_squared_error(np.log(1 + train_p_c_raw.values[:, d]), preds_c[:, d]))\n        m2 = np.sqrt(mean_squared_error(np.log(1 + train_p_f_raw.values[:, d]), preds_f[:, d]))\n        print(f\"{d}: {(m1 + m2)/2:8.5f} [{m1:8.5f} {m2:8.5f}]\")\n\n    print()\n\n    m1 = np.sqrt(mean_squared_error(np.log(1 + train_p_c_raw.values[:, TRAIN_N:TRAIN_N+val_len]).flatten(), preds_c[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n    m2 = np.sqrt(mean_squared_error(np.log(1 + train_p_f_raw.values[:, TRAIN_N:TRAIN_N+val_len]).flatten(), preds_f[:, TRAIN_N:TRAIN_N+val_len].flatten()))\n    print(f\"{(m1 + m2)/2:8.5f} [{m1:8.5f} {m2:8.5f}]\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.style.use(['default'])\nfig = plt.figure(figsize = (15, 5))\n\n#idx = worst_idx\n#print(AREAS[idx])\n\nidx = np.where(AREAS == 'Austria_N/A')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='darkblue')\nplt.plot(preds_c[idx], linestyle='--', color='darkblue')\n\nidx = np.where(AREAS == 'Germany_N/A')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='red')\nplt.plot(preds_c[idx], linestyle='--', color='red')\n\n\nidx = np.where(AREAS == 'China_Hubei')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='grey')\nplt.plot(preds_c[idx], linestyle='--', color='grey')\n\n\nidx = np.where(AREAS == 'Iran_N/A')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='green')\nplt.plot(preds_c[idx], linestyle='--', color='green')\n\n\nidx = np.where(AREAS == 'Japan_N/A')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='purple')\nplt.plot(preds_c[idx], linestyle='--', color='purple')\n\n\nidx = np.where(AREAS == 'Brazil_N/A')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='black')\nplt.plot(preds_c[idx], linestyle='--', color='black')\n\n\nidx = np.where(AREAS == 'Denmark_N/A')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='yellow')\nplt.plot(preds_c[idx], linestyle='--', color='yellow')\n\nidx = np.where(AREAS == 'Italy_N/A')[0][0]\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='blue')\nplt.plot(preds_c[idx], linestyle='--', color='blue')\n\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.style.use(['default'])\nfig = plt.figure(figsize = (15, 5))\n\n#idx = worst_idx\n#print(AREAS[idx])\n\nidx = np.where(AREAS == 'Austria_N/A')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='darkblue')\nplt.plot(preds_f[idx], linestyle='--', color='darkblue')\n\nidx = np.where(AREAS == 'Germany_N/A')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='red')\nplt.plot(preds_f[idx], linestyle='--', color='red')\n\n\nidx = np.where(AREAS == 'China_Hubei')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='grey')\nplt.plot(preds_f[idx], linestyle='--', color='grey')\n\n\nidx = np.where(AREAS == 'Iran_N/A')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='green')\nplt.plot(preds_f[idx], linestyle='--', color='green')\n\n\nidx = np.where(AREAS == 'Japan_N/A')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='purple')\nplt.plot(preds_f[idx], linestyle='--', color='purple')\n\n\nidx = np.where(AREAS == 'Brazil_N/A')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='black')\nplt.plot(preds_f[idx], linestyle='--', color='black')\n\n\nidx = np.where(AREAS == 'Denmark_N/A')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='yellow')\nplt.plot(preds_f[idx], linestyle='--', color='yellow')\n\nidx = np.where(AREAS == 'Italy_N/A')[0][0]\nplt.plot(np.log(1+train_p_f.values[idx]), label=AREAS[idx], color='blue')\nplt.plot(preds_f[idx], linestyle='--', color='blue')\n\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.style.use(['default'])\nfig = plt.figure(figsize = (15, 5))\n\nidx = np.random.choice(N_AREAS)\nprint(AREAS[idx])\n\nplt.plot(np.log(1+train_p_c.values[idx]), label=AREAS[idx], color='darkblue')\nplt.plot(preds_c[idx], linestyle='--', color='darkblue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EU_COUNTRIES = ['Austria', 'Italy', 'Belgium', 'Latvia', 'Bulgaria', 'Lithuania', 'Croatia', 'Luxembourg', 'Cyprus', 'Malta', 'Czechia', \n                'Netherlands', 'Denmark', 'Poland', 'Estonia', 'Portugal', 'Finland', 'Romania', 'France', 'Slovakia', 'Germany', 'Slovenia', \n                'Greece', 'Spain', 'Hungary', 'Sweden', 'Ireland']\nEUROPE_OTHER = ['Albania', 'Andorra', 'Bosnia and Herzegovina', 'Liechtenstein', 'Monaco', 'Montenegro', 'North Macedonia',\n                'Norway', 'San Marino', 'Serbia', 'Switzerland', 'Turkey', 'United Kingdom']\nAFRICA = ['Algeria', 'Burkina Faso', 'Cameroon', 'Congo (Kinshasa)', \"Cote d'Ivoire\", 'Egypt', 'Ghana', 'Kenya', 'Madagascar',\n                'Morocco', 'Nigeria', 'Rwanda', 'Senegal', 'South Africa', 'Togo', 'Tunisia', 'Uganda', 'Zambia']\nNORTH_AMERICA = ['US', 'Canada', 'Mexico']\nSOUTH_AMERICA = ['Argentina', 'Bolivia', 'Brazil', 'Chile', 'Colombia', 'Ecuador', 'Paraguay', 'Peru', 'Uruguay', 'Venezuela']\nMIDDLE_EAST = ['Afghanistan', 'Bahrain', 'Iran', 'Iraq', 'Israel', 'Jordan', 'Kuwait', 'Lebanon', 'Oman', 'Qatar', 'Saudi Arabia', 'United Arab Emirates']\nASIA = ['Bangladesh', 'Brunei', 'Cambodia', 'India', 'Indonesia', 'Japan', 'Kazakhstan', 'Korea, South', 'Kyrgyzstan', 'Malaysia',\n                'Pakistan', 'Singapore', 'Sri Lanka', 'Taiwan*', 'Thailand', 'Uzbekistan', 'Vietnam']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plt1(ar, ar2, ax, col='darkblue', linew=0.2):\n    ax.plot(ar2, linestyle='--', linewidth=linew/2, color=col)\n    ax.plot(np.log(1+ar), linewidth=linew, color=col)\n\nplt.style.use(['default'])\nfig, axs = plt.subplots(3, 2, figsize=(18, 15), sharey=True)\n\nX = train_p_c.values\n#X = train_p_f.values\n\nfor ar in range(X.shape[0]):\n    \n    temp = X[ar]\n    temp2 = preds_c[ar]\n    if 'China' in AREAS[ar]:\n        plt1(temp, temp2, axs[0,0])\n    elif AREAS[ar].split('_')[0] in NORTH_AMERICA:\n        plt1(temp, temp2, axs[0,1])\n    elif AREAS[ar].split('_')[0] in EU_COUNTRIES + EUROPE_OTHER:\n        plt1(temp, temp2, axs[1,0])\n    elif AREAS[ar].split('_')[0] in SOUTH_AMERICA + AFRICA:\n        plt1(temp, temp2, axs[1,1])\n    elif AREAS[ar].split('_')[0] in MIDDLE_EAST + ASIA:\n        plt1(temp, temp2, axs[2,0])\n    else:\n        plt1(temp, temp2, axs[2,1])\n\nprint(\"Confirmed Cases\")\naxs[0,0].set_title('China')\naxs[0,1].set_title('North America')\naxs[1,0].set_title('Europe')\naxs[1,1].set_title('Africa + South America')\naxs[2,0].set_title('Asia + Middle East')\naxs[2,1].set_title('Other')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n\ndef plt1(ar, ar2, ax, col='darkblue', linew=0.2):\n    ax.plot(ar2, linestyle='--', linewidth=linew/2, color=col)\n    ax.plot(np.log(1+ar), linewidth=linew, color=col)\n\nplt.style.use(['default'])\nfig, axs = plt.subplots(3, 2, figsize=(18, 15), sharey=True)\n\n#X = train_p_c.values\nX = train_p_f.values\n\nfor ar in range(X.shape[0]):\n    \n    temp = X[ar]\n    temp2 = preds_f[ar]\n    if 'China' in AREAS[ar]:\n        plt1(temp, temp2, axs[0,0])\n    elif AREAS[ar].split('_')[0] in NORTH_AMERICA:\n        plt1(temp, temp2, axs[0,1])\n    elif AREAS[ar].split('_')[0] in EU_COUNTRIES + EUROPE_OTHER:\n        plt1(temp, temp2, axs[1,0])\n    elif AREAS[ar].split('_')[0] in SOUTH_AMERICA + AFRICA:\n        plt1(temp, temp2, axs[1,1])\n    elif AREAS[ar].split('_')[0] in MIDDLE_EAST + ASIA:\n        plt1(temp, temp2, axs[2,0])\n    else:\n        plt1(temp, temp2, axs[2,1])\n\nprint(\"Fatalities\")\naxs[0,0].set_title('China')\naxs[0,1].set_title('North America')\naxs[1,0].set_title('Europe')\naxs[1,1].set_title('Africa + South America')\naxs[2,0].set_title('Asia + Middle East')\naxs[2,1].set_title('Other')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntemp = pd.DataFrame(np.clip(np.exp(preds_c) - 1, 0, None))\ntemp['Area'] = AREAS\ntemp = temp.melt(id_vars='Area', var_name='days', value_name=\"ConfirmedCases\")\n\ntest = test_orig.merge(temp, how='left', left_on=['Area', 'days'], right_on=['Area', 'days'])\n\ntemp = pd.DataFrame(np.clip(np.exp(preds_f) - 1, 0, None))\ntemp['Area'] = AREAS\ntemp = temp.melt(id_vars='Area', var_name='days', value_name=\"Fatalities\")\n\ntest = test.merge(temp, how='left', left_on=['Area', 'days'], right_on=['Area', 'days'])\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv(\"submission.csv\", index=False, columns=[\"ForecastId\", \"ConfirmedCases\", \"Fatalities\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.days.nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, rec in test.groupby('Area').last().sort_values(\"ConfirmedCases\", ascending=False).iterrows():\n    print(f\"{rec['ConfirmedCases']:10.1f} {rec['Fatalities']:10.1f}  {rec['Country_Region']}, {rec['Province_State']}\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"{test.groupby('Area')['ConfirmedCases'].last().sum():10.1f}\")\nprint(f\"{test.groupby('Area')['Fatalities'].last().sum():10.1f}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_p_c = test.pivot(index='Area', columns='days', values='ConfirmedCases').sort_index().values\ntest_p_f = test.pivot(index='Area', columns='days', values='Fatalities').sort_index().values\ndates = test.Date.dt.strftime('%d.%m.%Y').unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Confirmed Cases\")\nfor i in [7,14,21,28,35,42]:\n    print(f'week{i//7-1}  ', dates[i],  f'   {round(test_p_c[:,i].sum(),0):,}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Fatalities\")\nfor i in [7,14,21,28,35,42]:\n    print(f'week{i//7-1}  ', dates[i],  f'   {round(test_p_f[:,i].sum(),0):,}', )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}