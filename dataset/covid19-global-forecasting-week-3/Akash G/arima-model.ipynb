{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"pd.set_option('mode.chained_assignment', None)\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\")\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")\ntrain['Province_State'].fillna('', inplace=True)\ntest['Province_State'].fillna('', inplace=True)\ntrain['Date'] =  pd.to_datetime(train['Date'])\ntest['Date'] =  pd.to_datetime(test['Date'])\ntrain = train.sort_values(['Country_Region','Province_State','Date'])\ntest = test.sort_values(['Country_Region','Province_State','Date'])\n\n# Fix error in train data\ntrain[['ConfirmedCases', 'Fatalities']] = train.groupby(['Country_Region', 'Province_State'])[['ConfirmedCases', 'Fatalities']].transform('cummax') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nimport warnings\n\ndef RMSLE(pred,actual):\n    return np.sqrt(np.mean(np.power((np.log(pred+1)-np.log(actual+1)),2)))\n\nfeature_day = [1,20,50,100,200,500,1000,5000,10000,15000,20000,50000,100000,200000]\ndef CreateInput(data):\n    feature = []\n    for day in feature_day:\n        #Get information in train data\n        data.loc[:,'Number day from ' + str(day) + ' case'] = 0\n        if (train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].count() > 0):\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['ConfirmedCases'] < day)]['Date'].max()        \n        else:\n            fromday = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].min()       \n        for i in range(0, len(data)):\n            if (data['Date'].iloc[i] > fromday):\n                day_denta = data['Date'].iloc[i] - fromday\n                data['Number day from ' + str(day) + ' case'].iloc[i] = day_denta.days \n        feature = feature + ['Number day from ' + str(day) + ' case']\n    \n    return data[feature]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pmdarima","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pmdarima as pm\n\npred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n    #for country in ['Vietnam']:\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\")\n                df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n                df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                X_train = CreateInput(df_train)\n                y_train_confirmed = df_train['ConfirmedCases'].ravel()\n                y_train_fatalities = df_train['Fatalities'].ravel()\n                X_pred = CreateInput(df_test)\n\n                # Define feature to use by X_pred\n                feature_use = X_pred.columns[0]\n                for i in range(X_pred.shape[1] - 1,0,-1):\n                    if (X_pred.iloc[0,i] > 10):\n                        feature_use = X_pred.columns[i]\n                        break\n                idx = X_train[X_train[feature_use] == 0].shape[0]          \n                adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n                adjusted_y_train_confirmed = y_train_confirmed[idx:]\n                adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n\n                pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n                min_test_date = pred_data['Date'].min()            \n\n                model = pm.auto_arima(adjusted_y_train_confirmed, suppress_warnings=True, seasonal=False, error_action=\"ignore\")            \n                y_hat_confirmed = model.predict(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n                y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)                        \n\n                model = pm.auto_arima(adjusted_y_train_fatalities, suppress_warnings=True, seasonal=False, error_action=\"ignore\")            \n                y_hat_fatalities = model.predict(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n                y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)            \n\n                pred_data['ConfirmedCases_hat'] = y_hat_confirmed\n                pred_data['Fatalities_hat'] = y_hat_fatalities\n                pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\n    \ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\n\ndf_val_1 = df_val.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from bokeh.plotting import figure, show, output_notebook\nfrom bokeh.models import NumeralTickFormatter\nfrom bokeh.palettes import Spectral11\noutput_notebook()\ndef plotCountry(df_country, name):\n    p = figure(title=name + \" Confirmed Cases Forecast\", x_axis_label='Date', x_axis_type='datetime', y_axis_label='Confirmed Cases')\n    p.line(df_country['Date'], df_country['ConfirmedCases_hat'], legend_label=\"Confirmed Cases\", line_width=2)\n    p.legend.location = \"top_left\"\n    p.yaxis.formatter=NumeralTickFormatter(format=\"‘0.0a\")    \n    show(p)\n\n    p = figure(title=name + \" Fatalities Forecast\", x_axis_label='Date', x_axis_type='datetime', y_axis_label='Fatalities Cases')\n    p.line(df_country['Date'], df_country['Fatalities_hat'], legend_label=\"Fatalities \", line_width=2)\n    p.legend.location = \"top_left\"\n    p.yaxis.formatter=NumeralTickFormatter(format=\"‘0.0a\")    \n    show(p)\n\ndef plotTop(df_val):\n    df_now = train.groupby(['Date','Country_Region']).sum().sort_values(['Country_Region','Date']).reset_index()\n    df_now['New Cases'] = df_now['ConfirmedCases'].diff()\n    df_now['New Fatalities'] = df_now['Fatalities'].diff()\n    df_now = df_now.groupby('Country_Region').apply(lambda group: group.iloc[-1:]).reset_index(drop = True)\n\n    p = figure(title=\" Top 5 Confirmed Cases Forecast\", x_axis_label='Date', x_axis_type='datetime', y_axis_label='Confirmed Cases')\n    mypalette=Spectral11[0:5]\n    i = 0\n    for country in df_now.sort_values('ConfirmedCases', ascending=False).head(5)['Country_Region'].values:\n        df_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\n        idx = df_country[((df_country['ConfirmedCases'].isnull() == False) & (df_country['ConfirmedCases'] > 0))].shape[0]\n        p.line(df_country['Date'], df_country['ConfirmedCases_hat'], legend_label= country + \" Confirmed Cases\", line_color=mypalette[i], line_width=2)\n        p.legend.location = \"top_left\"\n        p.yaxis.formatter=NumeralTickFormatter(format=\"‘0.0a\")    \n        i = i+1\n\n    show(p)        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = \"Vietnam\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nplotCountry(df_country,country)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_country = df_val.groupby(['Date']).sum().reset_index()\nplotCountry(df_country,'World')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from statsmodels.tsa.statespace.sarimax import SARIMAX\n\npred_data_all = pd.DataFrame()\nwith tqdm(total=len(train['Country_Region'].unique())) as pbar:\n    for country in train['Country_Region'].unique():\n    #for country in ['Spain']:\n        for province in train[(train['Country_Region'] == country)]['Province_State'].unique():\n            with warnings.catch_warnings():\n                warnings.filterwarnings(\"ignore\")\n                df_train = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]\n                df_test = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                X_train = CreateInput(df_train)\n                y_train_confirmed = df_train['ConfirmedCases'].ravel()\n                y_train_fatalities = df_train['Fatalities'].ravel()\n                X_pred = CreateInput(df_test)\n\n                # Define feature to use by X_pred\n                feature_use = X_pred.columns[0]\n                for i in range(X_pred.shape[1] - 1,0,-1):\n                    if (X_pred.iloc[0,i] > 10):\n                        feature_use = X_pred.columns[i]\n                        break\n                idx = X_train[X_train[feature_use] == 0].shape[0]          \n                adjusted_X_train = X_train[idx:][feature_use].values.reshape(-1, 1)\n\n                adjusted_y_train_confirmed = y_train_confirmed[idx:]\n                adjusted_y_train_fatalities = y_train_fatalities[idx:] #.values.reshape(-1, 1)\n                \n                # Log to forecast Not log because of decrease trending\n                #adjusted_y_train_confirmed = np.log1p(adjusted_y_train_confirmed + 1)\n                #adjusted_y_train_fatalities = np.log1p(adjusted_y_train_fatalities + 1)\n                \n\n                pred_data = test[(test['Country_Region'] == country) & (test['Province_State'] == province)]\n                max_train_date = train[(train['Country_Region'] == country) & (train['Province_State'] == province)]['Date'].max()\n                min_test_date = pred_data['Date'].min()            \n\n                #model = pm.auto_arima(adjusted_y_train_confirmed, suppress_warnings=True, seasonal=False, error_action=\"ignore\")            \n                #y_hat_confirmed = model.predict(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                model = SARIMAX(adjusted_y_train_confirmed, order=(1,1,0),\n                                #seasonal_order=(1,1,0,12),\n                                measurement_error=True).fit(disp=False)\n                y_hat_confirmed = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                # inverse log\n                #y_hat_confirmed = np.expm1(y_hat_confirmed)\n                \n                y_train_confirmed = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['ConfirmedCases'].values\n                y_hat_confirmed = np.concatenate((y_train_confirmed,y_hat_confirmed), axis = 0)                        \n\n                #model = pm.auto_arima(adjusted_y_train_fatalities, suppress_warnings=True, seasonal=False, error_action=\"ignore\")\n                #y_hat_fatalities = model.predict(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                # inverse log\n                #y_hat_fatalities = np.expm1(y_hat_fatalities)\n                \n                model = SARIMAX(adjusted_y_train_fatalities, order=(1,1,0),\n                                #seasonal_order=(1,1,0,12),\n                                measurement_error=True).fit(disp=False)\n                y_hat_fatalities = model.forecast(pred_data[pred_data['Date'] > max_train_date].shape[0])\n                                \n                y_train_fatalities = train[(train['Country_Region'] == country) & (train['Province_State'] == province) & (train['Date'] >=  min_test_date)]['Fatalities'].values\n                y_hat_fatalities = np.concatenate((y_train_fatalities,y_hat_fatalities), axis = 0)            \n\n                pred_data['ConfirmedCases_hat'] = y_hat_confirmed\n                pred_data['Fatalities_hat'] = y_hat_fatalities\n                pred_data_all = pred_data_all.append(pred_data)\n        pbar.update(1)\n    \ndf_val = pd.merge(pred_data_all,train[['Date','Country_Region','Province_State','ConfirmedCases','Fatalities']],on=['Date','Country_Region','Province_State'], how='left')\ndf_val.loc[df_val['Fatalities_hat'] < 0,'Fatalities_hat'] = 0\ndf_val.loc[df_val['ConfirmedCases_hat'] < 0,'ConfirmedCases_hat'] = 0\n\ndf_val_2 = df_val.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country = \"Vietnam\"\ndf_country = df_val[df_val['Country_Region'] == country].groupby(['Date','Country_Region']).sum().reset_index()\nplotCountry(df_country,country)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_country = df_val.groupby(['Date']).sum().reset_index()\nplotCountry(df_country,'World')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotTop(df_val_1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plotTop(df_val_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_val = df_val_2\nsubmission = df_val[['ForecastId','ConfirmedCases_hat','Fatalities_hat']]\nsubmission.columns = ['ForecastId','ConfirmedCases','Fatalities']\nsubmission = submission.round({'ConfirmedCases': 0, 'Fatalities': 0})\nsubmission.to_csv('submission.csv', index=False)\nsubmission","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}