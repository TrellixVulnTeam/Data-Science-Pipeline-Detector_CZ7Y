{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/covid19-global-forecasting-week-3/train.csv', sep=',')\ndf['Date'] = pd.to_datetime(df['Date'])\ntrain_last_date = df.Date.unique()[-1]\nprint(f\"Dataset has training data untill : {train_last_date}\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Add Population Distributions By Country"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nwpop = pd.read_csv('/kaggle/input/worldpopulationbyage/WPP2019_PopulationByAgeSex_Medium.csv')\n\ncountry_mapper = {\n'Iran (Islamic Republic of)' : \"Iran\",\n'Bolivia (Plurinational State of)' : 'Bolivia',\n'Brunei Darussalam' : 'Brunei',\n'Congo' : 'Congo (Kinshasa)',\n'Democratic Republic of the Congo' : \"Congo (Brazzaville)\",\n\"Côte d'Ivoire\": \"Cote d'Ivoire\",\n\"Gambia\" : \"Gambia, The\",\n\"Republic of Korea\": \"Korea, South\",\n\"Republic of Moldova\": \"Moldova\",\n'Réunion' : \"Reunion\",\n'Russian Federation' : \"Russia\",\n'China, Taiwan Province of China' : \"Taiwan*\",\n\"United Republic of Tanzania\": \"Tanzania\",\n\"Bahamas\": \"The Bahamas\",\n\"Gambia\": \"The Gambia\",\n\"United States of America (and dependencies)\" : \"US\",\n\"Venezuela (Bolivarian Republic of)\" : \"Venezuela\",\n'Viet Nam' : \"Vietnam\"}\n\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\nwpop = wpop[wpop['Time']==2020].reset_index(drop=True)\nwpop['Location'] = wpop.Location.apply(lambda x : rename_countries(x, country_mapper))\nclean_wpop = wpop[wpop['Location'].isin(df['Country_Region'].unique())].reset_index()\n\npopulation_distribution = []\nfor country, gpdf in clean_wpop.groupby(\"Location\"):\n    aux = {f\"age_{age_grp}\": tot for age_grp, tot in zip(gpdf.AgeGrp, gpdf.PopTotal)}\n    aux[\"Country_Region\"] = country\n    population_distribution.append(aux)\n    \ndf_pop_distrib = pd.DataFrame(population_distribution)\n\n# add missing countries with median values\nno_data = []\nfor country in df['Country_Region'].unique():\n    if country not in df_pop_distrib['Country_Region'].unique():\n        aux = df_pop_distrib.drop('Country_Region', axis=1).median(axis=0).to_dict()\n        aux[\"Country_Region\"] = country\n        no_data.append(aux)\ndf_no_data = pd.DataFrame(no_data)\n\ndf_pop_distrib = pd.concat([df_pop_distrib, df_no_data], axis=0)\n\n# normalize features\nnorm_pop_distrib = df_pop_distrib.drop(\"Country_Region\", axis=1).div(df_pop_distrib.drop(\"Country_Region\", axis=1).sum(axis=1), axis=0)\nnorm_pop_distrib['total_pop'] = df_pop_distrib.drop(\"Country_Region\", axis=1).sum(axis=1)\nnorm_pop_distrib[\"Country_Region\"] = df_pop_distrib[\"Country_Region\"]\n\ndel df_pop_distrib\ndel df_no_data\n# del clean_wpop\n# del wpop\n\ndf = df.merge(norm_pop_distrib, on=\"Country_Region\", how='left')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wpop.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add Smokers Percentages By Country****"},{"metadata":{"trusted":true},"cell_type":"code","source":"#https://ourworldindata.org/smoking#prevalence-of-smoking-across-the-world\nsmokers = pd.read_csv('/kaggle/input/smokingstats/share-of-adults-who-smoke.csv')\nsmokers = smokers[smokers.Year == 2016].reset_index(drop=True)\n\nsmokers_country_dict = {'North America' : \"US\",\n 'Gambia' : \"The Gambia\",\n 'Bahamas': \"The Bahamas\",\n \"'South Korea'\" : \"Korea, South\",\n'Papua New Guinea' : \"Guinea\",\n \"'Czech Republic'\" : \"Czechia\",\n 'Congo' : \"Congo (Brazzaville)\"}\n\nsmokers['Entity'] = smokers.Entity.apply(lambda x : rename_countries(x, smokers_country_dict))\n\nno_datas_smoker = []\nfor country in df['Country_Region'].unique():\n    if country not in smokers.Entity.unique():\n        mean_score = smokers[['Smoking prevalence, total (ages 15+) (% of adults)']].mean().to_dict()\n        mean_score['Entity'] = country\n        no_datas_smoker.append(mean_score)\nno_data_smoker_df = pd.DataFrame(no_datas_smoker)   \nclean_smoke_data = pd.concat([smokers, no_data_smoker_df], axis=0)[['Entity','Smoking prevalence, total (ages 15+) (% of adults)']]\nclean_smoke_data.rename(columns={\"Entity\": \"Country_Region\",\n                                  \"Smoking prevalence, total (ages 15+) (% of adults)\" : \"smokers_perc\"}, inplace=True)\n\ndf = df.merge(clean_smoke_data, on=\"Country_Region\", how='left')\ndf.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smokers.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"smokers.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Health, Corruption"},{"metadata":{"trusted":true},"cell_type":"code","source":"countries = list(df.Country_Region.unique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"healht_info = pd.read_csv('../input/health-nutrition-and-population-statistics/data.csv')\n#healht_info.sample(5)\n\nhealth_cols_2014 = [\n'GNI per capita, Atlas method (current US$)',\n       'Health expenditure per capita (current US$)',\n       'Health expenditure per capita, PPP',\n       'Health expenditure, private (% of GDP)',\n       'Health expenditure, private (% of total health expenditure)',\n       'Health expenditure, public (% of GDP)',\n       'Health expenditure, public (% of government expenditure)',\n       'Health expenditure, public (% of total health expenditure)',\n       'Health expenditure, total (% of GDP)',\n        'Prevalence of overweight (% of adults)',\n        ]\nhealth_cols_2015 = ['Diabetes prevalence (% of population ages 20 to 79)',]\nhealth_BCG_col =['Immunization, BCG (% of one-year-old children)',]\nhealth_cols_index = ['Country Name', 'Country Code', 'Indicator Name']\n\nhealht1 = healht_info[healht_info['Indicator Name'].isin(health_cols_2014)].pivot(index ='Country Code', columns ='Indicator Name', values = '2014').reset_index()\nhealht2 = healht_info[healht_info['Indicator Name'].isin(health_cols_2015)].pivot(index ='Country Code', columns ='Indicator Name', values = '2015').reset_index()\nhealht3 = healht_info[healht_info['Indicator Name'].isin(health_BCG_col)].pivot(index ='Country Code', columns ='Indicator Name', values = [ '1980', '1990', '2000'])\nhealht3.columns = healht3.columns.get_level_values(0)\nhealht3.columns = [' '.join(col).strip() for col in healht3.columns.values]\nhealht3 = healht3.add_prefix('BCG_')\nhealht3 = healht3.reset_index()\n#healht1.drop(columns=['Indicator Name'], axis=1, inplace=True)\n\nhealth_countries = healht_info[['Country Code','Country Name']].drop_duplicates(subset=['Country Code','Country Name'], keep=\"first\", inplace=False)\n#health_countries\n\nhealht_merged = health_countries.merge(healht1, on='Country Code').merge(healht2, on='Country Code').merge(healht3, on='Country Code')\n###\nhealht_merged.loc[healht_merged['Country Code']=='RUS',['BCG_1 9 8 0','BCG_1 9 9 0' ]] = [96.0,96.0]\nhealht_merged.loc[healht_merged['Country Code']=='UKR',['BCG_1 9 8 0','BCG_1 9 9 0' ]] = [98.0,98.0]\nhealht_merged.loc[healht_merged['Country Code']=='BLR',['BCG_1 9 8 0','BCG_1 9 9 0' ]] = [99.0,99.0]\nhealht_merged.drop(columns=['Country Name'], axis=1, inplace=True)\n##\nhealht_merged.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n****"},{"metadata":{"trusted":true},"cell_type":"code","source":"corruption_info = pd.read_csv('../input/corruption-index/index.csv')\ncorruption_info.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corruption_info.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ISO Country codes"},{"metadata":{"trusted":true},"cell_type":"code","source":"iso_info = pd.read_csv('../input/iso-country-codes-global/wikipedia-iso-country-codes.csv')\niso_info.rename(columns={\"Alpha-3 code\": \"Country Code\", 'English short name lower case':'Country Name',\n                                 }, inplace=True)\niso_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"iso_info.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### religion"},{"metadata":{"trusted":true},"cell_type":"code","source":"rel_info = pd.read_csv('../input/religions-vs-gdp-per-capita/religion_vs_GDP_per_Capita.csv')\nrel_info.rename(columns={\"country\": \"Country Name\" }, inplace=True)\nrel_info.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_mapper = {\n'Laos' : \"Lao People's Democratic Republic\",\n'Hong Kong' : 'Hong Kong S.A.R., China',\n'Democratic Republic of the Congo' : 'Congo (Brazzaville)',\n    'Moldova': 'Moldova, Republic of',\n    'Macedonia': 'Macedonia, the former Yugoslav Republic of'       \n}\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\n\nrel_info['Country Name'] = rel_info['Country Name'].apply(lambda x : rename_countries(x, country_mapper))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(set(rel_info.loc[:,'Country Name'].unique()) - set(iso_info.loc[:,'Country Name'].unique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sars"},{"metadata":{"trusted":true},"cell_type":"code","source":"sars_2003_info = pd.read_csv('../input/sars-outbreak-2003-complete-dataset/sars_2003_complete_dataset_clean.csv')\nsars_2003_info.sample(5)\n#sars_2003_info.Date.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sars_2003_info_ = sars_2003_info.iloc[:,1:].groupby('Country').max().add_prefix('sars_').reset_index()\n#sars_2003_info_.head()\ncountry_mapper = {\n'Russian Federation' : \"Russia\",\n'Hong Kong SAR, China' : 'Hong Kong S.A.R., China',\n'Taiwan, China' : 'Taiwan',\n    'Macao SAR, China': 'Macao',\n    'Republic of Korea': 'South Korea',\n    'Republic of Ireland': 'Ireland',\n    'Viet Nam': 'Vietnam'    \n}\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\n\nsars_2003_info_['Country'] = sars_2003_info_['Country'].apply(lambda x : rename_countries(x, country_mapper))\n\n\nsars_2003_info_ = sars_2003_info_.merge(iso_info[['Country Code', 'Country Name']], left_on= 'Country', right_on = 'Country Name')\n#sars_2003_info_ = sars_2003_info_.drop(\"English short name lower case\")\nsars_2003_info_.iloc[:,1:-1].sample()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"freedom_info = pd.read_csv('../input/cato-2017-human-freedom-index/cato_2017_hfi_by_year_summary.csv')\nfreedom_info = freedom_info.loc[freedom_info.Year==2015,['ISO_Code','PERSONAL FREEDOM (Score)','ECONOMIC FREEDOM (Score)','HUMAN FREEDOM (Score)'] ]\nfreedom_info.rename(columns={\"ISO_Code\": \"Country Code\",\n                                 }, inplace=True)\nfreedom_info.info()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hh_info = pd.read_csv('../input/global-household-data/hh_by_country.csv', decimal=',')\nhh_info_ = hh_info.merge(iso_info[['Country Code', 'Numeric code']], left_on= 'ISO Code', right_on = 'Numeric code')\nhh_info_.iloc[:,4:-1].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged1 = iso_info[['Country Code','Country Name']].merge(healht_merged,  on='Country Code', how='left').merge(corruption_info[['Country Code', 'Corruption Perceptions Index (CPI)']], on='Country Code', how='left').\\\n    merge(sars_2003_info_.iloc[:,1:-1], on='Country Code', how='left').\\\n        merge(hh_info_.iloc[:,4:-1], on='Country Code', how='left').\\\n            merge(freedom_info, on='Country Code', how='left').merge(rel_info[['Country Name', 'religiousity%']], on='Country Name', how='left')\n\nmerged1.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merged1 = healht_merged.merge(corruption_info[['Country Code', 'Corruption Perceptions Index (CPI)']], on='Country Code', how='left').\\\n#     merge(sars_2003_info_.iloc[:,1:-1], on='Country Code', how='left').merge(hh_info_.iloc[:,4:-1], on='Country Code', how='left')\n# merged1.info()\n\ncountry_mapper = {\n'Iran (Islamic Republic of)' : \"Iran\",\n'Bolivia (Plurinational State of)' : 'Bolivia',\n'Brunei Darussalam' : 'Brunei',\n    'The Bahamas': 'Bahamas',\n'Congo' : 'Congo (Kinshasa)',\n'Democratic Republic of the Congo' : \"Congo (Brazzaville)\",\n\"Côte d'Ivoire\": \"Cote d'Ivoire\",\n\"Gambia\" : \"Gambia, The\",\n\"Republic of Korea\": \"Korea, South\",\n\"Republic of Moldova\": \"Moldova\",\n'Réunion' : \"Reunion\",\n'Russian Federation' : \"Russia\",\n\"United Republic of Tanzania\": \"Tanzania\",\n\"Bahamas, The\": \"Bahamas\",\n\"Gambia\": \"The Gambia\",\n\"United States\" : \"US\",\n\"Venezuela, RB\" : \"Venezuela\",\n'Viet Nam' : \"Vietnam\",\n'Egypt, Arab Rep.':'Egypt',\n'Czech Republic': 'Czechia',\n'Macedonia, FYR':'North Macedonia',\n'Gambia, The':'Gambia',\n'Iran, Islamic Rep.':'Iran',\n'Slovak Republic':'Slovakia',\n'South Korea':'Korea, South',\n'Kyrgyz Republic':'Kyrgyzstan',\n    'Syrian Arab Republic':'Syria', \n'Taiwan':'Taiwan*',\n'Myanmar':'Burma',\n'St. Vincent and the Grenadines':'Saint Vincent and the Grenadines',\n'Swaziland':'Eswatini',\n'Macedonia, the former Yugoslav Republic of':'North Macedonia',\n'Moldova, Republic of':'Moldova'}\ndef rename_countries(x, country_dict):\n    new_name = country_dict.get(x)\n    if new_name is not None:\n        #print(x, \"-->\", new_name)\n        return new_name\n    else:\n        return x\n\n\nmerged1['Country Name'] = merged1['Country Name'].apply(lambda x : rename_countries(x, country_mapper))\n\n\nlist(set(countries) - set(merged1.loc[:,'Country Name'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.merge(merged1, left_on=\"Country_Region\",right_on=\"Country Name\", how='left')\ndf.drop(columns=['Country Code', 'Country Name'], axis=1, inplace=True)\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Concatenate Country and Region Province"},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_country_province(country, province):\n    if not isinstance(province, str):\n        return country\n    else:\n        return country+\"_\"+province\n\n# Concatenate region and province for training\ndf[\"Country_Region\"] = df[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"Country_Region\"].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# country_info = pd.read_csv('/kaggle/input/countryinfo/covid19countryinfo.csv')\n# country_info = country_info[~country_info.country.isnull()].reset_index(drop=True)\n# country_info.drop([ c for c in country_info.columns if c.startswith(\"Unnamed\")], axis=1, inplace=True)\n# country_info.drop(columns=['pop', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'medianage', \"smokers\", \"sexratio\"],\n#                   axis=1,\n#                   inplace=True)\n# ##","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lock_info = pd.read_csv('/kaggle/input/covid19-lockdown-dates-by-country/countryLockdowndates.csv')\n# Concatenate region and province for training\nlock_info[\"Country_Region\"] = lock_info[[\"Country/Region\", \"Province\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\nlock_info.loc[lock_info.Country_Region=='Vatican City',['Country_Region']]=\"Holy See\"\nlock_info[\"lockdown\"] = pd.to_datetime(lock_info[\"Date\"])\n#lock_info.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(set(df[\"Country_Region\"]) - set(lock_info[\"Country_Region\"].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lock_info.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.merge(lock_info[['Country_Region','lockdown']], on=\"Country_Region\", how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_info = pd.read_csv('/kaggle/input/countryinfo/covid19countryinfo.csv')\ncountry_info = country_info[~country_info.country.isnull()].reset_index(drop=True)\ncountry_info.drop([ c for c in country_info.columns if c.startswith(\"Unnamed\")], axis=1, inplace=True)\ncountry_info.drop(columns=['pop', 'sex0', 'sex14', 'sex25', 'sex54', 'sex64', 'sex65plus', 'medianage', \"smokers\", \"sexratio\"],\n                  axis=1,\n                  inplace=True)\n##\ncountry_info = country_info.drop(country_info[country_info.country=='Mali'].index)\n#country_info.loc[country_info.country=='Ukraine','quarantine'] = '3/12/2020'\n# country_info.loc[country_info.country=='Ukraine','gathering'] = '3/12/2020'\n# country_info.loc[country_info.country=='Ukraine','schools'] = '3/12/2020'\n# country_info.loc[country_info.country=='Ukraine','nonessential'] = '4/06/2020'\n####\n# Columns with dates\ncountry_info[\"quarantine\"] = pd.to_datetime(country_info[\"quarantine\"])\ncountry_info[\"publicplace\"] = pd.to_datetime(country_info[\"publicplace\"])\ncountry_info[\"gathering\"] = pd.to_datetime(country_info[\"gathering\"])\ncountry_info[\"nonessential\"] = pd.to_datetime(country_info[\"nonessential\"])\ncountry_info[\"schools\"] = pd.to_datetime(country_info[\"schools\"])\ncountry_info[\"firstcase\"] = pd.to_datetime(country_info[\"firstcase\"])\n##\ncountry_info['gdp2019'] = country_info['gdp2019'].str.replace(',', '')\ncountry_info['healthexp'] = country_info['healthexp'].str.replace(',', '')\n\n\n\n\nsame_state = []\nfor country in df[\"Province_State\"].unique():\n    if country in country_info.country.unique():\n        same_state.append(country)\n    else:\n        pass\n        # This part can help matching different external dataset and find corresponding countries\n        #print(country)\n        #matches = []\n        #scores = []\n        #if str(country)==\"nan\":\n        #    continue\n        #for possible_match in country_info.country.unique():\n        #    matches.append(possible_match)\n        #    scores.append(fuzz.partial_ratio(country, possible_match))\n            \n        #top_5_index = np.argsort(scores)[::-1][:5]\n        #print(np.array(matches)[top_5_index])\n        #print(np.array(scores)[top_5_index])\n        #print(\"-------------------\")\n        \ncountry_to_state_country = {}\nfor state in same_state:\n    #print(state)\n    #print(df[df[\"Province/State\"]==state][\"Country/Region\"].unique())\n    #print(\"----\")\n    country_to_state_country[state] = df[df[\"Province_State\"]==state][\"Country_Region\"].unique()[0]+\"_\"+state\n\ncountry_info['country'] =country_info[[\"country\", \"region\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)                                                                      \n\n\ndates_info = [\"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]\ncoutry_merge_info = country_info[[\"country\", \"density\", \"urbanpop\", \"hospibed\", \"lung\",\n                                  \"femalelung\", \"malelung\",'gdp2019', 'healthexp', 'healthperpop', 'fertility'] + dates_info]\n\ncols_median = [\"density\", \"urbanpop\", \"hospibed\", \"lung\", \"femalelung\", \"malelung\",'gdp2019', 'healthexp', 'healthperpop', 'fertility']\ncoutry_merge_info.loc[:, cols_median] = coutry_merge_info.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\n\nmerged = df.merge(coutry_merge_info, left_on=\"Country_Region\", right_on=\"country\", how=\"left\")\nmerged.loc[:, cols_median] = merged.loc[:, cols_median].apply(lambda x: x.fillna(x.median()),axis=0)\n\ncountry_dates_info = country_info[[\"country\", \"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]]\n\n\n\n# def dates_diff_days(date_curr, date_):\n#     if date_curr>date_:\n#         return (date_curr - date_).days\n#     else :\n#         return 0\n\n\n# for col in dates_info:\n#     #print(merged.shape)\n#     merged[col+'_days'] =merged[[\"Date\", col]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)                                                                      \n\nprint(merged.shape)\n#drop_country_cols = [x for x in merged.columns if x.startswith(\"country\")] + dates_info\ndrop_country_cols = [x for x in merged.columns if x.startswith(\"country\")]\nmerged.drop(columns=drop_country_cols, axis=1, inplace=True)\nprint(merged.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.Country_Region.value_counts().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.sample(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Weather"},{"metadata":{"trusted":true},"cell_type":"code","source":"# weather_info = pd.read_csv('../input/weather-info/training_data_with_weather_info_week_2.csv')\n# weather_info.sample(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# weather_info.Date.min(), weather_info.Date.max() , weather_info.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merged.Date.min(), merged.Date.max(), merged.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# weather_info[\"Country_Region\"] = weather_info[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n# weather_info[\"Date\"] = pd.to_datetime(weather_info[\"Date\"])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merged_ = merged.merge(weather_info[['temp','min','max','stp','wdsp','prcp','fog','Country_Region', 'Date']], on=[\"Country_Region\", 'Date'])\n# merged_.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# merged_.Country_Region.value_counts().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.to_csv('enriched_covid_19_week_3.csv', index=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}