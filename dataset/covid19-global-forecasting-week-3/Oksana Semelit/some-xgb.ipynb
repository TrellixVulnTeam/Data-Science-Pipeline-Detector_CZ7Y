{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import csv\nimport os\nimport xgboost\n\nimport re\nimport string\nfrom sklearn import ensemble\nfrom sklearn import metrics\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.offline as pyo\npyo.init_notebook_mode()\n\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import confusion_matrix, roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score, KFold\nfrom xgboost import XGBClassifier\nimport xgboost as xgb\n\n\ntrain = pd.read_csv(\"../input/covid19-global-forecasting-week-3/train.csv\")\ntest = pd.read_csv(\"../input/covid19-global-forecasting-week-3/test.csv\")\ndf_1 = pd.read_csv('https://raw.githubusercontent.com/plotly/datasets/master/2014_world_gdp_with_codes.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train['Date'].min())\nprint(train['Date'].max())\n\nprint(test['Date'].min())\nprint(test['Date'].max())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Added new features in train and test sets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Date'] = pd.to_datetime(train['Date'])\ntest['Date'] = pd.to_datetime(test['Date'])\n\ntrain['dayofmonth'] = train['Date'].dt.day\ntrain['dayofweek'] = train['Date'].dt.dayofweek\ntrain['month'] = train['Date'].dt.month\ntrain['weekNumber'] = train['Date'].dt.week\ntrain['dayofyear'] = train['Date'].dt.dayofyear\n## added in training set\ntrain['Fatalities_ratio'] = train['Fatalities'] / train['ConfirmedCases']\n\n#train['Change_ConfirmedCases'] = train.groupby('Country_Region').ConfirmedCases.pct_change()\n#train['Change_Fatalities'] = train.groupby('Country_Region').Fatalities.pct_change()\n\n## to deal with data wih Province State\ntrain['Change_ConfirmedCases'] = train.groupby(np.where(train['Province_State'].isnull(), train['Country_Region'], train['Province_State'])).ConfirmedCases.pct_change()\ntrain['Change_Fatalities'] = train.groupby(np.where(train['Province_State'].isnull(), train['Country_Region'], train['Province_State'])).Fatalities.pct_change()\n\n## added in Test set\ntest['dayofmonth'] = test['Date'].dt.day\ntest['dayofweek'] = test['Date'].dt.dayofweek\ntest['month'] = test['Date'].dt.month\ntest['weekNumber'] = test['Date'].dt.week\ntest['dayofyear'] = test['Date'].dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train[train.Date<'2020-03-26']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Total Confirmed Cases and Fatalities By Countries On World Map"},{"metadata":{},"cell_type":"markdown","source":"### Grouped by Date and added ratio by running total for visualizations "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Exponential Moving Average with 7 days and 14 days average"},{"metadata":{},"cell_type":"markdown","source":"## Training and Fitting the Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"enriched = pd.read_csv(\"/kaggle/input/data-prep-week3/enriched_covid_19_week_3.csv\")\nenriched['Date'] = pd.to_datetime(train['Date'])\nenriched['Date'] = pd.to_datetime(test['Date'])\nenriched[\"quarantine\"] = pd.to_datetime(enriched[\"quarantine\"])\nenriched[\"publicplace\"] = pd.to_datetime(enriched[\"publicplace\"])\nenriched[\"gathering\"] = pd.to_datetime(enriched[\"gathering\"])\nenriched[\"nonessential\"] = pd.to_datetime(enriched[\"nonessential\"])\nenriched[\"schools\"] = pd.to_datetime(enriched[\"schools\"])\nenriched[\"firstcase\"] = pd.to_datetime(enriched[\"firstcase\"])\n\ndates_info = [\"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\",\"firstcase\"]\n\nenriched[\"age_40-59\"] = enriched.loc[:,[\"age_40-44\", \"age_45-49\", \"age_50-54\", \"age_55-59\"]].values.sum(1)\nenriched[\"age_60-79\"] = enriched.loc[:,[\"age_60-64\", \"age_65-69\", \"age_70-74\", \"age_75-79\"]].values.sum(1)\nenriched[\"age_80+\"]  = enriched.loc[:,[\"age_80-84\", \"age_85-89\", \"age_90-94\", \"age_95-99\",\"age_100+\"]].values.sum(1)\n\nenriched.drop([\n    \"age_0-4\", \"age_5-9\", \"age_10-14\", \"age_15-19\", \"age_20-24\", \"age_25-29\", \"age_30-34\", \"age_35-39\",\n    \"age_40-44\", \"age_45-49\", \"age_50-54\", \"age_55-59\", \"age_60-64\", \"age_65-69\", \"age_70-74\", \"age_75-79\",\n    \"age_80-84\", \"age_85-89\", \"age_90-94\",\"age_95-99\",\"age_100+\", \"femalelung\", \"malelung\"], \n    axis = 1, inplace = True)\n\nenriched.head()\n\nenriched = enriched.iloc[:,:]\nenriched.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#enriched[enriched.Country_Region=='Ukraine'].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def concat_country_province(country, province):\n    if not isinstance(province, str):\n        return country\n    else:\n        return country+\"_\"+province\n\n# Concatenate region and province for training\ntrain[\"Country_Region_\"] = train[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\ntest[\"Country_Region_\"] = test[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\n\nenriched[\"Country_Region_\"] = enriched[[\"Country_Region\", \"Province_State\"]].apply(lambda x : concat_country_province(x[0], x[1]), axis=1)\nenriched = enriched.drop_duplicates(subset=['Country_Region_'], keep=\"first\", inplace=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.merge(enriched.iloc[:, 6:], on ='Country_Region_', how='left')\ntest = test.merge(enriched.iloc[:, 6:], on ='Country_Region_', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def dates_diff_days(date_curr, date_):\n    if date_curr>date_:\n        return (date_curr - date_).days\n    else :\n        return 0\n\nfor col in [\"publicplace\", \"gathering\", \"nonessential\", \"quarantine\", \"schools\"]:\n    #print(merged.shape)\n    train[\"days_to_\"+ col] =train[[col, 'firstcase']].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)  \n    test[\"days_to_\"+ col] =test[[col, 'firstcase' ]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1) \n\n\n# train['days_to_quarantine'] =train[[\"quarantine\", 'firstcase']].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)  \n# test['days_to_quarantine'] =test[[\"quarantine\", 'firstcase']].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)  \n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in dates_info:\n    #print(merged.shape)\n    train[col] =train[[\"Date\", col]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1)  \n    test[col] =test[[\"Date\", col]].apply(lambda x : dates_diff_days(x[0], x[1]), axis=1) \n\nprint(test.shape)\n\n#drop_country_cols = [x for x in merged.columns if x.startswith(\"country\")] + dates_info","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def to_log(x):\n#     return np.log(x + 1)\n\n\n# def to_exp(x):\n#     return np.exp(x) - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_each_location(df):\n    dfs = []\n    for loc, df in df.groupby('Country_Region_'):\n        df = df.sort_values(by='Date')\n#         df['Fatalities'] = df['Fatalities'].cummax()\n#         df['ConfirmedCases'] = df['ConfirmedCases'].cummax()\n#         df['LogFatalities'] = df['LogFatalities'].cummax()\n#         df['LogConfirmed'] = df['LogConfirmed'].cummax()\n        df['Confirmed_shift7'] = df['ConfirmedCases'].shift(-7)\n        df['Confirmed_shift1'] = df['ConfirmedCases'].shift(-1)\n        #df['Date_10Confirmed'] = df.loc[df.ConfirmedCases ==10, 'Date'].min()\n        df['Fatalities_shift7'] = df['Fatalities'].shift(-7)\n        df['Fatalities_shift1'] = df['Fatalities'].shift(-1)\n        #df['Date_10Fatalities'] = df.loc[df.Fatalities ==10, 'Date'].min()\n        #\n        dfs.append(df.fillna(0))\n    return pd.concat(dfs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def zero_div(a,b):\n    if b==0 | a==0:\n        return 0\n    else:\n        return a/b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train = process_each_location(train)\n# test = process_each_location(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train.Country_Region_=='Ukraine']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nfrom xgboost import XGBRegressor\n\n\ntrain['ConfirmedCases_diff'] = train.loc[:, ['ConfirmedCases', 'Country_Region_']].groupby('Country_Region_').diff().fillna('0')\ntrain['Fatalities_diff'] = train.loc[:, ['Fatalities', 'Country_Region_']].groupby('Country_Region_').diff().fillna('0')\n\n\n\n# train['ConfirmedCases_'] = to_log(train.ConfirmedCases)\n# train['Fatalities_'] = to_log(train.Fatalities)\n# train['ConfirmedCases_diff'] = train.loc[:, ['ConfirmedCases_', 'Country_Region_']].groupby('Country_Region_').diff().fillna('0')\n# train['Fatalities_diff'] = train.loc[:, ['Fatalities_', 'Country_Region_']].groupby('Country_Region_').diff().fillna('0')\n# train  = train.drop(columns=['ConfirmedCases_', 'Fatalities_'])\ntrain = train.astype({'ConfirmedCases_diff': 'float64','Fatalities_diff': 'float64' })\n#\n# train.loc[train.ConfirmedCases_diff<0, 'ConfirmedCases_diff'] = 0\n# train.loc[train.Fatalities_diff<0, 'Fatalities_diff'] = 0\n# train['ConfirmedCases_diff'] = to_log(train.ConfirmedCases_diff)\n# train['Fatalities_diff'] = to_log(train.Fatalities_diff)\n\n#####\n\ntrain['Country_Region'] = le.fit_transform(train['Country_Region'])\ntrain['Province_State'] = le.fit_transform(train['Province_State'].fillna('0'))\n\ntest['Country_Region'] = le.fit_transform(test['Country_Region'])\ntest['Province_State'] = le.fit_transform(test['Province_State'].fillna('0'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# #with validation\n# y1_train = train.loc[train.Date<'2020-03-26','ConfirmedCases_diff']\n# y2_train = train.loc[train.Date<'2020-03-26','Fatalities_diff']\n\n# y1_val = train.loc[train.Date>='2020-03-26','ConfirmedCases_diff']\n# y2_val = train.loc[train.Date>='2020-03-26','Fatalities_diff']\n\n# X_Id = train['Id']\n\n# # X_train = train.drop(columns=['Id', 'Date','ConfirmedCases', 'Fatalities', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# # X_test  = test.drop(columns=['ForecastId', 'Date'])\n\n# X_val = train.loc[train.Date>='2020-03-26',:].drop(columns=['Id', 'Fatalities', 'Date',\n#                               'Fatalities_ratio','Change_ConfirmedCases'\n#                               ,'Change_Fatalities','Country_Region_','ConfirmedCases','Fatalities_diff','ConfirmedCases_diff'])\n\n# X_train = train.loc[train.Date>='2020-03-26',:].drop(columns=['Id', 'Fatalities', 'Date',\n#                               'Fatalities_ratio','Change_ConfirmedCases'\n#                               ,'Change_Fatalities','Country_Region_','ConfirmedCases','Fatalities_diff','ConfirmedCases_diff'])\n# X_test  = test.drop(columns=['ForecastId','Country_Region_', 'Date'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" \ny1_train = train['ConfirmedCases_diff']\ny2_train = train['Fatalities_diff']\n\n# y1_val = train['ConfirmedCases_diff']\n# y2_val = train['Fatalities_diff']\n\nX_Id = train['Id']\n\n# X_train = train.drop(columns=['Id', 'Date','ConfirmedCases', 'Fatalities', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId', 'Date'])\n\nX_val = train.drop(columns=['Id', 'Fatalities', 'Date',\n                              'Fatalities_ratio','Change_ConfirmedCases'\n                              ,'Change_Fatalities','Country_Region_','ConfirmedCases','Fatalities_diff','ConfirmedCases_diff'])\n\nX_train = train.drop(columns=['Id', 'Fatalities', 'Date',\n                              'Fatalities_ratio','Change_ConfirmedCases'\n                              ,'Change_Fatalities','Country_Region_','ConfirmedCases','Fatalities_diff','ConfirmedCases_diff'])\nX_test  = test.drop(columns=['ForecastId','Country_Region_', 'Date'])\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from fbprophet import Prophet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = train.drop(columns=['Id', 'Fatalities', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId'])\n\n# model=Prophet()\n# model.fit(X_train \\\n#               .rename(columns={'Date':'ds',\n#                                'ConfirmedCases':'y'}))\n# forecast_conf=model.predict(df=X_test \\\n#                                    .rename(columns={'Date':'ds'}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = train.drop(columns=['Id', 'ConfirmedCases', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId'])\n\n# model_1=Prophet()\n# model_1.fit(X_train \\\n#               .rename(columns={'Date':'ds',\n#                                'Fatalities':'y'}))\n# forecast_Fatilities=model.predict(df=X_test \\\n#                                    .rename(columns={'Date':'ds'}))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_xgb_d = pd.DataFrame({'ForecastId': test.ForecastId, 'ConfirmedCases': forecast_conf.yhat, 'Fatalities': forecast_Fatilities.yhat })\n# df_xgb_d.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# X_train = train.drop(columns=['Id', 'Date','ConfirmedCases', 'Fatalities', 'Fatalities_ratio','Change_ConfirmedCases','Change_Fatalities'])\n# X_test  = test.drop(columns=['ForecastId', 'Date'])\n\nmodel = xgboost.XGBRegressor(colsample_bytree=0.8,\n                 gamma=0,                 \n                 learning_rate=0.1,\n                 max_depth=5,\n                 min_child_weight=1.5,\n                 n_estimators=2000,                                                                    \n                 reg_alpha=0.75,\n                 reg_lambda=0.45,\n                 subsample=0.7,\n                 seed=42                           ) \n\n\nmodel.fit(X_train, y1_train)\ny1_pred = model.predict(X_test)\n\n\nmodel.fit(X_train, y2_train)\ny2_pred = model.predict(X_test)\n\n\ndf = pd.DataFrame({'ForecastId': test.ForecastId, 'ConfirmedCases': y1_pred, 'Fatalities': y2_pred})\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.sample(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pylab as plt\nfrom matplotlib import pyplot\nfrom xgboost import plot_importance\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pylab import rcParams\nrcParams['figure.figsize'] = 5, 10\n\nplot_importance(model, max_num_features=30) # top 10 most important features\n#rcParams['figure.figsize'] = 15, 10\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = test.copy()\ntest1['ConfirmedCases'] = y1_pred\ntest1['Fatalities']=y2_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.Date.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_max = train[['Country_Region_', 'ConfirmedCases','Fatalities']].groupby('Country_Region_').max().add_prefix('max_').reset_index()\ntrain_max.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1 = test1.merge(train_max, on='Country_Region_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" test1.loc[test1.ConfirmedCases<0, 'ConfirmedCases']=0\n test1.loc[test1.Fatalities<0, 'Fatalities']=0\n#  test1['ConfirmedCases'] = to_exp(test1.ConfirmedCases)\n#  test1['Fatalities'] = to_exp(test1.Fatalities)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1['ConfirmedCases'] = test1.groupby('Country_Region_')['ConfirmedCases'].cumsum()\ntest1['Fatalities'] = test1.groupby('Country_Region_')['Fatalities'].cumsum()\ntest1['ConfirmedCases'] = test1['ConfirmedCases'] + test1['max_ConfirmedCases']\ntest1['Fatalities'] = test1['Fatalities'] + test1['max_Fatalities']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#test1.loc[test1.Country_Region_=='Ukraine','femalelung':]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"subm_fit_bell = pd.read_csv('../input/covid19-forecast-wk3/submission.csv')\nsubm_fit_bell.rename(columns={\"ConfirmedCases\": \"ConfirmedCases_bell\", 'Fatalities':'Fatalities_bell',\n                                 }, inplace=True)\nsubm_fit_bell.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1_ = test1.merge(subm_fit_bell, on ='ForecastId')\ntest1_.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1_['ConfirmedCases'] = test1_['ConfirmedCases']*0.5 + test1_['ConfirmedCases_bell']*0.5\ntest1_['Fatalities'] = test1_['Fatalities']*0.5 + test1_['Fatalities_bell']*0.5\n#\"ConfirmedCases\": \"ConfirmedCases_bell\", 'Fatalities':'Fatalities_bell'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1_.loc[test1.Country_Region_=='Ukraine',[ 'Date', 'ConfirmedCases', 'Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1_.loc[test1.Country_Region_=='Spain',:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test1.loc[test1.Country_Region_=='Italy',[ 'Date', 'ConfirmedCases', 'Fatalities']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df =test1_[['ForecastId','ConfirmedCases','Fatalities']]\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Log diff"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport random\nimport pandas as pd\nfrom scipy.integrate import odeint\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.dates as mdates\nfrom matplotlib import dates\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom datetime import datetime\nfrom lmfit import minimize, Parameters, Parameter, report_fit","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}