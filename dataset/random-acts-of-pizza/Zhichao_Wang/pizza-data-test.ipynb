{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Data and Data Structures\nimport json\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom datetime import datetime\nfrom subprocess import check_output\n\n# Machine Learning\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.metrics import classification_report\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn import preprocessing\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.mixture import GaussianMixture\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.random_projection import sparse_random_matrix\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestRegressor\n\n# Visualization\n%matplotlib inline\nimport matplotlib as mpl\nfrom matplotlib.colors import ListedColormap\nfrom matplotlib.colors import LogNorm\nimport matplotlib.pyplot as plt\nplt.style.use('bmh')\nfrom wordcloud import WordCloud, STOPWORDS","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:04:23.421566Z","iopub.execute_input":"2021-08-29T05:04:23.42191Z","iopub.status.idle":"2021-08-29T05:04:23.437474Z","shell.execute_reply.started":"2021-08-29T05:04:23.421883Z","shell.execute_reply":"2021-08-29T05:04:23.436336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Load dataset","metadata":{}},{"cell_type":"code","source":"# Load Train Data\nwith open('../input/random-acts-of-pizza/train.json') as fin:\n    trainjson = json.load(fin)\ntrain = pd.io.json.json_normalize(trainjson)\n\n# Load Test Data\nwith open('../input/random-acts-of-pizza/test.json') as fin:\n    testjson = json.load(fin)\ntest = pd.io.json.json_normalize(testjson)\n\nprint(\"Train Shape:\", train.shape)\nprint(\"Test Shape:\", test.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:13:29.130846Z","iopub.execute_input":"2021-08-29T05:13:29.13125Z","iopub.status.idle":"2021-08-29T05:13:29.940172Z","shell.execute_reply.started":"2021-08-29T05:13:29.131219Z","shell.execute_reply":"2021-08-29T05:13:29.939263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check data, we can see there are two types: numeric and textual.\n# The first step is business understanding. This is a classification problem. It seems text feature \"request_text\" \"request_text_edit_awar\" play the crtical role in this task. Then this will be a NLP feature representation problem. Namely, how to convert the text feature into a meaningful vector such that ML models, such as XGboost could handle. We could use some popular NLP packages such as word embending, bag-of-word, or Bert method to model the text feature.","metadata":{}},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:15:23.096114Z","iopub.execute_input":"2021-08-29T05:15:23.096518Z","iopub.status.idle":"2021-08-29T05:15:23.147734Z","shell.execute_reply.started":"2021-08-29T05:15:23.096486Z","shell.execute_reply":"2021-08-29T05:15:23.14649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:19:24.671673Z","iopub.execute_input":"2021-08-29T05:19:24.672085Z","iopub.status.idle":"2021-08-29T05:19:24.699413Z","shell.execute_reply.started":"2021-08-29T05:19:24.672053Z","shell.execute_reply":"2021-08-29T05:19:24.698731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # **From above table, we can see null values, so check missing values**","metadata":{}},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:12:22.812929Z","iopub.execute_input":"2021-08-29T05:12:22.813331Z","iopub.status.idle":"2021-08-29T05:12:22.840043Z","shell.execute_reply.started":"2021-08-29T05:12:22.813297Z","shell.execute_reply":"2021-08-29T05:12:22.838831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # only 3046 null values in one specific column requester_user_flair which don't not appear in the following test.colums, so we could drop requester_user_flair ","metadata":{}},{"cell_type":"code","source":"print(\"Common columns in train and test:\")\nprint(train.columns[train.columns.isin(test.columns)])\nprint(\"----\")\nprint(\"Columns in train but NOT test:\")\nprint(train.columns[~train.columns.isin(test.columns)])","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:26:12.405201Z","iopub.execute_input":"2021-08-29T05:26:12.405704Z","iopub.status.idle":"2021-08-29T05:26:12.416035Z","shell.execute_reply.started":"2021-08-29T05:26:12.405666Z","shell.execute_reply":"2021-08-29T05:26:12.41472Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data limitions: This dataset contains some attributes that are only available on the train dataset but not on the test dataset, so these attributes cannot actually be utilised. If such kinds of attributes are available on both train and test, it is possible to check the impact of these attributes on the success of the pizza request.","metadata":{}},{"cell_type":"markdown","source":"# # Label and features","metadata":{}},{"cell_type":"code","source":"train_labels_master = train[['requester_received_pizza']]\ntrain_data_master = train[test.columns]","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:38:08.180673Z","iopub.execute_input":"2021-08-29T05:38:08.181052Z","iopub.status.idle":"2021-08-29T05:38:08.194038Z","shell.execute_reply.started":"2021-08-29T05:38:08.181022Z","shell.execute_reply":"2021-08-29T05:38:08.19306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape, train_data_master.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:38:54.387244Z","iopub.execute_input":"2021-08-29T05:38:54.387971Z","iopub.status.idle":"2021-08-29T05:38:54.39456Z","shell.execute_reply.started":"2021-08-29T05:38:54.387913Z","shell.execute_reply":"2021-08-29T05:38:54.393416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_master.describe()\ntrain_data_master.info()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:39:33.942754Z","iopub.execute_input":"2021-08-29T05:39:33.943107Z","iopub.status.idle":"2021-08-29T05:39:33.996225Z","shell.execute_reply.started":"2021-08-29T05:39:33.943078Z","shell.execute_reply":"2021-08-29T05:39:33.995316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the label ratio of different buckets, False around 3000 but True around 1000, this is a imblance classification problem. So to aviod model bias problem, under sampling or over sampling could be further considered","metadata":{}},{"cell_type":"code","source":"(sns.countplot(x = train_labels_master.requester_received_pizza).\nset_title(\"# of received vs nor received a pizza\"));","metadata":{"execution":{"iopub.status.busy":"2021-08-29T05:41:10.014481Z","iopub.execute_input":"2021-08-29T05:41:10.014933Z","iopub.status.idle":"2021-08-29T05:41:10.218417Z","shell.execute_reply.started":"2021-08-29T05:41:10.014895Z","shell.execute_reply":"2021-08-29T05:41:10.217404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"#  due to time limit, we can only deal with numberic features in data, however, the text feaure also must deserve to be further analysized","metadata":{}},{"cell_type":"code","source":"granted = train_data_master[train_labels_master['requester_received_pizza']==True]\nungranted = train_data_master[train_labels_master['requester_received_pizza']==False]","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:07:05.605602Z","iopub.execute_input":"2021-08-29T07:07:05.60597Z","iopub.status.idle":"2021-08-29T07:07:05.618427Z","shell.execute_reply.started":"2021-08-29T07:07:05.60594Z","shell.execute_reply":"2021-08-29T07:07:05.617607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # The numberic feature distribution with requester_received_pizza == True","metadata":{}},{"cell_type":"code","source":"df_num = (granted.select_dtypes(include = ['float64', 'int64']))\ndf_num.shape\n\nfig = df_num.hist(figsize=(16, 10), bins=50, xlabelsize=8, ylabelsize=8, ec=\"k\")\nfig = [x.title.set_size(10) for x in fig.ravel()]\nfig;","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:07:19.766039Z","iopub.execute_input":"2021-08-29T07:07:19.766546Z","iopub.status.idle":"2021-08-29T07:07:23.1999Z","shell.execute_reply.started":"2021-08-29T07:07:19.766498Z","shell.execute_reply":"2021-08-29T07:07:23.199116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # The numberic feature distribution with requester_received_pizza == False","metadata":{}},{"cell_type":"markdown","source":"# Comparing above figure between label = Ture and False. For example, we can find the distributions of last 2 features are different between True and False.","metadata":{}},{"cell_type":"code","source":"df_num = (ungranted.select_dtypes(include = ['float64', 'int64']))\ndf_num.shape\n\nfig = df_num.hist(figsize=(16, 10), bins=50, xlabelsize=8, ylabelsize=8, ec=\"k\")\nfig = [x.title.set_size(10) for x in fig.ravel()]\nfig;","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:07:58.124683Z","iopub.execute_input":"2021-08-29T07:07:58.125177Z","iopub.status.idle":"2021-08-29T07:08:00.911214Z","shell.execute_reply.started":"2021-08-29T07:07:58.125146Z","shell.execute_reply":"2021-08-29T07:08:00.910535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# # Compute some statistics such as corrlation matrix to explot the relations among features then used for feature selection. The following is lable = Ture","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(25,25))\nXr = granted\nsns.heatmap(Xr.corr(), annot = True,  cbar_kws= {'orientation': 'horizontal'} )","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:08:22.705435Z","iopub.execute_input":"2021-08-29T07:08:22.706028Z","iopub.status.idle":"2021-08-29T07:08:24.040147Z","shell.execute_reply.started":"2021-08-29T07:08:22.705992Z","shell.execute_reply":"2021-08-29T07:08:24.039453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# # Compute some statistics such as corrlation matrix to explot the relations among features, lable = False","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(25,25))\nXr = ungranted\nsns.heatmap(Xr.corr(), annot = True,  cbar_kws= {'orientation': 'horizontal'} )","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:04:21.361329Z","iopub.execute_input":"2021-08-29T07:04:21.361862Z","iopub.status.idle":"2021-08-29T07:04:22.785903Z","shell.execute_reply.started":"2021-08-29T07:04:21.361814Z","shell.execute_reply":"2021-08-29T07:04:22.784669Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# #   Generate Word Clouds of Granted and Ungranted Requests, where we could also use some usefel word-vector NLP technicial methods to encode text feature as numberical vector. But due to time limit, we omit this step here and could expolore further. Actually the text feature frequently happens in Customer survey and Customer retention. If I have more time, I will take further steps to improve the performance.\n# 1.  generate the additional feature from the textual analysis of the posts and add to the original selected features.we can endcode linguistic feature as some feature representation such as sentiment/words length/Politeness/... and so on \n# 2.  consider high-level topic features engineering such as using Latent Dirichlet Allocation  to explore whether request is dependent on the topic to which it belongs\n# 3. If possible, we should incoporate more features as many as we can, but this is based on specific task/data understanding ","metadata":{}},{"cell_type":"code","source":"mpl.rcParams['font.size']=12        \nmpl.rcParams['savefig.dpi']=100         \nmpl.rcParams['figure.subplot.bottom']=.1 \n\nstopwords = set(STOPWORDS)\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=50,\n                          max_font_size=50, \n                          random_state=42\n                         ).generate(str(granted['request_text_edit_aware']))\n\nfig = plt.figure(1)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.title(\"Word Cloud for Granted Requests\",fontsize=22, fontweight='bold')\nplt.show()\n\nwordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=stopwords,\n                          max_words=50,\n                          max_font_size=50, \n                          random_state=42\n                         ).generate(str(ungranted['request_text_edit_aware']))\n\nfig = plt.figure(1)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.title(\"Word Cloud for Ungranted Requests\",fontsize=22, fontweight='bold')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-29T07:09:06.611247Z","iopub.execute_input":"2021-08-29T07:09:06.611803Z","iopub.status.idle":"2021-08-29T07:09:07.124246Z","shell.execute_reply.started":"2021-08-29T07:09:06.611768Z","shell.execute_reply":"2021-08-29T07:09:07.123004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Question: What would be your high level recommendations to someone trying to get a free pizza from kind strangers on Reddit circa 2016?\n# Answer: According to the word cloud results, the successful requests are polite and emphasise the problems you are facing such as weather and unemployed. Unsuccessful requests are more self-effacing, using the words \"hungry\" and \"need\". Recommendations to improve chance to success: write politele, display the difficulty situations and gratitude to the community if your situations improved.","metadata":{}},{"cell_type":"markdown","source":"# # Finally, we could combine above  linguistic feature and numberic feature as input to ML models such as XGBoost/Logistic regression/SVM and so on","metadata":{}}]}