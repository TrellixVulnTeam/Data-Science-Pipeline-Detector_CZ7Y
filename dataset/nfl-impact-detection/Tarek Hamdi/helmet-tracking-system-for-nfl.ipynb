{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Overview\n1. build your own helmet tracking system for NFL using computer vision and Python\n2. Understand different approaches for tracking fast-moving objects in a sports video\n3. We will also discuss the various use cases of a ball tracking system"},{"metadata":{},"cell_type":"markdown","source":"## [Object Detection](https://www.analyticsvidhya.com/blog/2018/10/a-step-by-step-introduction-to-the-basic-object-detection-algorithms-part-1/) is one of the most fascinating concepts in computer vision. It has a far-reaching role in different domains such as defense, space, sports, and other fields. Here, I have listed a few interesting use cases of Object Detection in Defense and Space:\n### - Automatic Target Aimer\n### - Training Robots in real word simulations to retrieve people in hazardous physical environments\n### - Detecting Space Debris\n\n# Object Detection = Image Classfication + Localization"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install imutils","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install opencv-python","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, let’s read a video file and save the frames to a folder:\nimport cv2\nimport numpy as np\nimport imutils\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom skimage.color import rgb2gray\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy import ndimage\nimport os\nimport sys\nimport random\nimport math\nimport skimage.io\nimport matplotlib\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# How to play mp4 video on kaggle?"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nfrom base64 import b64encode\nvid1 = open('../input/nfl-impact-detection/train/57583_000082_Endzone.mp4','rb').read()\ndata_url = \"data:video/mp4;base64,\" + b64encode(vid1).decode()\nHTML(\"\"\"\n<video width=600 controls>\n      <source src=\"%s\" type=\"video/mp4\">\n</video>\n\"\"\" % data_url)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Recognizing people in a video\n## From video to frames\n## In cv2.VideoCapture(VIDEO_STREAM), we just have to mention the video name with it’s extension.\n\n## You can set frame rate which is widely known as fps (frames per second). Here I set 0.5 so it will capture a frame at every 0.5 seconds, means 2 frames (images) for each second.\n\n## It will save images with name as image1.jpg, image2.jpg and so on."},{"metadata":{"trusted":true},"cell_type":"code","source":"VIDEO_STREAM = \"../input/nfl-impact-detection/train/57583_000082_Endzone.mp4\"\n\nvidcap = cv2.VideoCapture(VIDEO_STREAM)\ndef getFrame(sec):\n    vidcap.set(cv2.CAP_PROP_POS_MSEC,sec*1000)\n    hasFrames,image = vidcap.read()\n    if hasFrames:\n        cv2.imwrite(\"image\"+str(count)+\".jpg\", image) # save frame as JPG file\n        plt.imshow(image)\n    return hasFrames\n\nsec = 0\nframeRate = 0.1 #//it will capture image in each 0.5 second\ncount=1\nsuccess = getFrame(sec)\nwhile success:\n    count = count + 1\n    sec = sec + frameRate\n    sec = round(sec, 2)\n    success = getFrame(sec)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_frame_n(n):\n    pic = plt.imread('image'+str(n)+'.jpg')\n    print(pic.shape)\n    plt.imshow(pic)\nshow_frame_n(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pic = plt.imread('image5.jpg')\ngray = rgb2gray(pic)\nplt.imshow(gray, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import cv2 as cv\nimport os\nimport matplotlib.pylab as plt\ntrain_dir = '../input/nfl-impact-detection/train/'\nfig, ax = plt.subplots(1,1, figsize=(15, 15))\ntrain_video_files = [train_dir + x for x in os.listdir(train_dir)]\n# video_file = train_video_files[30]\nvideo_file = '../input/nfl-impact-detection/train/57583_000082_Endzone.mp4'\ncap = cv.VideoCapture(video_file)\nsuccess, image = cap.read()\nimage = cv.cvtColor(image, cv.COLOR_BGR2RGB)\ncap.release()   \nax.imshow(image)\nax.xaxis.set_visible(False)\nax.yaxis.set_visible(False)\nax.title.set_text(f\"FRAME 0: {video_file.split('/')[-1]}\")\nplt.grid(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2\nimport numpy as np\nimport os\nimport re\n\n#listing down all the file names\nframes = os.listdir('./')\n\n#reading frames\nimages=[]\nfor i in frames[:-2]:\n    try:\n        img = cv2.imread('./'+i)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n        img = cv2.GaussianBlur(img,(25,25),0)\n        images.append(img)\n    except: continue\n        \n\nimages=np.array(images)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nonzero=[]\nfor i in range((len(images)-1)):\n    mask = cv2.absdiff(images[i],images[i+1])\n    _ , mask = cv2.threshold(mask, 50, 255, cv2.THRESH_BINARY)\n    num = np.count_nonzero((mask.ravel()))\n    nonzero.append(num)\n    \n    \nx = np.arange(0,len(images)-1)\ny = nonzero\n\nplt.figure(figsize=(20,4))\nplt.scatter(x,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold = 1000\nfor i in range(len(images)-1):\n    if(nonzero[i]>threshold): \n        scene_change_idx = i\n        break\n        \nframes = frames[:(scene_change_idx+1)]\nlen(frames)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img= cv2.imread('./' + frames[0])\ngray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\ngray = cv2.GaussianBlur(gray,(25,25),0)\n\nplt.figure(figsize=(5,10))\nplt.imshow(gray,cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"_ , mask = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY)\n\nplt.figure(figsize=(5,5))\nplt.imshow(mask,cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# To be continued"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}