{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n**Main Topic**\n\nThis notebook is for **generating coco format json files** using **images** and **image_labels.csv**\n\nBecasue I don't know how to approch this competition well, I'm trying to make Object Detection Model using images and videos first.\n\nSo for the first step, I converted bbox informations to coco json format.\n\nPlease tell me if there is any bug or improvement.\n\nafter this nb you can refer [Detecting Helmet using MMdetection w/o internet](https://www.kaggle.com/jinssaa/detecting-helmet-using-mmdetection-w-o-internet) to building \n\n`Helmet` detection model\n\n**References**\n\nI just customized this code from my old files, so please refer to me if there is any references code made by below style "},{"metadata":{},"cell_type":"markdown","source":"# Set up environment"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#-*- coding: utf-8 -*-\n\nimport json\nimport os\nimport cv2\nimport string\nimport random\nimport numpy as np\nimport pandas as pd\n\nfrom glob import glob\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_labels = pd.read_csv('../input/nfl-impact-detection/image_labels.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_labels.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_classes(CLASSES):\n    classes = list()      \n    \n    for i, CLASS in enumerate(CLASSES):\n        single_class = {} \n        single_class['id'] = i + 1\n        single_class['name'] = CLASS\n        classes.append(single_class)\n    return classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASSES = list(image_labels['label'].unique())\nclasses = gen_classes(CLASSES)\nclasses","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"I'm not sure but we might customize this classse to kind of {helmet, helmet-impact, shoulder-impact} etc, \n\nor predicting helmet can make some rule-based inference. I will just set `classes` only `Helmet`"},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = classes[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_objs(df, validation_ratio = 0.2, debug = False):\n    \n    if debug:\n        \n        df = df[:int(len(df)*0.05)]\n        \n    \n    img_lists = list(df['image'].unique()) ## gen unique image lists\n    imgs = list()\n    train_objs = list()\n    valid_objs = list() \n    \n    ## gen images information\n    for i in tqdm(range(len(img_lists))):\n        '''\n        \n        I just notice that all images were preprocessed image size 720x1280\n        If you want to check real image size, use this code below\n        \n        img = cv2.imread(os.path.join(data_path, img_lists[i]))\n        \n        single_img_obj = {}\n        single_img_obj['file_name'] = img_lists[i]\n        single_img_obj['height'] = img.shape[0]\n        single_img_obj['width'] = img.shape[1]\n        single_img_obj['id'] = i + 1\n        '''\n        \n        single_img_obj = {}\n        single_img_obj['file_name'] = img_lists[i]\n        single_img_obj['height'] = 720 \n        single_img_obj['width'] = 1280\n        single_img_obj['id'] = i + 1        \n        \n        imgs.append(single_img_obj)\n        \n        \n    ## gen train & val objs information        \n    train_df, valid_df = train_test_split(df, test_size = validation_ratio, random_state=42)\n    train_df = train_df.reset_index()\n    valid_df = valid_df.reset_index()\n    \n    ## gen train objs information    \n    for j in tqdm(range(len(train_df))):\n        single_obj = {}\n        single_obj['id'] = j + 1\n        single_obj['image_id'] = img_lists.index(df['image'][j]) + 1\n        single_obj['category_id'] = 1 # If you wanna set multi-class, set CLASSES.index(df['label'][j]) + 1\n        single_obj['area'] = float(df['width'][j]*df['height'][j])\n        single_obj['bbox'] = [int(df['left'][j]), int(df['top'][j]), int(df['width'][j]), int(df['height'][j])] ## [min_x, min_y, width, height]\n        single_obj['iscrowd'] = 0        \n        \n        train_objs.append(single_obj)\n        \n    ## gen valid objs information\n    for k in tqdm(range(len(valid_df))):\n        single_obj = {}\n        single_obj['id'] = k + 1\n        single_obj['image_id'] = img_lists.index(df['image'][k]) + 1\n        single_obj['category_id'] = 1 # If you wanna set multi-class, set CLASSES.index(df['label'][j]) + 1\n        single_obj['area'] = float(df['width'][k]*df['height'][k])\n        single_obj['bbox'] = [int(df['left'][k]), int(df['top'][k]), int(df['width'][k]), int(df['height'][k])]\n        single_obj['iscrowd'] = 0        \n        \n        valid_objs.append(single_obj)        \n    \n    print(f'images: {len(imgs)}, train objs: {len(train_objs)}, valid objs: {len(valid_objs)}')\n    \n    return imgs, train_objs, valid_objs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs, train_objs, valid_objs = gen_objs(image_labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"imgs[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_objs[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def gen_coco(outpath, classes, objs, imgs, train=True):\n    if train:\n        data_dict = {}\n        data_dict['images'] = []\n        data_dict['annotations'] = []\n        data_dict['categories'] = []\n        data_dict['images'].extend(imgs)\n        data_dict['annotations'].extend(objs)\n        data_dict['categories'].extend(classes)\n        \n    else:\n        data_dict = {}\n        data_dict['images'] = []\n        data_dict['categories'] = []\n        \n        data_dict['images'].extend(imgs)\n        data_dict['categories'].extend(classes)   \n\n    with open(outpath, 'w') as f_out:\n        json.dump(data_dict, f_out)\n    print(f'file generate at {outpath}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gen_coco('train.json', classes, train_objs, imgs, train=True)\ngen_coco('valid.json', classes, valid_objs, imgs, train=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}