{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction\n\n**Main Topic**\n\nThis notebook is for **Detecting Helmet using [MMdetection](https://github.com/open-mmlab/mmdetection) without internet** using **images** and **image_labels.csv**\n\nBefore you start this Kernel you need to make COCO format train, val.json, you can check [Create COCO Anntations](https://www.kaggle.com/jinssaa/create-coco-anntations) nb or refer [mydataset](https://www.kaggle.com/jinssaa/nflweightutils).\n\n\n**References**\n\n**Chris Deotte Grand master** : [How to Install Without Internet](https://www.kaggle.com/c/severstal-steel-defect-detection/discussion/113195)\n\n[**MMdetection Official Documents**](https://mmdetection.readthedocs.io/)\n"},{"metadata":{},"cell_type":"markdown","source":"# Install MMdetection from scratch\n\n**Version info.**\n\n- MMdetection 2.6.0\n- mmcv-full 1.2.0, torch 1.6, cu102\n\nBecause this Competetion is [Notebook Competetion](https://www.kaggle.com/docs/competitions#notebooks-only-FAQ), we need to inference .mp4 video without interent. \n\nSo I made `*.whl` files to install MMdetection, mmcv-full without internet. you can use this files from [mmdetection-v2.6.0 dataset](https://www.kaggle.com/jinssaa/mmdetectionv260).\n\n- note I think we don't need to `train` without internet so use local env if you want. this step for `inference` using weight."},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install ../input/mmdetectionv260/addict-2.4.0-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install ../input/mmdetectionv260/mmcv_full-latesttorch1.6.0cu102-cp37-cp37m-manylinux1_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install ../input/mmdetectionv260/mmpycocotools-12.0.3-cp37-cp37m-linux_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"! pip install ../input/mmdetectionv260/mmdet-2.6.0-py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Set up environment"},{"metadata":{"trusted":true},"cell_type":"code","source":"import copy\nimport os.path as osp\n\n# Check Pytorch installation\nimport torch, torchvision\nprint(torch.__version__, torch.cuda.is_available())\n\n# Check MMDetection installation\nimport mmdet\nprint(mmdet.__version__)\n\n# Check mmcv installation\nimport mmcv\nfrom mmcv.ops import get_compiling_cuda_version, get_compiler_version\nfrom mmcv import Config\nprint(get_compiling_cuda_version())\nprint(get_compiler_version())\n\nfrom mmdet.datasets import build_dataset, CocoDataset\nfrom mmdet.models import build_detector\nfrom mmdet.datasets.builder import DATASETS\nfrom mmdet.datasets.custom import CustomDataset\nfrom mmdet.apis import train_detector, set_random_seed, init_detector, inference_detector\n\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\n\nimport nflimpact\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\n\nfrom IPython.core.display import display, HTML","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Set Dataset\n\nThis class is from [MMdetection COCO.py](https://github.com/open-mmlab/mmdetection/blob/master/mmdet/datasets/coco.py)\n\n\nI just set `CLASSES` only `Helmet`, So you can customize if you want.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"@DATASETS.register_module()\nclass ImpactDataset(CocoDataset):\n    CLASSES = ('Helmet')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Get Config\n\nI shared [NFL-weight-utils Dataset](https://www.kaggle.com/jinssaa/nflweightutils). there are files below.\n\n- configs.py : Default faster R-CNN configs. you can customize, please check [Official MMdetection configs](https://github.com/open-mmlab/mmdetection/tree/master/configs)\n- train.json : train.json made by [Create COCO Anntations](https://www.kaggle.com/jinssaa/create-coco-anntations)\n- valid.json : valid.json made by [Create COCO Anntations](https://www.kaggle.com/jinssaa/create-coco-anntations)\n- resnet50-19c8e357.pth : Official pytorch resnet50 weight\n- latest.pth : pretrained faster R-CNN model trained by below configs, 10 epochs"},{"metadata":{"trusted":true},"cell_type":"code","source":"config_file = '../input/nflweightutils/configs.py'\ncfg = Config.fromfile(config_file)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"You need to modify some configs below."},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg.total_epochs = 1\ncfg.work_dir = './'\ncfg.seed = 0\nset_random_seed(0, deterministic=False)\ncfg.gpu_ids = range(1)\ncfg.data_root = '../input/nfl-impact-detection/'\n\ncfg.data.train.ann_file='../input/nflweightutils/train.json'\ncfg.data.train.img_prefix= cfg.data_root + 'images/'\n\ncfg.data.val.ann_file='../input/nflweightutils/valid.json',\ncfg.data.val.img_prefix= cfg.data_root + 'images/'\n\ncfg.data.test.ann_file='../input/nflweightutils/valid.json', ## I just set validation data for test because it's not our main purpose\ncfg.data.test.img_prefix= cfg.data_root + 'images/'\ncfg.model.pretrained = '../input/nflweightutils/resnet50-19c8e357.pth'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's check configs"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Config:\\n{cfg.pretty_text}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train model\n\nWhen we submit our result, we need to install MMdetection without internet. so install MMdetection locally.\n\njust build datasets and train model. I just train 1 epoch in this cell because it's not our main purpose. You can use MMdetection in local envs"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Build dataset\ndatasets = [build_dataset(cfg.data.train)]\n\n# Build the detector\nmodel = build_detector(\n    cfg.model, train_cfg=cfg.train_cfg, test_cfg=cfg.test_cfg)\n# Add an attribute for visualization convenience\nmodel.CLASSES = datasets[0].CLASSES\n\n# Create work_dir\nmmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))\ntrain_detector(model, datasets, cfg, distributed=False, validate=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test video\n\nLet's test video and visualize"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\n\n# Specify the path to model config and checkpoint file\ncheckpoint_file = '../input/nflweightutils/latest.pth' # 10 epochs\n\n# build the model from a config file and a checkpoint file\nmodel = init_detector(config_file, checkpoint_file, device='cuda:0')\n\n# test a video and show the results\nvideo = mmcv.VideoReader('../input/nfl-impact-detection/test/57906_000718_Endzone.mp4')\n\nims = []\n\nfor frame in video:\n    result = inference_detector(model, frame)\n    single_img = model.show_result(frame, result, wait_time=1)\n    im = plt.imshow(single_img, animated=True)\n    ims.append([im])\n    \nani = animation.ArtistAnimation(fig, ims, interval=50, blit=True,\n                                repeat_delay=1000)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Display video\n\nSorry for the low resolution. please let's me know if there a way to improve video rendering resolution !"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(HTML(ani.to_html5_video()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Next Step\n\nI think this Competition is quite a hard competition. it's hard to find way to predict `impact`. So please share your idea :)\n\nI'will try method below\n\n1. Get `impact` frames from  `train` folder. I made [full frame train images](https://www.kaggle.com/jinssaa/nfl-frame)(14GB) from train *.mp4. take only `impact` images and build `impact` detection model.\n\n2. train `impact` detection model, and configure using rule-based way(ex. get intersection pred vs pred)\n\n3. **any ideas?**\n\nThank you! Happy Kaggle !\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}