{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom pandas import read_csv\nimport statsmodels \nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns\nfrom datetime import datetime,date\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nimport keras\nimport math\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\n!pip install --upgrade pip\n!pip install -I Cython==0.28.5\n!pip install pyarrow\n\nimport pandas as pd\nimport pyarrow\nimport pyarrow.parquet\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_data = pd.read_csv(\"../input/nfl-impact-detection/train_player_tracking.csv\", header=0, index_col=3)\nnlf_label= pd.read_csv(\"../input/nfl-impact-detection/train_labels.csv\", header=0)\nnlf_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlf_label.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\" where train_label.video like\n57906_000718_Endzone\n57906_000718_Sideline\n57995_000109_Endzone\n57995_000109_Sideline\n58102_002798_Endzone\n58102_002798_Sideline\n\ntarget from train_label\ngamekey,join key\nplayID,join key\nview,\nvideo,\nframe,\nleft,\nwidth,\ntop,\nheight\n\nin really, I think I should predict the video by computer vision. but I still I don't leant and I think If it will be the 'nextH' we should predict similar like the sample_submission.csv\nmy udemy course include library what i think visionaly the videos. maybe. \n\nwhy we have test_player_tracking.csv? here we have keys but thats all. \n\n\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nlf_features = ['playID','view','video','frame','label','left','width','top','height']\nX = train_data[nlf_features]\nX.describe()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing import image_dataset_from_directory \n\nds_train_data = image_dataset_from_directory(\"../input/nfl-impact-detection\",\n                                             labels='inferred',\n                                             label_mode='binary',\n                                             image_size=[128,128],\n                                             interpolation='nearest',\n                                             batch_size=64,\n                                             shuffle=True,\n                                             )\nds_valid_ = image_dataset_from_directory(\n                                            \"../input/nfl-impact-detection\",\n                                            labels ='inferred',\n                                            label_mode='binary',\n                                            image_size=[128,128],\n                                            interpolation='nearest',\n                                            batch_size=64,\n                                            shuffle=False,\n                                            )\ndef convert_to_float(image, label):\n    image=tf.image.convert_image_dtype(image, dtype=df.float32)\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as keras\nimport tensorflow.keras.layers as layers\nfrom keras.datasets import mnist\nfrom keras.models import Sequential\nfrom keras.utils.np_utils import to_categorical\nfrom keras.layers import Dense, Conv2D, Flatten\n\n\n(X_train, y_train), (X_test, y_test) = mnist.load_data()\n\nX_train = X_train.reshape(60000,28,28,1)\nX_test = X_test.reshape(10000,28,28,1)\ny_train = to_categorical(y_train)\ny_test = to_categorical(y_test)\ny_train[0]\n\nmodel = Sequential()\nmodel.add(Conv2D(64, kernel_size=3, activation='relu',input_shape=(28,28,1)))\nmodel.add(Conv2D(32, kernel_size=3, activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(10,activation='softmax'))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.compile(optimizer='adam', loss='categorical_crossentropy',metrics=['accuracy'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction = model.predict(X_test[:4])\ny_test[:4]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pandas","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction2 = list(prediction) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_df = pd.DataFrame([id, prediction2]).transpose()\nout_df = out_df.rename(columns={0: 'id', 1: 'prediction2'})\nout_df ['prediction2'] = out_df['prediction2'].replace([2,0], [0,2])\nout_df.to_csv('submission.csv',index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}