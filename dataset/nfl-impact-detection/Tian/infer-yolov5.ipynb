{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfrom tqdm.auto import tqdm\nimport torch\nimport cv2\nfrom glob import glob","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"!cp -r ../input/yolov5git/yolov5-master/* .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATA_ROOT_PATH = 'test_images'\nWEIGHTS = '../input/yolov5m-1024-tmp/best.pt'\ndevice = torch.device( 'cuda' if torch.cuda.is_available() else 'cpu' )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/its7171/2class-object-detection-inference/\ndef mk_images(video_name, video_labels, video_dir, out_dir, only_with_impact=True):\n    video_path=f\"{video_dir}/{video_name}\"\n    video_name = os.path.basename(video_path)\n    vidcap = cv2.VideoCapture(video_path)\n    if only_with_impact:\n        boxes_all = video_labels.query(\"video == @video_name\")\n        print(video_path, boxes_all[boxes_all.impact == 1.0].shape[0])\n    else:\n        print(video_path)\n    frame = 0\n    while True:\n        it_worked, img = vidcap.read()\n        if not it_worked:\n            break\n        frame += 1\n        if only_with_impact:\n            boxes = video_labels.query(\"video == @video_name and frame == @frame\")\n            boxes_with_impact = boxes[boxes.impact == 1.0]\n            if boxes_with_impact.shape[0] == 0:\n                continue\n        img_name = f\"{video_name}_frame{frame}\"\n        image_path = f'{out_dir}/{video_name}'.replace('.mp4',f'_{frame}.png')\n        _ = cv2.imwrite(image_path, img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"out_dir = DATA_ROOT_PATH\nif not os.path.exists(out_dir):\n    !mkdir -p $out_dir\n    video_dir = '/kaggle/input/nfl-impact-detection/test'\n    uniq_video = [path.split('/')[-1] for path in glob(f'{video_dir}/*.mp4')]\n    for video_name in uniq_video:\n        mk_images(video_name, pd.DataFrame(), video_dir, out_dir, only_with_impact=False)\n        # for fast commit\n        if len(uniq_video) == 6:\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from utils.datasets import LoadImages\nfrom models.experimental import attempt_load\nfrom utils.torch_utils import time_synchronized\nfrom utils.general import *\nfrom utils.plots import plot_one_box","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = attempt_load(weights=WEIGHTS, map_location=device)  # load FP32 model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"names = model.module.names if hasattr(model, 'module') else model.names","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = LoadImages(DATA_ROOT_PATH, img_size=1024)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conf_thres = 0.25\niou_thres = 0.35\nscore_thres = 0.4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_image_ids = []\nresults_boxes = []\nresults_scores = []\n\nt0 = time.time()\nfor path, img, im0s, vid_cap in dataset:\n    img = torch.from_numpy(img).to(device).float()\n    img /= 255.0  # 0 - 255 to 0.0 - 1.0\n    if img.ndimension() == 3:\n        img = img.unsqueeze(0)\n\n    # Inference\n    t1 = time_synchronized()\n    pred = model(img, augment=False)[0]\n\n    # Apply NMS\n    pred = non_max_suppression(pred, conf_thres, iou_thres, classes=None, agnostic=False)\n    t2 = time_synchronized()\n\n    image_id = Path(path).name\n    \n    # Process detections\n    for i, det in enumerate(pred):  # detections per image\n        p, s, im0 = Path(path), '', im0s\n\n        det = det[det[:, 5] > 0]  # filter out 0\n        \n        if len(det):\n            # Rescale boxes from img_size to im0 size\n            det[:, :4] = scale_coords(img.shape[2:], det[:, :4], im0.shape).round()\n            \n            det[:, 2] = det[:, 2] - det[:, 0]\n            det[:, 3] = det[:, 3] - det[:, 1]\n            det[:, 0] = det[:, 0].clip(min=0, max=1280-1)\n            det[:, 2] = det[:, 2].clip(min=0, max=1280-1)\n            det[:, 1] = det[:, 1].clip(min=0, max=720-1)\n            det[:, 3] = det[:, 3].clip(min=0, max=720-1)\n            \n            result_image_ids += [image_id]*len(det)\n            results_boxes.append(det[:, :4].cpu().data.numpy())\n            results_scores.append(det[:, 4].cpu().data.numpy())\n\n            # Print results\n            for c in det[:, -1].unique():\n                n = (det[:, -1] == c).sum()  # detections per class\n                s += '%g %ss, ' % (n, names[int(c)])  # add to string\n\n        # Print time (inference + NMS)\n        print('%sDone. (%.3fs)' % (s, t2 - t1))\n\nprint('Done. (%.3fs)' % (time.time() - t0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"box_df = pd.DataFrame(np.concatenate(results_boxes), columns=['left', 'top', 'width', 'height'])\ntest_df = pd.DataFrame({'scores':np.concatenate(results_scores), 'image_name':result_image_ids})\ntest_df = pd.concat([test_df, box_df], axis=1)\n\ntest_df = test_df[test_df.scores > score_thres]\n\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#gameKey,playID,view,video,frame,left,width,top,height\n#57590,3607,Endzone,57590_003607_Endzone.mp4,1,1,1,1,1\ntest_df['gameKey'] = test_df.image_name.str.split('_').str[0].astype(int)\ntest_df['playID'] = test_df.image_name.str.split('_').str[1].astype(int)\ntest_df['view'] = test_df.image_name.str.split('_').str[2]\ntest_df['frame'] = test_df.image_name.str.split('_').str[3].str.replace('.png','').astype(int)\ntest_df['video'] = test_df.image_name.str.rsplit('_',1).str[0] + '.mp4'\ntest_df = test_df[[\"gameKey\",\"playID\",\"view\",\"video\",\"frame\",\"left\",\"width\",\"top\",\"height\"]]\ntest_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mv * /tmp/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import nflimpact\nenv = nflimpact.make_env()\nenv.predict(test_df) # d","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}