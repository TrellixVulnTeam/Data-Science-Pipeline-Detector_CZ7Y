{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('/kaggle/input/raft-pytorch')\nimport numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport torch\n\nfrom glob import glob\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:12.370193Z","iopub.execute_input":"2021-07-21T04:58:12.370593Z","iopub.status.idle":"2021-07-21T04:58:14.043045Z","shell.execute_reply.started":"2021-07-21T04:58:12.370559Z","shell.execute_reply":"2021-07-21T04:58:14.042269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom os import walk\nimport ast\nimport matplotlib.cm as cm\nimport matplotlib.animation as animation\nimport time\nimport pickle\n","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:14.044657Z","iopub.execute_input":"2021-07-21T04:58:14.044995Z","iopub.status.idle":"2021-07-21T04:58:14.053981Z","shell.execute_reply.started":"2021-07-21T04:58:14.044968Z","shell.execute_reply":"2021-07-21T04:58:14.052844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=sorted(int(x) for x in os.listdir(\"../input/dataflow\"))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:14.055241Z","iopub.execute_input":"2021-07-21T04:58:14.055779Z","iopub.status.idle":"2021-07-21T04:58:14.077757Z","shell.execute_reply.started":"2021-07-21T04:58:14.055715Z","shell.execute_reply":"2021-07-21T04:58:14.077041Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=[str(x) for x in a]\nstart=120+40","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:14.078754Z","iopub.execute_input":"2021-07-21T04:58:14.079015Z","iopub.status.idle":"2021-07-21T04:58:14.087407Z","shell.execute_reply.started":"2021-07-21T04:58:14.078988Z","shell.execute_reply":"2021-07-21T04:58:14.086562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a=a[40:80]","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:14.092429Z","iopub.execute_input":"2021-07-21T04:58:14.092707Z","iopub.status.idle":"2021-07-21T04:58:14.099447Z","shell.execute_reply.started":"2021-07-21T04:58:14.092679Z","shell.execute_reply":"2021-07-21T04:58:14.09852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data=[]\nfor i in range(len(a)):\n    rooot_filename=os.path.join(\"../input/dataflow\",a[i])\n    data.append({\n        \"filename\":os.path.join(rooot_filename,\"imgs\"),\n        \"annot\":os.path.join(rooot_filename,\"annotation.json\")\n    })","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:14.10271Z","iopub.execute_input":"2021-07-21T04:58:14.103145Z","iopub.status.idle":"2021-07-21T04:58:14.10922Z","shell.execute_reply.started":"2021-07-21T04:58:14.10311Z","shell.execute_reply":"2021-07-21T04:58:14.108231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"folder=[]\nannotations=[]\nfor i in range(len(data)):#len(data)):\n    filename=data[i][\"filename\"]\n    annot=data[i][\"annot\"]\n    \n    files=[]\n    for (dirpath, dirnames, f1) in walk(filename):\n        files.append(f1)\n        \n    with open(annot) as f:\n        d1= ast.literal_eval(f.read())\n        annotations.append(d1)\n    files=sorted([int(x[:-4]) for x in files[0]])\n    files=['{0:03}'.format(x) for x in files]\n    files=[os.path.join(filename,str(x)+'.jpg') for x in files]\n    folder.append(files)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:14.110693Z","iopub.execute_input":"2021-07-21T04:58:14.111184Z","iopub.status.idle":"2021-07-21T04:58:15.151751Z","shell.execute_reply.started":"2021-07-21T04:58:14.111146Z","shell.execute_reply":"2021-07-21T04:58:15.150828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# imagelist=[]\n# for d1,files in zip(annotations,folder):\n#     positions=[]\n#     for i in range(len(d1)):\n#         positionx,positiony=[int(x) for x in d1[i][\"position\"]]\n#         top=int(d1[i][\"bbox\"]['top'])\n#         left=int(d1[i][\"bbox\"]['left'])\n#         right=int(d1[i][\"bbox\"]['right'])\n#         bottom=int(d1[i][\"bbox\"]['bottom'])\n#         positions.append([positionx,positiony,top,left,right,bottom]) \n#     #print(positions)\n#     lis=[]\n#     for i in range(len(files)):\n#         #print(files[i])\n#         image = cv2.imread(os.path.join(files[i]))\n#         height, width, channels = image.shape\n#         for j in positions:\n#             start_point = (j[3],j[2])\n#             end_point = (j[4], j[5])\n#             color = (0,0,255)\n#             thickness = 2\n#             image = cv2.rectangle(image, start_point, end_point, color, thickness)\n#         imagelist.append(image)\n#     #imagelist.append(lis)\nfold=np.copy(folder)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:15.155355Z","iopub.execute_input":"2021-07-21T04:58:15.15564Z","iopub.status.idle":"2021-07-21T04:58:15.163884Z","shell.execute_reply.started":"2021-07-21T04:58:15.155611Z","shell.execute_reply":"2021-07-21T04:58:15.163083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# RAFT introduction\n\nI introduce the model: **RAFT: Recurrent All-Pairs Field Transforms for Optical Flow** which is originally introduced in ECCV2020 by Teed et. al. in Princeton University and prized Best Paper Award!.\n* https://arxiv.org/abs/2003.12039\n* https://github.com/princeton-vl/RAFT (licensed under the BSD 3-Clause License)\n\nBriefly, RAFT has below features\n* Recurrent optical flow estimation\n* Compute pixel-wise correlation between pair-wise input images and reuse it in the following recurrent step\n* Lightweight, rapid inference, and high accuracy\n\n![RAFT architecture image from https://github.com/princeton-vl/RAFT](https://github.com/princeton-vl/RAFT/raw/master/RAFT.png)\n\nThis is [my explanation slide](https://speakerdeck.com/daigo0927/raft-recurrent-all-pairs-field-transforms-for-optical-flow) in Japanese.","metadata":{}},{"cell_type":"markdown","source":"# Run RAFT on sample images","metadata":{}},{"cell_type":"code","source":"from raft.core.raft import RAFT\nfrom raft.core.utils import flow_viz\nfrom raft.core.utils.utils import InputPadder\nfrom raft.config import RAFTConfig","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","execution":{"iopub.status.busy":"2021-07-21T04:58:15.165404Z","iopub.execute_input":"2021-07-21T04:58:15.165722Z","iopub.status.idle":"2021-07-21T04:58:15.571891Z","shell.execute_reply.started":"2021-07-21T04:58:15.165693Z","shell.execute_reply":"2021-07-21T04:58:15.570976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = RAFTConfig(\n    dropout=0,\n    alternate_corr=False,\n    small=False,\n    mixed_precision=False\n)\n\nmodel = RAFT(config)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:15.575402Z","iopub.execute_input":"2021-07-21T04:58:15.575688Z","iopub.status.idle":"2021-07-21T04:58:15.699989Z","shell.execute_reply.started":"2021-07-21T04:58:15.575659Z","shell.execute_reply":"2021-07-21T04:58:15.699034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f'device: {device}')\n\nweights_path = '/kaggle/input/raft-pytorch/raft-sintel.pth'\n#weights_path = '/kaggle/input/raft-pytorch/raft-things.pth'\n\nckpt = torch.load(weights_path, map_location=device)\nmodel.to(device)\nmodel.load_state_dict(ckpt)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:15.703374Z","iopub.execute_input":"2021-07-21T04:58:15.703664Z","iopub.status.idle":"2021-07-21T04:58:20.263402Z","shell.execute_reply.started":"2021-07-21T04:58:15.703635Z","shell.execute_reply":"2021-07-21T04:58:20.2625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# image_files = glob('/kaggle/input/raft-pytorch/raft/demo-frames/*.png')\n# image_files = sorted(image_files)\n\n# print(f'Found {len(image_files)} images')\n# print(sorted(image_files))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:20.265038Z","iopub.execute_input":"2021-07-21T04:58:20.265474Z","iopub.status.idle":"2021-07-21T04:58:20.270009Z","shell.execute_reply.started":"2021-07-21T04:58:20.265429Z","shell.execute_reply":"2021-07-21T04:58:20.268753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_image(imfile, device):\n    img = np.array(Image.open(imfile)).astype(np.uint8)\n    img = torch.from_numpy(img).permute(2, 0, 1).float()\n    return img[None].to(device)\n\n\ndef viz(img1, img2, flo):\n    img1 = img1[0].permute(1,2,0).cpu().numpy()\n    img2 = img2[0].permute(1,2,0).cpu().numpy()\n    flo = flo[0].permute(1,2,0).cpu().numpy()\n    \n    # map flow to rgb image\n    flo = flow_viz.flow_to_image(flo)\n    \n    fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 4))\n    ax1.set_title('input image1')\n    ax1.imshow(img1.astype(int))\n    ax2.set_title('input image2')\n    ax2.imshow(img2.astype(int))\n    ax3.set_title('estimated optical flow')\n    ax3.imshow(flo)\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:20.271626Z","iopub.execute_input":"2021-07-21T04:58:20.272037Z","iopub.status.idle":"2021-07-21T04:58:20.287099Z","shell.execute_reply.started":"2021-07-21T04:58:20.271988Z","shell.execute_reply":"2021-07-21T04:58:20.286437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#len(imagelist[3])\n#imagelist","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:20.288062Z","iopub.execute_input":"2021-07-21T04:58:20.288318Z","iopub.status.idle":"2021-07-21T04:58:20.299321Z","shell.execute_reply.started":"2021-07-21T04:58:20.288272Z","shell.execute_reply":"2021-07-21T04:58:20.298501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for il,imagelist in enumerate(fold):\n    flows1=[]\n    model.eval()\n    n_vis = len(imagelist)-1\n    os.mkdir(f'{start+il+1}')\n    for i,(file1, file2) in enumerate(tqdm(zip(imagelist[:n_vis], imagelist[1:1+n_vis]))):\n        image1 = load_image(file1, device)\n        image2 = load_image(file2, device)\n\n        padder = InputPadder(image1.shape)\n        image1, image2 = padder.pad(image1, image2)\n\n        with torch.no_grad():\n            flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n\n        #viz(image1, image2, flow_up)\n        flo=flow_up\n        flo = flo[0].permute(1,2,0).cpu().numpy()\n        flo = flow_viz.flow_to_image(flo)\n        im = Image.fromarray(flo)\n        filename=os.path.join(f'{start+il+1}',f'{i}.jpeg')\n        im.save(filename)\n        #flows1.append(flo)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T04:58:20.301612Z","iopub.execute_input":"2021-07-21T04:58:20.301914Z","iopub.status.idle":"2021-07-21T05:15:42.494436Z","shell.execute_reply.started":"2021-07-21T04:58:20.301867Z","shell.execute_reply":"2021-07-21T05:15:42.493521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The first and second columns are input paired images and right column is the predicted optical flow.","metadata":{}},{"cell_type":"code","source":"# img=Image.open('./1/0.jpeg')\n# plt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.49585Z","iopub.execute_input":"2021-07-21T05:15:42.496372Z","iopub.status.idle":"2021-07-21T05:15:42.5006Z","shell.execute_reply.started":"2021-07-21T05:15:42.496328Z","shell.execute_reply":"2021-07-21T05:15:42.499774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# len(os.listdir('./1'))","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.501865Z","iopub.execute_input":"2021-07-21T05:15:42.502419Z","iopub.status.idle":"2021-07-21T05:15:42.512577Z","shell.execute_reply.started":"2021-07-21T05:15:42.502381Z","shell.execute_reply":"2021-07-21T05:15:42.51191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Run on NFL video","metadata":{}},{"cell_type":"code","source":"# video_file = '/kaggle/input/nfl-impact-detection/train/57583_000082_Endzone.mp4'\n\n# cap = cv2.VideoCapture(video_file)\n\n# frames = []\n# while True:\n#     has_frame, image = cap.read()\n    \n#     if has_frame:\n#         image = image[:, :, ::-1] # convert BGR -> RGB\n#         frames.append(image)\n#     else:\n#         break\n# frames = np.stack(frames, axis=0)\n\n# print(f'frame shape: {frames.shape}')    \n# plt.imshow(frames[0])","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.514033Z","iopub.execute_input":"2021-07-21T05:15:42.514409Z","iopub.status.idle":"2021-07-21T05:15:42.521572Z","shell.execute_reply.started":"2021-07-21T05:15:42.51437Z","shell.execute_reply":"2021-07-21T05:15:42.520514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# flows1=[]\n# n_vis = len(frames)-1\n\n# for i in range(n_vis):\n#     image1 = torch.from_numpy(frames[i]).permute(2, 0, 1).float().to(device)\n#     image2 = torch.from_numpy(frames[i+1]).permute(2, 0, 1).float().to(device)\n    \n#     image1 = image1[None].to(device)\n#     image2 = image2[None].to(device)\n\n#     padder = InputPadder(image1.shape)\n#     image1, image2 = padder.pad(image1, image2)\n    \n#     with torch.no_grad():\n#         flow_low, flow_up = model(image1, image2, iters=20, test_mode=True)\n# #     viz(image1, image2, flow_low)\n#     flo=flow_up\n#     flo = flo[0].permute(1,2,0).cpu().numpy()\n#     flo = flow_viz.flow_to_image(flo)\n#     flows1.append(flo)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.522772Z","iopub.execute_input":"2021-07-21T05:15:42.523141Z","iopub.status.idle":"2021-07-21T05:15:42.533083Z","shell.execute_reply.started":"2021-07-21T05:15:42.523103Z","shell.execute_reply":"2021-07-21T05:15:42.532344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RAFT seems to capture the motion of each player.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# frames = [] # for storing the generated images\n# fig = plt.figure()\n# plt.axis('off')\n# for i in range(len(flows1)):\n#     frames.append([plt.imshow(flows1[i], cmap=cm.Greys_r,animated=True)])\n\n# ani = animation.ArtistAnimation(fig, frames, interval=200, blit=True,\n#                                 repeat_delay=1000)\n# ani.save('movie.mp4')\n# plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.536464Z","iopub.execute_input":"2021-07-21T05:15:42.536726Z","iopub.status.idle":"2021-07-21T05:15:42.541725Z","shell.execute_reply.started":"2021-07-21T05:15:42.5367Z","shell.execute_reply":"2021-07-21T05:15:42.541032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# from IPython.display import HTML\n# from base64 import b64encode\n# filename12='./movie.mp4'\n# def play(filename12):\n#     html = ''\n#     video = open(filename12,'rb').read()\n#     src = 'data:video/mp4;base64,' + b64encode(video).decode()\n#     html += '<video width=1000 controls autoplay><source src=\"%s\" type=\"video/mp4\"></video>' % src \n#     return HTML(html)\n\n# play('./movie.mp4')","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.54293Z","iopub.execute_input":"2021-07-21T05:15:42.543316Z","iopub.status.idle":"2021-07-21T05:15:42.549884Z","shell.execute_reply.started":"2021-07-21T05:15:42.543258Z","shell.execute_reply":"2021-07-21T05:15:42.549214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !wget --quiet https://github.com/matterport/Mask_RCNN/releases/download/v2.0/mask_rcnn_coco.h5","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.553014Z","iopub.execute_input":"2021-07-21T05:15:42.553265Z","iopub.status.idle":"2021-07-21T05:15:42.558303Z","shell.execute_reply.started":"2021-07-21T05:15:42.55324Z","shell.execute_reply":"2021-07-21T05:15:42.557562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import pixellib\n# from pixellib.instance import instance_segmentation\n# import cv2\n\n# segment_video = instance_segmentation()\n# segment_video.load_model(\"mask_rcnn_coco.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.559903Z","iopub.execute_input":"2021-07-21T05:15:42.560481Z","iopub.status.idle":"2021-07-21T05:15:42.566196Z","shell.execute_reply.started":"2021-07-21T05:15:42.560315Z","shell.execute_reply":"2021-07-21T05:15:42.565384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# segment_video.process_video(\"../input/nfl-impact-detection/test/57906_000718_Endzone.mp4\", show_bboxes = True, frames_per_second= 15, output_video_name=\"traffic_monitor.mp4\")","metadata":{"execution":{"iopub.status.busy":"2021-07-21T05:15:42.567638Z","iopub.execute_input":"2021-07-21T05:15:42.568093Z","iopub.status.idle":"2021-07-21T05:15:42.577539Z","shell.execute_reply.started":"2021-07-21T05:15:42.568052Z","shell.execute_reply":"2021-07-21T05:15:42.576802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}