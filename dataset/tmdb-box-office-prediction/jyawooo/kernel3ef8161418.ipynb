{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# TMDB Box Office Prediction\n\n## 데이터 전처리\n\n- 'id', 'homepage', 'imdb_id', 'original_title', 'overvie', 'status', 'tagline', 'title', 'Keywords'와 같은 문자 데이터 또는 null값이 많은 데이터는 drop해주었다.\n\n\n- 딕셔너리 형태의 데이터를 가지고 있는 'genres', 'spoken languages', 'cast', 'crew' 와 같은 피처들은 그 수를 count하는 걸로 전처리를 했다.\n\n\n- 'belongs_to_collection'은 시리즈가 있는 것과 없는 것으로, 'original_language'는 영어와 비영어로 분류했다.\n\n\n- 'release_date'는 데이터의 형태가 list형으로 되어있어 날짜형 데이터로 바꾼 후 'release_year', 'release_month', 'release_day'로 쪼갰다."},{"metadata":{},"cell_type":"markdown","source":"#### import 후 데이터 확인하기"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn import preprocessing\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n\ntrain_df = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest_df = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\nprint(train_df.shape, test_df.shape)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# null값이 많은 데이터나 text위주의 데이터는 제외했다. 하지만, belongs_to_collection과 같은 피처는 revenue를 결정하는 데 유의미할 것 같아 drop하지 않았다.\ntrain_df = train_df[['belongs_to_collection', 'budget', 'genres', 'original_language', 'popularity', 'release_date', 'runtime', 'spoken_languages', 'cast', 'crew', 'revenue']]\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"isnull_series = train_df.isnull().sum()\nprint('\\n ### Null 칼럼과 그 건수 ### \\n', isnull_series[isnull_series>0].sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fillna를 이용해서 null을 0으로 바꿔준 후,\n# lambda 식을 통해 시리즈가 제작되지 않은 경우 0, 제작된 경우 1로 데이터를 변환했다.\ntrain_df['belongs_to_collection'] = train_df['belongs_to_collection'].fillna(0)\ntrain_df['belongs_to_collection'] = train_df['belongs_to_collection'].apply(lambda x : 0 if x == 0 else 1)\ntrain_df['belongs_to_collection'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['budget'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['original_language'] = train_df['original_language'].apply(lambda x : 1 if x == \"en\" else 0)\ntrain_df['original_language'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['popularity'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['release_date'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def date(x):\n    x=str(x)\n    year=x.split('/')[2]\n    if int(year)<20:\n        return x[:-2]+'20'+year\n    else:\n        return x[:-2]+'19'+year\ntrain_df['release_date']=train_df['release_date'].apply(lambda x: date(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['release_date']=train_df['release_date'].apply(lambda x : pd.datetime.strptime(x, '%m/%d/%Y'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['release_year']=train_df['release_date'].apply(lambda x : x.year)\ntrain_df['release_month']=train_df['release_date'].apply(lambda x : x.month)\ntrain_df['release_day']=train_df['release_date'].apply(lambda x : x.day)\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['runtime'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['spoken_languages'] = train_df['spoken_languages'].astype(str)\ntrain_df['spoken_languages'] = train_df['spoken_languages'].apply(lambda x:x.count(\"name\"))\ntrain_df['spoken_languages'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['spoken_languages'][train_df['spoken_languages']==0]=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['spoken_languages'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['cast'] = train_df['cast'].astype(str)\ntrain_df['cast'] = train_df['cast'].apply(lambda x:x.count(\"cast_id\"))\ntrain_df['cast'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['crew'] = train_df['crew'].astype(str)\ntrain_df['crew'] = train_df['crew'].apply(lambda x:x.count(\"credit_id\"))\ntrain_df['crew'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['genres'] = train_df['genres'].astype(str)\ntrain_df['genres'] = train_df['genres'].apply(lambda x:x.count(\"name\"))\ntrain_df['genres'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['revenue'].hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 최종 train_df\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#runtime 값이 null인 데이터를 발견해 평균값으로 대체\ntrain_df = train_df.drop('release_date', axis = 1)\ntrain_df['runtime'] = train_df['runtime'].fillna(train_df['runtime'].mean())\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('\\n ### 학습 데이터 정보 ### \\n')\nprint(train_df.info())\nprint('\\n ### 데이터 세트의 Shape ### \\n:', train_df.shape)\nprint('\\n ### 전체 피처의 type ### \\n', train_df.dtypes.value_counts())\nisnull_series = train_df.isnull().sum()\nprint('\\n ### Null 칼럼과 그 건수 ### \\n', isnull_series[isnull_series>0].sort_values(ascending=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error, mean_absolute_error\n\ndef rmsle(y, pred):\n    log_y = np.log1p(y)\n    log_pred = np.log1p(pred)\n    squared_error = (log_y - log_pred) ** 2\n    rmsle = np.sqrt(np.mean(squared_error))\n    return rmsle\n\ndef rmse(y, pred):\n    return np.sqrt(mean_squared_error(y, pred))\n\ndef evaluate_regr(y, pred):\n    rmsle_val = rmsle(y, pred)\n    rmse_val = rmse(y, pred)\n    mae_val = mean_absolute_error(y, pred)\n    print('RMSLE:{0:.3f}, RMSE:{1:.3F}, MAE:{2:.3F}'.format(rmsle_val, rmse_val, mae_val))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\n\ndef get_scaled_data(method='None', input_data=None):\n    if method == 'Standard':\n        scaled_data = StandardScaler().fit_transform(input_data)\n    elif method == 'MinMax':\n        scaled_data = MinMaxScaler().fit_transform(input_data)\n    elif method == 'Log' :\n        scaled_data = np.log1p(input_data)\n    else:\n        scaled_data = input_data\n                \n    return scaled_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ny_target = train_df['revenue']\nX_data = train_df.drop('revenue', axis=1, inplace = False)\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size = 0.5)\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\npred = lr.predict(X_test)\n\nevaluate_regr(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_target.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_target = get_scaled_data(method = 'Log', input_data = y_target)\ny_target.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_data, y_target,\n                                                    test_size = 0.5, random_state = 156)\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\npred = lr.predict(X_test)\n\nevaluate_regr(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data = get_scaled_data(method = 'Standard', input_data = X_data)\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_target,\n                                                    test_size = 0.5, random_state = 156)\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\npred = lr.predict(X_test)\n\nevaluate_regr(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_data = get_scaled_data(method = 'MinMax', input_data = X_data)\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_target, test_size = 0.5,\n                                                   random_state = 156)\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\npred = lr.predict(X_test)\n\nevaluate_regr(y_test, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\ny_target = train_df['revenue']\ny_target = np.log1p(y_target)\nX_data = train_df.drop('revenue', axis=1, inplace = False)\n\nX_train, X_test, y_train, y_test = train_test_split(X_data, y_target,\n                                                    test_size = 0.5, random_state = 156)\n\nlr = LinearRegression()\nlr.fit(X_train, y_train)\ny_preds = lr.predict(X_test)\nmse = mean_squared_error(y_test, y_preds)\nrmse = np.sqrt(mse)\n\nprint('MSE : {0:.3f}, RMSE : {1:.3F}'.format(mse, rmse))\nprint('Variance score : {0:.3f}'.format(r2_score(y_test, y_preds)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_names = ['belongs_to_collection', 'budget', 'genres', 'original_language', 'popularity', 'runtime', 'spoken_languages', 'cast', 'crew', 'release_year', 'release_month', 'release_day']\nfig, axs = plt.subplots(figsize=(16,8), ncols = 4, nrows = 3)\nfor i, feature in enumerate(col_names):\n    row = int(i/4)\n    col = i%4\n    \n    sns.regplot(x=feature, y='revenue', data=train_df, ax=axs[row][col])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.ensemble import RandomForestRegressor\n\nrf_reg = RandomForestRegressor(n_estimators = 1000)\nneg_mse_scores = cross_val_score(rf_reg, X_data, y_target, scoring=\"neg_mean_squared_error\", cv = 5)\nrmse_scores = np.sqrt(-1 * neg_mse_scores)\navg_rmse = np.mean(rmse_scores)\n\nprint(' 5 교차 검증의 개별 Negative MSE scores: ', np.round(neg_mse_scores, 2))\nprint(' 5 교차 검증의 개별 RMSE scores: ', np.round(rmse_scores, 2))\nprint(' 5 교차 검증의 평균 RMSE: {0:.3f}'.format(avg_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_cv_prediction(model, X_data, y_target):\n    neg_mse_scores=cross_val_score(model, X_data, y_target, scoring=\"neg_mean_squared_error\", cv=5)\n    rmse_scores = np.sqrt(-1*neg_mse_scores)\n    avg_rmse = np.mean(rmse_scores)\n    print('#### ', model.__class__.__name__, ' ####')\n    print(' 5 교차 검증의 평균 RMSE: {0:.3f}'.format(avg_rmse))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\ndt_reg = DecisionTreeRegressor(random_state=0, max_depth=4)\nrf_reg = RandomForestRegressor(random_state=0, n_estimators=1000)\ngb_reg = GradientBoostingRegressor(random_state=0, n_estimators=1000)\nxgb_reg = XGBRegressor(n_estimators=1000)\nlgb_reg = LGBMRegressor(n_estimators=1000)\n\nmodels = [dt_reg, rf_reg, gb_reg, xgb_reg, lgb_reg]\nfor model in models:\n    get_model_cv_prediction(model, X_data, y_target)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf_reg = RandomForestRegressor(n_estimators = 1000)\n\nrf_reg.fit(X_data, y_target)\n\nfeature_series = pd.Series(data=rf_reg.feature_importances_, index = X_data.columns)\nfeature_series = feature_series.sort_values(ascending=False)\nsns.barplot(x=feature_series, y=feature_series.index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}