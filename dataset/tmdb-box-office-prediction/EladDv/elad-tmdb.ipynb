{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Libraries\nimport numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split, KFold\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\nimport os\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nimport json\nimport ast\nimport eli5\nimport shap\nfrom tqdm import tqdm\nfrom catboost import CatBoostRegressor\nfrom urllib.request import urlopen\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainAdditionalFeatures = pd.read_csv('../input/tmdb-competition-additional-features/TrainAdditionalFeatures.csv')\ntestAdditionalFeatures = pd.read_csv('../input/tmdb-competition-additional-features/TestAdditionalFeatures.csv')\n\ntrain = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\n\ntrain = pd.merge(train, trainAdditionalFeatures, how='left', on=['imdb_id'])\ntest = pd.merge(test, testAdditionalFeatures, how='left', on=['imdb_id'])\ntest['revenue'] = -np.inf\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\ntrain.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000\n\n#Clean Data\ntest.loc[test['id'] == 6733,'budget'] = 5000000\ntest.loc[test['id'] == 3889,'budget'] = 15000000\ntest.loc[test['id'] == 6683,'budget'] = 50000000\ntest.loc[test['id'] == 5704,'budget'] = 4300000\ntest.loc[test['id'] == 6109,'budget'] = 281756\ntest.loc[test['id'] == 7242,'budget'] = 10000000\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\ntest.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30\n\n# from this kernel: https://www.kaggle.com/gravix/gradient-in-a-box\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ntrain = text_to_dict(train)\ntest = text_to_dict(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_date(x):\n    \"\"\"\n    Fixes dates which are in 20xx\n    \"\"\"\n    if not isinstance(x, str): return x\n    year = x.split('/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year\n\ntrain.loc[train['release_date'].isnull() == True, 'release_date'] = '01/01/19'\ntest.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/19'\n    \n#train[\"RevByBud\"] = train[\"revenue\"] / train[\"budget\"]\n    \ntrain['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])\n\n\n\ntrain['year'] = train['release_date'].dt.year\ntrain['month'] = train['release_date'].dt.month\ntrain['day'] = train['release_date'].dt.day\ntrain['weekday'] = train['release_date'].dt.weekday\n\n\ntest['year'] = test['release_date'].dt.year\ntest['month'] = test['release_date'].dt.month\ntest['day'] = test['release_date'].dt.day\ntest['weekday'] = test['release_date'].dt.weekday\ntrain_cp = train.copy()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfeatures_to_num = ['production_companies', 'production_countries', 'Keywords', 'cast', 'crew']\nfor f in features_to_num:\n    train_cp['num_'+f] = train_cp[f].apply(lambda x : len(x))\n\nfeatures = ['year','budget', 'revenue', 'popularity', 'num_production_companies', 'num_production_countries', 'runtime', 'num_Keywords', 'num_cast', 'num_crew']\n\nmeans = train_cp[features].groupby('year').mean()\nmeans['budget'] = np.log1p(means['budget'])\nmeans['revenue'] = np.log1p(means['revenue'])\n\nmedians = train_cp[features].groupby('year').median()\nmedians['budget'] = np.log1p(medians['budget'])\nmedians['revenue'] = np.log1p(medians['revenue'])\n\nfor f in features_to_num:\n    train_cp['median_num_'+f] = train_cp[f]\n    train_cp['mean_num_'+f] = train_cp[f]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in means.columns:\n    fig, ax = plt.subplots(figsize = (16, 6))\n    z = np.polyfit(range(len(means.index.values)), means[col], 1)\n    p = np.poly1d(z)\n    plt.plot(means.index.values, means[col]);\n    plt.plot(means.index.values,p(range(len(means.index.values))),\"b--\")\n    plt.text(0.1,0.9,\"a=%.6f, b=%.6f\"%(z[0],z[1]), horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n    plt.title('mean %s as a function of year'%col)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in medians.columns:\n    fig, ax = plt.subplots(figsize = (16, 6))\n    z = np.polyfit(range(len(medians.index.values)), medians[col], 1)\n    p = np.poly1d(z)\n    plt.plot(medians.index.values, medians[col]);\n    plt.plot(medians.index.values,p(range(len(medians.index.values))),\"b--\")\n    plt.text(0.1,0.9,\"a=%.6f, b=%.6f\"%(z[0],z[1]), horizontalalignment='center', verticalalignment='center', transform=ax.transAxes)\n    plt.title('median %s as a function of year'%col)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16, 6))\nplt.scatter(np.log1p(train_cp['budget']), np.log1p(train_cp['revenue']), c=train['year'], cmap=plt.cm.hot_r)\nplt.title('Log Revenue vs Log Budget')\nplt.xlabel(\"Log Budget\")\nlabel = set(train['year'].values)\nplt.xlabel(\"Log Revenue\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.countplot(train_cp['year'].sort_values())\nplt.title(\"Movie Release count by Year\",fontsize=20)\nloc, labels = plt.xticks()\nplt.xticks(fontsize=12,rotation=90)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.countplot(train['month'].sort_values())\nplt.title(\"Release Month Count\",fontsize=20)\nloc, labels = plt.xticks()\nloc, labels = loc, [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\nplt.xticks(loc, labels,fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.countplot(train['day'].sort_values())\nplt.title(\"Release Day Count\",fontsize=20)\nplt.xticks(fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.countplot(train['weekday'].sort_values())\nplt.title(\"Total movies released on Day Of Week\",fontsize=20)\nloc, labels = plt.xticks()\nloc, labels = loc, [\"Mon\",\"Tue\",\"Wed\",\"Thu\",\"Fri\",\"Sat\",\"Sun\"]\nplt.xticks(loc, labels,fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meanRevenueByMonth = train.groupby(\"month\")[\"revenue\"].aggregate('mean')\nmeanRevenueByMonth.plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release Month\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue Release Month\",fontsize=20)\nplt.show()\n\nmedianRevenueByMonth = train.groupby(\"month\")[\"revenue\"].aggregate('median')\nmedianRevenueByMonth.plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release Month\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Median Revenue Release Month\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meanRevenueByDay = train.groupby(\"day\")[\"revenue\"].aggregate('mean')\nmeanRevenueByDay.plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release Day\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue Release Day\",fontsize=20)\nplt.show()\n\nmedianRevenueByDay = train.groupby(\"day\")[\"revenue\"].aggregate('median')\nmedianRevenueByDay.plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release Day\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Median Revenue Release Day\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"meanRevenueByDay = train.groupby(\"weekday\")[\"revenue\"].aggregate('mean')\nmeanRevenueByDay.plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release WeekDay\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue Release WeekDay\",fontsize=20)\nplt.show()\n\nmedianRevenueByDay = train.groupby(\"weekday\")[\"revenue\"].aggregate('median')\nmedianRevenueByDay.plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release WeekDay\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Median Revenue Release WeekDay\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,12))\nsns.countplot(train['rating'].sort_values())\nplt.title(\"Train Rating Count\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cp['meanRevenueByRating'] = train.groupby(\"rating\")[\"revenue\"].aggregate('mean')\ntrain_cp['meanRevenueByRating'].plot(figsize=(15,10),color=\"g\")\nplt.xlabel(\"Release Year\")\nplt.ylabel(\"Revenue\")\nplt.title(\"Movie Mean Revenue By Rating\",fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_dictionary(s):\n    try:\n        d = ''\n        d_l = [k['name'] for k in s]\n        for l in d_l:\n            d += l + ','\n        d = d[:-1]\n    except:\n        d = ''\n    return d\n#train = train\n#train['genres'] = train['genres'].map(lambda x: sorted([d['name'] for d in get_dictionary(x)])).map(lambda x: ','.join(map(str, x)))\ndata = pd.concat([train,test], axis=0, sort=False)\ngenres = data['genres'].apply(get_dictionary)\ngenres = genres.str.get_dummies(sep=',')\ndata = pd.concat([data, genres], axis=1, sort=False)\n\ntrain = data[data['revenue'] != -np.inf]\ntest = data[data['revenue'] == -np.inf]\n\nprint(\"Action Genres Movie           \", train[train.Action == 1].shape[0])\nprint(\"Adventure Genres Movie        \", train[train.Adventure == 1].shape[0])\nprint(\"Animation Genres Movie        \", train[train.Animation == 1].shape[0])\nprint(\"Comedy Genres Movie           \", train[train.Comedy == 1].shape[0])\nprint(\"Crime Genres Movie            \", train[train.Crime == 1].shape[0])\nprint(\"Documentary Genres Movie      \", train[train.Documentary == 1].shape[0])\nprint(\"Drama Genres Movie            \", train[train.Drama == 1].shape[0])\nprint(\"Family Genres Movie           \", train[train.Family == 1].shape[0])\nprint(\"Fantasy Genres Movie          \", train[train.Fantasy == 1].shape[0])\nprint(\"Foreign Genres Movie          \", train[train.Foreign == 1].shape[0])\nprint(\"History Genres Movie          \", train[train.History == 1].shape[0])\nprint(\"Music Genres Movie            \", train[train.Music == 1].shape[0])\nprint(\"Mystery Genres Movie          \", train[train.Mystery == 1].shape[0])\nprint(\"Romance Genres Movie          \", train[train.Romance == 1].shape[0])\nprint(\"Science Fiction Genres Movie  \", train[train['Science Fiction'] == 1].shape[0])\nprint(\"TV Movie Genres Movie         \", train[train['TV Movie'] == 1].shape[0])\nprint(\"Thriller Genres Movie         \", train[train.Thriller == 1].shape[0])\nprint(\"War Genres Movie              \", train[train.War == 1].shape[0])\nprint(\"Western Genres Movie          \", train[train.Western == 1].shape[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.genres[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['has_homepage'] = 1\ntrain.loc[pd.isnull(train['homepage']) ,\"has_homepage\"] = 0\nplt.figure(figsize=(15,8))\nsns.countplot(train['has_homepage'].sort_values())\nplt.title(\"Has Homepage?\",fontsize=20)\nplt.show()\n\ntrain['isTaglineNA'] = 0\ntrain.loc[pd.isnull(train['tagline']) ,\"isTaglineNA\"] = 1\nsns.catplot(x=\"isTaglineNA\", y=\"revenue\", data=train)\nplt.title('Revenue of movies with and without a tagline')\nplt.show()\n\ntrain['isTitleDifferent'] = 1\ntrain.loc[ train['original_title'] == train['title'] ,\"isTitleDifferent\"] = 0 \nsns.catplot(x=\"isTitleDifferent\", y=\"revenue\", data=train)\nplt.title('Revenue of movies with single and multiple titles')\nplt.show()\n\ntrain['isOriginalLanguageEng'] = 0 \ntrain.loc[ train['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\nsns.catplot(x=\"isOriginalLanguageEng\", y=\"revenue\", data=train)\nplt.title('Revenue of movies when Original Language is English and Not English')\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntest['has_homepage'] = 1\ntest.loc[pd.isnull(test['homepage']) ,\"has_homepage\"] = 0\nplt.figure(figsize=(15,8))\nsns.countplot(test['has_homepage'].sort_values())\nplt.title(\"Has Homepage?\",fontsize=20)\nplt.show()\n\ntest['isTaglineNA'] = 0\ntest.loc[pd.isnull(test['tagline']) ,\"isTaglineNA\"] = 1\n#sns.catplot(x=\"isTaglineNA\", y=\"revenue\", data=test)\n#plt.title('Revenue of movies with and without a tagline')\n#plt.show()\n\ntest['isTitleDifferent'] = 1\ntest.loc[ test['original_title'] == test['title'] ,\"isTitleDifferent\"] = 0 \n#sns.catplot(x=\"isTitleDifferent\", y=\"revenue\", data=test)\n#plt.title('Revenue of movies with single and multiple titles')\n#plt.show()\n\ntest['isOriginalLanguageEng'] = 0 \ntest.loc[ test['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n#sns.catplot(x=\"isOriginalLanguageEng\", y=\"revenue\", data=test)\n#plt.title('Revenue of movies when Original Language is English and Not English')\n#plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ndef fill(df, col):\n    return random.choice(df[df[col] != np.nan][col])\n\ntrain['rating'] = train['rating'].map(lambda x: fill(train, 'rating') if np.isnan(x) else x)\ntrain['totalVotes'] = train['totalVotes'].map(lambda x: fill(train, 'totalVotes') if np.isnan(x) else x)\n#train['totalVotes'].fillna(lambda x: fill(train, 'totalVotes'))\n\ntest['rating'] = test['rating'].map(lambda x: fill(test, 'rating') if np.isnan(x) else x)\ntest['totalVotes'] = test['totalVotes'].map(lambda x: fill(test, 'totalVotes') if np.isnan(x) else x)\n\n#test['rating'].fillna(lambda x: fill(test, 'rating'))\n#test['totalVotes'].fillna(lambda x: fill(test, 'totalVotes'))\n\nplt.figure(figsize=(20,12))\nsns.countplot(train['rating'].sort_values())\nplt.title(\"Train Rating Count\",fontsize=20)\nplt.show()\n\nplt.figure(figsize=(20,12))\nsns.countplot(train['totalVotes'].sort_values())\nplt.title(\"Train Votes Count\",fontsize=20)\nplt.show()\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_plot = train[['budget','rating','totalVotes','popularity','runtime','year','month','day', 'weekday','revenue']]\nf,ax = plt.subplots(figsize=(10, 8))\nsns.heatmap(train_plot.corr(), annot=True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([train,test], sort=False)\nrating_null = df_all.groupby([\"year\",\"original_language\"])['rating'].mean().reset_index()\ndf_all[df_all.rating.isna()]['rating'] = df_all.merge(rating_null, how = 'left' ,on = [\"year\",\"original_language\"])\n\ntrain = df_all[df_all['revenue'] != -np.inf]  \ntest = df_all[df_all['revenue'] == -np.inf]  \n\n# Adding Producer and Director column to data\ntrain['Producer'] = train['crew'].apply(lambda x : [str(i['name']) for i in x if i['job']=='Producer'])\ntest['Producer'] = test['crew'].apply(lambda x : [str(i['name']) for i in x if i['job']=='Producer'])\n\ntrain['ProducerT'] = train['Producer'].apply(lambda x: str(x)[2:-2])\ntest['ProducerT'] = test['Producer'].apply(lambda x: str(x)[2:-2])\n\ntrain['Director'] = train['crew'].apply(lambda x : [i['name'] for i in x if i['job']=='Director'])\ntest['Director'] = test['crew'].apply(lambda x : [i['name'] for i in x if i['job']=='Director'])\n\ntrain['DirectorT'] = train['Director'].apply(lambda x: str(x)[2:-2])\ntest['DirectorT'] = test['Director'].apply(lambda x: str(x)[2:-2])\n\n# Creates list and data frame for producers and directors\ndirectors_list = np.concatenate((train['DirectorT'].unique(),test['DirectorT'].unique()))\nunique_directors = np.unique(directors_list).tolist()\ndf = pd.DataFrame(unique_directors, columns = ['name' ])\ndf['movies_num'] = 0\ndf['score'] = 0\ndf['popularity'] = 0.0\ndf['director_avg_score'] = 0.0\ndf['director_avg_popularity'] = 0.0\ndf.set_index('name', inplace=True)\n\n\nproducers_list = np.concatenate((train['ProducerT'].unique(),test['ProducerT'].unique()))\nunique_producers = np.unique(producers_list).tolist()\ndf2 = pd.DataFrame(unique_producers, columns = ['name' ])\ndf2['movies_num'] = 0\ndf2['score'] = 0\ndf2['popularity'] = 0.0\ndf2['producer_avg_score'] = 0.0\ndf2['producer_avg_popularity'] = 0.0\ndf2.set_index('name', inplace=True)\n\n\n# Calculates the average rating and popularity of each Director/Producer\nfor i in tqdm(range(len(train))):\n    df.at[train['DirectorT'][i],'score'] += train['rating'][i]\n    df.at[train['DirectorT'][i],'popularity'] += train['popularity'][i]\n    df.at[train['DirectorT'][i],'movies_num'] += 1\n     \n    df2.at[train['ProducerT'][i],'score'] += train['rating'][i]\n    df2.at[train['ProducerT'][i],'popularity'] += train['popularity'][i]\n    df2.at[train['ProducerT'][i],'movies_num'] += 1\n        \nfor i in tqdm(range(len(test))):\n    try: \n        df.at[test['DirectorT'][i],'score'] += test['rating'][i]\n        df.at[test['DirectorT'][i],'popularity'] += test['popularity'][i]\n        df.at[test['DirectorT'][i],'movies_num'] += 1\n    except:\n        pass\n    \n    try:\n        df2.at[test['ProducerT'][i],'score'] += test['rating'][i]\n        df2.at[test['ProducerT'][i],'popularity'] += test['popularity'][i]\n        df2.at[test['ProducerT'][i],'movies_num'] += 1\n    except:\n        pass\nfor i in tqdm(range(len(unique_directors))):\n    df.at[unique_directors[i],'director_avg_score'] = df.at[unique_directors[i],'score']/df.at[unique_directors[i],'movies_num']\n    df.at[unique_directors[i],'director_avg_popularity'] = df.at[unique_directors[i],'popularity']/df.at[unique_directors[i],'movies_num']\nfor i in tqdm(range(len(unique_producers))):   \n    df2.at[unique_producers[i],'producer_avg_score'] = df2.at[unique_producers[i],'score']/df2.at[unique_producers[i],'movies_num']\n    df2.at[unique_producers[i],'producer_avg_popularity'] = df2.at[unique_producers[i],'popularity']/df2.at[unique_producers[i],'movies_num']\n    \n# Creates new columns of the average score/popularity of directors/producers in specific film\ntest['director_avg_score'] = 0.0\ntest['director_avg_popularity'] = 0.0\ntrain['director_avg_score'] = 0.0\ntrain['director_avg_popularity'] = 0.0\n\ntest['producer_avg_score'] = 0.0\ntest['producer_avg_popularity'] = 0.0\ntrain['producer_avg_score'] = 0.0\ntrain['producer_avg_popularity'] = 0.0\n\nlunch = False\nif lunch:\n    for i in tqdm(range(len(train))):\n        director, ld = df.loc[train['DirectorT'][i]][['director_avg_popularity', 'director_avg_score']],len(train['Director'][i])\n        producer, lp = df2.loc[train['ProducerT'][i]][['producer_avg_popularity', 'producer_avg_score']],len(train['Producer'][i])\n        if ld==0:\n            train['director_avg_popularity'][i] = 0.0\n            train['director_avg_score'][i] = 0.0\n        else :\n            train['director_avg_popularity'][i] = director[0]/ld\n            train['director_avg_score'][i] = director[1]/ld \n\n        if lp==0:\n            train['producer_avg_popularity'][i] = 0.0\n            train['producer_avg_score'][i] = 0.0\n        else :\n            train['producer_avg_popularity'][i] = producer[0]/lp\n            train['producer_avg_score'][i] = producer[1]/lp \n\n    for i in tqdm(range(len(test))):\n        director, ld = df.loc[test['DirectorT'][i]][['director_avg_popularity', 'director_avg_score']],len(test['Director'][i])\n        producer, lp = df2.loc[test['ProducerT'][i]][['producer_avg_popularity', 'producer_avg_score']],len(test['Producer'][i])\n        if ld==0:\n            test['director_avg_popularity'][i] = 0.0\n            test['director_avg_score'][i] = 0.0\n        else :\n            test['director_avg_popularity'][i] = director[0]/ld\n            test['director_avg_score'][i] = director[1]/ld \n\n        if lp==0:\n            test['producer_avg_popularity'][i] = 0.0\n            test['producer_avg_score'][i] = 0.0\n        else :\n            test['producer_avg_popularity'][i] = producer[0]/lp\n            test['producer_avg_score'][i] = producer[1]/lp \n\n    for i in tqdm(range(len(unique_directors))):\n        df.loc[unique_directors[i]]['score'] = df.loc[unique_directors[i]]['score']/df.loc[unique_directors[i]]['movies_num']\n\n    # Crew popularity is more relevant than avg rating/popularity \n    train['crew_popularity'] = train['producer_avg_popularity'] + train['director_avg_popularity']\n    test['crew_popularity'] = test['producer_avg_popularity'] + test['director_avg_popularity']\n\n    # Deletes producer,director and crew columns\ndrop_colums = ['Producer', 'Director', 'DirectorT', 'ProducerT']\nfor i in drop_colums:\n    train = train.drop([i], axis=1)\n    test = test.drop([i], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# get all actors names\n\ndf = pd.concat([train,test], sort=False)\n\ndef get_all_names(col):\n    all_names = []\n    for col_list in df[col]:\n        for value in col_list:\n            if not value['name'] in all_names:\n                all_names.append(value['name'])\n    return all_names\nactors_names = get_all_names('cast')\nprint('number of actors: ',len(actors_names))\n\nactors = pd.DataFrame(0, index=actors_names, columns=['num_movies', 'mean_revenue'])\n\nfor index, row in tqdm(df.iterrows(), total=df.shape[0]):\n    movie = row['title']\n    cast = row['cast']\n    genres = row['genres']\n    rev = row['revenue']\n    actors_in_movie = [a['name'] for a in cast]\n    genres_in_movie = [a['name'] for a in genres]\n    # save data on actor\n    for a in actors_in_movie:\n        if rev != -np.inf:\n            actors.loc[a]['num_movies'] += 1\n            actors.loc[a]['mean_revenue'] += rev\n        \n# calculate mean revenue\nactors['num_movies'][actors['num_movies'] == 0] = 1\nactors['mean_revenue'] = actors['mean_revenue']/actors['num_movies']\nactors['mean_revenue'] = actors.apply(lambda row: np.nan if row['num_movies'] < 2 else row['mean_revenue'], axis=1)\n# bin actors by profit\nq = list(actors.mean_revenue.quantile(q=[0.25, 0.5, 0.75]))\nbins = [-np.inf]\nbins.extend(q)\nbins.append(np.inf)\nlables = [0, 1, 2, 3]\nactors['level'] = pd.cut(actors['mean_revenue'], bins=bins, labels=lables, include_lowest=False)\nactors['level'] = actors['level'].cat.add_categories(4).fillna(4)\n#actors['level'] = actors['level'].cat.reorder_categories(new_categories=(0,1,2,3))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare(train_df):\n    df = train_df.copy() \n    #print(df.columns)\n    \n    #rating_null = df.groupby([\"year\",\"original_language\"])['rating'].mean().reset_index()\n    #df[df.rating.isna()]['rating'] = df.merge(rating_null, how = 'left' ,on = [\"year\",\"original_language\"])\n\n    df['inflationBudget'] = df['budget'] + df['budget']*1.8/100*(2018-df['year']) #Inflation simple formula \n    df['log_budget'] = np.log1p(df['budget'])\n    df['log_inflationBudget'] = np.log1p(df['inflationBudget'])\n    \n    df['genders_0_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\n    df['genders_1_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\n    df['genders_2_crew'] = df['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n    df['is_in_collection'] = df['belongs_to_collection'].apply(lambda x: 1 if x != {} else 0)\n    df['movies_in_collection'] = df['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n    df['num_genres'] = df['genres'].apply(lambda x: len(x) if x != {} else 0)\n    df['num_spoken_langs'] = df['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\n    df['num_Keywords'] = df['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n    df['num_cast'] = df['cast'].apply(lambda x: len(x) if x != {} else 0)\n    \n    df['popularity_mean_year'] = df['popularity'] / df.groupby(\"year\")[\"popularity\"].transform('mean')\n    df['runtime_mean_year'] = df['runtime'] / df.groupby(\"year\")[\"runtime\"].transform('mean')\n    df['log_budget_mean_year'] = df['log_budget']/ df.groupby(\"year\")[\"log_budget\"].transform('mean')\n    df['totalVotes_mean_year'] = df['totalVotes'] / df.groupby(\"year\")[\"totalVotes\"].transform('mean')\n    df['rating_mean_year'] = df['rating'] / df.groupby(\"year\")[\"rating\"].transform('mean')\n    df['log_budget_runtime_ratio'] = df['log_budget']/df['runtime'] \n    df['log_budget_popularity_ratio'] = df['log_budget']/df['popularity']\n    \n    df['popularity_totalVotes_ratio'] = df['totalVotes']/df['popularity']\n    df['rating_popularity_ratio'] = df['rating']/df['popularity']\n    df['rating_totalVotes_ratio'] = df['totalVotes']/df['rating']\n    df['budget_rating_ratio'] = df['log_budget']/df['rating']\n    df['runtime_rating_ratio'] = df['runtime']/df['rating']\n    df['budget_totalVotes_ratio'] = df['log_budget']/df['totalVotes']\n    \n    df['has_homepage'] = 1\n    df.loc[pd.isnull(df['homepage']) ,\"has_homepage\"] = 0\n     \n    df['has_tagline'] = 0\n    df.loc[df['tagline'] == 0 ,\"has_tagline\"] = 1 \n\n    df['is_eng'] = 0 \n    df.loc[ df['original_language'] == \"en\" ,\"is_eng\"] = 1\n    \n    df['isTitleDifferent'] = 1\n    df.loc[ df['original_title'] == df['title'] ,\"isTitleDifferent\"] = 0 \n\n    # get collection id    \n    df['original_title_letter_count'] = df['original_title'].str.len() \n    df['original_title_word_count'] = df['original_title'].str.split().str.len() \n\n\n    df['title_word_count'] = df['title'].str.split().str.len()\n    df['overview_word_count'] = df['overview'].str.split().str.len()\n    df['tagline_word_count'] = df['tagline'].str.split().str.len()\n    \n    df['production_countries_count'] = df['production_countries'].apply(lambda x : len(x))\n    df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\n    df['cast_count'] = df['cast'].apply(lambda x : len(x))\n    df['crew_count'] = df['crew'].apply(lambda x : len(x))\n    \n    levels = np.zeros((len(df),5))\n    for i, row in tqdm(df.iterrows(), total=df.shape[0]):\n        cast = row['cast']\n        actors_in_movie = [a['name'] for a in cast]\n        # save data on actor\n        for a in actors_in_movie:\n            levels[i, actors.loc[a]['level']] += 1  \n    df[[\"level_0\", \"level_1\", \"level_2\", \"level_3\", \"level_-1\"]] = levels\n    df[[\"level_0\", \"level_1\", \"level_2\", \"level_3\", \"level_-1\"]] /= df['cast_count']\n\n    df = df.drop(['id','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline', 'budget'\n    ],axis=1)\n    #print(df.columns)\n    df.fillna(value=0.0, inplace = True) \n    return df\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\n\ndef intersection(lst1, lst2): \n    lst3 = [value for value in lst1 if not value in lst2] \n    return lst3 \n\nprint(len(set(test.columns.values)))\nprint(len(set(train.columns.values)))\nprint(intersection(list(test.columns.values), list(train.columns.values)))\nprint(intersection(list(train.columns.values), list(test.columns.values)))\nprint(test.shape, train.shape)\n\ndf = pd.concat([train,test], sort=False)\ndata_df = prepare(df)\ntrain_df = data_df[data_df['revenue'] != -np.inf]\ntest_df = data_df[data_df['revenue'] == -np.inf]\n\nX, y = train_df.drop(['revenue'],axis=1), np.log1p(train_df['revenue'])\nXtest = test_df.drop(['revenue'],axis=1)\n\nrandom_seed = 42\nk = 5\nfold = list(KFold(k, shuffle = True, random_state = random_seed).split(X,y))\nnp.random.seed(random_seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"import xgboost as xgb\nimport lightgbm as lgb\nfrom catboost import CatBoostRegressor\n\ndef cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n    model = CatBoostRegressor(iterations=100000,\n                                 learning_rate=0.004,\n                                 depth=5,\n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.8,\n                                 random_seed = random_seed,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=200\n                                )\n    model.fit(trn_x, trn_y,\n                 eval_set=(val_x, val_y),\n                 use_best_model=True,\n                 verbose=False)\n    \n    val_pred = model.predict(val_x)\n    test_pred = model.predict(test)\n    #print('error:', model.get_best_score())\n    return {'val':val_pred, \n            'test':test_pred, \n            'error':model.get_best_score()['validation']['RMSE']}\n\ndef xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    params = {'objective': 'reg:linear', \n              'eta': 0.01, \n              'max_depth': 6, \n              'subsample': 0.6, \n              'colsample_bytree': 0.7,  \n              'eval_metric': 'rmse', \n              'seed': random_seed, \n              'silent': True,\n    }\n    \n    record = dict()\n    model = xgb.train(params\n                      , xgb.DMatrix(trn_x, trn_y)\n                      , 100000\n                      , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n                      , verbose_eval=verbose\n                      , early_stopping_rounds=500\n                      , callbacks = [xgb.callback.record_evaluation(record)])\n    best_idx = np.argmin(np.array(record['valid']['rmse']))\n\n    val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n    test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n\n    return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}\n\ndef lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n\n    params = {'objective':'regression',\n         'num_leaves' : 30,\n         'min_data_in_leaf' : 20,\n         'max_depth' : 9,\n         'learning_rate': 0.004,\n         #'min_child_samples':100,\n         'feature_fraction':0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         'lambda_l1': 0.2,\n         \"bagging_seed\": random_seed,\n         \"metric\": 'rmse',\n         #'subsample':.8, \n          #'colsample_bytree':.9,\n         \"random_state\" : random_seed,\n         \"verbosity\": -1}\n\n    record = dict()\n    model = lgb.train(params\n                      , lgb.Dataset(trn_x, trn_y)\n                      , num_boost_round = 100000\n                      , valid_sets = [lgb.Dataset(val_x, val_y)]\n                      , verbose_eval = verbose\n                      , early_stopping_rounds = 500\n                      , callbacks = [lgb.record_evaluation(record)]\n                     )\n    best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\n    val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n    test_pred = model.predict(test, num_iteration = model.best_iteration)\n    \n    return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_dict = dict()\nval_pred = np.zeros(train.shape[0])\ntest_pred = np.zeros(test.shape[0])\nfinal_err = 0\nverbose = False\nimport time\ndef now():\n    return datetime.datetime.fromtimestamp(time.time())\nfor i, (trn, val) in enumerate(fold) :\n    print(i+1, \"fold.    RMSE\")\n    \n    trn_x = X.loc[trn, :]\n    trn_y = y[trn]\n    val_x = X.loc[val, :]\n    val_y = y[val]\n    \n    fold_val_pred = []\n    fold_test_pred = []\n    fold_err = []\n    \n    #\"\"\" xgboost\n    start = now()\n    result = xgb_model(trn_x, trn_y, val_x, val_y, Xtest, verbose)\n    fold_val_pred.append(result['val']*0.2)\n    fold_test_pred.append(result['test']*0.2)\n    fold_err.append(result['error'])\n    print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((now()-start).seconds/60)) + 'm)')\n    #\"\"\"\n    \n    #\"\"\" lightgbm\n    start = now()\n    result = lgb_model(trn_x, trn_y, val_x, val_y, Xtest, verbose)\n    fold_val_pred.append(result['val']*0.4)\n    fold_test_pred.append(result['test']*0.4)\n    fold_err.append(result['error'])\n    print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((now()-start).seconds/60)) + 'm)')\n    #\"\"\"\n    \n    #\"\"\" catboost model\n    start = now()\n    result = cat_model(trn_x, trn_y, val_x, val_y, Xtest, verbose)\n    fold_val_pred.append(result['val']*0.4)\n    fold_test_pred.append(result['test']*0.4)\n    fold_err.append(result['error'])\n    print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((now()-start).seconds/60)) + 'm)')\n    #\"\"\"\n    \n    # mix result of multiple models\n    val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n    #print(fold_test_pred)\n    #print(fold_test_pred.shape)\n    #print(fold_test_pred.columns)\n    test_pred += np.mean(np.array(fold_test_pred), axis = 0) / k\n    final_err += (sum(fold_err) / len(fold_err)) / k\n    \n    print(\"---------------------------\")\n    print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n    print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n    \n    print('')\n    \nprint(\"fianl avg   err.\", final_err)\nprint(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/tmdb-box-office-prediction/sample_submission.csv')\ndf_sub = pd.DataFrame()\ndf_sub['id'] = sub['id']\ndf_sub['revenue'] = np.expm1(test_pred*3)\n#print(df_sub['revenue'])\ndf_sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}