{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"## Курс DS-75. Павлов Иван Иванович. Предсказание дохода от показа фильмов по базе TMDB (соревнование kaggle https://www.kaggle.com/c/tmdb-box-office-prediction/overview/evaluation) \n\nВ рамках итоговой работы по курсу давайте попробуем предсказать выручку от показа фильмов по данным базы TMDB.\n\nСоответственно имеем задачу регрессии\n\nМетрика, используемая для оценки качества предсказания - RMSLE - корень из среднеквартатичного логарифмического отклонения. \n"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nimport datetime\nfrom sklearn.model_selection import train_test_split, KFold, cross_val_score, GridSearchCV\nfrom collections import Counter\nfrom sklearn.preprocessing import StandardScaler\nimport os\nimport xgboost as xgb\nfrom sklearn import model_selection\nimport ast\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f2d5bc8da572783121324a1544483cc1dcaaa4d"},"cell_type":"markdown","source":"## Анализ данных"},{"metadata":{"trusted":true,"_uuid":"52ed3da69987f737ae87ffb99496ebc28a1203e6","_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e8c010c6a78931b0513fe24a49a93dcf96a7dfa8"},"cell_type":"code","source":"#Посмотрим на исходные данные\nprint(train.shape)\nprint(test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bd4d7985ce8d835f4257efd7892dc96eeb665f5b"},"cell_type":"code","source":"train.info()\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Посмотрим на зависимость некоторых признаков и целевой переменной, как она распределена\nfeatures = ['budget', 'popularity', 'runtime', 'revenue']\nsns.pairplot(train[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#построим матрицу корреляции\nsns.heatmap(train[features].corr(), linewidths=.5, cmap=\"Reds\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#от признаков в денежном выражении возьмем логарифм\ntrain['log_budget'] = np.log1p(train['budget'])\ntest['log_budget'] = np.log1p(test['budget'])\n\ntrain['log_revenue'] = np.log1p(train['revenue'])\n\nfig, ax = plt.subplots(figsize = (15, 5))\nplt.subplot(1, 3, 1)\nplt.title('Распределение бэджета')\nsns.distplot(train['log_budget'], color='Green');\nplt.subplot(1, 3, 2)\nplt.title('Распределение дохода')\nsns.distplot(train['log_revenue'], color='Orange');\nplt.subplot(1, 3, 3)\nplt.title('Зависимость дохода от бюджета')\nplt.scatter(train['log_budget'], train['log_revenue'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"36a9c1234ec130389a300039a71ed72f6684ac9f","scrolled":true},"cell_type":"code","source":"#Видим, что многие признаки содержат большое количество пустых значений\nfig = plt.figure(figsize=(10, 8))\ntrain.isna().sum().sort_values(ascending=True).plot(kind='barh',colors='LightGreen')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Подготовка признаков"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Попробуем из данных, представленных в виде json выделить важные составляющие\n\n#функция преобразования дат, т.к. у всех только две последние цифры\ndef fix_date(x):\n    year = x.split('/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year\n\ndf = pd.concat([train, test]).reset_index(drop = True)\nprint('All data shape')\nprint(df.shape)\n\njson_features=[\"belongs_to_collection\", \"genres\", \"production_companies\", \"production_countries\", \"spoken_languages\"]\n\nfor feature in json_features:\n    df.loc[df[feature].notnull(),feature]=df.loc[df[feature].notnull(),feature].apply(lambda x : ast.literal_eval(x)).apply(lambda x : [y[\"name\"] for y in x])\n\ndf[\"in_collection\"]=1\ndf.loc[df[\"belongs_to_collection\"].isnull(),\"in_collection\"]=0\ndf[\"genres_len\"]=df.loc[df[\"genres\"].notnull(),\"genres\"].apply(lambda x : len(x))\ndf[\"production_companies_len\"]=df.loc[df[\"production_companies\"].notnull(),\"production_companies\"].apply(lambda x : len(x))\ndf[\"production_countries_len\"]=df.loc[df[\"production_countries\"].notnull(),\"production_countries\"].apply(lambda x : len(x))\ndf[\"spoken_languages_len\"]=df.loc[df[\"spoken_languages\"].notnull(),\"spoken_languages\"].apply(lambda x : len(x))\n\ndf.loc[df[\"cast\"].notnull(),\"cast\"]=df.loc[df[\"cast\"].notnull(),\"cast\"].apply(lambda x : ast.literal_eval(x))\ndf.loc[df[\"crew\"].notnull(),\"crew\"]=df.loc[df[\"crew\"].notnull(),\"crew\"].apply(lambda x : ast.literal_eval(x))\ndf[\"cast_len\"] = df.loc[df[\"cast\"].notnull(),\"cast\"].apply(lambda x : len(x))\ndf[\"crew_len\"] = df.loc[df[\"crew\"].notnull(),\"crew\"].apply(lambda x : len(x))\n\ndf.loc[df[\"homepage\"].notnull(),\"homepage\"]=1\ndf[\"homepage\"]=df[\"homepage\"].fillna(0)\n\ndf[\"has_tagline\"]=1\ndf.loc[df[\"tagline\"].isnull(),\"has_tagline\"]=0\n\ndf[\"title_different\"]=1\ndf.loc[df[\"title\"]==df[\"original_title\"],\"title_different\"]=0\n\ndf.loc[df[\"release_date\"].notnull(),\"release_date\"]=df.loc[df[\"release_date\"].notnull(),\"release_date\"].apply(lambda x : fix_date(x))\nrelease_date=pd.to_datetime(df[\"release_date\"])\ndf[\"release_year\"]=release_date.dt.year\ndf[\"release_month\"]=release_date.dt.month\ndf[\"release_day\"]=release_date.dt.day\ndf[\"release_wd\"]=release_date.dt.dayofweek\ndf[\"release_quarter\"]=release_date.dt.quarter\n\n#кодируем строковый атрибут как число\nencoder = LabelEncoder()\nencoder.fit(list(df['original_language'].fillna('')))\ndf['original_language'] = encoder.transform(df['original_language'].fillna('').astype(str))\n\ndf['log_popularity']=np.log1p(df['popularity'])\n\n#заполним пропуски\ndf.fillna(value=0.0, inplace = True)\n\ntrain = df.loc[:train.shape[0] - 1,:]\ntest = df.loc[train.shape[0]:,:]\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c30883d68576ee2b482da68b2068857d133abf69"},"cell_type":"code","source":"#Таким образом, скорее всего признаки, где большая часть данных пустая не повлияют на результат - удалим их\n#Также видим, что есть очевидные бесполезные признаки, как например imdb_id или status\nuseless_features = ['belongs_to_collection', 'homepage', 'tagline', \n                    'Keywords', 'id', 'imdb_id', 'status', 'poster_path', \n                    'title', 'original_title', 'genres', 'production_companies', \n                    'production_countries', 'spoken_languages', 'cast', \n                    'crew', 'release_date', 'overview', 'budget', 'popularity']\ntrain = train.drop(useless_features, axis=1)\ntrain = train.drop('revenue', axis=1)\ntest = test.drop(useless_features + ['revenue', 'log_revenue'], axis=1)\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#сформируем выборку данных для обучения модели\nX = train.drop(['log_revenue'], axis=1)\ny = train['log_revenue']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X.shape)\nprint(y.shape)\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=12, shuffle=False)\nprint('Train data shape')\nprint(X_train.shape)\nprint('Test data shape')\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Обучение модели и валидация"},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y_test, y_pred):\n    return np.sqrt(mean_squared_error(y_test, y_pred))\n\ndef predict(model):\n    model.fit(X_train.values, y_train)\n    y_pred = model.predict(X_test.values)\n    print(rmsle(y_test, y_pred))\n    return y_pred\n    \nn_folds = 5\n\ndef rmsle_cv(model):\n    kf = KFold(n_folds, shuffle=True, random_state=42).get_n_splits(X_train.values)\n    rmse = np.sqrt(-cross_val_score(model, X_train.values, y_train, scoring=\"neg_mean_squared_error\", cv=kf))\n    return(rmse)\n\ndef eval_model(model, name):\n    start_time = time.time()\n    score = rmsle_cv(model)\n    print(\"{} score: {:.4f} ({:.4f}),     execution time: {:.1f}\".format(name, score.mean(), score.std(), time.time()-start_time))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mod_xgb = xgb.XGBRegressor(objective  = 'reg:linear', \n          eta = 0.01, \n          max_depth = 6,\n          min_child_weight = 3,\n          subsample = 0.8, \n          colsample_bytree = 0.8,\n          colsample_bylevel = 0.50, \n          gamma = 0.1, \n          eval_metric = 'rmse',\n          seed = 12, n_estimators = 2000)\neval_model(mod_xgb, \"xgb\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = predict(mod_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\nplt.plot(np.array(y_test[:100]),label=\"Реальная\")\nplt.plot(train_pred[:100],label=\"Предсказанная\")\nplt.legend(fontsize=15)\nplt.title(\"Значения предсказанной и реальной выручки\",fontsize=24)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Пройдемся еще раз алгоритмом XGBoost с использованием интерфейса враппера\nparams = {'objective': 'reg:linear', \n          'eta': 0.01, \n          'max_depth': 6, \n          'min_child_weight': 3,\n          'subsample': 0.8,\n          'colsample_bytree': 0.8,\n          'colsample_bylevel': 0.50, \n          'gamma': 0.1, \n          'eval_metric': 'rmse', \n          'seed': 12, \n          'silent': True    \n}\nxgb_data = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test), 'valid')]\nmod_xgb_base = xgb.train(params, \n                  xgb.DMatrix(X_train, y_train),\n                  5000,  \n                  xgb_data, \n                  verbose_eval=200,\n                  early_stopping_rounds=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = mod_xgb_base.predict(xgb.DMatrix(X_test), ntree_limit=mod_xgb_base.best_ntree_limit)\nplt.figure(figsize=(30,10))\nplt.plot(np.array(y_test[:100]),label=\"Реальная\")\nplt.plot(train_pred[:100],label=\"Предсказанная\")\nplt.legend(fontsize=15)\nplt.title(\"Значения предсказанной и реальной выручки\",fontsize=24)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,12))\nxgb.plot_importance(mod_xgb_base, max_num_features=40, height = 0.5, ax = ax)\nplt.title('XGBOOST распределение самых важных фич')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Попробуем обучить другую модель"},{"metadata":{"trusted":true},"cell_type":"code","source":"nr_cv = 5\nlinreg = LinearRegression()\nparameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\ngrid_linear = GridSearchCV(linreg, parameters, cv=nr_cv, verbose=1 , scoring = \"neg_mean_squared_error\")\ngrid_linear.fit(X, y)\n\nprint(grid_linear.best_params_)\nprint(grid_linear.best_estimator_)\n\nlinreg = LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=True)\neval_model(linreg, 'Linear Regression')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pred = predict(linreg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,10))\nplt.plot(np.array(y_test[:100]),label=\"Реальная\")\nplt.plot(train_pred[:100],label=\"Предсказанная\")\nplt.legend(fontsize=15)\nplt.title(\"Значения предсказанной и реальной выручки\",fontsize=24)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Графики и score показывают, что алгоритм градиентного бустинга дает меньшую ошибку, но и работает дольше"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}