{"cells":[{"metadata":{},"cell_type":"markdown","source":"As a person who does not have a full grip on field of data science and still in in the learning phase, I found it quite suitable to work with this dataset. I succesfully cleaned the dataset and performed exploratory data analysis on it. Even if it was not perfect, it was still upto my satisfaction.\nFor prediction making, I chose boosting algorithms. I have to admit that, even after trying certain variations and even after employing gridsearchcv, I wasn't able to get satisfactory score. But I am sure someone will find the code quite helpful and and by making few modifications in the model fitting he or she will be able to get a good score. Thanks.","execution_count":null},{"metadata":{"id":"0KAfnPZBkcQl","trusted":true},"cell_type":"code","source":"#Importing necessary dependancies\nimport pandas as pd\nimport numpy as np\nimport ast\nfrom pandas.io.json import json_normalize\nimport json\nfrom scipy import stats\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score\nfrom collections import Counter\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom xgboost import plot_tree\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\nfrom numpy import mean\nfrom numpy import std\nfrom numpy import asarray\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score","execution_count":null,"outputs":[]},{"metadata":{"id":"1qg1eWup34DR","outputId":"a718d6ef-f9a4-4ac7-9a72-3093ee029771","trusted":true},"cell_type":"code","source":"# This block of code is unnecessary(needed for google colab)\n#from google.colab import drive\n#drive.mount('/content/drive')","execution_count":null,"outputs":[]},{"metadata":{"id":"O4g2eSHTkcQw","trusted":true},"cell_type":"code","source":"train=pd.read_csv(\"../input/tmdb-box-office-prediction/train.csv\")\ntest=pd.read_csv(\"../input/tmdb-box-office-prediction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"t6bQpbXIkcQ3"},"cell_type":"markdown","source":"# Data Cleaning and Feature Engineering","execution_count":null},{"metadata":{"id":"EhoYxNMlkcQ4","outputId":"4b7ca846-0f74-40de-b9d7-09edd13e09ec","trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"kFp2i90ykcRA","outputId":"f74aecf5-4e32-4d92-ff7c-59f024664588","trusted":true},"cell_type":"code","source":"train.columns,test.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"GsVcBhPPkcRH","outputId":"152f6dac-72b8-4c0c-9359-9f9f4387b4f3","trusted":true},"cell_type":"code","source":"train.info(),test.info()","execution_count":null,"outputs":[]},{"metadata":{"id":"bZhotBjgkcRT","outputId":"b7fbae21-ac71-4568-8d0e-30e7904f8859","trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"id":"uaDwd2cMkcRg","outputId":"15c89d5f-59c6-40f7-f79b-e2db6d70261b","trusted":true},"cell_type":"code","source":"#Number of missing values in each column  \ntrain.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"k0UWLRm4kcRr"},"cell_type":"markdown","source":"#### Genres ","execution_count":null},{"metadata":{"id":"a4WC1Z80kcRs","trusted":true},"cell_type":"code","source":"#code block copied from kaggle. Similar code has also been used further. It is to extract information from columns having JSON type values\ntrain.genres=train.genres.fillna('[{}]')\n\ngenresList=[]\nfor index,row in train.genres.iteritems():\n    genresStr=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            genresStr=genresStr+','+dic['name'] \n    genresStr=genresStr.strip(',') # trim leading ,\n    genresList.append(genresStr)\n    \ntempDF=pd.DataFrame(genresList,columns=['genres'])\ntrain.genres=tempDF['genres']","execution_count":null,"outputs":[]},{"metadata":{"id":"vfJalrMCkcR9","trusted":true},"cell_type":"code","source":"test.genres=test.genres.fillna('[{}]')\n\ngenresList=[]\nfor index,row in test.genres.iteritems():\n    genresStr=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            genresStr=genresStr+','+dic['name'] \n    genresStr=genresStr.strip(',') # trim leading ,\n    genresList.append(genresStr)\n    \ntempDF=pd.DataFrame(genresList,columns=['genres'])\ntest.genres=tempDF['genres']\n","execution_count":null,"outputs":[]},{"metadata":{"id":"CUb3_eDPkcRy","trusted":true},"cell_type":"code","source":"train['num_of_genres']=train.genres.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n#train = train.join(train.genres.str.get_dummies(','))\ntest['num_of_genres']=test.genres.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n#test= test.join(test.genres.str.get_dummies(','))","execution_count":null,"outputs":[]},{"metadata":{"id":"__b2HbsI6zV3","outputId":"ab6d0ca5-46d0-44de-a885-1b5595cd91f2","trusted":true},"cell_type":"code","source":"#Finding most common values in the given column and manually doing one hot encoding.Similar method has been employed for further columns\nGen=train['genres'].str.cat(sep=',')\nwords = Gen.split(\",\")  \nGen1  = Counter(words).most_common(15)\nGen1\nDum=[]\nfor i in range(0,15):\n  e=Gen1[i][0]\n  Dum.append(e)\nfor gen in Dum:\n    train['genre_' + gen] = train['genres'].apply(lambda x: 1 if gen in x else 0)\n    test['genre_' + gen] = test['genres'].apply(lambda x: 1 if gen in x else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"vlznJg6dkcSC"},"cell_type":"markdown","source":"#### Production Companies","execution_count":null},{"metadata":{"id":"cqmafSPckcSD","trusted":true},"cell_type":"code","source":"train.production_companies=train.production_companies.fillna('[{}]')\n\nList=[]\nfor index,row in train.production_companies.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['production_companies'])\ntrain.production_companies=tempDF['production_companies']","execution_count":null,"outputs":[]},{"metadata":{"id":"Rgl86RnpkcSI","trusted":true},"cell_type":"code","source":"test.production_companies=test.production_companies.fillna('[{}]')\n\nList=[]\nfor index,row in test.production_companies.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['production_companies'])\ntest.production_companies=tempDF['production_companies']\n\n\ntrain['num_of_productioncompanies']=train.production_companies.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n#train = train.join(train.production_companies.str.get_dummies(','))\n\ntest['num_of_productioncompanies']=test.production_companies.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n#test= test.join(test.production_companies.str.get_dummies(','))","execution_count":null,"outputs":[]},{"metadata":{"id":"P2qhptgIkcSN","trusted":true},"cell_type":"code","source":"Com=train['production_companies'].str.cat(sep=',')\nwords = Com.split(\",\")  \nCom1  = Counter(words).most_common(15)\nDum=[]\nfor i in range(0,15):\n  e=Com1[i][0]\n  Dum.append(e)\nfor com in Dum:\n    train['Company_' + com] = train['production_companies'].apply(lambda x: 1 if com in x else 0)\n    test['Company_' + com] = test['production_companies'].apply(lambda x: 1 if com in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"unhJqQu-kcSS"},"cell_type":"markdown","source":"#### Production_Countries","execution_count":null},{"metadata":{"id":"Lij2YKahkcST","trusted":true},"cell_type":"code","source":"train.production_countries=train.production_countries.fillna('[{}]')\n\nList=[]\nfor index,row in train.production_countries.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['production_countries'])\ntrain.production_countries=tempDF['production_countries']","execution_count":null,"outputs":[]},{"metadata":{"id":"n7CmNCVFkcSZ","trusted":true},"cell_type":"code","source":"test.production_countries=test.production_countries.fillna('[{}]')\n\nList=[]\nfor index,row in test.production_countries.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['production_countries'])\ntest.production_countries=tempDF['production_countries']","execution_count":null,"outputs":[]},{"metadata":{"id":"YQUpPC-XkcSf","trusted":true},"cell_type":"code","source":"train['num_of_productioncountries']=train.production_countries.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\ntest['num_of_productioncountries']=test.production_countries.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n#train = train.join(train.production_countries.str.get_dummies(','))\n#test = test.join(test.production_countries.str.get_dummies(','))\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"W99qpzSqKF1M","trusted":true},"cell_type":"code","source":"Cou=train['production_countries'].str.cat(sep=',')\nwords = Cou.split(\",\")  \nCou1  = Counter(words).most_common(15)\nDum=[]\nfor i in range(0,15):\n  e=Cou1[i][0]\n  Dum.append(e)\nfor cou in Dum:\n    train['Country_' + cou] = train['production_countries'].apply(lambda x: 1 if cou in x else 0)\n    test['Country_' + cou] = test['production_countries'].apply(lambda x: 1 if cou in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"Wf_ssTG8kcSn"},"cell_type":"markdown","source":"#### Spoken_Languages","execution_count":null},{"metadata":{"id":"w7oCzOV2kcSo","trusted":true},"cell_type":"code","source":"train.spoken_languages=train.spoken_languages.fillna('[{}]')\n\nList=[]\nfor index,row in train.spoken_languages.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['spoken_languages'])\ntrain.spoken_languages=tempDF['spoken_languages']","execution_count":null,"outputs":[]},{"metadata":{"id":"m1PwvrgXkcSv","trusted":true},"cell_type":"code","source":"test.spoken_languages=test.spoken_languages.fillna('[{}]')\n\nList=[]\nfor index,row in test.spoken_languages.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['spoken_languages'])\ntest.spoken_languages=tempDF['spoken_languages']\n\n\ntrain['num_of_spokenlanguages']=train.spoken_languages.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n#train = train.join(train.spoken_languages.str.get_dummies(','))\n\ntest['num_of_spokenlanguages']=test.spoken_languages.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n#test= test.join(test.spoken_languages.str.get_dummies(','))","execution_count":null,"outputs":[]},{"metadata":{"id":"JmZuCIqfK4_g","trusted":true},"cell_type":"code","source":"Lan=train['spoken_languages'].str.cat(sep=',')\nwords = Lan.split(\",\")  \nLan1  = Counter(words).most_common(15)\nDum=[]\nfor i in range(0,15):\n  e=Lan1[i][0]\n  Dum.append(e)\nfor lan in Dum:\n    train['Language_' + lan] = train['spoken_languages'].apply(lambda x: 1 if lan in x else 0)\n    test['Language_' + lan] = test['spoken_languages'].apply(lambda x: 1 if lan in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"9btSYR_bkcS0"},"cell_type":"markdown","source":"#### keywords","execution_count":null},{"metadata":{"id":"g5vQ_2fckcS0","trusted":true},"cell_type":"code","source":"train.Keywords=train.Keywords.fillna('[{}]')\n\nList=[]\nfor index,row in train.Keywords.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['Keywords'])\ntrain.Keywords=tempDF['Keywords']","execution_count":null,"outputs":[]},{"metadata":{"id":"Invi6KgokcS7","trusted":true},"cell_type":"code","source":"test.Keywords=test.Keywords.fillna('[{}]')\n\nList=[]\nfor index,row in test.Keywords.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['Keywords'])\ntest.Keywords=tempDF['Keywords']\n\ntrain['num_of_keywords']=train.Keywords.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\ntest['num_of_keywords']=test.Keywords.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"1MJavo4sLmKA","trusted":true},"cell_type":"code","source":"key=train['Keywords'].str.cat(sep=',')\nwords = key.split(\",\")  \nkey1  = Counter(words).most_common(15)\nDum=[]\nfor i in range(0,15):\n  e=key1[i][0]\n  Dum.append(e)\nfor Key in Dum:\n    train['Keyword_' + Key] = train['Keywords'].apply(lambda x: 1 if Key in x else 0)\n    test['Keyword_' + Key] = test['Keywords'].apply(lambda x: 1 if Key in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"W0bmBRTHkcTD"},"cell_type":"markdown","source":"#### Cast","execution_count":null},{"metadata":{"id":"xxHo0u1WkcTE","trusted":true},"cell_type":"code","source":"#Avoid this code\n\n#train.cast=train.cast.fillna('[{}]')\n\n#List=[]\n#for index,row in train.cast.iteritems():\n    #Str=''\n    #listofDict=ast.literal_eval(row)\n    #for dic in listofDict:\n        \n        #if('name' in dic.keys()):\n            #string=str(dic['gender'])\n            #Str=Str+','+string\n    #Str=Str.strip(',') # trim leading ,\n    #List.append(Str)\n    #print(List)\n    \n#tempDF=pd.DataFrame(List,columns=['Gender'])\n#train['Gender']=tempDF['Gender']\n#train = train.join(train.Gender.str.get_dummies(','))","execution_count":null,"outputs":[]},{"metadata":{"id":"AnmTW3PnkcTJ","trusted":true},"cell_type":"code","source":"train.cast=train.cast.fillna('[{}]')\n\nList=[]\nfor index,row in train.cast.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['cast'])\ntrain.cast=tempDF['cast']","execution_count":null,"outputs":[]},{"metadata":{"id":"Ue6SSsRfkcTP","trusted":true},"cell_type":"code","source":"test.cast=test.cast.fillna('[{}]')\n\nList=[]\nfor index,row in test.cast.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['cast'])\ntest.cast=tempDF['cast']","execution_count":null,"outputs":[]},{"metadata":{"id":"So5WEyBpkcTT","trusted":true},"cell_type":"code","source":"train['total_castmembers']=train.cast.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\ntest['total_castmembers']=test.cast.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"IxriKREPkcTX"},"cell_type":"markdown","source":"#### Crew","execution_count":null},{"metadata":{"id":"aeiM-SyykcTY","trusted":true},"cell_type":"code","source":"train.crew=train.crew.fillna('[{}]')\n\nList=[]\nfor index,row in train.crew.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['crew_members'])\ntrain['crew_members']=tempDF['crew_members']","execution_count":null,"outputs":[]},{"metadata":{"id":"GWBAesYkkcTe","trusted":true},"cell_type":"code","source":"test.crew=test.crew.fillna('[{}]')\n\nList=[]\nfor index,row in test.crew.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('name' in dic.keys()):\n            Str=Str+','+dic['name'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['crew_members'])\ntest['crew_members']=tempDF['crew_members']\n\ntrain['total_crew_members']=train.crew_members.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\ntest['total_crew_members']=test.crew_members.apply(lambda x : len(list(x.split(','))) if x != '[{}]' else 0)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"-gap-E-TkcTj","trusted":true},"cell_type":"code","source":"List=[]\nfor index,row in train.crew.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('department' in dic.keys()):\n            Str=Str+','+dic['department'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['crew_department'])\ntrain['crew_department']=tempDF['crew_department']","execution_count":null,"outputs":[]},{"metadata":{"id":"AFDkWVR8kcTo","trusted":true},"cell_type":"code","source":"List=[]\nfor index,row in test.crew.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('department' in dic.keys()):\n            Str=Str+','+dic['department'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['crew_department'])\ntest['crew_department']=tempDF['crew_department']","execution_count":null,"outputs":[]},{"metadata":{"id":"065nvFnPkcTs","trusted":true},"cell_type":"code","source":"List=[]\nfor index,row in train.crew.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('job' in dic.keys()):\n            Str=Str+','+dic['job'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['crew_job'])\ntrain['crew_job']=tempDF['crew_job']","execution_count":null,"outputs":[]},{"metadata":{"id":"N1lyjQ69kcTx","trusted":true},"cell_type":"code","source":"List=[]\nfor index,row in test.crew.iteritems():\n    Str=''\n    listofDict=ast.literal_eval(row)\n    for dic in listofDict:\n        \n        if('job' in dic.keys()):\n            Str=Str+','+dic['job'] \n    Str=Str.strip(',') # trim leading ,\n    List.append(Str)\n    \ntempDF=pd.DataFrame(List,columns=['crew_job'])\ntest['crew_job']=tempDF['crew_job']","execution_count":null,"outputs":[]},{"metadata":{"id":"HHhyLD4jkcT1","trusted":true},"cell_type":"code","source":"#bro= train['crew_department'].str.get_dummies(',')\n#bro.drop(['Crew'],axis=1,inplace=True)\n#train=train.join(bro)\n#bro1=test['crew_department'].str.get_dummies(',')\n#bro1.drop(['Crew'],axis=1,inplace=True)\n#test=test.join(bro1)\n#bro2=train['crew_job'].str.get_dummies(',')\n#bro2columns= bro2.columns\n#for i in bro2columns:\n    #bro2.rename(columns={i: 'job'+i}, inplace=True)\n#train=train.join(bro2)\n#bro3=test['crew_job'].str.get_dummies(',')\n#bro3columns= bro3.columns\n#for i in bro3columns:\n    #bro3.rename(columns={i: 'job'+i}, inplace=True)\n#test=test.join(bro3)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"DKf7qxDdkcT6","trusted":true},"cell_type":"code","source":"dep=train['crew_department'].str.cat(sep=',')\nwords = dep.split(\",\")  \ndep1  = Counter(words).most_common(10)\ndep1\nDum=[]\nfor i in range(0,10):\n  e=dep1[i][0]\n  Dum.append(e)\nfor Dep in Dum:\n    train['Department_' + Dep] = train['crew_department'].apply(lambda x: 1 if Dep in x else 0)\n    test['Department_' + Dep] = test['crew_department'].apply(lambda x: 1 if Dep in x else 0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"X-uI5X1aOohG","trusted":true},"cell_type":"code","source":"Job=train['crew_job'].str.cat(sep=',')\nwords = Job.split(\",\")  \nJob1  = Counter(words).most_common(15)\nJob1\nDum=[]\nfor i in range(0,15):\n  e=Job1[i][0]\n  Dum.append(e)\nfor job in Dum:\n    train['Job_' + job] = train['crew_job'].apply(lambda x: 1 if job in x else 0)\n    test['Job_' + job] = test['crew_job'].apply(lambda x: 1 if job in x else 0)\n\n","execution_count":null,"outputs":[]},{"metadata":{"id":"do3dGIBWkcT-"},"cell_type":"markdown","source":"#### Belongs_to_Collection","execution_count":null},{"metadata":{"id":"KUIU2Cn1kcT_","trusted":true},"cell_type":"code","source":"train.belongs_to_collection=train.belongs_to_collection.fillna('[{}]')\n\ntrain.belongs_to_collection=train.belongs_to_collection.apply(lambda x: 1 if x != '[{}]' else 0 )","execution_count":null,"outputs":[]},{"metadata":{"id":"wmA8wZg-kcUD","trusted":true},"cell_type":"code","source":"test.belongs_to_collection=test.belongs_to_collection.fillna('[{}]')\n\ntest.belongs_to_collection=test.belongs_to_collection.apply(lambda x: 1 if x != '[{}]' else 0 )","execution_count":null,"outputs":[]},{"metadata":{"id":"VX7ogDhHkcUI"},"cell_type":"markdown","source":"#### Homepage","execution_count":null},{"metadata":{"id":"GPcQQ-W7kcUK","trusted":true},"cell_type":"code","source":"train.homepage=train.homepage.fillna('[{}]')\n\ntrain.homepage=train.homepage.apply(lambda x: 1 if x != '[{}]' else 0 )\n\ntest.homepage=test.homepage.fillna('[{}]')\n\ntest.homepage=test.homepage.apply(lambda x: 1 if x != '[{}]' else 0 )","execution_count":null,"outputs":[]},{"metadata":{"id":"dNnf0xmikcUU"},"cell_type":"markdown","source":"#### Release Date","execution_count":null},{"metadata":{"id":"C1yUMufRkcUV","trusted":true},"cell_type":"code","source":"#Seperating the date, day and year column\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntrain.loc[train['release_date'].dt.year >= 2020, 'release_date'] -= pd.DateOffset(years=100)\ntrain['Year'], train['Month'],train['Date'] = train['release_date'].dt.year, train['release_date'].dt.month,train['release_date'].dt.day\n","execution_count":null,"outputs":[]},{"metadata":{"id":"DiQoTLxkkcUd","trusted":true},"cell_type":"code","source":"test = test[test['release_date'].notnull()]","execution_count":null,"outputs":[]},{"metadata":{"id":"tU8DtGnIkcUj","trusted":true},"cell_type":"code","source":"test['release_date'] = pd.to_datetime(test['release_date'])\ntest.loc[test['release_date'].dt.year >= 2020, 'release_date'] -= pd.DateOffset(years=100)\ntest['Year'], test['Month'],test['Date'] = test['release_date'].dt.year, test['release_date'].dt.month,test['release_date'].dt.day\n","execution_count":null,"outputs":[]},{"metadata":{"id":"T7nzLNRikcUp","trusted":true},"cell_type":"code","source":"train['First_Quarter_Release']=train.Month.apply(lambda x: 1 if x <= 3 else 0)\ntrain['Second_Quarter_Release']=train.Month.apply(lambda x: 1 if x <= 6 and x > 3 else 0)\ntrain['Third_Quarter_Release']=train.Month.apply(lambda x: 1 if x <= 9 and x > 6 else 0)\ntrain['Fourth_Quarter_Release']=train.Month.apply(lambda x: 1 if x <= 12 and x > 9 else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"MbLMOLZgkcUv","trusted":true},"cell_type":"code","source":"test['First_Quarter_Release']=test.Month.apply(lambda x: 1 if x <= 3 else 0)\ntest['Second_Quarter_Release']=test.Month.apply(lambda x: 1 if x <= 6 and x > 3 else 0)\ntest['Third_Quarter_Release']=test.Month.apply(lambda x: 1 if x <= 9 and x > 6 else 0)\ntest['Fourth_Quarter_Release']=test.Month.apply(lambda x: 1 if x <= 12 and x > 9 else 0)","execution_count":null,"outputs":[]},{"metadata":{"id":"3OupGIxDkcU4"},"cell_type":"markdown","source":"#### Text Columns","execution_count":null},{"metadata":{"id":"KrWbBHxckcU6","trusted":true},"cell_type":"code","source":"#This block of code has been copid from kaggle notebook by Andrew Lukyan\n\nfor col in ['title', 'tagline', 'overview', 'original_title']:\n    train['len_' + col] = train[col].fillna('').apply(lambda x: len(str(x)))\n    train['words_' + col] = train[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n    test['len_' + col] = test[col].fillna('').apply(lambda x: len(str(x)))\n    test['words_' + col] = test[col].fillna('').apply(lambda x: len(str(x.split(' '))))","execution_count":null,"outputs":[]},{"metadata":{"id":"ZzWvluYbkcVB"},"cell_type":"markdown","source":"## Exploratory Data Analysis","execution_count":null},{"metadata":{"id":"8a27mSrGkcVI"},"cell_type":"markdown","source":"#### Budget","execution_count":null},{"metadata":{"id":"KxeGAc0-kcVP","trusted":true},"cell_type":"code","source":"#plotting different features vs target values\nBudget=train.budget.value_counts().to_frame()","execution_count":null,"outputs":[]},{"metadata":{"id":"hqFU8OdSkcVe","trusted":true},"cell_type":"code","source":"Budget.rename(columns={'budget':'Value_Counts'},inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"mR_2sAxSkcVk","outputId":"2d9956ac-df6e-4c93-af91-10c466948b6a","trusted":true},"cell_type":"code","source":"Budget.index.name = 'Budget'\nBudget.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"id":"BRNi4kC9kcVy","outputId":"fd418f24-9486-46a2-a00a-aae3323de506","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,8))\nax1  = plt.subplot(1,2,1)\nsns.regplot(x=\"budget\", y=\"revenue\", data=train)\n\nax2  = plt.subplot(1,2,2)\nsns.kdeplot(np.log1p(train['budget']), shade=True)\nplt.legend()\n\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"u2LMG7fckcV5"},"cell_type":"markdown","source":"#### Genre","execution_count":null},{"metadata":{"id":"hdsRLhrhkcV5","trusted":true},"cell_type":"code","source":"#list(train.columns.values.tolist()) ","execution_count":null,"outputs":[]},{"metadata":{"id":"jaWiZZyPkcV-","trusted":true},"cell_type":"code","source":"Genres=['genre_Drama','genre_Comedy','genre_Thriller','genre_Action','genre_Romance','genre_Crime','genre_Adventure','genre_Horror','genre_Science Fiction','genre_Family','genre_Fantasy','genre_Mystery','genre_Animation','genre_History','genre_Music']","execution_count":null,"outputs":[]},{"metadata":{"id":"BPq544rzkcWE","outputId":"6858d419-eb62-4fec-d76a-9537cd9d094d","trusted":true},"cell_type":"code","source":"sns.barplot(train['num_of_genres'],np.log1p(train['revenue']))","execution_count":null,"outputs":[]},{"metadata":{"id":"dh_2xedVkcWO","outputId":"bf0e94c7-7e09-48ce-e87c-43096f0adc07","trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(28, 14))\nplt.suptitle('Barplot of genres vs. their count')\nfor i, e in enumerate(Genres):\n    Gr=train.groupby([e],as_index=False)['id'].count()\n    Gr.rename(columns={'id':'Count'},inplace=True)\n    sns.barplot(data=Gr, x=e, y = \"Count\", ax=axes[i //5 ][i % 5 ])\n    \n    \n","execution_count":null,"outputs":[]},{"metadata":{"id":"-l-xOiDbkcWZ","outputId":"c4f7f4af-fb4f-4c90-fd4b-709d1387a9ec","trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(28, 14))\nplt.suptitle('Barplot of genres vs. revenue')\nfor i, e in enumerate(Genres):\n    Gr=train.groupby([e],as_index=False)['revenue'].mean()\n    Gr.rename(columns={'revenue':'Revenue_Mean'},inplace=True)\n    sns.barplot(data=Gr, x=e, y = \"Revenue_Mean\", ax=axes[i //5 ][i % 5 ])","execution_count":null,"outputs":[]},{"metadata":{"id":"F7WnJUgnkcWj"},"cell_type":"markdown","source":"#### Homepage","execution_count":null},{"metadata":{"id":"2MsU_47rkcWl","outputId":"c469eff3-ad7a-4da4-91e6-3dd7ab56353f","trusted":true},"cell_type":"code","source":"sns.violinplot(data=train, x='homepage', y = \"revenue\")","execution_count":null,"outputs":[]},{"metadata":{"id":"56Ddr8q9kcWw"},"cell_type":"markdown","source":"#### Overview","execution_count":null},{"metadata":{"id":"gxtLVCEJkcWy","trusted":true},"cell_type":"code","source":"stopwords = set(STOPWORDS)","execution_count":null,"outputs":[]},{"metadata":{"id":"FpfO6o88kcW4","trusted":true},"cell_type":"code","source":"Overview= ' '.join(train['overview'].fillna('').values)","execution_count":null,"outputs":[]},{"metadata":{"id":"Xy4oYH6fkcXA","outputId":"63de9c15-a577-4d7c-a9fb-d98d040b5d95","trusted":true},"cell_type":"code","source":"plt.figure(figsize =(13,13))\nov_wc = WordCloud(\n    background_color='white',\n    max_words=500,\n    stopwords=stopwords\n)\n\n# generate the word cloud\nov_wc.generate(Overview)\nplt.imshow(ov_wc)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"2qzHqfm0kcXI"},"cell_type":"markdown","source":"#### Popularity","execution_count":null},{"metadata":{"id":"VFcQ2R5BkcXJ","outputId":"53cbf64e-1fb4-4f65-e9cb-646cc48df25c","trusted":true},"cell_type":"code","source":"count, bin_edges = np.histogram(train['popularity'])\n\ntrain['popularity'].plot(kind='hist', figsize=(8, 5), xticks=bin_edges)\nplt.title(\"Popularity vs Count\")\nplt.xlabel(\"Popularity\")\nplt.ylabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"qm4ALTotkcXY","outputId":"1bd5e8b8-1cc3-42ed-f381-6544d95e484b","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='popularity', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Popularity vs Revenue')\nplt.xlabel('Popularity')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"lUA4TNKCkcXf","outputId":"a032d90f-78bf-4ac9-9cdf-39851abc2c9d","trusted":true},"cell_type":"code","source":"train['log_revenue']=np.log1p(train['revenue'])\ntrain.plot(kind='scatter', x='popularity', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Popularity vs Revenue')\nplt.xlabel('Popularity')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"pGLEieI3kcXk"},"cell_type":"markdown","source":"#### Number of production Companies","execution_count":null},{"metadata":{"id":"GWeyCjyMkcXl","outputId":"cc3c7251-bbc0-4cda-959b-c012a291d273","trusted":true},"cell_type":"code","source":"PC=train.groupby(['num_of_productioncompanies'],as_index=False)['id'].count()\nPC.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=PC, x='num_of_productioncompanies', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"uaYsFzGwkcXo","outputId":"d875e6f8-44c0-405f-bf24-b735a014ce7d","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='num_of_productioncompanies', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Number of Production Companies vs Revenue')\nplt.xlabel('Number of Production Companies')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"cC6U_4SJkcXr","outputId":"edefa0a0-a660-415b-b21c-3bd5b322cab0","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='num_of_productioncompanies', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Number of Production Companies vs Revenue')\nplt.xlabel('Number of Production Companies')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"KS-UCdCBWNQb","trusted":true},"cell_type":"code","source":"Companies=['Company_Warner Bros.','Company_Universal Pictures','Company_Paramount Pictures','Company_','Company_Twentieth Century Fox Film Corporation','Company_Columbia Pictures','Company_Metro-Goldwyn-Mayer (MGM)','Company_New Line Cinema','Company_Touchstone Pictures','Company_Walt Disney Pictures','Company_Columbia Pictures Corporation','Company_TriStar Pictures','Company_Relativity Media','Company_Canal+','Company_United Artists']","execution_count":null,"outputs":[]},{"metadata":{"id":"fU6mgxAbWbXB","outputId":"ce7cea14-0a1f-4d18-d265-e81b08886068","trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(28, 14))\nplt.suptitle('Barplot of companies vs. revenue')\nfor i, e in enumerate(Companies):\n    Gr=train.groupby([e],as_index=False)['revenue'].mean()\n    Gr.rename(columns={'revenue':'Revenue_Mean'},inplace=True)\n    sns.barplot(data=Gr, x=e, y = \"Revenue_Mean\", ax=axes[i //5 ][i % 5 ])","execution_count":null,"outputs":[]},{"metadata":{"id":"gz5dyJU8WoHq"},"cell_type":"markdown","source":"**Production Countries**","execution_count":null},{"metadata":{"id":"fXcDWvfiVDJN","trusted":true},"cell_type":"code","source":"Countries=['Country_United States of America','Country_United Kingdom','Country_France','Country_Germany','Country_Canada','Country_India','Country_Italy','Country_Japan','Country_Australia','Country_Russia','Country_Spain','Country_China','Country_Hong Kong','Country_Ireland','Country_']","execution_count":null,"outputs":[]},{"metadata":{"id":"hcT_23jlVhQG","outputId":"ba570049-cbc4-476b-f4c4-97a86c56cdb6","trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(28, 14))\nplt.suptitle('Barplot of countries vs. revenue')\nfor i, e in enumerate(Countries):\n    Gr=train.groupby([e],as_index=False)['revenue'].mean()\n    Gr.rename(columns={'revenue':'Revenue_Mean'},inplace=True)\n    sns.barplot(data=Gr, x=e, y = \"Revenue_Mean\", ax=axes[i //5 ][i % 5 ])","execution_count":null,"outputs":[]},{"metadata":{"id":"6hTeDRl9kcXv"},"cell_type":"markdown","source":"#### Number of Spoken Languages","execution_count":null},{"metadata":{"id":"7_mhxz00kcXw","outputId":"66b223b3-8e93-41ce-afbe-5ad73bf5c14e","trusted":true},"cell_type":"code","source":"SL=train.groupby(['num_of_spokenlanguages'],as_index=False)['id'].count()\nSL.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=SL, x='num_of_spokenlanguages', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"jmyrzCDNkcX3","outputId":"304e74de-41c4-45ac-96cd-445724f69b51","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='num_of_spokenlanguages', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Number of Spoken Languages vs Revenue')\nplt.xlabel('Number of Spoken Languages')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"MRdVKGINkcX7","outputId":"9f6a49e5-9480-4f38-d92c-7f9412d695aa","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='num_of_spokenlanguages', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Number of Spoken Languages vs Revenue')\nplt.xlabel('Number of Spoken Languages')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"9z1-3bvbXJME","trusted":true},"cell_type":"code","source":"Spoken_Languages=['Language_English','Language_Français','Language_Español','Language_Deutsch','Language_Pусский','Language_Italiano','Language_日本語','Language_普通话','Language_हिन्दी','Language_Português','Language_العربية','Language_한국어/조선말','Language_广州话 / 廣州話','Language_','Language_தமிழ்']","execution_count":null,"outputs":[]},{"metadata":{"id":"ix_q4OTnW11z","trusted":true},"cell_type":"code","source":"#f, axes = plt.subplots(3, 5, figsize=(28, 14))\n#plt.suptitle('Barplot of spoken languages vs. revenue')\n#for i, e in enumerate(Spoken_Languages):\n    #Gr=train.groupby([e],as_index=False)['revenue'].mean()\n    #Gr.rename(columns={'revenue':'Revenue_Mean'},inplace=True)\n    #sns.barplot(data=Gr, x=e, y = \"Revenue_Mean\", ax=axes[i //5 ][i % 5 ])","execution_count":null,"outputs":[]},{"metadata":{"id":"FungQ3MpkcX_"},"cell_type":"markdown","source":"#### Keywords","execution_count":null},{"metadata":{"id":"4sZPjf4OkcYA","outputId":"61e89234-9b2d-4aa3-a9bf-fe29af0d0762","trusted":true},"cell_type":"code","source":"keywords= ' '.join(train['Keywords'].fillna('').values)\nplt.figure(figsize =(13,13))\nkw_wc = WordCloud(\n    background_color='white',\n    max_words=500,\n    stopwords=stopwords\n)\n\n# generate the word cloud\nkw_wc.generate(keywords)\nplt.imshow(kw_wc)\nplt.axis('off')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"PAxWP-EAkcYD","outputId":"9aee44b6-8249-4db3-f1da-4fba596fd9c0","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='num_of_keywords', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Number of keywords vs Revenue')\nplt.xlabel('Number of Keywords')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"e0pSjnDbkcYI"},"cell_type":"markdown","source":"#### Runtime","execution_count":null},{"metadata":{"id":"n4ALK9LlkcYJ","trusted":true},"cell_type":"code","source":"avg_runtime = train['runtime'].astype('float').mean(axis=0)\ntrain['runtime'].replace(np.nan, avg_runtime, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"Cc1aB7imkcYL","outputId":"9438f13b-5c0b-45f3-aeca-92edff6e53d6","trusted":true},"cell_type":"code","source":"count, bin_edges = np.histogram(train['runtime'])\n\ntrain['runtime'].plot(kind='hist', figsize=(8, 5), xticks=bin_edges)\nplt.title(\"Runtime vs Count\")\nplt.xlabel(\"Runtime\")\nplt.ylabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"RpwHA4hGkcYR","outputId":"eab87289-da20-4337-a90e-bf70e91d9e40","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='runtime', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Runtime vs Revenue')\nplt.xlabel('Runtime')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"A_0GBFGFkcYX","outputId":"360858c8-45c9-40ba-88dc-312f33d5d9a9","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='runtime', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Runtime vs Revenue')\nplt.xlabel('Runtime')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"b8xKnbmDkcYc"},"cell_type":"markdown","source":"#### Status","execution_count":null},{"metadata":{"id":"K2mzj_APkcYd","outputId":"d9c2ab5b-d09f-490e-f99a-86bf65a8da05","trusted":true},"cell_type":"code","source":"ST=train.groupby(['status'],as_index=False)['id'].count()\nST.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=ST, x='status', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"vuhnVDrAkcYi"},"cell_type":"markdown","source":"#### Cast Members","execution_count":null},{"metadata":{"id":"pjqHe0zFkcYj","outputId":"c68ca81f-d79a-430b-e4f4-c61df67181cb","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,15))\nCM=train.groupby(['total_castmembers'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='total_castmembers', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"mvhFjJRvkcYn","outputId":"2406f316-59b3-412a-8ba5-c08f8a85904d","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='total_castmembers', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Total Cast Members vs Revenue')\nplt.xlabel('Total Cast Members')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"CjLj_3tIkcYt","outputId":"242b7f5e-bbb9-4b27-9e47-37431b49fb7d","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='total_castmembers', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Total Cast Members vs Revenue')\nplt.xlabel('Total Cast Members')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"ZHHejjunkcYw"},"cell_type":"markdown","source":"#### Total Number of Crew","execution_count":null},{"metadata":{"id":"wRNhGyR0kcYw","outputId":"1c87381c-d616-4548-d3c4-eca1f4a37a41","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,15))\nCM=train.groupby(['total_crew_members'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='total_crew_members', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"C4f42jMzkcYz","outputId":"e67e4f67-82a9-41c1-8b82-e35e3c7fbc68","trusted":true},"cell_type":"code","source":"count, bin_edges = np.histogram(train['total_crew_members'])\n\ntrain['total_crew_members'].plot(kind='hist', figsize=(8, 5), xticks=bin_edges)\nplt.title(\"Total crew members vs Count\")\nplt.xlabel(\"Total Crew Members\")\nplt.ylabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"BWKkpddNkcY3","outputId":"8aab9e03-7a7e-4ad0-9f04-1ee4038a87b2","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='total_crew_members', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Total Crew Members vs Revenue')\nplt.xlabel('Total Crew Members')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"QV3ymxW0kcY6","outputId":"ad301f2e-dc6e-4be0-afbe-4b5ffb9f79fb","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='total_crew_members', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Total Crew Members vs Revenue')\nplt.xlabel('Total Crew Members')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"0xaADuwJkcY-","outputId":"c3cb10e7-30cb-4402-8f3b-a0ed39397cc5","trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"XyWKBJhQkcZC"},"cell_type":"markdown","source":"#### Year","execution_count":null},{"metadata":{"id":"AIWiIRLgkcZD","outputId":"b0852e6c-db45-4c1d-e612-8622de49759e","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(30,15))\nCM=train.groupby(['Year'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='Year', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"ljpS4tTJkcZG","outputId":"3a50b5a6-f08f-4de9-f4de-a4cd1c47a9ca","trusted":true},"cell_type":"code","source":"count, bin_edges = np.histogram(train['Year'])\n\ntrain['Year'].plot(kind='hist', figsize=(8, 5), xticks=bin_edges)\nplt.title(\"Year vs Count\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Count\")\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"lkG2rGyQkcZK","outputId":"f97e12fa-9ced-41b3-f700-05db5089b02e","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='Year', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Year vs Revenue')\nplt.xlabel('Year')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"3UIN3W1skcZN","outputId":"677143db-bf9e-4f62-b833-0927e4ccd542","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='Year', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Year vs Revenue')\nplt.xlabel('Year')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Tzmo0GfWkcZQ"},"cell_type":"markdown","source":"#### Month","execution_count":null},{"metadata":{"id":"i1dDBmg3kcZR","outputId":"04aeff69-f628-4ba3-e565-d3a238c7def5","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nCM=train.groupby(['Month'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='Month', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"p7zDi8s6kcZU","outputId":"219c3032-5ff6-4712-ae62-12e7d4c48259","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nCM=train.groupby(['Month'],as_index=False)['id'].count()\nCM.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=CM, x='Month', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"MVoLzC5PkcZX","outputId":"be767efb-3874-44d7-f598-6b5d55c72639","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='Month', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Month vs Revenue')\nplt.xlabel('Month')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"UlzMABTLkcZa","outputId":"df469527-346a-4345-e84a-33bc3fcb6ba0","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='Month', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Month vs Revenue')\nplt.xlabel('Month')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"F20V4xnzkcZh"},"cell_type":"markdown","source":"#### Date","execution_count":null},{"metadata":{"id":"mAFITN5RkcZh","outputId":"68dd92c7-91a1-4214-a79e-437a71e2c558","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nCM=train.groupby(['Date'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='Date', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"UoM7UWDdkcZl","outputId":"d904e2d4-73b1-47a6-b2ad-0071facb3ce1","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nCM=train.groupby(['Date'],as_index=False)['id'].count()\nCM.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=CM, x='Date', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"NP0I55aAkcZr","outputId":"4919ec68-7d04-45a5-8755-e235fc26f497","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='Date', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Date vs Revenue')\nplt.xlabel('Date')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"esRjacw4kcZw","outputId":"1d0d4ed3-1cfa-41e5-a98d-323de4901f8c","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='Date', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Date vs Revenue')\nplt.xlabel('Date')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"PbHTO5mnkcZz","outputId":"22f2c1b5-0cc8-42eb-a93d-61e0ad9eba9e","trusted":true},"cell_type":"code","source":"train.columns","execution_count":null,"outputs":[]},{"metadata":{"id":"lvReVXEAkcZ2"},"cell_type":"markdown","source":"#### First Quarter Release","execution_count":null},{"metadata":{"id":"bbH9Vgf2kcZ2","outputId":"f2cbd41d-1562-48a9-ca53-799c4f534434","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nCM=train.groupby(['First_Quarter_Release'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='First_Quarter_Release', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"7GfSXafdkcZ8","outputId":"be2dc2bb-61cc-4e62-f7d1-51e1e26e32ea","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nCM=train.groupby(['First_Quarter_Release'],as_index=False)['id'].count()\nCM.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=CM, x='First_Quarter_Release', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"RTyQWhqykcaA"},"cell_type":"markdown","source":"#### Second Quarter Release","execution_count":null},{"metadata":{"id":"ONhZVkgZkcaB","outputId":"42279227-6519-4d0d-8450-5b714d370f1b","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nCM=train.groupby(['Second_Quarter_Release'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='Second_Quarter_Release', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"s_OemfcSkcaK","outputId":"3c453b45-4204-4a78-afbd-ffe33924d7c2","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nCM=train.groupby(['Second_Quarter_Release'],as_index=False)['id'].count()\nCM.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=CM, x='Second_Quarter_Release', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"0UFFJDU6kcaO"},"cell_type":"markdown","source":"#### Third Quarter Release","execution_count":null},{"metadata":{"id":"1aPZzGCgkcaP","outputId":"10ed85ec-1828-4188-e44f-784e901cb91c","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nCM=train.groupby(['Third_Quarter_Release'],as_index=False)['revenue'].mean()\nCM.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=CM, x='Third_Quarter_Release', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"cV3e9ZT3kcaS","outputId":"b617e324-4540-4fa3-c2ca-5cbba0833088","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nCM=train.groupby(['Third_Quarter_Release'],as_index=False)['id'].count()\nCM.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=CM, x='Third_Quarter_Release', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"eSEGTaMskcaW"},"cell_type":"markdown","source":"#### Fourth Quarter Release","execution_count":null},{"metadata":{"id":"nJy3ShP8kcaW","outputId":"587e4686-4fa6-413e-81d6-ca47e5bf5b1a","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nFOQ=train.groupby(['Fourth_Quarter_Release'],as_index=False)['revenue'].mean()\nFOQ.rename(columns={'revenue':'revenue_mean'},inplace=True)\nsns.barplot(data=FOQ, x='Fourth_Quarter_Release', y = \"revenue_mean\")","execution_count":null,"outputs":[]},{"metadata":{"id":"J40F038nkcad","outputId":"c1e21625-19ae-4c11-ac87-5ce76030feca","trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nFOQ=train.groupby(['Fourth_Quarter_Release'],as_index=False)['id'].count()\nFOQ.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=FOQ, x='Fourth_Quarter_Release', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"S4V4iaBekcaf"},"cell_type":"markdown","source":"#### Number of production countries","execution_count":null},{"metadata":{"id":"ygdQYGW0kcag","outputId":"d0f69a9b-250a-408b-c308-1da71b3e1928","trusted":true},"cell_type":"code","source":"PCO=train.groupby(['num_of_productioncountries'],as_index=False)['id'].count()\nPCO.rename(columns={'id':'Count'},inplace=True)\nsns.barplot(data=PCO, x='num_of_productioncountries', y = \"Count\")","execution_count":null,"outputs":[]},{"metadata":{"id":"1YsQlGv5kcaj","outputId":"57638436-6782-4c2e-889d-f7f98f7e93b0","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='num_of_productioncountries', y='revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Number of Production Countries vs Revenue')\nplt.xlabel('Number of Production Countries')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Jdm2Zy7ukcaq","outputId":"11894e0d-591e-4333-985c-ecf929e28b87","trusted":true},"cell_type":"code","source":"train.plot(kind='scatter', x='num_of_productioncountries', y='log_revenue', figsize=(10, 6), color='darkblue')\n\nplt.title('Number of Production Countries vs Revenue')\nplt.xlabel('Number of Production Countries')\nplt.ylabel('Revenue')\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"Ut4X5F-ekcau"},"cell_type":"markdown","source":"## Model Fitting","execution_count":null},{"metadata":{"id":"16dI0HHJZFTF","outputId":"2b5325b7-7c9a-4b84-e8cf-3166f646a01c","trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"NSzwVUitmK16","trusted":true},"cell_type":"code","source":"#list(train.columns.values.tolist()) ","execution_count":null,"outputs":[]},{"metadata":{"id":"7QKu_DPZkcav","trusted":true},"cell_type":"code","source":"# Converting big budget values into smaller values by taking log\ntrain['log_budget']=np.log1p(train['budget'])","execution_count":null,"outputs":[]},{"metadata":{"id":"PWb04MQEkcaz","trusted":true},"cell_type":"code","source":"#Dropping the unnecessary columns\nX=train.drop(['id','genres','imdb_id','original_language','original_title','overview','poster_path','production_companies','production_countries','release_date','spoken_languages','status', 'tagline', 'title', 'Keywords', 'cast', 'crew','revenue','crew_members','crew_department','crew_job','log_revenue','budget','Country_','Company_','Language_','Keyword_'],axis=1)\nY= train['log_revenue']\ntest['log_budget']=np.log1p(test['budget'])\ntest.drop(['id','genres','imdb_id','original_language','original_title','overview','poster_path','production_companies','production_countries','release_date','spoken_languages','status', 'tagline', 'title', 'Keywords', 'cast', 'crew','budget','crew_members','crew_department','crew_job','Country_','Company_','Language_','Keyword_'],axis=1,inplace =True)","execution_count":null,"outputs":[]},{"metadata":{"id":"VtvIZxHdLlP9","outputId":"5babe543-9ee4-401d-db6e-a552e2f298f2","trusted":true},"cell_type":"code","source":"X.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{"id":"7f6GX_Eokca3","trusted":true},"cell_type":"code","source":"#Splitting the dataset into train and test set\ntrain_X,test_X,train_Y,test_Y=train_test_split(X,Y,random_state=1,test_size=0.2)\n","execution_count":null,"outputs":[]},{"metadata":{"id":"skEDMbTAkca6"},"cell_type":"markdown","source":"### Gradient Boosting with Scikit Learn","execution_count":null},{"metadata":{"id":"xVMCsFXzkca6","outputId":"b92bbd29-4771-44cb-b7a1-d86ed3885222","trusted":false},"cell_type":"code","source":"from numpy import mean\nfrom numpy import std\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedKFold\n\n# evaluate the model\nmodel = GradientBoostingRegressor()\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(model, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n# fit the model on the whole dataset\nmodel = GradientBoostingRegressor()\nmodel.fit(train_X,train_Y )\n","execution_count":null,"outputs":[]},{"metadata":{"id":"l3YZyhsVkca9","outputId":"0eb5a3a2-52d6-4f44-aeab-d675ff3394a5","trusted":false},"cell_type":"code","source":"from sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nmse = mean_squared_error(test_Y, model.predict(test_X))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mse))\nrmse = mean_squared_error(test_Y, model.predict(test_X),squared=False)\nprint(\"The root mean squared error (RMSE) on test set: {:.4f}\".format(rmse))\nr2 = r2_score(test_Y, model.predict(test_X))\nprint(\"The R2  on test set: {:.4f}\".format(r2))","execution_count":null,"outputs":[]},{"metadata":{"id":"Km8UIP3ekcbE"},"cell_type":"markdown","source":"### Gradient boosting with XGBOOST","execution_count":null},{"metadata":{"id":"DYFkyqFS-i9Q","trusted":false},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"id":"Z7c1wicikcbE","trusted":false},"cell_type":"code","source":"from numpy import mean\nfrom numpy import std\nfrom numpy import asarray\nfrom xgboost import XGBRegressor\n# evaluate the model\nmodelXGB = XGBRegressor(objective='reg:squarederror')\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(modelXGB, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n# fit the model on the whole dataset\nmodelXGB = XGBRegressor()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"lr-Ta7XMFTN1","trusted":false},"cell_type":"code","source":"params = {'min_child_weight':[4,5], 'gamma':[i/10.0 for i in range(3,6)],  'subsample':[i/10.0 for i in range(6,11)],\n'colsample_bytree':[i/10.0 for i in range(6,11)], 'max_depth': [2,3,4]}\ngrid = GridSearchCV(modelXGB, params)\ngrid.fit(train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"id":"j0Q9n5hqMbUz","trusted":false},"cell_type":"code","source":"best_model=grid.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"id":"N9JLxp3uteux","outputId":"5d9aab95-0a33-4aef-baa3-289322d96166","trusted":false},"cell_type":"code","source":"msexgb = mean_squared_error(test_Y, best_model.predict(test_X))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(msexgb))\nrmsexgb = mean_squared_error(test_Y, best_model.predict(test_X),squared= False)\nprint(\"The root mean squared error (RMSE) on test set: {:.4f}\".format(rmsexgb))\nr2 = r2_score(test_Y, best_model.predict(test_X))\nprint(\"The R2  on test set: {:.4f}\".format(r2))","execution_count":null,"outputs":[]},{"metadata":{"id":"HGM85B-AdFoY","outputId":"8cb2de95-8511-4109-bec3-9f8e104d314d","trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(30, 30))\nplot_tree(best_model, num_trees=1, ax=ax)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"id":"9PSIwZPqtuxj"},"cell_type":"markdown","source":"**Light GBM**\n","execution_count":null},{"metadata":{"id":"6-d1u_uwuPT6","trusted":false},"cell_type":"code","source":"from lightgbm import LGBMRegressor\nmodellgbm = LGBMRegressor()\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(modellgbm, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n# fit the model on the whole dataset\nmodellgbm = LGBMRegressor()","execution_count":null,"outputs":[]},{"metadata":{"id":"HJmbPhwmQhfs","trusted":false},"cell_type":"code","source":"param_grid = {\n        'objective': ['regression'],\n        'num_leaves': [15, 23, 31],\n        'learning_rate': [0.1, 0.2],\n        'n_estimators': [100]}\n\n\ngs_reg = GridSearchCV(modellgbm, param_grid,\n                          n_jobs=1, cv=5,\n                          scoring='neg_mean_squared_error')     \ngs_reg.fit(train_X, train_Y)","execution_count":null,"outputs":[]},{"metadata":{"id":"hQUGk8LkTEcS","trusted":false},"cell_type":"code","source":"best_lgbm = gs_reg.best_estimator_","execution_count":null,"outputs":[]},{"metadata":{"id":"9FbnVvBJuor2","outputId":"ac4b4cfa-1e5c-471c-e7ec-cd6cc1b8f74e","trusted":false},"cell_type":"code","source":"mselgbm = mean_squared_error(test_Y, best_lgbm.predict(test_X))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(mselgbm))\nrmselgbm = mean_squared_error(test_Y, best_lgbm.predict(test_X),squared=False)\nprint(\"The root mean squared error (RMSE) on test set: {:.4f}\".format(rmselgbm))\nr2 = r2_score(test_Y, best_lgbm.predict(test_X))\nprint(\"The R2  on test set: {:.4f}\".format(r2))","execution_count":null,"outputs":[]},{"metadata":{"id":"ZPbDtJB3fVEs","trusted":false},"cell_type":"code","source":"!pip install shap","execution_count":null,"outputs":[]},{"metadata":{"id":"HVsJ9Ae8e1Pt","outputId":"80e0c7ce-3cf9-43e6-c5f9-060f0b37d0ab","trusted":false},"cell_type":"code","source":"#Trying to explain the results through shap. This is just an intro as I don't have enough knowledge about shap\nimport shap\n%time shap_values = shap.TreeExplainer(best_lgbm).shap_values(test_X)\nshap.summary_plot(shap_values, test_X)","execution_count":null,"outputs":[]},{"metadata":{"id":"tEuZWbVxft3z","outputId":"de932c27-e835-40bd-8af1-4a0d49e6b362","trusted":false},"cell_type":"code","source":"shap.dependence_plot(\"log_budget\", shap_values, test_X)\n#Similarly visualize for other features\n","execution_count":null,"outputs":[]},{"metadata":{"id":"hctL35Omu5_0"},"cell_type":"markdown","source":"**Catboost**","execution_count":null},{"metadata":{"id":"P1O1JR-rvC22","outputId":"9f8a40e9-102e-4a38-8223-bfecb72bb399","trusted":true},"cell_type":"code","source":"#!pip install catboost\nfrom catboost import CatBoostRegressor\nmodelcat = CatBoostRegressor(verbose=0, n_estimators=100)\ncv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\nn_scores = cross_val_score(modelcat, X, Y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\nprint('MAE: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))\n# fit the model on the whole dataset\nmodelcat = CatBoostRegressor(iterations=100000,\n                                 learning_rate=0.004,\n                                 depth=5,\n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.8,\n                                 random_seed = 2019,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=200\n                                )\nmodelcat.fit(train_X, train_Y,\n                 eval_set=(test_X,test_Y),\n                 use_best_model=True,\n                 verbose=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"y5I95wy8vXIy","outputId":"def24e14-7538-4797-bb3e-3548ee6ef261","trusted":true},"cell_type":"code","source":"msecat = mean_squared_error(test_Y, modelcat.predict(test_X))\nprint(\"The mean squared error (MSE) on test set: {:.4f}\".format(msecat))\nrmsecat = mean_squared_error(test_Y, modelcat.predict(test_X),squared=False)\nprint(\"The root mean squared error (RMSE) on test set: {:.4f}\".format(rmsecat))\nr2 = r2_score(test_Y, modelcat.predict(test_X))\nprint(\"The R2  on test set: {:.4f}\".format(r2))","execution_count":null,"outputs":[]},{"metadata":{"id":"DQ5NKVIX73ND"},"cell_type":"markdown","source":"****Predictions****","execution_count":null},{"metadata":{"id":"Zt7u93SXaM6Y","trusted":true},"cell_type":"code","source":"#Making predictions on validation set and comparing it with target values\neval=modelcat.predict(test_X)\nevaluations=np.expm1(eval)\nevaluations1=np.expm1(test_Y)\nEvaluations=pd.DataFrame()\nEvaluations['revenue']=evaluations\nEvaluations['original_revenue']=evaluations1\n","execution_count":null,"outputs":[]},{"metadata":{"id":"D2jQsDOg_T7a","trusted":true},"cell_type":"code","source":"test.replace(np.nan, 0, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"xL7pBi9SUJJA","trusted":true},"cell_type":"code","source":"#making predictions on unknown test set\nresult=modelcat.predict(test)","execution_count":null,"outputs":[]},{"metadata":{"id":"Uw_D-NOEUSxC","trusted":true},"cell_type":"code","source":"#Taking back anti log\npredictions=np.expm1(result)","execution_count":null,"outputs":[]},{"metadata":{"id":"adTOzuSaUXVB","outputId":"c1518faf-a4f6-468b-c1e1-226ace26dbb5","trusted":true},"cell_type":"code","source":"predictions","execution_count":null,"outputs":[]},{"metadata":{"id":"0DwfOTQ1Vlm0","trusted":true},"cell_type":"code","source":"Predictions=pd.DataFrame()\nPredictions['revenue']=predictions","execution_count":null,"outputs":[]},{"metadata":{"id":"szVwTf9wYAjD","outputId":"f24017fa-e7e7-4bc1-f854-8d5c174bc32a","trusted":true},"cell_type":"code","source":"Predictions.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}