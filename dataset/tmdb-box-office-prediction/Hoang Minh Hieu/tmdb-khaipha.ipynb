{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"#thêm thư viện \nimport numpy as np # Đại số tuyến tính\nimport pandas as pd # load file .CSV(I/O)\nimport matplotlib.pyplot as plt #vẽ\nimport seaborn as sns #vẽ\nsns.set()\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1 load dữ liệu\ntrain_orig = pd.read_csv('../input/train.csv')\ntest_orig = pd.read_csv('../input/test.csv')\nsubm = pd.DataFrame()\nsubm['id'] = test_orig.id.values\ntrain_orig.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#2 \ntrain_orig['bool_belongs_to_collection'] = (train_orig['belongs_to_collection'].notnull()).astype(int)\ntest_orig['bool_belongs_to_collection'] = (test_orig['belongs_to_collection'].notnull()).astype(int)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"#3\ntrain_orig['split'] = 'train'\ntest_orig['split'] = 'test'\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#4\ntrain_test = pd.concat([train_orig[['popularity','budget','split','bool_belongs_to_collection']], test_orig[['popularity','budget','split','bool_belongs_to_collection']]])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#5\ntrain_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#6 biểu đồ giữa train và test (sự nổi tiếng và ngân sách)\nfig, ax = plt.subplots()\nsns.scatterplot(x=\"popularity\", y=\"budget\", hue=\"split\", data=train_test,ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#7 fig \nfig, ax = plt.subplots()\nfig.set_size_inches(18.5, 10.5)\nsns.scatterplot(x=\"popularity\", y=\"budget\", hue=\"split\",style='bool_belongs_to_collection', data=train_test,ax=ax, alpha=0.4)\nax.set_xlim([0,100])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#8 biểu đồ về sự nổi tiếng(budget)\ng = sns.catplot(x='split',y='budget',data=train_test, kind='box' )\ng.set_axis_labels(\"Split\", \"budget\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#9 Biêu đồ về sự nổi tiếng và doanh thu (popularity và revenue)\nfrom bokeh.plotting import figure, output_file, show, output_notebook\nfrom bokeh.models import ColumnDataSource\noutput_notebook()\n#gán\nx = train_orig.popularity\ny = train_orig.revenue\n\nsource = ColumnDataSource(data=dict(\n    popularity=train_orig.popularity,\n    revenue=train_orig.revenue,\n    original_language=train_orig.original_language,\n))\n\n#xuất file html\noutput_file(\"popularity_revenue.html\", title=\"Popularity, Revenue\", mode=\"cdn\")\nTOOLTIPS = [\n    (\"Popularity\", \"@popularity\"),\n    (\"Revenue\", \"@revenue\"),\n    (\"Original Language\", \"@original_language\"),  \n]\n\np = figure(tooltips=TOOLTIPS,y_axis_type=\"log\")\np.circle('popularity', 'revenue',fill_alpha=0.6, line_color=None, source = source)\np.xaxis.axis_label = \"popularity\"\np.yaxis.axis_label = \"revenue\"\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#10 biểu đồ về doanh thu và ngân sách(revenue và budget)\nfrom bokeh.plotting import figure, output_file, show, output_notebook\nfrom bokeh.models import ColumnDataSource\noutput_notebook()\n\nx = train_orig.budget\ny = train_orig.revenue\n\nsource = ColumnDataSource(data=dict(\n    budget=train_orig.budget,\n    revenue=train_orig.revenue,\n    original_language=train_orig.original_language,\n))\n\noutput_file(\"budget_revenue.html\", title=\"Budget, Revenue\", mode=\"cdn\")\nTOOLTIPS = [\n    (\"Budget\", \"@budget\"),\n    (\"Revenue\", \"@revenue\"),\n    (\"Original Language\", \"@original_language\"),\n    \n]\n\np = figure(tooltips=TOOLTIPS,y_axis_type=\"log\")\n\np.circle('budget', 'revenue',fill_alpha=0.6, line_color=None, source = source)\np.xaxis.axis_label = \"budget\"\np.yaxis.axis_label = \"revenue\"\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#11 out ngôn ngữ và số lượng phim > 5 của tập train\nprint(len(train_orig.columns))#độ dài cột train\nprint(len(test_orig.columns))#độ dài cột test\nolang = train_orig.original_language.value_counts()[train_orig.original_language.value_counts()>5].index.tolist()\nprint(olang)\nprint(len(olang))\ntrain_orig_sample = train_orig[train_orig.original_language.isin(olang)].copy()\nprint(train_orig_sample.original_language.value_counts())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#12\ntrain_orig_sample.loc[:,'revenue'] = np.log(train_orig_sample['revenue'].fillna(0)+1)\n#13 biểu đồ Doanh thu theo ngôn ngữ\ng = sns.catplot(x='original_language',y='revenue',data=train_orig_sample, kind='box', aspect=2 )\ng.set_axis_labels(\"Original language\", \"Log of revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#14 out thông tin (các cột và số dòng non-null)\ntrain_orig.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#15 \ntrain_olang = pd.get_dummies(train_orig.original_language)[olang]\ntrain_orig = pd.concat([train_orig,train_olang], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#16\ndef extract_id(cell):\n    return yaml.load(cell)[0]['id']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#17 các cột của train\ntrain_orig.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#18 tính toán bên test\ntest_olang = pd.get_dummies(test_orig.original_language)[olang]\ntest_orig = pd.concat([test_orig,test_olang], axis=1)\ntest_orig.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#19\ntrain_orig['cast_crew'] = train_orig.cast + ' ' + train_orig.crew \ntest_orig['cast_crew'] = test_orig.cast + ' ' + test_orig.crew","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#20 diễn viên và phi hành đoàn\nvec = TfidfVectorizer(analyzer='word',max_features=450,token_pattern=r\"'name': '(.*?)'\")\nvec.fit(train_orig.cast_crew.fillna(''))\nvocab = vec.get_feature_names()\nvec = TfidfVectorizer(analyzer='word',vocabulary=vocab)\ntrain_crew_w = vec.fit_transform(train_orig.cast_crew.fillna(''))\ntest_crew_w = vec.transform(test_orig.cast_crew.fillna(''))\ntrain_crew_w_cols = vec.get_feature_names()\ntrain_crew_w_cols = ['crew_'+a for a in train_crew_w_cols]\nprint(train_crew_w.shape)\nprint(test_crew_w.shape)\nprint(train_crew_w_cols)\ntrain_crew_w = pd.DataFrame(train_crew_w.toarray(),columns=train_crew_w_cols)\ntest_crew_w = pd.DataFrame(test_crew_w.toarray(),columns=train_crew_w_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#21 tên công ty\nvec = TfidfVectorizer(analyzer='word',max_features=100,token_pattern=r\"'name': '(.*?)'\")\nvec.fit(train_orig.production_companies.fillna(''))\nvocab = vec.get_feature_names()\nvec = TfidfVectorizer(analyzer='word',vocabulary=vocab)\ntrain_production_companies_w = vec.fit_transform(train_orig.production_companies.fillna(''))\ntest_production_companies_w = vec.transform(test_orig.production_companies.fillna(''))\ntrain_production_companies_w_cols = vec.get_feature_names()\ntrain_production_companies_w_cols = ['prod_comp_'+a for a in train_production_companies_w_cols]\nprint(train_production_companies_w.shape)\nprint(test_production_companies_w.shape)\nprint(train_production_companies_w_cols)\ntrain_production_companies_w = pd.DataFrame(train_production_companies_w.toarray(),columns=train_production_companies_w_cols)\ntest_production_companies_w = pd.DataFrame(test_production_companies_w.toarray(),columns=train_production_companies_w_cols)  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#22 quốc gia \nvec = TfidfVectorizer(analyzer='word',max_features=20,token_pattern=r\"'name': '(.*?)'\")\nvec.fit(train_orig.production_countries.fillna(''))\nvocab = vec.get_feature_names()\nvec = TfidfVectorizer(analyzer='word',vocabulary=vocab)\ntrain_production_countries_w = vec.fit_transform(train_orig.production_countries.fillna(''))\ntest_production_countries_w = vec.transform(test_orig.production_countries.fillna(''))\ntrain_production_countries_w_cols = vec.get_feature_names()\ntrain_production_countries_w_cols = ['prod_country_'+a for a in train_production_countries_w_cols]\nprint(train_production_countries_w.shape)\nprint(test_production_countries_w.shape)\nprint(train_production_countries_w_cols)\ntrain_production_countries_w = pd.DataFrame(train_production_countries_w.toarray(),columns=train_production_countries_w_cols)\ntest_production_countries_w = pd.DataFrame(test_production_countries_w.toarray(),columns=train_production_countries_w_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#23 bộ sưu tập\nvec = TfidfVectorizer(analyzer='word',max_features=50,token_pattern=r\"'name': '(.*?)'\")\n\ntrain_belongs_to_collection_w = vec.fit_transform(train_orig.belongs_to_collection.fillna(''))\ntest_belongs_to_collection_w = vec.transform(test_orig.belongs_to_collection.fillna(''))\ntrain_belongs_to_collection_w_cols = vec.get_feature_names()\ntrain_belongs_to_collection_w_cols = ['collection_'+a for a in train_belongs_to_collection_w_cols]\nprint(train_belongs_to_collection_w.shape)\nprint(test_belongs_to_collection_w.shape)\nprint(train_belongs_to_collection_w_cols)\ntrain_belongs_to_collection_w = pd.DataFrame(train_belongs_to_collection_w.toarray(),columns=train_belongs_to_collection_w_cols)\ntest_belongs_to_collection_w = pd.DataFrame(test_belongs_to_collection_w.toarray(),columns=train_belongs_to_collection_w_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#24 thể loại(genres)\nvec = TfidfVectorizer(stop_words='english',analyzer='word',max_features=50,token_pattern=r'(?u)\\b[A-Za-z]{3,}\\b')\ntrain_genres_w = vec.fit_transform(train_orig.genres.fillna(''))\ntest_genres_w = vec.transform(test_orig.genres.fillna(''))\ntrain_genres_w_cols = vec.get_feature_names()\ntrain_genres_w_cols = ['genre_'+a for a in train_genres_w_cols]\nprint(train_genres_w.shape)\nprint(test_genres_w.shape)\nprint(train_genres_w_cols)\ntrain_genres_w = pd.DataFrame(train_genres_w.toarray(),columns=train_genres_w_cols)\ntest_genres_w = pd.DataFrame(test_genres_w.toarray(),columns=train_genres_w_cols)\nprint(train_genres_w.shape)\nprint(test_genres_w.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#25\n#https://stackoverflow.com/questions/51643427/how-to-make-tfidfvectorizer-only-learn-alphabetical-characters-as-part-of-the-vo\ntrain_orig['Keywords_tagline_overview'] = train_orig.title + ' ' + train_orig.Keywords +' ' + train_orig.tagline + ' ' + train_orig.overview\ntest_orig['Keywords_tagline_overview'] = test_orig.title + ' ' + test_orig.Keywords + ' ' + test_orig.tagline + ' ' + test_orig.overview\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvec = TfidfVectorizer(stop_words='english',analyzer='word',max_features=60,token_pattern=r'(?u)\\b[A-Za-z]{3,}\\b')\ntrain_tagline_keyword_w = vec.fit_transform(train_orig.Keywords_tagline_overview.fillna(''))\ntrain_tagline_keyword_w_cols = vec.get_feature_names()\nprint(train_tagline_keyword_w.shape)\ntest_tagline_w = vec.transform(test_orig.Keywords_tagline_overview.fillna(''))\nprint(test_tagline_w.shape)\ntrain_tagline_keyword_w_cols = ['kw_tg_ow_' + a for a in train_tagline_keyword_w_cols]\ntrain_tagline_keyword_w = pd.DataFrame(train_tagline_keyword_w.toarray(),columns=train_tagline_keyword_w_cols)\ntest_tagline_keyword_w = pd.DataFrame(test_tagline_w.toarray(),columns=train_tagline_keyword_w_cols)\ntrain = pd.concat([train_orig,train_tagline_keyword_w,train_genres_w,train_belongs_to_collection_w,\n                   train_production_companies_w,train_crew_w,train_production_countries_w], axis=1)\ntest = pd.concat([test_orig,test_tagline_keyword_w,test_genres_w,test_belongs_to_collection_w,\n                  test_production_companies_w,test_crew_w,test_production_countries_w], axis=1)\nprint(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#26\ntrain['bool_belongs_to_collection'] = (train['belongs_to_collection'].notnull()).astype(int)\ntest['bool_belongs_to_collection'] = (test['belongs_to_collection'].notnull()).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#27\nlen(train_tagline_keyword_w_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#28\ntrain['release_date'] = pd.to_datetime(train['release_date'] )\ntest['release_date'] = pd.to_datetime(test['release_date'] )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#29\ntrain['release_month'] = train['release_date'].dt.month\n#print(train['release_month'].value_counts())\ntest['release_month'] = test['release_date'].dt.month\n#print(test['release_month'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#30\ntrain['release_year'] = train['release_date'].dt.year\n#print(train['release_year'].value_counts())\ntest['release_year'] = test['release_date'].dt.year\n#print(test['release_year'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#31 --> 33\ntrain['release_dayofyear'] = train['release_date'].dt.dayofyear\ntest['release_dayofyear'] = test['release_date'].dt.dayofyear\ntrain['release_day_of_week'] = train['release_date'].dt.dayofweek\n#print(train['release_day_of_week'].value_counts())\ntest['release_day_of_week'] = test['release_date'].dt.dayofweek\n#print(test['release_day_of_week'].value_counts())\ntrain['release_week'] = train['release_date'].dt.week\ntest['release_week'] = test['release_date'].dt.week\ntest['release_month'].mode()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#34-->36\ntest['release_year'].mode()\ntest['release_week'].mode()\ntest['release_year'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#37-->46\ntest['release_month'] = test['release_month'].fillna(9.0)\ntest['release_year'] = test['release_year'].fillna(2014.0)\ntest['release_week'] = test['release_week'].fillna(36.0)\ntrain['bool_homepage'] = (train['homepage'].notnull()).astype(int)\ntest['bool_homepage'] = (test['homepage'].notnull()).astype(int)\ntrain['production_companies_len'] = train['production_companies'].str.len()\ntest['production_companies_len'] = test['production_companies'].str.len()\ntrain['production_countries_len'] = train['production_countries'].str.len()\ntest['production_countries_len'] = test['production_countries'].str.len()\ntrain['Keywords_len'] = train['Keywords'].str.len()\ntest['Keywords_len'] = test['Keywords'].str.len()\ntrain['title_len'] = train['title'].str.len()\ntest['title_len'] = test['title'].str.len()\ntrain['genres_len'] = train['genres'].str.len() \ntest['genres_len'] = test['genres'].str.len() \ntrain['cast_crew_len'] = train['cast'].str.len() + train['crew'].str.len()\ntest['cast_crew_len'] = test['cast'].str.len() + test['crew'].str.len()\ntrain['cast_crew_len'].fillna(train['cast_crew_len'].median(),inplace=True)\ntrain['runtime'].fillna(train['runtime'].median(),inplace=True)\ntrain['genres_len'].fillna(train['genres_len'].median(),inplace=True)\ntrain['production_companies_len'].fillna(train['production_companies_len'].median(),inplace=True)\ntrain['production_countries_len'].fillna(train['production_countries_len'].median(),inplace=True)\ntrain['Keywords_len'].fillna(train['Keywords_len'].median(),inplace=True)\n(train['release_year']>2019).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#47-->49\ntrain.loc[(train['release_year']>2019),'release_year']=train['release_year'].median()\ntrain['month_into_year'] = train['release_month']*train['release_year']\n(test['release_year']>2019).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#50 -->54\ntest.loc[(test['release_year']>2019),'release_year']=test['release_year'].median()\nvcast_crew_len = test['cast_crew_len'].median()\ntest['cast_crew_len'].fillna(vcast_crew_len, inplace=True)\ntest['runtime'].fillna(test['runtime'].median(),inplace=True)\ntest['release_month'].fillna(test['release_month'].median(),inplace=True)\ntest['title_len'].fillna(test['title_len'].median(),inplace=True)\ntest['release_year'].fillna(test['release_year'].median(),inplace=True)\ntest['release_day_of_week'].fillna(test['release_day_of_week'].median(),inplace=True)\ntest['release_dayofyear'].fillna(test['release_dayofyear'].median(),inplace=True)\ntest['genres_len'].fillna(test['genres_len'].median(),inplace=True)\ntest['production_companies_len'].fillna(test['production_companies_len'].median(),inplace=True)\ntest['production_countries_len'].fillna(test['production_countries_len'].median(),inplace=True)\ntest['Keywords_len'].fillna(test['Keywords_len'].median(),inplace=True)\ntest['month_into_year'] = test['release_month']*test['release_year']\nfeatures = ['bool_homepage', 'release_dayofyear','production_companies_len', 'production_countries_len', 'Keywords_len' , 'cast_crew_len','budget','popularity','runtime','release_month','release_day_of_week','release_week','genres_len','bool_belongs_to_collection', 'title_len','release_year']\ntrain['log_revenue'] = np.log(train['revenue'].fillna(0)+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#55 Biểu đồ revenue với cast_crew_len\nfrom bokeh.plotting import figure, output_file, show, output_notebook\nfrom bokeh.models import ColumnDataSource\noutput_notebook()\n\n\nsource = ColumnDataSource(data=dict(\n    cast_crew_len=train.cast_crew_len,\n    revenue=train.revenue,\n    original_language=train.original_language,\n))\n\n\noutput_file(\"cast_crew_len_revenue.html\", title=\"cast_crew_len, Revenue\", mode=\"cdn\")\nTOOLTIPS = [\n    (\"cast_crew_len\", \"@cast_crew_len\"),\n    (\"Revenue\", \"@revenue\"),\n    (\"Original Language\", \"@original_language\"),\n    \n]\n\np = figure(tooltips=TOOLTIPS,y_axis_type=\"log\")\n\np.circle('cast_crew_len', 'revenue',fill_alpha=0.6, line_color=None, source = source)\np.xaxis.axis_label = \"cast_crew_len\"\np.yaxis.axis_label = \"revenue\"\nshow(p)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#56  Biểu đồ về tổng  doanh thu có homepage hoặc không \ng = sns.catplot(x='bool_homepage',y='log_revenue',data=train, kind='box', aspect=1 )\ng.set_axis_labels(\"Is there a homepage\", \"Log of Revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#57 Biểu đồ doanh thu theo tháng\ng = sns.catplot(x='release_month',y='log_revenue',data=train, kind='box', aspect=2 )\ng.set_axis_labels(\"Release month\", \"Log of Revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#58 Biểu đồ doanh thu theo ngày trong tuần \ng = sns.catplot(x='release_day_of_week',y='log_revenue',data=train, kind='box', aspect=2 )\ng.set_axis_labels(\"Release day of week\", \"Log of Revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#59 Biểu đồ doanh thu Tuần trong năm\n#https://www.kaggle.com/jlove5/avocados-usa-prices\n\ng = sns.catplot(x='release_week',y='log_revenue',data=train, kind='box', aspect=3 )\ng.set_axis_labels(\"Release week\", \"Log of Revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#60 Doanh thu theo thể loại có drama hay k\ntrain['is_genre_drama'] = (train['genre_drama']>0).astype(int)\ng = sns.catplot(x='is_genre_drama',y='log_revenue', data=train,kind='box' )\ng.set_axis_labels(\"is_genre_drama\", \"Log of Revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#61\ntrain['is_kw_tg_ow_death'] = (train['kw_tg_ow_death']>0).astype(int)\ng = sns.catplot(x='is_kw_tg_ow_death',y='log_revenue', data=train,kind='box' )\ng.set_axis_labels(\"is_kw_tg_ow_death\", \"Log of Revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#62\ntrain['is_genre_thriller'] = (train['genre_thriller']>0).astype(int)\ng = sns.catplot(x='is_genre_thriller',y='log_revenue', data=train,kind='box' )\ng.set_axis_labels(\"is_genre_thriller\", \"Log of Revenue\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#63 Doanh thu theo năm\n#https://www.kaggle.com/jlove5/avocados-usa-prices\n\ng = sns.catplot(x='release_year',y='log_revenue',data=train, kind='box', aspect=3 )\ng.set_axis_labels(\"Release year\", \"Log of Revenue\")\ng.set_xticklabels(rotation=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#64\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#65\nfeatures = features+olang+train_tagline_keyword_w_cols+train_genres_w_cols+train_belongs_to_collection_w_cols \\\n+train_production_companies_w_cols + train_crew_w_cols + train_production_countries_w_cols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#66\nlen(features)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#67\ntest.release_year.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#68\ntrain[features].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#69\ntest[features].info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#70\ntarget_column = 'revenue'\ncolumns_for_prediction=features\nX = train[columns_for_prediction].copy()\nimport sklearn.preprocessing as preprocessing\ny_scale = preprocessing.PowerTransformer()\n#y = np.log(train[target_column])\n#https://stackoverflow.com/questions/26584971/how-to-not-standarize-target-data-in-scikit-learn-regression\ny = y_scale.fit_transform(train[target_column].values.reshape(-1, 1) )\n\nX_unseen = test[columns_for_prediction].copy()\nscale = preprocessing.PowerTransformer()\nX = pd.DataFrame(scale.fit_transform(X),columns=columns_for_prediction)\nX_unseen = pd.DataFrame(scale.transform(test[columns_for_prediction]),columns=columns_for_prediction)\n\nbudget_min = X['budget'].quantile(0.28)\nX['budget'] = X['budget'].replace(0,budget_min)\n\nX_unseen['budget'] = X_unseen['budget'].replace(0,budget_min)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#71\ncolumns_for_prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#73\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.1, random_state=2019)\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error\nparams = {'n_estimators': 700, 'max_depth': 4, 'min_samples_split': 2,\n          'learning_rate': 0.01, 'loss': 'ls'}\n\nreg = GradientBoostingRegressor(**params).fit(X_train, y_train)\nscore = reg.score(X_test, y_test)\nprint('Test score %d'%score)\npreds = reg.predict(X_test)\nerr = mean_squared_error(y_test, preds)\nprint('Test mse %d'%err)\nreg = GradientBoostingRegressor(n_estimators=700).fit(X, y)\nscore = reg.score(X, y)\nprint('Train score %d'%score)\npreds_first = reg.predict(X_unseen)","execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-41331c171d1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#73\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2019\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensemble\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGradientBoostingRegressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"#75 dùng hồi quy để tính toán \n#https://www.kaggle.com/hendraherviawan/regression-with-kerasregressor\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\n#Chuẩn hóa dữ liệu\ndef norm(x):\n  return (x - train_stats.loc['mean']) / train_stats.loc['std']\ntrain_dataset = X\n#train_labels = y.values\ntrain_labels = y\ntest_dataset = X_unseen\ntrain_stats = train_dataset.describe()\nnormed_train_data = train_dataset\nnormed_test_data = test_dataset\n\n#Xây dựng model\ndef build_model():\n  model = keras.Sequential([\n    layers.Dense(200, activation=tf.nn.leaky_relu, kernel_initializer='normal', input_shape=[len(train_dataset.keys())]),\n    layers.Dropout(.8),  \n    layers.Dense(100, activation=tf.nn.leaky_relu, kernel_initializer='normal'),\n    layers.Dropout(.6), \n    layers.Dense(50, activation=tf.nn.leaky_relu, kernel_initializer='normal'),\n    layers.Dropout(.4),   \n    layers.Dense(20, activation=tf.nn.leaky_relu, kernel_initializer='normal'),\n    layers.Dropout(.2),   \n    layers.Dense(1, activation='linear', kernel_initializer='normal')\n  ])\n\n  optimizer = tf.keras.optimizers.RMSprop(0.0001)\n  #optimizer = tf.keras.optimizers.Adam(0.001)\n  model.compile(loss='mean_squared_error',\n                optimizer=optimizer,\n                metrics=['mean_absolute_error', 'mean_squared_error'])\n  return model\n\nmodel = build_model()\n# summary method để in mô tả về đơn giản về mô hình\nmodel.summary()\n\n# Display training progress by printing a single dot for each completed epoch\nclass PrintDot(keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs):\n    if epoch % 100 == 0: print('')\n    print('.', end='')\n\nEPOCHS = 1000\n\nhistory = model.fit(\n  normed_train_data, train_labels,batch_size = 100,\n  epochs=EPOCHS, validation_split = 0.1, verbose=1,\n callbacks=[PrintDot()])\n\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch\nhist.tail()\n\n\ndef plot_history(history):\n  hist = pd.DataFrame(history.history)\n  hist['epoch'] = history.epoch\n    \n  \n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Abs Error ')\n  plt.plot(hist['epoch'], hist['mean_absolute_error'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mean_absolute_error'],\n           label = 'Val Error')\n  \n  plt.legend()\n  \n  plt.figure()\n  plt.xlabel('Epoch')\n  plt.ylabel('Mean Square Error ')\n  plt.plot(hist['epoch'], hist['mean_squared_error'],\n           label='Train Error')\n  plt.plot(hist['epoch'], hist['val_mean_squared_error'],\n           label = 'Val Error')\n  \n  plt.legend()\n  plt.show()\n\n\nplot_history(history)\n","execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'X' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-5df1244f7925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mean'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'std'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#train_labels = y.values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\nearly_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\nhistory = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n                    validation_split = 0.2, verbose=0, callbacks=[early_stop])\nplot_history(history)\n\npreds_estop = model.predict(normed_test_data).flatten()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#80\npreds[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#82 Xuất file kết quả\nmedian_revenue = train[target_column].median()\npreds = preds_estop\npreds = y_scale.inverse_transform(preds.reshape(-1, 1))\npreds[preds < 0] = median_revenue\nsubm['revenue'] = preds\nsubm.to_csv('Submission.csv', index=False)\nprint(subm.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#83\nlen(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#84\nimport seaborn as sns\n#sns.distplot(train['revenue'] )\ntrain['revenue'].hist(log=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#85\nlen(subm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#86\n#sns.distplot(subm['revenue'] )\nsubm['revenue'].hist(log=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"#87\nax = sns.scatterplot(x=\"popularity\", y=\"revenue\",\n                     hue=\"release_year\", \n                     data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#88\nax = sns.scatterplot(x=test.popularity, y=subm.revenue,\n                     hue=test.release_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#89\nax = sns.scatterplot(x=\"budget\", y=\"revenue\",\n                     hue=\"release_year\", \n                     data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#90\nax = sns.scatterplot(x=test.budget, y=subm.revenue,\n                     hue=test.release_year)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#91\ntrain[ ['release_date', 'revenue']].set_index('release_date').resample('A').mean()[:'2019'].plot(style='--')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#92\ntest['revenue'] = subm['revenue']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#93\ntest[ ['release_date', 'revenue']].set_index('release_date').resample('A').mean()[:'2019'].plot(style='--')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}