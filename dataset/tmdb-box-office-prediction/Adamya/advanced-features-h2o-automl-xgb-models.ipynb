{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# TMDB Box Office Prediction","metadata":{}},{"cell_type":"markdown","source":"**If you use parts of this notebook in your scripts/notebooks, giving some kind of credit would be very much appreciated :) You can for instance link back to this notebook. Thanks!**","metadata":{}},{"cell_type":"markdown","source":"![boxoffice.jpg](http://sanjeevwritings.files.wordpress.com/2018/05/boxoffice.jpg)","metadata":{}},{"cell_type":"markdown","source":"### Introduction","metadata":{}},{"cell_type":"markdown","source":"In a world... where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's \"You had me at 'Hello.'\" For others, the trailer falls short of expectations and you think \"What we have here is a failure to communicate.\"\n\nIn this, we're presented with metadata on over 7,000 past films from The Movie Database to try and predict their overall worldwide box office revenue. Data points provided include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries. You can collect other publicly available data to use in your model predictions, but in the spirit of this competition, use only data that would have been available before a movie's release.\n","metadata":{}},{"cell_type":"markdown","source":"### Load Libraries","metadata":{}},{"cell_type":"code","source":"#Libraries\nimport numpy as np\nimport plotly.express as px\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport datetime\nimport ast\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom PIL import Image\nfrom urllib.request import urlopen\nfrom sklearn.model_selection import train_test_split, cross_val_score, cross_val_predict, RandomizedSearchCV\nfrom sklearn.linear_model import LinearRegression,Lasso, Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load Data","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\n\ndict_columns = ['belongs_to_collection','genres','spoken_languages','production_companies',\n                'production_countries','Keywords','cast','crew']\n\ndef text_to_dict(df):\n    for columns in dict_columns:\n        df[columns] = df[columns].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n    return df\n\ntrain = text_to_dict(train)\ntest = text_to_dict(test)\n\ntest['revenue'] = np.nan\n\n# features from https://www.kaggle.com/kamalchhirang/eda-simple-feature-engineering-external-data\n# Aditional Features\ntrain = pd.merge(train, pd.read_csv('../input/tmdb-competition-additional-features/TrainAdditionalFeatures.csv'), how='left', on=['imdb_id'])\ntest = pd.merge(test, pd.read_csv('../input/tmdb-competition-additional-features/TestAdditionalFeatures.csv'), how='left', on=['imdb_id'])\n\ntrain.head(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape , test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Fixes from https://www.kaggle.com/somang1418/happy-valentines-day-and-keep-kaggling-3\n\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\ntrain.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000\n\n#Clean Data\ntest.loc[test['id'] == 6733,'budget'] = 5000000\ntest.loc[test['id'] == 3889,'budget'] = 15000000\ntest.loc[test['id'] == 6683,'budget'] = 50000000\ntest.loc[test['id'] == 5704,'budget'] = 4300000\ntest.loc[test['id'] == 6109,'budget'] = 281756\ntest.loc[test['id'] == 7242,'budget'] = 10000000\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\ntest.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30\n","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only 3000 rows to train the data.\nWe can see that some of columns contain lists with dictionaries. Some lists contain a single dictionary, some have several. Let's extract data from these columns!","metadata":{}},{"cell_type":"markdown","source":"__Data Description id__ - Integer unique id of each movie\n\n__belongs_to_collection__ - Contains the TMDB Id, Name, Movie Poster and Backdrop URL of a movie in JSON format. You can see the Poster and Backdrop Image like this: https://image.tmdb.org/t/p/original/. Example: https://image.tmdb.org/t/p/original//iEhb00TGPucF0b4joM1ieyY026U.jpg\n\n__budget__:Budget of a movie in dollars. 0 values mean unknown.\n\n__genres__ : Contains all the Genres Name & TMDB Id in JSON Format\n\n__homepage__ - Contains the official homepage URL of a movie. Example: http://sonyclassics.com/whiplash/ , this is the homepage of Whiplash movie.\n\n__imdb_id__ - IMDB id of a movie (string). You can visit the IMDB Page like this: https://www.imdb.com/title/\n\n__original_language__ - Two digit code of the original language, in which the movie was made. Like: en = English, fr = french.\n__original_title__ - The original title of a movie. Title & Original title may differ, if the original title is not in English.\n\n__overview__ - Brief description of the movie.\n\n__popularity__ - Popularity of the movie in float.\n\n__poster_path__ - Poster path of a movie. You can see the full image like this: https://image.tmdb.org/t/p/original/\n\n__production_companies__ - All production company name and TMDB id in JSON format of a movie.\n\n__production_countries__ - Two digit code and full name of the production company in JSON format.\n\n__release_date__ - Release date of a movie in mm/dd/yy format.\n\n__runtime__ - Total runtime of a movie in minutes (Integer).\n\n__spoken_languages__ - Two digit code and full name of the spoken language.\n\n__status__ - Is the movie released or rumored?\n\n__tagline__ - Tagline of a movie\n\n__title__ - English title of a movie\n\n__Keywords__ - TMDB Id and name of all the keywords in JSON format.\n\n__cast__ - All cast TMDB id, name, character name, gender (1 = Female, 2 = Male) in JSON format\n\n__crew__ - Name, TMDB id, profile path of various kind of crew members job like Director, Writer, Art, Sound etc.\n\n__revenue__ - Total revenue earned by a movie in dollars.","metadata":{"_kg_hide-input":true}},{"cell_type":"markdown","source":"Let's check the skewness and kurtosis of the columns and make these columns normal for better working of features.","metadata":{}},{"cell_type":"code","source":"pd.DataFrame(train.skew().sort_values(ascending=False)).head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.DataFrame(train.kurtosis().sort_values(ascending=False)).head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can transform popularity, revenue,totalVotes, budget, runtime and popularity2","metadata":{}},{"cell_type":"code","source":"train['popularity'] = np.log1p(train['popularity'])   #log(1+x)  #expm1 - inverse\ntrain['revenue'] = np.log1p(train['revenue'])\ntrain['totalVotes'] = np.log1p(train['totalVotes'])\ntrain['budget'] = np.log1p(train['budget'])\ntrain['runtime'] = np.log1p(train['runtime'])\ntrain['popularity2'] = np.log1p(train['popularity2'])\n\ntest['popularity'] = np.log1p(test['popularity'])  \ntest['totalVotes'] = np.log1p(test['totalVotes'])\ntest['budget'] = np.log1p(test['budget'])\ntest['runtime'] = np.log1p(test['runtime'])\ntest['popularity2'] = np.log1p(test['popularity2'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature Engineering","metadata":{}},{"cell_type":"markdown","source":"#### Belongs to collection","metadata":{}},{"cell_type":"code","source":"for i,e in enumerate(train['belongs_to_collection'][:2]):\n    print(i,e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['belongs_to_collection'].apply(lambda x: 1 if x!= {} else 0).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"2396 dont have any value. 604 have collection values. We will store collection name separtely as another features, as rest of the values won't be much needed, so we'll drop them.","metadata":{}},{"cell_type":"code","source":"train['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x!={} else 0)\ntest['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x!={} else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sample(2)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly we will check all the dictionaries and clean them.\nNow we will check for Genres.\n### Genres","metadata":{}},{"cell_type":"code","source":"for i,e in enumerate(train['genres'][:2]):\n    print(i,e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of genres in films:')\ntrain['genres'].apply(lambda x: len(x) if x!={} else 0).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This shows that majority of the films have 2-3 genres. 5-6 are also possible but 0-7 might be outliers. ","metadata":{}},{"cell_type":"code","source":"list_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x!={} else []).values)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\ntext = ' '.join(i for j in list_of_genres for i in j)\nwordcloud = WordCloud(max_font_size = None, width = 1200, height = 1000,\n                      collocations =False).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top Genres')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Counter([i for j in list_of_genres for i in j]).most_common(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, Drama, Comedy, Thriller , Action are the most common genres.","metadata":{}},{"cell_type":"code","source":"top_genres =[m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(10)]\nprint(top_genres)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see, Drama and Comedy are the most common genres.\nWe can create separate features. \nOne for num of genres.\nAnother for value of all genres.\nand then for most common genres.","metadata":{}},{"cell_type":"code","source":"train['num_of_genres'] = train['genres'].apply(lambda x: len(x) if x!={} else 0)\ntrain['all_genres'] = train['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x ])) \n                                           if x!= {} else '')\ntest['num_of_genres'] = test['genres'].apply(lambda x: len(x) if x!={} else 0)\ntest['all_genres'] = test['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x ])) \n                                           if x!= {} else '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for g in top_genres:\n    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\n    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's look briefly at production companies.\n#### Production Companies","metadata":{}},{"cell_type":"code","source":"for i,e in enumerate(train['production_companies'][:2]):\n    print(i,e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of Production Companies for a movie:')\ntrain['production_companies'].apply(lambda x: len(x) if x!= {} else 0).value_counts()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As you can see, majority of the movie's have 1-3 production companies.\nThere are movie's with more than 10 production companies. We will have a look at these companies to check if the data is valid.","metadata":{}},{"cell_type":"code","source":"train[train['production_companies'].apply(lambda x: len(x) if x!= {} else 0) > 10]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"All of the movie's look real, so we will keep the data.","metadata":{}},{"cell_type":"markdown","source":"Now lets see the most common production companies.","metadata":{}},{"cell_type":"code","source":"list_of_companies = list(train['production_companies'].apply(lambda x : [i['name'] for i in x] \n                                                            if x!= {} else []).values)\nCounter(i for j in list_of_companies for i in j).most_common(20)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We will create binary columns for the top 10 production house and later see what we do with this data. We will also create additional features.","metadata":{}},{"cell_type":"code","source":"train['num_prod_companies'] = train['production_companies'].apply(lambda x: len(x) if\n                                                                 x!={} else 0)\ntest['num_prod_companies'] = test['production_companies'].apply(lambda x: len(x) if \n                                                               x!={} else 0)\ntrain['all_prod_companies'] = train['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x!={} else '' )\ntest['all_prod_companies'] = test['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x!={} else '')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_prod_companies = [m[0] for m in Counter(i for j in list_of_companies for i in j).most_common(10)]\nfor pc in top_prod_companies:\n    train['production_' + pc] = train['all_prod_companies'].apply(lambda x: 1 if pc in x else 0)\n    test['production_'+ pc] = test['all_prod_companies'].apply(lambda x: 1 if pc in x else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Similarly we will check for production countries.\n#### Production Countries","metadata":{}},{"cell_type":"code","source":"for i, e in enumerate(train['production_countries'][:2]):\n    print(i,e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of Production Countries in Movies:')\ntrain['production_countries'].apply(lambda x: len(x) if x!={} else 0).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Majority of the movies have 1 or 2 production countries. Some movies have more. Let's check the movie's with more than 5 production countries.","metadata":{}},{"cell_type":"code","source":"train[train['production_countries'].apply(lambda x: len(x) if x!= {} else 0) > 5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are only 4 movies with more than 5 production countries, all of which look valid. Now let's see which are the most common production countries.","metadata":{}},{"cell_type":"code","source":"List_of_countries = list(train['production_countries'].apply(lambda x: [i['name'] for i in x] \n                                                             if x!= {} else []))\n#Count of production countries in movies\nCounter(i for j in List_of_countries for i in j).most_common(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['num_prod_countries'] = train['production_countries'].apply(lambda x: len(x) if x!= {} \n                                                                  else 0)\ntest['num_prod_countries'] = test['production_countries'].apply(lambda x: len(x) if x!={}\n                                                               else 0)\ntrain['all_prod_countries'] = train['production_countries'].apply(lambda x: ' '.join(sorted(i['name'] for i in x))\n                                                                 if x!= {} else '')\ntest['all_prod_countries'] = test['production_countries'].apply(lambda x: ' '.join(sorted(i['name'] for i in x))\n                                                               if x!= {} else '')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_prod_countries = [m[0] for m in Counter(i for j in List_of_countries for i in j).most_common(6)]\nfor t in top_prod_countries:\n    train['prod_country_' + t] = train['all_prod_countries'].apply(lambda x: 1 if t in x else 0)\n    test['prod_country_'+ t] = test['all_prod_countries'].apply(lambda x: 1 if t in x else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Spoken Languages","metadata":{}},{"cell_type":"code","source":"for i, e in enumerate(train['spoken_languages'][:2]):\n    print(i,e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of languages for a movie:')\ntrain['spoken_languages'].apply(lambda x: len(x) if x!={} else 0).value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This shows that most of the movies have 1-2 languages.","metadata":{}},{"cell_type":"code","source":"list_of_langs = list(train['spoken_languages'].apply(lambda x: [i['name'] for i in x]\n                                                    if x!= {} else []))\ntop_langs = [m[0] for m in Counter(i for j in list_of_langs for i in j).most_common(5)]\nCounter(i for j in list_of_langs for i in j).most_common(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['num_of_langs'] = train['spoken_languages'].apply(lambda x: len(x) if x!= {} else 0)\ntest['num_of_langs'] = test['spoken_languages'].apply(lambda x: len(x) if x!= {} else 0)\n\ntrain['all_langs'] = train['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                                    if x!= {} else '')\ntest['all_langs'] = test['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name'] for i in x]))\n                                                  if x!= {} else '')\n\nfor l in top_langs:\n    train['lang_' + l] = train['all_langs'].apply(lambda x: 1 if l in x else 0)\n    test['lang_'+ l] = test['all_langs'].apply(lambda x: 1 if l in x else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\ntext2 = ' '.join(i for j in list_of_langs for i in j)\nwordcloud2 = WordCloud(collocations=False).generate(text2)\nplt.imshow(wordcloud2)\nplt.axis('off')\nplt.title('Top Spoken Languages in Movies')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Keywords","metadata":{}},{"cell_type":"code","source":"for i, e in enumerate(train['Keywords'][:2]):\n    print(i,e)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_of_keys = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x!= {} else []))\nCounter(i for j in list_of_keys for i in j).most_common(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_keywords = [m[0] for m in Counter(i for j in list_of_keys for i in j).most_common(10)]\ntrain['num_of_keywords'] = train['Keywords'].apply(lambda x: len(x) if x!={} else 0)\ntest['num_of_keywords'] = test['Keywords'].apply(lambda x: len(x) if x!={} else 0)\n\ntrain['all_keywords'] = train['Keywords'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                               if x!= {} else '')\ntest['all_keywords'] = test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x]))\n                                             if x!={} else '')\nfor k in top_keywords:\n    train['keyword_'+ k] = train['all_keywords'].apply(lambda x: 1 if k in x else 0)\n    test['keyword_'+ k] = test['all_keywords'].apply(lambda x: 1 if k in x else 0)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\ntext3 = ' '.join(['_'.join(i.split(' ')) for j in list_of_keys for i in j])\nwordcloud3 = WordCloud(collocations = False).generate(text3)\nplt.imshow(wordcloud3)\nplt.title('Top Keywords')\nplt.axis('off')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Cast","metadata":{}},{"cell_type":"code","source":"for i, e in enumerate(train['cast'][:1]):\n    print(i,e)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of casts used per movie:')\ntrain['cast'].apply(lambda x: len(x) if x!={} else 0).value_counts().head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_cast_name = list(train['cast'].apply(lambda x: [i['name'] for i in x]if x!= {} else []))\ntop_cast_name = [m[0] for m in Counter(i for j in list_cast_name for i in j).most_common(20)]\nCounter(i for j in list_cast_name for i in j).most_common(20)","metadata":{"scrolled":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['num_of_cast']= train['cast'].apply(lambda x: len(x) if x!={} else 0)\ntest['num_of_cast'] = test['cast'].apply(lambda x: len(x) if x!={} else 0)\n\ntrain['all_cast_name'] = train['cast'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                             if x!={} else '')\ntest['all_cast_name'] = test['cast'].apply(lambda x: ' '.join(sorted([i['name']for i in x]))\n                                          if x!= {} else '')\nfor c in top_cast_name:\n    train['cast_name_'+ c]= train['all_cast_name'].apply(lambda x: 1 if c in x else 0)\n    test['cast_name_'+ c]= test['all_cast_name'].apply(lambda x: 1 if c in x else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Crew","metadata":{}},{"cell_type":"code","source":"for i,e in enumerate(train['crew'][:1]):\n    print(i,e)","metadata":{"_kg_hide-output":true,"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Number of crew members per movie:')\ntrain['crew'].apply(lambda x: len(x) if x!= {} else 0).value_counts().head(10)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x!= {} else []).values)\nCounter(i for j in list_crew_names for i in j).most_common(15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_crew_names = [m[0] for m in Counter(i for j in list_crew_names for i in j).most_common(20)]\ntrain['num_of_crew'] = train['crew'].apply(lambda x: len(x) if x!= {} else 0)\ntest['num_of_crew']= test['crew'].apply(lambda x: len(x) if x!= {} else 0)\nfor cn in top_crew_names:\n    train['crew_name_'+ cn]= train['crew'].apply(lambda x: 1 if cn in str(x) else 0)\n    test['crew_name_'+ cn] = test['crew'].apply(lambda x: 1 if cn in str(x) else 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Homepage","metadata":{}},{"cell_type":"code","source":"train['homepage'].isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['has_homepage'] = 1\ntrain.loc[pd.isnull(train['homepage']) ,\"has_homepage\"] = 0\ntest['has_homepage'] = 1\ntest.loc[pd.isnull(test['homepage']) ,\"has_homepage\"] = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['runtime'].isna().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['runtime'].fillna(train['runtime'].mean(),inplace= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['runtime'].fillna(test['runtime'].mean(),inplace= True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Visualization\nWe'll do Data Visualization for our features and then add additional features .","metadata":{}},{"cell_type":"markdown","source":"### __Target Variable: Revenue__","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (12,5))\nsns.set()\nplt.subplot(1,2,1)\nplt.hist(np.expm1(train['revenue']), bins =10)\nplt.title('Distribution of revenue',fontsize=15)\nplt.subplot(1,2,2)\nplt.hist(train['revenue'], bins =10) \nplt.title('Distribution of log revenue', fontsize=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We converted Revenue to log Revenue earlier and we can see a better distribution of data now.","metadata":{}},{"cell_type":"markdown","source":"### Budget","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (14,5))\nsns.set()\nplt.subplot(1,2,1)\nplt.hist(np.expm1(train['budget']), bins =10)\nplt.title('Distribution of budget',fontsize=15)\nplt.subplot(1,2,2)\nplt.hist(train['budget'], bins =10) \nplt.title('Distribution of log budget', fontsize=15)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(data_frame = train, x='budget',y='revenue', title = 'Log Budget vs Log Revenue')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(data_frame = train, x='budget',y='popularity', title = 'Log Budget vs Log Popularity')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.scatter(data_frame = train, x='budget',y='runtime', title = 'Log Budget vs Log Runtime')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Original Language","metadata":{}},{"cell_type":"code","source":"fig = px.line(train, x=\"budget\", y=\"revenue\", color=\"original_language\", title = 'Log Budget vs Log Revenue in different languages')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"px.box(train.loc[train['original_language'].isin(train['original_language'].value_counts().head(6).index)], x='original_language', y='revenue', title='Log Revenue Distribution for top languages')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Original Title","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\ntext4 = ' '.join(train['original_title'].sort_values(ascending=False))\nwordcloud = WordCloud(collocations=False).generate(text4)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Most Common words in title', fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Overview","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,10))\ntext5 = ' '.join(train['overview'].fillna('').values)\nwordcloud = WordCloud(collocations=False).generate(text5)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Top words in Overview', fontsize=15)\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Popularity","metadata":{}},{"cell_type":"code","source":"px.scatter(train.loc[train['original_language'].isin(train['original_language'].value_counts().head(6).index)],\n           x='popularity', y='revenue',color = 'original_language',size='budget', title = 'Log Revenue vs Log Popularity (Buble size=Budget)')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Release Date","metadata":{}},{"cell_type":"code","source":"train.loc[train['release_date'].isnull() == True, 'release_date'] = '01/01/98'\ntest.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/98'\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fix_date(x):\n    \"\"\"\n    Fixes dates which are in 20xx\n    \"\"\"\n    year = x.split('/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_date(df):\n    date_parts = [\"year\", \"weekday\", \"month\", 'weekofyear', 'day', 'quarter']\n    for part in date_parts:\n        part_col = 'release' + \"_\" + part\n        df[part_col] = getattr(df['release_date'].dt, part).astype(int)\n    \n    return df\n\ntrain = process_date(train)\ntest = process_date(test)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d = train['release_date'].dt.year.value_counts().sort_index()\ng = train.groupby('release_date')['revenue'].sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"d1 = train['release_year'].value_counts().sort_index()\nd2 = train.groupby(['release_year'])['revenue'].sum()\nd3 = train.groupby(['release_year'])['budget'].sum()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='film count'), \n        go.Scatter(x=d2.index, y=d2.values, name='total revenue', yaxis='y2'),\n        go.Scatter(x=d3.index, y=d3.values, name='total budget', yaxis='y2')]\nlayout = go.Layout(dict(title = \"Number of films and total revenue per year\",\n                  xaxis = dict(title = 'Year'),\n                  yaxis = dict(title = 'Count'),\n                  yaxis2=dict(title='Capital', overlaying='y', side='right')\n                  ),legend=dict(\n                orientation=\"v\"))\nfig = go.Figure(data, layout)\nfig.update_xaxes(\n    rangeslider_visible=True)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The film industry has grown significantly over the last few decades as we can see the significant increase in Number of films and Revenue generated by them each year.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.stripplot(x='release_weekday', y= 'revenue', data=train)\nplt.xlabel('Weekday')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by release day of week', fontsize=17)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like Wednesday, Thursday and Friday releases generate more revenue.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.stripplot(x='release_quarter', y= 'revenue', data=train)\nplt.xlabel('Quarter')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by release quater of year', fontsize=17)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Not much different. It hardly matters in which quarter the movie is releasing.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,7))\nsns.stripplot(x='release_month', y= 'revenue', data=train)\nplt.xlabel('Month')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by release month', fontsize=17)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Runtime","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.regplot(data=train, x='runtime', y='revenue')\nplt.xlabel('Runtime')\nplt.ylabel('Revenue')\nplt.title('Log Revenue by Log Runtime', fontsize=17)\nplt.subplot(1,2,2)\nplt.hist(train['runtime'], bins=10)\nplt.xlabel('Runtime')\nplt.ylabel('Count')\nplt.title('Distribution by Log Runtime', fontsize=17)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Runtime doesn't look like a strong explanatory variable.","metadata":{}},{"cell_type":"markdown","source":"### Status","metadata":{}},{"cell_type":"code","source":"train['status'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Since majority of the movies are released, this variable is useless.","metadata":{}},{"cell_type":"markdown","source":"### Tagline","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,12))\ntext6 = ' '.join(train['tagline'].fillna('').values)\nwordcloud = WordCloud(collocations = False).generate(text6)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.title('Top words in tagline')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Has Collection","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.stripplot(data=train, x='has_collection', y= 'revenue')\nplt.title('Stripplot of Log Revenue vs Collection', fontsize=17)\nplt.subplot(1,2,2)\nsns.boxplot(data=train, x='has_collection', y= 'revenue')\nplt.title('Boxplot of Log Revenue vs Collection',fontsize=17)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This gives us an indication that the movies that are the part of a collection are expected to earn more on average than the others.","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.stripplot(data=train, x='has_homepage', y= 'revenue')\nplt.title('Stripplot of Log Revenue vs Homepage', fontsize=17)\nplt.subplot(1,2,2)\nsns.boxplot(data=train, x='has_homepage', y= 'revenue')\nplt.title('Boxplot of Log Revenue vs Homepage',fontsize=17)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Genres","metadata":{}},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (14,5))\nplt.subplot(1,2,1)\nsns.stripplot(data=train, x='num_of_genres', y= 'revenue')\nplt.title('Stripplot of Log Revenue vs Number of Genres', fontsize=17)\nplt.subplot(1,2,2)\nsns.boxplot(data=train, x='num_of_genres', y= 'revenue')\nplt.title('Boxplot of Log Revenue vs Number of Genres',fontsize=17)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Surprisingly movies with 3-4 genres are expected to earn more than the rest.","metadata":{}},{"cell_type":"code","source":"f, axes = plt.subplots(4, 3, figsize=(15, 12))\nfor i,e in enumerate([col for col in train if col.startswith('genre_')]):\n    sns.stripplot(data=train, x=e, y='revenue',  ax=axes[i // 3][i % 3])\nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can see that Adventure and Science Fiction are expected to earn more on average than other genres.","metadata":{}},{"cell_type":"markdown","source":"### Production Companies","metadata":{}},{"cell_type":"code","source":"fig = px.box(train, x='num_prod_companies', y= 'revenue',\n             color='has_collection',title='Log Revenue vs Number of Production companys')\nfig.update_traces(quartilemethod=\"exclusive\") # or \"inclusive\", or \"linear\" by default\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Number of Production companies doesn't matter much in movies with no collection but in movies with collection, average revenue increases with increasing number of production companies, till a certain limit.","metadata":{}},{"cell_type":"markdown","source":"### Production Countries","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.set()\nsns.stripplot(x='num_prod_countries', y='revenue', data=train)\nplt.xlabel('Production Countries',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Log Revenue vs Number of countries producing the film',fontsize=15);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As the number of Production Countries increases, the revenues is decreasing. The films produced in 1-2 countries have the highest revenue.","metadata":{}},{"cell_type":"code","source":"f, axes = plt.subplots(2, 3, figsize=(12, 10))\nplt.suptitle('Log revenue vs Top Production Countries', fontsize=15)\nfor i,e in enumerate([col for col in train if col.startswith('prod_country_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i // 3][i % 3])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Movies produced in USA generates more revenue on Average as compared to movies produced in other countries.","metadata":{}},{"cell_type":"markdown","source":"### Languages\nThe number of languages a movie is released in.","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nsns.set()\nsns.stripplot(x='num_of_langs', y='revenue', data=train)\nplt.xlabel('Number of languages',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Log Revenue vs Number of languages movie released in',fontsize=15);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Keywords","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.set()\nsns.stripplot(x='num_of_keywords', y='revenue', data=train)\nplt.xlabel('Number of Keywords',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Revenue vs Number of keywords',fontsize=15);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(4, 3, figsize=(15, 15))\nplt.suptitle('Boxplot of Log Revenue vs Top Keywords', fontsize=16)\nfor i,e in enumerate([col for col in train if col.startswith('keyword_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i // 3][i % 3])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cast","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.set()\nsns.regplot(x='num_of_cast', y='revenue', data=train)\nplt.xlabel('Number of Cast',fontsize=15)\nplt.ylabel('Revenue',fontsize=15)\nplt.title('Log Revenue vs Number of Cast',fontsize=16);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(5, 4, figsize=(15, 13))\nplt.suptitle('Boxplot of Log Revenue vs Top Cast', fontsize=16)\nfor i,e in enumerate([col for col in train if col.startswith('cast_name_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i // 4][i % 4])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We can clearly see, movies of some actors generate more revenue than others.","metadata":{}},{"cell_type":"markdown","source":"### Crew","metadata":{}},{"cell_type":"code","source":"px.scatter(data_frame = train, x='num_of_crew',y='revenue', title = 'Crew vs Log Revenue(Bubble size= Number of cast, color= Budget)',\n           size='num_of_cast',color='budget')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"f, axes = plt.subplots(5, 4, figsize=(15, 20))\nplt.suptitle('Boxplot of Log Revenue vs Top Crew', fontsize=16)\nfor i,e in enumerate([col for col in train if col.startswith('crew_name_')]):\n    sns.boxplot(data=train, x=e, y='revenue',  ax=axes[i // 4][i % 4])\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some crew definetly produce more revenue.","metadata":{}},{"cell_type":"markdown","source":"#### Additional Features","metadata":{}},{"cell_type":"code","source":"rating_na = train.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\ntrain[train.rating.isna()]['rating'] = train.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\nvote_count_na = train.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\ntrain[train.totalVotes.isna()]['totalVotes'] = train.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\ntrain['weightedRating'] = ( train['rating']*train['totalVotes'] + 6.367 * 1000 ) / ( train['totalVotes'] + 1000 )\n\ntrain['inflationBudget'] = np.log1p(np.expm1(train['budget']) + np.expm1(train['budget'])*1.8/100*(2018-train['release_year'])) \n#Inflation simple formula\ntrain['_popularity_mean_year'] = train['popularity'] / train.groupby(\"release_year\")[\"popularity\"].transform('mean')\ntrain['_budget_runtime_ratio'] = train['budget']/train['runtime'] \ntrain['_budget_popularity_ratio'] = train['budget']/train['popularity']\ntrain['_budget_year_ratio'] = train['budget']/(train['release_year']*train['release_year'])\ntrain['_releaseYear_popularity_ratio'] = train['release_year']/train['popularity']\n\ntrain['_popularity_totalVotes_ratio'] = train['totalVotes']/train['popularity']\ntrain['_rating_popularity_ratio'] = train['rating']/train['popularity']\ntrain['_rating_totalVotes_ratio'] = train['totalVotes']/train['rating']\ntrain['_totalVotes_releaseYear_ratio'] = train['totalVotes']/train['release_year']\ntrain['_budget_rating_ratio'] = train['budget']/train['rating']\ntrain['_runtime_rating_ratio'] = train['runtime']/train['rating']\ntrain['_budget_totalVotes_ratio'] = train['budget']/train['totalVotes']\n    \ntrain['meanruntimeByYear'] = train.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\ntrain['meanPopularityByYear'] = train.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\ntrain['meanBudgetByYear'] = train.groupby(\"release_year\")[\"budget\"].aggregate('mean')\ntrain['meantotalVotesByYear'] = train.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\ntrain['meanTotalVotesByRating'] = train.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n\ntrain['isTaglineNA'] = 0\ntrain.loc[train['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n    \ntrain['isTitleDifferent'] = 1\ntrain.loc[ train['original_title'] == train['title'] ,\"isTitleDifferent\"] = 0 \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rating_na = test.groupby([\"release_year\",\"original_language\"])['rating'].mean().reset_index()\ntest[test.rating.isna()]['rating'] = test.merge(rating_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\nvote_count_na = test.groupby([\"release_year\",\"original_language\"])['totalVotes'].mean().reset_index()\ntest[test.totalVotes.isna()]['totalVotes'] = test.merge(vote_count_na, how = 'left' ,on = [\"release_year\",\"original_language\"])\ntest['weightedRating'] = ( test['rating']*test['totalVotes'] + 6.367 * 1000 ) / ( test['totalVotes'] + 1000 )\n\n\ntest['inflationBudget'] = np.log1p(np.expm1(test['budget']) + np.expm1(test['budget'])*1.8/100*(2018-test['release_year'])) #Inflation simple formula\n \ntest['_popularity_mean_year'] = test['popularity'] / test.groupby(\"release_year\")[\"popularity\"].transform('mean')\ntest['_budget_runtime_ratio'] = test['budget']/test['runtime'] \ntest['_budget_popularity_ratio'] = test['budget']/test['popularity']\ntest['_budget_year_ratio'] = test['budget']/(test['release_year']*test['release_year'])\ntest['_releaseYear_popularity_ratio'] = test['release_year']/train['popularity']\n\ntest['_popularity_totalVotes_ratio'] = test['totalVotes']/test['popularity']\ntest['_rating_popularity_ratio'] = test['rating']/test['popularity']\ntest['_rating_totalVotes_ratio'] = test['totalVotes']/test['rating']\ntest['_totalVotes_releaseYear_ratio'] = test['totalVotes']/test['release_year']\ntest['_budget_rating_ratio'] = test['budget']/test['rating']\ntest['_runtime_rating_ratio'] = test['runtime']/test['rating']\ntest['_budget_totalVotes_ratio'] = test['budget']/test['totalVotes']\n    \ntest['meanruntimeByYear'] = test.groupby(\"release_year\")[\"runtime\"].aggregate('mean')\ntest['meanPopularityByYear'] = test.groupby(\"release_year\")[\"popularity\"].aggregate('mean')\ntest['meanBudgetByYear'] = test.groupby(\"release_year\")[\"budget\"].aggregate('mean')\ntest['meantotalVotesByYear'] = test.groupby(\"release_year\")[\"totalVotes\"].aggregate('mean')\ntest['meanTotalVotesByRating'] = test.groupby(\"rating\")[\"totalVotes\"].aggregate('mean')\n\ntest['isTaglineNA'] = 0\ntest.loc[test['tagline'] == 0 ,\"isTaglineNA\"] = 1 \n    \ntest['isTitleDifferent'] = 1\ntest.loc[ test['original_title'] == test['title'] ,\"isTitleDifferent\"] = 0 \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.drop(['id','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline','all_genres',\n                    'all_prod_companies','all_prod_countries','all_langs','all_keywords','all_cast_name'],axis=1)\ntest = test.drop(['id','belongs_to_collection','genres','homepage','imdb_id','overview','runtime'\n    ,'poster_path','production_companies','production_countries','release_date','spoken_languages'\n    ,'status','title','Keywords','cast','crew','original_language','original_title','tagline','all_genres',\n                    'all_prod_companies','all_prod_countries','all_langs','all_keywords','all_cast_name'],axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.fillna(value=0.0, inplace = True) \ntest.fillna(value=0.0, inplace = True) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_dataset(df):\n    assert isinstance(df, pd.DataFrame), \"df needs to be a pd.DataFrame\"\n    df.dropna(inplace=True)\n    indices_to_keep = ~df.isin([np.nan, np.inf, -np.inf]).any(1)\n    return df[indices_to_keep].astype(np.float64)\ntrain = clean_dataset(train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Modeling","metadata":{}},{"cell_type":"markdown","source":"First we will try simple regressions model like Linear Regression, Lasso Regression, Decision Tree, Random Forest Regressor.","metadata":{}},{"cell_type":"code","source":"X = train.drop(['revenue'],axis=1)\ny = train.revenue\n\nX_train, X_valid, y_train, y_valid = train_test_split(X,y,test_size=0.2,random_state=25)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Linear Regression","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train, y_train)\npred = lr.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Linear Regression R2 Score: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_pred = cross_val_predict(lr,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) R2 Score: ', cv_accuracy)\n#REsidual Plots","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Lasso Regression","metadata":{}},{"cell_type":"code","source":"ls = Lasso()\nls.fit(X_train, y_train)\npred = ls.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Lasso Regression R2 Score: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Squared Error', np.sqrt(mse))\n\ncv_pred = cross_val_predict(ls,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) Lasso Regression Accuracy: ', cv_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Decision Tree Regressor","metadata":{}},{"cell_type":"code","source":"dt = DecisionTreeRegressor()\ndt.fit(X_train, y_train)\npred = dt.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Decision Tree R2 Score: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_pred = cross_val_predict(dt,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) Decision Tree Accuracy: ', cv_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"rf = RandomForestRegressor()\nrf.fit(X_train, y_train)\npred = rf.predict(X_valid)\naccuracy = r2_score(y_valid,pred)\nprint('Random Forest Regressor R2: ', accuracy)\n\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_pred = cross_val_predict(rf,X,y,n_jobs=-1, cv=10)\ncv_accuracy = r2_score(y,cv_pred)\nprint('Cross-Predicted(KFold) Random Forest R2: ', cv_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Random Forest looks like a better predictor than other models, let's tune it and see how much accuracy we can get.","metadata":{}},{"cell_type":"markdown","source":"#### Randomized Search CV on Random Forest Regressor","metadata":{}},{"cell_type":"code","source":"rfr = RandomForestRegressor()\nn_estimators = [int(x) for x in np.linspace(start = 50 , stop = 300, num = 5)] # returns 10 numbers \nmax_features = [10,20,40,60,80,100,120]\nmax_depth = [int(x) for x in np.linspace(5, 10, num = 2)] \nmax_depth.append(None)\nbootstrap = [True, False]\nr_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'bootstrap': bootstrap}\ncv_random = RandomizedSearchCV(estimator=rfr, param_distributions=r_grid, n_iter = 20,\n                                scoring='neg_mean_squared_error', cv = 3, verbose=2, random_state=42,\n                                n_jobs=-1, return_train_score=True)\n\ncv_random.fit(X_train, y_train);\n\nprint(cv_random.best_params_)\n\npred = cv_random.predict(X_valid)\nmse = mean_squared_error(y_valid,pred)\nprint('Mean Squared Error: ', mse)\nprint('Root Mean Square Error',np.sqrt(mse))\n\ncv_accuracy = r2_score(y_valid,pred)\nprint('Random Forest Predict R2: ', cv_accuracy)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_imp = [col for col in zip(X_train.columns, cv_random.best_estimator_.feature_importances_)]\nfeature_imp.sort(key=lambda x:x[1], reverse=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imp = pd.DataFrame(feature_imp[0:40], columns=['feature', 'importance'])\nplt.figure(figsize=(14, 12))\nsns.barplot(y='feature', x='importance', data=imp)\nplt.title('30 Most Important Features', fontsize=16)\nplt.ylabel(\"Feature\", fontsize=15)\nplt.xlabel(\"Importance Param\",fontsize=15)\nplt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the 30 most important features.","metadata":{}},{"cell_type":"code","source":"imp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### H2o AutoML\nNow let's try H2o AutoML on our Data to check if it gives better accuracy and less error.","metadata":{}},{"cell_type":"code","source":"import h2o\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\nfrom h2o.automl import H2OAutoML","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2o.init()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2o_df=h2o.H2OFrame(train)\nh2o_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"splits = h2o_df.split_frame(ratios=[0.8],seed=1)\nh2o_train = splits[0]\nh2o_valid = splits[1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = \"revenue\" \nx = h2o_df.columns \nx.remove(y) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aml = H2OAutoML(max_runtime_secs=180, seed=1,stopping_metric='RMSE')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aml.train(x=x,y=y, training_frame=h2o_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lb = aml.leaderboard\nlb.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The best rmse is for the Stacked Ensemble Model which is 1.90,which shows that our Random Forest Regressor was a good model as we were able to achieve rmse of 1.92","metadata":{}},{"cell_type":"code","source":"# Get model ids for all models in the AutoML Leaderboard\nmodel_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n# Get the \"All Models\" Stacked Ensemble model\nse = h2o.get_model([mid for mid in model_ids if \"StackedEnsemble_AllModels\" in mid][0])\n# Get the Stacked Ensemble metalearner model\nmetalearner = h2o.get_model(se.metalearner()['name'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#This shows us how much each base learner is contributing to the ensemble.\n%matplotlib inline\nmetalearner.std_coef_plot()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = aml.predict(h2o_valid)\npred.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"h2o.save_model(aml.leader, path=\"./model_bin\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's try if we can get better accuracy and less error from XGBoost.","metadata":{}},{"cell_type":"markdown","source":"#### XGBoost","metadata":{}},{"cell_type":"code","source":"import xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\nparams = {'objective': 'reg:linear', \n          'eta': 0.01, \n          'max_depth': 6, \n          'min_child_weight': 3,\n          'subsample': 0.8,\n          'colsample_bytree': 0.8,\n          'colsample_bylevel': 0.50, \n          'gamma': 1.45, \n          'eval_metric': 'rmse', \n          'seed': 12, \n          'silent': True}\n# create dataset for xgboost\nxgb_data = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_valid, y_valid), 'valid')]\nprint('Starting training...')\n# train\nxgb_model = xgb.train(params, \n                  xgb.DMatrix(X_train, y_train),\n                  10000,  \n                  xgb_data, \n                  verbose_eval=300,\n                  early_stopping_rounds=300)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RMSE is even better as compared to the best model by H2o AutoML. So we will stick with our XGBoost as our final model.","metadata":{}},{"cell_type":"code","source":"xgb_pred = xgb_model.predict(xgb.DMatrix(X_valid))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(figsize=(20,12))\nxgb.plot_importance(xgb_model, max_num_features=30, height = 0.8, ax = ax)\nplt.title('XGBOOST Features (avg over folds)')\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.shape, test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test = test.drop('revenue',axis=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_test[X_test==np.inf]=np.nan\nX_test.fillna(X_test.mean(), inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_xgb = xgb_model.predict(xgb.DMatrix((X_test)), ntree_limit=xgb_model.best_ntree_limit)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_pred_xgb[0]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Cat Boost","metadata":{}},{"cell_type":"code","source":"from catboost import CatBoostRegressor\nmodel = CatBoostRegressor(iterations=100000,\n                                 learning_rate=0.005,\n                                 depth=5,\n                                 eval_metric='RMSE',\n                                 colsample_bylevel=0.8,\n                                 random_seed = 21,\n                                 bagging_temperature = 0.2,\n                                 metric_period = None,\n                                 early_stopping_rounds=200\n                                )\nmodel.fit(X_train, y_train,eval_set=(X_valid, y_valid),use_best_model=True,verbose=500)\n    \nval_pred = model.predict(X_valid)\nprint('RMSE',np.sqrt(mean_squared_error(val_pred,y_valid)))\ntest_pred_cat = model.predict(X_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"CatBoost gave even less error than the XGB, now let's try LightGBM.","metadata":{}},{"cell_type":"markdown","source":"### LightGBM Model","metadata":{}},{"cell_type":"code","source":"import lightgbm as lgb\nparams = {'objective':'regression',\n         'num_leaves' : 30,\n         'min_data_in_leaf' : 20,\n         'max_depth' : 9,\n         'learning_rate': 0.004,\n         #'min_child_samples':100,\n         'feature_fraction':0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         'lambda_l1': 0.2,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         #'subsample':.8, \n          #'colsample_bytree':.9,\n         \"random_state\" : 11,\n         \"verbosity\": -1}\nrecord = dict()\nmodel = lgb.train(params\n                      , lgb.Dataset(X_train, y_train)\n                      , num_boost_round = 100000\n                      , valid_sets = [lgb.Dataset(X_valid, y_valid)]\n                      , verbose_eval = 500\n                      , early_stopping_rounds = 500\n                      , callbacks = [lgb.record_evaluation(record)]\n                     )\nbest_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\nval_pred = model.predict(X_valid, num_iteration = model.best_iteration)\ntest_pred_gbm = model.predict(X_test, num_iteration = model.best_iteration)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the final submission you can try different combinations of model to predict the target revenue. For me the below model made sense and gave great prediction.","metadata":{}},{"cell_type":"code","source":"sub = pd.read_csv('../input/tmdb-box-office-prediction/sample_submission.csv')\ndf_sub = pd.DataFrame()\ndf_sub['id'] = sub['id']\nfinal_pred = 0.3*test_pred_xgb + 0.7*test_pred_cat\ndf_sub['revenue'] = np.expm1(final_pred)\nprint(df_sub['revenue'])\ndf_sub.to_csv(\"submission.csv\", index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Conclusion**\n\nThat's it we reached the end of our exercise.\n\nWe started with data exploration and cleaning, checked skewness,then we jumped straight out to feature creation, we converted all the text features to usable features for our model.\nThen we did Data Visualization and checked correlation between various features and our target variable 'Revenue' and then created additional features.\nFinally we created some models and checked performance based on rmse. Random Forest showed us good result. H2o AutoML gave us an even better performance, but since it is a blackbox model, we rather tried XGBoost model which gave us an equally good performance. \nIt took me many many hours of effort to get this all done.\nDo drop comments where you think I can improve the model or features.\nUpvote if you liked what you saw.\nThanks and much more to come ;)","metadata":{}}]}