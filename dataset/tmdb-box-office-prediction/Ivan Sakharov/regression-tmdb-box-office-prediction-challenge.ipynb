{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n#---Some visualization libraries----\nfrom matplotlib import pyplot as plt\n\nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('darkgrid')\n\n\n\nfrom wordcloud import WordCloud\n\n#-----------------------------------\n\nfrom scipy.stats import norm, skew\nfrom scipy import stats\n\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nimport eli5\n\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\n\n## Some other snippit of codes to get the setting right \n## This is so that the chart created by matplotlib can be shown in the jupyter notebook. \n%matplotlib inline \n%config InlineBackend.figure_format = 'retina' ## This is preferable for retina display. \n\n#import warnings ## importing warnings library. \n#warnings.filterwarnings('ignore') ## Ignore warning\n\n#def ignore_warn(*args, **kwargs):\n#    pass\n#warnings.warn = ignore_warn #ignore annoying warning (from sklearn and seaborn)\n\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x)) #Limiting floats output to 3 decimal points\npd.set_option('max_columns', None)\n\nimport os ## imporing os\nprint(os.listdir(\"../input/\"))\n\n#text_to_dict\nimport ast\nfrom collections import Counter\nimport time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data loading and overview**"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"#feature engineering from https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation\n\ntrain = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')\n\ntrain.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from this kernel: https://www.kaggle.com/gravix/gradient-in-a-box\n\n#this thing converts dicts to correct text, which later can be parsed\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ntrain = text_to_dict(train)\ntest = text_to_dict(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"extract data from these columns"},{"metadata":{},"cell_type":"markdown","source":"*dict \"belongs_to_collection\"*"},{"metadata":{"trusted":true},"cell_type":"code","source":"#first five\nfor i, e in enumerate(train['belongs_to_collection'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape , test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ntrain['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n\ntest['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ntest['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n\ntrain = train.drop(['belongs_to_collection'], axis=1)\ntest = test.drop(['belongs_to_collection'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*dict genres*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['genres'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of genres in films')\ntrain['genres'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_genres","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 8))\ntext = ' '.join([i for j in list_of_genres for i in j])\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top genres')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter([i for j in list_of_genres for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create binary columns for top-15 genres ."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_genres'] = train['genres'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_genres'] = train['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_genres = [m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(15)]\nfor g in top_genres:\n    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_genres'] = test['genres'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_genres'] = test['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_genres:\n    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['genres'], axis=1)\ntest = test.drop(['genres'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*dict production_companies*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['production_companies'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of production companies in films')\ntrain['production_companies'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_companies = list(train['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Counter([i for j in list_of_companies for i in j]).most_common(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"create binary columns for top-30 companies."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_companies'] = train['production_companies'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_production_companies'] = train['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_companies = [m[0] for m in Counter([i for j in list_of_companies for i in j]).most_common(30)]\nfor g in top_companies:\n    train['production_company_' + g] = train['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_companies'] = test['production_companies'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_production_companies'] = test['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_companies:\n    test['production_company_' + g] = test['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['production_companies', 'all_production_companies'], axis=1)\ntest = test.drop(['production_companies', 'all_production_companies'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*dict - production_countries*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['production_countries'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of production countries in films')\ntrain['production_countries'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_countries = list(train['production_countries'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_countries for i in j]).most_common(25)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"top-25 countries"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_countries'] = train['production_countries'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_countries'] = train['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_countries = [m[0] for m in Counter([i for j in list_of_countries for i in j]).most_common(25)]\nfor g in top_countries:\n    train['production_country_' + g] = train['all_countries'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_countries'] = test['production_countries'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_countries'] = test['production_countries'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_countries:\n    test['production_country_' + g] = test['all_countries'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['production_countries', 'all_countries'], axis=1)\ntest = test.drop(['production_countries', 'all_countries'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*dict - Spoken languages*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['spoken_languages'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of spoken languages in films')\ntrain['spoken_languages'].apply(lambda x: len(x) if x != {} else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_languages = list(train['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_languages for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"top-30 language"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_languages'] = train['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_languages'] = train['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_languages = [m[0] for m in Counter([i for j in list_of_languages for i in j]).most_common(30)]\nfor g in top_languages:\n    train['language_' + g] = train['all_languages'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_languages'] = test['spoken_languages'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_languages'] = test['spoken_languages'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_languages:\n    test['language_' + g] = test['all_languages'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['spoken_languages', 'all_languages'], axis=1)\ntest = test.drop(['spoken_languages', 'all_languages'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*dict - Keywords*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['Keywords'][:5]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of Keywords in films')\ntrain['Keywords'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_keywords = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nplt.figure(figsize = (16, 12))\ntext = ' '.join(['_'.join(i.split(' ')) for j in list_of_keywords for i in j])\nwordcloud = WordCloud(max_font_size=None, background_color='black', collocations=False,\n                      width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top keywords')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"most 30"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_Keywords'] = train['Keywords'].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_Keywords'] = train['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\ntop_keywords = [m[0] for m in Counter([i for j in list_of_keywords for i in j]).most_common(30)]\nfor g in top_keywords:\n    train['keyword_' + g] = train['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n    \ntest['num_Keywords'] = test['Keywords'].apply(lambda x: len(x) if x != {} else 0)\ntest['all_Keywords'] = test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_keywords:\n    test['keyword_' + g] = test['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n\ntrain = train.drop(['Keywords', 'all_Keywords'], axis=1)\ntest = test.drop(['Keywords', 'all_Keywords'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*dict cast*"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['cast'][:1]):\n    print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of casted persons in films')\ntrain['cast'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_names = list(train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_genders = list(train['cast'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_genders for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_characters = list(train['cast'].apply(lambda x: [i['character'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_characters for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"top 15 cast name, 3 genders, top 15 cast character"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_cast'] = train['cast'].apply(lambda x: len(x) if x != {} else 0)\ntop_cast_names = [m[0] for m in Counter([i for j in list_of_cast_names for i in j]).most_common(15)]\nfor g in top_cast_names:\n    train['cast_name_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\ntrain['genders_0_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\ntop_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(15)]\nfor g in top_cast_characters:\n    train['cast_character_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\n    \ntest['num_cast'] = test['cast'].apply(lambda x: len(x) if x != {} else 0)\nfor g in top_cast_names:\n    test['cast_name_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\ntest['genders_0_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\nfor g in top_cast_characters:\n    test['cast_character_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\n\ntrain = train.drop(['cast'], axis=1)\ntest = test.drop(['cast'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"dict crew"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, e in enumerate(train['crew'][:1]):\n    print(i, e[:10])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of casted persons in films')\ntrain['crew'].apply(lambda x: len(x) if x != {} else 0).value_counts().head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_names = list(train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_jobs = list(train['crew'].apply(lambda x: [i['job'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_jobs for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_genders = list(train['crew'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_genders for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_departments = list(train['crew'].apply(lambda x: [i['department'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_departments for i in j]).most_common(14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_names = train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values\nCounter([i for j in list_of_crew_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['num_crew'] = train['crew'].apply(lambda x: len(x) if x != {} else 0)\ntop_crew_names = [m[0] for m in Counter([i for j in list_of_crew_names for i in j]).most_common(15)]\nfor g in top_crew_names:\n    train['crew_name_' + g] = train['crew'].apply(lambda x: 1 if g in str(x) else 0)\ntrain['genders_0_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\ntop_crew_names = [m[0] for m in Counter([i for j in list_of_crew_names for i in j]).most_common(15)]\n\ntop_crew_jobs = [m[0] for m in Counter([i for j in list_of_crew_jobs for i in j]).most_common(15)]\nfor j in top_crew_jobs:\n    train['jobs_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\ntop_crew_departments = [m[0] for m in Counter([i for j in list_of_crew_departments for i in j]).most_common(15)]\nfor j in top_crew_departments:\n    train['departments_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n    \ntest['num_crew'] = test['crew'].apply(lambda x: len(x) if x != {} else 0)\nfor g in top_crew_names:\n    test['crew_name_' + g] = test['crew'].apply(lambda x: 1 if g in str(x) else 0)\ntest['genders_0_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n\nfor j in top_crew_jobs:\n    test['jobs_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\nfor j in top_crew_departments:\n    test['departments_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n\ntrain = train.drop(['crew'], axis=1)\ntest = test.drop(['crew'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape,test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Data exploration**"},{"metadata":{},"cell_type":"markdown","source":"*skewness*"},{"metadata":{},"cell_type":"markdown","source":"target"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16, 6))\nplt.subplot(1, 2, 1)\nplt.hist(train['revenue']);\nplt.title('Distribution of revenue');\nplt.subplot(1, 2, 2)\nplt.hist(np.log1p(train['revenue']));\nplt.title('Distribution of log of revenue');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_revenue'] = np.log1p(train['revenue'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"budget"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(figsize = (16, 6))\nplt.subplot(1, 2, 1)\nplt.hist(train['budget']);\nplt.title('Distribution of budget');\nplt.subplot(1, 2, 2)\nplt.hist(np.log1p(train['budget']));\nplt.title('Distribution of log of budget');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_budget'] = np.log1p(train['budget'])\ntest['log_budget'] = np.log1p(test['budget'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"homepage"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['has_homepage'] = 0\ntrain.loc[train['homepage'].isnull() == False, 'has_homepage'] = 1\ntest['has_homepage'] = 0\ntest.loc[test['homepage'].isnull() == False, 'has_homepage'] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='has_homepage', y='revenue', data=train);\nplt.title('Revenue for film with and without homepage');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"original language"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(16, 8))\nplt.subplot(1, 2, 1)\nsns.boxplot(x='original_language', y='revenue', data=train.loc[train['original_language'].isin(train['original_language'].value_counts().head(10).index)]);\nplt.title('Mean revenue per language');\nplt.subplot(1, 2, 2)\nsns.boxplot(x='original_language', y='log_revenue', data=train.loc[train['original_language'].isin(train['original_language'].value_counts().head(10).index)]);\nplt.title('Mean log revenue per language');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"original_title"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 12))\ntext = ' '.join(train['original_title'].values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top words in titles')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"overview"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12, 12))\ntext = ' '.join(train['overview'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top words in overview')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(\n            sublinear_tf=True,\n            analyzer='word',\n            token_pattern=r'\\w{1,}',\n            ngram_range=(1, 2),\n            min_df=5)\n\noverview_text = vectorizer.fit_transform(train['overview'].fillna(''))\nlinreg = LinearRegression()\nlinreg.fit(overview_text, train['log_revenue'])\neli5.show_weights(linreg, vec=vectorizer, top=20, feature_filter=lambda x: x != '<BIAS>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Target value:', train['log_revenue'][1000])\neli5.show_prediction(linreg, doc=train['overview'].values[1000], vec=vectorizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"release_date"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/98'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_date(x):\n    \"\"\"\n    Fixes dates which are in 20xx\n    \"\"\"\n    year = x.split('/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating features based on dates\ndef process_date(df):\n    date_parts = [\"year\", \"weekday\", \"month\", 'weekofyear', 'day', 'quarter']\n    for part in date_parts:\n        part_col = 'release_date' + \"_\" + part\n        df[part_col] = getattr(df['release_date'].dt, part).astype(int)\n    \n    return df\n\ntrain = process_date(train)\ntest = process_date(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x='release_date_month', y='revenue', data=train);\nplt.title('Revenue on different number of week of release');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Collections"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x='has_collection', y='revenue', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.violinplot(x='genre_Drama', y='revenue', data=train[:100]);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(24, 12))\nplt.suptitle('Violinplot of revenue vs genres')\nfor i, e in enumerate([col for col in train.columns if 'genre_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Basic modelling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(['homepage', 'imdb_id', 'poster_path', 'release_date', 'status', 'log_revenue'], axis=1)\ntest = test.drop(['homepage', 'imdb_id', 'poster_path', 'release_date', 'status'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in train.columns:\n    if train[col].nunique() == 1:\n        print(col)\n        train = train.drop([col], axis=1)\n        test = test.drop([col], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['original_language', 'collection_name', 'all_genres']:\n    le = LabelEncoder()\n    le.fit(list(train[col].fillna('')) + list(test[col].fillna('')))\n    train[col] = le.transform(train[col].fillna('').astype(str))\n    test[col] = le.transform(test[col].fillna('').astype(str))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_texts = train[['title', 'tagline', 'overview', 'original_title']]\ntest_texts = test[['title', 'tagline', 'overview', 'original_title']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in ['title', 'tagline', 'overview', 'original_title']:\n    train['len_' + col] = train[col].fillna('').apply(lambda x: len(str(x)))\n    train['words_' + col] = train[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n    train = train.drop(col, axis=1)\n    test['len_' + col] = test[col].fillna('').apply(lambda x: len(str(x)))\n    test['words_' + col] = test[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n    test = test.drop(col, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# data fixes from https://www.kaggle.com/somang1418/happy-valentines-day-and-keep-kaggling-3\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'revenue'] = 6800000       # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntest.loc[test['id'] == 3889,'budget'] = 15000000       # Colossal\ntest.loc[test['id'] == 6733,'budget'] = 5000000        # The Big Sick\ntest.loc[test['id'] == 3197,'budget'] = 8000000        # High-Rise\ntest.loc[test['id'] == 6683,'budget'] = 50000000       # The Pink Panther 2\ntest.loc[test['id'] == 5704,'budget'] = 4300000        # French Connection II\ntest.loc[test['id'] == 6109,'budget'] = 281756         # Dogtooth\ntest.loc[test['id'] == 7242,'budget'] = 10000000       # Addams Family Values\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n\npower_six = train.id[train.budget > 1000][train.revenue < 100]\n\nfor k in power_six :\n    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Additional feature generation"},{"metadata":{"trusted":true},"cell_type":"code","source":"def new_features(df):\n    df['budget_to_popularity'] = df['budget'] / df['popularity']\n    df['budget_to_runtime'] = df['budget'] / df['runtime']\n    \n    # some features from https://www.kaggle.com/somang1418/happy-valentines-day-and-keep-kaggling-3\n    df['_budget_year_ratio'] = df['budget'] / (df['release_date_year'] * df['release_date_year'])\n    df['_releaseYear_popularity_ratio'] = df['release_date_year'] / df['popularity']\n    df['_releaseYear_popularity_ratio2'] = df['popularity'] / df['release_date_year']\n    \n    df['runtime_to_mean_year'] = df['runtime'] / df.groupby(\"release_date_year\")[\"runtime\"].transform('mean')\n    df['popularity_to_mean_year'] = df['popularity'] / df.groupby(\"release_date_year\")[\"popularity\"].transform('mean')\n    df['budget_to_mean_year'] = df['budget'] / df.groupby(\"release_date_year\")[\"budget\"].transform('mean')\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = new_features(test)\ntrain = new_features(train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"missing values"},{"metadata":{"trusted":true},"cell_type":"code","source":"test['runtime'] = test['runtime'].fillna((test['runtime'].mean()))\ntrain['runtime'] = train['runtime'].fillna((test['runtime'].mean()))\n\nall_data = pd.concat((train, test)).reset_index(drop=True)\n\nall_data_na = (all_data.isnull().sum() / len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_feats_test = test.dtypes[test.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats_test = test[numeric_feats_test].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness_test = pd.DataFrame({'Skew' :skewed_feats_test})\nskewness_test.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Box Cox Transformation of (highly) skewed features"},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness_test = skewness_test[abs(skewness_test) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness_test.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features_test = skewness_test.index\nlam_test = 0.15\nfor feat_test in skewed_features_test:\n    if feat_test !='revenue':\n        test[feat_test] = boxcox1p(test[feat_test], lam_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"numeric_feats_train = train.dtypes[train.dtypes != \"object\"].index\n\n# Check the skew of all numerical features\nskewed_feats_train = train[numeric_feats_train].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nprint(\"\\nSkew in numerical features: \\n\")\nskewness_train = pd.DataFrame({'Skew' :skewed_feats_train})\nskewness_train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"skewness_train = skewness_train[abs(skewness_train) > 0.75]\nprint(\"There are {} skewed numerical features to Box Cox transform\".format(skewness_train.shape[0]))\n\nfrom scipy.special import boxcox1p\nskewed_features_train = skewness_train.index\nlam_train = 0.15\nfor feat_train in skewed_features_train:\n    if feat_train !='revenue':\n        train[feat_train] = boxcox1p(train[feat_train], lam_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = train.drop(['id', 'revenue'], axis=1)\ny = np.log1p(train['revenue']) # do not forget to un-log in the end: sub['revenue'] = np.expm1(prediction_lgb)\nX_testfile = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape,train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Modelling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold, cross_val_score, train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape, y_train.shape, y_test.shape,X_testfile.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\nparams = {'num_leaves': 30,\n         'min_data_in_leaf': 20,\n         'objective': 'regression',\n         'max_depth': 5,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.2,\n         \"verbosity\": -1}\nmodel_lgb = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\nmodel_lgb.fit(X_train, y_train\n        ,eval_set=[(X_train, y_train), (X_test, y_test)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"eli5.show_weights(model_lgb, feature_filter=lambda x: x != '<BIAS>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_lgb_train=model_lgb.predict(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))\n\n#have to use np.expm1() as y was np.log1p() earlier\nprint(rmsle(y_train, prediction_lgb_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_lgb_test=model_lgb.predict(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(rmsle(y_test, prediction_lgb_test))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_lgb_testfile=model_lgb.predict(X_testfile)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\nsub['revenue'] = np.expm1(prediction_lgb_testfile)\nsub.to_csv(\"lgb.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}