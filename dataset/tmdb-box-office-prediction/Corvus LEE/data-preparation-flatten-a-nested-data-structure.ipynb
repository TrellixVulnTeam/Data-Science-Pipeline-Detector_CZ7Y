{"cells":[{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","collapsed":true,"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"markdown","source":"<p>This notebook demonstrates the thinking process of preparing a complex dateset (nested data structure) for further analysis.\n<p>Key techniques:\n    * ast.literal_eval()\n    * pd.DataFrame.from_dict()\n    * df.merge()\n    \n> \"[{'id': 313576, 'name': 'Hot Tub Time Machine Collection', 'poster_path': '/iEhb00TGPucF0b4joM1ieyY026U.jpg', 'backdrop_path': '/noeTVcgpBiD48fDjFVic1Vz7ope.jpg'}]\"\n"},{"metadata":{},"cell_type":"markdown","source":"# Data Import"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport ast","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Variables\nPATH_INPUT = \"/kaggle/input/\"\nPATH_WORKING = \"/kaggle/working/\"\nPATH_TMP = \"/tmp/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Reading data into a df\ndf_raw = pd.read_csv(f'{PATH_INPUT}train.csv', low_memory=False, skipinitialspace=True)\ndf_raw.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Take a look at the first 10 rows\ndf_raw.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preparation"},{"metadata":{},"cell_type":"markdown","source":"Some columns contain data which look like `dict`. Let's see how we can parse them"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define columns with data of dict type to process\ncols = ['belongs_to_collection', 'genres', 'production_companies', 'spoken_languages', 'Keywords', 'cast', 'crew']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the data type\ndf_raw[cols].dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Trial with the first column"},{"metadata":{},"cell_type":"markdown","source":"Looks like the columns are `string`. See how we can parse the column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# copy the column to a pandas series\ns = df_raw[cols[0]].copy()\ns.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the first record\ns[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# evaluate as a list\nl = ast.literal_eval(s[0])\nl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the data type\nprint(type(l), type(l[0]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks good. Let's try the 3rd row with NaN value"},{"metadata":{"trusted":true},"cell_type":"code","source":"s[3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"literal_eval(nan) will return an error. Replace with an empty dict in a list wrapped as str `'[{}]'`"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Let's put the steps together and parse a single column"},{"metadata":{"trusted":true},"cell_type":"code","source":"# copy one column to a pandas series\ns = df_raw[cols[0]].copy()\n# fillna with [None]\ns.fillna('[{}]', inplace=True)\n\nl = []  # init an empty list\n\nfor i in s:\n    if i == [{}]:\n        # append [{}] to the list\n        l += i\n    else:\n        # evaluate as a list\n        l += ast.literal_eval(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(l)  # should be 3000 if processed correctly","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note that `nan` are processed as empty `dict`"},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(10):\n    print(type(l[i]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks good. See how we can make a df from the list of dict"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp = pd.DataFrame.from_dict(l)\ndf_tmp[:10]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Rewrite as functions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_list_of_dict(series):\n    \"\"\"\n    Evaluate a pandas series as a list of dict\n    \n    Input:\n    \"[{'one': 1, 'two': 2, 'three': 3}]\"\n    \n    Output:\n    [{'one': 1,\n      'two': 2,\n      'three' : 3}]\n    \"\"\"\n    l = []  # init an empty list\n    s = series.fillna('[{}]')  # map nan to [{}] for further eval\n    \n    # loop through the whole series\n    for i in s:\n        if i == [{}]:\n            # append [{}] to the list\n            l += i\n        else:\n            # evaluate as a list\n            l += ast.literal_eval(i)\n    \n    return l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def column_conversion(col, df):\n    \"\"\"\n    Merge a pandas series with data like list of dict back to the dataframe\n    \n    Input:\n    \"[{'one': 1, 'two': 2, 'three': 3}]\"\n    \n    Output:\n    A dataframe with the original column removed, each dict's key in a new column\n    \"\"\"\n    l = to_list_of_dict(df[col])  # convert to list of dict\n    df_right = pd.DataFrame.from_dict(l)  # convert to df\n    df_merged = df.merge(df_right.add_prefix(col+'_'),  # add the original column name as prefix\n                         left_index=True, right_index=True)  # merge df with df_right\n    df_merged.drop(col, axis=1, inplace=True) # drop the original column\n    \n    return df_merged","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Test\ncolumn_conversion(cols[0], df_raw)[:3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Process all columns at once"},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the columns to process\ncols","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make a copy\ndf = df_raw.copy()\n\n# process the columns one by one\nfor col in cols:\n    df = column_conversion(col, df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check the first record\ndf[:1]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cool! The dataframe is now flattened for further analysis."}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}