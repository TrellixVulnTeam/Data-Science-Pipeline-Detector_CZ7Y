{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Project 2\n\n<b>From Kaggle:</b>\n<p> https://www.kaggle.com/c/tmdb-box-office-prediction </p>\n\n<b>Goal:</b> Predicting Movie revenue from given dataset"},{"metadata":{},"cell_type":"markdown","source":"### Step:\n<ol>\n    <li>Load Data</li>\n    <li>Treat missing values</li>\n    <li>Visualization</li>\n    <li>Build Model</li>\n</ol>"},{"metadata":{},"cell_type":"markdown","source":"## 1. Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/train.csv')\n\nprint(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/test.csv')\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.concat([train, test], sort=False).reset_index()\ndata = data.drop('index', axis=1)\nprint(data.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Some columns has string in dictionary format.<br>\nLet's translate string into dictionary"},{"metadata":{"trusted":false},"cell_type":"code","source":"import ast\n\ndict_columns = ['belongs_to_collection','genres','production_companies','production_countries','spoken_languages','Keywords','cast','crew']\n\ndef get_dict(item):\n    try:\n        new_item = ast.literal_eval(item)\n    except:\n        new_item = {}\n    return new_item\n\nfor col in dict_columns:\n#     train[col] = train[col].apply(lambda x: {} if pd.isnull(x) else ast.literal_eval(x))\n#     test[col] = test[col].apply(lambda x: {} if pd.isnull(x) else ast.literal_eval(x))\n#     data[col] = data[col].apply(lambda x: {} if pd.isnull(x) else ast.literal_eval(x))\n#     train[col] = train[col].apply(lambda x: get_dict(x))\n#     test[col] = test[col].apply(lambda x: get_dict(x))\n    data[col] = data[col].apply(lambda x: get_dict(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Treat missing values"},{"metadata":{"trusted":false},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\n\ntrain_null_pct = train.isnull().sum().sort_values() / len(train)\ntest_null_pct = test.isnull().sum().sort_values() / len(test)\n\nfig, ax = plt.subplots(1,2, figsize=(10,8), sharey=False)\nfig.subplots_adjust(wspace=0.8)\nax[0].barh(train_null_pct.index, train_null_pct)\nax[0].set_title('Train dataset Null')\nax[0].set_xlabel('Null proportion')\nax[1].barh(test_null_pct.index, test_null_pct)\nax[1].set_title('Test dataset Null')\nax[1].set_xlabel('Null proportion')\n\nprint(data.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<p>There are missing values in 'homepage', 'tagline', 'overview', 'poster_path', 'release_date', 'runtime', 'status', 'title'</p>\n\n#### homepage\nCreate new column 'has_homepage', and put 1 if homepage is available, else 0<br>\nAnd drop 'homepage' column "},{"metadata":{"trusted":false},"cell_type":"code","source":"data['has_homepage'] = data['homepage'].apply(lambda x: 0 if pd.isnull(x) else 1)\ndata = data.drop('homepage', axis=1)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### tagline\n\nFill empty string('') in missing values"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['tagline'] = data['tagline'].fillna('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### overview\nFill empty string('') in missing values"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['overview'] = data['overview'].fillna('')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### poster_path\nDrop 'poster_path' column. We won't analize pictures"},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop('poster_path', axis=1)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### release_date\nSince we have only 1 missing value in 'release_date' column, <br>\nWe can search on the internet"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.loc[data['release_date'].isnull(), 'title']\n## Jails, Hospitals & Hip-Hop\n# It released on May 2000\ndata.loc[data['release_date'].isnull(), 'release_date'] = '05/01/2000'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### title\nThere are only 3 missing values on 'title' column.<br>\nHowever, the 'original_title' is available, so we can search the english title on the internet"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.loc[data['title'].isnull(), ['id','original_title']]\ndata.loc[data['id']==5399, 'title'] = 'The Life of Guskou Budori'  #グスコーブドリの伝記\ndata.loc[data['id']==5426, 'title'] = ''  #La Vérité si je Mens ! 3  # couldn't find english title\ndata.loc[data['id']==6629, 'title'] = 'Barefoot'  #Barefoot","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### runtime\nFill missing value in 'runtime' column with median.<br>\nReplace runtime 0 to median"},{"metadata":{"trusted":false},"cell_type":"code","source":"data.loc[data['runtime'].isnull(), 'runtime'] = data['runtime'].median()\ndata.loc[data['runtime']==0, 'runtime'] = data['runtime'].median()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### status"},{"metadata":{"trusted":false},"cell_type":"code","source":"print(data['status'].isnull().sum())\nprint(train['status'].value_counts())\nprint(test['status'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'status' column has three different categorical value ('Released', 'Rumored', 'Post Production').<br>\nHowever, only test dataset has 'Post Production' and only few movies are in different status.<br>\nSo, it seems to be not useful. Drop the column"},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop('status', axis=1)\ndata.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 3. Visualization"},{"metadata":{},"cell_type":"markdown","source":"Since Movie data has many unique values, <br>\nit is necessary to be transformed in representative values or categorical variables"},{"metadata":{},"cell_type":"markdown","source":"#### revenue\nSince revenue has big range, it is reasonable to take log on 'revenue'"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['revenue'].min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\n\nfig, ax = plt.subplots(1,2, figsize=(10,5))\nax[0].hist(data['revenue'])\nax[0].set_title('revenue')\nax[1].hist(np.log(data['revenue']+1))\nax[1].set_title('log_revenue')\nplt.show()\n\ndata['log_revenue'] = np.log(data['revenue']+1)  # add 1 to avoid log(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### belongs_to_collection\n\nIf it belongs to the collection, put 1 else 0"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['belongs_to_collection'] = data['belongs_to_collection'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp_train = data.iloc[:3000]\nisin_collection_rev = tmp_train.loc[tmp_train['belongs_to_collection']==1, 'revenue']\nnotin_collection_rev = tmp_train.loc[tmp_train['belongs_to_collection']==0, 'revenue']\n\nisin_collection_rev_log = tmp_train.loc[tmp_train['belongs_to_collection']==1, 'log_revenue']\nnotin_collection_rev_log = tmp_train.loc[tmp_train['belongs_to_collection']==0, 'log_revenue']\n\nfig, ax = plt.subplots(1,2, figsize=(12,5))\nax[0].boxplot([isin_collection_rev_log, notin_collection_rev_log])\nax[0].set_title('log_revenue')\nax[0].set_xticklabels(['in_collection', 'not_in_collection'])\nax[1].boxplot([isin_collection_rev, notin_collection_rev])\nax[1].set_title('revenue')\nax[1].set_xticklabels(['in_collection', 'not_in_collection'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The movies which are in collection has relatively high revenue than those not in collection"},{"metadata":{},"cell_type":"markdown","source":"#### budget\n\nSome movies have '0' budget accidently.<br>\nHowever, this feature absolutely a great predictor for the revenue<br>"},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.hist(data['budget'])\nplt.xlabel('Budget')\nplt.ylabel('Counts')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"'butget' has big scale, so it is also reasonable to take log on 'budget'"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['log_budget'] = np.log(data['budget']+1)  # add 1 to avoid log(0)\nfig, ax = plt.subplots(1,2, figsize=(10,5))\nax[0].scatter(data['budget'], data['revenue'], alpha=0.1)\nax[0].set_title('budget - revenue')\nax[0].set_xlabel('budget')\nax[0].set_ylabel('revenue')\nax[1].scatter(data['log_budget'], data['log_revenue'], alpha=0.1)\nax[1].set_title('log_budget - log_revenue')\nax[1].set_xlabel('log_budget')\nax[1].set_ylabel('log_revenue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like there is some relationship between 'budget' and 'revenue'"},{"metadata":{},"cell_type":"markdown","source":"#### genres"},{"metadata":{"trusted":false},"cell_type":"code","source":"gen_cnt = data['genres'].apply(lambda x: len(x)).value_counts()\nplt.bar(gen_cnt.index, gen_cnt)\nplt.xticks(range(gen_cnt.index.max()+1))\nplt.title('Number of genres that movies in')\nplt.xlabel('Number of genres')\nplt.ylabel('Movie counts')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Most of movies are in 1~4 genres"},{"metadata":{"trusted":false},"cell_type":"code","source":"import collections\nfrom wordcloud import WordCloud\n\ntotal_gen_list = []\n\ndef gen_list(x):\n    for i in x:\n        total_gen_list.append(i['name'])\n\n        \nfig, ax = plt.subplots(1,2, figsize=(20,7))\ndata['genres'].apply(lambda x: gen_list(x))\ngen_cnt = collections.Counter(total_gen_list).most_common()\nfor gen, cnt in gen_cnt[::-1]:\n    ax[0].barh(gen,cnt)\nax[0].set_title('Genre Frequencies')\n\nwordcloud = WordCloud(background_color='white', width=800, height=500).generate_from_frequencies(dict(gen_cnt))\nax[1].axis('off')\nax[1].imshow(wordcloud, interpolation = 'bilinear')\nax[1].set_title('Genre majorities')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"There are total 20 different genres for these movies.<br>\nMake dummy variables for each genres"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['genres_list'] = data['genres'].apply(lambda x: [i['name'] for i in x])\n\nfor gen in dict(gen_cnt).keys():\n    data['genre_'+gen] = data['genres_list'].apply(lambda x: 1 if gen in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp_train = data[:3000]\nplt.figure(figsize=(6,6))\nfor idx, gen in enumerate(dict(gen_cnt).keys()):\n    plt.boxplot(tmp_train.loc[tmp_train['genre_'+gen]==1,'log_revenue'], labels=[gen], positions=range(idx, idx+1), vert=False)\nplt.xlabel('log_revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop(['genres', 'genres_list'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### imdb_id\nThis is unique id.<br>\nDrop the column"},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop('imdb_id', axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### release_date\n'release_date' column has 'mm/dd/yy' data<br>"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['year'] = data['release_date'].str.split('/').apply(lambda x: 2000+int(x[2]) if int(x[2]) < 19 else 1900+int(x[2]))\ndata.loc[data['year']==3900,'year'] = 2000   ## there is a typo in dataset\ndata['month'] = data['release_date'].str.split('/').apply(lambda x: int(x[0]))\ndata = data.drop('release_date', axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(2,2, figsize=(13,10))\nax[0,0].scatter(data['year'], data['revenue'], alpha=0.3, s=20)\nax[0,0].set_title('year - revenue')\nax[0,0].set_xlabel('year')\nax[0,0].set_ylabel('revenue')\nax[0,1].scatter(data['year'], data['log_revenue'], alpha=0.3, s=20)\nax[0,1].set_xlabel('year')\nax[0,1].set_ylabel('log_revenue')\nax[0,1].set_title('year - log_revenue')\nax[1,0].scatter(data['month'], data['revenue'], alpha=0.3, s=20)\nax[1,0].set_xlabel('month')\nax[1,0].set_ylabel('revenue')\nax[1,0].set_title('month - revenue')\nax[1,1].scatter(data['month'], data['log_revenue'], alpha=0.3, s=20)\nax[1,1].set_title('month - log_revenue')\nax[1,1].set_xlabel('month')\nax[1,1].set_ylabel('log_revenue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"It looks like there is some relationship between year & revenue<br><br>\nRevenue seems to have some pattern along to the month<br>\nMake dummy variables for month"},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.get_dummies(data, columns=['month'], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### crew\nPeople tend to have high expectation if the director and writer of a movie are popular or well known.<br>\nHowever, the directors and writers are too sparse in our dataset. <br>\nIt is hard to use it as predictor. We dropped the column."},{"metadata":{"trusted":false},"cell_type":"code","source":"def find_director(x):\n    director=''\n    for i,v in enumerate(x):\n        if v['job']=='Director':\n            director = v['name']\n    return director\n\ndef find_writer(x):\n    writer=''\n    for i,v in enumerate(x):\n        if v['job'] == 'Writer':\n            writer = v['name']\n    return writer\n\ndata['director'] = data['crew'].apply(lambda x: find_director(x))\ndata['writer'] = data['crew'].apply(lambda x: find_writer(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"collections.Counter(data['director']).most_common(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"collections.Counter(data['writer']).most_common(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop(['director', 'writer', 'crew'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### cast\nTop actors can affact the revenue.<br>\nSelect Top 100 actors and create dummy variables.<br>\nThe number of cast may affect the revenue."},{"metadata":{"trusted":false},"cell_type":"code","source":"data['cast_list'] = data['cast'].apply(lambda x: [i['name'] for i in x])\ndata['n_cast'] = data['cast'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"total_cast_list = []\ndef get_cast_list(x):\n    total_cast_list.extend(x)\n\ndata['cast_list'].apply(lambda x: get_cast_list(x))\ntop_cast = list(dict(collections.Counter(total_cast_list).most_common(100)).keys())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"collections.Counter(total_cast_list).most_common(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for cast in top_cast:\n    data['cast_'+cast] = data['cast_list'].apply(lambda x: 1 if cast in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp_train = data[:3000]\nfor idx, cast in enumerate(top_cast[:23][::-1]):\n    cast_rev = tmp_train.loc[tmp_train['cast_'+cast]==1, 'log_revenue']\n    plt.boxplot(cast_rev, positions=range(idx, idx+1), labels=[cast], vert=False)\nplt.xlabel('log_revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop(['cast', 'cast_list'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### original_language & spoken_languages\nThe language is important for targeting the market.<br><br>\nWith original_language, create dummy variables,<br>\nwith spoken_languages, create the number of spoken languages which can be indicator of market expansion"},{"metadata":{"trusted":false},"cell_type":"code","source":"# choose language which \ntop_langs = dict(data['original_language'].value_counts()[:17]).keys()\n\nfor lang in top_langs:\n    data['lang_'+lang] = data['original_language'].apply(lambda x: 1 if lang == x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['n_spoken_languages'] = data['spoken_languages'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"for lang in list(top_langs)[::-1]:\n    plt.barh(lang, data.loc[data['lang_'+lang]==1, 'log_revenue'])\nplt.xlabel('log_revenue')\nplt.title('original_language')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.scatter(data['n_spoken_languages'], data['log_revenue'], alpha=.3)\nplt.xlabel('n_spoken_languages')\nplt.ylabel('log_revenue')\nplt.title('spoken_languages')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop(['original_language','spoken_languages','n_spoken_languages'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### title, tagline, Keywords, overview\nCombine all string information and create clusters for dividing topics."},{"metadata":{"trusted":false},"cell_type":"code","source":"data['keyword_str'] = data['Keywords'].apply(lambda x: ', '.join([i['name'] for i in x]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['text'] = data['title'] + '. '+ data['tagline'] + '. ' + data['overview'] + '. ' + data['keyword_str']","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.decomposition import LatentDirichletAllocation\n\nvect = CountVectorizer(ngram_range=(1,3), stop_words='english')\nX = vect.fit_transform(data['text'])\nlda = LatentDirichletAllocation(n_components=10, random_state = 0)\ndocument_topics = lda.fit_transform(X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"n = 8\n# Get features (tokens) from CountVectorizer\nfeature_names = np.array(vect.get_feature_names())\n# Find top n tokens\ntopics = dict()\nfor idx, component in enumerate(lda.components_): \n    top_n_indices = component.argsort()[:-(n + 1): -1] \n    topic_tokens = [feature_names[i] for i in top_n_indices] \n    topics[idx] = topic_tokens\n\ntopics","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(5,5))\nfor k, v in collections.Counter(document_topics.argmax(axis=1)).items():\n    plt.bar(k,v)\nplt.xlabel('Topic clusters')\nplt.ylabel('Number of movies')\nplt.title('Topic frequencies')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data['topics'] = document_topics.argmax(axis=1)\ntmp_train = data[:3000]\nplt.figure(figsize=(5,5))\nfor idx in range(10):\n    plt.boxplot(tmp_train.loc[tmp_train['topics']==idx, 'log_revenue'],positions=range(idx, idx+1), labels=[idx])\nplt.xlabel('topics')\nplt.ylabel('log_revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = pd.get_dummies(data, columns=['topics'], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop(['original_title','overview','tagline','title','Keywords', 'keyword_str','text'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### production_companies, production_countries\nExpecting more countries and companies participated in filmmaking, more revenue will be collected.<br><br>\nSome companies are garanteed to make high quality movies.<br>\nCreate dummy variables for the top companies."},{"metadata":{"trusted":false},"cell_type":"code","source":"data['n_production_countries'] = data['production_countries'].apply(lambda x: len(x))\ndata['n_production_companies'] = data['production_companies'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"company_list = []\ndef get_company_list(x):\n    for i in x:\n        company_list.append(i['name'])\ndata['production_companies'].apply(lambda x: get_company_list(x))\nfor company in dict(collections.Counter(company_list).most_common(30)).keys():\n    data['production_'+company] = data['production_companies'].apply(lambda x: 1 if company in [i['name'] for i in x] else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data.drop(['production_companies', 'production_countries'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"fig, ax = plt.subplots(1,2, figsize=(12,5))\nax[0].scatter(data['n_production_countries'], data['log_revenue'], alpha=0.1)\nax[0].set_xlabel('n_production_countries')\nax[0].set_ylabel('log_revenue')\nax[1].scatter(data['n_production_companies'], data['log_revenue'], alpha=0.1)\nax[1].set_xlabel('n_production_companies')\nax[1].set_ylabel('log_revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp_train = data[:3000]\nplt.figure(figsize=(10,10))\nfor idx, company in enumerate(dict(collections.Counter(company_list).most_common(30)).keys()):\n    com_rev = tmp_train.loc[tmp_train['production_'+company]==1, 'log_revenue']\n    plt.boxplot(com_rev, positions=range(idx, idx+1), labels = [company], vert=False)\nplt.xlabel('log_revenue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### runtime\nThere would be the most favorable runtime.<br><br>\nCutting the runtime in percentile.<br>"},{"metadata":{"trusted":false},"cell_type":"code","source":"data['runtime_cat'] = pd.qcut(data['runtime'],10, labels=False)","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"plt.scatter(data['runtime_cat'], data['log_revenue'], alpha=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"tmp_train = data[:3000]\nfor i in range(10):\n    plt.boxplot(tmp_train.loc[data['runtime_cat']==i,'log_revenue'], positions=range(i, i+1))\nplt.xlabel('runtime categories')\nplt.ylabel('log_revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"data = data = pd.get_dummies(data, columns=['runtime_cat'], drop_first=True)\ndata = data.drop(['runtime'],axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 4. Model Building\nModels:\n<ul>\n    <li>Multiple Regression</li>\n    <li>SVM - SVR</li>\n    <li>Random Forest Regression</li>\n    <li>NN - MLPRegressor</li>\n    <li>SGD Regressor</li>\n</ul>"},{"metadata":{"trusted":false},"cell_type":"code","source":"def rmse_score(y1, y2):\n    return np.sqrt(np.power(y1-y2,2).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"X = data[:3000].drop(['id','revenue','log_revenue', 'budget'],axis=1)\ny = data[:3000]['log_revenue']\n\nsub_X = data[3000:].drop(['id','revenue','log_revenue','budget'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, cross_val_score\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Linear Regression"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nLR_model = LinearRegression()\nLR_model.fit(X_train,y_train)\ny_hat = LR_model.predict(X_test)\nprint(rmse_score(y_hat, y_test))\nsub_y = LR_model.predict(sub_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub_csv = pd.DataFrame({'id':data[3000:]['id'], 'revenue': np.exp(sub_y)})\nsub_csv.to_csv('LR_predict.csv', index=False)\n\n## 2.40021","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### SVR"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.svm import SVR\n\nSVR_model = SVR(C = 5)\nSVR_model.fit(X_train, y_train)\n\ny_hat = SVR_model.predict(X_test)\nprint(rmse_score(y_hat, y_test))\nsub_y = SVR_model.predict(sub_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub_csv = pd.DataFrame({'id':data[3000:]['id'], 'revenue': np.exp(sub_y)})\nsub_csv.to_csv('SVR_predict.csv', index=False)\n\n## 2.27148   # c=1.0\n## 2.21529   # c=5\n## 2.21807   # c=10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### RandomForest Regressor"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nRF_model = RandomForestRegressor(random_state =0, n_estimators=500, max_depth=10)\nRF_model.fit(X_train, y_train)\n\ny_hat = RF_model.predict(X_test)\nprint(rmse_score(y_hat, y_test))\nsub_y = RF_model.predict(sub_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub_csv = pd.DataFrame({'id':data[3000:]['id'], 'revenue': np.exp(sub_y)})\nsub_csv.to_csv('RF_predict.csv', index=False)\n\n## 2.20717   #n_esimators=200, max_depth=8\n## 2.20054   #n_estimators=500, max_depth=10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### MLP Regressor"},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.neural_network import MLPRegressor\nMLP_model = MLPRegressor(random_state = 0, hidden_layer_sizes=(50,50))\nMLP_model.fit(X_train, y_train)\n\ny_hat = MLP_model.predict(X_test)\nprint(rmse_score(y_hat, y_test))\nsub_y = MLP_model.predict(sub_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sub_csv = pd.DataFrame({'id':data[3000:]['id'], 'revenue': np.exp(sub_y)})\nsub_csv.to_csv('MLP_predict.csv', index=False)\n\n## 2.29088   hidden=(30,500)\n## 2.40497   hidden=(100,)\n## 2.26413   hidden=(200,30)\n## 2.31559   hidden=(50,50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}