{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# <br><center>**TMDB Box Office Prediction**</center></br>\n\nEl presente documento muestra el procedimiento utilizado para predecir el recaudo que tendrá una pelicula, identificando aquellas variables que pueden ser relevantes para la predicción. Este modelo se construye a partir de una metadata de más de 7.000 títulos, donde se proporcionan datos como elenco, palabras clave de la trama, presupuesto, carteles, fechas de lanzamiento, idiomas, compañías de producción y países. Adicionalmente se tomara información de rotten tomatoes, buscando tener un mayor alcance en la predicción.\n\n![](https://images.news18.com/optimize/oUhEuCS2t4VGvzjhVq8c93o7c1U=/532x353/images.news18.com/ibnlive/uploads/532x353/jpg/2019/07/Avengers_Endgame-Boxoffice.jpg)\n*(Screenshot tomado de https://www.news18.com/news/movies/marvels-avengers-endgame-dethrones-james-cameron-avatar-as-highest-grossing-film-in-history-2239389.html)*"},{"metadata":{},"cell_type":"markdown","source":"El procedimiento a utilizar se mustra en la siguiente gráfica:"},{"metadata":{"trusted":true},"cell_type":"code","source":"from PIL import Image\nimport pandas as pd\nim_frame = Image.open('../input/process-pred/Proceso_pred.png')\nim_frame = im_frame.resize((700,650))\ndisplay(im_frame)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Content\n\n* [1 Visión general de la información](#cargar_datos)\n* [1.1 Columnas diccionario](#col_dict)\n* [1.1.1 Información top](#top_inf)\n* [1.1.2 Ajuste columnas diccionario](#ajuste_dic)\n* [2 Data exploration](#de)\n* [2.1 Variables numericas](#va)\n* [2.2 Variables categocas](#vc)\n* [2.3 Variables con text](#vt)\n* [3 Generación de modelos](#model)\n* [3.1 Definición de train y test](#def_train_test)\n* [3.2 Configuración de hiperparametos](#hiper)\n* [3.3 Fitting Model](#fittin)"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split, KFold\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\nimport os\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nimport json\nimport ast\nimport eli5\nimport shap\nfrom catboost import CatBoostRegressor\nfrom urllib.request import urlopen\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\nfrom shutil import copyfile\ncopyfile(src = \"../input/funcdefd/Funciones.py\", dst = \"../working/Funciones.py\")\nfrom Funciones import *","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2f2d5bc8da572783121324a1544483cc1dcaaa4d"},"cell_type":"markdown","source":"<a id=\"cargar_datos\"></a>\n## Visión General de la información"},{"metadata":{"trusted":true,"_uuid":"52ed3da69987f737ae87ffb99496ebc28a1203e6","_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Se hace identifican 7 columnas donde la información es un diccionario de datos. \n## Se transforman estas columnas en el formato apropiado. Para esto nos basamos en el siguiente kernel:\n## https://www.kaggle.com/gravix/gradient-in-a-box\n## La libreria ast permite identificar el tipo de dato, basados en una iteración sobre cada componente del diccionario\n## guardado en cada columna.\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\n        \ntrain = text_to_dict(train,dict_columns)\ntest = text_to_dict(test,dict_columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1b26b787554be942b36bb05b2d411f115e71e47d"},"cell_type":"code","source":"# Inspeccionando el tamaño de nuestros datos\ntrain.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Efectivamente hay aproximadamente 7000 titulos. 3000 para definir nuestro modelo.  \nPara las columnas que son diccionarios de datos vamos a estraer la información.  \n<a id=\"col_dict\"></a>\n### Columnas diccionario\n"},{"metadata":{"trusted":true,"_uuid":"bd4d7985ce8d835f4257efd7892dc96eeb665f5b"},"cell_type":"code","source":"## Inspección visual de la información. \nfor a in dict_columns:\n    print(a)\n    for i, e in enumerate(train[a][:1]):\n        print(i, e)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a in dict_columns:\n    inf=pd.DataFrame(train[a].apply(lambda x: len(x) if x != {} else 0).value_counts())\n    print('Porcentaje registros sin infromación: ',(inf[inf.index==0].iloc[0,:]/len(train))*100)\nprint('Total registros: ',len(train))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"De la inspección anterior se observa:\n\n1. Completitud de las columnas:\n\n    Porcentaje registros sin infromación:  belongs_to_collection    79.866667%  \n    Porcentaje registros sin infromación:  genres    0.233333%  \n    Porcentaje registros sin infromación:  production_companies    5.2%  \n    Porcentaje registros sin infromación:  production_countries    1.833333%  \n    Porcentaje registros sin infromación:  spoken_languages    0.666667%  \n    Porcentaje registros sin infromación:  Keywords    9.2%  \n    Porcentaje registros sin infromación:  cast    0.866667%  \n    Porcentaje registros sin infromación:  crew    0.533333%  \n    Total registros:  3000  \n\n2. Campos con información que podría ser útil:\n\n    belongs_to_collection: name.  \n    genres: name  \n    production_companies: name  \n    production_countries: name  \n    spoken_languages: name  \n    Keywords: name  \n    cast: character,name,gender (0 is unspecified, 1 is female, and 2 is male. (https://www.kaggle.com/c/tmdb-box-office-prediction/discussion/80983#475572)  \n    crew: department, job,name, gender"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"top_inf\"></a>\n### Información top\n#### Top de generos de peliculas, compañias de producción, lenguajes, casting y personal que trabaja en la producción"},{"metadata":{"trusted":true},"cell_type":"code","source":"lista=['genres','production_companies','production_countries','spoken_languages','cast','crew']\nfor i in lista:\n    list_ = list(train[i].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n    list_ = [i for i in list_ if i]\n    \n    df=pd.DataFrame(list_)\n    df=df[0].str.replace(' ', '_')\n    list_=list([df])\n    plt.figure(figsize = (12, 8))\n    text = ' '.join([i for j in list_ for i in j])\n    \n    wordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                          width=1200, height=1000).generate(text)\n    plt.imshow(wordcloud)\n    plt.title('Top '+i)\n    plt.axis(\"off\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Palabras mas comunes\nlist_ = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nlist_ = [i for i in list_ if i]\nplt.figure(figsize = (12, 8))\ntext = ' '.join([i for j in list_ for i in j])\n\nwordcloud = WordCloud(max_font_size=None, background_color='white', collocations=False,\n                      width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top keywords')\nplt.axis(\"off\")\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_genders = list(train['cast'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_genders for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_genders = list(train['crew'].apply(lambda x: [i['gender'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_genders for i in j]).most_common()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_characters = list(train['cast'].apply(lambda x: [i['character'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_characters for i in j]).most_common(15)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_jobs = list(train['crew'].apply(lambda x: [i['job'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_jobs for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_crew_departments = list(train['crew'].apply(lambda x: [i['department'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_departments for i in j]).most_common(14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_genres = list(train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_crew_departments for i in j]).most_common(14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_cast_names = list(train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_cast_names for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_languages = list(train['spoken_languages'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_languages for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_keywords = list(train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_keywords for i in j]).most_common(15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_companies = list(train['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\nCounter([i for j in list_of_companies for i in j]).most_common(30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"ajuste_dic\"></a>\n### Ajuste de las columnas diccionario.  \n#### Se toma la información relevante de cada columna del diccionario:"},{"metadata":{"trusted":true,"_uuid":"c30883d68576ee2b482da68b2068857d133abf69"},"cell_type":"code","source":"# Diccionario de columnas donde el valor relevante es la columna name:\ndict_columns_com = ['belongs_to_collection','genres','production_companies','production_countries','spoken_languages','Keywords','cast','crew']\n\nfor i in dict_columns_com:\n    train['num_'+i] = train[i].apply(lambda x: len(x) if x != {} else 0)\n    train['all_'+i] = train[i].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n    test['num_'+i] = test[i].apply(lambda x: len(x) if x != {} else 0)\n    test['all_'+i] = test[i].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n    train['all_'+i]=train['all_'+i].str.replace(' ', '_')\n    test['all_'+i]=test['all_'+i].str.replace(' ', '_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Columnas con información especial\ntrain['num_cast'] = train['cast'].apply(lambda x: len(x) if x != {} else 0)\ntrain['genders_0_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_cast'] = train['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n\ntest['num_cast'] = test['cast'].apply(lambda x: len(x) if x != {} else 0)\ntest['genders_0_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_cast'] = test['cast'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n\ntrain['num_crew'] = train['crew'].apply(lambda x: len(x) if x != {} else 0)\ntrain['genders_0_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntrain['genders_1_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntrain['genders_2_crew'] = train['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\ntest['num_crew'] = test['crew'].apply(lambda x: len(x) if x != {} else 0)\ntest['genders_0_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 0]))\ntest['genders_1_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 1]))\ntest['genders_2_crew'] = test['crew'].apply(lambda x: sum([1 for i in x if i['gender'] == 2]))\n\ntrain['num_crew_dep'] = train[i].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_crew_dep'] = train[i].apply(lambda x: ' '.join(sorted([i['department'] for i in x])) if x != {} else '')\ntest['num_crew_dep'] = test[i].apply(lambda x: len(x) if x != {} else 0)\ntest['all_crew_dep'] = test[i].apply(lambda x: ' '.join(sorted([i['department'] for i in x])) if x != {} else '')\ntrain['num_crew_job'] = train[i].apply(lambda x: len(x) if x != {} else 0)\ntrain['all_crew_job'] = train[i].apply(lambda x: ' '.join(sorted([i['job'] for i in x])) if x != {} else '')\ntest['num_crew_job'] = test[i].apply(lambda x: len(x) if x != {} else 0)\ntest['all_crew_job'] = test[i].apply(lambda x: ' '.join(sorted([i['job'] for i in x])) if x != {} else '')\n\ntrain['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ntrain['has_collection'] = train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n\ntest['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ntest['has_collection'] = test['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Se crean una columnas con lo mas destacado de cada diccionario."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in dict_columns_com:\n    list_ = list(train[i].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n    top_ = [m[0] for m in Counter([i for j in list_ for i in j]).most_common(20)]\n    for g in top_:\n        train[i+'_' + g] = train['all_'+i].apply(lambda x: 1 if g in x else 0)\n\n    for g in top_:\n        test[i+'_' + g] = test['all_'+i].apply(lambda x: 1 if g in x else 0)\n\ntop_genres = [m[0] for m in Counter([i for j in list_of_genres for i in j]).most_common(15)]\nfor g in top_genres:\n    train['genre_' + g] = train['all_genres'].apply(lambda x: 1 if g in x else 0)\ntop_cast_names = [m[0] for m in Counter([i for j in list_of_cast_names for i in j]).most_common(15)]\nfor g in top_cast_names:\n    train['cast_name_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\ntop_cast_characters = [m[0] for m in Counter([i for j in list_of_cast_characters for i in j]).most_common(15)]\nfor g in top_cast_characters:\n    train['cast_character_' + g] = train['cast'].apply(lambda x: 1 if g in str(x) else 0)\n\nfor g in top_genres:\n    test['genre_' + g] = test['all_genres'].apply(lambda x: 1 if g in x else 0)\nfor g in top_cast_names:\n    test['cast_name_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\nfor g in top_cast_characters:\n    test['cast_character_' + g] = test['cast'].apply(lambda x: 1 if g in str(x) else 0)\n\ntop_crew_jobs = [m[0] for m in Counter([i for j in list_of_crew_jobs for i in j]).most_common(15)]\nfor j in top_crew_jobs:\n    train['jobs_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\ntop_crew_departments = [m[0] for m in Counter([i for j in list_of_crew_departments for i in j]).most_common(15)]\nfor j in top_crew_departments:\n    train['departments_' + j] = train['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n\nfor j in top_crew_jobs:\n    test['jobs_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['job'] == j]))\n\nfor j in top_crew_departments:\n    test['departments_' + j] = test['crew'].apply(lambda x: sum([1 for i in x if i['department'] == j])) \n    \ntop_companies = [m[0] for m in Counter([i for j in list_of_companies for i in j]).most_common(30)]\nfor g in top_companies:\n    train['production_company_' + g] = train['all_production_companies'].apply(lambda x: 1 if g in x else 0)\nfor g in top_companies:\n    test['production_company_' + g] = train['all_production_companies'].apply(lambda x: 1 if g in x else 0)\n    \ntop_languages = [m[0] for m in Counter([i for j in list_of_languages for i in j]).most_common(30)]\nfor g in top_languages:\n    train['language_' + g] = train['all_spoken_languages'].apply(lambda x: 1 if g in x else 0)\nfor g in top_languages:\n    test['language_' + g] = test['all_spoken_languages'].apply(lambda x: 1 if g in x else 0)\n\ntop_keywords = [m[0] for m in Counter([i for j in list_of_keywords for i in j]).most_common(30)]\nfor g in top_keywords:\n    train['keyword_' + g] = train['all_Keywords'].apply(lambda x: 1 if g in x else 0)\nfor g in top_keywords:\n    test['keyword_' + g] = test['all_Keywords'].apply(lambda x: 1 if g in x else 0)\n\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in dict_columns_com:\n    train = train.drop([i], axis=1)\n    test = test.drop([i], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"64eb5d6d8c7d40e836288e80a3f768e3035dcf49"},"cell_type":"markdown","source":"<a id=\"de\"></a>\n## Data exploration"},{"metadata":{"trusted":true,"_uuid":"cff4344b90fb2bac25e55cc14172b30d05d7b288"},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"va\"></a>\n## Variables numericas"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Función objetivo\nfig, ax = plt.subplots(figsize = (16, 6))\nplt.subplot(1, 1, 1)\nplt.hist(train['revenue']);\nplt.title('Distribución de los ingresos');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import scipy.stats as ss\nfrom scipy import stats\ndist_continu = [d for d in dir(stats) if isinstance(getattr(stats, d), stats.rv_continuous)]\ncount, bins, ignored = plt.hist(train[\"revenue\"], 100, density=True, align='mid')\nparams = stats.lognorm.fit(count)\nd, pvalor = stats.kstest(count,\"lognorm\",params)\n\nif pvalor < 0.05:\n    print(\"No se ajusta a una lognorm\")\nelse:\n    print(\"Se puede ajustar a una lognorm\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"evalua_dist(train['revenue'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"La función objetivo se ajusta a una distribución Beta."},{"metadata":{},"cell_type":"markdown","source":"## Se realiza un comparativo entre todas las variables numéricas, teniendo encuenta su distribución de probabilidad"},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sb\nnumericos = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\ndatos_num = train.select_dtypes(include=numericos)\ndatos_num.drop(columns=['id'],inplace=True)\ndatos_num.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.pairplot(datos_num[[\n'revenue',\n'budget',\n'popularity',\n'runtime',\n'num_genres',\n'num_production_companies',\n'num_production_countries',\n'num_spoken_languages',\n'num_Keywords',\n'num_cast',\n'num_crew']])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Al parecer cuando el lanzamiento de la pelicula es un miercoles, jueves o viernes, es probable que haya mejores ingresos."},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in datos_num[[\n'revenue',\n'budget',\n'popularity',\n\n'num_genres',\n'num_production_companies',\n'num_production_countries',\n'num_spoken_languages',\n'num_Keywords',\n'num_cast',\n'num_crew']]:\n    print('Distribución '+i)\n    evalua_dist(train[i])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Generamos algunas gráficas para ver el impacto de variables numéricas sobre el ingreso de las peliculas"},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\ncolor=[]\ningresos=[]\nfor i in range(1,len(train)):\n    prue=\"rgba(\"+str(random.randint(0,255))+\",\"+str(random.randint(0,255))+\",\"+str(random.randint(0,255))+\",0.5)\"\n    color.append(prue)\n    \nfor i in train.revenue.iteritems():\n    ingresos.append(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\ntrace = go.Scatter(\n                    x = train['popularity'],\n                    y = train['budget'],\n                    mode = \"markers\",\n                    marker = dict(color = color,size = (train['revenue']*100)/train['revenue'].max()),\n                    text= train.title+' '+train.release_date\n)\ndata = [trace]\nlayout = dict(title = 'Influencia del Presupuesto y Popularidad en los ingresos',\n              xaxis= dict(title= 'Popularidad',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Presupuesto',ticklen= 5,zeroline= False)\n             )             \nfig = dict(data = data, layout = layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Scatter(\n                    x = train['runtime'],\n                    y = train['budget'],\n                    mode = \"markers\",\n                    marker = dict(color = color,size = (train['revenue']*100)/train['revenue'].max()),\n                    text= train.title+' '+train.release_date\n)\ndata = [trace]\nlayout = dict(title = 'Influencia del Presupuesto y Duracion en los ingresos',\n              xaxis= dict(title= 'Duración',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Presupuesto',ticklen= 5,zeroline= False)\n             )             \nfig = dict(data = data, layout = layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trace = go.Scatter(\n                    x = train['popularity'],\n                    y = train['num_cast'],\n                    mode = \"markers\",\n                    marker = dict(color = color,size = (train['revenue']*100)/train['revenue'].max()),\n                    text= train.title+' '+train.release_date\n)\ndata = [trace]\nlayout = dict(title = 'Influencia del Presupuesto y Duracion en los ingresos',\n              xaxis= dict(title= 'Popularidad',ticklen= 5,zeroline= False),\n              yaxis= dict(title= 'Numero de actrores',ticklen= 5,zeroline= False)\n             )             \nfig = dict(data = data, layout = layout)\niplot(fig)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"datos=train.sort_values(by=['revenue'], ascending=False)\ndatos=datos.iloc[:,0:20]\ntrace1 = go.Bar(\n    y=datos.title,\n    x=datos.budget,\n    name='Presupuesto',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(255, 107, 51, 0.5)',\n        line = dict(\n            color = 'rgba(255, 107, 51, 1.0)',\n            width = 3)\n    )\n)\ntrace2 = go.Bar(\n    y=datos.title,\n    x=datos.revenue-datos.budget,\n    name='Ganancias',\n    orientation = 'h',\n    marker = dict(\n        color = 'rgba(51, 153, 255, 0.5)',\n        line = dict(\n            color = 'rgba(51, 153, 255, 1.0)',\n            width = 3)\n    )\n)\n\ndata = [trace1, trace2]\nlayout = go.Layout(title = 'Relación presupuesto ganancias',\n    barmode='stack'\n)\n\nfig = go.Figure(data=data, layout=layout)\niplot(fig)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"vc\"></a>\n## Variables categóricas"},{"metadata":{},"cell_type":"markdown","source":"### Titulo"},{"metadata":{"trusted":true},"cell_type":"code","source":"#Palabras comunes en los titulos\nplt.figure(figsize = (12, 12))\ntext = ' '.join(train['original_title'].values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top de palabras en los títulos')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"dc372a3bbc52ab93648f9223b6fae0dbc178c565"},"cell_type":"markdown","source":"### Reseña"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"72cdad64f13403a6526c781b32fa968872691c11"},"cell_type":"code","source":"# Palabras que sobre salen en las reseñas\nplt.figure(figsize = (12, 12))\ntext = ' '.join(train['overview'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top de palabas en las reseñas')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fecha de Lanzamiento"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/98'\ntrain['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\ntrain['release_date'] = pd.to_datetime(train['release_date'])\ntest['release_date'] = pd.to_datetime(test['release_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creando variables basados en fechas\ntrain = process_date(train)\ntest = process_date(test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Influencia de las fechas en los ingresos"},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = train['release_date_year'].value_counts().sort_index()\nd2 = test['release_date_year'].value_counts().sort_index()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='train'), go.Scatter(x=d2.index, y=d2.values, name='test')]\nlayout = go.Layout(dict(title = \"Peliculas por año\",\n                  xaxis = dict(title = 'Year'),\n                  yaxis = dict(title = 'Count'),\n                  ),legend=dict(\n                orientation=\"v\"))\niplot(dict(data=data, layout=layout))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = train['release_date_year'].value_counts().sort_index()\nd2 = train.groupby(['release_date_year'])['revenue'].sum()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='film count'), go.Scatter(x=d2.index, y=d2.values, name='total Ingresos', yaxis='y2')]\nlayout = go.Layout(dict(title = \"Numero de peliculas por año y total de ingresos por año\",\n                  xaxis = dict(title = 'Año'),\n                  yaxis = dict(title = 'Cantidad'),\n                  yaxis2=dict(title='Total ingresos', overlaying='y', side='right')\n                  ),legend=dict(\n                orientation=\"v\"))\niplot(dict(data=data, layout=layout))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d1 = train['release_date_year'].value_counts().sort_index()\nd2 = train.groupby(['release_date_year'])['revenue'].mean()\ndata = [go.Scatter(x=d1.index, y=d1.values, name='film count'), go.Scatter(x=d2.index, y=d2.values, name='Ingresos promedio', yaxis='y2')]\nlayout = go.Layout(dict(title = \"Numero de peliculas e ingreso promedio por año\",\n                  xaxis = dict(title = 'Año'),\n                  yaxis = dict(title = 'Cantiad'),\n                  yaxis2=dict(title='Ingreso promedio', overlaying='y', side='right')\n                  ),legend=dict(\n                orientation=\"v\"))\niplot(dict(data=data, layout=layout))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Las dos gráficas muestran un incremento en la industria cinematrográfica,aunque con unos años mejores que otros."},{"metadata":{"trusted":true},"cell_type":"code","source":"train['log_revenue'] = np.log1p(train['revenue'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e22f1900d813f4682f8e54df8d90c24997d4acff"},"cell_type":"markdown","source":"### Reseña corta"},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"e40a80c45be1d769a6d863fbe74b1c19b4a6ac2c"},"cell_type":"code","source":"plt.figure(figsize = (12, 12))\ntext = ' '.join(train['tagline'].fillna('').values)\nwordcloud = WordCloud(max_font_size=None, background_color='white', width=1200, height=1000).generate(text)\nplt.imshow(wordcloud)\nplt.title('Top de palabras tagline')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0cccf2021f08cd988fc45d6f1c7e6d74527d7b16"},"cell_type":"markdown","source":"## Miraremos si hay alguna relación entre algunas variables y los ingresos"},{"metadata":{"_uuid":"c6c8dbb4e924247f1df9e25c938278584f078507"},"cell_type":"markdown","source":"### Genero de la película - Ingresos"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"b3f63777808be2f4bf85dea68dd8b0f8f332a680"},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(24, 12))\nplt.suptitle('Ingresos vs Genero')\nfor i, e in enumerate([col for col in train.columns if 'genre_' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"9565a25d5842131215edce5833b68d752c89e251"},"cell_type":"markdown","source":"Las gráficas muestran que los ingresos pueden variar de acuerdo al genero de la pelicula."},{"metadata":{"_uuid":"92ebe983c07c8bd4627912b040cf611088ce9d16"},"cell_type":"markdown","source":"### Compañia que produce vs Ingresos"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"7baa1946748738be98ae56ee5fabe4c400ace547"},"cell_type":"code","source":"f, axes = plt.subplots(6, 5, figsize=(24, 32))\nplt.suptitle('Compañia de producción vs Ingresos')\nfor i, e in enumerate([col for col in train.columns if 'production_company' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f5896b7ff192a4f36146f7480e7b867863ebfff5"},"cell_type":"markdown","source":"### Reparto vs Ingresos"},{"metadata":{"trusted":true,"scrolled":false,"_uuid":"d2507d0f239b00f2e50d629436561984d94a5752"},"cell_type":"code","source":"f, axes = plt.subplots(3, 5, figsize=(24, 18))\nplt.suptitle('Reparto vs Ingresos')\nfor i, e in enumerate([col for col in train.columns if 'cast_name' in col]):\n    sns.violinplot(x=e, y='revenue', data=train, ax=axes[i // 5][i % 5]);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"vt\"></a>\n## Variables con text"},{"metadata":{},"cell_type":"markdown","source":"Es conveniente hacer un análisis sobre si la reseña tiene algún impacto sobre ingresos futuros. "},{"metadata":{"trusted":true},"cell_type":"code","source":"vectorizer = TfidfVectorizer(\n            sublinear_tf=True,\n            analyzer='word',\n            token_pattern=r'\\w{1,}',\n            ngram_range=(1, 2),\n            min_df=5)\n\noverview_text = vectorizer.fit_transform(train['overview'].fillna(''))\nlinreg = LinearRegression()\nlinreg.fit(overview_text, train['revenue'])\neli5.show_weights(linreg, vec=vectorizer, top=20, feature_filter=lambda x: x != '<BIAS>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Target value:', train['revenue'][1000])\neli5.show_prediction(linreg, doc=train['overview'].values[1000], vec=vectorizer)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se puede ver que algunas palabras pueden contribuir a la predicción de ingreso aunque se presenta un sesgo importante."},{"metadata":{"_uuid":"3ba0024111403d77d8ab177767e0ddd5a40455dd"},"cell_type":"markdown","source":"<a id=\"model\"></a>\n## Generación de modelos"},{"metadata":{},"cell_type":"markdown","source":"<a id=\"def_train_test\"></a>\n## Definición de train y test"},{"metadata":{"trusted":true,"_uuid":"e9ad418c31137decb3749e097588ea5d5627df1c"},"cell_type":"code","source":"train = train.drop(['homepage', 'imdb_id', 'poster_path', 'release_date', 'status', 'log_revenue'], axis=1)\ntest = test.drop(['homepage', 'imdb_id', 'poster_path', 'release_date', 'status'], axis=1)\ntrain = train.drop(['all_belongs_to_collection', 'all_production_companies', 'all_production_countries', 'all_spoken_languages', 'all_Keywords', 'all_cast', 'all_crew', 'all_crew_dep', 'all_crew_job'], axis=1)\ntest = test.drop(['all_belongs_to_collection', 'all_production_companies', 'all_production_countries', 'all_spoken_languages', 'all_Keywords', 'all_cast', 'all_crew', 'all_crew_dep', 'all_crew_job'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a9b81368c44b20c81b00b8a5ad1873b0f3a8bd06"},"cell_type":"code","source":"for col in train.columns:\n    if train[col].nunique() == 1:\n        print(col)\n        train = train.drop([col], axis=1)\n        test = test.drop([col], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tratamiento de variables categóricas. Codificación."},{"metadata":{"trusted":true,"_uuid":"a4ceed1b74dd3de3b7678afa5409fc408464d8f0"},"cell_type":"code","source":"for col in ['original_language', 'collection_name', 'all_genres']:\n    le = LabelEncoder()\n    le.fit(list(train[col].fillna('')) + list(test[col].fillna('')))\n    train[col] = le.transform(train[col].fillna('').astype(str))\n    test[col] = le.transform(test[col].fillna('').astype(str))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Tratamiento de variables con texto"},{"metadata":{"trusted":true,"_uuid":"6c0104e927d1ad9f0c23cc5d12d04b34c0893325"},"cell_type":"code","source":"train_texts = train[['title', 'tagline', 'overview', 'original_title']]\ntest_texts = test[['title', 'tagline', 'overview', 'original_title']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f05aa3c34b2b1d3ca528461e2c655545773b5245"},"cell_type":"code","source":"for col in ['title', 'tagline', 'overview', 'original_title']:\n    train['len_' + col] = train[col].fillna('').apply(lambda x: len(str(x)))\n    train['words_' + col] = train[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n    train = train.drop(col, axis=1)\n    test['len_' + col] = test[col].fillna('').apply(lambda x: len(str(x)))\n    test['words_' + col] = test[col].fillna('').apply(lambda x: len(str(x.split(' '))))\n    test = test.drop(col, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"55356a620f90a4475c41eaedbd95db6f83543725"},"cell_type":"code","source":"# Datos faltante from https://www.kaggle.com/somang1418/happy-valentines-day-and-keep-kaggling-3\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'revenue'] = 6800000       # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntest.loc[test['id'] == 3889,'budget'] = 15000000       # Colossal\ntest.loc[test['id'] == 6733,'budget'] = 5000000        # The Big Sick\ntest.loc[test['id'] == 3197,'budget'] = 8000000        # High-Rise\ntest.loc[test['id'] == 6683,'budget'] = 50000000       # The Pink Panther 2\ntest.loc[test['id'] == 5704,'budget'] = 4300000        # French Connection II\ntest.loc[test['id'] == 6109,'budget'] = 281756         # Dogtooth\ntest.loc[test['id'] == 7242,'budget'] = 10000000       # Addams Family Values\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n\npower_six = train.id[train.budget > 1000][train.revenue < 100]\n\nfor k in power_six :\n    train.loc[train['id'] == k,'revenue'] =  train.loc[train['id'] == k,'revenue'] * 1000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4d4f4a5b8945723acb5a1206cffc60fbab151ae8"},"cell_type":"code","source":"X = train.drop(['id', 'revenue'], axis=1)\ny = np.log1p(train['revenue'])\nX_test = test.drop(['id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"dd747f7dc0506664d8dbe8e3eb4dc8b6c71f244a"},"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.1)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true,"_uuid":"994c032c62219dceec9c287f83ac91aeff8c8239"},"cell_type":"code","source":"params = {'num_leaves': 30,\n         'min_data_in_leaf': 20,\n         'objective': 'regression',\n         'max_depth': 5,\n         'learning_rate': 0.01,\n         \"boosting\": \"gbdt\",\n         \"feature_fraction\": 0.9,\n         \"bagging_freq\": 1,\n         \"bagging_fraction\": 0.9,\n         \"bagging_seed\": 11,\n         \"metric\": 'rmse',\n         \"lambda_l1\": 0.2,\n         \"verbosity\": -1}\nmodel1 = lgb.LGBMRegressor(**params, n_estimators = 20000, nthread = 4, n_jobs = -1)\nmodel1.fit(X_train, y_train, \n        eval_set=[(X_train, y_train), (X_valid, y_valid)], eval_metric='rmse',\n        verbose=1000, early_stopping_rounds=200)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f0eb8c69f9ffd8d0e664ec331e001ab59552d5ff"},"cell_type":"code","source":"eli5.show_weights(model1, feature_filter=lambda x: x != '<BIAS>')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5d7d29134a25355c517250b00079dae64523f5e"},"cell_type":"code","source":"n_fold = 10\nfolds = KFold(n_splits=n_fold, shuffle=True, random_state=42)\nprint(folds)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"hiper\"></a>\n## Configuración de hiperparametos"},{"metadata":{"trusted":true},"cell_type":"code","source":"def parametros(modelo):\n    if modelo=='xgb':\n        params = {'eta': 0.01,\n                      'objective': 'reg:linear',\n                      'max_depth': 15,\n                      'subsample': 0.8,\n                      'colsample_bytree': 0.8,\n                      'eval_metric': 'rmse',\n                      'seed': 11,\n                      'silent': True}\n    if modelo=='lgb':\n        params = {'num_leaves': 30,\n                 'min_data_in_leaf': 10,\n                 'objective': 'regression',\n                 'max_depth': 5,\n                 'learning_rate': 0.01,\n                 \"boosting\": \"gbdt\",\n                 \"feature_fraction\": 0.9,\n                 \"bagging_freq\": 1,\n                 \"bagging_fraction\": 0.9,\n                 \"bagging_seed\": 11,\n                 \"metric\": 'rmse',\n                 \"lambda_l1\": 0.2,\n                 \"verbosity\": -1}\n\n    if modelo=='cat':\n        params = {'learning_rate': 0.002,\n                      'depth': 5,\n                      'l2_leaf_reg': 10,\n                      # 'bootstrap_type': 'Bernoulli',\n                      'colsample_bylevel': 0.8,\n                      'bagging_temperature': 0.2,\n                      #'metric_period': 500,\n                      'od_type': 'Iter',\n                      'od_wait': 100,\n                      'random_seed': 11,\n                      'allow_writing_files': False}\n    if modelo=='lgb_1':\n        params = {'num_leaves': 30,\n                 'min_data_in_leaf': 20,\n                 'objective': 'regression',\n                 'max_depth': 5,\n                 'learning_rate': 0.01,\n                 \"boosting\": \"gbdt\",\n                 \"feature_fraction\": 0.9,\n                 \"bagging_freq\": 1,\n                 \"bagging_fraction\": 0.9,\n                 \"bagging_seed\": 11,\n                 \"metric\": 'rmse',\n                 \"lambda_l1\": 0.2,\n                 \"verbosity\": -1}\n\n    if modelo=='lgb_2':\n        params = {'num_leaves': 30,\n                 'min_data_in_leaf': 20,\n                 'objective': 'regression',\n                 'max_depth': 7,\n                 'learning_rate': 0.02,\n                 \"boosting\": \"gbdt\",\n                 \"feature_fraction\": 0.7,\n                 \"bagging_freq\": 5,\n                 \"bagging_fraction\": 0.7,\n                 \"bagging_seed\": 11,\n                 \"metric\": 'rmse',\n                 \"lambda_l1\": 0.2,\n                 \"verbosity\": -1}\n    if modelo=='Random_Forest':\n        params={'n_estimators':20000, \n                         'criterion':'rmse', \n                         'max_depth':15, \n                         'bootstrap':True, \n                         'oob_score':False, \n                         'n_jobs':-1, \n                         'random_state':53}\n    return params","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id=\"fittin\"></a>\n## Fitting Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"modelos=['lgb', 'xgb', 'cat', 'lgb_1', 'lgb_2','Random_Forest']\nmodelos=['cat', 'lgb_1', 'lgb_2']\n\nsub = pd.read_csv('../input/tmdb-box-office-prediction/sample_submission.csv')\n\nfor i in modelos:\n    params=parametros(i)\n    oof_, prediction_= train_model(X, X_test, y, params,folds, i, True,i)\n    sub['revenue'] = np.expm1(prediction_)\n    sub.to_csv(i+\".csv\", index=False)\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}