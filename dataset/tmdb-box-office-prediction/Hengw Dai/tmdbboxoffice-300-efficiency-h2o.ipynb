{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import time\nimport os\nimport psutil\nimport pandas as pd\nimport numpy as np\nfrom tqdm import tqdm\nfrom collections import OrderedDict\n\ndef count_time(func):\n    def int_time():\n        start_time = time.time()\n        func()\n        over_time = time.time()\n        total_time = over_time - start_time\n        tps = COUNT/total_time\n        print(\"The Tps: %s Item/s\" % tps)\n    return int_time","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:18:42.476335Z","iopub.execute_input":"2022-05-09T08:18:42.476675Z","iopub.status.idle":"2022-05-09T08:18:42.50796Z","shell.execute_reply.started":"2022-05-09T08:18:42.476592Z","shell.execute_reply":"2022-05-09T08:18:42.507301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\nCOUNT = len(df_train)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:18:44.013443Z","iopub.execute_input":"2022-05-09T08:18:44.014187Z","iopub.status.idle":"2022-05-09T08:18:44.547396Z","shell.execute_reply.started":"2022-05-09T08:18:44.014137Z","shell.execute_reply":"2022-05-09T08:18:44.546668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"length=0\nct=0\nfor item in df_train['overview'].apply(str).to_list():\n    length+=len(item)\n    ct+=1\nprint('Avg char length of text column:',length/ct)","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:18:53.820363Z","iopub.execute_input":"2022-05-09T08:18:53.821064Z","iopub.status.idle":"2022-05-09T08:18:53.832673Z","shell.execute_reply.started":"2022-05-09T08:18:53.821025Z","shell.execute_reply":"2022-05-09T08:18:53.831098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import h2o\nfrom h2o.estimators import H2OWord2vecEstimator, H2OGradientBoostingEstimator\ndocuments = df_train['overview'].to_list()\ndoc_ids = list(range(len(documents)))\n@count_time\ndef calcu_h2o():\n    h2o.init()\n    input_frame = h2o.H2OFrame(OrderedDict([('DocID', doc_ids), ('Document', documents)]),\n                                    column_types=['numeric', 'string'])\n    STOP_WORDS = [\"ax\",\"i\",\"you\",\"edu\",\"s\",\"t\",\"m\",\"subject\",\"can\",\n                  \"lines\",\"re\",\"what\",\"there\",\"all\",\"we\",\"one\",\"the\",\n                  \"a\",\"an\",\"of\",\"or\",\"in\",\"for\",\"by\",\"on\",\"but\",\"is\",\n                  \"in\",\"a\",\"not\",\"with\",\"as\",\"was\",\"if\",\"they\",\"are\",\n                  \"this\",\"and\",\"it\",\"have\",\"from\",\"at\",\"my\",\"be\",\"by\",\n                  \"not\",\"that\",\"to\",\"from\",\"com\",\"org\",\"like\",\"likes\",\n                  \"so\"]\n    # Make the 'tokenize' function:\n    def tokenize(sentences, stop_word = STOP_WORDS):\n        tokenized = sentences.tokenize(\"\\\\W+\")\n        tokenized_lower = tokenized.tolower()\n        tokenized_filtered = tokenized_lower[(tokenized_lower.nchar() >= 2) | (tokenized_lower.isna()),:]\n        tokenized_words = tokenized_filtered[tokenized_filtered.grep(\"[0-9]\",invert=True,output_logical=True),:]\n        tokenized_words = tokenized_words[(tokenized_words.isna()) | (~ tokenized_words.isin(STOP_WORDS)),:]\n        return tokenized_words\n\n    words = tokenize(input_frame[\"Document\"])\n\n    # Build word2vec model:\n    w2v_model = H2OWord2vecEstimator(sent_sample_rate = 0.0, epochs = 10)\n    w2v_model.train(training_frame=words)\n\n    # Find synonyms for the words \"teacher\":\n    w2v_model.find_synonyms(\"teacher\", count = 5)\n\n    vecs = w2v_model.transform(words, aggregate_method = \"AVERAGE\")\n# In [4]:\ncalcu_h2o()","metadata":{"execution":{"iopub.status.busy":"2022-05-09T08:19:10.994085Z","iopub.execute_input":"2022-05-09T08:19:10.994593Z","iopub.status.idle":"2022-05-09T08:19:49.102095Z","shell.execute_reply.started":"2022-05-09T08:19:10.994547Z","shell.execute_reply":"2022-05-09T08:19:49.100445Z"},"trusted":true},"execution_count":null,"outputs":[]}]}