{"cells":[{"metadata":{},"cell_type":"markdown","source":"Hi, We will try how to do different methods of feature selection in this kernel. Thanks for your upvotes."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# importing the essential libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport ast\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/train.csv')\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# let us see the types of data in the training set\ntrain_data.dtypes","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like we have a lot of feature engineering to do. \n1. the columns belongs to collectoins, imdb_id, homepage, original_title, overview, poster_path, realese_date, tagline, title, keywords, cast and crew can be removed (for now). We can deal with it later. \n2. We have features with values of dictionary. So we have to convert the dictionary with some other specific format."},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data = train_data.drop(['id', 'belongs_to_collection', 'homepage', 'imdb_id', 'original_title',\n                                'overview', 'poster_path', 'release_date', 'tagline', 'title',\n                                'Keywords', 'cast', 'crew'], axis = 1)\ntraining_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking the missing values\ntraining_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filling the missing values\ntraining_data = training_data.fillna('0')\ntraining_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can apply this logic to the dictionary values and convert them into numeric data using Label Encoder. \nI prefer to use Label Encoder instead of one hot encoder (get dummies) because label encoder uses a single feature and adds numbers in it. on the other hand get_dummies will create new columns."},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_engineering(series):\n    # Feature engineering for genres\n    string_list = []\n    for i in series:\n        string = []\n        if (i != '0'):\n            o = ast.literal_eval(i)\n            for i in o:\n                for j in i.items():\n                    if (j[0] == 'name'):\n                        string.append(j[1])\n        string_list.append(' + '.join(string))\n    return LabelEncoder().fit_transform(string_list)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering\ntraining_data.index = train_data['id']\ntraining_data['genres'] = feature_engineering(training_data['genres'])\ntraining_data['production_companies'] = feature_engineering(training_data['production_companies'])\ntraining_data['production_countries'] = feature_engineering(training_data['production_countries'])\ntraining_data['spoken_languages'] = feature_engineering(training_data['spoken_languages'])\ntraining_data['original_language'] = LabelEncoder().fit_transform(training_data['original_language'])\ntraining_data['status'] = LabelEncoder().fit_transform(training_data['status'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will visualize few features"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(training_data.corr())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Budget and popularity are the most correlated features with the revenue. Let us see some more plotting (scatter)"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(training_data['revenue'], training_data['budget'], 'o', label = 'revenue VS budget')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(training_data['revenue'], training_data['popularity'], 'o', label = 'revenue VS popularity')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Looks like we need to handle outliers too. (I will work on it in the next version)"},{"metadata":{"trusted":true},"cell_type":"code","source":"X = training_data.drop(['revenue'], axis = 1)\ny = training_data['revenue']\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 101)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\nvalidations = model.predict(X_val)\n\nprint(np.sqrt(mean_squared_error(validations, y_val)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we will import test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/test.csv')\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data = test_data.drop(['id', 'belongs_to_collection', 'homepage', 'imdb_id', 'original_title',\n                                'overview', 'poster_path', 'release_date', 'tagline', 'title',\n                                'Keywords', 'cast', 'crew'], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# filling the missing values\ntesting_data = testing_data.fillna('0')\ntesting_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Feature Engineering\ntesting_data.index = test_data['id']\ntesting_data['genres'] = feature_engineering(testing_data['genres'])\ntesting_data['production_companies'] = feature_engineering(testing_data['production_companies'])\ntesting_data['production_countries'] = feature_engineering(testing_data['production_countries'])\ntesting_data['spoken_languages'] = feature_engineering(testing_data['spoken_languages'])\ntesting_data['original_language'] = LabelEncoder().fit_transform(testing_data['original_language'])\ntesting_data['status'] = LabelEncoder().fit_transform(testing_data['status'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = model.predict(testing_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Now creating a dataset and submitting\nsubmission = pd.DataFrame({'id' : test_data['id'], 'revenue' : predictions})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thank you for viewing my kernel. Appreciate your time and encouragement. :)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}