{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport string\nimport re\n%matplotlib inline\n%precision 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y = train[\"revenue\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train, test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['overview','status','imdb_id','poster_path','original_title'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#辞書型に変換\nimport ast\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ndfx = text_to_dict(train)\nfor col in dict_columns:\n       train[col]=dfx[col]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### runtime","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train[\"runtime\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['id'] == 1336,'runtime'] = 130 #kololyovの上映時間を調べて入力\ntrain.loc[train['id'] == 2303,'runtime'] = 80 #HappyWeekendの上映時間を調べて入力","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"runtime\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train[\"runtime\"]==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['id'] == 391,'runtime'] = 96 #The Worst Christmas of My Lifeの上映時間を調べて入力\ntrain.loc[train['id'] == 592,'runtime'] = 90 #А поутру они проснулисьの上映時間を調べて入力\ntrain.loc[train['id'] == 925,'runtime'] = 86 #¿Quién mató a Bambi?の上映時間を調べて入力\ntrain.loc[train['id'] == 978,'runtime'] = 93 #La peggior settimana della mia vitaの上映時間を調べて入力\ntrain.loc[train['id'] == 1256,'runtime'] = 92 #Cry, Onion!の上映時間を調べて入力\ntrain.loc[train['id'] == 1542,'runtime'] = 93 #All at Onceの上映時間を調べて入力\ntrain.loc[train['id'] == 1875,'runtime'] = 93 #Vermistの上映時間を調べて入力\ntrain.loc[train['id'] == 2151,'runtime'] = 108 #Mechenosetsの上映時間を調べて入力\ntrain.loc[train['id'] == 2499,'runtime'] = 86 #Na Igre 2. Novyy Urovenの上映時間を調べて入力\ntrain.loc[train['id'] == 2646,'runtime'] = 98 #My Old Classmateの上映時間を調べて入力\ntrain.loc[train['id'] == 2786,'runtime'] = 111 #Revelationの上映時間を調べて入力\ntrain.loc[train['id'] == 2866,'runtime'] = 96 #Tutto tutto niente nienteの上映時間を調べて入力","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train[\"runtime\"], kde=False, rug=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test[\"runtime\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['id'] == 3244,'runtime'] = 93 #La caliente niña Julietta\tの上映時間を調べて入力\ntest.loc[test['id'] == 4490,'runtime'] = 90 #Pancho, el perro millonarioの上映時間を調べて入力\ntest.loc[test['id'] == 4633,'runtime'] = 108 #Nunca en horas de claseの上映時間を調べて入力\ntest.loc[test['id'] == 6818,'runtime'] = 90 #Miesten välisiä keskustelujaの上映時間を調べて入力","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test[\"runtime\"]==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.loc[test['id'] == 4074,'runtime'] = 103 #Shikshanachya Aaicha Ghoの上映時間を調べて入力\ntest.loc[test['id'] == 4222,'runtime'] = 91 #Street Knightの上映時間を調べて入力\ntest.loc[test['id'] == 4431,'runtime'] = 96 #Plus oneの上映時間を調べて入力\ntest.loc[test['id'] == 5520,'runtime'] = 86 #Glukhar v kinoの上映時間を調べて入力\ntest.loc[test['id'] == 5845,'runtime'] = 83 #Frau Müller muss weg!の上映時間を調べて入力\ntest.loc[test['id'] == 5849,'runtime'] = 140 #Shabdの上映時間を調べて入力\ntest.loc[test['id'] == 6210,'runtime'] = 104 #The Last Breathの上映時間を調べて入力\ntest.loc[test['id'] == 6804,'runtime'] = 140 #Chaahat Ek Nasha...の上映時間を調べて入力\ntest.loc[test['id'] == 7321,'runtime'] = 87 #El truco del mancoの上映時間を調べて入力","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(test[\"runtime\"], kde=False, rug=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = train.corr()\nplt.subplots(figsize=(12, 8))\nsns.heatmap(corrmat, square=True, cmap='coolwarm', annot=True,vmin=-1)\n#plt.savefig(\"TMDBcorr.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### budget","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train[\"budget\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train[\"budget\"]==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test[\"runtime\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[test[\"budget\"]==0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"budgetが0の物が多いので手入力は厳しい →①補完しない②補完する\n\n②補完する場合の方法を考える(保留)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#release_dateを年、月、日に分解\ndef date_features(df):\n    df['release_date'] = pd.to_datetime(df['release_date'])\n    df['release_year'] = df['release_date'].dt.year\n    df['release_month'] = df['release_date'].dt.month\n    df['release_day'] = df['release_date'].dt.day\n    df['release_quarter'] = df['release_date'].dt.quarter\n    df.drop(columns=['release_date'], inplace=True)\n    return df\n\ntrain=date_features(train)\ntest=date_features(test)\n\ntrain['release_year'].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train, test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop(columns=['status','imdb_id','poster_path','original_title'], inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#budgetが0の物を予測（テスト）、0でない物をtrainingデータとする\nbudget0 = df[df[\"budget\"] == 0]\nbudget = df[df[\"budget\"] != 0]\ntrain_X = budget[[\"popularity\",\"runtime\"]]\ntrain_y = budget[\"budget\"]\ntest_X = budget0[[\"popularity\",\"runtime\"]]\ntest_y = budget0[\"budget\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"budget0","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"#budgetが0の物を線形回帰で予測\nfrom sklearn.linear_model import RidgeCV\nrcv= RidgeCV(cv=3, alphas = 10**np.arange(-2, 2, 0.1))\nrcv.fit(train_X, train_y)\ny_pred = rcv.predict(test_X)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"budget0[\"id\"].index = range(0,2023)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"budget_pred = pd.DataFrame(y_pred,columns=[\"pred\"])\nbudget_id = pd.DataFrame(budget0[\"id\"],columns=[\"id\"])\nbudget_pred = pd.concat([budget_id,budget_pred],axis = 1)\nbudget_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"budget_pred.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#予算が0を下回っているものはおかしいので0に戻す。\nbudget_pred.loc[budget_pred[\"pred\"] < 0, \"pred\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.merge(df, budget_pred, on=\"id\", how=\"left\") \ndf.loc[budget_pred[\"id\"]-1, \"budget\"] = df.loc[budget_pred[\"id\"]-1, \"pred\"]\ndf = df.drop(\"pred\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corrmat = df.corr()\nplt.subplots(figsize=(12, 8))\nsns.heatmap(corrmat, square=True, cmap='coolwarm', annot=True,vmin=-1)\n#plt.savefig(\"TMDBcorr.png\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### overview","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"].isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]=df[\"overview\"].apply(lambda x : str(x))\ntrain[\"overview\"]=train[\"overview\"].apply(lambda x : str(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#全て小文字に変換\ndef lower_text(text):\n    return text.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]=df[\"overview\"].apply(lambda x : lower_text(x))\ntrain[\"overview\"]=train[\"overview\"].apply(lambda x : lower_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#短縮形を元に戻す\nshortened = {\n    '\\'m': ' am',\n    '\\'re': ' are',\n    'don\\'t': 'do not',\n    'doesn\\'t': 'does not',\n    'didn\\'t': 'did not',\n    'won\\'t': 'will not',\n    'wanna': 'want to',\n    'gonna': 'going to',\n    'gotta': 'got to',\n    'hafta': 'have to',\n    'needa': 'need to',\n    'outta': 'out of',\n    'kinda': 'kind of',\n    'sorta': 'sort of',\n    'lotta': 'lot of',\n    'lemme': 'let me',\n    'gimme': 'give me',\n    'getcha': 'get you',\n    'gotcha': 'got you',\n    'letcha': 'let you',\n    'betcha': 'bet you',\n    'shoulda': 'should have',\n    'coulda': 'could have',\n    'woulda': 'would have',\n    'musta': 'must have',\n    'mighta': 'might have',\n    'dunno': 'do not know',\n}\ndf[\"overview\"] = df[\"overview\"].replace(shortened)\ntrain[\"overview\"] = train[\"overview\"].replace(shortened)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#記号の排除\ndef remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]=df[\"overview\"].apply(lambda x : remove_punct(x))\ntrain[\"overview\"]=train[\"overview\"].apply(lambda x : remove_punct(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 連続した数字を0で置換\ndef normalize_number(text):\n    replaced_text = re.sub(r'\\d+', '0', text)\n    return replaced_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]=df[\"overview\"].apply(lambda x : normalize_number(x))\ntrain[\"overview\"]=train[\"overview\"].apply(lambda x : normalize_number(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#レンマ化\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nwnl = WordNetLemmatizer()\ndf[\"overview\"]=df[\"overview\"].apply(wnl.lemmatize)\ntrain[\"overview\"]=train[\"overview\"].apply(wnl.lemmatize)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#空白ごとの文章の分割\ndf[\"overview\"]=df[\"overview\"].apply(lambda x : str(x).split())\ntrain[\"overview\"]=train[\"overview\"].apply(lambda x : str(x).split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_overview = df[\"overview\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def most_common(docs, n=100):#(文章、上位n個の単語)#上位n個の単語を抽出\n    fdist = Counter()\n    for doc in docs:\n        for word in doc:\n            fdist[word] += 1\n    common_words = {word for word, freq in fdist.most_common(n)}\n    print('{}/{}'.format(n, len(fdist)))\n    return common_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common(df_overview,100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_stop_words(docs, n=100, min_freq=1):#上位n個の単語、頻度がmin_freq以下の単語を列挙（あまり特徴のない単語等）\n    fdist = Counter()\n    for doc in docs:\n        for word in doc:\n            fdist[word] += 1\n    common_words = {word for word, freq in fdist.most_common(n)}\n    rare_words = {word for word, freq in fdist.items() if freq <= min_freq}\n    stopwords = common_words.union(rare_words)\n    print('{}/{}'.format(len(stopwords), len(fdist)))\n    return stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = get_stop_words(df_overview)\nstopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopwords(words, stopwords):#不要な単語を削除\n    words = [word for word in words if word not in stopwords]\n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]=df[\"overview\"].apply(lambda x : remove_stopwords(x,stopwords))\ntrain[\"overview\"]=train[\"overview\"].apply(lambda x : remove_stopwords(x,stopwords))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]=[\" \".join(review) for review in df[\"overview\"].values]\ntrain[\"overview\"]=[\" \".join(review) for review in train[\"overview\"].values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"overview\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer#ベクトル化\nvec_tfidf = TfidfVectorizer()\nX = vec_tfidf.fit_transform(df[\"overview\"])\nTfid_overview = pd.DataFrame(X.toarray(), columns=vec_tfidf.get_feature_names())\n\nX2 = vec_tfidf.fit_transform(df[\"overview\"])\nTfid_train_overview = pd.DataFrame(X2.toarray(), columns=vec_tfidf.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tfid_overview","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n#目的変数とベクトルの線形回帰による単語の重要度比較（途中）\nfrom sklearn.linear_model import LinearRegression\nlinreg = LinearRegression()\nlinreg.fit(X2, np.log1p(train['revenue']))\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"\"\"\"\ncoef = pd.Series(linreg.coef_, index=Tfid_overview.columns)\ndf_coef = pd.DataFrame(coef[coef!=0], columns=[\"coef\"])\ndf_coef.sort_values(\"coef\", ascending=False)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tagline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#単語数\ndf['tagline_word_count'] = df['tagline'].apply(lambda x: len(str(x).split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#文字数\ndf['tagline_char_count'] = df['tagline'].apply(lambda x: len(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 記号の個数\ndf['tagline_punctuation_count'] = df['tagline'].apply(lambda x: len([c for c in str(x) if c in string.punctuation]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tagline']=df['tagline'].apply(lambda x : str(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"tagline\"] = df[\"tagline\"].replace(shortened)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tagline']=df['tagline'].apply(lambda x : lower_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tagline']=df['tagline'].apply(lambda x : remove_punct(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"tagline\"]=df[\"tagline\"].apply(lambda x : normalize_number(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tagline']=df['tagline'].apply(lambda x : str(x).split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tagline = df[\"tagline\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_common(tagline)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = get_stop_words(tagline)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tagline']=df['tagline'].apply(lambda x : remove_stopwords(x,stopwords))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nan = {\"nan\"}\ndef remove_nan(words):\n    words = [word for word in words if word not  in nan]\n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tagline']=df['tagline'].apply(lambda x : remove_nan(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['tagline']=[\" \".join(review) for review in df['tagline'].values]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ベクトル化\nX = vec_tfidf.fit_transform(df['tagline'])\nTfid_tagline = pd.DataFrame(X.toarray(), columns=vec_tfidf.get_feature_names())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Tfid_tagline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 使用する変数","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use = df[[\"runtime\",'budget','tagline_char_count']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_use = pd.concat([df_use,Tfid_overview],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#使用する変数\ndf_use = df_use.loc[:,~df_use.columns.duplicated()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open('df_use.pkl', 'wb') as f:\n      pickle.dump(df_use , f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainX = df_use.iloc[:train.shape[0],:].reset_index(drop=True)\ntest_X = df_use.iloc[train.shape[0]:,:].reset_index(drop=True)\ntrainy = train[\"revenue\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(trainX,trainy,test_size=0.3,random_state=100)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Xgboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import xgboost as xgb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndtrain = xgb.DMatrix(X_train, label=y_train)  \ndvalid = xgb.DMatrix(X_test, label=y_test)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#param = {'max_depth': 5, 'eta': 0.5, 'objective': 'reg:squaredlogerror', 'eval_metric': 'rmsle','alpha':0.5} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nevallist = [(dvalid, 'eval'), (dtrain, 'train')]  \nnum_round = 20\nbst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=5)  \"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"reg = xgb.XGBRegressor()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\n# ハイパーパラメータ探索\nfrom sklearn.model_selection import GridSearchCV\n#reg_cv = GridSearchCV(reg, {'max_depth': [2,4,6], 'n_estimators': [100]})\nreg.fit(X_train, y_train)\n#print (reg_cv.best_params_, reg_cv.best_score_)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Lasso","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nfrom sklearn.linear_model import Lasso\nfrom sklearn.metrics import mean_squared_error\nbest_rmse = 1\nfor num in range(1,100):\n    alpha = num*0.0001\n    reg=Lasso(alpha=alpha,max_iter=3000)\n    reg.fit(X_train,y_train)\n    y_pred=reg.predict(X_test)\n    rmse=np.sqrt(mean_squared_error(y_pred,y_test))\n    if best_rmse>rmse:\n        best_rmse=rmse\n        best_alpha=alpha\nprint(\"best_alpha\",alpha,\"rmse\",best_rmse)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nreg1=Lasso(alpha=0.0099,max_iter=3000)\nreg1.fit(X_train,y_train)\ny_pred1=reg.predict(test_X)\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#y_pred1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}