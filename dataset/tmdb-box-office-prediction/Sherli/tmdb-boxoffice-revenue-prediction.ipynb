{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Objective: For given information about movies which include cast, crew, plot keywords, budget, posters, release dates, languages, production companies, and countries we have to build a model which will accurately predict the overall worldwide revenue for a movie.\nFollowing are few important features present in dataset:\nbelongs_to_collection : This feautue is present only for true movie sequels.\nbudget: Buget of film in USD\ngenres\noriginal_language: Language with the original version of the film.\noriginal_title: Title of film when it is first officially released locally\noverview: Describe the plot of the movie.\npopularity\nproduction_companies\nproduction_countries\nrelease_date\nruntime: Length of movie.\nspoken_languages: Languages spoken in the movie\nstatus: Whether movie is release or not.\nKeywords\ncast: Information all cast memebers\ncrew: Information of, director, producer, writer etc.\nrevenue: Target variable. Revenue of film in USD\nData types present in dataset:\nString\nNumeric\nDate\nJSON\nHandling JSON data\nThere are various attributes such as cast, crew, genres which represents important information about movie. This are multivalued fields. Each value in these fields is a JSON object.\nEx. of genres. [{'id': 35, 'name': 'Comedy'}, {'id': 18, 'name': 'Drama'}, {'id': 10751, 'name': 'Family'}, {'id': 10749, 'name': 'Romance'}]\nFrom these JSON object, I will be extracting the name only. So the multivalued field will contain list of strings rather than list of JSON objects.\nFor each multivalued field there will be many JSON object which means many name fields. Including all those name fields for encoding will increase the dimensionality of data by huge factor and this will impact the model training. So I will be including 30 most occured names for each multivalued field and the other names will be marked as 'other'.\nThis list of names can encoded further using MutliLabelBinarizer."},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = pd.read_csv(\"../input/tmdb-box-office-prediction/train.csv\")\nprint(data.shape)\ndata.head(n=2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Data Exploration**"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore = data.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore['is_sequel'] = data_explore['belongs_to_collection'].apply(lambda x: 0 if pd.isna(x) else 1).astype('int64')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def modify_date(x):\n    \"\"\"\n    Given data format is mm/dd/YY. This function will extract the year, month and day on which movie is release.\n    \"\"\"\n    x=str(x)\n    year=x.split('/')[2]\n    if int(year)<20:\n        return x[:-2]+'20'+year\n    else:\n        return x[:-2]+'19'+year\n    \ndata_explore['release_date']=data_explore['release_date'].apply(lambda x: modify_date(x))\ndata_explore['release_year'] = pd.DatetimeIndex(data_explore['release_date']).year\ndata_explore['release_month'] = pd.DatetimeIndex(data_explore['release_date']).month\ndata_explore['release_day'] = pd.DatetimeIndex(data_explore['release_date']).day\ndata_explore['release_dow'] = pd.DatetimeIndex(data_explore['release_date']).dayofweek","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['id', 'belongs_to_collection', 'homepage', 'imdb_id', 'release_date', 'poster_path', 'tagline', 'title']\ndata_explore = data_explore.drop(columns=drop_cols, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_cols = data_explore.isna().sum()\nnan_cols[nan_cols>0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Except runtime, all columns which contain NULL values are the columns which are multi-valued. So will replace them with empty set.\nNULL value in runtime will be replace by the median value."},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Min budget, runtime is zero\nMin revenue is one"},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\ndict_cols = ['genres', 'production_companies', 'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\nfor col in dict_cols:\n    data_explore[col] = data_explore[col].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"na_cols = data_explore.columns[data_explore.isna().any()].tolist()\nna_cols.remove('overview')\nna_cols.remove('runtime')\ndata_explore['runtime'].fillna(value=data_explore['runtime'].median(), inplace=True)\ndata_explore['overview'].fillna(value='', inplace=True)\nfor col in na_cols:\n    data_explore[col].fillna(value='', inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_names(x, col):\n    \"\"\"\n        Get the name field from each JSON object.\n        For crew field, considering the Director only.\n        For cast field, considering the first 3 cast members. Generally they are the main roles from movie.\n    \"\"\"\n    names = []\n    for item in x:\n        if col=='crew':\n            if item['job']=='Director':\n                names.append(item['name'])\n        elif col=='cast':\n            if item['order'] in (0, 1, 2):\n                names.append(item['name'])\n        else:\n            names.append(item['name'])\n    return names\n    \nfor col in dict_cols:\n    data_explore[col] = data_explore[col].apply(lambda x: get_names(x, col))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Q1 = data_explore.quantile(0.25)\nQ3 = data_explore.quantile(0.75)\nIQR = Q3 - Q1\noutliers = ((data_explore < (Q1 - 1.5 * IQR)) | (data_explore > (Q3 + 1.5 * IQR))).sum()\noutliers[outliers>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore.hist(figsize=(15, 15))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Top 20 most popular movies**"},{"metadata":{"trusted":true},"cell_type":"code","source":"most_popular_movies = data_explore.sort_values('popularity', ascending=False).head(n=20)\nmost_popular_movies['revenue(million)'] = most_popular_movies['revenue'].apply(lambda x : x//1000000)    # revenue in millions\nmost_popular_movies['budget(million)'] = most_popular_movies['budget'].apply(lambda x : x//1000000)    # revenue in millions\nmost_popular_movies[['genres', 'original_title', 'production_companies', 'popularity', 'cast', 'crew', 'budget(million)', 'revenue(million)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nax = sns.barplot(y='original_title', x='popularity', data=most_popular_movies, order=most_popular_movies.sort_values('popularity', ascending=False).original_title, orient='h')\nfor p in ax.patches:\n        ax.annotate('{}'.format(int(p.get_width())), (p.get_width(), p.get_y()+0.5), fontsize=12)\nplt.title('Top 20 Most Popular Movies', fontsize=12)\nplt.ylabel('')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"highest_revenue_movies = data_explore.sort_values('revenue', ascending=False).head(n=20)\nhighest_revenue_movies['revenue(million)'] = highest_revenue_movies['revenue'].apply(lambda x : x//1000000)    # revenue in millions\nhighest_revenue_movies['budget(million)'] = highest_revenue_movies['budget'].apply(lambda x : x//1000000)    # revenue in millions\nhighest_revenue_movies[['genres', 'original_title', 'production_companies', 'popularity', 'cast', 'crew', 'budget(million)', 'revenue(million)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nax = sns.barplot(y='original_title', x='revenue(million)', data=highest_revenue_movies, order=highest_revenue_movies.sort_values('revenue(million)', ascending=False).original_title, orient='h')\nfor p in ax.patches:\n        ax.annotate('{}'.format(int(p.get_width())), (p.get_width(), p.get_y()+0.5), fontsize=12)\nplt.title('Top 20 High Revenue(million) Movies', fontsize=12)\nplt.ylabel('')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Top 20 High Budget Movies**"},{"metadata":{"trusted":true},"cell_type":"code","source":"highest_budget_movies = data_explore.sort_values('budget', ascending=False).head(n=20)\nhighest_budget_movies['revenue(million)'] = highest_budget_movies['revenue'].apply(lambda x : x//1000000)    # revenue in millions\nhighest_budget_movies['budget(million)'] = highest_budget_movies['budget'].apply(lambda x : x//1000000)    # revenue in millions\nhighest_budget_movies[['genres', 'original_title', 'production_companies', 'popularity', 'cast', 'crew', 'budget(million)', 'revenue(million)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nax = sns.barplot(y='original_title', x='budget(million)', data=highest_budget_movies, order=highest_budget_movies.sort_values('budget(million)', ascending=False).original_title, orient='h')\nfor p in ax.patches:\n        ax.annotate('{}'.format(int(p.get_width())), (p.get_width(), p.get_y()+0.5), fontsize=12)\nplt.title('Top 20 High Budget(million) Movies', fontsize=12)\nplt.ylabel('')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Top 20 Highest Grossing Movies**"},{"metadata":{"trusted":true},"cell_type":"code","source":"most_profit_movies = data_explore.copy()\nmost_profit_movies['revenue(million)'] = most_profit_movies['revenue'].apply(lambda x : x//1000000)    # revenue in millions\nmost_profit_movies['budget(million)'] = most_profit_movies['budget'].apply(lambda x : x//1000000)    # revenue in millions\nmost_profit_movies['profit(million)'] = most_profit_movies['revenue(million)']-most_profit_movies['budget(million)']\nmost_profit_movies = most_profit_movies.sort_values('profit(million)', ascending=False).head(n=20)\nmost_profit_movies[['genres', 'original_title', 'production_companies', 'popularity', 'cast', 'crew', 'budget(million)', 'revenue(million)', 'profit(million)']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 10))\nax = sns.barplot(y='original_title', x='profit(million)', data=most_profit_movies, order=most_profit_movies.sort_values('profit(million)', ascending=False).original_title, orient='h')\nfor p in ax.patches:\n        ax.annotate('{}'.format(int(p.get_width())), (p.get_width(), p.get_y()+0.5), fontsize=12)\nplt.title('Top 20 Highest Grossing Movies', fontsize=12)\nplt.ylabel('')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_explore_enc = data_explore['genres'].apply(lambda x: pd.Series([1] * len(x), index=x)).fillna(0, downcast='infer')\ndata_explore_genres = pd.concat([data_explore, data_explore_enc], axis=1)\ngenres = data_explore_enc.columns\ndata_explore_genres.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genres_info = []\nfor col in genres:\n    total_movies, total_budget, median_budget, total_revenue, median_revenue, median_popularity=0, 0, 0, 0, 0, 0\n    total_movies = data_explore_genres[data_explore_genres[col]==1][col].count()\n    total_budget = data_explore_genres[data_explore_genres[col]==1]['budget'].sum()\n    median_budget = data_explore_genres[data_explore_genres[col]==1]['budget'].median()\n    total_revenue = data_explore_genres[data_explore_genres[col]==1]['revenue'].sum()\n    median_revenue = data_explore_genres[data_explore_genres[col]==1]['revenue'].median()\n    median_popularity = data_explore_genres[data_explore_genres[col]==1]['popularity'].median()\n    genres_info.append([col, total_movies, total_budget, median_budget, total_revenue, median_revenue, median_popularity])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"genres_info = pd.DataFrame(genres_info, columns=['genres', 'movies_count', 'total_budget', 'median_budget', 'total_revenue', 'median_revenue', 'median_popularity'])\ngenres_info['total_budget(million)'] = genres_info['total_budget'].apply(lambda x : x//1000000)    # budget in millions\ngenres_info['median_budget(million)'] = genres_info['median_budget'].apply(lambda x : x//1000000)    # budget in millions\ngenres_info['total_revenue(million)'] = genres_info['total_revenue'].apply(lambda x : x//1000000)    # revenue in millions\ngenres_info['median_revenue(million)'] = genres_info['median_revenue'].apply(lambda x : x//1000000)    # revenue in millions\ngenres_info[['genres', 'movies_count', 'total_budget(million)', 'median_budget(million)', 'total_revenue(million)', 'median_revenue(million)', 'median_popularity']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nax = sns.barplot(x='genres', y='movies_count', data=genres_info, order=genres_info.sort_values('movies_count', ascending=False).genres)\nfor p in ax.patches:\n        ax.annotate('{}'.format(int(p.get_height())), (p.get_x()+0.1, p.get_height()+10))\nplt.xticks(rotation=45)\nplt.ylabel('# of Movies', fontsize=12)\nplt.xlabel('Genres', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nax = sns.barplot(x='genres', y='median_popularity', data=genres_info, order=genres_info.sort_values('median_popularity', ascending=False).genres)\nfor p in ax.patches:\n        ax.annotate('{}'.format(np.round(p.get_height(), 2)), (p.get_x()+0.1, p.get_height()))\nplt.xticks(rotation=45)\nplt.ylabel('Median Popularity', fontsize=12)\nplt.xlabel('Genres', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nax = sns.barplot(x='genres', y='median_popularity', data=genres_info, order=genres_info.sort_values('median_popularity', ascending=False).genres)\nfor p in ax.patches:\n        ax.annotate('{}'.format(np.round(p.get_height(), 2)), (p.get_x()+0.1, p.get_height()))\nplt.xticks(rotation=45)\nplt.ylabel('Median Popularity', fontsize=12)\nplt.xlabel('Genres', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nx_indexes = np.arange(len(genres))     \nwidth = 0.35                            \ngenres_info = genres_info.sort_values('total_revenue(million)', ascending=False)\nplt.bar(x_indexes,  genres_info['total_revenue(million)'], label=\"Total Movies Revenue\", width=width)\nplt.bar(x_indexes + width,  genres_info['total_budget(million)'], label=\"Total Movies Budget\", width=width)\nplt.legend(loc=\"upper right\", fontsize=12)\nplt.xticks(ticks=x_indexes+0.5, labels=genres_info['genres'].values, fontsize=12, rotation=-45)\nplt.xlabel('Genres', fontsize=12)\nplt.ylabel('Sum value(million)', fontsize=12)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nx_indexes = np.arange(len(genres))     \nwidth = 0.35                            \ngenres_info = genres_info.sort_values('median_revenue(million)', ascending=False)\nplt.bar(x_indexes,  genres_info['median_revenue(million)'], label=\"Median Movies Revenue\", width=width)\nplt.bar(x_indexes + width,  genres_info['median_budget(million)'], label=\"Median Movies Budget\", width=width)\nplt.legend(loc=\"upper right\", fontsize=12)\nplt.xticks(ticks=x_indexes+0.5, labels=genres_info['genres'].values, fontsize=12, rotation=-45)\nplt.xlabel('Genres', fontsize=12)\nplt.ylabel('Median value(million)', fontsize=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Revenue"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(7, 7))\nsns.boxplot(x='revenue', data=data_explore, orient='v')\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_ylim(0, 300000000)\nax.set_title('Distribution of Revenue')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.scatterplot(x='budget', y='revenue', data=data_explore)\nax = plt.gca()\nax.get_xaxis().get_major_formatter().set_scientific(False)\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Revenue Vs. Budget')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# [[](http://)](http://)Observation"},{"metadata":{},"cell_type":"markdown","source":"There is not any clear trend between budget and revenue. But we can see that higher budget films generally earn more compare to small budget films."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nsns.scatterplot(x='popularity', y='revenue', data=data_explore)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Revenue Vs. Popularity')\nplt.xlim(0, 60)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.scatterplot(x='runtime', y='revenue', data=data_explore)\nplt.xticks(rotation=90)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Revenue Vs. Movie Runtime')\nplt.xlim(50, 200)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.barplot(x='release_year', y='revenue', data=data_explore, estimator=np.mean)\nplt.xticks(rotation=90)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Avg. Revenue Each Year (Since 1960)')\nax.set_xlim(left=31.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.barplot(x='release_month', y='revenue', data=data_explore, estimator=np.mean)\nplt.xticks(rotation=90)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Avg. Revenue Each Month')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 5))\nsns.barplot(x='release_dow', y='revenue', data=data_explore, estimator=np.mean)\nplt.xticks(rotation=90)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Avg. Revenue on Each Day of Week')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 6))\nsns.boxplot(x='original_language', y='revenue', data=data_explore)\n# plt.xticks(rotation=90)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_ylim(top=400000000)\nax.set_xlim(right=15.5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def boxplot_sorted(df, by, column):\n    # use dict comprehension to create new dataframe from the iterable groupby object\n    # each group name becomes a column in the new dataframe\n    df2 = pd.DataFrame({col:vals[column] for col, vals in df.groupby(by)})\n    # find and sort the median values in this new dataframe\n    meds = df2.mean().sort_values(ascending=False)\n    # use the columns in the dataframe, ordered sorted by median value\n    # return axes so changes can be made outside the function\n    return df2[meds.index].boxplot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\naxes = boxplot_sorted(data_explore, by = ['original_language'], column = 'revenue')\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_ylim((-10000000, 300000000))\nax.set_xlim(right=10.5)\nplt.xlabel('Orignal Language')\nplt.ylabel('Revenue')\nplt.title('Distribution of Revenue for Top 10 Movies(by Average Revenue)')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15, 7))\naxes = boxplot_sorted(data_explore, by = ['release_year'], column = 'revenue')\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_ylim((-10000000, 400000000))\nax.set_xlim(right=20.5)\nplt.xlabel('Release Year')\nplt.ylabel('Revenue')\nplt.title('Distribution of Revenue for Top 20 Years (by Average Revenue)')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Corelation Plot"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12, 7))\ncorr_matrix = data_explore.corr()\nsns.heatmap(corr_matrix, mask=np.zeros_like(corr_matrix, dtype=np.bool), square=True, annot=True, cbar=False)\nplt.tight_layout()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corr_matrix['revenue'].sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"In this step I will create a pipeline to handle all data preprocessing operations.\nPipeline will do following tasks:\n* Dropping unwanted columns\n* Fill null values\n* Scaling numerical features\n* Encoding single valued & multivalued categorical fields\n* Creating new features from existing ones\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder, PowerTransformer, MultiLabelBinarizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = data.drop(columns=['revenue'], axis=1).copy()\ny = data['revenue'].copy()\nX.shape, y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ntop_30_values = dict()\n\nlist_of_genres_names = list(X['genres'].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x)).apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\ntop_30_genres = (Counter([i for j in list_of_genres_names for i in j]).most_common(30))\ntop_30_values['genres'] = [x for x, y in top_30_genres]\n\nlist_of_production_companies_names = list(X['production_companies'].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x)).apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\ntop_30_production_companies = (Counter([i for j in list_of_production_companies_names for i in j]).most_common(30))\ntop_30_values['production_companies'] = [x for x, y in top_30_production_companies]\n\nlist_of_production_countries_names = list(X['production_countries'].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x)).apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\ntop_30_production_countries = (Counter([i for j in list_of_production_countries_names for i in j]).most_common(30))\ntop_30_values['production_countries'] = [x for x, y in top_30_production_countries]\n\nlist_of_keywords = list(X['Keywords'].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x)).apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\ntop_30_keywords = (Counter([i for j in list_of_keywords for i in j]).most_common(30))\ntop_30_values['Keywords'] = [x for x, y in top_30_keywords]\n\nlist_of_cast_names = list(X['cast'].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x)).apply(lambda x: [i['name'] for i in x if i['order'] in (0, 1, 2)] if x != {} else []).values)\ntop_30_cast = (Counter([i for j in list_of_cast_names for i in j]).most_common(30))\ntop_30_values['cast'] = [x for x, y in top_30_cast]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_cols = ['id', 'homepage', 'imdb_id', 'original_title', 'spoken_languages', 'overview', 'poster_path', 'tagline', 'title', 'crew']\nencoded_cols = [] # This will contain all the encoded column names of multivalued field","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomAttr(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        pass\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        try:\n            X['is_sequel'] = X['belongs_to_collection'].apply(lambda x: 0 if pd.isna(x) else 1)\n#             print(\"is_sequel attribute added!\")\n            \n            X['release_date']= X['release_date'].apply(lambda x: self.modify_date(x))\n            \n            X['release_year'] = pd.DatetimeIndex(X['release_date']).year\n#             print(\"release_year attribute added!\")\n            \n            X['release_month'] = pd.DatetimeIndex(X['release_date']).month\n#             print(\"release_month attribute added!\")\n            \n            X['release_day'] = pd.DatetimeIndex(X['release_date']).day\n#             print(\"release_day attribute added!\")\n            \n            X['release_dow'] = pd.DatetimeIndex(X['release_date']).dayofweek\n#             print(\"release_dow attribute added!\")\n            \n            X = X.drop(['belongs_to_collection', 'release_date'], axis=1)\n#             print(\"belongs_to_collection, release_date attribute removed!\")\n            return X\n        except Exception as e:\n            print(\"CustomAttr: Exception caught: {}\".format(e))\n\n    @staticmethod\n    def modify_date(x):\n        \"\"\"\n            Converting date: mm/dd/YY to mm/dd/YYYY\n            NaN date fields are handle here only.\n        \"\"\"\n        try:\n            if x is np.nan:\n                x='01/01/00'\n            x=str(x)\n            year=x.split('/')[2]\n            if int(year)<20:\n                return x[:-2]+'20'+year\n            else:\n                return x[:-2]+'19'+year\n        except Exception as e:\n            print(\"CustomAttr: modify_date() function -  exception caught for date {}: {}\".format(x,e))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class JSONHandler(BaseEstimator, TransformerMixin):\n    def __init__(self):\n        \"\"\"\n        For each multivalued field, there will be a MultiLabelBinarizer.\n        \"\"\"\n        self.mlbs = dict()\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def transform(self, X):\n        for col in list(X.columns):\n            try:\n                X[col] = X[col].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x))\n                X[col] = X[col].apply(lambda x: self.get_names(x, col))\n                if not (col in self.mlbs.keys()):\n                    self.mlbs[col] = MultiLabelBinarizer()\n                    X_enc = pd.DataFrame(self.mlbs[col].fit_transform(X[col]),columns=self.mlbs[col].classes_, \n                                         index=X.index)\n                    encoded_cols.extend(list(self.mlbs[col].classes_))\n                else:\n                    X_enc = pd.DataFrame(self.mlbs[col].transform(X[col]),columns=self.mlbs[col].classes_, \n                                         index=X.index)\n                X = X.drop(col, axis=1)\n                X = pd.concat([X, X_enc], axis=1)\n#                 print(\"{}, {}, {}\".format(col, X_enc.shape, X.shape))\n#                 print(\"{} attribute encoded &  removed!\".format(col))\n            except Exception as e:\n                print(\"JSONHandler: Exception caught for {}: {}\".format(col,e))\n        return X\n       \n\n    @staticmethod\n    def get_names(x, col):\n        \"\"\"\n            Get the name field value from JSON object.\n        \"\"\"\n        names = []\n        try:\n            names = [item['name'] for item in x if item['name'] in top_30_values[col]]\n            if len(names)==0:\n                names.append('other_'+col)\n            return names\n        except Exception as e:\n            print(\"JSONHandler: get_names() function -  exception caught {}: {}\".format(x,e))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_pipeline = Pipeline([('imputer', SimpleImputer(strategy='median')),\n                        ('scaler', PowerTransformer())])\n\ncat_pipeline = Pipeline([('imputer', SimpleImputer(strategy='most_frequent')),\n                         ('cat_enc', OneHotEncoder(handle_unknown='ignore'))])\n\npre_process = ColumnTransformer([('drop_cols', 'drop', drop_cols),\n                                 ('num_process', num_pipeline, ['budget', 'popularity', 'runtime']),\n                                 ('add_custom_attrs', CustomAttr(), ['belongs_to_collection', 'release_date']),\n                                 ('cat_process', cat_pipeline, ['original_language', 'status']),\n                                 ('jason_handler', JSONHandler(), ['genres', 'production_companies', 'production_countries', 'Keywords', 'cast'])], remainder='passthrough')\n\nX_transformed = pre_process.fit_transform(X)\nX_transformed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train_transformed, X_test_transformed, y_train, y_test = train_test_split(X_transformed, np.log1p(y), test_size=0.2, random_state=42)\nX_train_transformed.shape, X_test_transformed.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_columns = ['budget', 'popularity', 'runtime', 'is_sequel', 'release_year', 'release_month', 'release_day', 'release_dow'] + list(pre_process.transformers_[3][1]['cat_enc'].get_feature_names(['original_language', 'status'])) + encoded_cols\nlen(feature_columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Modelling**"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import KFold\n\nkf = KFold(n_splits=5, shuffle=True, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\n\nresults = []\n\ndef performance_measures(model, store_results=True):    \n    train_rmses = cross_val_score(model, X_train_transformed, y_train, scoring='neg_root_mean_squared_error', cv=kf, n_jobs=-1)\n    train_rmses *= -1\n    train_mean_rmse = np.mean(train_rmses)\n    \n    test_rmses = cross_val_score(model, X_test_transformed, y_test, scoring='neg_root_mean_squared_error', cv=kf, n_jobs=-1)\n    test_rmses *= -1\n    test_mean_rmse = np.mean(test_rmses)\n    \n    print(\"Train Mean RMSE: {}\\nTest Mean RMSE: {}\".format(train_mean_rmse, test_mean_rmse))\n    \n    if store_results:\n        results.append([model.__class__.__name__, train_mean_rmse, test_mean_rmse])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_importance(feature_columns, importance_values):\n    feature_imp = [ col for col in zip(feature_columns, importance_values)]\n    feature_imp.sort(key=lambda x:x[1], reverse=True)\n\n    imp = pd.DataFrame(feature_imp[0:15], columns=['feature', 'importance'])\n    plt.figure(figsize=(10, 8))\n    sns.barplot(y='feature', x='importance', data=imp, orient='h')\n    plt.title('15 Most Important Features', fontsize=16)\n    plt.ylabel(\"Feature\", fontsize=16)\n    plt.xlabel(\"\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import Ridge\n\nridge_reg = Ridge(alpha=1, random_state=42)\nridge_reg.fit(X_train_transformed, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(feature_columns, ridge_reg.coef_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_measures(ridge_reg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nforest_reg = RandomForestRegressor(n_estimators=500, max_depth=16, max_features=0.2, n_jobs=-1, random_state=42)\nforest_reg.fit(X_train_transformed, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(feature_columns, forest_reg.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_measures(forest_reg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from xgboost import XGBRegressor\n\nxgb_reg = XGBRegressor(objective='reg:squarederror', n_estimators = 1000, max_depth = 14, learning_rate = 0.01, \n                       gamma=1.0, subsample = 0.7, colsample_bytree = 0.6, colsample_bylevel = 0.5, \n                       random_state=42, n_jobs=-1)\nxgb_reg.fit(X_train_transformed, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(feature_columns, xgb_reg.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_measures(xgb_reg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostRegressor\n\ncat_boost_reg = CatBoostRegressor(loss_function='RMSE', bagging_temperature = 0.3, colsample_bylevel = 0.7, \n                                  depth = 9, eval_metric = 'RMSE', iterations = 1500, \n                                  random_state=42, verbose=0)\ncat_boost_reg.fit(X_train_transformed, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(feature_columns, cat_boost_reg.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_measures(cat_boost_reg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from lightgbm import LGBMRegressor\n\nlgb_reg = LGBMRegressor(objective = 'regression', num_iterations = 100, max_depth = 12, learning_rate= 0.03, \n                        metric = 'rmse', colsample_bytree= 0.6, subsample_freq= 1, subsample= 0.5, n_jobs=-1, \n                        random_state=42)\nlgb_reg.fit(X_train_transformed, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_importance(feature_columns, lgb_reg.feature_importances_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_measures(lgb_reg)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import VotingRegressor\n\nnamed_estimators = [('cat_bost', cat_boost_reg), ('xgb_reg', xgb_reg), ('lgb_reg', lgb_reg), ('forest_reg', forest_reg), ('ridge_reg', ridge_reg)]\n\nvoting_reg = VotingRegressor(estimators=named_estimators, n_jobs=-1)\nvoting_reg.fit(X_train_transformed, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"performance_measures(voting_reg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Model Evaluation**"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame(results, columns=['Model', 'Train RMSE', 'Test RMSE'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Among all models voting regressor gives better RMLSE. I will be taking it as a final model\nNow lets see how model is performing on overall dataset. This will be helpful to understand where the model is accurate and where it is not."},{"metadata":{"trusted":true},"cell_type":"code","source":"predicted_revenue = voting_reg.predict(X_transformed)\noverall_data = X.copy()\noverall_data['revenue'] = y.copy()\noverall_data['predicted_revenue'] = np.expm1(predicted_revenue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"overall_data.head(n=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.scatterplot(x='budget', y='revenue', data=overall_data, label='Observed')\nsns.scatterplot(x='budget', y='predicted_revenue', data=overall_data, color='red', label='Predicted')\nplt.ylim(0, 750000000)\nplt.xlim(0, 250000000)\nplt.xlabel('Budget', fontsize=14)\nplt.ylabel('Revenue', fontsize=14)\nax = plt.gca()\nax.get_xaxis().get_major_formatter().set_scientific(False)\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Revenue Vs. Budget')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We can see that model is failed to predict the high revenue movies. There are many low budget high earning movies for which model has predicted less revenue.\nAlso model is less accuracte for high budget films."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10, 5))\nsns.scatterplot(x='popularity', y='revenue', data=overall_data, label='Observed')\nsns.scatterplot(x='popularity', y='predicted_revenue', data=overall_data, color='red', label='Predicted')\nplt.ylim(0, 500000000)\nplt.xlim(0, 50)\nplt.xlabel('Popularity', fontsize=14)\nplt.ylabel('Revenue', fontsize=14)\nax = plt.gca()\nax.get_xaxis().get_major_formatter().set_scientific(False)\nax.get_yaxis().get_major_formatter().set_scientific(False)\nax.set_title('Revenue Vs. Popularity')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For most popular movies, model is less accuracte.\nIt seems that model has learn that for least popular movies revenue will be less. We can see that in bottom left corner, there are least popular movies which have earn high revenue, but model has predicted less."},{"metadata":{"trusted":true},"cell_type":"code","source":"year_info = overall_data[['release_date', 'revenue', 'predicted_revenue']].copy()\nyear_info['release_date']=year_info['release_date'].apply(lambda x: modify_date(x))\nyear_info['release_year'] = pd.DatetimeIndex(year_info['release_date']).year\nyear_info = year_info.groupby(['release_year']).median()\nyear_info = year_info.sort_values('release_year')\n\nrelease_years = list(year_info.index)\nx_indexes = np.arange(len(release_years))     \nwidth = 0.25                            \n\nplt.figure(figsize=(10, 5))\nplt.bar(x_indexes,  year_info['revenue'], label=\"Median Observed Movies Revenue\", width=width)\nplt.bar(x_indexes + width,  year_info['predicted_revenue'], label=\"Median Predicted Movies Revenue\", width=width)\nplt.legend(loc=\"upper left\", fontsize=12)\nplt.xticks(ticks=x_indexes+0.5, labels=release_years, fontsize=12, rotation=-45)\nplt.title('1990-2017')\nplt.xlabel('Release Year', fontsize=12)\nplt.ylabel('Revenue', fontsize=12)\nplt.xlim(left=61.5, right=90)\nplt.ylim(top=50000000)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_indexes = np.arange(len(release_years))     \nwidth = 0.35                            \n\nplt.figure(figsize=(10, 5))\nplt.bar(x_indexes,  year_info['revenue'], label=\"Median Observed Movies Revenue\", width=width)\nplt.bar(x_indexes + width,  year_info['predicted_revenue'], label=\"Median Predicted Movies Revenue\", width=width)\nplt.legend(loc=\"upper left\", fontsize=12)\nplt.xticks(ticks=x_indexes+0.5, labels=release_years, fontsize=12, rotation=-45)\nplt.title('1960-1989')\nplt.xlabel('Release Year', fontsize=12)\nplt.ylabel('Revenue', fontsize=12)\nplt.xlim(left=32, right=62)\nplt.ylim(top=80000000)\nax = plt.gca()\nax.get_yaxis().get_major_formatter().set_scientific(False)\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"final_model = Pipeline([('pre_process', pre_process),\n                        ('voting_reg', voting_reg)])\nfinal_model.fit(X, np.log1p(y))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\nprint(test_data.shape)\ntest_data.head(n=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = final_model.predict(test_data)\npredictions = np.expm1(predictions)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output = pd.DataFrame(test_data['id'])\noutput['revenue'] = predictions.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.to_csv(\"./submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}