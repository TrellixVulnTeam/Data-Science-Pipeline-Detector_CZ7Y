{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.drop(['revenue'],axis=1)\ny_train = train['revenue']\nprint(X_train.shape, y_train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([X_train, test], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['has_homepage'] = X['homepage'].isnull() == False\nX['is_original_english'] = X['original_language'] == 'en'\nX['has_collection'] = X['belongs_to_collection'].isnull() == False\nX['has_two_titles'] = X['original_title'] != X['title']\nX.drop(['status','original_language','poster_path', 'homepage', 'imdb_id','belongs_to_collection', 'id'], axis=1, inplace=True)\nX.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.loc[pd.isnull(X['spoken_languages']) == True,'spoken_languages'] = 0\nX['lang'] = list(map(lambda x: [i['iso_639_1'] for i in eval(x)] if x!=0 else [], X['spoken_languages'].values))\nX['n_lang'] = X['lang'].apply(lambda x: len(x))\n\n# temp_lang = ' '.join(list(map(lambda x: ' '.join(x), X['lang']))).split(' ')\n\nspoken_features = ['' + i for i in ['', 'la', 'it', 'cs', 'ta', 'pt', 'hu', 'zh', 'pl', 'ar', 'en', 'ja', 'de', 'ko', 'cn', 'tr',\n 'he', 'sv', 'el', 'ru', 'fr', 'es', 'hi', 'th']]\n\nfor i in spoken_features:\n    X[i] = X['lang'].apply(lambda x: i[7:] in x)\n\nX.drop(['original_title', 'spoken_languages', 'lang'], axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.loc[pd.isnull(X['genres']) == True,'genres'] = 0\ngenres = set(' '.join([' '.join(i) for i in list(map(lambda x: [i['name'] for i in eval(x)] if x!=0 else [], X['genres'].values))]).split())\n\nX['genres'] = list(map(lambda x: [i['name'] for i in eval(x)] if x!=0 else [], X['genres'].values))\n\nfor i in genres:\n    X['genre_' + i] = X['genres'].apply(lambda x: i in x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['n_genres'] =  X['genres'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['release_month'] = 0\nX['release_day'] = 0\nX['release_year'] = 0\n\nX = pd.concat([X, X['release_date'].str.split('/', expand=True)], axis=1)\nX.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.iloc[:,-1] = X.iloc[:,-1].fillna('0').astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"year_mod = []\nfor i in X.iloc[:,-1].values:\n    if i in range(0, 19):\n        year_mod.extend([2000 + i])\n    else:\n        year_mod.extend([1900 + i])\nyear_mod\n\nX['release_year'] = year_mod","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = pd.concat([X, pd.get_dummies(X[0], prefix='release_month')], axis=1)\nX.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['release_date'] = pd.to_datetime(X['release_date'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['release_weekday'] = X['release_date'].dt.weekday.fillna(8).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.loc[:,'production_companies'] = X.loc[:,'production_companies'].fillna('[]')\n\ncompanies = ','.join([','.join(i) for i in list(map(lambda x: [i['name'] for i in eval(x)], X['production_companies'].values))]).split(',')\nunique_companies = set(companies)\n# print(companies)\n\nX['production_companies'] = list(map(lambda x: [i['name'] for i in eval(x)], X['production_companies'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_count = {i: sum([1 for j in companies if i == j]) for i in unique_companies}\n\nmost_famous_prod = [k for k,v in prod_count.items() if v > 100 and k]\nfamous_prod = [k for k,v in prod_count.items() if 30 <= v < 100 and k]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['n_production_companies'] = X['production_companies'].apply(lambda x: len(x))\nX['most_famous_prod'] = X['production_companies'].apply(lambda x: sum([1 for i in x if i in most_famous_prod]))\nX['famous_prod'] = X['production_companies'].apply(lambda x: sum([1 for i in x if i in famous_prod]))\nX.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.loc[:,'production_countries'] = X.loc[:,'production_countries'].fillna('[]')\n\ncountries = ','.join([','.join(i) for i in list(map(lambda x: [i['iso_3166_1'] for i in eval(x)], X['production_countries'].values))]).split(',')\nunique_countries = set(countries)\n# print(unique_countries)\n\nX['production_countries'] = list(map(lambda x: [i['iso_3166_1'] for i in eval(x)], X['production_countries'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"country_count = {i: sum([1 for j in countries if i == j]) for i in unique_countries}\n# sorted(country_count.items(), key=lambda x: x[1], reverse=True)\n\nmost_famous_countries= [k for k,v in country_count.items() if v > 100 and k]\nfamous_countries = [k for k,v in country_count.items() if 30 <= v < 100 and k]\n\nX['n_production_countries'] = X['production_countries'].apply(lambda x: len(x))\nX['most_famous_countries'] = X['production_countries'].apply(lambda x: sum([1 for i in x if i in most_famous_countries]))\nX['famous_countries'] = X['production_countries'].apply(lambda x: sum([1 for i in x if i in famous_countries]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['has_tagline'] = X['tagline'].apply(lambda x: pd.isnull(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.drop(['genres', 'overview', 'production_companies', 'production_countries', 'release_date', 'tagline', 'release_month', 'release_day', 0, 2,\n       'title', 'Keywords', 'cast','crew'], axis=1, inplace=True)\nX.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['runtime'] = X['runtime'].fillna(X['runtime'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X[1] = X[1].fillna(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for f in X.dtypes[X.dtypes == 'bool'].index:\n    X[f] = X[f].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['popularity'] = (X['popularity'] - X['popularity'].mean()) / (X['popularity'].max()-X['popularity'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['runtime'] = (X['runtime'] - X['runtime'].mean()) / (X['runtime'].max()-X['runtime'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['inflationBudget'] = X['budget'] + X['budget']*1.8/100*(2019-X['release_year'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X['budget'] = (X['budget'] - X['budget'].mean()) / (X['budget'].max()-X['budget'].min())\nX['inflationBudget'] = (X['inflationBudget'] - X['inflationBudget'].mean()) / (X['inflationBudget'].max()-X['inflationBudget'].min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = X.reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LinearRegression\n\nregressor = LinearRegression(normalize=True)\nregressor.fit(X[:X_train.shape[0]], y_train)\n\ny_test_pred = regressor.predict(X[X_train.shape[0]:])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test_pred.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import mean_squared_log_error, make_scorer\n\nscore = cross_val_score(regressor, X[:X_train.shape[0]], y_train)\n(abs(score[0]) + abs(score[1]) + abs(score[2]))/3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import xgboost as xgb\n\n# def xgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n#     params = {'objective': 'reg:linear', \n#               'eta': 0.01, \n#               'max_depth': 6, \n#               'subsample': 0.6, \n#               'colsample_bytree': 0.7,  \n#               'eval_metric': 'rmse', \n#               'seed': random_seed, \n#               'silent': True,\n#     }\n    \n#     record = dict()\n#     model = xgb.train(params\n#                       , xgb.DMatrix(trn_x, trn_y)\n#                       , 100000\n#                       , [(xgb.DMatrix(trn_x, trn_y), 'train'), (xgb.DMatrix(val_x, val_y), 'valid')]\n#                       , verbose_eval=verbose\n#                       , early_stopping_rounds=500\n#                       , callbacks = [xgb.callback.record_evaluation(record)])\n#     best_idx = np.argmin(np.array(record['valid']['rmse']))\n\n#     val_pred = model.predict(xgb.DMatrix(val_x), ntree_limit=model.best_ntree_limit)\n#     test_pred = model.predict(xgb.DMatrix(test), ntree_limit=model.best_ntree_limit)\n\n#     return {'val':val_pred, 'test':test_pred, 'error':record['valid']['rmse'][best_idx], 'importance':[i for k, i in model.get_score().items()]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import lightgbm as lgb\n\n# def lgb_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n\n#     params = {'objective':'regression',\n#          'num_leaves' : 30,\n#          'min_data_in_leaf' : 20,\n#          'max_depth' : 9,\n#          'learning_rate': 0.004,\n#          #'min_child_samples':100,\n#          'feature_fraction':0.9,\n#          \"bagging_freq\": 1,\n#          \"bagging_fraction\": 0.9,\n#          'lambda_l1': 0.2,\n#          \"bagging_seed\": random_seed,\n#          \"metric\": 'rmse',\n#          #'subsample':.8, \n#           #'colsample_bytree':.9,\n#          \"random_state\" : random_seed,\n#          \"verbosity\": -1}\n\n#     record = dict()\n#     model = lgb.train(params\n#                       , lgb.Dataset(trn_x, trn_y)\n#                       , num_boost_round = 100000\n#                       , valid_sets = [lgb.Dataset(val_x, val_y)]\n#                       , verbose_eval = verbose\n#                       , early_stopping_rounds = 500\n#                       , callbacks = [lgb.record_evaluation(record)]\n#                      )\n#     best_idx = np.argmin(np.array(record['valid_0']['rmse']))\n\n#     val_pred = model.predict(val_x, num_iteration = model.best_iteration)\n#     test_pred = model.predict(test, num_iteration = model.best_iteration)\n    \n#     return {'val':val_pred, 'test':test_pred, 'error':record['valid_0']['rmse'][best_idx], 'importance':model.feature_importance('gain')}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from catboost import CatBoostRegressor\n\n# def cat_model(trn_x, trn_y, val_x, val_y, test, verbose) :\n    \n#     model = CatBoostRegressor(iterations=100000,\n#                                  learning_rate=0.004,\n#                                  depth=5,\n#                                  eval_metric='RMSE',\n#                                  colsample_bylevel=0.8,\n#                                  random_seed = random_seed,\n#                                  bagging_temperature = 0.2,\n#                                  metric_period = None,\n#                                  early_stopping_rounds=200\n#                                 )\n#     model.fit(trn_x, trn_y,\n#                  eval_set=(val_x, val_y),\n#                  use_best_model=True,\n#                  verbose=False)\n    \n#     val_pred = model.predict(val_x)\n#     test_pred = model.predict(test)\n    \n#     return {'val':val_pred, \n#             'test':test_pred, \n#             'error':model.get_best_score()['validation_0']['RMSE']}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# result_dict = dict()\n# val_pred = np.zeros(train.shape[0])\n# test_pred = np.zeros(test.shape[0])\n# final_err = 0\n# verbose = False\n\n# for i, (trn, val) in enumerate(fold) :\n#     print(i+1, \"fold.    RMSE\")\n    \n#     trn_x = train.loc[trn, :]\n#     trn_y = y[trn]\n#     val_x = train.loc[val, :]\n#     val_y = y[val]\n    \n#     fold_val_pred = []\n#     fold_test_pred = []\n#     fold_err = []\n    \n#     #\"\"\" xgboost\n#     start = datetime.now()\n#     result = xgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n#     fold_val_pred.append(result['val']*0.2)\n#     fold_test_pred.append(result['test']*0.2)\n#     fold_err.append(result['error'])\n#     print(\"xgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n#     #\"\"\"\n    \n#     #\"\"\" lightgbm\n#     start = datetime.now()\n#     result = lgb_model(trn_x, trn_y, val_x, val_y, test, verbose)\n#     fold_val_pred.append(result['val']*0.4)\n#     fold_test_pred.append(result['test']*0.4)\n#     fold_err.append(result['error'])\n#     print(\"lgb model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n#     #\"\"\"\n    \n#     #\"\"\" catboost model\n#     start = datetime.now()\n#     result = cat_model(trn_x, trn_y, val_x, val_y, test, verbose)\n#     fold_val_pred.append(result['val']*0.4)\n#     fold_test_pred.append(result['test']*0.4)\n#     fold_err.append(result['error'])\n#     print(\"cat model.\", \"{0:.5f}\".format(result['error']), '(' + str(int((datetime.now()-start).seconds/60)) + 'm)')\n#     #\"\"\"\n    \n#     # mix result of multiple models\n#     val_pred[val] += np.mean(np.array(fold_val_pred), axis = 0)\n#     #print(fold_test_pred)\n#     #print(fold_test_pred.shape)\n#     #print(fold_test_pred.columns)\n#     test_pred += np.mean(np.array(fold_test_pred), axis = 0) / k\n#     final_err += (sum(fold_err) / len(fold_err)) / k\n    \n#     print(\"---------------------------\")\n#     print(\"avg   err.\", \"{0:.5f}\".format(sum(fold_err) / len(fold_err)))\n#     print(\"blend err.\", \"{0:.5f}\".format(np.sqrt(np.mean((np.mean(np.array(fold_val_pred), axis = 0) - val_y)**2))))\n    \n#     print('')\n    \n# print(\"fianl avg   err.\", final_err)\n# print(\"fianl blend err.\", np.sqrt(np.mean((val_pred - y)**2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/sample_submission.csv')\nsubmission['revenue'] = y_test_pred\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a href=\"./submission.csv\"> Download File </a>"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}