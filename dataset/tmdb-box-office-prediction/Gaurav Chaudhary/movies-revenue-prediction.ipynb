{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV ,KFold, cross_val_score, train_test_split\nfrom sklearn.linear_model import ElasticNet, Lasso\nfrom sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MultiLabelBinarizer ,LabelEncoder\nfrom sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\nfrom sklearn.metrics import mean_squared_error\nimport lightgbm as lgb\nimport xgboost\nimport math\nimport ast\nfrom datetime import datetime\nimport calendar\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom scipy.special import boxcox1p\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/train.csv')\ntest_data = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def nullColumns(train_data):\n    list_of_nullcolumns =[]\n    for column in train_data.columns:\n        total= train_data[column].isna().sum()\n        try:\n            if total !=0:\n                print('Total Na values is {0} for column {1}' .format(total, column))\n                list_of_nullcolumns.append(column)\n        except:\n            print(column,\"-----\",total)\n    print('\\n')\n    return list_of_nullcolumns\n\n\ndef percentMissingFeature(data):\n    data_na = (data.isnull().sum() / len(data)) * 100\n    data_na = data_na.drop(data_na[data_na == 0].index).sort_values(ascending=False)[:30]\n    missing_data = pd.DataFrame({'Missing Ratio' :data_na})\n    print(missing_data.head(20))\n    return data_na\n\n\ndef plotMissingFeature(data_na):\n    f, ax = plt.subplots(figsize=(15, 12))\n    plt.xticks(rotation='90')\n    if(data_na.empty ==False):\n        sns.barplot(x=data_na.index, y=data_na)\n        plt.xlabel('Features', fontsize=15)\n        plt.ylabel('Percent of missing values', fontsize=15)\n        plt.title('Percent missing data by feature', fontsize=15)\n\ndef extract_key_val(df,colname):\n    \n    for idx, row in df.iterrows():\n        \n        try:\n            y =ast.literal_eval(row[colname])  \n            z= []\n            for i in y:\n                z.append(i['name'])\n            df[colname][idx] = z\n        \n        except Exception as e:\n            print(idx ,e)\n    \n    return df\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"listOfNullColumns = nullColumns(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"listOfNullColumns = nullColumns(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['revenue'] = 0\ncombined_data = pd.concat([train_data,test_data],axis =0)\ncombined_data = combined_data.reset_index(drop = True)\ncombined_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_column =combined_data.pop('revenue')[:3000]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_data =combined_data.drop(columns=['belongs_to_collection','homepage','poster_path','id'],axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def correct_year(df,colname):\n    \n    df[colname] = df[colname].apply(lambda x : (x-100) if x>2017 else x)\n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_date_features(calendar,colname):\n    \n    df = pd.DataFrame()\n    \n    df['Year'] = pd.to_datetime(calendar[colname]).dt.year\n\n    df['Month'] = pd.to_datetime(calendar[colname]).dt.month\n\n    df['Day'] = pd.to_datetime(calendar[colname]).dt.day\n\n    df['Dayofweek'] = pd.to_datetime(calendar[colname]).dt.dayofweek\n\n    df['DayOfyear'] = pd.to_datetime(calendar[colname]).dt.dayofyear\n\n    df['Week'] = pd.to_datetime(calendar[colname]).dt.week\n\n    df['Quarter'] = pd.to_datetime(calendar[colname]).dt.quarter \n\n    df['Is_month_start'] = pd.to_datetime(calendar[colname]).dt.is_month_start\n\n    df['Is_month_end'] = pd.to_datetime(calendar[colname]).dt.is_month_end\n\n    df['Is_quarter_start'] = pd.to_datetime(calendar[colname]).dt.is_quarter_start\n\n    df['Is_quarter_end'] = pd.to_datetime(calendar[colname]).dt.is_quarter_end\n\n    df['Is_year_start'] = pd.to_datetime(calendar[colname]).dt.is_year_start\n\n    #df['Is_year_end'] = pd.to_datetime(calendar[colname]).dt.is_year_end\n\n    df['Semester'] = np.where(df['Quarter'].isin([1,2]),1,2)\n\n    df['Is_weekend'] = np.where(df['Dayofweek'].isin([5,6]),1,0)\n\n    df['Is_weekday'] = np.where(df['Dayofweek'].isin([0,1,2,3,4]),1,0)\n\n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_features = generate_date_features(combined_data,'release_date')\ndate_features = correct_year(date_features,'Year')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"date_features.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_data = pd.concat([date_features,combined_data],axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize =(20,20))\nplt.xticks(rotation='90')\nsns.pointplot(combined_data.loc[:3000,'Year'],target_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nsns.barplot(combined_data.loc[:3000,'original_language'],target_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"combined_data['genres'] = combined_data['genres'].fillna('[{\"id\": 9999, \"name\": \"unknown1\"}]')\n#train_data['production_companies'] = train_data['production_companies'].fillna('[{\"id\": 9999, \"name\": \"unknown2\"}]')\n#train_data['production_countries'] = train_data['production_countries'].fillna('[{\"iso_3166_1\": \"unknown3\", \"name\": \"unknown4\"}]')\n#train_data['spoken_languages'] = train_data['spoken_languages'].fillna('[{\"iso_639_1\": \"unknown5\", \"name\": \"unknown6\"}]')\n#train_data['Keywords'] = train_data['Keywords'].fillna('[{\"id\": \"unknown7\", \"name\": \"unknown8\"}]')\n#train_data['cast'] = train_data['cast'].fillna('[{\"cast_id\": \"unknown9\", \"name\": \"unknown10\"}]')\n#train_data['runtime'] =train_data['runtime'].fillna(train_data['runtime'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = extract_key_val(combined_data,'genres')\n#extract_vals(train_data,'production_companies')\n#extract_vals(train_data,'production_countries')\n#extract_vals(train_data,'spoken_languages')\n#extract_vals(train_data,'Keywords')\n#extract_vals(train_data,'cast')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nsns.distplot(target_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_column = np.log1p(target_column[:3000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (20,20))\nsns.distplot(target_column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#lb = LabelEncoder()\n#df['original_language'] = lb.fit_transform(df['original_language'])\nmlb = MultiLabelBinarizer()\n#df['original_language'] = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"original_language\"]),columns=mlb.classes_, index=df.index)],axis =1)\ndf = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"genres\"]),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"production_companies\"]),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"production_countries\"]),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"Keywords\"].apply(lambda x :x[0:1])),columns=mlb.classes_, index=df.index)],axis =1)\n#df = pd.concat([df,pd.DataFrame(mlb.fit_transform(df[\"cast\"].apply(lambda x : x[0:2])),columns=mlb.classes_, index=df.index)],axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['count_genres'] = df['genres'].apply(lambda x : len(x))\n#df['noofPrCom'] = df[\"production_companies\"].apply(lambda x : len(x))\n#df['noofPrCou'] = df[\"production_countries\"].apply(lambda x : len(x))\n#df['noofkey'] = df[\"Keywords\"].apply(lambda x : len(x))\n#df['noofcast'] = df[\"cast\"].apply(lambda x : len(x))\n#df['noofspokenlang'] =df[\"spoken_languages\"].apply(lambda x : len(x))\n#df['sequel'] = mlb.fit_transform(df[\"Keywords\"])[:,5869]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for col in df.columns:\n    if df.dtypes[col] != 'O':\n        #print(col)\n        df[col] =boxcox1p(df[col],0.15)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(columns = ['release_date'\n                                ,'imdb_id'\n                                ,'title'\n                                ,'overview'\n                                ,'production_companies'\n                                ,'production_countries'\n                                ,'spoken_languages'\n                                ,'status'\n                                ,'tagline'\n                                ,'title'\n                                ,'cast'\n                                ,'crew'\n                                ,'Keywords'\n                                ,'original_language'\n                                ,'genres'\n                                ,'original_title'\n                                ,'TV Movie'\n                                ,'unknown1'\n                               ])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_val,y_train,y_val = train_test_split(df.iloc[:3000,:],target_column,test_size =0.2,random_state = 1001)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def RMSLE(y, y_pred):     \n    assert len(y) == len(y_pred)\n    terms_to_sum = []\n    for p , a in zip(y_pred,y):\n        terms_to_sum.append((math.log(p + 1) - math.log(a + 1)) ** 2.0)\n    \n    return 'RMSLE',(sum(terms_to_sum) * (1.0/len(y))) ** 0.5, False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def feature_importance(model, X_train=X_train):\n\n    print(model.feature_importances_)\n    names = X_train.columns.values\n    ticks = [i for i in range(len(names))]\n    plt.bar(ticks, model.feature_importances_)\n    plt.xticks(ticks, names,rotation =90)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_submission_file(model_list):\n    preds = 0\n    submission = pd.read_csv('../input/tmdb-box-office-prediction/sample_submission.csv')\n    for model in model_list:\n        preds = preds + np.expm1(model.predict(df.iloc[3000:,:]))\n    submission.loc[:,'revenue'] = preds/len(model_list)\n    !rm './submission.csv'\n    submission.to_csv('submission.csv', index = False, header = True)\n    print(submission.head())\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_xgb = xgboost.XGBRegressor(colsample_bytree=0.4, gamma=0.045, \n                             learning_rate=0.1, max_depth=6, \n                             min_child_weight=1.7817, n_estimators=1000,\n                             reg_alpha=0.45, reg_lambda=0.8,\n                             subsample=0.5213, silent=1,\n                             random_state =7, nthread = -1,seed=42)\n\nmodel_xgb.fit(X_train,y_train,eval_set=[(X_train, y_train), (X_val, y_val)],\n        eval_metric='rmsle',\n        early_stopping_rounds = 50,\n        verbose=2)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize =(20,20))\nfeature_importance(model_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LightGBM Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lgb = lgb.LGBMRegressor(bagging_fraction=0.8, bagging_frequency=4, boosting_type='gbdt',\n              class_weight=None, colsample_bytree=1.0, feature_fraction=0.5,\n              importance_type='split', learning_rate=0.1, max_depth=3,\n              min_child_samples=20, min_child_weight=30, min_data_in_leaf=70,\n              min_split_gain=0.0001, n_estimators=200, n_jobs=-1,\n              num_leaves=1200, objective='regression' ,random_state=101, reg_alpha=0.2,\n              reg_lambda=0.6, silent=True, subsample=1.0,\n              subsample_for_bin=200000, subsample_freq=0)\n\nmodel_lgb.fit(X_train, y_train,eval_set=[(X_train, y_train), (X_val, y_val)],\n        eval_metric=RMSLE,\n        early_stopping_rounds = 100,\n        verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize =(20,20))\nfeature_importance(model_xgb)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"create_submission_file([model_lgb,model_xgb])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}