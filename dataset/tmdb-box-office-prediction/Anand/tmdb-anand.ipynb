{"cells":[{"metadata":{},"cell_type":"markdown","source":"### TMDB revenue forecasting contest"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport math\nimport random\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\nimport sklearn as sk\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime\nimport ast\nimport warnings\nimport json\n\nimport itertools\nfrom collections import Counter\n\n\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import mean_squared_error\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport xgboost as xgb\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import train_test_split\n\n# Any results you write to the current directory are saved as output.\n%matplotlib inline\nwarnings.filterwarnings('ignore')","execution_count":2,"outputs":[{"output_type":"stream","text":"['test.csv', 'train.csv', 'sample_submission.csv']\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"sns.set(style ='darkgrid')\nsns.set(palette = 'muted')\ncol = sns.color_palette()\nsns.palplot(col)","execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 720x72 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAkgAAABQCAYAAADiBIpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAAsxJREFUeJzt2S9r1VEAxvGz/xr2h22ozbIV8QWILPkODEaRBZNJnCiIiGFlDgRBDAYZRt+DyWCyGGexiIxt3M2g806v5WJ4mpcdzhyfTznpwPMrP75whnq9Xq8AAPDXcOsBAADHjUACAAgCCQAgCCQAgCCQAACCQAIACAIJACAIJACAIJAAAIJAAgAIAgkAIAgkAIAwOujFOy82y/Z+9yi3HBsb9y6UvefLrWdUM33rVXn48X7rGVXc2DgsC+vr5dPKSuspVSysr5fXj962nlHN9cdXysu711rPqObmkzfl89P3rWdUc/72pbK2ttZ6RhVXL++VxaXVsvnuQespVSwurZZnH760nlHF5PhIWb549p/vDRxI2/vdstU5mYFUSim/97ZaT6hq9+dO6wlVdLe7/XO78ZJ6vu1+bz2hqv2dr60nVHXYOWg9oapOp9N6QhXdH7v982T+O0spZe/gV+sJx4onNgCAIJAAAIJAAgAIAgkAIAgkAIAgkAAAgkACAAgCCQAgCCQAgCCQAACCQAIACAIJACAIJACAIJAAAIJAAgAIAgkAIAgkAIAgkAAAgkACAAgCCQAgCCQAgCCQAACCQAIACAIJACAIJACAIJAAAIJAAgAIAgkAIAgkAIAgkAAAgkACAAgCCQAgCCQAgCCQAACCQAIACAIJACAIJACAIJAAAIJAAgAIAgkAIAgkAIAgkAAAgkACAAgCCQAgCCQAgCCQAACCQAIACAIJACAIJACAIJAAAIJAAgAIo4NenJ8aO8odx87w9JnWE6qaHZ9rPaGKsfnD/jnfeEk9k7OnW0+oamruXOsJVY3OTLSeUNXMzEzrCVWMnRrqnyfz31lKKdMTI60nVDE5Pth3DfV6vd4RbwEA+K95YgMACAIJACAIJACAIJAAAIJAAgAIAgkAIAgkAIAgkAAAgkACAAgCCQAgCCQAgCCQAADCH1TgVG4Hqz9HAAAAAElFTkSuQmCC\n"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"### Plot multiple Y axes for a common X axis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_2y(df,x,y1,y2):\n    fig,ax1 = plt.subplots(figsize = (15,10))\n    ax1.plot(df[x],df[y1],'ro-')\n    ax2 =ax1.twinx()\n    ax2.plot(df[x], df[y2],'bo-')\n    ax1.set_xlabel(x)\n    ax1.set_ylabel(y1)\n    ax2.set_ylabel(y2)\n    if x == 'Month ':\n        plt.title('Monthly delay incidents between '+ str(df['Month '].dt.year.min()) + ' and ' + str(df['Month '].dt.year.max()))\n    else:\n        plt.title(y1+' and '+ y2 +' vs '+ x)\n    ax1.legend()\n    ax2.legend(loc=1)\n    plt.xticks(rotation = 45)\n    plt.tight_layout()\n    plt.show()","execution_count":4,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot multiple scatter plots for the same independent variable"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_scatter(df,xdata,ydata1,ydata2=None,ydata3=None):\n    plt.figure(figsize = (15,10))\n    plt.scatter(df[xdata],df[ydata1],c='r')\n    if pd.notna(ydata2):\n        plt.scatter(df[xdata],df[ydata2],c='b')\n        if pd.notna(ydata3):\n            plt.scatter(df[xdata],df[ydata3],c='k')\n    else:\n        plt.ylabel(ydata1)\n    plt.xlabel(xdata)\n    plt.title(ydata1 + ' vs ' + xdata)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plot boxplots for boolean features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def booleanBoxPlot(df, bool_feature, other_feature, lang):\n    \"\"\" Box plot of values of other_feature when bool_feature == True and \n    bool__feature == False\"\"\"\n    \n    fig = plt.figure(figsize=(15, 10))\n    \n    sns.boxplot(x = bool_feature, y = other_feature, data = df, whis=[10, 90], showfliers  = False)\n    plt.xlabel(bool_feature)\n    plt.ylabel(other_feature)\n    \n    title = other_feature + ' distributed by ' + bool_feature + ' for ' + lang\n    plt.suptitle(title)","execution_count":6,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to round up to the nearest integer that is larger than x"},{"metadata":{"trusted":true},"cell_type":"code","source":"def roundup(x):\n    return int(math.floor(x/10.0)) * 10","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to convert JSON fields into dictionaries"},{"metadata":{"trusted":true},"cell_type":"code","source":"def json_to_dict(df, field):\n     df.loc[df[field].notnull(), field] = df.loc[df[field].notnull(),field].apply(lambda x: x.lstrip('\\\"([').rstrip(']\\\")')).apply(eval) ","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_json_dict(s):\n    \"\"\" indirect way of converting json into python dictionary \"\"\"\n    try:\n        d = eval(s)\n    except:\n        d = {}\n    return d","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_director(df):\n    for index,row in df.iterrows():\n        allCrew = get_json_dict(row['crew'])\n        director = next((x['name'] for x in allCrew if ('name' in x) and ('job' in x) and (x['job'] == 'Director')),None)\n        df.loc[index,'Director'] = director","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_cast(df):\n    for index,row in df.iterrows():\n        allCast = get_json_dict(row['cast'])\n        lead = next((x['name'] for x in allCast if ('name' in x)),None)\n        df.loc[index,'Lead'] = lead","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Function to convert dictionary to a list of values in the dictionary"},{"metadata":{"trusted":true},"cell_type":"code","source":"def dict_to_list(df, field):\n    if field == 'genres':\n        findex = 1\n    else:\n        findex = 0\n    for index,row in df.loc[df[field].notna(),field].iteritems():\n        if type(row) is dict:\n            df.loc[index,field] = list(row.values())[findex]\n        elif type(row) is tuple:\n            field_list = []\n            for i in np.arange(len(row)):\n                field_list.append(list(row[i].values())[findex])\n            df.at[index,field] = field_list","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to transform raw data - convert everything to log and perform one-hot encoding on selected features"},{"metadata":{"trusted":true},"cell_type":"code","source":"def transform_ridge(df, top_languages = [], top_directors = [], top_cast = [], additional = 0, ohe_director = 0, ohe_cast = 0):\n\n    df_copy = df.copy()\n    df_copy['release_date'] = pd.to_datetime(df_copy['release_date'], infer_datetime_format = True)\n    df_copy['year'] = df_copy.loc[df_copy['release_date'].notna(),'release_date'].dt.year\n    df_copy['year'] = df_copy['year'].apply(lambda x: x-100 if x> 2019 else x)\n    df_copy['year'].fillna(df_copy['year'].median(), inplace = True)\n    df_copy['year'] = df_copy['year'].astype('int64')\n    \n    df_copy['dayofrelease'] = df_copy.loc[df_copy['release_date'].notna(),'release_date'].dt.dayofweek\n    df_copy['dayofrelease'].fillna(df_copy['dayofrelease'].median(),inplace = True)\n        \n    # No budget correction except changing all 0 values to 1\n    df_copy.loc[df_copy['budget'] == 0,'budget'] = 1\n    df_copy['log_budget'] = df_copy['budget'].apply(math.log)  \n    \n    # Run time of the movie\n    df_copy['runtime'].fillna(df_copy['runtime'].median(),inplace = True)\n    \n    # One hot encoding of collection and homepage\n    df_copy.loc[df_copy['belongs_to_collection'].notna(),'belongs_to_collection'] = 1\n    df_copy.loc[df_copy['belongs_to_collection'].isna(),'belongs_to_collection'] = 0\n    \n    df_copy.loc[df_copy['homepage'].notna(),'homepage'] = 1\n    df_copy.loc[df_copy['homepage'].isna(),'homepage'] = 0\n    \n    df_copy.loc[df_copy['tagline'].notna(),'has_tag'] = 1\n    df_copy.loc[df_copy['tagline'].isna(),'has_tag'] = 0\n    \n    df_copy.loc[df_copy['status'] == 'Released','released'] = 1\n    df_copy.loc[df_copy['status'] == 'Post Production','released'] = 0\n    df_copy.loc[df_copy['status'] == 'Rumored','released'] = 0\n    df_copy.loc[df_copy['status'].isna(),'released'] = 0\n    \n    # df_copy['popularity'] = np.log(df_copy['popularity'])\n    features = ['year','dayofrelease','log_budget','runtime','belongs_to_collection','homepage', 'has_tag', 'released','popularity']\n    \n    if 'revenue' in df.columns:\n        top_languages = list(train['original_language'].value_counts().index[0:10])\n        df_copy.loc[~df_copy['original_language'].isin(top_languages),'original_language'] = 'other lang'\n        # One hot encoding of top 10 original languages and the rest as others\n        ohe = OneHotEncoder(handle_unknown='ignore')\n        lang_ohe = ohe.fit_transform(np.array(df_copy['original_language']).reshape(-1,1))\n        df_copy_lang = pd.DataFrame(data = lang_ohe.toarray(), columns = ohe.categories_[0])\n        top_languages = ohe.categories_[0]\n\n    else:\n        df_copy.loc[~df_copy['original_language'].isin(top_languages), 'original_language'] ='other lang'\n        ohe = OneHotEncoder(handle_unknown='ignore')\n        lang_ohe = ohe.fit_transform(np.array(df_copy['original_language']).reshape(-1,1))\n        df_copy_lang = pd.DataFrame(data = lang_ohe.toarray(), columns = ohe.categories_[0])\n    \n    df_copy = df_copy.merge(df_copy_lang, left_index = True, right_index = True) \n    features.extend(top_languages)\n    \n    # If this flag is set, then we add the additional features like genre, production countries etc. \n    if additional == 1:\n        json_to_dict(df_copy,'production_countries')\n        dict_to_list(df_copy,'production_countries')\n        df_copy['US production'] = df.loc[df['production_countries'].notnull(),'production_countries'].apply(lambda x: 1 if 'US' in x else 0)\n        df_copy['US production'].fillna(0,inplace = True)\n        features.append('US production')\n\n        big_productions = ['Paramount Pictures','Universal Pictures','Metro-Goldwyn-Mayer (MGM)', 'Warner Bros.','Twentieth Century Fox Film Corporation']\n        json_to_dict(df_copy,'production_companies')\n        dict_to_list(df_copy,'production_companies')\n        df_copy['Big production'] = df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'].apply(lambda x: 1 if any(comp in x for comp in big_productions) else 0)\n        df_copy['Big production'].fillna(0,inplace = True)\n        features.append('Big production')\n        \n        df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'] = df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'].apply(lambda x: [x] if type(x) is str else x)\n        df_copy['no_production_companies'] = df_copy.loc[df_copy['production_companies'].notnull(),'production_companies'].apply(len)\n        df_copy['no_production_companies'].fillna(0,inplace = True)\n        features.append('no_production_companies')\n        \n        top_genres = ['Drama','Comedy','Action','Thriller','Romance']\n        json_to_dict(df_copy,'genres')\n        dict_to_list(df_copy,'genres')\n        df_copy['Top genres'] = df_copy.loc[df_copy['genres'].notnull(),'genres'].apply(lambda x: 1 if any(genre in x for genre in top_genres) else 0)\n        df_copy['Top genres'].fillna(0, inplace = True)\n        features.append('Top genres')\n        \n        json_to_dict(df_copy,'spoken_languages')\n        dict_to_list(df_copy,'spoken_languages')\n        df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'] = df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'].apply(lambda x: [x] if type(x) is str else x)\n        df_copy['no_languages'] = df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'].apply(len)\n        df_copy['no_languages'].fillna(0,inplace = True)\n        features.append('no_languages')\n        \n        df_copy.loc[df_copy['spoken_languages'].notnull(),'english_spoken'] = df_copy.loc[df_copy['spoken_languages'].notnull(),'spoken_languages'].apply(lambda x: 1 if 'en' in x else 0) \n        df_copy['english_spoken'].fillna(0, inplace = True)\n        features.append('english_spoken')\n        \n        get_director(df_copy)\n        if 'revenue' in df.columns:\n            # revenue_cutoff = df_copy['revenue'].min() + (0.75) * (df_copy['revenue'].max() - df_copy['revenue'].min())\n            revenue_cutoff = df_copy['revenue'].quantile(0.75)\n            top_movies    = df_copy.loc[df_copy['revenue'] >= revenue_cutoff]\n            top_directors = list(top_movies['Director'].value_counts().index[0:10])\n            \n        if ohe_director == 1:\n            df_copy.loc[~df_copy['Director'].isin(top_directors), 'Director'] = 'other dir'\n            direct_ohe = ohe.fit_transform(np.array(df_copy['Director']).reshape(-1,1))\n            df_copy_direct = pd.DataFrame(data = direct_ohe.toarray(), columns = ohe.categories_[0])\n            top_directors = ohe.categories_[0]\n            df_copy = df_copy.merge(df_copy_direct, left_index = True, right_index = True)\n            features.extend(top_directors)\n        else:\n            df_copy.loc[df_copy['Director'].notnull(),'top_directors'] = df_copy.loc[df_copy['Director'].notnull(),'Director'].apply(lambda x: 1 if x in top_directors else 0)\n            df_copy['top_directors'].fillna(0,inplace = True)\n            features.append('top_directors')\n        \n        get_cast(df_copy)\n        if 'revenue' in df.columns:\n            revenue_cutoff = df_copy['revenue'].quantile(0.75)\n            top_movies     = df_copy.loc[df_copy['revenue'] >= revenue_cutoff]\n            top_cast       = list(top_movies['Lead'].value_counts().index[0:10]) \n        if ohe_cast == 1:\n            df_copy.loc[~df_copy['Lead'].isin(top_cast), 'Lead'] = 'other actors'\n            cast_ohe = ohe.fit_transform(np.array(df_copy['Lead']).reshape(-1,1))\n            df_copy_cast = pd.DataFrame(data = cast_ohe.toarray(), columns = ohe.categories_[0])\n            top_cast = ohe.categories_[0]\n            df_copy = df_copy.merge(df_copy_cast, left_index = True, right_index = True)\n            features.extend(top_cast)\n        else:\n            df_copy.loc[df_copy['Lead'].notnull(),'top_cast'] = df_copy.loc[df_copy['Lead'].notnull(),'Lead'].apply(lambda x: 1 if x in top_cast else 0)\n            df_copy['top_cast'].fillna(0, inplace = True)\n            features.append('top_cast')\n        \n        if 'revenue' in df_copy.columns:\n            df_copy['log_revenue'] = df_copy['revenue'].apply(math.log)\n            features.append('log_revenue')\n        df_out = df_copy[features]\n        print(df_out.columns)\n    return df_out, top_languages, top_directors, top_cast","execution_count":13,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function for cross-validation to estimate the best $\\alpha$ value"},{"metadata":{"trusted":true},"cell_type":"code","source":" def cross_validation(train_df, k = 1):\n    # alpha_val  = [0.1, 0.5, 1, 2, 5, 10]\n    alpha_val = np.arange(0,2,0.01)\n    rmsle = {}\n    rmsle_alpha = {}\n    train_size = train_df.shape[0]\n    train_splits = {}\n    for fold in np.arange(k):\n        train_splits[fold] = train_df.loc[fold * train_size/k : (fold+1) * (train_size/k) -1,:]\n        \n    for i,alpha in enumerate(alpha_val):\n        rmsle[i] = []\n        rmsle_alpha[i] =[]\n        for fold in np.arange(k):\n            train_cv = train_splits[fold%k].iloc[:,:-1].append(train_splits[(fold+1)%k].iloc[:,:-1]).append(train_splits[(fold+2)%k].iloc[:,:-1])\n            train_label = train_splits[fold%k].loc[:,'log_revenue'].append(train_splits[(fold+1)%k].loc[:,'log_revenue']).append(train_splits[(fold+2)%k].loc[:,'log_revenue'])\n            test_cv = train_splits[(fold+3)%k].iloc[:,:-1]\n            test_label = train_splits[(fold+3)%k].loc[:,'log_revenue']\n        \n            clf = Ridge(alpha=alpha, normalize = True)\n            # Normalizing is not the same as standard scaling - Standard scaling is more appropriate for getting the features on the same range\n            clf.fit(train_cv,train_label)\n            rmsle[i].append(np.sqrt(mean_squared_error(test_label, clf.predict(test_cv))))\n        rmsle_alpha[i] = np.mean(rmsle[i])\n        \n\n    print('Lowest RMSLE value on cross-validation -', min(rmsle_alpha))\n    alpha_best = alpha_val[np.argmin(rmsle_alpha)]\n    \n    plt.figure()\n    plt.plot(alpha_val,rmsle_alpha.values(),'r-')\n    plt.xlabel('alpha')\n    plt.ylabel('RMSLE')\n    plt.title('Cross-validation for alpha')\n    plt.show()\n    \n    return alpha_best","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Function to run ridge regression on training data, learn the model and test its performance on test datam"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ridge_regression_model(train_df, test_df , alpha_best, no_models = 2):\n    train_df = train_df.copy()\n    test_df = test_df.copy()\n    if no_models == 1:\n        clf_all = Ridge(alpha = alpha_best, normalize = False)\n        features = list(train_df.columns)\n        clf_all.fit(train_df.loc[:,features[:-1]], train_df.loc[:,'log_revenue'])\n        train_df.loc[:,'log_revenue_pred'] = clf_all.predict(train_df.loc[:,features[:-1]])\n\n        \n    elif no_models == 2:\n        # Two separate models, one for those with budget, others for those without budget\n        clf_budget = Ridge(alpha=alpha_best, normalize = False)\n        features = list(train_df.columns)\n        clf_budget.fit(train_df.loc[train_df['log_budget']<=np.log(10000),features[:-1]],\n                       train_df.loc[train_df['log_budget']<=np.log(10000),'log_revenue'])\n        train_df.loc[train_df['log_budget']<=np.log(10000),'log_revenue_pred'] =  clf_budget.predict(train_df.loc[train_df['log_budget']<=np.log(10000),features[:-1]])\n                                                                                                                  \n        clf_no_budget = Ridge(alpha = alpha_best, normalize = False)\n        features.remove('log_budget')\n        clf_no_budget.fit(train_df.loc[train_df['log_budget']>np.log(10000),features[:-1]], \n                          train_df.loc[train_df['log_budget']>np.log(10000),'log_revenue'])\n        train_df.loc[train_df['log_budget']>np.log(10000),'log_revenue_pred'] =  clf_no_budget.predict(train_df.loc[train_df['log_budget']>np.log(10000),features[:-2]])\n\n    print('RMSLE on training set', np.sqrt(mean_squared_error(train_df['log_revenue'],train_df['log_revenue_pred'])))\n    \n    # Testing\n    if 'log_revenue_pred' not in test_df.columns:\n        if no_models == 1:\n            test_df.loc[:,'log_revenue_pred'] = clf_all.predict(test_df)\n        elif no_models == 2:\n            test_df.loc[test_df['log_budget']<=np.log(10000),'log_revenue_pred'] = clf_budget.predict(test_df.loc[test_df['log_budget']<=np.log(10000)])\n            test_df.loc[test_df['log_budget']>np.log(10000),'log_revenue_pred'] = clf_no_budget.predict(test_df.loc[test_df['log_budget']>np.log(10000),features[:-1]])\n    return test_df","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def file_for_submission(test_df):\n    test_df['id'] = np.arange(3001,7399)\n    test_df['revenue'] = test_df['log_revenue_pred'].apply(np.exp)\n    test_df[['id','revenue']].to_csv('submission.csv',index = False)","execution_count":16,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Reading the train and the test files"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest  = pd.read_csv('../input/test.csv')","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### $$ RMSLE = \\sqrt{\\frac{1}{N}\\sum_{i=1}^N \\Bigl[\\log(\\hat{y_i}) -\\log(y_i)\\Bigr]^2} $$"},{"metadata":{},"cell_type":"markdown","source":"1. ### Ridge regression"},{"metadata":{"trusted":true},"cell_type":"code","source":"def ridge_test(df_train, df_test):\n    train_copy,top_lang,top_direct,top_cast = transform_ridge(df_train, additional =1, ohe_director = 1, ohe_cast = 1)\n    print(train_copy.head())\n    test_copy,_,_,_ = transform_ridge(df_test, top_lang, top_direct, top_cast, additional =1, ohe_director = 1, ohe_cast = 1)\n    print(test_copy.head())\n    alpha_best = cross_validation(train_copy)\n    df_test = ridge_regression_model(train_copy, test_copy, alpha_best, no_models = 1)\n    return df_test","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color = red> Need to look at error in the test set </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled_ridge = ridge_test(train,test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled_ridge.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_for_submission(test_filled_ridge)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Random Forest regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"def random_forest_test(df_train, df_test):\n    train_copy,top_lang,top_direct,top_cast = transform_ridge(df_train, additional =1,ohe_director = 1, ohe_cast=1)\n    test_copy,_,_,_ = transform_ridge(df_test, top_lang, top_direct, top_cast, additional =1, ohe_director = 1, ohe_cast = 1)\n    rf_reg = RandomForestRegressor(criterion = 'mse', max_depth = 10, n_estimators = 100)\n    rf_reg.fit(train_copy.iloc[:,:-1],train_copy.iloc[:,-1])\n    train_copy['log_revenue_pred'] = rf_reg.predict(train_copy.iloc[:,:-1])\n    print('RMSLE on training data', np.sqrt(mean_squared_error(train_copy['log_revenue'],train_copy['log_revenue_pred'])))\n    \n    test_copy['log_revenue_pred']  = rf_reg.predict(test_copy)\n    return test_copy","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled_rf = random_forest_test(train, test)","execution_count":19,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'random_forest_test' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-56dbd26bd4e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_filled_rf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_forest_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'random_forest_test' is not defined"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_for_submission(test_filled_rf)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled_rf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### XG Boost regressor"},{"metadata":{"trusted":true},"cell_type":"code","source":"def xgb_test(df_train,df_test):\n    train_copy,top_lang,top_direct,top_cast = transform_ridge(df_train, additional =1,ohe_director = 1, ohe_cast=1)\n    test_copy,_,_,_ = transform_ridge(df_test, top_lang, top_direct, top_cast, additional =1, ohe_director =1, ohe_cast = 1)\n    xgb_reg = xgb.XGBRegressor(max_depth = 5, learning_rate = 0.05, n_estimators= 500)\n    xgb_reg.fit(train_copy.iloc[:,:-1],train_copy.iloc[:,-1])\n    train_copy['log_revenue_pred'] = xgb_reg.predict(train_copy.iloc[:,:-1])\n    print('RMSLE on training data', np.sqrt(mean_squared_error(train_copy['log_revenue'],train_copy['log_revenue_pred'])))\n    \n    test_copy['log_revenue_pred'] = xgb_reg.predict(test_copy)\n    return test_copy","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled_xgb  = xgb_test(train, test)","execution_count":22,"outputs":[{"output_type":"stream","text":"Index(['year', 'dayofrelease', 'log_budget', 'runtime',\n       'belongs_to_collection', 'homepage', 'has_tag', 'released',\n       'popularity', 'cn', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ko',\n       'other lang', 'ru', 'zh', 'US production', 'Big production',\n       'no_production_companies', 'Top genres', 'no_languages',\n       'english_spoken', 'Ivan Reitman', 'Jon Turteltaub',\n       'M. Night Shyamalan', 'Martin Campbell', 'Michael Bay',\n       'Paul W.S. Anderson', 'Peter Jackson', 'Ron Howard', 'Steven Spielberg',\n       'Todd Phillips', 'other dir', 'Arnold Schwarzenegger',\n       'Denzel Washington', 'George Clooney', 'Harrison Ford', 'Jim Carrey',\n       'Mark Wahlberg', 'Owen Wilson', 'Sylvester Stallone', 'Tom Cruise',\n       'Tom Hanks', 'other actors', 'log_revenue'],\n      dtype='object')\nIndex(['year', 'dayofrelease', 'log_budget', 'runtime',\n       'belongs_to_collection', 'homepage', 'has_tag', 'released',\n       'popularity', 'cn', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'ko',\n       'other lang', 'ru', 'zh', 'US production', 'Big production',\n       'no_production_companies', 'Top genres', 'no_languages',\n       'english_spoken', 'Ivan Reitman', 'Jon Turteltaub',\n       'M. Night Shyamalan', 'Martin Campbell', 'Michael Bay',\n       'Paul W.S. Anderson', 'Peter Jackson', 'Ron Howard', 'Steven Spielberg',\n       'Todd Phillips', 'other dir', 'Arnold Schwarzenegger',\n       'Denzel Washington', 'George Clooney', 'Harrison Ford', 'Jim Carrey',\n       'Mark Wahlberg', 'Owen Wilson', 'Sylvester Stallone', 'Tom Cruise',\n       'Tom Hanks', 'other actors'],\n      dtype='object')\nRMSLE on training data 1.168665414221414\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"file_for_submission(test_filled_xgb)","execution_count":23,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled_xgb.head()","execution_count":24,"outputs":[{"output_type":"execute_result","execution_count":24,"data":{"text/plain":"   year  dayofrelease      ...         id       revenue\n0  2007           5.0      ...       3001  3.341477e+05\n1  1958           6.0      ...       3002  3.765177e+05\n2  1997           4.0      ...       3003  8.577222e+06\n3  2010           5.0      ...       3004  7.187182e+05\n4  2005           4.0      ...       3005  1.012666e+06\n\n[5 rows x 51 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>dayofrelease</th>\n      <th>log_budget</th>\n      <th>runtime</th>\n      <th>belongs_to_collection</th>\n      <th>homepage</th>\n      <th>has_tag</th>\n      <th>released</th>\n      <th>popularity</th>\n      <th>cn</th>\n      <th>en</th>\n      <th>es</th>\n      <th>fr</th>\n      <th>hi</th>\n      <th>it</th>\n      <th>ja</th>\n      <th>ko</th>\n      <th>other lang</th>\n      <th>ru</th>\n      <th>zh</th>\n      <th>US production</th>\n      <th>Big production</th>\n      <th>no_production_companies</th>\n      <th>Top genres</th>\n      <th>no_languages</th>\n      <th>english_spoken</th>\n      <th>Ivan Reitman</th>\n      <th>Jon Turteltaub</th>\n      <th>M. Night Shyamalan</th>\n      <th>Martin Campbell</th>\n      <th>Michael Bay</th>\n      <th>Paul W.S. Anderson</th>\n      <th>Peter Jackson</th>\n      <th>Ron Howard</th>\n      <th>Steven Spielberg</th>\n      <th>Todd Phillips</th>\n      <th>other dir</th>\n      <th>Arnold Schwarzenegger</th>\n      <th>Denzel Washington</th>\n      <th>George Clooney</th>\n      <th>Harrison Ford</th>\n      <th>Jim Carrey</th>\n      <th>Mark Wahlberg</th>\n      <th>Owen Wilson</th>\n      <th>Sylvester Stallone</th>\n      <th>Tom Cruise</th>\n      <th>Tom Hanks</th>\n      <th>other actors</th>\n      <th>log_revenue_pred</th>\n      <th>id</th>\n      <th>revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2007</td>\n      <td>5.0</td>\n      <td>0.000000</td>\n      <td>90.0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.851534</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>12.719338</td>\n      <td>3001</td>\n      <td>3.341477e+05</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1958</td>\n      <td>6.0</td>\n      <td>11.385092</td>\n      <td>65.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.559789</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>12.838720</td>\n      <td>3002</td>\n      <td>3.765177e+05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1997</td>\n      <td>4.0</td>\n      <td>0.000000</td>\n      <td>100.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.085194</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>15.964621</td>\n      <td>3003</td>\n      <td>8.577222e+06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2010</td>\n      <td>5.0</td>\n      <td>15.732433</td>\n      <td>130.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.596012</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13.485225</td>\n      <td>3004</td>\n      <td>7.187182e+05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2005</td>\n      <td>4.0</td>\n      <td>14.508658</td>\n      <td>92.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.217680</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>13.828097</td>\n      <td>3005</td>\n      <td>1.012666e+06</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_filled_xgb[['id','revenue']].to_csv('submission.csv',index = False)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <font color = 'red'> Some useless analysis </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_scatter(train_copy[train_copy['log_budget']!=0],'log_budget','log_revenue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n### Aggregating budget and revenue by year"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_yearly = train_copy.groupby(train_copy['year']).aggregate({'log_revenue' : 'mean', 'log_budget':'mean', 'id':'count'}).reset_index()\ntrain_yearly.rename(columns ={'id':'Number','log_revenue':'mean_log_revenue','log_budget':'mean_log_budget'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Plotting the mean log revenue by year"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ntrain_yearly.plot(x = 'year', y= 'mean_log_revenue', kind = 'bar',figsize =(25,10))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_2y(train_yearly,'year','mean_log_revenue','Number')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Comparison of mean log budget and mean log revenue by year"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ntrain_yearly.plot(x = 'year', y=['mean_log_budget','mean_log_revenue'], kind = 'bar',figsize =(25,10))\nplt.tight_layout()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Aggregating based on decade of release"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['decade'] = train['year'].apply(roundup)\ntrain_decade = train.groupby(train['decade']).aggregate({'log_budget':'mean','log_revenue':'mean', 'id':'count'}).reset_index()\ntrain_decade.rename(columns = {'log_budget':'mean_log_budget', 'log_revenue':'mean_log_revenue'}, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure()\ntrain_decade.plot(x = 'decade', y=['mean_log_budget','mean_log_revenue'], kind = 'bar',figsize =(15,10))\nplt.tight_layout()\nplt.title('Decade-wise mean log budget v mean log revenue',fontsize = 15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Language-wise linear model"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lang_table = train['original_language'].value_counts().reset_index()\ntrain_lang_table.rename(columns={'index':'language', 'original_language':'Number'},inplace= True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lang_table.loc[10,'language']='others'\ntrain_lang_table.loc[10,'Number'] = train_lang_table.loc[10:,'Number'].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lang_table[0:11]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_lang = {}\nno_lang = 9\ni = 0\nplt.figure(figsize = (15,10))\nfor lang in train['original_language'].unique()[0:no_lang]:\n    train_lang[lang] = train[train['original_language']== lang]\n    x = train_lang[lang][train_lang[lang]['log_budget']!=0]['log_budget']\n    y = train_lang[lang][train_lang[lang]['log_budget']!=0]['log_revenue']\n    A = np.vstack([np.array(x), np.ones(len(x))]).T\n    m, c = np.linalg.lstsq(A,np.array(y), rcond=None)[0]\n    plt.scatter(x,y,s=20, c = col[i])\n    plt.plot(x,m*x+c,c = col[i])\n\n    i = i + 1\nplt.title('Scatter plot of mean log revenue vs mean log budget for various languages')\nplt.legend(train['original_language'].unique()[0:no_lang])\nplt.xlabel('Mean log budget')\nplt.ylabel('Mean log revenue')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"booleanBoxPlot(train_copy,'belongs_to_collection','log_revenue', 'en')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"booleanBoxPlot(train_copy,'homepage','log_revenue','en')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nsns.distplot(train.loc[train['popularity']<=100,'popularity'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,10))\nplt.scatter(train.loc[train['popularity']<=40,'popularity'],train.loc[train['popularity']<=40,'log_revenue'],c = 'r')\nx = train.loc[train['popularity']<=40,'popularity']\ny = train.loc[train['popularity']<=40,'log_revenue']\nA = np.vstack([np.array(x),np.ones(len(x))]).T\nm,c = np.linalg.lstsq(A,np.array(y),rcond = None)[0]\nplt.plot(x,m*x +c, 'r^-')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}