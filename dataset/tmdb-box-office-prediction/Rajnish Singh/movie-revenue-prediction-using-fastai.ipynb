{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Fastai Library\nfrom fastai import *\nfrom fastai.tabular import *\n\n# visualization library\nfrom wordcloud import WordCloud\nimport seaborn as sb\nsb.set(rc={'figure.figsize':(11.7,8.27)})","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Load data and inspect it"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ndf_test = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.set_option('display.max_rows', None)\npd.set_option('display.max_columns', None)\npd.set_option('display.expand_frame_repr', True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(1).T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Check for null columns in train and test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Rename all columns lowercase names and replacing space with _"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns = df_train.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_test.columns = df_test.columns.str.strip().str.lower().str.replace(' ', '_')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Inspect continuous variable column to see if the distribution is normal"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.revenue.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.budget.min()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.revenue, ax=ax1)\nsb.distplot(np.log1p(df_train.revenue), ax=ax2)\nax1.set_title('Distribution of revenue')\nax2.set_title('Distribution of log of revenue')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Revenue data is skewed so will take log(log1p) to make it normal distribution. Log1p because we have value 0 in budget."},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.budget, ax=ax1)\nsb.distplot(np.log1p(df_train.budget), ax=ax2)\nax1.set_title('Distribution of Budget')\nax2.set_title('Distribution of log of Budget')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Budget data is skewed so will take log(log1p) to make it normal distribution. Log1p because we have value 0 in budget."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['log_revenue'] = np.log1p(df_train.revenue)\ndf_train['log_budget'] = np.log1p(df_train.budget)\n\ndf_test['log_budget'] = np.log1p(df_test.budget)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.popularity, ax=ax1)\nsb.distplot(np.log1p(df_train.popularity), ax=ax2)\nax1.set_title('Distribution of popularity')\nax2.set_title('Distribution of log of popularity')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.fillna({'runtime': df_train['runtime'].mean()}, inplace=True)\ndf_test.fillna({'runtime': df_test['runtime'].mean()}, inplace=True)\n\nfig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\nsb.distplot(df_train.runtime, ax=ax1)\nsb.distplot(np.log1p(df_train.runtime), ax=ax2)\nax1.set_title('Distribution of runtime')\nax2.set_title('Distribution of log of runtime')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['log_popularity'] = np.log1p(df_train.popularity)\ndf_train['log_runtime'] = np.log1p(df_train.runtime)\n\ndf_test['log_popularity'] = np.log1p(df_test.popularity)\ndf_test['log_runtime'] = np.log1p(df_test.runtime)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will inspect data for NaN percentage and ignore columns with very high NaN percentage in our model creation"},{"metadata":{"trusted":true},"cell_type":"code","source":"nan_percentage = pd.DataFrame({'ColName':df_train.columns, 'NaN%':df_train.isnull().mean()})\nplt.figure(figsize=(16, 8))\nchart = sb.barplot(x=nan_percentage['ColName'], y=nan_percentage['NaN%'])\nplt.xticks(rotation=45, horizontalalignment='right', fontweight='light', fontsize='x-large')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"belongs_to_collection and homepage have very high NaN%, so probably will discard those columns"},{"metadata":{},"cell_type":"markdown","source":"The data in many columns are in string containg list of dictionary format so lets convert them to list of dictionary"},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\nfor df in (df_train, df_test):\n    df.belongs_to_collection = df.belongs_to_collection.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.genres = df.genres.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.production_companies = df.production_companies.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.production_countries = df.production_countries.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.spoken_languages = df.spoken_languages.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.keywords = df.keywords.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.cast = df.cast.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))\n    df.crew = df.crew.apply(lambda x: x if pd.isna(x) else ast.literal_eval(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.belongs_to_collection.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.genres.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.barplot(x=df_train.genres.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This graph tells us the number of genres makes a huge impact on revenue. Movies with 1 and 6 genres contribute a lot towards revenue."},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.production_companies.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.barplot(x=df_train.production_companies.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Movies with 1, 3, 7, 118, 775 production companies contribute a lot towards revenue."},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.production_countries.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.barplot(x=df_train.production_countries.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Movies with 3 and 2222 production countries contribute a lot towards revenue."},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.spoken_languages.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.barplot(x=df_train.spoken_languages.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.keywords.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.barplot(x=df_train.keywords.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.cast.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.barplot(x=df_train.cast.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.crew.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sb.barplot(x=df_train.crew.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0).value_counts(), y=df_train.revenue)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_features(df, col):\n    #     Separate features into  individual features\n    features = set()\n    for f in df[col]:\n        if np.any(pd.notna(f)):\n            for x in range(len(f)):\n                features.add(str(f[x]['name']))\n            \n    return features\n    \ndef create_features(df, col, features):\n    for f in features:\n        df[col+'_'+f]=0\n        \n    for index, f in enumerate(df[col]):\n        if np.any(pd.notna(f)):\n            for x in range(len(f)):\n                if f[x]['name'] in features:\n                    df.loc[index, col+'_'+f[x]['name']] = 1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new features from existing features"},{"metadata":{"trusted":true},"cell_type":"code","source":"f_train = extract_features(df_train, 'genres')\nf_test = extract_features(df_test, 'genres')\nlen(f_train), len(f_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f_train - f_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (df_train, df_test):\n    # Create features from belongs to collection\n    # df['collection_name'] = df.belongs_to_collection.apply(lambda x: x[0]['name'] if np.any(pd.notna(x)) else x)\n    df['is_series'] = df.belongs_to_collection.apply(lambda x: 1 if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual genres\n    create_features(df, 'genres', f_train)\n    df['total_genres'] = df.genres.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    \n    # Create features for individual production_companies\n    # create_features(df, 'production_companies')\n    df['total_production_companies'] = df.production_companies.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual production_countries\n    # create_features(df, 'production_countries')\n    df['total_production_countries'] = df.production_countries.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual spoken_languages\n    # create_features(df, 'spoken_languages')\n    df['total_spoken_languages'] = df.spoken_languages.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual keywords\n    # create_features(df, 'keywords')\n    df['total_keywords'] = df.keywords.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual cast\n    # create_features(df, 'cast')\n    df['total_cast'] = df.cast.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create features for individual crew\n    # create_features(df, 'crew')\n    df['total_crew'] = df.crew.apply(lambda x: len(x) if np.any(pd.notna(x)) else 0)\n    \n    # Create feature from date\n    add_datepart(df, 'release_date')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Data visualization of all individual genres"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(4, 5, figsize=(16, 16))\nsb.barplot(df_train.genres_Action, df_train.revenue, ax=ax[0,0])\nsb.barplot(df_train.genres_Adventure, df_train.revenue, ax=ax[0,1])\nsb.barplot(df_train.genres_Animation, df_train.revenue, ax=ax[0,2])\nsb.barplot(df_train.genres_Comedy, df_train.revenue, ax=ax[0,3])\nsb.barplot(df_train.genres_Crime, df_train.revenue, ax=ax[0,4])\nsb.barplot(df_train.genres_Documentary, df_train.revenue, ax=ax[1,0])\nsb.barplot(df_train.genres_Drama, df_train.revenue, ax=ax[1,1])\nsb.barplot(df_train.genres_Family, df_train.revenue, ax=ax[1,2])\nsb.barplot(df_train.genres_Fantasy, df_train.revenue, ax=ax[1,3])\nsb.barplot(df_train.genres_Foreign, df_train.revenue, ax=ax[1,4])\nsb.barplot(df_train.genres_History, df_train.revenue, ax=ax[2,0])\nsb.barplot(df_train.genres_Horror, df_train.revenue, ax=ax[2,1])\nsb.barplot(df_train.genres_Music, df_train.revenue, ax=ax[2,2])\nsb.barplot(df_train.genres_Mystery, df_train.revenue, ax=ax[2,3])\nsb.barplot(df_train.genres_Romance, df_train.revenue, ax=ax[2,4])\nsb.barplot(df_train.genres_Thriller, df_train.revenue, ax=ax[3,0])\nsb.barplot(df_train.genres_War, df_train.revenue, ax=ax[3,1])\nsb.barplot(df_train.genres_Western, df_train.revenue, ax=ax[3,2])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.production_companies.apply(lambda x: print(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train.production_companies.apply(lambda x: ' ' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x))).replace(' ', '_'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Create new features with most popular item"},{"metadata":{"trusted":true},"cell_type":"code","source":"prod_comp = ','.join(df_train.production_companies.apply(lambda x: 'NaN' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x))).replace(' ', '_')))\n# Create and generate a word cloud image:\nwordcloud = WordCloud(background_color=\"white\").generate(prod_comp)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_words = [word for word in prod_comp.split(',')]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(20):\n    words.append(letter)\n    counts.append(count)\n    \n\nsb.barplot(x=counts, y=words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['prod_wb'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Warner Bros.' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_up'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Universal Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_pp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Paramount Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_tcffc'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Twentieth Century Fox Film Corporation' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_cp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_mgm'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Metro-Goldwyn-Mayer (MGM)' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_nlc'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'New Line Cinema' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_tp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Touchstone Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_wdp'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Walt Disney Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['prod_cpc'] = df_train.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures Corporation' in list((map(lambda y: y['name'], x))) else 0)\n\ndf_train['prod_wb'].value_counts(), df_train['prod_up'].value_counts(), df_train['prod_pp'].value_counts(), df_train['prod_tcffc'].value_counts(), df_train['prod_cp'].value_counts(), df_train['prod_mgm'].value_counts(), df_train['prod_nlc'].value_counts(), df_train['prod_tp'].value_counts(), df_train['prod_wdp'].value_counts(), df_train['prod_cpc'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['prod_wb'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Warner Bros.' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_up'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Universal Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_pp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Paramount Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_tcffc'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Twentieth Century Fox Film Corporation' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_cp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_mgm'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Metro-Goldwyn-Mayer (MGM)' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_nlc'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'New Line Cinema' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_tp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Touchstone Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_wdp'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Walt Disney Pictures' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['prod_cpc'] = df_test.production_companies.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'Columbia Pictures Corporation' in list((map(lambda y: y['name'], x))) else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(2, 5, figsize=(16, 8))\nsb.barplot(df_train.prod_wb, df_train.revenue, ax=ax[0,0])\nsb.barplot(df_train.prod_up, df_train.revenue, ax=ax[0,1])\nsb.barplot(df_train.prod_pp, df_train.revenue, ax=ax[0,2])\nsb.barplot(df_train.prod_tcffc, df_train.revenue, ax=ax[0,3])\nsb.barplot(df_train.prod_cp, df_train.revenue, ax=ax[0,4])\nsb.barplot(df_train.prod_mgm, df_train.revenue, ax=ax[1,0])\nsb.barplot(df_train.prod_nlc, df_train.revenue, ax=ax[1,1])\nsb.barplot(df_train.prod_tp, df_train.revenue, ax=ax[1,2])\nsb.barplot(df_train.prod_wdp, df_train.revenue, ax=ax[1,3])\nsb.barplot(df_train.prod_cpc, df_train.revenue, ax=ax[1,4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lang = ','.join(df_train.spoken_languages.apply(lambda x: '' if np.any(pd.isna(x)) else ','.join((map(lambda y: y['name'], x)))))\n# Create and generate a word cloud image:\nwordcloud = WordCloud(background_color=\"white\").generate(lang)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_words = [word for word in lang.split(',')]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(20):\n    words.append(letter)\n    counts.append(count)\n    \nsb.barplot(x=counts, y=words)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Mostly all films are in English so will ignore individual feature "},{"metadata":{"trusted":true},"cell_type":"code","source":"# (df_train.keywords.apply(lambda x: '' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x)))))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keys = ','.join(df_train.keywords.apply(lambda x: 'NaN' if np.all(pd.isna(x)) else ','.join((map(lambda y: y['name'], x)))))\n# Create and generate a word cloud image:\nwordcloud = WordCloud(background_color=\"white\").generate(keys)\n\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_words = [word for word in keys.split(',')]\ncounted_words = collections.Counter(filtered_words)\n\nwords = []\ncounts = []\nfor letter, count in counted_words.most_common(10):\n    words.append(letter)\n    counts.append(count)\n    \nsb.barplot(x=counts, y=words)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['key_women'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'woman director' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_independent'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'independent film' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_credit'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'duringcreditsstinger' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_murder'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'murder' in list((map(lambda y: y['name'], x))) else 0)\ndf_train['key_novel'] = df_train.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'based on novel' in list((map(lambda y: y['name'], x))) else 0)\n\ndf_train.key_women.value_counts(), df_train.key_independent.value_counts(), df_train.key_murder.value_counts(), df_train.key_credit.value_counts(), df_train.key_novel.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig, ax = plt.subplots(1, 5, figsize=(16, 4))\nsb.barplot(df_train.key_women, df_train.revenue, ax=ax[0])\nsb.barplot(df_train.key_independent, df_train.revenue, ax=ax[1])\nsb.barplot(df_train.key_credit, df_train.revenue, ax=ax[2])\nsb.barplot(df_train.key_murder, df_train.revenue, ax=ax[3])\nsb.barplot(df_train.key_novel, df_train.revenue, ax=ax[4])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['key_women'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'woman director' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_independent'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'independent film' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_credit'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'duringcreditsstinger' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_murder'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'murder' in list((map(lambda y: y['name'], x))) else 0)\ndf_test['key_novel'] = df_test.keywords.apply(lambda x: x if np.all(pd.isna(x)) else 1 if 'based on novel' in list((map(lambda y: y['name'], x))) else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns = df_train.columns.str.strip().str.lower().str.replace(' ', '_')\ndf_test.columns = df_test.columns.str.strip().str.lower().str.replace(' ', '_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train.columns), len(df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Two columns(revenue and log_revenue) are not there in test dataset which is fine."},{"metadata":{"trusted":true},"cell_type":"code","source":"for df in (df_train, df_test):\n    print('='*10)\n    for column in df:\n        if (df[column].apply(lambda x: True if np.any(pd.isna(x)) else False).max()): print(column)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cat_names = ['original_language', 'status',\n             'is_series', 'genres_war', 'genres_thriller', 'genres_science_fiction',\n             'genres_mystery', 'genres_foreign', 'genres_tv_movie', 'genres_western',\n             'genres_drama', 'genres_crime', 'genres_fantasy', 'genres_romance',\n             'genres_adventure', 'genres_family', 'genres_comedy',\n             'genres_documentary', 'genres_history', 'genres_music', 'genres_action',\n             'genres_animation', 'genres_horror', 'total_genres',\n             'total_production_companies', 'total_production_countries',\n             'total_spoken_languages', 'total_keywords', 'total_cast', 'total_crew',\n             'release_year', 'release_month', 'release_week', 'release_day',\n             'release_dayofweek', 'release_dayofyear', 'release_is_month_end',\n             'release_is_month_start', 'release_is_quarter_end',\n             'release_is_quarter_start', 'release_is_year_end',\n             'release_is_year_start', 'release_elapsed', 'prod_wb', 'prod_up',\n             'prod_pp', 'prod_tcffc', 'prod_cp', 'prod_mgm', 'prod_nlc', 'prod_tp',\n             'prod_wdp', 'prod_cpc', 'key_women', 'key_independent', 'key_credit',\n             'key_murder', 'key_novel'\n            ]\ncont_names = ['log_budget', 'log_popularity', 'log_runtime']\ndep_var = 'log_revenue'\nprocs = [Categorify, FillMissing, Normalize]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for c in cont_names:\n    df_train[cont_names] = df_train[cont_names].fillna(0).astype('float32')\n    df_test[cont_names] = df_test[cont_names].fillna(0).astype('float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"db_test = TabularList.from_df(df_test, cat_names=cat_names, cont_names=cont_names, procs=procs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"db_train = (TabularList.from_df(df_train, cat_names=cat_names, cont_names=cont_names, procs=procs)\n            .split_by_idx(list(range(700)))\n            .label_from_df(cols=dep_var)\n            .add_test(db_test, label = 0)\n            .databunch())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#A function to calculate Root Mean Squared Logarithmic Error (RMSLE)\n# def rmsle(y, y_pred):\n#     assert len(y) == len(y_pred)\n#     terms_to_sum = [(np.log(y_pred[i] + 1) - np.log(y[i] + 1)) ** 2.0 for i,pred in enumerate(y_pred)]\n#     return (sum(terms_to_sum) * (1.0/len(y))) ** 0.5\n\ndef rmsle(y, y_pred):\n#     print(len(y), len(y_pred))\n    sum=0.0\n    assert len(y) == len(y_pred)\n    for x in range(len(y_pred)):\n#         print(y[x], y_pred[x])\n        if y_pred[x]<0 or y[x]<0: #check for negative values\n            continue\n        p = np.log(y_pred[x]+1)\n        r = np.log(y[x]+1)\n        sum = sum + (p - r)**2\n    return (sum/len(y_pred))**0.5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn = tabular_learner(db_train, layers=[200, 100], metrics=rmsle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.lr_find()\nlearn.recorder.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.fit(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.recorder.plot_losses()\nlearn.recorder.plot_metrics()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"learn.save('TMDB')\nlearn.load('TMDB')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions, _ = learn.get_preds(DatasetType.Test)\npredictions = np.exp(predictions) - 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred = list()\nfor each in predictions.data.tolist():\n    pred.append(each[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.read_csv('../input/tmdb-box-office-prediction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame({'id': df_test['id'], 'revenue': pred})\nsubmission_df.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import HTML\nimport base64\n\ndef create_download_link( df, title = \"Download CSV file\", filename = \"data.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = f'<a download=\"{filename}\" href=\"data:text/csv;base64,{payload}\" target=\"_blank\">{title}</a>'\n    return HTML(html)\n\ncreate_download_link(submission_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}