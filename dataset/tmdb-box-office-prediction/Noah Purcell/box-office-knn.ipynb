{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f040e477b429e2b2d59735181e2132aef64d26b4"},"cell_type":"code","source":"from collections import Counter\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.model_selection import KFold\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"2d08d9992ae389ccabb5806fcbbc99cb1bd44001"},"cell_type":"markdown","source":"# Data Cleaning"},{"metadata":{"trusted":true,"_uuid":"08858afbeace0d938ef616a2f5578e1a2f8a5266"},"cell_type":"code","source":"train = pd.read_csv(\"../input/train.csv\")\ntest = pd.read_csv(\"../input/test.csv\")\nprint(set(train.columns).difference(set(test.columns)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7bcc56508d206f637b770b628ee819ad0f429b79","scrolled":true},"cell_type":"code","source":"test[\"revenue\"] = np.nan\nall_movies = pd.concat([train, test])\nall_movies.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2c8305dc635bfd9da506ff66eaf0851c45ef7f63"},"cell_type":"code","source":"all_movies.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5f8a272c41b0439358cd5f44a723c227c4cfa68","scrolled":true},"cell_type":"code","source":"def clean_belongs_to_collection(x):\n    if x is np.nan:\n        return \"\"\n    x = x[1:-1]\n    return eval(x)['name']\n\nall_movies[\"collection\"] = all_movies[\"belongs_to_collection\"].apply(clean_belongs_to_collection)\nprint(all_movies[\"collection\"].isnull().sum())\nprint(all_movies[\"collection\"].head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"f479834c053a2c9330a80bb95789af328272040a"},"cell_type":"code","source":"def get_genres(x):\n    if x is np.nan:\n        return \"\"\n    genres = list()\n    for genre_dict in eval(x):\n        genres.append(genre_dict['name'])\n    return \",\".join(genres)\n\nall_movies[\"genres_list\"] = all_movies[\"genres\"].apply(get_genres)\nprint(all_movies[\"genres_list\"].isnull().sum())\nall_movies[\"genres_list\"].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6f085db8bf258f28eccae4629a9245bc00091481","scrolled":true},"cell_type":"code","source":"genres = list()\nfor i in range(all_movies.shape[0]):\n    genres += (all_movies.iloc[i][\"genres_list\"].split(\",\"))\ngenres = Counter(genres)\ngenres.most_common(25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fa0b84ca6483314a45a93ee1696178679bac43a5","scrolled":true},"cell_type":"code","source":"for genre, count in genres.most_common(25)[:-2]:\n    all_movies[genre] = all_movies[\"genres_list\"].apply(lambda x: 1 if genre in x else 0)\nall_movies = all_movies.drop([\"genres_list\"], axis=1)\nall_movies.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"11b8db5e4f118cb04c32cd4185d21aa9ab9c009b"},"cell_type":"code","source":"all_movies[\"has_webpage\"] = all_movies[\"homepage\"].apply(lambda x: 0 if x is np.nan else 1)\n# I'll use imdb_id to scrape critic scores in a later kernel\nall_movies = all_movies.drop([\"belongs_to_collection\", \"genres\",\n                              \"homepage\", \"imdb_id\", \"poster_path\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d5cee4195e481f772034a44a07978917e4569ab7"},"cell_type":"code","source":"dummy_orig_langs = pd.get_dummies(all_movies[\"original_language\"], prefix=\"original_lang\")\nall_movies = pd.concat([all_movies,dummy_orig_langs], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7aa1c3a6ebd9a51e6ce160a9f26a34337212b4ec","scrolled":true},"cell_type":"code","source":"stop_words = set(stopwords.words('english'))\ntext_cols = [\"overview\", \"tagline\"]\novw_words = list()\ntag_words = list()\nfor i in range(all_movies.shape[0]):\n    try:\n        ovw_words += (all_movies.iloc[i][\"overview\"].replace(\",\",\"\").replace(\".\",\"\").lower().split())\n        tag_words += (all_movies.iloc[i][\"tagline\"].replace(\",\",\"\").replace(\".\",\"\").lower().split())\n    except AttributeError as e:\n        continue\novw_words = Counter([w for w in ovw_words if len(w) > 4 and w not in stop_words])\ntag_words = Counter([w for w in tag_words if len(w) > 4 and w not in stop_words])\nprint(ovw_words.most_common(10))\nprint(tag_words.most_common(10))","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"for word, _ in ovw_words.most_common(100):\n    col = \"overview_\"+word\n    all_movies[col] = all_movies[\"overview\"].apply(lambda x: 0 if x is np.nan else 1 if word in x.lower() else 0)\nfor word, _ in tag_words.most_common(100):\n    col = \"tagline_\"+word\n    all_movies[col] = all_movies[\"tagline\"].apply(lambda x: 0 if x is np.nan else 1 if word in x.lower() else 0)\nall_movies.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c3cc053d82d5d475c2a7991f4fd798ceddc1641"},"cell_type":"code","source":"ovw_high_var_list = list()\ntag_high_var_list = list()\ntrain_idx = train.shape[0]\ntrain = all_movies.iloc[:train_idx]\novw_cols = [col for col in list(train.columns) if \"overview_\" in col]\ntag_cols = [col for col in list(train.columns) if \"tagline_\" in col]\nfor col in ovw_cols:\n    ovw_high_var_list.append((col, train[train[col] == 1][\"revenue\"].var()))\nfor col in tag_cols:\n    tag_high_var_list.append((col, train[train[col] == 1][\"revenue\"].var()))\novw_high_var_list = sorted(ovw_high_var_list, key=lambda x: x[1], reverse=True)\ntag_high_var_list = sorted(tag_high_var_list, key=lambda x: x[1], reverse=True)\n\n# take the top half of variances in revenue\novw_drop_cols = [x[0] for x in ovw_high_var_list[50:]]\ntag_drop_cols = [x[0] for x in tag_high_var_list[50:]]\nall_movies = all_movies.drop((ovw_drop_cols + tag_drop_cols), axis=1)\nall_movies.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"35e924fbaebde4ce35741b49e51c6e733d205319"},"cell_type":"code","source":"all_movies.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b8a6b8ff2e0ba3e038fc3cd00759cd7550cef6e"},"cell_type":"code","source":"all_movies[\"status\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e4cd0f21d088c4d1deb8404d8a4f7411ae47a3ca"},"cell_type":"markdown","source":"Code in below cell is lifted from dgk1's excellent kernel found [here](https://www.kaggle.com/dgk1234/basic-fe-lgbm)."},{"metadata":{"trusted":true,"_uuid":"f2cbd438688ccbf08bca0ecd73a445117d97f562"},"cell_type":"code","source":"all_movies.loc[all_movies['title'].isnull(), 'title'] = all_movies.loc[all_movies['title'].isnull(), 'original_title']\nall_movies['status'].fillna(\"Released\", inplace = True)\n\n# fill runtime based on info found at https://www.imdb.com\nall_movies.loc[all_movies['title']=='Happy Weekend', 'runtime'] = 81\nall_movies.loc[all_movies['title']=='Miesten välisiä keskusteluja', 'runtime'] = 90\nall_movies.loc[all_movies['title']=='Nunca en horas de clase', 'runtime'] = 100\nall_movies.loc[all_movies['title']=='Pancho, el perro millonario', 'runtime'] = 91\nall_movies.loc[all_movies['title']=='La caliente niña Julietta', 'runtime'] = 93\nall_movies.loc[all_movies['title']=='Королёв', 'runtime'] = 130\n\n# release date of Jails, Hospitals & Hip-Hop movie : May 2000\nall_movies.loc[all_movies['release_date'].isnull(), 'release_date'] = '5/1/00'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fbf2722fc46a261bfd85871109c9902610103ca"},"cell_type":"code","source":"#all_movies[\"release_day\"] = all_movies[\"release_date\"].apply(lambda x: int(x.split(\"/\")[1])).astype(int)\nall_movies[\"release_month\"] = all_movies[\"release_date\"].apply(lambda x: x.split(\"/\")[0])\nall_movies[\"release_month\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"778043f6f051a894dff0b93233b4f089551b9cb5","scrolled":true},"cell_type":"code","source":"# this function was used above as get_genres\ndef get_list_of_values(x, key):\n    if x is np.nan:\n        return \"\"\n    vals = list()\n    for val in eval(x):\n        vals.append(val[key])\n    return \",\".join(vals)\n\ndef find_most_common(col, n):\n    values = list()\n    for i in range(all_movies.shape[0]):\n        values += all_movies.iloc[i][col].split(\",\")\n    return Counter(values).most_common(n)\n\ndef one_hot_encode_most_common(new_col, list_col, cmn_lst):\n    for name, cnt in cmn_lst:\n        all_movies[new_col+\"_\"+name] = all_movies[list_col].apply(\n            lambda x: 1 if name in x else 0)\n    return None\n\n# production companies\nall_movies[\"companies_list\"] = all_movies[\"production_companies\"].apply(\n    get_list_of_values, args=('name',))\nmost_cmn_comps = find_most_common(\"companies_list\", 10)\none_hot_encode_most_common(\"production_companies\", \"companies_list\", most_cmn_comps)\n\n# production countries\nall_movies[\"countries_list\"] = all_movies[\"production_countries\"].apply(\n    get_list_of_values, args=('iso_3166_1',))\nmost_cmn_countries = find_most_common(\"countries_list\", 25)\none_hot_encode_most_common(\"production_countries\", \"countries_list\", most_cmn_countries)\n\n# spoken languages\nall_movies[\"spoken_lang_list\"] = all_movies[\"spoken_languages\"].apply(\n    get_list_of_values, args=('iso_639_1',))\nmost_cmn_langs = find_most_common(\"spoken_lang_list\", 25)\none_hot_encode_most_common(\"spoken_languages\", \"spoken_lang_list\", most_cmn_langs)\n\n# Keywords\nall_movies[\"keywords_list\"] = all_movies[\"Keywords\"].apply(\n    get_list_of_values, args=('name',))\nmost_cmn_kywds = find_most_common(\"keywords_list\", 25)\none_hot_encode_most_common(\"Keywords\", \"keywords_list\", most_cmn_kywds)\n\n# cast\nall_movies.loc[all_movies['cast'].isnull(), 'cast'] = \"[{'gender':'','gender':'','gender':''}]\"\nall_movies['cast_gender_0'] = all_movies['cast'].apply(lambda x: np.nan if len(eval(x)) < 1 else eval(x)[0]['gender'])\nall_movies['cast_gender_1'] = all_movies['cast'].apply(lambda x: np.nan if len(eval(x)) < 2 else eval(x)[1]['gender'])\nall_movies['cast_gender_2'] = all_movies['cast'].apply(lambda x: np.nan if len(eval(x)) < 3 else eval(x)[2]['gender'])\n\nall_movies.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a26cd34915762c2af4b6ea9a9fd78335480d69d1"},"cell_type":"code","source":"all_movies = all_movies.drop([\"release_date\", \"production_companies\", \"production_countries\",\n                             \"spoken_languages\", \"Keywords\", \"cast\", \"crew\", \"overview\", \"tagline\",\n                             \"companies_list\", \"countries_list\", \"spoken_lang_list\",\"keywords_list\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9f1ff97a13e17fc07aed9d168cedcdf16505ca4e"},"cell_type":"code","source":"all_movies.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"90bf6b19acffe3efd9e86a2c86eebdb3cfac648d"},"cell_type":"code","source":"all_movies[\"cast_gender_0\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e1dfb3d30780c062a1bcd89f013af122b2a1174c"},"cell_type":"code","source":"# there are more than two genders\ndummy_genders_0 = pd.get_dummies(all_movies[\"cast_gender_0\"], prefix=\"first_cast_gender\")\nall_movies = pd.concat([all_movies, dummy_genders_0], axis=1)\ndummy_genders_1 = pd.get_dummies(all_movies[\"cast_gender_1\"], prefix=\"scnd_cast_gender_1\")\nall_movies = pd.concat([all_movies, dummy_genders_1], axis=1)\ndummy_genders_2 = pd.get_dummies(all_movies[\"cast_gender_2\"], prefix=\"thrd_cast_gender_2\")\nall_movies = pd.concat([all_movies, dummy_genders_2], axis=1)\nall_movies = all_movies.drop([\"cast_gender_0\", \"cast_gender_1\", \"cast_gender_2\"], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3ea9a55a6618c4b8d8a46819a374bb620238f110"},"cell_type":"code","source":"all_movies[[col for col in all_movies.columns.tolist() if col != \"revenue\"]].isnull().sum().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"e2575dd170976b37b437a824c88d8cf36bef0edb"},"cell_type":"code","source":"dummy_months = pd.get_dummies(all_movies[\"release_month\"], prefix=\"month\")\nall_movies = pd.concat([all_movies, dummy_months], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"77331a2e3ec528c85c492e08e52f2602ee7ad3c7"},"cell_type":"code","source":"all_movies = all_movies.drop(['original_language','original_title','status','title',\n                             'collection'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3986482ee58661db52d84108403f4d89f847b6fa"},"cell_type":"code","source":"all_movies.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"61c47b1047a845ea09d329db49b2f4a8e105f999"},"cell_type":"code","source":"num_movies = all_movies.select_dtypes(include=['float64'])\nnum_movies = pd.concat([num_movies, all_movies[[\"budget\"]]], axis=1)\nnum_movies.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2211dd45e2ad4dfa5f19c3a9f1be48ab650baf2"},"cell_type":"markdown","source":"To use KNN I need to normalized the two numeric columns, budget, runtime and populatrity, "},{"metadata":{"trusted":true,"_uuid":"dd5a299901aabb6484efe95ecc1a8ec338d2c805"},"cell_type":"code","source":"def normalize_col(df, col):\n    df[col+\"_norm\"] = (df[col] - df[col].min()) / (df[col].max() - df[col].min())\n    return None\n\nnormalize_col(all_movies, \"popularity\")\nnormalize_col(all_movies, \"runtime\")\nnormalize_col(all_movies, \"budget\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c4991671b7c9f947439a49d6d4a81eef34e98f67"},"cell_type":"code","source":"all_movies[[\"popularity_norm\", \"runtime_norm\", \"budget_norm\"]].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72ef5e3a0040f082618dc8cdb0ffe6f517503fc6"},"cell_type":"code","source":"train = all_movies.iloc[:train_idx]\ntest = all_movies.iloc[train_idx:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d2007cd816a6531764e45170eeaf71acaa92c792"},"cell_type":"code","source":"all_movies.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a1f7ef62a85e63a898b35433ae701fd4825e6665"},"cell_type":"markdown","source":"# Data Exploration"},{"metadata":{"trusted":true,"_uuid":"325c1185256cc4e037ad6c14d56fee4c3ffa9678","scrolled":false},"cell_type":"code","source":"month_pivot = train.pivot_table(index=\"release_month\", values=\"revenue\", aggfunc=np.mean)\nmonth_pivot.plot.bar()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8e08c559d9b9a712fa4b6e28da80001e905dbb46"},"cell_type":"markdown","source":"Summer and winter months when the family is all together seem to be like better months for movie revenue. I'll simplify the month features to one hot encode summer and winter months."},{"metadata":{"trusted":true,"_uuid":"634d011ede136724f7e84a989caa4858abcb1e9a"},"cell_type":"code","source":"all_movies[\"release_month\"].dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"55bf518f1f2a565e428ec1a2be9319c338d76082"},"cell_type":"code","source":"all_movies[\"summer\"] = all_movies[\"release_month\"].apply(lambda x: 1 if x in ['5','6','7'] else 0)\nall_movies[\"winter\"] = all_movies[\"release_month\"].apply(lambda x: 1 if x in ['11', '12'] else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"72ef5e3a0040f082618dc8cdb0ffe6f517503fc6"},"cell_type":"code","source":"train_idx = train.shape[0]\ntrain = all_movies.iloc[:train_idx]\ntest = all_movies.iloc[train_idx:]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91c6880b48772e49eb17d885cb9feb52e6fc74b2"},"cell_type":"markdown","source":"# Modeling"},{"metadata":{"trusted":true,"_uuid":"2ec21bff46ff1b3b7b5162dbba76fa32e9787199"},"cell_type":"code","source":"train.columns.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"05f0e985a01c5a3e887bb7bb733e12228916fe0a"},"cell_type":"code","source":"simple_features = ['popularity_norm', 'runtime_norm', 'budget_norm']\nother_features = ['has_webpage']\noverview_features = [col for col in train.columns.tolist() if \"overview\" in col]\ntagline_features = [col for col in train.columns.tolist() if \"tagline\" in col]\ncompany_features = [col for col in train.columns.tolist() if \"production_companies\" in col]\ncountry_features = [col for col in train.columns.tolist() if \"production_countries\" in col]\nspoken_lang_features = [col for col in train.columns.tolist() if \"spoken_languages\" in col]\nkeyword_features = [col for col in train.columns.tolist() if \"Keywords_\" in col]\ncast_gender_features = [col for col in train.columns.tolist() if \"cast_gender_\" in col]\nmonth_features = [col for col in train.columns.tolist() if \"month_\" in col]\nseason_features = ['summer', 'winter']\njune = ['month_6']\nall_features =  [col for col in train.columns.tolist() if col not in [\"revenue\", \"id\", \"released_month\",\n                                                                     \"budget\", \"popularity\", \"runtime\"]]\ngenre_features = ['Drama',\n 'Comedy',\n 'Thriller',\n 'Action',\n 'Romance',\n 'Adventure',\n 'Crime',\n 'Science Fiction',\n 'Horror',\n 'Family',\n 'Fantasy',\n 'Mystery',\n 'Animation',\n 'History',\n 'Music',\n 'War',\n 'Documentary',\n 'Western',\n 'Foreign']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d313d82dc912098614ec7f95aac5b9da4ea8d6a8","_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"feature_sets = [simple_features,other_features,overview_features,tagline_features,\n                company_features,country_features,spoken_lang_features,keyword_features,\n                cast_gender_features,month_features,season_features,june,\n                all_features,genre_features]\nfeature_set_strings = [\"simple_features\",\"other_features\",\"overview_features\",\"tagline_features\",\n                \"company_features\",\"country_features\",\"spoken_lang_features\",\"keyword_features\",\n                \"cast_gender_features\",\"month_features\", \"season_features\", \"june\",\n                       \"all_features\",\"genre_features\"]\n\ny = train[\"revenue\"]\nk_s = [3,5,7,9,11,13,15, 17, 19]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    print(set_string)\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        i = 0\n        print(str(k)+\" neighbors\")\n        for train_idx, test_idx in kf.split(X):\n            i +=1\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n            print(\"Fold \"+str(i) + \": \"+str(round(error,4)))\n        print(set_string + \" \"+ str(k)+\" neigbors mean: \" + str(round(np.mean(feature_set_errors),4)))\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"229b97c2fc25252dd3c85a0fd6230d438ffe8389"},"cell_type":"code","source":"model_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:30]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"414a79043af3a0354369e94684a013ecef3099a2"},"cell_type":"markdown","source":"Now, test company, country, june features with between 1 and 7 neighbors. More than 7 seems to underfit."},{"metadata":{"trusted":true,"_uuid":"d313d82dc912098614ec7f95aac5b9da4ea8d6a8","_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true},"cell_type":"code","source":"all_features = simple_features + other_features + company_features + country_features + june\nmy_hunch = simple_features + company_features + june\nfeature_sets = [simple_features,other_features,company_features,country_features,\n                june, all_features, my_hunch]\nfeature_set_strings = ['simple_features','other_features','company_features','country_features',\n                       'june', 'all_features', 'my_hunch']\n\ny = train[\"revenue\"]\nk_s = [k for k in range(1,8)]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    print(set_string)\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        i = 0\n        print(str(k)+\" neighbors\")\n        for train_idx, test_idx in kf.split(X):\n            i +=1\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n            print(\"Fold \"+str(i) + \": \"+str(round(error,4)))\n        print(set_string + \" \"+ str(k)+\" neigbors mean: \" + str(round(np.mean(feature_set_errors),4)))\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"3fb01ff185092189e585176f0119d5bfc784e6a1"},"cell_type":"code","source":"model_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:25]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"db9796fffe6cf8cd6215d935423d7aef3d56979d"},"cell_type":"markdown","source":"Looks like I was wrong for these models with much fewer features."},{"metadata":{"trusted":true,"_uuid":"d313d82dc912098614ec7f95aac5b9da4ea8d6a8","_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true},"cell_type":"code","source":"all_features = simple_features + other_features + company_features + country_features + june\nmy_hunch = simple_features + company_features + june\nfeature_sets = [simple_features,other_features,company_features,country_features,\n                june, all_features, my_hunch]\nfeature_set_strings = ['simple_features','other_features','company_features','country_features',\n                       'june', 'all_features', 'my_hunch']\n\ny = train[\"revenue\"]\nk_s = [k for k in range(1,20)]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        for train_idx, test_idx in kf.split(X):\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])\nmodel_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:25]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d313d82dc912098614ec7f95aac5b9da4ea8d6a8","_kg_hide-input":true,"_kg_hide-output":true,"scrolled":true},"cell_type":"code","source":"my_hunch = simple_features + company_features + june\nfeature_sets = [company_features, my_hunch]\nfeature_set_strings = ['company_features','my_hunch']\n\ny = train[\"revenue\"]\nk_s = [k for k in range(1,30)]\nmodel_results = list()\nfor feature_set, set_string in zip(feature_sets, feature_set_strings):\n    features = list(set((feature_set + simple_features)))\n    X = train[features]\n    kf = KFold(n_splits=5, random_state=319, shuffle=True)\n    feature_set_errors = list()\n    for k in k_s:\n        for train_idx, test_idx in kf.split(X):\n            model = KNeighborsRegressor(n_neighbors=k)\n            X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n            model.fit(X_train, y_train)\n            predictions = model.predict(X_test)\n            error = np.sqrt(mean_squared_log_error(y_test, predictions))\n            feature_set_errors.append(error)\n        model_results.append([(set_string+\"_\"+str(k)), round(np.mean(feature_set_errors),4)])\nmodel_results = sorted(model_results, key=lambda x: x[1])\nmodel_results[:25]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d822dad74b3f34f35f2b7cd6f45ff198622feca3"},"cell_type":"markdown","source":"Still convinced from an initial result that k=17 is going to underfit."},{"metadata":{"trusted":true,"_uuid":"7fcbd2dda7717f6474b86418c652dbdd0c3b0b1f","scrolled":true},"cell_type":"code","source":"features = (company_features + simple_features)\nknn = KNeighborsRegressor(n_neighbors=17)\nknn.fit(train[features], train['revenue'])\npredictions17 = knn.predict(test[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74f2c70f5afcc42884a19cd1a66395a838c14023"},"cell_type":"code","source":"submission_df = {\"id\": test['id'], \"revenue\": predictions17}\nsubmission17 = pd.DataFrame(submission_df)\nsubmission17.to_csv(\"knn_submission_17.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7fcbd2dda7717f6474b86418c652dbdd0c3b0b1f","scrolled":true},"cell_type":"code","source":"features = (company_features + simple_features)\nknn = KNeighborsRegressor(n_neighbors=3)\nknn.fit(train[features], train['revenue'])\npredictions3 = knn.predict(test[features])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74f2c70f5afcc42884a19cd1a66395a838c14023"},"cell_type":"code","source":"submission_df = {\"id\": test['id'], \"revenue\": predictions3}\nsubmission3 = pd.DataFrame(submission_df)\nsubmission3.to_csv(\"knn_submission_3.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c603ba77aa08d2e850a8209c6fdad5532524cf8c"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}