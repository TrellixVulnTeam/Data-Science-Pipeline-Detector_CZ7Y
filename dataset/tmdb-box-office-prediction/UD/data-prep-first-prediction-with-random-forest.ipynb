{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import MultiLabelBinarizer, LabelEncoder, OneHotEncoder\nfrom sklearn.cluster import KMeans\nimport datetime as dtm\nimport missingno\nimport holidays\nfrom collections import Counter","execution_count":3,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Importing the raw data and Initial data exploration"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_data1 = pd.read_csv(\"../input/train.csv\")\nraw_data2 = pd.read_csv(\"../input/test.csv\")\nraw_data2[\"revenue\"] = 0\nraw_data1[\"train_test\"] = \"train\"\nraw_data2[\"train_test\"] = \"test\"\nraw_data = pd.concat([raw_data1, raw_data2],ignore_index=True)\ninput_Data = pd.DataFrame(raw_data)\ninput_Data[\"release_date_mod\"] = pd.to_datetime(input_Data[\"release_date\"], format=\"%m/%d/%y\")\ninput_Data[\"identifier\"] = input_Data[\"id\"]\ninput_Data = input_Data.drop([\"id\",\"homepage\", \"imdb_id\", \"original_title\", \"overview\", \"poster_path\", \"tagline\", \"title\"],axis = 1)","execution_count":9,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#### Columns with dictionaries are originally read as string. Converting them in to dictionary\ncolumns_with_dictionaries = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\nfor cols in columns_with_dictionaries:\n    input_Data[cols] = input_Data[cols].apply(lambda x: {} if pd.isna(x) else eval(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Exploratory data analysis - Univariate Analysis"},{"metadata":{},"cell_type":"markdown","source":"#### Understanding Missing Values"},{"metadata":{"trusted":false},"cell_type":"code","source":"missingno.bar(raw_data1,figsize=(15,6))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"missingno.bar(raw_data2,figsize=(15,6))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Understanding Belongs_to_collection variable"},{"metadata":{"trusted":false},"cell_type":"code","source":"#### Indicator if the movie belongs to a certain collection or series\n\ninput_Data[\"collection\"] = input_Data[\"belongs_to_collection\"].apply(lambda x: 0 if len(x) == 0 else 1)\ninput_Data = input_Data.drop(\"belongs_to_collection\", axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#### Checking if movies belonging to collection have higher average revenue as compared to non collection movies. \n#### The difference is clearly visible\n\nsns.barplot(x = \"collection\", y = \"revenue\",estimator=np.mean, data=input_Data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Understanding Genres"},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"genre_extract\"] = input_Data[\"genres\"].apply(lambda x: [\"genre na\"] if len(x) == 0 else [i[\"name\"] for i in x])\ninput_Data[\"genre_count\"] = input_Data[\"genre_extract\"].apply(lambda x: 0 if \"genre na\" in x else len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(15,4))\nplt.subplot(1,2,1)\nsns.countplot(\"genre_count\",data=input_Data)\nplt.subplot(1,2,2)\nsns.barplot(x = \"genre_count\",y = \"revenue\",data=input_Data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#### Converting the list of values to columns\nmlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"genre_extract\"]),columns=mlb.classes_, index=input_Data.index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#### deleting original variables which are not required\ninput_Data = input_Data.drop([\"genres\",\"genre_extract\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Understanding Release Date"},{"metadata":{"trusted":false},"cell_type":"code","source":"sum(input_Data[\"release_date_mod\"].isnull())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#### There was 1 movie with no release date. Googled and filled the actual release date.\ndtval = pd.to_datetime('01-05-2005', format= '%d-%m-%Y')\ninput_Data.loc[3828,\"release_date_mod\"] = dtval ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#### Generating other variables using Date\ninput_Data[\"year\"] = input_Data[\"release_date_mod\"].dt.year\ninput_Data[\"month\"] = input_Data[\"release_date_mod\"].dt.month\ninput_Data[\"day\"] = input_Data[\"release_date_mod\"].dt.day\ninput_Data[\"year\"] = input_Data[\"year\"].apply(lambda x: x-100 if x>2019 else x)\ninput_Data[\"release_date_mod\"] = pd.to_datetime(input_Data[['year','month','day']])\ninput_Data[\"day_of_week\"] = input_Data[\"release_date_mod\"].dt.weekday_name\ninput_Data[\"week_of_year\"] = input_Data[\"release_date_mod\"].dt.weekofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data = pd.concat([input_Data,pd.get_dummies(input_Data[\"day_of_week\"])],axis = 1)\ninput_Data = input_Data.drop(\"day_of_week\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#### Understanding if the release date was a holiday\ninput_Data[\"holiday1\"] = 0\nCountries = ['AR','AU','AT','BY','BE','BR','BG','CA','CO','HR','CZ','DK','FI','FRA','DE','HU','IND','IE','IT','JP','LT','LU','MX','NL','NZ','NO','PL','PT','PTE','RU','SI','SK','ZA','ES','SE','CH','UA','UK','US']\nfor i in range(len(Countries)):\n    for j in range(len(input_Data)):\n        try:\n            if input_Data.loc[j,\"holiday1\"] == 1:\n                continue\n            elif input_Data.loc[j,\"release_date_mod\"] in holidays.CountryHoliday(Countries[i]):\n                input_Data.loc[j,\"holiday1\"] = 1\n                continue\n            else:\n                continue\n        except:\n            continue","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data = input_Data.drop([\"release_date\", \"release_date_mod\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling Budget"},{"metadata":{"trusted":false},"cell_type":"code","source":"budget = pd.DataFrame(input_Data[[\"identifier\",\"year\",\"budget\"]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"cluster = budget[\"budget\"].values.reshape(-1,1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"score = []\nfor i in range(1,20):\n    model = KMeans(n_clusters=i)\n    model.fit(cluster)\n    score.append(model.inertia_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.plot(score,marker = \".\")\nplt.xticks(range(0,19,1))\nplt.annotate(\"# of clusters\", xy =(3,1000000000000000000), xytext = (7.5,5000000000000000000), arrowprops = dict(facecolor = \"black\"))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"check = pd.pivot_table(budget, index=\"year\", values=\"budget\", aggfunc=\"mean\").reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.barplot(x = \"year\", y = \"budget\", data=check)\nplt.xticks(rotation = 90)\nplt.show()\ndel check","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"budget[\"year_category\"] = budget[\"year\"].apply(lambda x: \"Before 1955\" if x<=1955 else (\"1955 to 1990\" if x<= 1990 else \"Post 1990\"))","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"avg_bud = pd.pivot_table(budget[budget[\"year\"] != 1927], index=\"year_category\", values=\"budget\", aggfunc=\"mean\").reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"avg_bud","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"budget = pd.merge(budget, avg_bud, on=\"year_category\", how=\"left\")\nbudget[\"Modified_budget\"] = budget[[\"budget_x\", \"budget_y\"]].apply(lambda x: x[1] if x[0] == 0 else x[0], axis = 1) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data = pd.merge(input_Data, budget[[\"identifier\", \"Modified_budget\"]], on=\"identifier\", how=\"left\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data = input_Data.drop(\"budget\", axis = 1)\ndel budget\ndel avg_bud\ndel cluster\ndel score\ndel model","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling spoken Languages"},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"language_extract\"] = input_Data[[\"original_language\",\"spoken_languages\"]].apply(lambda x: [x[0]] if len(x[1]) == 0 else [i[\"iso_639_1\"] for i in x[1]], axis = 1)\ninput_Data[\"language_coverage\"] = input_Data[\"language_extract\"].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(\"language_coverage\", data = input_Data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"language_extract\"]), index = input_Data.index, columns = mlb.classes_))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data = input_Data.drop([\"language_extract\",\"spoken_languages\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling Production Countries"},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"country_extract\"] = input_Data[\"production_countries\"].apply(lambda x: [\"country na\"] if len(x) == 0 else [i[\"name\"] for i in x])\ninput_Data[\"country_coverage\"] = input_Data[\"country_extract\"].apply(lambda x: 0 if 'country na' in x else len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.countplot(\"country_coverage\", data=input_Data)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#mlb = MultiLabelBinarizer()\n#language_check = input_Data[[\"year\", \"original_language\"]].join(pd.DataFrame(mlb.fit_transform(input_Data[\"Country_extract\"]), columns = mlb.classes_))\n#language_check_inter = language_check.groupby([\"year\", \"original_language\"]).sum().reset_index()\n#language_check_inter = language_check_inter.melt(id_vars=[\"year\", \"original_language\"], var_name=\"Country\")\n#language_check_inter = language_check_inter[language_check_inter[\"value\"] != 0]\n#language_check_inter = language_check_inter.sort_values([\"year\",\"original_language\",\"value\"], ascending = False).drop_duplicates([\"year\", \"original_language\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#input_Data = pd.merge(input_Data, language_check_inter[[\"year\", \"original_language\", \"Country\"]], on=[\"year\", \"original_language\"], how=\"left\")\n#input_Data[\"Country_extract_mod\"] = input_Data[[\"Country_extract\", \"Country\"]].apply(lambda x:  [x[1]] if \"Not Available\" in x[0] else x[0], axis = 1)\n#input_Data.at[1757,\"Country_extract_mod\"] = [\"Vietnam\"]\n#input_Data.at[2342,\"Country_extract_mod\"] = [\"Turkey\"]\n#input_Data.at[3939,\"Country_extract_mod\"] = [\"Germany\"]\n#input_Data.at[5526,\"Country_extract_mod\"] = [\"UnitedArabEmirates\"]\n#input_Data.at[6153,\"Country_extract_mod\"] = [\"Turkey\"]\n#input_Data[\"Country_coverage\"] = input_Data[\"Country_coverage\"].apply(lambda x: 1 if x == 0 else x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#sns.countplot(\"Country_coverage\", data=input_Data)\n#plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"country_extract\"]), index = input_Data.index, columns = mlb.classes_))\ninput_Data = input_Data.drop([\"country_extract\",\"production_countries\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling runtime null values"},{"metadata":{"trusted":false},"cell_type":"code","source":"np.isnan(input_Data[\"runtime\"]).sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"yearly_runtime = input_Data[np.isnan(input_Data[\"runtime\"]) == False][[\"year\",\"runtime\"]]\nyearly_runtime = pd.pivot_table(yearly_runtime, index=\"year\", values=\"runtime\", aggfunc=\"mean\").reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(15,6))\nsns.barplot(x=\"year\",y = \"runtime\", data = yearly_runtime)\nplt.xticks(rotation = 90)\nplt.show()\ndel yearly_runtime","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"runtime\"] = input_Data[\"runtime\"].fillna(np.mean(input_Data[\"runtime\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling Production Houses"},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"prod_house_extract\"] = input_Data[\"production_companies\"].apply(lambda x: \"prod house na\" if len(x) == 0 else [i[\"name\"] for i in x])\ninput_Data[\"prod_house_coverage\"] = input_Data[\"prod_house_extract\"].apply(lambda x: 0 if 'prod house na' in x else len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"mlb = MultiLabelBinarizer()\ninput_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"prod_house_extract\"]),columns=mlb.classes_, index = input_Data.index))\ninput_Data = input_Data.drop([\"prod_house_extract\",\"production_companies\"], axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling Crew\n- First finding the crew count\n- Second handling crew director\n- Third handling crew producer"},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"crew_count\"] = input_Data.crew.apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"crew_check = pd.pivot_table(input_Data, index=\"year\", values=\"crew_count\", aggfunc=\"mean\").reset_index()\nplt.figure(figsize=(15,6))\nsns.barplot(\"year\", \"crew_count\",data = crew_check)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"crew_count\"] = input_Data[\"crew_count\"].fillna(input_Data[\"crew_count\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"def get_crew(x,crew):\n    crew_ret = []\n    if crew == \"director\":\n        if pd.isnull(x) == True:\n            crew_ret.append(\"director not known\")\n        else:\n            for i,name in enumerate(re.split(\"}\",x)):\n                if len(re.findall(r\"Director'.*,\",str(name))) != 0:\n                    crew_ret.append(re.sub(r\"[',\\s\\\"\\]-]\",\"\",re.split(\":\",str(re.findall(r\"Director'.*,\",name)))[1]))\n                else:\n                    continue\n        if len(crew_ret) == 0:\n            crew_ret.append(\"No Director\")\n    else:\n        if pd.isnull(x) == True:\n            crew_ret.append(\"producer not known\")\n        else:\n            for i,name in enumerate(re.split(\"}\",x)):\n                if len(re.findall(r\"Producer'.*,\",str(name))) != 0:\n                    crew_ret.append(re.sub(r\"[',\\s\\\"\\]-]\",\"\",re.split(\":\",str(re.findall(r\"Producer'.*,\",name)))[1]))\n                else:\n                    continue\n        if len(crew_ret) == 0:\n            crew_ret.append(\"No Producer\")\n    return crew_ret","execution_count":null,"outputs":[]},{"metadata":{"scrolled":true,"trusted":false},"cell_type":"code","source":"#input_Data[\"Directors\"] = input_Data[\"crew\"].apply(get_crew,crew = \"director\")\n#input_Data[\"Producers\"] = input_Data[\"crew\"].apply(get_crew,crew = \"producer\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#mlb = MultiLabelBinarizer()\n#input_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"Directors\"]),columns=mlb.classes_+\"_director\", index = input_Data.index))\n#input_Data = input_Data.join(pd.DataFrame(mlb.fit_transform(input_Data[\"Producers\"]),columns=mlb.classes_+\"_producer\", index = input_Data.index))\n#input_Data = input_Data.drop([\"Directors\",\"Producers\",\"crew\"],axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data = input_Data.drop(\"crew\",axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Handling Cast"},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"cast_count\"] = input_Data.cast.apply(len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"crew_check = pd.pivot_table(input_Data, index=\"year\", values=\"cast_count\", aggfunc=\"mean\").reset_index()\nplt.figure(figsize=(15,6))\nsns.barplot(\"year\", \"cast_count\",data = crew_check)\nplt.xticks(rotation = 90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data[\"cast_count\"] = input_Data[\"cast_count\"].fillna(input_Data[\"cast_count\"].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"input_Data = input_Data.drop(\"cast\",axis = 1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# First Dataset for model development\n\n1. All the variables explored in their raw state with the following exceptions made:\n    - Target variable is log transformed\n    - In case of spoken language is blank, original language is used for imputation\n    - For continuous variables like budget, runtime etc, cluster and mean imputations are done\n2. Following needs to be explored\n    - Cast and crew names not explored till now. Information on cast and crew gender is not understood\n    - Different categories can be grouped on the basis of exploratory data analysis\n    - Transformation of Continuous variables depending upon their distributions\n    - hyperparameter tuning to get the best model results\n    - Feature engineering to see if any additional features can help in improving the predictions"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"nbformat":4,"nbformat_minor":1}