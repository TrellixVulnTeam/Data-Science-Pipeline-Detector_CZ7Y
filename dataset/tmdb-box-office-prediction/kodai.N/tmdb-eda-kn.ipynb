{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd  \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\nimport nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nimport string\n%matplotlib inline\n%precision 3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 欠損値の補完と追加データ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.loc[train['id'] == 1336,'runtime'] = 130 #kololyovの上映時間を調べて入力\ntrain.loc[train['id'] == 2303,'runtime'] = 80 #HappyWeekendの上映時間を調べて入力\ntrain.loc[train['id'] == 391,'runtime'] = 96 #The Worst Christmas of My Lifeの上映時間を調べて入力\ntrain.loc[train['id'] == 592,'runtime'] = 90 #А поутру они проснулисьの上映時間を調べて入力\ntrain.loc[train['id'] == 925,'runtime'] = 86 #¿Quién mató a Bambi?の上映時間を調べて入力\ntrain.loc[train['id'] == 978,'runtime'] = 93 #La peggior settimana della mia vitaの上映時間を調べて入力\ntrain.loc[train['id'] == 1256,'runtime'] = 92 #Cry, Onion!の上映時間を調べて入力\ntrain.loc[train['id'] == 1542,'runtime'] = 93 #All at Onceの上映時間を調べて入力\ntrain.loc[train['id'] == 1875,'runtime'] = 93 #Vermistの上映時間を調べて入力\ntrain.loc[train['id'] == 2151,'runtime'] = 108 #Mechenosetsの上映時間を調べて入力\ntrain.loc[train['id'] == 2499,'runtime'] = 86 #Na Igre 2. Novyy Urovenの上映時間を調べて入力\ntrain.loc[train['id'] == 2646,'runtime'] = 98 #My Old Classmateの上映時間を調べて入力\ntrain.loc[train['id'] == 2786,'runtime'] = 111 #Revelationの上映時間を調べて入力\ntrain.loc[train['id'] == 2866,'runtime'] = 96 #Tutto tutto niente nienteの上映時間を調べて入力\ntest.loc[test['id'] == 3244,'runtime'] = 93 #La caliente niña Julietta\tの上映時間を調べて入力\ntest.loc[test['id'] == 4490,'runtime'] = 90 #Pancho, el perro millonarioの上映時間を調べて入力\ntest.loc[test['id'] == 4633,'runtime'] = 108 #Nunca en horas de claseの上映時間を調べて入力\ntest.loc[test['id'] == 6818,'runtime'] = 90 #Miesten välisiä keskustelujaの上映時間を調べて入力\ntest.loc[test['id'] == 4074,'runtime'] = 103 #Shikshanachya Aaicha Ghoの上映時間を調べて入力\ntest.loc[test['id'] == 4222,'runtime'] = 91 #Street Knightの上映時間を調べて入力\ntest.loc[test['id'] == 4431,'runtime'] = 96 #Plus oneの上映時間を調べて入力\ntest.loc[test['id'] == 5520,'runtime'] = 86 #Glukhar v kinoの上映時間を調べて入力\ntest.loc[test['id'] == 5845,'runtime'] = 83 #Frau Müller muss weg!の上映時間を調べて入力\ntest.loc[test['id'] == 5849,'runtime'] = 140 #Shabdの上映時間を調べて入力\ntest.loc[test['id'] == 6210,'runtime'] = 104 #The Last Breathの上映時間を調べて入力\ntest.loc[test['id'] == 6804,'runtime'] = 140 #Chaahat Ek Nasha...の上映時間を調べて入力\ntest.loc[test['id'] == 7321,'runtime'] = 87 #El truco del mancoの上映時間を調べて入力","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_add = pd.read_csv('../input/tmdb-competition-additional-features/TrainAdditionalFeatures.csv')\ntest_add = pd.read_csv('../input/tmdb-competition-additional-features/TestAdditionalFeatures.csv')\n\ntrain = pd.merge(train, train_add, how='left', on=['imdb_id'])\ntest = pd.merge(test, test_add, how='left', on=['imdb_id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.concat([train, test]).set_index(\"id\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.loc[df.index == 90,'budget'] = 30000000\ndf.loc[df.index == 118,'budget'] = 60000000\ndf.loc[df.index == 149,'budget'] = 18000000\ndf.loc[df.index == 464,'budget'] = 20000000\ndf.loc[df.index == 819,'budget'] = 90000000\ndf.loc[df.index == 1112,'budget'] = 6000000\ndf.loc[df.index == 1131,'budget'] = 4300000\ndf.loc[df.index == 1359,'budget'] = 10000000\ndf.loc[df.index == 1570,'budget'] = 15800000\ndf.loc[df.index == 1714,'budget'] = 46000000\ndf.loc[df.index == 1865,'budget'] = 80000000\ndf.loc[df.index == 2602,'budget'] = 31000000\n#idが105と2941のものの予算は不明","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 各ワードの有無を表す 01 のデータフレームを作成\ndef count_word_list(series):\n    len_max = series.apply(len).max() # ジャンル数の最大値\n    tmp = series.map(lambda x: x+[\"nashi\"]*(len_max-len(x))) # listの長さをそろえる\n    \n    word_set = set(sum(list(series.values), [])) # 全ジャンル名のset\n    for n in range(len_max):\n        word_dfn = pd.get_dummies(tmp.apply(lambda x: x[n]))\n        word_dfn = word_dfn.reindex(word_set, axis=1).fillna(0).astype(int)\n        if n==0:\n            word_df = word_dfn\n        else:\n            word_df = word_df + word_dfn\n    \n    return word_df#.drop(\"nashi\", axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ralease date","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import datetime","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df[\"release_date\"].isnull()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 公開日の欠損1件 id=3829\n# May,2000 (https://www.imdb.com/title/tt0210130/) \n# 日は不明。1日を入れておく\ndf.loc[3829, \"release_date\"] = \"5/1/00\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"release_year\"] = pd.to_datetime(df[\"release_date\"]).dt.year.astype(int)\n# 年の20以降を、2020年より後の未来と判定してしまうので、補正。\ndf.loc[df[\"release_year\"]>2020, \"release_year\"] = df.loc[df[\"release_year\"]>2020, \"release_year\"]-100\n\ndf[\"release_month\"] = pd.to_datetime(df[\"release_date\"]).dt.month.astype(int)\ndf[\"release_day\"] = pd.to_datetime(df[\"release_date\"]).dt.day.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"release_year\"] = pd.to_datetime(train[\"release_date\"]).dt.year.astype(int)\n# 年の20以降を、2020年より後の未来と判定してしまうので、補正。\ntrain.loc[train[\"release_year\"]>2020, \"release_year\"] = train.loc[train[\"release_year\"]>2020, \"release_year\"]-100\n\ntrain[\"release_month\"] = pd.to_datetime(train[\"release_date\"]).dt.month.astype(int)\ntrain[\"release_day\"] = pd.to_datetime(train[\"release_date\"]).dt.day.astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.lineplot(x=\"release_year\", y=\"budget\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.lineplot(x=\"release_year\", y=\"revenue\", data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(train.release_year)\nplt.xticks(rotation=90)\nplt.xlabel('Years')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['budget_releaseyear_ratio'] = train['budget']/train['release_year']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.distplot(train['budget_releaseyear_ratio'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## belongstocollection","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df['isbelongs_to_collectionNA'] = 1\ndf.loc[pd.isnull(df['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['isbelongs_to_collectionNA'] = 1\ntrain.loc[pd.isnull(train['belongs_to_collection']) ,\"isbelongs_to_collectionNA\"] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='isbelongs_to_collectionNA', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.boxplot(x='isbelongs_to_collectionNA', y='revenue', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"シリーズものはrevenueが高いのでシリーズがあるかどうかを特徴量に入れてみる","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## genres","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# JSON text を辞書型のリストに変換\nimport ast\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\nfor col in dict_columns:\n    df[col]=df[col].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x) )\n    train[col]=train[col].apply(lambda x: [] if pd.isna(x) else ast.literal_eval(x) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"genre_names\"] = df[\"genres\"].apply(lambda x : [ i[\"name\"] for i in x])\ntrain[\"genre_names\"] = train[\"genres\"].apply(lambda x : [ i[\"name\"] for i in x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['num_genres'] = df['genres'].apply(lambda x: len(x) if x != {} else 0)\ntrain['num_genres'] = train['genres'].apply(lambda x: len(x) if x != {} else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.barplot(x='num_genres', y='revenue', data=train);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"genre数が3,4が収益は高い","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## production company","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"production_names\"] = df[\"production_companies\"].apply(lambda x : [ i[\"name\"] for i in x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['production_companies_count'] = df['production_companies'].apply(lambda x : len(x))\ntrain['production_companies_count'] = train['production_companies'].apply(lambda x : len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['production_companies']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['production_companies_count'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.countplot(x='production_companies_count', data=train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(15,8))\nsns.stripplot(x='production_companies_count', y='revenue', data=train);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tmp = count_word_list(df[\"production_names\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[\"production_names\"]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## title","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list'] = train['title'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#記号の排除\ndef remove_punct(text):\n    table=str.maketrans('','',string.punctuation)\n    return text.translate(table)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"title\"]=train[\"title\"].apply(lambda x : remove_punct(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#全て小文字に変換\ndef lower_text(text):\n    return text.lower()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"title\"]=train[\"title\"].apply(lambda x : lower_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#短縮形を元に戻す\nshortened = {\n    '\\'m': ' am',\n    '\\'re': ' are',\n    'don\\'t': 'do not',\n    'doesn\\'t': 'does not',\n    'didn\\'t': 'did not',\n    'won\\'t': 'will not',\n    'wanna': 'want to',\n    'gonna': 'going to',\n    'gotta': 'got to',\n    'hafta': 'have to',\n    'needa': 'need to',\n    'outta': 'out of',\n    'kinda': 'kind of',\n    'sorta': 'sort of',\n    'lotta': 'lot of',\n    'lemme': 'let me',\n    'gimme': 'give me',\n    'getcha': 'get you',\n    'gotcha': 'got you',\n    'letcha': 'let you',\n    'betcha': 'bet you',\n    'shoulda': 'should have',\n    'coulda': 'could have',\n    'woulda': 'would have',\n    'musta': 'must have',\n    'mighta': 'might have',\n    'dunno': 'do not know',\n}\ndf[\"title\"] = df[\"title\"].replace(shortened)\ntrain[\"title\"] = train[\"title\"].replace(shortened)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(text):\n    return [w for w in text if not w in stop]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list'] = train['title'].apply(lambda x:str(x).split())\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}