{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"## importing the necessary packages\nimport pandas as pd\nimport ast\nfrom collections import defaultdict\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nfrom scipy import stats\nimport datetime as dt\nimport xgboost as xgb\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import mean_squared_error\n","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/train.csv')\ntest = pd.read_csv('../input/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Fixing values that are missing/incorrect for the train and test sets\n## These are given pre-release so there is no leakage in the data\n## Thanks to the discussion forums for this information\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\ntrain.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000\n\n\ntest.loc[test['id'] == 6733,'budget'] = 5000000\ntest.loc[test['id'] == 3889,'budget'] = 15000000\ntest.loc[test['id'] == 6683,'budget'] = 50000000\ntest.loc[test['id'] == 5704,'budget'] = 4300000\ntest.loc[test['id'] == 6109,'budget'] = 281756\ntest.loc[test['id'] == 7242,'budget'] = 10000000\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\ntest.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# getting the number of NA values\n# test na: homepage 2978, overview 14, poster_path 1, release_date 1, runtime 4, status 2, \n# tagline 863, title 3, \nprint(\"Test NA: \",test.isna().sum())\n# train na: homepage: 2054, overview 8, poster_path 1, runtime 2, tagline 597\nprint(\"\\nTrain NA: \",train.isna().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# certain columns have issues with dictionaries coming through, so those need to\n# be adjusted\nissue_cols = ['belongs_to_collection', 'genres','production_companies','production_countries',\n              'spoken_languages','Keywords','cast','crew']\ndef fix_cols(df, cols):\n    for col in cols:\n        df[col] = df[col].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n    return df\n\ntrain = fix_cols(train, issue_cols)\ntest = fix_cols(test, issue_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## adjusting the collection columns\ntrain['collection_name'] = train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x!={} else '')\ntest['collection_name'] = test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x!={} else '')\ntrain['has_collection'] = train['collection_name'].apply(lambda x: 0 if '' else 1)\ntest['has_collection'] = test['collection_name'].apply(lambda x: 0 if '' else 1)\n\ntrain = train.drop(['belongs_to_collection'], axis=1)\ntest = test.drop(['belongs_to_collection'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fixing most of the columns at once\ndef fixing_columns(train, test, original_col, count_col, num_to_return):\n    train[original_col] = train[original_col].apply(lambda x: sorted(i['name'] for i in x) if x != {} else '')\n    train[count_col] = train[original_col].apply(lambda x: len(x))\n    \n    col_list = list(train[original_col].apply(lambda x: [i for i in x]))\n    col_counts = defaultdict(int)\n    for row in col_list:\n        for i in row:\n            col_counts[i] += 1\n        \n    top = [i[0] for i in sorted(col_counts.items(), key=lambda kv: kv[1], reverse=True)[:num_to_return]]\n    \n    # One hot encoding if the production company is in the top 20 and exists in the record\n    for top_var in list(top):\n        train[top_var] = train[original_col].apply(lambda x: 1 if top_var in x else 0)\n    \n    # doing the same for test\n    # fixing the production_companies column and adding a pc count column\n    test[original_col] = test[original_col].apply(lambda x: sorted(i['name'] for i in x) if x != {} else '')\n    test[count_col] = test[original_col].apply(lambda x: len(x))\n    \n    # One hot encoding if the production company is in the top 20 and exists in the record\n    for top_var in list(top):\n        test[top_var] = test[original_col].apply(lambda x: 1 if top_var in x else 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# how many top values to keep for each column\nnumber_to_keep = [20, 20, 5, 3, 10, 10, 10]\nissue_cols = ['genres','production_companies','production_countries',\n              'spoken_languages','Keywords','cast','crew']\nfor i in range(len(issue_cols)):\n    fixing_columns(train, test, issue_cols[i],'num_'+issue_cols[i],number_to_keep[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping the unnecessary columns\ndrop_columns = ['genres','homepage','imdb_id','original_title','overview','poster_path',\n                'production_companies','production_countries','spoken_languages',\n                'status','tagline','title','Keywords','cast','crew']\ntrain = train.drop(drop_columns, axis=1)\ntest = test.drop(drop_columns, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing the N/A values and just replacing them with 0\nprint(\"Test NA: \",test.columns[test.isna().sum()>0].tolist())\nprint(\"\\nTrain NA: \",train.columns[train.isna().sum()>0].tolist())\n\ntrain[train.isna().any(axis=1)]   \ntrain[train.isna().any(axis=1)]    \n\n# using 0 to fill the na columns\ntrain.fillna(0, inplace=True)\ntest.fillna(0, inplace=True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# adjusting the date values\ndef date_adjust(df):\n    # getting the release date into proper format\n    df[['release_month', 'release_day','release_year']] = df['release_date'].str.split('/',expand=True).replace(np.nan,0).astype(int)\n    \n    #df.loc[df['release_year'] <=18, 'release_year'] += 2000\n    #df.loc[df['release_year'] > 18, 'release_year'] += 1900\n    releaseDate = pd.to_datetime(df['release_date'])\n    df['release_week'] = releaseDate.dt.week\n    df['release_dayofweek'] = releaseDate.dt.dayofweek\n    df['release_quarter'] = releaseDate.dt.quarter\n    df['original_english'] = df['original_language'].apply(lambda x: 1 if x == 'en' else 0)\n    df = df.drop(['collection_name','original_language','release_date'], axis=1)\n\n\ndate_adjust(train)\ndate_adjust(test)\n\ntrain = train.drop(['collection_name','original_language','release_date','id'], axis=1)\ntest = test.drop(['collection_name','original_language','release_date','id'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating some new features based on combinations of high performing ones\n\ndef feature_transform(df):\n    df['budget_runtime'] = (df['budget'] + 1)/(df['runtime']+1)\n    df['poularity_year'] = (df['popularity']+1)/(df['release_year']+1)\n    df['budget_popularity'] = (df['budget']+1)/(df['popularity']+1)\n    df['budget_year'] = (df['budget'] + 1)/(df['release_year']+1)\n    df['runtime_year'] = (df['runtime']+1)/(df['release_year']+1)\n\nfeature_transform(train)\nfeature_transform(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['budget'] = train['budget'].apply(np.log1p)\ntest['budget'] = test['budget'].apply(np.log1p)\nX = np.asarray(train.drop(['revenue'], axis=1))\ny = np.asarray(train.revenue.apply(np.log1p))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# training and running an xgboost model\nparams = {'objective':'reg:linear',\n          'eta':0.01,\n          'max_depth':6,\n          'min_child_weight':3,\n          'subsample':0.8,\n          'colsample_bytree':0.8,\n          'colsample_bylevel':.5,\n          'gamma':1.45,\n          'eval_metric':'rmse',\n          'seed':1,\n          'silent':True}\n\ndef train_xgb(X_train, y_train, X_test, y_test):\n    xgb_data = [(xgb.DMatrix(X_train, y_train), 'train'), (xgb.DMatrix(X_test, y_test),'valid')]\n    xgb_model = xgb.train(params, xgb.DMatrix(X_train,y_train),\n          5000, xgb_data,\n          verbose_eval=100,\n          early_stopping_rounds=500)\n    return xgb_model\n\nerror = []\nkf = list(KFold(n_splits=10, random_state=1, shuffle=True).split(X))\nfor i, (train_index, test_index) in enumerate(kf):\n    X_train, X_test =X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n    \n    xgb_model = train_xgb(X_train, y_train, X_test, y_test)\n    error.append(xgb_model.best_score)\n    \nprint(\"Error: {} +/- {}\".format(np.mean(error), np.std(error)))\n  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting the feature importance of the last fold\nxgb_model.feature_names = train.columns.tolist()\nfig, ax = plt.subplots(figsize=(20,10))\nxgb.plot_importance(xgb_model, max_num_features=30,ax=ax, height=.9)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fitting on the full training set\nxgb_full_train = xgb.XGBRegressor(objective = 'reg:linear',\n                                  eta = 0.01,\n                                  max_depth = 6,\n                                  min_child_weight = 3,\n                                  subsample = 0.8,\n                                  colsample_bytree = 0.7,\n                                  eval_metric = 'rmse',\n                                  seed = 1,\n                                  n_estimators = 2800)\n\n\nxgb_full_train.fit(X, y)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_predictions = xgb_full_train.predict(test.values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv(\"../input/sample_submission.csv\")\nsubmission['revenue'] = np.exp(y_predictions)\n\n\nsubmission.to_csv('xgb_sub.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}