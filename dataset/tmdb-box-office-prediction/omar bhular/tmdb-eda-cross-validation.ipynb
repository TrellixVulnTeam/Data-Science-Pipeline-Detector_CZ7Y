{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# <u>**TMDB BOX OFFICE PREDICTION**</u>"},{"metadata":{},"cell_type":"markdown","source":"## Introduction\n\nIn a worldâ€¦ where movies made an estimated $41.7 billion in 2018, the film industry is more popular than ever. But what movies make the most money at the box office? How much does a director matter? Or the budget? For some movies, it's \"You had me at 'Hello.'\" For others, the trailer falls short of expectations and you think \"What we have here is a failure to communicate.\""},{"metadata":{},"cell_type":"markdown","source":"## Import Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib as mpl\nimport matplotlib.pyplot as plt \nimport matplotlib.dates as md\n%matplotlib inline\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport statsmodels.api as sm\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import make_scorer\nimport ast\nfrom scipy import stats\nfrom sklearn.linear_model import LinearRegression\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\nplt.style.use('seaborn')\nmpl.rcParams['figure.figsize'] = (15,5)\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Read Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# data from https://www.kaggle.com/c/tmdb-box-office-prediction/data\ndf_train = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tmdb-box-office-prediction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_train.shape)\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_test.shape)\ndf_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Describe the Datasets\n### <font color = 'blue'>Training Dataframe </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color = 'blue'>Testing Dataframe </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <font color = 'blue'>Read Data Summary </font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_vary = []\ntest_col = df_test.columns\ntrain_col = df_train.columns\nvar = list(set(df_train)-set(df_test))\n\nprint(\"The Training DataFrame contains all the same Headers as the Testing DataFrame except \" + str(var[0])) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From our initial look of the data we see that we have 2 diffent data sets. \n\n<b>Training:</b> \n<ul>\n    <li>Has 3000 rows of data and 23 columns </li>\n    <li>Looking at the Medium and the Mean there seems to be some outliers with the <b>Budget</b> and <b>Runtime</b></li>\n    <li>It is odd that there are runtime and budgets of 0</li>            \n</ul>\n<b>Test:</b>\n<ul>\n    <li>This will be used to run our analysis on to predict <b>Revenue</b> </li>\n    <li>Has 4398 Rows of Data </li>\n</ul>\n      "},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Outliers\n\nFrom Reading our data we noticed Outlier values. Here we will create a secondary Dataframe that will remove outliers for both <b>Runtime</b> and <b>Budget</b>"},{"metadata":{},"cell_type":"markdown","source":"### <font color = 'blue'>Runtime</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df_train['runtime'])\nplt.title('Boxplot of Runtime')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### <font color = 'blue'>Budget</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df_train['budget'])\nplt.title('Boxplot of Budget')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_na = df_train.isna().sum().sort_values(ascending=True)\ndf_train_na.plot(kind='barh')\nplt.title(\"Distribution of NA\")\n\nfor i, v in enumerate(sorted(df_train_na)):\n    plt.text(v, i, str(v), va=\"center\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### <font color = 'blue'>Remove Outliers</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"bq_low = df_train['budget'].quantile(0.01)\nbq_hi  = df_train['budget'].quantile(0.99)\nrq_low = df_train['runtime'].quantile(0.01)\nrq_hi  = df_train['runtime'].quantile(0.99)\ndf_train_filtered = df_train[(df_train['budget'] < bq_hi) & (df_train['budget'] > bq_low) & (df_train['runtime'] < rq_hi) & (df_train['runtime'] > rq_low)]\ndf_train_filtered.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df_train_filtered['runtime'])\nplt.title('Boxplot of Runtime(Outliers Removed)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=df_train_filtered['budget'])\nplt.title('Boxplot of Budget(Outliers Removed)')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train) - len(df_train_filtered)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" ### <font color = 'blue'> Outliers Summary</font>\nRemoving Outliers removes 885 rows. If the dataset was larger it may be useful to remove outliers but since the Dataset is so small it may be useful to keep the outliers in training our model"},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Dictionary Columns\nReading our data we noticed that there were Dictionaries in our data frame. we need to convert columns with Dictionaries into actual dictionaries that we can use."},{"metadata":{"trusted":true},"cell_type":"code","source":"# from this kernel: https://www.kaggle.com/gravix/gradient-in-a-box\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ndf_train = text_to_dict(df_train)\ndf_test = text_to_dict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head(2)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Manipulating Data"},{"metadata":{},"cell_type":"markdown","source":"### Belongs to Collection\n#### <font color = 'blue'>Training Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# original code from: https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation\n\n# creates a new column with collection name\ndf_train['collection_name'] = df_train['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ndf_train['collection_name'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a bool val if in collection or not\ndf_train['has_collection'] = df_train['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\ndf_train['has_collection'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"col_count = df_train['has_collection'].value_counts()\nprint(\" In the Trainining data there are \" + str(col_count[0])+\" Films in a collection\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <font color = 'blue'>Testing Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a new column with collection name for Testing df\ndf_test['collection_name'] = df_test['belongs_to_collection'].apply(lambda x: x[0]['name'] if x != {} else 0)\ndf_test['collection_name'].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a bool val if in collection or not for Testing df\ndf_test['has_collection'] = df_test['belongs_to_collection'].apply(lambda x: len(x) if x != {} else 0)\ndf_test['has_collection'].head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Genres\n#### <font color = 'blue'>Training Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# original code from: https://www.kaggle.com/artgor/eda-feature-engineering-and-model-interpretation\n\n# creates a list of all the possible genres\nlist_of_genres = list(df_train['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_genres column on the train df that has the number of genres that a movie has.\ndf_train['num_genres'] = df_train['genres'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the genres out of the Dictionary \ndf_train['all_genres'] = df_train['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n# create a list of unique genres for Training dataframe\nunique_genres = []\nfor l in list_of_genres:\n    for g in l:\n        if g not in unique_genres:\n            unique_genres.append(g)\n        else:\n            pass\n# create a separate column for all the genres with bool values if true\nfor g in unique_genres:\n    df_train['genre_' + g] = df_train['all_genres'].apply(lambda x: 1 if g in x else 0)\ndf_train.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <font color = 'blue'>Testing Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible genres for Testing df\nlist_of_genres = list(df_test['genres'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_genres column on the test df that has the number of genres that a movie has.\ndf_test['num_genres'] = df_test['genres'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the test df that takes all the genres out of the Dictionary \ndf_test['all_genres'] = df_test['genres'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n\n\n# create a separate column for all the genres with bool values if true\nfor g in unique_genres:\n    df_test['genre_' + g] = df_test['all_genres'].apply(lambda x: 1 if g in x else 0)\n        \ndf_test.head(3)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Production Company\n#### <font color = 'blue'>Training Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible production companies\nlist_of_production = list(df_train['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_prod_co column on the train df that has the number of genres that a movie has.\ndf_train['num_prod_co'] = df_train['production_companies'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the production companies out of the Dictionary \ndf_train['all_prod_co'] = df_train['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n# create a list of unique genres for Training dataframe\nunique_prod_co = []\nfor l in list_of_production:\n    for g in l:\n        if g not in unique_prod_co:\n            unique_prod_co.append(g)\n        else:\n            pass\nprint(\" There are \"+ str(len(unique_prod_co)) + \" unique Production Companies\")\n# creates a boolean column on the train df for each of the possible production co\ntop_prod_co = [m[0] for m in Counter([i for j in list_of_production for i in j]).most_common(15)]\nfor g in top_prod_co:\n    df_train['prod_co_' + g] = df_train['all_prod_co'].apply(lambda x: 1 if g in x else 0)\n    \ntop_prod_co","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"> #### <font color = 'blue'>Testing Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"list_of_production = list(df_test['production_companies'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_prod_co column on the train df that has the number of genres that a movie has.\ndf_test['num_prod_co'] = df_test['production_companies'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the production companies out of the Dictionary \ndf_test['all_prod_co'] = df_test['production_companies'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n# creates a boolean column on the train df for each of the possible production co\ntop_prod_co = [m[0] for m in Counter([i for j in list_of_production for i in j]).most_common(15)]\nfor g in top_prod_co:\n    df_test['prod_co_' + g] = df_test['all_prod_co'].apply(lambda x: 1 if g in x else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Keywords\n#### <font color = 'blue'>Training Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible keywords\nlist_of_keywords = list(df_train['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_keywords column on the train df that has the number of keywords.\ndf_train['num_keywords'] = df_train['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the keywords out of the Dictionary \ndf_train['all_keywords'] = df_train['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n# create a list of unique keywords for Training dataframe\nunique_keywords = []\nfor l in list_of_keywords:\n    for g in l:\n        if g not in unique_keywords:\n            unique_keywords.append(g)\n        else:\n            pass\nprint(\" There are \"+ str(len(unique_keywords)) + \" unique Keywords\")\n# creates a boolean column on the train df for each of the possible keywords\ntop_keywords = [m[0] for m in Counter([i for j in list_of_keywords for i in j]).most_common(15)]\nfor g in top_keywords:\n    df_train['keyword_' + g] = df_train['all_keywords'].apply(lambda x: 1 if g in x else 0)\n    \ntop_keywords\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <font color ='blue'>Testing Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible keywords\nlist_of_keywords = list(df_test['Keywords'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_keywords column on the train df that has the number of keywords.\ndf_test['num_keywords'] = df_test['Keywords'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the keywords out of the Dictionary \ndf_test['all_keywords'] = df_test['Keywords'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_keywords:\n    df_test['keyword_' + g] = df_test['all_keywords'].apply(lambda x: 1 if g in x else 0)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Cast\n#### <font color = 'blue'>Training Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible cast\nlist_of_cast = list(df_train['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_keywords column on the train df that has the number of keywords.\ndf_train['num_cast'] = df_train['cast'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the keywords out of the Dictionary \ndf_train['all_cast'] = df_train['cast'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n# create a list of unique keywords for Training dataframe\nunique_cast = []\nfor l in list_of_cast:\n    for g in l:\n        if g not in unique_cast:\n            unique_cast.append(g)\n        else:\n            pass\nprint(\" There are \"+ str(len(unique_cast)) + \" unique cast\")\n# creates a boolean column on the train df for each of the possible keywords\ntop_cast = [m[0] for m in Counter([i for j in list_of_cast for i in j]).most_common(15)]\nfor g in top_cast:\n    df_train['cast_' + g] = df_train['all_cast'].apply(lambda x: 1 if g in x else 0)\ntop_cast","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <font color ='blue'>Testing Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible cast\nlist_of_cast = list(df_test['cast'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_keywords column on the train df that has the number of keywords.\ndf_test['num_cast'] = df_test['cast'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the keywords out of the Dictionary \ndf_test['all_cast'] = df_test['cast'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_cast:\n    df_test['cast_' + g] = df_test['all_cast'].apply(lambda x: 1 if g in x else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Crew\n#### <font color = 'blue'> Training Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible cast\nlist_of_crew = list(df_train['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_keywords column on the train df that has the number of keywords.\ndf_train['num_crew'] = df_train['crew'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the keywords out of the Dictionary \ndf_train['all_crew'] = df_train['crew'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\n# create a list of unique keywords for Training dataframe\nunique_crew = []\nfor l in list_of_crew:\n    for g in l:\n        if g not in unique_crew:\n            unique_crew.append(g)\n        else:\n            pass\nprint(\" There are \"+ str(len(unique_crew)) + \" unique cast\")\n# creates a boolean column on the train df for each of the possible keywords\ntop_crew = [m[0] for m in Counter([i for j in list_of_crew for i in j]).most_common(15)]\nfor g in top_crew:\n    df_train['crew_' + g] = df_train['all_crew'].apply(lambda x: 1 if g in x else 0)\ntop_crew","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <font color = 'blue'>Training Dataframe</font>\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creates a list of all the possible cast\nlist_of_crew = list(df_test['crew'].apply(lambda x: [i['name'] for i in x] if x != {} else []).values)\n# creates a num_keywords column on the train df that has the number of keywords.\ndf_test['num_crew'] = df_test['crew'].apply(lambda x: len(x) if x != {} else 0)\n# creates a column on the train df that takes all the keywords out of the Dictionary \ndf_test['all_crew'] = df_test['crew'].apply(lambda x: ' '.join(sorted([i['name'] for i in x])) if x != {} else '')\nfor g in top_crew:\n    df_test['crew_' + g] = df_test['all_crew'].apply(lambda x: 1 if g in x else 0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Month / DOW\n#### <font color = 'blue'> Training Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['release_date'] = pd.DataFrame(pd.to_datetime(df_train['release_date'],dayfirst=True))\ndf_train['release_month'] = df_train['release_date'].dt.month\ndf_train['release_DOW'] = df_train['release_date'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### <font color = 'blue'>Testing Dataframe</font>"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['release_date'] = pd.DataFrame(pd.to_datetime(df_test['release_date'],dayfirst=True))\ndf_test['release_month'] = df_test['release_date'].dt.month\ndf_test['release_DOW'] = df_test['release_date'].dt.dayofweek","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(15, 20))\ndf_train_corr = df_train.corr()\nax = sns.heatmap(df_train_corr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train_corr[['revenue']].sort_values(by=['revenue'],ascending = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"---"},{"metadata":{},"cell_type":"markdown","source":"## Predictions\n### <font color = 'green'>Linear Regression</font>\nWith the R value for budget and revenue being pretty high at  0.75 we want to find a model that produces better results than relying on a linear regression model. "},{"metadata":{"trusted":true},"cell_type":"code","source":"slope, intercept, r_value, p_value, std_err = stats.linregress(df_train['budget'],df_train['revenue'])\nax = sns.regplot(data=df_train, x='budget',y='revenue',line_kws={'label':\"y={0:.1f}x+{1:.1f}\".format(slope,intercept)})\nax.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_linear = np.array(df_train['budget']).reshape(-1,1)\ny_linear = np.array(df_train['revenue']).reshape(-1,1)\nmodel_linear=LinearRegression()\nmodel_linear.fit(X_linear,y_linear)\ny_pred = model_linear.predict(X_linear)\nval_mae = mean_absolute_error(y_linear,y_pred)\nval_mape = np.mean(np.abs((y_linear - y_pred) / y_linear)) * 100\nprint( 'MAE: ' + str(val_mae))\nprint('MAPE: '+ str(val_mape))\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"With Linear Regression we get a Mean Absolute Error value of <b>45M</b>. While the R value is pretty high, such a high MAE is not a great predictor of Box office revenue."},{"metadata":{},"cell_type":"markdown","source":"### <font color = 'green'>Cross Validation with Random Forrest</font>"},{"metadata":{},"cell_type":"markdown","source":"First we need to confirm Training and Testing Dataframe contain all the same columns besides revenue"},{"metadata":{"trusted":true},"cell_type":"code","source":"col_vary = []\ntest_col = df_test.columns\ntrain_col = df_train.columns\nvar = list(set(df_train)-set(df_test))\n\nprint(\"The Training DataFrame contains all the same Headers as the Testing DataFrame except \" + str(var[0])) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"drop_col = [\n    'id',\n    'imdb_id',\n    'original_title',\n    'belongs_to_collection',\n    'genres',\n    'homepage',\n    'overview',\n    'poster_path',\n    'production_countries',\n    'production_companies',\n    'spoken_languages',\n    'status',\n    'tagline',\n    'title',\n    'Keywords',\n    'cast',\n    'crew',\n    'revenue',\n    'collection_name'  \n]\nfeatures = []\nfor i in df_train.columns:\n    if i not in drop_col:\n        features.append(i)\n    else:\n        pass\n    \nfeatures\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X=df_train[features].copy()\ny=df_train['revenue'].copy()\nX_test = df_test[features].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Select categorical columns with relatively low cardinality (convenient but arbitrary)\ncategorical_cols = [cname for cname in X.columns if\n                    X[cname].nunique() < 10 and \n                    X[cname].dtype == \"object\"]\n\n# Select numerical columns\nnumerical_cols = [cname for cname in X.columns if \n                X[cname].dtype in ['int64', 'float64']]\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='constant')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='most_frequent')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer, numerical_cols),\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\ndef rmsle_error(y_true, y_pred): \n    assert len(y_true) == len(y_pred)\n    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n\nrmsle_score = make_scorer(rmsle_error, greater_is_better=False)\n\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', RandomForestRegressor(n_estimators=5,n_jobs=-1,min_samples_split=6, random_state=0))\n                             ])\nscores = -1 * cross_val_score(my_pipeline, X, y,\n                              cv=5,\n                              scoring=rmsle_score)\nresults = scores.mean()\nresults","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\npred = cross_val_predict(my_pipeline,X,y,cv=5)\ncol = ['id','revenue']\ndf_compare = df_train[col].copy()\ndf_compare['predicted'] = pred\ndf_compare['residual'] = df_compare['revenue'] - df_compare['predicted']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(df_compare['predicted'],df_compare['revenue'])\nplt.plot(df_compare['revenue'],df_compare['revenue'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weights = np.ones_like(df_compare['residual']) / (len(df_compare['residual']))\nplt.hist(df_compare['residual'],bins = 10,weights = weights)\nplt.ylabel('Probability')\nplt.xlabel('Residual');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_pipeline.fit(X,y)\ny_pred = my_pipeline.predict(X_test)\ny_pred\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.DataFrame(df_test['id'].copy())\nsubmission['revenue'] = y_pred\nsubmission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}