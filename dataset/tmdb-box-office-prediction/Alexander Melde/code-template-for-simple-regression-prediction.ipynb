{"cells":[{"metadata":{"_uuid":"09f6a8d87d557778716c712633c08d359d82af9b"},"cell_type":"markdown","source":"# Code Template for Revenue-Prediction (using a Simple Regression)\nThis is a template that can be used to quick-start into more detailed projects. In this example we remove a lot of information, so the expected result will have a very low accuracy. But it will be a great starting point for your own kernel."},{"metadata":{"_uuid":"32a41c48dabb61461303494fb7f750b22e9c3fb6"},"cell_type":"markdown","source":"## 1/4 Import Modules and Dataset\nWe need to load two python modules and the datasets to get started."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# 1.) Import python modules\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler\n\n# 2.) Import datasets\noriginal_df_trainval = pd.read_csv(\"../input/train.csv\")\noriginal_df_test_X = pd.read_csv(\"../input/test.csv\")\n\n# 3.) Output the first rows of one of the datasets\noriginal_df_trainval.head(2)","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"   id    ...      revenue\n0   1    ...     12314651\n1   2    ...     95149435\n\n[2 rows x 23 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>belongs_to_collection</th>\n      <th>budget</th>\n      <th>genres</th>\n      <th>homepage</th>\n      <th>imdb_id</th>\n      <th>original_language</th>\n      <th>original_title</th>\n      <th>overview</th>\n      <th>popularity</th>\n      <th>poster_path</th>\n      <th>production_companies</th>\n      <th>production_countries</th>\n      <th>release_date</th>\n      <th>runtime</th>\n      <th>spoken_languages</th>\n      <th>status</th>\n      <th>tagline</th>\n      <th>title</th>\n      <th>Keywords</th>\n      <th>cast</th>\n      <th>crew</th>\n      <th>revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[{'id': 313576, 'name': 'Hot Tub Time Machine ...</td>\n      <td>14000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}]</td>\n      <td>NaN</td>\n      <td>tt2637294</td>\n      <td>en</td>\n      <td>Hot Tub Time Machine 2</td>\n      <td>When Lou, who has become the \"father of the In...</td>\n      <td>6.575393</td>\n      <td>/tQtWuwvMf0hCc2QR2tkolwl7c3c.jpg</td>\n      <td>[{'name': 'Paramount Pictures', 'id': 4}, {'na...</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>2/20/15</td>\n      <td>93.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>The Laws of Space and Time are About to be Vio...</td>\n      <td>Hot Tub Time Machine 2</td>\n      <td>[{'id': 4379, 'name': 'time travel'}, {'id': 9...</td>\n      <td>[{'cast_id': 4, 'character': 'Lou', 'credit_id...</td>\n      <td>[{'credit_id': '59ac067c92514107af02c8c8', 'de...</td>\n      <td>12314651</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[{'id': 107674, 'name': 'The Princess Diaries ...</td>\n      <td>40000000</td>\n      <td>[{'id': 35, 'name': 'Comedy'}, {'id': 18, 'nam...</td>\n      <td>NaN</td>\n      <td>tt0368933</td>\n      <td>en</td>\n      <td>The Princess Diaries 2: Royal Engagement</td>\n      <td>Mia Thermopolis is now a college graduate and ...</td>\n      <td>8.248895</td>\n      <td>/w9Z7A0GHEhIp7etpj0vyKOeU1Wx.jpg</td>\n      <td>[{'name': 'Walt Disney Pictures', 'id': 2}]</td>\n      <td>[{'iso_3166_1': 'US', 'name': 'United States o...</td>\n      <td>8/6/04</td>\n      <td>113.0</td>\n      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n      <td>Released</td>\n      <td>It can take a lifetime to find true love; she'...</td>\n      <td>The Princess Diaries 2: Royal Engagement</td>\n      <td>[{'id': 2505, 'name': 'coronation'}, {'id': 42...</td>\n      <td>[{'cast_id': 1, 'character': 'Mia Thermopolis'...</td>\n      <td>[{'credit_id': '52fe43fe9251416c7502563d', 'de...</td>\n      <td>95149435</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"5dc7e43e627511ccb4690eba5dc32ef2ea7eac47"},"cell_type":"markdown","source":"## 2/4 Prepare Data\nWe need to prepare our test and training data. Usually, implementing this takes a lot of time, but for this simple example we will just remove features that would be too complicated to preprocess."},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"# This function will be called later to prepare our input data\ndef prepare_data(df):\n    # a.) Use the `id` feature as the index column of the data frame\n    df = df.set_index('id')\n\n    # b.) Only use easy to process features\n    #  Warning: huge information loss here, you should propably include more features in your production code.\n    df = df[['budget', 'original_language' ,'popularity', 'runtime', 'status']]\n    \n    # c.) One-Hot-Encoding for all nominal data\n    df = pd.get_dummies(df)\n    \n    # d.) The `runtime` feature is not filled in 2 of the rows. We replace those empty cells / NaN values with a 0.\n    #  Warning: in production code, please use a better method to deal with missing cells like interpolation or additional `is_missing` feature columns.\n    return df.fillna(0)\n\n\n# 1.) Extract the target variable `revenue` and use the `id` column as index of that data frame\ndf_trainval_y = original_df_trainval[['id','revenue']].set_index('id')\n\n# 2.) Prepare the training and test data by using the function we defined above\ndf_trainval_X = prepare_data(original_df_trainval)\ndf_test_X  = prepare_data(original_df_test_X)\n\n# 3.) Create columns in train/test dataframes if they only exist in one of them (can happen through one hot encoding / get_dummies)\n#  Example: There are no status=`Post Production` entries in the training set, but there are some in the test set.\ndf_trainval_X, df_test_X = df_trainval_X.align(df_test_X, join='outer', axis=1, fill_value=0)\n\n# 4.) Show the first rows of one of the prepared tables\ndf_trainval_X.head(2)","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"      budget       ...        status_Rumored\nid                 ...                      \n1   14000000       ...                     0\n2   40000000       ...                     0\n\n[2 rows x 50 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>budget</th>\n      <th>original_language_af</th>\n      <th>original_language_ar</th>\n      <th>original_language_bm</th>\n      <th>original_language_bn</th>\n      <th>original_language_ca</th>\n      <th>original_language_cn</th>\n      <th>original_language_cs</th>\n      <th>original_language_da</th>\n      <th>original_language_de</th>\n      <th>original_language_el</th>\n      <th>original_language_en</th>\n      <th>original_language_es</th>\n      <th>original_language_fa</th>\n      <th>original_language_fi</th>\n      <th>original_language_fr</th>\n      <th>original_language_he</th>\n      <th>original_language_hi</th>\n      <th>original_language_hu</th>\n      <th>original_language_id</th>\n      <th>original_language_is</th>\n      <th>original_language_it</th>\n      <th>original_language_ja</th>\n      <th>original_language_ka</th>\n      <th>original_language_kn</th>\n      <th>original_language_ko</th>\n      <th>original_language_ml</th>\n      <th>original_language_mr</th>\n      <th>original_language_nb</th>\n      <th>original_language_nl</th>\n      <th>original_language_no</th>\n      <th>original_language_pl</th>\n      <th>original_language_pt</th>\n      <th>original_language_ro</th>\n      <th>original_language_ru</th>\n      <th>original_language_sr</th>\n      <th>original_language_sv</th>\n      <th>original_language_ta</th>\n      <th>original_language_te</th>\n      <th>original_language_th</th>\n      <th>original_language_tr</th>\n      <th>original_language_ur</th>\n      <th>original_language_vi</th>\n      <th>original_language_xx</th>\n      <th>original_language_zh</th>\n      <th>popularity</th>\n      <th>runtime</th>\n      <th>status_Post Production</th>\n      <th>status_Released</th>\n      <th>status_Rumored</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>14000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>6.575393</td>\n      <td>93.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>40000000</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8.248895</td>\n      <td>113.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"41284c4ad66984d744abb63ac1d4a46a5054a167"},"cell_type":"markdown","source":"## 3/4 Predict Values (Linear Regression)\nIn this example we will use a linear regression model to predict the target value (revenue)."},{"metadata":{"trusted":true,"_uuid":"f14f070eb1aeb65c60782bd3e81807e2b9571c58"},"cell_type":"code","source":"# 1.) Remove table meta data, column names etc. → Just use values for prediction.\nX_trainval = df_trainval_X.values\ny_trainval = df_trainval_y.values\n\nX_test  = df_test_X.values\n\n# 2.) Create Validation Split\nX_train, X_val, y_train, y_val = train_test_split(X_trainval, y_trainval, test_size=0.5, random_state=56)\n\n# 3.) Scale\nX_scaler = StandardScaler()\nX_train_scaled  = X_scaler.fit_transform(X_train)\nX_val_scaled    = X_scaler.transform(X_val)\nX_test_scaled   = X_scaler.transform(X_test)\n\ny_scaler = MinMaxScaler((0,1)) # transform and convert column-vector y to a 1d array with ravel\ny_train_scaled  = y_scaler.fit_transform(np.log(y_train)).ravel() \n#y_val_scaled  = y_scaler.transform(np.log(y_val)).ravel() #not used but here for consistency\n\n# 4.) Calculate the coefficients of the linear regression / \"Train\"\nreg     = KNeighborsRegressor().fit(X_train_scaled, y_train_scaled)\n\n# 5.) Define functions to calculate a score\ndef score_function(y_true, y_pred):\n    # see https://www.kaggle.com/c/tmdb-box-office-prediction/overview/evaluation\n    # we use Root Mean squared logarithmic error (RMSLE) regression loss\n    assert len(y_true) == len(y_pred)\n    return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n\ndef score_function2(y_true, y_pred):\n    # alternative implementation\n    y_pred = np.where(y_pred>0, y_pred, 0)\n    return np.sqrt(mean_squared_log_error(y_true, y_pred))\n\ndef inverseY(y):\n    return np.exp(y_scaler.inverse_transform(np.reshape(y, (-1,1))))\n\n# 6.) Apply the regression model on the prepared train, validation and test set and invert the logarithmic scaling\ny_train_pred  = inverseY(reg.predict(X_train_scaled))\ny_val_pred    = inverseY(reg.predict(X_val_scaled))\ny_test_pred   = inverseY(reg.predict(X_test_scaled))\n                   \n# 7.) Print the RMLS error on training, validation and test set. it should be as low as possible\nprint(\"RMLS Error on Training Dataset:\\t\", score_function(y_train , y_train_pred), score_function2(y_train, y_train_pred))\nprint(\"RMLS Error on Val Dataset:\\t\", score_function(y_val , y_val_pred), score_function2(y_val , y_val_pred))\nprint(\"RMLS Error on Test Dataset:\\t Check by submitting on kaggle\")","execution_count":7,"outputs":[{"output_type":"stream","text":"RMLS Error on Training Dataset:\t 2.1159215354096195 2.1159215354096195\nRMLS Error on Val Dataset:\t 2.3979569481101604 2.3979569481101604\nRMLS Error on Test Dataset:\t Check by submitting on kaggle\n","name":"stdout"}]},{"metadata":{"_uuid":"eb1965792afcc7b7d489514b881ad607d05673b2"},"cell_type":"markdown","source":"## 4/4 Convert Prediction to submittable CSV file\nIn order to get our test accuracy, we need to convert our prediction to a comma seperated table file which we can upload to kaggle [here](https://www.kaggle.com/c/tmdb-box-office-prediction/data)."},{"metadata":{"trusted":true,"_uuid":"d84a8d56ec184ea9850f7144116ce7b222bd747b"},"cell_type":"code","source":"# 1.) Add the predicted values to the original test data\ndf_test = original_df_test_X.assign(revenue=y_test_pred)\n\n# 2.) Extract a table of ids and their revenue predictions\ndf_test_y = df_test[['id','revenue']].set_index('id')\n\n# 3.) save that table to a csv file. On Kaggle, the file will be visible in the \"output\" tab if the kernel has been commited at least once.\ndf_test_y.to_csv(\"submission.csv\")\n\n# 4.) output the head of our file her to check if it looks good :)\npd.read_csv(\"submission.csv\").head(5)","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"     id       revenue\n0  3001  1.183195e+07\n1  3002  2.205244e+05\n2  3003  3.704143e+06\n3  3004  2.011876e+06\n4  3005  4.728737e+04","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>revenue</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>3001</td>\n      <td>1.183195e+07</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3002</td>\n      <td>2.205244e+05</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3003</td>\n      <td>3.704143e+06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3004</td>\n      <td>2.011876e+06</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>3005</td>\n      <td>4.728737e+04</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"_uuid":"3d695dce833840a30e6bd77f8ceddba70023e47b"},"cell_type":"markdown","source":"## That's it!\nI hope you liked this basic template, if you have any suggestions on how to improve this kernel feel free to write a comment.\n\nIf this kernel helped you quick-start into your own data science project please make sure to leave an upvote :)"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}