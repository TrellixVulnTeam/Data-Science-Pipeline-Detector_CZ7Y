{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('max_columns', None)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nplt.style.use('ggplot')\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split, KFold\nfrom wordcloud import WordCloud\nfrom collections import Counter\nfrom nltk.corpus import stopwords\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.preprocessing import StandardScaler\nstop = set(stopwords.words('english'))\nimport os\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport xgboost as xgb\nimport lightgbm as lgb\nfrom sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nimport json\nimport ast\nimport eli5\nimport shap\nfrom catboost import CatBoostRegressor\nfrom urllib.request import urlopen\nfrom PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"trainAdditionalFeatures = pd.read_csv('../input/tmdb-competition-additional-features/TrainAdditionalFeatures.csv')\ntestAdditionalFeatures = pd.read_csv('../input/tmdb-competition-additional-features/TestAdditionalFeatures.csv')\n\ntrain = pd.read_csv('../input/tmdb-box-office-prediction/train.csv')\ntest = pd.read_csv('../input/tmdb-box-office-prediction/test.csv')\n\ntrain = pd.merge(train, trainAdditionalFeatures, how='left', on=['imdb_id'])\ntest = pd.merge(test, testAdditionalFeatures, how='left', on=['imdb_id'])\ntest['revenue'] = -np.inf\ntrain.loc[train['id'] == 16,'revenue'] = 192864          # Skinning\ntrain.loc[train['id'] == 90,'budget'] = 30000000         # Sommersby          \ntrain.loc[train['id'] == 118,'budget'] = 60000000        # Wild Hogs\ntrain.loc[train['id'] == 149,'budget'] = 18000000        # Beethoven\ntrain.loc[train['id'] == 313,'revenue'] = 12000000       # The Cookout \ntrain.loc[train['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\ntrain.loc[train['id'] == 464,'budget'] = 20000000        # Parenthood\ntrain.loc[train['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\ntrain.loc[train['id'] == 513,'budget'] = 930000          # From Prada to Nada\ntrain.loc[train['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\ntrain.loc[train['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\ntrain.loc[train['id'] == 850,'budget'] = 90000000        # Modern Times\ntrain.loc[train['id'] == 1007,'budget'] = 2              # Zyzzyx Road \ntrain.loc[train['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\ntrain.loc[train['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \ntrain.loc[train['id'] == 1359,'budget'] = 10000000       # Stir Crazy \ntrain.loc[train['id'] == 1542,'budget'] = 1              # All at Once\ntrain.loc[train['id'] == 1570,'budget'] = 15800000       # Crocodile Dundee II\ntrain.loc[train['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\ntrain.loc[train['id'] == 1714,'budget'] = 46000000       # The Recruit\ntrain.loc[train['id'] == 1721,'budget'] = 17500000       # Cocoon\ntrain.loc[train['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\ntrain.loc[train['id'] == 1885,'budget'] = 12             # In the Cut\ntrain.loc[train['id'] == 2091,'budget'] = 10             # Deadfall\ntrain.loc[train['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\ntrain.loc[train['id'] == 2491,'budget'] = 6              # Never Talk to Strangers\ntrain.loc[train['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\ntrain.loc[train['id'] == 2612,'budget'] = 15000000       # Field of Dreams\ntrain.loc[train['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\ntrain.loc[train['id'] == 2801,'budget'] = 10000000       # Fracture\ntrain.loc[train['id'] == 335,'budget'] = 2 \ntrain.loc[train['id'] == 348,'budget'] = 12\ntrain.loc[train['id'] == 470,'budget'] = 13000000 \ntrain.loc[train['id'] == 513,'budget'] = 1100000\ntrain.loc[train['id'] == 640,'budget'] = 6 \ntrain.loc[train['id'] == 696,'budget'] = 1\ntrain.loc[train['id'] == 797,'budget'] = 8000000 \ntrain.loc[train['id'] == 850,'budget'] = 1500000\ntrain.loc[train['id'] == 1199,'budget'] = 5 \ntrain.loc[train['id'] == 1282,'budget'] = 9               # Death at a Funeral\ntrain.loc[train['id'] == 1347,'budget'] = 1\ntrain.loc[train['id'] == 1755,'budget'] = 2\ntrain.loc[train['id'] == 1801,'budget'] = 5\ntrain.loc[train['id'] == 1918,'budget'] = 592 \ntrain.loc[train['id'] == 2033,'budget'] = 4\ntrain.loc[train['id'] == 2118,'budget'] = 344 \ntrain.loc[train['id'] == 2252,'budget'] = 130\ntrain.loc[train['id'] == 2256,'budget'] = 1 \ntrain.loc[train['id'] == 2696,'budget'] = 10000000\n\n#Clean Data\ntest.loc[test['id'] == 6733,'budget'] = 5000000\ntest.loc[test['id'] == 3889,'budget'] = 15000000\ntest.loc[test['id'] == 6683,'budget'] = 50000000\ntest.loc[test['id'] == 5704,'budget'] = 4300000\ntest.loc[test['id'] == 6109,'budget'] = 281756\ntest.loc[test['id'] == 7242,'budget'] = 10000000\ntest.loc[test['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\ntest.loc[test['id'] == 5591,'budget'] = 4000000        # The Orphanage\ntest.loc[test['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\ntest.loc[test['id'] == 3033,'budget'] = 250 \ntest.loc[test['id'] == 3051,'budget'] = 50\ntest.loc[test['id'] == 3084,'budget'] = 337\ntest.loc[test['id'] == 3224,'budget'] = 4  \ntest.loc[test['id'] == 3594,'budget'] = 25  \ntest.loc[test['id'] == 3619,'budget'] = 500  \ntest.loc[test['id'] == 3831,'budget'] = 3  \ntest.loc[test['id'] == 3935,'budget'] = 500  \ntest.loc[test['id'] == 4049,'budget'] = 995946 \ntest.loc[test['id'] == 4424,'budget'] = 3  \ntest.loc[test['id'] == 4460,'budget'] = 8  \ntest.loc[test['id'] == 4555,'budget'] = 1200000 \ntest.loc[test['id'] == 4624,'budget'] = 30 \ntest.loc[test['id'] == 4645,'budget'] = 500 \ntest.loc[test['id'] == 4709,'budget'] = 450 \ntest.loc[test['id'] == 4839,'budget'] = 7\ntest.loc[test['id'] == 3125,'budget'] = 25 \ntest.loc[test['id'] == 3142,'budget'] = 1\ntest.loc[test['id'] == 3201,'budget'] = 450\ntest.loc[test['id'] == 3222,'budget'] = 6\ntest.loc[test['id'] == 3545,'budget'] = 38\ntest.loc[test['id'] == 3670,'budget'] = 18\ntest.loc[test['id'] == 3792,'budget'] = 19\ntest.loc[test['id'] == 3881,'budget'] = 7\ntest.loc[test['id'] == 3969,'budget'] = 400\ntest.loc[test['id'] == 4196,'budget'] = 6\ntest.loc[test['id'] == 4221,'budget'] = 11\ntest.loc[test['id'] == 4222,'budget'] = 500\ntest.loc[test['id'] == 4285,'budget'] = 11\ntest.loc[test['id'] == 4319,'budget'] = 1\ntest.loc[test['id'] == 4639,'budget'] = 10\ntest.loc[test['id'] == 4719,'budget'] = 45\ntest.loc[test['id'] == 4822,'budget'] = 22\ntest.loc[test['id'] == 4829,'budget'] = 20\ntest.loc[test['id'] == 4969,'budget'] = 20\ntest.loc[test['id'] == 5021,'budget'] = 40 \ntest.loc[test['id'] == 5035,'budget'] = 1 \ntest.loc[test['id'] == 5063,'budget'] = 14 \ntest.loc[test['id'] == 5119,'budget'] = 2 \ntest.loc[test['id'] == 5214,'budget'] = 30 \ntest.loc[test['id'] == 5221,'budget'] = 50 \ntest.loc[test['id'] == 4903,'budget'] = 15\ntest.loc[test['id'] == 4983,'budget'] = 3\ntest.loc[test['id'] == 5102,'budget'] = 28\ntest.loc[test['id'] == 5217,'budget'] = 75\ntest.loc[test['id'] == 5224,'budget'] = 3 \ntest.loc[test['id'] == 5469,'budget'] = 20 \ntest.loc[test['id'] == 5840,'budget'] = 1 \ntest.loc[test['id'] == 5960,'budget'] = 30\ntest.loc[test['id'] == 6506,'budget'] = 11 \ntest.loc[test['id'] == 6553,'budget'] = 280\ntest.loc[test['id'] == 6561,'budget'] = 7\ntest.loc[test['id'] == 6582,'budget'] = 218\ntest.loc[test['id'] == 6638,'budget'] = 5\ntest.loc[test['id'] == 6749,'budget'] = 8 \ntest.loc[test['id'] == 6759,'budget'] = 50 \ntest.loc[test['id'] == 6856,'budget'] = 10\ntest.loc[test['id'] == 6858,'budget'] =  100\ntest.loc[test['id'] == 6876,'budget'] =  250\ntest.loc[test['id'] == 6972,'budget'] = 1\ntest.loc[test['id'] == 7079,'budget'] = 8000000\ntest.loc[test['id'] == 7150,'budget'] = 118\ntest.loc[test['id'] == 6506,'budget'] = 118\ntest.loc[test['id'] == 7225,'budget'] = 6\ntest.loc[test['id'] == 7231,'budget'] = 85\ntest.loc[test['id'] == 5222,'budget'] = 5\ntest.loc[test['id'] == 5322,'budget'] = 90\ntest.loc[test['id'] == 5350,'budget'] = 70\ntest.loc[test['id'] == 5378,'budget'] = 10\ntest.loc[test['id'] == 5545,'budget'] = 80\ntest.loc[test['id'] == 5810,'budget'] = 8\ntest.loc[test['id'] == 5926,'budget'] = 300\ntest.loc[test['id'] == 5927,'budget'] = 4\ntest.loc[test['id'] == 5986,'budget'] = 1\ntest.loc[test['id'] == 6053,'budget'] = 20\ntest.loc[test['id'] == 6104,'budget'] = 1\ntest.loc[test['id'] == 6130,'budget'] = 30\ntest.loc[test['id'] == 6301,'budget'] = 150\ntest.loc[test['id'] == 6276,'budget'] = 100\ntest.loc[test['id'] == 6473,'budget'] = 100\ntest.loc[test['id'] == 6842,'budget'] = 30\n\n# from this kernel: https://www.kaggle.com/gravix/gradient-in-a-box\ndict_columns = ['belongs_to_collection', 'genres', 'production_companies',\n                'production_countries', 'spoken_languages', 'Keywords', 'cast', 'crew']\n\ndef text_to_dict(df):\n    for column in dict_columns:\n        df[column] = df[column].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x) )\n    return df\n        \ntrain = text_to_dict(train)\ntest = text_to_dict(test)\n\ndef fix_date(x):\n    \"\"\"\n    Fixes dates which are in 20xx\n    \"\"\"\n    if not isinstance(x, str): return x\n    year = x.split('/')[2]\n    if int(year) <= 19:\n        return x[:-2] + '20' + year\n    else:\n        return x[:-2] + '19' + year\n\ntrain.loc[train['release_date'].isnull() == True, 'release_date'] = '01/01/19'\ntest.loc[test['release_date'].isnull() == True, 'release_date'] = '01/01/19'\n    \n#train[\"RevByBud\"] = train[\"revenue\"] / train[\"budget\"]\n    \ntrain['release_date'] = train['release_date'].apply(lambda x: fix_date(x))\ntest['release_date'] = test['release_date'].apply(lambda x: fix_date(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#target - revenue\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['revenue'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.distplot(train['revenue']);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot revenue/budget\nvar = 'budget'\ndata = pd.concat([train['revenue'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='revenue');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot revenue/total votes\nvar = 'totalVotes'\ndata = pd.concat([train['revenue'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='revenue');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot revenue/total votes\n#mabe we need to do log later\nvar = 'popularity2'\ndata = pd.concat([train['revenue'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='revenue');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot revenue/total votes\nvar = 'totalVotes'\ndata = pd.concat([train['popularity'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='popularity');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data frame to date time\ndef to_datetime(df):\n    df.release_date = pd.to_datetime(df.release_date)\n\nto_datetime(train)\nto_datetime(test)\n\n#split to columns\ndef split_date_to_col(df):\n    df['day'] = df['release_date'].dt.day\n    df['month'] = df['release_date'].dt.month\n    df['year'] = df['release_date'].dt.year \n    df['week_day'] = df['release_date'].dt.weekday\n    \nsplit_date_to_col(train)\nsplit_date_to_col(test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot year/bodget \nvar = 'year'\ndata = pd.concat([train['budget'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='budget');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#box plot month/runtime \nvar = 'month'\ndata = pd.concat([train['rating'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"rating\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#box plot month/runtime \nvar = 'month'\ndata = pd.concat([train['runtime'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"runtime\", data=data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#box plot month/runtime \nvar = 'month'\ndata = pd.concat([train['revenue'], train[var]], axis=1)\nf, ax = plt.subplots(figsize=(8, 6))\nfig = sns.boxplot(x=var, y=\"revenue\", data=data)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing data train\ntotal = train.isnull().sum().sort_values(ascending=False)\npercent = (train.isnull().sum()/train.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_data.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#scatter plot year/bodget \nvar = 'day'\ndata = pd.concat([train['revenue'], train[var]], axis=1)\ndata.plot.scatter(x=var, y='revenue');\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"train['belongs_to_collection'][0][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_collection(df):\n    list_of_collection_names = []\n    for  i in df['belongs_to_collection']:\n        if i !={}:\n            list_of_collection_names.append(1)\n        else: list_of_collection_names.append(0)\n    df['is_collection'] = list_of_collection_names\n    \nis_collection(train)\nis_collection(test)\n\n\ntrain = train.drop(columns=['belongs_to_collection'], axis =1)\ntest = test.drop(columns=['belongs_to_collection'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def genres_lists(df):\n    list_of_genres = []\n    for i in df['genres']:\n            if len(i)>1:\n                genre_list_per_one = []\n                for genre in i:\n                    genre_list_per_one.append(genre['name'])\n                list_of_genres.append(genre_list_per_one)\n            if len(i)==1:\n                list_of_genres.append([i[0]['name']])\n            if len(i)==0:\n                list_of_genres.append(['None'])\n    df['genres_lists'] = list_of_genres\n\ngenres_lists(train)\ngenres_lists(test)\n\ntrain_dummies =  pd.get_dummies(train['genres_lists'].apply(pd.Series), prefix='', prefix_sep='').sum(level=0, axis=1)\ntest_dummies =  pd.get_dummies(test['genres_lists'].apply(pd.Series), prefix='', prefix_sep='').sum(level=0, axis=1)\n\ntrain = pd.concat([train, train_dummies],axis=1)\ntest = pd.concat([test, test_dummies],axis=1)\n\ntrain = train.drop(columns=['genres','genres_lists','poster_path','overview'], axis =1)\ntest = test.drop(columns=['genres','genres_lists','poster_path','overview'], axis =1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#correlation matrix\ncorrmat = train.corr()\nf, ax = plt.subplots(figsize=(12, 9))\nsns.heatmap(corrmat, vmax=.8, square=True);\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns=['imdb_id','id'], axis =1)\ntest = test.drop(columns=['imdb_id','id'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_reveneu_over_feature(df,feature):\n    sns.set(font_scale = 2)\n    f, axes = plt.subplots(1, 3, figsize=(45,15))\n    #     targets = [train['lrevenue']]\n#     lables = ['log-revenue']\n    targets = []\n    lables = []\n\n    # Sort the dataframe by target \n    all_values = sorted(df[feature].unique())\n    targets = [train.loc[df[feature]==all_values[i]]['lrevenue'] for i in range(len(all_values))]\n    lables = all_values\n\n    for lbl, dist in zip(lables, targets):\n#         sns.lineplot(dist, hist=False, rug=False, label=lbl)\n        sns.distplot(dist, hist=False, rug=True, label=lbl, ax=axes[0])\n    # violin\n#     sns.violinplot(x=feature, y=\"revenue\", data=train, ax=axes[1])\n    sns.barplot(x=feature, y=\"revenue\", data=train, ax=axes[1])\n    # pie\n    # Plot\n    size = train[feature].value_counts().sort_values()\n    axes[2].pie(list(size), labels=size.index, autopct='%1.1f%%', shadow=True, startangle=140)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['has_homepage'] = 1\ntrain.loc[pd.isnull(train['homepage']) ,\"has_homepage\"] = 0\ntest['has_homepage'] = 1\ntest.loc[pd.isnull(test['homepage']) ,\"has_homepage\"] = 0\n\nplt.figure(figsize=(15,8))\nsns.countplot(train['has_homepage'].sort_values())\nplt.title(\"Has Homepage?\",fontsize=20)\nplt.show()\n\ntrain['isTaglineNA'] = 0\ntrain.loc[pd.isnull(train['tagline']) ,\"isTaglineNA\"] = 1\n\ntest['isTaglineNA'] = 0\ntest.loc[pd.isnull(test['tagline']) ,\"isTaglineNA\"] = 1\n\nsns.catplot(x=\"isTaglineNA\", y=\"revenue\", data=train)\nplt.title('Revenue of movies with and without a tagline')\nplt.show()\n\ntrain['isTitleDifferent'] = 1\ntrain.loc[ train['original_title'] == train['title'] ,\"isTitleDifferent\"] = 0 \n\ntest['isTitleDifferent'] = 1\ntest.loc[ test['original_title'] == test['title'] ,\"isTitleDifferent\"] = 0 \n\nsns.catplot(x=\"isTitleDifferent\", y=\"revenue\", data=train)\nplt.title('Revenue of movies with single and multiple titles')\nplt.show()\n\ntrain['isOriginalLanguageEng'] = 0 \ntrain.loc[ train['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\ntest['isOriginalLanguageEng'] = 0 \ntest.loc[ test['original_language'] == \"en\" ,\"isOriginalLanguageEng\"] = 1\n\nsns.catplot(x=\"isOriginalLanguageEng\", y=\"revenue\", data=train)\nplt.title('Revenue of movies when Original Language is English and Not English')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = train.drop(columns=['homepage','tagline','release_date','status','original_title','title'], axis =1)\ntest = test.drop(columns=['homepage','tagline','release_date','status','original_title','title'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_day_2'] = 0\ntrain.loc[ train['week_day'] == 2 ,\"is_day_2\"] = 1 \ntest['is_day_2'] = 0\ntest.loc[ test['week_day'] == 2 ,\"is_day_2\"] = 1 \n\nsns.catplot(x=\"is_day_2\", y=\"revenue\", data=train)\nplt.title('Revenue of movies in the second day of week')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_month_6'] = 0\ntrain.loc[ train['month'] == 6 ,\"is_month_6\"] = 1 \ntest['is_month_6'] = 0\ntest.loc[ test['month'] == 6 ,\"is_month_6\"] = 1 \nsns.catplot(x=\"is_month_6\", y=\"revenue\", data=train)\nplt.title('Revenue of movies in the 6 month')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"test shape: \" + str(test.shape))\nprint(\"train shape: \" + str(train.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['budget'] = np.log1p(train['budget'])\n#train['revenue'] = np.log1p(train['revenue'])\n\n#test['budget'] = np.log1p(test['budget'])\n#test['revenue'] = np.log1p(test['revenue'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def spoken_lang_lists(df):\n    list_of_genres = []\n    for i in df['spoken_languages']:\n            if len(i)>1:\n                genre_list_per_one = []\n                for genre in i:\n                    genre_list_per_one.append(genre['iso_639_1'])\n                list_of_genres.append(genre_list_per_one)\n            if len(i)==1:\n                list_of_genres.append([i[0]['iso_639_1']])\n            if len(i)==0:\n                list_of_genres.append(['None'])\n    df['spoken_languages_new'] = list_of_genres\n\nspoken_lang_lists(train)\nspoken_lang_lists(test)\n\ntrain_dummies =  pd.get_dummies(train['spoken_languages_new'].apply(pd.Series), prefix='', prefix_sep='').sum(level=0, axis=1)\ntest_dummies =  pd.get_dummies(test['spoken_languages_new'].apply(pd.Series), prefix='', prefix_sep='').sum(level=0, axis=1)\n\ntrain = pd.concat([train, train_dummies],axis=1)\ntest = pd.concat([test, test_dummies],axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dummies.columns\ntrain_lang_to_drop = []\ntest_lang_to_drop = []\n\nfor i in train_dummies.columns:\n    if i not in test_dummies.columns:\n        train_lang_to_drop.append(i)\n        \nfor i in test_dummies.columns:\n    if i not in train_dummies.columns:\n        test_lang_to_drop.append(i)\n        \ntrain = train.drop(columns = train_lang_to_drop, axis =1)\ntest = test.drop(columns = test_lang_to_drop, axis =1)\nprint(test.shape)\nprint(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i  in zip(train['original_language'],train['spoken_languages_new']):\n    if i[0] not in i[1]:\n        train['is_spoken_lang_is_origin'] = 0\n    else: train['is_spoken_lang_is_origin'] = 1\n    \n\nsns.catplot(x=\"is_spoken_lang_is_origin\", y=\"revenue\", data=train)\nplt.title('spoken lang_is_origin')\nplt.show()\n\ntrain = train.drop(columns=['is_spoken_lang_is_origin','spoken_languages_new'], axis =1)\ntest = test.drop(columns=['spoken_languages_new'], axis =1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train['production_companies'][0]\ndef is_production_companies(df):\n    list_of_production_copmanies = []\n    for  i in df['production_companies']:\n        if i !={}:\n            list_of_production_copmanies.append(1)\n        else: list_of_production_copmanies.append(0)\n    df['belong_to_prod_comp'] = list_of_production_copmanies\n    \nis_production_companies(train)\nis_production_companies(test)\n\nsns.catplot(x=\"belong_to_prod_comp\", y=\"revenue\", data=train)\nplt.title('belong to prod comp?')\nplt.show()\ntrain = train.drop(columns=['production_companies'], axis =1)\ntest = test.drop(columns=['production_companies'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prod_cont(df):\n    list_of_genres = []\n    for i in df['production_countries']:\n            if len(i)>1:\n                genre_list_per_one = []\n                for genre in i:\n                    genre_list_per_one.append(genre['iso_3166_1'])\n                list_of_genres.append(genre_list_per_one)\n            if len(i)==1:\n                list_of_genres.append([i[0]['iso_3166_1']])\n            if len(i)==0:\n                list_of_genres.append(['None'])\n    df['production_countries_new'] = list_of_genres\n    final_list =[]\n    for i in df['production_countries_new']:\n        i = i[0]\n        final_list.append(i)\n    df['production_countries_new'] = final_list\n\nprod_cont(train)\nprod_cont(test)\n\n#train['production_countries_new']\n#train['production_countries'][5]\n\n\n#spoken_lang_lists(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"production_countries_new\", y=\"revenue\", data=train, height=10,  aspect=2)\nplt.title('prod contries vs revenue?')\nplt.xticks(fontsize=12,rotation=90)\nplt.show()\n\nplt.figure(figsize=(20,12))\nsns.countplot(train['production_countries_new'].sort_values())\nplt.title(\"Movie Release count by Year\",fontsize=20)\nloc, labels = plt.xticks()\nplt.xticks(fontsize=12,rotation=90)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_have_prod_com'] = 1\ntrain.loc[ train['production_countries_new'] == 'None' ,\"is_have_prod_com\"] = 0 \ntest['is_have_prod_com'] = 1\ntest.loc[ test['production_countries_new'] == 'None' ,\"is_have_prod_com\"] = 0\n\ntrain = train.drop(columns=['production_countries'], axis =1)\ntest = test.drop(columns=['production_countries'], axis =1)\n\ntarget = 'revenue'\ncol_name = 'original_language'\n\ncol = train[col_name]\ngroup_col = train[target].groupby(col).mean().sort_values(ascending  = False)\nprint (group_col)\nselected = list(group_col.index)\ng = sns.catplot(x=col_name, y=target, data=pd.concat([col, train[target]], axis=1).reset_index(), height=7, ci = None,   kind = 'bar', order = selected)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['is_origin_en'] = 0\ntrain.loc[ train['original_language'] == 'en' ,\"is_origin_en\"] = 1 \ntest['is_origin_en'] = 0\ntest.loc[ test['original_language'] == 'en' ,\"is_origin_en\"] = 1\n\ntrain['is_origin_zh'] = 0\ntrain.loc[ train['original_language'] == 'zh' ,\"is_origin_zh\"] = 1 \ntest['is_origin_zh'] = 0\ntest.loc[ test['original_language'] == 'zh' ,\"is_origin_zh\"] = 1\n\ntrain['is_origin_tr'] = 0\ntrain.loc[ train['original_language'] == 'tr' ,\"is_origin_tr\"] = 1 \ntest['is_origin_tr'] = 0\ntest.loc[ test['original_language'] == 'tr' ,\"is_origin_tr\"] = 1\n\ntrain = train.drop(columns=['original_language','production_countries_new','spoken_languages'], axis =1)\ntest = test.drop(columns=['original_language','production_countries_new','spoken_languages'], axis =1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in train['Keywords']:\n    print('start: \\n')\n    print(i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_key_words(df):\n    list_of_key_words = []\n    for i in df['Keywords']:\n            if len(i)>1:\n                genre_list_per_one = []\n                for genre in i:\n                    genre_list_per_one.append(genre['name'])\n                list_of_key_words.append(genre_list_per_one)\n                print(genre_list_per_one)\n            if len(i)==1:\n                list_of_key_words.append([i[0]['name']])\n            if len(i)==0:\n                list_of_key_words.append(['None'])\n    df['Keywords'] = list_of_key_words\n    final_list =[]\n    for i in df['Keywords']:\n        i = str(i).strip('[]')\n        final_list.append(i)\n    df['Keywords_lists'] = final_list\n\nextract_key_words(train)\nextract_key_words(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"s2 = train['Keywords_lists'][0]\ns2","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"NLP for keywords"},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import sentiwordnet as swn\nimport nltk\nfrom nltk.corpus import stopwords\n\ndef nlp_keywords(df):\n    pos_or_neg =[]\n    for s2 in  df['Keywords_lists']:\n        pos = 0.0\n        neg = 0.0\n        #might be\n        obj=0\n        total = 0.0\n        words = [word for word in s2.split()]# if word.lower() not in stopwords.words('english')]\n        for wr in words:\n            ls = list(swn.senti_synsets(wr,'r')) # adverb (try with v/n/a/none)\n            for s in ls:\n                r = swn.senti_synset(s.synset.name())\n                pos += r.pos_score()\n                neg += r.neg_score()\n                obj+= r.obj_score()\n        if pos > neg :\n             pos_or_neg.append('pos')\n        if pos< neg :\n            pos_or_neg.append('neg')\n        if obj > 0  and pos==0 and neg==0 :\n            pos_or_neg.append('obj')\n        if pos == 0 and neg ==0 and 0 == obj:\n            pos_or_neg.append('unknown')\n        if pos == neg and obj>0 and pos>0:\n            pos_or_neg.append('obj')\n    df['pos_or_neg'] = pos_or_neg\nnlp_keywords(train)\ntrain['pos_or_neg']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.catplot(x=\"pos_or_neg\", y=\"revenue\", data=train, height=10,  aspect=2)\nplt.title('positive &negetive  vs revenue?')\nplt.xticks(fontsize=12,rotation=90)\nplt.show()\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}