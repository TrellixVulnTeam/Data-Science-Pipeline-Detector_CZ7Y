{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from trackml.dataset import load_event, load_dataset\nfrom trackml.score import score_event\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\n\n\nimport numpy as np\nimport pandas as pd\nimport timeit\nimport multiprocessing\nfrom multiprocessing import Pool\n\ndef find_labels(params):\n    hits, dz = params\n    a = hits['phi'].values\n    z = hits['z'].values\n    zr = hits['zr'].values\n    aa = a + np.sign(z) * dz * z\n\n    f0 = np.cos(aa)\n    f1 = np.sin(aa)\n    f2 = zr\n    X = StandardScaler().fit_transform(np.column_stack([f0, f1, f2]))\n\n    _, l = dbscan(X, eps=0.0045, min_samples=1, n_jobs=4)\n    return l + 1\n\ndef add_count(l):\n    unique, reverse, count = np.unique(l, return_counts=True, return_inverse=True)\n    c = count[reverse]\n    c[np.where(l == 0)] = 0\n    c[np.where(c > 20)] = 0\n    return (l, c)\n\ndef do_dbscan_predict(hits):\n    start_time = timeit.default_timer()\n\n    hits['r'] = np.sqrt(hits['x'] ** 2 + hits['y'] ** 2)\n    hits['zr'] = hits['z'] / hits['r']\n    hits['phi'] = np.arctan2(hits['y'], hits['x'])\n\n    params = []\n    for i in range(0, 20):\n        dz = i * 0.00001\n        params.append((hits, dz))\n        if i > 0:\n             params.append((hits, -dz))\n    # Kernel time is limited. So we skip some angles.\n    for i in range(20, 60):\n        dz = i * 0.00001\n        if i % 2 == 0:\n            params.append((hits, dz))\n        else:\n             params.append((hits, -dz))\n             \n    pool = Pool(processes=4)\n    labels_for_all_steps = pool.map(find_labels, params)\n    results = [add_count(l) for l in labels_for_all_steps]\n    pool.close()\n\n    labels, counts = results[0]\n    for i in range(1, len(results)):\n        l, c = results[i]\n        idx = np.where((c - counts > 0))[0]\n        labels[idx] = l[idx] + labels.max()\n        counts[idx] = c[idx]\n\n    print('time spent:', timeit.default_timer() - start_time)\n\n    return labels\n\ndef create_one_event_submission(event_id, hits, labels):\n    sub_data = np.column_stack(([event_id]*len(hits), hits, labels))\n    submission = pd.DataFrame(data=sub_data, columns=[\"event_id\", \"hit_id\", \"track_id\"]).astype(int)\n    return submission\n\ndef run_dbscan():\n    data_dir = '../input/train_1'\n\n    event_ids = ['000001000']\n    sum = 0\n    sum_score = 0\n    for i, event_id in enumerate(event_ids):\n        hits, cells, particles, truth = load_event(data_dir + '/event' + event_id)\n        labels = do_dbscan_predict(hits)\n        submission = create_one_event_submission(0, hits['hit_id'].values, labels)\n        score = score_event(truth, submission)\n        print('[%2d] score : %0.8f' % (i, score))\n        sum_score += score\n        sum += 1\n\n    print('--------------------------------------')\n    print(sum_score / sum)\n\nif __name__ == '__main__':\n    print('estimate score by known events')\n    run_dbscan()\n\n    path_to_test = \"../input/test\"\n    test_dataset_submissions = []\n\n    create_submission = True  # True for submission\n    if create_submission:\n        print('process test events')\n        for event_id, hits in load_dataset(path_to_test, parts=['hits']):\n            print('Event ID: ', event_id)\n            labels = do_dbscan_predict(hits)\n            # Prepare submission for an event\n            one_submission = create_one_event_submission(event_id, hits['hit_id'].values, labels)\n            test_dataset_submissions.append(one_submission)\n\n        # Create submission file\n        submussion = pd.concat(test_dataset_submissions, axis=0)\n        submussion.to_csv('submission_.csv', index=False)","execution_count":2,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"No module named 'trackml.dataset'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-8c7fdb9c0b46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtrackml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_event\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtrackml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscore_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDBSCAN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'trackml.dataset'"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}