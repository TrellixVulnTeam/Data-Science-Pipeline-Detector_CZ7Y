{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport spacy\nimport re\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\ntrain = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\nsample = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def text_cleaner(text):\n    \"\"\"\n    Cleans the text with some usual patterns.\n    \"\"\"\n    text = text.lower()\n    text = re.sub(r\"https?:\\/\\/.*?( |$)\", r\"\", text)\n    text = re.sub(r\"<.*?>\", r\"\", text)\n    text = re.sub(r\"[/(){}\\[\\]\\|@,;]\", r\"\", text)\n    #text = re.sub(r\"[^0-9a-z #+_]\", r\"\", text)\n    text = text.strip()\n    return text\n\n\ntrain[\"text\"] = train[\"text\"].apply(lambda x: text_cleaner(str(x)))\ntest[\"text\"] = test[\"text\"].apply(lambda x: text_cleaner(str(x)))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Creates positives, negative and neutral DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pos_mask = [train['sentiment'] == 'positive']\ntrain_positive = train[train_pos_mask[0]]\ntrain_neg_mask = [train['sentiment'] == 'negative']\ntrain_negative = train[train_neg_mask[0]]\ntrain_neutral_mask = [train['sentiment'] == 'neutral']\ntrain_neutral = train[train_neutral_mask[0]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pos_mask = [test['sentiment'] == 'positive']\ntest_positive = test[test_pos_mask[0]]\ntest_neg_mask = [test['sentiment'] == 'negative']\ntest_negative = test[test_neg_mask[0]]\ntest_neutral_mask = [test['sentiment'] == 'neutral']\ntest_neutral = test[test_neutral_mask[0]]\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Initial look of the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"def initial_look(df):\n\n    print(\"Number of samples:\", df.shape[0])\n    print(\"\")\n    columns = [\"text\", \"selected_text\"]\n    for column in columns:\n        feature = df[column]\n        print(column)\n        print(\"number of NAs:\", feature.isna().sum())\n        print(\"Unique values:\", feature.nunique())\n        if column == \"selected_text\":\n            print(\"Most common selected_text:\")\n            print(feature.value_counts(ascending=False)[:100])\n        print(\"\")\n\n\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Positive training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_look(train_positive)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain_positive[\"selected_text\"].value_counts()[:30].plot.bar(figsize=(15,10), title=\"Count of selected_text\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_positive[\"selected_text\"].apply(lambda x: len(str(x))).value_counts()[:20].plot.bar(figsize=(15,10), title=\"Length of the selected text\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Negative training data"},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_look(train_negative)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(20,10))\ntrain_negative[\"selected_text\"].value_counts()[:30].plot.bar(figsize=(15,10), title=\"Count of selected_text\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_negative[\"selected_text\"].apply(lambda x: len(str(x))).value_counts()[:20].plot.bar(figsize=(15,10), title=\"Length of the selected text\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_look(train_neutral)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_neutral[\"selected_text\"].apply(lambda x: len(str(x))).value_counts()[:20].plot.bar(figsize=(15,10), title=\"Length of the selected text\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_training_data_for_spacy(df):\n    \"\"\"\n    Example\n    TRAIN_DATA = [\n    (\" haha better drunken tweeting you mean? \", {\"entities\": [(6, 12, \"SELECTED_TEXT\")]}),\n    (\"had an awsome salad! I recommend getting the Spicey buffalo chicken salad!\", {\"entities\": [(0, 20, \"SELECTED_TEXT\")]}),\n    \"\"\"\n    train_data =[]\n    for i in range(df.shape[0]):\n        selected_text_start = str(df.iloc[i, 1]).find(str(df.iloc[i, 2]))\n        selected_text_end = selected_text_start + len(str(df.iloc[i, 2]))\n        train_data.append((df.iloc[i, 1], {\"entities\":[(selected_text_start, selected_text_end, \"SELECTED_TEXT\")]}))\n\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_spacy_positive = create_training_data_for_spacy(train_positive)\ntrain_spacy_negative = create_training_data_for_spacy(train_negative)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_spacy_positive","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!/usr/bin/env python\n# coding: utf8\n\"\"\"Example of training spaCy's named entity recognizer, starting off with an\nexisting model or a blank model.\n\nFor more details, see the documentation:\n* Training: https://spacy.io/usage/training\n* NER: https://spacy.io/usage/linguistic-features#named-entities\n\nCompatible with: spaCy v2.0.0+\nLast tested with: v2.1.0\n\"\"\"\nfrom __future__ import unicode_literals, print_function\n\nimport plac\nimport random\nfrom pathlib import Path\nimport spacy\nfrom spacy.util import minibatch, compounding\nimport os\n\ndef spacy_ner_train(train_data, model=None, output_dir=None, n_iter=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    if model is not None:\n        nlp = spacy.load(model)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n\n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n\n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # reset and initialize the weights randomly â€“ but only if we're\n        # training a new model\n        if model is None:\n            nlp.begin_training()\n        for itn in range(n_iter):\n            random.shuffle(train_data)\n            losses = {}\n            # batch up the examples using spaCy's minibatch\n            batches = minibatch(train_data, size=compounding(4.0, 32.0, 1.001))\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(\n                    texts,  # batch of texts\n                    annotations,  # batch of annotations\n                    drop=0.5,  # dropout - make it harder to memorise data\n                    losses=losses,\n                )\n            print(\"Losses\", losses)\n\n\n    # save model to output directory\n    if output_dir is not None:\n        #output_dir = Path(output_dir)\n        if not Path(output_dir).exists():\n            os.makedirs(output_dir)\n        \n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spacy_ner_train(train_spacy_positive, model=None, output_dir=\"../models/model_positive\", n_iter=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_spacy_negative","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spacy_ner_train(train_spacy_negative, model=None, output_dir=\"../models/model_negative\", n_iter=5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_positive = spacy.load(\"../models/model_positive\")\nmodel_negative = spacy.load(\"../models/model_negative\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n        \ndef predict_entities(text, model):\n    doc = model(text)\n    ent_list = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_list:\n            ent_list.append([start, end, ent.label_])\n    selected_text = text[ent_list[0][0]: ent_list[0][1]] if len(ent_list) > 0 else text\n    return selected_text         \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_text_positive_predicted = test_positive[\"text\"].apply(lambda x: predict_entities(x, model_positive))\nselected_text_negative_predicted = test_negative[\"text\"].apply(lambda x: predict_entities(x, model_negative))\nselected_text_neutral_predicted = test_neutral[\"text\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[\"selected_text\"] = selected_text_positive_predicted.append(selected_text_negative_predicted).append(selected_text_neutral_predicted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nsample[\"selected_text\"] = test[\"selected_text\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}