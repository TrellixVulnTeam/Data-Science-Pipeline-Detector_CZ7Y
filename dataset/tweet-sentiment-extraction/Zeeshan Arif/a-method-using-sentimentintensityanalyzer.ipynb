{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Here I will give the simple solution for tweet text extraction using SentimentIntensityAnalyzer."},{"metadata":{},"cell_type":"markdown","source":"This method includes following 2 steps\n* First split the tweet into words.\n* Finding the word with highest intensity of sentiment using SentimentIntensityAnalyzer"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport scipy.io\nfrom array import *\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv ('../input/tweet-sentiment-extraction/train.csv')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv ('../input/tweet-sentiment-extraction/test.csv')\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unique_list(l):\n    ulist = []\n    [ulist.append(x) for x in l if x not in ulist]\n    return ulist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Below code will get the words with highest polarity **"},{"metadata":{"trusted":true},"cell_type":"code","source":"def choosing_selectedword(df_process):\n    train_data = df_process['text']\n    train_data_sentiment = df_process['sentiment']\n    selected_text_processed = []\n    analyser = SentimentIntensityAnalyzer()\n    for j in range(0 , len(train_data)):\n        text = re.sub(r'http\\S+', '', str(train_data.iloc[j]))\n        if(train_data_sentiment.iloc[j] == \"neutral\" or len(text.split()) < 2):\n            selected_text_processed.append(str(text))\n        if(train_data_sentiment.iloc[j] == \"positive\" and len(text.split()) >= 2):\n            aa = re.split(' ', text)\n        \n            ss_arr = \"\"\n            polar = 0\n            for qa in range(0,len(aa)):\n                score = analyser.polarity_scores(aa[qa])\n                if score['compound'] >polar:\n                    polar = score['compound']\n                    ss_arr = aa[qa]\n            if len(ss_arr) != 0:\n                selected_text_processed.append(ss_arr)   \n            if len(ss_arr) == 0:\n                selected_text_processed.append(text)\n        if(train_data_sentiment.iloc[j] == \"negative\"and len(text.split()) >= 2):\n            aa = re.split(' ', text)\n        \n            ss_arr = \"\"\n            polar = 0\n            for qa in range(0,len(aa)):\n                score = analyser.polarity_scores(aa[qa])\n                if score['compound'] <polar:\n                    polar = score['compound']\n                    ss_arr = aa[qa]\n            if len(ss_arr) != 0:\n                selected_text_processed.append(ss_arr)   \n            if len(ss_arr) == 0:\n                selected_text_processed.append(text)  \n    return selected_text_processed","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_text_train = choosing_selectedword(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Checking training data accuracey"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_selected_data = df_train['selected_text']\naverage = 0;\nfor i in range(0,len(train_selected_data)):\n    ja_s = jaccard(str(selected_text_train[i]),str(train_selected_data[i]))\n    average = ja_s+average\nprint('Training Data accuracey')\nprint(average/len(selected_text_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_text_test = choosing_selectedword(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_textid = df_test['textID']\ntext_id_list = []\nfor kk in range(0,len(df_textid)):\n    text_id_list.append(df_textid.iloc[kk])\ndf_sub = pd.DataFrame({'textID':text_id_list,'selected_text':selected_text_test})\ndf_sub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}