{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"TRAIN_PATH = \"data/train.json\"\nTEST_PATH = \"data/test.json\"\nRESULT_DIR = \"results\"\nINPUT_DIR = \"../input/tweet-sentiment-extraction/\"\n\nMODEL_TYPE = \"roberta\"\nMODEL_NAME_OR_PATH = \"roberta-large\"\n\nEPOCHS = 3\nLEARNING_RATE = 4e-5\nBATCH_SIZE = 16\nMAX_SEQ_LENGTH = 192\nDOC_STRIDE = 64","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train, data_test = pd.read_csv(f'{INPUT_DIR}train.csv'), pd.read_csv(f'{INPUT_DIR}test.csv')\ndata_train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\n\ndef find_all(input_str, search_str):\n    l1 = []\n    length = len(input_str)\n    index = 0\n    while index < length:\n        i = input_str.find(search_str, index)\n        if i == -1:\n            return l1\n        l1.append(i)\n        index = i + 1\n    return l1\n\ndef convert2squad(data, output_path):\n  output = {}\n  output['version'] = 'v1.0'\n  output['data'] = []\n\n  if 'selected_text' in data.columns:\n    clear_data = zip(data['textID'], data['sentiment'].apply(str).values.tolist(),\\\n                    data['text'].apply(str).values.tolist(), data['selected_text'].apply(str).values.tolist())\n  else:\n    clear_data = zip(data['textID'], data['sentiment'].apply(str).values.tolist(),\\\n                    data['text'].apply(str).values.tolist(), [None] * data.shape[0])\n\n  for qid, question, context, answer in clear_data:\n    answers = []\n    \n    if answer:\n      answer_starts = find_all(context, answer)\n      for answer_start in answer_starts:\n        answers.append({'answer_start': answer_start, 'text': answer})\n    else:\n      answers.append({'answer_start': 1000000, 'text': '__None__'})\n\n    qas = [{'question': question, 'id': qid, 'is_impossible': False, 'answers': answers}]\n\n    paragraphs = [{'context': context, 'qas': qas}]\n    output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n    \n  with open(output_path, 'w') as output_file:\n    json.dump(output, output_file)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p data\nconvert2squad(data_train, TRAIN_PATH)\nconvert2squad(data_test, TEST_PATH)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p $RESULT_DIR","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/huggingface/transformers; cd transformers; pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python transformers/examples/run_squad.py \\\n--model_type $MODEL_TYPE \\\n--model_name_or_path $MODEL_NAME_OR_PATH \\\n--do_lower_case \\\n--do_train \\\n--do_eval \\\n--data_dir . \\\n--cache_dir ./cache \\\n--train_file $TRAIN_PATH \\\n--predict_file $TEST_PATH \\\n--learning_rate $LEARNING_RATE \\\n--num_train_epochs $EPOCHS \\\n--max_seq_length $MAX_SEQ_LENGTH \\\n--doc_stride $DOC_STRIDE \\\n--output_dir $RESULT_DIR \\\n--per_gpu_eval_batch_size=$BATCH_SIZE \\\n--per_gpu_train_batch_size=$BATCH_SIZE \\\n--save_steps=100000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = json.load(open(f'{RESULT_DIR}/predictions_.json', 'r'))\n\nsubmission = pd.read_csv(open(f'{INPUT_DIR}sample_submission.csv', 'r'))\n\nfor i in range(len(submission)):\n    id_ = submission['textID'][i]\n    if data_test['sentiment'][i] == 'neutral': # neutral postprocessing\n        submission.loc[i, 'selected_text'] = data_test['text'][i]\n    else:\n        submission.loc[i, 'selected_text'] = predictions[id_]\n\nsubmission.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}