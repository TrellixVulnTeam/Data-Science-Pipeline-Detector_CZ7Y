{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#!pip install bert","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nimport tokenizers\nimport tensorflow as tf\nimport transformers\nfrom keras.models import Model,Sequential\nfrom keras.callbacks import ModelCheckpoint\n\nMAX_LEN =100\nPATH='/kaggle/input/tf-roberta/'\nTRAIN_BATCH_SIZE= 32\nVALID_BATCH_SIZE=16\n\nTOKENIZER =  tokenizers.ByteLevelBPETokenizer(\n    vocab_file=f\"{PATH}/vocab-roberta-base.json\", \n    merges_file=f\"{PATH}/merges-roberta-base.txt\", \n    lowercase=True,\n    add_prefix_space=True\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df= pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv').dropna().reset_index(drop=True)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent_id = {\n        'positive': 1313,\n        'negative': 2430,\n        'neutral': 7974\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(item):\n        tweet=\" \".join(str(item['text']).split())\n        selected_text=\" \".join(str(item['selected_text']).split())\n        \n\n        len_sel_text= len(selected_text)\n        idx0 =None\n        idx1 =None\n        for ind in (i for i,e in enumerate(tweet) if e==selected_text[0]):\n            if tweet[ind:ind+len_sel_text]==selected_text:\n                idx0= ind\n                idx1= ind+ len(selected_text)-1\n                break\n        \n        char_targets=[0]*len(tweet)\n\n        if idx0!=None and idx1!=None:\n            for j in range(idx0,idx1+1):\n                    char_targets[j]=1;\n        \n        tok_tweet =TOKENIZER.encode(tweet)\n        tok_tweet_tokens=tok_tweet.tokens\n        tok_tweet_ids=tok_tweet.ids\n        tok_tweet_offsets=tok_tweet.offsets[1:-1]\n\n        targets=[]\n        for j,(offset1,offset2) in enumerate(tok_tweet_offsets):\n            if sum(char_targets[offset1:offset2])>0:\n                targets.append(j)\n\n        tok_tweet_ids= [0]+tok_tweet_ids+[2]\n        tok_tweet_ids=tok_tweet_ids+[2]+[sent_id[item['sentiment']]]+[2]\n        \n        targets_start=[0]*(MAX_LEN)\n        targets_end=[0]*(MAX_LEN)\n        \n        if len(targets)>0:\n            targets_start[targets[0]+1]=1\n            targets_end[targets[-1]+1]=1\n        \n        mask=[1]*len(tok_tweet_ids)\n        \n        padding_len= MAX_LEN- len(tok_tweet_ids)\n        ids= tok_tweet_ids+[1]*padding_len\n        mask= mask+[0]*padding_len\n        token_type=[0]*MAX_LEN\n        return {\n            'ids': np.array(ids,dtype=np.int32),\n            'mask': np.array(mask,dtype=np.int32),\n            'tok_ids':np.array(token_type,dtype=np.int32),\n            'start':np.array(targets_start,dtype=np.int32),\n            'end':np.array(targets_end,dtype=np.int32)\n            \n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_ids,tr_att,tr_tok,tr_st,tr_end=[],[],[],[],[]\nfor x in range(df.shape[0]):\n    out= preprocess(df.iloc[x])\n    tr_ids.append(out['ids'])\n    tr_att.append(out['mask'])\n    tr_tok.append(out['tok_ids'])\n    tr_st.append(out['start'])\n    tr_end.append(out['end'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tr_ids== tf.convert_to_tensor(tr_ids,dtype=tf.int32)\n# tr_att= tf.convert_to_tensor(tr_att,dtype=tf.int32)\n# tr_tok= tf.convert_to_tensor(tr_tok,dtype=tf.int32)\n# tr_st= tf.convert_to_tensor(tr_st,dtype=tf.int32)\n# tr_end=tf.convert_to_tensor(tr_end,dtype=tf.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_ids=np.array(tr_ids,dtype=np.int32)\ntr_att= np.array(tr_att,dtype=np.int32)\ntr_tok= np.array(tr_tok,dtype=np.int32)\ntr_st= np.array(tr_st,dtype=np.int32)\ntr_end=np.array(tr_end,dtype=np.int32)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_st.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n\n    config = transformers.RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = transformers.TFRobertaModel.from_pretrained(PATH+\n            'pretrained-roberta-base.h5',config=config)\n    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n\n    x1 = tf.keras.layers.Conv1D(1,1)(x[0])\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n\n    x2 = tf.keras.layers.Conv1D(1,1)(x[0])\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer,metrics=['accuracy'])\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model= build_model()\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a)==0) & (len(b)==0): return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df= pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocesstest(item):\n        tweet=\" \".join(str(item['text']).split())\n        tok_tweet =TOKENIZER.encode(tweet)\n        tok_tweet_tokens=tok_tweet.tokens\n        tok_tweet_ids=tok_tweet.ids\n        tok_tweet_offsets=tok_tweet.offsets[1:-1]\n\n        tok_tweet_ids= [0]+tok_tweet_ids+[2]  \n        \n        tok_tweet_ids=tok_tweet_ids+[2]+[sent_id[item['sentiment']]]+[2]\n        mask=[1]*len(tok_tweet_ids)\n        \n        padding_len= MAX_LEN- len(tok_tweet_ids)\n        ids= tok_tweet_ids+[1]*padding_len\n        mask= mask+[0]*padding_len\n  \n        token_type=[0]*MAX_LEN\n        return {\n            'ids': tf.convert_to_tensor(ids,dtype=tf.int32),\n            'mask': tf.convert_to_tensor(mask,dtype=tf.int32),\n            'tok_ids':tf.convert_to_tensor(token_type,dtype=tf.int32)\n        }\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fold=1\njacks=[]\nskf = StratifiedKFold(n_splits=5,shuffle=True,random_state=101)\nfor fold,(idxT,idxV) in enumerate(skf.split(tr_ids,df.sentiment.values)):\n    print('*'*10)\n    print('Fold ',fold+1)\n    fold+=1\n    \n    model.fit(x=[tr_ids[idxT],tr_att[idxT],tr_tok[idxT]],y=[tr_st[idxT],tr_end[idxT]],epochs=4,validation_data=([tr_ids[idxV],tr_att[idxV],tr_tok[idxV]],[tr_st[idxV],tr_end[idxV]]),shuffle=True,batch_size=64)\n    \n    scores=[]\n    for inx in idxV:\n        sent=df['text'][inx]\n        ids=tr_ids[inx]\n        att=tr_att[inx]\n        tok=tr_tok[inx]\n        ids= np.reshape(ids,(1,len(ids)))\n        att= np.reshape(att,(1,len(att)))\n        tok= np.reshape(tok,(1,len(tok)))\n        start,end = model.predict([ids,att,tok])\n        stidx= np.argmax(start)\n        stend= np.argmax(end)\n        if stidx>stend:\n            t=stidx\n            stidx=stend\n            stend=t\n        text1 = \" \".join(sent.split())\n        enc = TOKENIZER.encode(text1)\n        st = TOKENIZER.decode(enc.ids[stidx-1:stend+1])\n        scores.append(jaccard(sent,st))\n    jacks.append(np.mean(scores))\n    print(np.mean(scores))\n    print('*'*10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nprint(np.mean(jacks))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=[]\nindices=[]\nfor x in range(test_df.shape[0]):\n    sent=test_df.iloc[x]['text']\n    inp = preprocesstest(test_df.iloc[x])\n    ids= (inp['ids'])\n    att = (inp['mask'])\n    tok = inp['tok_ids']\n    ids= tf.reshape(ids,(1,len(ids)))\n    att= tf.reshape(att,(1,len(att)))\n    tok= tf.reshape(tok,(1,len(tok)))\n    start,end= model.predict([ids,att,tok])\n    stidx= np.argmax(start)\n    stend= np.argmax(end)\n    if stidx>stend:\n        t=stidx\n        stidx=stend\n        stend=t\n        \n    text1 = \" \".join(sent.split())\n    enc = TOKENIZER.encode(text1)\n    st = TOKENIZER.decode(enc.ids[stidx-1:stend+1])\n    output.append(st)\n    indices.append([stidx,stend])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub= pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsub.loc[:,'selected_text']=output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.drop(['text','sentiment'],axis=1,inplace=True)\nsub.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub.to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for x in range(79,100):\n#     print(\"*\"*25)\n#     print(test_df.iloc[x]['text'])\n#     print(indices[x])\n#     print(output[x])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}