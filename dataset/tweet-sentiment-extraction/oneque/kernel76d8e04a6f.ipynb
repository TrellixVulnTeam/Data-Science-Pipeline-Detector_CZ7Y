{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd \n\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dropout\nfrom nltk.stem.lancaster import LancasterStemmer\nfrom keras.callbacks import EarlyStopping\nfrom keras.callbacks import ModelCheckpoint\nimport matplotlib.pylab as plt\n\nimport nltk\nimport re\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train dada loading and reviwing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Input data : column 'text', tatget : column 'sentiment'","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Nan value dropping\ntrain_df = train_df.dropna()\n\n# train_data_X\nX = train_df.drop('sentiment', axis = 1)\n\n#  train_data_y as target\ny = train_df['sentiment']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# stopword download","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# stopwords download\nnltk.download('stopwords')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for further processing\ntemp_data = X.copy()\n\n# chagein original index to number\ntemp_data.reset_index(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len_result = [len(s) for s in temp_data]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len_result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"unique_elements, counts_elements = np.unique(y, return_counts=True)\nprint(np.asarray((unique_elements, counts_elements)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# unuque data # 확인","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.subplot(1,2,1)\nplt.bar(['neg','neu','pos'],counts_elements )\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Preprocessing :stemer : LancasterStemmer\n\nstemmer = LancasterStemmer()\ncorpus = []\n\nfor i in range(0, len(temp_data)):\n    \n    result = re.sub('[^a-zA-Z]', ' ', str(temp_data['text'][i]))\n    result = result.lower()\n    result = result.split()\n    \n    result = [stemmer.stem(word) for word in result if not word in stopwords.words('english')]\n    result = ' '.join(result)\n    corpus.append(result)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# voc size\nvoc_size = 5000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# One Hot Encoding\nonehot_code = [one_hot(words, voc_size) for words in corpus]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# making same length sentences\nsent_length = 30\nembedded_size = pad_sequences(onehot_code, padding = 'pre', maxlen = sent_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the numberof labels\ntext_num = len(temp_data['text'])\nnum_labels = len(set(train_df['sentiment']))\nnum_labels_set = set(train_df['sentiment'])\n\nprint(text_num,num_labels,num_labels_set)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM Model 적용","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# structure setting\nvector_size = 30 \n\n## Creating model\nmodel=Sequential()\nmodel.add(Embedding(voc_size,vector_size,input_length=sent_length))\nmodel.add(LSTM(100))#100\nmodel.add(Dense(num_labels,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='rmsprop',metrics=['acc'])\nprint(model.summary())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label encoding","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import preprocessing\n\n# labeel encoding \nlabel_enconding = preprocessing.LabelEncoder()\ny = label_enconding.fit_transform(y)\n\nX_final = np.array(embedded_size)\ny_final = np.array(y)\n\nfrom keras.utils import to_categorical\ny_final = to_categorical(y_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.3, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 20, batch_size = 64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(X):\n    \n    # Drop Nan Values\n    X = X.fillna(0)\n    \n    temp_data = X.copy()\n\n    temp_data.reset_index(inplace = True)\n\n    # Dataset Preprocessing\n    stemmer = LancasterStemmer()\n\n    corpus = []\n\n    for i in range(0, len(temp_data)):\n        \n        result = re.sub('[^a-zA-Z]', ' ', str(temp_data['text'][i]))\n        result = result.lower()\n        result = result.split()\n\n        result = [stemmer.stem(word) for word in result if not word in stopwords.words('english')]\n        result = ' '.join(result)\n        corpus.append(result)\n\n    # voc size\n    voc_size = 5000\n\n    onehot_code = [one_hot(words, voc_size) for words in corpus]\n\n    \n    # making  same length sentence\n    sent_length = 30\n    \n    # Embedding Representation\n    embedded_size = pad_sequences(onehot_code, padding = 'pre', maxlen = sent_length)\n\n    X_final = np.array(embedded_size)\n    \n    \n    return X_final, X","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test data load","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading test data and pre-processing\ntest_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nX_test,X_test_drop = preprocess(test_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test = model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.DataFrame()\ndf_sub['id'] = X_test_drop['textID']\ndf_sub['text'] = X_test_drop['text']\ndf_sub['sentiment_predicted'] = label_enconding.inverse_transform(y_pred_test)\ndf_sub['sentiment_actual'] = X_test_drop['sentiment']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submission.cvs 생성","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Creating a confusion matrix","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve,auc\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\ncm = confusion_matrix(df_sub['sentiment_actual'].values , df_sub['sentiment_predicted'].values)\ncm = cm.astype(np.float) / cm.sum(axis=1)[:, np.newaxis]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Transform to df for easier plotting\nfinal_cm = pd.DataFrame(cm, index = label_enconding.classes_,\n                     columns = label_enconding.classes_\n                    )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Confusion Matrix Graph","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (5,5))\nsns.heatmap(final_cm, annot = True,cmap='Greys',cbar=False)\nplt.title('Emotion Classify')\nplt.ylabel('True class')\nplt.xlabel('Prediction class')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}