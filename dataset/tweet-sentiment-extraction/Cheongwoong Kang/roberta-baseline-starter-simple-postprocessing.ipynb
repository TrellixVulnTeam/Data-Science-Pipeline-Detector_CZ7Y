{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":false},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":false},"cell_type":"code","source":"pd_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\npd_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"train = np.array(pd_train)\ntest = np.array(pd_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing\nI formulate this task as an extractive question answering problem, such as SQuAD.  \nGiven a question and context, the model is trained to find the answer spans in the context.\n\nTherefore, I use sentiment as question, text as context, selected_text as answer.\n- Question: sentiment\n- Context: text\n- Answer: selected_text\n"},{"metadata":{"trusted":false},"cell_type":"code","source":"def find_all(input_str, search_str):\n    l1 = []\n    length = len(input_str)\n    index = 0\n    while index < length:\n        i = input_str.find(search_str, index)\n        if i == -1:\n            return l1\n        l1.append(i)\n        index = i + 1\n    return l1","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"!mkdir data","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert training data\n\noutput = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\n\nfor line in train:\n    paragraphs = []\n    \n    context = line[1]\n    \n    qas = []\n    question = line[-1]\n    qid = line[0]\n    answers = []\n    answer = line[2]\n    if type(answer) != str or type(context) != str or type(question) != str:\n        print(context, type(context))\n        print(answer, type(answer))\n        print(question, type(question))\n        continue\n    answer_starts = find_all(context, answer)\n    for answer_start in answer_starts:\n        answers.append({'answer_start': answer_start, 'text': answer})\n    qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n    \n    paragraphs.append({'context': context, 'qas': qas})\n    output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n\nwith open('data/train.json', 'w') as outfile:\n    json.dump(output, outfile)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Convert test data\n\noutput = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\n\nfor line in test:\n    paragraphs = []\n    \n    context = line[1]\n    \n    qas = []\n    question = line[-1]\n    qid = line[0]\n    if type(context) != str or type(question) != str:\n        print(context, type(context))\n        print(answer, type(answer))\n        print(question, type(question))\n        continue\n    answers = []\n    answers.append({'answer_start': 1000000, 'text': '__None__'})\n    qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n    \n    paragraphs.append({'context': context, 'qas': qas})\n    output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n\nwith open('data/test.json', 'w') as outfile:\n    json.dump(output, outfile)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finetuning RoBERTa"},{"metadata":{},"cell_type":"markdown","source":"Install the pytorch-transformers package (v2.5.1) of [huggingface](https://github.com/huggingface/transformers/tree/v2.5.1)."},{"metadata":{"trusted":false},"cell_type":"code","source":"!cd /kaggle/input/pytorchtransformers/transformers-2.5.1; pip install .","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"!mkdir results_roberta_large","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finetune a RoBERTa-QA model."},{"metadata":{"trusted":false},"cell_type":"code","source":"!python /kaggle/input/pytorchtransformers/transformers-2.5.1/examples/run_squad.py \\\n--model_type roberta \\\n--model_name_or_path roberta-large \\\n--do_lower_case \\\n--do_train \\\n--do_eval \\\n--data_dir ./data \\\n--cache_dir /kaggle/input/cached-roberta-large-pretrained/cache \\\n--train_file train.json \\\n--predict_file test.json \\\n--learning_rate 5e-5 \\\n--num_train_epochs 2 \\\n--max_seq_length 192 \\\n--doc_stride 64 \\\n--output_dir results_roberta_large \\\n--per_gpu_eval_batch_size=16 \\\n--per_gpu_train_batch_size=16 \\\n--save_steps=100000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Submission"},{"metadata":{"trusted":false},"cell_type":"code","source":"# Copy predictions to submission file.\npredictions = json.load(open('results_roberta_large/predictions_.json', 'r'))\nsubmission = pd.read_csv(open('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv', 'r'))\nfor i in range(len(submission)):\n    id_ = submission['textID'][i]\n    if pd_test['sentiment'][i] == 'neutral': # neutral postprocessing\n        submission.loc[i, 'selected_text'] = pd_test['text'][i]\n    else:\n        submission.loc[i, 'selected_text'] = predictions[id_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# Save the submission file.\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}