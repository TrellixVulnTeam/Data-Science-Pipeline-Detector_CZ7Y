{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Problem Formulation\nI formulate this task as an extractive question answering problem, such as SQuAD.  \nGiven a question and context, the model is trained to find the answer spans in the context.\n\nTherefore, I use sentiment as question, text as context, selected_text as answer.\n- Question: sentiment\n- Context: text\n- Answer: selected_text"},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameters & Options "},{"metadata":{"trusted":true},"cell_type":"code","source":"# Hyperparameters\nbatch_size = 16 # batch size\nlr = 5e-5 # learning rate\nepochs = 2 # number of epochs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport json\nimport os","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing\n### Load Data"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"pd_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\npd_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n#pd_external = pd.read_csv('/kaggle/input/sentiment140/training.1600000.processed.noemoticon.csv', sep=',', header=None, encoding='latin')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd_external.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np_train = np.array(pd_train)\nnp_test = np.array(pd_test)\n#np_external = np.array(pd_external)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lm_train = open('tweet.train.raw', 'w')\nfor line in np_train:\n    context = line[1]\n    if type(context) != str:\n        continue\n    context = context.lower()\n    lm_train.write(context.strip() + '\\n')\n\n#for line in np_external:\n#    context = line[-1].lower()\n#    if type(context) != str:\n#        continue\n#    context = context.lower()\n#    lm_train.write(context.strip() + '\\n')\n    \nlm_test = open('tweet.test.raw', 'w')\nfor line in np_test:\n    context = line[1].lower()\n    if type(context) != str:\n        continue\n    context = context.lower()\n    lm_test.write(context.strip() + '\\n')\n    \n    lm_train.write(context.strip() + '\\n')\n\nlm_train.close()\nlm_test.close()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finetuning\nInstall the pytorch-transformers package (v2.5.1) of [huggingface](https://github.com/huggingface/transformers)."},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/pytorchtransformers/transformers-2.5.1; pip install .","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":false,"trusted":true},"cell_type":"code","source":"def run_script(train_file, predict_file, batch_size=16, lr=5e-5, epochs=2):\n    !python /kaggle/input/pytorchtransformers/transformers-2.5.1/examples/run_language_modeling.py \\\n    --output_dir=results \\\n    --model_type=distilbert \\\n    --model_name_or_path=distilbert-base-uncased \\\n    --cache_dir /kaggle/input/cached-distilbert-base-uncased/cache \\\n    --do_train \\\n    --train_data_file=$train_file \\\n    --do_eval \\\n    --eval_data_file=$predict_file \\\n    --learning_rate=$lr \\\n    --mlm \\\n    --line_by_line \\\n    --num_train_epochs=$epochs \\\n    --per_gpu_eval_batch_size=$batch_size \\\n    --per_gpu_train_batch_size=$batch_size \\\n    --save_steps=1000000","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir results","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"train_file = \"tweet.train.raw\"\npredict_file = \"tweet.test.raw\"\nrun_script(train_file, predict_file, batch_size, lr, epochs)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.6"}},"nbformat":4,"nbformat_minor":4}