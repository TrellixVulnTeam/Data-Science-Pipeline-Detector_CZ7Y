{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n#  <span style=\"color:green\"> <center> A Quick Look at ```Selected Text``` Noise\n\n### In this notebook, I am exploring the noise in the dataset. \n1. I analysed the ```selected_text``` column in the original dataset.\n2. I compared ```selected_text``` with the ```prediction``` of a reference model to find out why I am getting low performance in positive and negative sentiment predictions.\n\n\n### Reference Model\nI am using prediction of a trained model ```(5 fold ensemble of a RoBERTa-Base with public LB 0.712)``` to find out anamolies. I can identify many of them by performing error analysis. In particular, when my Jaccard score is very low, many times it's due to the inherent noise in the data.\n\n\n### <span style=\"color:orange\"> Can We Use It For Our Benefits?\n\n\n\n### <span style=\"color:green\">  If you find it useful, please upvote! Thank you! ðŸ”¥</span>\n\n** N.B. I just listed a few noise. At the end of the notebook you can generate random samples to find more variety of noise. **"},{"metadata":{},"cell_type":"markdown","source":"## Include Prerequisites"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# PACKAGES\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport sys, os\nfrom IPython.core.display import *\n\n# DATA I/O\nprint('Loading Ground Truth')\ntrain_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ndisplay(train_df.head())\n\n# Load prediction of Trained RoBERTa Model (5 fold ensemble, 0.712LB)\nprint('Loading Trained Model Predictions')\npreds = pd.read_csv('/kaggle/input/tweeterroranalysis/error-analysis-roberta-base-5model.csv')\npreds.drop(columns=['textID'], inplace=True)\ndisplay(preds.head())\n\n# Analmoly Statistics\nanamoly = train_df.copy().drop(columns=['textID','text','selected_text','sentiment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Estimate Jaccard Score of the Model Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    \"\"\" Compute Jaccard Score \n    \"\"\"\n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\npreds['Jaccard'] = preds.apply(lambda x: jaccard(str(x.selected_text), str(x.prediction)), axis=1)\npreds['word_length'] = preds['prediction'].apply(lambda x: len(x.split()))\ndisplay(preds.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Let's Look @ my Jaccard Distribution\n\n- There are tons of errors in postive and negative sentiment predictions.\n- During prediction my model copied whole text to prediction when sentiment in ```neutral```. Looks like it is not a perfect strategy as it has a few non perfect Jaccard scores.\n- Average Jaccard values for 3 sentiments: \n``` \nPOSITIVE: 0.5814722049084579\nNEGATIVE: 0.5906752954713453\nNEUTRAL:  0.9764467881939682\n```"},{"metadata":{"trusted":true},"cell_type":"code","source":"dfg = preds.groupby(['sentiment'])\ndf_pos = dfg.get_group('positive')\ndf_neg = dfg.get_group('negative')\ndf_neutral = dfg.get_group('neutral')\nfig=px.histogram(df_pos, x='Jaccard',title='Positive Sentiment');fig.show();\nfig=px.histogram(df_neg, x='Jaccard',title='Negative Sentiment');fig.show();\nfig=px.histogram(df_neutral, x='Jaccard',title='Neutral Sentiment');fig.show();\n\nprint(\"All data Jaccard: \" + str(preds.Jaccard.mean()))\nprint(\"+ data Jaccard: \" + str(df_pos.Jaccard.mean()))\nprint(\"- data Jaccard: \" + str(df_neg.Jaccard.mean()))\nprint(\"= data Jaccard: \" + str(df_neutral.Jaccard.mean()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# ðŸ‘» Warmup: Let's Look at the Lonely Characters in ```selected_text```\n\n### Not many of those!"},{"metadata":{"trusted":true},"cell_type":"code","source":"lonely_comma_indices = train_df.selected_text.apply(lambda x: 1 if (',' in str(x).split()) else 0)\nanamoly['lonely comma'] = lonely_comma_indices\n\nlonely_semicolon_indices = train_df.selected_text.apply(lambda x: 1 if (';' in str(x).split()) else 0)\nanamoly['lonely semicolon'] = lonely_semicolon_indices\n\nlonely_colon_indices = train_df.selected_text.apply(lambda x: 1 if (':' in str(x).split()) else 0)\nanamoly['lonely colon'] = lonely_colon_indices\n\nlonely_period_indices = train_df.selected_text.apply(lambda x: 1 if ('.' in str(x).split()) else 0)\nanamoly['lonely period'] = lonely_period_indices\n\nlonely_at_indices = train_df.selected_text.apply(lambda x: 1 if ('@' in str(x).split()) else 0)\nanamoly['lonely @'] = lonely_at_indices\n\nlonely_underscore_indices = train_df.selected_text.apply(lambda x: 1 if ('_' in str(x).split()) else 0)\nanamoly['lonely _'] = lonely_underscore_indices\n\nprint(\"Lonely Charater Statistics\")\ndisplay(pd.DataFrame(anamoly.iloc[:,:6].sum()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Now Let's See Where My Model Scored Jaccard=0 for Positive and Negative Sentiments.\n\n### NOT FAIR!ðŸ˜³ I am penalized because:\n\n### 1. Missing a ```!```  <span style=\"color:orange\">Damn! It ```hurts!!!```\n\n### 2. Missing a ```.```  <span style=\"color:orange\">It is ```stupid...```\n\n### 3. Missing ```d``` in ```good```?  <span style=\"color:orange\">LOL. It's not ```goo```\n\n### 4. Missing ```ng``` in ```amazing```?  <span style=\"color:orange\">Dude. It's not ```amazi``` at all!\n\n### 5. Words are not complete in the data! E.g. ```st jokin``` instead of ```just joking```.\n\n### ..."},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all0 = df_neg[df_neg.Jaccard==0].append(df_pos[df_pos.Jaccard==0]).reset_index().drop(columns=['index'])\nprint('Missing !')\ndisplay(df_all0[df_all0.index==340])\nprint('Missing .')\ndisplay(df_all0[df_all0.index==226])\nprint('Data has missing character at the end')\ndisplay(df_all0[df_all0.index==792])\nprint('Data has missing multiple characters at the end')\ndisplay(df_all0[df_all0.index==621])\nprint('Data has words only containing last two characters')\ndisplay(df_all0[df_all0.index==1150])\ndisplay(df_all0[df_all0.index==581])\ndisplay(df_all0[df_all0.index==906])\nprint('Data has words only containing last one character')\ndisplay(df_all0[df_all0.index==181])\ndisplay(df_all0[df_all0.index==984])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <span style=\"color:red\"> I gained 0.001LB Just by adding following post-processing! Can you come up with more ways to improve?"},{"metadata":{},"cell_type":"markdown","source":"```\nsample = pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\nsample.loc[:, 'selected_text'] = final_output\n\nsample['selected_text'] = sample['selected_text'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\nsample['selected_text'] = sample['selected_text'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\nsample['selected_text'] = sample['selected_text'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\n```"},{"metadata":{},"cell_type":"markdown","source":"# To find more noise, you can run the following code to get random samples!"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all0.sample(20) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Scrap"},{"metadata":{"trusted":true},"cell_type":"code","source":"df = preds.copy()\n\nprint('Before')\nprint(df.Jaccard.mean())\n\ndf['prediction'] = df['prediction'].apply(lambda x: x.replace('!!!!', '!') if len(x.split())==1 else x)\ndf['prediction'] = df['prediction'].apply(lambda x: x.replace('..', '.') if len(x.split())==1 else x)\ndf['prediction'] = df['prediction'].apply(lambda x: x.replace('...', '.') if len(x.split())==1 else x)\ndf['Jaccard'] = df.apply(lambda x: jaccard(str(x.selected_text), str(x.prediction)), axis=1)\n\nprint('After')\nprint(df.Jaccard.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\n\ndef post_process(s):\n    a = re.findall('[^A-Za-z0-9]',s)\n    b = re.sub('[^A-Za-z0-9]+', '', s)\n\n    try:\n        if a.count('.')==3:\n            text = b + '. ' + b + '..'\n        elif a.count('!')==4:\n            text = b + '! ' + b + '!! ' +  b + '!!!'\n        else:\n            text = s\n        return text\n    except:\n        return text\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = preds.copy()\n#df = df_all0.copy()\n\nprint('Before')\nprint(df.Jaccard.mean())\n\ndf['prediction'] = df.apply(lambda x: post_process(x['prediction']) if (len(str(x['prediction']).split())==1) else x['prediction'], axis=1)\ndf['Jaccard'] = df.apply(lambda x: jaccard(str(x.selected_text), str(x.prediction)), axis=1)\n\nprint('After')\nprint(df.Jaccard.mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Improved {100*len(df[df.Jaccard>0])/len(df[df.Jaccard==0])}% entries')\ndf[df.Jaccard>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df[df.Jaccard>0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df_all0.copy()\ndf['pred_count'] = df.apply(lambda x: x['prediction'].count('.') if ((len(x['prediction'].split())==1)&(len(x['selected_text'].split())==1)) else x['prediction'], axis=1)\ndf['gt_count'] = df.apply(lambda x: x['selected_text'].count('.') if ((len(x['prediction'].split())==1)&(len(x['selected_text'].split())==1)) else x['selected_text'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"a = df[df.word_length==1]\n\nprint('1 .')\nt = a[a.pred_count==1].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();\n\nprint('2 .')\nt = a[a.pred_count==2].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();\n\nprint('3 .')\nt = a[a.pred_count==3].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();\n\nprint('4 .')\nt = a[a.pred_count==4].gt_count\nu = plt.hist(t)\nplt.bar(np.arange(len(u[0])),u[0]); plt.show();","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}