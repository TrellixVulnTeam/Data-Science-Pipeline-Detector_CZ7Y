{"cells":[{"metadata":{},"cell_type":"markdown","source":"<centre> ![image.png](attachment:image.png) \n\n# <center>   HuggingFace Tokenizer Cheat-Sheet","attachments":{"image.png":{"image/png":"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"}}},{"metadata":{},"cell_type":"markdown","source":"### This notebook contains handy information to help building NLP models using Hugging Face Library (https://huggingface.co/transformers). \n\n#### I will keep updating this notebook. \n\n\nPlease upvote if this is useful!\n"},{"metadata":{},"cell_type":"markdown","source":"## Import Useful Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nimport transformers\nimport tokenizers","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"# TOKENIZERS"},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green\">BERT Base Uncased </span>\n\n### Offline loading in Kaggle Notebook (Thanks to https://www.kaggle.com/abhishek)\n\n```\nhttps://www.kaggle.com/abhishek/bert-base-uncased\n```\n\nThat contains:\n\n```\nconfig.json\nvocab.txt\npytorch_model.bin\n```\n\n<span style=\"color:blue\">Example usage: </span>\n```\nimport tokenizers\n\nTOKENIZER = tokenizers.BertWordPieceTokenizer(\n    f\"{BERT_PATH}/vocab.txt\", \n    lowercase=True\n)\n```\n\n\n### Online loading in Kaggle Notebook (needs Internet) using ```BertTokenizer```\n\n```\nhttps://huggingface.co/transformers/_modules/transformers/tokenization_bert.html\n```\n\n<span style=\"color:blue\">Example usage: </span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer\nTOKENIZER = BertTokenizer.from_pretrained(\"bert-base-uncased\")\nenc = TOKENIZER.encode(\"Hello there!\")\ndec = TOKENIZER.decode(enc)\nprint(\"Encode: \" + str(enc))\nprint(\"Decode: \" + str(dec))\nprint(\"[CLS]: \" + str(enc[0]))\nprint(\"[SEP]: \" + str(enc[4]))\nprint(\"[PAD]: \" + str(TOKENIZER.encode(\"[PAD]\")[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note: There are also tons of other pretrained models other than ```\"bert-base-uncased\"```:**\n```\nPRETRAINED_INIT_CONFIGURATION = {\n    \"bert-base-uncased\": {\"do_lower_case\": True},\n    \"bert-large-uncased\": {\"do_lower_case\": True},\n    \"bert-base-cased\": {\"do_lower_case\": False},\n    \"bert-large-cased\": {\"do_lower_case\": False},\n    \"bert-base-multilingual-uncased\": {\"do_lower_case\": True},\n    \"bert-base-multilingual-cased\": {\"do_lower_case\": False},\n    \"bert-base-chinese\": {\"do_lower_case\": False},\n    \"bert-base-german-cased\": {\"do_lower_case\": False},\n    \"bert-large-uncased-whole-word-masking\": {\"do_lower_case\": True},\n    \"bert-large-cased-whole-word-masking\": {\"do_lower_case\": False},\n    \"bert-large-uncased-whole-word-masking-finetuned-squad\": {\"do_lower_case\": True},\n    \"bert-large-cased-whole-word-masking-finetuned-squad\": {\"do_lower_case\": False},\n    \"bert-base-cased-finetuned-mrpc\": {\"do_lower_case\": False},\n    \"bert-base-german-dbmdz-cased\": {\"do_lower_case\": False},\n    \"bert-base-german-dbmdz-uncased\": {\"do_lower_case\": True},\n    \"bert-base-finnish-cased-v1\": {\"do_lower_case\": False},\n    \"bert-base-finnish-uncased-v1\": {\"do_lower_case\": True},\n    \"bert-base-dutch-cased\": {\"do_lower_case\": False},\n}\n```"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"## <span style=\"color:green\">RoBERTa </span>\n\n### Offline loading in Kaggle Notebook (Thanks to https://www.kaggle.com/abhishek)\n\n```\nhttps://www.kaggle.com/abhishek/roberta-base\n```\n\nThat contains:\n\n```\nconfig.json\nvocab.json\nmerges.txt\npytorch_model.bin\n```\n\n\n<span style=\"color:blue\">Example usage: </span>\n```\nimport tokenizers\n\nROBERTA_PATH = \"../input/roberta-base\"\nTOKENIZER = tokenizers.ByteLevelBPETokenizer(\n    vocab_file=f\"{ROBERTA_PATH}/vocab.json\", \n    merges_file=f\"{ROBERTA_PATH}/merges.txt\", \n    lowercase=True,\n    add_prefix_space=True\n)\n```\n\n\n### Online loading in Kaggle Notebook (needs Internet) using ```RobertaTokenizer```\n\n```\nhttps://huggingface.co/transformers/_modules/transformers/tokenization_roberta.html\n```\n\n<span style=\"color:blue\">Example usage: </span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import RobertaTokenizer\nTOKENIZER = RobertaTokenizer.from_pretrained(\"roberta-base\")\nenc = TOKENIZER.encode(\"Hello there!\")\ndec = TOKENIZER.decode(enc)\nprint(\"Encode: \" + str(enc))\nprint(\"Decode: \" + str(dec))\nprint(\"[CLS]: \" + str(enc[0]))\nprint(\"[SEP]: \" + str(enc[4]))\nprint(\"<pad>: \" + str(TOKENIZER.encode(\"<pad>\")[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note: There are also tons of other pretrained models other than ```\"roberta-base\"```:**\n\n```\nPRETRAINED_VOCAB_FILES_MAP = {\n    \"vocab_file\": {\n        \"roberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json\",\n        \"roberta-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json\",\n        \"roberta-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-vocab.json\",\n        \"distilroberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-vocab.json\",\n        \"roberta-base-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-vocab.json\",\n        \"roberta-large-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-vocab.json\",\n    },\n    \"merges_file\": {\n        \"roberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt\",\n        \"roberta-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt\",\n        \"roberta-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-mnli-merges.txt\",\n        \"distilroberta-base\": \"https://s3.amazonaws.com/models.huggingface.co/bert/distilroberta-base-merges.txt\",\n        \"roberta-base-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-base-merges.txt\",\n        \"roberta-large-openai-detector\": \"https://s3.amazonaws.com/models.huggingface.co/bert/roberta-large-merges.txt\",\n    },\n}\n```"},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green\">ALBERT</span>\n\n### Offline loading in Kaggle Notebook\n\n```\n[TODO] Planning to create a dataset in future!\n```\n\n\n\n### Online loading in Kaggle Notebook (needs Internet) using ```AlbertTokenizer```\n\n```\nhttps://huggingface.co/transformers/_modules/transformers/tokenization_albert.html\n```\n\n<span style=\"color:blue\">Example usage: </span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import AlbertTokenizer\nTOKENIZER = AlbertTokenizer.from_pretrained(\"albert-base-v1\")\nenc = TOKENIZER.encode(\"Hello there!\")\ndec = TOKENIZER.decode(enc)\nprint(\"Encode: \" + str(enc))\nprint(\"Decode: \" + str(dec))\nprint(\"[CLS]: \" + str(enc[0]))\nprint(\"[SEP]: \" + str(enc[4]))\nprint(\"<pad>: \" + str(TOKENIZER.encode(\"<pad>\")[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Note: There are also tons of other pretrained models other than ```\"albert-base-v1\"```:**\n```\nPRETRAINED_VOCAB_FILES_MAP = {\n    \"vocab_file\": {\n        \"albert-base-v1\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v1-spiece.model\",\n        \"albert-large-v1\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-v1-spiece.model\",\n        \"albert-xlarge-v1\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xlarge-v1-spiece.model\",\n        \"albert-xxlarge-v1\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v1-spiece.model\",\n        \"albert-base-v2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-base-v2-spiece.model\",\n        \"albert-large-v2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-large-v2-spiece.model\",\n        \"albert-xlarge-v2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xlarge-v2-spiece.model\",\n        \"albert-xxlarge-v2\": \"https://s3.amazonaws.com/models.huggingface.co/bert/albert-xxlarge-v2-spiece.model\",\n    }\n}\n\n```"},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green\">Bart </span>\n\n### Offline loading in Kaggle Notebook\n\n```\n[TODO]\n```\n\n\n### Online loading in Kaggle Notebook (needs Internet) using ```RobertaTokenizer```\n\n```\nhttps://huggingface.co/transformers/_modules/transformers/modeling_bart.html\n```\n\n<span style=\"color:blue\">Example usage: </span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BartTokenizer\nTOKENIZER = BartTokenizer.from_pretrained('bart-large')\nenc = TOKENIZER.encode(\"Hello there!\")\ndec = TOKENIZER.decode(enc)\nprint(\"Encode: \" + str(enc))\nprint(\"Decode: \" + str(dec))\nprint(\"[CLS]: \" + str(enc[0]))\nprint(\"[SEP]: \" + str(enc[4]))\nprint(\"<pad>: \" + str(TOKENIZER.encode(\"<pad>\")[1]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"\n**Note: There are also tons of other pretrained models other than ```\"bart-large\"```:**\n\n```\nBART_PRETRAINED_MODEL_ARCHIVE_MAP = {\n    \"bart-large\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large/pytorch_model.bin\",\n    \"bart-large-mnli\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-mnli/pytorch_model.bin\",\n    \"bart-large-cnn\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-cnn/pytorch_model.bin\",\n    \"bart-large-xsum\": \"https://s3.amazonaws.com/models.huggingface.co/bert/facebook/bart-large-xsum/pytorch_model.bin\",\n}\n```"},{"metadata":{},"cell_type":"markdown","source":"## <span style=\"color:green\">ELECTRA </span>\n\n### Offline loading in Kaggle Notebook (Thanks to https://www.kaggle.com/ratan123)\n\n```\nhttps://www.kaggle.com/ratan123/electra-base\n```\n\n\n<span style=\"color:blue\">Example usage: </span>\n```\nimport tokenizers\n\nELECTRA_PATH = \"/kaggle/input/electra-base/\"\nTOKENIZER = tokenizers.BertWordPieceTokenizer(\n    f\"{ELECTRA_PATH}/vocab.txt\", \n    lowercase=True\n)\n```\n\n### Online loading in Kaggle Notebook (needs Internet) using ```ElectraTokenizer```\n\n```\nhttps://huggingface.co/transformers/_modules/transformers/tokenization_electra.html\n```\n\n<span style=\"color:blue\">Example usage: </span>"},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import BertTokenizer\n# class:`~transformers.ElectraTokenizer` is identical to :class:`~transformers.BertTokenizer` and runs end-to-end tokenization: punctuation splitting + wordpiece.\nTOKENIZER = BertTokenizer.from_pretrained('google/electra-base-generator')\nenc = TOKENIZER.encode(\"Hello there!\")\ndec = TOKENIZER.decode(enc)\nprint(\"Encode: \" + str(enc))\nprint(\"Decode: \" + str(dec))\nprint(\"[CLS]: \" + str(enc[0]))\nprint(\"[SEP]: \" + str(enc[4]))\nprint(\"[PAD]: \" + str(TOKENIZER.encode(\"[PAD]\")[1]))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}