{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Prequels/sequels\n\n- **FastChai sessions: Tweet Sentiment Extraction (data-prep) | [Extended Dataset](https://www.kaggle.com/neomatrix369/tweet-sentiment-extraction-extended)**\n- [FastChai sessions: Tweet Sentiment Extraction (analysis)](https://www.kaggle.com/neomatrix369/fastchai-tweet-sentiment-extraction-analysis/)\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport gc\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install -U nlp_profiler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from nlp_profiler.core import apply_text_profiling\nfrom nlp_profiler_class import NLPProfiler","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASET_UPLOAD_FOLDER='/kaggle/working/upload'\nEXTENDED_DATA_FOLDER='/kaggle/input/tweet-sentiment-extraction-extended'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\nDATASET_UPLOAD_FOLDER='/kaggle/working/upload'\nmkdir -p ${DATASET_UPLOAD_FOLDER}\ncp /kaggle/input/tweet-sentiment-extraction-extended/*.csv ${DATASET_UPLOAD_FOLDER} || true","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_csv_if_exists(filepath: str) -> pd.DataFrame:\n    result = None\n    if os.path.exists(filepath): \n        result = pd.read_csv(filepath)\n        print(f'Finished loading {result.shape[0]} rows from {filepath}')\n    else: \n        print(f'Warning: Did NOT find \"{filepath}\"')\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_to_csv_file(dataframe, filename, field_to_drop='text'):\n    dataframe_copy = dataframe.drop(field_to_drop, axis=1, errors='ignore')\n    dataframe_copy.to_csv(filename, index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_dataset = pd.read_csv(f'{EXTENDED_DATA_FOLDER}/train.csv')\ntest_dataset = pd.read_csv(f'{EXTENDED_DATA_FOLDER}/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_dataset.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training dataset: text column"},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_train_text_sentiment = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_text_sentiment.csv')\nprofiled_train_text_ease_of_reading = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_text_ease_of_reading.csv')\nprofiled_train_text_grammar = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_text_grammar_check.csv')\nprofiled_train_text_spelling = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_text_spelling_check.csv')\nprofiled_train_text_granular = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_text_granular_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_text_sentiment is None:\n    profiled_train_text_sentiment = NLPProfiler().apply_text_profiling(\n        training_dataset, 'text', \n        params={'high_level': True, # only sentiment analysis will be return\n                'ease_of_reading_check': False,\n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_text_ease_of_reading is None:\n    profiled_train_text_ease_of_reading = NLPProfiler().apply_text_profiling(\n        training_dataset, 'text', \n        params={'high_level': False, # only sentiment analysis will be return\n                'ease_of_reading_check': True,\n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_text_grammar is None:\n    profiled_train_text_grammar = NLPProfiler().apply_text_profiling(\n        training_dataset, 'text', \n        params={'high_level': False,\n                'ease_of_reading_check': False,                \n                'spelling_check': False,\n                'grammar_check': True,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_text_spelling is None:\n    profiled_train_text_spelling = NLPProfiler().apply_text_profiling(\n        training_dataset, 'text', \n        params={'high_level': False,\n                'ease_of_reading_check': False,                \n                'spelling_check': True,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nforce_generate = True\nif (profiled_train_text_granular is None) or force_generate:\n    profiled_train_text_granular = NLPProfiler().apply_text_profiling(\n        training_dataset, 'text', \n        params={'high_level': False,\n                'ease_of_reading_check': False,                \n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': True,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_train_text = pd.concat([training_dataset['text'], profiled_train_text_granular, profiled_train_text_sentiment, \n                                 profiled_train_text_ease_of_reading, profiled_train_text_grammar, profiled_train_text_spelling], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_train_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsave_to_csv_file(profiled_train_text_sentiment, f'{DATASET_UPLOAD_FOLDER}/profiled_train_text_sentiment.csv')\nsave_to_csv_file(profiled_train_text_ease_of_reading, f'{DATASET_UPLOAD_FOLDER}/profiled_train_text_ease_of_reading.csv')\nsave_to_csv_file(profiled_train_text_grammar, f'{DATASET_UPLOAD_FOLDER}/profiled_train_text_grammar_check.csv')\nsave_to_csv_file(profiled_train_text_spelling, f'{DATASET_UPLOAD_FOLDER}/profiled_train_text_spelling_check.csv')\nsave_to_csv_file(profiled_train_text_granular, f'{DATASET_UPLOAD_FOLDER}/profiled_train_text_granular_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del profiled_train_text_sentiment, profiled_train_text_ease_of_reading, profiled_train_text_grammar, \ndel profiled_train_text_spelling, profiled_train_text_granular\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training dataset: selected_text column"},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_train_selected_text_sentiment = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_selected_text_sentiment.csv')\nprofiled_train_selected_text_ease_of_reading = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_selected_text_ease_of_reading.csv')\nprofiled_train_selected_text_grammar = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_selected_text_grammar_check.csv')\nprofiled_train_selected_text_spelling = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_selected_text_spelling_check.csv')\nprofiled_train_selected_text_granular = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_train_selected_text_granular_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_selected_text_sentiment is None:\n    profiled_train_selected_text_sentiment = NLPProfiler().apply_text_profiling(\n        training_dataset, 'selected_text', \n        params={'high_level': True, # only sentiment analysis will be return\n                'ease_of_reading_check': False,\n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_selected_text_ease_of_reading is None:\n    profiled_train_selected_text_ease_of_reading = NLPProfiler().apply_text_profiling(\n        training_dataset, 'selected_text', \n        params={'high_level': False, \n                'ease_of_reading_check': True,\n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_selected_text_grammar is None:\n    profiled_train_selected_text_grammar = NLPProfiler().apply_text_profiling(\n        training_dataset, 'selected_text', \n        params={'high_level': False,\n                'ease_of_reading_check': False,                \n                'spelling_check': False,\n                'grammar_check': True,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_train_selected_text_spelling is None:\n    profiled_train_selected_text_spelling = NLPProfiler().apply_text_profiling(\n        training_dataset, 'selected_text', \n        params={'high_level': False,\n                'ease_of_reading_check': False,                \n                'spelling_check': True,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nforce_generate = True\nif (profiled_train_selected_text_granular is None) or force_generate:\n    profiled_train_selected_text_granular = NLPProfiler().apply_text_profiling(\n        training_dataset, 'selected_text', \n        params={'high_level': False,\n                'ease_of_reading_check': False,                \n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': True,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_train_selected_text = pd.concat([training_dataset['selected_text'], profiled_train_selected_text_granular,\n                                          profiled_train_selected_text_sentiment, profiled_train_selected_text_ease_of_reading, \n                                          profiled_train_selected_text_grammar, profiled_train_selected_text_spelling], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_train_selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nsave_to_csv_file(profiled_train_selected_text_sentiment, f'{DATASET_UPLOAD_FOLDER}/profiled_train_selected_text_sentiment.csv', 'selected_text')\nsave_to_csv_file(profiled_train_selected_text_ease_of_reading, f'{DATASET_UPLOAD_FOLDER}/profiled_train_selected_text_ease_of_reading.csv', 'selected_text')\nsave_to_csv_file(profiled_train_selected_text_grammar, f'{DATASET_UPLOAD_FOLDER}/profiled_train_selected_text_grammar_check.csv', 'selected_text')\nsave_to_csv_file(profiled_train_selected_text_spelling, f'{DATASET_UPLOAD_FOLDER}/profiled_train_selected_text_spelling_check.csv', 'selected_text')\nsave_to_csv_file(profiled_train_selected_text_granular, f'{DATASET_UPLOAD_FOLDER}/profiled_train_selected_text_granular_features.csv', 'selected_text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del profiled_train_selected_text_sentiment, profiled_train_selected_text_ease_of_reading, profiled_train_selected_text_grammar\ndel profiled_train_selected_text_spelling, profiled_train_selected_text_granular\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test dataset: text column"},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_test_text_sentiment = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_test_text_sentiment.csv')\nprofiled_test_text_ease_of_reading = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_test_text_ease_of_reading.csv')\nprofiled_test_text_grammar = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_test_text_grammar_check.csv')\nprofiled_test_text_spelling = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_test_text_spelling_check.csv')\nprofiled_test_text_granular = load_csv_if_exists(f'{EXTENDED_DATA_FOLDER}/profiled_test_text_granular_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_test_text_sentiment is None:\n    profiled_test_text_sentiment = NLPProfiler().apply_text_profiling(\n        test_dataset, 'text', \n        params={'high_level': True, # only sentiment analysis will be return\n                'ease_of_reading_check': False,\n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_test_text_ease_of_reading is None:\n    profiled_test_text_ease_of_reading = NLPProfiler().apply_text_profiling(\n        test_dataset, 'text', \n        params={'high_level': False,\n                'ease_of_reading_check': True,\n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_test_text_grammar is None:\n    profiled_test_text_grammar = NLPProfiler().apply_text_profiling(\n        test_dataset, 'text', \n        params={'high_level': False, \n                'ease_of_reading_check': False,                \n                'spelling_check': False,\n                'grammar_check': True,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nif profiled_test_text_spelling is None:\n    profiled_test_text_spelling = NLPProfiler().apply_text_profiling(\n        test_dataset, 'text', \n        params={'high_level': False, \n                'ease_of_reading_check': False,                \n                'spelling_check': True,\n                'grammar_check': False,\n                'granular': False,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nforce_generate = True\nif (profiled_test_text_granular is None) or force_generate:\n    profiled_test_text_granular = NLPProfiler().apply_text_profiling(\n        test_dataset, 'text', \n        params={'high_level': False,\n                'ease_of_reading_check': False,                \n                'spelling_check': False,\n                'grammar_check': False,\n                'granular': True,                 \n                'parallelisation_method': 'using_swifter'}\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_test_text = pd.concat([test_dataset['text'], profiled_test_text_granular, profiled_test_text_sentiment, \n                                profiled_test_text_ease_of_reading, profiled_test_text_grammar, profiled_test_text_spelling], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"profiled_test_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"save_to_csv_file(profiled_test_text_sentiment, f'{DATASET_UPLOAD_FOLDER}/profiled_test_text_sentiment.csv')\nsave_to_csv_file(profiled_test_text_ease_of_reading, f'{DATASET_UPLOAD_FOLDER}/profiled_test_text_ease_of_reading.csv')\nsave_to_csv_file(profiled_test_text_grammar, f'{DATASET_UPLOAD_FOLDER}/profiled_test_text_grammar_check.csv')\nsave_to_csv_file(profiled_test_text_spelling, f'{DATASET_UPLOAD_FOLDER}/profiled_test_text_spelling_check.csv')\nsave_to_csv_file(profiled_test_text_granular, f'{DATASET_UPLOAD_FOLDER}/profiled_test_text_granular_features.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del profiled_test_text_sentiment, profiled_test_text_ease_of_reading, profiled_test_text_grammar\ndel profiled_test_text_spelling, profiled_test_text_granular\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Uploading newly created/updated csv to your Kaggle Dataset\n\nSetup your local environment with your Kaggle login details (`KAGGLE_KEY` and `KAGGLE_USERNAME`)."},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\n\nimport os\nos.environ['KAGGLE_KEY'] = user_secrets.get_secret(\"KAGGLE_KEY\")\nos.environ['KAGGLE_USERNAME'] = user_secrets.get_secret(\"KAGGLE_USERNAME\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using the kaggle Python client login, into your account from within the kernel."},{"metadata":{"trusted":true},"cell_type":"code","source":"import kaggle\nkaggle.api.authenticate()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Get the metadata for the dataset you have already created manually - it's best to manually create it and upload the initial csv file(s) into it, to avoid subsequent issues with updating the dataset (as seen during my own end-to-end cycle).\n\nSave the metadata file as a json file but before that, add/update two keys id and id_no with the respective details as shown below and then save it."},{"metadata":{"trusted":true},"cell_type":"code","source":"OWNER_SLUG='neomatrix369'\nDATASET_SLUG='tweet-sentiment-extraction-extended'\ndataset_metadata = kaggle.api.metadata_get(OWNER_SLUG, DATASET_SLUG)\ndataset_metadata['id'] = dataset_metadata[\"ownerUser\"] + \"/\" + dataset_metadata['datasetSlug']\ndataset_metadata['id_no'] = dataset_metadata['datasetId']\nimport json\nwith open(f'{DATASET_UPLOAD_FOLDER}/dataset-metadata.json', 'w') as file:\n    json.dump(dataset_metadata, file, indent=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally call the dataset_create_version() api and pass it the folder where the metadata file exists and also where your .csv and .fth file(s) - those file(s) that you would like to upload into your existing Dataset (as a new version)."},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# !kaggle datasets version -m \"Updating datasets\" -p /kaggle/working/upload\nkaggle.api.dataset_create_version(DATASET_UPLOAD_FOLDER, 'Updating datasets')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Prequels/sequels\n\n- **FastChai sessions: Tweet Sentiment Extraction (data-prep) | [Extended Dataset](https://www.kaggle.com/neomatrix369/tweet-sentiment-extraction-extended)**\n- [FastChai sessions: Tweet Sentiment Extraction (analysis)](https://www.kaggle.com/neomatrix369/fastchai-tweet-sentiment-extraction-analysis/)"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}