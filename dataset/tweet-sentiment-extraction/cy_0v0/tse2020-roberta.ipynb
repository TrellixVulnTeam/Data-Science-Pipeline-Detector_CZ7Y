{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import libraries <a class=\"anchor\" id=\"1\"></a>\n\n[Back to Table of Contents](#0.1)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.patches as mpatches\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.express as px\nimport seaborn as sns; sns.set(style='white')\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfrom wordcloud import WordCloud\nfrom sklearn.decomposition import PCA, TruncatedSVD\nimport math\nimport pickle\n\nfrom scipy.cluster import hierarchy\nfrom scipy.spatial.distance import pdist\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\n\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom transformers import *\nimport tokenizers\nfrom sklearn.model_selection import StratifiedKFold\n\npd.set_option('max_colwidth', 40)","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-07-10T13:33:09.3804Z","iopub.execute_input":"2021-07-10T13:33:09.380773Z","iopub.status.idle":"2021-07-10T13:33:17.245689Z","shell.execute_reply.started":"2021-07-10T13:33:09.380731Z","shell.execute_reply":"2021-07-10T13:33:17.244532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Download data & FE ","metadata":{}},{"cell_type":"code","source":"MAX_LEN = 96\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab_file=PATH+'vocab-roberta-base.json', \n    merges_file=PATH+'merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True\n)\nEPOCHS = 3 # originally 3\nBATCH_SIZE = 32 # originally 32\nPAD_ID = 1\nSEED = 88888\nLABEL_SMOOTHING = 0.1\ntf.random.set_seed(SEED)\nnp.random.seed(SEED)\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T13:33:17.248007Z","iopub.execute_input":"2021-07-10T13:33:17.248634Z","iopub.status.idle":"2021-07-10T13:33:17.495485Z","shell.execute_reply.started":"2021-07-10T13:33:17.248569Z","shell.execute_reply":"2021-07-10T13:33:17.494648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv').fillna('')\n\nct = test.shape[0]\ninput_ids_t = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask_t = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids_t = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(test.shape[0]):\n        \n    # INPUT_IDS\n    text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n    enc = tokenizer.encode(text1)                \n    s_tok = sentiment_id[test.loc[k,'sentiment']]\n    input_ids_t[k,:len(enc.ids)+3] = [0, s_tok] + enc.ids + [2]\n    attention_mask_t[k,:len(enc.ids)+3] = 1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-10T13:33:17.496744Z","iopub.execute_input":"2021-07-10T13:33:17.497083Z","iopub.status.idle":"2021-07-10T13:33:18.116857Z","shell.execute_reply.started":"2021-07-10T13:33:17.497056Z","shell.execute_reply":"2021-07-10T13:33:18.115863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Model tuning","metadata":{}},{"cell_type":"markdown","source":"## 3.1. My upgrade of parameters","metadata":{}},{"cell_type":"code","source":"Dropout_new = 0.15     # originally 0.1\nn_split = 5            # originally 5\nlr = 3e-5              # originally 3e-5","metadata":{"execution":{"iopub.status.busy":"2021-07-10T13:33:18.118247Z","iopub.execute_input":"2021-07-10T13:33:18.118623Z","iopub.status.idle":"2021-07-10T13:33:18.123089Z","shell.execute_reply.started":"2021-07-10T13:33:18.118585Z","shell.execute_reply":"2021-07-10T13:33:18.122286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3.2. Model training","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef save_weights(model, dst_fn):\n    weights = model.get_weights()\n    with open(dst_fn, 'wb') as f:\n        pickle.dump(weights, f)\n\n\ndef load_weights(model, weight_fn):\n    with open(weight_fn, 'rb') as f:\n        weights = pickle.load(f)\n    model.set_weights(weights)\n    return model\n\ndef loss_fn(y_true, y_pred):\n    # adjust the targets for sequence bucketing\n    ll = tf.shape(y_pred)[1]\n    y_true = y_true[:, :ll]\n    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred,\n        from_logits=False, label_smoothing=LABEL_SMOOTHING)\n    loss = tf.reduce_mean(loss)\n    return loss\n\n\ndef build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    padding = tf.cast(tf.equal(ids, PAD_ID), tf.int32)\n\n    lens = MAX_LEN - tf.reduce_sum(padding, -1)\n    max_len = tf.reduce_max(lens)\n    ids_ = ids[:, :max_len]\n    att_ = att[:, :max_len]\n    tok_ = tok[:, :max_len]\n\n    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n    x = bert_model(ids_,attention_mask=att_,token_type_ids=tok_)\n    \n    x1 = tf.keras.layers.Dropout(Dropout_new)(x[0])\n    x1 = tf.keras.layers.Conv1D(768, 2,padding='same')(x1)\n    x1 = tf.keras.layers.LeakyReLU()(x1)\n    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n    x1 = tf.keras.layers.Dense(1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(Dropout_new)(x[0]) \n    x2 = tf.keras.layers.Conv1D(768, 2,padding='same')(x2)\n    x2 = tf.keras.layers.LeakyReLU()(x2)\n    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n    x2 = tf.keras.layers.Dense(1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=lr) \n    model.compile(loss=loss_fn, optimizer=optimizer)\n    \n    # this is required as `model.predict` needs a fixed size!\n    x1_padded = tf.pad(x1, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n    x2_padded = tf.pad(x2, [[0, 0], [0, MAX_LEN - max_len]], constant_values=0.)\n    \n    padded_model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1_padded,x2_padded])\n    return model, padded_model","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-10T13:33:18.125851Z","iopub.execute_input":"2021-07-10T13:33:18.126493Z","iopub.status.idle":"2021-07-10T13:33:18.15237Z","shell.execute_reply.started":"2021-07-10T13:33:18.126453Z","shell.execute_reply":"2021-07-10T13:33:18.15132Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a)==0) & (len(b)==0): return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-10T13:33:18.153721Z","iopub.execute_input":"2021-07-10T13:33:18.154069Z","iopub.status.idle":"2021-07-10T13:33:18.163384Z","shell.execute_reply.started":"2021-07-10T13:33:18.154033Z","shell.execute_reply":"2021-07-10T13:33:18.162688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ct = train.shape[0]\ninput_ids = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\nstart_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\nend_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n\nfor k in range(train.shape[0]):\n    \n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n    text2 = \" \".join(train.loc[k,'selected_text'].split())\n    idx = text1.find(text2)\n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)]=1\n    if text1[idx-1]==' ': chars[idx-1] = 1 \n    enc = tokenizer.encode(text1) \n        \n    # ID_OFFSETS\n    offsets = []; idx=0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx,idx+len(w)))\n        idx += len(w)\n    \n    # START END TOKENS\n    toks = []\n    for i,(a,b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm>0: toks.append(i) \n        \n    s_tok = sentiment_id[train.loc[k,'sentiment']]\n    input_ids[k,:len(enc.ids)+3] = [0, s_tok] + enc.ids + [2]\n    attention_mask[k,:len(enc.ids)+3] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+2] = 1\n        end_tokens[k,toks[-1]+2] = 1","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-10T13:33:18.165974Z","iopub.execute_input":"2021-07-10T13:33:18.16621Z","iopub.status.idle":"2021-07-10T13:33:31.35696Z","shell.execute_reply.started":"2021-07-10T13:33:18.166188Z","shell.execute_reply":"2021-07-10T13:33:31.355998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\njac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\noof_start = np.zeros((input_ids.shape[0],MAX_LEN))\noof_end = np.zeros((input_ids.shape[0],MAX_LEN))\npreds_start_train = np.zeros((input_ids.shape[0],MAX_LEN))\npreds_end_train = np.zeros((input_ids.shape[0],MAX_LEN))\npreds_start = np.zeros((input_ids_t.shape[0],MAX_LEN))\npreds_end = np.zeros((input_ids_t.shape[0],MAX_LEN))\n\nskf = StratifiedKFold(n_splits=n_split,shuffle=True,random_state=SEED)\nfor fold,(idxT,idxV) in enumerate(skf.split(input_ids,train.sentiment.values)):\n\n    print('#'*25)\n    print('### FOLD %i'%(fold+1))\n    print('#'*25)\n    \n    K.clear_session()\n    model, padded_model = build_model()\n        \n    #sv = tf.keras.callbacks.ModelCheckpoint(\n    #    '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n    #    save_weights_only=True, mode='auto', save_freq='epoch')\n    inpT = [input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]]\n    targetT = [start_tokens[idxT,], end_tokens[idxT,]]\n    inpV = [input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]]\n    targetV = [start_tokens[idxV,], end_tokens[idxV,]]\n    # sort the validation data\n    shuffleV = np.int32(sorted(range(len(inpV[0])), key=lambda k: (inpV[0][k] == PAD_ID).sum(), reverse=True))\n    inpV = [arr[shuffleV] for arr in inpV]\n    targetV = [arr[shuffleV] for arr in targetV]\n    #weight_fn = '%s-roberta-%i.h5'%(VER,fold)\n    for epoch in range(1, EPOCHS + 1):\n        # sort and shuffle: We add random numbers to not have the same order in each epoch\n        shuffleT = np.int32(sorted(range(len(inpT[0])), key=lambda k: (inpT[0][k] == PAD_ID).sum() + np.random.randint(-3, 3), reverse=True))\n        # shuffle in batches, otherwise short batches will always come in the beginning of each epoch\n        num_batches = math.ceil(len(shuffleT) / BATCH_SIZE)\n        batch_inds = np.random.permutation(num_batches)\n        shuffleT_ = []\n        for batch_ind in batch_inds:\n            shuffleT_.append(shuffleT[batch_ind * BATCH_SIZE: (batch_ind + 1) * BATCH_SIZE])\n        shuffleT = np.concatenate(shuffleT_)\n        # reorder the input data\n        inpT = [arr[shuffleT] for arr in inpT]\n        targetT = [arr[shuffleT] for arr in targetT]\n        model.fit(inpT, targetT, \n            epochs=epoch, initial_epoch=epoch - 1, batch_size=BATCH_SIZE, verbose=DISPLAY, callbacks=[],\n            validation_data=(inpV, targetV), shuffle=False)  # don't shuffle in `fit`\n        #save_weights(model, weight_fn)\n\n    #print('Loading model...')\n    # model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n    #load_weights(model, weight_fn)\n\n    print('Predicting OOF...')\n    oof_start[idxV,],oof_end[idxV,] = padded_model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n    \n    print('Predicting all Train for Outlier analysis...')\n    preds_train = padded_model.predict([input_ids,attention_mask,token_type_ids],verbose=DISPLAY)\n    preds_start_train += preds_train[0]/skf.n_splits\n    preds_end_train += preds_train[1]/skf.n_splits\n\n    print('Predicting Test...')\n    preds = padded_model.predict([input_ids_t,attention_mask_t,token_type_ids_t],verbose=DISPLAY)\n    preds_start += preds[0]/skf.n_splits\n    preds_end += preds[1]/skf.n_splits\n    \n    # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k,])\n        b = np.argmax(oof_end[k,])\n        if a>b: \n            st = train.loc[k,'text'] # IMPROVE CV/LB with better choice here\n        else:\n            text1 = \" \"+\" \".join(train.loc[k,'text'].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-2:b-1])\n        all.append(jaccard(st,train.loc[k,'selected_text']))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n    print()","metadata":{"execution":{"iopub.status.busy":"2021-07-10T13:33:31.358271Z","iopub.execute_input":"2021-07-10T13:33:31.358637Z","iopub.status.idle":"2021-07-10T14:10:11.202201Z","shell.execute_reply.started":"2021-07-10T13:33:31.358602Z","shell.execute_reply":"2021-07-10T14:10:11.201307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('>>>> OVERALL 5Fold CV Jaccard =',np.mean(jac))\nprint(jac) # Jaccard CVs","metadata":{"execution":{"iopub.status.busy":"2021-07-10T14:10:11.203604Z","iopub.execute_input":"2021-07-10T14:10:11.203952Z","iopub.status.idle":"2021-07-10T14:10:11.209555Z","shell.execute_reply.started":"2021-07-10T14:10:11.203924Z","shell.execute_reply":"2021-07-10T14:10:11.208484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 4. Submission ","metadata":{}},{"cell_type":"code","source":"all = []\nfor k in range(input_ids_t.shape[0]):\n    a = np.argmax(preds_start[k,])\n    b = np.argmax(preds_end[k,])\n    if a>b: \n        st = test.loc[k,'text']\n    else:\n        text1 = \" \"+\" \".join(test.loc[k,'text'].split())\n        enc = tokenizer.encode(text1)\n        st = tokenizer.decode(enc.ids[a-2:b-1])\n    all.append(st)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-07-10T14:10:11.210966Z","iopub.execute_input":"2021-07-10T14:10:11.211648Z","iopub.status.idle":"2021-07-10T14:10:11.711324Z","shell.execute_reply.started":"2021-07-10T14:10:11.211611Z","shell.execute_reply":"2021-07-10T14:10:11.710592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['selected_text'] = all\ntest[['textID','selected_text']].to_csv('submission.csv',index=False)\ntest.sample(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-10T14:10:11.713478Z","iopub.execute_input":"2021-07-10T14:10:11.714087Z","iopub.status.idle":"2021-07-10T14:10:11.927658Z","shell.execute_reply.started":"2021-07-10T14:10:11.714047Z","shell.execute_reply":"2021-07-10T14:10:11.926926Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"[Go to Top](#0)","metadata":{}}]}