{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nimport time\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nfrom decimal import *\nfrom nltk.stem.porter import PorterStemmer\nimport re\nfrom stop_words import get_stop_words\nimport itertools\nimport numpy as np\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainData = pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\ntrainData.sample(6)\ntestData=pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ntestData.sample(6)\nsub=pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def del_miss_val(df):\n    total=df.isnull().sum()\n    return pd.concat([total],axis=1,keys=['Total'])\nprint(\"Missing values for train dataset \\n\")\nprint(del_miss_val(trainData))\ntrainData=trainData.dropna()\nprint(len(trainData[\"sentiment\"]))\nprint(len(trainData[\"text\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_punct(text):\n    line = re.sub(r'[!\"\\$%&\\'()*+,\\-.\\/:;=#@?\\[\\\\\\]^_`{|}~]+',\" \",text)\n    return \" \".join(line.split())\nv=remove_punct('Sons of ****, why couldn`t they put them on t...')\nv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def delete_link(string): \n    url = re.sub('http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+','', string)\n    return \"\".join(url) \ntest=delete_link('last session of the day http://twitpic.com/67ezh')\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train= [delete_link(str(text)) for text in trainData['text']]\n# train = pd.DataFrame(train)\n# train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train= [remove_punct(str(text)) for text in train]\ntrain = pd.DataFrame(train)\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test= [delete_link(text) for text in testData['text']]\ntestData['text']= [remove_punct(str(text)) for text in test]\ntestData['text'] = pd.DataFrame(testData['text'])\ntestData['text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stpwd(text,langue='en'):\n    text=text.split()\n    stop_words = get_stop_words(langue)\n    text=' '.join([token for token in text if token not in stop_words and len(token)>1])\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x=remove_stpwd('Shanghai is also really exciting precisely sky')\nx","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"porter_stemmer=PorterStemmer()\nwords=testData['text']\nwords = [porter_stemmer.stem(word) for word in words]\n\nwords=[remove_stpwd(word) for word in words]\n# test['selected_text'] = stemming_tokenizer()\n# submission=testData[['textID','selected_text']]\n# submission.to_csv('submission.csv',index=False)\n# submission.head(5)\nwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testData['selected_text'] = words\nsubmission=testData[['textID','selected_text']]\nsubmission.to_csv('submission.csv',index=False)\nsubmission.head(5)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}