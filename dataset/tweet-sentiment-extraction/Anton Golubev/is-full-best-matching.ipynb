{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import gc\nimport os\nos.chdir(\"..\")\nos.chdir('input')\nos.chdir('mypractices')\nos.chdir('TwitterSentimentExtraction')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport shutil\nimport shutil\nfrom eda import *\nfrom csv2json import *","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\ntest_data = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\nted_data_for_second = test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocessing for the 1st model\ntest_data = prepare_data_for_first_model(test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating sample сsv2json\ncreate_samples('/kaggle/working', test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generating dataset for 1st model predictions\nowd = os.getcwd()\nos.chdir('generate')\n!python generate_rambler2011_json_NLI_M_first_model.py\nos.chdir(owd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 1st model predictions\nif os.path.exists('/kaggle/working/results'):\n        shutil.rmtree('/kaggle/working/results')\n\n!python run_classifier_TABSA_pretrained.py \\\n--task_name rambler2011_json_NLI_M \\\n--data_dir /kaggle/working/ \\\n--vocab_file '/kaggle/input/mypractices/TwitterSentimentExtraction/conversational_cased_L-12_H-768_A-12_v1/vocab.txt' \\\n--bert_config_file '/kaggle/input/mypractices/TwitterSentimentExtraction/conversational_cased_L-12_H-768_A-12_v1/bert_config.json' \\\n--init_checkpoint '/kaggle/input/mypractices/TwitterSentimentExtraction/conversational_cased_L-12_H-768_A-12_v1/pytorch_model.bin' \\\n--eval_test \\\n--do_lower_case \\\n--max_seq_length 512 \\\n--train_batch_size 8 \\\n--learning_rate 2e-5 \\\n--num_train_epochs 2.0 \\\n--output_dir /kaggle/working/results/ \\\n--seed 42 \\\n--model_number first_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# results of first task to submission file (0 means marker=text)\ndata_first_model = pd.read_csv('/kaggle/working/test_NLI_M.tsv', sep='\\t')\nresults_first_model = []\nwith open('/kaggle/working/results/results.txt') as f:\n    for line in f:\n        results_first_model.append(int(line.split()[0]))\ndata_first_model['answer'] = results_first_model\ndata_first_model['sentence1'] = data_first_model['sentence1'].apply(lambda x: x[15:])\ntest_data['text_tok'] = test_data['text_tok'].apply(lambda x: x[12:])\n\ntest_data = test_data.set_index('selected_text_tok').join(data_first_model.set_index('tonal_word'))[\n    ['textID', 'text', 'text_tok', 'answer']]\ntest_data['answer'] = test_data.apply(lambda row: row['text'] if row['answer'] == 0 else 'ask 2nd model', axis=1)\nfor_2nd_model = test_data[test_data['answer'] == 'ask 2nd model']['textID']\n\nsample_submission = sample_submission.set_index('textID').join(test_data.set_index('textID'))[\n    ['answer']].reset_index()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preprocessing for 2nd model\ntest_data = ted_data_for_second[ted_data_for_second['textID'].isin(for_2nd_model)]\ntest_data = prepare_data_for_second_model(test_data, 3)\ntest_data.to_csv('/kaggle/working/test_data_for_2nd_model.csv', index=False, sep='\\t')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating sample сsv2json\ncreate_samples_2nd_model('raw_data', test_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# generating dataset for 2nd model predictions\nos.chdir('generate')\n!python generate_rambler2011_json_NLI_M_second_model.py\nos.chdir(owd)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 2nd model predictions\nif os.path.exists('/kaggle/working/results'):\n\tshutil.rmtree('/kaggle/working/results')\n\n!python run_classifier_TABSA_pretrained.py \\\n--task_name rambler2011_json_NLI_M \\\n--data_dir /kaggle/working/ \\\n--vocab_file '/kaggle/input/mypractices/TwitterSentimentExtraction/conversational_cased_L-12_H-768_A-12_v1/vocab.txt' \\\n--bert_config_file '/kaggle/input/mypractices/TwitterSentimentExtraction/conversational_cased_L-12_H-768_A-12_v1/bert_config.json' \\\n--init_checkpoint '/kaggle/input/mypractices/TwitterSentimentExtraction/conversational_cased_L-12_H-768_A-12_v1/pytorch_model.bin' \\\n--eval_test \\\n--do_lower_case \\\n--max_seq_length 512 \\\n--train_batch_size 8 \\\n--learning_rate 2e-5 \\\n--num_train_epochs 2.0 \\\n--output_dir /kaggle/working/results/ \\\n--seed 42 \\\n--model_number second_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#  results of second task to submission file + extract best marker for each sentence\ndata_second_model = pd.read_csv('/kaggle/working/test_NLI_M.tsv', sep='\\t')\nanswer_second_model = []\nlogit_zero = []\nlogit_one = []\n\n# with open('results/rambler2011_json/NLI_M/results_second.txt') as f:\nwith open('/kaggle/working/results/results.txt') as f:\n    for line in f:\n        answer_second_model.append(int(line.split()[0]))\n        logit_zero.append(float(line.split()[1]))\n        logit_one.append(float(line.split()[2]))\n        \ndata_second_model['answer'] = answer_second_model\ndata_second_model['logit_zero'] = logit_zero\ndata_second_model['logit_one'] = logit_one\ndata_second_model['best'] = data_second_model.groupby(['id'])['logit_one'].rank(method='first', ascending=True)\nans = data_second_model[data_second_model['best'] == 1][['id', 'sentence2']]\nans['sentence2'] = ans['sentence2'].apply(lambda x: x[25:])\nans.rename(columns={\"id\": \"textID\", \"sentence2\": \"selected_text\"}, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.rename(columns={\"textID\": \"textID\", \"answer\": \"selected_text\"}, inplace=True)\nsample_submission.set_index('textID', inplace=True)\nsample_submission.update(ans.set_index('textID'))\nsample_submission = sample_submission.reset_index()\nsample_submission.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}