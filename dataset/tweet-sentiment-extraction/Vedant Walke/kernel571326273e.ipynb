{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"## Import all libraries\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Dense,Input,Embedding\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.models import load_model\nimport keras.backend as K\nfrom transformers import *\nimport tokenizers\nfrom tokenizers import ByteLevelBPETokenizer\nimport os\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.preprocessing import LabelEncoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Importing the dataset.\ntrain = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv', keep_default_na=False)\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv', keep_default_na=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Config\nMax_length = 120","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"##All functions \n## function returning overlap between two id vectors\ndef list_in(a, b):\n  y_seq = np.zeros((len(b)),dtype='int32')\n  for i in range(0,len(b) - len(a) + 1):\n    if b[i:i + len(a)] == a:\n      y_seq[i:i+len(a)] = 1\n      if b[i-1] == \" \":\n        y_seq[i-1] = 1\n      break\n  return y_seq\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a)==0) & (len(b)==0): return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Making Dataset for training on complete dataset(preprocessing for roberta)\n## Defining the tokenizer.\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab_file = \"/kaggle/input/roberta-base/vocab-roberta-base.json\" ,\n    merges_file = \"/kaggle/input/roberta-base/merges-roberta-base.txt\",\n    lowercase=True,\n    add_prefix_space=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Max_length = 120\nobs = train.shape[0]\ninput_tokens = np.ones((obs,Max_length),dtype='int32')\nmask = np.zeros((obs,Max_length),dtype='int32')\nseg = np.zeros((obs,Max_length),dtype='int32')\nst_vec = np.zeros((obs,Max_length),dtype='int32')\nend_vec = np.zeros((obs,Max_length),dtype='int32') \n\nfor i in range(0,obs):\n  ## Overlap character-wise.\n  overlap_char = list_in(\" \".join(train.selected_text.values[i].split()),\" \"+\" \".join(train.text.values[i].split()))\n\n  ## Encoding the tweet\n  tweet_ex = tokenizer.encode(\" \"+\" \".join(train.text.values[i].split()))\n\n  ## Tweet ids \n  tweet_ex_ids = tweet_ex.ids\n  input_tokens[i,0:len(tweet_ex_ids)+5] = [0]+tweet_ex_ids+[2,2]+tokenizer.encode(train.sentiment.values[i]).ids + [2]\n  mask[i,0:len(tweet_ex_ids)+5] = 1\n    \n  ## Tweet Offsets\n  tweet_ex_off = tweet_ex.offsets\n\n  ## Encoding selected part of tweet \n  selected_text_tweet = tokenizer.encode(\" \"+\" \".join(train.selected_text.values[i].split()))\n\n  tokens = []\n  for j,(a,b) in enumerate(tweet_ex_off):\n    if sum( overlap_char[a:b] ) > 0:\n      tokens.append(j)\n\n  ## Start Vector and End Vector\n  if len(tokens)>0:\n    st_vec[i,tokens[0]+1] = 1\n    end_vec[i,tokens[-1]+1] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"obs1 = test.shape[0]\ninput_tokens_test = np.ones((obs1,Max_length),dtype='int32')\nmask_test = np.zeros((obs1,Max_length),dtype='int32')\nseg_test = np.zeros((obs1,Max_length),dtype='int32')\n\nfor i in range(0,obs1):\n  ## Encoding the tweet\n  tweet_ex_test = tokenizer.encode(\" \"+\" \".join(test.text.values[i].split()))\n\n  ## Tweet ids \n  tweet_ex_ids_test = tweet_ex_test.ids\n  input_tokens_test[i,0:len(tweet_ex_ids_test)+5] = [0]+tweet_ex_ids_test+[2,2]+tokenizer.encode(test.sentiment.values[i]).ids + [2]\n  mask_test[i,0:len(tweet_ex_ids_test)+5] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Model Building(MODEL_1)(Sentiment used in tokens)\ndef Create_Model():\n  token_inputs = Input((Max_length,), dtype=tf.int32, name='token_inputs')\n  mask_inputs = Input((Max_length,), dtype=tf.int32, name='mask_inputs')\n  seg_inputs = Input((Max_length,), dtype=tf.int32, name='seg_inputs')\n  # sentiment_input = Input((Max_length,2,),dtype=tf.float32,name='sentiment_inputs')\n\n  config = BertConfig.from_pretrained(\"/kaggle/input/roberta-base/config-roberta-base.json\") \n  model = TFRobertaModel.from_pretrained(\"/kaggle/input/roberta-base/pretrained-roberta-base.h5\",config=config )\n\n  pool_output,seq_out = model([token_inputs, mask_inputs, seg_inputs])\n  # x1 = tf.keras.layers.concatenate([pool_output,sentiment_input])\n  x1 = tf.keras.layers.Dropout(0.1)(pool_output) \n  x1 = tf.keras.layers.Conv1D(128, 2,padding='same')(x1)\n  x1 = tf.keras.layers.LeakyReLU()(x1)\n  x1 = tf.keras.layers.Conv1D(64,2,padding='same')(x1)\n  x1 = tf.keras.layers.Dense(1)(x1)\n  x1 = tf.keras.layers.Flatten()(x1)\n  x1 = tf.keras.layers.Activation('softmax')(x1)\n\n  # x2 = tf.keras.layers.concatenate([pool_output,sentiment_input])\n  x2 = tf.keras.layers.Dropout(0.1)(pool_output) \n  x2 = tf.keras.layers.Conv1D(128, 2, padding='same',activation='relu')(x2)\n  x2 = tf.keras.layers.LeakyReLU(0.1)(x2) \n  x2 = tf.keras.layers.Conv1D(64,2,padding='same',activation='relu')(x2)\n  x2 = tf.keras.layers.Dense(1)(x2)\n  x2 = tf.keras.layers.Flatten()(x2)\n  x2 = tf.keras.layers.Activation('softmax')(x2)\n\n  bert_model1 = Model([token_inputs, mask_inputs, seg_inputs],[x1,x2])\n  return bert_model1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_fn(tokens,mask,seg,start_vec,end_vec,sentiment,tokens_test,mask_test,seg_test,start_vec_test,end_vec_test,sentiment_test,fold): \n    # tokens_tr = []\n    # mask_tr = []\n    # seg_tr = []\n    # start_vec_tr = []\n    # end_vec_tr = []\n    # sentiment_tr = []\n    # for i in range(0,len(tokens)):\n    #   #if sentiment.iloc[i] != \"neutral\":\n    #   if sentiment[i] != \"neutral\":\n    #     tokens_tr.append(tokens[i])\n    #     mask_tr.append(mask[i]) \n    #     seg_tr.append(seg[i])\n    #     start_vec_tr.append(start_vec[i])\n    #     end_vec_tr.append(end_vec[i])\n    # tokens_tr = np.asarray(tokens_tr, dtype=np.int32) \n    # mask_tr = np.asarray(mask_tr, dtype=np.int32) \n    # seg_tr = np.asarray(seg_tr, dtype=np.int32) \n    # start_vec_tr = np.asarray(start_vec_tr, dtype=np.int32) \n    # end_vec_tr = np.asarray(end_vec_tr, dtype=np.int32) \n\n    # tokens_tst = []\n    # mask_tst = []\n    # seg_tst = []\n    # start_vec_tst = []\n    # end_vec_tst = []\n    # for i in range(0,len(tokens_test)):\n    #   if sentiment_test[i] != \"neutral\":\n    #     tokens_tst.append(tokens[i])\n    #     mask_tst.append(mask[i]) \n    #     seg_tst.append(seg[i])\n    #     start_vec_tst.append(start_vec[i])\n    #     end_vec_tst.append(end_vec[i])\n    # tokens_tst = np.asarray(tokens_tst, dtype=np.int32) \n    # mask_tst = np.asarray(mask_tst, dtype=np.int32) \n    # seg_tst = np.asarray(seg_tst, dtype=np.int32) \n    # start_vec_tst = np.asarray(start_vec_tst, dtype=np.int32) \n    # end_vec_tst = np.asarray(end_vec_tst, dtype=np.int32) \n\n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n\n    if fold > 0:\n      tf.tpu.experimental.initialize_tpu_system(resolver)\n\n    with strategy.scope():\n      bert_model1 = Create_Model()\n      #bert_model2.compile(optimizer=optimizer,loss = \"binary_crossentropy\")\n      bert_model1.compile(optimizer=optimizer,loss = \"binary_crossentropy\")\n    \n    # bert_model1 = Create_Model()\n    # #bert_model2.compile(optimizer=optimizer,loss = \"binary_crossentropy\")\n    # bert_model1.compile(optimizer=optimizer,loss = \"binary_crossentropy\")\n\n    def scheduler(epoch):\n      return 3e-5 * 0.2**epoch\n    DISPLAY = 1\n    # K.clear_session()\n    reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\n    # bert_model2.fit([tokens_tr,mask_tr,seg_tr,sentiment_tr],[start_vec_tr,end_vec_tr],epochs=5,batch_size =8,verbose=DISPLAY,callbacks=[reduce_lr,cp_callback])\n  #For Roberta Model\n    bert_model1.fit([tokens,mask,seg],[start_vec,end_vec],epochs=5,batch_size =32,verbose=DISPLAY,callbacks=[reduce_lr,cp_callback],\n                      validation_data = ([tokens_test,mask_test,seg_test],[start_vec_test,end_vec_test]))\n    return bert_model1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## When submitting on kaggle\ndef prediction_fn(tokens_test,mask_test,seg_test,sentiment,text):\n  tokens_tst = []\n  mask_tst = []\n  seg_tst = []\n  txt = []\n  for i in range(0,len(tokens_test)):\n    if sentiment[i] != \"neutral\":\n      tokens_tst.append(tokens_test[i])\n      mask_tst.append(mask_test[i]) \n      seg_tst.append(seg_test[i])\n      txt.append(text[i])\n  tokens_tst = np.asarray(tokens_tst, dtype=np.int32) \n  mask_tst = np.asarray(mask_tst, dtype=np.int32) \n  seg_tst = np.asarray(seg_tst, dtype=np.int32)  \n\n  #prediction = bert_model2.predict([tokens_tst,mask_tst,seg_tst,sentiment_tr],verbose=1)\n  prediction = bert_model1.predict([tokens_tst,mask_tst,seg_tst],verbose=1)\n\n  prediction1 =[]\n  for i in range(0,len(prediction[0])):\n    a = np.argmax(prediction[0][i])\n    b = np.argmax(prediction[1][i])\n    if b>=a:\n      #predict1 = tokenizer.decode(tokens_tst[i][a:b+1])\n      text1 = \" \"+\" \".join(txt[i].split())\n      enc = tokenizer.encode(text1)\n      predict1 = tokenizer.decode(enc.ids[a-1:b])\n    else:\n      predict1 = txt[i]\n    prediction1.append(predict1)\n  return {'prediction_string':prediction1,\n          'prediction':prediction} ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def evaluation(prediction_string,test_text,sentiment,text):\n  flag = 0\n  total_prediction_string = []\n  for i in range(0,len(test_text)):\n    if sentiment[i] == 'neutral':\n      total_prediction_string.append(text[i])\n      # print(i,test_text[i])\n    if sentiment[i] != 'neutral':\n      total_prediction_string.append(prediction_string[flag])\n      # print(i,prediction_string[flag])\n      flag+=1\n  jaccard_metric = []\n  for i in range(0,len(total_prediction_string)):\n    jaccard_metric.append(jaccard(total_prediction_string[i],test_text[i]))\n  return sum(jaccard_metric)/len(jaccard_metric)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"models_path = '/kaggle/input/roberta-model-v16/'\nlength = len(test[test.sentiment!='neutral'].sentiment)\npred0 = np.zeros((length,Max_length))\npred1 = np.zeros((length,Max_length))\nfor i in range(0,5):\n  bert_model1 = Create_Model()\n  print('loading model weights')\n  bert_model1.load_weights(models_path + 'v16-roberta-%i.h5'%(i))\n  print('making predictions')\n  predictions = prediction_fn(input_tokens_test,mask_test,seg_test,test.sentiment.values,test.text.values)[\"prediction\"]\n  prediction_string = prediction_fn(input_tokens_test,mask_test,seg_test,test.sentiment.values,test.text.values)[\"prediction_string\"]\n  pred0 += predictions[0]/5\n  pred1 += predictions[1]/5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction1 = []\n## converting predictions to binary form.\nflag = 0\nfor i in range(0,len(test.text)):\n  if test.sentiment.values[i] != 'neutral':\n    a = np.argmax(pred0[flag])\n    b = np.argmax(pred1[flag])\n    flag += 1\n    if b>=a:\n      predict1 = tokenizer.decode(input_tokens_test[i][a:b+1])\n    else:\n      predict1 = test.text[i]\n    prediction1.append(predict1)\n  if test.sentiment.values[i] == 'neutral':\n    prediction1.append(test.text.iloc[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.selected_text = prediction1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}