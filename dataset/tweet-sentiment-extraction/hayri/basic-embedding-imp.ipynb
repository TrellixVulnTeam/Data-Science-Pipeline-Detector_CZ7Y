{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!ls /kaggle/input/tweet-sentiment-extraction\ninput_dir = '/kaggle/input/tweet-sentiment-extraction'","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-11T14:00:28.06498Z","iopub.execute_input":"2022-01-11T14:00:28.065496Z","iopub.status.idle":"2022-01-11T14:00:28.858772Z","shell.execute_reply.started":"2022-01-11T14:00:28.065392Z","shell.execute_reply":"2022-01-11T14:00:28.857647Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport pandas as pd\nimport numpy as np\nimport os","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:00:30.768187Z","iopub.execute_input":"2022-01-11T14:00:30.768473Z","iopub.status.idle":"2022-01-11T14:00:35.831017Z","shell.execute_reply.started":"2022-01-11T14:00:30.768441Z","shell.execute_reply":"2022-01-11T14:00:35.830213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_csv = pd.read_csv(os.path.join(input_dir, 'train.csv'))\ntrain_csv.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:00:35.832478Z","iopub.execute_input":"2022-01-11T14:00:35.832704Z","iopub.status.idle":"2022-01-11T14:00:36.02226Z","shell.execute_reply.started":"2022-01-11T14:00:35.832676Z","shell.execute_reply":"2022-01-11T14:00:36.021456Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"texts = train_csv['text'].values.astype(np.str)\nstr_labels = train_csv['sentiment'].values\n\ntexts, str_labels","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:00:41.757795Z","iopub.execute_input":"2022-01-11T14:00:41.75808Z","iopub.status.idle":"2022-01-11T14:00:41.789169Z","shell.execute_reply.started":"2022-01-11T14:00:41.758046Z","shell.execute_reply":"2022-01-11T14:00:41.78834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  ONEHOT ENCODE LABELS\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\n\nencoded_labels = le.fit_transform(str_labels)\n\nlabels = tf.one_hot(encoded_labels, 3).numpy() # neutral, negative, positive","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:00:50.060546Z","iopub.execute_input":"2022-01-11T14:00:50.060889Z","iopub.status.idle":"2022-01-11T14:00:50.975873Z","shell.execute_reply.started":"2022-01-11T14:00:50.060853Z","shell.execute_reply":"2022-01-11T14:00:50.975077Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nmaxlen = len(max(texts, key = len).split())\ntraining_samples = 20481   # of 27481\nvalidation_samples = 7000 # of 27481\nmax_words = 10000\n\ntokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(texts)\nsequences = tokenizer.texts_to_sequences(texts)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ndata = pad_sequences(sequences, maxlen = maxlen)\n\nprint(\"Shape of data tensor: \", data.shape)\nprint(\"Shape of label tensor: \", labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:01:05.570895Z","iopub.execute_input":"2022-01-11T14:01:05.571162Z","iopub.status.idle":"2022-01-11T14:01:07.691407Z","shell.execute_reply.started":"2022-01-11T14:01:05.571134Z","shell.execute_reply":"2022-01-11T14:01:07.690564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"indices = np.arange(data.shape[0])\nnp.random.shuffle(indices)\ndata = data[indices]\nlabels = labels[indices]\n\nx_train = data[:training_samples]\ny_train = labels[:training_samples]\nx_val = data[training_samples: training_samples + validation_samples]\ny_val = labels[training_samples: training_samples + validation_samples]","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:01:07.693356Z","iopub.execute_input":"2022-01-11T14:01:07.693645Z","iopub.status.idle":"2022-01-11T14:01:07.707705Z","shell.execute_reply.started":"2022-01-11T14:01:07.693605Z","shell.execute_reply":"2022-01-11T14:01:07.706903Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, SimpleRNN\n\nmodel = Sequential()\nmodel.add(Embedding(max_words, 16, input_length=maxlen))\nmodel.add(SimpleRNN(32))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dense(3, activation = 'softmax'))\nmodel.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:10:15.405694Z","iopub.execute_input":"2022-01-11T14:10:15.406645Z","iopub.status.idle":"2022-01-11T14:10:15.494795Z","shell.execute_reply.started":"2022-01-11T14:10:15.406598Z","shell.execute_reply":"2022-01-11T14:10:15.493968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = 'rmsprop',\n             loss = 'categorical_crossentropy',\n             metrics = ['acc'])\n\n\nhistory = model.fit(x_train, y_train,\n                   epochs = 10,\n                   batch_size = 32,\n                   validation_data = (x_val, y_val),\n                   callbacks = [\n                       tf.keras.callbacks.ModelCheckpoint(\n                        'model_save.h5',\n                        monitor=\"val_loss\",\n                        verbose=0,\n                        save_best_only=True,\n                        save_weights_only=True,\n                        mode=\"auto\",\n                        save_freq=\"epoch\"\n                        )\n                   ])","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:10:18.005033Z","iopub.execute_input":"2022-01-11T14:10:18.0053Z","iopub.status.idle":"2022-01-11T14:11:30.437974Z","shell.execute_reply.started":"2022-01-11T14:10:18.005271Z","shell.execute_reply":"2022-01-11T14:11:30.437363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TEST","metadata":{}},{"cell_type":"code","source":"test_csv = pd.read_csv(os.path.join(input_dir, 'test.csv'))\ntest_csv.head()","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:04:45.737401Z","iopub.execute_input":"2022-01-11T14:04:45.7398Z","iopub.status.idle":"2022-01-11T14:04:45.775431Z","shell.execute_reply.started":"2022-01-11T14:04:45.739736Z","shell.execute_reply":"2022-01-11T14:04:45.774463Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_texts = test_csv['text'].values.astype(np.str)\ntest_str_labels = test_csv['sentiment'].values\n\ntest_texts, test_str_labels","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:04:47.86414Z","iopub.execute_input":"2022-01-11T14:04:47.86494Z","iopub.status.idle":"2022-01-11T14:04:47.874171Z","shell.execute_reply.started":"2022-01-11T14:04:47.864897Z","shell.execute_reply":"2022-01-11T14:04:47.87319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  ONEHOT ENCODE LABELS\ntest_le = LabelEncoder()\n\ntest_encoded_labels = test_le.fit_transform(test_str_labels)\n\ntest_labels = tf.one_hot(test_encoded_labels, 3).numpy() # neutral, negative, positive","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:04:56.907296Z","iopub.execute_input":"2022-01-11T14:04:56.907602Z","iopub.status.idle":"2022-01-11T14:04:56.914109Z","shell.execute_reply.started":"2022-01-11T14:04:56.907547Z","shell.execute_reply":"2022-01-11T14:04:56.913052Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = Tokenizer(num_words = max_words)\ntokenizer.fit_on_texts(test_texts)\ntest_sequences = tokenizer.texts_to_sequences(test_texts)\n\nword_index = tokenizer.word_index\nprint('Found %s unique tokens.' % len(word_index))\n\ntest_data = pad_sequences(test_sequences, maxlen = maxlen)\n\nprint(\"Shape of data tensor: \", test_data.shape)\nprint(\"Shape of label tensor: \", test_labels.shape)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:04:58.547102Z","iopub.execute_input":"2022-01-11T14:04:58.54763Z","iopub.status.idle":"2022-01-11T14:04:58.731535Z","shell.execute_reply.started":"2022-01-11T14:04:58.547593Z","shell.execute_reply":"2022-01-11T14:04:58.730663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.load_weights('./model_save.h5')\nmodel.evaluate(test_data, test_labels)","metadata":{"execution":{"iopub.status.busy":"2022-01-11T14:11:45.725116Z","iopub.execute_input":"2022-01-11T14:11:45.725602Z","iopub.status.idle":"2022-01-11T14:11:46.240977Z","shell.execute_reply.started":"2022-01-11T14:11:45.725535Z","shell.execute_reply":"2022-01-11T14:11:46.240166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}