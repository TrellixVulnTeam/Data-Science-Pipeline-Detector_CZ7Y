{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Adversarial Validattion Using USE(Universal Sentence Encoder) and LightGBM"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if 'selected_text' in train.columns:\n    train.drop(columns='selected_text', inplace=True)\ntrain['is_train'] = 1\ntest['is_train'] = 0\nmerged = pd.concat([train, test], sort=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nle.fit(merged['sentiment'].values)\nmerged['sentiment'] = le.transform(merged['sentiment'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"err_text_ids = []\nfor i,t in enumerate(merged['text'].values):\n    if type(t) != str:\n        err_text_ids.append(merged.iloc[i, :]['textID'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for e in err_text_ids:\n    merged = merged.loc[merged['textID']!=e, :]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## USE(Universal Sentence Encoder)\nYou can download an USE model [here](https://tfhub.dev/google/universal-sentence-encoder/4)."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_hub as hub\n\nuse = hub.load('/kaggle/input/universalsentenceencoderlarge4')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"texts = merged['text'].values\nembedded = []\nfor t in texts:\n    embedded.append(use([t])['outputs'].numpy().flatten())\nembedded_df = pd.DataFrame(embedded)\nembedded_df['textID'] = merged['textID'].values\nmerged=merged.merge(embedded_df, on='textID', how='left')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = merged.iloc[:, 2:].drop(columns='is_train')\ny = merged.iloc[:, 3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## LightGBM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgb\n\nn_splits = 3\nSEED = 3\nEARLY_STOPPING = 200\noof = np.zeros(len(X))\ncategorical_features = ['sentiment']\nskf = StratifiedKFold(n_splits=n_splits,random_state=SEED, shuffle=True)\nfor train_idx, valid_idx in skf.split(X, y):\n    X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n    y_train, y_valid = y.iloc[train_idx], y.iloc[valid_idx]\n    \n    train_data = lgb.Dataset(X_train, label=y_train, categorical_feature=categorical_features)\n    valid_data = lgb.Dataset(X_valid, label=y_valid, categorical_feature=categorical_features)\n    watchlist = [train_data, valid_data]\n\n    params = {\n        \"objective\": \"binary\",\n        \"num_leaves\": 50,\n        \"learning_rate\": 0.02,\n        \"bagging_freq\": 5,\n        \"bagging_fraction\": 0.5,\n        \"feature_fraction\": 0.8,\n        \"metric\": \"binary_logloss\",\n        'device':'gpu',\n        'gpu_id':0,\n        'updater':'grow_gpu_hist'\n    }\n\n    model_lgb = lgb.train(params, train_set=train_data, num_boost_round=999, valid_sets=watchlist, verbose_eval=101, early_stopping_rounds=EARLY_STOPPING)\n    y_pred_valid = model_lgb.predict(X_valid, num_iteration=model_lgb.best_iteration)\n    oof[valid_idx] += y_pred_valid\n    gc.collect()\noof /= n_splits-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data = {\n    'textID':merged['textID'].values,\n    'is_train': y.values,\n    'oof':oof\n}\noof_df = pd.DataFrame(data).sort_values(by='oof')\noof_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}