{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport os\nimport sys \nimport torch\nimport transformers\nimport nltk\nimport random\nfrom tqdm import tqdm\n# import spacy\nfrom nltk.corpus import wordnet\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-11-02T09:14:35.776815Z","iopub.execute_input":"2021-11-02T09:14:35.77709Z","iopub.status.idle":"2021-11-02T09:14:35.782763Z","shell.execute_reply.started":"2021-11-02T09:14:35.777061Z","shell.execute_reply":"2021-11-02T09:14:35.782002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iterative_paraphrasing(data, sentiments, num_beam=2, iterations=2, batch_size=8):\n    from transformers import PegasusForConditionalGeneration, PegasusTokenizer\n    \n    model_name = 'tuner007/pegasus_paraphrase'\n    torch_device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    tokenizer = PegasusTokenizer.from_pretrained(model_name)\n    model = PegasusForConditionalGeneration.from_pretrained(model_name).to(torch_device)\n    \n    num_beams = num_beam\n    final_data = []\n    final_sentiments = []\n    num = 0\n    num_sentence = len(data)\n    num_batches = int(np.ceil(num_sentence/batch_size))\n    \n    for i in tqdm(range(num_batches)):\n        batch_ = data[i*batch_size: (i+1)*batch_size]\n        sentiment_batch = sentiments[i*batch_size: (i+1)*batch_size]\n        \n        final_data.extend(batch_)\n        final_sentiments.extend(sentiment_batch)\n        \n        input_text = batch_\n        \n        for num in range(iterations):\n            batch = tokenizer(input_text, truncation=True, padding='longest', return_tensors=\"pt\").to(torch_device)\n            translated = model.generate(**batch, num_beams=3, num_return_sequences=3, temperature=1.5)\n            tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)      \n            input_text = [x for num, x in enumerate(tgt_text) if ((num+1)%3==0)]\n            if num > 0:\n                final_data.extend(input_text)\n                final_sentiments.extend(sentiment_batch)\n            \n        batch = tokenizer(batch_, truncation=True,padding='longest', return_tensors=\"pt\").to(torch_device)\n        translated = model.generate(**batch, num_beams=num_beams, num_return_sequences=num_beams, temperature=1.5)\n        tgt_text = tokenizer.batch_decode(translated, skip_special_tokens=True)\n        \n        for num in range(len(sentiment_batch)):\n            final_sentiments.extend([sentiment_batch[num]]*num_beams)\n        final_data.extend(tgt_text)\n        \n    return final_data, final_sentiments","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:36.432376Z","iopub.execute_input":"2021-11-02T09:14:36.432931Z","iopub.status.idle":"2021-11-02T09:14:36.445477Z","shell.execute_reply.started":"2021-11-02T09:14:36.432896Z","shell.execute_reply":"2021-11-02T09:14:36.444473Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def iterative_backtranslation(data, sentiments, iterations=3, batch_size=8):\n    from transformers import MarianMTModel, MarianTokenizer\n    \n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    \n    en_to_de_model_name = 'Helsinki-NLP/opus-mt-en-de'\n    en_to_de_tokenizer = MarianTokenizer.from_pretrained(en_to_de_model_name)\n    en_to_de_model = MarianMTModel.from_pretrained(en_to_de_model_name).to(device)\n    \n    de_to_en_model_name = 'Helsinki-NLP/opus-mt-de-en'\n    de_to_en_tokenizer = MarianTokenizer.from_pretrained(de_to_en_model_name)\n    de_to_en_model = MarianMTModel.from_pretrained(de_to_en_model_name).to(device)\n    \n    german_sentence = []\n    final_data = []\n    final_sentiments = []\n    \n    num_sentence = len(data)\n    num_batches = int(np.ceil(num_sentence/batch_size))\n    \n    \n    for i in tqdm(range(num_batches)):\n        batch = data[i*batch_size: (i+1)*batch_size]\n        sentiments_batch = sentiments[i*batch_size: (i+1)*batch_size]\n        \n        final_data.extend(batch)\n        final_sentiments.extend(sentiments_batch)\n        \n        src_text = batch\n        for num in range(iterations):\n            \n            german_translated = en_to_de_model.generate(**en_to_de_tokenizer(src_text, return_tensors=\"pt\", padding=True, truncation=True).to(device))\n            german_text = en_to_de_tokenizer.batch_decode(german_translated, skip_special_tokens=True)\n            \n            english_translated = de_to_en_model.generate(**de_to_en_tokenizer(german_text, return_tensors=\"pt\", padding=True, truncation=True).to(device))\n            english_text = de_to_en_tokenizer.batch_decode(english_translated, skip_special_tokens=True)\n            \n            src_text = english_text\n        final_data.extend(english_text)\n        final_sentiments.extend(sentiments_batch)\n        \n    \n    return final_data, final_sentiments","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:37.09492Z","iopub.execute_input":"2021-11-02T09:14:37.095181Z","iopub.status.idle":"2021-11-02T09:14:37.105941Z","shell.execute_reply.started":"2021-11-02T09:14:37.095152Z","shell.execute_reply":"2021-11-02T09:14:37.105216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def para_to_interative_back(\n    data, \n    y,\n    para_iteration=1,\n    num_beam=2,\n    back_trans_iter=1,\n    batch_size=32,\n):\n    data, y = iterative_paraphrasing(data,y, num_beam, para_iteration, batch_size)\n    data, y = iterative_backtranslation(data, y, back_trans_iter, batch_size)\n    \n    return data, y","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:37.600394Z","iopub.execute_input":"2021-11-02T09:14:37.601088Z","iopub.status.idle":"2021-11-02T09:14:37.606452Z","shell.execute_reply.started":"2021-11-02T09:14:37.601044Z","shell.execute_reply":"2021-11-02T09:14:37.605703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_synonms(data, sentiments, num_words_replaced=2, sentence_repeat=2):\n    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n    final_data = []\n    final_sentiments = []\n    synonm_idx = [0, 5, 10, 15, 20]\n    for x, sentiment in tqdm(zip(data, sentiments), total=len(sentiments)):\n        tokenized_sentence = tokenizer.tokenize(x)\n        final_data.append(tokenized_sentence)\n        final_sentiments.append(sentiment)\n        \n        for rep in range(sentence_repeat):\n            x = tokenized_sentence.copy()\n            synonm_idx = np.random.randint(0, len(tokenized_sentence), num_words_replaced)\n            for idx in synonm_idx:\n                root_word = tokenized_sentence[idx]\n                for i, syn in enumerate(wordnet.synsets(root_word)):\n                    if i == 1:\n                        break\n                    for j, l in enumerate(syn.lemmas()):\n                        if j == 1:\n                            break\n                        if l.name() != root_word:\n                            x[idx] = l.name()\n            if x != tokenized_sentence:\n                final_data.append(x)\n                final_sentiments.append(sentiment)\n            \n    final_data = [\" \".join(x) for x in final_data]\n    \n    return final_data, final_sentiments","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:37.984436Z","iopub.execute_input":"2021-11-02T09:14:37.9847Z","iopub.status.idle":"2021-11-02T09:14:37.993818Z","shell.execute_reply.started":"2021-11-02T09:14:37.984671Z","shell.execute_reply":"2021-11-02T09:14:37.993006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def adding_random_words(data, classes):\n    words_per_class = {}\n    all_data_tokens = []\n    final_data = []\n    final_classes = []\n    tokenizer = nltk.tokenize.TreebankWordTokenizer()\n    for x, class_  in tqdm(zip(data, classes), total=len(data)):\n        tokens = tokenizer.tokenize(x)\n        all_data_tokens.append(tokens)\n        if class_ not in words_per_class:\n            words_per_class[class_] = [set(), 0]\n        words_per_class[class_][0].update(tokens)\n        words_per_class[class_][1] += 1\n    \n    for class_ in words_per_class:\n        words_per_class[class_][0] = list(words_per_class[class_][0])\n        \n    for x, class_ in tqdm(zip(all_data_tokens, classes), total=len(classes)):\n        final_data.append(\" \".join(x))\n        final_classes.append(class_)\n        \n        adding_word_idx = random.randint(0, words_per_class[class_][1])\n        insert_idx = random.randint(0, len(x))\n        x.insert(insert_idx, words_per_class[class_][0][adding_word_idx])\n        \n        final_data.append(\" \".join(x))\n        final_classes.append(class_)\n    \n    return final_data, final_classes\n        ","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:38.370515Z","iopub.execute_input":"2021-11-02T09:14:38.370977Z","iopub.status.idle":"2021-11-02T09:14:38.379847Z","shell.execute_reply.started":"2021-11-02T09:14:38.370941Z","shell.execute_reply":"2021-11-02T09:14:38.379169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocessing(train_x_, train_y_, preprocessing_type, preprocessing_args):\n    preprocessing_args[0] = train_x_\n    preprocessing_args[1] = train_y\n    train_x_, train_y_ = preprocessing_type(*preprocessing_args)\n    return train_x_, train_y_","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:38.739134Z","iopub.execute_input":"2021-11-02T09:14:38.739606Z","iopub.status.idle":"2021-11-02T09:14:38.744217Z","shell.execute_reply.started":"2021-11-02T09:14:38.739568Z","shell.execute_reply":"2021-11-02T09:14:38.743327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def training_and_testing(train_x, train_y, test_x, test_y, classifier, preprocessing_name):\n    classifier.fit(train_x, train_y)\n    prediction = classifier.predict(test_x)\n    print(f\"Preprocessing Type = {preprocessing_name} | Testing Accuracy = {accuracy_score(prediction, test_y)*100}%\")\n    ","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:39.107282Z","iopub.execute_input":"2021-11-02T09:14:39.108033Z","iopub.status.idle":"2021-11-02T09:14:39.112723Z","shell.execute_reply.started":"2021-11-02T09:14:39.107985Z","shell.execute_reply":"2021-11-02T09:14:39.111667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def vectorizer(data, labels, train=True):\n    if train:\n        cv.fit(data)\n        lb.fit(labels)\n    labels = lb.transform(labels)\n    vectorized_reviews = cv.transform(data)\n    return vectorized_reviews, labels","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:39.453848Z","iopub.execute_input":"2021-11-02T09:14:39.454532Z","iopub.status.idle":"2021-11-02T09:14:39.458959Z","shell.execute_reply.started":"2021-11-02T09:14:39.454495Z","shell.execute_reply":"2021-11-02T09:14:39.458276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_extration(path):\n    df = pd.read_csv(path).sample(frac=1).reset_index(drop=True)\n    df.dropna(inplace=True)\n#     reviews = df.iloc[:, 1].tolist()\n#     target = df.iloc[:, 0].tolist()\n    reviews = df[\"text\"].apply(lambda x: x.lower()).tolist()\n    target =  df[\"sentiment\"].tolist()\n    \n    return reviews, target","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:40.306362Z","iopub.execute_input":"2021-11-02T09:14:40.307132Z","iopub.status.idle":"2021-11-02T09:14:40.312189Z","shell.execute_reply.started":"2021-11-02T09:14:40.307094Z","shell.execute_reply":"2021-11-02T09:14:40.311246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = \"../input/tweet-sentiment-extraction/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:41.530704Z","iopub.execute_input":"2021-11-02T09:14:41.531178Z","iopub.status.idle":"2021-11-02T09:14:41.534891Z","shell.execute_reply.started":"2021-11-02T09:14:41.531141Z","shell.execute_reply":"2021-11-02T09:14:41.534152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = data_extration(path)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:42.350412Z","iopub.execute_input":"2021-11-02T09:14:42.350963Z","iopub.status.idle":"2021-11-02T09:14:42.524755Z","shell.execute_reply.started":"2021-11-02T09:14:42.350925Z","shell.execute_reply":"2021-11-02T09:14:42.523974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x, test_x, train_y, test_y = train_test_split(x, y, test_size=0.3, stratify=y)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:50.477676Z","iopub.execute_input":"2021-11-02T09:14:50.4782Z","iopub.status.idle":"2021-11-02T09:14:50.528624Z","shell.execute_reply.started":"2021-11-02T09:14:50.478161Z","shell.execute_reply":"2021-11-02T09:14:50.527881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 32\nback_iterations = 3\npara_iterations = 2\n\nnum_words_replaced = 2\nsentence_repeat = 5\n\nnum_beams = 2\n\n\npreprocessing_types = {\n    \"No Preprocessing\": [None, None],\n    \"Adding Random Words\": [adding_random_words, [None, None]],\n    \"Adding Synonms\": [add_synonms, [None, None, num_words_replaced, sentence_repeat]],\n    \"Iterative Paraphrasing\": [iterative_paraphrasing, [None, None, num_beams, para_iterations, batch_size]],\n    \"Iterative Backtranslation\": [iterative_backtranslation, [None, None, back_iterations, batch_size]],\n#     \"Paraphrase and Back translation\": [para_to_interative_back, [None, None, para_iterations, num_beams, back_iterations, batch_size]],\n}","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:14:57.666908Z","iopub.execute_input":"2021-11-02T09:14:57.667172Z","iopub.status.idle":"2021-11-02T09:14:57.672557Z","shell.execute_reply.started":"2021-11-02T09:14:57.667143Z","shell.execute_reply":"2021-11-02T09:14:57.671887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for preprocessing_name, (preprocessing_type, preprocessing_args) in preprocessing_types.items():\n    \n    if preprocessing_type is not None:\n        train_x_, train_y_ = preprocessing(\n            train_x, \n            train_y, \n            preprocessing_type,\n            preprocessing_args\n        )\n        \n    else:\n        train_x_, train_y_ = train_x, train_y\n        \n    x = list(zip(train_x_, train_y_))\n    random.shuffle(x)\n    train_x_, train_y_ = zip(*x)\n    \n    cv = TfidfVectorizer()\n    lb = LabelEncoder()\n    train_x_vec, train_y_vec = vectorizer(train_x_, train_y_, train=True)\n    test_x_vec, test_y_vec = vectorizer(test_x, test_y, train=False)\n    classifier = LogisticRegression(solver='liblinear')\n    classifier = RandomForestClassifier()\n    training_and_testing(train_x_vec, train_y_vec, test_x_vec, test_y_vec, classifier, preprocessing_name)","metadata":{"execution":{"iopub.status.busy":"2021-11-02T09:20:55.962559Z","iopub.execute_input":"2021-11-02T09:20:55.96288Z","iopub.status.idle":"2021-11-02T09:21:14.988216Z","shell.execute_reply.started":"2021-11-02T09:20:55.962844Z","shell.execute_reply":"2021-11-02T09:21:14.987474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}