{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-21T16:21:39.166325Z","iopub.execute_input":"2021-08-21T16:21:39.166724Z","iopub.status.idle":"2021-08-21T16:21:39.180458Z","shell.execute_reply.started":"2021-08-21T16:21:39.166626Z","shell.execute_reply":"2021-08-21T16:21:39.179495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We need to install a wide variety of libraries. For this we will install pandas, numpy, seaborn and matplotlib libraries.\n\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport string\nimport re\nsns.set()\n\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom nltk import ngrams\n\n\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\n\n\n\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Graphics in retina format are more sharp and legible\n%config InlineBackend.figure_format = 'retina'","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:39.182181Z","iopub.execute_input":"2021-08-21T16:21:39.182792Z","iopub.status.idle":"2021-08-21T16:21:40.627575Z","shell.execute_reply.started":"2021-08-21T16:21:39.182756Z","shell.execute_reply":"2021-08-21T16:21:40.626763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1- Reading the datasets","metadata":{}},{"cell_type":"code","source":"train_data = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntest_data = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:40.629272Z","iopub.execute_input":"2021-08-21T16:21:40.629636Z","iopub.status.idle":"2021-08-21T16:21:40.774681Z","shell.execute_reply.started":"2021-08-21T16:21:40.629607Z","shell.execute_reply":"2021-08-21T16:21:40.77391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data.describe()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:40.776664Z","iopub.execute_input":"2021-08-21T16:21:40.776918Z","iopub.status.idle":"2021-08-21T16:21:40.885424Z","shell.execute_reply.started":"2021-08-21T16:21:40.776894Z","shell.execute_reply":"2021-08-21T16:21:40.884675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2- EDA","metadata":{}},{"cell_type":"markdown","source":"### `Missing Values treatment in the dataset`","metadata":{}},{"cell_type":"code","source":"train_data.isnull().sum()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:40.886785Z","iopub.execute_input":"2021-08-21T16:21:40.887157Z","iopub.status.idle":"2021-08-21T16:21:40.9085Z","shell.execute_reply.started":"2021-08-21T16:21:40.887109Z","shell.execute_reply":"2021-08-21T16:21:40.907502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We found one row is missing for text and selected_text, so we need to replace it or drop it.","metadata":{}},{"cell_type":"code","source":"# Dropping missing values\ntrain_data.dropna(inplace= True)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:40.910018Z","iopub.execute_input":"2021-08-21T16:21:40.910548Z","iopub.status.idle":"2021-08-21T16:21:40.930607Z","shell.execute_reply.started":"2021-08-21T16:21:40.910509Z","shell.execute_reply":"2021-08-21T16:21:40.92966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `Distribution of the Sentiment Column`","metadata":{}},{"cell_type":"code","source":"train_data['sentiment'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:40.934112Z","iopub.execute_input":"2021-08-21T16:21:40.93436Z","iopub.status.idle":"2021-08-21T16:21:40.948755Z","shell.execute_reply.started":"2021-08-21T16:21:40.934336Z","shell.execute_reply":"2021-08-21T16:21:40.947891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['sentiment'].value_counts(normalize= True)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:40.950988Z","iopub.execute_input":"2021-08-21T16:21:40.951423Z","iopub.status.idle":"2021-08-21T16:21:40.967621Z","shell.execute_reply.started":"2021-08-21T16:21:40.951384Z","shell.execute_reply":"2021-08-21T16:21:40.966302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.countplot(data= train_data, x= 'sentiment',\n             order = train_data['sentiment'].value_counts().index);","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:40.969534Z","iopub.execute_input":"2021-08-21T16:21:40.970114Z","iopub.status.idle":"2021-08-21T16:21:41.276106Z","shell.execute_reply.started":"2021-08-21T16:21:40.970075Z","shell.execute_reply":"2021-08-21T16:21:41.274956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `Examples of each sentiment`","metadata":{}},{"cell_type":"code","source":"# Positive tweet\nprint('Positive Tweet example:', train_data[train_data['sentiment'] == 'positive']['text'].values[0])\n\n# Negative tweet\nprint('negative Tweet example:', train_data[train_data['sentiment'] == 'negative']['text'].values[0])\n\n# Neutral tweet\nprint('Neutral Tweet example:', train_data[train_data['sentiment'] == 'neutral']['text'].values[0])","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:41.277557Z","iopub.execute_input":"2021-08-21T16:21:41.278007Z","iopub.status.idle":"2021-08-21T16:21:41.304892Z","shell.execute_reply.started":"2021-08-21T16:21:41.277966Z","shell.execute_reply":"2021-08-21T16:21:41.303976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3- Text Data Preprocessing\nWe need to pre-process the data to get it all in a consistent format.We need to clean, tokenize and convert our data into a matrix. Let's create a function which will perform the following tasks on the text columns:\n\n* Tokenizes\n* Make text lowercase\n* Removes hyperlinks\n* Remove punctuation\n* Removes numbers\n* Removes useless words \"stopwords\"\n* Stemming/Lemmatization\n\n","metadata":{}},{"cell_type":"code","source":"stop_words = stopwords.words('english')\nstemmer    = nltk.SnowballStemmer(\"english\")","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:41.306347Z","iopub.execute_input":"2021-08-21T16:21:41.306729Z","iopub.status.idle":"2021-08-21T16:21:41.315517Z","shell.execute_reply.started":"2021-08-21T16:21:41.306675Z","shell.execute_reply":"2021-08-21T16:21:41.314684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def clean_text(text):\n    '''\n        Make text lowercase, remove text in square brackets,remove links,remove punctuation\n        and remove words containing numbers.\n    '''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text) # remove urls\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text) # remove punctuation\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:41.317195Z","iopub.execute_input":"2021-08-21T16:21:41.317868Z","iopub.status.idle":"2021-08-21T16:21:41.324645Z","shell.execute_reply.started":"2021-08-21T16:21:41.317801Z","shell.execute_reply":"2021-08-21T16:21:41.323744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def preprocess_data(text):\n    text = clean_text(text)                                                     # Clean puntuation, urls, and so on\n    text = ' '.join(word for word in text.split() if word not in stop_words)    # Remove stopwords\n    text = ' '.join(stemmer.stem(word) for word in text.split())                # Stemm all the words in the sentence\n    return text","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:41.326143Z","iopub.execute_input":"2021-08-21T16:21:41.326882Z","iopub.status.idle":"2021-08-21T16:21:41.335953Z","shell.execute_reply.started":"2021-08-21T16:21:41.326846Z","shell.execute_reply":"2021-08-21T16:21:41.335017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data['clean_text'] = train_data['text'].apply(preprocess_data)\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:41.337056Z","iopub.execute_input":"2021-08-21T16:21:41.337291Z","iopub.status.idle":"2021-08-21T16:21:46.051373Z","shell.execute_reply.started":"2021-08-21T16:21:41.337268Z","shell.execute_reply":"2021-08-21T16:21:46.05061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert sentiment to numerical variable\ntrain_data['label'] = train_data.sentiment.map({'negative': 0,\n                                                'positive': 1,\n                                                'neutral': 2})\ntrain_data.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:46.052661Z","iopub.execute_input":"2021-08-21T16:21:46.053017Z","iopub.status.idle":"2021-08-21T16:21:46.071547Z","shell.execute_reply.started":"2021-08-21T16:21:46.05298Z","shell.execute_reply":"2021-08-21T16:21:46.070502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 4- Analyzing Text Statistics\nWe can now do some statistical analysis to explore the data like:\n* Text length analysis.\n    * length for whole sentence, # of each character in the sentence.\n    *  count # of word in each sentence.\n* word frequency analysis\n\n","metadata":{}},{"cell_type":"code","source":"train_data['text_n_chars'] = train_data.text.apply(len) # count all chars in each sentence\ntrain_data['text_n_words'] = train_data.text.apply(lambda sent: len(sent.split())) # count number of words in each sentence\ntrain_data.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:46.072843Z","iopub.execute_input":"2021-08-21T16:21:46.073317Z","iopub.status.idle":"2021-08-21T16:21:46.134589Z","shell.execute_reply.started":"2021-08-21T16:21:46.073278Z","shell.execute_reply":"2021-08-21T16:21:46.133605Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `The distribution of number of words for each sentiment.`","metadata":{}},{"cell_type":"code","source":"sns.histplot(data= train_data, x= 'text_n_words', hue= 'sentiment', multiple= 'stack');\n","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:46.135984Z","iopub.execute_input":"2021-08-21T16:21:46.136322Z","iopub.status.idle":"2021-08-21T16:21:46.804203Z","shell.execute_reply.started":"2021-08-21T16:21:46.136287Z","shell.execute_reply":"2021-08-21T16:21:46.803427Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### `The distribution of number of letters for each sentiment`","metadata":{}},{"cell_type":"code","source":"sns.histplot(data= train_data, x= 'text_n_chars', hue= 'sentiment', multiple= 'stack');\n","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:46.805421Z","iopub.execute_input":"2021-08-21T16:21:46.80591Z","iopub.status.idle":"2021-08-21T16:21:47.422883Z","shell.execute_reply.started":"2021-08-21T16:21:46.805873Z","shell.execute_reply":"2021-08-21T16:21:47.421905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Most frequent words.","metadata":{}},{"cell_type":"markdown","source":"#### `In whole Text`","metadata":{}},{"cell_type":"code","source":"from collections import Counter","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.426843Z","iopub.execute_input":"2021-08-21T16:21:47.427189Z","iopub.status.idle":"2021-08-21T16:21:47.431148Z","shell.execute_reply.started":"2021-08-21T16:21:47.42716Z","shell.execute_reply":"2021-08-21T16:21:47.430022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"words = [word for sent in train_data['clean_text'] for word in sent.split()]\nwords[:10] # words without sorting","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.433358Z","iopub.execute_input":"2021-08-21T16:21:47.43389Z","iopub.status.idle":"2021-08-21T16:21:47.470651Z","shell.execute_reply.started":"2021-08-21T16:21:47.43385Z","shell.execute_reply":"2021-08-21T16:21:47.469584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sort words descending order\nfreq_words = Counter(words)\nfreq_words_sorted = sorted(freq_words.items(), key=lambda pair: pair[1], reverse=True)\nfreq_words_df = pd.DataFrame(freq_words_sorted[:20], columns=['word', 'counts'])","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.472307Z","iopub.execute_input":"2021-08-21T16:21:47.472748Z","iopub.status.idle":"2021-08-21T16:21:47.515075Z","shell.execute_reply.started":"2021-08-21T16:21:47.472684Z","shell.execute_reply":"2021-08-21T16:21:47.513955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"freq_words_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.516543Z","iopub.execute_input":"2021-08-21T16:21:47.517033Z","iopub.status.idle":"2021-08-21T16:21:47.53444Z","shell.execute_reply.started":"2021-08-21T16:21:47.516995Z","shell.execute_reply":"2021-08-21T16:21:47.533547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nsns.barplot(data= freq_words_df , x= 'counts', y= 'word')\nplt.title('Top 20 words in whole text')\nplt.show();","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.53596Z","iopub.execute_input":"2021-08-21T16:21:47.536399Z","iopub.status.idle":"2021-08-21T16:21:47.866271Z","shell.execute_reply.started":"2021-08-21T16:21:47.536347Z","shell.execute_reply":"2021-08-21T16:21:47.865441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Frequent words for each sentiment","metadata":{}},{"cell_type":"code","source":"def freq_sentiment_words(text, sentiment, num):\n    '''\n        take the whole data, and return data which is have # of words in each sentiment has been passed\n    '''\n    words = [word for sent in text[text['sentiment'] == sentiment]['clean_text'] for word in sent.split()]\n    freq_words = Counter(words)\n    freq_words_sorted = sorted(freq_words.items(), key=lambda pair: pair[1], reverse=True)\n    freq_words_df = pd.DataFrame(freq_words_sorted[:num], columns=['word', 'counts'])\n    return freq_words_df","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.867581Z","iopub.execute_input":"2021-08-21T16:21:47.868142Z","iopub.status.idle":"2021-08-21T16:21:47.874674Z","shell.execute_reply.started":"2021-08-21T16:21:47.868103Z","shell.execute_reply":"2021-08-21T16:21:47.873854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `In Positive Sentiment`","metadata":{}},{"cell_type":"code","source":"positive_words = freq_sentiment_words(train_data, 'positive', 20)\npositive_words.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.877292Z","iopub.execute_input":"2021-08-21T16:21:47.877559Z","iopub.status.idle":"2021-08-21T16:21:47.924809Z","shell.execute_reply.started":"2021-08-21T16:21:47.877534Z","shell.execute_reply":"2021-08-21T16:21:47.924059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_freq(data, st):\n    '''\n        take the data, and st refeere to kind of sentiment\n    '''\n    plt.figure(figsize=(12, 6))\n    sns.barplot(data= data , x= 'counts', y= 'word')\n    plt.title(f'Top 20 words in {st} sentiment')\n    plt.show();","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.926638Z","iopub.execute_input":"2021-08-21T16:21:47.927214Z","iopub.status.idle":"2021-08-21T16:21:47.93257Z","shell.execute_reply.started":"2021-08-21T16:21:47.927173Z","shell.execute_reply":"2021-08-21T16:21:47.931777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_freq(positive_words, 'positive')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:47.935763Z","iopub.execute_input":"2021-08-21T16:21:47.936059Z","iopub.status.idle":"2021-08-21T16:21:48.276265Z","shell.execute_reply.started":"2021-08-21T16:21:47.936024Z","shell.execute_reply":"2021-08-21T16:21:48.275441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `In Negative Sentiment`","metadata":{}},{"cell_type":"code","source":"negative_words = freq_sentiment_words(train_data, 'negative', 20)\nnegative_words.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:48.277629Z","iopub.execute_input":"2021-08-21T16:21:48.277982Z","iopub.status.idle":"2021-08-21T16:21:48.313754Z","shell.execute_reply.started":"2021-08-21T16:21:48.277946Z","shell.execute_reply":"2021-08-21T16:21:48.312805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_freq(negative_words, 'negative')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:48.315099Z","iopub.execute_input":"2021-08-21T16:21:48.315443Z","iopub.status.idle":"2021-08-21T16:21:48.656618Z","shell.execute_reply.started":"2021-08-21T16:21:48.315407Z","shell.execute_reply":"2021-08-21T16:21:48.655602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `In Neutral Sentiment`","metadata":{}},{"cell_type":"code","source":"neutral_words = freq_sentiment_words(train_data, 'neutral', 20)\nneutral_words.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:48.658111Z","iopub.execute_input":"2021-08-21T16:21:48.658443Z","iopub.status.idle":"2021-08-21T16:21:48.702969Z","shell.execute_reply.started":"2021-08-21T16:21:48.65841Z","shell.execute_reply":"2021-08-21T16:21:48.702017Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_freq(neutral_words, 'neutral')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:48.704347Z","iopub.execute_input":"2021-08-21T16:21:48.704725Z","iopub.status.idle":"2021-08-21T16:21:49.04035Z","shell.execute_reply.started":"2021-08-21T16:21:48.704677Z","shell.execute_reply":"2021-08-21T16:21:49.039285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Distribution of top n-grams","metadata":{}},{"cell_type":"code","source":"def get_top_n_gram(corpus, sentiment,  n_gram, top_n=None):\n    \n    # list of splited senteces, which is just list of words\n    text = [word for sent in corpus[corpus['sentiment'] == sentiment]['clean_text'] for word in sent.split()]\n\n    grams = ngrams(text, n_gram)\n    grams = (' '.join(g) for g in grams)\n    num_of_grams = [words for words in grams]\n    freq_words = Counter(num_of_grams)\n    freq_words_sorted = sorted(freq_words.items(), key=lambda pair: pair[1], reverse=True)\n    freq_words_df = pd.DataFrame(freq_words_sorted[:top_n], columns=['word', 'counts'])\n    return freq_words_df[:top_n]","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:49.041799Z","iopub.execute_input":"2021-08-21T16:21:49.042131Z","iopub.status.idle":"2021-08-21T16:21:49.050338Z","shell.execute_reply.started":"2021-08-21T16:21:49.042096Z","shell.execute_reply":"2021-08-21T16:21:49.04944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `Bi-Gram for positive sentiment`","metadata":{}},{"cell_type":"code","source":"positive_gram = get_top_n_gram(train_data, 'positive', 2, 20)\npositive_gram.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:49.051684Z","iopub.execute_input":"2021-08-21T16:21:49.052078Z","iopub.status.idle":"2021-08-21T16:21:49.148188Z","shell.execute_reply.started":"2021-08-21T16:21:49.052039Z","shell.execute_reply":"2021-08-21T16:21:49.147244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_freq(positive_gram, 'positive')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:49.149587Z","iopub.execute_input":"2021-08-21T16:21:49.149939Z","iopub.status.idle":"2021-08-21T16:21:49.498471Z","shell.execute_reply.started":"2021-08-21T16:21:49.149902Z","shell.execute_reply":"2021-08-21T16:21:49.497631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `Bi-Gram for negative sentiment`","metadata":{}},{"cell_type":"code","source":"negative_gram = get_top_n_gram(train_data, 'negative', 2, 20)\nnegative_gram.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:49.499551Z","iopub.execute_input":"2021-08-21T16:21:49.499877Z","iopub.status.idle":"2021-08-21T16:21:49.581647Z","shell.execute_reply.started":"2021-08-21T16:21:49.499844Z","shell.execute_reply":"2021-08-21T16:21:49.580734Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_freq(negative_gram, 'negative')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:49.583037Z","iopub.execute_input":"2021-08-21T16:21:49.583383Z","iopub.status.idle":"2021-08-21T16:21:50.050742Z","shell.execute_reply.started":"2021-08-21T16:21:49.583347Z","shell.execute_reply":"2021-08-21T16:21:50.049739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### `Bi-Gram for neutral sentiment`","metadata":{}},{"cell_type":"code","source":"netutral_gram = get_top_n_gram(train_data, 'neutral', 2, 20)\nnetutral_gram.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:50.052146Z","iopub.execute_input":"2021-08-21T16:21:50.052485Z","iopub.status.idle":"2021-08-21T16:21:50.15201Z","shell.execute_reply.started":"2021-08-21T16:21:50.05245Z","shell.execute_reply":"2021-08-21T16:21:50.15103Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_freq(netutral_gram, 'neutral')","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:50.15365Z","iopub.execute_input":"2021-08-21T16:21:50.154003Z","iopub.status.idle":"2021-08-21T16:21:50.522463Z","shell.execute_reply.started":"2021-08-21T16:21:50.153966Z","shell.execute_reply":"2021-08-21T16:21:50.5217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We can easily make tri-grams for sentiment using this function `get_top_n_gram` by passing n_gram = 3**","metadata":{}},{"cell_type":"markdown","source":"### Word Cloud","metadata":{}},{"cell_type":"code","source":"# getting list of positive words \npositive_text_clean = train_data[train_data['sentiment' ] == 'positive']['clean_text']\npositive_clean_words = [word for words in positive_text_clean for word in words.split()]\npositive_clean_words[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:50.524523Z","iopub.execute_input":"2021-08-21T16:21:50.525115Z","iopub.status.idle":"2021-08-21T16:21:50.546383Z","shell.execute_reply.started":"2021-08-21T16:21:50.525069Z","shell.execute_reply":"2021-08-21T16:21:50.545627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting list of negative words \nnegative_text_clean = train_data[train_data['sentiment' ] == 'negative']['clean_text']\nnegative_clean_words = [word for words in negative_text_clean for word in words.split()]\nnegative_clean_words[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:50.547562Z","iopub.execute_input":"2021-08-21T16:21:50.547934Z","iopub.status.idle":"2021-08-21T16:21:50.569585Z","shell.execute_reply.started":"2021-08-21T16:21:50.547897Z","shell.execute_reply":"2021-08-21T16:21:50.568863Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# getting list of neutral words \nneutral_text_clean = train_data[train_data['sentiment' ] == 'neutral']['clean_text']\nneutral_clean_words = [word for words in neutral_text_clean for word in words.split()]\nneutral_clean_words[:10]","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:50.570775Z","iopub.execute_input":"2021-08-21T16:21:50.571092Z","iopub.status.idle":"2021-08-21T16:21:50.596007Z","shell.execute_reply.started":"2021-08-21T16:21:50.571058Z","shell.execute_reply":"2021-08-21T16:21:50.595076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from wordcloud import WordCloud\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[30, 15])\nwordcloud1 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(positive_clean_words))\nax1.imshow(wordcloud1)\nax1.axis('off')\nax1.set_title('Positive text',fontsize=40);\n\nwordcloud2 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(negative_clean_words))\nax2.imshow(wordcloud2)\nax2.axis('off')\nax2.set_title('Negative text',fontsize=40);\n\nwordcloud3 = WordCloud( background_color='white',\n                        width=600,\n                        height=400).generate(\" \".join(neutral_clean_words))\nax3.imshow(wordcloud3)\nax3.axis('off')\nax3.set_title('Neutral text',fontsize=40);","metadata":{"execution":{"iopub.status.busy":"2021-08-21T16:21:50.597246Z","iopub.execute_input":"2021-08-21T16:21:50.597584Z","iopub.status.idle":"2021-08-21T16:21:54.879757Z","shell.execute_reply.started":"2021-08-21T16:21:50.597548Z","shell.execute_reply":"2021-08-21T16:21:54.8789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Thanks for your time ^_^.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}