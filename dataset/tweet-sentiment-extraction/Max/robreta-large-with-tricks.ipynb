{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"If you find this kernel helpful, Please check and upvote the original notebook by @cheongwoongkang and the fork by @raghaw. \nhttps://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing  \nhttps://www.kaggle.com/raghaw/roberta-baseline-starter-test?scriptVersionId=31358810"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"This script is meant to display the \"tricks\" you can use in this competition, these are due to the labeling errors in the data as well as the evaluation implementation of the metric.\n\nNotebook explaining the labeling errors:\nhttps://www.kaggle.com/dhananjay3/investigating-html\n\nPost Processing to increase jaccard, credit to @aerdem4 for discovering it\nhttps://www.kaggle.com/c/tweet-sentiment-extraction/discussion/140942\n"},{"metadata":{},"cell_type":"markdown","source":"## Import Packages"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport json\nimport re","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preprocessing"},{"metadata":{},"cell_type":"markdown","source":"### Load Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"pd_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\npd_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Preprocessing\nI formulate this task as an extractive question answering problem, such as SQuAD.  \nGiven a question and context, the model is trained to find the answer spans in the context.\n\nTherefore, I use sentiment as question, text as context, selected_text as answer.\n- Question: sentiment\n- Context: text\n- Answer: selected_text\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_all(input_str, search_str):\n    l1 = []   \n    length = len(input_str)\n    index = 0\n    while index < length:\n        i = input_str.find(search_str, index)\n        if i == -1:\n            return l1\n        l1.append(i)\n        index = i + 1\n    return l1","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Removing and adding html tags"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_html(text):\n    text = re.sub(\"&quot;\", '\"', text)\n    text = re.sub(\"&gt;\", \">\", text)\n    text = re.sub(\"&lt;\", \"<\", text)\n    text = re.sub(\"&le;\", \"≤\", text)\n    text = re.sub(\"&ge;\", \"≥\", text)\n    text = re.sub(\"&amp;\", \"&\", text)\n    return text\n\ndef add_html(text):\n    text = re.sub(\"&\", \"&amp;\", text)   \n    text = re.sub('\"', \"&quot;\",  text)\n    text = re.sub(\">\", \"&gt;\", text)\n    text = re.sub(\"<\", \"&lt;\", text)\n    text = re.sub(\"≤\", \"&le;\", text)\n    text = re.sub(\"≥\", \"&ge;\", text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### @aerdem4 trick for boosting jaccard"},{"metadata":{"trusted":true},"cell_type":"code","source":"def f(selected):\n     return \" \".join(set(selected.lower().split()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Make output dirs"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir data\n!mkdir results_roberta_large","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert training data to json, remove html-tags and fix answers"},{"metadata":{"trusted":true},"cell_type":"code","source":"output = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\ntrain = np.array(pd_train)\n\nconverted = 0\nfor line in train:\n    paragraphs = []\n    context = line[1]\n    qas = []\n    qid = line[0]\n    answers = []\n    orig_answer = line[2]\n    question = line[3]\n    if type(orig_answer) != str or type(context) != str or type(question) != str:\n        print(context, type(context))\n        print(orig_answer, type(orig_answer))\n        print(question, type(question))\n        continue\n    \n    # get start index and then covert html-tag\n    answer_starts = find_all(context, orig_answer)\n    context = remove_html(context)\n\n    for answer_start in answer_starts:\n        # get new answer, if there are no html-tags answer will be the same as given in train.csv\n        answer = context[answer_start:answer_start+len(orig_answer)]\n        answers.append({'answer_start': answer_start, 'text': answer})\n        if orig_answer != answer:\n#             print(\"original:\", orig_answer)\n#             print(\"new:\", answer)\n            converted += 1\n    qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n    \n    paragraphs.append({'context': context, 'qas': qas})\n    output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n\nwith open('data/train.json', 'w') as outfile:\n    json.dump(output, outfile)\n    \nprint(\"converted:\" , converted)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Convert pd_test data\n\noutput = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\n\n# covert html-tags\npd_test.text = pd_test.text.map(remove_html)\ntest_array = np.array(pd_test)\n\nfor line in test_array:\n    paragraphs = []\n    context = line[1]\n    qas = []\n    question = line[-1]\n    qid = line[0]\n \n    if type(context) != str or type(question) != str:\n        print(context, type(context))\n        print(answer, type(answer))\n        print(question, type(question))\n        continue\n\n    answers = []\n    answers.append({'answer_start': 1000000, 'text': '__None__'})\n    qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n    \n    paragraphs.append({'context': context, 'qas': qas})\n    output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n\nwith open('data/test.json', 'w') as outfile:\n    json.dump(output, outfile)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Finetuning RoBERTa"},{"metadata":{},"cell_type":"markdown","source":"Install the pytorch-transformers package (v2.5.1) of [huggingface](https://github.com/huggingface/transformers/tree/v2.5.1)."},{"metadata":{"trusted":true},"cell_type":"code","source":"!cd /kaggle/input/pytorchtransformers/transformers-2.5.1; pip install .","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### train and/or evaluate "},{"metadata":{"trusted":true},"cell_type":"code","source":"!python /kaggle/input/pytorchtransformers/transformers-2.5.1/examples/run_squad.py \\\n--model_type roberta \\\n--model_name_or_path /kaggle/input/roberta-large-model/results_roberta_large/ \\\n--do_lower_case \\\n--do_eval \\\n--data_dir ./data \\\n--cache_dir /kaggle/input/cached-roberta-large-pretrained/cache \\\n--train_file train.json \\\n--predict_file test.json \\\n--learning_rate 2.5e-5 \\\n--num_train_epochs 3 \\\n--max_seq_length 192 \\\n--doc_stride 64 \\\n--output_dir results_roberta_large \\\n--per_gpu_eval_batch_size=16 \\\n--per_gpu_train_batch_size=16 \\\n--save_steps=100000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modify answers with html-tags and submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = json.load(open('results_roberta_large/predictions_.json', 'r'))\n\nfor i in range(len(pd_test)):\n    id_ = pd_test['textID'][i]\n    selected_text = predictions[id_]\n    text = pd_test['text'][i]\n    text = \" \".join(text.split())\n    starts = find_all(text, selected_text)\n    \n    # if none of (&><≤≥\") exist before the end of the answer nothing will change by adding html-tags \n    # if there is more than one answer in the context we cannot know which to modify\n    if len(starts) == 1 and any(c in text[:starts[0]+len(selected_text)] for c in list('&><≤≥\"')):\n        text = add_html(text)\n        start = starts[0]\n#         print(\"original:\", selected_text)\n        selected_text = text[start:start+len(selected_text)]\n#         print(\"new:\", selected_text)\n    \n    if pd_test['sentiment'][i] == 'neutral': # neutral postprocessing\n        pd_test.loc[i, 'selected_text'] = pd_test['text'][i]\n    else:\n        pd_test.loc[i, 'selected_text'] = selected_text\n\npd_test.selected_text = pd_test.selected_text.map(f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the submission file.\npd_test[[\"textID\", \"selected_text\"]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}