{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn import preprocessing,metrics\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n\n# #### 1.\tLoad the dataset and create a dataframe.\ntrain_reviews_df = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntest_reviews_df = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\nsubmission_sample_df = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reviews_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_reviews_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_reviews_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tweets_df = train_reviews_df[['text','sentiment']]\ntrain_tweets_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tweets_df = test_reviews_df[['text','sentiment']]\ntest_tweets_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tweets_df.shape, test_tweets_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tweets_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tweets_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_tweets_df = train_tweets_df.dropna()\ntrain_tweets_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Preprocessing\nfrom nltk.corpus import stopwords\ndef tweet_preprocessing(tweets_df):\n    \n    # Replace special symbols\n    tweets_df['processed_text'] = tweets_df['text'].replace(to_replace ='(@[\\w]+)', value ='', regex = True) \n    \n    #remove any links from the tweet: Links not required for performing sentiment analysis.\n    tweets_df['processed_text'] = tweets_df['processed_text'].str.replace('((www\\.[\\s]+)|(https?://[^\\s]+))','\\0',regex=True)\n    \n    # remove special characters, numbers, punctuations: None of them would add any value to the sentiment score.\n    tweets_df['processed_text'] = tweets_df['processed_text'].str.replace(\"[^a-zA-Z]+\", \" \")\n    \n    #Converting into lower case and splitting into wrods.\n    tweets_df[\"processed_text\"] = tweets_df[\"processed_text\"].str.lower()\n    tweets_df[\"processed_text\"] = tweets_df[\"processed_text\"].str.split()\n    \n    stop = stopwords.words('english')\n    #tweets_df['processed_text']=tweets_df['processed_text'].apply(lambda x: [item for item in x if item not in stop])\n\n    return tweets_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings(\"ignore\")\n\ntrain_tweets_df = tweet_preprocessing(train_tweets_df)\ntrain_tweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tweets_df = tweet_preprocessing(test_tweets_df)\ntest_tweets_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rejoin_words(train_tweets_df):\n    my_list = train_tweets_df['processed_text']\n    joined_words = ( \" \".join(my_list))\n    #print(joined_words)\n    return joined_words\n\ntrain_tweets_df['new_processed_text'] = train_tweets_df.apply(rejoin_words, axis=1)\ntrain_tweets_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_tweets_df['new_processed_text'] = test_tweets_df.apply(rejoin_words, axis=1)\ntest_tweets_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\n\ncount_vectorizer = CountVectorizer(max_features=23618)\ntest_x = test_tweets_df['new_processed_text']\ntest_transformed_vector = count_vectorizer.fit_transform(test_x)\ntest_transformed_vector.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_transformed_vector.shape[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(max_features = 6770)\nX = train_tweets_df['new_processed_text']\ntrain_transformed_vector = count_vectorizer.fit_transform(X)\ntrain_transformed_vector.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nY = train_tweets_df['sentiment']\nx_train, x_test, y_train, y_test = train_test_split(train_transformed_vector, Y, test_size = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.shape, x_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB().fit(x_train.toarray(), y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GNB_pred=clf.predict(x_test.toarray())\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score \nfrom sklearn.metrics import classification_report \nmodel_perforamnce = confusion_matrix(y_test,GNB_pred)\nmodel_perforamnce","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (classification_report(y_test, GNB_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's do the import for Naive Bayes\nfrom sklearn.naive_bayes import MultinomialNB\n# creating instance\ntweet_analysis_mnb = MultinomialNB()\ntweet_analysis_mnb.fit(x_train, y_train)\nmnb_pred = tweet_analysis_mnb.predict(x_test)\nfrom sklearn.metrics import confusion_matrix\nMNB_model_perforamnce = confusion_matrix(y_test,mnb_pred)\nMNB_model_perforamnce","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mnb_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (classification_report(y_test,mnb_pred))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nlogistic_regression = LogisticRegression()\nlogistic_regression.fit(x_train, y_train)\nlr_prediction = logistic_regression.predict(x_test)\nfrom sklearn.metrics import confusion_matrix\nlr_model_perforamnce = confusion_matrix(y_test,lr_prediction)\nlr_model_perforamnce","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print (classification_report(y_test,lr_prediction))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nrandom_forest_classifer = RandomForestClassifier()\nrandom_forest_classifer.fit(x_train, y_train)\nrfc_prediction = random_forest_classifer.predict(x_test)\nfrom sklearn.metrics import confusion_matrix\nrfc_model_perforamnce = confusion_matrix(y_test,rfc_prediction)\nrfc_model_perforamnce","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrfc_classification_report = classification_report(y_test,rfc_prediction)\nprint (rfc_classification_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import svm\n#Create a svm Classifier\nSVM = svm.SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\nSVM.fit(x_train, y_train)# predict the labels on validation dataset\npredictions_SVM = SVM.predict(x_test)# Use accuracy_score function to get the accuracy\nprint(\"SVM Accuracy Score -> \",accuracy_score(predictions_SVM, y_test)*100)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nrfc_classification_report = classification_report(y_test,predictions_SVM)\nprint (rfc_classification_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_test_prediction_report(y_test, GNB_pred, mnb_pred, lr_prediction, rfc_prediction, predictions_SVM):\n    frame = { 'Actual Value': y_test,'SVM':predictions_SVM,'GNB ': GNB_pred, 'MNB' :mnb_pred, 'LR':lr_prediction,'RFC':rfc_prediction} \n    result_pd = pd.DataFrame(frame)\n    return result_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result_pd = prepare_test_prediction_report(y_test, GNB_pred, mnb_pred, lr_prediction, rfc_prediction, predictions_SVM)\nresult_pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data_svm_pred = SVM.predict(test_transformed_vector.toarray())\ntest_data_svm_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# SVM for multi-class classification using built-in one-vs-one\nfrom sklearn.datasets import make_classification\nfrom sklearn.svm import SVC\n# define dataset\n# define model\nsvc = SVC(decision_function_shape='ovo')\n# fit model\n#train_tweets_df['sentiment']\n#Y = pd.get_dummies(train_tweets_df.sentiment)\ntrain_tweets_df['sentiment'].replace(to_replace=['negative', 'neutral', 'positive'], value=[1, 2, 3], inplace=True)\nY = train_tweets_df['sentiment']\nsvc.fit(train_transformed_vector, Y)\n# make predictions\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"svc_pred = svc.predict(train_transformed_vector)\n\nsvc_classification_report = classification_report(Y,svc_pred)\nprint (svc_classification_report)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    \ndef prediction_report():\n    test_data_svm_pred = SVM.predict(test_transformed_vector.toarray())\n    test_reviews_df['SVM'] = test_data_svm_pred\n    svc_test_pred = svc.predict(test_transformed_vector)\n    test_reviews_df['SVC'] = svc_test_pred\n    test_reviews_df['SVC'].replace(to_replace=[1, 2, 3], value=['negative', 'neutral', 'positive'], inplace=True)\n    lr_prediction = logistic_regression.predict(test_transformed_vector)\n    test_reviews_df['LR'] = lr_prediction\n    rfc_prediction = random_forest_classifer.predict(test_transformed_vector)\n    test_reviews_df['RFC'] = rfc_prediction\n    mnb_pred = tweet_analysis_mnb.predict(test_transformed_vector)\n    test_reviews_df['MNB'] = mnb_pred\n    GNB_pred=clf.predict(test_transformed_vector.toarray())\n    test_reviews_df['GNB'] = GNB_pred\n    return test_reviews_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"prediction_report()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import precision_recall_fscore_support as score\nprecision,recall,fscore,support=score(Y,svc_pred,average='macro')\nprint('Precision : {}'.format(precision*100)) \nprint( 'Recall    : {}'.format(recall*100))\nprint( 'F-score   : {}'.format(fscore*100))\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}