{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"markdown","source":"Some people seem to not like [WordCloud](https://amueller.github.io/word_cloud/)? I've read recently that [Manoj](https://www.kaggle.com/mks2192) found them [useless](https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/152852).\n\n\nJoke aside, in this notebook I will explore this NLP vizualization technique and compare it to another recent one: [Shifterator](https://pypi.org/project/shifterator/). \n\nSome of the work is inspired from this [notebook](https://www.kaggle.com/mrisdal/shifterator-analysis-on-animal-crossing-reviews), so if you found this notebook useful, consider also exploring it. \n\nLet's get started!","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","collapsed":true,"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":false},"cell_type":"markdown","source":"# WordCloud","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Alright, let's start with the most popular (is that so?) technique: WordCloud. \n\n\nBefore that, we need few processing steps: \n\n- extract the words into a single string\n- remove [stopwords](https://en.wikipedia.org/wiki/Stop_words) (i.e. words that don't add much to the meaning)\n- (optional) select an appropriate mask\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Some useful imports\n\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pylab as plt\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport requests\nfrom io import BytesIO\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading train and test datasets\ntrain_df = pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\ntest_df = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking some of the stopwords\ncount = 0\nfor sw in STOPWORDS:\n    print(sw)\n    count += 1\n    if count == 10:\n        break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Here is an \"appropriate\" mask.\nurl = \"https://static01.nyt.com/images/2014/08/10/magazine/10wmt/10wmt-articleLarge-v4.jpg\"\nresponse = requests.get(url)\nimg = Image.open(BytesIO(response.content))\n\nmask = np.array(img)\nimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# And finally, generating the train wordcloud\ntext = \" \".join(train_df[\"text\"].dropna().str.lower().values)\nstopwords = set(STOPWORDS)\n\nwc = WordCloud(max_words=3000, mask=mask, stopwords=stopwords, margin=10,\n               random_state=1, contour_color='white', contour_width=1).generate(text)\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\n\nax.imshow(wc, interpolation=\"bilinear\")\nax.set_title(\"Tweeter Sentiment Extraction Train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's do the same thing but this time for the test dataset\ntext = \" \".join(test_df[\"text\"].dropna().str.lower().values)\n\nwc = WordCloud(max_words=3000, mask=mask, stopwords=stopwords, margin=10,\n               random_state=1, contour_color='white', contour_width=1).generate(text)\n\nfig, ax = plt.subplots(1, 1, figsize=(15, 15))\n\nax.imshow(wc, interpolation=\"bilinear\")\nax.set_title(\"Tweeter Sentiment Extraction Test\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That was easy and \"cute\". Time to move to the second contender: Shifterator. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Shifterator","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Alright, before we start, let's get something out of the way: this technique isn't comparble to wordcloud.\nIt is a another recent vizualization technique of NLP words but that's about the only common thing. Will see how they differ \nquite soon. \n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# First, we need to install the library.\n!pip install shifterator","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We also need to get the frequency (i.e. occurence) of each word, thus this short utility function.\nfrom collections import Counter\nfrom itertools import chain\n\ndef get_word_freq(s):\n\n    return Counter(v for v in chain(*s.dropna().str.lower().str.split().values) if v not in STOPWORDS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will start with what's called word shift graphs. ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Word Shift Graphs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For this type of graph, you will need four inputs: \n    \n1. Word frequencies for text 1\n2. Word frequencies for text 2\n3. Sentiment dict for text 1\n4. Sentiment dict for text 2\n\nWill use this graphical representation to compare train and test datasets. \n    \nAlso, here is a nice forumla for computing a word shift from the Github repo: \n\n<img src=\"https://raw.githubusercontent.com/ryanjgallagher/shifterator/master/figures/contribution.png\"> \n\nCheck it [out](https://github.com/ryanjgallagher/shifterator) for more details.\n\n(Note: for now, the displayed graph isn't correct and I am struggling to build the sentiments' dicts. Please share your tips, thanks!)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from shifterator import relative_shift as rs\n\n\ntrain_freq = dict(get_word_freq(train_df[\"text\"]))\ntest_freq = dict(get_word_freq(test_df[\"text\"]))\n\n# TODO: These doesn't look right, fix! If you have any idea in the comments, pleas share!\n# TODO: How to make the sentiment dict?\ntrain_pos =  get_word_freq(train_df.loc[lambda df: df[\"sentiment\"] == \"positive\", \"text\"].copy())\ntrain_neg = get_word_freq(train_df.loc[lambda df: df[\"sentiment\"] == \"negative\", \"text\"].copy())\ntest_pos = get_word_freq(test_df.loc[lambda df: df[\"sentiment\"] == \"positive\", \"text\"].copy())\ntest_neg = get_word_freq(test_df.loc[lambda df: df[\"sentiment\"] == \"negative\", \"text\"].copy())\ntrain_sentiment_score = {**train_pos, **train_neg}\ntest_sentiment_score = {**test_pos, **test_neg}\n\n\n\n\nsentiment_shift = rs.SentimentShift(train_freq, test_freq, train_sentiment_score, test_sentiment_score)\n\nsentiment_shift.get_shift_graph(title=\"Word Shift for Train (left) vs Test (right) datasets\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we will explore entrop shift graphs. Notice that there are other similar graphs to the entropy one (Kullback-Leibler Divergence \nand Jensen-Shannon Divergence) but we won't explore these since they are quite similar.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Entropy Shift Graphs","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"For these graphs, you will only need two things: \n    \n1. Word frequencies for text 1\n2. Word frequencies for text 2\n\nIn what follows, we will build three different entropy shift graphs: \n\n- Positive train vs negative train\n- Positive test vs negative test\n- Train vs test","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from shifterator import relative_shift as rs\n\n\ntrain_pos_freq = get_word_freq(train_df.loc[lambda df: df[\"sentiment\"] == \"positive\", \"text\"])\ntrain_neg_freq = get_word_freq(train_df.loc[lambda df: df[\"sentiment\"] == \"negative\", \"text\"])\n\n\n\nsentiment_shift = rs.EntropyShift(reference=train_pos_freq,\n                                  comparison=train_neg_freq)\n\nsentiment_shift.get_shift_graph(title=\"Entropy Shift for Train Positive (left) vs Negative (right) Sentiments\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_pos_freq = get_word_freq(test_df.loc[lambda df: df[\"sentiment\"] == \"positive\", \"text\"])\ntest_neg_freq = get_word_freq(test_df.loc[lambda df: df[\"sentiment\"] == \"negative\", \"text\"])\n\n\n\nsentiment_shift = rs.EntropyShift(reference=test_pos_freq,\n                                  comparison=test_neg_freq)\nsentiment_shift.get_shift_graph(title=\"Entropy Shift for Test Positive (left) vs Negative (right) Sentiments\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from shifterator import relative_shift as rs\n\n\ntrain_freq = get_word_freq(train_df[\"text\"])\ntest_freq = get_word_freq(test_df[\"text\"])\n\n\n\nsentiment_shift = rs.EntropyShift(reference=train_freq,\n                                  comparison=test_freq)\nsentiment_shift.get_shift_graph(title=\"Entropy Shift for Train (left) vs Test (right) datasets\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To sum up: \n    \n- Shifterator offers graphs to compare two different texts using word shift graphs. These can be based on **relative word shifts** or **entropy** (and similar metrics) shifts. \n- WordCloud is used to quickly visualize words that are used the most. The more frequent the word, the bigger its size in \nthe representation.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"That's it for now. I am quite new to the world  of word shift graphs so please leave comments and I will try to improve this notebook as time permits. \nFinally, thanks to [Ryan Gallagher](https://github.com/ryanjgallagher) for creating the library. \n\n(Note: as stated above, my sentiment shift isn't quite correct and I will try to fix it in the upcoming days so please let me know\nif you have any hints/tips. Many thanks!)","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}