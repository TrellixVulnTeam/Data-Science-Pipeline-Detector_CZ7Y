{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\nsample = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collecting the info about the train data\ntrain.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We have null value for text and selected_text only\ntrain.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Collecting info for the test data\ntest.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**EDA**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selected_text is subset of text"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"lets look at the distribution of tweets in the train set"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by = 'text', ascending = False)\ntemp.style.background_gradient(cmap = 'Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting the sentiments count\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize = (12,6))\nsns.countplot(x = 'sentiment', data = train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(go.Funnelarea(\ntext = temp.sentiment,\nvalues = temp.text,\ntitle = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n))\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"Jackard Similarity"},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c))/(len(a) + len(b) -len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results_jaccard = []\n\nfor ind, row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n    \n    jaccard_score = jaccard(sentence1, sentence2)\n    results_jaccard.append([sentence1, sentence2,jaccard_score])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.iterrows()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jaccard = pd.DataFrame(results_jaccard, columns = [\"text\", \"selected_text\", \"jaccard_score\"])\ntrain = train.merge(jaccard, how = 'outer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jaccard.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Num_words_ST'] = train['selected_text'].apply(lambda x: len(str(x).split())) # Number of words in Selected Text\ntrain['Num_word_text'] = train['text'].apply(lambda x: len(str(x).split())) # Number of words in main text\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] # Difference in number of words text and selected text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look at the distribution of Meta-Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_data = [train['Num_words_ST'], train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels, show_curve = False)\nfig.update_layout(title_text = 'Distribtion of Number of words')\nfig.update_layout(\nautosize = False,\nwidth = 900,\nheight = 700,\npaper_bgcolor = 'LightSteelBlue'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_data = [train['Num_words_ST'], train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels, show_curve = True)\nfig.update_layout(title_text = 'Distribtion of Number of words')\nfig.update_layout(\nautosize = False,\nwidth = 900,\nheight = 700,\npaper_bgcolor = 'LightSteelBlue'\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The number of words plot is really interesting, the tweets having number of words greater than 25 are very less and thus the number of words distribution plot is right skewed."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\np1 = sns.kdeplot(train['Num_words_ST'], shade = True, color = \"r\").set_title('Kernel Distribution of Number of words')\np1 = sns.kdeplot(train['Num_word_text'], shade = True, color = 'b')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\np1 = sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade = True, color = \"b\").set_title('Kernel Distribution of Difference in Number of Words')\np2 = sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade = True, color = 'r')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\nsns.distplot(train[train['sentiment']=='neutral']['difference_in_words'], kde = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"since most of the value obtained in difference in numbers of word is zero so we can.t plot kde plot for sentiment analysis hence we have taken kde = False in the above case"},{"metadata":{"trusted":true},"cell_type":"code","source":"k = train[train['sentiment']=='neutral']['difference_in_words']\nk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\np1 = sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade = True, color = 'b').set_title(\"KDE of Jaccard Scores across different Sentiments\")\np2 = sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade = True, color = 'r')\nplt.legend(labels = ['positive', 'negative'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"raw","source":"for the same reason mentioned above I am unable to plot the kde plot for the jaccard_score of neutral tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize = (12,6))\nsns.distplot(train[train['sentiment']=='neutral']['jaccard_score'], kde = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k = train[train['Num_word_text']<=2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k.groupby('sentiment').mean()['jaccard_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Num_words_ST'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(k)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(k[k['sentiment']=='positive'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k[k['sentiment']=='positive']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cleaning the Corpus"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets, remove links, remove punctuation and remove words containing numbers'''\n    text = str(text).lower()\n    text = re.sub('\\[*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\W*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'] = train['text'].apply(lambda x: clean_text(x))\ntrain['selected_text'] = train['text'].apply(lambda x: clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list'] = train['selected_text'].apply(lambda x: str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words', 'count']\ntemp.style.background_gradient(cmap = 'Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x = 'count', y = 'Common_words', title = 'Common Words Text', orientation = 'h',\n            width = 700, height = 700, color = 'Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"  Removing the stop words"},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x: remove_stopword(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words', 'count']\ntemp.style.background_gradient(cmap = 'Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp, path = ['Common_words'], values = 'count', title = 'Tree of Most Common Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most Common Words in Text**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list1'] = train['text'].apply(lambda x: str(x).split()) # List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x: remove_stopword(x)) # Removing Stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:, :]\ntemp.columns = ['Common_words', 'count']\ntemp.style.background_gradient(cmap = 'Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x = 'count', y = \"Common_words\", title = \"Common Words in Text\",\n            orientation = 'h', width = 700, height = 700, color = 'Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Most Common Words Sentiments Wise**"},{"metadata":{"trusted":true},"cell_type":"code","source":"Positive_sent = train[train['sentiment'] == 'positive']\nNegative_sent = train[train['sentiment'] == 'negative']\nNeutral_sent = train[train['sentiment'] == 'neutral']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# MOst Common Positive Words\ntop = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap = 'Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most Common Negative Words\ntop = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words', 'count']\ntemp_negative.style.background_gradient(cmap = 'Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp_negative, path = ['Common_words'], values = 'count', title = 'Tree of Most Common Negative Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Most Common Neutral words\ntop = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.iloc[1:,:]\ntemp_neutral.columns = ['Common_words', 'count']\ntemp_neutral.style.background_gradient(cmap = 'Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp_neutral, x = 'count', y = 'Common_words', title = 'Most Common Neutral Words',\n            orientation = 'h', width = 700, height = 700, color = 'Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp_neutral, path = ['Common_words'], values = 'count', title = 'Tree of Most Common Neutral Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Let's Look at Unique Words in each Segment**"},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_text = [word for word_list in train['temp_list1'] for word in word_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def words_unique(sentiment, numwords, raw_words):\n    '''\n    Input:\n        segment - Segment Category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result;\n        raw_word = list for item in train_data[train_data.segments == segments]['temp_list1']:\n    \n    Output:\n    dataframe giving information about the name of the specific ingredient and how many times it\n    occurs in the chosen cuisine (in descending order based on their counts)...\n    '''\n    \n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother.append(word)\n    allother = list(set(allother))\n        \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    \n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n            \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words', 'count'])\n    \n    return Unique_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\nUnique_Positive.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(Unique_Positive, path = ['words'], values = 'count', title = 'Tree Of Unique Positive Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize = (16,10))\nmy_circle = plt.Circle((0,0), 0.7, color = 'white')\nplt.pie(Unique_Positive['count'], labels = Unique_Positive.words, colors = Pastel1_7.hex_colors)\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Positive Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Negative = words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\nUnique_Negative.style.background_gradient(cmap = 'Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize = (16,10))\nmy_circle = plt.Circle((0,0), 0.7, color = 'white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(Unique_Negative['count'], labels = Unique_Negative.words, colors = Pastel1_7.hex_colors)\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Negative Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Neutral = words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap = 'Oranges')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize = (16,10))\nmy_circle = plt.Circle((0,0), 0.7, color = 'white')\nplt.pie(Unique_Neutral['count'], labels = Unique_Neutral.words, colors = Pastel1_7.hex_colors)\np = plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Neutral Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**It's Time For WordClouds**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_wordcloud(text, mask = None, max_words = 200, max_font_size = 100,)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}