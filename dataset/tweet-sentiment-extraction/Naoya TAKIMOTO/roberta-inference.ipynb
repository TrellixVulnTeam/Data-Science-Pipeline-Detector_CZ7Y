{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"jupyter nbconvert --ExecutePreprocessor.timeout=6000","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport tokenizers\nimport string\nimport torch\nimport transformers\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom tqdm import tqdm\nimport re","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"MAX_LEN = 192\nTRAIN_BATCH_SIZE = 32\nVALID_BATCH_SIZE = 8\nEPOCHS = 5\n\nfrom transformers import RobertaTokenizer\nTOKENIZER = RobertaTokenizer.from_pretrained(\"roberta-base\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from transformers import RobertaConfig, RobertaModel\n# Initializing a RoBERTa configuration\nconfiguration = RobertaConfig()\n# Initializing a model from the configuration\nmodel = RobertaModel(configuration)\n# Accessing the model configuration\nconf = model.config","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TweetModel(transformers.BertPreTrainedModel):\n    def __init__(self, conf):\n        super(TweetModel, self).__init__(conf)\n        self.roberta = RobertaModel(configuration)\n        self.drop_out = nn.Dropout(0.1)\n        self.l0 = nn.Linear(768 * 2, 2)\n        torch.nn.init.normal_(self.l0.weight, std=0.02)\n    \n    def forward(self, ids, mask, token_type_ids):\n        _, _, out = self.roberta(\n            ids,\n            attention_mask=mask,\n            token_type_ids=token_type_ids\n        )\n\n        out = torch.cat((out[-1], out[-2]), dim=-1)\n        out = self.drop_out(out)\n        logits = self.l0(out)\n\n        start_logits, end_logits = logits.split(1, dim=-1)\n\n        start_logits = start_logits.squeeze(-1)\n        end_logits = end_logits.squeeze(-1)\n\n        return start_logits, end_logits","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data(tweet, selected_text, sentiment, tokenizer, max_len):\n    tweet = \" \" + \" \".join(str(tweet).split())\n    selected_text = \" \" + \" \".join(str(selected_text).split())\n\n    len_st = len(selected_text) - 1\n    idx0 = None\n    idx1 = None\n\n    for ind in (i for i, e in enumerate(tweet) if e == selected_text[1]):\n        if \" \" + tweet[ind: ind+len_st] == selected_text:\n            idx0 = ind\n            idx1 = ind + len_st - 1\n            break\n\n    char_targets = [0] * len(tweet)\n    if idx0 != None and idx1 != None:\n        for ct in range(idx0, idx1 + 1):\n            char_targets[ct] = 1\n    \n    #tok_tweet = tokenizer.encode(tweet)\n    tok_tweet = tokenizer(tweet, return_tensors='pt', padding=True, truncation=True)\n    input_ids_orig = tok_tweet['input_ids']\n    tweet_offsets = tok_tweet.offsets\n    \n    target_idx = []\n    for j, (offset1, offset2) in enumerate(tweet_offsets):\n        if sum(char_targets[offset1: offset2]) > 0:\n            target_idx.append(j)\n    \n    targets_start = target_idx[0]\n    targets_end = target_idx[-1]\n\n    sentiment_id = {\n        'positive': 1313,\n        'negative': 2430,\n        'neutral': 7974\n    }\n    \n    input_ids = [0] + [sentiment_id[sentiment]] + [2] + [2] + input_ids_orig + [2]\n    token_type_ids = [0, 0, 0, 0] + [0] * (len(input_ids_orig) + 1)\n    mask = [1] * len(token_type_ids)\n    tweet_offsets = [(0, 0)] * 4 + tweet_offsets + [(0, 0)]\n    targets_start += 4\n    targets_end += 4\n\n    padding_length = max_len - len(input_ids)\n    if padding_length > 0:\n        input_ids = input_ids + ([1] * padding_length)\n        mask = mask + ([0] * padding_length)\n        token_type_ids = token_type_ids + ([0] * padding_length)\n        tweet_offsets = tweet_offsets + ([(0, 0)] * padding_length)\n    \n    return {\n        'ids': input_ids,\n        'mask': mask,\n        'token_type_ids': token_type_ids,\n        'targets_start': targets_start,\n        'targets_end': targets_end,\n        'orig_tweet': tweet,\n        'orig_selected': selected_text,\n        'sentiment': sentiment,\n        'offsets': tweet_offsets\n    }\n\n\nclass TweetDataset:\n    def __init__(self, tweet, sentiment, selected_text):\n        self.tweet = tweet\n        self.sentiment = sentiment\n        self.selected_text = selected_text\n        self.tokenizer = TOKENIZER\n        self.max_len = MAX_LEN\n    \n    def __len__(self):\n        return len(self.tweet)\n\n    def __getitem__(self, item):\n        data = process_data(\n            self.tweet[item], \n            self.selected_text[item], \n            self.sentiment[item],\n            self.tokenizer,\n            self.max_len\n        )\n\n        return {\n            'ids': torch.tensor(data[\"ids\"], dtype=torch.long),\n            'mask': torch.tensor(data[\"mask\"], dtype=torch.long),\n            'token_type_ids': torch.tensor(data[\"token_type_ids\"], dtype=torch.long),\n            'targets_start': torch.tensor(data[\"targets_start\"], dtype=torch.long),\n            'targets_end': torch.tensor(data[\"targets_end\"], dtype=torch.long),\n            'orig_tweet': data[\"orig_tweet\"],\n            'orig_selected': data[\"orig_selected\"],\n            'sentiment': data[\"sentiment\"],\n            'offsets': torch.tensor(data[\"offsets\"], dtype=torch.long)\n        }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def calculate_jaccard_score(\n    original_tweet, \n    target_string, \n    sentiment_val, \n    idx_start, \n    idx_end, \n    offsets,\n    verbose=False):\n    \n    if idx_end < idx_start:\n        idx_end = idx_start\n    \n    filtered_output  = \"\"\n    for ix in range(idx_start, idx_end + 1):\n        filtered_output += original_tweet[offsets[ix][0]: offsets[ix][1]]\n        if (ix+1) < len(offsets) and offsets[ix][1] < offsets[ix+1][0]:\n            filtered_output += \" \"\n\n    if sentiment_val == \"neutral\" or len(original_tweet.split()) < 2:\n        filtered_output = original_tweet\n\n    if sentiment_val != \"neutral\" and verbose == True:\n        if filtered_output.strip().lower() != target_string.strip().lower():\n            print(\"********************************\")\n            print(f\"Output= {filtered_output.strip()}\")\n            print(f\"Target= {target_string.strip()}\")\n            print(f\"Tweet= {original_tweet.strip()}\")\n            print(\"********************************\")\n\n    jac = jaccard(target_string, filtered_output)\n    return jac, filtered_output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\n\ndf_train.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\ndf_test.head","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\ndf_test = pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\ndf_test.loc[:, \"selected_text\"] = df_test.text.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\")\nmodel_config = RobertaConfig()\nmodel_config.output_hidden_states = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model1 = TweetModel(conf=model_config)\nmodel1.to(device)\n#model1.load_state_dict(torch.load(\"../input/roberta-base/pytorch_model.bin\"))\nmodel1.eval()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_output = []\njac_score = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.optim as optim\n\ntrain_dataset = TweetDataset(\n        tweet=df_train.text.values,\n        sentiment=df_train.sentiment.values,\n        selected_text=df_train.selected_text.values\n    )\n\ntest_dataset = TweetDataset(\n        tweet=df_test.text.values,\n        sentiment=df_test.sentiment.values,\n        selected_text=df_test.selected_text.values\n    )\n\ntrain_data_loader = torch.utils.data.DataLoader(\n    train_dataset,\n    shuffle=True,\n    batch_size=TRAIN_BATCH_SIZE,\n    num_workers=4\n)\n\ntest_data_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    shuffle=False,\n    batch_size=VALID_BATCH_SIZE,\n    num_workers=1\n)\n\nloss = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model1.parameters(),lr=1e-5)\n\nfor epoch in tqdm(range(EPOCHS)):\n    for bi, d in enumerate(tqdm(train_data_loader)):\n        ids = d[\"ids\"]\n        token_type_ids = d[\"token_type_ids\"]\n        mask = d[\"mask\"]\n        sentiment = d[\"sentiment\"]\n        orig_selected = d[\"orig_selected\"]\n        orig_tweet = d[\"orig_tweet\"]\n        targets_start = d[\"targets_start\"]\n        targets_end = d[\"targets_end\"]\n        offsets = d[\"offsets\"].numpy()\n\n        ids = ids.to(device, dtype=torch.long)\n        token_type_ids = token_type_ids.to(device, dtype=torch.long)\n        mask = mask.to(device, dtype=torch.long)\n        targets_start = targets_start.to(device, dtype=torch.long)\n        targets_end = targets_end.to(device, dtype=torch.long)\n\n        outputs_start1, outputs_end1 = model1(\n            ids=ids,\n            mask=mask,\n            token_type_ids=token_type_ids\n        )\n\n\n        outputs_start = (outputs_start1 ) / 1\n        outputs_end = (outputs_end1 ) / 1\n\n        loss_1 = loss(outputs_start1, targets_start)\n        loss_2 = loss(outputs_end1, targets_end)\n\n        optimizer.zero_grad()\n        loss_0 = loss_1 + loss_2\n        loss_0.backward()\n        optimizer.step()\n\n\n\n        outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n        outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n        jaccard_scores = []\n        for px, tweet in enumerate(orig_tweet):\n            selected_tweet = orig_selected[px]\n            tweet_sentiment = sentiment[px]\n            jac, output_sentence = calculate_jaccard_score(\n                original_tweet=tweet,\n                target_string=selected_tweet,\n                sentiment_val=tweet_sentiment,\n                idx_start=np.argmax(outputs_start[px, :]),\n                idx_end=np.argmax(outputs_end[px, :]),\n                offsets=offsets[px]\n            )\n            jac_score.append(jac)\n            final_output.append(output_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jac_score[-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub = pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\nprint(df_sub.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_output = []\nfor bi, d in enumerate(test_data_loader):\n    ids = d[\"ids\"]\n    token_type_ids = d[\"token_type_ids\"]\n    mask = d[\"mask\"]\n    sentiment = d[\"sentiment\"]\n    orig_selected = d[\"orig_selected\"]\n    orig_tweet = d[\"orig_tweet\"]\n    targets_start = d[\"targets_start\"]\n    targets_end = d[\"targets_end\"]\n    offsets = d[\"offsets\"].numpy()\n\n    ids = ids.to(device, dtype=torch.long)\n    token_type_ids = token_type_ids.to(device, dtype=torch.long)\n    mask = mask.to(device, dtype=torch.long)\n    targets_start = targets_start.to(device, dtype=torch.long)\n    targets_end = targets_end.to(device, dtype=torch.long)\n\n    outputs_start, outputs_end = model1(\n        ids=ids,\n        mask=mask,\n        token_type_ids=token_type_ids\n    )\n    outputs_start = torch.softmax(outputs_start, dim=1).cpu().detach().numpy()\n    outputs_end = torch.softmax(outputs_end, dim=1).cpu().detach().numpy()\n    \n    for px, tweet in enumerate(orig_tweet):\n        selected_tweet = orig_selected[px]\n        tweet_sentiment = sentiment[px]\n        jac, output_sentence = calculate_jaccard_score(\n            original_tweet=tweet,\n            target_string=selected_tweet,\n            sentiment_val=tweet_sentiment,\n            idx_start=np.argmax(outputs_start[px, :]),\n            idx_end=np.argmax(outputs_end[px, :]),\n            offsets=offsets[px]\n        )\n        jac_score.append(jac)\n        final_output.append(output_sentence)\n\n\ndf_sub.loc[:, 'selected_text'] = final_output\ndf_sub.to_csv(\"submission.csv\", index=False)\n\nprint(np.asarray(jac_score).mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_sub","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}