{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport os\nimport sklearn\nimport json\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# install neccessary packages\n\n!pip install '../input/required-packages/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '../input/required-packages/simpletransformers-0.22.1-py3-none-any.whl' -q","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_FILES_PATH = \"/kaggle/input/tweet-sentiment-extraction/\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(INPUT_FILES_PATH + \"train.csv\")\n# df_train = df_train[:1000]\ndf_train = df_train.dropna()\ndf_train.reset_index(drop=True, inplace=True)\n\ndf_test = pd.read_csv(INPUT_FILES_PATH + \"test.csv\")\n# df_test = df_test[:1000]\ndf_test = df_test.dropna()\ndf_test.reset_index(drop=True, inplace=True)\n\n\nsample_submission = pd.read_csv(INPUT_FILES_PATH + \"sample_submission.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# use GPU to do calculation, if the computer support it\nuse_cuda = torch.cuda.is_available()\nuse_cuda","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getSelectedTextStartIndex(text, selected_text):\n    return text.lower().find(selected_text.lower())\n\nstart_indices = []\nfor tupl in df_train.itertuples():\n    start_indices.append(getSelectedTextStartIndex(tupl.text, tupl.selected_text))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# To train question-asnwering tasks, we need context, question and answer\n# Treat sentiment as question\n# text as context\n# selected_text as answer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Data format\n\n# For question answering tasks, the input data can be in JSON files or in a Python list of dicts in the correct format.\n\n# The file should contain a single list of dictionaries. A dictionary represents a single context and its associated questions.\n\n# Each such dictionary contains two attributes, the \"context\" and \"qas\".\n\n#     context: The paragraph or text from which the question is asked.\n#     qas: A list of questions and answers.\n\n# Questions and answers are represented as dictionaries. Each dictionary in qas has the following format.\n\n#     id: (string) A unique ID for the question. Should be unique across the entire dataset.\n#     question: (string) A question.\n#     is_impossible: (bool) Indicates whether the question can be answered correctly from the context.\n#     answers: (list) The list of correct answers to the question.\n\n# A single answer is represented by a dictionary with the following attributes.\n\n#     answer: (string) The answer to the question. Must be a substring of the context.\n#     answer_start: (int) Starting index of the answer in the context.\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert data into JSON and follows simpletransformers format\n#preprocess train data\ndef train_preprocessing(df_train):\n    out = []\n    for tupl in df_train.itertuples():\n        #question and answer\n       \n        question = tupl.sentiment\n        answer = tupl.selected_text\n        context = tupl.text\n        qid = tupl.Index\n        answer_start = start_indices[qid]\n        \n        ans = [{\"answer_start\": answer_start, \"text\": answer.lower()}]\n        qas = [{\"question\": question, \"id\": qid, \"is_impossible\": False, \"answers\": ans}]\n        out.append({\"context\": context.lower(), \"qas\": qas})\n\n    return out\n\n#preprocess test data, no answer provided\ndef test_preprocessing(df_test):\n    out = []\n    for tupl in df_test.itertuples():\n        #question and answer\n        qas = []\n        con = []\n        ans = []\n        question = tupl.sentiment\n        context = tupl.text\n        qid = tupl.Index\n        \n        ans = [{\"answer_start\": 1000000, \"text\": \"__None__\"}]\n        qas = [{\"question\": question, \"id\": qid, \"is_impossible\": False, \"answers\": ans}]\n        out.append({\"context\": context.lower(), \"qas\": qas})\n\n    return out","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preparing paths to use"},{"metadata":{"trusted":true},"cell_type":"code","source":"MODEL_PATH = './bert_qa_data/output/'\nMODEL_POS = MODEL_PATH + 'model_pos'\nMODEL_NEG = MODEL_PATH + 'model_neg'\n\nfor path in [MODEL_PATH, MODEL_POS, MODEL_NEG]:\n    if not os.path.exists(path):\n        os.makedirs(path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Create the model using simpletransformers"},{"metadata":{},"cell_type":"markdown","source":"## Using distilbert-base-uncased-distilled-squad\ndistilbert is a smaller general-purpose language representation model of bert but retained most of the accuracy\n\n\nthis model has been pretrained to specifically suited to question answering task using SQuAD - the Stanford Question Answering Dataset"},{"metadata":{"trusted":true},"cell_type":"code","source":"from simpletransformers.question_answering import QuestionAnsweringModel\nimport time\nBERT_PATH = \"../input/required-packages/distilbert-base-uncased-distilled-squad\"\nstart = time.time()\n\nargs={\n 'reprocess_input_data': True,#If True, the input data will be reprocessed even if a cached file of the input data exists in the cache_dir.\n 'overwrite_output_dir': True, #If True, the trained model will be saved to the ouput_dir and will overwrite existing saved models in the same directory.\n 'learning_rate': 5e-5, #The learning rate for training.\n 'num_train_epochs': 4, #The number of epochs the model will be trained for.\n 'doc_stride': 64, #When splitting up a long document into chunks, how much stride to take between chunks.\n 'fp16': False,#fp16 (half-precision floating points) mode on or off, \n}\n\n# Create the models\nQA_model_pos = QuestionAnsweringModel('distilbert', BERT_PATH, args=args, use_cuda=use_cuda)\nQA_model_neg = QuestionAnsweringModel('distilbert', BERT_PATH, args=args, use_cuda=use_cuda)\n\nend = time.time()\nprint(end - start)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training positive tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_preprocessing(df_train[df_train[\"sentiment\"] == \"positive\"])\n\nQA_model_pos.train_model(train_data = train_data, output_dir=MODEL_POS, show_running_loss=True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training negative tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = train_preprocessing(df_train[df_train[\"sentiment\"] == \"negative\"])\n\nQA_model_neg.train_model(train_data = train_data, output_dir=MODEL_POS, show_running_loss=True )","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Ignore neutral tweets"},{"metadata":{},"cell_type":"markdown","source":"# Make prediction"},{"metadata":{},"cell_type":"markdown","source":"## Predict positive data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_pos = df_test[df_test[\"sentiment\"]==\"positive\"].copy()\ndf_test_pos.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_pos = QA_model_pos.predict(test_preprocessing(df_test_pos))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predict negative data"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test_neg = df_test[df_test[\"sentiment\"]==\"negative\"].copy()\ndf_test_neg.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions_neg = QA_model_neg.predict(test_preprocessing(df_test_neg))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Ignore neutral tweets"},{"metadata":{},"cell_type":"markdown","source":"# Make submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# combine predictions\nprediction_test_pos = pd.DataFrame.from_dict(predictions_pos)\nprediction_test_pos.index = df_test_pos.index.copy()\n\nprediction_test_neg = pd.DataFrame(predictions_neg)\nprediction_test_neg.index = df_test_neg.index.copy()\n\nprediction_test_neu = df_test[df_test[\"sentiment\"] == \"neutral\"].copy()\nprediction_test_neu.rename(columns = {\"text\": \"answer\" }, inplace=True)\n\nsubmission_df = pd.concat([prediction_test_pos, prediction_test_neg, prediction_test_neu], axis=0)\nsubmission_df.sort_index(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission[\"selected_text\"] = submission_df[\"answer\"]\n\nsample_submission.to_csv(\"submission.csv\", index = False)\nprint(\"File submitted successfully.\")\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}