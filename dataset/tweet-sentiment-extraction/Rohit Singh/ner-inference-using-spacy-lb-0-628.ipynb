{"cells":[{"metadata":{},"cell_type":"markdown","source":"### This kernel is in continuation to my other kernel [NER - training using spacy (0.628 LB)](https://www.kaggle.com/rohitsingh9990/ner-training-using-spacy-0-628-lb)\n\n* The training kernel has all information regarding how to solve this problem as NER using spacy\n* This kernel shows how to make submission using trained spacy models\n"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# !pip install chart_studio\n\nimport re\n# Tutorial about Python regular expressions: https://pymotw.com/2/re/ import string\nfrom pandas_profiling import ProfileReport\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom gensim.models import Word2Vec \nfrom gensim.models import KeyedVectors \nimport matplotlib.pyplot as plt\nimport pickle\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport seaborn as sns\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom plotly import tools\n# import chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\n\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nfrom collections import Counter # suppress warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nsns.set(style=\"ticks\", color_codes=True)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 1. Reading Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"BASE_PATH = '../input/tweet-sentiment-extraction/'\nMODELS_BASE_PATH = '../input/tse-spacy-model/models/'\nMODELS_BASE_PATH2 = '../input/tse-spacy-model/models2/'\n\ntest_df = pd.read_csv( BASE_PATH + 'test.csv')\nsubmission_df = pd.read_csv( BASE_PATH + 'sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## 2. Loading Spacy Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_texts = []\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH2 + 'model_neg')\n    model_neu = spacy.load(MODELS_BASE_PATH + 'model_neu')\n        \n    for index, row in test_df.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) < 4:\n#             output_str = text\n#             selected_texts.append(predict_entities(text, model_neu))\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ntest_df['selected_text'] = selected_texts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df['selected_text'] = test_df['selected_text']\nsubmission_df.to_csv(\"submission.csv\", index=False)\ndisplay(submission_df.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5. Whats Next?\n\n* I am going to create a discussion thread for those who are trying to approach this problem as NER. Will share link soon.\n* Will try to update this kernel with more approaches to increase LB score.\n* Suggestions are most welcome."},{"metadata":{},"cell_type":"markdown","source":"Note: If you like my work, please, upvote â˜º"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}