{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom transformers import *\nimport tokenizers\nprint('TF version',tf.__version__)\nimport os\nfrom tokenizers import BertWordPieceTokenizer\nfrom transformers import BertTokenizer, TFBertModel, BertConfig\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom transformers import BertTokenizer, TFBertForQuestionAnswering\nfrom sklearn.model_selection import train_test_split\nimport gc\nfrom keras.callbacks import ModelCheckpoint\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"max_len = 128\ntrain_mode = False\n\n# Load the fast tokenizer from saved file\ntokenizer = BertWordPieceTokenizer(\"../input/bert-qa-best/bert-large-uncased-whole-word-masking-finetuned-squad-vocab.txt\", lowercase=True)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# loading train data.\nsentiment_id = {'positive': 3893, 'negative': 4997, 'neutral': 8699}\ndata = pd.read_csv('../input/tweet-sentiment-extraction/train.csv').fillna('')\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# removing empty rows\ndata['text'].replace('', np.nan, inplace=True)\ndata.dropna(subset=['text'], inplace=True)\ndata.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train Test CV split\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test = train_test_split(data, test_size = 0.05, random_state=42)\nx_train,x_cv = train_test_split(x_train, test_size = 0.2, random_state = 42)\n\nprint(\"x_train shape is\", x_train.shape)\nprint(\"x_cv shape is\", x_cv.shape)\nprint(\"x_test shape is\", x_test.shape)\nx_train.reset_index(drop=True, inplace=True)\nx_cv.reset_index(drop=True, inplace=True)\nx_test.reset_index(drop=True, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Data Preparation"},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch\n# Example to explain operations in text_process function\n\ntweet = 'WHY DO WE FALL? SO THAT WE CAN LEARN TO PICK OURSELVES BACK UP.'\nselected_text = 'LEARN TO PICK OURSELVES BACK UP'\nsentiment = 'positive'\nprint('text',tweet)\nprint('select_text:',selected_text)\nprint('sentiment:', sentiment)\n# idx0 and idx1 and start and end indices of select_text in tweet.\nidx0 = None\nidx1 = None\nst_len = len(selected_text)\nfor i in range(len(tweet)):\n    if(tweet[i:i+st_len]==selected_text):\n        idx0 = i\n        idx1 = i + st_len -1\n        break\n\n# char_tartgets is of length tweet, assign indices with select text =1 \nchar_targets = [0]*len(tweet)\nfor i in range(len(tweet)):\n    if idx0 != None and idx1!=None:\n        if i>=idx0 and i<=idx1:\n            char_targets[i] = 1\n\nprint('char_targets:',char_targets)\n# encoding tweet using tokenizer, it returns ids(token for each word) and offsets(span of each word)\ntok_tweet = tokenizer.encode(tweet)\n\ninput_ids = tok_tweet.ids[1:-1] # word ids given by tokenizer stripping first[cls] and last token [sep]\noffsets = tok_tweet.offsets[1:-1] # offsets of the tweet \n\nprint('input_ids:',input_ids)\nprint('offsets:',offsets)\n# start index and end index of tweet words with select_text\ntargets_index = []\nfor i, (off1,off2) in enumerate(offsets):\n    if sum(char_targets[off1:off2])>0:\n        targets_index.append(i)       \ntarget_start = targets_index[0] \ntarget_end = targets_index[-1]\n\nprint('target_start:',target_start)\nprint('target_end:', target_end)\n\n# creating ids, token_type_ids, mask into bert format, changing target_start and target_end accordingly.\nids = [101] + [sentiment_id[sentiment]] + [102] + input_ids  + [102]\ntoken_type_ids = [0,0,0] + [1]*(len(input_ids) + 1)\nmask = [1] * len(token_type_ids)\ntarget_start+=3 \ntarget_end+=3\noffsets = [(0,0)]*3 + offsets + [(0,0)]\n\n# padding \npadding_length = max_len - len(ids)\nif padding_length > 0:\n    ids = ids + ([0] * padding_length)\n    mask = mask + ([0] * padding_length)\n    token_type_ids = token_type_ids + ([0] * padding_length)\n    offsets = offsets + ([(0, 0)] * padding_length)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# https://www.kaggle.com/abhishek/bert-base-uncased-using-pytorch\n\ndef text_process(tweet, sentiment, tokenizer, max_len, selected_text=None):\n    \n    \"\"\"\n    inputs:\n    tweets: text \n    sentiment: sentiment of the tweet\n    tokenizer: tokenizer\n    max_len: max length of ids, mask and token_type_ids (inputs of bert)\n    selected_text: selected_text (optional)\n    \n    operation:\n    \n    Given inputs it calculates  ids, mask , token_type_ids, offsets and target_start and target_end.\n    \n    outputs:\n    dictionary with keys as below,\n    ids: input tokens for bert in format as 101 <sentiment tokens> 102 <text tokens> 102\n    mask: array with length as max_len and has 1's in the indices of text and zeros elsewhere.\n    token_type_ids: 1's in the place of text and zeros elsewhere , size max_len\n    target_start,target_end: begin and end of select_text (returned only when select_text is given)\n    offsets: offsets of text \n    \n    \"\"\"\n    \n    if selected_text!=None:\n        idx0 = None\n        idx1 = None\n        st_len = len(selected_text)\n        for i in range(len(tweet)):\n            if(tweet[i:i+st_len]==selected_text):\n                idx0 = i\n                idx1 = i + st_len -1\n                break\n\n        char_targets = [0]*len(tweet)\n\n        for i in range(len(tweet)):\n            if idx0 != None and idx1!=None:\n                if i>=idx0 and i<=idx1:\n                    char_targets[i] = 1\n\n        tok_tweet = tokenizer.encode(tweet)\n\n        input_ids = tok_tweet.ids[1:-1] \n        offsets = tok_tweet.offsets[1:-1] \n        \n        targets_index = []\n\n        for i, (off1,off2) in enumerate(offsets):\n            if sum(char_targets[off1:off2])>0:\n                targets_index.append(i)\n\n        target_start = targets_index[0] \n        target_end = targets_index[-1]\n        \n        \n        ids = [101] + [sentiment_id[sentiment]] + [102] + input_ids  + [102]\n        token_type_ids = [0,0,0] + [1]*(len(input_ids) +1)\n        mask = [1] * len(token_type_ids)\n        target_start+=3 \n        target_end+=3\n        offsets = [(0,0)]*3 + offsets + [(0,0)]\n\n        padding_length = max_len - len(ids)\n        if padding_length > 0:\n            ids = ids + ([0] * padding_length)\n            mask = mask + ([0] * padding_length)\n            token_type_ids = token_type_ids + ([0] * padding_length)\n            offsets = offsets + ([(0, 0)] * padding_length)\n            \n        return {\n            \n            'ids': ids,\n            'token_type_ids':token_type_ids,\n            'mask':mask,\n            'target_start':target_start,\n            'target_end':target_end,\n            'offsets':offsets\n        }\n    else:\n\n        tok_tweet = tokenizer.encode(tweet)\n        \n        input_ids = tok_tweet.ids[1:-1] \n        offsets = tok_tweet.offsets[1:-1] \n\n        ids = [101] + [sentiment_id[sentiment]] + [102] + input_ids  + [102]\n        token_type_ids = [0,0,0] + [1]*(len(input_ids) + 1)\n        mask = [1] * len(token_type_ids)\n        offsets = [(0,0)]*3 + offsets + [(0,0)]\n\n        padding_length = max_len - len(ids)\n        if padding_length > 0:\n            ids = ids + ([0] * padding_length)\n            mask = mask + ([0] * padding_length)\n            token_type_ids = token_type_ids + ([0] * padding_length)\n            offsets = offsets + ([(0, 0)] * padding_length)\n            \n        return {\n            \n            'ids': ids,\n            'token_type_ids':token_type_ids,\n            'mask':mask,\n            'offsets':offsets\n        }\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = x_train.shape[0]\n\ntrain_ids = np.zeros((rows,max_len), dtype = 'int32')\ntrain_mask = np.zeros((rows,max_len), dtype = 'int32')\ntrain_type_ids = np.zeros((rows,max_len), dtype = 'int32')\ntrain_start_idx = np.zeros((rows,max_len), dtype = 'int32')\ntrain_end_idx = np.zeros((rows,max_len), dtype = 'int32')\n\nfor i in range(x_train.shape[0]):\n    \n    encoding = text_process(x_train.loc[i,'text'], x_train.loc[i,'sentiment'], tokenizer, max_len,x_train.loc[i,'selected_text'] )\n    \n    train_ids[i] = encoding['ids']\n    train_start_idx[i,encoding['target_start']] = 1\n    train_end_idx[i, encoding['target_end']] = 1\n    \n    train_type_ids[i] = encoding['token_type_ids']\n    train_mask[i] = encoding['mask']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking\n\ni = 10\n\nencoding = text_process(x_train.loc[i,'text'], x_train.loc[i,'sentiment'], tokenizer, max_len,x_train.loc[i,'selected_text'] )\n\ntrain_ids[i] = encoding['ids']\n\n\ntrain_start_idx[i,encoding['target_start']] = 1\ntrain_end_idx[i, encoding['target_end']] = 1\n\ntrain_type_ids[i] = encoding['token_type_ids']\ntrain_mask[i] = encoding['mask']\n\ntweet = x_train.loc[i,'text']\nselect_text = x_train.loc[i,'selected_text']\n\ntarget_start = np.argmax(train_start_idx[i,])\ntarget_end = np.argmax(train_end_idx[i, ])\n\noffsets = encoding['offsets']\n\n\nprint('tweet:',tweet)\nprint('selected_text:',select_text)\ntweet[offsets[target_start][0]:offsets[target_end][-1]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = x_cv.shape[0]\n\ncv_ids = np.zeros((rows,max_len), dtype = 'int32')\ncv_mask = np.zeros((rows,max_len), dtype = 'int32')\ncv_type_ids = np.zeros((rows,max_len), dtype = 'int32')\ncv_start_idx = np.zeros((rows,max_len), dtype = 'int32')\ncv_end_idx = np.zeros((rows,max_len), dtype = 'int32')\n\nfor i in range(x_cv.shape[0]):\n    \n    encoding = text_process(x_cv.loc[i,'text'], x_cv.loc[i,'sentiment'], tokenizer, max_len,x_cv.loc[i,'selected_text'] )\n    \n    cv_ids[i] = encoding['ids']\n    cv_start_idx[i,encoding['target_start']] = 1\n    cv_end_idx[i, encoding['target_end']] = 1\n    \n    cv_type_ids[i] = encoding['token_type_ids']\n    cv_mask[i] = encoding['mask']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = x_test.shape[0]\n\ntest_ids = np.zeros((rows,max_len), dtype = 'int32')\ntest_mask = np.zeros((rows,max_len), dtype = 'int32')\ntest_type_ids = np.zeros((rows,max_len), dtype = 'int32')\ntest_start_idx = np.zeros((rows,max_len), dtype = 'int32')\ntest_end_idx = np.zeros((rows,max_len), dtype = 'int32')\n\nfor i in range(x_test.shape[0]):\n    \n    encoding = text_process(x_test.loc[i,'text'], x_test.loc[i,'sentiment'], tokenizer, max_len,x_test.loc[i,'selected_text'] )\n    \n    test_ids[i] = encoding['ids']\n    test_start_idx[i,encoding['target_start']] = 1\n    test_end_idx[i, encoding['target_end']] = 1\n    \n    test_type_ids[i] = encoding['token_type_ids']\n    test_mask[i] = encoding['mask']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Metric\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    \n    if (len(a)==0) & (len(b)==0): \n        return 0.5\n    \n    c = a.intersection(b)\n    \n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_model():\n    # Create Model\n       \n    ids = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n    att = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((max_len,), dtype=tf.int32)\n\n\n    #bert = TFBertForQuestionAnswering.from_pretrained(modelName) this needs internet hence loading model from disk.\n    bert = TFBertForQuestionAnswering.from_pretrained('../input/bert-squad/bert-large-uncased-whole-word-masking-finetuned-squad-tf_model.h5', config = '../input/bert-squad/bert-large-uncased-whole-word-masking-finetuned-squad-config.json')\n    x = bert(ids, attention_mask = att, token_type_ids = tok)\n\n    x1 = tf.keras.layers.Dropout(0.3)(x[0]) \n    x1 = tf.keras.layers.Activation('softmax')(x1)\n\n    x2 = tf.keras.layers.Dropout(0.3)(x[1]) \n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs = [ids, att, tok], outputs=[x1, x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate = 3e-5)\n\n   # model.compile(loss = custom_loss, optimizer = optimizer)\n    model.compile(loss= 'categorical_crossentropy', optimizer=optimizer)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"/kaggle/working/best_model.h5\" \ncheckpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, save_weights_only = True, mode = 'auto', save_freq = 'epoch')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = build_model()\n\n\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# clearing space\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training or loading trained model for predictions.\nif train_mode:\n    model.fit([train_ids, train_mask, train_type_ids], [train_start_idx, train_end_idx], \n                      epochs = 3, \n                      batch_size = 8, \n                      verbose = True, \n                      callbacks = [checkpoint],\n                      validation_data = ([cv_ids,cv_mask,cv_type_ids], [cv_start_idx, cv_end_idx]),\n                      shuffle = True)\nelse:\n    \n    model.load_weights('../input/bert-qa-best/best_model (1).h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = x_test.shape[0]\n\npreds_start = np.zeros((rows,max_len))\npreds_end = np.zeros((rows,max_len))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict([test_ids, test_mask, test_type_ids], verbose = True)\npreds_start += preds[0]\npreds_end += preds[1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nscore = 0\nfor k in range(x_test.shape[0]):\n    \n        \n    \n        encoding = text_process(x_test.loc[k,'text'], x_test.loc[k,'sentiment'], tokenizer, max_len)\n        offsets = encoding['offsets']\n        #targets_start,targets_end = model.predict(encoding['ids'], encoding['mask'], encoding['token_type_ids'] )\n        targets_start = np.argmax(preds_start[k,])\n        targets_end = np.argmax(preds_end[k,])\n\n        pred = x_test.loc[k,'text'][offsets[targets_start][0]:offsets[targets_end][-1]]\n        score+=jaccard(x_test.loc[k,'selected_text'], pred)\n\n    \n    \nscore=score/x_test.shape[0]    \nprint('score on local test_data',score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# prediction samples\n\nfor k in range(0,x_test.shape[0],100):\n    \n        encoding = text_process(x_test.loc[k,'text'], x_test.loc[k,'sentiment'], tokenizer, max_len)\n        offsets = encoding['offsets']\n        targets_start = np.argmax(preds_start[k,])\n        targets_end = np.argmax(preds_end[k,])\n\n        pred = x_test.loc[k,'text'][offsets[targets_start][0]:offsets[targets_end][-1]]\n        print('text:', x_test.text[k])\n        print('selected text:', x_test.selected_text[k])\n        print('sentiment:',x_test.sentiment[k] )\n        print('predicted:', pred)\n        print('jaccard_score:', jaccard(pred, x_test.loc[k,'selected_text']))\n        print('#########################################')\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\nrows = x_test.shape[0]\npreds_start = np.zeros((rows,max_len))\npreds_end = np.zeros((rows,max_len))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rows = x_test.shape[0]\n\ntest_ids = np.zeros((rows,max_len), dtype = 'int32')\ntest_mask = np.zeros((rows,max_len), dtype = 'int32')\ntest_type_ids = np.zeros((rows,max_len), dtype = 'int32')\ntest_start_idx = np.zeros((rows,max_len), dtype = 'int32')\ntest_end_idx = np.zeros((rows,max_len), dtype = 'int32')\n\nfor i in range(x_test.shape[0]):\n    \n    encoding = text_process(x_test.loc[i,'text'], x_test.loc[i,'sentiment'], tokenizer, max_len )\n    test_ids[i] = encoding['ids']\n    test_type_ids[i] = encoding['token_type_ids']\n    test_mask[i] = encoding['mask']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = model.predict([test_ids, test_mask, test_type_ids], verbose = True)\npreds_start += preds[0]\npreds_end += preds[1] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor k in range(x_test.shape[0]):\n    \n    encoding = text_process(x_test.loc[k,'text'], x_test.loc[k,'sentiment'], tokenizer, max_len)\n    offsets = encoding['offsets']\n    targets_start = np.argmax(preds_start[k,])\n    targets_end = np.argmax(preds_end[k,])\n\n    pred = x_test.loc[k,'text'][offsets[targets_start][0]:offsets[targets_end][-1]]\n    submission.loc[k,'selected_text'] = pred\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}