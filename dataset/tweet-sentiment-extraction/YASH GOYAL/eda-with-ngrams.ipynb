{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(context=\"notebook\", style=\"darkgrid\", palette=\"deep\", font=\"sans-serif\", font_scale=1, color_codes=True)\nimport nltk\nfrom nltk import word_tokenize\nfrom nltk import ngrams\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"Train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\nTest = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\nSub = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Train.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Test.head(2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Sub.head(1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Example of Jaccard score\ndef jac(str1,str2):\n    a = set(str1.lower().split())\n    b= set(str2.lower().split())\n    c = a.intersection(b)\n    \n    d = float(len(c))/(len(a)+len(b)-len(c))\n    return d\n\nSentence_1 = 'Life well spent is life good'\nSentence_2 = 'Life is an art and it is good so far'\nSentence_3 = 'Life is good'\n\nprint(jac(Sentence_1,Sentence_2))\nprint(jac(Sentence_1,Sentence_3))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#### EDA\nprint(Train.shape)\nprint(Test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train  = Train.dropna()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(Train.isnull(),cmap=\"viridis\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"sentiment\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"sentiment\"].value_counts(normalize=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = Train[\"sentiment\"].value_counts(normalize=True)\nplt.pie(x,labels=x.index,autopct='%1.1f%%',explode = (0, 0.1,0.1))\nplt.title(\"Sentiment distribution\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"sentiment\",data=Train,order=Train[\"sentiment\"].value_counts().index)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(x=\"sentiment\",data=Test,order=Test[\"sentiment\"].value_counts().index)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\ndef clean_text(text):\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\ndef text_preprocessing(text):\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(remove_stopwords)\n    return combined_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"text_clean\"] = Train[\"text\"].astype(str).apply(lambda x: text_preprocessing(x))\nTest[\"text_clean\"] = Test[\"text\"].astype(str).apply(lambda x: text_preprocessing(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"original_text :\",Train[\"text\"].values[1])\nprint(\"cleaned_text :\",Train[\"text_clean\"].values[1])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"clean_sl_tx\"] = Train[\"selected_text\"].astype(str).apply(lambda x: text_preprocessing(x))\n\nprint(\"Original_selected_text :\", Train[\"selected_text\"].values[2])\nprint(\"cleaned_selected_text :\", Train[\"clean_sl_tx\"].values[2])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"text_len\"] = Train[\"text_clean\"].astype(str).apply(len)\nTrain[\"text_word_count\"] = Train['text_clean'].apply(lambda x: len(str(x).split()))  \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Train[\"text_len\"][1])\nprint(Train[\"text_word_count\"][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"sl_text_len\"]  = Train[\"clean_sl_tx\"].astype(str).apply(len)\nTrain[\"sl_text_word_count\"] = Train['clean_sl_tx'].apply(lambda x: len(str(x).split())) \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Train[\"sl_text_len\"][1])\nprint(Train[\"sl_text_word_count\"][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train[\"difference of length\"]  = Train[\"text_len\"] - Train[\"sl_text_len\"]\nTrain[\"Difference of word count\"] = Train[\"text_word_count\"] - Train[\"sl_text_word_count\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Train[\"difference of length\"][1])\nprint(Train[\"Difference of word count\"][1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(Train.groupby(\"sentiment\").count()[\"text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_data = Train[Train[\"sentiment\"]==\"positive\"]\nnegative_data = Train[Train[\"sentiment\"]==\"negative\"]\nneutral_data = Train[Train[\"sentiment\"]==\"neutral\"]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## text length analysis of training data\nfig = plt.figure(1, figsize=(10, 10))\nplt.hist(positive_data[\"text_len\"],bins=50,color=\"red\")\nplt.title(\"Positive text length distribution\")\nplt.xlabel(\"Text_length\")\nplt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(10, 10))\nplt.hist(negative_data[\"text_len\"],bins=50,color=\"green\")\nplt.title(\"negative_data text length distribution\")\nplt.xlabel(\"Text_length\")\nplt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(10, 10))\nplt.hist(neutral_data[\"text_len\"],bins=50,color=\"blue\")\nplt.title(\"neutral_data text length distribution\")\nplt.xlabel(\"Text_length\")\nplt.ylabel(\"Count\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kwargs = dict(hist_kws={'alpha':.4}, kde_kws={'linewidth':5})\nplt.figure(figsize=(10,7), dpi= 80)\nsns.distplot(positive_data[\"text_len\"], color=\"dodgerblue\", label=\"Positive\", **kwargs)\nsns.distplot(negative_data[\"text_len\"], color=\"orange\", label=\"Negative\", **kwargs)\nsns.distplot(neutral_data[\"text_len\"], color=\"deeppink\", label=\"Neutral\", **kwargs)\nplt.xlim(0,120)\nplt.legend()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Text word count analysis\nfig = plt.figure(1, figsize=(10, 10))\nplt.hist(positive_data[\"text_word_count\"],bins=20,color=\"red\")\nplt.title(\"Positive word count distribution\")\nplt.xlabel(\"word count\")\nplt.ylabel(\"Count\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(10, 10))\nplt.hist(negative_data[\"text_word_count\"],bins=20,color=\"green\")\nplt.title(\"negative_data word count distribution\")\nplt.xlabel(\"word count\")\nplt.ylabel(\"Count\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(10, 10))\nplt.hist(neutral_data[\"text_word_count\"],bins=20,color=\"blue\")\nplt.title(\"neutral_data word count distribution\")\nplt.xlabel(\"word count\")\nplt.ylabel(\"Count\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kwargs = dict(hist_kws={'alpha':.4}, kde_kws={'linewidth':5})\nplt.figure(figsize=(10,10), dpi= 80)\nsns.distplot(positive_data[\"text_word_count\"], color=\"dodgerblue\", label=\"Positive\", **kwargs)\nsns.distplot(negative_data[\"text_word_count\"], color=\"orange\", label=\"Negative\", **kwargs)\nsns.distplot(neutral_data[\"text_word_count\"], color=\"deeppink\", label=\"Neutral\", **kwargs)\nplt.xlim(0,20)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(10, 10))\nsns.boxplot(x=\"sentiment\",y=\"text_word_count\",data=Train)\nplt.title(\"Word count of text\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(1, figsize=(10, 10))\nsns.boxplot(x=\"sentiment\",y=\"text_len\",data=Train)\nplt.title(\"text length\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function for plotting Top 50 words of each category\nimport heapq\nfrom operator import itemgetter\nfrom collections import Counter\n\ndef Top50(data,title=None):\n    token_data= []\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    for i in data:\n        l = tokenizer.tokenize(i)\n        token_data.append(l)\n    corpus = []\n    for i in token_data:\n       for j in i:\n         corpus.append(j)\n    c = Counter(corpus)\n    Di = dict(c)\n    TOp_50 = dict(heapq.nlargest(50, Di.items(), key=itemgetter(1)))\n    dd = pd.DataFrame(TOp_50.items(),columns=[\"word\",\"frequency\"])\n    fig = plt.figure(1, figsize=(15, 15))\n    plt.bar(range(len(TOp_50)),TOp_50.values(),align='center')        \n    plt.xticks(range(len(TOp_50)), list(TOp_50.keys()))\n    plt.tick_params(axis=\"x\",rotation=90) \n    if title==None:\n        plt.title(\"Top 50 words\")\n    else:\n        plt.title(title)\n    return dd.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top50(positive_data[\"text_clean\"],title=\"Top 50 Positive words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top50(negative_data[\"text_clean\"],title=\"Top 50 negative words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top50(neutral_data[\"text_clean\"],title=\"Top 50 Neutral words\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top50(Train[\"text_clean\"],title=\"most common words in whole data\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function for plotting Ngrams\ndef Ngram(data,num,title=None):\n    token_data= []\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    for i in data:\n        n_grams = ngrams(tokenizer.tokenize(i), num)\n        p = [ ' '.join(grams) for grams in  n_grams]\n        token_data.append(p)\n    corpus = []\n    for i in token_data:\n       for j in i:\n         corpus.append(j)\n    c = Counter(corpus)\n    Di = dict(c)\n    TOp_50 = dict(heapq.nlargest(50, Di.items(), key=itemgetter(1)))\n    fig = plt.figure(1, figsize=(12, 12))\n    plt.bar(range(len(TOp_50)),TOp_50.values(),align='center')        \n    plt.xticks(range(len(TOp_50)), list(TOp_50.keys()))\n    plt.tick_params(axis=\"x\",rotation=90) \n    \n    if title == None:\n        plt.title(\"Ngram\")\n    else:\n        plt.title(title)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Biagram\nNgram(positive_data[\"text_clean\"],2,title=\"Bigram of Positive Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ngram(negative_data[\"text_clean\"],2,title=\"Bigram of Negative Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ngram(neutral_data[\"text_clean\"],2,title=\"Bigram of Neutral Tweets\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## trigram\nNgram(positive_data[\"text_clean\"],3,title=\"Trigram of Positive Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ngram(negative_data[\"text_clean\"],3,title=\"Trigram of Negative Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Ngram(neutral_data[\"text_clean\"],3,title=\"Trigram of Neutral Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"### Wordcloud\nfrom wordcloud import WordCloud\ndef show_wordcloud(data,title=None):\n    if title == None:\n        fig = plt.figure(1, figsize=(12, 12))\n        plt.title(\"Wordclud\")\n    else :\n        fig = plt.figure(1, figsize=(12, 12))\n        plt.title(title)\n    wordcloud = WordCloud(background_color='white',max_font_size=60,max_words=2000, random_state=1,width=600,height=400).generate(str(data))\n    plt.axis('off')\n    plt.imshow(wordcloud,interpolation=\"bilinear\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(Train[\"text_clean\"],title=\"whole data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(Train.loc[Train[\"sentiment\"]==\"positive\",\"text_clean\"],title=\"Positive wordcloud\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(Train.loc[Train[\"sentiment\"]==\"negative\",\"text_clean\"],title=\"Negative wordcloud\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(Train.loc[Train[\"sentiment\"]==\"neutral\",\"text_clean\"],title=\"Neutral wordcloud\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Gonna deal with selected text\nTop50(positive_data[\"clean_sl_tx\"],title=\"most common positive words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top50(negative_data[\"clean_sl_tx\"],title=\"most common negative words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top50(neutral_data[\"clean_sl_tx\"],title=\"most common neutral words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Top50(Train[\"clean_sl_tx\"],title=\"most common selected words in whole data\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kwargs = dict(hist_kws={'alpha':.4}, kde_kws={'linewidth':5})\nplt.figure(figsize=(10,7), dpi= 80)\nsns.distplot(positive_data[\"sl_text_len\"], color=\"dodgerblue\", label=\"Positive\", **kwargs)\nsns.distplot(negative_data[\"sl_text_len\"], color=\"orange\", label=\"Negative\", **kwargs)\nsns.distplot(neutral_data[\"sl_text_len\"], color=\"deeppink\", label=\"Neutral\", **kwargs)\nplt.xlim(0,100)\nplt.legend()\nplt.title(\"selected text length distribution\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"kwargs = dict(hist_kws={'alpha':.5}, kde_kws={'linewidth':3})\nplt.figure(figsize=(10,7), dpi= 80)\nsns.distplot(positive_data[\"sl_text_word_count\"], color=\"dodgerblue\", label=\"Positive\", **kwargs)\nsns.distplot(negative_data[\"sl_text_word_count\"], color=\"orange\", label=\"Negative\", **kwargs)\nsns.distplot(neutral_data[\"sl_text_word_count\"], color=\"deeppink\", label=\"Neutral\", **kwargs)\nplt.xlim(0,15)\nplt.legend()\nplt.title(\"Selected text word count distribution\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(Train[\"text_len\"],shade=True,color=\"r\")\nsns.kdeplot(Train[\"sl_text_len\"],shade=True,color=\"b\")\nplt.xlabel(\"length of text\")\nplt.title(\"length distribution\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.kdeplot(Train[\"text_word_count\"],shade=True,color=\"r\")\nsns.kdeplot(Train[\"sl_text_word_count\"],shade=True,color=\"b\")\nplt.xlabel(\"Word count\")\nplt.title(\"Word count distribution\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"sentiment\",y=\"sl_text_word_count\",data=Train)\nplt.title(\"Selected text word count\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.boxplot(x=\"sentiment\",y=\"sl_text_len\",data=Train)\nplt.title(\"selected text length\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jaccard_score = []\nfor i,j in Train.iterrows():\n    str1 = j.text\n    str2 = j.selected_text\n    \n    JC_score = round(jac(str1,str2),2)\n    jaccard_score.append(JC_score)\n\nTrain[\"Jaccard_score\"] = jaccard_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"jc_0 = Train[Train[\"Jaccard_score\"]==0]\njc_1 = Train[Train[\"Jaccard_score\"]==1]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(jc_0.shape)\nprint(jc_1.shape)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}