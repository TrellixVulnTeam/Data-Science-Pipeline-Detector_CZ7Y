{"cells":[{"metadata":{"id":"-Q_2gSfsfiL5","trusted":false},"cell_type":"code","source":"# !pip install -U -q kaggle\n# !mkdir -p ~/.kaggle\n# !echo '{\"username\":\"sidhsatam\",\"key\":\"846c7036c3ab10803db8e808150818ec\"}' > ~/.kaggle/kaggle.json\n# !chmod 600 ~/.kaggle/kaggle.json","execution_count":0,"outputs":[]},{"metadata":{"id":"jknirkVvfTjW","outputId":"38196636-e37a-475f-a943-e64ce707ec49","trusted":false},"cell_type":"code","source":"# !kaggle competitions download -c tweet-sentiment-extraction","execution_count":null,"outputs":[]},{"metadata":{"id":"WcUYWxo6f5qq","outputId":"41f58a37-b8e1-4f9e-b548-a24dc72d8838","trusted":false},"cell_type":"code","source":"# !unzip /content/train.csv.zip","execution_count":null,"outputs":[]},{"metadata":{"id":"-D22utLLRJGt","outputId":"ba98d362-60a9-4da0-a713-2d3a74a6b42a","trusted":false},"cell_type":"code","source":"# !pip install vaderSentiment","execution_count":null,"outputs":[]},{"metadata":{"id":"FR5cM63XVjoV","outputId":"684d4275-a8a6-4a89-8a69-d0dd4c661b8b","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport nltk\nimport re \nfrom nltk import ngrams \nfrom textblob import TextBlob\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.tokenize import word_tokenize\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{"id":"dL5aYngNWKdS","outputId":"7abe0b04-a7ec-4256-c470-bbbf9f0c7f46","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"KehRtz04DZ6c","outputId":"06957a3a-253b-4a19-d7df-06b8ddcf9ae1","trusted":true},"cell_type":"code","source":"test = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")","execution_count":null,"outputs":[]},{"metadata":{"id":"rAmgt05IazGJ","trusted":true},"cell_type":"code","source":"train['text'] = train['text'].astype(str) \ntest['text'] = test['text'].astype(str) ","execution_count":null,"outputs":[]},{"metadata":{"id":"To1yZhygeJyM","trusted":true},"cell_type":"code","source":"analyzer = SentimentIntensityAnalyzer()\npos = []\nneg = []\nfor index, row in train.iterrows():\n  senti = row['sentiment']\n  if row['text'] == row['selected_text']:\n    vs = analyzer.polarity_scores(row['text'])\n    if senti=='positive' and vs['compound']>=0.05:\n      pos.append(vs['compound'])\n    elif senti=='negative' and vs['compound']<=-0.05:\n      neg.append(vs['compound'])","execution_count":null,"outputs":[]},{"metadata":{"id":"nt-paNTyglyy","trusted":true},"cell_type":"code","source":"min_pos = sum(pos)/len(pos)\nmax_neg = sum(neg)/len(neg)","execution_count":null,"outputs":[]},{"metadata":{"id":"YMYRilOqcsDW","trusted":true},"cell_type":"code","source":"def answer(row):\n    cleantext = re.sub('http[s]?://\\S+', '', row['text'])\n    analyzer = SentimentIntensityAnalyzer()\n    senti = row['sentiment']\n    t_pol = analyzer.polarity_scores(cleantext)['compound']\n    if (t_pol>min_pos and senti=='positive') or (t_pol<max_neg and senti=='negative') or senti=='neutral':\n        return cleantext\n    elif (t_pol>0.05 and senti=='positive') or (t_pol<-0.05 and senti=='negative'):\n        best_grams = []\n        best_scores = []\n        for i in range(1, len(word_tokenize(cleantext)), 2):\n            words = word_tokenize(cleantext)\n            no_grams = i\n            grams = [words[i:i+no_grams] for i in range(len(words)-no_grams+1)]\n            gramslist = []\n            for gram in grams:\n                ngram = ' '.join(gram)\n                gramslist.append(ngram)\n        \n            for gram in gramslist:\n                gram_pol = analyzer.polarity_scores(gram)['compound']\n                if abs(gram_pol) >= abs(t_pol):\n                    best_grams.append(gram)\n                    best_scores.append(abs(gram_pol))\n        try:\n            flag = 0\n            return best_grams[np.argmax(best_scores)]\n        except:\n            flag = 1\n\n    if (t_pol<0.05 and senti=='positive') or (t_pol>-0.05 and senti=='negative') or flag==1:\n        words = word_tokenize(cleantext)\n        if senti == 'positive':\n            scores = []\n            for word in words:\n                scores.append(analyzer.polarity_scores(word)['compound'])\n            \n            return words[np.argmax(scores)]\n            \n        elif senti == 'negative':\n            scores = []\n            for word in words:\n                scores.append(analyzer.polarity_scores(word)['compound'])\n            \n            return words[np.argmin(scores)]","execution_count":null,"outputs":[]},{"metadata":{"id":"1gAEJSmpiBJu","trusted":true},"cell_type":"code","source":"test['selected_text'] = test.apply(answer, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"id":"gAo-2MqF6Pc9","trusted":true},"cell_type":"code","source":"final = test[['textID', 'selected_text']]","execution_count":null,"outputs":[]},{"metadata":{"id":"BNehkgyhjHvl","trusted":true},"cell_type":"code","source":"final.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"Copy of nlp m3.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"nbformat":4,"nbformat_minor":4}