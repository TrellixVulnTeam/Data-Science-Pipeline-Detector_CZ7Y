{"cells":[{"metadata":{"id":"PsHiwN6O9Njb"},"cell_type":"markdown","source":"# Sentiment Extraction -- Assign Weights & Select Most Important Words"},{"metadata":{},"cell_type":"markdown","source":"\n                                Count           Logistic\n                                Vectorizer      Regression\n\n    +----------------------+   +-----------+   +-----------+         +------------+\n    | Features  |  Targets |   |           |   |           |  word   |    Most    |\n    +----------------------+-->| Vectorizer|-->| Classifier|-------->| important  |\n    | Tweets    | Sentiment|   |           |   |           | weights |    words   |\n    +----------------------+   +-----------+   +-----------+         +------------+\n"},{"metadata":{"id":"xBl0mF1tO6LB","trusted":true},"cell_type":"code","source":"import os\nfrom time import time\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.base import BaseEstimator, TransformerMixin\n\nimport warnings\nwarnings.simplefilter(action='ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"r4LDmfUEO6LH","trusted":true},"cell_type":"code","source":"# config\nDATA_DIR = '../input/tweet-sentiment-extraction'\nTRAIN_DATA_FILE = 'train.csv'\nTEST_DATA_FILE = 'test.csv'\nSUBMISSION_FILE = 'submission.csv'\n\nRANDOM_STATE = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"7CdW7nVrZYJH"},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"id":"zWPPnCj0O6LK","scrolled":true,"trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(os.path.join(DATA_DIR, TRAIN_DATA_FILE)).fillna('')\ntest_data = pd.read_csv(os.path.join(DATA_DIR, TEST_DATA_FILE)).fillna('')","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":2356,"status":"ok","timestamp":1587659704808,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"gdFQ315wF-Ej","outputId":"a892408e-f896-4700-b8d5-32bd3d76f538","trusted":true},"cell_type":"code","source":"train_data = train_data[['textID', 'text', 'sentiment', 'selected_text']]\ntrain_data[17:22]","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1356,"status":"ok","timestamp":1587659708501,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"3SBkKC8TGDV8","outputId":"0d489b48-7821-4f0a-c59f-a94e0d3b9318","trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"KYOxxuvqX3W-"},"cell_type":"markdown","source":"## Text-Sentiment Classification Model"},{"metadata":{"id":"W5bkupWJIgR0","trusted":true},"cell_type":"code","source":"def create_model():\n    clf = Pipeline([\n        ('vect', CountVectorizer(tokenizer=lambda x: x.split())\n        ),\n        ('clf', LogisticRegression(\n                                   max_iter=1000,\n                                   random_state=RANDOM_STATE\n                                  )\n        )\n    ])\n    return clf\n\nX = pd.concat([train_data['text'], test_data['text']], axis=0)\nY = pd.concat([train_data['sentiment'], test_data['sentiment']], axis=0)\nY = Y.map({'negative': -1, 'positive': 1, 'neutral': 0})\nprint(X.shape, Y.shape)\n\nmodel = create_model()\n\nmodel.fit(X, Y)\n\npred = model.predict(X)\nprint(classification_report(y_true=Y, y_pred=pred))","execution_count":null,"outputs":[]},{"metadata":{"id":"E3TJyEV5YSkC"},"cell_type":"markdown","source":"## Grid Search for Text-Sentiment Classifier"},{"metadata":{"id":"Xlrzrem7TRT3","trusted":true},"cell_type":"code","source":"# Grid search with CV doesn't seem to make sense here because the model\n# is not used to make predictions on the test data\n# parameters = {\n#     'clf__C': [0.001, 0.009, 0.01, 0.09, 1, 5, 10, 25],\n#     'clf__class_weight': [None, 'balanced']\n# }\n\n# gs_clf = GridSearchCV(model,\n#                       parameters,\n#                       cv=5,\n#                       verbose=2,\n#                       n_jobs=-1\n#                      )\n\n# gs_clf = gs_clf.fit(X, Y)\n\n# gs_clf.best_params_","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Word Selector Model\n\nImplementing the word selection process as a custom estimator class allows using GridSearchCV to find best parameters "},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"VOCAB = model.named_steps['vect'].vocabulary_\nCOEF = model.named_steps['clf'].coef_\n\nclass WordSelector(BaseEstimator, TransformerMixin):\n    \"\"\"Provide a class to select words supporing the sentiment.\"\"\"\n    \n    def __init__(self, pos_class_std=2.2, neg_class_std=2.2):\n        # number of standard deviations to select words \n        # with unusual weights from a tweet\n        self.pos_class_std = pos_class_std\n        self.neg_class_std = neg_class_std\n        \n        self.vocabulary_ = VOCAB  # word vocab from CountVectorizer\n        self.coef_ = COEF         # word importance weight from LogRegression\n        \n        self.weights_by_classes = {\n            'negative': list(enumerate(self.coef_[0])),\n            'neutral':  list(enumerate(self.coef_[1])),\n            'positive': list(enumerate(self.coef_[2]))\n        }\n        \n        # Translation dict from vocab indexes to words\n        # Only used for plotting\n        self.index_to_word = {\n            ind: word\n            for (word, ind)\n            in self.vocabulary_.items()\n            }\n    \n    ##### PLOTTING-RELATED METHODS###############################\n    def get_words_from_idx(self, indexes):\n        \"\"\"Return a list of words from indexes for plotting.\"\"\"\n        return [self.index_to_word[index] for index in indexes]\n\n    \n    def plot_top_features(self, class_label, max_top_feat):\n        \"\"\"Plot a bar chart of top features for a given label.\"\"\"\n        idx_coef_list = sorted(self.weights_by_classes[class_label],\n                               key=lambda pair: pair[1], \n                               reverse=True\n                              )\n        idx, coef = zip(*idx_coef_list)\n        top_words = self.get_words_from_idx(idx[:max_top_feat])\n        plt.figure(figsize=(12,4))\n        plt.bar(top_words, coef[:max_top_feat])\n        plt.title(f'Top-{max_top_feat} features in category {class_label}')\n        plt.xlabel('Features')\n        plt.ylabel('Weights')\n        plt.xticks(rotation = '45')\n        plt.show()\n    ############################################################\n    \n    \n    def get_weights(self, text_list, class_weights):\n        \"\"\"Return a list of weights for text.\"\"\"\n        text_idx = [self.vocabulary_[tok] for tok in text_list]\n\n        return [class_weights[idx][1] for idx in text_idx]\n\n    def get_top_words(self, words_list, weights_list, num_std):\n        \"\"\"Return a string of words with unusually high weights.\"\"\"\n        mean = np.mean(weights_list)\n        std = np.std(weights_list)\n        top_words = []\n        for word, weight in zip(words_list, weights_list):\n            if weight > (mean +  num_std * std):\n                top_words.append(word)\n        return ' '.join(top_words)\n\n\n    def select_words(self, text_sentiment):\n        \"\"\"Select words given sentiment label by calling get_top_words().\"\"\"\n        text, sentiment = text_sentiment\n\n        if sentiment == 'neutral':\n            return text\n\n        text = text.lower().split()\n        weights = self.get_weights(text,\n                              self.weights_by_classes[sentiment]  \n                             )\n\n        if sentiment == 'positive':\n            res = self.get_top_words(text, weights, num_std=self.pos_class_std)\n\n        if sentiment == 'negative':\n            res = self.get_top_words(text, weights, num_std=self.neg_class_std)\n\n        if res == '':\n            res = ' '.join(text)\n\n        return res\n    \n    def fit(self, X, y=None):\n        return self\n    \n    def predict(self, X):\n        \"\"\"Return predicted 'selected_text' as a Pandas series.\n        \n        X: Pandas dataframe with columns 'text', sentiment'\n        \"\"\"\n\n        res = pd.DataFrame()\n        res['sentiment'] = X['sentiment']\n        res['text'] = X['text'].map(lambda s: s.lower())\n        res['selected_text'] = X[['text', 'sentiment']].apply(self.select_words, axis=1)\n\n        return res['selected_text']\n    \n    def jaccard(self, predicted_selected):\n        \"\"\"Provide an evaluation metric.\n        \n        predicted_selected: a tuple (predicted text, true selected text)\n        \"\"\"\n        str1, str2 = predicted_selected\n        a = set(str1.lower().split()) \n        b = set(str2.lower().split())\n        if (len(a) == 0) & (len(b) == 0):\n            return 0.5\n        c = a.intersection(b)\n        return float(len(c)) / (len(a) + len(b) - len(c))\n\n    def score(self, X, y):\n        \"\"\"Return a mean Jaccard score.\n        \n        X: Pandas dataframe with columns 'text', sentiment'\n        y: Pandas series containing true 'selected_text'\n        \"\"\"\n        \n        res = pd.DataFrame()\n        \n        res['selected_text'] = y\n        res['sentiment'] = X['sentiment']\n        res['text'] = X['text']\n\n        res['predictions'] = self.predict(res[['text', 'sentiment']])\n        \n        res['score'] = res[['predictions', 'selected_text']].apply(self.jaccard, axis=1)\n\n        return res['score'].mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_selector = WordSelector(pos_class_std=1.8, neg_class_std=2.4)\n\nprint('Jaccard score for training data:')\nword_selector.score(train_data[['text', 'sentiment']], train_data['selected_text'])\n\n# [0. , 0.8, 1.6, 2.4, 3.2, 4. ]\n# pos_class_std=1.6, neg_class_std=2.4\n# 0.6535060973409171\n\n# [1. , 1.4, 1.8, 2.2, 2.6, 3. ]\n# {'neg_class_std': 2.2, 'pos_class_std': 1.8}\n# 0.6552466246349189\n\n#     'pos_class_std': [1.6, 1.7, 1.8, 1.9],  \n#     'neg_class_std': [2.1, 2.2, 2.3, 2.4]\n# {'neg_class_std': 2.4, 'pos_class_std': 1.8}\n# 0.6553365154317554","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Jaccard score by sentiment\ntemp_df = pd.DataFrame()\ntemp_df['sentiment'] = train_data['sentiment']\ntemp_df['text'] = train_data['text']  #.map(lambda s: s.lower())\n\ntemp_df['predicted_text'] = word_selector.predict(train_data[['text', 'sentiment']])\n\ntemp_df['selected_text'] = train_data['selected_text']\n\ntemp_df['score'] = temp_df[['predicted_text', 'selected_text']].apply(word_selector.jaccard, axis=1)\n\nprint('Jaccard score by sentiment:')\nprint(temp_df.groupby('sentiment')['score'].mean())\nprint('\\nTotal score:', temp_df['score'].mean())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sentiment in ['negative', 'neutral', 'positive']:\n    word_selector.plot_top_features(sentiment, 20)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Grid Search for Word Selector Model"},{"metadata":{"scrolled":true,"trusted":true},"cell_type":"code","source":"# print('Performing GridSearch for WordSelect parameters...')\n# parameters = {\n#     'pos_class_std': [1.6, 1.7, 1.8, 1.9],  \n#     'neg_class_std': [2.1, 2.2, 2.3, 2.4]\n# }\n\n# gs = GridSearchCV(WordSelector(\n#                               ),\n#                   parameters,\n#                   cv=5,\n#                   verbose=1,\n#                   n_jobs=-1\n#                  )\n\n\n# gs = gs.fit(train_data[['text', 'sentiment']], train_data['selected_text'])\n\n# gs.best_params_","execution_count":null,"outputs":[]},{"metadata":{"id":"kMYVgbzyZERg"},"cell_type":"markdown","source":"## Kaggle submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"submission_df = pd.DataFrame() \nsubmission_df['textID'] = test_data['textID']\n\nsubmission_df['selected_text']= word_selector.predict(test_data[['text', 'sentiment']])\nsubmission_df.to_csv(SUBMISSION_FILE, index = False)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":553,"status":"ok","timestamp":1587660976733,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"by6UrCKcMqbP","outputId":"9e4cd02c-6ceb-41db-a828-c46a4591c7a8","trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth', 80)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":496,"status":"ok","timestamp":1587660976737,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"u3q_M5RRTdcF","outputId":"c123fc3f-c464-4c09-f8a5-68166f7271a8","trusted":true},"cell_type":"code","source":"submission_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Length Distributions -- True and Predicted Substrings in Training Data & Predicted Substrings in Testing Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(train_data['selected_text'].map(len), alpha=0.8, bins=40)\nplt.title('Distribution of Lengths of TRUE Substrings in Training Data')\nplt.xlabel('Char length')\nplt.ylabel('How often')\nplt.show()\n\nplt.hist(temp_df['predicted_text'].map(len), alpha=0.8, bins=40)\nplt.title('Distribution of Lengths of PREDICTED Substrings in Training Data')\nplt.xlabel('Char length')\nplt.ylabel('How often')\nplt.show()\n\nplt.hist(submission_df['selected_text'].map(len), alpha=0.8, bins=40)\nplt.title('Distribution of Lengths of PREDICTED Substrings in Testing Data')\nplt.xlabel('Char length')\nplt.ylabel('How often')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"zJy_wbPkTfCK","trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ml_fasttext_skf.ipynb","provenance":[{"file_id":"185PsLtnlsIdTe9SAMgdVLbaWKetjxtxr","timestamp":1587544419206}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}