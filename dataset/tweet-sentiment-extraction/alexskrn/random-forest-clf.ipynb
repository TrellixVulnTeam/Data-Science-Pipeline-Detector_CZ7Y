{"cells":[{"metadata":{"id":"PsHiwN6O9Njb"},"cell_type":"markdown","source":"# Sentiment Extraction -- Random Forest Classification"},{"metadata":{"id":"K_j2qL5i4x_g"},"cell_type":"markdown","source":"       Input                    Random    Predictions\n       FastText                 Forest\n       Embedding      Merge               \n    +----------+      inputs    +-----+  +---------+\n    |   tweets |----+        +->| RF_1|->|start_idx|\n    +----------+    |        |  +-----+  +---------+\n    vecs (200,1)  +--------+ |  \n                  | concat |-+ \n                  +--------+ |  \n    +----------+    |        |  +-----+  +---------+\n    |sentiments|----+        +->| RF_1|->|end_idx  |\n    +----------+                +-----+  +---------+\n    vecs (200,1)\n\n   get_embedding('neutral', fast_text, 200)[:20]\n\n   array([ 0.0182893 ,  0.21087576, -0.0981252 , -0.56553006, -0.05680547,\n        0.25680679,  0.26141363, -0.51580322,  0.13086239, ....])"},{"metadata":{"id":"xBl0mF1tO6LB","trusted":true},"cell_type":"code","source":"import os\nfrom time import time\n\nimport pandas as pd\nimport numpy as np\n\n# for classification\nfrom sklearn.ensemble import RandomForestClassifier\n\n# for cross validation\nfrom sklearn.model_selection import StratifiedKFold\n# for searching for best params\nfrom sklearn.model_selection import GridSearchCV\n\n# for FastText vectorization\nimport gensim\n\nimport warnings\nwarnings.simplefilter(action='ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"r4LDmfUEO6LH","trusted":true},"cell_type":"code","source":"# config\nDATA_DIR = '../input/tweet-sentiment-extraction'\nTRAIN_DATA_FILE = 'train.csv'\nTEST_DATA_FILE = 'test.csv'\nSUBMISSION_FILE = 'submission.csv'\n\nRANDOM_STATE = 0","execution_count":null,"outputs":[]},{"metadata":{"id":"7CdW7nVrZYJH"},"cell_type":"markdown","source":"## Load Data"},{"metadata":{"id":"zWPPnCj0O6LK","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(os.path.join(DATA_DIR, TRAIN_DATA_FILE)).fillna('')\ntest_data = pd.read_csv(os.path.join(DATA_DIR, TEST_DATA_FILE)).fillna('')","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":2356,"status":"ok","timestamp":1587659704808,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"gdFQ315wF-Ej","outputId":"a892408e-f896-4700-b8d5-32bd3d76f538","trusted":true},"cell_type":"code","source":"train_data = train_data[['textID', 'text', 'sentiment', 'selected_text']]\ntrain_data[17:22]","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":1356,"status":"ok","timestamp":1587659708501,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"3SBkKC8TGDV8","outputId":"0d489b48-7821-4f0a-c59f-a94e0d3b9318","trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"id":"Kczy91anZbCb"},"cell_type":"markdown","source":"## Target Columns"},{"metadata":{"executionInfo":{"elapsed":805,"status":"ok","timestamp":1587659715760,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"bjQSMsBGO6LS","outputId":"bbc63036-edb5-432a-f001-8576b3871a40","trusted":true},"cell_type":"code","source":"# create 2 target columns for 2 models \nstarts = []\nends = []\nfor text, selected_text in zip(train_data['text'], train_data['selected_text']):\n  start = text.find(selected_text)\n  starts.append(start)\n  ends.append(start + len(selected_text))\n\ntrain_data['start_idx'] = starts\ntrain_data['end_idx'] = ends\n\ntrain_data.head(3)","execution_count":null,"outputs":[]},{"metadata":{"id":"sl3aub7VZnDi"},"cell_type":"markdown","source":"## FastText Vectorization Model"},{"metadata":{"executionInfo":{"elapsed":40831,"status":"ok","timestamp":1587659774678,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"wV0HTXc9y_rf","outputId":"74ae2a21-ff8c-41f8-b4f7-b7914bc00922","scrolled":true,"trusted":true},"cell_type":"code","source":"DIM = 200  # vector size\nprint('Creating corpus for FastText model...')\nt0 = time()\ncorpus = [text.lower().split() for text in train_data['text']]\ncorpus.extend([text.lower().split() for text in test_data['text']])\ncorpus.extend(train_data['sentiment'].unique().tolist())\nprint(f'Done in {time() - t0} seconds')\n\nprint('Building FastText model from corpus...')\nt0 = time()\nfast_text = gensim.models.FastText(corpus, size=DIM, min_count=1, min_n=1)\nprint(f'Done in {time() - t0} seconds')","execution_count":null,"outputs":[]},{"metadata":{"id":"Z8y_2dwPy_rt","trusted":true},"cell_type":"code","source":"# source: https://github.com/nstsj/compling_nlp_hse_course/blob/master/notebooks/Embeddings.ipynb\ndef get_embedding(text, model, dim):\n    \"\"\"Return FastText embeddings.\"\"\"\n    from collections import Counter\n    text = text.lower().split()\n    # text = text.split()\n    \n    words = Counter(text)\n    total = len(text)\n    vectors = np.zeros((len(words), dim))\n    \n    for i,word in enumerate(words):\n        try:\n            v = model[word]\n            vectors[i] = v*(words[word]/total)\n        except (KeyError, ValueError):\n            raise\n            # continue\n    \n    if vectors.any():\n        vector = np.average(vectors, axis=0)\n    else:\n        vector = np.zeros((dim))\n    \n    return vector","execution_count":null,"outputs":[]},{"metadata":{"id":"XeASddvZXtCh"},"cell_type":"markdown","source":"## Training Data"},{"metadata":{"executionInfo":{"elapsed":6323,"status":"ok","timestamp":1587659795982,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"cGdR6_yr0KY1","outputId":"87a867cc-88e3-4a3d-e70b-f0864f97af54","trusted":true},"cell_type":"code","source":"print('Create embeddings for \\'text\\' ...')\nX_text_ft = np.zeros((train_data.shape[0], DIM))\n\nt0 = time()\nfor i, text in enumerate(train_data['text'].values):\n    X_text_ft[i] = get_embedding(text, fast_text, DIM)\nprint(f'Done in {time() - t0} seconds')\n\nX_sentiment_ft = np.zeros((train_data.shape[0], DIM))\n\nprint('... and \\'sentiment\\' columns in train data')\nt0 = time()\nfor i, text in enumerate(train_data['sentiment'].values):\n    X_sentiment_ft[i] = get_embedding(text, fast_text, DIM)\nprint(f'Done in {time() - t0} seconds')\n\nprint(X_text_ft.shape, X_sentiment_ft.shape)\n\nprint('Concatenated text and sentiment vectors:')\ntrain_data_ft = np.concatenate([X_text_ft, X_sentiment_ft], axis=1)\nprint(train_data_ft.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"qPIF4yF0XlLz"},"cell_type":"markdown","source":"## Testing Data"},{"metadata":{"executionInfo":{"elapsed":1483,"status":"ok","timestamp":1587659808933,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"uLiy9lToXi15","outputId":"9e5b0b53-8805-4333-b2d6-3080db6db4a7","trusted":true},"cell_type":"code","source":"print('Create embeddings for \\'text\\' ...')\ntext_ft = np.zeros((test_data.shape[0], DIM))\n\nt0 = time()\nfor i, text in enumerate(test_data['text'].values):\n    text_ft[i] = get_embedding(text, fast_text, DIM)\nprint(f'Done in {time() - t0} seconds')\n\nprint('... and \\'sentiment\\' columns in test data')\nsentiment_ft = np.zeros((test_data.shape[0], DIM))\n\nt0 = time()\nfor i, text in enumerate(test_data['sentiment'].values):\n    sentiment_ft[i] = get_embedding(text, fast_text, DIM)\nprint(f'Done in {time() - t0} seconds')\n\nprint(text_ft.shape, sentiment_ft.shape)\n\nprint('Concatenated text and sentiment vectors:')\nkaggle_test_ft = np.concatenate([text_ft, sentiment_ft], axis=1)\nprint(kaggle_test_ft.shape)","execution_count":null,"outputs":[]},{"metadata":{"id":"KYOxxuvqX3W-"},"cell_type":"markdown","source":"## Models"},{"metadata":{"id":"W5bkupWJIgR0","trusted":true},"cell_type":"code","source":"# Build models\ndef create_model_starts():\n    clf = RandomForestClassifier(\n        max_depth=20,\n        min_samples_leaf=2,\n        min_samples_split=2,\n        n_estimators=50,\n        random_state=RANDOM_STATE\n        )\n    return clf\n\ndef create_model_ends():\n    clf = RandomForestClassifier(\n        n_estimators=50,\n        max_depth=20,\n        min_samples_leaf=17,\n        min_samples_split=2,\n        random_state=RANDOM_STATE\n        )\n    return clf","execution_count":null,"outputs":[]},{"metadata":{"id":"E3TJyEV5YSkC"},"cell_type":"markdown","source":"## Grid Search"},{"metadata":{"id":"Xlrzrem7TRT3","trusted":true},"cell_type":"code","source":"# # Grid Search for Models\n# params = {\n#     'n_estimators': [20, 50, 80, 120],\n#     'max_depth': [7, 20, None],\n#     'min_samples_leaf': [2, 10, 17, 25],\n#     'min_samples_split': [2, 3],\n#     'class_weight': [None, 'balanced']\n# }\n\n# starts_model = create_model_starts()\n# print('Searching for best params for StartsModel...')\n# gs_starts = GridSearchCV(starts_model,\n#                          params,\n#                          cv=5,\n#                          verbose=2,\n#                          n_jobs=-1\n#                          )\n\n# t0 = time()\n# gs_starts.fit(train_data_ft, train_data['start_idx'])\n# print(f'Done in {time() - t0} seconds')\n\n# print('Best parameters for StartsModel')\n# print(gs_starts.best_params_)\n# # # # {'clf__C': 0.001, 'clf__class_weight': None, 'reduce__n_components': 2}\n\n# # # 'Done in 2589.2142584323883 seconds' LOG_REG\n# # # {'clf__C': 0.001, 'clf__class_weight': None}\n\n\n# # 'Done in 9542.264384746552 seconds'\n# # {'clf__max_depth': 20,\n# #  'clf__min_samples_leaf': 2,\n# #  'clf__min_samples_split': 2,\n# #  'clf__n_estimators': 50}\n\n# ends_model = create_model_ends()\n# print('Searching for best params for EndssModel...')\n# gs_ends = GridSearchCV(ends_model,\n#                        params,\n#                        cv=5,\n#                        verbose=2,\n#                        n_jobs=-1\n#                        )\n\n# t0 = time()\n# gs_ends.fit(train_data_ft, train_data['end_idx'])\n# print(f'Done in {time() - t0} seconds')\n\n# print('Best parameters for StartsModel')\n# print(gs_ends.best_params_)","execution_count":null,"outputs":[]},{"metadata":{"id":"4or6q1ErX95x"},"cell_type":"markdown","source":"## Evaluation Metric"},{"metadata":{"id":"eb6neukVO6Lk","trusted":true},"cell_type":"code","source":"def jaccard(top_selected):\n    str1, str2 = top_selected\n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    if (len(a) == 0) & (len(b) == 0):\n        return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"id":"GfflyDRlYA_M"},"cell_type":"markdown","source":"## Evaluate Models"},{"metadata":{"executionInfo":{"elapsed":397787,"status":"ok","timestamp":1587660874566,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"mXeXQcNSJkgc","outputId":"6f1561b2-3860-45a1-a7f6-a83cbcd6ddce","trusted":true},"cell_type":"code","source":"import warnings\nwarnings.simplefilter(action='ignore')\n\njac = []  # container for Jaccard scores per fold\n\nskf = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n\n# five-fold cross validation\nfor fold, (train_idx, test_idx) in enumerate(skf.split(train_data['text'], train_data['sentiment'])):\n    \n    print(f'>>> FOLD {fold + 1}')\n\n    print('Training model 1...')\n    model_starts = create_model_starts()\n    t0 = time()\n    model_starts.fit(train_data_ft[train_idx], train_data['start_idx'].loc[train_idx])\n    print(f'Done in {time() - t0} seconds')\n\n    print('Training model 2...')\n    model_ends = create_model_ends()\n    t0 = time()\n    model_ends.fit(train_data_ft[train_idx], train_data['end_idx'].loc[train_idx])\n    print(f'Done in {time() - t0} seconds')\n\n    # Predict, evaluate\n    print('Evaluating...')\n    res = pd.DataFrame()\n    res['pred_starts'] = model_starts.predict(train_data_ft[test_idx])  # predict starts\n    res['pred_ends'] = model_ends.predict(train_data_ft[test_idx])      # predict ends\n    \n    columns = ['text', 'sentiment', 'selected_text']\n    res[columns] = train_data[columns].loc[test_idx].reset_index(drop=True)\n\n    # res['pred_select'] = res[['text', 'pred_starts', 'pred_ends']].apply(slice_text, axis=1)\n    res['pred_select'] = res[['text', 'pred_starts', 'pred_ends']].apply(lambda x: x[0][x[1]:x[2]], axis=1)\n    # Handle cases where start >= end\n    condition = res['pred_starts'] >= res['pred_ends']\n    res.loc[:, 'pred_select'][condition] = res.loc[:, 'text'][condition]\n\n    res['score'] = res[['pred_select', 'selected_text']].apply(jaccard, axis=1)\n\n    print(res.groupby('sentiment')['score'].mean())\n    mean_jac = res['score'].mean()\n    print(f\"Mean score in Fold {fold + 1}: {mean_jac}\")\n\n    jac.append(mean_jac)\n\ntotal_score = np.mean(jac)\nprint('>' * 10)\nprint(f'Total Jaccard score for 5 folds = {total_score}')","execution_count":null,"outputs":[]},{"metadata":{"id":"60NZ7DqXZADS"},"cell_type":"markdown","source":"## Train Models"},{"metadata":{"executionInfo":{"elapsed":461609,"status":"ok","timestamp":1587660975759,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"K4dGkRgMOfeI","outputId":"4cbcd7b3-c250-4d8a-b7c3-340985baa849","trusted":true},"cell_type":"code","source":"# Train models on all data\nprint('Training models on all data...')\nt0 = time()\nmodel_starts = create_model_starts()\nmodel_starts.fit(train_data_ft, train_data['start_idx'])\n\nmodel_ends = create_model_ends()\nmodel_ends.fit(train_data_ft, train_data['end_idx'])\n\nprint(f'Done in {time() - t0} seconds')","execution_count":null,"outputs":[]},{"metadata":{"id":"kMYVgbzyZERg"},"cell_type":"markdown","source":"## Kaggle submission"},{"metadata":{"executionInfo":{"elapsed":456843,"status":"ok","timestamp":1587660976126,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"gudSnDPmKxii","outputId":"e03ff2ce-9589-49b7-8a13-e43778a1bfac","trusted":true},"cell_type":"code","source":"temp_df = pd.DataFrame()\ntemp_df['pred_starts'] = model_starts.predict(kaggle_test_ft)  # predict starts\ntemp_df['pred_ends'] = model_ends.predict(kaggle_test_ft)      # predict ends\n    \n# columns = ['text', 'sentiment']\ntemp_df['text'] = test_data['text']\nprint(temp_df.head())\ntemp_df['selected_text'] = temp_df[[\n                          'text', \n                          'pred_starts', \n                          'pred_ends']\n                                ].apply(lambda x: x[0][x[1]:x[2]], axis=1)\n\n# Handle cases where start >= end\ncondition = temp_df['pred_starts'] >= temp_df['pred_ends']\ntemp_df.loc[:, 'selected_text'][condition] = temp_df.loc[:, 'text'][condition]\n\nsubmission_df = pd.DataFrame() \nsubmission_df['textID'] = test_data['textID']\nsubmission_df['selected_text'] = temp_df['selected_text']\nsubmission_df.to_csv(SUBMISSION_FILE, index = False)","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":553,"status":"ok","timestamp":1587660976733,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"by6UrCKcMqbP","outputId":"9e4cd02c-6ceb-41db-a828-c46a4591c7a8","trusted":true},"cell_type":"code","source":"pd.set_option('max_colwidth', 80)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"executionInfo":{"elapsed":496,"status":"ok","timestamp":1587660976737,"user":{"displayName":"Alex Skornyakov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhvDGL0gITiWuZeBk8WuqiFgNjo86fRwcdf3MuZHg=s64","userId":"00614715397981539727"},"user_tz":-180},"id":"u3q_M5RRTdcF","outputId":"c123fc3f-c464-4c09-f8a5-68166f7271a8","trusted":true},"cell_type":"code","source":"submission_df.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"id":"zJy_wbPkTfCK","trusted":true},"cell_type":"code","source":"plt.hist(res['selected_text'].map(len), alpha=0.8, bins=40)\nplt.title('Distribution of Lengths of TRUE Substrings in Training Data')\nplt.xlabel('Char length')\nplt.ylabel('How often')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(res['pred_select'].map(len), alpha=0.8, bins=40)\nplt.title('Distribution of Lengths of PREDICTED Substrings in Training Data')\nplt.xlabel('Char length')\nplt.ylabel('How often')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.hist(submission_df['selected_text'].map(len), alpha=0.8, bins=40)\nplt.title('Distribution of Lengths of PREDICTED Substrings in Testing Data')\nplt.xlabel('Char length')\nplt.ylabel('How often')\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"ml_fasttext_skf.ipynb","provenance":[{"file_id":"185PsLtnlsIdTe9SAMgdVLbaWKetjxtxr","timestamp":1587544419206}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}