{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport unicodedata\nimport string\nimport re\nimport random\nimport numpy as np\nimport pandas as pd\nfrom pprint import pprint\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.optim import lr_scheduler\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.autograd import Variable\n\nimport gensim\nfrom gensim.models.fasttext import FastText\nfrom gensim.models.wrappers import FastText\nfrom gensim.test.utils import datapath\nfrom gensim import corpora\nfrom gensim.utils import simple_preprocess\nfrom gensim.models import KeyedVectors\n\n# encoder_path = './encoder_hs1000es300p1100.pt'\n# decoder_path = './decoder_hs1000es300p1100.pt'\n# model_path = './model_hs1000es300p1100.pt'\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ntrain = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ntrain = train.dropna()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pairs = train[['text','selected_text']]\ntrain_pairs = train_pairs.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_df = pd.concat([train['text'],test['text']],axis=0,ignore_index=True)\nvocab_list = vocab_df.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = test['text']\ntest_list = test_df.values.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SOS_token = 0\nEOS_token = 34\n\nsos_tensor = torch.tensor(SOS_token, dtype=torch.long, device=device)\neos_tensor = torch.tensor(EOS_token, dtype=torch.long, device=device)\n\n# class Lang:\n#     def __init__(self, name):\n#         self.name = name\n#         self.word2index = {}\n#         self.word2count = {}\n#         self.index2word = {0: \"SOS\", 1: \"EOS\"}\n#         self.n_words = 2  # Count SOS and EOS\n        \n#     def addSentence(self, sentence):\n#         for word in sentence.split(' '):\n#             self.addWord(word)\n\n#     def addWord(self, word):\n#         if word not in self.word2index:\n#             self.word2index[word] = self.n_words\n#             self.word2count[word] = 1\n#             self.index2word[self.n_words] = word\n#             self.n_words += 1\n#         else:\n#             self.word2count[word] += 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def unicodeToAscii(s):\n    return ''.join(\n        c for c in unicodedata.normalize('NFD', s)\n        if unicodedata.category(c) != 'Mn')\n\n\ndef normalizeString(s):\n#     s = re.sub(r'https?:\\/\\/.\\S+', \"\", s)\n#     s = re.sub(r'[-*0123456789¿½()\"]', ' ', s)\n    s = unicodeToAscii(s.lower().strip())\n#     s = re.sub(r\"([.!?])\", r\" \\1\", s)\n#     s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n#     s = \" \".join([asd for asd in re.split(\"([A-Z][a-z]+[^A-Z]*)\",s) if asd])\n    s = s.strip()\n    s = s.split()\n    return \" \".join(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_list = [normalizeString(l) for l in vocab_list]\ntest_list = [normalizeString(l) for l in test_list]\ntrain_pairs = [[normalizeString(s) for s in l] for l in train_pairs]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def readLangs(lang:str):\n#     pairs = train_pairs \n#     vocab_lang = Lang(lang)\n#     return vocab_lang, pairs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def prepareData(lang:str):\n#     vocab_lang, pairs = readLangs(lang)\n    \n#     print(\"Read %s sentence pairs\" % len(pairs))\n#     print(\"Counting words...\")\n#     for sentence in vocab_list:\n#         vocab_lang.addSentence(sentence)\n#     for sentence_pair in pairs:\n#         for sentence1 in sentence_pair:\n#             vocab_lang.addSentence(sentence1)\n        \n#     print(\"Counted words:\")\n#     print(vocab_lang.name, vocab_lang.n_words)\n#     return vocab_lang, pairs\n\n\n# vocab,  pairs = prepareData('vocab')\n\n# print(random.choice(pairs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, vocab_size, embedding_size, hidden_size, dropout_odds=0.3):\n        super(Encoder, self).__init__()\n        self.dropout = nn.Dropout(dropout_odds)\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n        self.embedding.weight.requires_grad = True\n        self.gru = nn.GRU(embedding_size, hidden_size, bidirectional=True)\n        self.fc_hidden = nn.Linear(hidden_size*2, hidden_size)\n        \n    def forward(self, x):\n        embedded = self.dropout(self.embedding(x)).unsqueeze(1)\n        output, hidden = self.gru(embedded)\n        hidden = self.fc_hidden(torch.cat((hidden[0:1],hidden[1:2]),dim=2))\n        \n        return output, hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# a,b,c = tensorFromPair(train_pairs[0][0])\n# hidden_size = 256\n# embedding_size=300\n# vocab_size = 35\n# dropout_odds = 0.3\n# encoder = Encoder(vocab_size, embedding_size, hidden_size).to(device)\n# encoder_outputs,hidden = encoder(a[0])\n# # dropout = nn.Dropout(dropout_odds).to(device)\n# # embedding = nn.Embedding(35, embedding_size).to(device)\n# # gru = nn.GRU(embedding_size, hidden_size, bidirectional=True).to(device)\n# # fc_hidden = nn.Linear(hidden_size*2, hidden_size).to(device)\n# # x = training_pairs[0][0]\n\n# # zxc = embedding(x)\n# # embedded = dropout(embedding(x)).unsqueeze(1)\n# # output, hidden = gru(embedded)\n# # hidden = fc_hidden(torch.cat((hidden[0:1],hidden[1:2]),dim=2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# embedding = nn.Embedding(vocab_size, embedding_size).to(device)\n# energy = nn.Linear(hidden_size*3, 1).to(device)\n# gru = nn.GRU(hidden_size*2+embedding_size, hidden_size).to(device)\n# out = nn.Linear(hidden_size, vocab_size).to(device)\n# relu = nn.ReLU().to(device)\n# softmax_en = nn.Softmax(dim=0).to(device)\n# x = sos_tensor\n# target = a[1]\n# target_len = target.shape[0]\n# decoder_outputs = torch.zeros(target_len, 35).to(device)\n# eos_loss_tensor = torch.tensor([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,100]).to(device)\n# teacher_force_ratio = 0.5\n\n# embedded = embedding(x).unsqueeze(0).unsqueeze(0)\n# sequence_length = encoder_outputs.shape[0]\n# h_reshaped = hidden[0].repeat(sequence_length, 1,1)\n# energy_ = relu(energy(torch.cat((h_reshaped, encoder_outputs), dim=2)))\n# attention = softmax_en(energy_)\n# context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_outputs)\n# rnn_input = torch.cat((context_vector, embedded),dim=2)\n# output, hidden = gru(rnn_input, hidden)\n# output = relu(out(hidden)).squeeze(0)\n# if output.argmax() not in target[:-1]:\n#     output = torch.ger(output.squeeze(0),eos_loss_tensor.float())[1]\n# decoder_outputs[1] = output\n# best_guess = output.argmax()\n# x = target[1] if random.random() < teacher_force_ratio else best_guess\n# print(output)\n# print(output.argmax())\n# print(hidden.shape)\n# print(outVector2wordList(output,c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Decoder(nn.Module):\n    def __init__(self, vocab_size, embedding_size, hidden_size, dropout_odds=0.3):\n        super(Decoder, self).__init__()\n        self.dropout = nn.Dropout(dropout_odds)\n        self.embedding = nn.Embedding(vocab_size, embedding_size)\n        self.embedding.weight.requires_grad = True\n        self.energy = nn.Linear(hidden_size*3, 1)\n        self.gru = nn.GRU(hidden_size*2+embedding_size, hidden_size)\n        self.out = nn.Linear(hidden_size, 35)\n        self.relu = nn.ReLU()\n        self.softmax_en = nn.Softmax(dim=0)\n\n\n    def forward(self, x, hidden, encoder_outputs):\n        embedded = self.dropout(self.embedding(x)).unsqueeze(0).unsqueeze(0)\n        sequence_length = encoder_outputs.shape[0]\n        h_reshaped = hidden[0].repeat(sequence_length, 1,1)\n        energy_ = self.relu(self.energy(torch.cat((h_reshaped, encoder_outputs), dim=2)))\n        attention = self.softmax_en(energy_)\n        context_vector = torch.einsum(\"snk,snl->knl\", attention, encoder_outputs)\n        rnn_input = torch.cat((context_vector, embedded),dim=2)\n        output, hidden = self.gru(rnn_input, hidden)\n        \n        output = self.relu(self.out(hidden)).squeeze(0)\n        return output, hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Seq2seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n        \n    def forward(self, source, target, teacher_force_ratio=0.5, output_size = 35):\n        sourse_len = source.shape[0]\n        target_len = target.shape[0]\n#         eos_loss_tensor = torch.tensor([1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,100]).to(device)\n#         target_vocab_size = vocab.n_words\n#         hidden = torch.zeros(hiden_size)\n#         encoder_outputs =  torch.zeros(sourse_len,1, hidden_size*2).to(device)\n        decoder_outputs = torch.zeros(target_len, output_size).to(device)\n#         attention_outputs = torch.zeros(target_len,sourse_len).to(device)\n#         for ei in range(sourse_len):\n        encoder_states, hidden = self.encoder(source)\n#             encoder_outputs[ei] = encoder_states\n        x = sos_tensor\n\n        for t in range(target_len):\n#             output, hidden, _ = self.decoder(x, hidden, encoder_outputs)\n            output, hidden = self.decoder(x, hidden, encoder_states)\n            decoder_outputs[t] = output\n            best_guess = output.argmax()\n            x = target[t] if random.random() < teacher_force_ratio else best_guess\n            \n\n        return decoder_outputs\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def indexFromSentence(sentence):\n#     return [vocab.word2index[word] for word in sentence.split(' ')]\n\n# def tensorFromIndex(sentance):\n#     indexes = indexFromSentence(sentance)\n#     indexes.append(EOS_token)\n#     return torch.tensor(indexes, dtype=torch.long, device=device)   \n    \n# def tensorsFromPair(pair):\n#     input_tensor = tensorFromIndex(pair[0])\n#     target_tensor = tensorFromIndex(pair[1])\n#     return (input_tensor, target_tensor)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def indexFromInput(sentence):\n    i=1\n    word2idx_voc = {'SOS':0,'EOS':34}\n    idx2word_voc = {0:'SOS',34:'EOS'}\n    idx_list = []\n    for word in sentence.split(' '):\n        if word not in word2idx_voc:\n            word2idx_voc[word] = i\n            idx2word_voc[i] = word\n        idx_list.append(i)\n        i+=1\n    idx_list.append(34)\n    return word2idx_voc, idx_list, idx2word_voc\n\ndef indexFromPair(pair):\n    j=1\n    trg_lis = []\n    w2ivoc, inp_lis, i2wvoc = indexFromInput(pair[0])\n    for word in pair[1].split(' '):\n        try:\n            trg_lis.append(voc[word])\n            j=voc[word]\n        except:\n            trg_lis.append(j+1)\n            j+=1\n    trg_lis.append(34)    \n    return inp_lis, trg_lis, w2ivoc, i2wvoc\n        \n\ndef tensorFromPair(pair):\n    lisInput,lisTarget,w2ivoc, i2wvoc = indexFromPair(pair)\n    inp = torch.tensor(lisInput, dtype=torch.long, device=device)\n    tar = torch.tensor(lisTarget, dtype=torch.long, device=device)\n    return (inp,tar), w2ivoc, i2wvoc","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import time\nimport math\n\n\ndef asMinutes(s):\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\n# def timeSince(since, percent):\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n#     es = s / (percent)\n#     rs = es - s\n#     return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n    return asMinutes(s)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def outVector2wordList(out,vocab):\n    list1 = []\n    for i in out.argmax(1):\n        try:\n            list1.append(vocab[i.item()])\n        except:\n            list1.append('TUNK')\n    return ' '.join(list1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def targetVector2wordsList(trgt,vocab):\n    list2 = []\n    for i in range(len(trgt)):\n        try:\n            list2.append(vocab[trgt[i].item()])\n        except:\n            list2.append('VUNK')\n    return ' '.join(list2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hidden_size = 512\nembedding_size = 300\nvocab_size = 35\nepochs = 5\npatience_s = 100\nweight_list = [1,1,1,1,1,1,0.9,0.9,0.9,0.9,0.9,0.9,0.7,0.7,0.7,0.7,0.7,0.7,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.5,0.1]\nweight_tensor = torch.tensor(weight_list,dtype=torch.float).to(device)\nencoder = Encoder(vocab_size, embedding_size, hidden_size).to(device)\n# encoder.load_state_dict(torch.load(encoder_path,map_location=torch.device('cpu')))\ndecoder = Decoder(vocab_size, embedding_size, hidden_size).to(device)\n# decoder.load_state_dict(torch.load(decoder_path,map_location=torch.device('cpu')))\nmodel = Seq2seq(encoder,decoder).to(device)\n# model.load_state_dict(torch.load(model_path,map_location=torch.device('cpu')))\noptimizer = optim.Adam(model.parameters(), lr=0.00001)\n# optimizer = Adam16(model.parameters(), lr=0.0001)\nscheduler = lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, factor=0.1, verbose=True)\n# class_weights = torch.tensor(weights,dtype=torch.float16).to(device)\ncriterion = nn.CrossEntropyLoss(weight=weight_tensor).to(device)\n# training_pairs = [tensorFromPair(pair) for pair in train_pairs[:2200]]\n# model.eval()\n# encoder.train()\n# decoder.train()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rubicon = 27000\nstart = time.time()\nloss1=9999\nloss2=9999\nindx = 0\nfor epoch in range(1,epochs+1):\n    model.train()\n    print(f\"[Epoch {epoch} / {epochs}]\")\n    loss_sum = 0\n    loss_sum_valid = 0\n    jaccard_score_train = 0\n    jaccard_score_valid = 0\n        \n    for t_pair in train_pairs[:rubicon]:\n        tp,w2ivocab,i2wvocab = tensorFromPair(t_pair)\n        inp_data = tp[0]\n        target = tp[1]\n        output = model(inp_data, target)\n        optimizer.zero_grad()\n        loss = criterion(output, target)\n        loss_sum +=loss.item()\n        loss.backward()\n        optimizer.step()\n        jaccard_score_train += jaccard(outVector2wordList(output[:-1],i2wvocab),t_pair[1])\n        \n    \n    with torch.no_grad():\n        model.eval()\n        for v_pair in train_pairs[rubicon:]:\n            vp,w2ivocab_valid,i2wvocab_valid = tensorFromPair(v_pair)\n            valid_data = vp[0]\n            valid_target = vp[1]\n            valid_output = model(valid_data,valid_target)\n            valid_loss = criterion(valid_output, valid_target)\n            jaccard_score_valid += jaccard(outVector2wordList(valid_output[:-1],i2wvocab_valid),v_pair[1])\n            loss_sum_valid +=valid_loss.item()\n    \n    \n            \n    loss2 = loss1\n    loss1 = loss_sum_valid/len(train_pairs[rubicon:])\n    \n    print(\"Train loss: {:.4f},|Valid loss: {:.4f},|Train Jaccard: {:.4f},|Valid Jaccard: {:.4f},|Already gone: {}\".\n          format(loss_sum/len(train_pairs[:rubicon]),loss_sum_valid/len(train_pairs[rubicon:]),\n        jaccard_score_train/len(train_pairs[:rubicon]),jaccard_score_valid/len(train_pairs[rubicon:]),\n        timeSince(start)\n    ))\n    print('train_out:',outVector2wordList(output,i2wvocab))\n    print('train_target:',t_pair[1])\n    print('valid_out:',outVector2wordList(valid_output,i2wvocab_valid))\n    print('valid_target:',v_pair[1])\n    if loss2<loss1:\n        indx+=1\n        torch.save(model.state_dict(),'model_hs1024es300full'+str(epoch)+'epoch.pt')\n        torch.save(encoder.state_dict(),'encoder_hs1024es300full'+str(epoch)+'epoch.pt')\n        torch.save(decoder.state_dict(),'decoder_hs1024es300full'+str(epoch)+'epoch.pt')\n    else:\n        indx=0\n    if indx==patience_s:\n        break\n    scheduler.step(loss_sum/len(train_pairs[:rubicon]))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.eval()\njacca = 0\nfor pair in train_pairs:    \n    pt,w2i,i2w = tensorFromPair(pair)\n    inp = pt[0]\n    trg = pt[1]\n    test_out = model(inp,trg)\n    jacca += jaccard(pair[1],outVector2wordList(test_out[:-1],i2w))\nprint(jacca/len(train_pairs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pred(encoder,decoder, source, teacher_force_ratio=0.5, max_length=35):\n    sourse_len = source.shape[0]\n    encoder_outputs =  torch.zeros(sourse_len, hidden_size*2, device=device).to(dtype=torch.float16,device=device)\n    decoder_outputs = []\n#     for ei in range(sourse_len):\n    encoder_states, hidden = encoder(source)\n#         encoder_outputs[ei] = encoder_states\n\n#     x = source[0]\n    x = sos_tensor\n    for di in range(max_length):\n        output, hidden = decoder(x, hidden, encoder_states)\n        best_guess = output.argmax()\n        \n        if best_guess==eos_tensor:\n#             decoder_outputs.append(vocab.index2word[best_guess.item()])\n            break\n        else:\n            decoder_outputs.append(output)\n\n    return torch.cat(decoder_outputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoder.eval()\ndecoder.eval()\nl = []\nfor sentance in test_list:    \n    w2i, idx_list, i2w = indexFromInput(sentance)\n    inp = torch.tensor(idx_list).to(device)\n    test_out = pred(encoder,decoder,inp)\n    test_out = outVector2wordList(test_out[:-1],i2w)\n    l.append(test_out)\n# print(jacca/len(train_pairs))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l = pd.Series(l)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['selected_text'] = l","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[['textID','selected_text']].to_csv('submission.csv', index=False)\ntest","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.eval()\n# note = 3\n# pt,w2i,i2w = tensorFromPair(train_pairs[note])\n# inp = pt[0]\n# trg = pt[1]\n# test_out = model(inp,trg)\n# print(outVector2wordList(test_out,i2w))\n# print(train_pairs[note])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# model.eval()\n# mnb=7\n# zxc = model(training_pairs[mnb][0],training_pairs[mnb][1])\n# print('input sentance:',train_pairs[mnb][0])\n# print('out sentance:',outVector2wordList(zxc))\n# print('target sentance:',targetVector2wordsList(training_pairs[mnb][1]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def softmixer(vec):\n#     return torch.exp(vec)/sum(torch.exp(vec))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# def evaluation(encoder,decoder, source, teacher_force_ratio=0.5,target_vocab_size = vocab.n_words):\n#     source = tensorFromIndex(source)\n#     source_len = source.shape[0]\n#     encoder_outputs =  torch.zeros(source_len, hidden_size*2, device=device).to(device)\n#     attention_outputs = []\n#     decoder_outputs = []\n#     for ei in range(source_len):\n#         encoder_states, hidden = encoder(source[ei])\n#         encoder_outputs[ei] = encoder_states\n\n# #     x = source[0]\n#     x = sos_tensor\n#     for di in range(source_len):\n#         output, hidden, attention = decoder(x, hidden, encoder_outputs)\n#         attention_outputs.append(attention.cpu().squeeze(1).detach().numpy())\n#         best_guess = output.argmax()\n#         x = best_guess\n#         if best_guess.item()==eos_tensor.item():\n# #             decoder_outputs.append(vocab.index2word[best_guess.item()])\n#             break\n#         else:\n#             decoder_outputs.append(vocab.index2word[best_guess.item()])\n        \n#         max_tensor,_ = torch.tensor(attention_outputs).max(axis=0)\n#         softmax_tensor = softmixer(max_tensor)\n        \n#     return decoder_outputs, softmax_tensor, torch.tensor(attention_outputs),hidden","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change = 23\n# print(test_list[change])\n# out,smt, attn,h = evaluation(encoder,decoder,test_list[change])\n# print(out)\n# print(smt)\n# print(attn)\n# print(h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change = 2\n# print(pairs_list[change][0])\n# out,smt, attn,h = evaluation(encoder,decoder,pairs_list[change][0])\n# print(out)\n# print(smt)\n# print(attn)\n# print(h)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# change = 2\n# print(pairs_list[change][0])\n# out,smt, attn,h = evaluation(encoder,decoder,pairs_list[change][0])\n# print(out)\n# print(smt)\n# print(attn)\n# print(h)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}