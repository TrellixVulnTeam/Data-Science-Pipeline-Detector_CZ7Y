{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport sys # to get error message when exception occurs.\nimport re\nimport datetime as dt\n\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\nfrom spacy.util import decaying\nfrom spacy import displacy\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#activated = spacy.require_gpu()#prefer_gpu()\n#print(f'is GPU activited for spacy: {activated}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#Load train and test data\ntrain_data = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ntest_data = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n\nprint(f'train_data.shape: {train_data.shape}')\nprint(f'test_data.shape: {test_data.shape}')\ntrain_data.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Train data: Check for null entries\ntrain_data.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Test data: Check for null entries\ntest_data.isnull().mean()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data contains 1 null entry thefore it's safe to drop it.\ntrain_data[train_data.text.isnull() == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.dropna(inplace=True)\ntrain_data.reset_index(inplace=True) #reset index post dropping NA\nlen(train_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'train_data sentiment unique entries: {train_data.sentiment.unique()}')\nprint(f'test_data sentiment unique entries: {test_data.sentiment.unique()}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validate selected_text match with text in train_data\n\nvalidIdx=[]\ninvalidIdx=[]\nfor row in train_data.index.tolist():\n    try:\n        if train_data.iloc[row].selected_text in train_data.iloc[row].text:\n            validIdx.append(row)\n        else:\n            invalidIdx.append(row)\n        #break\n    except:\n        e = sys.exc_inf()[0]\n        print(e)\n        print(train_data.iloc[row].text)\n\nlen(validIdx), len(invalidIdx)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train_data['neutral_sel_tx_diff'] = train_data.loc[lambda d: d.sentiment == 'neutral'][['text', 'selected_text']].apply(lambda d: len(d.text) - len(d.selected_text))\n\nf1 = lambda d: d.sentiment == 'neutral'\n#f2 = lambda d: (len(d.text) - len(d.selected_text)) > 0\n#train_data.loc[lambda d: d.neutral_sel_tx_diff > 0][['text', 'selected_text']]\ntrain_data.loc[f1]\n\ntrain_data['txt_and_sel_txt_diff'] = [(len(d.text) - len(d.selected_text)) for d in train_data.itertuples()]\ntrain_data['txt_and_sel_txt_diff_strip'] = [(len(d.text.strip()) - len(d.selected_text.strip())) for d in train_data.itertuples()]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst = train_data.loc[lambda d: d.sentiment == 'neutral'].loc[lambda d: d.txt_and_sel_txt_diff > 0].txt_and_sel_txt_diff.value_counts()\nlst_strip = train_data.loc[lambda d: d.sentiment == 'neutral'].loc[lambda d: d.txt_and_sel_txt_diff_strip > 0].txt_and_sel_txt_diff_strip.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst[lst > 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lst_strip[lst_strip > 3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loc[lambda d: d.sentiment == 'neutral'].loc[lambda d: d.txt_and_sel_txt_diff > 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loc[f1].loc[lambda d: d.txt_and_sel_txt_diff_strip > 10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loc[f1].loc[lambda d: d.txt_and_sel_txt_diff_strip > 1].loc[lambda d: d.text.str.find('http') > -1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_url(string): \n  \n    # findall() has been used  \n    # with valid conditions for urls in string \n    regex = r\"(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\\\".,<>?«»“”‘’]))\"\n    url = re.findall(regex,string)       \n    return [x[0] for x in url] \n\ndef replace_url(txt):\n    dat = txt\n    for s in find_url(txt):\n        dat = dat.replace(s,\"\")\n    return dat\n\nprint(replace_url('Hello this www.google.com is google website!!!'))\n\ndef cust_strip(df, lst):\n    for col in lst:\n        df[col] = df[col].str.strip()\n\n#Remove space at the begining of text and selected_text.\ncust_strip(train_data, ['text', 'selected_text'])\n\n#Remove url as they are not part of selected text as per train data\n#train_data.text = train_data.text.apply(replace_url)\n\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Remove space at the begining of text and selected_text.\ncust_strip(test_data, ['text'])\n\n#Remove url as they are not part of selected text as per train data\n#test_data.text = test_data.text.apply(replace_url)\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Max len of negative and positive sentiment\nprint(train_data['text'].str.len().max(), \n    train_data.loc[lambda d: d.sentiment == 'neutral']['selected_text'].str.len().max(),\n    train_data.loc[lambda d: d.sentiment == 'positive']['selected_text'].str.len().max(),\n    train_data.loc[lambda d: d.sentiment == 'negative']['selected_text'].str.len().max())\n\n#Max len of negative and positive sentiment\nprint(train_data['text'].str.len().min(), \n    train_data.loc[lambda d: d.sentiment == 'neutral']['selected_text'].str.len().min(),\n    train_data.loc[lambda d: d.sentiment == 'positive']['selected_text'].str.len().min(),\n    train_data.loc[lambda d: d.sentiment == 'negative']['selected_text'].str.len().min())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.loc[lambda d: d.selected_text.str.len() <3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Function prepares data for given row for Spacy model.\n\ndef parse_data(df, idx,lFlag=False):\n    txt = df.iloc[idx].text.lower()\n    sel_txt = df.iloc[idx].selected_text.lower()\n    senti = df.iloc[idx].sentiment.lower()\n    parsedTxt = ''\n    \n    if lFlag == True: # Logging\n        print(f'row: {idx}')\n        print(f'text:{txt}')\n        print(f'sel_txt:{sel_txt}')\n    \n    if sel_txt in txt:\n        start = txt.index(sel_txt)\n        end = start+len(sel_txt)\n        entityTuple = (start, end, senti)\n        parsedTxt = (txt, {'entities': [entityTuple]})\n    \n    if lFlag == True : #Logging\n        s = parsedTxt[1][\"entities\"][0][0]\n        e = parsedTxt[1][\"entities\"][0][1]\n        print(f'sel_txt and parsedTxt matched => {txt[s:e] == sel_txt}')\n    \n    return parsedTxt \n\n#Validate function parse_train_data \nfor row in range(5):\n    print(parse_data(train_data, row))\n    print()\n\n\n#Function to create spacy blank model and add custom labels to ner.\ndef create_blank_nlp(parsed_data):\n    nlp = spacy.blank('en')\n    ner = nlp.create_pipe('ner')\n    nlp.add_pipe(ner, last=True)\n    ner = nlp.get_pipe('ner')\n    for _, annotations in parsed_data:\n        if len(annotations.get(\"entities\")[0]) == 3:\n            #print(annotations.get(\"entities\"))\n            ner.add_label(annotations.get(\"entities\")[0][2])\n    print(f'These labels added to ner: {ner.labels}')\n    return nlp\n\n \ndef train_model(df, model, epoch=20, minBatch=4.0, maxBatch=16.0, lr=1.01, drop=0.5, \n                enableBatchScheme=False, batchScheme=[100,200,300,400,500]):\n    #print(f'nlp pipeline: {nlp.pipeline}')\n    #dropout=decaying(0.6,0.1,1e-4)\n    nextBatchIdx = 0\n    losses_output = []\n    optimizer = model.begin_training()\n    for i in range(epoch):\n        start_dt = dt.datetime.now()\n        random.shuffle(df)\n        losses = {}\n        if enableBatchScheme and epoch >= len(batchScheme):\n            cnt = i%(epoch/len(batchScheme))\n            if cnt == 0:\n                minBatch = batchScheme[nextBatchIdx]\n                maxBatch = batchScheme[nextBatchIdx]\n                nextBatchIdx += 1\n                #print(f'mini and max batch is: {minBatch}')\n        batches = minibatch(df, size=compounding(minBatch, maxBatch, lr))\n        for batch in batches:\n            txt, annotations = zip(*batch)\n            model.update(txt, annotations, sgd=optimizer, \n                         #drop=next(dropout), \n                         drop=drop,\n                         losses=losses)\n            end_dt = dt.datetime.now()\n            diff = end_dt - start_dt\n        losses_output.append(losses['ner'].max())\n        #print(f'{i}: Losses - {losses} - epoch took {diff}')\n    #print(f'losses_output: {losses_output}')\n    fig = plt.figure(figsize=[20,5])\n    ax = plt.axes()\n    x = [x_i for x_i in range(len(losses_output))]\n    z = np.polyfit(x,losses_output,3)\n    p = np.poly1d(z)\n    ax.plot(x,p(x), 'r--')\n    ax.plot(x, losses_output)\n    print(f'final losses: {x[len(x)-1]}')\n        \n\ndef create_model(df):\n    df.reset_index(drop=True, inplace=True)\n    parse_dt = [parse_data(df,row) for row in df.index.tolist()] \n    return create_blank_nlp(parse_dt), parse_dt\n\nmodels = {}\ndef collect_model(key, model):\n    models[key] = model\n    print(f'Model added for {key} sentiment.')\n    \ndef get_doc(txt, sentiment, is_lower=True):\n    model = models[sentiment]\n    if is_lower:\n        return model(txt.lower())\n    else:\n        return model(txt) \n    \n\n#Method to evaluate for submission\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#redudent\n#parsed_train_data = [parse_data(train_data,row) for row in train_data.index.tolist()] \n#nlp = create_blank_nlp(parsed_train_data)\n\n#Visual inpection of parsed_train_data for word 'happy'. it returns ('text', 'annotation', 'selected_text')\n#parsed_train_data[0:5]\nsearch_word='happy'\n#g = ((dt, anno, dt[anno['entities'][0][0]:anno['entities'][0][1]]) for dt, anno in parsed_train_data if search_word in dt.lower())\n\n#for i in range(5):\n#    print(next(g))\n\n#train_model(parsed_train_data,nlp,70)\n\n#nlp.to_disk('/kaggle/working/my_model')\n#nlp = nlp.from_disk('/kaggle/working/my_model')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n#Create Seaparate Models each for one sentiment\n#nlp_neg, parse_dt_neg = create_model(train_data.loc[lambda d: d.sentiment == 'negative'])\n#nlp_pos, parse_dt_pos = create_model(train_data.loc[lambda d: d.sentiment == 'positive'])\n#nlp_nu, parse_dt_nu = create_model(train_data.loc[lambda d: d.sentiment == 'neutral'])\n#collect_model('negative', nlp_neg)\n#collect_model('positive', nlp_pos)\n#collect_model('neutral', nlp_nu)\n\n#Create single model for all sentiment\nnlp_all , parse_dt_all = create_model(train_data)\ncollect_model('all', nlp_all)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Visual inpection of train_data for search_word\ntrain_data.loc[lambda d: d['text'].str.lower().str.contains(search_word)].head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custBatchScheme = [(cnt+1)*100 for cnt in range(10)]\n#custBatchScheme","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n#train_model(parse_dt_neg,nlp_neg, 50, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n#train_model(parse_dt_pos,nlp_pos, 50, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#%%time\n#train_model(parse_dt_nu,nlp_nu, 50, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_model(parse_dt_all,nlp_all, 300, enableBatchScheme=True, lr=1.1, batchScheme=custBatchScheme)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validate to see if NER is working as expected\n\n#doc = nlp_neg('Sooo SAD I will miss you here in San Diego!!!'.lower())\ndoc = nlp_all('Sooo SAD I will miss you here in San Diego!!!'.lower())\ndisplacy.render(doc, style='ent')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Validate randon 25 records to see if NER is working as expected \nfor i in range(25):\n    idx = i#random.choices(train_data.index)[0]\n    doc = nlp_all(train_data.iloc[idx].text.lower())\n    #doc = get_doc(train_data.iloc[idx].text, train_data.iloc[idx].sentiment)\n    displacy.render(doc, style='ent')\n    print(f'row index: {idx}')\n    print(f'predicted selected_text: {doc.ents}')\n    print(f'   actual selected_text: {train_data.iloc[idx].selected_text}')\n    senti = ()\n    if len(doc.ents) > 0:\n        senti = doc.ents[0].label_\n    print(f'predicted sentiment: {senti}')\n    print(f'   actual sentiment: {train_data.iloc[idx].sentiment}')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction with nlp model with all entities i.e. neutral AND positive AND negative\ntest_data.head()\ntest_data[\"predict\"] = ''\ntest_data['txt_predict']=''\ntest_data['is_predicted'] = 0\nfor row in test_data.index.tolist():\n    doc = nlp_all(test_data.iloc[row].text.lower())\n    identified_senti = ''\n    senti = ''\n    txt_predict = ''\n    is_predi = 0\n    if len(doc.ents) > 0:\n        all_senti = {}\n        #print(f' doc.ents: {doc.ents}')\n        len_doc_ent = len(doc.ents)\n        all_senti = {doc.ents[idx].label_: idx for idx in range(len(doc.ents))}\n        if 'negative' in all_senti:\n            senti = 'negative'\n        elif 'positive' in all_senti:\n            senti = 'positive'\n        else:\n            senti = 'neutral'\n        is_predi = 1\n        txt_predict = doc.ents[all_senti[senti]].text\n    test_data[\"predict\"].iloc[row] = senti\n    test_data[\"txt_predict\"].iloc[row] = txt_predict\n    test_data[\"is_predicted\"].iloc[row] = is_predi\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"doc = get_doc('I know him. he is good guy!', 'positive')\ndisplacy.render(doc, style='ent')\nlen(doc.ents)\ndoc.ents[0].label_\ndoc.ents[0].text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction with individual nlp model with entity neutral OR positive OR negative\n# test_data.head()\n# test_data[\"predict\"] = ''\n# test_data['txt_predict']=''\n# test_data['is_predicted'] = 0\n# for row in test_data.index.tolist():\n#     doc = get_doc(test_data.iloc[row].text, test_data.iloc[row].sentiment)\n#     test_data[\"is_predicted\"].iloc[row] = 0\n#     test_data[\"predict\"].iloc[row] = 'cannot_predict'\n#     if len(doc.ents) > 0:\n#         test_data[\"predict\"].iloc[row] = doc.ents[0].label_\n#         test_data[\"txt_predict\"].iloc[row] = doc.ents[0].text\n#         test_data[\"is_predicted\"].iloc[row] = 1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = test_data[test_data[\"is_predicted\"] == 1]\nd.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'            sentiment: {test_data.sentiment.unique()}')\nprint(f'              predict: {test_data.predict.unique()}')\ntotal_rec = len(test_data)\ncnt = len(test_data[test_data.is_predicted == 0])\nprint(f'   count of test_data: {total_rec}')\nprint(f'couldnt predict count: {cnt}')\ncnt_percent = cnt/total_rec\nprint(f'couldnt predict count: {cnt_percent}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(test_data.sentiment, test_data.predict)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(classification_report(test_data.sentiment, test_data.predict))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment Analysis using VADER (Valance Aware Dictionary for Sentiment Reasoning)"},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install vaderSentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"analyzer = SentimentIntensityAnalyzer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def v_sentiment(x):\n    return analyzer.polarity_scores(x)\n\ndef v_sentiment_class(x):\n    if x['compound'] <= -0.05:\n        return 'negative'\n    elif x['compound'] <= 0.05:\n        return 'neutral'\n    else:\n        return 'positive'\n\nnlp1 = spacy.load('en_core_web_sm')\ndef rem_stop_word(txt):\n    return ' '.join([word.text for word in nlp1(txt) if nlp1.vocab[word.text].is_stop == False])\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction - with stop words\n\ntest_data['v_senti_sw'] = test_data['text'].apply(v_sentiment)\ntest_data['v_senti_sw_class'] = test_data['v_senti_sw'].apply(v_sentiment_class)\ntest_data['v_senti_sw_c_score'] = [txt['compound'] for txt in test_data['text'].apply(v_sentiment)]\ntest_data.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.sentiment.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.v_senti_sw_class.unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"confusion_matrix(test_data.sentiment, test_data.v_senti_sw_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction - including stop words\nprint(classification_report(test_data.sentiment, test_data.v_senti_sw_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# find out data for which sentiment and vader prediction doesn't match\ndf = test_data.loc[lambda d: d['sentiment'] != d['v_senti_sw_class']]\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#1230 records sentiment doesn't match with vader prediction\ndf.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Neutral sentiment (given data) was predicted incorrect by vader \ndf.loc[lambda d: d.sentiment == 'neutral'].v_senti_sw_class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Positive sentiment (given data) was predicted incorrect by vader \ndf.loc[lambda d: d.sentiment == 'positive'].v_senti_sw_class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Negative sentiment (given data) was predicted incorrect by vader \ndf.loc[lambda d: d.sentiment == 'negative'].v_senti_sw_class.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Sample of data in which given sentiment wasn't predicted by vader correctly\ntest_data[test_data.textID == '00d5195223']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Prediction - without stop words\n\ntest_data['v_senti_nsw'] = test_data['text'].apply(rem_stop_word).apply(v_sentiment)\ntest_data['v_senti_nsw_class'] = test_data['v_senti_nsw'].apply(v_sentiment_class)\ntest_data['v_senti_nsw_c_score'] = [txt['compound'] for txt in test_data['text'].apply(rem_stop_word).apply(v_sentiment)]\ntest_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Matrix between vader prediction \"with\" and vader prediction \"without\" stop word.\nconfusion_matrix(test_data.v_senti_sw_class, test_data.v_senti_nsw_class)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report between vader prediction \"with\" and vader prediction \"without\" stop word.\nprint(classification_report(test_data.v_senti_sw_class, test_data.v_senti_nsw_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report between given sentiment and vader prediction \"with\" stop word.\nprint(classification_report(test_data.sentiment, test_data.v_senti_sw_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report between given sentiment and vader prediction \"without\" stop word.\nprint(classification_report(test_data.sentiment, test_data.v_senti_nsw_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Classification report between given sentiment and spacy ner prediction \"with\" stop word.\n\nprint(classification_report(test_data.sentiment, test_data.predict))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = test_data[['textID','txt_predict']]\nsub_df.columns = [['textID', 'selected_text']]\nsub_df.to_csv('/kaggle/working/submission.csv', index=False, header=True)\nprint(\"done\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.loc[test_data.textID =='1fa8e6ad66']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}