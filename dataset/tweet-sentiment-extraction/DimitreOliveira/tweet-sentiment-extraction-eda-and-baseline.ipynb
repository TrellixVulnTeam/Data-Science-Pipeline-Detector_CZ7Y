{"cells":[{"metadata":{},"cell_type":"markdown","source":"<center><img src='https://www.kdnuggets.com/images/sentiment-fig-1-689.jpg' height=\"200\" width=\"500\"></center>\n<h1><center>Tweet Sentiment Extraction</center></h1>\n<h2><center>Extract support phrases for sentiment labels</center></h2>\n\nIn this competition our objective is to construct a model that can look at the labeled sentiment for a given tweet and figure out what word or phrase best supports it.\n(work in progress)"},{"metadata":{},"cell_type":"markdown","source":"## Dependencies"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import random, warnings\nimport pandas as pd\nimport seaborn as sns\nfrom nltk import FreqDist\nfrom nltk.corpus import stopwords\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nSEED = 0\nwarnings.filterwarnings(\"ignore\")","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Auxiliary functions\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\ndef evaluate_model(train_set, validation_set):\n    train_set['jaccard'] = train_set.apply(lambda x: jaccard(x['selected_text'], x['prediction']), axis=1)\n    validation_set['jaccard'] = validation_set.apply(lambda x: jaccard(x['selected_text'], x['prediction']), axis=1)\n\n    print('Train set Jaccard: %.3f' % train_set['jaccard'].mean())\n    print('Validation set Jaccard: %.3f' % validation_set['jaccard'].mean())\n\n    print('\\nMetric by sentiment')\n    for sentiment in train_df['sentiment'].unique():\n        print('\\nSentiment == %s' % sentiment)\n        print('Train set Jaccard: %.3f' % train_set[train_set['sentiment'] == sentiment]['jaccard'].mean())\n        print('Validation set Jaccard: %.3f' % validation_set[validation_set['sentiment'] == sentiment]['jaccard'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\n\nprint('Train samples: %s' % len(train))\nprint('Test samples: %s' % len(test))\ndisplay(train.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" # EDA\n \n # First let's look at some samples"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sample_0 = 0\nsample_1 = 1\nsample_2 = 2\n\nprint('Example %d' % sample_0)\nprint('Text: %s' % train['text'].values[sample_0])\nprint('Sentiment: %s' % train['sentiment'].values[sample_0])\nprint('Selected text (label): %s' % train['selected_text'].values[sample_0])\n\nprint('\\nExample %d' % sample_1)\nprint('Text: %s' % train['text'].values[sample_1])\nprint('Sentiment: %s' % train['sentiment'].values[sample_1])\nprint('Selected text (label): %s' % train['selected_text'].values[sample_1])\n\nprint('\\nExample %d' % sample_2)\nprint('Text: %s' % train['text'].values[sample_2])\nprint('Sentiment: %s' % train['sentiment'].values[sample_2])\nprint('Selected text (label): %s' % train['selected_text'].values[sample_2])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Sentiment distribution\n\nAs we can see the distribution of the sentiment feature is practically the same between train and test sets."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sentiment_order = train['sentiment'].unique()\nsns.set(style=\"darkgrid\")\nf, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 6))\nsns.countplot(x='sentiment', data=train, palette=\"Set3\", order=sentiment_order, ax=ax1).set_title(\"Train\")\nsns.countplot(x='sentiment', data=test, palette=\"Set3\", order=sentiment_order, ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text data statistics\n\n# Text length and word count"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train['text'].fillna('', inplace=True)\ntrain['selected_text'].fillna('', inplace=True)\n\ntrain['text_len'] = train['text'].apply(lambda x : len(x))\ntrain['text_wordCnt'] = train['text'].apply(lambda x : len(x.split(' ')))\ntrain['selected_text_len'] = train['selected_text'].apply(lambda x : len(x))\ntrain['selected_text_wordCnt'] = train['selected_text'].apply(lambda x : len(x.split(' ')))\ntest['text_len'] = test['text'].apply(lambda x : len(x))\ntest['text_wordCnt'] = test['text'].apply(lambda x : len(x.split(' ')))\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 10), sharex=True)\nsns.distplot(train['text_len'], ax=ax1).set_title(\"Train\")\nsns.distplot(test['text_len'], ax=ax2).set_title(\"Test\")\nplt.show()\n\nf, (ax1, ax2) = plt.subplots(2, 1, figsize=(24, 10), sharex=True)\nsns.distplot(train['text_wordCnt'], ax=ax1).set_title(\"Train\")\nsns.distplot(test['text_wordCnt'], ax=ax2).set_title(\"Test\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Selected text (label) length and word count"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(1, 1, figsize=(24, 5), sharex=True)\nsns.distplot(train['selected_text_len'], ax=ax).set_title(\"Train\")\nplt.show()\n\nf, ax = plt.subplots(1, 1, figsize=(24, 5), sharex=True)\nsns.distplot(train['selected_text_wordCnt'], ax=ax).set_title(\"Train\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train set word frequency"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"eng_stopwords = stopwords.words('english')\n\ntrain['text'] = train['text'].str.replace('[^a-z ]','')\ntrain['selected_text'] = train['selected_text'].str.replace('[^a-z ]','')\ntrain['text'] = train['text'].apply(lambda x: x.lower())\ntrain['selected_text'] = train['selected_text'].apply(lambda x: x.lower())\n\nfreq_dist = FreqDist([word for comment in train['text'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on text').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()\n\nfreq_dist = FreqDist([word for comment in train['selected_text'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on selected_text').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test set word frequency"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test['text'] = test['text'].str.replace('[^a-z ]','')\ntest['text'] = test['text'].apply(lambda x: x.lower())\n\nfreq_dist = FreqDist([word for comment in test['text'] for word in comment.split() if word not in eng_stopwords])\nplt.figure(figsize=(20, 6))\nplt.title('Word frequency on text').set_fontsize(20)\nfreq_dist.plot(60, marker='.', markersize=10)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's take a look if the text size seems to have an impact on the selected text size\n\nIt seems that the text length is nicely distributed along with the values and the selected text size has most of its values very short, with less than 10 characters."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.jointplot(\"selected_text_len\", \"text_len\", data=train, kind=\"reg\", color=\"m\", height=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# And now text word count\n\nAgain the text word count has a nice distribution along with the values with a small peak around 10 words and the selected text word count has most of its values around with less than 3 words."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"sns.jointplot(\"selected_text_wordCnt\", \"text_wordCnt\", data=train, kind=\"reg\", color=\"m\", height=12)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train/validation split"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"train_df, validation_df = train_test_split(train, test_size=0.2, random_state=SEED)\n\nprint('Train set size: %s' % len(train_df))\nprint('Validation set size: %s' % len(validation_df))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's evaluate some heuristic models\n\n## Last 5 words"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[-5:]))\nvalidation_df[\"prediction\"] = validation_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[-5:]))\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## First 5 words"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[5:]))\nvalidation_df[\"prediction\"] = validation_df[\"text\"].apply(lambda x: \" \".join(x.strip().split(' ')[5:]))\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Same as text"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"]\nvalidation_df[\"prediction\"] = validation_df[\"text\"]\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Last 20 characters"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"# Heuristic model\ntrain_df[\"prediction\"] = train_df[\"text\"].apply(lambda x: \" \".join(x.split()[-20:]))\nvalidation_df[\"prediction\"] = validation_df[\"text\"].apply(lambda x: \" \".join(x.split()[-20:]))\n# Metric does not works with empty labels\ntrain_df[\"prediction\"] = train_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\nvalidation_df[\"prediction\"] = validation_df[\"prediction\"].apply(lambda x: '.' if x.strip() == '' else x)\n\nevaluate_model(train_df, validation_df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test set predictions"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\nsubmission[\"selected_text\"] = test[\"text\"]\nsubmission.to_csv(\"submission.csv\", index=False)\ndisplay(submission.head(10))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}