{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow as tf\nimport keras\nimport keras.layers as L\nfrom keras.layers import Dense,Embedding,SimpleRNN,Flatten,InputLayer\nfrom keras.models import Sequential\nfrom keras.layers import LSTM\nimport nltk\ndef jaccard(ox,oy):\n    evaluator=0\n    count=0\n    for i in range(len(ox)):\n        x=nltk.word_tokenize(ox[i])\n        y=nltk.word_tokenize(oy[i])\n#         x=ox\n#         y=oy\n        xs=set(map(lambda i:i.lower(),x))\n        ys=set(map(lambda i:i.lower(),y))\n        c=xs.intersection(ys)\n        count+=1\n        evaluator+=(len(c)) / (len(xs) + len(ys) - len(c))\n    evaluator=evaluator/count                           \n    return evaluator    \ntrain_org=pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntrain_org.head()\ntrain=train_org.dropna(axis=0)\niii=train.text.values\ndocument=' '.join(list(iii))\ndocument+=\" padpad\"\ndocument+=' unkunk'\npad='padpad'\nunk='unkunk'\n# adding vocab\ntokenize_words=nltk.word_tokenize(document)\nfrom collections import Counter\ncounted_vocab=Counter(tokenize_words)\nvocab=counted_vocab.keys()\ntoken_id={}\nfor num,i in enumerate(vocab):\n    token_id[i]=num\nn_tokens=len(vocab)\nmax_len=50\ndef to_matrix(batch,token_id=token_id):\n    mat=[]\n    for i in batch:\n        mat1=[]\n        for token in list(nltk.word_tokenize(i)):\n            st=str(token)\n            if(st in token_id.keys()):\n                mat1.append(token_id[st])\n            else:\n                mat1.append(token_id[unk])\n        mat.append(mat1)\n    return mat\ndef pad_to_mat(matrix,pad_token=token_id[pad],max_len=max_len):\n    zero=np.zeros((len(matrix),max_len)) + pad_token\n    for i in range (len(matrix)):\n        for num,j in enumerate(matrix[i]):\n            if(num<max_len):\n                zero[i][num]=j\n    return zero\ndef maskvalue(xl,token_id=token_id):\n    mask_array=[]\n    for i in range(len(xl)):\n        mask_array1=[]\n        for j in range(len(xl[i])):\n            if(xl[i][j]==token_id[pad] or xl[i][j]==token_id[unk]):\n                mask_array1.append(0)\n            else:\n                mask_array1.append(1)\n        mask_array.append(mask_array1)        \n    return np.array(mask_array) \ndef preprocessing(batch,max_len=max_len):\n    mat1=to_matrix(batch)\n    mat2=pad_to_mat(mat1,max_len=max_len)\n    mat3=maskvalue(mat2)\n    return mat1,mat2,mat3","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def output(batch_X,batch_y,max_len=max_len):\n    _,ip1,_=preprocessing(batch_X,max_len=max_len)\n    out1,_,_=preprocessing(batch_y,max_len=max_len)\n    res=[]\n    for i in range(len(ip1)):\n        res1=[]\n        for j in range(len(ip1[i])):\n            if(ip1[i][j] in out1[i] or ip1[i][j]==token_id[pad]):\n                res1.append(1)\n            else:\n                res1.append(0)\n        res.append(res1)\n    ret_res=np.array(keras.backend.one_hot(res,num_classes=2))\n    return ret_res\ndef real_values(model,val_x,mask=None,token_id=token_id):\n    prediction=model.predict(val_x)\n    true_value=[]\n    for i in prediction:\n        true_value1=[]\n        for j in i:\n            true_value1.append(np.argmax(j))\n        true_value.append(true_value1)      \n    pred_token_id=[]\n    for i in range(len(true_value)):\n        pred_token1_id=[]\n        for j in range(len(true_value[0])):\n            try:\n                if(mask[i][j]==1):\n                    if(val_x[i][j]!=token_id[pad] and val_x[i][j]!=token_id[unk]):\n                        pred_token1_id.append(val_x[i][j])\n            except:\n                if(val_x[i][j]!=token_id[pad] and val_x[i][j]!=token_id[unk]):\n                    pred_token1_id.append(val_x[i][j])\n                \n        pred_token_id.append(pred_token1_id)\n    int_id=[]\n    for i in pred_token_id:\n        int_id1=[]\n        for j in i:\n            int_id1.append(int(j))\n        int_id.append(int_id1)\n    pred_token_id=int_id        \n    keylist=list(token_id.keys())\n    ret_pred_token=[]\n    for i in range(len(pred_token_id)):\n        pred_token1=[]\n        for j in range(len(pred_token_id[i])):\n            pred_token1.append(keylist[pred_token_id[i][j]])\n        ret_pred_token.append(pred_token1)\n    return ret_pred_token","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test=pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\nfrom keras.datasets import imdb\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\n# fix random seed for reproducibility\n\nnumpy.random.seed(7)\n# load the dataset but only keep the top n words, zero the rest\ntop_words = n_tokens\nX_train,_,_=preprocessing(train.text.values)\ny_train=output(train.text.values,train.selected_text.values)\n\n# y_test=output(X_pos_valid.values,y_pos_valid.values)\n# truncate and pad input sequences\nmax_review_length = 50\nX_train = sequence.pad_sequences(X_train, maxlen=max_review_length,value=token_id[pad], padding='post')\n# X_test = sequence.pad_sequences(X_test, maxlen=max_review_length,value=token_id[pad], padding='post')\n# create the model\nembedding_vecor_length = 300\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_train=train[train.sentiment=='positive']\nneg_train=train[train.sentiment=='negative']\nneu_train=train[train.sentiment=='neutral']\nfrom sklearn.model_selection import train_test_split\nX_pos_train,X_pos_valid,y_pos_train,y_pos_valid=train_test_split(pos_train.text,pos_train.selected_text,random_state=42)\nX_neg_train,X_neg_valid,y_neg_train,y_neg_valid=train_test_split(neg_train.text,neg_train.selected_text,random_state=42)\nX_neu_train,X_neu_valid,y_neu_train,y_neu_valid=train_test_split(neu_train.text,neu_train.selected_text,random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pos_test=test[test.sentiment=='positive']\nneg_test=test[test.sentiment=='negative']\nneu_test=test[test.sentiment=='neutral']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training_model(X,X1,y,y1,X2,max_len=max_len):\n    top_words = n_tokens\n    X_train,_,_=preprocessing(X.values,max_len=max_len)\n    y_train=output(X.values,y.values,max_len=max_len)\n    \n    X_valid,_,_=preprocessing(X1.values,max_len=max_len)\n    y_valid=output(X1.values,y1.values,max_len)\n    \n    X_test,_,_=preprocessing(X2.text.values,max_len=max_len)\n    \n    max_review_length = max_len\n    \n    X_train = sequence.pad_sequences(X_train, maxlen=max_review_length,value=token_id[pad], padding='post')\n    \n    X_valid = sequence.pad_sequences(X_valid, maxlen=max_review_length,value=token_id[pad], padding='post')\n    \n    X_test = sequence.pad_sequences(X_test, maxlen=max_review_length,value=token_id[pad], padding='post')\n    \n    embedding_vecor_length = 100\n    rnn=300\n    tf.keras.backend.clear_session()\n    model = tf.keras.Sequential()\n    model.add(tf.keras.Input(shape=(max_review_length,)))\n    model.add(tf.keras.layers.Masking(mask_value=token_id[pad]))\n    model.add(tf.keras.layers.Embedding(top_words, embedding_vecor_length))\n    model.add(tf.keras.layers.Dropout(0.4))\n    model.add(tf.keras.layers.LSTM(rnn,return_sequences=True))\n    model.add(tf.keras.layers.Dropout(0.4))\n    step_wise_dense=tf.keras.layers.Dense(100,input_shape=(rnn,),activation='relu')\n    step_wise_dense1=tf.keras.layers.TimeDistributed(step_wise_dense)\n    model.add(step_wise_dense1)\n    model.add(tf.keras.layers.Dense(300,activation='relu',input_shape=(max_len,)))\n    model.add(tf.keras.layers.Dense(150, activation='elu'))\n    model.add(tf.keras.layers.Dropout(0.4))\n#     model.add(Dense(150, activation='elu'))\n#     model.add(Dropout(0.4))\n#     model.add(Dense(50, activation='elu'))\n#     model.add(Dropout(0.4))\n    model.add(tf.keras.layers.Dense(2, activation='softmax'))\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    print(model.summary())\n    model.fit(X_train, y_train, epochs=20, batch_size=32,validation_data=[X_valid,y_valid])\n    # Final evaluation of the model\n    scores = model.evaluate(X_train, y_train, verbose=0)\n    scores1 = model.evaluate(X_train, y_train, verbose=0)\n          \n    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n    print(\"1 Accuracy: %.2f%%\" % (scores1[1]*100))\n          \n    predpred=real_values(model,X_train,mask=maskvalue(X_train),token_id=token_id)\n    predp=[]\n    for i in predpred:\n        predp1=' '.join(i)\n        predp.append(predp1)\n    df=pd.DataFrame(predp,columns=['selected_text'])\n    print(\"train jaccard : \",jaccard(y.values,df.selected_text.values))\n          \n    predpred=real_values(model,X_valid,mask=maskvalue(X_valid),token_id=token_id)\n    predp=[]\n    for i in predpred:\n        predp1=' '.join(i)\n        predp.append(predp1)\n    df=pd.DataFrame(predp,columns=['selected_text'])\n    print(\"train jaccard : \",jaccard(y1.values,df.selected_text.values))\n    \n    tpredpred=real_values(model,X_test,mask=maskvalue(X_test),token_id=token_id)\n    tpredp=[]\n    for i in tpredpred:\n        tpredp1=' '.join(i)\n        tpredp.append(tpredp1)\n#     print(len(tpredp))\n    dft=pd.DataFrame(tpredp,columns=['selected_text'],index=X2.index)\n#     print(dft.shape)\n    dftt=pd.concat([X2.textID,dft],axis=1)\n    print(dftt.shape)\n    print(X2.shape)\n#     assert dft.shape[0]==X2.shape[0]\n    return dftt            \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1=training_model(X_pos_train,X_pos_valid,y_pos_train,y_pos_valid,pos_test,max_len=35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df2=training_model(X_neg_train,X_neg_valid,y_neg_train,y_neg_valid,neg_test,max_len=35)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df3=training_model(X_neu_train,X_neu_valid,y_neu_train,y_neu_valid,neu_test,max_len=50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df=pd.concat([df1,df2,df3],axis=0)\nfinal_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}