{"cells":[{"metadata":{"_uuid":"559582cd-f836-409c-89a8-719dfe0dbc5c","_cell_guid":"f92be7d9-0412-46a9-a7a1-06c5a55d82e7","trusted":true},"cell_type":"markdown","source":"# NLP M3 \nB.Tech Data Science  \nJ007 - Amrusha Buddhiraju  \nJ031- Sanika Mhadgut  \nJ046- Gayathri Shrikanth"},{"metadata":{"_uuid":"3b11aed3-8452-414a-8385-6a1b559eb9db","_cell_guid":"3e6e0acd-b208-4e19-826e-c933082d5e35","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"3a18a65d-40df-4689-8d07-72770ec11b9c","_cell_guid":"55814ecb-a31c-40b2-9177-ce95b1806d99","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport scipy.io\nfrom array import *\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport re, string\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('vader_lexicon')\nimport string\nfrom string import digits\nSTOPWORDS = set(stopwords.words('english'))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"6757905a-faea-4956-9f8f-406d6fde764e","_cell_guid":"c4a290c2-e372-42c8-9059-411e29dc9b21","trusted":true},"cell_type":"markdown","source":"Reading the Dataset"},{"metadata":{"_uuid":"185f2ed4-d5ee-46dc-a3d9-cde7872901fc","_cell_guid":"4a426351-e3d5-40cf-b41f-cf85f724f8c3","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\", dtype=str)\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv', dtype=str)\nsub = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"acdecac8-8d58-4ad5-a7e5-eaf4bdd81297","_cell_guid":"86a160fe-d8c0-47ef-ad90-8b9238db1dd3","trusted":true},"cell_type":"code","source":"train.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"bd9f1dcc-8174-4397-82e2-6ea0258fcd4c","_cell_guid":"7e13ba6f-8bbd-48de-9eaa-e70084627d56","trusted":true},"cell_type":"code","source":"test.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ad2031eb-8705-47b6-9ecd-397d7a2dfd21","_cell_guid":"10ebeeaa-c095-4363-a246-a0d900a32ca0","trusted":true},"cell_type":"code","source":"sub.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"5527b7f2-7d8e-49d2-b536-ca55e06ced23","_cell_guid":"9900d21d-6e5c-46a9-a383-c6d3613df5f0","trusted":true},"cell_type":"markdown","source":"Cleaning the Dataset"},{"metadata":{"_uuid":"17335bcc-57bc-4e59-a570-fb36b9632357","_cell_guid":"c4440890-431a-46ab-89c1-b69a7a293c45","trusted":true},"cell_type":"code","source":"def clean_text(text):\n    ## Remove puncuation\n    #text = text.translate(string.punctuation)\n    text = str(text)\n    text= text.lower()\n    ## Convert words to lower case and split them\n    url = re.compile(r'https?://\\S+|www\\.\\S+')\n    text= url.sub(r'',text)\n    html=re.compile(r'<.*?>')\n    text= html.sub(r'',text)\n    remove_digits = str.maketrans('', '', digits)\n    text = text.translate(remove_digits)\n    ## Remove stop words\n    #text=\" \".join([word for word in str(text).split() if word not in STOPWORDS])\n    return text","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"308283b9-c346-4baf-ac45-ee9d91fdd2ab","_cell_guid":"971d24c1-aa77-49b3-b6cb-0f3112c873f9","trusted":true},"cell_type":"code","source":"train[\"text\"]=train[\"text\"].apply(clean_text)\ntest[\"text\"]=test[\"text\"].apply(clean_text)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ebf759da-dbfb-467c-8e60-1f416bad7813","_cell_guid":"4389dc92-421e-4253-b6e0-f3f226b4b403","trusted":true},"cell_type":"code","source":"train.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"1abb3616-15fb-4899-a783-74356e5f5dd9","_cell_guid":"889e190f-bd96-46a6-9532-b2de325b92eb","trusted":true},"cell_type":"markdown","source":"Text Extraction based on Polarity"},{"metadata":{"_uuid":"4c1d1036-b670-442a-b11c-015774661cd3","_cell_guid":"c1019714-92e9-49fc-b1be-5d36f7cfc96f","trusted":true},"cell_type":"code","source":"def choosing_selectedword(df_process):\n    train_text = df_process['text']\n    train_sentiment = df_process['sentiment']\n    selected_text_processed = []\n    analyser = SentimentIntensityAnalyzer()\n    for j in range(0 , len(train_text)):\n        text = str(train_text.iloc[j])\n        # For Neutral append the full sentence\n        if(train_sentiment.iloc[j] == \"neutral\"):\n            selected_text_processed.append(str(text))\n        #For positive take only words with positive polarity\n        if(train_sentiment.iloc[j] == \"positive\"):\n            token = re.split(' ', text)\n            ss_arr = \"\"\n            polar = 0\n            for word in token:\n                score = analyser.polarity_scores(word)\n                if score['compound'] >polar:\n                    polar = score['compound']\n                    ss_arr = ss_arr + \" \"+word\n            if len(ss_arr) != 0:\n                selected_text_processed.append(ss_arr)   \n            if len(ss_arr) == 0:\n                selected_text_processed.append(text)\n        #for negative take words with negative polarity \n        if(train_sentiment.iloc[j] == \"negative\"):\n            token = re.split(' ', text)\n            ss_arr = \"\"\n            polar = 0\n            for word in token:\n                score = analyser.polarity_scores(word)\n                if score['compound'] <polar:\n                    polar = score['compound']\n                    ss_arr = ss_arr + \" \" + word\n            if len(ss_arr) != 0:\n                selected_text_processed.append(ss_arr)   \n            if len(ss_arr) == 0:\n                selected_text_processed.append(text)  \n    return selected_text_processed","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"ea5b914a-1980-4cf7-b4a2-2951e3f55d9f","_cell_guid":"6b6a7ded-9e78-430a-8998-4156af776f8b","trusted":true},"cell_type":"code","source":"train[\"predicted\"]=choosing_selectedword(train)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b6166531-2b76-4803-ad7e-594424bf7788","_cell_guid":"37ce07c8-ff7d-4cc2-b66d-fe5a94d76a46","trusted":true},"cell_type":"code","source":"train.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"17cdc61e-efc8-47fc-82ad-a8368439c22c","_cell_guid":"eb74e55f-2c1a-45ec-bb04-75aaec66028b","trusted":true},"cell_type":"code","source":"test[\"selected_text\"]= choosing_selectedword(test)\nsub[\"selected_text\"]= choosing_selectedword(test)","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"f37b0c01-cc0e-44d4-aacc-71616f38b6b2","_cell_guid":"0c0b16df-4089-4dd2-aad3-49c4e2355b56","trusted":true},"cell_type":"code","source":"sub.head()","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"5529e68f-4f15-4669-a1f8-98f11852890c","_cell_guid":"5023896f-0496-470f-9e6a-4ed2ee469065","trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"167b4fa5-e7a0-47de-92e1-d89ef5813626","_cell_guid":"17f16e1b-0c0a-4f9e-8f87-44126822d4bc","trusted":true},"cell_type":"markdown","source":"Jaccard score on train set"},{"metadata":{"_uuid":"b1f6b0d8-89d8-459c-820a-a86ce7f8a92d","_cell_guid":"808ba99f-7d68-4d4a-839b-4281f02df8e3","trusted":true},"cell_type":"code","source":"average = 0\nfor i in range(0,train.shape[0]):\n    jaccard_score = jaccard(str(train[\"selected_text\"][i]),str(train[\"predicted\"][i]))\n    average += jaccard_score \nprint('Training Data average jaccard score is ', average/len(train[\"selected_text\"]))","execution_count":0,"outputs":[]},{"metadata":{"_uuid":"b99911a5-5b59-4bb5-b55d-309851f4eecd","_cell_guid":"e8f22ca4-bd8b-4bc0-91ea-b69ca2cf4918","trusted":true},"cell_type":"code","source":"sub.to_csv('submission.csv', index = False)","execution_count":0,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}