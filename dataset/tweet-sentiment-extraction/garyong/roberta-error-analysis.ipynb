{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Roberta error analysis\nIt is often the case in deep learning that we do abit of both random search and gradient descent. I realise alot of people including me do alot of random search but rarely do output analysis to figure out how to improve the model(aka gradient descent). The analysis here are done using [Abhishek Thakur's](https://www.kaggle.com/abhishek) v2 folds.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Experimental procedure\nModel : Roberta  \nTraining procedure: secret but very similar to [Abhishek Thakur's](https://www.kaggle.com/abhishek) original kernel  \nThe outputs are the 5 out of fold prediction. Note that I used the best validation fold as the saved model so it will overfit this training data abit.  \nThis can be seen as the expectation on the training set when your model deals with new unseen examples.  ","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Import stuff","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nCSV_PATH = '../input/tweet5foldoutputs'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading and combining csv","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_ls = [] \nfor i in range(5):\n    df = pd.read_csv(f'{CSV_PATH}/fold_{i}.csv')\n    df_ls.append(df)\ndf = pd.concat(df_ls)\ndf = df.drop(['Unnamed: 0'], axis=1)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating Jaccard scores","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\ndef calculate_jac(df):\n    ls = []\n    for row in df.iterrows():\n        row = row[1]\n        a = row.selected_text\n        b = row.selected_text_out\n        jac = jaccard(a,b)\n        ls.append(jac)\n    return ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"jaccard_scores = calculate_jac(df)\ndf['jaccard'] = jaccard_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Jaccard2 -> Alternative calculation more resilient to noise??\nWe will name this as **jaccard2**  \nInstead of splitting just on spaces we split both on spaces AND punctuation  \nThen we calculate the jaccard scores","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['selected_text_2'] = df['selected_text'].apply(lambda x: re.findall(r\"[\\w']+|[.,!?;]\",x))\ndf['selected_text_2_out'] = df['selected_text_out'].apply(lambda x: re.findall(r\"[\\w']+|[.,!?;]\",x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def jaccard2(a,b):\n    ls_a = []\n    ls_b = []\n    for word in a:\n        ls_a.append(word.lower())\n    for word in b:\n        ls_b.append(word.lower())\n    a = set(ls_a) \n    b = set(ls_b)\n    c = a.intersection(b)\n    denom = (len(a) + len(b) - len(c))\n    if denom == 0:\n        return 1\n    return float(len(c)) / denom\ndef calculate_jac2(df):\n    ls = []\n    for row in df.iterrows():\n        row = row[1]\n        a = row.selected_text_2\n        b = row.selected_text_2_out\n        jac = jaccard2(a,b)\n        ls.append(jac)\n    return ls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df['jaccard2'] = calculate_jac2(df)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Analysis\n## Final Jaccard Scores","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print(df['jaccard'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Final Jaccard2 Scores","execution_count":null},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print(df['jaccard2'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Jaccard per fold\nNotice some difference even within each fold","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"for i in range(5):\n    df_i = df[df.kfold == i]\n    jac = df_i['jaccard'].mean()\n    print(f'For out of fold {i}, jaccard is {jac}')","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"for i in range(5):\n    df_i = df[df.kfold == i]\n    jac = df_i['jaccard2'].mean()\n    print(f'For out of fold {i}, jaccard2 is {jac}')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# See why the model fails  \nSince this is a conditional probability of predicting selected text given sentiment we should analyse by each sentiment","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"df_positive = df[df['sentiment']=='positive']\ndf_negative = df[df['sentiment']=='negative']\ndf_neutral = df[df['sentiment']=='neutral']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Jaccard scores for each sentiment","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Jaccard for positive',df_positive['jaccard'].mean())\nprint('Jaccard for negative',df_negative['jaccard'].mean())\nprint('Jaccard for neutral',df_neutral['jaccard'].mean())","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Jaccard2 for positive',df_positive['jaccard2'].mean())\nprint('Jaccard2 for negative',df_negative['jaccard2'].mean())\nprint('Jaccard2 for neutral',df_neutral['jaccard2'].mean())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bad examples of each sentiment","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def print_bad_examples(df,num=10):\n    df = df.sort_values(by=['jaccard'])\n    for i in range(num):\n        row = df.iloc[i]\n        print('text:             ', row.text.strip())\n        print('selected text:    ', row.selected_text.strip())\n        print('my selected text: ',row.selected_text_out.strip())\n        print('-'*50)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def print_bad_examples2(df,num=10):\n    df = df.sort_values(by=['jaccard2'])\n    for i in range(num):\n        row = df.iloc[i]\n        print('text:             ', row.text.strip())\n        print('selected text:    ', row.selected_text.strip())\n        print('my selected text: ',row.selected_text_out.strip())\n        print('-'*50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bad examples for positive sentiments\nSeems to me here that even for bad examples the model performs fairly well and most of this can be attributed to human labelling issues.  \n'Best Model' that wins the competition might not be objectively useful as it might learn the bias of the human labellers.  \nFor example `good` and `nice` are both acceptable to me in the first/worst example!  ","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Jaccard Worst Examples positive sentiment \\n')\nprint_bad_examples(df_positive)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Jaccard2 Worst Examples positive sentiment \\n')\nprint_bad_examples2(df_positive)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Bad examples for negative sentiments\nSimilar conclusion to positive. But perhaps when there are two or more sentiments in the model, the model fails to pick the one that is more intense?  \nFor example in `****` vs `pissed` and `stupid` vs `i hate`","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Jaccard Worst Examples negative sentiment \\n')\nprint_bad_examples(df_negative)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Jaccard2 Worst Examples negative sentiment \\n')\nprint_bad_examples2(df_negative)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bad examples for neutral sentiments\nHere I just returned the selected text as it is. Seems to me here that most of the errors are punctuations.  \nA way to easily get higher score is to objectively truncate the punctuations such as to maximise jaccard scores.  \nSeems like some of the examples are mislabbeled sentiments. The last 5 rows are to me at least mislabelled.","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"print('Jaccard Worst Examples neutral sentiment \\n')\nprint_bad_examples(df_neutral)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Jaccard2 Worst Examples neutral sentiment \\n')\nprint_bad_examples2(df_neutral)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets plot the distribution of my model","execution_count":null},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 3))\naxes[0].hist(df.jaccard.values)\naxes[0].set_title('Histogram of all jaccard scores')\naxes[1].hist(df.jaccard2.values)\naxes[1].set_title('Histogram of all jaccard2 scores')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 3))\naxes[0].hist(df_neutral.jaccard.values)\naxes[0].set_title('Histogram of all neutral jaccard scores')\naxes[1].hist(df.jaccard2.values)\naxes[1].set_title('Histogram of all neutral jaccard2 scores')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 3))\naxes[0].hist(df_positive.jaccard.values)\naxes[0].set_title('Histogram of all positive jaccard scores')\naxes[1].hist(df.jaccard2.values)\naxes[1].set_title('Histogram of all positive jaccard2 scores')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(9, 3))\naxes[0].hist(df_negative.jaccard.values)\naxes[0].set_title('Histogram of all negative jaccard scores')\naxes[1].hist(df.jaccard2.values)\naxes[1].set_title('Histogram of all negative jaccard2 scores')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Conclusion\n## For positive/negative sentiments\nit seems like the model might miss out the context and only pick the word with the sentiment.  \nAlso when there are more than 1 sentiment in a sentence sometimes the model picks the less intense word/span.  \n## For neutral sentiments\nPunctuations truncations or extention. Pick the optimal truncation/extension strategy such that it maximises your jaccard scores.  \nSome mislabelled examples in training set when it is suppose to be positive or negative spotting this might result in improve of scores!\n\n## Last words\nSolving the above issues will take considerable effort and some needs to be hardcoded :(. Hardcoding in any solution in my opinion is bad as it is not generaliable to other problems. The best solution would be to solve the above problems without hardcoding any rules.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}