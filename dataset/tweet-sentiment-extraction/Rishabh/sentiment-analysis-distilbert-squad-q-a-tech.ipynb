{"cells":[{"metadata":{"_uuid":"92555058-7d04-47cd-bdf0-1cd7a05d1dbb","_cell_guid":"5e74d7df-1620-4b7f-b74b-9e79d0aa79e7","trusted":true},"cell_type":"markdown","source":"# Problem Statement:\nThis problem is quite different than default NLP task in which we are asked to predict the sentiment of sentence. In this competition given, the polarity we are asked to determine/select the words that are going to decide the polarity of the sentence."},{"metadata":{"_uuid":"f3e16826-4baa-412f-b2ab-8a3bea3110b1","_cell_guid":"e283b927-7888-4f46-9b25-26af12aadf41","trusted":true},"cell_type":"markdown","source":"# Evaluation Metric\n\nEvaluation metric here is **Jacard Score**. Which is also called Intersection over union and used mainly in CNN tasks. \n![](https://www.displayr.com/wp-content/uploads/2018/09/Jaccard-formula.png)\n![](https://upload.wikimedia.org/wikipedia/commons/c/c7/Intersection_over_Union_-_visual_equation.png)"},{"metadata":{"_uuid":"d77c6b7f-509e-48e9-8d14-3c21b4b06331","_cell_guid":"8264c1b0-a9bc-4a8b-a620-a3424980bc4e","trusted":true},"cell_type":"markdown","source":"# Table of Content\n- 1. Dataset and Libraries\n   - 1.1 Importing libraries\n   - 1.2 Reading Data\n- 2. Exploratory Data Analysis\n   - 2.1 Finding the missing values\n   - 2.2 Distribution of sentiment class\n- 3. Analysis of text and selected_data\n   - 3.1 Percentage of neutral, negative, positive words in train and test data\n   - 3.2 Length of words for in each category\n   - 3.3 Comparing test and selected text column\n- 4. Text Statistics\n   - 4.1 Percentage of text column sentences is equal selected_text column for neutral sentiment\n   - 4.2 Punctuation Count\n- 5. Word Cloud\n- 6. N Grams\n- 7. DistilBERT + SQuAD + Question Answering Technique\n   - 7.1 Data Preprocessing"},{"metadata":{"_uuid":"aa757db3-42fa-4fbd-b627-0be1001d146f","_cell_guid":"f647beea-8df4-4116-ad2a-c0faf3ce63cc","trusted":true},"cell_type":"markdown","source":"**Do upvote this kernal also. It helped me alot in BERT modelling**\n\nhttps://www.kaggle.com/jonathanbesomi/question-answering-starter-pack"},{"metadata":{"_uuid":"f52677f4-dad1-4437-8ca6-9a401bf350b4","_cell_guid":"dec3d1a3-3479-4aa4-b596-db11d8761c63","trusted":true},"cell_type":"markdown","source":"# 1. Dataset and Libraries"},{"metadata":{"_uuid":"8855b7c1-b5a3-4923-8177-e76a7347e18b","_cell_guid":"1104c60a-2985-46fe-b52a-44a0ee75ca88","trusted":true},"cell_type":"markdown","source":"**1.1 Importing Libraries**"},{"metadata":{"_uuid":"8d5dd82a-1638-4fd3-ab1b-203c697ce664","_cell_guid":"7e15f9bc-7a50-4f45-8198-5f7eecc1b41e","trusted":true},"cell_type":"code","source":"!mkdir data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"df1ab864-8e13-4f08-b6aa-5710c39671d9","_cell_guid":"bb3af48e-4160-42c7-8360-601662df5ad6","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nfrom wordcloud import WordCloud, STOPWORDS\nimport tensorflow as tf\nimport missingno as msno\nfrom collections import defaultdict\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport json\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1d31ed6a-5a2e-4010-86d1-498d5db8be58","_cell_guid":"88b9d935-b591-4a92-944b-fe7eeab46962","trusted":true},"cell_type":"markdown","source":" **1.2 Reading Data**"},{"metadata":{"_uuid":"ad42984f-5c6c-401f-89df-341478156bb7","_cell_guid":"39c1874c-86ac-4979-abc5-acf1aa44cfc6","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\nsample_submission = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"535372ea-7008-4e37-8ddd-c8d2038e521f","_cell_guid":"07bb98ad-cd35-449c-b34d-22418543cb71","trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e40cb3c6-17a6-4fae-9915-470ea34c9ab6","_cell_guid":"1ac79209-02d7-44c8-82aa-7a6f0cb4bff9","trusted":true},"cell_type":"markdown","source":"# 2. Exploratory Data Analysis"},{"metadata":{"_uuid":"2237a0af-1bab-4ef2-b883-3a5102fd790d","_cell_guid":"f93f3884-6f6c-474a-a72b-e572b630b057","trusted":true},"cell_type":"markdown","source":"**2.1 Finding the missing values**"},{"metadata":{"_uuid":"e992932f-ef2c-4448-9e8b-93229cff6ff3","_cell_guid":"acffd340-6377-4a67-869d-7494d9dd5392","trusted":true},"cell_type":"code","source":"# Finding the missing values\nfig, axes = plt.subplots(1, 2, figsize=(15,6))\nplt.tight_layout(pad = 10)\nmsno.bar(train, ax = axes[0])\nmsno.bar(test, ax = axes[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"750be8ba-8e5b-4c3a-89d8-0914aee8eeff","_cell_guid":"f4e72bea-a15c-430c-acf7-4d91914f3003","trusted":true},"cell_type":"markdown","source":"There is one missing value in text and selected_text column in train data"},{"metadata":{"_uuid":"ad3f2295-6d93-4d2a-8db6-fca975d4252f","_cell_guid":"43f30978-7835-4eb2-a11a-27b435f26a33","trusted":true},"cell_type":"code","source":"print(train[train[\"text\"].isnull() == True])\n# We can drop this row\ntrain.dropna(inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fa4f1698-7f93-4f6e-872a-6eb0d1b2cf27","_cell_guid":"c2336f69-09c5-4b65-8e43-0fb2aa37d468","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(15,6))\nplt.tight_layout(pad = 10)\nmsno.bar(train, ax = axes[0])\nmsno.bar(test, ax = axes[1])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a0cafea-4ab3-4595-83a0-2cae9a2829f3","_cell_guid":"a1b8d864-b444-4b4c-a63c-a6d846b92803","trusted":true},"cell_type":"markdown","source":"No null value left in the train and test data"},{"metadata":{"_uuid":"f0715793-9e8d-4653-9547-8e6168f739dc","_cell_guid":"06044a14-d956-461d-b01d-56554bdbef0d","trusted":true},"cell_type":"markdown","source":"**2.2 Distribution of missing class**"},{"metadata":{"_uuid":"3924872d-37dc-48bc-8e6d-6008b5f2e294","_cell_guid":"9106b5f5-a281-4797-8e02-cd6ba67cb364","trusted":true},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"724d1c21-97cf-4452-b0d2-7d033310406b","_cell_guid":"bbdd6e00-0b4d-4b69-8c12-85aec8868ede","trusted":true},"cell_type":"code","source":"# Distribution of sentiment class\nfig, axes = plt.subplots(1, 2, figsize=(15,8))\nfig.suptitle(\"Comparing Ratio of Neutral Negative and Positive in train and test data\", fontsize = 25)\nplt.tight_layout(pad = 3.5)\nsns.countplot(x = \"sentiment\", data = train, ax = axes[0])\nsns.countplot(x = \"sentiment\", data = test, ax = axes[1])\naxes[0].set_xlabel(\"Sentiment\", fontsize = 20)\naxes[0].set_ylabel(\"Count\", fontsize = 20)\naxes[1].set_xlabel(\"Sentiment\", fontsize = 20)\naxes[1].set_ylabel(\"Count\", fontsize = 20)\nsns.despine()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0f67d289-3d58-49df-83e0-87772ff5cada","_cell_guid":"072a8e29-1db0-4ed2-8a03-b7eb72b75bc6","trusted":true},"cell_type":"markdown","source":"# 3. Analysis of text and selected_text"},{"metadata":{"_uuid":"67156a4d-05a0-4927-b5eb-e1ebaac23f9f","_cell_guid":"cb2e9800-ab71-4be3-b260-d1707e595054","trusted":true},"cell_type":"markdown","source":"**3.1 Percentage of neutral, negative, positive words in train and test data**"},{"metadata":{"_uuid":"676bcf83-58ef-49f8-bf5c-abacde9ba1b3","_cell_guid":"41a7a2da-2161-47be-b87b-a3ac7b3dbd36","trusted":true},"cell_type":"code","source":"# Percentage of neutral, negative, positive words in train and test data\ndef pert_count(data, category):\n    return (len(data[data[\"sentiment\"] == category])/len(data)) * 100\n\nprint(f\"Percentage of neutral words in train --> {pert_count(train, 'neutral')}%\")\nprint(f\"Percentage of negative words in train --> {pert_count(train, 'negative')}%\")\nprint(f\"Percentage of positive words in train --> {pert_count(train, 'positive')}%\")\nprint(f\"Percentage of neutral words in test --> {pert_count(test, 'neutral')}%\")\nprint(f\"Percentage of negative words in test --> {pert_count(test, 'negative')}%\")\nprint(f\"Percentage of positive words in test --> {pert_count(test, 'positive')}%\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8836bb0a-a7c3-42a7-9abb-b60854f07edf","_cell_guid":"14ef6044-8735-4d10-83b8-a97b4f78abea","trusted":true},"cell_type":"markdown","source":"**We can see from above analysis that the percentage of neutral, positive and negative words are quite similar. It may be due to the fact that train and test data came from same sample**"},{"metadata":{"_uuid":"f843e8b9-48c6-4f11-b9b2-383801a03317","_cell_guid":"ba88e572-5231-4b7c-b7df-4b00b96e879f","trusted":true},"cell_type":"markdown","source":"**3.2 Length of words for in each category**"},{"metadata":{"_uuid":"339db384-415b-4947-a3d0-c7ec81417307","_cell_guid":"09eff635-b6a8-4bbb-b610-9a4243a2ccbd","trusted":true},"cell_type":"code","source":"# Length of words for in each category\ndef len_sent(data):\n    return len(data.split())\n\ntrain[\"num_words_text\"] = train[\"text\"].apply(lambda x : len_sent(x))\ntest[\"num_words_text\"] = test[\"text\"].apply(lambda x : len_sent(x))\ntrain[\"num_words_selected_text\"] = train[\"selected_text\"].apply(lambda x : len_sent(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"de0dde5e-1b35-4de9-8bed-cf384cf924e7","_cell_guid":"86978dd6-0dd4-494a-b31f-de7f74357c7f","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, sharey = True, figsize = (15, 20))\nfig.suptitle(\"Comparing train and test data based on sentiment length\", fontsize = 25)\nsns.kdeplot(train[train[\"sentiment\"] == \"neutral\"][\"num_words_text\"].values, ax  = axes[0], shade = True, color = \"blue\", label = \"train\")\nsns.kdeplot(test[test[\"sentiment\"] == \"neutral\"][\"num_words_text\"].values, ax  = axes[0], shade = True, color = \"red\", label = \"test\")\nsns.kdeplot(train[train[\"sentiment\"] == \"negative\"][\"num_words_text\"].values, ax  = axes[1], shade = True, color = \"blue\", label = \"train\")\nsns.kdeplot(test[test[\"sentiment\"] == \"negative\"][\"num_words_text\"].values, ax  = axes[1], shade = True, color = \"red\", label = \"test\")\nsns.kdeplot(train[train[\"sentiment\"] == \"positive\"][\"num_words_text\"].values, ax  = axes[2], shade = True, color = \"blue\", label = \"train\")\nsns.kdeplot(test[test[\"sentiment\"] == \"positive\"][\"num_words_text\"].values, ax  = axes[2], shade = True, color = \"red\", label = \"test\")\naxes[0].set_xlabel(\"Sentiment_length_neutral\", fontsize = 20)\naxes[0].set_ylabel(\"Distribution\", fontsize = 20)\naxes[1].set_xlabel(\"Sentiment_length_negative\", fontsize = 20)\naxes[1].set_ylabel(\"Distribution\", fontsize = 20)\naxes[2].set_xlabel(\"Sentiment_length_positive\", fontsize = 20)\naxes[2].set_ylabel(\"Distribution\", fontsize = 20)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c47638ce-3a28-4b9c-9bca-5920ef9f4656","_cell_guid":"416bb826-6b4a-4b6d-bfb6-b303af8a8b19","trusted":true},"cell_type":"markdown","source":"We can see from above distribution plots that distribution of word length is quite similar in train and test data for each sentiment category"},{"metadata":{"_uuid":"4747f7c6-030d-4ed9-8339-9efbc22f66fe","_cell_guid":"02db7a26-cf37-45e8-9282-6b8c0fef3d9f","trusted":true},"cell_type":"markdown","source":"**3.3 Comparing test and selected text column**"},{"metadata":{"_uuid":"ae079bd2-4e5f-488e-b674-fb4db118bde3","_cell_guid":"ee57c861-4aa9-42f8-a450-151e35173fae","trusted":true},"cell_type":"code","source":"# Comparing test and selected text column\nfig, axes = plt.subplots(3, 1, sharey = True, figsize = (15, 20))\nfig.suptitle(\"\", fontsize = 25)\nsns.kdeplot(train[train[\"sentiment\"] == \"neutral\"][\"num_words_text\"].values, ax  = axes[0], shade = True, color = \"blue\", label = \"text\")\nsns.kdeplot(train[train[\"sentiment\"] == \"neutral\"][\"num_words_selected_text\"].values, ax  = axes[0], shade = True, color = \"red\", label = \"selected_text\")\nsns.kdeplot(train[train[\"sentiment\"] == \"negative\"][\"num_words_text\"].values, ax  = axes[1], shade = True, color = \"blue\", label = \"text\")\nsns.kdeplot(train[train[\"sentiment\"] == \"negative\"][\"num_words_selected_text\"].values, ax  = axes[1], shade = True, color = \"red\", label = \"selected_text\")\nsns.kdeplot(train[train[\"sentiment\"] == \"positive\"][\"num_words_text\"].values, ax  = axes[2], shade = True, color = \"blue\", label = \"text\")\nsns.kdeplot(train[train[\"sentiment\"] == \"positive\"][\"num_words_selected_text\"].values, ax  = axes[2], shade = True, color = \"red\", label = \"selected_text\")\naxes[0].set_xlabel(\"Sentiment_length_neutral\", fontsize = 20)\naxes[0].set_ylabel(\"Distribution\", fontsize = 20)\naxes[1].set_xlabel(\"Sentiment_length_negative\", fontsize = 20)\naxes[1].set_ylabel(\"Distribution\", fontsize = 20)\naxes[2].set_xlabel(\"Sentiment_length_positive\", fontsize = 20)\naxes[2].set_ylabel(\"Distribution\", fontsize = 20)\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7a12c977-5b08-491e-bec8-c0f9eff37d3d","_cell_guid":"0e2c561a-6871-4cde-92dd-ebf687e7fdbb","trusted":true},"cell_type":"markdown","source":"We can see from above graphs that for neutral sentences the distribution of length is approximately the same in text and selected_text column. For negative and positive sentiment the length of selected_text column is shorter than text column"},{"metadata":{"_uuid":"71f2ad4a-6b88-4dac-b4b2-55f5f1069c09","_cell_guid":"6f73993c-1497-4047-8a2b-5d77e49ce0e8","trusted":true},"cell_type":"markdown","source":"# 4. Text Statistics"},{"metadata":{"_uuid":"f57083cf-af64-4444-b40c-f2faf4ded7a2","_cell_guid":"7be52890-176a-40ed-b357-0e6f0e28d193","trusted":true},"cell_type":"markdown","source":""},{"metadata":{"_uuid":"e3479a89-8b1e-4286-9557-a79cfb64d8b4","_cell_guid":"85627ddc-5b14-4445-ae84-6f16bf3027b3","trusted":true},"cell_type":"markdown","source":" **4.1 Percentage of text column sentences is equal selected_text column for neutral sentiment**"},{"metadata":{"_uuid":"ed5face9-9527-4864-b558-fa9bfcb29a4d","_cell_guid":"dc42bf3e-5768-4fe4-822b-045f651ae6b7","trusted":true},"cell_type":"code","source":"train[\"text\"] = train[\"text\"].apply(lambda x : x.strip())\ntrain[\"selected_text\"] = train[\"selected_text\"].apply(lambda x : x.strip())\n\n\ntrain[\"is_equal\"] = (train[\"text\"] == train[\"selected_text\"])\ndf_neutral = train[train[\"sentiment\"] == \"neutral\"]\npercentage = (len(df_neutral[df_neutral[\"is_equal\"] == True])/len(df_neutral)) * 100\nprint(f\"Percentage of text column sentences is equal selected_text column for neutral sentiment --> {percentage}\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4c304f48-9717-4d45-9449-7702abe59060","_cell_guid":"6332ad52-95f8-472f-9c34-d2a0293a840b","trusted":true},"cell_type":"markdown","source":"**As most of the train[\"text\"] data is same as train[\"selected_text\"] for neutral sentiment. So I will simply copy paste test[\"text\"] for neutral sentiment prediction"},{"metadata":{"_uuid":"1be009f7-b0b1-41c3-a753-d37ba4c81ab3","_cell_guid":"9158c147-279b-4997-8cd8-647fb65e2d4f","trusted":true},"cell_type":"markdown","source":"**4.2 Punctuation count**"},{"metadata":{"_uuid":"a72a7970-d13e-49bf-8da3-44cf6a0619fe","_cell_guid":"bd1f6f7a-efa5-4f02-9d0d-3c51f70adc52","trusted":true},"cell_type":"code","source":"# Punctuation count in train[\"text\"], train[\"selected_text\"]\ndef punc_count(data):\n    return len([w for w in data if w in string.punctuation])\n\ntrain[\"text_punc_count\"] = train[\"text\"].apply(lambda x : punc_count(x))\ntrain[\"selected_text_punc_count\"] = train[\"selected_text\"].apply(lambda x : punc_count(x))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"58775e24-a74e-47e9-b618-8055e201e34e","_cell_guid":"b8aaeaaf-bb54-4251-a324-75de2d6436fe","trusted":true},"cell_type":"code","source":"plt.figure(figsize = (15, 8))\nsns.kdeplot(train[\"text_punc_count\"].values, shade = True, color = \"blue\", label = \"Text punc count\")\nsns.kdeplot(train[\"selected_text_punc_count\"].values, shade = True, color = \"yellow\", label = \"Selected text punc count\")\nplt.title(\"Punctuation Count\", fontsize = 30)\nplt.xlabel(\"Punctuation Count\", fontsize = 20)\nplt.ylabel(\"Distribution\", fontsize = 20)\nsns.despine()\nplt.legend(loc = \"lower right\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cfa53608-7776-4401-964d-22cddcbfc0fa","_cell_guid":"8c6c6ee7-ae63-4188-b510-6cc9d4e955f4","trusted":true},"cell_type":"markdown","source":"# 5. Word Cloud"},{"metadata":{"_uuid":"653c6001-a753-4ebb-bfdb-e5ea438cf49d","_cell_guid":"25fe9d27-82b1-4b6e-8516-110800f84ebe","trusted":true},"cell_type":"code","source":"# Most repeated words in text column and selected_text\nstopwords = set(STOPWORDS)\ndef word_cloud(data, title):\n    wordcloud = WordCloud(\n    background_color = \"black\",\n    max_font_size = 40,\n    max_words = 200,\n    stopwords = stopwords,\n    scale = 3).generate(str(data))\n    fig = plt.figure(figsize = (15, 15))\n    plt.axis(\"off\")\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.25)\n\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f9d46937-a062-4876-82b8-516d4056d678","_cell_guid":"3df7a5eb-9f82-4dc2-a678-5eccfd8a1216","trusted":true},"cell_type":"code","source":"word_cloud(train[\"text\"], \"Most Repeated words in train['text']\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5b99724-db3a-47d5-93e8-26c1c27c1b9a","_cell_guid":"528429bc-f4eb-484f-81d7-0bb4f9b62c12","trusted":true},"cell_type":"code","source":"word_cloud(train[train[\"sentiment\"] == \"neutral\"][\"text\"], \"Most Repeated words in neural sentences train['text']\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"45307317-c7f9-44c2-bf8d-fa99506d40ba","_cell_guid":"ac3b8ac6-3980-4e4e-8029-12e1d7494aff","trusted":true},"cell_type":"code","source":"word_cloud(train[train[\"sentiment\"] == \"negative\"][\"text\"], \"Most Repeated words in negative sentences train['text']\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e5a8056a-c440-437f-a529-7f3b188e021f","_cell_guid":"485ccbb7-f4c1-4cf2-bbcb-59f58e4eb189","trusted":true},"cell_type":"code","source":"word_cloud(train[train[\"sentiment\"] == \"positive\"][\"text\"], \"Most Repeated words in positive sentences train['text']\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"943907cc-49df-4385-b4c0-f05b0a2c5c11","_cell_guid":"b5ac2fec-4597-48c8-929a-ee7e9233e91e","trusted":true},"cell_type":"markdown","source":"# 6. N Grams"},{"metadata":{"_uuid":"2d8130e3-5e77-4c47-be59-67a66d817cab","_cell_guid":"1a2197b9-4b63-4e68-90b4-e494a8a13f14","trusted":true},"cell_type":"code","source":"# N-Grams for neutral, positive negative sentences\ndef n_grams(ngram, data):\n    freq_dict = defaultdict(int)\n    for text in data:\n        tokens = [w for w in text.lower().split() if w != \" \" if w not in stopwords]\n        ngrams = zip(*[tokens[i:] for i in range(ngram)])\n        list_grams = [\" \".join(ngram) for ngram in ngrams]\n        for word in list_grams:\n            freq_dict[word] += 1\n    fd_sorted =  pd.DataFrame(sorted(freq_dict.items(), key=lambda x: x[1])[::-1])   \n    fd_sorted.columns = [\"word\", \"wordcount\"]\n    return fd_sorted\n                    \nfd_sorted_neutral1 = n_grams(1, train[train[\"sentiment\"] == \"neutral\"][\"text\"])    \nfd_sorted_negative1 = n_grams(1, train[train[\"sentiment\"] == \"negative\"][\"text\"])    \nfd_sorted_positive1 = n_grams(1, train[train[\"sentiment\"] == \"positive\"][\"text\"]) \n\nfd_sorted_neutral2 = n_grams(2, train[train[\"sentiment\"] == \"neutral\"][\"text\"])    \nfd_sorted_negative2 = n_grams(2, train[train[\"sentiment\"] == \"negative\"][\"text\"])    \nfd_sorted_positive2 = n_grams(2, train[train[\"sentiment\"] == \"positive\"][\"text\"]) \n\nfd_sorted_neutral3 = n_grams(3, train[train[\"sentiment\"] == \"neutral\"][\"text\"])    \nfd_sorted_negative3 = n_grams(3, train[train[\"sentiment\"] == \"negative\"][\"text\"])    \nfd_sorted_positive3 = n_grams(3, train[train[\"sentiment\"] == \"positive\"][\"text\"])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c576202e-4d8a-45ca-a2de-51e7017b1a79","_cell_guid":"f08c5262-a06a-4721-ad5b-77c0ef58a788","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize = (10, 18))\nplt.tight_layout(pad = 7.5)\nplt.suptitle(\"Unigrams\", fontsize = 25)\nsns.despine()\nl = [\"neutral\", \"negative\", \"positive\"]\nfor i in range(3):\n    sns.barplot(x = \"wordcount\", y = \"word\", data = globals()[\"fd_sorted_\" + str(l[i]) + str(1)].iloc[:20, :], ax = axes[i])\n    axes[i].set_title(f\"Most repeated words in {l[i]} sentences\", fontsize = 20)\n    axes[i].set_xlabel(\"WordCount\", fontsize = 15)    \n    axes[i].set_ylabel(\"Word\", fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5403f158-7b87-466a-b6e6-b2ee312636b3","_cell_guid":"e6308e78-c65a-4805-9b6a-11dfed235cfc","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize = (10, 18))\nplt.tight_layout(pad = 7.5)\nplt.suptitle(\"Bigrams\", fontsize = 25)\nsns.despine()\nl = [\"neutral\", \"negative\", \"positive\"]\nfor i in range(3):\n    sns.barplot(x = \"wordcount\", y = \"word\", data = globals()[\"fd_sorted_\" + str(l[i]) + str(2)].iloc[:20, :], ax = axes[i])\n    axes[i].set_title(f\"Most repeated words in {l[i]} sentences\", fontsize = 20)\n    axes[i].set_xlabel(\"WordCount\", fontsize = 15)    \n    axes[i].set_ylabel(\"Word\", fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a1e2a7a5-fbf9-4582-88c4-4700f6cf44af","_cell_guid":"0aaf7aee-eaa3-450b-9c92-b41abdb96aaf","trusted":true},"cell_type":"code","source":"fig, axes = plt.subplots(3, 1, figsize = (10, 18))\nplt.tight_layout(pad = 7.5)\nplt.suptitle(\"Trigrams\", fontsize = 25)\nsns.despine()\nl = [\"neutral\", \"negative\", \"positive\"]\nfor i in range(3):\n    sns.barplot(x = \"wordcount\", y = \"word\", data = globals()[\"fd_sorted_\" + str(l[i]) + str(3)].iloc[:20, :], ax = axes[i])\n    axes[i].set_title(f\"Most repeated words in {l[i]} sentences\", fontsize = 20)\n    axes[i].set_xlabel(\"WordCount\", fontsize = 15)    \n    axes[i].set_ylabel(\"Word\", fontsize = 15)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f099e3d0-6167-4097-b869-4f537670a87f","_cell_guid":"748eee9a-2b9e-4f02-8a3c-9d70eda03538","trusted":true},"cell_type":"markdown","source":"# 7 DistilBERT + SQuAD + Question Answering Technique"},{"metadata":{"_uuid":"f18c2850-1935-459e-a87b-d5e1004700d5","_cell_guid":"a2112536-ba0d-49b1-afb4-0a205b3544b1","trusted":true},"cell_type":"code","source":"train_array = np.array(train.iloc[:, :4])\ntest_array = np.array(test.iloc[:, :3])\nuse_cuda = True","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4564e7a5-742f-40bc-81a8-96d95863cc64","_cell_guid":"f2d327e8-198d-4f15-8a1b-86005722f3bf","trusted":true},"cell_type":"markdown","source":"# 7.1 Data preparation"},{"metadata":{"_uuid":"483cca37-0c00-4dcd-90a7-662271efe58e","_cell_guid":"81e8e880-215c-4e89-885d-88f22dbd7fe4","trusted":true},"cell_type":"code","source":"# Getting starting index of selected_text found in text\ndef start_index(text, selected_text):\n    start_index = text.lower().find(selected_text.lower())\n    l.append(start_index)\n    \nl = []\nfor i in range(len(train_array)):\n    start_index(train_array[i, 1], train_array[i, 2])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cbe41ea3-a03c-4268-8694-ddc5d805e461","_cell_guid":"b6c4c54e-a91d-4621-8520-1419c1c47de0","trusted":true},"cell_type":"code","source":"# We are taking\n# question --> sentiment\n# context --> text\n# answer --> selected_text\n\ndef quesa_format_train(train):\n    out = []\n    for i, row in enumerate(train):\n        qas = []\n        con = []\n        ans = []\n        question = row[-1]\n        answer = row[2]\n        context = row[1]\n        qid = row[0]\n        answer_start = l[i]\n        ans.append({\"answer_start\": answer_start, \"text\": answer.lower()})\n        qas.append({\"question\": question, \"id\": qid, \"is_impossible\": False, \"answers\": ans})\n        out.append({\"context\": context.lower(), \"qas\": qas})\n\n    return out\n        \n    \ntrain_json_format = quesa_format_train(train_array)\nwith open('data/train.json', 'w') as outfile:\n    json.dump(train_json_format, outfile)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"382f3247-80a7-438a-9ce1-957c7a0b63a9","_cell_guid":"db996e90-9791-47ce-ba7a-afcd2ed4ccd3","trusted":true},"cell_type":"code","source":"# Similarly for text data\n\ndef quesa_format_test(train):\n    out = []\n    for i, row in enumerate(train):\n        qas = []\n        con = []\n        ans = []\n        question = row[-1]\n#         answer = row[2]\n        context = row[1]\n        qid = row[0]\n        answer_start = l[i]\n        ans.append({\"answer_start\": 1000000, \"text\": \"__None__\"})\n        qas.append({\"question\": question, \"id\": qid, \"is_impossible\": False, \"answers\": ans})\n        out.append({\"context\": context.lower(), \"qas\": qas})\n    return out\n        \n    \ntest_json_format = quesa_format_test(test_array)\n\nwith open('data/test.json', 'w') as outfile:\n    json.dump(test_json_format, outfile)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"526a0874-8d60-4c11-9478-49cdb4b05c0d","_cell_guid":"46c0baa9-4c5f-45d0-8b73-3d36f871df4f","trusted":true},"cell_type":"code","source":"!pip install '/kaggle/input/train-requirements/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '/kaggle/input/train-requirements/simpletransformers-0.22.1-py3-none-any.whl' -q","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c3ff9388-a8af-413a-8f5d-1d845390a590","_cell_guid":"af6cf7d5-75d2-4401-b47a-9a246844c199","trusted":true},"cell_type":"code","source":"from simpletransformers.question_answering import QuestionAnsweringModel\n\nmodel_path = '/kaggle/input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad/'\n# MODEL_PATH = QuestionAnsweringModel.from_pretrained('distilbert-base-uncased-distilled-squad'\n\n# Create the QuestionAnsweringModel\nmodel = QuestionAnsweringModel('distilbert', \n                               model_path, \n                               args={'reprocess_input_data': True,\n                                     'overwrite_output_dir': True,\n                                     'learning_rate': 5e-5,\n                                     'num_train_epochs': 4,\n                                     'max_seq_length': 128,\n                                     'doc_stride': 64,\n                                     'fp16': False,\n                                    },\n                              use_cuda=use_cuda)\n\nmodel.train_model('data/train.json')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3a34ace5-b6ba-49a5-ac52-cc50cc4b8989","_cell_guid":"7a042bac-2c97-42e6-8d29-e845e3fb43b9","trusted":true},"cell_type":"code","source":"pred = model.predict(test_json_format)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7484ca6e-dd5e-4264-aaab-f900e2c4e1d4","_cell_guid":"19022863-a23c-4edd-afb9-df9947dc16cc","trusted":true},"cell_type":"code","source":"df = pd.DataFrame.from_dict(pred)\nsample_submission[\"selected_text\"] = df[\"answer\"]\n# new_df = sample_submission.merge(test,how=\"inner\",on=\"textID\")\n# new_df[\"selected_text\"] = np.where((new_df[\"sentiment\"] == \"neutral\"),new_df[\"text\"], new_df[\"selected_text\"])\n# submission = new_df[[\"textID\", \"selected_text\"]]\nsample_submission.to_csv(\"submission.csv\", index = False)\nprint(\"File submitted successfully.\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"592c608b-69ce-4beb-91ef-3498022d13f7","_cell_guid":"6f6c43eb-a234-4685-b840-441ff633473c","trusted":true},"cell_type":"markdown","source":"<span style=\"color:green\">**Do upvote this kernel if you found this helpful. Stay tuned!, i will update this kernel regularly**</span>"}],"metadata":{"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"}},"nbformat":4,"nbformat_minor":4}