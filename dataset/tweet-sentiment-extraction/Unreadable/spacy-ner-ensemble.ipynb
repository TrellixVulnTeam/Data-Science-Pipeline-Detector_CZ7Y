{"cells":[{"metadata":{},"cell_type":"markdown","source":"In this notebook, I treat the task of selecting a supporting phrase for a given tweet as a named entity recognition (NER) problem and train spaCy NER models.\n* No text pre-processing is necessary.\n* I train a blank spaCy model only on positive and negative sentiment.\n* As others pointed out, just using the whole text as the selection for neutral sentiment gives pretty good results, so I don't train a model on this subset.\n* I track Jaccard scores on both training and validation data. \n* I make a model ensemble using cross-validation.\n* I use majority voting to make a final prediction of the ensemble.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data loading","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ntrain_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv', na_filter=False)\ntest_df = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv', na_filter=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2):\n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    if len(a) + len(b) == len(c):\n        return 0.0\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def eval_jaccard(y_pred, y_true):\n    return sum(jaccard(sp, st) for sp, st in zip(y_pred, y_true)) / len(y_true)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Baseline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"eval_jaccard(train_df[\"text\"], train_df[\"selected_text\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"So, if we just use the full text field as our selected text, we can get pretty high already: ~0.6 Jaccard (mostly due to the neutral sentiment data).","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Data preparation","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 2020","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def to_spacy_format(X, Y, S):\n    data = []\n    for x, y, s in zip(X, Y, S):\n        if not x:\n            print(f\"'{x}': no tweet given\")\n            continue\n        if y and (s == \"positive\" or s == \"negative\"):            \n            start = x.find(y)\n            if start < 0:\n                print(\"Can't find a phrase: skipping...\")\n                continue\n            ex = (x, {\"entities\": [(start, start + len(y), s)]})\n        else:\n            ex = (x, {\"entities\": []})\n        data.append(ex)\n    return data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def from_spacy_format(data):\n    X, Y = [], []\n    for x, ann in data:\n        X.append(x)\n        if ann[\"entities\"]:\n            s = []\n            for e in ann[\"entities\"]:\n                s.append(x[e[0]: e[1]])                \n            Y.append(\" \".join(s))\n        else:\n            Y.append(x)\n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_spacy(nlp, X):\n    Y = []\n    for x in X:\n        doc = nlp(x)\n        if doc.ents:\n            y = \" \".join([e.text for e in doc.ents])\n        else:\n            y = x\n        Y.append(y)\n    return Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def baseline(data):\n    X, Y = from_spacy_format(data)\n    return eval_jaccard(X, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pathlib import Path\n\nmodel_dir = Path(\"/kaggle/working/model/\")\nmodel_dir.mkdir(exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import random\nimport numpy as np\nfrom spacy.util import minibatch, compounding, decaying\n\n\ndef train_model(nlp, train_data, model_dir,\n                valid_data=None, blank=False,\n                epochs=100, \n                dropouts=decaying(0.6, 0.2, 1e-6), \n                batch_sizes=compounding(1.0, 16.0, 1.0 + 1e-4)\n               ):\n    \n    x_train, y_train = from_spacy_format(train_data)    \n    \n    if valid_data:\n        best_score = 0\n        x_valid, y_valid = from_spacy_format(valid_data)\n    \n    random.seed(SEED)\n    \n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    else:\n        ner = nlp.get_pipe(\"ner\")\n        \n    ner.add_label(\"positive\")\n    ner.add_label(\"negative\")\n    \n    # get names of other pipes to disable them during training\n    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n    \n    # only train NER\n    with nlp.disable_pipes(*other_pipes):\n        \n        # reset and initialize the weights randomly\n        if blank:\n            optimizer = nlp.begin_training()\n        else:\n            optimizer = nlp.resume_training()\n        \n        for i in range(epochs):\n            random.shuffle(train_data)\n            losses = {}\n            \n            # batch up the examples using spaCy's minibatch\n            batches = minibatch(train_data, size=batch_sizes)\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                dropout = next(dropouts)\n                \n                nlp.update(\n                    texts,  # batch of texts\n                    annotations,  # batch of annotations\n                    sgd=optimizer,\n                    drop=dropout,  # dropout - make it harder to memorise data\n                    losses=losses,\n                )\n            \n            loss = losses['ner']\n            batch_size = next(batch_sizes)\n            dropout = next(dropouts)\n            \n            y_pred = predict_spacy(nlp, x_train)\n            tr_score = eval_jaccard(y_pred, y_train)\n            \n            message = f\"epoch {i + 1}: batch_size={batch_size:.1f}, dropout={dropout:.3f}, loss={loss:.3f}, tr_score={tr_score:.3f}\"\n            \n            if valid_data:\n                y_pred = predict_spacy(nlp, x_valid)\n                val_score = eval_jaccard(y_pred, y_valid)          \n                \n                if val_score > best_score:\n                    best_score = val_score\n                    if not model_dir.exists():\n                        model_dir.mkdir(parents=True)\n                    nlp.to_disk(model_dir)\n                \n                message = f\"{message}, val_score={val_score:.3f}\"\n            \n            print(message)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import spacy\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\n\n\ndef cross_validate(df, model_dir, folds=10, epochs=10, blank=True):\n    print(f\"Cross-validation: folds={folds}\")\n        \n    data = to_spacy_format(df.text, df.selected_text, df.sentiment)\n    \n    models = []    \n    skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state=SEED)\n    \n    for fold, (train_idx, valid_idx) in enumerate(skf.split(data, df.sentiment), start=1): \n        print(f'Fold: {fold}')\n        \n        train_set = set(train_idx)\n        valid_set = set(valid_idx)\n        \n        train_data = [x for i, x in enumerate(data) if i in train_set]\n        valid_data = [x for i, x in enumerate(data) if i in valid_set]\n        \n        baseline_score = baseline(valid_data)\n        print(f\"Baseline={baseline_score:.3f}\")\n        \n        if blank:\n            model = spacy.blank(\"en\")\n        else:\n            model = spacy.load(\"en_core_web_sm\")\n        \n        dropouts=decaying(0.5, 0.3, 1e-6)\n        batch_sizes=compounding(4.0, 16.0, 1.0 + 1e-4)\n        \n        model_path = Path(model_dir.joinpath(f\"spacy_fold_{fold}\"))\n        model_path.mkdir(parents=True)\n        \n        train_model(model, train_data, model_path, valid_data,\n                    dropouts=dropouts, batch_sizes=batch_sizes, \n                    blank=blank, epochs=epochs)\n        \n        models.append(model)\n    \n    return models","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_pn_df = train_df[(train_df[\"sentiment\"] == \"positive\") | (train_df[\"sentiment\"] == \"negative\")]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodels = cross_validate(train_pn_df, model_dir, folds=10, epochs=7, blank=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport math\n\ndef mode(array, prefer_min=True):\n    (values, counts) = np.unique(array, return_counts=True)\n    max_count = np.max(counts)\n    best = math.inf if prefer_min else - math.inf\n    for i in range(len(values)):\n        if counts[i] == max_count:\n            if prefer_min and best > values[i]:\n                best = values[i]\n            if not prefer_min and best < values[i]:\n                best = values[i]\n    return best","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def majority_vote(ys, x):\n    starts, ends = [], []\n    for y in ys:\n        start = x.find(y)\n        end = start + len(y)\n        starts.append(start)\n        ends.append(end)\n    y = x[mode(starts, prefer_min=True): mode(ends, prefer_min=False)]\n    return y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_all(models):\n    Y = []\n    for x, s in zip(test_df.text, test_df.sentiment):\n        if s == \"neutral\":\n            Y.append(x)\n        else:\n            ys = []\n            for model in models:\n                ys.append(predict_spacy(model, [x])[0])\n            Y.append(majority_vote(ys, x))\n    return Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nY_pred = predict_all(models)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df[\"selected_text\"] = Y_pred","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.DataFrame({\n    'textID': test_df['textID'],\n    'selected_text': Y_pred\n})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.to_csv('/kaggle/working/submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df.sample(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil\nshutil.rmtree(model_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}