{"cells":[{"metadata":{"_uuid":"2fc5ed87-41a7-468f-8de6-88802c6b1865","_cell_guid":"a56ebbdf-1bff-41cf-8a64-3c1ffa6d994b","trusted":true},"cell_type":"markdown","source":"# Loading Libraries"},{"metadata":{"_uuid":"8c752fe7-27f3-4cf2-9d3a-30deb79f0b14","_cell_guid":"0cbeb3a3-97e4-49fb-9ca6-8d1ba7cde0c7","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport re\nimport emoji\n\nfrom IPython.display import Markdown as md\nplt.style.use('ggplot')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f3d69169-d92a-4016-b28c-878485ea0b87","_cell_guid":"0089ca06-3571-42d0-9f64-c3ce6c235bbe","trusted":true},"cell_type":"code","source":"from sklearn.metrics import classification_report,accuracy_score,confusion_matrix","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d3afce68-d6a8-4acb-a151-bcb3ff524707","_cell_guid":"566497c8-56ca-4cfe-a668-0c77b947bef4","trusted":true},"cell_type":"markdown","source":"# Loading Data"},{"metadata":{"_uuid":"461be15f-4c27-4519-beca-5f670d8e4124","_cell_guid":"ca34000b-3247-40c1-803f-c05e6c8b023b","trusted":true},"cell_type":"code","source":"train_path = \"../input/tweet-sentiment-extraction/train.csv\"\ntest_path = \"../input/tweet-sentiment-extraction/test.csv\"\nsample_submission_path = \"../input/tweet-sentiment-extraction/sample_submission.csv\"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1ce2bba2-37d0-4d23-afc7-93ceaf54e303","_cell_guid":"1185db41-f0c8-41b7-bced-da3f1ddab3d0","trusted":true},"cell_type":"code","source":"df_train = pd.read_csv(train_path)\ndf_test = pd.read_csv(test_path)\nsubmission = pd.read_csv(sample_submission_path)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Explore Data"},{"metadata":{"_uuid":"c05724da-0f22-4797-a4a6-cf07cb88f4d4","_cell_guid":"a3d32cae-0cb9-449c-ab95-ad9967e6f622","trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4ef00386-de13-494a-9765-185789eddfae","_cell_guid":"38ea7643-6836-425f-9eb1-6d1ce4ec855b","trusted":true},"cell_type":"code","source":"df_train.info()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3ee23fb5-6dcd-402a-b468-2d9185fc4000","_cell_guid":"aeff4219-67bb-4626-849f-0361d2031753","trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Training data shape: ', df_train.shape)\nprint('Testing data shape: ', df_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Preprocessing"},{"metadata":{"_uuid":"0766f98e-fd6f-47d3-9c7e-eb53e5a020a7","_cell_guid":"a479277d-6347-4124-ad0e-ee12e24bedaf","trusted":true},"cell_type":"markdown","source":"### 2-1) Missing Values treatment in the dataset"},{"metadata":{"_uuid":"b2cb2697-d0e9-4e8a-a598-660a1b791151","_cell_guid":"19de41e6-ee19-4f79-8cce-482644329f66","trusted":true},"cell_type":"code","source":"#Missing values in training set\ndf_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Missing values in test set\ndf_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Drop missing value\ndf_train.dropna(axis = 0, how ='any',inplace=True) ;\ndf_test.dropna(axis = 0, how ='any',inplace=True) ;\ndf_train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.to_csv('./train_v1.csv', index = False)\ndf_test.to_csv('./test_v1.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7525e86c-8789-48bc-9515-e3877e07718b","_cell_guid":"b52d50d2-dfa2-43e1-b6ac-5c85cf2b045e","trusted":true},"cell_type":"markdown","source":"# Preprocessing with one function"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install text-preprocessing\n!pip install nltk","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!python -m pip install ../input/textpreprocessing/text_preprocessing-0.0.8-py2.py3-none-any.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import text_preprocessing\nimport string\n\n!pip install contractions\nimport contractions\n\nimport nltk\nnltk.download('punkt')\nfrom nltk.tokenize import word_tokenize\n\nimport string\npunc = string.punctuation\n\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\nnltk.download('averaged_perceptron_tagger')\n\nnltk.download('wordnet')\nfrom nltk.corpus import wordnet\n\nfrom nltk.stem import WordNetLemmatizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# text preprocessing helper functions\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = contractions.fix(text)\n    return text\n\n\ndef text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(tokenized_text)\n    return combined_text","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ea2bd7be-54d1-4643-a523-a4f53f063cd5","_cell_guid":"99e2dc5b-7c22-4d9a-8e5d-adf6b18e053b","trusted":true},"cell_type":"code","source":"# Applying the cleaning function to both test and training datasets\n#df_train['text_clean'] = df_train['text'].apply(str).apply(lambda x: text_preprocessing(x))\n\ndf_test['text_clean'] = df_test['text'].apply(str).apply(lambda x: text_preprocessing(x))\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.sample(frac=0.05)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"46c5b31d-215b-4452-b67a-6def04186659","_cell_guid":"575c48f7-0004-49fb-9776-5bb1b5ac880b","trusted":true},"cell_type":"code","source":"df_train.to_csv('./train_v1.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.to_csv('./test_v1.csv', index = False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Padding"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer.fit_on_texts(df_train['selected_text'])\nencoded_train = tokenizer.texts_to_sequences(df_train['selected_text'])\n\ntokenizer.fit_on_texts(df_test['text_clean'])\nencoded_test = tokenizer.texts_to_sequences(df_test['text_clean'])\n\nprint(encoded_train, encoded_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(encoded_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_len_train = max(len(item) for item in encoded_train)\nmax_len_test = max(len(item) for item in encoded_test)\nprint(max_len_train, max_len_test)\n\n#max_len: train, test equalize\nmax_len_train = 35\nmax_len_test = 35","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for item in encoded_train:\n    while len(item) < max_len_train:  \n        item.append(0)\n\npadded_np_train = np.array(encoded_train)\n\nfor item in encoded_test:\n    while len(item) < max_len_test:  \n        item.append(0)\n\npadded_np_test = np.array(encoded_test)\n\n#save\nnp.save('./padded_train.npy',padded_np_train)\nnp.save('./padded_test.npy',padded_np_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"padded_np_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"padded_np_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_test['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**from here"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"padded_train=np.load('../input/final-data/padded_train.npy')\npadded_test=np.load('../input/final-data/padded_test.npy')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/final-data/train_v1.csv')\ndf_test = pd.read_csv('../input/final-data/test_v1.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['sentiment'].shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding the number of labels\nnum_labels = len(set(df_train['sentiment']))\nprint(num_labels)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Label Encoder"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nlb=LabelEncoder()\nsent_train=lb.fit_transform(df_train['sentiment'])\nsent_test=lb.fit_transform(df_test['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(sent_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import the libraries\nimport seaborn as sns\n\nsns.countplot(x='sentiment',data=df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sent_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nonehot_encoder = OneHotEncoder(sparse=False)\n\n#train\nsent_train = sent_train.reshape(len(sent_train), 1)\ny_final = onehot_encoder.fit_transform(sent_train)\n\n#test\nsent_test = sent_test.reshape(len(sent_test), 1)\ny_test = onehot_encoder.fit_transform(sent_test)\n\nprint(y_final.shape, y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(y_final)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_final=padded_train\nx_final.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x_final, y_final, test_size=0.33, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Build Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(padded_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.unique(padded_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(np.unique(padded_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"voc_size=len(np.unique(padded_train))+1\nprint(voc_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#hyperparameter\nmax_features = voc_size\n\nembedding_dims = 300 # feature\nmax_len = 35 # time_step","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Embedding, SimpleRNN, LSTM, Dropout, Bidirectional","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Simple RNN (vanilla RNN)"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_model():\n    model = Sequential()\n    # 2d_array (data, max_len)\n    model.add(Embedding(voc_size, embedding_dims, input_length=max_len))\n    # 3d_array (data, max_len, embedding_dims)\n    model.add(SimpleRNN(32))\n    # 2d_array (data, value)\n    model.add(Dense(3, activation='softmax'))\n    # 1d_array [0, 1, 0, 0, 1]\n    \n    model.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'categorical_crossentropy')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = create_model()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 10, batch_size = 64)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 10, batch_size = 512)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras import regularizers","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.callbacks import ModelCheckpoint\nimport os\n\ncheckpoint_path = \"./cp-{epoch:04d}.ckpt\"\ncheckpoint_dir = os.path.dirname(checkpoint_path)\n\ncp_callback = ModelCheckpoint(checkpoint_path, verbose=1, \n                              save_weights_only=True, period=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_lstm_model():\n    model=Sequential()\n    model.add(Embedding(voc_size, embedding_dims, input_length=max_len))\n    model.add(LSTM(128))\n    model.add(Dense(3,activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    return model\n\nmodel_lstm = create_lstm_model()\nprint(model_lstm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history=model_lstm.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 10, batch_size = 512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss, acc = model_lstm.evaluate(x_test,  y_test, verbose=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history1=model_lstm.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 20, batch_size = 512)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(loss) + 1)\n\nplt.plot(epochs, loss, 'r', label = 'Training loss')\nplt.plot(epochs, val_loss, 'b', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()      \n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nplt.plot(epochs, acc, 'r', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'b', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_lstm.save('./save_model_lstm.h5')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN+RNN"},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.layers import Conv1D","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_cnn_model():\n    model = Sequential()\n    model.add(Embedding(voc_size, embedding_dims, input_length=max_len))\n    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(35,1)))\n    model.add(SimpleRNN(32))\n    model.add(Dense(3, activation='softmax'))\n    \n    model.compile(optimizer = 'adam', metrics=['accuracy'], loss = 'categorical_crossentropy')\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cnn = create_cnn_model()\nprint(model_cnn.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cnn.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 10, batch_size = 512)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN+LSTM"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_cnnlstm_model():\n    model=Sequential()\n    model.add(Embedding(voc_size, embedding_dims, input_length=max_len))\n    model.add(Conv1D(filters=64, kernel_size=2, activation='relu', input_shape=(35,1)))\n    model.add(LSTM(100))\n    model.add(Dense(3,activation='softmax'))\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n    return model\n\nmodel_cnnlstm = create_cnnlstm_model()\nprint(model_lstm.summary())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_cnnlstm.fit(x_train, y_train, validation_data = (x_test, y_test), epochs = 10, batch_size = 512)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"load model"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model\n# load model from single file\nmodel = create_lstm_model()\nmodel_lstm = load_model('../input/weight/save_model_lstm.h5')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}