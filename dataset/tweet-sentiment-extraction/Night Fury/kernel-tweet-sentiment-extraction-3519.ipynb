{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\npaths = []\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        paths.append(os.path.join(dirname, filename))\n        \ndef read_train():\n    train=pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\n    train['text']=train['text'].astype(str)\n    train['selected_text']=train['selected_text'].astype(str)\n    return train\n\ndef read_test():\n    test=pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\n    test['text']=test['text'].astype(str)\n    return test\n\ndef read_submission():\n    test=pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\n    return test      \n!mkdir -p data\n!pip install '/kaggle/input/simple-transformers-pypi/seqeval-0.0.12-py3-none-any.whl' -q\n!pip install '/kaggle/input/simple-transformers-pypi/simpletransformers-0.22.1-py3-none-any.whl' -q\nprint(\"installation done\")\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_all(input_str, search_str):\n    l1 = []\n    length = len(input_str)\n    index = 0\n    while index < length:\n        i = input_str.find(search_str, index)\n        if i == -1:\n            return l1\n        l1.append(i)\n        index = i + 1\n    return l1\n\ndef do_qa_train(train):\n\n    output = {}\n    output['version'] = 'v1.0'\n    output['data'] = []\n    paragraphs = []\n    for line in train:\n        context = line[1]\n\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        answers = []\n        answer = line[2]\n        if type(answer) != str or type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answer_starts = find_all(context, answer)\n        for answer_start in answer_starts:\n            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n            break\n\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        paragraphs.append({'context': context.lower(), 'qas': qas})\n        output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n        \n    return paragraphs\n\ndef do_qa_test(test):\n    paragraphs = []\n    for line in test:\n        context = line[1]\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        if type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answers = []\n        answers.append({'answer_start': 1000000, 'text': '__None__'})\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        paragraphs.append({'context': context.lower(), 'qas': qas})\n        output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n    return paragraphs\n\nfrom simpletransformers.question_answering import QuestionAnsweringModel\nfrom copy import deepcopy\nimport json\n\nuse_cuda = False\ntrain_df = read_train()\ntest_df = read_test()\nsubmission_df_distil = read_submission()\n\n\ntrain = np.array(train_df)\ntest = np.array(test_df)\nqa_train = do_qa_train(train)\n\n\nwith open('data/train.json', 'w') as outfile:\n    json.dump(qa_train, outfile)\noutput = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\n\nqa_test = do_qa_test(test)\n\nwith open('data/test.json', 'w') as outfile:\n    json.dump(qa_test, outfile)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Data formating to fead model"},{"metadata":{},"cell_type":"markdown","source":"### Exploration\n##### start"},{"metadata":{},"cell_type":"markdown","source":"#### Findings\n* train[0] ---> array(['cb774db0d1', ' I`d have responded, if I were going', ' I`d have responded, if I were going', 'neutral'], dtype=object)\n* tarin[6] , qa_train[6] --->  train_data: \n> \n> ['6e0c6d75b1'\n>  '2am feedings for the baby are fun when he is all smiles and coos' 'fun','positive']\n> \n> \n>  Processed_train_data : \n> {'context': '2am feedings for the baby are fun when he is all smiles and coos', 'qas': [{'question': 'positive', 'id': '6e0c6d75b1', 'is_impossible': False, 'answers': [{'answer_start': 30, 'text': 'fun'}]}]}"},{"metadata":{"trusted":true},"cell_type":"code","source":"def post_process(submission_df, test_df):\n\n    index_to_selected_text = {}\n    for i, row in test_df.iterrows():\n        _id = row[0]\n        text = row[1]\n        sentiment = row[2]\n        if len(text.split(\" \")) <= 3 or sentiment == \"neutral\":\n            index_to_selected_text[_id] = text\n    \n    submission_rows = submission_df.to_dict(\"records\")\n    new_rows = []\n    for row in submission_rows:\n        _id = row['textID']\n        if _id in index_to_selected_text:\n            new_row = deepcopy(row)\n            new_row['selected_text'] = index_to_selected_text[_id]\n        else:\n            new_row = row\n        \n        new_rows.append(new_row)\n\n    return pd.DataFrame(new_rows)\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"    \nMODEL_PATH = '/kaggle/input/transformers-pretrained-distilbert/distilbert-base-uncased-distilled-squad/'\nmodel = QuestionAnsweringModel('distilbert', \n                               MODEL_PATH, \n                              args={\"reprocess_input_data\": True,\n                               \"overwrite_output_dir\": True,\n                               \"learning_rate\": 8e-05,\n                               \"num_train_epochs\": 3,\n                               \"max_seq_length\": 192,\n                               \"weight_decay\": 0.001,\n                               \"doc_stride\": 64,\n                               \"save_model_every_epoch\": False,\n                               \"fp16\": False,\n                               \"do_lower_case\": True,\n                                 'max_query_length': 8,\n                               'max_answer_length': 150\n                                    },\n                              use_cuda=True)\n\nmodel.train_model('data/train.json')\npredictions = model.predict(qa_test)\n\npredictions_df = pd.DataFrame.from_dict(predictions)\n\nsubmission_df_distil['selected_text'] = predictions_df['answer']\n\nsubmission_df_distil = post_process(submission_df_distil, test_df)\n\nsubmission_df_distil.to_csv('data/submission.csv', index=False)\n\nsubmission_df_distil.to_csv('submission.csv', index=False)\n\n","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}