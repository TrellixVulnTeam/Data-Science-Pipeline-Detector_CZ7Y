{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nimport string\nimport math\nfrom nltk.tokenize import word_tokenize\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import *\nimport tokenizers\nprint('TF version', tf.__version__)","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":8.865132,"end_time":"2021-11-15T19:08:35.288427","exception":false,"start_time":"2021-11-15T19:08:26.423295","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:22.297436Z","iopub.execute_input":"2021-11-15T21:08:22.297784Z","iopub.status.idle":"2021-11-15T21:08:31.002112Z","shell.execute_reply.started":"2021-11-15T21:08:22.297707Z","shell.execute_reply":"2021-11-15T21:08:31.000701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits = 5\nEPOCHS = 3\nBATCH_SIZE = 32\nMAX_LEN = 96\nPAD_ID = 1\nLABEL_SMOOTHING = 0.1\n\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    PATH+'vocab-roberta-base.json',\n    PATH+'merges-roberta-base.txt',\n    lowercase=True,\n    add_prefix_space=True\n)\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}","metadata":{"papermill":{"duration":0.17877,"end_time":"2021-11-15T19:08:35.478469","exception":false,"start_time":"2021-11-15T19:08:35.299699","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:31.00409Z","iopub.execute_input":"2021-11-15T21:08:31.004584Z","iopub.status.idle":"2021-11-15T21:08:31.143426Z","shell.execute_reply.started":"2021-11-15T21:08:31.004539Z","shell.execute_reply":"2021-11-15T21:08:31.142672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_train():\n    train = pd.read_csv(\n        '../input/tweet-sentiment-extraction/train.csv').fillna('')\n    train['text'] = train['text'].astype(str)\n    train['selected_text'] = train['selected_text'].astype(str)\n    return train\n\n\ndef read_test():\n    test = pd.read_csv(\n        '../input/tweet-sentiment-extraction/test.csv').fillna('')\n    test['text'] = test['text'].astype(str)\n    return test\n\n\ndef read_submission():\n    test = pd.read_csv(\n        '../input/tweet-sentiment-extraction/sample_submission.csv').fillna('')\n    return test\n\n\ndef jaccard_improve(str1, str2):\n    str1 = str1.lower()\n    str2 = str2.lower()\n    index = str1.find(str2)\n    text1 = str1[:index]\n    # print(text1)\n    text2 = str1[index:].replace(str2, '')\n    words1 = text1.split()\n    words2 = text2.split()\n    # print(words1[-3:])\n\n    if len(words1) > len(words2):\n        words1 = words1[-3:]\n        mod_text = \" \".join(words1)+\" \" + str2\n    else:\n        words2 = words2[0:2]\n        mod_text = str2+\" \"+\" \".join(words2)\n    return mod_text\n\n\ndef loss_fn(y_true, y_pred):\n    # adjust the targets for sequence bucketing\n    l = tf.shape(y_pred)[1]\n    y_true = y_true[:, :l]\n    loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred,\n                                                    from_logits=False, label_smoothing=LABEL_SMOOTHING)\n    loss = tf.reduce_mean(loss)\n    return loss\n\n\ndef scheduler(epoch):\n    return 3e-5 * 0.2**epoch\n\n\ndef build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    padding = tf.cast(tf.equal(ids, PAD_ID), tf.int32)\n\n    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained(\n        PATH+'pretrained-roberta-base.h5', config=config)\n\n    x = bert_model(ids, attention_mask=att, token_type_ids=tok)\n\n    x1 = tf.keras.layers.Dropout(0.1)(x[0])\n    x1 = tf.keras.layers.Conv1D(768, 2, padding='same')(x1)\n    x1 = tf.keras.layers.LeakyReLU()(x1)\n    x1 = tf.keras.layers.Conv1D(64, 2, padding='same')(x1)\n    x1 = tf.keras.layers.Dense(1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n\n    x2 = tf.keras.layers.Dropout(0.1)(x[0])\n    x2 = tf.keras.layers.Conv1D(768, 2, padding='same')(x2)\n    x2 = tf.keras.layers.LeakyReLU()(x2)\n    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n    x2 = tf.keras.layers.Dense(1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1, x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n    model.compile(loss=loss_fn, optimizer=optimizer)\n\n    return model\n\n\ndef jaccard(str1, str2):\n    a = set(str1.lower().split())\n    b = set(str2.lower().split())\n    if (len(a) == 0) & (len(b) == 0):\n        return 0.5\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","metadata":{"papermill":{"duration":0.036559,"end_time":"2021-11-15T19:08:35.52563","exception":false,"start_time":"2021-11-15T19:08:35.489071","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:31.14634Z","iopub.execute_input":"2021-11-15T21:08:31.147163Z","iopub.status.idle":"2021-11-15T21:08:31.171444Z","shell.execute_reply.started":"2021-11-15T21:08:31.147123Z","shell.execute_reply":"2021-11-15T21:08:31.170674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = read_train()\ntest = read_test()\nsubmission_df = read_submission()","metadata":{"papermill":{"duration":0.194091,"end_time":"2021-11-15T19:08:35.730207","exception":false,"start_time":"2021-11-15T19:08:35.536116","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:31.174677Z","iopub.execute_input":"2021-11-15T21:08:31.175229Z","iopub.status.idle":"2021-11-15T21:08:31.351852Z","shell.execute_reply.started":"2021-11-15T21:08:31.175191Z","shell.execute_reply":"2021-11-15T21:08:31.351072Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = train.loc[train.sentiment !=\n                     \"neutral\"].reset_index(drop=True, inplace=False)\ntest_df = test.loc[test.sentiment != \"neutral\"].reset_index(\n    drop=True, inplace=False)\nprint(f\"non neutral train data: {train_df.shape}\")\nprint(f\"non neutral test data: {test_df.shape}\")","metadata":{"papermill":{"duration":0.029654,"end_time":"2021-11-15T19:08:35.770849","exception":false,"start_time":"2021-11-15T19:08:35.741195","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:31.353674Z","iopub.execute_input":"2021-11-15T21:08:31.354209Z","iopub.status.idle":"2021-11-15T21:08:31.372824Z","shell.execute_reply.started":"2021-11-15T21:08:31.354171Z","shell.execute_reply":"2021-11-15T21:08:31.371898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ct = train_df.shape[0]\ninput_ids = np.ones((ct, MAX_LEN), dtype='int32')\nattention_mask = np.zeros((ct, MAX_LEN), dtype='int32')\ntoken_type_ids = np.zeros((ct, MAX_LEN), dtype='int32')\nstart_tokens = np.zeros((ct, MAX_LEN), dtype='int32')\nend_tokens = np.zeros((ct, MAX_LEN), dtype='int32')\n\nprint(input_ids.shape)\nprint(attention_mask.shape)\nprint(token_type_ids.shape)\nprint(start_tokens.shape)\nprint(end_tokens.shape)","metadata":{"papermill":{"duration":0.023047,"end_time":"2021-11-15T19:08:35.805005","exception":false,"start_time":"2021-11-15T19:08:35.781958","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:31.374281Z","iopub.execute_input":"2021-11-15T21:08:31.375114Z","iopub.status.idle":"2021-11-15T21:08:31.386766Z","shell.execute_reply.started":"2021-11-15T21:08:31.375074Z","shell.execute_reply":"2021-11-15T21:08:31.385763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for k in range(train_df.shape[0]):\n\n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(train_df.loc[k, 'text'].split())\n    text2 = \" \".join(train_df.loc[k, 'selected_text'].split())\n    idx = text1.find(text2)\n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)] = 1\n    text1[idx-1] == ' '\n    if text1[idx-1] == ' ':\n        chars[idx-1] = 1\n    enc = tokenizer.encode(text1)\n\n    # ID_OFFSETS\n    offsets = []\n    idx = 0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx, idx+len(w)))\n        idx += len(w)\n\n    # START END TOKENS\n    toks = []\n    for i, (a, b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm > 0:\n            toks.append(i)\n\n    s_tok = sentiment_id[train_df.loc[k, 'sentiment']]\n    input_ids[k, :len(enc.ids)+5] = [0] + [s_tok] + [2, 2] + enc.ids + [2]\n    attention_mask[k, :len(enc.ids)+5] = 1\n    if len(toks) > 0:\n        start_tokens[k, toks[0]+1] = 1\n        end_tokens[k, toks[-1]+1] = 1","metadata":{"papermill":{"duration":5.358819,"end_time":"2021-11-15T19:08:41.175202","exception":false,"start_time":"2021-11-15T19:08:35.816383","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:31.388618Z","iopub.execute_input":"2021-11-15T21:08:31.389Z","iopub.status.idle":"2021-11-15T21:08:36.43762Z","shell.execute_reply.started":"2021-11-15T21:08:31.388964Z","shell.execute_reply":"2021-11-15T21:08:36.436852Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ct = test_df.shape[0]\ninput_ids_t = np.ones((ct, MAX_LEN), dtype='int32')\nattention_mask_t = np.zeros((ct, MAX_LEN), dtype='int32')\ntoken_type_ids_t = np.zeros((ct, MAX_LEN), dtype='int32')\n\nfor k in range(test_df.shape[0]):\n\n    # INPUT_IDS\n    text1 = \" \"+\" \".join(test_df.loc[k, 'text'].split())\n\n    enc = tokenizer.encode(text1)\n    s_tok = sentiment_id[test_df.loc[k, 'sentiment']]\n    input_ids_t[k, :len(enc.ids)+5] = [0] + [s_tok] + [2, 2] + enc.ids + [2]\n    attention_mask_t[k, :len(enc.ids)+5] = 1","metadata":{"papermill":{"duration":0.229776,"end_time":"2021-11-15T19:08:41.416672","exception":false,"start_time":"2021-11-15T19:08:41.186896","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:36.439023Z","iopub.execute_input":"2021-11-15T21:08:36.440731Z","iopub.status.idle":"2021-11-15T21:08:36.649611Z","shell.execute_reply.started":"2021-11-15T21:08:36.4407Z","shell.execute_reply":"2021-11-15T21:08:36.648902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"jac = []\nVER = 'v3'\nDISPLAY = 1  # USE display=1 FOR INTERACTIVE\noof_start = np.zeros((input_ids.shape[0], MAX_LEN))\noof_end = np.zeros((input_ids.shape[0], MAX_LEN))\n\nskf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=777)\nfor fold, (idxT, idxV) in enumerate(skf.split(input_ids, train_df.sentiment.values)):\n\n    print('#'*25)\n    print('### FOLD %i' % (fold+1))\n    print('#'*25)\n\n    K.clear_session()\n    model = build_model()\n\n    reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        '%s-roberta-%i.h5' % (VER, fold), monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='auto', save_freq='epoch')\n\n    hist = model.fit([input_ids[idxT, ], attention_mask[idxT, ], token_type_ids[idxT, ]],\n                     [start_tokens[idxT, ], end_tokens[idxT, ]],\n                     epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=DISPLAY,\n                     callbacks=[sv, reduce_lr],\n                     validation_data=([input_ids[idxV, ], attention_mask[idxV, ], token_type_ids[idxV, ]],\n                                      [start_tokens[idxV, ], end_tokens[idxV, ]]))\n\n    print('Loading model...')\n    model.load_weights('%s-roberta-%i.h5' % (VER, fold))\n\n    print('Predicting OOF...')\n    oof_start[idxV, ], oof_end[idxV, ] = model.predict(\n        [input_ids[idxV, ], attention_mask[idxV, ], token_type_ids[idxV, ]], verbose=DISPLAY)\n\n    # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k, ])\n        b = np.argmax(oof_end[k, ])\n        if a > b:\n            # IMPROVE CV/LB with better choice here\n            st = train_df.loc[k, 'text']\n        else:\n            text1 = \" \"+\" \".join(train_df.loc[k, 'text'].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-1:b])\n        all.append(jaccard(st, train_df.loc[k, 'selected_text']))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard =' % (fold+1), np.mean(all))\n    print()\n\n\nprint('>>>> OVERALL 5Fold CV Jaccard =', np.mean(jac))","metadata":{"papermill":{"duration":1638.514283,"end_time":"2021-11-15T19:35:59.942806","exception":false,"start_time":"2021-11-15T19:08:41.428523","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:10:52.399231Z","iopub.execute_input":"2021-11-15T21:10:52.39951Z","iopub.status.idle":"2021-11-15T21:21:41.905708Z","shell.execute_reply.started":"2021-11-15T21:10:52.399478Z","shell.execute_reply":"2021-11-15T21:21:41.904476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_start = np.zeros((input_ids_t.shape[0], MAX_LEN))\npreds_end = np.zeros((input_ids_t.shape[0], MAX_LEN))\nDISPLAY = 1\nfor i in range(5):\n    print('#'*25)\n    print('### MODEL %i' % (i+1))\n    print('#'*25)\n\n    K.clear_session()\n    model = build_model()\n    # model.load_weights('../input/model-v3/v3-roberta-%i.h5'%i)\n    model.load_weights('./v3-roberta-%i.h5' % i)\n\n    print('Predicting Test...')\n    preds = model.predict([input_ids_t, attention_mask_t,\n                           token_type_ids_t], verbose=DISPLAY)\n    preds_start += preds[0]/n_splits\n    preds_end += preds[1]/n_splits","metadata":{"papermill":{"duration":2.480699,"end_time":"2021-11-15T19:36:04.956928","exception":false,"start_time":"2021-11-15T19:36:02.476229","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:55.652874Z","iopub.status.idle":"2021-11-15T21:08:55.65365Z","shell.execute_reply.started":"2021-11-15T21:08:55.65339Z","shell.execute_reply":"2021-11-15T21:08:55.653414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all = []\nfor k in range(input_ids_t.shape[0]):\n    a = np.argmax(preds_start[k, ])\n    b = np.argmax(preds_end[k, ])\n    if a > b:\n        st = test_df.loc[k, 'text']\n    else:\n        text1 = \" \"+\" \".join(test_df.loc[k, 'text'].split())\n        enc = tokenizer.encode(text1)\n        st = tokenizer.decode(enc.ids[a-1:b])\n    all.append(st)","metadata":{"papermill":{"duration":2.910955,"end_time":"2021-11-15T19:36:10.403661","exception":false,"start_time":"2021-11-15T19:36:07.492706","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:55.655087Z","iopub.status.idle":"2021-11-15T21:08:55.655512Z","shell.execute_reply.started":"2021-11-15T21:08:55.65528Z","shell.execute_reply":"2021-11-15T21:08:55.655302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"selected_text\"] = \"\"  # make a column for predictions\n\n# make predictions for neutral sentiment\ntest.loc[test.sentiment == \"neutral\",\n         \"selected_text\"] = test.loc[test.sentiment == \"neutral\", \"text\"]\n\n# make predictions for neutral sentiment\ntest.loc[test.sentiment != \"neutral\", \"selected_text\"] = all","metadata":{"papermill":{"duration":2.537604,"end_time":"2021-11-15T19:36:15.462196","exception":false,"start_time":"2021-11-15T19:36:12.924592","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:55.656591Z","iopub.status.idle":"2021-11-15T21:08:55.657544Z","shell.execute_reply.started":"2021-11-15T21:08:55.657303Z","shell.execute_reply":"2021-11-15T21:08:55.657326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.shape, test_df.shape, submission_df.shape","metadata":{"papermill":{"duration":2.569361,"end_time":"2021-11-15T19:36:21.013743","exception":false,"start_time":"2021-11-15T19:36:18.444382","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:55.658513Z","iopub.status.idle":"2021-11-15T21:08:55.659273Z","shell.execute_reply.started":"2021-11-15T21:08:55.659026Z","shell.execute_reply":"2021-11-15T21:08:55.659053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test_df['selected_text'] = all\ntest[['textID', 'selected_text']].to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":2.51506,"end_time":"2021-11-15T19:36:26.292809","exception":false,"start_time":"2021-11-15T19:36:23.777749","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:55.660445Z","iopub.status.idle":"2021-11-15T21:08:55.661961Z","shell.execute_reply.started":"2021-11-15T21:08:55.661705Z","shell.execute_reply":"2021-11-15T21:08:55.661731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"papermill":{"duration":2.509403,"end_time":"2021-11-15T19:36:31.349938","exception":false,"start_time":"2021-11-15T19:36:28.840535","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-11-15T21:08:55.6632Z","iopub.status.idle":"2021-11-15T21:08:55.663843Z","shell.execute_reply.started":"2021-11-15T21:08:55.663597Z","shell.execute_reply":"2021-11-15T21:08:55.663621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":2.537327,"end_time":"2021-11-15T19:36:36.640073","exception":false,"start_time":"2021-11-15T19:36:34.102746","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}