{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-04T11:32:12.736676Z","iopub.execute_input":"2021-07-04T11:32:12.737433Z","iopub.status.idle":"2021-07-04T11:32:12.771356Z","shell.execute_reply.started":"2021-07-04T11:32:12.737327Z","shell.execute_reply":"2021-07-04T11:32:12.770238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyenchant","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:12.77332Z","iopub.execute_input":"2021-07-04T11:32:12.773631Z","iopub.status.idle":"2021-07-04T11:32:19.766178Z","shell.execute_reply.started":"2021-07-04T11:32:12.773601Z","shell.execute_reply":"2021-07-04T11:32:19.764992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install pyenchant pysastrawi","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:19.76848Z","iopub.execute_input":"2021-07-04T11:32:19.768785Z","iopub.status.idle":"2021-07-04T11:32:26.548748Z","shell.execute_reply.started":"2021-07-04T11:32:19.768751Z","shell.execute_reply":"2021-07-04T11:32:26.54773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget http://archive.ubuntu.com/ubuntu/pool/main/libr/libreoffice-dictionaries/hunspell-id_6.4.3-1_all.deb\n!dpkg -i hunspell-id_6.4.3-1_all.deb","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:26.550534Z","iopub.execute_input":"2021-07-04T11:32:26.550844Z","iopub.status.idle":"2021-07-04T11:32:29.083852Z","shell.execute_reply.started":"2021-07-04T11:32:26.550808Z","shell.execute_reply":"2021-07-04T11:32:29.082913Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!apt update && apt install -y enchant libenchant1c2a hunspell hunspell-en-us libhunspell-1.6-0","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:29.085078Z","iopub.execute_input":"2021-07-04T11:32:29.085365Z","iopub.status.idle":"2021-07-04T11:32:34.226844Z","shell.execute_reply.started":"2021-07-04T11:32:29.085335Z","shell.execute_reply":"2021-07-04T11:32:34.225706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\ntrain_df = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ntest_df = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ntrain_df\ntest_df\n# train_df_sample = train_df.sample(n=50000, random_state=1).reset_index()","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:34.230041Z","iopub.execute_input":"2021-07-04T11:32:34.230355Z","iopub.status.idle":"2021-07-04T11:32:34.672388Z","shell.execute_reply.started":"2021-07-04T11:32:34.230322Z","shell.execute_reply":"2021-07-04T11:32:34.671594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df.rename(columns={\"airline_sentiment\": \"sentiment\"})\ntrain_df = train_df[['text', 'sentiment']]\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:34.673579Z","iopub.execute_input":"2021-07-04T11:32:34.67405Z","iopub.status.idle":"2021-07-04T11:32:34.692376Z","shell.execute_reply.started":"2021-07-04T11:32:34.673999Z","shell.execute_reply":"2021-07-04T11:32:34.691232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df[['text', 'sentiment']]\ntest_df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:34.693651Z","iopub.execute_input":"2021-07-04T11:32:34.693973Z","iopub.status.idle":"2021-07-04T11:32:34.70942Z","shell.execute_reply.started":"2021-07-04T11:32:34.693921Z","shell.execute_reply":"2021-07-04T11:32:34.708321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_df = train_df.rename(columns={\"airline_sentiment\": \"sentiment\"})\ntrain_df = train_df[['text', 'sentiment']]\ntrain_df","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:34.712863Z","iopub.execute_input":"2021-07-04T11:32:34.713222Z","iopub.status.idle":"2021-07-04T11:32:34.730905Z","shell.execute_reply.started":"2021-07-04T11:32:34.713189Z","shell.execute_reply":"2021-07-04T11:32:34.729716Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# **Text Preprocessing**","metadata":{"execution":{"iopub.status.busy":"2021-07-03T16:15:04.6157Z","iopub.execute_input":"2021-07-03T16:15:04.616082Z","iopub.status.idle":"2021-07-03T16:15:04.623514Z","shell.execute_reply.started":"2021-07-03T16:15:04.616051Z","shell.execute_reply":"2021-07-03T16:15:04.622371Z"}}},{"cell_type":"code","source":"#removing stopwords\nimport nltk\nfrom nltk.corpus import stopwords\nstopwords.words('english')\nfrom nltk.tokenize import word_tokenize\ntext = \"Nick likes to play football, however he is not too fond of tennis.\"\ntext_tokens = word_tokenize(text)\n\ntokens_without_sw = [word for word in text_tokens if not word in stopwords.words()]\ntokens_without_sw","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:34.732745Z","iopub.execute_input":"2021-07-04T11:32:34.733066Z","iopub.status.idle":"2021-07-04T11:32:36.121865Z","shell.execute_reply.started":"2021-07-04T11:32:34.733033Z","shell.execute_reply":"2021-07-04T11:32:36.120854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nimport sys\nimport spacy\nimport re\nimport enchant\n\nfrom nltk.corpus import stopwords\nimport string\n\nBAD_SYMBOLS_RE = re.compile('[^a-z #+_]')\n\nnlp = spacy.load(\"en_core_web_sm\", disable=['parser','ner'])\n\nstop = set(stopwords.words('english'))\n\npunc = set(string.punctuation)\n\ndef clean_text(text):\n\n    text = text.lower()\n    \n    text = BAD_SYMBOLS_RE.sub('', text)\n\n    wordList = text.split()\n\n    wordList = [\"\".join(x for x in word if x not in punc) for word in wordList]    \n\n    wordList = [word for word in wordList if word not in stop]\n    \n#     eng_dict = enchant.Dict('en')\n\n#     wordList= [word for word in wordList if eng_dict.check(word)]\n\n    reformed_sentence = \" \".join(wordList)\n    doc = nlp(reformed_sentence)\n    return \" \".join([token.lemma_ for token in doc])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:36.123129Z","iopub.execute_input":"2021-07-04T11:32:36.123432Z","iopub.status.idle":"2021-07-04T11:32:38.090645Z","shell.execute_reply.started":"2021-07-04T11:32:36.123403Z","shell.execute_reply":"2021-07-04T11:32:38.089176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_normalized=train_df.copy()\nval_normalized=test_df.copy()\ntrain_normalized['text'] = train_normalized['text'].astype('str').apply(clean_text)\nval_normalized['text'] = val_normalized['text'].astype('str').apply(clean_text)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:32:38.092405Z","iopub.execute_input":"2021-07-04T11:32:38.092772Z","iopub.status.idle":"2021-07-04T11:34:02.112448Z","shell.execute_reply.started":"2021-07-04T11:32:38.092732Z","shell.execute_reply":"2021-07-04T11:34:02.111006Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train=train_normalized['text']\ny_train=train_normalized['sentiment']\n\nX_test=val_normalized['text']\ny_test=val_normalized['sentiment']","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:02.114385Z","iopub.execute_input":"2021-07-04T11:34:02.114709Z","iopub.status.idle":"2021-07-04T11:34:02.119687Z","shell.execute_reply.started":"2021-07-04T11:34:02.114675Z","shell.execute_reply":"2021-07-04T11:34:02.118987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"! pip install -U pip\n! pip install -U tensorflow\n! pip install -U tensorflow_hub","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:02.121016Z","iopub.execute_input":"2021-07-04T11:34:02.121597Z","iopub.status.idle":"2021-07-04T11:34:23.538983Z","shell.execute_reply.started":"2021-07-04T11:34:02.121558Z","shell.execute_reply":"2021-07-04T11:34:23.537774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\nimport spacy\nnlp = spacy.load(\"en_core_web_sm\")\n\nBAD_SYMBOLS_RE = re.compile('[^A-Za-z]+')\ndef cleanUpEmails(txt):\n    txt = txt.lower()\n    txt = re.sub('\\n', ' ', txt)\n    txt = re.sub('\\S*@\\S*\\s?', '', txt)\n    txt = re.sub('\\S*.com.\\S*', '', txt)\n    txt = re.sub('\\S*.\\S*.com', '', txt)\n    txt = re.sub('pm', '', txt)\n    txt = BAD_SYMBOLS_RE.sub(' ', txt)\n    \n    doc = nlp(txt)\n\n    lemma_list = []\n    for token in doc:\n        lemma_list.append(token.lemma_)\n    \n    #Filter the stopword\n    filtered_sentence =[] \n    for word in lemma_list:\n        lexeme = nlp.vocab[word]\n        if lexeme.is_stop == False:\n            filtered_sentence.append(word) \n    return \" \".join([word for word in filtered_sentence if len(word)>1])","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:23.540845Z","iopub.execute_input":"2021-07-04T11:34:23.541319Z","iopub.status.idle":"2021-07-04T11:34:24.725383Z","shell.execute_reply.started":"2021-07-04T11:34:23.541269Z","shell.execute_reply":"2021-07-04T11:34:24.724336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_emails=pd.read_csv('/kaggle/input/email-sentiment-analysis/test.csv')\ntest_emails=test_emails['email_body']\ntest_emails","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:24.727111Z","iopub.execute_input":"2021-07-04T11:34:24.727521Z","iopub.status.idle":"2021-07-04T11:34:24.745317Z","shell.execute_reply.started":"2021-07-04T11:34:24.727475Z","shell.execute_reply":"2021-07-04T11:34:24.744166Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_emails = test_emails.astype('str').apply(cleanUpEmails)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:24.747085Z","iopub.execute_input":"2021-07-04T11:34:24.747514Z","iopub.status.idle":"2021-07-04T11:34:26.038871Z","shell.execute_reply.started":"2021-07-04T11:34:24.747467Z","shell.execute_reply":"2021-07-04T11:34:26.037445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntok_emails = tf.keras.preprocessing.text.Tokenizer(nb_words=2500)\ntok_emails.fit_on_texts(test_emails)\nsequences_test_emails = tok_emails.texts_to_sequences(test_emails)\nX_test_for_lstm_emails = tf.keras.preprocessing.sequence.pad_sequences(sequences_test_emails,maxlen=25)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:26.040477Z","iopub.execute_input":"2021-07-04T11:34:26.040901Z","iopub.status.idle":"2021-07-04T11:34:28.215735Z","shell.execute_reply.started":"2021-07-04T11:34:26.040853Z","shell.execute_reply":"2021-07-04T11:34:28.214432Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\ntok = tf.keras.preprocessing.text.Tokenizer(nb_words=2500)\nall_texts=X_train.append(X_test)\ntok.fit_on_texts(all_texts)\nsequences_train = tok.texts_to_sequences(X_train)\nX_train_for_lstm = tf.keras.preprocessing.sequence.pad_sequences(sequences_train,maxlen=25)\nsequences_test = tok.texts_to_sequences(X_test)\nX_test_for_lstm = tf.keras.preprocessing.sequence.pad_sequences(sequences_test,maxlen=25)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:28.265633Z","iopub.execute_input":"2021-07-04T11:34:28.266281Z","iopub.status.idle":"2021-07-04T11:34:29.619457Z","shell.execute_reply.started":"2021-07-04T11:34:28.266234Z","shell.execute_reply":"2021-07-04T11:34:29.618385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom sklearn.preprocessing import OneHotEncoder\n\nenc = OneHotEncoder(handle_unknown='ignore')\nenc.fit(y_train.values.reshape(-1, 1))\n\ny_train_transformed = enc.transform(y_train.values.reshape(-1, 1))\ny_test_transformed = enc.transform(y_test.values.reshape(-1, 1))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:29.620995Z","iopub.execute_input":"2021-07-04T11:34:29.621388Z","iopub.status.idle":"2021-07-04T11:34:29.64114Z","shell.execute_reply.started":"2021-07-04T11:34:29.621346Z","shell.execute_reply":"2021-07-04T11:34:29.640201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import scipy\ny_train_one_hot=scipy.sparse.csr_matrix.toarray(y_train_transformed)\ny_test_one_hot=scipy.sparse.csr_matrix.toarray(y_test_transformed)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:29.64225Z","iopub.execute_input":"2021-07-04T11:34:29.642677Z","iopub.status.idle":"2021-07-04T11:34:29.652675Z","shell.execute_reply.started":"2021-07-04T11:34:29.642646Z","shell.execute_reply":"2021-07-04T11:34:29.651915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train_one_hot","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:29.653726Z","iopub.execute_input":"2021-07-04T11:34:29.654045Z","iopub.status.idle":"2021-07-04T11:34:29.664211Z","shell.execute_reply.started":"2021-07-04T11:34:29.654014Z","shell.execute_reply":"2021-07-04T11:34:29.663418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend\ndef f1(y_true, y_pred):\n    \n    def recall(y_true, y_pred):\n        true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n        possible_positives = backend.sum(backend.round(backend.clip(y_true, 0, 1)))\n        recall = true_positives / (possible_positives + backend.epsilon())\n        return recall\n    \n    def precision(y_true, y_pred):\n        true_positives = backend.sum(backend.round(backend.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = backend.sum(backend.round(backend.clip(y_pred, 0, 1)))\n        precision = true_positives / (predicted_positives + backend.epsilon())\n        return precision\n    \n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+backend.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:29.665506Z","iopub.execute_input":"2021-07-04T11:34:29.665778Z","iopub.status.idle":"2021-07-04T11:34:29.673866Z","shell.execute_reply.started":"2021-07-04T11:34:29.665752Z","shell.execute_reply":"2021-07-04T11:34:29.673157Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_NB_WORDS = 4000\n\nEMBEDDING_DIM = 25\n\nmodel = tf.keras.Sequential()\nmodel.add(tf.keras.layers.Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X_train_for_lstm.shape[1]))\nmodel.add(tf.keras.layers.Dropout(0.2))\nmodel.add(tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(100, dropout=0.2, recurrent_dropout=0.2)))\nmodel.add(tf.keras.layers.Dense(3, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', \n              optimizer='adam', metrics=[tf.keras.metrics.Precision(),\n               tf.keras.metrics.Recall(),\n                   tf.keras.metrics.AUC(num_thresholds=200,curve=\"ROC\",summation_method=\"interpolation\"),'accuracy',f1])\n\nepochs = 15\nbatch_size = 64\n\nhistory = model.fit(X_train_for_lstm, y_train_one_hot,\n                    epochs=epochs, batch_size=batch_size, \n                    validation_data=(X_test_for_lstm,y_test_one_hot))","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:34:29.676567Z","iopub.execute_input":"2021-07-04T11:34:29.676958Z","iopub.status.idle":"2021-07-04T11:42:10.592268Z","shell.execute_reply.started":"2021-07-04T11:34:29.676912Z","shell.execute_reply":"2021-07-04T11:42:10.591229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result=model.predict(X_test_for_lstm_emails)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:42:10.593984Z","iopub.execute_input":"2021-07-04T11:42:10.594301Z","iopub.status.idle":"2021-07-04T11:42:11.131732Z","shell.execute_reply.started":"2021-07-04T11:42:10.594263Z","shell.execute_reply":"2021-07-04T11:42:11.130703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = np.argmax(result, axis=1)","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:44:25.183107Z","iopub.execute_input":"2021-07-04T11:44:25.183494Z","iopub.status.idle":"2021-07-04T11:44:25.188477Z","shell.execute_reply.started":"2021-07-04T11:44:25.183451Z","shell.execute_reply":"2021-07-04T11:44:25.187413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict","metadata":{"execution":{"iopub.status.busy":"2021-07-04T11:44:27.481028Z","iopub.execute_input":"2021-07-04T11:44:27.48136Z","iopub.status.idle":"2021-07-04T11:44:27.488025Z","shell.execute_reply.started":"2021-07-04T11:44:27.481333Z","shell.execute_reply":"2021-07-04T11:44:27.487007Z"},"trusted":true},"execution_count":null,"outputs":[]}]}