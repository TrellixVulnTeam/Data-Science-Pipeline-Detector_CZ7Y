{"cells":[{"metadata":{},"cell_type":"markdown","source":"# **NLP Mid Term 3**\nGroup Members:\n1. Nidhi Bhatt (J006)\n2. Mitali Kambli (J025)\n3. J. Sharat Shankar (J045)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Libraries Required**"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport re\nimport nltk\nimport numpy as np\nfrom textblob import TextBlob\nfrom nltk.corpus import stopwords\nfrom string import digits,punctuation \nfrom nltk.tokenize import word_tokenize\nnltk.download('punkt')\nnltk.download('wordnet')\nnltk.download('stopwords') \nnltk.download('averaged_perceptron_tagger')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Reading the Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ndf_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train.dropna()\ndf_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to remove the unwanted links from the tweets.\ndef linkremoval(str):\n  text = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', '', str, flags=re.MULTILINE)\n  return text","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Sentiment Wise Dictionaries**\nThe below function reads each word and predicts the sentiment conveyed by it and stores in a dictionary with the sentiments as the keys. These dictionaries are later used for extraction."},{"metadata":{"trusted":true},"cell_type":"code","source":"def sentiments_in_texts(text):\n  text = text.split()\n  polarity = dict()\n  pos_word_list=[]\n  neu_word_list=[]\n  neg_word_list=[]\n\n  for word in text:\n    if (TextBlob(word).sentiment[0]) > 0:\n      pos_word_list.append(word)\n    elif (TextBlob(word).sentiment[0]) < 0:\n      neg_word_list.append(word)\n    else:\n      neu_word_list.append(word)\n\n  polarity['positive'] = pos_word_list\n  polarity['negative'] = neg_word_list\n  polarity['neutral'] = neu_word_list \n\n  return polarity","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Overall Sentiment of the Tweet**\nThe below function predicts the overall sentiment of the tweet which is used to check the ACCURACY of textblob in classifying the tweets"},{"metadata":{"trusted":true},"cell_type":"code","source":"def overall_sentiment(str):\n  text1 = TextBlob(str)\n  if text1.sentiment.polarity>0:\n    return 'positive'\n  if text1.sentiment.polarity<0:\n    return 'negative'\n  if text1.sentiment.polarity==0:\n    return 'neutral'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Selected Text**\nThe function below gets all the words in the tweet that represent the overall sentiment of the tweet. We use the generated polarity_dict for each row here."},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_selected_text(df):\n  textlist = []\n  for index, row in df.iterrows():\n    word_dict = row['polarity_dict']\n    textlist.append(word_dict[row['Overall_Sentiment_using_tweet']])\n  return textlist","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Jaccard Score**\nThe function below calculates the jaccard score for the actual selected text and the text selected by textblob"},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(df1, df2):\n  jaccard_scores = []\n  for i in range(0,len(df2)):\n    a = set(df1[i])\n    x = \" \".join(df2[i])\n    b = set(x)\n    c = a.intersection(b)\n    jaccard_scores.append(float(len(c)) / (len(a) + len(b) - len(c)))\n  return jaccard_scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Training Dataset**\nApplying TextBlob on the training dataset and getting the classification report for the sentiments classified"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['text1'] = df_train['text'].apply(linkremoval)\ndf_train['Overall_Sentiment_using_tweet'] = df_train['text'].apply(overall_sentiment)\ndf_train['polarity_dict'] = df_train['text1'].apply(sentiments_in_texts)\ndf_train['sentiment'] = pd.Categorical(df_train['sentiment'])\ndf_train['sentiment'].cat.categories\ndf_train['Overall_Sentiment_using_tweet'] = pd.Categorical(df_train['Overall_Sentiment_using_tweet'])\ndf_train['Overall_Sentiment_using_tweet'].cat.categories\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(df_train[\"sentiment\"],df_train[\"Overall_Sentiment_using_tweet\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Selected Text on the Training Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_selected_text_pred = get_selected_text(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_selected_text = pd.DataFrame()\nfor i in train_selected_text_pred:\n  txt = \" \".join(i)\n  txt = pd.Series([txt])\n  train_selected_text = pd.concat([train_selected_text,txt],axis=0,ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_selected_text.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Jaccard Scores**"},{"metadata":{"trusted":true},"cell_type":"code","source":"jaccard_scores = jaccard(list(df_train['selected_text']),train_selected_text_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_jaccard_scores = pd.DataFrame()\nfor i in jaccard_scores:\n  score = pd.Series(str(i))\n  train_jaccard_scores = pd.concat([train_jaccard_scores,score],axis=0,ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_jaccard_scores.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean Jaccard Scores: \", np.mean(jaccard_scores))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# **Testing Dataset**"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test['text1'] = df_test['text'].apply(linkremoval)\ndf_test['Overall_Sentiment_using_tweet'] = df_test['text'].apply(overall_sentiment)\ndf_test['polarity_dict'] = df_test['text1'].apply(sentiments_in_texts)\ndf_test['sentiment'] = pd.Categorical(df_test['sentiment'])\ndf_test['sentiment'].cat.categories\ndf_test['Overall_Sentiment_using_tweet'] = pd.Categorical(df_test['Overall_Sentiment_using_tweet'])\ndf_test['Overall_Sentiment_using_tweet'].cat.categories\n\nfrom sklearn.metrics import classification_report\nprint(classification_report(df_test[\"sentiment\"],df_test[\"Overall_Sentiment_using_tweet\"]))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_selected_text_pred = get_selected_text(df_test)\ntest_selected_text = pd.DataFrame()\nfor i in test_selected_text_pred:\n  txt = \" \".join(i)\n  txt = pd.Series([txt])\n  test_selected_text = pd.concat([test_selected_text,txt],axis=0,ignore_index = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = df_test['textID']\nsubmission = pd.concat([submission,test_selected_text[0]],axis=1)\nsubmission = submission.rename(columns={0:'selected_text'})\nsubmission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}