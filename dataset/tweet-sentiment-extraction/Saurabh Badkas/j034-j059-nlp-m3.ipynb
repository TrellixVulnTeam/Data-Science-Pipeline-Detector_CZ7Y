{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"id":"vqDqkHZ4Vlot","outputId":"3f638acd-9e59-4721-8d1c-5582f035be25","trusted":true},"cell_type":"code","source":"import sys\nimport nltk\nimport sklearn\nimport re\nimport string\nimport heapq\nimport scipy.io\nfrom array import *\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter","execution_count":null,"outputs":[]},{"metadata":{"id":"_NF-okCIVr9T","trusted":true},"cell_type":"code","source":"df_train=pd.read_csv('../input/tweet-sentiment-extraction/train.csv',na_filter=False)\ndf_test=pd.read_csv('../input/tweet-sentiment-extraction/test.csv',na_filter=False)\nFINAL=pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"id":"lZnPTJ9YVsAG","outputId":"bdad69fb-e627-4a34-b75d-2de037fb26e1","trusted":true},"cell_type":"code","source":"print(df_train.info())\nprint(df_train.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df_test.info())\nprint(df_test.head())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"id":"pEDn_znXVsCt","outputId":"e6865af4-64e6-4054-c464-9560ea591670","trusted":true},"cell_type":"code","source":"# check class distribution\nclasses = df_train['sentiment']\nprint(classes.value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Num_words_ST'] = df_train['selected_text'].apply(lambda x:len(str(x).split()))\ndf_train['Num_word_text'] = df_train['text'].apply(lambda x:len(str(x).split()))\ndf_train['difference_in_words'] = df_train['Num_word_text'] - df_train['Num_words_ST'] \ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plot the graph\ndf_train.sentiment.value_counts().plot(figsize=(12,5),kind='bar',color='orange');\nplt.xlabel('Sentiment')\nplt.ylabel(' Sentiments for Training Data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def cleaning(text):\n\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['text'] = df_train['text'].apply(lambda x:cleaning(x))\ndf_train['selected_text'] = df_train['selected_text'].apply(lambda x:cleaning(x))","execution_count":null,"outputs":[]},{"metadata":{"id":"WZHEhNrFWCqK","outputId":"5365c02a-7d9a-47b2-9dde-ab35e19c378e","trusted":true},"cell_type":"code","source":"# removing stopwords\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\ndef remove(x):\n    return [y for y in x if y not in stopwords.words('english')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['temp_list_T'] = df_train['text'].apply(lambda x:str(x).split())\ndf_train['temp_list_T'] = df_train['temp_list_T'].apply(lambda x:remove(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['temp_list_ST'] = df_train['selected_text'].apply(lambda x:str(x).split())\ndf_train['temp_list_ST'] = df_train['temp_list_ST'].apply(lambda x:remove(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# calculation of jaccard score\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / ((len(a) + len(b) - len(c))+0.1)\n\njaccard_score1=[]\n\nfor ind,row in df_train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    jaccard_score1.append([sentence1,sentence2,jaccard_score])\n\n    \n# putting jaccard output in main train file\nJaccard_score = pd.DataFrame(jaccard_score1,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ndf_train = df_train.merge(Jaccard_score,how='outer')\ndf_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Pos = df_train[df_train['sentiment']=='positive']\nNe = df_train[df_train['sentiment']=='negative']\nN = df_train[df_train['sentiment']=='neutral']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#most positive words finder\ntop = Counter([item for sublist in Pos['temp_list_ST'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# most number of negative words finder\ntop = Counter([item for sublist in Ne['temp_list_ST'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#MosT number of neutral words finder\ntop = Counter([item for sublist in N['temp_list_ST'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def polar(data):\n    \n    training_data = data['text']\n    training_data_sentiment = data['sentiment']\n    selected_text_processed = []\n    analyser = SentimentIntensityAnalyzer()\n\n    \n    for i in range(len(training_data)):\n        text = re.sub(r'http\\S+', '', str(training_data.iloc[i]))\n    \n        score = []\n    \n        if(training_data_sentiment.iloc[i] == \"positive\"):\n            \n            words = re.split(' ', text)\n            for w in words:\n                score.append(analyser.polarity_scores(w)['compound'])\n            \n            maximum = np.argmax(score)\n            word = words[maximum]\n            selected_text_processed.append(word)\n        \n        if(training_data_sentiment.iloc[i] == \"negative\"):\n            \n            words = re.split(' ', text)\n            for w in words:\n                score.append(analyser.polarity_scores(w)['compound'])\n       \n            maximum = np.argmin(score)\n            word = words[maximum]\n            selected_text_processed.append(word)\n        \n        if(training_data_sentiment.iloc[i] == \"neutral\"):\n        \n            selected_text_processed.append(text)\n            \n    return selected_text_processed            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trainST = polar(df_train)\nlen(trainST)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Calculation of jaccard value\ntrain_selected_data = df_train['selected_text']\naverage = 0;\nfor i in range(0,len(train_selected_data)):\n    jaccard_score = jaccard(str(trainST[i]),str(train_selected_data[i]))\n    average = jaccard_score+average \nprint('Training accuracy')\nprint(average/len(trainST))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# using our made func to find words with high polar value\ntestST = polar(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#FINAL\nFINAL['selected_text'] =testST\nFINAL.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FINAL.to_csv('submission.csv',index = False)","execution_count":null,"outputs":[]}],"metadata":{"colab":{"name":"spamdetectionemail3295.ipynb","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":4}