{"cells":[{"metadata":{},"cell_type":"markdown","source":"Tới đoạn trích xuất được span của row 0"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial = pd.read_csv('../input/dataset-for-toxic-span-detection/tsd_trial.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spans = trial.spans\ntext = trial.text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"spans[0]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Trích xuất selected text từ span**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import json\nfor i in range(0, len(spans)):\n    spans[i] = json.loads(spans[i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected = []\nfor n in range(0, len(spans)):\n    temp = \"\"\n    for i in range(0, len(spans[n])):\n        if i>0 and spans[n][i]-spans[n][i-1] != 1:\n            temp += ' '\n        temp += text[n][spans[n][i]]\n    selected.append(temp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_text = pd.DataFrame(selected, columns = ['selected_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial2 = pd.concat([trial, selected_text], axis = 1, sort = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial2 = trial2.drop(['spans'], axis = 1)\n#Bỏ cột spans","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**MOST COMMON WORDS IN SPANS**"},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ntrial2['temp_list'] = trial2['Selected text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in trial2['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')\n\"\"\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'../working/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pass model = nlp if you want to train on top of existing model \n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_out_path():\n    model_out_path = 'models/model_neg'\n    return model_out_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#modify here\ndef get_training_data():\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in trial2.iterrows():\n        selected_text = row.selected_text\n        text = row.text\n        start = text.find(selected_text)\n        end = start + len(selected_text)\n        train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = get_training_data()\nmodel_path = get_model_out_path()\n\ntrain(train_data, model_path, n_iter=30, model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MODELS_BASE_PATH = './models/'\nmodel_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_texts = []\nfor index, row in trial2.iterrows():\n        text = row.text\n        output_str = \"\"\n        selected_texts.append(predict_entities(text, model_neg))\nselected_texts = pd.DataFrame(selected_texts, columns = ['output3'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial2 = pd.concat([trial2, selected_texts], axis = 1, sort = False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial2.head(n = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"trial2.head(n = 30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}