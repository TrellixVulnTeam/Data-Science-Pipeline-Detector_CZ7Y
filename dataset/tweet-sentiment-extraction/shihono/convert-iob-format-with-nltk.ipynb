{"cells":[{"metadata":{},"cell_type":"markdown","source":"# IOB format\n\nconvert training data into IOB format to apply NER approach.\n\n> https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import re\nimport numpy as np\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_path = '/kaggle/input/tweet-sentiment-extraction/train.csv'\ntest_path = '/kaggle/input/tweet-sentiment-extraction/test.csv'\nsubmit_path = '/kaggle/input/tweet-sentiment-extraction/sample_submission.csv'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(train_path)\ndf.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## preprocess\n\n- drop na\n- strip text\n    - strip URL and other words (if needed)"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.dropna(axis = 0, how ='any',inplace=True)\n\ndf.text = df.text.str.strip()\ndf.selected_text = df.selected_text.str.strip()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# add IOB tag with NLTK\n\nTo keep information of char position, use [TreebankWordTokenizer.span_tokenize](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.treebank.TreebankWordTokenizer.span_tokenize).\n\nanother `span_tokenize` is OK. \n([nltk.tokenize package](https://docs.huihoo.com/nltk/3.0/api/nltk.tokenize.html) for your reference)\n\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import nltk\nfrom nltk.tokenize import TreebankWordTokenizer\n# from nltk.tokenize import sent_tokenize, word_tokenize\ntwt = TreebankWordTokenizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['span_list'] = df.text.apply(twt.span_tokenize)\ndf[['text', 'span_list']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_iob(text, selected_text, twt=twt, sentiment=None):\n    \"\"\"\n    :param text: text\n    :param selected_text: selected_text\n    :param twt: Tokenizer that has `span_tokenize()` function\n    :param sentiment: add sentiment info to IB tag e.g. `B-positive`, `I-neutral`\n    :returns: iob string\n    \"\"\"\n    sentiment_dict = {'positive':'POS', 'negative':'NEG', 'neutral': 'NEU'}\n\n    start, end = re.search(re.escape(selected_text), text).span()\n    # list of (start_idx, stop_idx)\n    span_list = twt.span_tokenize(text)\n    \n    iob_list = []\n    for start_sp, end_sp in span_list:\n        iob_tag = 'O'\n        if start_sp == start:\n            iob_tag = 'B'\n        elif start < start_sp and end_sp <= end:\n            iob_tag = 'I'\n            \n        if sentiment is not None and iob_tag!='O':\n            iob_tag += '-{}'.format(sentiment_dict[sentiment])\n        iob_list.append(iob_tag)\n    return ' '.join(iob_list)\n    \n\ndef get_iob_format_from_row(row, twt=twt, add_sentiment=False):\n    if add_sentiment:\n        return get_iob(row.text, row.selected_text, twt=twt, sentiment=row.sentiment)\n    return get_iob(row.text, row.selected_text, twt=twt)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### sample output"},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head().apply(get_iob_format_from_row,axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# iob with sentiment info\ndf.head().apply(lambda x:get_iob_format_from_row(x, add_sentiment=True), axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# apply DataFrame"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_pn = df.query('sentiment!=\"neutral\"').copy()\ndf_pn['iob'] = df_pn.apply(lambda x:get_iob_format_from_row(x, add_sentiment=True), axis=1)\ndf_pn[['text','iob']].head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_data = df_pn['text'].str.split()\niob_data = df_pn['iob'].str.split()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# test data\n\ndata without `selected_text`"},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv(test_path)\ndf_test.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.text = df_test.text.str.strip()\n# df_test_pn = df_test.query('sentiment!=\"neutral\"').copy()\n\n# twt = TreebankWordTokenizer()\ndf_test['text_list'] = df_test.text.apply(lambda x: [x[start_i:end_i] for start_i, end_i in twt.span_tokenize(x)])\n\n# df_test_pn['pos_list'] = df_test_pn.text.apply(lambda x: nltk.pos_tag([x[start_i:end_i] for start_i, end_i in twt.span_tokenize(x)]))\ndf_test.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}