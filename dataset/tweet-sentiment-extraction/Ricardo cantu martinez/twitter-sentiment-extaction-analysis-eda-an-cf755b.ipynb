{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Acerca de esta competencia\n\nUsted es alguien que está comenzando recientemente en PNL o se ha convertido en un maestro, independientemente de dónde se encuentre en la cadena de aprendizaje, puedo apostar que ha trabajado en el análisis de sentimientos y, si no lo hará, simplemente no puede evitarlo. . ¿Puedes?. El <b> análisis de sentimientos </b> es para PNL. <b> '¿Qué feliz cumpleaños para ti' </b> es para los guitarristas, verdad? Empiece aquí <br>\n<br>\nEn caso de que no esté al tanto del análisis de sentimientos, aquí hay un muy buen artículo: https://towardsdatascience.com/sentiment-analysis-concept-analysis-and-applications-6c94d6f58c17\n<br> <br>\nRecientemente, Kaggle lanzó una nueva competencia para el COVID-19 Scare, llamada Twitter Sentiment Extraction, sé que es una competencia de análisis de sentimientos de Twitter, pero Kaggle nunca te decepciona, no podría haber sido tan sencillo, después de todo, ha durado dos meses. Entonces, lo que pide esta competencia no son las puntuaciones de sentimiento, sino la parte del tweet (palabra o frase) que refleja el sentimiento. Interesante, ¿no? Esta competencia es especial, así que si quieres mejorar tus habilidades de PNL, esta competencia es para ti.\n\n# Agradecimientos\n* https://www.kaggle.com/aashita/word-clouds-of-various-shapes -> FUNCIÓN WORDCLOUDS\n* https://www.kaggle.com/rohitsingh9990/ner-training-using-spacy-0-628-lb -> Para comprender cómo entrenar NER espacial en entradas personalizadas\n\n\n# Acerca de este cuaderno\n\nEn este kernel, explicaré brevemente la estructura del conjunto de datos y generaré y analizaré metafunciones. Luego, visualizaré el conjunto de datos usando Matplotlib, seaborn y Plotly para obtener la mayor información posible. También abordaré este problema como un problema NER para construir un modelo\n<br> <br>\nEn caso de que recién esté comenzando con la PNL, aquí hay una guía para abordar casi cualquier problema de PNL del Gran Maestro @Abhishek Thakur\nhttps://www.slideshare.net/abhishekkrthakur/approaching-almost-any-nlp-problem\n\n\n<b> Este kernel es un trabajo en progreso, y seguiré actualizándolo a medida que avanza la competencia y aprendo más y más cosas sobre los datos </b>\n\n** <span style = \"color: Red\"> Si encuentra útil este kernel, por favor vote hacia arriba, me motiva a escribir más contenido de calidad ** "},{"metadata":{},"cell_type":"markdown","source":"# Importación de necesidades "},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** A continuación se muestra una función auxiliar que genera colores aleatorios que se pueden usar para dar diferentes colores a sus gráficos. Siéntase libre de usarla ** "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def random_colours(number_of_colors):\n    '''\n    Simple function for random colours generation.\n    Input:\n        number_of_colors - integer value indicating the number of colours which are going to be generated.\n    Output:\n        Color in the following format: ['#E86DA4'] .\n    '''\n    colors = []\n    for i in range(number_of_colors):\n        colors.append(\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]))\n    return colors","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Leer los datos "},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nss = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Así que tenemos 27486 tweets en el conjunto de trenes y 3535 tweets en el conjunto de prueba "},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tenemos un valor nulo en el tren, ya que el campo de prueba para el valor es NAN, simplemente lo eliminaremos "},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No hay valores nulos en el conjunto de prueba "},{"metadata":{},"cell_type":"markdown","source":"# Si "},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Selected_text es un subconjunto de texto "},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veamos la distribución de tweets en el tren. "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.countplot(x='sentiment',data=train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dibujemos un gráfico de embudo para una mejor visualización "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = go.Figure(go.Funnelarea(\n    text =temp.sentiment,\n    values = temp.text,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Qué sabemos actualmente sobre nuestros datos:\n\nAntes de comenzar, veamos algunas cosas que ya sabemos sobre los datos y que nos ayudarán a obtener más conocimientos nuevos:\n* Sabemos que selected_text es un subconjunto de texto\n* Sabemos que selected_text contiene solo un segmento de texto, es decir, no salta entre dos oraciones. Por ejemplo: - Si el texto es 'Pasé toda la mañana en una reunión con un proveedor, y mi jefe no estaba contento con ellos. Mucha diversión. Tenía otros planes para mi mañana 'El texto seleccionado puede ser' mi jefe no estaba contento con ellos. Mucha diversión 'o' Mucha diversión 'pero no puede ser' Buenos días, vendedor y mi jefe,\n* Gracias a esta discusión: https: //www.kaggle.com/c/tweet-sentiment-extraction/discussion/138520 Sabemos que los tweets neutrales tienen una similitud jaccard del 97 por ciento entre el texto y el texto seleccionado\n* También como se discutió aquí https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/138272, hay filas donde selected_text comienza entre las palabras y, por lo tanto, selected_texts no siempre tienen sentido y ya que no lo sabemos si la salida del conjunto de prueba contiene estas discrepancias o no, no estamos seguros de que el preprocesamiento y la eliminación de las puntuaciones sea una buena idea o no "},{"metadata":{},"cell_type":"markdown","source":"## Generación de metacaracterísticas "},{"metadata":{},"cell_type":"markdown","source":"** En las versiones anteriores de este cuaderno, utilicé Número de palabras en el texto seleccionado y el texto principal, Longitud de las palabras en el texto y seleccionadas como meta características principales, pero en el contexto de esta competencia donde tenemos que predecir selected_text que es un subconjunto de texto, las características más útiles para generar serían **: -  * Diferencia en el número de palabras de Selected_text y Text  * Puntuaciones de similitud de Jaccard entre el texto y Selected_text  Por lo tanto, no será útil para nosotros generar características que usamos antes, ya que aquí no tienen importancia.  Para quién no sabe qué es Jaccard Similarity: https://www.geeksforgeeks.org/find-the-jaccard-index-and-jaccard-distance-between-the-two-given-sets/ "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"results_jaccard=[]\n\nfor ind,row in train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append([sentence1,sentence2,jaccard_score])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"jaccard = pd.DataFrame(results_jaccard,columns=[\"text\",\"selected_text\",\"jaccard_score\"])\ntrain = train.merge(jaccard,how='outer')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train['Num_words_ST'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['Num_word_text'] = train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ntrain['difference_in_words'] = train['Num_word_text'] - train['Num_words_ST'] #Difference in Number of words text and Selected Text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Veamos la distribución de las metacaracterísticas "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"hist_data = [train['Num_words_ST'],train['Num_word_text']]\n\ngroup_labels = ['Selected_Text', 'Text']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot(hist_data, group_labels,show_curve=False)\nfig.update_layout(title_text='Distribution of Number Of words')\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=700,\n    paper_bgcolor=\"LightSteelBlue\",\n)\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* El diagrama de número de palabras es realmente interesante, los tweets que tienen un número de palabras superior a 25 son muy inferiores y, por lo tanto, el diagrama de distribución del número de palabras está sesgado a la derecha "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train['Num_words_ST'], shade=True, color=\"r\").set_title('Kernel Distribution of Number Of words')\np1=sns.kdeplot(train['Num_word_text'], shade=True, color=\"b\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Ahora será más interesante ver la diferencia en el número de palabras y puntuaciones de jaccard en diferentes sentimientos ** "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Kernel Distribution of Difference in Number Of words')\np2=sns.kdeplot(train[train['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.distplot(train[train['sentiment']=='neutral']['difference_in_words'],kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No pude trazar el gráfico kde para tweets neutrales porque la mayoría de los valores para la diferencia en el número de palabras eran cero. Podemos verlo claramente ahora, si hubiéramos usado la función al principio, habríamos sabido que el texto y el texto seleccionado son en su mayoría lo mismo para los tweets neutrales, por lo que siempre es importante tener en cuenta el objetivo final al realizar EDA "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('KDE of Jaccard Scores across different Sentiments')\np2=sns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")\nplt.legend(labels=['positive','negative'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No pude trazar kde de jaccard_scores de tweets neutrales por la misma razón, por lo que trazaré una trama de distribución "},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.distplot(train[train['sentiment']=='neutral']['jaccard_score'],kde=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver algunas tendencias interesantes aquí:  * Los tweets positivos y negativos tienen una alta curtosis y, por lo tanto, los valores se concentran en dos regiones estrechas y de alta densidad.  * Los tweets neutrales tienen un valor de curtosis bajo y su densidad aumenta cerca de los valores de 1  Para aquellos que no saben:  * La curtosis es la medida de cuán pico es una distribución y cuánta propagación está alrededor de ese pico.  * La asimetría mide cuánto se desvía una curva de una distribución normal "},{"metadata":{},"cell_type":"markdown","source":"## Conclusión de EDA  * Podemos ver en la gráfica de puntuación de jaccard que hay un pico para la gráfica negativa y positiva alrededor de la puntuación de 1. Eso significa que hay un grupo de tweets donde hay una alta similitud entre el texto y los textos seleccionados, si podemos encontrar esos grupos, entonces podemos predecir texto para textos seleccionados para esos tweets independientemente del segmento  Veamos si podemos encontrar esos grupos, una idea interesante sería revisar los tweets que tienen un número de palabras menor a 3 en el texto, porque allí el texto podría usarse completamente como texto. "},{"metadata":{"trusted":true},"cell_type":"code","source":"k = train[train['Num_word_text']<=2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"k.groupby('sentiment').mean()['jaccard_score']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos ver que existe similitud entre el texto y el texto seleccionado. Veamos más de cerca "},{"metadata":{"trusted":true},"cell_type":"code","source":"k[k['sentiment']=='positive']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Por lo tanto, está claro que la mayoría de las veces, el texto se usa como texto seleccionado. Podemos mejorar esto procesando previamente el texto que tiene una longitud de palabra menor a 3. Recordaremos esta información y la usaremos en la construcción de modelos. "},{"metadata":{},"cell_type":"markdown","source":"### Limpieza del Corpus  Ahora, antes de sumergirnos en la extracción de información de palabras en texto y texto seleccionado, primero limpiemos los datos "},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Palabras más comunes en nuestro texto seleccionado de destino "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Selected Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"¡Vaya! Mientras limpiamos nuestro conjunto de datos, no eliminamos las palabras vacías y, por lo tanto, podemos ver que la palabra más común es 'para'. Intentemos de nuevo después de eliminar las palabras vacías "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Palabras más comunes en el texto  Veamos también las palabras más comunes en Text "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"train['temp_list1'] = train['text'].apply(lambda x:str(x).split()) #List of words in every row for text\ntrain['temp_list1'] = train['temp_list1'].apply(lambda x:remove_stopword(x)) #Removing Stopwords","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Entonces, las dos primeras palabras comunes fueron I'm, así que la eliminé y tomé datos de la segunda fila "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Commmon Words in Text', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Entonces podemos ver que las palabras más comunes en el texto seleccionado y el texto son casi las mismas, lo cual era obvio "},{"metadata":{},"cell_type":"markdown","source":"# Palabras más comunes Sentimientos Sabio  Veamos las palabras más comunes en diferentes sentimientos. "},{"metadata":{"trusted":true},"cell_type":"code","source":"Positive_sent = train[train['sentiment']=='positive']\nNegative_sent = train[train['sentiment']=='negative']\nNeutral_sent = train[train['sentiment']=='neutral']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#MosT common positive words\ntop = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['Common_words','count']\ntemp_positive.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.bar(temp_positive, x=\"count\", y=\"Common_words\", title='Most Commmon Positive Words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#MosT common negative words\ntop = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.treemap(temp_negative, path=['Common_words'], values='count',title='Tree Of Most Common Negative Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"#MosT common Neutral words\ntop = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.bar(temp_neutral, x=\"count\", y=\"Common_words\", title='Most Commmon Neutral Words', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"fig = px.treemap(temp_neutral, path=['Common_words'], values='count',title='Tree Of Most Common Neutral Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"* Podemos ver palabras como get, go, dont, got, u, can, lol, like son comunes en los tres segmentos. Eso es interesante porque palabras como no y no puedo son más de naturaleza negativa y palabras como lol son más de naturaleza positiva. ¿Significa esto que nuestros datos están etiquetados incorrectamente, tendremos más información sobre esto después del análisis de N-gram  * Será interesante ver la palabra única para diferentes sentimientos. "},{"metadata":{},"cell_type":"markdown","source":"## Veamos palabras únicas en cada segmento  Veremos palabras únicas en cada segmento en el siguiente orden:  * Positivo  * Negativo  * Neutral "},{"metadata":{"trusted":true},"cell_type":"code","source":"raw_text = [word for word_list in train['temp_list1'] for word in word_list]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def words_unique(sentiment,numwords,raw_words):\n    '''\n    Input:\n        segment - Segment category (ex. 'Neutral');\n        numwords - how many specific words do you want to see in the final result; \n        raw_words - list  for item in train_data[train_data.segments == segments]['temp_list1']:\n    Output: \n        dataframe giving information about the name of the specific ingredient and how many times it occurs in the chosen cuisine (in descending order based on their counts)..\n\n    '''\n    allother = []\n    for item in train[train.sentiment != sentiment]['temp_list1']:\n        for word in item:\n            allother .append(word)\n    allother  = list(set(allother ))\n    \n    specificnonly = [x for x in raw_text if x not in allother]\n    \n    mycounter = Counter()\n    \n    for item in train[train.sentiment == sentiment]['temp_list1']:\n        for word in item:\n            mycounter[word] += 1\n    keep = list(specificnonly)\n    \n    for word in list(mycounter):\n        if word not in keep:\n            del mycounter[word]\n    \n    Unique_words = pd.DataFrame(mycounter.most_common(numwords), columns = ['words','count'])\n    \n    return Unique_words","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Tweets positivos "},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Positive= words_unique('positive', 20, raw_text)\nprint(\"The top 20 unique words in Positive Tweets are:\")\nUnique_Positive.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(Unique_Positive, path=['words'], values='count',title='Tree Of Unique Positive Words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Positive['count'], labels=Unique_Positive.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Positive Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Negative= words_unique('negative', 10, raw_text)\nprint(\"The top 10 unique words in Negative Tweets are:\")\nUnique_Negative.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.rcParams['text.color'] = 'black'\nplt.pie(Unique_Negative['count'], labels=Unique_Negative.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Negative Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Unique_Neutral= words_unique('neutral', 10, raw_text)\nprint(\"The top 10 unique words in Neutral Tweets are:\")\nUnique_Neutral.style.background_gradient(cmap='Oranges')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='white')\nplt.pie(Unique_Neutral['count'], labels=Unique_Neutral.words, colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('DoNut Plot Of Unique Neutral Words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Al observar las palabras únicas de cada sentimiento, ahora tenemos mucha más claridad sobre los datos, estas palabras únicas son determinantes muy fuertes del sentimiento de los tweets ** "},{"metadata":{},"cell_type":"markdown","source":"## Es hora de nubes de palabras  Construiremos nubes de palabras en el siguiente orden:  * WordCloud de tweets neutrales  * WordCloud de tweets positivos  * WordCloud de tweets negativos "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def plot_wordcloud(text, mask=None, max_words=200, max_font_size=100, figure_size=(24.0,16.0), color = 'white',\n                   title = None, title_size=40, image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords = {'u', \"im\"}\n    stopwords = stopwords.union(more_stopwords)\n\n    wordcloud = WordCloud(background_color=color,\n                    stopwords = stopwords,\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    width=400, \n                    height=200,\n                    mask = mask)\n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'bottom'})\n    plt.axis('off');\n    plt.tight_layout()  \nd = '/kaggle/input/masks-for-wordclouds/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"He agregado más palabras como im, u (que decimos que estaban allí en las palabras más comunes, perturbando nuestro análisis) como palabras vacías "},{"metadata":{},"cell_type":"markdown","source":"#### NUBE DE PALABRAS DE TWEETS NEUTRALES  Ya hemos visualizado nuestras palabras negativas más comunes, pero las nubes de palabras nos brindan mucha más claridad "},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"pos_mask = np.array(Image.open(d+ 'twitter_mask.png'))\nplot_wordcloud(Neutral_sent.text,mask=pos_mask,color='white',max_font_size=100,title_size=30,title=\"WordCloud of Neutral Tweets\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_wordcloud(Positive_sent.text,mask=pos_mask,title=\"Word Cloud Of Positive tweets\",title_size=30)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plot_wordcloud(Negative_sent.text,mask=pos_mask,title=\"Word Cloud of Negative Tweets\",color='white',title_size=30)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelado\n\nEsta es la primera competencia de kaggle, en la que estoy participando y este podría ser el caso de muchos de nosotros. Debido a la estructura única del planteamiento del problema, es difícil para cualquier principiante o novato de competencias responder a la pregunta \"¿Qué modelo to Use \"?. Mis pensamientos iniciales fueron que esta competencia no es para mí y ya terminé aquí, pero luego recordé algo, estuve en el KaggleDays Meetup Delhi este año y tuve esta maravillosa oportunidad de conocer al Gran Maestro Abhishek Thakur y durante el Sesión de preguntas y respuestas Le pregunté que las competiciones de kaggle son tan diversas, únicas, requieren muchos conocimientos previos y, por lo tanto, da miedo participar, a lo que respondió y cito \"¡Aterrador, sí! aprende si no vas a participar \".\n\nAsí que aquí estoy luchando para abrirme camino a través de esta competencia y tratando de aprender cosas diferentes e insto a todos a hacer lo mismo, puede que no esté tan bien establecido para dar consejos, pero realmente quería compartir esa historia para motivar a la gente.\n\nDespués de pasar por los foros de discusión, seguir los consejos de los expertos y ver el tutorial de Abhishek Sir anoche, este problema se puede modelar de la siguiente manera:\n* Reconocimiento de entidad nombrada\n* Problema de preguntas y respuestas\n* También encontré un enfoque simple compartido por Nick en su hermoso kernel donde tiene el concepto de Gini Impurity para dar peso a las palabras presentes en los tweets y luego predecir usando el peso de esas palabras: https://www.kaggle.com/ nkoprowicz / a-simple-solution-using-only-word-count / notebook. Compruébelo.\n* Otras ideas de modelado: - https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139803 -> Aquí hay una muy buena idea\n* Otra idea útil: - https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139335\n\nRecursos:\n* Para problemas de modelado como NER: https://www.kaggle.com/rohitsingh9990/ner-training-using-spacy-0-628-lb\n* Para problemas de modelado AS Q&A: https://www.kaggle.com/jonathanbesomi/question-answering-starter-pack ---> Esta es una guía completa y desde cero "},{"metadata":{},"cell_type":"markdown","source":"## 1) Modelando el problema como NER\n\nEl reconocimiento de entidades con nombre (NER) es un problema estándar de PNL que implica detectar entidades con nombre (personas, lugares, organizaciones, etc.) de un fragmento de texto y clasificarlas en un conjunto predefinido de categorías.\nPara comprender NER, aquí hay un muy buen artículo: https://towardsdatascience.com/named-entity-recognition-with-nltk-and-spacy-8c4a7d88e7da\n\nUsaremos spacy para crear nuestro propio modelo o modelos NER personalizados (separados para cada Sentiment). La motivación para este enfoque es, por supuesto, el kernel compartido por Rohit Singh, así que si encuentra útil su kernel, por favor vote por él.\n\n¿Qué será diferente con mi solución?\n* Usaré text como selected_text para todos los tweets neutrales debido a su gran similitud con jaccard\n* También usaré text como selected_text para todos los tweets que tengan un número de palabras menor a 3 en el texto como se explicó antes\n* Entrenaré dos modelos diferentes para tweets positivos y negativos\n* No preprocesaré los datos porque el texto seleccionado contiene texto sin formato "},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ndf_test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\ndf_submission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_train[df_train['Num_words_text']>=3]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"** Para una comprensión completa de cómo entrenar Spacy NER con entradas personalizadas, lea la documentación de Spacy junto con la presentación del código en este cuaderno: https://spacy.io/usage/training#ner Siga las instrucciones de Actualización de Spacy NER * * "},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'../working/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# pass model = nlp if you want to train on top of existing model \n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models/model_neg'\n    return model_out_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Modelos de entrenamiento para tweets positivos y negativos "},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n# For DEmo Purposes I have taken 3 iterations you can train the model as you want\ntrain(train_data, model_path, n_iter=3, model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\ntrain(train_data, model_path, n_iter=3, model=None)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predicción con el modelo entrenado "},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_texts = []\nMODELS_BASE_PATH = '../input/tse-spacy-model/models/'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n    for index, row in df_test.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ndf_test['selected_text'] = selected_texts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Notas finales\nKaggle siempre proporciona muchos días para una competencia que uno puede utilizar para aprender y crecer.Como prometí, presenté mi primer modelo, junto con una explicación, puede leer la documentación de Spacy y el kernel de Rohit Singh ya que todo el código proviene de su. si comprende cualquier parte del código, no dude en comentar y preguntar, intentaré resolverlo.\nComo esta es mi primera competencia, también estoy aprendiendo a lo largo del camino, volveré con ideas más originales y algunos modelos geniales a medida que aprenda más y más sobre preguntas / respuestas, otras técnicas diferentes, varias formas de BERT y los datos en sí.\n\n** Gracias por el enorme amor y aprecio, lamento no haber actualizado el kernel con el enfoque de preguntas y respuestas, todavía estoy aprendiendo todas las técnicas necesarias, ¡lo actualizaré pronto! **\n<br> <br> ¡MANTÉNGASE SINTONIZADO!\n\n<span style = \"color: Red\"> Espero que les haya gustado mi kernel. Un upvote es un gesto de agradecimiento y aliento que me llena de energía para seguir mejorando mis esfuerzos, sea amable de mostrar uno ;-) "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}