{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport re\nimport string\nfrom tqdm import tqdm\nimport time\nfrom collections import Counter\n\nimport nltk\nimport torch\nimport spacy\nfrom sklearn.preprocessing import binarize\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.utils.data import random_split, Subset","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint('Using device:', device)\nprint()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nss = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')\n\ntrain.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\nprint(test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    if (len(a) + len(b) - len(c)) == 0:\n        return 0\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\ndef evaluate(true, pred):\n    jac = 0\n    for s1, s2 in zip(true, pred):\n        jac += jaccard(s1, s2)\n    jac /= len(true)\n    return jac","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    # links\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    # multiple dots\n    text = re.sub('<.*?>+', '', text)\n    # punctuation\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    # new lines\n    text = re.sub('\\n', '', text)\n    # words containing numbers\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n# en = spacy.load('en') # en_core_web_sm\n\n# def tokenize_en(sentence):\n#     return [tok.text for tok in en.tokenizer(sentence)]\n\ndef preprocess_text(text):\n    \"\"\"\n    Cleaning and parsing the text.\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    #tokenized_text = tokenize_en(nopunc)\n    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(tokenized_text)\n    return combined_text\n\ndef preprocess_data(df):\n    \"\"\"\n    Preprocess dataframe.\n    text_clean and selected_text_clean will be used for training.\n    \"\"\"\n    df['text_clean'] = df['text'].apply(str).apply(lambda x: preprocess_text(x))\n    if 'selected_text' not in df.columns:\n        df['selected_text_clean'] = ''\n    else:\n        df['selected_text_clean'] = df['selected_text'].apply(str).apply(lambda x: preprocess_text(x))\n    # filter empty text after cleaning\n    return df[df['text_clean'].map(len) > 0]\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = preprocess_data(train)\ntest = preprocess_data(test)\ntrain.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.iloc[6].text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text = '2am feedings for the baby are fun when he is all smiles and coos'.split()\nselected_text = '2am feedings for the baby are fun when he is all smiles and coos'.split()\n\nprint(text)\nprint(selected_text)\n1*np.isin(text, selected_text).astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Vocab:\n    def __init__(self, texts):\n        words = [w for sent in texts for w in sent.split()]\n        self.counter = Counter(words)\n        self.PAD_IND = 0\n        self.TOK_IND = 1\n        self.UNK_IND = 2\n        self.word2index = {'PAD': self.PAD_IND, 'UNK': self.UNK_IND, 'TOK': self.TOK_IND}\n        num_special = len(self.word2index)\n        self.word2index.update({w: idx + num_special for idx, w in enumerate(set(words))})\n        self.word2index.update({'positive': self.word2index.get('positive', len(self.word2index))})\n        self.word2index.update({'negative': self.word2index.get('negative', len(self.word2index))})\n        self.word2index.update({'neutral': self.word2index.get('neutral', len(self.word2index))})\n        self.index2word = {ind: word for word, ind in self.word2index.items()}\n    \n    def __len__(self):\n        return len(self.word2index)\n    \n    def __getitem__(self, key):\n        return self.word2index.get(key, self.word2index['UNK'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Padder:\n    def __init__(self, dim=0, pad_symbol=0, max_len=None):\n        self.dim = dim\n        self.pad_symbol = pad_symbol\n        self.max_len = max_len\n        \n    def __call__(self, batch):\n        def merge(sequences):\n            lengths = [len(seq) for seq in sequences]\n            max_len = self.max_len if self.max_len is not None else max(lengths)\n            padded_seqs = torch.zeros(len(sequences), max_len).long()\n            for i, seq in enumerate(sequences):\n                end = lengths[i]\n                padded_seqs[i, :end] = seq[:end]\n            return padded_seqs, lengths\n    \n        sentiment, x, y = zip(*batch)\n\n        sentiment = torch.cat(sentiment)\n        x, x_lengths = merge(x)\n        y, y_lengths = merge(y)\n\n        return sentiment, x, y\n\nclass SentimentDataset:\n    def __init__(self, text, sentiment, selected_text, vocab):\n        self.text = text\n        self.sentiment = sentiment\n        self.selected_text = selected_text\n        self.vocab = vocab\n    \n    def __len__(self):\n        return len(self.text)\n    \n    def _prepare_data(self, sentiment, text, selected_text):\n        text_words = text.split()\n        selected_text_words = selected_text.split()\n        selected = np.isin(text_words, selected_text_words).astype(int)\n                    \n        x_seq = [self.vocab[w] for w in text_words]\n        y_seq = self.vocab.TOK_IND*selected\n        \n        return [self.vocab[sentiment]], x_seq, y_seq\n\n    def __getitem__(self, idx):\n        orig_text = self.text[idx]\n        orig_selected_text = self.selected_text[idx]\n        orig_sentiment = self.sentiment[idx]\n        sentiment, x, y = self._prepare_data(sentiment=orig_sentiment,\n                                  text=orig_text,\n                                  selected_text=orig_selected_text)\n        sentiment = torch.tensor(sentiment, dtype=torch.long)\n        x = torch.tensor(x, dtype=torch.long)\n        y = torch.tensor(y, dtype=torch.long)\n        return sentiment, x, y #, orig_text, orig_selected_text, orig_sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_LEN = 35\nvocab = Vocab(train['text_clean'].values)\ntrain_dataset = SentimentDataset(\n    text=train['text_clean'].values,\n    sentiment=train['sentiment'].values,\n    selected_text=train['selected_text_clean'].values,\n    vocab=vocab\n)\ntest_dataset = SentimentDataset(\n    text=test['text_clean'].values,\n    sentiment=test['sentiment'].values,\n    selected_text=train['selected_text_clean'].values,\n    vocab=vocab\n)\n\nsize = len(train_dataset)\nprint(f'dataset size={size}')\nval_size = int(size*0.15)\nprint(f'val size={val_size}')\ntrain_size = size - val_size\nprint(f'train size={train_size}')\nprint(f'test size={len(test_dataset)}')\n\ntrn, val = random_split(train_dataset, [train_size, val_size])\ntst = test_dataset\n\nprint(len(val))\nprint(len(trn))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(vocab['neutral'])\nprint(vocab['positive'])\nprint(vocab['negative'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_glove():\n    f = open('/kaggle/input/glove840b300dtxt/glove.840B.300d.txt')\n    \n    embeddings = {}\n    for i, line in enumerate(tqdm(f)):\n        value = line.split(' ')\n        word = value[0]\n        vec = np.array(value[1:],dtype = 'float32')\n        embeddings[word] = vec\n    return embeddings\n\nglove_embeddings = load_glove()\nEMBEDDING_SIZE = list(glove_embeddings.values())[0].shape[0]\n\nlen(glove_embeddings)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_embedding_matrix(vocab: Vocab, embeddings: dict):\n    num_words = len(vocab)\n    embedding_size = list(embeddings.values())[0].shape[0]\n    matrix = np.empty((num_words, embedding_size))\n    default_emb = np.mean(list(embeddings.values()), axis=0)\n    words_not_found = []\n    for word, ind in vocab.word2index.items():\n        if word not in embeddings:\n            words_not_found.append(word)\n            matrix[ind] = default_emb\n        else:\n            matrix[ind] = embeddings[word]\n    print(f'Embedding not found for {len(words_not_found)} words out of {num_words}')\n    return matrix, words_not_found","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"emb_matrix, not_found = build_embedding_matrix(vocab, glove_embeddings)\nemb_matrix = torch.LongTensor(emb_matrix)\ndel glove_embeddings\n\nemb_matrix = torch.LongTensor(emb_matrix)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, hidden_dim, emb_dim, num_embeddings, emb_vectors=None, padding_idx=None, dropout=0):\n        super().__init__()\n        self.emb = nn.Embedding(num_embeddings=num_embeddings,\n                                embedding_dim=emb_dim,\n                                padding_idx=padding_idx)\n        if emb_vectors is not None:\n            self.emb.weight.data.copy_(emb_vectors)\n        self.rnn = nn.LSTM(input_size=emb_dim,\n                          hidden_size=hidden_dim,\n                          batch_first=True,\n                          bidirectional=True\n                        )\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(dropout)\n        self.out_size = MAX_LEN\n        self.fc = nn.Linear(in_features=hidden_dim*2,\n                            out_features=self.out_size)\n\n    def forward(self, sentiment, input, hidden=None):\n        # input   :  (batch_size, seq_length)\n        # add sentiment before input sequence\n        input = torch.cat([sentiment.unsqueeze(dim=1).t(), input.t()]).t()\n        batch_size = input.shape[0]\n        emb = self.emb(input)                   # (batch_size, seq_length, emb_dim)\n        #print(f'emb shape= {emb.shape}')\n        rnn_out, hidden = self.rnn(emb, hidden) # (batch_size, seq_length, hidden_dim*2)\n        out = self.relu(rnn_out)                # (batch_size, seq_length, hidden_dim*2)\n        out = self.dropout(out)                 # (batch_size, seq_length, hidden_dim*2)\n        out = self.fc(out)                      # (batch_size, seq_length, output_size)\n        #print(f'out1 shape= {out.shape}')\n        out = out.view(batch_size, -1)          # (batch_size, seq_length*output_size)\n        #print(f'out2 shape= {out.shape}')\n        # get last batch of labels\n        preds = out[:, -self.out_size:]\n        #print(f'preds shape= {preds.shape}')\n        return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"HIDDEN_DIM = 300\nEMBEDDING_SIZE = 300\nmodel = RNN(hidden_dim=HIDDEN_DIM, emb_dim=EMBEDDING_SIZE, num_embeddings=len(vocab), emb_vectors=emb_matrix, padding_idx=vocab.PAD_IND, dropout=0.1)\nprint(model)\n\n\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\nloss_func = nn.BCEWithLogitsLoss()\nN_EPOCHS = 12\nBATCH_SIZE = 32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train(model, train, val, optimizer, loss_func, batch_size=BATCH_SIZE, epochs=N_EPOCHS):\n    losses = []\n    val_losses = []\n    times = []\n    if torch.cuda.is_available():\n        model.cuda()\n    for epoch in range(epochs):\n        start = time.time()\n        total_loss = 0\n        batcher = torch.utils.data.DataLoader(dataset=train, batch_size=batch_size, shuffle=True, collate_fn=Padder(max_len=MAX_LEN))\n        t = 0\n        model.train()\n        for sentiment, x, y in batcher:\n            if torch.cuda.is_available():\n                sentiment = sentiment.cuda()\n                x = x.cuda()\n                y = y.cuda()\n            y = y.float()\n\n            preds = model(sentiment, x)   \n            loss = loss_func(preds, y)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n\n            t += 1\n        total_loss /= len(batcher)\n        losses.append(total_loss)\n\n        # validation loss\n        test_batcher = torch.utils.data.DataLoader(dataset=val, batch_size=len(val), shuffle=False, collate_fn=Padder(max_len=MAX_LEN))\n        sentiment, test_x, test_y = next(iter(test_batcher))\n\n        if torch.cuda.is_available():\n            sentiment = sentiment.cuda()\n            test_x = test_x.cuda()\n            test_y = test_y.cuda()\n        test_y = test_y.float()\n        optimizer.zero_grad()\n        model.eval()\n        preds = model(sentiment, test_x)   \n        val_loss = loss_func(preds, test_y)\n        val_loss = val_loss.item()\n        val_losses.append(val_loss)\n\n        end = time.time()\n        times.append(float(end - start)/60)\n        print(f'Epoch {epoch}')\n        print(f'\\tTraining loss = {total_loss:.4}')\n        print(f'\\tValidation loss = {val_loss:.5}')\n        print('\\tEpoch took %.2f minutes' % (float(end - start)/60))\n    return losses, val_losses","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_losses(losses, val_losses):\n    fig, ax = plt.subplots(1,1, figsize=(16,4))\n    ax.set(xlabel='epoch', ylabel='total loss',\n        title='loss per epoch')\n    ax.grid()\n    losses = np.array(losses)\n    ax.plot(losses, color='b', label='Train loss')\n    ax.plot(val_losses, color='r', label='Validation loss')\n    ax.legend()\n    \nlosses, val_losses = train(model, trn, val, optimizer, loss_func)\nplot_losses(losses, val_losses)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def decode_prediction(test_x, preds, threshold=0.5):\n    test_x = test_x.to('cpu').detach().numpy()\n    preds = preds.to('cpu').detach().numpy()\n        \n    binary_preds = binarize(preds, threshold=threshold)\n    selected_words = []\n    for test_seq, pred_seq in zip(test_x, binary_preds):\n        test_inds = test_seq\n        selected_seq = [vocab.index2word[ind] for ind, select in zip(test_inds, pred_seq) if select == vocab.TOK_IND]\n        selected_words.append(selected_seq)\n    return selected_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def validate(model, dataset, threshold):\n    # get prediction\n    test_batcher = torch.utils.data.DataLoader(dataset=dataset, batch_size=len(dataset), shuffle=False, collate_fn=Padder(max_len=MAX_LEN))\n    sentiment, test_x, test_y = next(iter(test_batcher))\n    if torch.cuda.is_available():\n        sentiment = sentiment.cuda()\n        test_x = test_x.cuda()\n    optimizer.zero_grad()\n    model.eval()\n    preds = model(sentiment, test_x)   \n    probability_preds = torch.sigmoid(preds)\n\n    y_pred = decode_prediction(test_x, probability_preds, threshold=threshold)\n    y_true = decode_prediction(test_x, test_y)\n    y_pred_text = [' '.join(words) for words in y_pred]\n    y_true_text = [' '.join(words) for words in y_true]\n    score = evaluate(y_true_text, y_pred_text)\n    print(f'Jaccard test score={score:.3f}')\n    return score\n\nvalidate(model, val, threshold=0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_by_sentiment(dataset):\n    sentiment_inds = {\n        'neutral': [],\n        'positive': [],\n        'negative': [],\n    }\n    for i, (sentiment_tok, x, y) in enumerate(dataset):\n        sentiment = vocab.index2word[sentiment_tok.numpy()[0]]\n        sentiment_inds[sentiment].append(i)\n    ds_neutral = Subset(dataset, sentiment_inds['neutral'])\n    ds_positive = Subset(dataset, sentiment_inds['positive'])\n    ds_negative = Subset(dataset, sentiment_inds['negative'])\n    return {\n        'neutral': ds_neutral,\n        'positive': ds_positive,\n        'negative': ds_negative,\n    }\n\nval_by_sentiment = split_by_sentiment(val)\nval_neutral = val_by_sentiment['neutral']\nval_positive = val_by_sentiment['positive']\nval_negative = val_by_sentiment['negative']\n\nvalidate(model, val_neutral, threshold=0.4)\nvalidate(model, val_positive, threshold=0.4)\nvalidate(model, val_negative, threshold=0.4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_batcher = torch.utils.data.DataLoader(dataset=test_dataset, batch_size\n=len(test_dataset), shuffle=False, collate_fn=Padder(max_len=MAX_LEN))\nsentiment, test_x, test_y = next(iter(test_batcher))\nif torch.cuda.is_available():\n    sentiment = sentiment.cuda()\n    test_x = test_x.cuda()\nmodel.eval()\npreds = model(sentiment, test_x)   \nprobability_preds = torch.sigmoid(preds)\n\ny_pred = decode_prediction(test_x, probability_preds, threshold=0.4)\ny_true = decode_prediction(test_x, test_y)\ny_pred_text = [' '.join(words) for words in y_pred]\ny_true_text = [' '.join(words) for words in y_true]\nscore = evaluate(y_true_text, y_pred_text)\n\nassert(len(y_pred_text) == len(test))\ny_pred_text = [txt.replace(' PAD', '') for txt in y_pred_text]\ntest['selected_text']=y_pred_text\n# if neutral leave whole text\ntest.loc[test['sentiment'] == 'neutral', 'selected_text'] = test.loc[test['sentiment'] == 'neutral', 'text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ss.loc[:, 'selected_text']=test['selected_text']\nss[['textID','selected_text']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"checkpoint = {'model': model,\n              'state_dict': model.state_dict(),\n              'optimizer' : optimizer.state_dict()}\n\ntorch.save(checkpoint, 'submission.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}