{"cells":[{"metadata":{},"cell_type":"markdown","source":"<h1>Tweet Sentiment Extraction - Exploratory Data Analysis</h1>\n\n\nThe objective of this competition is to extract a selected text from entire text that corresponds to a given sentiment, for each data sample. \n\nThe train data contains as well the extracted text, while test data only contains the text and sentiment.  "},{"metadata":{},"cell_type":"markdown","source":"# Load packages"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n%matplotlib inline \nstopwords = set(STOPWORDS)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load data"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"DATA_FOLDER = \"/kaggle/input/tweet-sentiment-extraction/\"\ntrain_df = pd.read_csv(os.path.join(DATA_FOLDER, \"train.csv\"))\ntest_df = pd.read_csv(os.path.join(DATA_FOLDER, \"test.csv\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Glimpse the data"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"train: {train_df.shape}  test: {test_df.shape}\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data exploration\n\nLet's explore the train and test data.\n\n\nWe start by looking to the text distribution in train and test, as well as selected text in train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=stopwords,\n        max_words=200,\n        max_font_size=40, \n        scale=5,\n        random_state=1\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(10,8))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=14)\n        fig.subplots_adjust(top=2.3)\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df['text'], 'train: text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(train_df['selected_text'], 'train: selected text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_wordcloud(test_df['text'], 'test: text')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's look to the distribution of sentiments in the train and test data."},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_sentiment_count(data_df, title):\n    plt.figure(figsize=(8,6))\n    sns.countplot(data_df['sentiment'])\n    plt.title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sentiment_count(train_df, \"Sentiment distribution: train\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_sentiment_count(test_df, \"Sentiment distribution: test\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The sentiment data is not balanced and, more that this, it is not balanced with respect to train and test data.  \n\nLet's look as well to the train/test words distribution, grouped on sentiment.  \n"},{"metadata":{"trusted":true},"cell_type":"code","source":"for sentiment in train_df.sentiment.unique():\n    show_wordcloud(train_df.loc[train_df['sentiment']==sentiment, 'text'], f'train data - (sentiment: {sentiment}): text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sentiment in train_df.sentiment.unique():\n    show_wordcloud(train_df.loc[train_df['sentiment']==sentiment, 'selected_text'], f'train data - (sentiment: {sentiment}): selected text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sentiment in test_df.sentiment.unique():\n    show_wordcloud(test_df.loc[test_df['sentiment']==sentiment, 'text'], f'test data - (sentiment: {sentiment}): text')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pre-process text\n\nWe will perform the following text transformations:\n* Clean special characters;  \n* Clean punctuations;  \n* Eliminate stopwords;  \n* Convert to lovercase;"},{"metadata":{"trusted":true},"cell_type":"code","source":"punct_mapping = \"/-'?!.,#$%\\'()*+-/:;<=>@[\\\\]^_`{|}~\" + '\"\"“”’' + '∞θ÷α•à−β∅³π‘₹´°£€\\×™√²—–&'\npunct_mapping += '©^®` <→°€™› ♥←×§″′Â█½à…“★”–●â►−¢²¬░¶↑±¿▾═¦║―¥▓—‹─▒：¼⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸¾Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡√'\n\npuncts = {\"‘\": \"'\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', '…': ' '}\n\ndef clean_special_chars(text, punct, mapping):\n    '''\n    credits to: https://www.kaggle.com/christofhenkel/how-to-preprocessing-when-using-embeddings \n    credits to: https://www.kaggle.com/anebzt/quora-preprocessing-model\n    input: current text, punctuations, punctuation mapping\n    output: cleaned text\n    '''\n    for p in mapping:\n        text = text.replace(p, mapping[p])\n    for p in punct:\n        text = text.replace(p, f' {p} ') \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].fillna(\"\")\ntrain_df['selected_text'] = train_df['selected_text'].fillna(\"\")\ntest_df['text'] = test_df['text'].fillna(\"\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['cleaned_text'] = train_df['text'].apply(lambda x: clean_special_chars(x, punct_mapping, puncts))\ntest_df['cleaned_text'] = test_df['text'].apply(lambda x: clean_special_chars(x, punct_mapping, puncts))\ntrain_df['cleaned_selected_text'] = train_df['selected_text'].apply(lambda x: clean_special_chars(x, punct_mapping, puncts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\ndef preprocess(text):\n    result = []\n    for token in gensim.utils.simple_preprocess(text):\n        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 2:\n            result.append(token)\n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['preproc_text'] = train_df['cleaned_text'].apply(lambda x: preprocess(x))\ntest_df['preproc_text'] = test_df['cleaned_text'].apply(lambda x: preprocess(x))\ntrain_df['preproc_selected_text'] = train_df['cleaned_selected_text'].apply(lambda x: preprocess(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's count now the tokens.  \nWe will visualize the distribution of number of tokens / each sentiment."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['cnt_text'] = train_df['preproc_text'].apply(lambda x: len(x))\ntest_df['cnt_text'] = test_df['preproc_text'].apply(lambda x: len(x))\ntrain_df['cnt_selected_text'] = train_df['preproc_selected_text'].apply(lambda x: len(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_feature_density(data_df, feature='cnt_text', title=''):\n    plt.figure(figsize=(8,6))\n    for sentiment in data_df.sentiment.unique():\n        sns.distplot(data_df.loc[data_df['sentiment']==sentiment, feature], kde=True, hist=False, label=sentiment)\n    plt.title(title)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_density(train_df, 'cnt_text', 'Word count distribution - text - train')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_density(test_df, 'cnt_text', 'Word count distribution - text - test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_feature_density(train_df, 'cnt_selected_text', 'Word count distribution - selected text - train')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}