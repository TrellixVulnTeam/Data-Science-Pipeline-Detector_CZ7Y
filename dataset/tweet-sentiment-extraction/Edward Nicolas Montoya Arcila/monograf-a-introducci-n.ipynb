{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Comparativa de modelos predictivos para identificación de sentimientos\n\nEl análisis de sentimientos es una técnica que permite detectar el sentimiento subyacente de un fragmento de texto. Los sentimientos se suelen clasificar como: neutros, positivos y negativos. Existen diferentes maneras de analizar el texto para poder identificar el proposito o sentimiento del texto."},{"metadata":{},"cell_type":"markdown","source":"## ¿Por qué es importante el análisis de texto?\n\nEl análisis de sentimientos es esencial para múltiples tareas empresariales y retos del nuevo siglo. Mediante éste, ha sido posible mejorar en gran medida la atención al cliente y la automatización de procesos donde el lenguaje humano es altamente utilizado. Estos son algunos de los sectores donde es más usado el análisis de sentimientos:\n\n- Sector comercial.\n- Sector bancario.\n- Sector social.\n- Sector logistico.\n- Sector de transporte.\n\nLas aplicaciones del análisis de sentimientos son amplias y poderosas. La capacidad de extraer conocimientos de los datos sociales es una práctica que está siendo adoptada ampliamente por organizaciones de todo el mundo. El lenguaje humano es complejo. Enseñar a una máquina a analizar los diversos matices gramaticales, variaciones culturales, jergas y errores ortográficos que se producen en las menciones online es un proceso difícil. Enseñar a una máquina a comprender cómo el contexto puede afectar el tono es aún más difícil."},{"metadata":{},"cell_type":"markdown","source":"# Configuración de ambiente\n\nEl conjunto de datos elegido para este proyecto esta conformado por un conjunto de tweets, el sentimiento que expresa y aquellas palabras que soportan el sentimiento.\n\nLos tweets fueron obtenidos de la plataforma \"Data for Everyone\" de Figure Eight. El conjunto de datos se titula Análisis de sentimiento: tweets de emoción en texto con etiquetas de sentimiento existentes. El conjunto de datos se encuentra licenciado como creative commons 4.0, licencia internacional. \n\n## ¿Qué archivos conforman el conjunto de datos?\n\n- **train.csv:** Conjunto de datos de entrenamiento\n- **test.csv:** Conjunto de datos de prueba\n\n## Columnas del conjunto de datos\n\n- textID: Identificador único por tweet\n- text: Texto del tweet\n- sentiment: Sentimiento del tweet\n- selected_text: [Solo entrenamiento] Texto que soporta el sentimiento\n\nCada fila contiene el texto de un tweet y una etiqueta de opinión. En el conjunto de entrenamiento, se le proporciona una palabra o frase extraída del tweet (selected_text) que encapsula el sentimiento proporcionado.\n\n"},{"metadata":{},"cell_type":"markdown","source":"Para comenzar con el proceso de análisis de datos, primero importamos las librerías que necesitaremos en todo el proceso."},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade plotly==4.0.0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\nfrom sklearn.preprocessing import LabelEncoder\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense,Input,Activation,Flatten,Embedding,GlobalAveragePooling1D,Dropout,LSTM,Conv1D\nfrom tensorflow.keras.models import Model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nfrom wordcloud import WordCloud, STOPWORDS\nimport tensorflow as tf\nimport missingno as msno\nfrom collections import defaultdict\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport json\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Cargamos los datos de entrada proporcionados por tweet-sentiment-extraction"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\ntarget = train['sentiment']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Con los datos cargados, procedemos a realizar una analisis inicial de los datos para tratar de identificar posibles problemas o dificultades."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Podemos identificar que existen algunos datos nulos, procedemos a eliminarlos"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análisis exploratorio"},{"metadata":{},"cell_type":"markdown","source":"Con los datos listos podemos proceder al analisis exploratorio de los datos"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(16,6))\nax = fig.add_subplot(1,2,1)\nsns.countplot(x='sentiment',data=train)\nplt.title('Distribución de los sentimientos para los datos de entrenamiento')\nplt.xlabel('Sentimientos')\nplt.ylabel('Cantidad')\n\nax = fig.add_subplot(1,2,2)\nsns.countplot(x='sentiment',data=test)\nplt.title('Distribución de los sentimientos para los datos de prueba')\nplt.xlabel('Sentimientos')\nplt.ylabel('Cantidad')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = go.Figure(go.Funnelarea(text =temp.sentiment, values = temp.text))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Procedemos a hallar el indice de jaccard entre el texto del tweet y el texto seleccionado. También obtenemos algunas variables relevantes como: número de palabras en el texto, número de palabras en el texto seleccionado y diferencia de palabras."},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = train.copy()\n\nresults_jaccard=[]\nfor ind,row in temp.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append(jaccard_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp['jaccard_score'] = results_jaccard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp['count_st'] = train['selected_text'].apply(lambda x:len(str(x).split())) \ntemp['count_t'] = train['text'].apply(lambda x:len(str(x).split())) \ntemp['difference_in_words'] = temp['count_t'] - temp['count_st']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Contamos la cantidad de palabras que existe en el texto completo y el texto seleccionado para tener una idea de la distribución que siguen los datos de entrada. Esta apróximación nos da una idea de posibles soluciones a plantear."},{"metadata":{},"cell_type":"markdown","source":"En los siguientes graficos nos podemos dar una idea del tamaño del texto seleccionado (en caracteres) según el sentimiento. \n\n**Anotaciones**\n\n- La distribución para los tweets negativos y positivos es casi la misma.\n- El texto seleccionado en los tweets neutrales es considerablemente más grande, que en los demás casos."},{"metadata":{"trusted":true},"cell_type":"code","source":"rug_text_one = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j',\n                'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't',\n                'u', 'v', 'w', 'x', 'y', 'z']\n\nrug_text_two = ['aa', 'bb', 'cc', 'dd', 'ee', 'ff', 'gg', 'hh', 'ii', 'jj',\n                'kk', 'll', 'mm', 'nn', 'oo', 'pp', 'qq', 'rr', 'ss', 'tt',\n                'uu', 'vv', 'ww', 'xx', 'yy', 'zz']\ngroup_labels = ['Selected_Text', 'Text']\nrug_text = [rug_text_one, rug_text_two] # for hover in rug plot\ncolors = ['rgb(0, 0, 100)', 'rgb(0, 200, 200)']\n\n# Create distplot with custom bin_size\nfig = ff.create_distplot([temp['count_st'], temp['count_t']], group_labels,show_curve=False, rug_text=rug_text, colors=colors)\nfig.update_layout(title_text='Distribución de número de palabras')\nfig.update_layout(\n    autosize=False,\n    width=900,\n    height=700,\n    paper_bgcolor=\"LightSteelBlue\",\n)\n\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vals=[]\nsent = ['positive', 'negative', 'neutral']\nfor i in range(0,3):\n    x=temp[temp['sentiment']==sent[i]]['selected_text'].dropna().str.len()\n    vals.append(x)\n\nfig = ff.create_distplot(vals, sent)\nfig.update_layout(title=\"Distribución del número de caracteres en la variable Selected text\")\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"En los siguientes graficos podemos identificar que la distribución del número de palabras sigue un comportamiento similar a la distribución del número de caracteres.\n\nEl texto seleccionado en los tweets negativos y positivos presenta un claro sesgo hacia la izquierda, mientras para los tweets neutrales la distribución se mantiene muy similar al texto completo."},{"metadata":{"trusted":true},"cell_type":"code","source":"sent=temp.sentiment.unique()\ncolors = ['k', 'b', 'r']\nfig = plt.figure(figsize=(20,10))\nfor i in range(0,3):\n    ax = fig.add_subplot(1,3,i+1)\n    plt.hist(temp[temp['sentiment']==sent[i]]['count_t'], color=colors[i])\n    plt.title(sent[i])\nfig.suptitle(\"Ditribución de número de palabras por tweets\", fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sent=temp.sentiment.unique()\ncolors = ['k', 'b', 'r']\nfig = plt.figure(figsize=(20,10))\nfor i in range(0,3):\n    ax = fig.add_subplot(1,3,i+1)\n    plt.hist(temp[temp['sentiment']==sent[i]]['count_st'], color=colors[i])\n    plt.title(sent[i])\nfig.suptitle(\"Ditribución de número de palabras por tweets\", fontsize=14)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Las siguientes graficas nos permiten visualizar que el indice de Jaccard para los tweets neutrales en su mayoría es 1, es decir, la cantidad de palabras del texto seleccionado es la misma cantidad de palabras en el texto completo del tweet.**\n\nEn los sentimientos positivos y negativos, la distribución kernel del indice de Jaccard muestra dos nucleos principales de concentración de la palabras. El nucleo cercano a 1, nos da indicios que los tweets con muy pocas palabras siempre tienen el mismo número de palabras seleccionadas. Lo cual resulta bastante útil para la clasificación.\n\nEs interesante análizar la aproximación kernel del indice de Jaccard y de la diferencia de palabras. Pues, junto con los datos obtenidos anteriormente de la distribución de palabras seleccionadas y la distribución de palabras totales, nos pueden dar una idea del comportamiento del indice de Jaccard esperado (metrica de validación) según el sentimiento.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(temp[temp['sentiment']=='positive']['difference_in_words'], shade=True, color=\"b\").set_title('Distribución Kernel de diferencia de palabras')\np2=sns.kdeplot(temp[temp['sentiment']=='negative']['difference_in_words'], shade=True, color=\"r\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(temp[temp['sentiment']=='positive']['jaccard_score'], shade=True, color=\"b\").set_title('Distribución Kernel de diferencia de palabras')\np2=sns.kdeplot(temp[temp['sentiment']=='negative']['jaccard_score'], shade=True, color=\"r\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Análisis de palabras"},{"metadata":{},"cell_type":"markdown","source":"Para continuar con el análisis de palabras es necesario limpiar los tweets de:\n\n- Signos de puntuación.\n- Mayúsculas (Todo el texto se procesará en minúscula).\n- Información entre parentesis y brakets.\n- Números.\n- Palabras vácias"},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_clean = train.copy()\n\ntrain_clean['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain_clean['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_clean.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_clean['temp_list'] = train_clean['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train_clean['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['palabra_comun','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"palabra_comun\", title='Las palabras más comunes en el texto seleccionado', orientation='h', \n             width=700, height=700,color='palabra_comun')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dado que hay muchas palabaras vácias (Palabras sin significado de manera individual). Se debe proceder a limpiar el texto seleccionado para identificar las palabaras que mas se repiten."},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ntrain_clean['temp_list'] = train_clean['temp_list'].apply(lambda x:remove_stopword(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train_clean['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"Common_words\", title='Las palabras más comunes en el texto seleccionado SIN stopwords', orientation='h', \n             width=700, height=700,color='Common_words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_clean['temp_list1'] = train_clean['text'].apply(lambda x:str(x).split())\ntrain_clean['temp_list1'] = train_clean['temp_list1'].apply(lambda x:remove_stopword(x)) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train_clean['temp_list1'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(25))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['palabra_comun','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.bar(temp, x=\"count\", y=\"palabra_comun\", title='Palabras cómunes en los tweets', orientation='h', \n             width=700, height=700,color='palabra_comun')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## División por sentimientos."},{"metadata":{"trusted":true},"cell_type":"code","source":"Positive_sent = train_clean[train_clean['sentiment']=='positive']\nNegative_sent = train_clean[train_clean['sentiment']=='negative']\nNeutral_sent = train_clean[train_clean['sentiment']=='neutral']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in Positive_sent['temp_list'] for item in sublist])\ntemp_positive = pd.DataFrame(top.most_common(20))\ntemp_positive.columns = ['palabra_comun','count']\ntemp_positive.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in Negative_sent['temp_list'] for item in sublist])\ntemp_negative = pd.DataFrame(top.most_common(20))\ntemp_negative = temp_negative.iloc[1:,:]\ntemp_negative.columns = ['Common_words','count']\ntemp_negative.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in Neutral_sent['temp_list'] for item in sublist])\ntemp_neutral = pd.DataFrame(top.most_common(20))\ntemp_neutral = temp_neutral.loc[1:,:]\ntemp_neutral.columns = ['Common_words','count']\ntemp_neutral.style.background_gradient(cmap='Greys')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Es interesante resaltar que algunas palabras se repiten en las tres divisiones (get,go,dont,got,u,cant,lol,like). Esto a simple vista puede parecer un error de clasificación, sin embargo, solo es una muestra de lo nutrido que se encuentra nuestro conjunto de datos."},{"metadata":{},"cell_type":"markdown","source":"# Conclusiones EDA y Análisis de palabras\n\n- Es posible visualizar que las palabras seleccionadas para sustentar el sentimiento, siempre se encuentran dentro del texto principal.\n\n- Las palabras seleccionadas siempre son menores o iguales en cantidad a las palabras que contiene el texto principal del tweet.\n\n- En las palabras seleccionadas con sentimiento neutro existe una tendencia clara a que la cantidad de palabras seleccionadas tengan un tamaño igual al tamaño del texto principal.\n\n- La distribución de la cantidad de palabras de los tweet con sentimiento positivo y negativo son más complicadas de identificar y están distribuidas en dos secciones principalmente. Aquellas que contiene todas las palabras y aquellas que contiene aproximadamente una cuarta parte de las palabras del texto principal.\n\n- Las aproximaciones más comunes para este tipo de problemas son las Question And Answers (QA)."},{"metadata":{},"cell_type":"markdown","source":"# Análisis de sentimientos"},{"metadata":{},"cell_type":"markdown","source":"El análisis de sentimientos es el proceso que permite comprender una opinión sobre un tema escrito o hablado, en un idioma en particular. En el enfoque computacional, el análisis de sentimientos usan herramientas de Natural Language Processing (NLP), análisis de textos y computación linguistica para enfrentar problemas que requieran entender los sentimientos."},{"metadata":{},"cell_type":"markdown","source":"## ¿Cómo se debería enfrentar un problema de este estilo?"},{"metadata":{},"cell_type":"markdown","source":"1. Recopilar el texto que se desea analizar.\n2. Dividir el texto en palabras.\n3. Tokenizar las palabras.\n4. Transformar en vectores las palabra"},{"metadata":{},"cell_type":"markdown","source":"Para cualquier algoritmo de aprendizaje automático o aprendizaje profundo, se necesita que las entradas sean valores escalares o matrices de valores escalares. Normalmente se toman las palabras y se convierten en vectores. A cada palabra se le asigna un valor único de modo que cada vector de la palabra representa su contexto, significado y semántica.\n\n\nDe esta manera, las palabras con significado y contexto similares están en el mismo espacio vectorial. Una palabra que no tiene similitud se expresa en un ángulo de 90 grados. Las palabras con total similitud se colocan cerca del ángulo de 0 grados. En conclusión los vectores de las palabras son importantes porque nos permiten identificar la cercanía que pueden tener las palabras según su naturaleza."},{"metadata":{},"cell_type":"markdown","source":"## Selección de herramientas para clasificación"},{"metadata":{},"cell_type":"markdown","source":"A partir del EDA podemos identificar que el problema que encontramos en nuestro proyecto se puede afrontar mediante un análisis de sentimientos basado en Question And Answer (QA), el cual, consiste en diseñar modelos que permitan encontrar una respuesta dentro un contexto definido, es decir, dentro de un texto determinado, encontrar una respuesta basado en una pregunta.\n\nEn nuestro caso, el contexto hace referencia al Tweet, la respuesta sería el texto seleccionado y la pregunta el sentimiento asociado.\n\nNormalmente para este tipo de problemas se útilizan soluciones de embeddings con contexto como los propuestos por BERT o ELMO, combinados con algoritmos de machine learning. Sin embargo, para esta monografia también se quiere probar un enfoque más clásico combinando embedding sin contexto como Glove y algoritmos de machine learning. \n\nAntes de comenzar a plantear la solución, se realizará como prueba inicial un análisis de sentimientos basado en Glove para identificar si vale la pena plantear este tipo de solución o proponemos modelos tipo BERT unicamente."},{"metadata":{},"cell_type":"markdown","source":"### Aproximación - identificación de sentimientos mediante GloVe"},{"metadata":{"trusted":true},"cell_type":"code","source":"NB_START_EPOCHS = 10  # Número de iteraciones de entrenamiento\nBATCH_SIZE = 512  # Tamaño de grupos usados en entrenamiento\nGLOVE_DIM = 100  # Número de dimensiones los embeddings GloVe","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"El siguiente proceso de limpieza es menos agresivo que el realizado para nuestros datos iniciales. Este proceso mantiene más información y le permite a algoritmos como BERT mantener información que podrías ser relevante."},{"metadata":{"trusted":true},"cell_type":"code","source":"#Reference https://www.kaggle.com/parulpandey/eda-and-preprocessing-for-bert\n\ndef clean(tweet):\n  #Covert to lowercase\n  tweet=tweet.lower()\n\n  #Remove html tags\n  tweet=re.sub('<.*?>','',tweet)\n\n  #Remove text in square brackets\n  tweet=re.sub('\\[.*?\\]','',tweet)\n\n  #Remove hyperlinks\n  tweet=re.sub('https?://\\S+|www\\.\\S+','',tweet)\n\n  \n  return tweet","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Hallamos la cantidad de palabras que cubran la mayor parte de los datos, para esto contamos las palabras e identificamos el cuantil de apróximadamente 99.9999, tratando de apróximarlo a 100."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_temp = train.copy()\ntrain_temp['count'] = train_temp['selected_text'].apply(lambda x:len(str(x).split()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train_temp['count'].quantile(0.9999))\nprint(train_temp['count'].quantile(0.99999))\nprint(train_temp['count'].quantile(0.999999))\nprint(train_temp['count'].quantile(0.9999999))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"seq_length = 33","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Cleaning the text attribute\ntrain_sent = train.copy()\ntrain_sent['clean_text']=train_sent['text'].apply(clean)\ntrain_sent['clean_selected_text']=train_sent['selected_text'].apply(str.lower)\ntrain_sent = train_sent.reset_index()\ntrain_sent.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Dividimos los datos de entreamiento en dos grupos, los datos que nos van a permitir entrenar el modelo y los datos que nos van a permitir probar los resultados."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\nX_train,X_test,Y_train,Y_test=train_test_split(train_sent['clean_text'],train_sent['sentiment'],\n                                               test_size=0.2,random_state=17, stratify=train_sent['sentiment'])\n\n\nprint('X_train shape',X_train.shape,' Y_train shape ',Y_train.shape)\nprint('X_test shape',X_test.shape,' Y_test shape ',Y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Tokenizamos las frases para que sean representados por enteros y puedan ser procesadas por los algoritmos de machine learning"},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='UNK',filters='')\ntokenizer.fit_on_texts(X_train)\n\nX_train_clean_text = tokenizer.texts_to_sequences(X_train)\nX_train_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_train_clean_text,maxlen=seq_length,padding='post')\n\nX_test_clean_text = tokenizer.texts_to_sequences(X_test)\nX_test_tokens = tf.keras.preprocessing.sequence.pad_sequences(X_test_clean_text,maxlen=seq_length,padding='post')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Codificamos los sentimientos para que sean representados por vectores"},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.utils.np_utils import to_categorical\n\nle = LabelEncoder()\ny_train_le = le.fit_transform(Y_train)\ny_test_le = le.transform(Y_test)\ny_train_oh = to_categorical(y_train_le)\ny_test_oh = to_categorical(y_test_le)\n\ndisplay(y_train_oh)\ndisplay(y_test_oh)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Generamos un tercer grupo de datos para ayudar al algoritmo de la red neural de keras a validar los datos. Estos datos son tomados de los datos de entrenamiento."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_emb, X_valid_emb, y_train_emb, y_valid_emb = train_test_split(X_train_tokens, y_train_oh, test_size=0.2, random_state=37)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embeddings_index = {}\nf = open('/kaggle/input/glove-global-vectors-for-word-representation/glove.twitter.27B.100d.txt', encoding='utf-8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:], dtype='float32')\n    embeddings_index[word] = coefs\nf.close()\n\nprint('%s Vectores de palabras encontrados.' % len(embeddings_index))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vocab_size=len(tokenizer.word_index)+1\nprint(vocab_size)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"embedding_matrix = np.zeros((vocab_size, GLOVE_DIM ))\nfor word, i in tokenizer.word_index.items():\n  embedding_vector = embeddings_index.get(word)\n  if embedding_vector is not None:    \n    embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Se toma la desición de usar la siguiente arquitectura para generar una red sencilla que permita verificar los resultados generales que se puede tener de una apróximación de embedding tipo Glove (sin contexto) para identificar los sentimientos de unos tweets"},{"metadata":{},"cell_type":"markdown","source":"**Anotaciones**\n\n- Se usará el algoritmo de optimización Adam, pues permite mejorar los tiempos de procesamiento, manteniendo resultados aceptables. Algunas de sus caracteristicas son: Fácil de implementar, computacionalmente eficiente, requisitos de memoria pequeños, muy adecuado para problemas con grandes cantidades de datos y parámetros, apropiado para problemas con gradientes muy ruidosos o dispersos.\n- La metrica seleccionada para análizar la viabilidad del modelo fue la presición.\n- Es posible mejorar los resultados a variar el tamaño del BATCH de entrenamiento.\n- La función de perdida elegida fue la entropia cruzada pues es bastante recomendada para problemas donde existen dos o más etiquetas. Es decir, problemas de clasificación multiple."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer=Input((seq_length,),name='input')\nembedding_layer=Embedding(vocab_size, GLOVE_DIM ,weights=[embedding_matrix],input_length=seq_length,trainable=False)(input_layer)\n\nconv1d=Conv1D(6,2,kernel_initializer=tf.keras.initializers.glorot_uniform(seed=20),name='conv1d')(embedding_layer)\ndropout=Dropout(0.2,name=\"drop_out\")(conv1d)\nflatten=Flatten(name='flatten')(dropout)\n\noutput=Dense(3,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45),name='output')(flatten)\n\nsimpleNeural=Model(inputs=[input_layer],outputs=[output])\n\nsimpleNeural.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simpleNeural.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simpleNeural.fit(X_train_emb, y_train_emb,batch_size=BATCH_SIZE ,epochs=NB_START_EPOCHS ,\n           validation_data=(X_valid_emb, y_valid_emb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = simpleNeural.evaluate(X_test_tokens, y_test_oh)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\n\nY_test_predict = simpleNeural.predict(X_test_tokens)\npredicted_classes = numpy.argmax(Y_test_predict, axis=1)\npredicted_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nY_test_predict = simpleNeural.predict(X_test_tokens)\npredicted_classes = numpy.argmax(Y_test_predict, axis=1)\nconfusion_matrix(y_true=y_test_le, y_pred=predicted_classes, normalize='true')\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Los mejores resultados se encuentran en la clasificación de los tweets con sentimientos neutrales. Lo cual es posible visualizarse en la matriz de confusión presentada anteriormente."},{"metadata":{},"cell_type":"markdown","source":"#### Arquitectura de red neuronal con capa densa."},{"metadata":{"trusted":true},"cell_type":"code","source":"input_layer=Input((seq_length,),name='input')\nembedding_layer=Embedding(vocab_size,100,weights=[embedding_matrix],input_length=seq_length,trainable=False)(input_layer)\nflatten=Flatten(name='flatten')(embedding_layer)\noutput=Dense(3,activation='softmax',kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45),name='output')(flatten)\n\nsimpleNeuralDen=Model(inputs=[input_layer],outputs=[output])\n\nsimpleNeuralDen.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simpleNeuralDen.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n              loss=tf.keras.losses.CategoricalCrossentropy(), metrics=['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"simpleNeuralDen.fit(X_train_emb, y_train_emb,batch_size=BATCH_SIZE,epochs=NB_START_EPOCHS,\n           validation_data=(X_valid_emb, y_valid_emb))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"results = simpleNeuralDen.evaluate(X_test_tokens, y_test_oh)\nprint(results)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy\n\nY_test_predict = simpleNeuralDen.predict(X_test_tokens)\npredicted_classes = numpy.argmax(Y_test_predict, axis=1)\npredicted_classes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\n\nY_test_predict = simpleNeuralDen.predict(X_test_tokens)\npredicted_classes = numpy.argmax(Y_test_predict, axis=1)\nconfusion_matrix(y_true=y_test_le, y_pred=predicted_classes, normalize='true')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Conclusiones aproximaciones\n\n- Mediante metodologías de embbedings sin contexto como Glove es posible obtener resultados interesantes como punto de pantida para una análisis más extenso.\n- Existe un error considerable en los tweets neutrales que puede eliminarse al procesarlos bajo la luz de los resultados obtenidos en el EDA, es decir, para los tweets con sentimiento neutral se puede retornar inmediatamente el mismo valor de entrada.\n- El resultado con una capa convolucional para el caso de un modelo con redes neuronales brinda mejores resultados."}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}