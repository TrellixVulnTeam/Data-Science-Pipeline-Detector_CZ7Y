{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/fairseq-and-fastbpe/sacrebleu-1.4.9-py3-none-any.whl\n!pip install ../input/fairseq-and-fastbpe/fairseq-0.9.0-cp37-cp37m-linux_x86_64.whl\n!pip install ../input/fairseq-and-fastbpe/fastBPE-0.1.0-cp37-cp37m-linux_x86_64.whl","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport argparse\nimport warnings\nimport random\nimport torch \nfrom torch import nn\nimport torch.optim as optim\nfrom sklearn.model_selection import StratifiedKFold\nimport tokenizers\nfrom transformers import RobertaModel, RobertaConfig\nwarnings.filterwarnings('ignore')\nseed=18","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import TweetTokenizer\nfrom emoji import demojize\nimport re\n\ntokenizer = TweetTokenizer()\n\ndef normalizeToken(token):\n    lowercased_token = token.lower()\n    if token.startswith(\"@\"):\n        return \"@USER\"\n    elif lowercased_token.startswith(\"http\") or lowercased_token.startswith(\"www\"):\n        return \"HTTPURL\"\n    elif len(token) == 1:\n        return demojize(token)\n    else:\n        if token == \"’\":\n            return \"'\"\n        elif token == \"…\":\n            return \"...\"\n        else:\n            return token\n\ndef normalizeTweet(tweet):\n    tokens = tokenizer.tokenize(tweet.replace(\"’\", \"'\").replace(\"…\", \"...\"))\n    normTweet = \" \".join([normalizeToken(token) for token in tokens])\n\n    normTweet = normTweet.replace(\"cannot \", \"can not \").replace(\"n't \", \" n't \").replace(\"n 't \", \" n't \").replace(\"ca n't\", \"can't\").replace(\"ai n't\", \"ain't\")\n    normTweet = normTweet.replace(\"'m \", \" 'm \").replace(\"'re \", \" 're \").replace(\"'s \", \" 's \").replace(\"'ll \", \" 'll \").replace(\"'d \", \" 'd \").replace(\"'ve \", \" 've \")\n    normTweet = normTweet.replace(\" p . m .\", \"  p.m.\") .replace(\" p . m \", \" p.m \").replace(\" a . m .\", \" a.m.\").replace(\" a . m \", \" a.m \")\n\n    normTweet = re.sub(r\",([0-9]{2,4}) , ([0-9]{2,4})\", r\",\\1,\\2\", normTweet)\n    normTweet = re.sub(r\"([0-9]{1,3}) / ([0-9]{2,4})\", r\"\\1/\\2\", normTweet)\n    normTweet = re.sub(r\"([0-9]{1,3})- ([0-9]{2,4})\", r\"\\1-\\2\", normTweet)\n    \n    return \" \".join(normTweet.split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"normalizeTweet(' I`d have responded, if I were going')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path='../input/bertweet-dataset'\nconfig = RobertaConfig.from_pretrained(\n    os.path.join(base_path,\"BERTweet_base_transformers/config.json\"), output_hidden_states=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from fairseq.data.encoders.fastbpe import fastBPE\nfrom fairseq.data import Dictionary\nargs = argparse.Namespace(bpe_codes= os.path.join(base_path,\"BERTweet_base_transformers/bpe.codes\"))\nbpe = fastBPE(args)\nvocab = Dictionary()\nvocab.add_from_file(os.path.join(base_path,\"BERTweet_base_transformers/dict.txt\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class TweetDataset(torch.utils.data.Dataset):\n    def __init__(self, df, bpe, vocab, max_len=96):\n        self.df = df\n        self.labeled = 'selected_text' in df\n        self.bpe = bpe\n        self.vocab = vocab\n        self.max_len=max_len\n        \n    def __getitem__(self, index):\n        data={}\n        row=self.df.iloc[index]\n        #print(row.text)\n        #print(row.selected_text)\n        ids, masks, tweets_encoded = self.get_input_data(row)\n        data['ids'] = ids\n        data['masks'] = masks\n        data['tweets_encoded'] = tweets_encoded\n        data['tweet'] = row.text\n        data['sentiment']=row.sentiment\n        if self.labeled:\n            data['selected_tweet'] = row.selected_text\n            start_idx, end_idx = self.get_target_idx(row, tweets_encoded)\n            data['start_idx'] = start_idx\n            data['end_idx'] = end_idx\n        return data\n    \n    def __len__(self):\n        return len(self.df)\n    \n    def get_input_data(self, row):\n        normalized_tweets = normalizeTweet(row.text)\n        normalized_tweets = \" \" + \" \".join(normalized_tweets.split())\n        tweets_encoded = self.bpe.encode(normalized_tweets)\n        encoding_ids = self.vocab.encode_line(tweets_encoded, append_eos=False, add_if_not_exist=False).long().tolist()\n        sentiment_id = self.vocab.encode_line(self.bpe.encode(row.sentiment), append_eos=False, add_if_not_exist=False).long().tolist()\n        ids = [0]+sentiment_id+[2,2]+encoding_ids+[2]\n        \n        pad_len = self.max_len-len(ids)\n        if pad_len>0:\n            ids += [1] * pad_len\n        ids = torch.tensor(ids)\n        masks = torch.where(ids!=1, torch.tensor(1), torch.tensor(0))\n        \n        return ids, masks, tweets_encoded\n    \n    def get_target_idx(self, row, tweets_encoded):\n        normalized_selected_tweets = normalizeTweet(row.selected_text)\n        normalized_selected_tweets = ' '+' '.join(normalized_selected_tweets.split())\n        normalized_tweets = normalizeTweet(row.text)\n        normalized_tweets = \" \" + \" \".join(normalized_tweets.split())\n        #print(normalized_selected_tweets)\n        #print(normalized_tweets)\n        \n        len_st = len(normalized_selected_tweets) - 1\n        idx0 = None\n        idx1 = None\n        for ind in (i for i, e in enumerate(normalized_tweets) if e == normalized_selected_tweets[1]):\n            if \" \" + normalized_tweets[ind: ind+len_st] == normalized_selected_tweets:\n                idx0 = ind\n                idx1 = ind+len_st-1\n                break\n        if idx0==None and len(normalized_selected_tweets.split())>1:\n            normalized_selected_tweets_1=' '+' '.join(normalized_selected_tweets.split()[1:])\n            #print(normalized_selected_tweets_1)\n            len_st_1 = len(normalized_selected_tweets_1) - 1\n            for ind in (i for i, e in enumerate(normalized_tweets) if e == normalized_selected_tweets_1[1]):\n                if \" \" + normalized_tweets[ind: ind+len_st_1] == normalized_selected_tweets_1:\n                    idx0 = ind\n                    idx1 = ind+len_st_1-1\n                    break\n        if idx0==None and len(normalized_selected_tweets.split())>1:\n            normalized_selected_tweets_2=' '+' '.join(normalized_selected_tweets.split()[:-1])\n            #print(normalized_selected_tweets_2)\n            len_st_2 = len(normalized_selected_tweets_2) - 1\n            for ind in (i for i, e in enumerate(normalized_tweets) if e == normalized_selected_tweets_2[1]):\n                if \" \" + normalized_tweets[ind: ind+len_st_2] == normalized_selected_tweets_2:\n                    idx0 = ind\n                    idx1 = ind+len_st_2-1\n                    break\n        if idx0==None and len(normalized_selected_tweets.split())>1:\n            normalized_selected_tweets_3=' '+' '.join(normalized_selected_tweets_2.split()[:-1])\n            #print(normalized_selected_tweets_3)\n            len_st_3 = len(normalized_selected_tweets_3) - 1\n            for ind in (i for i, e in enumerate(normalized_tweets) if e == normalized_selected_tweets_3[1]):\n                if \" \" + normalized_tweets[ind: ind+len_st_3] == normalized_selected_tweets_3:\n                    idx0 = ind\n                    idx1 = ind+len_st_3-1\n                    break \n        sum_tot=-1\n        flag = 0\n        if idx0 != None and idx1 != None:\n            for i, token in enumerate(tweets_encoded.split()):\n                if '@@' not in token:\n                    sum_tot += len(token)+1\n                else:\n                    sum_tot += len(token)-2\n                if sum_tot>=idx0 and flag==0:\n                    start_idx = i\n                    flag = 1\n                if sum_tot>=idx1:\n                    end_idx = i\n                    break\n        if idx0==None or idx1==None:\n            start_idx=0\n            end_idx=0\n        return start_idx+4, end_idx+4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_train_val_loaders(df, train_idx, val_idx, batch_size=32):\n    train_df = df.iloc[train_idx]\n    val_df = df.iloc[val_idx]\n    \n    train_loader = torch.utils.data.DataLoader(\n        TweetDataset(train_df, bpe, vocab), \n        batch_size=batch_size, \n        shuffle=True,\n        drop_last=False)\n\n    val_loader = torch.utils.data.DataLoader(\n        TweetDataset(val_df, bpe, vocab), \n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=2)\n\n    dataloaders_dict = {\"train\": train_loader, \"val\": val_loader}\n\n    return dataloaders_dict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch.nn as nn\nimport torch.optim as optim\n\nclass BERTweetModel(nn.Module):\n    def __init__(self, conf):\n        super(BERTweetModel, self).__init__()\n        self.roberta = RobertaModel.from_pretrained(os.path.join(base_path,\"BERTweet_base_transformers/model.bin\"),config=conf)\n        self.dropout = nn.Dropout(0.5)\n        self.fc = nn.Linear(conf.hidden_size*4,2)\n        nn.init.xavier_uniform_(self.fc.weight)\n        nn.init.normal_(self.fc.bias,0)\n        \n    def forward(self, input_ids, attention_mask):\n        a, b, h = self.roberta(input_ids, attention_mask)\n        x = torch.cat([h[-1],h[-2],h[-3], h[-4]],dim=-1)\n        x = self.fc(self.dropout(x))\n        start_logits, end_logits = x.split(1, -1)\n        \n        return start_logits.squeeze(-1), end_logits.squeeze(-1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loss_fn(start_logits, end_logits, start_positions, end_positions):\n    ce_loss = nn.CrossEntropyLoss()\n    start_loss = ce_loss(start_logits, start_positions)\n    end_loss = ce_loss(end_logits, end_positions)    \n    total_loss = start_loss + end_loss\n    return total_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_selected_text(tweets_encoded, start_idx, end_idx):\n    selected_text = \"\"\n    for i, token in enumerate(tweets_encoded.split()[start_idx-4:end_idx-3]):\n            token=' '+token\n            selected_text+=token\n    selected_text=re.sub('@@ ', '', selected_text)\n    selected_text=re.sub('@@', '', selected_text)\n    return selected_text\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\ndef compute_jaccard_score(tweets_encoded, start_idx, end_idx, start_logits, end_logits):\n    start_pred = np.argmax(start_logits)\n    end_pred = np.argmax(end_logits)\n    #print('labels, outputs',start_idx, end_idx, start_pred, end_pred)    \n    length = len(tweets_encoded.split())\n    if start_pred<4:\n        start_pred=4\n    if end_pred>3+length:\n        end_pred=3+length\n    if start_pred > end_pred:\n        start_pred=4\n        end_pred=3+length\n        pred = get_selected_text(tweets_encoded, start_pred, end_pred).strip()\n    else:\n        pred = get_selected_text(tweets_encoded, start_pred, end_pred).strip()    \n    true = get_selected_text(tweets_encoded, start_idx, end_idx).strip()\n    #print(true)\n    #print(pred)\n    \n    return jaccard(true, pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(model, dataloaders_dict, criterion, optimizer, num_epochs, filename):\n    if torch.cuda.is_available():\n        model.cuda()\n    \n    loss_check=1000\n    for epoch in range(num_epochs):\n        for phase in ['train', 'val']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            epoch_loss = 0.0\n            epoch_jaccard = 0.0\n            count=0\n            for data in (dataloaders_dict[phase]):\n                if count%100==0:\n                    print(count)\n                count+=1\n                ids = data['ids']\n                masks = data['masks']\n                tweets_encoded = data['tweets_encoded']\n                \n                selected_tweet = data['selected_tweet']\n                start_idx = data['start_idx']\n                end_idx = data['end_idx']\n                #print(tweets_encoded[0])\n                #print(tweets_encoded[1])\n\n                if torch.cuda.is_available():\n                  ids=ids.cuda()\n                  masks=masks.cuda()\n                  start_idx=start_idx.cuda()\n                  end_idx=end_idx.cuda()\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n\n                    start_logits, end_logits = model(ids, masks)\n\n                    loss = criterion(start_logits, end_logits, start_idx, end_idx)\n                    \n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                    epoch_loss += loss.item() * len(ids)\n                    \n                    start_idx = start_idx.cpu().detach().numpy()\n                    end_idx = end_idx.cpu().detach().numpy()\n                    start_logits = torch.softmax(start_logits, dim=1).cpu().detach().numpy()\n                    end_logits = torch.softmax(end_logits, dim=1).cpu().detach().numpy()\n                    \n                    for i in range(len(ids)): \n                        #print(selected_tweet[i])                       \n                        jaccard_score = compute_jaccard_score(\n                            tweets_encoded[i],\n                            start_idx[i],\n                            end_idx[i],\n                            start_logits[i], \n                            end_logits[i])\n                        epoch_jaccard += jaccard_score\n                    \n            epoch_loss = epoch_loss / len(dataloaders_dict[phase].dataset)\n            epoch_jaccard = epoch_jaccard / len(dataloaders_dict[phase].dataset)\n            \n            print('Epoch {}/{} | {:^5} | Loss: {:.4f} | Jaccard: {:.4f}'.format(\n                epoch + 1, num_epochs, phase, epoch_loss, epoch_jaccard))\n        if epoch_loss<loss_check:\n            loss_check=epoch_loss\n            print(\"Saving model\")\n            torch.save(model.state_dict(), filename)\n        elif epoch>1:\n            print('Training stopping')\n            break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"num_epochs = 10\nbatch_size = 32\nskf = StratifiedKFold(n_splits=8, shuffle=True, random_state=seed)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def run(fold):\n    train_df = pd.read_csv('tweet-sentiment-extraction/train.csv').dropna().reset_index(drop=True)\n    train_df['text'] = train_df['text'].astype(str)\n    train_df['selected_text'] = train_df['selected_text'].astype(str)\n\n    (train_idx, val_idx) = list(skf.split(train_df, train_df.sentiment))[fold]\n    print(f'Fold: {fold}')\n    model = BERTweetModel(conf=config)\n    torch.save(model.state_dict(), f'drive/My Drive/Kaggle/check.pth')\n    optimizer = optim.AdamW(model.parameters(), lr=1e-5, betas=(0.9, 0.999))\n    criterion = loss_fn    \n    dataloaders_dict = get_train_val_loaders(train_df, train_idx, val_idx, batch_size)\n    print('starting training')\n    train_model(\n        model, \n        dataloaders_dict,\n        criterion, \n        optimizer, \n        num_epochs,\n        f'drive/My Drive/Kaggle/roberta_fold{fold}.pth')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_test_loader(df, batch_size=32):\n    loader = torch.utils.data.DataLoader(\n        TweetDataset(df, bpe, vocab), \n        batch_size=batch_size, \n        shuffle=False, \n        num_workers=2)    \n    return loader","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_path='../input/bertweet-dataset'\nconfig = RobertaConfig.from_pretrained(\n    os.path.join(base_path,\"BERTweet_base_transformers/config.json\"), output_hidden_states=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def postprocessing(pred, tweet):\n    pred_wo_spaces=''.join(pred.split())\n    length = len(pred_wo_spaces)\n    flag=0\n    if tweet[-1]=='@':\n        return tweet\n    else:\n        for index, value in enumerate(tweet):\n            count=0\n            letter=pred_wo_spaces[count]\n            if value==letter:\n                start_idx=index\n                end_idx=index\n                count+=1\n                end_idx+=1\n                while True:\n                    if tweet[end_idx]==' ':\n                        end_idx+=1\n                    elif tweet[end_idx]=='!' and pred_wo_spaces[count]!='!':\n                        end_idx+=1\n                    elif tweet[end_idx]=='.' and pred_wo_spaces[count]!='.':\n                        end_idx+=1\n                    elif tweet[end_idx]=='*' and pred_wo_spaces[count]!='*':\n                        end_idx+=1\n                    elif tweet[end_idx]=='-' and pred_wo_spaces[count]!='-':\n                        end_idx+=1\n                    elif tweet[end_idx]=='?' and pred_wo_spaces[count]!='?':\n                        end_idx+=1\n                    elif tweet[end_idx]==pred_wo_spaces[count]:\n                        end_idx+=1\n                        count+=1\n                    else:\n                        break\n                    if count==length:\n                        flag=1\n                        break\n                if flag==1:\n                    break\n        if flag==1:\n            #print(tweet[start_idx:end_idx])\n            while start_idx>0:\n                if tweet[start_idx-1]==' ':\n                    break\n                else:\n                    print('start_idx_changed')\n                    start_idx=start_idx-1\n            while end_idx<len(tweet)-1:\n                if tweet[end_idx]==' ':\n                    break\n                else:\n                    print('end_idx_changed')\n                    end_idx=end_idx+1\n            #print(tweet[start_idx:end_idx])\n            return tweet[start_idx:end_idx]\n        elif 'HTTPURL' in pred.split():\n            return tweet\n        elif '@USER' in pred.split():\n            return tweet\n        else:\n            print('No match found')\n            print(pred)\n            print(tweet)\n            return tweet","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ntest_df['text'] = test_df['text'].astype(str)\n#test_df['selected_text'] = test_df['selected_text'].astype(str)\n\ntest_loader = get_test_loader(test_df)\npredictions = []\nmodels = []\nfor fold in range(skf.n_splits):\n    model = BERTweetModel(conf=config)\n    if torch.cuda.is_available():\n        model.cuda()\n    model.load_state_dict(torch.load(f'../input/mosh1-data-orig/roberta_fold{fold}.pth',map_location=torch.device('cpu')))\n    model.eval()\n    models.append(model)\ncount=0\ncount_real=0\njaccard_total=0\nfor data in test_loader:\n    #print(count)\n    ids = data['ids']\n    masks = data['masks']\n    tweets_encoded = data['tweets_encoded']\n    tweet = data['tweet']\n    sentiment = data['sentiment']\n    \n    #selected_tweet = data['selected_tweet']\n\n    if torch.cuda.is_available():\n        ids=ids.cuda()\n        masks=masks.cuda()\n\n    start_logits = []\n    end_logits = []\n    for model in models:\n        with torch.no_grad():\n            output = model(ids, masks)\n            start_logits.append(torch.softmax(output[0], dim=1).cpu().detach().numpy())\n            end_logits.append(torch.softmax(output[1], dim=1).cpu().detach().numpy())\n    \n    start_logits = np.mean(start_logits, axis=0)\n    end_logits = np.mean(end_logits, axis=0)\n    for i in range(len(ids)):  \n        count_real+=1\n        #print('Coount', count_real)\n        start_pred = np.argmax(start_logits[i])\n        end_pred = np.argmax(end_logits[i])\n        #print(tweet[i].strip())\n        #print(tweets_encoded[i])\n        length = len(tweets_encoded[i].split())\n        if start_pred<4:\n            start_pred=4\n        if end_pred>3+length:\n            end_pred=3+length\n        if start_pred > end_pred:\n            start_pred=4\n            end_pred=3+length\n            pred = get_selected_text(tweets_encoded[i], start_pred, end_pred).strip()\n        else:\n            pred = get_selected_text(tweets_encoded[i], start_pred, end_pred).strip()    \n        #print(pred,'\\n')\n        try:\n            pred=postprocessing(pred, tweet[i].strip())\n        except:\n            print('Error')\n            print(tweet[i].strip())\n            print(pred)\n            pred=tweet[i]\n        \n        #this if loop is only for testing purposes on train data\n        #if pred.strip()!=selected_tweet[i].strip():\n            #count+=1\n            #print(count)\n            #print(sentiment[i]) \n            #print(tweet[i].strip())\n            #print(selected_tweet[i].strip())\n            #print(pred.strip())\n            #jaccard_total+=jaccard(selected_tweet[i].strip(),pred.strip())\n        #this above if loop only for testing purposes\n        \n        predictions.append(pred)\n        \n#print('Count', count)\n#print('Average jaccard', jaccard_total/count)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sub_df = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\nsub_df['selected_text'] = predictions\nsub_df.to_csv('submission.csv', index=False)\nsub_df.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}