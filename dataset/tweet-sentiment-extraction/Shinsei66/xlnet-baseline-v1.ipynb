{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Install and Import Libraries"},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"#!pip install /kaggle/input/pytorch-fairseq/fairseq-0.9.0/ > /dev/null\n#! pip install /kaggle/input/pytorchtransformers/transformers-2.5.1 > /dev/null","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"## Basic Library\nimport os, time, sys, gc\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport json\n\n## Pytorch\nimport torch\nimport pytorch_transformers\n\n\nfor dirname, _, filenames in os.walk('/kaggle/input/xlnet-pretrained-models-pytorch'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Global Parameters"},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUTDIR = '/kaggle/input/tweet-sentiment-extraction/'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Define Functions"},{"metadata":{},"cell_type":"markdown","source":"# Import Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ntrain_df = pd.read_csv(f'{INPUTDIR}/train.csv')\ntest_df = pd.read_csv(f'{INPUTDIR}/test.csv')\nprint('train shape is {}, and test shape is {}'.format(train_df.shape, test_df.shape))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = np.array(train_df)\ntest = np.array(test_df)\n\n!mkdir -p data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nPrepare training data in QA-compatible format\n\"\"\"\n\n# Adpated from https://www.kaggle.com/cheongwoongkang/roberta-baseline-starter-simple-postprocessing\ndef find_all(input_str, search_str):\n    l1 = []\n    length = len(input_str)\n    index = 0\n    while index < length:\n        i = input_str.find(search_str, index)\n        if i == -1:\n            return l1\n        l1.append(i)\n        index = i + 1\n    return l1\n\ndef do_qa_train(train):\n\n    output = {}\n    output['version'] = 'v1.0'\n    output['data'] = []\n    \n    for line in tqdm(train):\n        context = line[1]\n        paragraphs = []\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        answers = []\n        answer = line[2]\n        if type(answer) != str or type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answer_starts = find_all(context, answer)\n        for answer_start in answer_starts:\n            answers.append({'answer_start': answer_start, 'text': answer.lower()})\n            break\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        paragraphs.append({'context': context.lower(), 'qas': qas})\n        output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n        \n    return output\n\nqa_train = do_qa_train(train)\n\nwith open('data/train.json', 'w') as outfile:\n    json.dump(qa_train, outfile)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\nPrepare testing data in QA-compatible format\n\"\"\"\n\noutput = {}\noutput['version'] = 'v1.0'\noutput['data'] = []\n\ndef do_qa_test(test):\n    paragraphs = []\n    for line in tqdm(test):\n        paragraphs = []\n        context = line[1]\n        qas = []\n        question = line[-1]\n        qid = line[0]\n        if type(context) != str or type(question) != str:\n            print(context, type(context))\n            print(answer, type(answer))\n            print(question, type(question))\n            continue\n        answers = []\n        answers.append({'answer_start': 1000000, 'text': '__None__'})\n        qas.append({'question': question, 'id': qid, 'is_impossible': False, 'answers': answers})\n\n        paragraphs.append({'context': context.lower(), 'qas': qas})\n        output['data'].append({'title': 'None', 'paragraphs': paragraphs})\n    return output\n\nqa_test = do_qa_test(test)\n\nwith open('data/test.json', 'w') as outfile:\n    json.dump(qa_test, outfile)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir -p results_roberta_large","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sentencepiece","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-output":true},"cell_type":"code","source":"!python -m torch.distributed.launch --nproc_per_node=1 /kaggle/input/bert-squad/BERT-SQuAD-master/training/run_squad.py \\\n--model_type xlnet \\\n--model_name_or_path /kaggle/input/xlnet-pretrained-models-pytorch/xlnet-large-cased-pytorch_model.bin \\\n--tokenizer_name /kaggle/input/xlnet-pretrained-models-pytorch/xlnet-large-cased-spiece.model \\\n--config_name /kaggle/input/xlnet-pretrained-models-pytorch/xlnet-large-cased-config.json \\\n--do_train \\\n--do_eval \\\n--do_lower_case \\\n--train_file ./data/train.json \\\n--predict_file ./data/test.json \\\n--learning_rate 3e-5 \\\n--num_train_epochs 2 \\\n--max_seq_length 192 \\\n--doc_stride 64 \\\n--output_dir ./results_roberta_large/ \\\n--per_gpu_eval_batch_size=10   \\\n--per_gpu_train_batch_size=10   \\\n--save_steps=100000","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy predictions to submission file.\npredictions = json.load(open('results_roberta_large/predictions_.json', 'r'))\nsubmission = pd.read_csv(open('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv', 'r'))\nfor i in range(len(submission)):\n    id_ = submission['textID'][i]\n    if test_df['sentiment'][i] == 'neutral': # neutral postprocessing\n        submission.loc[i, 'selected_text'] = test_df['text'][i]\n    else:\n        submission.loc[i, 'selected_text'] = predictions[id_]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save the submission file.\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}