{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Imports"},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"!pip install chart_studio","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud ,STOPWORDS\nfrom PIL import Image\nimport re\nimport gc\nimport sys\nimport time\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport emoji\nimport random\nimport unicodedata\nimport multiprocessing\nimport seaborn as sns\nfrom functools import partial, lru_cache\nfrom tqdm import tqdm_notebook\nfrom wordcloud import WordCloud, STOPWORDS\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom plotly import tools\nimport chart_studio.plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom nltk import TweetTokenizer\nfrom nltk.stem import PorterStemmer, SnowballStemmer\nfrom nltk.stem.lancaster import LancasterStemmer","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Understanding data"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsub = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_len, test_len = len(train.index), len(test.index)\nprint(\"Train Size:\", train_len)\nprint(\"Test Size:\", test_len)\nprint(\"Train shape: \", train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**NOTE**: Need to remove links from the analysis."},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing values here."},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"No missing values here either."},{"metadata":{},"cell_type":"markdown","source":"### Target Plots"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.countplot(train[\"sentiment\"])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good to see that the data isn't too skewed to any one class."},{"metadata":{},"cell_type":"markdown","source":"Let's do some very basic feature engineering"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[\"num_words\"] = train[\"text\"].apply(lambda x: len(str(x).split()))\ntest[\"num_words\"] = test[\"text\"].apply(lambda x: len(str(x).split()))\ntrain['select_num_words'] = train[\"selected_text\"].apply(lambda x: len(str(x).split()))\n\n## Number of unique words in the text ##\ntrain[\"num_unique_words\"] = train[\"text\"].apply(lambda x: len(set(str(x).split())))\ntest[\"num_unique_words\"] = test[\"text\"].apply(lambda x: len(set(str(x).split())))\ntrain['select_num_unique_words'] = train[\"selected_text\"].apply(lambda x: len(set(str(x).split())))\n\n## Number of characters in the text ##\ntrain[\"num_chars\"] = train[\"text\"].apply(lambda x: len(str(x)))\ntest[\"num_chars\"] = test[\"text\"].apply(lambda x: len(str(x)))\ntrain['select_num_chars'] = train[\"selected_text\"].apply(lambda x: len(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def target_plot(column, title):\n    fig = go.Figure()\n    fig.add_trace(go.Histogram(x=train[str(column)],name = title + ' : train data'))\n    fig.add_trace(go.Histogram(x=test[str(column)],name = title + ' : test data'))\n    fig.add_trace(go.Histogram(x=train['select_'+str(column)],name =  title + ': selected text'))\n    fig.update_layout(barmode='stack')\n    fig.update_traces(opacity=0.75)\n    fig.show()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"target_plot(column='num_words', title=\"Number of words\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_plot(column=\"num_chars\", title=\"Number of characters\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_plot(column=\"num_unique_words\", title=\"Number of unique words\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Wordclouds"},{"metadata":{"trusted":true},"cell_type":"code","source":"stopwords = set(STOPWORDS)\ndef generate_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='black',\n        stopwords=stopwords,\n        max_words=100,\n        max_font_size=40, \n        scale=5,\n        random_state=23\n    ).generate(str(data))\n\n    fig = plt.figure(1, figsize=(20,20))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(train['text'], title = 'Prevalent words in tweets - train data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(test['text'], title = 'Prevalent words in tweets - test data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(train.loc[train['sentiment']=='neutral']['text'], title = 'Prevalent Neutral words in tweets - train data')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(train.loc[train['sentiment']=='positive']['text'], title = 'Prevalent Positive words in tweets - train data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Good to see `oprah` there haha."},{"metadata":{"trusted":true},"cell_type":"code","source":"generate_wordcloud(train.loc[train['sentiment']=='negative']['text'], title = 'Prevalent Negative words in tweets - train data')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Wonder how `http` and `Julie` made the cut."},{"metadata":{},"cell_type":"markdown","source":"### Emoji analysis"},{"metadata":{"trusted":true},"cell_type":"code","source":"def extract_emojis(string):\n    return [c for c in str(string) if c in emoji.UNICODE_EMOJI]\n\ntrain['emojis_count'] = train['text'].apply(lambda x: len(extract_emojis(x)))\nprint(\"Maximum Number of Emojis: \", max(train[\"emojis_count\"]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Well, clearly there are no emojis in these tweets. This simplifies the preprocessing process a bit."},{"metadata":{},"cell_type":"markdown","source":"## Preprocessing"},{"metadata":{"trusted":true},"cell_type":"code","source":"PORTER_STEMMER = PorterStemmer()\nLANCASTER_STEMMER = LancasterStemmer()\nSNOWBALL_STEMMER = SnowballStemmer(\"english\")\n\ndef word_forms(word):\n    yield word\n    yield word.lower()\n    yield word.upper()\n    yield word.capitalize()\n    yield PORTER_STEMMER.stem(word)\n    yield LANCASTER_STEMMER.stem(word)\n    yield SNOWBALL_STEMMER.stem(word)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TABLE = str.maketrans(\n    {\n        \"\\xad\": None,\n        \"\\x7f\": None,\n        \"\\ufeff\": None,\n        \"\\u200b\": None,\n        \"\\u200e\": None,\n        \"\\u202a\": None,\n        \"\\u202c\": None,\n        \"‘\": \"'\",\n        \"’\": \"'\",\n        \"`\": \"'\",\n        \"“\": '\"',\n        \"”\": '\"',\n        \"«\": '\"',\n        \"»\": '\"',\n        \"ɢ\": \"G\",\n        \"ɪ\": \"I\",\n        \"ɴ\": \"N\",\n        \"ʀ\": \"R\",\n        \"ʏ\": \"Y\",\n        \"ʙ\": \"B\",\n        \"ʜ\": \"H\",\n        \"ʟ\": \"L\",\n        \"ғ\": \"F\",\n        \"ᴀ\": \"A\",\n        \"ᴄ\": \"C\",\n        \"ᴅ\": \"D\",\n        \"ᴇ\": \"E\",\n        \"ᴊ\": \"J\",\n        \"ᴋ\": \"K\",\n        \"ᴍ\": \"M\",\n        \"Μ\": \"M\",\n        \"ᴏ\": \"O\",\n        \"ᴘ\": \"P\",\n        \"ᴛ\": \"T\",\n        \"ᴜ\": \"U\",\n        \"ᴡ\": \"W\",\n        \"ᴠ\": \"V\",\n        \"ĸ\": \"K\",\n        \"в\": \"B\",\n        \"м\": \"M\",\n        \"н\": \"H\",\n        \"т\": \"T\",\n        \"ѕ\": \"S\",\n        \"—\": \"-\",\n        \"–\": \"-\",\n    }\n)\n\nRE_SPACE = re.compile(r\"\\s\")\nRE_MULTI_SPACE = re.compile(r\"\\s+\")\nRE_URL = re.compile('http[s]?://\\S+')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize(text: str):\n    text = RE_URL.sub(\"URL\", text)\n    text = RE_SPACE.sub(\" \", text)\n    text = unicodedata.normalize(\"NFKD\", text)\n    text = text.translate(TABLE)\n    text = RE_MULTI_SPACE.sub(\" \", text).strip()\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train.copy()\nX_train[\"text\"] = [str(x) for x in X_train[\"text\"]]\nX_train[\"selected_text\"] = [str(x) for x in X_train[\"selected_text\"]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nwith multiprocessing.Pool(processes=3) as pool:\n    selected_train_list = pool.map(normalize, X_train.selected_text.tolist())\n    train_list = pool.map(normalize, X_train.text.tolist())\n    test_list = pool.map(normalize, test.text.tolist())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train['preprocessed_selected_text'] = selected_train_list\nX_train['preprocessed_text'] = train_list\ntest['preprocessed_text'] = test_list","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let's save this data for easier acess in the future."},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open('train.pickle', 'wb') as file:\n    pickle.dump(X_train, file, protocol=pickle.HIGHEST_PROTOCOL)\nwith open('test.pickle', 'wb') as file:\n    pickle.dump(test, file, protocol=pickle.HIGHEST_PROTOCOL)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"***Do upvote if you find this useful. More to come.***"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}