{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport re\nimport string \nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom collections import Counter\nimport spacy\n\nfrom tqdm import trange\nimport random\nfrom spacy.util import compounding,minibatch\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nstop = stopwords.words('english')\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('train shape:',train.shape)\nprint('test shape:',test.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Sentiment of text : {} \\nOur training text :\\n{}\\nSelected text to predict:\\n{}'.format(train['sentiment'][1],train['text'][1],train['selected_text'][1]))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.dropna(inplace=True)\nprint(train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.sentiment.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntemp=train.groupby('sentiment').count()['text'].reset_index().sort_values(by='text',ascending=False)\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig=make_subplots(1,2,subplot_titles=('Train set','Test set'))\nx=train.sentiment.value_counts()\nfig.add_trace(go.Bar(x=x.index,y=x.values,marker_color=['#3368d4','#32ad61','#f24e4e'],name='train'),row=1,col=1)\nx=test.sentiment.value_counts()\nfig.add_trace(go.Bar(x=x.index,y=x.values,marker_color=['#3368d4','#32ad61','#f24e4e'],name='test'),row=1,col=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as pt\nactivities= ['nutral', 'positive', 'negative']\nslices=[1430,1103,1001]\ncolors=['c','b','m']\npt.pie(slices, labels=activities, colors=colors, startangle=90, radius=2.0, autopct= '%1.1f%%')\npt.legend()\npt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as pt\nactivities= ['nutral', 'positive', 'negative']\nslices=[11118,8582,7781]\ncolors=['r','y','g']\npt.pie(slices, labels=activities, colors=colors, startangle=90, radius=2.0, autopct= '%1.1f%%')\npt.legend()\npt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard_similarity(str1,str2):\n    A = set(str1.lower().split())\n    B = set(str2.lower().split())\n    C = A.intersection(B)\n    return  float(len(C))/(len(A)+len(B)-len(C))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"str1 = 'MY NAME IS KEVIN'\nstr2 = 'MYSELF KEVIN'\njaccard_score = jaccard_similarity(str1,str2)\nprint('JACCARD SCORE :',jaccard_score)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def jaccard_similarity(df):\n    A = set(df['text'].lower().split())\n    B = set(df['selected_text'].lower().split())\n    C = A.intersection(B)\n    return float(len(C))/(len(A)+len(B)-len(C))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['jaccard_score'] = train.apply(jaccard_similarity,axis=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['NO_WORDS_ST'] = train.selected_text.apply(lambda x: len(str(x).split()))\ntrain['NO_WORDS_T'] = train.text.apply(lambda x: len(str(x).split()))\ntrain['DIFF_WORDS']  = train['NO_WORDS_T'] - train['NO_WORDS_ST'] ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(test.shape)\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#DISTRIBUTION OF LENGTH B/W SELECTED_TEXT AND TEXT'\nplt.hist(train['NO_WORDS_ST'],bins=20,label='selected_text')\nplt.hist(train['NO_WORDS_T'],bins=20,label='text')\nplt.title('DISTRIBUTION OF LENGTH B/W SELECTED_TEXT AND TEXT')\nplt.legend()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.kdeplot(train['NO_WORDS_ST'],shade=True,COLOR='B')\nsns.kdeplot(train['NO_WORDS_T'],shade=True,COLOR='R')\nplt.title('DISTRIBUTION OF LENGTH')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['NoOfSelectedTextWords'] = test['text'].apply(lambda x:len(str(x).split()))                #Number Of words in Selected Text           \ntest['NoOfTextWords'] = test['text'].apply(lambda x:len(str(x).split()))                                 #Number Of words in main text\ntest['DifferenceOfTextWordsToSelectedTextWords'] = test['NoOfTextWords'] - test['NoOfSelectedTextWords'] #Difference in Number of words text and Selected Text\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(10)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['NoOfSelectedTextWords'] = train['text'].apply(lambda x:len(str(x).split()))                #Number Of words in Selected Text           \ntrain['NoOfTextWords'] = train['text'].apply(lambda x:len(str(x).split()))                                 #Number Of words in main text\ntrain['DifferenceOfTextWordsToSelectedTextWords'] = train['NoOfTextWords'] - train['NoOfSelectedTextWords'] #Difference in Number of words text and Selected Text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly import graph_objs as go\n\nfig = go.Figure(go.Funnelarea(\n    text =train['sentiment'].value_counts().index,\n    values = train['sentiment'].value_counts().values,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.kdeplot(train[train['sentiment']=='positive']['DIFF_WORDS'],shade=True,COLOR='B',label='DIFF_WORDS_POS')\nsns.kdeplot(train[train['sentiment']=='negative']['DIFF_WORDS'],shade=True,COLOR='R',label='DIFF_WORDS_NEG')\nplt.title('DISTRIBUTION OF DIFFERNCE IN LENGTH OF POSITIVE WORDS & NEGATIVE WORDS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['NoOfSelectedTextWords'] = train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ntrain['NoOfTextWords'] =train['text'].apply(lambda x:len(str(x).split()))                  #Number Of words in main text\ntrain['DifferenceOfTextWordsToSelectedTextWords'] = train['NoOfTextWords'] - train['NoOfSelectedTextWords'] #Difference in Number of words text and Selected Text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.kdeplot(train[train['sentiment']=='positive']['jaccard_score'],shade=True,COLOR='B',label='jaccard_score_pos')\nsns.kdeplot(train[train['sentiment']=='negative']['jaccard_score'],shade=True,COLOR='R',label='jaccard_score_neg')\nplt.title('DISTRIBUTION OF JACCARD SCORE OF POSITIVE WORDS , NEGATIVE WORDS & NEUTRAL WORDS')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train[train['sentiment']=='neutral']['jaccard_score'].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,6))\nsns.countplot(test['sentiment'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.countplot(train['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(12,6))\nsns.boxplot(train[train['sentiment']=='neutral']['jaccard_score'])\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ntest['text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in test['sentiment'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(30))\ntemp.columns = ['Similar!!letters','count']\ntemp.style.background_gradient(cmap='Purples')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ntrain['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(30))\ntemp.columns = ['Similar!!words','count']\ntemp.style.background_gradient(cmap='Reds')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.plot(train[train['sentiment']=='neutral']['jaccard_score'],'r+')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CLEAN_TEXT(text):\n\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\s+|www\\.\\s+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CLEAN_TEXT1(text):\n\n    # TOKENIZE TEXT AND REMOVE PUNCUTATION\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # REMOVE WORDS THAT CONTAIN NUMBERS\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # REMOVE STOP WORDS\n    text = [x for x in text if x not in stop]\n    # REMOVE EMPTY TOKENS\n    text = [t for t in text if len(t) > 0]\n    # REMOVE WORDS WITH ONLY ONE LETTER\n    text = [t for t in text if len(t) > 1]\n    # JOIN ALL\n    text = \" \".join(text)\n    return(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'] = train['text'].apply(str).apply(lambda x: CLEAN_TEXT(x))\ntrain['selected_text'] = train.selected_text.apply(str).apply(lambda x: CLEAN_TEXT(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['CLEANED_TEXT'] = train['text'].apply(lambda x: CLEAN_TEXT1(x))\ntrain['CLEANED_SELECTED_TEXT'] = train.selected_text.apply(lambda x: CLEAN_TEXT1(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_token = word_tokenize(\"\".join(train['CLEANED_SELECTED_TEXT']))\nprint(word_token[:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_comman_token_15 = Counter(word_token).most_common(15)\nmost_comman_token_15_df = pd.DataFrame(most_comman_token_15)\nmost_comman_token_15_df.columns = ['word','count']\nmost_comman_token_15_df.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_wordcloud(text,mask=None,max_words=400,max_font_size=100,figure_size=(24.0,16.0),title=None,title_size=40,image_color=False):\n    stopwords = set(STOPWORDS)\n    more_stopwords={'u',\"im\"}\n    stopwords=stopwords.union(more_stopwords)\n    \n    wordcloud = WordCloud(background_color='White',\n                         stopwords = stopwords,max_words=max_words,\n                         max_font_size=max_font_size,random_state=42,mask=mask)\n    \n    wordcloud.generate(str(text))\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = imagegenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors),interpolation=\"BILINEAR\");\n        plt.title(title,fontdict={'SIZE':title_size,\n                                  'VERTICALALIGNMENT':'bottom'})\n    else:\n            plt.imshow(wordcloud);\n            plt.title(title,fontdict={'SIZE':title_size,'COLOR':'RED',\n                                     'VERTICALALIGNMENT':'bottom'})\n            plt.axis('OFF');\n    plt.tight_layout()  \n    \nD = '/kaggle/input/imagetc/'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_sentiment = train[train['sentiment']=='positive']\nnegative_sentiment = train[train['sentiment']=='negative']\nneutral_sentiment = train[train['sentiment']=='neutral']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(8,6))\nsns.kdeplot(neutral_sentiment['NO_WORDS_ST'],shade=True,COLOR='B',label='NEU_NO_WORDS_ST')\nsns.kdeplot(neutral_sentiment['NO_WORDS_T'],shade=True,COLOR='R',label='NEU_NO_WORDS_T')\nplt.title('DISTRIBUTION OF NUMBER OF WORDS IN SELECTED TEXT & TEXT IN NEUTRAL DATAFRAME')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_token_pos = word_tokenize(\"\".join(positive_sentiment['CLEANED_SELECTED_TEXT']))\nprint(word_token_pos[:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_comman_token_15_pos = Counter(word_token_pos).most_common(15)\nmost_comman_token_15_pos_df = pd.DataFrame(most_comman_token_15_pos)\nmost_comman_token_15_pos_df.columns = ['word','count']\nmost_comman_token_15_pos_df.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly import graph_objs as gpy\nimport plotly.express as ppy\nimport plotly.figure_factory as fpy\nfig = ppy.bar(temp, x=\"Similar!!words\", y=\"count\", title='Similar!!words in Selected_Text', orientation='v', \n             width=700, height=700, color='Similar!!words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"twitter_mask=np.array(Image.open(D+'twitter.png'))\nplot_wordcloud(positive_sentiment.text,mask=twitter_mask,max_font_size=80,title_size=30,title=\"WORDCLOUD FOR POSITIVE TWEETS\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_token_neg = word_tokenize(\"\".join(negative_sentiment['CLEANED_SELECTED_TEXT']))\nprint(word_token_neg[:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"most_comman_token_15_neg = Counter(word_token_neg).most_common(15)\nmost_comman_token_15_neg_df = pd.DataFrame(most_comman_token_15_neg)\nmost_comman_token_15_neg_df.columns = ['word','count']\nmost_comman_token_15_neg_df.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntwitter_mask=np.array(Image.open(D+'twitter.png'))\nplot_wordcloud(negative_sentiment.text,mask=twitter_mask,max_font_size=80,title_size=30,title=\"WORDCLOUD FOR NEGATIVE TWEETS\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nword_token_neu = word_tokenize(\"\".join(neutral_sentiment['CLEANED_SELECTED_TEXT']))\nprint(word_token_neu[:50])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nmost_comman_token_15_neu = Counter(word_token_neu).most_common(15)\nmost_comman_token_15_neu_df = pd.DataFrame(most_comman_token_15_neu)\nmost_comman_token_15_neu_df.columns = ['word','count']\nmost_comman_token_15_neu_df.style.background_gradient(cmap='Greens')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntwitter_mask=np.array(Image.open(D+'twitter.png'))\nplot_wordcloud(neutral_sentiment.text,mask=twitter_mask,max_font_size=80,title_size=30,title=\"WORDCLOUD FOR NEUTRAL TWEETS\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neutral = train[train['sentiment'] == 'neutral']\npositive = train[train['sentiment'] == 'positive']\nnegative = train[train['sentiment'] == 'negative']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_length = train['text'].apply(lambda x:len(str(x)))\n\nsns.distplot(tweets_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_top_n_words(corpus,n_grams=None):\n    vec = CountVectorizer(ngram_range=(n_grams,n_grams)).fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    \n    sum_of_words = bag_of_words.sum(axis=0)\n    word_freq = [(word, sum_of_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    word_freq = sorted(word_freq, key = lambda x: x[1], reverse=True)\n    return word_freq[:15]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_n_bigrams = get_top_n_words(train['text'].dropna(),2)\nx,y = map(list,zip(*top_n_bigrams))\nplt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_n_bigrams = get_top_n_words(train['selected_text'].dropna(),2)\nx,y = map(list,zip(*top_n_bigrams))\nplt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntop_n_trigrams = get_top_n_words(train['text'].dropna(),3)\nx,y = map(list,zip(*top_n_trigrams))\nplt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_n_trigrams = get_top_n_words(train['selected_text'].dropna(),3)\nx,y = map(list,zip(*top_n_trigrams))\nplt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_n_trigrams_pos = get_top_n_words(positive_sentiment['text'].dropna(),3)\nx,y = map(list,zip(*top_n_trigrams_pos))\nplt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_n_trigrams_neg = get_top_n_words(negative_sentiment['text'].dropna(),3)\nx,y = map(list,zip(*top_n_trigrams_neg))\nplt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top_n_trigrams_neu = get_top_n_words(neutral_sentiment['text'].dropna(),3)\nx,y = map(list,zip(*top_n_trigrams_neu))\nplt.figure(figsize=(9,7))\nsns.barplot(x=y,y=x)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_copy = train.copy()\ndata_train = data_copy[data_copy['NO_WORDS_T']>=3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='red')\nplt.rcParams['text.color'] = 'blue'\nplt.pie(temp['count'], labels=temp['Common_words'], colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('Common_words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_data(sentiment):\n    train_data=[]\n    \n    '''\n    RETURNS TRAINING DATA IN THE FORMAT NEEDED TO TRAIN SPACY NER\n    '''\n    for index,row in data_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.CLEANED_SELECTED_TEXT\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start,end,'selected_text']]}))\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"LOAD THE MODEL,SET UP THE PIPELINE AND TRAIN THE ENTITY RECOGNIZER\"\"\"\n    if model is not None:\n        nlp=spacy.load(model) #LOAD EXISTING SPACY MODEL\n        print(\"LOADED MODEL '%S'\" %model)\n    else:\n        nlp = spacy.blank(\"en\") #CREATE BLANK LANGUAGE CLASS\n        print(\"CREATED BLANK 'en' MODEL \")\n        \n        # THE PIPELINE EXECUTION\n        # CREATE THE BUILT-IN PIPELINE COMPONENTS AND THEM TO THE PIPELINE\n        # NLP.CREATE_PIPE WORKS FOR BUILT-INS THAT ARE REGISTERED IN THE SPACY\n        \n        if \"ner\" not in nlp.pipe_names:\n            ner = nlp.create_pipe(\"ner\")\n            nlp.add_pipe(ner,last=True)\n            \n             # OTHERWISE, GET IT SO WE CAN ADD LABELS\n        \n        else:\n            ner = nlp.get_pipe(\"ner\")\n            \n        # ADD LABELS \n        for _, annotations in train_data:\n                for ent in annotations.get(\"entities\"):\n                    ner.add_label(ent[2])\n                    # GET NAMES OF OTHER PIPES TO DISABLE THEM DURING TRAINING\n        \n        pipe_exceptions = [\"ner\",\"trf_wordpiecer\",\"trf_tok2vec\"]\n        other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n        \n        with nlp.disable_pipes(*other_pipes): # TRAINING OF ONLY NER\n            \n             # RESET AND INTIALIZE THE WEIGHTS RANDOML - BUT ONLY IF WE'RE\n            # TRAINING A MODEL\n            \n            if model is None:\n                nlp.begin_training()\n            else:\n                nlp.resume_training()\n            \n            for itn in trange(n_iter):\n                random.shuffle(train_data)\n                losses={}\n                # BATCH UP THE EXAMPLE USING SPACY'S MNIBATCH\n                batches = minibatch(train_data,size=compounding(4.0,1000.0,1.001))\n                #PRINT(BATCHES)\n                for batch in batches:\n                    texts , annotations = zip(*batch)\n                    nlp.update(\n                        texts, #BATCH OF TEXTS\n                        annotations, # BATCH OF ANNOTATIONS\n                        drop = 0.5,  # DROPOUT - MAKE IT HARDER TO MEMORISE DATA\n                         losses = losses,\n                )\n            print(\"losses\", losses)\n        save_model(output_dir, nlp, 'st_ner')\n        \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_path(sentiment):\n    model_out_path = None \n    if sentiment == 'positive':\n        model_out_path = 'models/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models/model_neg'\n    return model_out_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(output_dir,nlp,new_model_name):\n    if output_dir is not None:\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"SAVED MODEL TO\",output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment ='positive'\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_path(sentiment)\ntraining(train_data,model_path,n_iter=3,model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment ='negative'\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_path(sentiment)\ntraining(train_data,model_path,n_iter=3,model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '/kaggle/working/models/'\nmodel_path_pos = model_path + 'model_pos'\nmodel_path_neg = model_path + 'model_neg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(text,model):\n    docx = model(text)\n    ent_arr=[]\n    for ent in docx.ents:\n        #PRINT(ENT.TEXT)\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        entity_arr = [start,end,ent.label_]\n        if entity_arr not in ent_arr:\n            ent_arr.append(entity_arr)\n    selected_text = text[ent_arr[0][0]:ent_arr[0][1]] if len(ent_arr)>0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_text=[]\nif model_path is not None:\n    print(\"LOADING MODELS  FROM \", model_path)\n    model_pos = spacy.load(model_path_pos)\n    model_neg = spacy.load(model_path_neg)\n    for index,row in test.iterrows():\n        text = row.text.lower()\n        if row.sentiment == 'neutral':\n            selected_text.append(text)\n        elif row.sentiment == 'positive':\n            selected_text.append(predict(text,model_pos))\n        else:\n            selected_text.append(predict(text,model_neg))       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert len(test.text) == len(selected_text)\nsubmission['selected_text'] = selected_text\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' ACCEPS A LIST OF IPYTABLE OBJECTS AND RETURNS A TABLE WHICH CONTAINS EACH IPYTABLE IN A CELL\n    '''\n    return HTML(\n        '<TABLE><TR STYLE=\"BACKGROUND-COLOR:WHITE;\">' + \n        ''.join(['<TD>' + table._repr_html_() + '</TD>' for table in table_list]) +\n        '</TR></TABLE>'\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_table([test.head(10),submission.head(10)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}