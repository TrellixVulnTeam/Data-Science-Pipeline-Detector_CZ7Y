{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport re\nfrom textblob import TextBlob\n\n#test process lib\nimport re\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\n\nimport spacy\n\ndata= pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\ndata.head()\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n#visualize lib\nstop = stopwords.words('english')\nfrom nltk.tokenize import word_tokenize\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.graph_objs as go\n\nfrom tqdm import tqdm\nimport random\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom plotly.offline import iplot\nfrom collections import Counter\nfrom string import *\nimport cufflinks\n\nimport tokenizers\nimport torch\nfrom spacy.util import compounding\n\n#transformers to tokenization\nfrom transformers import BertTokenizer\nfrom tqdm import trange\n\nfrom spacy.util import minibatch\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#file sys mangmnt\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\n\ndata= pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\nprint(data.shape)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['NoOfSelectedTextWords'] = data['text'].apply(lambda x:len(str(x).split()))                #Number Of words in Selected Text           \ndata['NoOfTextWords'] = data['text'].apply(lambda x:len(str(x).split()))                                 #Number Of words in main text\ndata['DifferenceOfTextWordsToSelectedTextWords'] = data['NoOfTextWords'] - data['NoOfSelectedTextWords'] #Difference in Number of words text and Selected Text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as pt\nactivities= ['nutral', 'positive', 'negative']\nslices=[1430,1103,1001]\ncolors=['c','b','m']\npt.pie(slices, labels=activities, colors=colors, startangle=90, radius=2.0, autopct= '%1.1f%%')\npt.legend()\npt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display= pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\nprint(display.shape)\ndisplay.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display['sentiment'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as pt\nactivities= ['nutral', 'positive', 'negative']\nslices=[11118,8582,7781]\ncolors=['r','y','g']\npt.pie(slices, labels=activities, colors=colors, startangle=90, radius=2.0, autopct= '%1.1f%%')\npt.legend()\npt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display['NoOfSelectedTextWords'] = display['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ndisplay['NoOfTextWords'] = display['text'].apply(lambda x:len(str(x).split()))                  #Number Of words in main text\ndisplay['DifferenceOfTextWordsToSelectedTextWords'] = display['NoOfTextWords'] - display['NoOfSelectedTextWords'] #Difference in Number of words text and Selected Text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display['temp_list'] = display['selected_text'].apply(lambda x:str(x).split())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(x):\n    return [y for y in x if y not in stopwords.words('english')]\ndisplay['temp_list'] = display['temp_list'].apply(lambda x:remove_stopword(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.figure(figsize=(10,6))\nsns.countplot(data['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(10,6))\nsns.countplot(display['sentiment'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ndata['text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in data['sentiment'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(30))\ntemp.columns = ['Similar!!letters','count']\ntemp.style.background_gradient(cmap='Purples')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import Counter\ndisplay['temp_list'] = display['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in display['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(30))\ntemp.columns = ['Similar!!words','count']\ntemp.style.background_gradient(cmap='Reds')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly import graph_objs as gpy\nimport plotly.express as ppy\nimport plotly.figure_factory as fpy\nfig = ppy.bar(temp, x=\"Similar!!words\", y=\"count\", title='Similar!!words in Selected_Text', orientation='v', \n             width=700, height=700, color='Similar!!words')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neutral = display[display['sentiment'] == 'neutral']\npositive = display[display['sentiment'] == 'positive']\nnegative = display[display['sentiment'] == 'negative']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tweets_length = display['text'].apply(lambda x:len(str(x)))\n\nsns.distplot(tweets_length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\ndef wc(df, text = 'text'):\n    \n    # Join all tweets in one string\n    corpus = \" \".join(str(review) for review in df[text])\n    print (f\"There are {len(corpus)} words in the combination of all review.\")\n    \n    wc = WordCloud(max_font_size=50, \n                          max_words=100, \n                          background_color=\"white\").generate(corpus)\n    \n    plt.figure(figsize=(15,15))\n    plt.imshow(wc, interpolation=\"bilinear\")\n    plt.axis(\"off\")\n    plt.show()\n\nwc(df = display)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wc(df = display, text = 'selected_text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wc(df = neutral, text = 'text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wc(df = positive, text = 'text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"wc(df = negative, text = 'text')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text):\n    '''Convert text to lowercase,remove punctuation, remove words containing numbers, ,remove links and remove text in square brackets,.'''\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display['text'] = display['text'].apply(lambda x:clean_text(x))\ndisplay['selected_text'] = display['selected_text'].apply(lambda x:clean_text(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def CLEAN_TEXT(text):\n\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\s+|www\\.\\s+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"stop = stopwords.words('english')\ndef CLEAN_TEXT1(text):\n\n    # TOKENIZE TEXT AND REMOVE PUNCUTATION\n    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n    # REMOVE WORDS THAT CONTAIN NUMBERS\n    text = [word for word in text if not any(c.isdigit() for c in word)]\n    # REMOVE STOP WORDS\n    text = [x for x in text if x not in stop]\n    # REMOVE EMPTY TOKENS\n    text = [t for t in text if len(t) > 0]\n    # REMOVE WORDS WITH ONLY ONE LETTER\n    text = [t for t in text if len(t) > 1]\n    # JOIN ALL\n    text = \" \".join(text)\n    return(text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display['text'] = display['text'].apply(str).apply(lambda x: CLEAN_TEXT1(x))\ndisplay['selected_text'] = display.selected_text.apply(str).apply(lambda x: CLEAN_TEXT1(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display['CLEANED_TEXT'] = display['text'].apply(lambda x: CLEAN_TEXT1(x))\ndisplay['CLEANED_SELECTED_TEXT'] = display.selected_text.apply(lambda x: CLEAN_TEXT1(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display.head(90)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text'] = display['text'].apply(str).apply(lambda x: CLEAN_TEXT1(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['CLEANED_TEXT'] = data['text'].apply(lambda x: CLEAN_TEXT1(x))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.head(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = '../input/tweet-sentiment-extraction/sample_submission.csv'\nsubmission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '/kaggle/working/models/'\nmodel_path_pos = model_path + 'model_pos'\nmodel_path_neg = model_path + 'model_neg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(text,model):\n    docx = model(text)\n    ent_arr=[]\n    for ent in docx.ents:\n        #PRINT(ENT.TEXT)\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        entity_arr = [start,end,ent.label_]\n        if entity_arr not in ent_arr:\n            ent_arr.append(entity_arr)\n    selected_text = text[ent_arr[0][0]:ent_arr[0][1]] if len(ent_arr)>0 else text\n    return selected_text\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' ACCEPS A LIST OF IPYTABLE OBJECTS AND RETURNS A TABLE WHICH CONTAINS EACH IPYTABLE IN A CELL\n    '''\n    return HTML(\n        '<TABLE><TR STYLE=\"BACKGROUND-COLOR:WHITE;\">' + \n        ''.join(['<TD>' + table._repr_html_() + '</TD>' for table in table_list]) +\n        '</TR></TABLE>'\n    )\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_table([data.head(10),submission.head(10)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = pd.DataFrame(top.most_common(20))\ntemp = temp.iloc[1:,:]\ntemp.columns = ['Common_words','count']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nfrom palettable.colorbrewer.qualitative import Pastel1_7\nplt.figure(figsize=(16,10))\nmy_circle=plt.Circle((0,0), 0.7, color='red')\nplt.rcParams['text.color'] = 'blue'\nplt.pie(temp['count'], labels=temp['Common_words'], colors=Pastel1_7.hex_colors)\np=plt.gcf()\np.gca().add_artist(my_circle)\nplt.title('Common_words')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from plotly import graph_objs as go\n\nfig = go.Figure(go.Funnelarea(\n    text =display['sentiment'].value_counts().index,\n    values = display['sentiment'].value_counts().values,\n    title = {\"position\": \"top center\", \"text\": \"Funnel-Chart of Sentiment Distribution\"}\n    ))\nfig.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_data(sentiment):\n    display_data=[]\n    \n    '''\n    RETURNS TRAINING DATA IN THE FORMAT NEEDED TO TRAIN SPACY NER\n    '''\n    for index,row in display.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.CLEANED_SELECTED_TEXT\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            display_data.append((text, {\"entities\": [[start,end,'selected_text']]}))\n    return display_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def training(display_data, output_dir, n_iter=20, model=None):\n    \"\"\"LOAD THE MODEL,SET UP THE PIPELINE AND TRAIN THE ENTITY RECOGNIZER\"\"\"\n    if model is not None:\n        nlp=spacy.load(model) #LOAD EXISTING SPACY MODEL\n        print(\"LOADED MODEL '%S'\" %model)\n    else:\n        nlp = spacy.blank(\"en\") #CREATE BLANK LANGUAGE CLASS\n        print(\"CREATED BLANK 'en' MODEL \")\n        \n        # THE PIPELINE EXECUTION\n        # CREATE THE BUILT-IN PIPELINE COMPONENTS AND THEM TO THE PIPELINE\n        # NLP.CREATE_PIPE WORKS FOR BUILT-INS THAT ARE REGISTERED IN THE SPACY\n        \n        if \"ner\" not in nlp.pipe_names:\n            ner = nlp.create_pipe(\"ner\")\n            nlp.add_pipe(ner,last=True)\n            \n             # OTHERWISE, GET IT SO WE CAN ADD LABELS\n                \n        else:\n            ner = nlp.get_pipe(\"ner\")\n            \n        # ADD LABELS \n        for _, annotations in display_data:\n                for ent in annotations.get(\"entities\"):\n                    ner.add_label(ent[2])\n                    # GET NAMES OF OTHER PIPES TO DISABLE THEM DURING TRAINING\n        \n        pipe_exceptions = [\"ner\",\"trf_wordpiecer\",\"trf_tok2vec\"]\n        other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n        \n        with nlp.disable_pipes(*other_pipes): # TRAINING OF ONLY NER\n            \n             # RESET AND INTIALIZE THE WEIGHTS RANDOML - BUT ONLY IF WE'RE\n            # TRAINING A MODEL\n            \n            if model is None:\n                nlp.begin_training()\n            else:\n                nlp.resume_training()\n            \n            for itn in trange(n_iter):\n                random.shuffle(train_data)\n                losses={}\n                # BATCH UP THE EXAMPLE USING SPACY'S MNIBATCH\n                batches = minibatch(train_data,size=compounding(4.0,1000.0,1.001))\n                #PRINT(BATCHES)\n                for batch in batches:\n                    texts , annotations = zip(*batch)\n                    nlp.update(\n                        texts, #BATCH OF TEXTS\n                        annotations, # BATCH OF ANNOTATIONS\n                        drop = 0.5,  # DROPOUT - MAKE IT HARDER TO MEMORISE DATA\n                         losses = losses,\n                )\n            print(\"losses\", losses)\n        save_model(output_dir, nlp, 'st_ner')\n        \n ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_path(sentiment):\n    model_out_path = None \n    if sentiment == 'positive':\n        model_out_path = 'models/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models/model_neg'\n    return model_out_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(output_dir,nlp,new_model_name):\n    if output_dir is not None:\n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"SAVED MODEL TO\",output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '/kaggle/working/models/'\nmodel_path_pos = model_path + 'model_pos'\nmodel_path_neg = model_path + 'model_neg'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' ACCEPS A LIST OF IPYTABLE OBJECTS AND RETURNS A TABLE WHICH CONTAINS EACH IPYTABLE IN A CELL\n    '''\n    return HTML(\n        '<TABLE><TR STYLE=\"BACKGROUND-COLOR:WHITE;\">' + \n        ''.join(['<TD>' + table._repr_html_() + '</TD>' for table in table_list]) +\n        '</TR></TABLE>'\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_table([data.head(10),submission.head(10)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ndata = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\nsubmission = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display['Num_words_text'] = display['text'].apply(lambda x:len(str(x).split())) #Number Of words in main Text in train set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display = display[display['Num_words_text']>=3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'../working/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# pass model = nlp if you want to train on top of existing model \n\ndef train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models/model_neg'\n    return model_out_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in display.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n# For DEmo Purposes I have taken 3 iterations you can train the model as you want\ntrain(train_data, model_path, n_iter=3, model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\ntrain(train_data, model_path, n_iter=3, model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_path = '/kaggle/working/models/'\nmodel_path_pos = model_path + 'model_pos'\nmodel_path_neg = model_path + 'model_neg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_text=[]\nif model_path is not None:\n    print(\"LOADING MODELS  FROM \", model_path)\n    model_pos = spacy.load(model_path_pos)\n    model_neg = spacy.load(model_path_neg)\n    for index,row in data.iterrows():\n        text = row.text.lower()\n        if row.sentiment == 'neutral':\n            selected_text.append(text)\n        elif row.sentiment == 'positive':\n            selected_text.append(predict(text,model_pos))\n        else:\n            selected_text.append(predict(text,model_neg))       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"assert len(data.text) == len(selected_text)\nsubmission['selected_text'] = selected_text\nsubmission.to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.core.display import HTML\ndef multi_table(table_list):\n    ''' ACCEPS A LIST OF IPYTABLE OBJECTS AND RETURNS A TABLE WHICH CONTAINS EACH IPYTABLE IN A CELL\n    '''\n    return HTML(\n        '<TABLE><TR STYLE=\"BACKGROUND-COLOR:WHITE;\">' + \n        ''.join(['<TD>' + table._repr_html_() + '</TD>' for table in table_list]) +\n        '</TR></TABLE>'\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"multi_table([data.head(10),submission.head(10)])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = px.treemap(temp, path=['Common_words'], values='count',title='Tree of Most Common Words and Letters')\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}