{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Objective:\n===\n- Given full tweet, sentiment: find the segment which decides the sentiment.\n- Need to identify the start token and end token.\n\n### Tasks:\n- Generate the start and end token and create the label data\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntrain.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = train.copy()\ndf = df.dropna(axis=0, subset=['text'])\ndf = df.fillna('')\ndf['select_len'] = df.selected_text.apply(lambda t: len(t.split()))\ndf['all_len'] = df.text.apply(lambda t: len(t.split()))\ndf['select_pct'] = df.apply(lambda r: r['select_len']/r['all_len']*100, axis=1)\nprint(df.head())\nprint(df.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ng = sns.FacetGrid(df, col=\"sentiment\")\ng.map(plt.hist, \"select_pct\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"sentiment\")\ng.map(plt.hist, \"all_len\");","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"g = sns.FacetGrid(df, col=\"sentiment\")\ng.map(plt.hist, \"select_len\");","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Neutral sentiment selected text is almost same as text.\n\n## highlight the key selected words for positive and negative"},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_text_list = df[df.sentiment == 'positive']['selected_text'].tolist()\npositive_text_list[:5]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Basic NER Model "},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import minibatch, compounding\nfrom pathlib import Path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Prepare Training Data for spacy nlp - ner \ndef create_training_data(df: pd.DataFrame, sentiment: str):\n    '''\n    ref: https://spacy.io/usage/training#ner\n    sample training data\n    TRAIN_DATA = [\n        (\"Who is Shaka Khan?\", {\"entities\": [(7, 17, \"PERSON\")]}),\n        (\"I like London and Berlin.\", {\"entities\": [(7, 13, \"LOC\"), (18, 24, \"LOC\")]}),\n    ]\n    '''\n    train_data = []\n    df_select = df[df.sentiment == sentiment]\n    for i, row in df_select.iterrows():\n        start = row['text'].find(row['selected_text'])\n        train_sample = (row['text'], \n                        {\"entities\": [(start,\n                                       start+len(row['selected_text']),\n                                      \"selected_text\")]})\n        train_data.append(train_sample)\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"LABEL = \"selected_text\"\n\ndef train(data, n_iter=10):\n    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n    random.seed(0)\n    nlp = spacy.blank(\"en\")  # create blank Language class\n    ner = nlp.create_pipe(\"ner\")\n    nlp.add_pipe(ner)\n    ner.add_label(LABEL)  # add new entity label to entity recognizer\n    optimizer = nlp.begin_training()\n    move_names = list(ner.move_names)\n    # get names of other pipes to disable them during training\n    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        for itn in range(n_iter):\n            random.shuffle(data)\n            batches = minibatch(data, size=sizes)\n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n            print(\"Losses\", losses)\n    return nlp","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def save_model(nlp, sentiment, outdir='/kaggle/working/models'):\n    # save model to output directory\n    output_dir = Path('/kaggle/working/models/'+sentiment)\n    if not output_dir.exists():\n        output_dir.mkdir(parents=True, exist_ok=True)\n    nlp.meta[\"name\"] = sentiment  # rename model\n    nlp.to_disk(output_dir)\n    print(\"Saved model to\", output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def is_model_trained(sentiment, outdir='/kaggle/working/models'):\n    if os.path.exists(os.path.join(outdir, sentiment+'/meta.json')):\n        return True\n    return False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"is_model_trained('nuetral')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for sent in df.sentiment.unique():\n    train_data = create_training_data(df,sent)\n    if not is_model_trained(sent):\n        print(f'training {sent} tweets selected_text ner model...')\n        model = train(train_data, n_iter=3)\n        save_model(model, sent)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Prediction for Test Data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')\ntest.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# load models\nmodels = {}\nmodels['positive'] = spacy.load('/kaggle/working/models/positive')\nmodels['negative'] = spacy.load('/kaggle/working/models/negative')\nmodels['neutral'] = spacy.load('/kaggle/working/models/neutral')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = []\nfor i, row in test.iterrows():\n    selected_text = predict_entities(row['text'], models[row['sentiment']])\n    predictions.append([row['textID'], selected_text])\ndf = pd.DataFrame(predictions)\ndf.columns=['textID', 'selected_text']\ndf.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}