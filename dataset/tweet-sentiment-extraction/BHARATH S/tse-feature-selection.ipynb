{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Libraries"},{"metadata":{"trusted":true},"cell_type":"code","source":"# libraries\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom nltk.tokenize import WordPunctTokenizer \nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.metrics import accuracy_score\n\nimport pandas as pd\nimport numpy as np","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"# reading train data\ndata = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\n\n# creating a new target variable based on sentiment\n\ndata['target'] = 0\n\ndata.loc[data['sentiment']=='positive', 'target'] = 1\ndata.loc[data['sentiment']=='negative', 'target'] = 2\n\ndata","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train cv split"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"\n# removing empty rows\ndata['text'].replace('', np.nan, inplace=True)\ndata.dropna(subset=['text'], inplace=True)\ndata.reset_index(drop=True, inplace=True)\n\n# spliting train data into train and cv\nx_train, x_cv, y_train, y_cv = train_test_split(data.drop(['sentiment'],axis = 1),data['target'], test_size = 0.2, random_state = 30)\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Vectorization using BOW"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating wordpuncttokenizer and using it as tokenizer for countvectorizer\ntokenizer = WordPunctTokenizer()\nuse_tokenizer = False\n\n# creating BOW\nif use_tokenizer:\n    vectorizer = CountVectorizer(tokenizer = tokenizer.tokenize,max_features = 10000, min_df=2, max_df=0.95)\nelse:\n    vectorizer = CountVectorizer(max_features = 10000 , min_df=2, max_df=0.95)\n\nx_train_text = vectorizer.fit_transform(x_train['text'],)\nx_cv_text = vectorizer.transform(x_cv['text'],)\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training a sentiment classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Training a classifier to predict sentiment\nalpha = [0.00001,0.0001,0.001,0.01,0.1,1,10,100]\ncv_score = []\nfor i in alpha:\n    clf = MultinomialNB(alpha = i)\n    clf.fit(x_train_text, y_train)\n    print('accuracy for alpha=',i, 'is:',accuracy_score(y_cv, clf.predict(x_cv_text)))\n    cv_score.append(accuracy_score(y_cv, clf.predict(x_cv_text)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# retraining with best alpha\nbest_alpha = alpha[cv_score.index(max(cv_score))]\nclf = MultinomialNB(alpha = best_alpha)\nclf.fit(x_train_text, y_train)\nprint('accuracy for best alpha=',best_alpha, 'is:',accuracy_score(y_cv, clf.predict(x_cv_text)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Criteria for picking selected_text:\n\n> For neutral we pick whole text as selected_text. (based on EDA findings)\n\n> For positive and neutral, we consider probabilities of word for a given sentiment.\n\nexample: P(good/positive) = 0.5, p(hate/positive) = 0.1\n\nwe set the threshold to 0.4 then we pick the word \"good\" into the selected_text and drop the word \"hate\".\n\nIn order to find the threshold we take sum of probabilities of all words in sentence, p(w1/sentiment), p(w2/sentiment) and divide by number of words. we multiply this value with k(hyperparamter).\n\nif prob(w1/sentiment) > k* threshold, we select the text else we ignore it."},{"metadata":{},"cell_type":"markdown","source":"## Metric"},{"metadata":{"trusted":true},"cell_type":"code","source":"# metric code is from kaggle page. https://www.kaggle.com/c/tweet-sentiment-extraction/overview/evaluation\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Training selected_text finder"},{"metadata":{"trusted":true},"cell_type":"code","source":"# each dictionary consists of probability of word in that target(0,1,2)\ndict0 = dict(zip(vectorizer.get_feature_names(),clf.feature_log_prob_[0] ))\ndict1 = dict(zip(vectorizer.get_feature_names(),clf.feature_log_prob_[1] ))\ndict2 = dict(zip(vectorizer.get_feature_names(),clf.feature_log_prob_[2] ))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def threshold_preds(k, use_tokenizer,df):\n    \"\"\"\n    Performs predictions of selected_text for tweets in given data frame.\n    inputs:\n    k: multiplier for average probabilties for words in each tweet\n    use_tokenizer: whether to use simple split or wordpuncttokenizer\n    df: dataframe on which to perform predictions\n    \n    output:\n    list of predictions of selected_text for a given dataframe\"\"\"\n    \n    preds = []\n\n    for index,item in df.iterrows():\n\n        if item.target!=0 :\n            if(use_tokenizer):\n                temp = WordPunctTokenizer().tokenize(item['text'])\n            else:\n                temp = item['text'].split()\n            sentiment = item['target']\n            if sentiment==1:\n                probs = dict1\n            else:\n                probs = dict2\n            temp_score = 0\n            temp_text = ''\n            for a in temp:\n                a = a.lower()\n                if a in probs:\n                    temp_score+=probs[a]\n                \n\n            for a in temp:\n                a = a.lower()\n                if a in probs:\n                    if probs[a]>k*temp_score/len(temp):\n                     \n                        temp_text=temp_text +' ' + a\n                \n            preds.append(temp_text)\n        else:\n            preds.append(item.text)\n    return preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# finding best k based on cv_score\nk = np.linspace(0,11,20)\ncv_score = []\n\nfor i in k:\n    preds = threshold_preds(i,use_tokenizer,x_cv)\n    score = 0\n    count = 0\n    for index,item in x_cv.iterrows():\n        score+=jaccard(item.selected_text,preds[count])\n        count+=1\n    score = score/count\n    cv_score.append(score)\n    print('jaccard score for threshold',i,'is:',score)       \nbest_k = k[cv_score.index(max(cv_score))]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Test Predictions"},{"metadata":{"trusted":true},"cell_type":"code","source":"# test predictions\n\ntest = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ntest['target'] = 0\ntest.loc[test['sentiment']=='positive', 'target'] = 1\ntest.loc[test['sentiment']=='negative', 'target'] = 2\n\n\npreds = threshold_preds(best_k,use_tokenizer,test)\n\nsubmission = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\nsubmission['selected_text'] = preds\n\nsubmission.to_csv('submission.csv', index = False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}