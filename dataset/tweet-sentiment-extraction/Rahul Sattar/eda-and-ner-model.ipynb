{"cells":[{"metadata":{"_uuid":"b782c94f-2af1-444d-b7c0-fd283349a111","_cell_guid":"3592a674-d2ec-4864-9e89-8915803ddb38","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"931022e8-01a5-4274-a353-220b08d12fb1","_cell_guid":"b14d6dee-dbb8-442b-bc8e-b83d1892820d","trusted":true},"cell_type":"markdown","source":"Loading the data into kernal","execution_count":null},{"metadata":{"_uuid":"89fdd287-6eb0-4adf-87b7-a828e6a1547c","_cell_guid":"1c938452-e7fe-4cf3-bac4-2dc0bb5bc435","trusted":true},"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/test.csv\")\nprint(\"Training Examples : {}\".format(len(train)))\nprint(\"Testing Examples : {}\".format(len(test)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0e8a822-bfe5-4aa8-8d67-350c7be338b1","_cell_guid":"f1e60d08-f467-4590-bb69-7fd5b666fe1f","trusted":true},"cell_type":"markdown","source":"Lets take a look at the data itself","execution_count":null},{"metadata":{"_uuid":"e1f4ad59-f5ac-4d27-a664-2804493f3a77","_cell_guid":"5caa73ac-43ff-4991-a0da-d641a0b8a7e9","trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"33af45fa-5015-4aab-b047-a15b9bfca1e8","_cell_guid":"cc0e0381-6ee2-4041-a4ab-9524ef7326ab","trusted":true},"cell_type":"markdown","source":"# Exploratory Data Analysis\n\nMostly we will be using plotly library for EDA. So lets start looking at at our sentiment distrubition","execution_count":null},{"metadata":{"_uuid":"6eed7650-fc85-40dc-8889-b3ae981bd9b6","_cell_guid":"458cb51f-bcc4-477e-9af8-3eea917d4fed","trusted":true},"cell_type":"code","source":"#Importing libraries for EDA\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b6608bc1-48e6-4b22-8822-2ebcda2d35df","_cell_guid":"bf805027-df6d-4055-a97d-4053e44f6e04","trusted":true},"cell_type":"code","source":"#Data preparation\nclass_dist = train.groupby([\"sentiment\"]).count()['textID'].reset_index()\n#Lets look at the distribution of classes\nfig = make_subplots(rows=1, cols=2, specs=[[{'type':'domain'}, {}]])\nfig.add_trace(go.Pie(labels=class_dist.sentiment, values=class_dist.textID, name=\"% Distribution\",hole=.5),\n              1, 1)\nfig.add_trace(go.Bar(x = class_dist.sentiment, y=class_dist.textID, name=\"Frequency Distribution\"),\n              1, 2)\nfig.update_layout(title=\"% Distribution and Frequency Disstibution\")","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b9706a25-2f82-4900-9763-2ea5ed713ca2","_cell_guid":"a1bf9251-f65e-4ce6-affe-f9a6dd0dd919","trusted":true},"cell_type":"markdown","source":"Data is pretty evenly distributed with 40% neutral sentenses and ~30% each postive and negative sentenses\n\nNow lets look into text similarity between text and selected_text. You can see that there is a 97% similarity between text and selected_text for neutral sentences [here](https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model) by jaccard similarity.\n\nIn this notebook, let us look into cosine similarity and check the same. \n\n### Checking sentence similarity between text and selected_text using COSINE similarity. \n\nYou can read about COSINE similarity [here](https://www.machinelearningplus.com/nlp/cosine-similarity/)\n\nCode was picked-up [here](https://stackoverflow.com/questions/15173225/calculate-cosine-similarity-given-2-sentence-strings)","execution_count":null},{"metadata":{"_uuid":"d7fa6ad9-025e-4a58-9dee-f1230b1ff05c","_cell_guid":"5105f5ce-9b09-4e94-85d9-ff3da754a706","trusted":true},"cell_type":"code","source":"import math\nimport re\nfrom collections import Counter\n\nWORD = re.compile(r\"\\w+\")\n\ndef text_to_vector(text):\n    words = WORD.findall(text)\n    return Counter(words)\n\ndef get_cosine(text1, text2):\n    vec1 = text_to_vector(text1)\n    vec2 = text_to_vector(text2)   \n    intersection = set(vec1.keys()) & set(vec2.keys())\n    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n\n    sum1 = sum([vec1[x] ** 2 for x in list(vec1.keys())])\n    sum2 = sum([vec2[x] ** 2 for x in list(vec2.keys())])\n    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n\n    if not denominator:\n        return 0.0\n    else:\n        return float(numerator) / denominator\n\n#testing the cosine similarity\nstr1 = train.text[0]\nstr2 = train.selected_text[0]\n\nprint(\"String 1 : {}\".format(str1))\nprint(\"String 2 : {}\".format(str2))\ncosine_score = get_cosine(str1,str2) \nprint(\"Cosine Similarity of the above two sentences : {}%\".format(np.round(cosine_score*100)))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a808053f-b63b-4607-a8a2-7432073be385","_cell_guid":"99e98723-338e-465c-8d1e-a2d76ca7f7ba","trusted":true},"cell_type":"markdown","source":"Looks good. Lets go ahead and apply the cosine similarity of the training set","execution_count":null},{"metadata":{"_uuid":"1ecf7a85-973c-4095-bdcf-cd23c75033c7","_cell_guid":"777c644f-731e-4da0-b715-e751083cafbf","trusted":true},"cell_type":"code","source":"train['COSINE_Score'] = train.apply(lambda row:get_cosine(str(row['text']),str(row['selected_text'])),axis=1)\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c7b63653-dd55-467b-84ec-074574deef4f","_cell_guid":"89e7e4c3-c8f1-41f1-94d6-11772a4d8b85","trusted":true},"cell_type":"markdown","source":"Now lets examine the difference between the COSINE scores in Nuetral vs Negative and Positve","execution_count":null},{"metadata":{"_uuid":"f9dc8328-984a-48ea-9960-96eaf04cf235","_cell_guid":"eef402f2-9489-4226-80c6-2aff82f45628","trusted":true},"cell_type":"code","source":"import plotly.express as px\nfig = px.box(train,x='sentiment',y='COSINE_Score',color='sentiment')\nfig.update_traces(quartilemethod=\"inclusive\") # or \"inclusive\", or \"linear\" by default\nfig.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"19be9a1e-20f0-4ac3-819a-299e02d85a1f","_cell_guid":"fa25b0e1-3510-4dd9-93ea-c7875e62c354","trusted":true},"cell_type":"markdown","source":"Median cosine score for neutral sentenses is 1, for negative it is 0.45 and for positive it is 0.40.\nShows that for neutral sentenses it is difficult to capture the part of the sentence effecting the overall sentiment of the sentence. \n\nAlso emphasizes on the fact that sentence sentiment will have a great impact on overall model performace in extracting the part of sentence which determines the sentence sentiment","execution_count":null},{"metadata":{"_uuid":"1e5b3034-654e-4d75-b9ee-1e1dc3e6efb1","_cell_guid":"6fd271cb-c983-449a-a78a-37e1282d8604","trusted":true},"cell_type":"markdown","source":"# Model\n\nAs we know that sentiment plays a role in the sentence selection. While creating entities, we shall consider the sentiment as a entity type too. \nWe will be using the NER, Named entity recognition model to begin with. As demonstrated by Mr_KnowNothing [here](https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model)\n\nBut the changes in this model are\n1. We will be using single model to handle all sentiment texts\n2. Sentiment is considered as entity","execution_count":null},{"metadata":{"_uuid":"fd1873fc-cdc8-46d2-affd-3d750a2e2485","_cell_guid":"2ff0fdb6-0350-4436-a025-5a37c368d55e","trusted":true},"cell_type":"code","source":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'../working/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a0440b2b-7b2d-4b08-8c4e-a82651614c9a","_cell_guid":"19d5cbb0-42cc-4960-8d5f-9e503ccbe4b4","trusted":true},"cell_type":"code","source":"#Training Model\n\n# pass model = nlp if you want to train on top of existing model \n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\ndef train_model(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"06fd456d-1c5c-49b1-ac34-114aad2180b3","_cell_guid":"7b903f66-0df9-4767-ad46-55627cc5f8e6","trusted":true},"cell_type":"markdown","source":"Lets now create the training data","execution_count":null},{"metadata":{"_uuid":"125df400-b117-48bf-8b54-bcb2f03ed107","_cell_guid":"7f913538-edda-4e35-9b1c-28534c0da7e3","trusted":true},"cell_type":"code","source":"def get_training_data(df_train):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        sentiment = row.sentiment #Store sentiment here\n        selected_text = str(row.selected_text)\n        text = str(row.text)\n        start = text.find(selected_text)\n        end = start + len(selected_text)\n        train_data.append((text, {\"entities\": [[start, end, sentiment]]})) #sentiment as training\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c0cc37a8-3f61-4256-8d66-c9fda8796e64","_cell_guid":"82bda94d-458e-4832-9afd-c2ee696dd9a5","trusted":true},"cell_type":"markdown","source":"Trainining the model","execution_count":null},{"metadata":{"_uuid":"932552fb-2c23-4388-a73b-a5559f5aa19c","_cell_guid":"c3505bf1-ce73-46b6-8926-7937a7e52657","trusted":true},"cell_type":"code","source":"model_path = '/models/model'\ntrain_data = get_training_data(train)\ntrain_model(train_data,model_path,n_iter=3,model=None)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"383ef3b0-4b4b-4c7d-ba29-4c1d5305aae5","_cell_guid":"ca12c3bc-dac9-48e4-a01e-c974194cf9da","trusted":true},"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc3551a5-f82f-4f31-a693-2e1e7e56c9af","_cell_guid":"01bdac33-5b66-4327-8092-fc8d8ad81ef4","trusted":true},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{"_uuid":"65cf7492-baa9-4376-94b3-5000b65c7f2a","_cell_guid":"46a1b359-b228-48e4-b3d7-53dd9d0b6032","trusted":true},"cell_type":"code","source":"selected_texts = []\nMODELS_BASE_PATH = '/kaggle/working/models/model'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model = spacy.load(MODELS_BASE_PATH)        \n    for index, row in test.iterrows():\n        text = row.text\n        output_str = \"\"\n        selected_texts.append(predict_entities(text, model))\n          \ntest['selected_text'] = selected_texts","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"96ab991d-e1e6-4981-9c7e-f3a76a7b4f17","_cell_guid":"92767e7f-3979-4867-a64d-9cb0cee2b696","trusted":true},"cell_type":"code","source":"df_submission = pd.read_csv(\"/kaggle/input/tweet-sentiment-extraction/sample_submission.csv\")\ndf_submission['selected_text'] = test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}