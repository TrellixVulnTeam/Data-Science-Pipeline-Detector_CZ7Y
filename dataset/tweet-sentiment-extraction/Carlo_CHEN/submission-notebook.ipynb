{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nfrom nltk.tokenize import sent_tokenize\nimport tokenizers\nimport transformers\nimport tensorflow as tf\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup\nfrom tqdm.autonotebook import tqdm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pip install pytorch_pretrained_bert","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom tqdm import tqdm, trange\nimport torch\nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom torch.nn.utils.rnn import pad_sequence\nfrom keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\nfrom pytorch_pretrained_bert import BertTokenizer, BertConfig\nfrom pytorch_pretrained_bert import BertForTokenClassification, BertAdam","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DATASETDIR1 = 'berttokenizer-base-uncased'\ntokenizer = transformers.BertTokenizer.from_pretrained(f'/kaggle/input/{DATASETDIR1}/vocab.txt')\n\nDATASETDIR = 'bert-base-uncased'\nconfig = transformers.BertConfig.from_pretrained(f'/kaggle/input/{DATASETDIR}/bert_config.json')\nmodel = transformers.BertModel.from_pretrained(f'/kaggle/input/{DATASETDIR}/pytorch_model.bin', config=config)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_save_name = 'BERT_for_negative_extraction.pt'\npath = F\"/kaggle/input/bert-negative/{model_save_name}\"\nmodel_negative = transformers.BertForTokenClassification.from_pretrained(f'/kaggle/input/{DATASETDIR}/pytorch_model.bin', config=config)\nmodel_negative = model_negative.cuda()\nmodel_negative.load_state_dict(torch.load(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_save_name = 'BERT_for_neutral_extraction.pt'\npath = F\"/kaggle/input/bert-neutral/{model_save_name}\"\nmodel_neutral = transformers.BertForTokenClassification.from_pretrained(f'/kaggle/input/{DATASETDIR}/pytorch_model.bin', config=config)\nmodel_neutral = model_negative.cuda()\nmodel_neutral.load_state_dict(torch.load(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_save_name = 'BERT_for_positive_extraction.pt'\npath = F\"/kaggle/input/bert-positive/{model_save_name}\"\nmodel_positive = transformers.BertForTokenClassification.from_pretrained(f'/kaggle/input/{DATASETDIR}/pytorch_model.bin', config=config)\nmodel_positive = model_positive.cuda()\nmodel_positive.load_state_dict(torch.load(path))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\ntest = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nn_gpu = torch.cuda.device_count()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"type(model_positive)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def keywordextract(model, sentence):\n    predicted_phrase = []\n    extracted_phrase = \"\"\n    text = sentence\n    tkns = tokenizer.tokenize(text)\n    indexed_tokens = tokenizer.convert_tokens_to_ids(tkns)\n    segments_ids = [0] * len(tkns)\n    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n    segments_tensors = torch.tensor([segments_ids]).to(device)\n#     print(tokens_tensor)\n#     print(segments_tensors)\n    model.eval()\n    prediction = []\n    logit = model(tokens_tensor, token_type_ids=None,\n                                  attention_mask=segments_tensors)   \n    logit = logit[0][0].detach().cpu().numpy()    \n    \n    for p in np.argmax(logit,axis=1):\n        prediction.append(p)\n\n    for k, j in enumerate(prediction):\n        if j == 1:\n            predicted_phrase.append(tokenizer.convert_ids_to_tokens(tokens_tensor[0].to('cpu').numpy())[k])\n    for element in predicted_phrase: \n        if (\"#\" in element):\n            element = element.replace(\"#\",\"\")\n        extracted_phrase += element\n        extracted_phrase += \" \"\n    return extracted_phrase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['extracted_phrase'] = \"\"\nfor i in range(test.shape[0]):\n    if (test['sentiment'][i] == \"positive\"):\n        test['extracted_phrase'][i] = keywordextract(model_positive,test['text'][i])\n    if (test['sentiment'][i] == \"negative\"):\n        test['extracted_phrase'][i] = keywordextract(model_negative,test['text'][i])\n    if (test['sentiment'][i] == \"neutral\"):\n        test['extracted_phrase'][i] = keywordextract(model_neutral,test['text'][i])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = test[['textID','extracted_phrase']]\nsubmission.columns = ['textID','selected_text']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/working/submission.csv')\ndf.iloc[:10,:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}