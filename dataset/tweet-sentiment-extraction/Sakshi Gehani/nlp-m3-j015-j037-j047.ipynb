{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_train():\n    train=pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\n    train['text']=train['text'].astype(str)\n    train['selected_text']=train['selected_text'].astype(str)\n    return train\n\ndef read_test():\n    test=pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\n    test['text']=test['text'].astype(str)\n    return test","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Model Building and training\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = read_train()\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing required modules\nimport nltk\n#nltk.download('punkt')\n#nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nimport re\n#nltk.download('words')\n#nltk.download('vader_lexicon')\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nfrom nltk.util import ngrams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Function to find 'selected_text'\n\nsid = SentimentIntensityAnalyzer()\ndef phrase(text, sentiment):\n  sentiment = sentiment[0:3]\n  sen_scores = sid.polarity_scores(text)\n  best_phrase, max_score = text, sen_scores[sentiment]\n  \n  for i in range (2,6):\n    n_grams = ngrams(nltk.word_tokenize(text), i)           ## generating n-grams\n    n_grams = [ ' '.join(grams) for grams in n_grams]\n    for ngram in n_grams:\n      #print(\"\\n\",ngram)\n      sen_scores = sid.polarity_scores(ngram)       ## for each n-gram calculate polarity score\n      if (sen_scores[sentiment] > max_score):\n          max_score = sen_scores[sentiment]       \n          best_phrase = ngram                       ## get the n-gram (phrase) that gives highest sentiment score for the given sentiment\n\n  return best_phrase","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.dropna(inplace=True)       ## eliminating the missing values from the data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Data Cleaning\n\nimport re, string\ndef clean_text(text):\n    text = str(text).lower()\n    #text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    \n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['text'] = train_df['text'].apply(clean_text)     ## apply the cleaning function on the 'text' column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\n\ntrain_df['predicted_phrase'] = np.vectorize(phrase)(train_df['text'], train_df['sentiment'])      ## get the predicted phrase for each pair of text, sentiment","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to find Jaccard Similarity Score\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['jaccard_score'] = np.vectorize(jaccard)(train_df['predicted_phrase'],train_df['selected_text'])     ## get the jaccard similarity score for the predicted phrases\n\ntrain_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df['jaccard_score'].mean(axis=0)      ## Acc = Avg(Jaccard scores) = ~35%","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predicting on Test data"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df = read_test()\ntest_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.dropna(inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df.sentiment.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['text'] = test_df['text'].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_df['selected_text'] = np.vectorize(phrase)(test_df['text'], test_df['sentiment'])\n\ntest_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = pd.DataFrame(test_df.iloc[:, [0,3]])\n\nfinal_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df.to_csv(\"submission.csv\", index=False)      ## save the final df to csv file","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}