{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Goal üéØ\n\n* To build text classification model and use SHAP value to **explain** sentiment \n* Use some sort of heuristic rules to select text\n\nMy idea is mostly sprouted from these discussions... so please make sure to check out these\n\n* https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139335\n* https://www.kaggle.com/c/tweet-sentiment-extraction/discussion/139803\n\n## Also referenced these awesome notebooks\n\n* https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model\n* https://towardsdatascience.com/explain-nlp-models-with-lime-shap-5c5a9f84d59b\n\n## Thoughs on number of models\n\nsince the goal of using classification model is **not about getting labels but rather getting interpretation labels**, we may want to consider \n\n* a model for prediction positive sentiment\n* a model for negative sentiment\n* for neutral sentiment, we use the original text (seems like a popular solution here)\n\n***üç© please upvote if you like this work,***\n\n#### Update\n\n* I added the model with word count and the shap value output seems make sense now. Not sure why TFIDF doesn't make much sense in the previous version.\n* Added LIME's solution\n\n***Note: This is currently a working solution, will keep updating the current solution üçï***","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Table of Contents\n\n[Feature engineering](#tag1)\n\n[Classification model](#tag2)\n\n[Improving model by hstack](#tag3)\n\n[Hyperparameter tuning](#tag4)\n\n[SHAP value](#tag5)\n\n[Heuristics for selecting texts 1](#tag6)\n\n[LIME value](#tag7)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Library\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport string\nimport numpy as np \nimport random\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom plotly import graph_objs as go\nimport plotly.express as px\nimport plotly.figure_factory as ff\nfrom collections import Counter\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n\nimport nltk\nfrom nltk.corpus import stopwords\n\nfrom tqdm import tqdm, tqdm_notebook\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split, KFold, StratifiedKFold,  cross_val_score\n\n# Libraries\nfrom scipy import stats\n#from scipy.sparse import hstack, csr_matrix\n#from sklearn.model_selection import train_test_split, KFold\n\n#import xgboost as xgb\n#from sklearn import model_selection\nfrom sklearn.metrics import accuracy_score\nimport json\n# import ast\n# import eli5\n# import shap\n#from catboost import CatBoostRegressor\nfrom urllib.request import urlopen\n# from PIL import Image\n#from sklearn.preprocessing import LabelEncoder\nimport time\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import linear_model\n\nfrom hyperopt import hp, tpe\nfrom hyperopt.fmin import fmin\n\n#from sklearn.model_selection import\n#from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer\n# import lightgbm as lgbm","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn import decomposition, ensemble\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing import text, sequence\nimport xgboost\nimport scipy","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shap","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.style.use('fivethirtyeight')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ndf_test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ndf_submission = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df_test.assign(selected_text=lambda x: x.text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#df_all.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='tag1'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Feature Engineering","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['selected_text'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train[df_train['text'].isna()]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.iloc[314]['text'] = 'None'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.iloc[314]['selected_text'] = 'None'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([df_train, df_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all[df_all.text.isna()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Target label encoding\n\nSince we are gonna build two separate models, we generate two list of labels","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.sentiment.unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Positive","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# encode the target variable\n# label encode the target variable \nencoder = preprocessing.LabelEncoder()\ntrain_y_POS = encoder.fit_transform(df_train.sentiment=='positive')\ntest_y_POS = encoder.fit_transform(df_test.sentiment=='positive')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.where(train_y_POS==1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.where(df_train.sentiment=='positive')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Negative","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train_y_NEG = encoder.fit_transform(df_train.sentiment=='negative')\ntest_y_NEG = encoder.fit_transform(df_test.sentiment=='negative')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### CountVectorizer","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.tokenize import TweetTokenizer\n# create a count vectorizer object \ntweet_token = TweetTokenizer(preserve_case=True, strip_handles=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#list(df_train['text'].fillna(\"\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train['text'].apply(lambda x: tweet_token.tokenize(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tweet_token_proces(x):\n    return tweet_token.tokenize(x)\ncount_vect = CountVectorizer(tokenizer=tweet_token_proces)\ncount_vect.fit(df_all['text']) ## fillna","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_index = count_vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# transform the training and validation data using count vectorizer object\nxtrain_count =  count_vect.transform(df_train.text)\nxtest_count =  count_vect.transform(df_test.text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### tf-idf\n\n* Word level\n* ngram level\n* character level","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ## tf idf\n\n# # word level tf-idf\n# tfidf_vect = TfidfVectorizer(tokenizer=tweet_token_proces, max_features=5000)\n# tfidf_vect.fit(df_all['text'].fillna(' '))\n# xtrain_tfidf =  tfidf_vect.transform(df_train.text.fillna(' '))\n# xtest_tfidf =  tfidf_vect.transform(df_test.text.fillna(' '))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # ngram level tf-idf \n# tfidf_vect_ngram = TfidfVectorizer(tokenizer=tweet_token_proces, ngram_range=(2,5), max_features=5000)\n# tfidf_vect_ngram.fit(df_all['text'].fillna(' '))\n# xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(df_train.text.fillna(' '))\n# xtest_tfidf_ngram =  tfidf_vect_ngram.transform(df_test.text.fillna(' '))\n\n# # characters level tf-idf\n# tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,5), max_features=5000)\n# tfidf_vect_ngram_chars.fit(df_all['text'].fillna(' '))\n# xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(df_train.text.fillna(' ')) \n# xtest_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(df_test.text.fillna(' ')) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### word embeddings","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# # load the pre-trained word-embedding vectors \n# embeddings_index = {}\n# for i, line in enumerate(open('../input/wiki-news-300d-1M.vec')):\n#     values = line.split()\n#     embeddings_index[values[0]] = np.asarray(values[1:], dtype='float32')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # create a tokenizer \n# # use keras.preprocessing.text\n# token = text.Tokenizer()\n# token.fit_on_texts(df_all['text'].fillna(' '))\n# word_index = token.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # convert text to sequence of tokens and pad them to ensure equal length vectors \n# train_seq_x = sequence.pad_sequences(token.texts_to_sequences(df_train.text.fillna(' ')), maxlen=70)\n# test_seq_x = sequence.pad_sequences(token.texts_to_sequences(df_test.text.fillna(' ')), maxlen=70)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # create token-embedding mapping\n# embedding_matrix = np.zeros((len(word_index) + 1, 300))\n# for word, i in word_index.items():\n#     embedding_vector = embeddings_index.get(word)\n#     if embedding_vector is not None:\n#         embedding_matrix[i] = embedding_vector","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### NLP based features ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train['text'] = df_train['text'].fillna('None')\n# df_test['text'] = df_test['text'].fillna('None')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train[df_train.text=='None']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_train['char_count'] = df_train['text'].apply(len)\n# df_test['char_count'] = df_test['text'].apply(len)\n\n# df_train['word_count'] = df_train['text'].apply(lambda x: len(x.split()))\n# df_test['word_count'] = df_test['text'].apply(lambda x: len(x.split()))\n\n# df_train['word_density'] = df_train['char_count'] / (df_train['word_count']+1)\n# df_test['word_density'] = df_test['char_count'] / (df_test['word_count']+1)\n\n# df_train['punctuation_count'] = df_train['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\n# df_test['punctuation_count'] = df_test['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) \n\n# df_train['title_word_count'] = df_train['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n# df_test['title_word_count'] = df_test['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.istitle()]))\n\n# df_train['upper_case_word_count'] = df_train['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))\n# df_test['upper_case_word_count'] = df_test['text'].apply(lambda x: len([wrd for wrd in x.split() if wrd.isupper()]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Special features for this challenge","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"## from the original notebook\n\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\nresults_jaccard=[]\n\nfor ind,row in df_train.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n    #print(ind)\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append(jaccard_score)\n\ndf_train['jaccard'] = results_jaccard\n\ndf_train['Num_words_ST'] = df_train['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ndf_train['Num_word_text'] = df_train['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ndf_train['difference_in_words'] = df_train['Num_word_text'] - df_train['Num_words_ST'] #Difference in Number of words text and Selected Text\n\nresults_jaccard=[]\n\nfor ind,row in df_test.iterrows():\n    sentence1 = row.text\n    sentence2 = row.selected_text\n\n    jaccard_score = jaccard(sentence1,sentence2)\n    results_jaccard.append(jaccard_score)\n\ndf_test['jaccard'] = results_jaccard\ndf_test['Num_words_ST'] = df_test['selected_text'].apply(lambda x:len(str(x).split())) #Number Of words in Selected Text\ndf_test['Num_word_text'] = df_test['text'].apply(lambda x:len(str(x).split())) #Number Of words in main text\ndf_test['difference_in_words'] = df_test['Num_word_text'] - df_test['Num_words_ST'] #Difference in Number of words text and Selected Text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.iloc[314]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='tag2'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Classification XGboost","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_model(classifier, feature_vector_train, label, feature_vector_test,  test_y,is_neural_net=False):\n    # fit the training dataset on the classifier\n    classifier.fit(feature_vector_train, label)\n    \n    # predict the labels on testation dataset\n    predictions = classifier.predict(feature_vector_test)\n    \n    if is_neural_net:\n        predictions = predictions.argmax(axis=-1)\n    \n    #return metrics.accuracy_score(predictions, test_y)\n    return metrics.accuracy_score(predictions, test_y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# Extereme Gradient Boosting on Count Vectors\n## Positive\naccuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y_POS, xtest_count.tocsc(), test_y_POS)\nprint(\"Xgb, Count Vectors POS: \", accuracy)\n## negative \naccuracy = train_model(xgboost.XGBClassifier(), xtrain_count.tocsc(), train_y_NEG, xtest_count.tocsc(), test_y_NEG)\nprint(\"Xgb, Count Vectors NEG: \", accuracy)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Extereme Gradient Boosting on Word Level TF IDF Vectors\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y_POS, xtest_tfidf.tocsc(), test_y_POS)\n# print(\"Xgb, WordLevel TF-IDF POS: \", accuracy)\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf.tocsc(), train_y_NEG, xtest_tfidf.tocsc(), test_y_NEG)\n# print(\"Xgb, WordLevel TF-IDF NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Extereme Gradient Boosting on ngram TF IDF Vectors\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(), train_y_POS, \\\n#                        xtest_tfidf_ngram.tocsc(), test_y_POS)\n# print(\"Xgb, ngram Vectors POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram.tocsc(), train_y_NEG, \\\n#                        xtest_tfidf_ngram.tocsc(), test_y_NEG)\n# print(\"Xgb, ngram Vectors NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Extereme Gradient Boosting on char level tfidf\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y_POS,\\\n#                        xtest_tfidf_ngram_chars.tocsc(), test_y_POS)\n# print(\"Xgb, CharLevel Vectors POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_ngram_chars.tocsc(), train_y_NEG, \\\n#                        xtest_tfidf_ngram_chars.tocsc(), test_y_NEG)\n# print(\"Xgb, CharLevel Vectors NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#type(train_seq_x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # Extereme Gradient Boosting on word embeddings\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), train_seq_x, train_y_POS,\\\n#                        test_seq_x, test_y_POS)\n# print(\"Xgb, word embedding POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), train_seq_x, train_y_NEG, \\\n#                        test_seq_x, test_y_NEG)\n# print(\"Xgb, word embedding NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='tag3'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## improve model by combining feature (hstack)\n\n","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"It seems that combining feature does imporve the model performance; although here the real question for ourself is :\n\n\n***should we prioritize building a better model or should we improve our heuristics? *** \n\nAdding too many additional feature also makes the interpretation of the model more complex; after few trial and error, we decided to use only word count feature, while not sacreficing too much performance reduction. ","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# ######### tfidf and word cout\n# xtrain_tfidf_wc = scipy.sparse.hstack((xtrain_tfidf, xtrain_count))\n# xtest_tfidf_wc = scipy.sparse.hstack((xtest_tfidf, xtest_count))\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_wc.tocsc(), train_y_POS, \\\n#                       xtest_tfidf_wc.tocsc(), test_y_POS)\n\n# print(\"POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_wc.tocsc(), train_y_NEG, \\\n#                       xtest_tfidf_wc.tocsc(), test_y_NEG)\n\n# print(\"NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ########### all tfidf features\n\n# xtrain_tfidf_all = scipy.sparse.hstack((xtrain_tfidf_ngram_chars, xtrain_tfidf, xtrain_tfidf_ngram))\n\n# xtest_tfidf_all = scipy.sparse.hstack((xtest_tfidf_ngram_chars, xtest_tfidf, xtest_tfidf_ngram))\n\n\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_all.tocsc(), train_y_POS, \\\n#                       xtest_tfidf_all.tocsc(), test_y_POS)\n\n# print(\"POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_all.tocsc(), train_y_NEG, \\\n#                       xtest_tfidf_all.tocsc(), test_y_NEG)\n\n# print(\"NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ###########  tfidf features with count\n\n# xtrain_tfidf_all_2 = scipy.sparse.hstack(( xtrain_tfidf, xtrain_tfidf_ngram, xtrain_count))\n\n# xtest_tfidf_all_2 = scipy.sparse.hstack(( xtest_tfidf, xtest_tfidf_ngram, xtest_count))\n\n\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_all_2.tocsc(), train_y_POS, \\\n#                       xtest_tfidf_all_2.tocsc(), test_y_POS)\n\n# print(\"POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_all_2.tocsc(), train_y_NEG, \\\n#                       xtest_tfidf_all_2.tocsc(), test_y_NEG)\n\n# print(\"NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ###########  tfidf features with count\n\n# xtrain_tfidf_all_3 = scipy.sparse.hstack(( xtrain_tfidf, xtrain_tfidf_ngram))\n\n# xtest_tfidf_all_3 = scipy.sparse.hstack(( xtest_tfidf, xtest_tfidf_ngram))\n\n\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_all_3.tocsc(), train_y_POS, \\\n#                       xtest_tfidf_all_3.tocsc(), test_y_POS)\n\n# print(\"POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_all_3.tocsc(), train_y_NEG, \\\n#                       xtest_tfidf_all_3.tocsc(), test_y_NEG)\n\n# print(\"NEG: \", accuracy)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# ########### tfidf nlp wc\n# nlp_features = ['char_count', 'word_count', 'word_density', \\\n#                 'punctuation_count', 'title_word_count','upper_case_word_count']\n# xtrain_tfidf_wc_nlp = scipy.sparse.hstack((xtrain_tfidf, xtrain_count, df_train[nlp_features]))\n# xtest_tfidf_wc_nlp = scipy.sparse.hstack((xtest_tfidf, xtest_count, df_test[nlp_features]))\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_wc_nlp.tocsc(), train_y_POS, \\\n#                       xtest_tfidf_wc_nlp.tocsc(), test_y_POS)\n\n# print(\"POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_wc_nlp.tocsc(), train_y_NEG, \\\n#                       xtest_tfidf_wc_nlp.tocsc(), test_y_NEG)\n\n# print(\"NEG: \", accuracy)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"######### tfidf wc special\n\n# xtrain_tfidf_wc_special = scipy.sparse.hstack((xtrain_tfidf, xtrain_count, df_train[special_features]))\n# xtest_tfidf_wc_special = scipy.sparse.hstack((xtest_tfidf, xtest_count, df_test[special_features]))\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_wc_special.tocsc(), train_y_POS, \\\n#                       xtest_tfidf_wc_special.tocsc(), test_y_POS)\n\n# print(\"POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_tfidf_wc_special.tocsc(), train_y_NEG, \\\n#                       xtest_tfidf_wc_special.tocsc(), test_y_NEG)\n\n# print(\"NEG: \", accuracy)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"########## mash up all features together\n\n# xtrain_all = scipy.sparse.hstack((xtrain_tfidf, xtrain_count, df_train[special_features + nlp_features]))\n# xtest_all = scipy.sparse.hstack((xtest_tfidf, xtest_count, df_test[special_features + nlp_features]))\n\n# ## POS\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_all.tocsc(), train_y_POS, \\\n#                       xtest_all.tocsc(), test_y_POS)\n\n# print(\"POS: \", accuracy)\n\n# ## NEG\n# accuracy = train_model(xgboost.XGBClassifier(), xtrain_all.tocsc(), train_y_NEG, \\\n#                       xtest_all.tocsc(), test_y_NEG)\n\n# print(\"NEG: \", accuracy)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='tag4'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Hyperparameter optimization","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"[see this documentation for f1 multiclass](https://scikit-learn.org/stable/modules/model_evaluation.html)","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"#### Positive tag","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"baseline = xgboost.XGBClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_baseline = baseline.fit(X=xtrain_count, y=train_y_POS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_baseline.get_params()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def objective(params):\n    params = {\n        'max_depth': int(params['max_depth']),\n        'gamma': \"{:.3f}\".format(params['gamma']),\n        'subsample': \"{:.2f}\".format(params['subsample']),\n        'reg_alpha': \"{:.3f}\".format(params['reg_alpha']),\n        'reg_lambda': \"{:.3f}\".format(params['reg_lambda']),\n        'learning_rate': \"{:.3f}\".format(params['learning_rate']),\n        'num_leaves': '{:.3f}'.format(params['num_leaves']),\n        'colsample_bytree': '{:.3f}'.format(params['colsample_bytree']),\n        'min_child_samples': '{:.3f}'.format(params['min_child_samples']),\n        'feature_fraction': '{:.3f}'.format(params['feature_fraction']),\n        'bagging_fraction': '{:.3f}'.format(params['bagging_fraction'])\n    }\n    \n    clf = xgboost.XGBClassifier(\n        n_estimators=100,\n        #learning_rate=0.1,\n        n_jobs=4,\n        \n        **params\n    )\n    \n    score = cross_val_score(clf, xtrain_count, train_y_POS, scoring='accuracy', cv=KFold(n_splits=5)).mean()\n    print(\"accuracy {:.3f} params {}\".format(score, params))\n    return -score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## code here is mostly borrowed from here: https://www.kaggle.com/kabure/extensive-eda-and-modeling-xgb-hyperopt\nspace = {\n    # The maximum depth of a tree, same as GBM.\n    # Used to control over-fitting as higher depth will allow model \n    # to learn relations very specific to a particular sample.\n    # Should be tuned using CV.\n    # Typical values: 3-10\n    'max_depth': hp.quniform('max_depth', 3, 6, 1),\n    \n    # reg_alpha: L1 regularization term. L1 regularization encourages sparsity \n    # (meaning pulling weights to 0). It can be more useful when the objective\n    # is logistic regression since you might need help with feature selection.\n    'reg_alpha':  hp.uniform('reg_alpha', 0.01, 0.4),\n    \n    # reg_lambda: L2 regularization term. L2 encourages smaller weights, this\n    # approach can be more useful in tree-models where zeroing \n    # features might not make much sense.\n    'reg_lambda': hp.uniform('reg_lambda', 0.01, .4),\n    \n    # eta: Analogous to learning rate in GBM\n    # Makes the model more robust by shrinking the weights on each step\n    # Typical final values to be used: 0.01-0.2\n    'learning_rate': hp.uniform('learning_rate', 0.01, 0.2),\n    \n    # colsample_bytree: Similar to max_features in GBM. Denotes the \n    # fraction of columns to be randomly samples for each tree.\n    # Typical values: 0.5-1\n    'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n    \n    # A node is split only when the resulting split gives a positive\n    # reduction in the loss function. Gamma specifies the \n    # minimum loss reduction required to make a split.\n    # Makes the algorithm conservative. The values can vary depending on the loss function and should be tuned.\n    'gamma': hp.uniform('gamma', 0.01, .7),\n    \n    # more increases accuracy, but may lead to overfitting.\n    # num_leaves: the number of leaf nodes to use. Having a large number \n    # of leaves will improve accuracy, but will also lead to overfitting.\n    'num_leaves': hp.choice('num_leaves', list(range(20, 250, 10))),\n    \n    # specifies the minimum samples per leaf node.\n    # the minimum number of samples (data) to group into a leaf. \n    # The parameter can greatly assist with overfitting: larger sample\n    # sizes per leaf will reduce overfitting (but may lead to under-fitting).\n    'min_child_samples': hp.choice('min_child_samples', list(range(100, 250, 10))),\n    \n    # subsample: represents a fraction of the rows (observations) to be \n    # considered when building each subtree. Tianqi Chen and Carlos Guestrin\n    # in their paper A Scalable Tree Boosting System recommend \n    'subsample': hp.choice('subsample', [0.2, 0.4, 0.5, 0.6, 0.7, .8, .9]),\n    \n    # randomly select a fraction of the features.\n    # feature_fraction: controls the subsampling of features used\n    # for training (as opposed to subsampling the actual training data in \n    # the case of bagging). Smaller fractions reduce overfitting.\n    'feature_fraction': hp.uniform('feature_fraction', 0.8, .9),\n    \n    # randomly bag or subsample training data.\n    'bagging_fraction': hp.uniform('bagging_fraction', 0.8, .9)\n    \n    # bagging_fraction and bagging_freq: enables bagging (subsampling) \n    # of the training data. Both values need to be set for bagging to be used.\n    # The frequency controls how often (iteration) bagging is used. Smaller\n    # fractions and frequencies reduce overfitting.\n}","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":true},"cell_type":"code","source":"%%time\n# this steps takes at least 20mins\n# best = fmin(fn=objective,\n#             space=space,\n#             algo=tpe.suggest, max_evals=30) ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Now use one set of parameters from this","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"best = {'bagging_fraction': 0.8768575337571937,\n 'colsample_bytree': 0.9933592930641432,\n 'feature_fraction': 0.816825176108506,\n 'gamma': 0.05587328363633812,\n 'learning_rate': 0.19879098664834996,\n 'max_depth': 6.0,\n 'min_child_samples': 9,\n 'num_leaves': 7,\n 'reg_alpha': 0.11806338517600543,\n 'reg_lambda': 0.23269341544465222,\n 'subsample': 0.6}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"best['max_depth'] = 6\nbest['subsample'] = .6","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#params = {'max_depth': 5, 'gamma': '0.332', 'subsample': '0.80', 'reg_alpha': '0.365', 'reg_lambda': '0.070', 'learning_rate': '0.200', 'num_leaves': '150.000', 'colsample_bytree': '0.792', 'min_child_samples': '120.000', 'feature_fraction': '0.710', 'bagging_fraction': '0.436'}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"params = best\n#params['max_depth'] = 6\n#params['subsample'] = .9","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb = xgboost.XGBClassifier(**params, n_estimators=100,\n        #learning_rate=0.05,\n        n_jobs=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## POSITIVE\nxgb_fit_POS = xgb.fit(xtrain_count.tocsc(), train_y_POS)\n\npredictions = xgb_fit_POS.predict(xtest_count.tocsc())\n\nmetrics.accuracy_score(predictions, test_y_POS) ## improved from 0.816","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## NEGATIVE\nxgb_neg = xgboost.XGBClassifier(**params, n_estimators=100,\n        #learning_rate=0.05,\n        n_jobs=4)\nxgb_fit_NEG = xgb_neg.fit(xtrain_count.tocsc(), train_y_NEG)\npredictions = xgb_fit_NEG.predict(xtest_count.tocsc())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.accuracy_score(predictions, test_y_NEG)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"<a id='tag5'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## SHAP value","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xtrain_all_dense = pd.DataFrame(xtrain_count.tocsc().todense())\nxtrain_all_dense.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"column_index = count_vect.get_feature_names()\nlen(column_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"By inspecting the shap value by each observation, we find that *** words with positive sentiment tend to have higher shap value, and vice versa***; since positive words are trying to push the target value to the positive side, vice versa.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.initjs()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#xgb_fit_POS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#import shap\nexplainer = shap.TreeExplainer(xgb_fit_POS)\nshap_values = explainer.shap_values(xtrain_all_dense)\n\n# visualize the first prediction's explanation (use matplotlib=True to avoid Javascript)\nshap.force_plot(explainer.expected_value, shap_values[1,:],\\\n                xtrain_all_dense.iloc[1,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Positive words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_index[10248], column_index[8282]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(shap_values[:, 10248]), np.mean(shap_values[:, 8282])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap_values.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"shap.force_plot(explainer.expected_value, shap_values[9011,:],\\\n                xtrain_all_dense.iloc[9011,:])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Negative words","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"column_index[4898], column_index[7229]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"np.mean(shap_values[:, 4898]), np.mean(shap_values[:, 7229])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we want to map out all the words in text that has an index in our shap value columns","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_word_index(x):\n    result = []\n    for i in x.split(' '):\n        try:\n            #current_word = wordnet_lemmatizer.lemmatize(i.lower())\n            result.append(column_index.index(i))\n        except ValueError:\n            pass\n            #result.append(-1)\n    return result\n\ndef get_word(x):\n    result = []\n    for i in x.split(' '):\n        try:\n            #current_word = wordnet_lemmatizer.lemmatize(i.lower())\n            column_index.index(i)\n            result.append(i)\n        except ValueError:\n            pass\n            #result.append('None')\n           \n    return result","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"column_index.index('making')","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['text_word_index'] = df_train.text.apply(lambda x: get_word_index(x))\ndf_train['text_word_has_index'] = df_train.text.apply(lambda x: get_word(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## now apply the same for selected text\ndf_train['selected_text_word_index'] = df_train.selected_text.apply(lambda x: get_word_index(x))\ndf_train['selected_text_word_has_index'] = df_train.selected_text.apply(lambda x: get_word(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## now map all the text for each words with shap value\nshap_extracted = []\n\n\nfor i in np.arange(len(df_train)):\n    shap_extracted.append(shap_values[i, df_train['text_word_index'][i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"shap_extracted_mean = [np.mean(i) for i in shap_extracted]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"## now do the same for selected text\nselected_shap_extracted = []\nfor i in np.arange(len(df_train)):\n    selected_shap_extracted.append(shap_values[i, df_train['selected_text_word_index'][i]])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"selected_shap_extracted_mean = [np.mean(i) for i in selected_shap_extracted]","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['shap_extracted'] = shap_extracted","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['shap_extracted_mean'] = shap_extracted_mean\ndf_train['selected_shap_extracted_mean'] = selected_shap_extracted_mean","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"*** Now let's look at the mean shap value by sentiment ***","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.stripplot(df_train.shap_extracted_mean,df_train.sentiment, jitter=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Here, the shap value is smaller for negative sentiment tweets; and positive words tend to have positive shap values. Now let us look at the words in the selected text. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.stripplot(df_train.selected_shap_extracted_mean, df_train.sentiment,jitter=True )","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"concat_pd = pd.concat([df_train[df_train.sentiment=='positive']['shap_extracted_mean'],\\\n           df_train[df_train.sentiment=='positive']['selected_shap_extracted_mean']])\n\nconcat_pd = pd.DataFrame(concat_pd).reset_index()\nconcat_pd['text'] = 'text'\nconcat_pd.columns = ['index', 'mean', 'text']\nconcat_pd.loc[8582:, 'text'] = 'selected_text'","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"sns.stripplot(concat_pd['mean'], concat_pd.text)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This plot gives us some hint on how to find out the selected text by SHAP value; selected text tend to have smaller values. ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train['mean_diff'] = df_train.selected_shap_extracted_mean - df_train.shap_extracted_mean","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"#df_train.mean_diff.hist(bins=30)\nsns.kdeplot(df_train[df_train['sentiment']=='positive']['mean_diff'], shade=True, color=\"b\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"plt.figure(figsize=(12,6))\np1=sns.kdeplot(df_train[df_train['sentiment']=='positive']['shap_extracted_mean'], shade=True, color=\"r\")\\\n.set_title('Kernel Distribution of SHAP values (raw text vs selected text)')\np1=sns.kdeplot(df_train[df_train['sentiment']=='positive']['selected_shap_extracted_mean'], shade=True, color=\"b\")\nplt.vlines(x=-0.15, ymax=7, ymin=0, linestyles='dashed' )\nplt.vlines(x=0.01, ymax=7, ymin=0, linestyles='dashed')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Interestingly, we see that **selected word tend to have more extreme shape value than the original text**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"To summeraize the density distribution of SHAP value from text and seleted text: \n\n* Seleted text has a thicker (left and right) tail than raw text","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='tag6'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Heuristic 1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Here we are trying to use ***Jaccard similarity*** between predicted selected text and selected text to find out a good cutoff for the shap value.\n\nThere are several steps:\n\n* Loop through a range of values, and find two cutoffs\n* Find out the indices of words that mets the criteria for shap values\n* Selected the text based on the indices\n* Calculate jaccard similarity of predicted selected text and true selected text","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Best cutoff: SHAP value < -0.4125 , and SHAP Value >  0.5","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# uncomment it if you want to run it","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"# def shap_cutoff_2(cutoff1, cutoff2, x):\n#     '''\n#     input: cutoff for shap value and x is the extracted shap value\n#     output: a tuple with indices for text selection\n#     '''\n#     try: \n#         min_idx_1 = np.where(x == np.min([i for i in x if i < cutoff1]))[0][0]\n#         max_idx_1 = np.where(x==np.max([i for i in x if i < cutoff1]))[0][0]\n#         min_idx_2 = np.where(x == np.min([i for i in x if i > cutoff2]))[0][0]\n#         max_idx_2 = np.where(x==np.max([i for i in x if i > cutoff2]))[0][0]\n        \n#         return (min_idx_1, max_idx_1, min_idx_2, max_idx_2)\n#     except:\n#         # if x is empty, then return an impossivle value\n#         return (100, 100, 100, 100)\n    \n# def jaccard(str1, str2): \n#     a = set(str1.lower().split()) \n#     b = set(str2.lower().split())\n#     c = a.intersection(b)\n#     return float(len(c)) / (len(a) + len(b) - len(c))\n\n# #for c1, c2 in zip(np.linspace(-.5, -0.01, 15), np.linspace(0.01, 0.5, 15)):\n#     ## use a cutoff to find word indices \n# for c1 in np.linspace(-.5, -.3, 5):\n#     for c2 in np.linspace(0.5, 0.6, 2):\n#         df_train['shap_cutoff_2'] = df_train.shap_extracted.apply(lambda x: shap_cutoff_2(c1,c2, x))\n#         partial_text=[]\n#         # get selected text\n#         for i,row in df_train.iterrows():\n#             if row.shap_cutoff_2== (100, 100, 100, 100):\n#                 partial_text.append(row.text.split(' '))\n#             else:\n#                 min_idx = np.min(row.shap_cutoff_2)\n#                 max_idx = np.max(row.shap_cutoff_2) + 1\n#                 partial_text.append(row.text_word_has_index[min_idx: max_idx])\n\n#         soln_sentence = [' '.join(i) for i in partial_text]\n#         df_train['selected_soln_1'] = soln_sentence\n\n#         # calculate jaccard\n#         results_jaccard=[]\n\n#         for ind,row in df_train.iterrows():\n#             sentence1 = row.selected_text\n#             sentence2 = row.selected_soln_1\n#             #print(ind)\n#             jaccard_score = jaccard(sentence1,sentence2)\n#             results_jaccard.append(jaccard_score)\n#         df_train['results_jaccard'] = results_jaccard\n\n#         print('cutoff: ', c1, ', ', c2)\n#         print('mean jaccard: ',df_train[df_train.sentiment=='positive'].results_jaccard.mean())\n#         sns.kdeplot(df_train[df_train['sentiment']=='positive']['results_jaccard'], shade=True, color=\"b\")\n#         plt.show()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The performance of SHAP value doesn't seem to be satisfying. We have to try something else to make accurate prediction.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"<a id='tag7'></a>","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## LIME","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"import numpy as np\nfrom scipy.spatial import distance\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.pipeline import Pipeline, make_pipeline\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"from sklearn.svm import SVC","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"import lime\nimport lime.lime_tabular\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"df_train[df_train.sentiment=='positive'][:10].index","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"count_vect = CountVectorizer(tokenizer=tweet_token_proces)\ngrad_boost = GradientBoostingClassifier(max_depth=6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe = make_pipeline(count_vect, grad_boost)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.fit(df_train.text, train_y_POS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"pipe.score(df_test.text, test_y_POS)","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"\n\nfrom lime.lime_text import LimeTextExplainer\nexplainer = LimeTextExplainer(class_names=['nonPOS', 'POS'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"idx = [6, 9, 11, 21, 25, 28, 30, 31, 33, 39, 27474]","execution_count":null,"outputs":[]},{"metadata":{"scrolled":false,"trusted":false},"cell_type":"code","source":"for i in idx:\n    exp = explainer.explain_instance(df_train.text[i], pipe.predict_proba)\n    print(df_train.selected_text.values[i])\n    exp.show_in_notebook()\n    ","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This short analysis gave us some heuristics to label the selected text; we can use a hard thresold based on the probability we get from the model.","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"exp.as_list()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"column_index = count_vect.get_feature_names()","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"# threshould = .07\n# select_text_list = []\n# for i in tqdm_notebook(range(len(df_train))):\n#     row = df_train.iloc[i]\n#     if row.sentiment=='positive':\n#         try:\n#             exp = explainer.explain_instance(row.text, pipe.predict_proba).as_list()\n#             exp_words =[k[0] for k in exp if k[1] > threshould]\n#             text_list = tweet_token_proces(row.text)\n#             idx = [text_list.index(k) for k in exp_words]\n#             if len(idx) < 1:\n#                 select_text_list.append([])\n#             if len(idx) ==1:\n#                 select_text_list.append(exp_words[0])\n#             else:\n\n#                 max_idx = max(idx)\n#                 min_idx = min(idx)\n#                 cur_text = text_list[min_idx:max_idx]\n#                     #cur_text_processed = [i if i.isalpha() else i + ' ' for i in cur_text]\n#                     #print(' '.join(cur_text))\n#                 select_text_list.append(cur_text)\n#         except:\n#             select_text_list.append([])\n#     else:\n#         select_text_list.append([])","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## TODO","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"* Adding selection methods for LIME ","execution_count":null},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":false},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}