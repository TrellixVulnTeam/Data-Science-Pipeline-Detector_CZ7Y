{"cells":[{"metadata":{"_uuid":"1543e09d-9a50-485a-ad2b-ec210679766f","_cell_guid":"368084b1-ff9e-4027-887c-f1b8e7220396","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"e22d630a-a3bf-4f63-ad27-c6a7dbe1af52","_cell_guid":"bf33d8b3-441e-49b7-94a1-f26f3e5341de","trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np\nimport tensorflow as tf\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import StratifiedKFold\nfrom transformers import *\nimport tokenizers\nprint('TF version',tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f390bbac-ca2b-4164-9179-a6ef09011188","_cell_guid":"1d482a55-83b5-41d9-9268-b0cb3f2987cb","trusted":true},"cell_type":"code","source":"# Pretrained model of roberta\nPATH = '../input/tf-roberta/'\ntokenizer = tokenizers.ByteLevelBPETokenizer(\n    vocab_file=PATH+'vocab-roberta-base.json', \n    merges_file=PATH+'merges-roberta-base.txt', \n    lowercase=True,\n    add_prefix_space=True\n)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4e3c019e-f86c-425e-9113-aed76812c10b","_cell_guid":"3532f004-4087-440c-8cda-c8b6c7e85971","trusted":true},"cell_type":"code","source":"import pandas as pd\ndef read_train():\n    train=pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\n    train['text']=train['text'].astype(str)\n    train['selected_text']=train['selected_text'].astype(str)\n    return train\n\ndef read_test():\n    test=pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\n    test['text']=test['text'].astype(str)\n    return test\n\ndef read_submission():\n    test=pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')\n    return test\n    \ntrain_df = read_train()\ntest_df = read_test()\nsubmission_df = read_submission()\n\ntest_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"52713847-6add-426c-9970-073d9d322fe8","_cell_guid":"11bcf619-2d51-4bf5-ad8c-f67b10346253","trusted":true},"cell_type":"code","source":"def jaccard(str1, str2): \n    a = set(str(str1).lower().split()) \n    b = set(str(str2).lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"1fb49ba0-6912-49ff-aebd-95050504325d","_cell_guid":"e1b9bea6-da62-4715-8797-786fb739cfd6","trusted":true},"cell_type":"code","source":"MAX_LEN = 96\n\n# Setup the dataset of a specific size, this is for properly training the test dataset.\n\nct = train_df.shape[0]\ninput_ids = np.ones((ct,MAX_LEN),dtype='int32')\nattention_mask = np.zeros((ct,MAX_LEN),dtype='int32')\ntoken_type_ids = np.zeros((ct,MAX_LEN),dtype='int32')\nstart_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\nend_tokens = np.zeros((ct,MAX_LEN),dtype='int32')\n\n# Sentiment ID value is encoded from tokenizer\nsentiment_id = {'positive': 1313, 'negative': 2430, 'neutral': 7974}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"efb22c36-f1c8-4f0d-8121-3815c13f0ecb","_cell_guid":"8ed39053-6b64-470e-a3eb-e59e1db9cf07","trusted":true},"cell_type":"code","source":"for k in range(train_df.shape[0]):\n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(train_df.loc[k,'text'].split())\n    text2 = \" \".join(train_df.loc[k,'selected_text'].split())\n    idx = text1.find(text2)\n    \n    chars = np.zeros((len(text1)))\n    chars[idx:idx+len(text2)]=1\n    if text1[idx-1]==' ': chars[idx-1] = 1 \n    enc = tokenizer.encode(text1)\n\n\n    # ID_OFFSETS\n    offsets = []; idx=0\n    for t in enc.ids:\n        w = tokenizer.decode([t])\n        offsets.append((idx,idx+len(w)))\n        idx += len(w)\n        \n    # START END TOKENS\n    toks = []\n    for i,(a,b) in enumerate(offsets):\n        sm = np.sum(chars[a:b])\n        if sm>0: toks.append(i) \n            \n    s_tok = sentiment_id[train_df.loc[k,'sentiment']]\n    input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    attention_mask[k,:len(enc.ids)+5] = 1\n    if len(toks)>0:\n        start_tokens[k,toks[0]+1] = 1\n        end_tokens[k,toks[-1]+1] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cb067cc6-759a-4fab-b66b-134e3859b6b9","_cell_guid":"9483563c-d560-47e7-a7bd-699278aafb13","trusted":true},"cell_type":"code","source":"MAX_LEN = 96\n\n# Setup the dataset of a specific size, this is for properly training the test dataset.\n\nct_test = test_df.shape[0]\ntest_input_ids = np.ones((ct_test,MAX_LEN),dtype='int32')\ntest_attention_mask = np.zeros((ct_test,MAX_LEN),dtype='int32')\ntest_token_type_ids = np.zeros((ct_test,MAX_LEN),dtype='int32')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3749d4f1-87d8-4b66-9a35-3c2d717a9b81","_cell_guid":"efebde49-7954-4177-8493-91a61e5c6d0a","trusted":true},"cell_type":"code","source":"for k in range(test_df.shape[0]):\n    # FIND OVERLAP\n    text1 = \" \"+\" \".join(test_df.loc[k,'text'].split())\n    enc = tokenizer.encode(text1)\n    \n    s_tok = sentiment_id[train_df.loc[k,'sentiment']]\n    test_input_ids[k,:len(enc.ids)+5] = [0] + enc.ids + [2,2] + [s_tok] + [2]\n    test_attention_mask[k,:len(enc.ids)+5] = 1","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"18e79800-da33-4873-9ca9-b95ca99e760c","_cell_guid":"9f147dba-385c-4c7b-91f9-534b15cf404f","trusted":true},"cell_type":"code","source":"ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\natt = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\ntok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n\nconfig = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\nbert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\nx = bert_model(ids,attention_mask=att,token_type_ids=tok)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"f8029b1b-4edc-4abd-a540-1b0f330a99d7","_cell_guid":"c354eac6-f78b-4129-b7c3-f0444da6eade","trusted":true},"cell_type":"code","source":"def build_model():\n    ids = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    att = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n    tok = tf.keras.layers.Input((MAX_LEN,), dtype=tf.int32)\n\n    config = RobertaConfig.from_pretrained(PATH+'config-roberta-base.json')\n    bert_model = TFRobertaModel.from_pretrained(PATH+'pretrained-roberta-base.h5',config=config)\n    x = bert_model(ids,attention_mask=att,token_type_ids=tok)\n    \n    \n    x1 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x1 = tf.keras.layers.Conv1D(128, 2,padding='same')(x1)\n    x1 = tf.keras.layers.LeakyReLU()(x1)\n    x1 = tf.keras.layers.Conv1D(64, 2,padding='same')(x1)\n    x1 = tf.keras.layers.Dense(1)(x1)\n    x1 = tf.keras.layers.Flatten()(x1)\n    x1 = tf.keras.layers.Activation('softmax')(x1)\n    \n    x2 = tf.keras.layers.Dropout(0.1)(x[0]) \n    x2 = tf.keras.layers.Conv1D(128, 2, padding='same')(x2)\n    x2 = tf.keras.layers.LeakyReLU()(x2)\n    x2 = tf.keras.layers.Conv1D(64, 2, padding='same')(x2)\n    x2 = tf.keras.layers.Dense(1)(x2)\n    x2 = tf.keras.layers.Flatten()(x2)\n    x2 = tf.keras.layers.Activation('softmax')(x2)\n\n    model = tf.keras.models.Model(inputs=[ids, att, tok], outputs=[x1,x2])\n    optimizer = tf.keras.optimizers.Adam(learning_rate=3e-5)\n    model.compile(loss='binary_crossentropy', optimizer=optimizer)\n\n    return model","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"7df0e437-830e-4e40-8e54-2b160d435b5f","_cell_guid":"016b132b-4f9e-4bf6-8717-429722f08377","trusted":true},"cell_type":"code","source":"jac = []; VER='v0'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\noof_start = np.zeros((input_ids.shape[0],MAX_LEN))                  # this is the out of fold perediction\noof_end = np.zeros((input_ids.shape[0],MAX_LEN))\npreds_start = np.zeros((test_input_ids.shape[0],MAX_LEN))              # this is the prediction for the test data set\npreds_end = np.zeros((test_input_ids.shape[0],MAX_LEN))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"984b5e2e-7206-4288-9236-0ede49e82606","_cell_guid":"feea9834-fa3b-421b-a127-9cbd70d94736","trusted":true},"cell_type":"code","source":"def scheduler(epoch):\n    return 3e-5 * 0.2**epoch\n\njac = []; VER='v4'; DISPLAY=1 # USE display=1 FOR INTERACTIVE\noof_start = np.zeros((input_ids.shape[0],MAX_LEN))\noof_end = np.zeros((input_ids.shape[0],MAX_LEN))\n\nn_splits = 5\nskf = StratifiedKFold(n_splits=n_splits,shuffle=True,random_state=777)\nfor fold,(idxT,idxV) in enumerate(skf.split(input_ids,train_df.sentiment.values)):\n\n    print('#'*25)\n    print('### FOLD %i'%(fold+1))\n    print('#'*25)\n    \n    K.clear_session()\n    model = build_model()\n        \n    reduce_lr = tf.keras.callbacks.LearningRateScheduler(scheduler)\n\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        '%s-roberta-%i.h5'%(VER,fold), monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='auto', save_freq='epoch')\n        \n    hist = model.fit([input_ids[idxT,], attention_mask[idxT,], token_type_ids[idxT,]], [start_tokens[idxT,], end_tokens[idxT,]], \n        epochs=5, batch_size=8, verbose=DISPLAY, callbacks=[sv, reduce_lr],\n        validation_data=([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]], \n        [start_tokens[idxV,], end_tokens[idxV,]]))\n    \n    print('Loading model...')\n    model.load_weights('%s-roberta-%i.h5'%(VER,fold))\n    \n    print('Predicting OOF...')\n    oof_start[idxV,],oof_end[idxV,] = model.predict([input_ids[idxV,],attention_mask[idxV,],token_type_ids[idxV,]],verbose=DISPLAY)\n    \n    # DISPLAY FOLD JACCARD\n    all = []\n    for k in idxV:\n        a = np.argmax(oof_start[k,])\n        b = np.argmax(oof_end[k,])\n        if a>b: \n            st = train_df.loc[k,'text'] # IMPROVE CV/LB with better choice here\n        else:\n            text1 = \" \"+\" \".join(train_df.loc[k,'text'].split())\n            enc = tokenizer.encode(text1)\n            st = tokenizer.decode(enc.ids[a-1:b])\n        all.append(jaccard(st,train_df.loc[k,'selected_text']))\n    jac.append(np.mean(all))\n    print('>>>> FOLD %i Jaccard ='%(fold+1),np.mean(all))\n    print() ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"91567ffa-fd5d-41e1-a8c6-1040938acbf8","_cell_guid":"2d5795a4-5197-4d70-9796-e5578e7fdbac","trusted":true},"cell_type":"code","source":"preds_start = np.zeros((test_input_ids.shape[0],MAX_LEN))\npreds_end = np.zeros((test_input_ids.shape[0],MAX_LEN))\nDISPLAY=1\nfor i in range(5):\n    print('#'*25)\n    print('### MODEL %i'%(i+1))\n    print('#'*25)\n    \n    K.clear_session()\n    model = build_model()\n    model.load_weights('/kaggle/working/v4-roberta-%i.h5'%i)\n\n    print('Predicting Test...')\n    preds = model.predict([test_input_ids,test_attention_mask,test_token_type_ids],verbose=DISPLAY)\n    preds_start += preds[0]/n_splits\n    preds_end += preds[1]/n_splits","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fde5dece-9f28-498f-9a13-e9a67fc3b8b0","_cell_guid":"0a2df638-514f-47f9-a57c-90380cc3ed54","trusted":true},"cell_type":"code","source":"all = []\nfor k in range(test_df.shape[0]):\n    a = np.argmax(preds_start[k,])\n    b = np.argmax(preds_end[k,])\n    if a>b: \n        st = test_df.loc[k,'text']\n    else:\n        text1 = \" \"+\" \".join(test_df.loc[k,'text'].split())\n        enc = tokenizer.encode(text1)\n        st = tokenizer.decode(enc.ids[a-1:b])\n    all.append(st)\nprint(all)    ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3df5f423-eb7c-49f8-9ee8-5633488e6740","_cell_guid":"b58e4d15-85e4-4454-85bc-57721e3d8ace","trusted":true},"cell_type":"code","source":"test_df['selected_text'] = all\ntest_df[['textID','selected_text']].to_csv('submission.csv',index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}