{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nfrom collections import Counter\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport re\nimport string\n\npd.options.display.max_columns = None\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load data","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"path = \"/kaggle/input/tweet-sentiment-extraction\"\n\ntrain = pd.read_csv(os.path.join(path, \"train.csv\"))\ntest = pd.read_csv(os.path.join(path, \"test.csv\"))\nsample_submission = pd.read_csv(os.path.join(path, \"sample_submission.csv\"))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Check data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_submission.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## EDA","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='darkgrid')\n\nsns.countplot(data=train, x='sentiment', color=\"b\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.set(style='darkgrid')\n\nsns.countplot(data=test, x='sentiment', color=\"b\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntop = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(6, 15))\n\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"count\", y=\"Common_words\", data=temp,\n            label=\"Count\", color=\"b\")\n\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, temp[\"count\"].max()), ylabel=\"\")\nsns.despine(left=True, bottom=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Cleaning data\n\n","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def remove_stopword(text):\n    return [w for w in text if not w in stop]\n\ndef clean_text(text):\n    text = str(text).lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['text'] = train['text'].apply(lambda x:clean_text(x))\ntrain['selected_text'] = train['selected_text'].apply(lambda x:clean_text(x))\ntrain.drop(columns=\"temp_list\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['temp_list'] = train['selected_text'].apply(lambda x:str(x).split())\ntrain['temp_list'] = train['temp_list'].apply(lambda x:remove_stopword(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"top = Counter([item for sublist in train['temp_list'] for item in sublist])\ntemp = pd.DataFrame(top.most_common(20))\ntemp.columns = ['Common_words','count']\ntemp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"f, ax = plt.subplots(figsize=(6, 15))\n\nsns.set_color_codes(\"pastel\")\nsns.barplot(x=\"count\", y=\"Common_words\", data=temp,\n            label=\"Count\", color=\"b\")\n\nax.legend(ncol=2, loc=\"lower right\", frameon=True)\nax.set(xlim=(0, temp[\"count\"].max()), ylabel=\"\")\nsns.despine(left=True, bottom=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Separate dataframe by sentiment","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_train = train[train[\"sentiment\"]==\"positive\"]\nnegative_train = train[train[\"sentiment\"]==\"negative\"]\nneutral_train = train[train[\"sentiment\"]==\"neutral\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def tokenizeandstopwords(text):\n    tokens = nltk.word_tokenize(text)\n    token_words = [w for w in tokens if w.isalpha()]\n    meaningful_words = [w for w in token_words if not w in stop]\n    joined_words = ( \" \".join(meaningful_words))\n    return joined_words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_train[\"selected_text\"] = positive_train[\"selected_text\"].apply(clean_text)\nnegative_train[\"selected_text\"] = negative_train[\"selected_text\"].apply(clean_text)\nneutral_train[\"selected_text\"] = neutral_train[\"selected_text\"].apply(clean_text)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_train[\"selected_text\"] = positive_train[\"selected_text\"].apply(tokenizeandstopwords)\nnegative_train[\"selected_text\"] = negative_train[\"selected_text\"].apply(tokenizeandstopwords)\nneutral_train[\"selected_text\"] = neutral_train[\"selected_text\"].apply(tokenizeandstopwords)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_train['temp_list'] = positive_train['selected_text'].apply(lambda x:str(x).split())\npositive_train['temp_list'] = positive_train['temp_list'].apply(lambda x:remove_stopword(x))\npositive_top = Counter([item for sublist in positive_train['temp_list'] for item in sublist])\npositive_temp = pd.DataFrame(positive_top.most_common(20))\npositive_temp.columns = ['Common_words','count']\npositive_temp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"negative_train['temp_list'] = negative_train['selected_text'].apply(lambda x:str(x).split())\nnegative_train['temp_list'] = negative_train['temp_list'].apply(lambda x:remove_stopword(x))\nnegative_top = Counter([item for sublist in negative_train['temp_list'] for item in sublist])\nnegative_temp = pd.DataFrame(negative_top.most_common(20))\nnegative_temp.columns = ['Common_words','count']\nnegative_temp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"neutral_train['temp_list'] = neutral_train['selected_text'].apply(lambda x:str(x).split())\nneutral_train['temp_list'] = neutral_train['temp_list'].apply(lambda x:remove_stopword(x))\nneutral_top = Counter([item for sublist in neutral_train['temp_list'] for item in sublist])\nneutral_temp = pd.DataFrame(neutral_top.most_common(20))\nneutral_temp.columns = ['Common_words','count']\nneutral_temp.style.background_gradient(cmap='Blues')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_train['number of words'] = positive_train['text'].apply(lambda x : len(str(x).split()))\nnegative_train['number of words'] = negative_train['text'].apply(lambda x : len(str(x).split()))\nneutral_train['number of words'] = neutral_train['text'].apply(lambda x : len(str(x).split()))\n\nplt.figure(figsize=(15,8))\np1=sns.kdeplot(negative_train['number of words'], shade=True, color=\"r\")\np1=sns.kdeplot(positive_train['number of words'], shade=True, color=\"b\")\np1=sns.kdeplot(neutral_train['number of words'], shade=True, color=\"g\")\np1.set_title('Distribution of Number Of words',fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer\n\n\ndef WordRanking(corpus,n_gram,n=None):\n   \n    vec = CountVectorizer(ngram_range=n_gram,stop_words = 'english').fit(corpus)\n    bag_of_words = vec.transform(corpus)\n    sum_words = bag_of_words.sum(axis=0) \n    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n    \n    return words_freq[:n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"positive_selected_text = train[train['sentiment']=='positive']['selected_text']\nnegative_selected_text = train[train['sentiment']=='negative']['selected_text']\nneutral_selected_text = train[train['sentiment']=='neutral']['selected_text']\n\npositive_bigrams = WordRanking(positive_selected_text,(2,2),20)\nnegative_bigrams = WordRanking(negative_selected_text,(2,2),20)\nneutral_bigrams = WordRanking(neutral_selected_text,(2,2),20)\n\npositive_bigrams = pd.DataFrame(positive_bigrams,columns=['word','counting'])\nnegative_bigrams = pd.DataFrame(negative_bigrams,columns=['word','counting'])\nneutral_bigrams = pd.DataFrame(neutral_bigrams,columns=['word','counting'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,10))\nax= sns.barplot(data=positive_bigrams,y='word',x='counting', color=\"b\")\nax.set_title('Top 20 positive bigram words from selected text'.title(),fontsize=20)\n\nax.set_ylabel('Word counting',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,10))\nax= sns.barplot(data=negative_bigrams,y='word',x='counting', color=\"b\")\nax.set_title('Top 20 negative bigram words from selected text'.title(),fontsize=20)\n\nax.set_ylabel('Word counting',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.figure(figsize=(19,10))\nax= sns.barplot(data=neutral_bigrams,y='word',x='counting', color=\"b\")\nax.set_title('Top 20 neutral bigram words from selected text'.title(),fontsize=20)\n\nax.set_ylabel('Word counting',fontsize=15)\nplt.show()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}