{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from __future__ import unicode_literals, print_function\nimport pandas as pd\nimport os\nimport re\nimport string\nfrom nltk.corpus import stopwords\n\nimport random\nfrom pathlib import Path\nimport spacy\nfrom spacy.util import minibatch, compounding\nimport datetime\nfrom tqdm import tqdm\n\n# spacy.prefer_gpu()\n\n\nLABEL = \"SELECTEDTEXT\"\n\n\ndef read_data(datadir):\n    train = pd.read_csv(os.path.join(datadir, \"train.csv\"))\n    test = pd.read_csv(os.path.join(datadir, \"test.csv\"))\n    sample_submission = pd.read_csv(os.path.join(datadir, \"sample_submission.csv\"))\n\n    return (train, test, sample_submission)\n\n\ndef jaccard_similarity(string1, string2):\n    wordset = lambda x: set(x.lower().split())\n    a, b = wordset(string1), wordset(string2)\n\n    c = a.intersection(b)\n\n    return float(len(c)) / (len(a) + len(b) - len(c))\n\n\ndef clean_text(text):\n    \"\"\"Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.\n    Source: https://www.kaggle.com/tanulsingh077/twitter-sentiment-extaction-analysis-eda-and-model\n    \"\"\"\n    text = str(text).lower()\n    text = re.sub(\"\\[.*?\\]\", \"\", text) # remove words in square brackets\n    text = re.sub(\"https?://\\S+|www\\.\\S+\", \"\", text)\n    text = re.sub(\"<.*?>+\", \"\", text)\n    text = re.sub(\"[%s]\" % re.escape(string.punctuation), \"\", text)\n    text = re.sub(\"\\n\", \"\", text)\n    text = re.sub(\"\\w*\\d\\w*\", \"\", text)\n    return text\n\n\ndef remove_stopwords(words):\n    return [word for word in words if word not in stopwords.words(\"english\")]\n\n\ndef training_data(dataframe):\n    data = (\n        dataframe.dropna()\n        .assign(\n            text=lambda x: x.apply(lambda x: x.text.lower(), axis=1),\n            selected_text=lambda x: x.apply(lambda x: x.selected_text.lower(), axis=1),\n        )\n        .assign(\n            start=lambda x: x.apply(lambda x: x.text.find(x.selected_text), axis=1),\n            end=lambda x: x.apply(lambda x: x.start + len(x.selected_text), axis=1),\n        )\n    )\n\n    positive = []\n    negative = []\n\n    for i, row in data.iterrows():\n        if row.end > row.start:\n            train_row = (row.text, {\"entities\": [(row.start, row.end, LABEL)]})\n\n            if row.sentiment == \"positive\":\n                positive.append(train_row)\n            elif row.sentiment == \"negative\":\n                negative.append(train_row)\n            else:\n                pass\n\n    print(f\"Positive data size: {len(positive):,}\")\n    print(f\"Negative data size: {len(negative):,}\")\n\n    return positive, negative\n\ndef run_model(data, positivemodel, negativemodel, outputpath=None):\n    print(\"Loading models...\")\n    positive_nlp = spacy.load(positivemodel)\n    negative_nlp = spacy.load(negativemodel)\n\n    data = data.dropna()\n\n    textIDs, selected_texts = [], []\n    jaccards = {\n        \"positive\": [],\n        \"negative\": [],\n        \"neutral\": []\n    }\n\n    input_train = \"selected_text\" in data.columns\n\n    print(\"Iterating data...\")\n    for _, row in tqdm(data.iterrows()):\n        if row.sentiment == \"positive\":\n            if len(row.text.split()) <= 2:\n                selected_text = row.text\n            else: \n                ents = positive_nlp(row.text).ents\n                selected_text = ents[0].text if len(ents) > 0 else row.text\n        elif row.sentiment == \"negative\":\n            if len(row.text.split()) <= 2:\n                selected_text = row.text\n            else:\n                ents = negative_nlp(row.text).ents\n                selected_text = ents[0].text if len(ents) > 0 else row.text\n        else:\n            selected_text = row.text\n\n        textIDs += [row.textID]\n        selected_texts += [selected_text]\n\n        if input_train:\n            jaccard = jaccard_similarity(row.text, selected_text)\n            jaccards[row.sentiment] += [jaccard]\n\n    output_df = pd.DataFrame({\"textID\": textIDs, \"selected_text\": selected_texts})\n    \n    if not input_train:\n        if not outputpath:\n            suffix = datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M-%S\")\n            outputpath = os.path.join(\"submissions\", \"submission_\" + suffix + \".csv\")\n        \n        print(\"Saving submission...\")\n        output_df.to_csv(outputpath, index=False)\n\n    if input_train:\n        nums, dens = [], []\n        for key in (\"positive\", \"negative\", \"neutral\"):\n            num = sum(jaccards[key])\n            den = len(jaccards[key])\n            jaccard_score = num / den\n            print(f\"Jaccard score for {key}: {num / den:.3f}\")\n\n            nums.append(num)\n            dens.append(den)\n\n        print(f\"Jaccard score for overall: {sum(nums) / sum(dens):.3f}\")\n        \n\ndef train_model(traindata, new_model_name, model=None, output_dir=None, n_iter=30):\n    \"\"\"Set up the pipeline and entity recognizer, and train the new entity.\"\"\"\n    random.seed(0)\n    if model is not None:\n        nlp = spacy.load(model)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    # Add entity recognizer to model if it's not in the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner)\n    # otherwise, get it, so we can add labels to it\n    else:\n        ner = nlp.get_pipe(\"ner\")\n\n    ner.add_label(LABEL)  # add new entity label to entity recognizer\n    # Adding extraneous labels shouldn't mess anything up\n    # ner.add_label(\"VEGETABLE\")\n    if model is None:\n        optimizer = nlp.begin_training()\n    else:\n        optimizer = nlp.resume_training()\n    move_names = list(ner.move_names)\n    # get names of other pipes to disable them during training\n    pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        for itn in range(n_iter):\n            random.shuffle(traindata)\n            batches = minibatch(traindata, size=sizes)\n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts, annotations, sgd=optimizer, drop=0.35, losses=losses)\n            print(\"Losses\", losses)\n\n    # test the trained model\n    test_text = \"i`d have responded, if i were going\"\n    doc = nlp(test_text)\n    print(\"Entities in '%s'\" % test_text)\n    for ent in doc.ents:\n        print(ent.label_, ent.text)\n\n    # save model to output directory\n    if output_dir is not None:\n        output_dir = Path(output_dir)\n        if not output_dir.exists():\n            output_dir.mkdir()\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)\n\n        # test the saved model\n        print(\"Loading from\", output_dir)\n        nlp2 = spacy.load(output_dir)\n        # Check the classes have loaded back consistently\n        assert nlp2.get_pipe(\"ner\").move_names == move_names\n        doc2 = nlp2(test_text)\n        for ent in doc2.ents:\n            print(ent.label_, ent.text)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"spacy.prefer_gpu()\n\nn_iter = 20\n\nmodelsdir = \"models\"\ndatadir = \"/kaggle/input/tweet-sentiment-extraction\"\n\n# preparing training dataset \ntrain, test, _ = read_data(datadir)\npositive, negative = training_data(train)\n\n# training positive model\n# os.mkdir(modelsdir)\n# print(\"Training positive model...\")\n# train_model(positive, \"positive\", output_dir=os.path.join(modelsdir, \"positive\"), n_iter=n_iter)\n\n# #training negative model\n# print(\"Training negative model...\")\n# train_model(negative, \"negative\", output_dir=os.path.join(modelsdir, \"negative\"), n_iter=n_iter)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# running model on test dataset\n\n# using uploaded model files trained with 100 iterations\nmodelsdir = \"/kaggle/input/tweetsentimentmodel/models\"\n\nrun_model(test, \n        os.path.join(modelsdir, \"positive\"),\n        os.path.join(modelsdir, \"negative\"),\n        outputpath=\"submission.csv\"\n        )","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}