{"cells":[{"metadata":{"id":"FA1TBaaGf-A_"},"cell_type":"markdown","source":"**EDA AND FEATURE ENGINEERING**"},{"metadata":{"trusted":true,"id":"veceTYJrf-BF","outputId":"bff0d1b6-da44-40d2-8880-e95927a11b16"},"cell_type":"code","source":"import pandas as pd\n\nfrom tqdm import tqdm\nimport os\nimport nltk\nimport spacy\nimport random\nfrom spacy.util import compounding\nfrom spacy.util import minibatch\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n\n\ntrain_x= pd.read_csv(\"../input/tweet-sentiment-extraction/train.csv\")\ntest_x= pd.read_csv(\"../input/tweet-sentiment-extraction/test.csv\")\ntrain_x.dropna(inplace=True)\ntrain_x.head()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"id":"wGyK_E2Uf-BG","outputId":"3731bf79-d244-402b-9c2d-52a58d16fb68"},"cell_type":"code","source":"train_x.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"xW9RQzsOf-BH","outputId":"5c81b3cc-2c0e-4c64-b29c-b3146618b8ef"},"cell_type":"code","source":"import re\nimport numpy as np\n\ndef number_words(text):\n    text=re.sub(r'[^\\w\\s]','',text)\n    text.strip()    \n    text_list=text.split()\n    return len(text_list)\ndef jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) / (len(a) + len(b) - len(c))\ndf=train_x.assign(jaccard_score=np.nan)\ndf[\"jaccard_score\"]= [jaccard(df.at[i,\"selected_text\"],df.at[i,\"text\"]) for i in df.index]\ndf[\"St_words_number\"]= [number_words(df.at[i,\"selected_text\"]) for i in df.index]\ndf[\"text_word_number\"]= [number_words(df.at[i,\"text\"]) for i in df.index]\ndf[\"diff_number_words\"]= df[\"text_word_number\"]-df[\"St_words_number\"]\ndf.head()\n\n\n\n\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"O04CgmGlf-BI","outputId":"0919c042-6f95-4411-a219-bde74b3b20d2"},"cell_type":"code","source":"import pandas as pd\npd.plotting.register_matplotlib_converters()\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nplt.figure(figsize=(12,6))\n\nsns.kdeplot(data=df['text_word_number'], shade=True)\nsns.kdeplot(data=df['St_words_number'], shade=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ykFjr0Qyf-BI","outputId":"739dbee4-dd78-4050-9eba-2fbf7dd2f67a"},"cell_type":"code","source":"\nplt.figure(figsize=(12,6))\ndf_neutral=df[df['sentiment']=='neutral']\nplt.figure(figsize=(12,6))\nsns.distplot(df_neutral['jaccard_score'],kde=False)\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"8hyLzFbvf-BI","outputId":"9755609f-a6b2-42ea-e5b0-c0eb840b0dc1"},"cell_type":"code","source":"plt.figure(figsize=(12,6))\ndf_positive=df[df['sentiment']=='positive']\nsns.kdeplot(data=df_positive['jaccard_score'],label=\"positive\",shade=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"CU0hyvAwf-BJ","outputId":"0b3aeaba-c864-46d5-9b50-0ceabebbfe91"},"cell_type":"code","source":"plt.figure(figsize=(12,6))\ndf_negative=df[df['sentiment']=='negative']\nsns.kdeplot(data=df_negative['jaccard_score'],label=\"negative\",color='red',shade=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"OcVSrAlnf-BJ","outputId":"6a21b7bc-af96-4250-db87-bd76f24fb6a9"},"cell_type":"code","source":"k=df[df['text_word_number']<=3]\nk.groupby('sentiment').mean()['jaccard_score']\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"DpUVKqSmf-BJ","outputId":"de82909c-524c-496a-ede7-71877363afe2"},"cell_type":"code","source":"k=df[df['text_word_number']<=2]\nk.groupby('sentiment').mean()['jaccard_score']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Xf7QKsqgf-BK","outputId":"3b1f924a-80a2-4479-94b0-f82ab88ad327"},"cell_type":"code","source":"import string\ndf['text']=df['text'].str.replace('[^\\w\\s]','')\ndf['selected_text']=df['selected_text'].str.replace('[^\\w\\s]','')\nk=df[df['text_word_number']<=2][df['jaccard_score']<1]\nk","execution_count":null,"outputs":[]},{"metadata":{"id":"sqovQpeyf-BK"},"cell_type":"markdown","source":"**NER MODEL**"},{"metadata":{"trusted":true,"id":"ZMcM2UlGf-BK"},"cell_type":"code","source":"df_train = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ndf_test = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')\ndf_submission = pd.read_csv('../input/tweet-sentiment-extraction/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"0fdsoruAf-BL"},"cell_type":"code","source":"df_train['Num_words_text'] = df_train['text'].apply(lambda x:len(str(x).split()))\ndf_train = df_train[df_train['Num_words_text']>3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"Yoy4nY9Xf-BL"},"cell_type":"code","source":"def save_model(output_dir, nlp, new_model_name):\n    ''' This Function Saves model to \n    given output directory'''\n    \n    output_dir = f'./tse-spacy-model/{output_dir}'\n    if output_dir is not None:        \n        if not os.path.exists(output_dir):\n            os.makedirs(output_dir)\n        nlp.meta[\"name\"] = new_model_name\n        nlp.to_disk(output_dir)\n        print(\"Saved model to\", output_dir)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"0PdHmfVnf-BL"},"cell_type":"code","source":"def get_model_out_path(sentiment):\n    '''\n    Returns Model output path\n    '''\n    model_out_path = None\n    if sentiment == 'positive':\n        model_out_path = 'models/model_pos'\n    elif sentiment == 'negative':\n        model_out_path = 'models/model_neg'\n    return model_out_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"U0o65SgLf-BL"},"cell_type":"code","source":"def get_training_data(sentiment):\n    '''\n    Returns Trainong data in the format needed to train spacy NER\n    '''\n    train_data = []\n    for index, row in df_train.iterrows():\n        if row.sentiment == sentiment:\n            selected_text = row.selected_text\n            text = row.text\n            start = text.find(selected_text)\n            end = start + len(selected_text)\n            train_data.append((text, {\"entities\": [[start, end, 'selected_text']]}))\n    return train_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"toPUEX5Af-BL"},"cell_type":"code","source":"def train(train_data, output_dir, n_iter=20, model=None):\n    \"\"\"Load the model, set up the pipeline and train the entity recognizer.\"\"\"\n    \"\"\n    if model is not None:\n        nlp = spacy.load(output_dir)  # load existing spaCy model\n        print(\"Loaded model '%s'\" % model)\n    else:\n        nlp = spacy.blank(\"en\")  # create blank Language class\n        print(\"Created blank 'en' model\")\n    \n    # create the built-in pipeline components and add them to the pipeline\n    # nlp.create_pipe works for built-ins that are registered with spaCy\n    if \"ner\" not in nlp.pipe_names:\n        ner = nlp.create_pipe(\"ner\")\n        nlp.add_pipe(ner, last=True)\n    # otherwise, get it so we can add labels\n    else:\n        ner = nlp.get_pipe(\"ner\")\n    \n    # add labels\n    for _, annotations in train_data:\n        for ent in annotations.get(\"entities\"):\n            ner.add_label(ent[2])\n\n    # get names of other pipes to disable them during training\n    other_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"ner\"]\n    with nlp.disable_pipes(*other_pipes):  # only train NER\n        # sizes = compounding(1.0, 4.0, 1.001)\n        # batch up the examples using spaCy's minibatch\n        if model is None:\n            nlp.begin_training()\n        else:\n            nlp.resume_training()\n\n\n        for itn in tqdm(range(n_iter)):\n            random.shuffle(train_data)\n            batches = minibatch(train_data, size=compounding(4.0, 500.0, 1.001))    \n            losses = {}\n            for batch in batches:\n                texts, annotations = zip(*batch)\n                nlp.update(texts,  # batch of texts\n                            annotations,  # batch of annotations\n                            drop=0.5,   # dropout - make it harder to memorise data\n                            losses=losses, \n                            )\n            print(\"Losses\", losses)\n    save_model(output_dir, nlp, 'st_ner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"GPuZ81Gpf-BM","outputId":"ed4c595d-7441-4824-99c2-da05631432e7"},"cell_type":"code","source":"sentiment = 'positive'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n# For DEmo Purposes I have taken 3 iterations you can train the model as you want\ntrain(train_data, model_path, n_iter=3, model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"NGEcuJa5f-BN","outputId":"02efb82c-6877-4fa0-e96c-00628a0c0c5b"},"cell_type":"code","source":"sentiment = 'negative'\n\ntrain_data = get_training_data(sentiment)\nmodel_path = get_model_out_path(sentiment)\n\ntrain(train_data, model_path, n_iter=3, model=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"ySOaUcfdf-BN"},"cell_type":"code","source":"def predict_entities(text, model):\n    doc = model(text)\n    ent_array = []\n    for ent in doc.ents:\n        start = text.find(ent.text)\n        end = start + len(ent.text)\n        new_int = [start, end, ent.label_]\n        if new_int not in ent_array:\n            ent_array.append([start, end, ent.label_])\n    selected_text = text[ent_array[0][0]: ent_array[0][1]] if len(ent_array) > 0 else text\n    return selected_text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"QuNK0zAIf-BN","outputId":"ea91e241-5082-4c16-9471-0b3b857280c6"},"cell_type":"code","source":"selected_texts = []\nMODELS_BASE_PATH = './tse-spacy-model/models/'\n\nif MODELS_BASE_PATH is not None:\n    print(\"Loading Models  from \", MODELS_BASE_PATH)\n    model_pos = spacy.load(MODELS_BASE_PATH + 'model_pos')\n    model_neg = spacy.load(MODELS_BASE_PATH + 'model_neg')\n        \n    for index, row in df_test.iterrows():\n        text = row.text\n        output_str = \"\"\n        if row.sentiment == 'neutral' or len(text.split()) <= 2:\n            selected_texts.append(text)\n        elif row.sentiment == 'positive':\n            selected_texts.append(predict_entities(text, model_pos))\n        else:\n            selected_texts.append(predict_entities(text, model_neg))\n        \ndf_test['selected_text'] = selected_texts","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"id":"U6v7qia_f-BO","outputId":"f98f149c-b2ac-4ff0-ba02-aa0ce44e356b"},"cell_type":"code","source":"df_submission['selected_text'] = df_test['selected_text']\ndf_submission.to_csv(\"submission.csv\", index=False)\ndisplay(df_submission.head(10))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}