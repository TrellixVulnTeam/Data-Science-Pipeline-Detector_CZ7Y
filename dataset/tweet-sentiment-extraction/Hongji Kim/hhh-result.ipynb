{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gensim.downloader as api\nimport re,os\nimport tensorflow\nimport tensorflow.compat.v1 as tf\nfrom tqdm import tqdm\n\ntf.disable_v2_behavior()\nprint(tf.__version__)\nprint(tf.test.is_gpu_available())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport sys\nimport numpy as np\nfrom skimage.util import view_as_windows\nimport warnings, logging\nimport tensorflow.compat.v1 as tf\nfrom collections import OrderedDict\nimport numpy as np\n\n\ndef make_batches(size, batch_size):\n    num_batches = (size + batch_size - 1) // batch_size  # round up\n    return [(i * batch_size, min(size, (i + 1) * batch_size))\n            for i in range(num_batches)]\n\n\ndef to_list(x, allow_tuple=False):\n    if isinstance(x, list):\n        return x\n    if allow_tuple and isinstance(x, tuple):\n        return list(x)\n    return [x]\n\n\ndef unpack_singleton(x):\n\n    if len(x) == 1:\n        return np.array(x)\n    return x\n\n\ndef slice_arrays(arrays, start=None, stop=None):\n\n    if arrays is None:\n        return [None]\n    elif isinstance(arrays, list):\n        return [None if x is None else x[start:stop] for x in arrays]\n    else:\n        return arrays[start:stop]\n\n\ndef placeholder_from_data(numpy_array):\n    if numpy_array is None:\n        return None\n    return tf.placeholder('float', [None,] + list(numpy_array.shape[1:]))\n\nSUPPORTED_ACTIVATIONS = [\n    'Relu', 'Elu', 'Sigmoid', 'Tanh', 'Softplus'\n]\n\nUNSUPPORTED_ACTIVATIONS = [\n    'CRelu', 'Relu6', 'Softsign'\n]\n\n_ENABLED_METHOD_CLASS = None\n_GRAD_OVERRIDE_CHECKFLAG = 0\n\n\n# -----------------------------------------------------------------------------\n# UTILITY FUNCTIONS\n# -----------------------------------------------------------------------------\n\n\ndef activation(type):\n    \"\"\"\n    Returns Tensorflow's activation op, given its type\n    :param type: string\n    :return: op\n    \"\"\"\n    if type not in SUPPORTED_ACTIVATIONS:\n        warnings.warn('Activation function (%s) not supported' % type)\n    f = getattr(tf.nn, type.lower())\n    return f\n\n\ndef original_grad(op, grad):\n    \"\"\"\n    Return original Tensorflow gradient for an op\n    :param op: op\n    :param grad: Tensor\n    :return: Tensor\n    \"\"\"\n    if op.type not in SUPPORTED_ACTIVATIONS:\n        warnings.warn('Activation function (%s) not supported' % op.type)\n    opname = '_%sGrad' % op.type\n    return f(op, grad)\n\n\n# -----------------------------------------------------------------------------\n# ATTRIBUTION METHODS BASE CLASSES\n# -----------------------------------------------------------------------------\n\n\nclass AttributionMethod(object):\n    \"\"\"\n    Attribution method base class\n    \"\"\"\n    def __init__(self, T, X, session, keras_learning_phase=None):\n        self.T = T  # target Tensor\n        self.X = X  # input Tensor\n        self.Y_shape = [None,] + T.get_shape().as_list()[1:]\n        # Most often T contains multiple output units. In this case, it is often necessary to select\n        # a single unit to compute contributions for. This can be achieved passing 'ys' as weight for the output Tensor.\n        self.Y = tf.placeholder(tf.float32, self.Y_shape)\n        # placeholder_from_data(ys) if ys is not None else 1.0  # Tensor that represents weights for T\n        self.T = self.T * self.Y\n        self.symbolic_attribution = None\n        self.session = session\n        self.keras_learning_phase = keras_learning_phase\n        self.has_multiple_inputs = type(self.X) is list or type(self.X) is tuple\n        logging.info('Model with multiple inputs: %s' % self.has_multiple_inputs)\n\n        # Set baseline\n        # TODO: now this sets a baseline also for those methods that does not require it\n        self._set_check_baseline()\n\n        # References\n        self._init_references()\n\n        # Create symbolic explanation once during construction (affects only gradient-based methods)\n        self.explain_symbolic()\n\n    def explain_symbolic(self):\n        return None\n\n    def run(self, xs, ys=None, batch_size=None):\n        pass\n\n    def _init_references(self):\n        pass\n\n    def _check_input_compatibility(self, xs, ys=None, batch_size=None):\n        if ys is not None:\n            if not self.has_multiple_inputs and len(xs) != len(ys):\n                raise RuntimeError('When provided, ys must have the same batch size as xs (xs has batch size {} and ys {})'.format(len(xs), len(ys)))\n            elif self.has_multiple_inputs and np.all([len(i) != len(ys) for i in xs]):\n                raise RuntimeError('When provided, ys must have the same batch size as all elements of xs')\n        if batch_size is not None and batch_size > 0:\n            if self.T.shape[0].value is not None and self.T.shape[0].value is not batch_size:\n                raise RuntimeError('When using batch evaluation, the first dimension of the target tensor '\n                                   'must be compatible with the batch size. Found %s instead' % self.T.shape[0].value)\n            if isinstance(self.X, list):\n                for x in self.X:\n                    if x.shape[0].value is not None and x.shape[0].value is not batch_size:\n                        raise RuntimeError('When using batch evaluation, the first dimension of the input tensor '\n                                           'must be compatible with the batch size. Found %s instead' % x.shape[\n                                               0].value)\n            else:\n                if self.X.shape[0].value is not None and self.X.shape[0].value is not batch_size:\n                    raise RuntimeError('When using batch evaluation, the first dimension of the input tensor '\n                                       'must be compatible with the batch size. Found %s instead' % self.X.shape[0].value)\n\n    def _session_run_batch(self, T, xs, ys=None):\n        feed_dict = {}\n        if self.has_multiple_inputs:\n            for k, v in zip(self.X, xs):\n                feed_dict[k] = v\n        else:\n            feed_dict[self.X] = xs\n\n        # If ys is not passed, produce a vector of ones that will be broadcasted to all batch samples\n        feed_dict[self.Y] = ys if ys is not None else np.ones([1,] + self.Y_shape[1:])\n\n        if self.keras_learning_phase is not None:\n            feed_dict[self.keras_learning_phase] = 0\n        return self.session.run(T, feed_dict)\n\n    def _session_run(self, T, xs, ys=None, batch_size=None):\n        num_samples = len(xs)\n        if self.has_multiple_inputs is True:\n            num_samples = len(xs[0])\n            if len(xs) != len(self.X):\n                raise RuntimeError('List of input tensors and input data have different lengths (%s and %s)'\n                                   % (str(len(xs)), str(len(self.X))))\n            if batch_size is not None:\n                for xi in xs:\n                    if len(xi) != num_samples:\n                        raise RuntimeError('Evaluation in batches requires all inputs to have '\n                                           'the same number of samples')\n\n        if batch_size is None or batch_size <= 0 or num_samples <= batch_size:\n            return self._session_run_batch(T, xs, ys)\n        else:\n            outs = []\n            batches = make_batches(num_samples, batch_size)\n            for batch_index, (batch_start, batch_end) in enumerate(batches):\n                # Get a batch from data\n                xs_batch = slice_arrays(xs, batch_start, batch_end)\n                # If the target tensor has one entry for each sample, we need to batch it as well\n                ys_batch = None\n                if ys is not None:\n                    ys_batch = slice_arrays(ys, batch_start, batch_end)\n                batch_outs = self._session_run_batch(T, xs_batch, ys_batch)\n                batch_outs = to_list(batch_outs)\n                if batch_index == 0:\n                    # Pre-allocate the results arrays.\n                    for batch_out in batch_outs:\n                        shape = (num_samples,) + batch_out.shape[1:]\n                        outs.append(np.zeros(shape, dtype=batch_out.dtype))\n                for i, batch_out in enumerate(batch_outs):\n                    outs[i][batch_start:batch_end] = batch_out\n            return unpack_singleton(outs)\n\n    def _set_check_baseline(self):\n        # Do nothing for those methods that have no baseline required\n        if not hasattr(self, \"baseline\"):\n            return\n\n        if self.baseline is None:\n            if self.has_multiple_inputs:\n                self.baseline = [np.zeros([1,] + xi.get_shape().as_list()[1:]) for xi in self.X]\n            else:\n                self.baseline = np.zeros([1,] + self.X.get_shape().as_list()[1:])\n\n        else:\n            if self.has_multiple_inputs:\n                for i, xi in enumerate(self.X):\n                    if list(self.baseline[i].shape) == xi.get_shape().as_list()[1:]:\n                        self.baseline[i] = np.expand_dims(self.baseline[i], 0)\n                    else:\n                        raise RuntimeError('Baseline shape %s does not match expected shape %s'\n                                           % (self.baseline[i].shape, self.X.get_shape().as_list()[1:]))\n            else:\n                if list(self.baseline.shape) == self.X.get_shape().as_list()[1:]:\n                    self.baseline = np.expand_dims(self.baseline, 0)\n                else:\n                    raise RuntimeError('Baseline shape %s does not match expected shape %s'\n                                       % (self.baseline.shape, self.X.get_shape().as_list()[1:]))\n\n\nclass GradientBasedMethod(AttributionMethod):\n    \"\"\"\n    Base class for gradient-based attribution methods\n    \"\"\"\n    def get_symbolic_attribution(self):\n        return tf.gradients(self.T, self.X)\n\n    def explain_symbolic(self):\n        if self.symbolic_attribution is None:\n            self.symbolic_attribution = self.get_symbolic_attribution()\n        return self.symbolic_attribution\n\n    def run(self, xs, ys=None, batch_size=None):\n        self._check_input_compatibility(xs, ys, batch_size)\n        results = self._session_run(self.explain_symbolic(), xs, ys, batch_size)\n        return results[0] if not self.has_multiple_inputs else results\n\n    @classmethod\n    def nonlinearity_grad_override(cls, op, grad):\n        return original_grad(op, grad)\n\n\nclass PerturbationBasedMethod(AttributionMethod):\n    \"\"\"\n       Base class for perturbation-based attribution methods\n       \"\"\"\n    def __init__(self, T, X, session, keras_learning_phase):\n        super(PerturbationBasedMethod, self).__init__(T, X, session, keras_learning_phase)\n        self.base_activation = None\n\n\n\n# -----------------------------------------------------------------------------\n# ATTRIBUTION METHODS\n# -----------------------------------------------------------------------------\n\"\"\"\nReturns zero attributions. For testing only.\n\"\"\"\n\n\nclass DummyZero(GradientBasedMethod):\n\n    def get_symbolic_attribution(self,):\n        return tf.gradients(self.T, self.X)\n\n    @classmethod\n    def nonlinearity_grad_override(cls, op, grad):\n        input = op.inputs[0]\n        return tf.zeros_like(input)\n\n\"\"\"\nSaliency maps\nhttps://arxiv.org/abs/1312.6034\n\"\"\"\n\n\nclass Saliency(GradientBasedMethod):\n\n    def get_symbolic_attribution(self):\n        return [tf.abs(g) for g in tf.gradients(self.T, self.X)]\n\n\n\"\"\"\nGradient * Input\nhttps://arxiv.org/pdf/1704.02685.pdf - https://arxiv.org/abs/1611.07270\n\"\"\"\n\n\nclass GradientXInput(GradientBasedMethod):\n\n    def get_symbolic_attribution(self):\n        return [g * x for g, x in zip(\n            tf.gradients(self.T, self.X),\n            self.X if self.has_multiple_inputs else [self.X])]\n\n\n\"\"\"\nIntegrated Gradients\nhttps://arxiv.org/pdf/1703.01365.pdf\n\"\"\"\n\n\nclass IntegratedGradients(GradientBasedMethod):\n\n    def __init__(self, T, X, session, keras_learning_phase, steps=100, baseline=None):\n        self.steps = steps\n        self.baseline = baseline\n        super(IntegratedGradients, self).__init__(T, X, session, keras_learning_phase)\n\n    def run(self, xs, ys=None, batch_size=None):\n        self._check_input_compatibility(xs, ys, batch_size)\n\n        gradient = None\n        for alpha in list(np.linspace(1. / self.steps, 1.0, self.steps)):\n            xs_mod = [b + (x - b) * alpha for x, b in zip(xs, self.baseline)] if self.has_multiple_inputs \\\n                else self.baseline + (xs - self.baseline) * alpha\n            _attr = self._session_run(self.explain_symbolic(), xs_mod, ys, batch_size)\n            if gradient is None: gradient = _attr\n            else: gradient = [g + a for g, a in zip(gradient, _attr)]\n\n        results = [g * (x - b) / self.steps for g, x, b in zip(\n            gradient,\n            xs if self.has_multiple_inputs else [xs],\n            self.baseline if self.has_multiple_inputs else [self.baseline])]\n\n        return results[0] if not self.has_multiple_inputs else results\n\n\n\"\"\"\nLayer-wise Relevance Propagation with epsilon rule\nhttp://journals.plos.org/plosone/article?id=10.1371/journal.pone.0130140\n\"\"\"\n\n\nclass EpsilonLRP(GradientBasedMethod):\n    eps = None\n\n    def __init__(self, T, X, session, keras_learning_phase, epsilon=1e-4):\n        assert epsilon > 0.0, 'LRP epsilon must be greater than zero'\n        global eps\n        eps = epsilon\n        super(EpsilonLRP, self).__init__(T, X, session, keras_learning_phase)\n\n    def get_symbolic_attribution(self):\n        return [g * x for g, x in zip(\n            tf.gradients(self.T, self.X),\n            self.X if self.has_multiple_inputs else [self.X])]\n\n    @classmethod\n    def nonlinearity_grad_override(cls, op, grad):\n        output = op.outputs[0]\n        input = op.inputs[0]\n        return grad * output / (input + eps *\n                                tf.where(input >= 0, tf.ones_like(input), -1 * tf.ones_like(input)))\n\n\"\"\"\nDeepLIFT\nThis reformulation only considers the \"Rescale\" rule\nhttps://arxiv.org/abs/1704.02685\n\"\"\"\n\n\nclass DeepLIFTRescale(GradientBasedMethod):\n\n    _deeplift_ref = {}\n\n    def __init__(self, T, X, session, keras_learning_phase, baseline=None):\n        self.baseline = baseline\n        super(DeepLIFTRescale, self).__init__(T, X, session, keras_learning_phase)\n\n    def get_symbolic_attribution(self):\n        return [g * (x - b) for g, x, b in zip(\n            tf.gradients(self.T, self.X),\n            self.X if self.has_multiple_inputs else [self.X],\n            self.baseline if self.has_multiple_inputs else [self.baseline])]\n\n    @classmethod\n    def nonlinearity_grad_override(cls, op, grad):\n        output = op.outputs[0]\n        input = op.inputs[0]\n        ref_input = cls._deeplift_ref[op.name]\n        ref_output = activation(op.type)(ref_input)\n        delta_out = output - ref_output\n        delta_in = input - ref_input\n        instant_grad = activation(op.type)(0.5 * (ref_input + input))\n        return tf.where(tf.abs(delta_in) > 1e-5, grad * delta_out / delta_in,\n                        original_grad(instant_grad.op, grad))\n\n\n\"\"\"\nOcclusion method\nGeneralization of the grey-box method presented in https://arxiv.org/pdf/1311.2901.pdf\nThis method performs a systematic perturbation of contiguous hyperpatches in the input,\nreplacing each patch with a user-defined value (by default 0).\nwindow_shape : integer or tuple of length xs_ndim\nDefines the shape of the elementary n-dimensional orthotope the rolling window view.\nIf an integer is given, the shape will be a hypercube of sidelength given by its value.\nstep : integer or tuple of length xs_ndim\nIndicates step size at which extraction shall be performed.\nIf integer is given, then the step is uniform in all dimensions.\n\"\"\"\n\n\nclass Occlusion(PerturbationBasedMethod):\n\n    def __init__(self, T, X, session, keras_learning_phase, window_shape=None, step=None):\n        super(Occlusion, self).__init__(T, X, session, keras_learning_phase)\n        if self.has_multiple_inputs:\n            raise RuntimeError('Multiple inputs not yet supported for perturbation methods')\n\n        input_shape = X[0].get_shape().as_list()\n        if window_shape is not None:\n            assert len(window_shape) == len(input_shape), \\\n                'window_shape must have length of input (%d)' % len(input_shape)\n            self.window_shape = tuple(window_shape)\n        else:\n            self.window_shape = (1,) * len(input_shape)\n\n        if step is not None:\n            assert isinstance(step, int) or len(step) == len(input_shape), \\\n                'step must be integer or tuple with the length of input (%d)' % len(input_shape)\n            self.step = step\n        else:\n            self.step = 1\n        self.replace_value = 0.0\n        logging.info('Input shape: %s; window_shape %s; step %s' % (input_shape, self.window_shape, self.step))\n\n    def run(self, xs, ys=None, batch_size=None):\n        self._check_input_compatibility(xs, ys, batch_size)\n        input_shape = xs.shape[1:]\n        batch_size = xs.shape[0]\n        total_dim = np.asscalar(np.prod(input_shape))\n\n        # Create mask\n        index_matrix = np.arange(total_dim).reshape(input_shape)\n        idx_patches = view_as_windows(index_matrix, self.window_shape, self.step).reshape((-1,) + self.window_shape)\n        heatmap = np.zeros_like(xs, dtype=np.float32).reshape((-1), total_dim)\n        w = np.zeros_like(heatmap)\n\n        # Compute original output\n        eval0 = self._session_run(self.T, xs, ys, batch_size)\n\n        # Start perturbation loop\n        for i, p in enumerate(idx_patches):\n            mask = np.ones(input_shape).flatten()\n            mask[p.flatten()] = self.replace_value\n            masked_xs = mask.reshape((1,) + input_shape) * xs\n            delta = eval0 - self._session_run(self.T, masked_xs, ys, batch_size)\n            delta_aggregated = np.sum(delta.reshape((batch_size, -1)), -1, keepdims=True)\n            heatmap[:, p.flatten()] += delta_aggregated\n            w[:, p.flatten()] += p.size\n\n        attribution = np.reshape(heatmap / w, xs.shape)\n        if np.isnan(attribution).any():\n            warnings.warn('Attributions generated by Occlusion method contain nans, '\n                          'probably because window_shape and step do not allow to cover the all input.')\n        return attribution\n\n\n\"\"\"\nShapley Value sampling\nComputes approximate Shapley Values using \"Polynomial calculation of the Shapley value based on sampling\",\nCastro et al, 2009 (https://www.sciencedirect.com/science/article/pii/S0305054808000804)\nsamples : integer (default 5)\nDefined the number of samples for each input feature. \nNotice that evaluating a model samples * n_input_feature times might take a while.\nsampling_dims : list of dimension indexes to run sampling on (feature dimensions).\nBy default, all dimensions except the batch dimension will be sampled.\nFor example, with a 4-D tensor that contains color images, single color channels are sampled.\nTo sample pixels, instead, use sampling_dims=[1,2]\n\"\"\"\n\n\nclass ShapleySampling(PerturbationBasedMethod):\n\n    def __init__(self, T, X, session, keras_learning_phase, samples=5, sampling_dims=None):\n        super(ShapleySampling, self).__init__(T, X, session, keras_learning_phase)\n        if self.has_multiple_inputs:\n            raise RuntimeError('Multiple inputs not yet supported for perturbation methods')\n        dims = len(X.shape)\n        if sampling_dims is not None:\n            if not 0 < len(sampling_dims) <= (dims - 1):\n                raise RuntimeError('sampling_dims must be a list containing 1 to %d elements' % (dims-1))\n            if 0 in sampling_dims:\n                raise RuntimeError('Cannot sample batch dimension: remove 0 from sampling_dims')\n            if any([x < 1 or x > dims-1 for x in sampling_dims]):\n                raise RuntimeError('Invalid value in sampling_dims')\n        else:\n            sampling_dims = list(range(1, dims))\n\n        self.samples = samples\n        self.sampling_dims = sampling_dims\n\n    def run(self, xs, ys=None, batch_size=None):\n        xs_shape = list(xs.shape)\n        batch_size = xs.shape[0]\n        n_features = int(np.asscalar(np.prod([xs.shape[i] for i in self.sampling_dims])))\n        result = np.zeros((xs_shape[0], n_features))\n\n        run_shape = list(xs_shape)  # a copy\n        run_shape = np.delete(run_shape, self.sampling_dims).tolist()\n        run_shape.insert(1, -1)\n\n        reconstruction_shape = [xs_shape[0]]\n        for j in self.sampling_dims:\n            reconstruction_shape.append(xs_shape[j])\n\n        for r in range(self.samples):\n            p = np.random.permutation(n_features)\n            x = xs.copy().reshape(run_shape)\n            y = None\n            for i in p:\n                if y is None:\n                    y = self._session_run(self.T, x.reshape(xs_shape), ys, batch_size)\n                x[:, i] = 0\n                y0 = self._session_run(self.T, x.reshape(xs_shape), ys, batch_size)\n                delta = y - y0\n                delta_aggregated = np.sum(delta.reshape((batch_size, -1)), -1, keepdims=False)\n                result[:, i] += delta_aggregated\n                y = y0\n\n        shapley = result / self.samples\n        return shapley.reshape(reconstruction_shape)\n\n\n# -----------------------------------------------------------------------------\n# END ATTRIBUTION METHODS\n# -----------------------------------------------------------------------------\n\n\nattribution_methods = OrderedDict({\n    'zero': (DummyZero, 0),\n    'saliency': (Saliency, 1),\n    'grad*input': (GradientXInput, 2),\n    'intgrad': (IntegratedGradients, 3),\n    'elrp': (EpsilonLRP, 4),\n    'deeplift': (DeepLIFTRescale, 5),\n    'occlusion': (Occlusion, 6),\n    'shapley_sampling': (ShapleySampling, 7)\n})\n\nclass DeepExplain(object):\n\n    def __init__(self, graph=None, session=tf.get_default_session()):\n        self.method = None\n        self.batch_size = None\n        self.session = session\n        self.graph = session.graph if graph is None else graph\n        self.graph_context = self.graph.as_default()\n        self.override_context = self.graph.gradient_override_map(self.get_override_map())\n        self.keras_phase_placeholder = None\n        self.context_on = False\n        if self.session is None:\n            raise RuntimeError('DeepExplain: could not retrieve a session. Use DeepExplain(session=your_session).')\n\n    def __enter__(self):\n        # Override gradient of all ops created in context\n        self.graph_context.__enter__()\n        self.override_context.__enter__()\n        self.context_on = True\n        return self\n\n    def __exit__(self, type, value, traceback):\n        self.graph_context.__exit__(type, value, traceback)\n        self.override_context.__exit__(type, value, traceback)\n        self.context_on = False\n\n    def get_explainer(self, method, T, X, **kwargs):\n        if not self.context_on:\n            raise RuntimeError('Explain can be called only within a DeepExplain context.')\n        global _ENABLED_METHOD_CLASS, _GRAD_OVERRIDE_CHECKFLAG\n        self.method = method\n        if self.method in attribution_methods:\n            method_class, method_flag = attribution_methods[self.method]\n        else:\n            raise RuntimeError('Method must be in %s' % list(attribution_methods.keys()))\n        if isinstance(X, list):\n            for x in X:\n                if 'tensor' not in str(type(x)).lower():\n                    raise RuntimeError('If a list, X must contain only Tensorflow Tensor objects')\n        else:\n            if 'tensor' not in str(type(X)).lower():\n                raise RuntimeError('X must be a Tensorflow Tensor object or a list of them')\n\n        if 'tensor' not in str(type(T)).lower():\n            raise RuntimeError('T must be a Tensorflow Tensor object')\n\n        logging.info('DeepExplain: running \"%s\" explanation method (%d)' % (self.method, method_flag))\n        self._check_ops()\n        _GRAD_OVERRIDE_CHECKFLAG = 0\n\n        _ENABLED_METHOD_CLASS = method_class\n        method = _ENABLED_METHOD_CLASS(T, X,\n                                       self.session,\n                                       keras_learning_phase=self.keras_phase_placeholder,\n                                       **kwargs)\n\n        if issubclass(_ENABLED_METHOD_CLASS, GradientBasedMethod) and _GRAD_OVERRIDE_CHECKFLAG == 0:\n            warnings.warn('DeepExplain detected you are trying to use an attribution method that requires '\n                          'gradient override but the original gradient was used instead. You might have forgot to '\n                          '(re)create your graph within the DeepExlain context. Results are not reliable!')\n        _ENABLED_METHOD_CLASS = None\n        _GRAD_OVERRIDE_CHECKFLAG = 0\n        self.keras_phase_placeholder = None\n        return method\n\n    def explain(self, method, T, X, xs, ys=None, batch_size=None, **kwargs):\n        explainer = self.get_explainer(method, T, X, **kwargs)\n        return explainer.run(xs, ys, batch_size)\n\n    @staticmethod\n    def get_override_map():\n        return dict((a, 'DeepExplainGrad') for a in SUPPORTED_ACTIVATIONS)\n\n    def _check_ops(self):\n        \"\"\"\n        Heuristically check if any op is in the list of unsupported activation functions.\n        This does not cover all cases where explanation methods would fail, and must be improved in the future.\n        Also, check if the placeholder named 'keras_learning_phase' exists in the graph. This is used by Keras\n         and needs to be passed in feed_dict.\n        :return:\n        \"\"\"\n        g = tf.get_default_graph()\n        for op in g.get_operations():\n            if len(op.inputs) > 0 and not op.name.startswith('gradients'):\n                if op.type in UNSUPPORTED_ACTIVATIONS:\n                    warnings.warn('Detected unsupported activation (%s). '\n                                  'This might lead to unexpected or wrong results.' % op.type)\n            elif 'keras_learning_phase' in op.name:\n                self.keras_phase_placeholder = op.outputs[0]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_norm(data, is_train, trainable=True, name=None, data_format='channels_last',\n               USE_FUSED_BN = True, BN_EPSILON = 0.001, BN_MOMENTUM = 0.99):\n    \n    bn_axis = -1 if data_format == 'channels_last' else 1\n    \n    with tf.name_scope(name):\n        return tf.layers.batch_normalization(data, training=is_train, name=name, momentum=BN_MOMENTUM, axis=bn_axis,\n                                             trainable=trainable, epsilon=BN_EPSILON, reuse=None, fused=USE_FUSED_BN)\n\nclass config:\n    def __init__(\n        self, num_output, max_seq_length = 33):\n        \n        self.num_output = num_output\n        self.max_seq_length = max_seq_length\n    \nclass create():\n    def __init__(self, config, seed=None, use_bias=False,\n                 num_layers=8, num_heads=8, linear_key_dim=32,\n                 linear_value_dim=32, model_dim=90, ffn_dim=50, num_vox_roi=90,\n                 gpu_memory_fraction=None, optimizer_type='adam', phase='train',\n                 freeze_encoder=False, ckpt_path=None):\n\n        self.config = config\n        self.num_layers = num_layers\n        self.num_heads = num_heads\n        self.linear_key_dim = linear_key_dim\n        self.linear_value_dim = linear_value_dim\n        self.model_dim = model_dim\n        self.ffn_dim = ffn_dim\n        self.optimizer_type = optimizer_type\n        self.freeze_encoder = freeze_encoder\n        \n        if phase not in ['train', 'test'] : raise  ValueError(\"phase must` be 'train' or 'test'.\")\n\n        self.graph = tf.get_default_graph()\n        config = tf.ConfigProto(log_device_placement=False, allow_soft_placement=True)\n        if gpu_memory_fraction is None:\n            config.gpu_options.allow_growth = True\n        else:\n            config.gpu_options.per_process_gpu_memory_fraction = gpu_memory_fraction\n        self.sess = tf.Session(config=config, graph=self.graph)    \n\n        with self.graph.as_default():\n            if seed is not None :\n                tf.set_random_seed(seed)\n            \n            #self.embedding_inputs = tf.convert_to_tensor(self.config.word_vectors, dtype=tf.float32)\n            self.encoder_inputs = tf.placeholder(tf.float32, [None, self.config.max_seq_length,self.model_dim], name=\"encoder_input\")\n            #self.targets = tf.placeholder(tf.float32, [None, self.config.max_seq_length, self.config.num_output], name = 'target')\n            self.targets = tf.placeholder(tf.int32, [None,], name = 'target')\n            self.batch_size = tf.shape(self.encoder_inputs)[0]\n            if phase == 'train':\n                self.is_train = tf.placeholder(tf.bool)\n                self.lr = tf.placeholder(tf.float32, name=\"lr\")\n            else :\n                self.is_train = False\n            \n            # Create Encoder\n            self.encoder_outputs = self.__create_embed(self.encoder_inputs, encoder=True)\n            self.encoder_outputs = self.__create_encoder(self.encoder_outputs, use_bias=use_bias)\n            \n            # Create Decoder\n            self.decoder_inputs = self.__create_embed(self.encoder_outputs, encoder=False)\n            self.decoder_outputs = self.__create_decoder(self.decoder_inputs, use_bias=use_bias)\n            \n            self.logits = self.__create_output(self.decoder_outputs, self.is_train)\n            self.class_logits = tf.reduce_mean(self.logits,1)\n            \n            if phase == 'train':\n                with tf.variable_scope('loss'):\n                    self.target_one_hot = tf.one_hot(self.targets,depth=self.config.num_output,axis=-1)\n                    self.loss = tf.losses.softmax_cross_entropy(self.target_one_hot, self.class_logits)\n                    #self.loss = tf.losses.mean_squared_error(self.targets, logits)\n                    self.train_op= self.__set_op(self.loss, self.lr, optimizer_type=self.optimizer_type)\n                    self.sess.run(tf.global_variables_initializer())\n                    \n            if ckpt_path is not None :\n                '''\n                vars_to_train = tf.trainable_variables()\n                if self.freeze_encoder :\n                    vars_to_train = [var for var in vars_to_train if 'encode_layer' in var.name]\n                saver = tf.train.Saver(vars_to_train)'''\n                saver = tf.train.Saver()\n                saver.restore(self.sess, ckpt_path)\n            \n    def positional_encoding(self, sentence_length, dtype=tf.float32):\n\n        encoded_vec = np.array([pos/np.power(10000, 2*i/self.model_dim) for pos in range(sentence_length) for i in range(self.model_dim)])\n        encoded_vec[::2] = np.sin(encoded_vec[::2])\n        encoded_vec[1::2] = np.cos(encoded_vec[1::2])\n\n        return tf.convert_to_tensor(encoded_vec.reshape([sentence_length, self.model_dim]), dtype=dtype)\n    \n    def __create_embed(self, inputs, encoder=True, name='Embeddings'):\n        with tf.variable_scope(name) as scope :\n            \n            # Positional Encoding\n            with tf.variable_scope('positional_encoding'):\n                positional_encoded = self.positional_encoding(self.config.max_seq_length)\n            \n            # Add positional encoded\n            position_inputs = tf.tile(tf.range(0, self.config.max_seq_length), [self.batch_size])\n            position_inputs = tf.reshape(position_inputs, [self.batch_size, self.config.max_seq_length])\n            '''    \n            if encoder :\n                inputs = tf.nn.embedding_lookup(self.embedding_inputs, inputs)\n            '''    \n            encoded_inputs = tf.add(inputs, tf.nn.embedding_lookup(positional_encoded, position_inputs))\n            \n            return encoded_inputs\n\n    def __create_encoder(self, enc_input, use_bias=False):\n        tensor = residual = tf.identity(enc_input)\n        for i in range(1, self.num_layers+1):\n            with tf.variable_scope(\"encode_layer{}\".format(i)):\n                tensor = self.self_attention(q=tensor, k=tensor, v=tensor)\n                tensor = tf.add(tensor, residual)\n                tensor = residual = batch_norm(tensor,self.is_train)\n                \n                tensor = tf.layers.dense(tensor, self.model_dim, use_bias=use_bias, activation=tf.nn.relu)\n                tensor = tf.layers.dense(tensor, self.model_dim, use_bias=use_bias)\n                \n                tensor = tf.add(tensor, residual)\n                tensor = batch_norm(tensor,self.is_train)\n                \n        return tensor\n    \n    def __create_decoder(self, dec_input, use_bias=False):\n        for i in range(1, self.num_layers+1):\n            if i == 1:\n                tensor = encoder_inputs =  residual = dec_input\n            else : \n                encoder_inputs = dec_input\n            with tf.variable_scope(\"decode_layer{}\".format(i)):\n                    \n                tensor = self.self_attention(q=tensor, k=tensor, v=tensor, model_dim=self.model_dim, masked=True, name='masked_self_attention')\n                tensor = tf.add(tensor, residual)\n                tensor = residual = batch_norm(tensor,self.is_train)\n                \n                tensor = self.self_attention(q=tensor, k=encoder_inputs, v=encoder_inputs, model_dim=self.model_dim, masked=True, name='encoder_decoder_attention')\n                tensor = tf.add(tensor, residual)\n                tensor = residual = batch_norm(tensor,self.is_train)\n                \n                tensor = tf.layers.dense(tensor, self.ffn_dim, use_bias=use_bias, activation=tf.nn.relu)\n                tensor = tf.layers.dense(tensor, self.model_dim, use_bias=use_bias)\n                \n                tensor = tf.add(tensor, residual)\n                tensor = batch_norm(tensor,self.is_train)\n                \n        return tensor\n    \n    def __create_output(self, decoder_outputs, is_train, use_bias=False, reuse=False):\n        with tf.variable_scope(\"Output\", reuse=reuse):\n            logits = tf.layers.dense(decoder_outputs, self.config.num_output, use_bias=use_bias)\n            logits = tf.layers.batch_normalization(logits, training=is_train, fused=True)\n            \n        return logits\n        \n    def self_attention(self, q, k, v, model_dim=None, masked=False, use_bias=False, name='self_attention'):\n        if model_dim is None:\n            model_dim = self.model_dim\n            \n        with tf.variable_scope(name):\n            # linear_projection\n            q = tf.layers.dense(q, self.linear_key_dim, use_bias=use_bias, name='q_proj')\n            k = tf.layers.dense(k, self.linear_key_dim, use_bias=use_bias, name='k_proj')\n            v = tf.layers.dense(v, self.linear_value_dim, use_bias=use_bias, name='v_proj')\n\n            # split_heads \n            q = self.__split_last_dimension(q, self.linear_key_dim)\n            k = self.__split_last_dimension(k, self.linear_key_dim)\n            v = self.__split_last_dimension(v, self.linear_value_dim)\n\n            # scaled dot product \n            key_dim_per_head = self.linear_key_dim // self.num_heads\n\n            output = tf.matmul(q, k, transpose_b=True)\n            output = output / (key_dim_per_head**0.5)\n\n            if masked:\n                diag_vals = tf.ones_like(output[0, 0, :, :]) # (batch_size, num_heads, query_dim, key_dim)\n                tril = tf.linalg.LinearOperatorLowerTriangular(diag_vals).to_dense() # (q_dim, k_dim)\n                masks = tf.tile(tf.reshape(tril, [1, 1] + tril.get_shape().as_list()),\n                                [tf.shape(output)[0], tf.shape(output)[1], 1, 1])\n                paddings = tf.ones_like(masks) * -1e9\n                output = tf.where(tf.equal(masks, 0), paddings, output)\n\n            output = tf.nn.softmax(output)\n            output = tf.matmul(output, v)\n\n            # concatenate heads\n            output = tf.transpose(output, [0, 2, 1, 3]) # [batch_size, max_seq_len, num_heads, dim]\n            t_shape = output.get_shape().as_list()\n            num_heads, dim = t_shape[-2:]\n            output = tf.reshape(output, [-1] + t_shape[1:-2] + [num_heads * dim])\n\n            output = tf.layers.dense(output, model_dim, use_bias=use_bias)\n            return output\n\n    def __split_last_dimension(self, tensor, dim):\n        t_shape = tensor.get_shape().as_list()\n        tensor = tf.reshape(tensor, [-1] + t_shape[1:-1] + [self.num_heads, dim // self.num_heads])\n        return tf.transpose(tensor, [0, 2, 1, 3])\n    \n    def __set_op(self, loss_op, learning_rate, optimizer_type=\"adam\"):\n        with self.graph.as_default():\n            if optimizer_type==\"adam\":\n                optimizer = tf.train.AdamOptimizer(learning_rate)\n            elif optimizer_type == \"adagrad\":\n                optimizer = tf.train.AdagradOptimizer(learning_rate, initial_accumulator_value=0.0001)\n            elif optimizer_type == \"sgd\":\n                optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n            elif optimizer_type == \"momentum\":\n                optimizer = tf.train.MomentumOptimizer(learning_rate, momentum=0.9)\n            elif optimizer_type == \"adadelta\":\n                optimizer = tf.train.AdadeltaOptimizer(learning_rate,rho=0.95,epsilon=1e-09)\n            else : raise ValueError(\"{} optimizer doesn't exist.\".format(optimizer_type))\n            \n            update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n            vars_to_train = tf.trainable_variables()\n            if self.freeze_encoder :\n                vars_to_train = [var for var in vars_to_train if 'encode_layer' not in var.name]\n                \n            with tf.control_dependencies(update_ops):\n                train_op = optimizer.minimize(loss_op, var_list=vars_to_train)\n\n            self.sess.run(tf.variables_initializer(optimizer.variables()))\n                \n        return train_op","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv').fillna('')\ntestset = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/test.csv').fillna('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_vocab = set(' '.join(dataset['text']).split())\ntest_vocab = set(' '.join(testset['text']).split())\n\ntotal_vocab = list(train_vocab) + list(test_vocab)\neng_word_vec = np.random.randn(len(total_vocab),100)\neng_word_vec = {w:v for w, v in zip(total_vocab,eng_word_vec)}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_word(sentense, max_len=33):\n    result = []\n    for w in sentense.split():\n        w = eng_word_vec[w]\n        result.append(w)\n\n    if len(result) != max_len:\n        for _ in range(max_len-len(result)):\n            result.append(np.zeros((100,)))\n    return np.array(result)\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentiment_cls = ['neutral','negative','positive']\ntrain_target = np.array([sentiment_cls.index(s) for s in dataset['sentiment']])\ntest_target = np.array([sentiment_cls.index(s) for s in testset['sentiment']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_input = list(map(preprocess_word,dataset['text']))\ntest_input = list(map(preprocess_word,testset['text']))\ndel eng_word_vec, dataset\n\nbatch_size = 500\n\ninput_sentences = []\ninput_sentiments = []\n\nbatch_sentences = []\nbatch_sentiments = []\n\nfor s, t in zip(train_input,train_target):\n    batch_sentences.append(s)\n    batch_sentiments.append(t)\n    if len(batch_sentences) == batch_size:\n        input_sentences.append(np.array(batch_sentences))\n        input_sentiments.append(np.array(batch_sentiments))\n        \n        batch_sentences.clear()\n        batch_sentiments.clear()\n        \nif len(batch_sentences) != batch_size:\n    input_sentences.append(np.array(batch_sentences))\n    input_sentiments.append(np.array(batch_sentiments))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_config = config(num_output=3, max_seq_length=33)\n\ntf.reset_default_graph()\nnet = create(tr_config,\n             phase = 'train',\n             num_heads=8,\n             num_layers=4,\n             linear_key_dim=8,\n             linear_value_dim=8,\n             model_dim=100,\n             optimizer_type='adam')\n\nwith tqdm(total=40) as pbar:\n    pbar.set_description('Training')\n    for _ in range(40):\n        total_pred = []\n        for i in range(len(input_sentences)):\n            feed_dict={net.encoder_inputs : input_sentences[i],\n                       net.targets : input_sentiments[i],\n                       net.lr : 1e-3, \n                       net.is_train : True}\n\n            pred, cost, _ = net.sess.run([net.class_logits, net.loss, net.train_op], feed_dict=feed_dict)\n            total_pred.append(pred)\n\n        total_pred = np.concatenate(total_pred).argmax(1)\n        total_targets = np.concatenate(input_sentiments)\n        train_acc = round(sum(total_pred == total_targets)/len(total_targets),5)\n\n        feed_dict = {net.encoder_inputs: test_input, net.is_train : True}\n        pred = net.sess.run(net.class_logits, feed_dict=feed_dict)\n        \n        pbar.set_postfix_str(f'train_ACC : {train_acc}')\n        pbar.update(1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ckpt_path = './sentiment_transformer'\nsaver = tf.train.Saver()\nsummary_writer = tf.summary.FileWriter(ckpt_path, net.sess.graph)\nsaver.save(net.sess, f\"{ckpt_path}/model.ckpt\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.reset_default_graph()\nnet = create(tr_config,\n             ckpt_path = './sentiment_transformer/model.ckpt',\n             phase = 'test',\n             num_heads=8,\n             num_layers=4,\n             linear_key_dim=8,\n             linear_value_dim=8,\n             model_dim=100,\n             optimizer_type='adam')\n\n\none_hot_value = np.eye(3)\n\ntest_target = np.array([one_hot_value[y] for y in test_target])\n\nfeed_dict = {net.encoder_inputs: test_input}\npred = net.sess.run(net.class_logits, feed_dict=feed_dict)\n\nwith DeepExplain(session=net.sess) as explainer:\n    explained_result = explainer.explain('elrp', net.class_logits * test_target, net.encoder_inputs, test_input)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.stats.mstats import winsorize\nall_seq_len = [len(text.split()) for text in testset['text']]\nrelevance_score = [s[:leng] for leng, s in zip(all_seq_len,explained_result)]\nr_std = np.array([r.std() if len(r)!=0 else 0 for r in relevance_score ]) \nr_std = (r_std-r_std.min())/(r_std.max()-r_std.min())\nrelevance_score = [winsorize(s,[abs(std-1e-16),0]) for s,std in zip(relevance_score,r_std) if len(s)!=0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"candidate_list = []\nsentiment_cls = ['neutral','negative','positive']\nidx=0\nfor text, cls in np.array(testset[['text','sentiment']]):\n    if len(text) == 0 : continue\n    cls = sentiment_cls.index(cls)\n    \n    if cls == 0:\n        candidate = text\n    else :\n        d_score = sum(relevance_score[idx].data.T)\n        d_where = d_score > (d_score.mean()+d_score.std())\n        \n        if sum(d_where) == 1:\n            candidate = np.array(text.split())[d_where][0]\n        elif sum(d_where) == 0 :\n            candidate = text\n        else :\n            candidate = np.array(text.split())[d_where]\n            candidate = [text.split().index(w) for w in candidate]\n            c_min = min(candidate)\n            c_max = max(candidate)\n            candidate = text.split()[c_min:c_max+1]\n            candidate = ' '.join(candidate)\n    candidate_list.append(candidate)\n    idx+=1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.system(f'rm -rf {ckpt_path}')\ntestset['selected_text'] = candidate_list\ntestset[['textID','selected_text']].to_csv('submission.csv',index=False)\nprint(\"Submission successful\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}