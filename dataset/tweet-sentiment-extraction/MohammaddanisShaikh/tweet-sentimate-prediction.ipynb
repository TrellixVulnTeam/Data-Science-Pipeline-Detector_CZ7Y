{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport pandas as pd\nimport numpy as np\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.svm import LinearSVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load data\ndata = pd.read_csv('/kaggle/input/tweet-sentiment-extraction/train.csv')\n\ndata.text = data.text.apply(str)\ndata.head(5)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Here only Text column is used for prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#split data in test and train data set\nx_train,x_test,y_train,y_test = train_test_split(data['text'], data.sentiment, test_size=0.3, random_state=2020, stratify= data.sentiment)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"markdown","source":"# LogisticRegression Model","execution_count":null},{"metadata":{"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"#Use LogisticRegression Model\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', LogisticRegression())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"LogisticRegression Model accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get preadiction from model\nmodel.predict(pd.Series(['this is so sad', 'This is good bro!', 'can you help me?']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# LinearSVC(Support Vector Classifier) Model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use LogisticRegression Model\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model',  LinearSVC())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"LinearSVC accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Get preadiction from model\nmodel.predict(pd.Series(['this is so sad', 'This is good bro!', 'can you help me?']))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# BernoulliNB","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', BernoulliNB())])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"BernoulliNB accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"# GradientBoostingClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', GradientBoostingClassifier(loss = 'deviance',\n                                                   learning_rate = 0.01,\n                                                   n_estimators = 5,\n                                                   max_depth = 500,\n                                                   random_state=55))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"GradientBoostingClassifier accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# DecisionTreeClassifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#Use DecisionTreeClassifier\n\npipe = Pipeline([('vect', CountVectorizer()),\n                 ('tfidf', TfidfTransformer()),\n                 ('model',  DecisionTreeClassifier(max_depth=150))])\n\nmodel = pipe.fit(x_train, y_train)\nprediction = model.predict(x_test)\nprint(\"DecisionTreeClassifier accuracy: {}%\".format(round(accuracy_score(y_test, prediction)*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" # We got max accuracy of 69.07% with LogisticRegression Model","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}