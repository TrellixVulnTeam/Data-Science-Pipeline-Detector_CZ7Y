{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import print_function, division\nfrom future.utils import iteritems\nfrom builtins import range, input\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport re\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = pd.read_csv('../input/tweet-sentiment-extraction/train.csv')\ndataset1 = pd.read_csv('../input/tweet-sentiment-extraction/test.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus = []\nfor i in range(0, 27481):\n    text_review = re.sub('[^a-zA-Z]',' ', str(dataset['text'][i]))+' '+str(dataset['sentiment'][i])\n    text_review = text_review.lower()\n    text_review = text_review.split()\n    ps = PorterStemmer()\n    text_review = [ps.stem(word) for word in text_review if not word in set(stopwords.words('english'))]\n    text_review = ' '.join(text_review)\n    corpus.append(text_review)\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus1 = []\nfor j in range(0, 3534):\n    text_review1 = re.sub('[^a-zA-Z]',' ', str(dataset1['text'][j]))+' '+str(dataset1['sentiment'][j])\n    text_review1 = text_review1.lower()\n    text_review1 = text_review1.split()\n    ps = PorterStemmer()\n    text_review1 = [ps.stem(word) for word in text_review1 if not word in set(stopwords.words('english'))]\n    text_review1 = ' '.join(text_review1)\n    corpus1.append(text_review1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv = CountVectorizer()\nX_fit = (cv.fit(corpus))\nX_train = X_fit.transform(corpus)\nX_test = X_fit.transform(corpus1)\nX_train_vect = pd.DataFrame(X_train.toarray())\nX_test_vect = pd.DataFrame(X_test.toarray())\n   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"corpus2 = []  \nfor i in range(0, 27481):\n    y_train = str(dataset['selected_text'][i])\n    y_train = y_train.split()\n    y_train = ' '.join(y_train)\n    corpus2.append(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"indexed_sentences = []\n\ni = 2\nword2idx = {'START': 0, 'END': 1}\nfor sentence in corpus2:\n    indexed_sentence = []\n    for token in sentence:\n        token = token.lower()\n        if token not in word2idx:\n            word2idx[token] = i\n            i += 1\n\n        indexed_sentence.append(word2idx[token])\n    indexed_sentences.append(indexed_sentence)\n\nprint(\"Vocab size:\", i)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word_idx_count = {\n    0: float('inf'),\n    1: float('inf'),\n  }\nidx2word = ['START', 'END']\nindex_sentences = []\nwordidx = {'START': 0, 'END': 1}\nfor sentence in corpus2:\n    index_sentence = []\n    for token in sentence:\n        token = token.lower()\n        if token not in wordidx:\n            idx2word.append(token)\n            wordidx[token] = i\n            i += 1\n\n      # keep track of counts for later sorting\n        idx = wordidx[token]\n        word_idx_count[idx] = word_idx_count.get(idx, 0) + 1\n\n        index_sentence.append(idx)\n    index_sentences.append(index_sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Y=MultiLabelBinarizer().fit_transform(indexed_sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"#from sklearn.ensemble import RandomForestClassifier\n#rf = RandomForestClassifier(n_estimators = 2, max_depth = None, n_jobs = -1)\n#rf_model= rf.fit(X_train_vect, vk)\n\nfrom sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train_vect, Y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"selected_text = classifier.predict(X_test_vect)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idxword = dict((v, k) for k, v in iteritems(wordidx))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"idxword[1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_words(sentence_num):\n    return ' '.join(idxword[z] for z in sentence)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"sent = []\nfor sentence_num in indexed_sentences:\n    word = get_words(sentence_num)\n    sent.append(word)   ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}