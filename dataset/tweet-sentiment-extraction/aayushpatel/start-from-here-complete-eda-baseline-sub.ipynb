{"cells":[{"metadata":{},"cell_type":"markdown","source":"\n# More To Come. Stay Tuned. !!\nIf there are any suggestions/changes you would like to see in the Kernel please let me know :). Appreciate every ounce of help!\n\nPlease leave any comments about further improvements to the notebook! Any feedback or constructive criticism is greatly appreciated!. \n\n### <span style=\"color:green;\">If you like it or it helps you , you can upvote and/or leave a comment :)</span>\n"},{"metadata":{},"cell_type":"markdown","source":"![](https://miro.medium.com/max/1400/1*VT7AxioAGXplMe7RAEYfSA.png)"},{"metadata":{},"cell_type":"markdown","source":"\n- <a href='#1'>1. Introduction</a>  \n- <a href='#2'>2. Retrieving the Data</a>\n     - <a href='#2-1'>2.1 Load libraries</a>\n     - <a href='#2-2'>2.2 Read the Data</a>\n- <a href='#3'>3. Glimpse of Data</a>\n     - <a href='#3-1'>3.1 Overview of tables</a>\n     - <a href='#3-2'>3.2 Statistical overview of the Data</a>\n- <a href='#4'>4. Check for missing data</a>\n- <a href='#5'>5. Data Exploration</a>\n    - <a href='#5-1'>5.1 Distribution for Text Length</a>\n    - <a href='#5-2'>5.2 Distribution for Selected Text Length</a>\n    - <a href='#5-3'>5.3 Word frequency in Text</a>\n    - <a href='#5-4'>5.4 Word frequency in Selected Text</a>\n- <a href='#6'>6. Sample Submission</a>"},{"metadata":{},"cell_type":"markdown","source":"# <a id='1'>1. Introduction</a>"},{"metadata":{},"cell_type":"markdown","source":"With all of the tweets circulating every second it is hard to tell whether the sentiment behind a specific tweet will impact a company, or a person's, brand for being viral (positive), or devastate profit because it strikes a negative tone. Capturing sentiment in language is important in these times where decisions and reactions are created and updated in seconds. But, which words actually lead to the sentiment description? In this competition you will need to pick out the part of the tweet (word or phrase) that reflects the sentiment.\n\nHelp build your skills in this important area with this broad dataset of tweets. Work on your technique to grab a top spot in this competition. What words in tweets support a positive, negative, or neutral sentiment? How can you help make that determination using machine learning tools?"},{"metadata":{},"cell_type":"markdown","source":" # <a id='2'>2. Retrieving the Data</a>"},{"metadata":{},"cell_type":"markdown","source":" ## <a id='2-1'>2.1 Load libraries</a>"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd # package for high-performance, easy-to-use data structures and data analysis\nimport numpy as np # fundamental package for scientific computing with Python\nimport matplotlib\nimport matplotlib.pyplot as plt # for plotting\nimport seaborn as sns # for making plots with seaborn\ncolor = sns.color_palette()\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.offline as offline\noffline.init_notebook_mode()\n#import cufflinks and offline mode\nimport cufflinks as cf\ncf.go_offline()\n\n# Venn diagram\nfrom matplotlib_venn import venn2\nimport re\nimport nltk\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nimport string\neng_stopwords = stopwords.words('english')\nimport gc\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.decomposition import TruncatedSVD","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nbase_dr = \"../input/tweet-sentiment-extraction\"\nprint(os.listdir(base_dr))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='2-2'>2.2 Reading Data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Reading data...')\ntrain_data = pd.read_csv(base_dr+'/train.csv')\ntest_data = pd.read_csv(base_dr+'/test.csv')\nsample_submission = pd.read_csv(base_dr+'/sample_submission.csv')\nprint('Reading data completed')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Size of train_data', train_data.shape)\nprint('Size of test_data', test_data.shape)\nprint('Size of sample_submission', sample_submission.shape)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='3'>3. Glimpse of Data</a>"},{"metadata":{},"cell_type":"markdown","source":"## <a id='3-1'>3.1 Overview of tables</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_data.head())\ndisplay(test_data.head())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='3-2'> 3.2 Statistical overview of the Data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"display(train_data.describe())\ndisplay(test_data.describe())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='4'> 4 Check for missing data</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking missing data\ntotal = train_data.isnull().sum().sort_values(ascending = False)\npercent = (train_data.isnull().sum()/train_data.isnull().count()*100).sort_values(ascending = False)\nmissing_train_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_train_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# checking missing data\ntotal = test_data.isnull().sum().sort_values(ascending = False)\npercent = (test_data.isnull().sum()/test_data.isnull().count()*100).sort_values(ascending = False)\nmissing_test_data  = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\nmissing_test_data.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='5'>5. Data Exploration</a>"},{"metadata":{},"cell_type":"markdown","source":"# <a id='5-1'>5.1 Distribution for Text Length</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_question_title=train_data['text'].str.len()\ntest_question_title=test_data['text'].str.len()\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,6))\nsns.distplot(train_question_title,ax=ax1,color='blue')\nsns.distplot(test_question_title,ax=ax2,color='green')\nax2.set_title('Distribution in test data')\nax1.set_title('Distribution in Training data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# <a id='5-2'>5.2 Distribution for Selected Text Length</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_question_title=train_data['selected_text'].str.len()\nfig,(ax1,ax2)=plt.subplots(1,2,figsize=(10,6))\nsns.distplot(train_question_title,ax=ax1,color='blue')\nax1.set_title('Distribution in Training data')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='5-3'>5-3 Word frequency in Text</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training data\nfreq_dist = FreqDist([word for text in train_data['text'].str.replace('[^a-za-z0-9^,!.\\/+-=]',' ') for word in str(text).split()])\nplt.figure(figsize=(20, 7))\nplt.title('Word frequency (Training Data)').set_fontsize(25)\nplt.xlabel('').set_fontsize(25)\nplt.ylabel('').set_fontsize(25)\nfreq_dist.plot(60,cumulative=False)\nplt.show()\n\n# test data\nfreq_dist = FreqDist([word for text in test_data['text'] for word in str(text).split()])\nplt.figure(figsize=(20, 7))\nplt.title('Word frequency (Test Data)').set_fontsize(25)\nplt.xlabel('').set_fontsize(25)\nplt.ylabel('').set_fontsize(25)\nfreq_dist.plot(60,cumulative=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='5-4'>5-4 Word frequency in Selected Text</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"# training data\nfreq_dist = FreqDist([word for text in train_data['selected_text'].str.replace('[^a-za-z0-9^,!.\\/+-=]',' ') for word in str(text).split()])\nplt.figure(figsize=(20, 7))\nplt.title('Word frequency (Training Data)').set_fontsize(25)\nplt.xlabel('').set_fontsize(25)\nplt.ylabel('').set_fontsize(25)\nfreq_dist.plot(60,cumulative=False)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='5-5'>5-5 Most Common Selected Text</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 10\ntrain_data['selected_text'].value_counts()[:n].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### <a id='5-5-1'>5-5-1 For categories</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 3\ntrain_data[train_data['sentiment']=='neutral']['selected_text'].value_counts()[:n].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 3\ntrain_data[train_data['sentiment']=='positive']['selected_text'].value_counts()[:n].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = 3\ntrain_data[train_data['sentiment']=='negative']['selected_text'].value_counts()[:n].index.tolist()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## <a id='6'>6 Sample Submission</a>"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['selected_text'] = 'good'\ntest_data['selected_text'] = np.where(test_data['sentiment']=='neutral' , 'I see', test_data['selected_text']) \ntest_data['selected_text'] = np.where(test_data['sentiment']=='negative' , 'miss', test_data['selected_text']) \ntest_data.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['selected_text'] = test_data['text']\ntest_data.head(6)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample = pd.read_csv(\"../input/tweet-sentiment-extraction/sample_submission.csv\")\nsample.loc[:, 'selected_text'] = test_data['selected_text']\nsample.to_csv(\"submission.csv\", index=False)\nsample.head(6)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# More To Come. Stay Tuned. !!"}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}