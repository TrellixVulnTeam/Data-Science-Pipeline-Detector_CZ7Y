{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Introduction\nThe challenge we are faced with in this competition is not a usual one for kaggle, at least not that frequent. I could not even take a part in it eventually due to lack of spare time. But... Climate? Sustainable Future? How can I not even explore what data is given? Hopefully you find my insights not totally useless. Thanks for checking the notebook out anyways :)"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"# imports\nimport os\nimport pandas as pd\nimport geopandas as gpd\nfrom shapely import wkt\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm.notebook import tqdm\nfrom nltk import word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.probability import FreqDist\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"root_dir = os.path.join('..', 'input', 'cdp-unlocking-climate-solutions')\nmain_paths = {'cities_disclosing': os.path.join(root_dir, 'Cities', 'Cities Disclosing'),\n         'cities_questionnaires': os.path.join(root_dir, 'Cities', 'Cities Responses'),\n         'corp_climate_change': os.path.join(root_dir, 'Corporations','Corporations Disclosing', 'Climate Change'),\n         'corp_water_seq': os.path.join(root_dir, 'Corporations','Corporations Disclosing', 'Water Security'),\n         'corp_quest_cc': os.path.join(root_dir, 'Corporations','Corporations Responses', 'Climate Change'),\n         'corp_quest_cc': os.path.join(root_dir, 'Corporations','Corporations Responses', 'Water Security')\n        }\n\ndfs = {}\nfor k, v in main_paths.items():\n    for f in os.listdir(v):\n        df = pd.read_csv(os.path.join(v, f))\n        dfs[k+'_'+f] = df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"cities_dics = pd.concat(\n    [dfs['cities_disclosing_2018_Cities_Disclosing_to_CDP.csv'],\n    dfs['cities_disclosing_2019_Cities_Disclosing_to_CDP.csv'],\n    dfs['cities_disclosing_2020_Cities_Disclosing_to_CDP.csv']])\n\ncities_quest = pd.concat(\n    [dfs['cities_questionnaires_2018_Full_Cities_Dataset.csv'],\n    dfs['cities_questionnaires_2019_Full_Cities_Dataset.csv'],\n    dfs['cities_questionnaires_2020_Full_Cities_Dataset.csv']])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_dics.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_dics.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_dics.describe()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"What jumped into my eyes right away is a huge standard deviation of population size and minimum population. Here, take a look."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"pop = cities_dics[['Population', 'City', 'Country']].dropna().sort_values('Population', ascending=False)\ntop_10 = pd.DataFrame({'Population': pop.Population.values[0:10],\n          'City': pop.City.values[0:10],\n            'Country': pop.Country.values[0:10]})\nbottom_10 = pd.DataFrame({'Population': pop.Population.values[-10:],\n             'City': pop.City.values[-10:],\n            'Country': pop.Country.values[-10:]})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = [11,5]\nfig, ax = plt.subplots(1, 2)\nax[0].bar(x=top_10['City'], height=top_10['Population'], color='gold');\nax[1].bar(x=bottom_10['City'], height=bottom_10['Population'], color='aqua');\nax[0].tick_params(axis='x', rotation=55);\nax[1].tick_params(axis='x', rotation=55);\nax[0].set_title('The most populated cities');\nax[1].set_title('The least populated cities');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = [11,5]\nfig, ax = plt.subplots(1, 2)\nax[0].bar(x=top_10['Country'], height=top_10['Population'], color='gold');\nax[1].bar(x=bottom_10['Country'], height=bottom_10['Population'], color='aqua');\nax[0].tick_params(axis='x', rotation=55);\nax[1].tick_params(axis='x', rotation=55);\nax[0].set_title('The most populated countries');\nax[1].set_title('The least populated countries');","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This certainly raises the question how data was collected especially when googling population sizes and getting far different results (in some cases even shifting the decimal point would not seem to help). Fixing each and every entery doesn't look like that easy task in this circumstances but we might consider this later."},{"metadata":{"trusted":true,"_kg_hide-input":true,"_kg_hide-output":true},"cell_type":"code","source":"del pop, top_10, bottom_10","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Let us look into another files, perphaps other files have something interesting. Say, questionnaires."},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_quest.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_quest.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('We have {} % responses. Others are NaNs.'.format(round(\n    100*cities_quest['Response Answer'].isna().sum()/len(cities_quest), 3)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_quest = cities_quest[cities_quest['Response Answer'].notnull()]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We have a lot of data here but for now I will limit it with only answes to which we have responses. Let us take a closer look at the texts."},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_quest['Question Name'].value_counts()[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_quest['Response Answer'].value_counts()[:10]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_quest['Response Answer'].value_counts()[-5:]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_quest[cities_quest['Response Answer']=='Question not applicable'].head(3)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"cell_type":"code","source":"def words_from_column(frame, column, sample=False):\n    \n    if sample:\n        words = frame[column].sample(n=1000)\n    else:\n        words = frame[column]\n        \n    words = [re.sub(r'[^\\w\\s]', '', x).lower() for x in words]\n    if len(words)==0:\n        words = frame[column]\n    words = tqdm([y for x in words for y in x.split(' ')])\n    words = [x for x in words if x not in stopwords.words('english')]\n    words = [x for x in words if x not in '`!@#$%^&*()_+=~\".,?']\n    \n    return words","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"words = words_from_column(cities_quest, 'Question Name', sample=True)\nprint('Top 10 words in questions sample are:\\n{}'.format(', '.join(words[:10])))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"words = words_from_column(cities_quest[cities_quest['Row Name'].notnull()], 'Row Name', True)\nprint('Top 10 words in topics sample are:\\n{}'.format(', '.join(words[:10])))","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"orgs = cities_quest[cities_quest['Response Answer'].notnull()].groupby('Organization')\ntop_responders = orgs.size().sort_values(ascending=False)[:10]\nplt.bar(top_responders.index, top_responders.values, color='green');\nplt.tick_params(axis='x', rotation=45);\nplt.title('Top 10 responders by questions counts');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = [16,10]\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\nax = world.plot(color='white', edgecolor='black')\ncities_dics['geometry'] = cities_dics['City Location'].dropna().reset_index(drop=True).apply(wkt.loads)\ncities_geo = gpd.GeoDataFrame(cities_dics, geometry='geometry')\ncities_geo.plot(color='green', ax=ax, markersize=5);","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For corporations questionnaire we actually have two parts: regarding climate change and water cecurity. Let us see if we should update our priors about the data these two files contain."},{"metadata":{"trusted":true},"cell_type":"code","source":"water_df = pd.concat(\n    [dfs['corp_quest_cc_2018_Full_Water_Security_Dataset.csv'],\n    dfs['corp_quest_cc_2019_Full_Water_Security_Dataset.csv'],\n    dfs['corp_quest_cc_2020_Full_Water_Security_Dataset.csv']])\nwater_df.head(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"water_df.shape","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":false,"trusted":true},"cell_type":"code","source":"water_df.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"water_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Remember the shape of the dataframe? Well, we have two columns with values missing, (almost) fully missing."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"print('Out of {} non-null values we have {} unique ones.'.format(\n    water_df.comments.dropna().shape[0], water_df.comments.dropna().nunique()))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"That's interesting. It is clear why would pure responses to questions not be unique, questions are the same and reponses templated. But why would not be comments? With next version of the notebook we will investigate it."},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"plt.rcParams[\"figure.figsize\"] = [15, 7]\norgs = water_df[water_df['response_value'].notnull()].groupby('organization')\ntop_responders = orgs.size().sort_values(ascending=False)[:15]\nplt.bar(top_responders.index, top_responders.values, color='#d52915');\nplt.tick_params(axis='x', rotation=45);\nplt.title('Top 10 responders by questions counts');","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}