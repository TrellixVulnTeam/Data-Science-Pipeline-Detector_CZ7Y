{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\nimport os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', None)\n\nimport random\nimport re\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nfrom PIL import Image\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nfrom nltk import pos_tag\nfrom nltk.corpus import stopwords\n\nimport gensim\nfrom gensim.utils import simple_preprocess\nfrom gensim.parsing.preprocessing import STOPWORDS\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom nltk.stem import WordNetLemmatizer, SnowballStemmer\nfrom nltk.stem.porter import *\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.rcParams.update({\n    'axes.labelsize': 18\n})\n\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def read_csv(path):\n    return pd.read_csv(path)\n\ndef get_questions_by_org(cities_df):\n    gb = cities_df.groupby(['Organization', 'Year Reported to CDP'])\n    \n    data = gb.agg({\n        'Question Number': 'nunique'\n    }).reset_index()\n    \n    return data\n\ndef get_org_with_missing_bars(questions_by_year, organizations, columns=None):\n    \n    arr1 = []\n    arr2 = []\n    arr3 = []\n\n    for org in organizations:\n        years_missing = list(set([2018, 2019, 2020]) - set(questions_by_year[questions_by_year['Organization'] == org]['Year Reported to CDP'].values))\n        arr2.extend(years_missing)\n        arr1.extend([org] * len(years_missing))\n        arr3.extend([0] * len(years_missing))\n        \n    return pd.DataFrame(zip(arr1, arr2, arr3), columns=columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":true},"cell_type":"code","source":"def stacked_bar_plot(data, labels, legends, title, colors, **rcParams):\n    def autolabel(current_rects, sum_widths, xpos='center', color='white'):\n        for i, rect in enumerate(current_rects):\n            width = int(rect.get_width())\n            yloc = rect.get_y() + rect.get_height() / 2\n            \n            if width == 0:\n                continue\n            ax.annotate('{}'.format(width), xy=(width / 2 + sum_widths[i], yloc), color=color, weight='bold', \n                        size=10, ha='center', va='center')\n            \n    def get_sum_bars(index, bars):\n        sum_bars = np.zeros(len(bars[index]))\n        prev_bars = bars[0:index]\n        for vects in prev_bars:\n            for i, elem in enumerate(vects):\n                sum_bars[i] += elem\n                \n        return sum_bars\n            \n    rects = []\n        \n    if rcParams and 'figsize' in rcParams:\n        fig, ax = plt.subplots(figsize = rcParams['figsize'])\n    else:\n        fig, ax = plt.subplots(figsize = (12, 8))\n        \n    y_pos = np.arange(len(labels))\n    \n    for k, bar in enumerate(bars):\n            \n        rect1 = ax.barh(y_pos, bar, left=get_sum_bars(k, bars), color=colors[k], edgecolor='yellow')\n        rects.insert(k, rect1)\n\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(labels)\n        \n    \n    for i, rect in enumerate(rects):\n        sum_widths = np.zeros(len(rect))\n        for r in rects[0:i]:\n            for i, j in enumerate(r):\n                sum_widths[i] += j.get_width()\n            \n        autolabel(rect, sum_widths)\n\n    plt.title(title, fontsize=13)\n    plt.legend(legends)\n    plt.show()\n    \ndef autolabel(current_rects, sum_widths, xpos='center', color='white'):\n    for i, rect in enumerate(current_rects):\n        width = int(rect.get_width())\n        yloc = rect.get_y() + rect.get_height() / 2\n        ax.annotate('{}'.format(width), xy=(width, yloc), color=color, weight='bold', size=13, verticalalignment='center')\n    \n    \ndef display_bar_plot(bars, labels, title):\n    \n    fig, ax = plt.subplots(figsize = (10, 7))\n        \n    y_pos = np.arange(len(bars))\n    rects = ax.barh(y_pos, bars, color='#0504aa', alpha=0.7, edgecolor='blue')\n    ax.set_yticks(y_pos)\n    ax.set_yticklabels(labels)\n    \n    autolabel(rects, [0] * len(rects))\n    plt.title(title, fontsize=14)\n    plt.show()\n    ","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true},"cell_type":"code","source":"def create_ngrams(response, n):\n    tokens = response.split()\n    \n    ngrams = list()\n    for i in range(0, len(tokens) - 1):\n        ngrams.append(\" \".join(tokens[i:i + n]))\n        \n    return ngrams","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SOURCE_PATH = \"../input/cdp-unlocking-climate-solutions/\"\nSUPPLE_PATH = \"../input/cdp-unlocking-climate-solutions/Supplementary Data/\"\n\nCOLORS = ['#0504aa', '#34495E', '#A15BF0']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 1. Read all files"},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls -l '/kaggle/input/cdp-unlocking-climate-solutions/Corporations/Corporations Disclosing/Water Security/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# cities response\n\ncities_2018 = read_csv(f\"{SOURCE_PATH}/Cities/Cities Responses/2018_Full_Cities_Dataset.csv\")\ncities_2019 = read_csv(f\"{SOURCE_PATH}/Cities/Cities Responses/2019_Full_Cities_Dataset.csv\")\ncities_2020 = read_csv(f\"{SOURCE_PATH}/Cities/Cities Responses/2020_Full_Cities_Dataset.csv\")\n\n# cities disclosing\n\ncities_dis_2018 = read_csv(f\"{SOURCE_PATH}/Cities/Cities Disclosing/2018_Cities_Disclosing_to_CDP.csv\")\ncities_dis_2019 = read_csv(f\"{SOURCE_PATH}/Cities/Cities Disclosing/2019_Cities_Disclosing_to_CDP.csv\")\ncities_dis_2020 = read_csv(f\"{SOURCE_PATH}/Cities/Cities Disclosing/2020_Cities_Disclosing_to_CDP.csv\")\n\n# corporations response\n\ncr_ws_2018 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Responses/Water Security/2018_Full_Water_Security_Dataset.csv\")\ncr_ws_2019 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Responses/Water Security/2019_Full_Water_Security_Dataset.csv\")\ncr_ws_2020 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Responses/Water Security/2020_Full_Water_Security_Dataset.csv\")\n\ncr_cc_2018 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Responses/Climate Change/2018_Full_Climate_Change_Dataset.csv\")\ncr_cc_2019 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Responses/Climate Change/2019_Full_Climate_Change_Dataset.csv\")\ncr_cc_2020 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Responses/Climate Change/2020_Full_Climate_Change_Dataset.csv\")\n\n# Corporations Disclosing water security\n\ncr_dis_ws_2018 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Disclosing/Water Security/2018_Corporates_Disclosing_to_CDP_Water_Security.csv\")\ncr_dis_ws_2019 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Disclosing/Water Security/2019_Corporates_Disclosing_to_CDP_Water_Security.csv\")\ncr_dis_ws_2020 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Disclosing/Water Security/2020_Corporates_Disclosing_to_CDP_Water_Security.csv\")\n\n# Corporations Disclosing climate change\n\ncr_dis_cc_2018 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Disclosing/Climate Change/2018_Corporates_Disclosing_to_CDP_Climate_Change.csv\")\ncr_dis_cc_2019 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Disclosing/Climate Change/2019_Corporates_Disclosing_to_CDP_Climate_Change.csv\")\ncr_dis_cc_2020 = read_csv(f\"{SOURCE_PATH}/Corporations/Corporations Disclosing/Climate Change/2020_Corporates_Disclosing_to_CDP_Climate_Change.csv\")\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"supp_cdp_rec = pd.read_excel(f\"{SUPPLE_PATH}/Recommendations from CDP/CDP_recommendations_for_supplementary_datasets_to_include.xlsx\")\n                             \nsupp_cdp_qs = pd.read_excel(f\"{SUPPLE_PATH}/Recommendations from CDP/CDP_recommendations_for_questions_to_focus_on.xlsx\")\n\nus_cities_mappings = read_csv(f\"{SUPPLE_PATH}/Simple Maps US Cities Data/uscities.csv\")\n\ncorp_locations = read_csv(f\"{SUPPLE_PATH}/Locations of Corporations/NA_HQ_public_data.csv\")\n\ncdc_VI_County = read_csv(f\"{SUPPLE_PATH}/CDC Social Vulnerability Index 2018/SVI2018_US_COUNTY.csv\")\n\ncdc_VI = read_csv(f\"{SUPPLE_PATH}/CDC Social Vulnerability Index 2018/SVI2018_US.csv\")\n\n# data dictionary\ndd = read_csv(f\"{SOURCE_PATH}/Cities/Cities Responses/Full_Cities_Response_Data_Dictionary.csv\")\n\ndd_cities_dis = read_csv(f\"{SOURCE_PATH}/Cities/Cities Disclosing/Cities_Disclosing_to_CDP_Data_Dictionary.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"STOPS = stopwords.words('english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def normalize_text(sentence):\n    \n    # 1. Split into sentences\n    sentences = sent_tokenize(sentence)\n    sentences = list(map(str.lower, sentences))\n    \n    return sentences","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Join data"},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_df = pd.concat([cities_2018, cities_2019, cities_2020])                  # Cities Response\n\ncities_dis_df = pd.concat([cities_dis_2018, cities_dis_2019, cities_dis_2020])  # Cities Disclosure\n\ncr_ws_df = pd.concat([cr_ws_2018, cr_ws_2019, cr_ws_2020])                      # Corporations Response Water Security\n\ncr_cc_df = pd.concat([cr_cc_2018, cr_cc_2019, cr_cc_2020])                      # Corporations Response Climate Change\n\ncr_dis_ws_df = pd.concat([cr_dis_ws_2018, cr_dis_ws_2019, cr_dis_ws_2020])      # Corporations Disclosure Water Supply\n\ncr_dis_cc_df = pd.concat([cr_dis_cc_2018, cr_dis_cc_2019, cr_dis_cc_2020])      # Corporations Disclosure Climate Change","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_df_merged = cities_df.merge(cities_dis_df, on=['CDP Region', 'Country', 'Account Number', 'Organization', 'Year Reported to CDP'], how='left', suffixes=('', '_dis'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sections_df = cities_df.groupby('Parent Section').agg({\n    'Section': 'unique'\n}).reset_index()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Currencies across organization"},{"metadata":{"trusted":true},"cell_type":"code","source":"temp = cities_df[cities_df['Question Number'] == '0.4']\n\nres = temp.groupby('Response Answer').agg({\n    'Organization': 'nunique',\n    'CDP Region': 'unique'\n}).reset_index()\n\nres['CDP Region'] = res['CDP Region'].apply(lambda x: \",\".join(x))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 10\nd = res.loc[random.sample(list(res.sort_values(by=['Organization'], ascending=[0]).index.ravel()[:N]), N)]\nbars = []\nbars.append(list(d['Organization'].values))\n\nstacked_bar_plot(bars, labels=d['Response Answer'], legends=['All'], title='# Organizations with currency', colors=COLORS)\n\ndel d\ndel N\ndel bars","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. Introduction"},{"metadata":{"trusted":true},"cell_type":"code","source":"def join_by_column_name(cities_df, used_cols):\n    grouped = cities_df.groupby('Parent Section')\n    \n    df = grouped.get_group('Introduction')\n    \n    df1 = df[df['Column Name'] == 'Current population']\n    df2 = df[df['Column Name'] == 'Projected population']\n    df3 = df[df['Column Name'] == 'Current population year']\n    df4 = df[df['Column Name'] == 'Projected population year']\n    \n    merged_df = df1[used_cols].merge(df2[used_cols], on=['Year Reported to CDP', 'Account Number'], suffixes=('_cur', '_proj'))\n    merged_df = merged_df.merge(df3[used_cols], on=['Year Reported to CDP', 'Account Number'])\n    merged_df = merged_df.merge(df4[used_cols], on=['Year Reported to CDP', 'Account Number'])\n    \n    merged_df = merged_df[filter_columns(merged_df.columns, used_cols)]\n    \n    merged_df.rename(columns={\n        'Response Answer_cur': merged_df['Column Name_cur'].iloc[0],\n        'Response Answer_proj': merged_df['Column Name_proj'].iloc[0],\n        'Response Answer_x': merged_df['Column Name_x'].iloc[0],\n        'Response Answer_y': merged_df['Column Name_y'].iloc[0]\n    }, inplace=True)\n    \n    merged_df.drop(columns=['Column Name_cur', 'Column Name_proj', 'Column Name_x', 'Column Name_y'], inplace=True)\n    \n    return merged_df\n\ndef filter_columns(all_cols, used_cols):\n    return [i for i in all_cols if i.split('_')[0] in used_cols]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_df = cities_df.sort_values(by=['Year Reported to CDP', 'Account Number', 'Question Number', 'Column Number', 'Row Number'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = cities_df.groupby(['Year Reported to CDP', 'Account Number', 'Question Number'])\n\ngrouped_sect = cities_df.groupby(['Parent Section'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df = join_by_column_name(cities_df, ['Year Reported to CDP', 'Account Number', 'Column Name', 'Response Answer'])\nmerged_df = merged_df.dropna()\n\nmerged_df = merged_df[~merged_df['Current population year'].isin(['216', '7', '19', '217'])]\nmerged_df['Current population'] = merged_df['Current population'].astype(float)\nmerged_df['Projected population'] = merged_df['Projected population'].astype(float)\n\ncity_names = cities_df.loc[cities_df['Account Number'].isin(merged_df['Account Number'])][['Account Number', 'Organization', 'Country']].drop_duplicates()\nmerged_df = merged_df.merge(city_names, on='Account Number', how='inner')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df['pop_diff'] = (merged_df['Projected population'] - merged_df['Current population'])\n\nmerged_df['years'] = merged_df['Projected population year'].astype(int) - merged_df['Current population year'].astype(int)\n\nmerged_df['unit_diff'] = merged_df['pop_diff'] / merged_df['years']                                                                                                                   \n                                                                                                                      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 10\nd = merged_df[(merged_df['Year Reported to CDP'] == 2020) & (merged_df['pop_diff'] == 0)][:N]\nbars = []\nbars.append(list(d['pop_diff'].values))\n\nstacked_bar_plot(bars, labels=d['Organization'].str.cat(d['Country'], sep=\"\\n\"), legends=['2020'], title='Population with no increase', colors=COLORS, **dict(figsize=(7, 5)))\n\ndel d\ndel N\ndel bars","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"merged_df[:2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"N = 10\nd = merged_df.loc[random.sample(list(merged_df[(merged_df['unit_diff'] > 0) & (merged_df['Year Reported to CDP'] == 2020)]['pop_diff'].sort_values()[::-1].index.ravel()[:10]), 10)]\n\nbars = []\nbars.append(list(d['unit_diff'].values))\n\nstacked_bar_plot(bars, labels=d['Organization'].str.cat(d['Country'], sep=\"\\n\"), legends=['2020'], title='Population with no increase', colors=COLORS, **dict(figsize=(10, 7)))\n\ndel d\ndel N\ndel bars","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Climate Hazards"},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_df[cities_df['Parent Section'].isin(['Climate Hazards', 'Climate Hazards & Vulnerability', 'Climate Hazards and Vulnerability'])]\\\n[['Question Number', 'Question Name']].drop_duplicates()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### 5.1 Risk Assessment actions"},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_df[(cities_df['Question Number'] == '2.0')]['Question Name'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q2_df = cities_df[(cities_df['Question Number'] == '2.0') & ~(cities_df['Response Answer'].isnull())]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"res = q2_df.groupby('Account Number')['Response Answer'].size().reset_index(name='size')\n\nfor ans in q2_df['Response Answer'].unique():\n    res[ans] = 0","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_words(answers, key):\n    return np.sum([1 for i in answers if i == key])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for ans in q2_df['Response Answer'].unique():\n    res[ans] = res.apply(lambda x: count_words(q2_df.groupby('Account Number').get_group(x['Account Number'])['Response Answer'], ans), axis=1)\n    \nfor ans in q2_df['Response Answer'].unique():\n    res[ans] = res[ans] / res['size']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"values = []\nfor ans in q2_df['Response Answer'].unique():\n    values.append(np.sum(res[ans] > 0) / len(res['Account Number']) * 100)\n\nvalues = pd.Series(values, index=list(q2_df['Response Answer'].unique()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q2_mappings = dict()\n\nfor i in range(len(res)):\n    q2_mappings[res.loc[i, 'Account Number']] = []\n    [q2_mappings[res.loc[i, 'Account Number']].append(ans) for ans in q2_df['Response Answer'].unique() if res.loc[i, ans] > 0]\n    \nfor k, v in q2_mappings.items():\n    q2_mappings[k] = \"-\".join(v)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bars = []\nd = pd.Series(q2_mappings.values()).value_counts()\nbars.append(d[d > 10])\n\nstacked_bar_plot(bars, labels=d[d>10].index, legends=['2018 + 2019 + 2020'], title='Cities with Risk Assessment actions', colors=COLORS, **dict(figsize=(8, 7)))\n\ndel d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q2_df = cities_df[(cities_df['Question Number'].isin(['2.0a', '2.0b', '2.0c', '2.0d']))]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"q2_df[q2_df['Question Number'] == '2.0a']['Question Name'].unique()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Primary methodology"},{"metadata":{"trusted":true},"cell_type":"code","source":"grouped = q2_df[(q2_df['Question Number'] == '2.0a') & (q2_df['Column Name'] == 'Primary methodology')].groupby('Response Answer').agg({\n    'Organization': 'nunique'\n}).reset_index()\n\ngrouped = grouped.sort_values(by=['Organization'], ascending=[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bars = []\nd = grouped[grouped['Organization'] > 1]\nbars.append(d['Organization'])\n\nstacked_bar_plot(bars, labels=d['Response Answer'], legends=['2018 + 2019 + 2020'], title='Primary methods', colors=COLORS, **dict(figsize=(8, 9)))\n\ndel d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = q2_df[(q2_df['Question Number'] == '2.0a') & ~(q2_df['Column Name'] == 'Primary methodology')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cities_df[(cities_df['Question Number'] == '2.1')]['Question Name'].unique()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"keywords = ['heat', 'rain', 'economic', 'environment', 'forest', 'hazards']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = cities_df[(cities_df['Question Number'] == '2.1')]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bars = []\nd = cities_df[(cities_df['Question Name'] == 'Does your city have an update / revision process for the climate risk or vulnerability assessment?')]\\\n.groupby('Response Answer').apply(len)\nbars.append(d)\n\nstacked_bar_plot(bars, labels=d.index, legends=['2018 + 2019 + 2020'], title='Cities with climate revision plan', colors=COLORS, **dict(figsize=(7, 5)))\n\ndel d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"list(df['Response Answer'].drop_duplicates())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vectorizer = CountVectorizer()\n\n# X = vectorizer.fit_transform(q2_df['Response Answer'].dropna())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}