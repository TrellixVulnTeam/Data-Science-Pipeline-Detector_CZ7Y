{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!curl https://raw.githubusercontent.com/pytorch/xla/master/contrib/scripts/env-setup.py -o pytorch-xla-env-setup.py\n!python pytorch-xla-env-setup.py --version 1.7 --apt-packages libomp5 libopenblas-dev","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-14T14:05:30.751037Z","iopub.execute_input":"2021-08-14T14:05:30.751474Z","iopub.status.idle":"2021-08-14T14:06:43.91248Z","shell.execute_reply.started":"2021-08-14T14:05:30.751373Z","shell.execute_reply":"2021-08-14T14:06:43.911396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install pytorch-lightning==1.1.5\n!pip install transformers","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:06:43.914164Z","iopub.execute_input":"2021-08-14T14:06:43.914442Z","iopub.status.idle":"2021-08-14T14:07:00.162829Z","shell.execute_reply.started":"2021-08-14T14:06:43.914412Z","shell.execute_reply":"2021-08-14T14:07:00.161917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nfrom tqdm.auto import tqdm\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers import AutoConfig, AutoModel, AutoTokenizer\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import  ModelCheckpoint, EarlyStopping\nfrom pytorch_lightning.loggers import TensorBoardLogger\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, multilabel_confusion_matrix\n\nimport seaborn as sns\nfrom pylab import rcParams\nimport matplotlib.pyplot as plt\nfrom matplotlib import rc\n\n%matplotlib inline\n%config InlineBackend.figure_format='retina'\n\nRANDOM_SEED = 716\n\nsns.set(style='whitegrid', palette='muted', font_scale=1.2)\nHAPPY_COLORS_PALETTE = [\"#01BEFE\", \"#FFDD00\", \"#FF7D00\", \"#FF006D\", \"#ADFF02\", \"#8F00FF\"]\nsns.set_palette(sns.color_palette(HAPPY_COLORS_PALETTE))\nrcParams['figure.figsize'] = 12, 8\n\npl.seed_everything(RANDOM_SEED)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:00.164563Z","iopub.execute_input":"2021-08-14T14:07:00.164958Z","iopub.status.idle":"2021-08-14T14:07:16.257204Z","shell.execute_reply.started":"2021-08-14T14:07:00.164917Z","shell.execute_reply":"2021-08-14T14:07:16.256441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input/jigsaw-multilingual-toxic-comment-classification/","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:16.258588Z","iopub.execute_input":"2021-08-14T14:07:16.258989Z","iopub.status.idle":"2021-08-14T14:07:17.007937Z","shell.execute_reply.started":"2021-08-14T14:07:16.258961Z","shell.execute_reply":"2021-08-14T14:07:17.006857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load data as pandas dataframe\ntrain_df = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv\")\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:17.011649Z","iopub.execute_input":"2021-08-14T14:07:17.011974Z","iopub.status.idle":"2021-08-14T14:07:19.7958Z","shell.execute_reply.started":"2021-08-14T14:07:17.01194Z","shell.execute_reply":"2021-08-14T14:07:19.79487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:19.797054Z","iopub.execute_input":"2021-08-14T14:07:19.797388Z","iopub.status.idle":"2021-08-14T14:07:19.802972Z","shell.execute_reply.started":"2021-08-14T14:07:19.797357Z","shell.execute_reply":"2021-08-14T14:07:19.80212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:19.804245Z","iopub.execute_input":"2021-08-14T14:07:19.804569Z","iopub.status.idle":"2021-08-14T14:07:20.733681Z","shell.execute_reply.started":"2021-08-14T14:07:19.804541Z","shell.execute_reply":"2021-08-14T14:07:20.732976Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# split data to train and valid\ntrain_df, val_df = train_test_split(train_df, test_size=0.1)\ntrain_df.shape, val_df.shape, test_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:20.735895Z","iopub.execute_input":"2021-08-14T14:07:20.736351Z","iopub.status.idle":"2021-08-14T14:07:20.801038Z","shell.execute_reply.started":"2021-08-14T14:07:20.736306Z","shell.execute_reply":"2021-08-14T14:07:20.800154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# distribution of labels\nLABEL_COLUMNS = train_df.columns.tolist()[2:]\ntrain_df[LABEL_COLUMNS].sum().sort_values().plot(kind=\"barh\");","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:20.802657Z","iopub.execute_input":"2021-08-14T14:07:20.802941Z","iopub.status.idle":"2021-08-14T14:07:21.179761Z","shell.execute_reply.started":"2021-08-14T14:07:20.802914Z","shell.execute_reply":"2021-08-14T14:07:21.178583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# distribution of clean and toxic comments\ntrain_toxic = train_df[train_df[LABEL_COLUMNS].sum(axis=1) > 0]\ntrain_clean = train_df[train_df[LABEL_COLUMNS].sum(axis=1) == 0]\n\npd.DataFrame(dict(\n  toxic=[len(train_toxic)], \n  clean=[len(train_clean)]\n)).plot(kind='barh');","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:21.181552Z","iopub.execute_input":"2021-08-14T14:07:21.181991Z","iopub.status.idle":"2021-08-14T14:07:21.519824Z","shell.execute_reply.started":"2021-08-14T14:07:21.181944Z","shell.execute_reply":"2021-08-14T14:07:21.518579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample clean comments and keep all the toxic comments\ntrain_df = pd.concat([\n  train_toxic,\n  train_clean.sample(20000)\n])\n\ntrain_df.shape, val_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:21.521455Z","iopub.execute_input":"2021-08-14T14:07:21.521852Z","iopub.status.idle":"2021-08-14T14:07:21.553036Z","shell.execute_reply.started":"2021-08-14T14:07:21.52181Z","shell.execute_reply":"2021-08-14T14:07:21.552199Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define the model to use from huggingface\nBERT_MODEL_NAME = 'bert-base-cased'\ntokenizer = AutoTokenizer.from_pretrained(BERT_MODEL_NAME)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:21.554166Z","iopub.execute_input":"2021-08-14T14:07:21.554439Z","iopub.status.idle":"2021-08-14T14:07:23.489578Z","shell.execute_reply.started":"2021-08-14T14:07:21.554412Z","shell.execute_reply":"2021-08-14T14:07:23.488603Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check a sample visually\n\nsample_row = train_df.iloc[456]\nsample_comment = sample_row.comment_text\nsample_labels = sample_row[LABEL_COLUMNS]\n\nprint(sample_comment)\nprint()\nprint(sample_labels.to_dict())","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:23.491117Z","iopub.execute_input":"2021-08-14T14:07:23.491531Z","iopub.status.idle":"2021-08-14T14:07:23.499368Z","shell.execute_reply.started":"2021-08-14T14:07:23.491487Z","shell.execute_reply":"2021-08-14T14:07:23.498232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# encode the sample comment\nencoding = tokenizer.encode_plus(\n    sample_comment,\n    add_special_tokens=True,\n    max_length=128,\n    return_token_type_ids=False,\n    padding=\"max_length\",\n    return_attention_mask=True,\n    return_tensors=\"pt\"\n)\n\nencoding.keys()","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:23.50064Z","iopub.execute_input":"2021-08-14T14:07:23.501038Z","iopub.status.idle":"2021-08-14T14:07:23.517646Z","shell.execute_reply.started":"2021-08-14T14:07:23.501008Z","shell.execute_reply":"2021-08-14T14:07:23.51662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define max token count as 128\nMAX_TOKEN_COUNT = 128","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:23.518825Z","iopub.execute_input":"2021-08-14T14:07:23.519259Z","iopub.status.idle":"2021-08-14T14:07:23.524226Z","shell.execute_reply.started":"2021-08-14T14:07:23.519228Z","shell.execute_reply":"2021-08-14T14:07:23.523531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define dataset\nclass ToxicDataset(Dataset):\n\n    def __init__(self,\n               data,\n               tokenizer,\n               max_token_len=128):\n        self.tokenizer = tokenizer\n        self.data = data\n        self.max_token_len = max_token_len\n\n  \n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n\n        data_row = self.data.iloc[idx]\n\n        comment_text = data_row.comment_text\n        labels = data_row[LABEL_COLUMNS]\n\n        encoding = self.tokenizer.encode_plus(\n          comment_text,\n          add_special_tokens=True,\n          max_length=self.max_token_len,\n          return_token_type_ids=False,\n          padding=\"max_length\",\n          truncation=True,\n          return_attention_mask=True,\n          return_tensors='pt',\n        )\n\n        return dict(\n          comment_text=comment_text,\n          input_ids=encoding[\"input_ids\"].flatten(),\n          attention_mask=encoding[\"attention_mask\"].flatten(),\n          labels=torch.FloatTensor(labels)\n        )","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:23.525525Z","iopub.execute_input":"2021-08-14T14:07:23.52618Z","iopub.status.idle":"2021-08-14T14:07:23.535977Z","shell.execute_reply.started":"2021-08-14T14:07:23.526104Z","shell.execute_reply":"2021-08-14T14:07:23.535241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create dataset for train\ntrain_dataset = ToxicDataset(\n    train_df,\n    tokenizer,\n    max_token_len=MAX_TOKEN_COUNT\n)\n\n# pick out a sample item\nsample_item = train_dataset[0]","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:23.537162Z","iopub.execute_input":"2021-08-14T14:07:23.537736Z","iopub.status.idle":"2021-08-14T14:07:23.559279Z","shell.execute_reply.started":"2021-08-14T14:07:23.537694Z","shell.execute_reply":"2021-08-14T14:07:23.558306Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check the shape\nsample_item['input_ids'].shape, sample_item['attention_mask'].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:23.560695Z","iopub.execute_input":"2021-08-14T14:07:23.561088Z","iopub.status.idle":"2021-08-14T14:07:23.570191Z","shell.execute_reply.started":"2021-08-14T14:07:23.561048Z","shell.execute_reply":"2021-08-14T14:07:23.569383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the model\nmodel = AutoModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:23.571496Z","iopub.execute_input":"2021-08-14T14:07:23.571811Z","iopub.status.idle":"2021-08-14T14:07:36.330903Z","shell.execute_reply.started":"2021-08-14T14:07:23.571782Z","shell.execute_reply":"2021-08-14T14:07:36.330035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# try passing a sample batch through the model and check the output shape\nsample_batch = next(iter(DataLoader(train_dataset, batch_size=8, num_workers=2)))\nsample_batch['input_ids'].shape, sample_batch['attention_mask'].shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:36.332376Z","iopub.execute_input":"2021-08-14T14:07:36.332794Z","iopub.status.idle":"2021-08-14T14:07:36.460714Z","shell.execute_reply.started":"2021-08-14T14:07:36.332751Z","shell.execute_reply":"2021-08-14T14:07:36.459506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# make outputs\noutput = model(sample_batch['input_ids'], sample_batch['attention_mask'])","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:36.462544Z","iopub.execute_input":"2021-08-14T14:07:36.462962Z","iopub.status.idle":"2021-08-14T14:07:38.495174Z","shell.execute_reply.started":"2021-08-14T14:07:36.462917Z","shell.execute_reply":"2021-08-14T14:07:38.494248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check shapes\noutput.last_hidden_state.shape, output.pooler_output.shape","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:38.496415Z","iopub.execute_input":"2021-08-14T14:07:38.49672Z","iopub.status.idle":"2021-08-14T14:07:38.503317Z","shell.execute_reply.started":"2021-08-14T14:07:38.496689Z","shell.execute_reply":"2021-08-14T14:07:38.502289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\"\"\"\n    Datamodule for Lightning\n\"\"\"\n\nclass ToxicDataModule(pl.LightningDataModule):\n\n    def __init__(self, train_df, test_df, tokenizer, batch_size=8, max_token_len=128):\n\n        super().__init__()\n        self.batch_size = batch_size\n        self.train_df = train_df\n        self.test_df = test_df\n        self.tokenizer = tokenizer\n        self.max_token_len = max_token_len\n\n    def setup(self, stage=None):\n\n        self.train_dataset = ToxicDataset(\n            self.train_df,\n            self.tokenizer,\n            self.max_token_len\n        )\n\n        self.test_dataset = ToxicDataset(\n            self.test_df,\n            self.tokenizer,\n            self.max_token_len\n        )\n\n    def train_dataloader(self):\n        return DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=True,\n            num_workers=4\n        )\n\n    def val_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=4\n        )\n\n    def test_dataloader(self):\n        return DataLoader(\n            self.test_dataset,\n            batch_size=self.batch_size,\n            shuffle=False,\n            num_workers=4\n        )","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:38.508149Z","iopub.execute_input":"2021-08-14T14:07:38.508551Z","iopub.status.idle":"2021-08-14T14:07:38.526425Z","shell.execute_reply.started":"2021-08-14T14:07:38.508514Z","shell.execute_reply":"2021-08-14T14:07:38.525315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# set epochs and batch_size\nN_EPOCHS = 10\nBATCH_SIZE = 32\n\n# create datamodule to be used in trainer later\ndata_module = ToxicDataModule(\n    train_df,\n    val_df,\n    tokenizer,\n    batch_size=BATCH_SIZE,\n    max_token_len=MAX_TOKEN_COUNT\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:38.528678Z","iopub.execute_input":"2021-08-14T14:07:38.529074Z","iopub.status.idle":"2021-08-14T14:07:38.539831Z","shell.execute_reply.started":"2021-08-14T14:07:38.529032Z","shell.execute_reply":"2021-08-14T14:07:38.539151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from pytorch_lightning.metrics.functional import accuracy, f1, auroc\nfrom transformers import AdamW, get_linear_schedule_with_warmup\n\nTHRESHOLD = 0.5\n\n\"\"\"\n    Define the model class extending LightningModule\n    \n\"\"\"\n\nclass ToxicModel(pl.LightningModule):\n\n    def __init__(self, n_classes=len(LABEL_COLUMNS), n_training_steps=None, n_warmup_steps=None):\n\n        super().__init__()\n\n        self.base = AutoModel.from_pretrained(BERT_MODEL_NAME, return_dict=True)\n        self.classifier = nn.Linear(self.base.config.hidden_size, n_classes)\n        self.n_training_steps = n_training_steps\n        self.n_warmup_steps = n_warmup_steps\n        self.criterion = nn.BCELoss() # loss function\n\n  \n    def forward(self, input_ids, attention_masks, labels=None):\n\n        output = self.base(input_ids, attention_mask=attention_masks)\n        output = self.classifier(output.pooler_output)\n        output = torch.sigmoid(output)\n\n        loss = 0\n        if labels is not None:\n            loss = self.criterion(output, labels)\n\n        return loss, output\n\n    def training_step(self, batch, batch_idx):\n\n        input_ids = batch[\"input_ids\"]\n        attention_masks = batch[\"attention_mask\"]\n        labels = batch[\"labels\"]\n\n        loss, output = self(input_ids, attention_masks, labels)\n\n        self.log(\"train_loss\", loss, prog_bar=True, logger=True)\n\n        return {\"loss\": loss, \"predictions\": output, \"labels\": labels}\n\n    def validation_step(self, batch, batch_idx):\n\n        input_ids = batch[\"input_ids\"]\n        attention_masks = batch[\"attention_mask\"]\n        labels = batch[\"labels\"]\n\n        loss, output = self(input_ids, attention_masks, labels)\n\n        self.log(\"val_loss\", loss, prog_bar=True, logger=True)\n\n        return {\"val_loss\": loss, \"predictions\": output, \"labels\": labels}\n\n    def test_step(self, batch, batch_idx):\n\n        input_ids = batch[\"input_ids\"]\n        attention_masks = batch[\"attention_mask\"]\n        labels = batch[\"labels\"]\n\n        loss, output = self(input_ids, attention_masks, labels)\n\n        self.log(\"test_loss\", loss, prog_bar=True, logger=True)\n\n        return loss\n\n  \n    def training_epoch_end(self, training_outputs):\n\n        labels = []\n        outputs = []\n\n        for output in training_outputs:\n            for out_labels in output[\"labels\"].detach().cpu():\n                labels.append(out_labels)\n            for out_preds in output[\"predictions\"].detach().cpu():\n                outputs.append(out_preds)\n\n        labels = torch.stack(labels).int()\n        preds = torch.stack(outputs)\n\n        for i, name in enumerate(LABEL_COLUMNS):\n            class_roc_auc = auroc(preds[:, i], labels[:, i])\n            self.logger.experiment.add_scalar(f\"{name}_roc_auc/Train\", class_roc_auc,\n                                            self.current_epoch)\n        \n        preds = torch.where(preds >= THRESHOLD, 1., 0.)\n        train_acc = accuracy(preds, labels)\n        self.log(\"train_acc\", train_acc, prog_bar=True, logger=True)\n        \n            \n    def validation_epoch_end(self, val_outputs):\n\n        labels = []\n        outputs = []\n\n        for output in val_outputs:\n            for out_labels in output[\"labels\"].detach().cpu():\n                labels.append(out_labels)\n            for out_preds in output[\"predictions\"].detach().cpu():\n                outputs.append(out_preds)\n\n        labels = torch.stack(labels).int()\n        preds = torch.stack(outputs)\n\n        preds = torch.where(preds >= THRESHOLD, 1., 0.)\n        val_acc = accuracy(preds, labels)\n        self.log(\"val_acc\", val_acc, prog_bar=True, logger=True)\n      \n\n    def configure_optimizers(self):\n\n        optimizer = AdamW(self.parameters(), lr=2e-5)\n\n        scheduler = get_linear_schedule_with_warmup(\n          optimizer,\n          num_warmup_steps=self.n_warmup_steps,\n          num_training_steps=self.n_training_steps\n        )\n\n        return dict(\n          optimizer=optimizer,\n          lr_scheduler=dict(\n            scheduler=scheduler,\n            interval='step'\n          )\n        )","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:38.542468Z","iopub.execute_input":"2021-08-14T14:07:38.543304Z","iopub.status.idle":"2021-08-14T14:07:38.575076Z","shell.execute_reply.started":"2021-08-14T14:07:38.543259Z","shell.execute_reply":"2021-08-14T14:07:38.574125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"steps_per_epoch = len(train_df) // BATCH_SIZE\ntotal_training_steps = steps_per_epoch * N_EPOCHS\n\nwarmup_steps = total_training_steps // 5\n\nwarmup_steps, total_training_steps","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:38.576469Z","iopub.execute_input":"2021-08-14T14:07:38.577087Z","iopub.status.idle":"2021-08-14T14:07:38.591096Z","shell.execute_reply.started":"2021-08-14T14:07:38.576954Z","shell.execute_reply":"2021-08-14T14:07:38.590385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = ToxicModel(\n    n_classes=len(LABEL_COLUMNS),\n    n_warmup_steps=warmup_steps,\n    n_training_steps=total_training_steps\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:38.592269Z","iopub.execute_input":"2021-08-14T14:07:38.592814Z","iopub.status.idle":"2021-08-14T14:07:40.31205Z","shell.execute_reply.started":"2021-08-14T14:07:38.59278Z","shell.execute_reply":"2021-08-14T14:07:40.311326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"_, predictions = model(sample_batch[\"input_ids\"], sample_batch[\"attention_mask\"])\npredictions","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:40.313353Z","iopub.execute_input":"2021-08-14T14:07:40.313883Z","iopub.status.idle":"2021-08-14T14:07:42.27017Z","shell.execute_reply.started":"2021-08-14T14:07:40.313841Z","shell.execute_reply":"2021-08-14T14:07:42.269148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"accuracy(torch.where(predictions > 0.5, 1, 0), sample_batch[\"labels\"])","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:42.2714Z","iopub.execute_input":"2021-08-14T14:07:42.271744Z","iopub.status.idle":"2021-08-14T14:07:42.280186Z","shell.execute_reply.started":"2021-08-14T14:07:42.271712Z","shell.execute_reply":"2021-08-14T14:07:42.279225Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -rf lightning_logs/\n!rm -rf checkpoints/","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:42.281742Z","iopub.execute_input":"2021-08-14T14:07:42.282077Z","iopub.status.idle":"2021-08-14T14:07:43.916565Z","shell.execute_reply.started":"2021-08-14T14:07:42.282046Z","shell.execute_reply":"2021-08-14T14:07:43.915308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"checkpoint_callback = ModelCheckpoint(\n  dirpath=\"checkpoints\",\n  filename=\"best-checkpoint\",\n  save_top_k=1,\n  verbose=True,\n  monitor=\"val_loss\",\n  mode=\"min\"\n)\n\nlogger = TensorBoardLogger(\"lightning_logs\", name=\"toxic-comments\")\n\nearly_stopping_callback = EarlyStopping(monitor='val_loss', patience=2)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:43.918495Z","iopub.execute_input":"2021-08-14T14:07:43.9188Z","iopub.status.idle":"2021-08-14T14:07:43.928307Z","shell.execute_reply.started":"2021-08-14T14:07:43.918769Z","shell.execute_reply":"2021-08-14T14:07:43.927248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer = pl.Trainer(\n  logger=logger,\n  callbacks=[early_stopping_callback, checkpoint_callback],\n  max_epochs=N_EPOCHS,\n  tpu_cores=8,\n  progress_bar_refresh_rate=30\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:43.929823Z","iopub.execute_input":"2021-08-14T14:07:43.930173Z","iopub.status.idle":"2021-08-14T14:07:43.947Z","shell.execute_reply.started":"2021-08-14T14:07:43.930118Z","shell.execute_reply":"2021-08-14T14:07:43.946198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.fit(model, data_module)","metadata":{"execution":{"iopub.status.busy":"2021-08-14T14:07:43.948231Z","iopub.execute_input":"2021-08-14T14:07:43.94877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.test()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model = ToxicModel.load_from_checkpoint(\n  trainer.checkpoint_callback.best_model_path,\n  n_classes=len(LABEL_COLUMNS),\n  n_training_steps=1,\n  n_warmup_steps=1\n)\ntrained_model.eval()\ntrained_model.freeze()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_model.device","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_comment = \"Hi, I'm Meredith and I'm an alch... good at supplier relations\"\n\nencoding = tokenizer.encode_plus(\n  test_comment,\n  add_special_tokens=True,\n  max_length=128,\n  return_token_type_ids=False,\n  padding=\"max_length\",\n  return_attention_mask=True,\n  return_tensors='pt',\n)\n\n_, test_prediction = trained_model(encoding[\"input_ids\"], encoding[\"attention_mask\"])\ntest_prediction = test_prediction.flatten().numpy()\n\nfor label, prediction in zip(LABEL_COLUMNS, test_prediction):\n    print(f\"{label}: {prediction}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}