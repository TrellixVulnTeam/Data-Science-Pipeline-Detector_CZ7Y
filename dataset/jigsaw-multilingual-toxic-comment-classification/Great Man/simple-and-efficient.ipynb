{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"try:\n\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom tqdm import tqdm\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import LSTM, GRU, SimpleRNN\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import BatchNormalization\nimport tensorflow.keras as keras\nfrom sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\nfrom tensorflow.keras.layers import GlobalMaxPooling1D, Conv1D, MaxPooling1D, Flatten, Bidirectional, SpatialDropout1D\nfrom tensorflow.keras.preprocessing import sequence, text\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.models import model_from_json \nimport os\nfrom keras.callbacks import EarlyStopping\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1)\n\n\nmax_len = 1200\nbatch_size = 400*strategy.num_replicas_in_sync\n\nepoch = 2\nimport matplotlib.pyplot as plt\n# train = pd.read_csv('jigsaw-toxic-comment-train.csv')\n# validation = pd.read_csv('validation.csv')\ntrain = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\nvalidation = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ntrain.drop(['id', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate'], axis=1, inplace=True)\nvalidation.drop(['id', 'lang'], axis=1, inplace=True)\nX = train.append(validation)\n\n\n\nX = X.sample(frac=1).reset_index(drop=True)\n# size_data = 50000\n# X = X.loc[:size_data, :]\n\n\n\n# max length of string\nprint(train.comment_text.apply(lambda x: len(str(x).split())).max())\ndef roc_auc(predictions,target):\n    \n    fpr, tpr, thresholds = metrics.roc_curve(target, predictions)\n    roc_auc = metrics.auc(fpr, tpr)\n    return roc_auc\nxtrain, xvalid, ytrain, yvalid = train_test_split(X.comment_text.values, X.toxic.values, \n                                                stratify=X.toxic.values, \n                                                random_state=42, \n                                                test_size=0.2, shuffle=True)\n\n# Tokenizer\ntoken = text.Tokenizer(num_words=None)\n\ntoken.fit_on_texts(list(xtrain) + list(xvalid))\nxtrain_seq = token.texts_to_sequences(xtrain)\nxvalid_seq = token.texts_to_sequences(xvalid)\n\n#zero pad the sequences\nxtrain_pad = sequence.pad_sequences(xtrain_seq, maxlen=max_len)\nxvalid_pad = sequence.pad_sequences(xvalid_seq, maxlen=max_len)\n\nword_index = token.word_index\n\ndef create_model():\n    model = Sequential()\n    model.add(Embedding(len(word_index) + 1,\n                    300,\n                    input_length=max_len))\n    model.add(SimpleRNN(100))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=[keras.metrics.TruePositives(name='tp'),\n        keras.metrics.FalsePositives(name='fp'),\n        keras.metrics.TrueNegatives(name='tn'),\n        keras.metrics.FalseNegatives(name='fn'),\n        keras.metrics.BinaryAccuracy(name='accuracy'),\n        keras.metrics.Precision(name='precision'),\n        keras.metrics.Recall(name='recall'),\n        keras.metrics.AUC(name='auc')])\n    return model\ndef save_model(model):\n    model_json = model.to_json()\n    with open(\"model.json\", \"w\") as json_file:\n        json_file.write(model_json)\n    model.save_weights(\"model.h5\")\n    print(\"Saved model to disk\")\n\ndef load_model():\n    json_file = open('model.json', 'r')\n    loaded_model_json = json_file.read()\n    json_file.close()\n    loaded_model = model_from_json(loaded_model_json)\n    loaded_model.load_weights(\"model.h5\")\n    print(\"Loaded model from disk\")\n    return loaded_model\n\nweightList = list(train.toxic.value_counts())\ntoxic_weights = (1/weightList[1]) * ((weightList[1] + weightList[0])/2)\nnontoxic_weights = (1/weightList[0]) * ((weightList[1] + weightList[0])/2)\nclass_weights = {0:nontoxic_weights, 1:toxic_weights}\n\nif os.path.exists(\"model.h5\") and os.path.exists('model.json'):\n    model = load_model()\nelse:\n    model = create_model()\n\nprint(model.summary())\n\n\nmodel.fit(xtrain_pad, ytrain, epochs=epoch, batch_size=batch_size, class_weight=class_weights, validation_data=(xvalid_pad, yvalid))\nsave_model(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"scores = model.predict(xvalid_pad)\nprint(\"Auc: %.2f%%\" % (roc_auc(scores,yvalid)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\ntest.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()\ntest_data = token.texts_to_sequences(test.content)\ntest_data_seq = sequence.pad_sequences(test_data, maxlen=max_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['toxic'] = model.predict(test_data_seq, verbose=1)\ntest[['id', 'toxic']].to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}