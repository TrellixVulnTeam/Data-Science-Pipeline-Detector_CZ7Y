{"cells":[{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-12-13T11:36:05.653422Z","iopub.status.busy":"2020-12-13T11:36:05.652288Z","iopub.status.idle":"2020-12-13T11:36:05.65978Z","shell.execute_reply":"2020-12-13T11:36:05.659024Z"},"papermill":{"duration":0.040891,"end_time":"2020-12-13T11:36:05.659951","exception":false,"start_time":"2020-12-13T11:36:05.61906","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2020-12-13T11:36:05.719378Z","iopub.status.busy":"2020-12-13T11:36:05.718513Z","iopub.status.idle":"2020-12-13T11:36:16.858283Z","shell.execute_reply":"2020-12-13T11:36:16.857513Z"},"papermill":{"duration":11.173355,"end_time":"2020-12-13T11:36:16.858416","exception":false,"start_time":"2020-12-13T11:36:05.685061","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:36:16.918885Z","iopub.status.busy":"2020-12-13T11:36:16.917849Z","iopub.status.idle":"2020-12-13T11:36:20.575139Z","shell.execute_reply":"2020-12-13T11:36:20.574291Z"},"papermill":{"duration":3.692054,"end_time":"2020-12-13T11:36:20.57527","exception":false,"start_time":"2020-12-13T11:36:16.883216","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom transformers import TFAutoModel, AutoTokenizer\nimport transformers\nfrom tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\nfrom tokenizers import BertWordPieceTokenizer\nfrom tqdm import tqdm","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:36:20.68584Z","iopub.status.busy":"2020-12-13T11:36:20.684943Z","iopub.status.idle":"2020-12-13T11:36:23.942887Z","shell.execute_reply":"2020-12-13T11:36:23.942111Z"},"papermill":{"duration":3.291841,"end_time":"2020-12-13T11:36:23.943025","exception":false,"start_time":"2020-12-13T11:36:20.651184","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"../input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df:\n    print(i,df[i].isna().sum(),df[i].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.drop_duplicates(subset =\"comment_text\", \n                     keep = False, inplace = True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in df:\n    if(df[i].isna().sum()>1000000):\n        del df[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('publication_id')['toxic'].mean().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('funny')['toxic'].mean().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('wow')['toxic'].mean().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('sexual_explicit')['toxic'].mean().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('identity_annotator_count')['toxic'].mean().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.groupby('toxicity_annotator_count')['toxic'].mean().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(df['sexual_explicit'][5]\n,df['comment_text'][5])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_nontoxic = df[(df['toxic'] == 0) & (df['severe_toxicity'] == 0) & (df['obscene'] == 0) & (df['threat'] == 0) & (df['insult'] == 0) & (df['identity_attack'] == 0) & (df['sexual_explicit'] == 0)]\ndf_toxic = df[(df['toxic'] != 0) | (df['severe_toxicity'] != 0) | (df['obscene'] != 0) | (df['threat'] != 0) | (df['insult'] !=0) | (df['identity_attack'] != 0) | (df['sexual_explicit'] != 0)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"new1 = df_nontoxic[['id', 'comment_text', 'toxic']].copy() \nnew2 = df_toxic[['id', 'comment_text', 'toxic']].copy()\nnew2 = new2.assign(toxic=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chakri = pd.concat([new1, new2], ignore_index=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"length=chakri['comment_text'].apply(lambda x: len(x))\nimport matplotlib.pyplot as plt\nplt.hist(length)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chakri['length']=length","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chakri.groupby('length')['toxic'].mean().sort_values(ascending=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":" chakri.drop(columns='length',inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"del df\ndel df_toxic\ndel df_nontoxic\ndel new1\ndel new2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chakri['toxic'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nX_train_test, X_val, Y_train_test, y_valid = train_test_split(chakri[\"comment_text\"], chakri['toxic'], test_size=0.2,random_state=44)\nX_train ,X_test ,y_train,Y_test = train_test_split(X_train_test, Y_train_test, test_size=0.07,random_state=44)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(X_train.shape)\nprint(X_val.shape)\nprint(X_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:36:24.005022Z","iopub.status.busy":"2020-12-13T11:36:24.003502Z","iopub.status.idle":"2020-12-13T11:36:24.009025Z","shell.execute_reply":"2020-12-13T11:36:24.008209Z"},"papermill":{"duration":0.040332,"end_time":"2020-12-13T11:36:24.009161","exception":false,"start_time":"2020-12-13T11:36:23.968829","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def fast_encode(texts, tokenizer, chunk_size=256, maxlen=512):\n    \"\"\"\n    Encoder for encoding the text into sequence of integers for BERT Input\n    Taken from Kaggle notebooks\n    \"\"\"\n    tokenizer.enable_truncation(max_length=maxlen)\n    tokenizer.enable_padding(max_length=maxlen)\n    all_ids = []\n    \n    for i in tqdm(range(0, len(texts), chunk_size)):\n        text_chunk = texts[i:i+chunk_size].tolist()\n        encs = tokenizer.encode_batch(text_chunk)\n        all_ids.extend([enc.ids for enc in encs])\n    \n    return np.array(all_ids)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:36:24.069321Z","iopub.status.busy":"2020-12-13T11:36:24.068553Z","iopub.status.idle":"2020-12-13T11:36:24.07223Z","shell.execute_reply":"2020-12-13T11:36:24.071609Z"},"papermill":{"duration":0.036492,"end_time":"2020-12-13T11:36:24.072365","exception":false,"start_time":"2020-12-13T11:36:24.035873","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def regular_encode(texts, tokenizer, maxlen=512):\n    enc_di = tokenizer.batch_encode_plus(\n        texts, \n        return_attention_masks=False, \n        return_token_type_ids=False,\n        pad_to_max_length=True,\n        max_length=maxlen\n    )\n    \n    return np.array(enc_di['input_ids'])","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:36:24.143288Z","iopub.status.busy":"2020-12-13T11:36:24.14248Z","iopub.status.idle":"2020-12-13T11:36:24.513811Z","shell.execute_reply":"2020-12-13T11:36:24.513064Z"},"papermill":{"duration":0.415036,"end_time":"2020-12-13T11:36:24.513953","exception":false,"start_time":"2020-12-13T11:36:24.098917","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nEPOCHS = 3\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nMAX_LEN = 192\nMODEL = 'jplu/tf-xlm-roberta-large'","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:36:24.579428Z","iopub.status.busy":"2020-12-13T11:36:24.578586Z","iopub.status.idle":"2020-12-13T11:36:25.708711Z","shell.execute_reply":"2020-12-13T11:36:25.707902Z"},"papermill":{"duration":1.165743,"end_time":"2020-12-13T11:36:25.708849","exception":false,"start_time":"2020-12-13T11:36:24.543106","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"tokenizer = transformers.DistilBertTokenizer.from_pretrained('distilbert-base-multilingual-cased')\ntokenizer.save_pretrained('.')\nfast_tokenizer = BertWordPieceTokenizer('vocab.txt', lowercase=False)\nfast_tokenizer","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:36:25.779645Z","iopub.status.busy":"2020-12-13T11:36:25.77879Z","iopub.status.idle":"2020-12-13T11:37:26.434389Z","shell.execute_reply":"2020-12-13T11:37:26.433609Z"},"papermill":{"duration":60.697283,"end_time":"2020-12-13T11:37:26.434571","exception":false,"start_time":"2020-12-13T11:36:25.737288","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"x_train = fast_encode(X_train.astype(str), fast_tokenizer, maxlen=MAX_LEN)\nx_valid = fast_encode(X_val.astype(str), fast_tokenizer, maxlen=MAX_LEN)\nx_test = fast_encode(X_test.astype(str), fast_tokenizer, maxlen=MAX_LEN)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:37:30.488362Z","iopub.status.busy":"2020-12-13T11:37:30.486072Z","iopub.status.idle":"2020-12-13T11:37:32.441843Z","shell.execute_reply":"2020-12-13T11:37:32.443999Z"},"papermill":{"duration":5.825968,"end_time":"2020-12-13T11:37:32.444882","exception":false,"start_time":"2020-12-13T11:37:26.618914","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"train_dataset = (tf.data.Dataset.from_tensor_slices((x_train, y_train)).repeat()\n                .shuffle(2048)\n                .batch(BATCH_SIZE)\n                .prefetch(AUTO))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_dataset = (tf.data.Dataset.from_tensor_slices((x_valid, y_valid))\n                .batch(BATCH_SIZE).cache()\n                .prefetch(AUTO))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = (tf.data.Dataset.from_tensor_slices(x_test).batch(BATCH_SIZE))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# class MyModel(Model):\n#     def __init__(self, **kwargs):\n#         super().__init__(**kwargs)\n#     def predict1(self, x, threshold=0.32):\n#         proba = super().predict(x)\n#         print(proba)\n#         return proba[proba>threshold].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:37:33.106376Z","iopub.status.busy":"2020-12-13T11:37:33.105397Z","iopub.status.idle":"2020-12-13T11:37:33.110474Z","shell.execute_reply":"2020-12-13T11:37:33.109646Z"},"papermill":{"duration":0.214957,"end_time":"2020-12-13T11:37:33.110636","exception":false,"start_time":"2020-12-13T11:37:32.895679","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def build_model(transformer, max_len=512):\n    input_word_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\")\n    sequence_output = transformer(input_word_ids)[0]\n    cls_token = sequence_output[:, 0, :]\n    out = Dense(1, activation='sigmoid')(cls_token)\n    \n    model =Model(inputs=input_word_ids, outputs=out)\n    model.compile(Adam(lr=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n    \n    return model","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:37:33.510361Z","iopub.status.busy":"2020-12-13T11:37:33.509504Z","iopub.status.idle":"2020-12-13T11:38:31.717683Z","shell.execute_reply":"2020-12-13T11:38:31.718938Z"},"papermill":{"duration":58.411465,"end_time":"2020-12-13T11:38:31.71918","exception":false,"start_time":"2020-12-13T11:37:33.307715","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"%%time\nwith strategy.scope():\n    transformer_layer = (\n        transformers.TFDistilBertModel\n        .from_pretrained('distilbert-base-multilingual-cased')\n    )\n    model = build_model(transformer_layer, max_len=MAX_LEN)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train.shape[0])\nprint(x_valid.shape[0])","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:38:32.111652Z","iopub.status.busy":"2020-12-13T11:38:32.110678Z","iopub.status.idle":"2020-12-13T11:48:04.829962Z","shell.execute_reply":"2020-12-13T11:48:04.829132Z"},"papermill":{"duration":572.918229,"end_time":"2020-12-13T11:48:04.83013","exception":false,"start_time":"2020-12-13T11:38:31.911901","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"n_steps = x_train.shape[0]\ntrain_history = model.fit(\n    train_dataset,\n    steps_per_epoch=n_steps,\n    validation_data=valid_dataset,\n    epochs=EPOCHS\n)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:48:09.578154Z","iopub.status.busy":"2020-12-13T11:48:09.573731Z","iopub.status.idle":"2020-12-13T11:49:05.224083Z","shell.execute_reply":"2020-12-13T11:49:05.224801Z"},"papermill":{"duration":57.960598,"end_time":"2020-12-13T11:49:05.225005","exception":false,"start_time":"2020-12-13T11:48:07.264407","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"n_steps = (x_valid.shape[0])\ntrain_history_2 = model.fit(\n    valid_dataset.repeat(),\n    steps_per_epoch=n_steps,\n    epochs=EPOCHS*2\n)","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:49:58.635582Z","iopub.status.busy":"2020-12-13T11:49:58.634784Z","iopub.status.idle":"2020-12-13T11:49:58.886672Z","shell.execute_reply":"2020-12-13T11:49:58.885905Z"},"papermill":{"duration":2.837479,"end_time":"2020-12-13T11:49:58.886848","exception":false,"start_time":"2020-12-13T11:49:56.049369","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"hist = train_history.history\nplt.plot(list(range(3)),hist['accuracy'],label='acc')\nplt.plot(list(range(3)),hist['val_accuracy'],label='val acc')\nplt.legend()\nplt.title('Train Vs Val Accuracy')\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:50:04.065683Z","iopub.status.busy":"2020-12-13T11:50:04.057812Z","iopub.status.idle":"2020-12-13T11:50:04.24758Z","shell.execute_reply":"2020-12-13T11:50:04.248115Z"},"papermill":{"duration":2.777611,"end_time":"2020-12-13T11:50:04.248288","exception":false,"start_time":"2020-12-13T11:50:01.470677","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"hist = train_history.history\nplt.plot(list(range(3)),hist['loss'],label='train loss')\nplt.plot(list(range(3)),hist['val_loss'],label='val loss')\nplt.legend()\nplt.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y = model.predict(test_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.DataFrame({\"y\": y}).y.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output=pd.DataFrame()\noutput['comment_text']=X_test\noutput['toxic']=y  ","execution_count":null,"outputs":[]},{"metadata":{"execution":{"iopub.execute_input":"2020-12-13T11:49:48.382655Z","iopub.status.busy":"2020-12-13T11:49:48.381886Z","iopub.status.idle":"2020-12-13T11:49:48.391982Z","shell.execute_reply":"2020-12-13T11:49:48.391103Z"},"papermill":{"duration":2.610584,"end_time":"2020-12-13T11:49:48.392114","exception":false,"start_time":"2020-12-13T11:49:45.78153","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"output.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"output.tail(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### ROC Score"},{"metadata":{"trusted":true},"cell_type":"code","source":"true_y = Y_test.values\npred_y = output.toxic.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from numpy import sqrt, argmax\nfrom matplotlib import pyplot\nfrom sklearn.metrics import roc_curve, auc\nfpr, tpr, thresholds = roc_curve(Y_test.values, output.toxic.values)\n# calculate the g-mean for each threshold\ngmeans = sqrt(tpr * (1-fpr))\n# locate the index of the largest g-mean\nix = argmax(gmeans)\nprint('Best Threshold=%f, G-Mean=%.3f' % (thresholds[ix], gmeans[ix]))\npyplot.plot([0,1], [0,1], linestyle='--', label='No Skill')\npyplot.plot(fpr, tpr, marker='.', label='Model')\npyplot.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best')\npyplot.xlabel('False Positive Rate')\npyplot.ylabel('True Positive Rate')\npyplot.legend()\npyplot.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bestThreshold = 0.295179","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def getPredictions(pred_y,threshold):\n    temp = np.copy(pred_y)\n    temp[temp < threshold] = 0\n    temp[temp >= threshold] = 1\n    return temp","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Best AUC score threshold - 0.295179 0.1 test size\nBest AUC score threshold - 0.377759 0.07 test size\n\nBest Accuracy score threshold - 0.68"},{"metadata":{"trusted":true},"cell_type":"code","source":"def getTPR(cm):\n    TN = cm[0][0]\n    FN = cm[1][0]\n    TP = cm[1][1]\n    FP = cm[0][1]\n    return TP/(TP+FN)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix\ncm = confusion_matrix(true_y, getPredictions(bestThreshold))\nprint(cm)\ngetTPR(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(true_y, getPredictions(0.311984))\nprint(cm)\ngetTPR(cm)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences = [\n    \"what the hell is going on here\",\n    \"hey, you are looking sexy\",\n    \"What a piece of shit\",\n    \"Go kill yourself\",\n    \"What's up buddy 🖕\",\n    \"Holy shit! An actual unpopular opinion, take an upvote you freak\",\n    \"Why are there so many replies from salty men (pun intended) in this thread talking about \\\nhow wearing a condom is like infringing on their rights or some shit lmao.\",\n    \"I'm sure women would fully support it.\",\n    \"It hurts you that much to wear one?\",\n    \"Men are such little bitches about condoms. \\\nIf i have to deal with birth control, periods, and other wacky vagina stuff you can deal with a piece of rubber\",\n    \"stopped at 'as a female'.\",\n    \"I wonder how many simps upvoted this shit\",\n    \"Yeah ok. Makes me vomit.\",\n    \"Here I am, busting my ass in a restaurant when I should be bumming around giving $3 to random college chicks\",\n    \"The amount of idiots defending this in these comments is staggering\",\n    \"What in the fuck?\",\n    \"the time of the week were this shit is reposted again this shits probably been on facebook already\",\n    \"Why are people so fucking stupid.\",\n    \"Jesus how many fucking times is this going to be reposted by karma whores?\",\n    \"BuT tHeY'rE iNsPiRaTiOnAl\",\n    \"Prostitutes don't get raped; they get paid. Also, how many rapes do you hear about at nudist colonies? I think I rest my case.\",\n    \"Literally used by design to keep you bickering while both sides rob you blind.\",\n    \"This is a prime example of why I dont get modernism. Like.... the portrai on the right looks like my \\\nfour year old drew it and someone shaded it for them. Im sure that incredibly ignorant but I dont know why\",\n    \"When you're a mediocre painter so you draw absolutely terrible images and call it 'art'\",\n    \"I'm guessing people jizz themselves over the one on the right? Probably sold for a ridiculous amount of money\",\n    \"It's trash. Looks like a fucking monkey drew it\",\n    \"This guy was never called an asshole.\",\n    \"Good. Stop printing money you fucking boomers.\",\n    \"mitch McConnell is a disgrace to republicans, i say that with confidence.\",\n    \"Literally the truth. The American system is broken when one fucking \\\nperson can prevent whatever they want. Where are these so-called checks and balances?\",\n    \"Can't wait until he is gone\",\n    \"Fucking hate politics.\",\n    \"This would be cooler if their music was better and the lead singer wasn’t a douche\",\n    \"Just drop a really heavy object on all 3\",\n    \"Wow they look like shit\",\n    \"Only an American idiot would misspell Woodstock.\",\n    \"So... everyone is just gonna ignore the obvious typo? Makes me think of of a Rick Flair convention. WOOOOOOSSTOCK\",\n    \"Good looking to describe men and hot to describe women just to make sure everyone knows you’re not gay.\",\n    \"Complete garbage, but super engrossing\",\n    \"Be an ignorant fool who just gathers money for no reason while they could just help the rest of the \\\nworld but they instead gather money that they don't even spend them for something....\",\n    \"being cis and straight lmao\",\n    \"Or you know you just turned to an easy crutch in a moment of weakness, fear and desperation like so many do. Open mindedness never leads to worshipping a god. You have to close your mind for that because knowledge and reason are the enemy of faith.\",\n    \"They are disgusting, expensive, loud, smelly, selfish, and obnoxious. awful in every possible way. And then factor in the possibility of having one that is damaged or broken in some manner, its like playing russian roulette with your future.\",\n    \n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(sentences)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_df = pd.DataFrame({'comment_text': sentences})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_set = fast_encode(custom_df.comment_text.astype(str), fast_tokenizer, maxlen=MAX_LEN)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.predict(custom_set)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"threshold=0.32","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_df['toxic']=getPredictions(model.predict(custom_set),threshold);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_df[['comment_text','toxic']].to_csv('output.csv', index=False)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"custom_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nimport joblib\n# pickle.dump(model, open('model.pkl','wb'))\nfilename = 'finalized_model.sav'\njoblib.dump(model, filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#numpy\n#pandas\n#tensorflow\n# import os\n# import tensorflow as tf\n# from tensorflow.keras.layers import Dense, Input\n# from tensorflow.keras.optimizers import Adam\n# from tensorflow.keras.models import Model\n# from tensorflow.keras.callbacks import ModelCheckpoint\n# from kaggle_datasets import KaggleDatasets\n# from transformers import TFAutoModel, AutoTokenizer\n# import transformers\n# from tokenizers import Tokenizer, models, pre_tokenizers, decoders, processors\n# from tokenizers import BertWordPieceTokenizer\n# from tqdm import tqdm\n#matplotlib","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}