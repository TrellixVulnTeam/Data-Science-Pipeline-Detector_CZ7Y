{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"from __future__ import print_function\nfrom builtins import range\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport transformers\nfrom transformers import TFAutoModel, AutoTokenizer\n#try:\n    # TPU detection. No parameters necessary if TPU_NAME environment variable is\n    # set: this is always the case on Kaggle.\n#    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#    print('Running on TPU ', tpu.master())\n#except ValueError:\n #   tpu = None\n\n#if tpu:\n #   tf.config.experimental_connect_to_cluster(tpu)\n  #  tf.tpu.experimental.initialize_tpu_system(tpu)\n   # strategy = tf.distribute.experimental.TPUStrategy(tpu)\n#else:\n    # Default distribution strategy in Tensorflow. Works on CPU and single GPU.\n #   strategy = tf.distribute.get_strategy()\n\n#print(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\n#AUTO = tf.data.experimental.AUTOTUNE\n\n# Data access\nMODEL = 'PD_TOXIC_X_CLASS'\n# Set your own project id here\n#PROJECT_ID = 'pd@toxic1234'\n#from google.cloud import storage\n#storage_client = storage.Client(project=PROJECT_ID)\n#from google.cloud import bigquery\n#bigquery_client = bigquery.Client(project=PROJECT_ID)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import os,sys,numpy as np,pandas as pd\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.layers import LSTM,Bidirectional,Dense,GlobalMaxPooling1D,Embedding,Input,MaxPooling1D\nfrom keras.models import Model\nfrom keras.optimizers import RMSprop\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#train data and test labels \ntrain = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\ntrain.head()\n#load word vectors\nword2vec = {}\nwith open(os.path.join('/kaggle/input/glove-vector/glove.6B.100d.txt')) as f:\n    for line in f:\n        values = line.split()\n        word = values[0]\n        vec = np.asarray((values [1:]))\n        word2vec[word] = vec\nprint('total vocab in glove',len(word2vec))\n        \n        \n        \nvalid = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ntest = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\nsub = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')\n\ny_valid = valid.toxic.values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(train.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.tail()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"max_seq_len = 20\nmax_voc_size = 400000\nembed_dim = 100\nval_split = 0.2\nbatch_size = 128\nepoch = 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#extract sentences\nsentences = train['comment_text'].fillna('DUMMY_VALUES').values\n#target\nlabels = ['toxic' ,'severe_toxic' ,'obscene' ,'threat' ,'insult' ,'identity_hate']\ntarget  = train[labels].values\nprint(sentences[1:2])\nprint(target[1:2])\n\n#SENTENCE FOR TEST\n#sentences_test = test['comment_text'].fillna('DUMMY_VALUES').values\n\n#SENTENCE FOR validate\n#sentences_validate = valid['comment_text'].fillna('DUMMY_VALUES').values\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(num_words = max_voc_size)\ntokenizer.fit_on_texts(sentences)\nsequences = tokenizer.texts_to_sequences(sentences)\n#sequences test\n#sequences_test = tokenizer.texts_to_sequences(sentences_test)\n\n#sequences validate\n#sequences_validate = tokenizer.texts_to_sequences(sentences_validate)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(sequences))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#word2idx\nword2idx = tokenizer.word_index","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#padding \npadded_seq = pad_sequences(sequences,maxlen=max_seq_len)\n\n#padding test data\n#padded_seq_test = pad_sequences(sequences_test , maxlen = max_seq_len)\n\n#padding the validate data\n#padded_seq_validate = pad_sequences(sequences_validate , maxlen = max_seq_len)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(padded_seq.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#embedding matrix\nnum_words = min(max_voc_size,len(word2idx)+1)\nembed_matrix = np.zeros((num_words,embed_dim))\nfor word , i in word2idx.items():\n    if i < max_voc_size:\n        #getting word vector\n        word_vec = word2vec.get(word)\n        if word_vec is not None:\n            embed_matrix[i]=word_vec","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#embedding layer\nembed_layer = Embedding(num_words,embed_dim,\n                        weights = [embed_matrix],\n                       input_length=max_seq_len,\n                       trainable = True)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building model\nfrom keras.optimizers import Adam\nfrom keras.layers import Activation\nimport tensorflow as tf\n# detect and init the TPU\n#tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n#tf.config.experimental_connect_to_cluster(tpu)\n#tf.tpu.experimental.initialize_tpu_system(tpu)\n\n# instantiate a distribution strategy\n#tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n#with tpu_strategy.scope():\n    \ninput_ = Input(shape = (20,))\n# = embed_layer(input_)\nx = Embedding(num_words , 20,input_length=max_seq_len)(input_)\nx = LSTM(20,return_sequences=True)(x)\nx = MaxPooling1D(3)(x)\nx = Bidirectional(LSTM(20,return_sequences = True))(x)\nx = GlobalMaxPooling1D()(x)\nx = Dense(6)(x)\nout = Activation('sigmoid')(x)\nmodel = Model(input_,out)\nmodel.compile(loss = 'binary_crossentropy',\n             optimizer = Adam(lr = 0.001),\n             metrics = ['categorical_accuracy'])\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#implementing callbacks\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\ncheckpoint = ModelCheckpoint(\"toxic_rnn.h5\",\n                            monitor=\"val_loss\",\n                            mode=\"min\",\n                            save_best_only=True,\n                            verbose=1)\nearly_stopping = EarlyStopping(monitor=\"val_loss\",\n                              min_delta=0,\n                              patience=3,\n                              verbose=1,\n                              restore_best_weights=True)\nreduce_lr = ReduceLROnPlateau(monitor=\"val_loss\",\n                             factor=0.1,\n                             patience=3,\n                             verbose=1,\n                             min_delta=0.0001)\n#putting callbacks in callbacks list\ncallbacks = [checkpoint,early_stopping,reduce_lr]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"r = model.fit(padded_seq,target,batch_size=batch_size,epochs=epoch,validation_split = 0.2 ,callbacks=callbacks)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('/kaggle/working/toxic_softmax3_notglove.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install simplejson","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import simplejson as json","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer_json = tokenizer.to_json()\nwith open('tokenizer.json', 'w', encoding='utf-8') as f:\n    f.write(json.dumps(tokenizer_json, ensure_ascii=False))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import load_model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2 = load_model('/kaggle/working/toxic_softmax3_notglove.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model2.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sentences_new = train['comment_text'].fillna('DUMMY_VALUES').values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.preprocessing.text import tokenizer_from_json\nwith open('tokenizer.json') as f:\n    data = json.load(f)\n    tokenizer4 = tokenizer_from_json(data)\n\n\n\n\n#tokenizer2 = Tokenizer(num_words = 20000)\n#tokenizer2.fit_on_texts(sentences_new)\nsequences_cus = tokenizer4.texts_to_sequences(sentences_new)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"word2idx = tokenizer2.word_index\nprint(word2idx[FUCKED])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#s = ['COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK']\ns = ['I amm happy for you brother']\ns2 = ['i will kill you motherfucker']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tokenizer2 = Tokenizer(num_words =  20000)\n#tokenizer.fit_on_texts(s)\nsequences_custom = tokenizer4.texts_to_sequences(s)\nsequences_custom2 = tokenizer4.texts_to_sequences(s2)\nprint(sequences_custom)\nprint(sequences_custom2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"padded_seq_cus = pad_sequences(sequences_custom,maxlen=20,padding  = 'post')\npadded_seq_cus_2 = pad_sequences(sequences_custom2,maxlen=20,padding  = 'post')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(padded_seq_cus_2)\nprint(padded_seq_cus_2.shape)\nprint(padded_seq_cus)\nprint(padded_seq_cus.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = model2.predict(padded_seq_cus)\nx2 = model2.predict(padded_seq_cus_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x.shape)\nprint(x2.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x)\nprint(x2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def category(arr):\n    label = ['toxic','severe','obscene','threat','insult','identity_hate']\n    for a in arr:\n        for x in range(6):\n            print ('sentence is {} percent toxic of category {} '.format(a[x],label[x]))\nprint(category(x))\nprint(category(x2))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def loaded(name):\n    from keras.preprocessing.text import tokenizer_from_json\n    with open(name) as f:\n        data = json.load(f)\n        tokenizer_loaded = tokenizer_from_json(data)\n        return tokenizer_loaded\ndef load_saved_model(location):\n     model_infer = load_model('/kaggle/working/toxic_softmax3_notglove.h5')\n     return model_infer\n\ndef pipeline(lis):\n    name = 'tokenizer.json'\n    location = '/kaggle/working/toxic_softmax3_notglove.h5'\n    model_infer = load_saved_model(location)\n    tokenizer_pipe = loaded(name)\n    sequences_custom_pipe = tokenizer_pipe.texts_to_sequences(lis)\n    padded_seq_cus_pipe = pad_sequences(sequences_custom_pipe,maxlen=20,padding  = 'post')\n    pred = model_infer.predict(padded_seq_cus_pipe)\n    category(pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lis = ['i want to kill you till death']\nlis2 = ['motherfucker fuck you man']\nlis3 = ['i am happy that you got the job']\npipeline(lis)\npipeline(lis2)\npipeline(lis3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}