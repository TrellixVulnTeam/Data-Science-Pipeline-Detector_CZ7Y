{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Exploratory Data Analysis","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-toxic-comment-train.csv')\ndf.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# dropping id and comment text\ndf_toxic = df.drop(['id', 'comment_text'], axis=1)\n# calculating total count of each category comments\ncounts = []\ncategories = list(df_toxic.columns.values)\nfor i in categories:\n    counts.append((i, df_toxic[i].sum()))\ndf_stats = pd.DataFrame(counts, columns=['category', 'count'])\ndf_stats","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# df_toxic.sum().plot(kind=\"bar\")\n\nsns.set(style=\"whitegrid\")\nsns.barplot(x='category', y='count', data=df_stats, palette=\"summer\")\nplt.title(\"Number Of Comments For Each Tag\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This shows that the number of comments in each category is extremely unbalanced. We can further check whether each comment has been tagged or not?","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"rowsums = df_toxic.iloc[:,:].sum(axis=1)\nvalcount = rowsums.value_counts()\nvalcount.plot.bar()\nplt.xlabel(\"# of labels tagged to\")\nplt.ylabel(\"# of comments\")\nplt.title(\"Comments that have multiple labels tagged\")\nplt.show()\n\nprint(valcount[0]*100/sum(valcount),\"% comments have no labels associated to them.\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This essentially shows that a large amount of the entire dataset is tagged to none of the six labels.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = df.comment_text.str.len()\nsns.distplot(lens)\nplt.title(\"Distribution for Lengths of Comments\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This indicates that most of the comments are of lengths less than 500, while some are of length 5000 as well.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"# Of Vacant Comments : \", df['comment_text'].isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(df.corr(), square=True, cmap='nipy_spectral')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_pickle('cleaned_data.pkl')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nimport seaborn as sns\nimport matplotlib.pyplot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_pickle('cleaned_data.pkl')\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ntrain, test = train_test_split(df, test_size=0.33, random_state=42, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape, test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = train['comment_text']\nX_test = test['comment_text']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Machine Learning Pipeline","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracies = [[],[],[]]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Multinomial Naive Bayes","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\ncvec = CountVectorizer()\ntvec = TfidfTransformer()\nmodel1 = MultinomialNB()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = tvec.fit_transform(cvec.fit_transform(X_train))\nX_test = tvec.transform(cvec.transform(X_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape, X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfor category in labels:\n    model1.fit(X_train, train[category])\n    accuracy = model1.score(X_test, test[category])\n    accuracies[0].append(accuracy)\n    print(\"Accuracy For {0} Class Is {1}%\".format(category,round(accuracy*100,2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Linear Support Vector Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\nfrom sklearn.svm import LinearSVC\nmodel2 = LinearSVC()\nfor category in labels:\n    model2.fit(X_train, train[category])\n    accuracy = model2.score(X_test, test[category])\n    accuracies[1].append(accuracy)\n    print(\"Accuracy For {0} Class Is {1}%\".format(category,round(accuracy*100,2)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Logistic Regression Classifier","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\nmodel3 = LogisticRegression(n_jobs=1, solver='liblinear')\nfor category in labels:\n    model3.fit(X_train, train[category])\n    accuracy = model3.score(X_test, test[category])\n    accuracies[2].append(accuracy)\n    print(\"Accuracy For {0} Class Is {1}%\".format(category,round(accuracy*100,2)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"accuracies = pd.DataFrame(accuracies)\nfig = accuracies.plot.bar(figsize=(16, 5), grid=True)\nplt.xticks(np.arange(3),('Multinomial Naive Bayes','Linear Support Vector Classifier','Logistic Regression'),rotation=0)\nplt.legend(labels)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(3):\n    print(\"Model -\",i+1,\"... Aggregate Accuracy -\",np.mean(accuracies.iloc[i,:]))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Thus, we can see that model0 performs best overall by a very slight margin. It is a multinomial naive bayes classifier.","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}