{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Importing Libraries","execution_count":null},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"cell_type":"code","source":"import pandas as pd, numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\nfrom scipy.sparse import hstack\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import WordNetLemmatizer,PorterStemmer\nfrom nltk.corpus import stopwords\nimport re\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Loading dataset","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train2 = pd.read_csv(\"/kaggle/input/jigsaw-multilingual-toxic-comment-classification/jigsaw-unintended-bias-train.csv\")\ntrain2.toxic = train2.toxic.round().astype(int)\nvalid1 = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/validation.csv')\ntest = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/test.csv')\nsubm = pd.read_csv('/kaggle/input/jigsaw-multilingual-toxic-comment-classification/sample_submission.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train2=train2[:500000] # as this a too large dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.concat([train2[['comment_text', 'toxic']].query('toxic==1'),\n    train2[['comment_text', 'toxic']].query('toxic==0'),valid1[['comment_text', 'toxic']]]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['comment_text'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['content'][0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = train.comment_text.str.len()\nlens.mean(), lens.std(), lens.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens.hist();","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens = test.content.str.len()\nlens.mean(), lens.std(), lens.max()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lens.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train),len(test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,6))\ncomment_len=train[train['toxic']==1]['comment_text'].str.len()\nax1.hist(comment_len,color='cyan',linewidth=2,edgecolor='k')\nax1.set_title('toxic comments')\ncomment_len=train[train['toxic']==0]['comment_text'].str.len()\nax2.hist(comment_len,color='blue',linewidth=2,edgecolor='k')\nax2.set_title('Not toxic comments')\nfig.suptitle('Characters in Comments',fontsize=20)\n\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,(ax1,ax2)=plt.subplots(1,2,figsize=(12,6))\ncomment_words=train[train['toxic']==1]['comment_text'].str.split().map(lambda x: len(x))\nax1.hist(comment_words,color='magenta',linewidth=2,edgecolor='k')\nax1.set_title('toxic comments')\ncomment_words=train[train['toxic']==0]['comment_text'].str.split().map(lambda x: len(x))\nax2.hist(comment_words,color='red',linewidth=2,edgecolor='k')\nax2.set_title('Non toxic comments')\nfig.suptitle('Words in comments',fontsize=20)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"label_cols = ['toxic']\n\ntrain.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['comment_text'].fillna(\"unknown\", inplace=True)\ntest['content'].fillna(\"unknown\", inplace=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Text Preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def lower(words):\n    return words.lower()\ntrain['comment_text']=train['comment_text'].apply(lambda x:lower(x))\ndef remove_numbers(words):\n    return re.sub(r'\\d+','',words)\ntrain['comment_text']=train['comment_text'].apply(lambda x: remove_numbers(x))\ndef remove_punctuation(words):\n    table=str.maketrans('','',string.punctuation)\n    return words.translate(table)\ntrain['comment_text']=train['comment_text'].apply(lambda x: remove_punctuation(x))\ntrain['comment_text']=train['comment_text'].apply(lambda x:word_tokenize(x))\ndef remove_stopwords(words):\n    stop_words=set(stopwords.words('english'))\n    return [word for word in words if word not in stop_words]\ntrain['comment_text']=train['comment_text'].apply(lambda x: remove_stopwords(x))\ndef remove_links(words):\n    \n    return [re.sub(r'(https?://\\S+)','',word)for word in words]\ntrain['comment_text']=train['comment_text'].apply(lambda x:remove_links(x))\ndef lemmatizing(words):\n    lemmatizer =WordNetLemmatizer()\n    return [lemmatizer.lemmatize(word) for word in words]\ntrain['comment_text']=train['comment_text'].apply(lambda x: lemmatizing(x))\ndef final_text(words):\n     return ' '.join(words)\ntrain['comment_text']=train['comment_text'].apply(lambda x:final_text(x))\n   \n                 ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n = train.shape[0]\nvec = TfidfVectorizer(ngram_range=(1,3),\n               strip_accents='unicode', use_idf=1,\n               smooth_idf=1, sublinear_tf=1 )\ntrn_term_doc = vec.fit_transform(train['comment_text'])\ntest_term_doc = vec.transform(test['content'])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def pr(y_i, y):\n    p = x[y==y_i].sum(0)\n    return (p+1) / ((y==y_i).sum()+1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = trn_term_doc\ntest_x = test_term_doc","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Training ML model","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model(y):\n    y = y.values\n    r = np.log(pr(1,y) / pr(0,y))\n    m = LogisticRegression(C=4, dual=False)\n    x_nb = x.multiply(r)\n    return m.fit(x_nb, y), r","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = np.zeros((len(test), len(label_cols)))\n\nfor i, j in enumerate(label_cols):\n    print('fit', j)\n    m,r = get_model(train[j])\n    preds[:,i] = m.predict_proba(test_x.multiply(r))[:,1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submid = pd.DataFrame({'id': subm[\"id\"]})\nsubmission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n\nsubmission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.head(n=20)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}