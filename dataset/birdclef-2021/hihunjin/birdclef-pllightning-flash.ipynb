{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%capture\n!pip install 'lightning-flash[image]'","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:05:32.410972Z","iopub.execute_input":"2021-12-16T15:05:32.411515Z","iopub.status.idle":"2021-12-16T15:06:08.650568Z","shell.execute_reply.started":"2021-12-16T15:05:32.41141Z","shell.execute_reply":"2021-12-16T15:06:08.649574Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfrom typing import Any, Dict, List\n\nimport flash\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport torch\nimport torchaudio\nfrom flash.audio import AudioClassificationData\nfrom flash.audio.classification.input import AudioClassificationInput\nfrom flash.core.data.io.input import DataKeys\nfrom flash.core.data.utilities.paths import PATH_TYPE, filter_valid_files, has_file_allowed_extension, make_dataset\nfrom flash.core.data.utilities.samples import to_samples\nfrom flash.image import ImageClassifier\nfrom pytorch_lightning import seed_everything\nfrom torchaudio.transforms import Spectrogram\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-12-16T15:06:08.652597Z","iopub.execute_input":"2021-12-16T15:06:08.652817Z","iopub.status.idle":"2021-12-16T15:06:25.177454Z","shell.execute_reply.started":"2021-12-16T15:06:08.652791Z","shell.execute_reply":"2021-12-16T15:06:25.176577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"csv_loc = '../input/birdclef-2021/train_metadata.csv'\ndf = pd.read_csv(csv_loc)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:06:25.17857Z","iopub.execute_input":"2021-12-16T15:06:25.178769Z","iopub.status.idle":"2021-12-16T15:06:25.697576Z","shell.execute_reply.started":"2021-12-16T15:06:25.178742Z","shell.execute_reply":"2021-12-16T15:06:25.696606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:06:25.699567Z","iopub.execute_input":"2021-12-16T15:06:25.699873Z","iopub.status.idle":"2021-12-16T15:06:25.72831Z","shell.execute_reply.started":"2021-12-16T15:06:25.699829Z","shell.execute_reply":"2021-12-16T15:06:25.727278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%\n# Seeding for reproducibility\nseed_everything(1234)\n\n# %% [markdown]\n# #### Audio parameters change as per your data location\n\n# %%\n\nDATASET_LOC = \"../input/birdclef-2021\"\nAUDIO_FOLDER = \"train_short_audio\"\n\n# %% [markdown]\n# #### Sneak peak of the data\n\n# %%\ntrain_metadata = pd.read_csv(os.path.join(DATASET_LOC, \"train_metadata.csv\"))\n# print(train_metadata.shape)\ntrain_metadata.head()","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:06:30.195395Z","iopub.execute_input":"2021-12-16T15:06:30.195748Z","iopub.status.idle":"2021-12-16T15:06:30.608724Z","shell.execute_reply.started":"2021-12-16T15:06:30.195714Z","shell.execute_reply":"2021-12-16T15:06:30.607897Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# %% [markdown]\n# ## Adding Dataloader\n\n# %%\nAUDIO_EXTENSIONS = (\".wav\", \".mp3\", \".flac\", \".ogg\")\n\n\ndef waveform_loader(filepath: str):\n    if has_file_allowed_extension(filepath, AUDIO_EXTENSIONS):\n        waveform, sr = torchaudio.load(filepath)\n    else:\n        raise Exception(f\"File {filepath} has unsupported extension. Can only load {AUDIO_EXTENSIONS}\")\n\n    return waveform, sr","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:06:31.917036Z","iopub.execute_input":"2021-12-16T15:06:31.917327Z","iopub.status.idle":"2021-12-16T15:06:31.92256Z","shell.execute_reply.started":"2021-12-16T15:06:31.91729Z","shell.execute_reply":"2021-12-16T15:06:31.921651Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# %%\n\n\nclass AudioClassificationFileInputToSpectrogram(AudioClassificationInput):\n    def load_data(self, folder: PATH_TYPE) -> List[Dict[str, Any]]:\n\n        files, targets = make_dataset(folder, extensions=AUDIO_EXTENSIONS)\n\n        if targets is None:\n            files = filter_valid_files(files, valid_extensions=AUDIO_EXTENSIONS)\n            return to_samples(files)\n\n        files, targets = filter_valid_files(files, targets, valid_extensions=AUDIO_EXTENSIONS)\n        self.load_target_metadata(targets)\n        return to_samples(files, targets)\n\n    def load_sample(self, sample: Dict[str, Any]) -> Dict[str, Any]:\n        filepath = sample[DataKeys.INPUT]\n        waveform, sr = waveform_loader(filepath)\n        sample[DataKeys.INPUT] = Spectrogram(sr, normalized=True)(waveform).squeeze(0).numpy()\n\n        sample = super().load_sample(sample)\n        sample[DataKeys.METADATA][\"filepath\"] = filepath\n        # plot_specgram(sample[DataKeys.INPUT])\n        return sample\n\n\n# %%\ndatamodule = AudioClassificationData.from_folders(\n    train_folder=os.path.join(DATASET_LOC, AUDIO_FOLDER),\n    input_cls=AudioClassificationFileInputToSpectrogram,\n    batch_size=64,\n    transform_kwargs=dict(spectrogram_size=(64, 64)),\n    val_split=0.2,\n)\n\n# %%\nlen(datamodule.train_dataset)","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:06:33.578397Z","iopub.execute_input":"2021-12-16T15:06:33.578875Z","iopub.status.idle":"2021-12-16T15:06:57.737075Z","shell.execute_reply.started":"2021-12-16T15:06:33.578821Z","shell.execute_reply":"2021-12-16T15:06:57.736148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %% [markdown]\n# ## Model\n# %%\nmodel = ImageClassifier(backbone=\"resnet18\", num_classes=datamodule.num_classes, backbone_kwargs={\"in_chans\": 1})\n\n# %% [markdown]\n# ## Training\n\n# %%\ntrainer = flash.Trainer(max_epochs=3, gpus=torch.cuda.device_count())\ntrainer.finetune(model, datamodule=datamodule, strategy=(\"freeze_unfreeze\", 1))\n\n# %%\ntrainer.save_checkpoint(\"audio_classification_model.pt\")\n\n\n# %%\n\n# %%","metadata":{"execution":{"iopub.status.busy":"2021-12-16T15:06:57.738866Z","iopub.execute_input":"2021-12-16T15:06:57.739246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}