{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![\"](https://storage.googleapis.com/kaggle-competitions/kaggle/25954/logos/header.png?t=2021-03-19-18-32-57)\n> # Complete EDAüîéüìäüìà for BirdCLEF 2021 - Birdcall Identification Challenge\n","metadata":{}},{"cell_type":"markdown","source":"\n\n\n\n\n\n---","metadata":{}},{"cell_type":"markdown","source":"\n# Competition Overview","metadata":{}},{"cell_type":"markdown","source":"Recent advances in machine listening have improved acoustic data collection. However, it remains a challenge to generate analysis outputs with high precision and recall. The majority of data is unexamined due to a lack of effective tools for efficient and reliable extraction of the signals of interests (e.g., bird calls).\n\nIn this competition, you‚Äôll automate the acoustic identification of birds in soundscape recordings. You'll examine an acoustic dataset to build detectors and classifiers to extract the signals of interest (bird calls). Innovative solutions will be able to do so efficiently and reliably.\n\n### **Task:-**\nYour challenge in this competition is to identify which birds are calling in long recordings, given training data generated in meaningfully different contexts. For each row_id/time window, you need to provide a space delimited list of the set of unique birds that made a call beginning or ending in that time window. If there are no bird calls in a time window, use the code nocall.","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"# Data Description","metadata":{}},{"cell_type":"markdown","source":"\n#### **train_short_audio -**\nThe bulk of the training data consists of short recordings of individual bird calls generously uploaded by users of xenocanto.org. These files have been downsampled to 32 kHz where applicable to match the test set audio and converted to the ogg format. The training data should have nearly all relevant files; we expect there is no benefit to looking for more on xenocanto.org.\n\n#### **train_soundscapes -** \nAudio files that are quite comparable to the test set. They are all roughly ten minutes long and in the ogg format. The test set also has soundscapes from the two recording locations represented here.\n\n#### **test_soundscapes -**\nWhen you submit a notebook, the test_soundscapes directory will be populated with approximately 80 recordings to be used for scoring. These will be roughly 10 minutes long and in ogg audio format. The file names include the date the recording was taken, which can be especially useful for identifying migratory birds.\n\nThis folder also contains text files with the name and approximate coordinates of the recording location plus a csv with the set of dates the test set soundscapes were recorded.\n\n#### **test.csv -** Only the first three rows are available for download; the full test.csv is in the hidden test set.\n\n**row_id:** ID code for the row.\n\n**site:** Site ID.\n\n**seconds:** the second ending the time window\n\n**audio_id:** ID code for the audio file.\n\n#### **train_metadata.csv -** A wide range of metadata is provided for the training data. The most directly relevant fields are:\n\n**primary_label:** a code for the bird species. You can review detailed information about the bird codes by appending the code to https://ebird.org/species/, such as https://ebird.org/species/amecro for the American Crow.\n\n**recodist:** the user who provided the recording.\n\n**latitude & longitude:** coordinates for where the recording was taken. Some bird species may have local call 'dialects,' so you may want to seek geographic diversity in your training data.\n\n**date:** while some bird calls can be made year round, such as an alarm call, some are restricted to a specific season. You may want to seek temporal diversity in your training data.\n\n**filename:** the name of the associated audio file.\n\n#### **train_soundscape_labels.csv -**\n\n**row_id:** ID code for the row.\n\n**site:** Site ID.\n\n**seconds:** the second ending the time window\n\n**audio_id:** ID code for the audio file.\n\n**birds:** space delimited list of any bird songs present in the 5 second window. The label nocall means that no call occurred.\n\n#### **sample_submission.csv -** A properly formed sample submission file. Only the first three rows are public, the remainder will be provided to your notebook as part of the hidden test set.\n\n**row_id**\n\n**birds:** space delimited list of any bird songs present in the 5 second window. If there are no bird calls, use the label nocall.\n","metadata":{}},{"cell_type":"markdown","source":"***","metadata":{}},{"cell_type":"markdown","source":"> ### **If you find this notebook useful, do give me an upvote.üëç**","metadata":{}},{"cell_type":"markdown","source":"# **Let's Understand the Data**","metadata":{}},{"cell_type":"markdown","source":"## ***Train Metadata***\n* It specifies the audible species for each recording.\n* Consists of information like Primary Label, Secondary Label, Type, Location, Time & Date, Rating etc.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nmeta = pd.read_csv('../input/birdclef-2021/train_metadata.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Now, Let's explore each column**","metadata":{}},{"cell_type":"markdown","source":"### <font color='red'>Primary Label</font>\n* A code for the bird species. \n* You can review detailed information about the bird codes by appending the code to https://ebird.org/species/, such as https://ebird.org/species/amecro for the American Crow.\n\n","metadata":{}},{"cell_type":"code","source":"import plotly.express as px\nspecies = meta['primary_label'].value_counts()\nfig = px.bar(species, x=species.index, y='primary_label', labels=dict(x=\"Species\", y=\"Count\"),title = \"Bird Species Count\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(species))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cnt = 0\nfor i in species:\n    if i > 300:\n        cnt += 1\nprint(cnt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* It contain recordings of 397 different primary labels(species).\n* As we can see from the graph, it is highly imbalanced training data kind of 'Multitailed Classification'.\n* Out of 397 species only 39 species have label count of more than 300","metadata":{}},{"cell_type":"markdown","source":"### <font color = 'red'>Secondary Labels</font>\n* It contains list of eBird codes (i.e., primary labels) that recordists annotated.\n* Can be used for Multi-label training.","metadata":{}},{"cell_type":"code","source":"meta['secondary_labels'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Around in 41358 rows, secondary label is not present.\n* Majority of recordings do not have an annotation of background species. \n* Yet, it is highly likely that most of them actually contain one or more additional species. ","metadata":{}},{"cell_type":"markdown","source":"### <font color = 'red'>Author</font>","metadata":{}},{"cell_type":"code","source":"meta['author'].nunique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"meta_exp = meta.groupby(['primary_label','author']).size()\nmeta_exp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Total 2129 authors are there.","metadata":{}},{"cell_type":"markdown","source":"### <font color = 'red'>Location</font>","metadata":{}},{"cell_type":"code","source":"# Code adapted from: https://www.kaggle.com/andradaolteanu/birdcall-recognition-eda-and-audio-fe\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport descartes\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n# SHP file\nworld_map = gpd.read_file(\"../input/world-shapefile/world_shapefile.shp\")\n\n# Coordinate reference system\ncrs = {\"init\" : \"epsg:4326\"}\n\n# Lat and Long need to be of type float, not object\nspecies_list = ['norcar', 'houspa', 'wesblu', 'banana']\ndata = meta[meta['primary_label'].isin(species_list)]\ndata[\"latitude\"] = data[\"latitude\"].astype(float)\ndata[\"longitude\"] = data[\"longitude\"].astype(float)\n\n# Create geometry\ngeometry = [Point(xy) for xy in zip(data[\"longitude\"], data[\"latitude\"])]\n\n# Geo Dataframe\ngeo_df = gpd.GeoDataFrame(data, crs=crs, geometry=geometry)\n\n# Create ID for species\nspecies_id = geo_df[\"primary_label\"].value_counts().reset_index()\nspecies_id.insert(0, 'ID', range(0, 0 + len(species_id)))\n\nspecies_id.columns = [\"ID\", \"primary_label\", \"count\"]\n\n# Add ID to geo_df\ngeo_df = pd.merge(geo_df, species_id, how=\"left\", on=\"primary_label\")\n\n# === PLOT ===\nfig, ax = plt.subplots(figsize = (16, 10))\nworld_map.plot(ax=ax, alpha=0.4, color=\"grey\")\n\npalette = iter(sns.hls_palette(len(species_id)))\nfor i in range(len(species_list)):\n    geo_df[geo_df[\"ID\"] == i].plot(ax=ax, \n                                   markersize=20, \n                                   color=next(palette), \n                                   marker=\"o\", \n                                   label = species_id['primary_label'].values[i]);\n    \nax.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Location data might be a good feature since It is poosible that certain bird species are from particular regions only.\nFor example, here :\nThe Bananaquit (banana) seems to only occur in Central and South America.\nHouse Sparrow (houspa) has occurrences around the globe.","metadata":{}},{"cell_type":"markdown","source":"### <font color ='red'>Date</font>","metadata":{}},{"cell_type":"markdown","source":"while some bird calls can be made year round, such as an alarm call, some are restricted to a specific season. You may want to seek temporal diversity in your training data.","metadata":{}},{"cell_type":"code","source":"meta['year'] = meta['date'].apply(lambda x: x.split('-')[0])\nmeta['month'] = meta['date'].apply(lambda x: x.split('-')[1])\nmeta['day_of_month'] = meta['date'].apply(lambda x: x.split('-')[2])\nmeta.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patterns = pd.DataFrame()\npatterns['time'] = pd.to_datetime(meta['time'], errors='coerce')\npatterns = patterns.dropna(subset=['time']).reset_index().drop('index',axis=1)\npatterns.time = patterns['time'].dt.hour.astype('int')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patterns.time","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patterns_type = []\nfor t in patterns.time:\n    if((t>4) and (t<12)):\n        patterns_type.append(0)\n    elif((t>=12) and (t<16)):\n        patterns_type.append(1)\n    elif((t>=16) and (t<19)):\n        patterns_type.append(2)\n    else:\n        patterns_type.append(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patterns['type'] = patterns_type","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patterns","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"b_types = patterns['type'].value_counts()\nb_types","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(patterns, x=b_types.index, y=b_types, title = \"Bird Call Time Distribution Graph\",)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here,\n\n0 : Morning\n\n1 : Afternoon\n\n2 : Evening\n\n3 : Night","metadata":{}},{"cell_type":"markdown","source":"### <font color = 'red'>Rating</font>","metadata":{}},{"cell_type":"code","source":"print(\"Minimum Rating:\",min(meta['rating']))\nprint(\"Maximum Rating:\",max(meta['rating']))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ratings = meta['rating'].value_counts()\nfig = px.bar(ratings, x=ratings.index, y='rating', title = \"Rating Count\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So most of the recordings have rating greater than 3.0 whcih is good. However, there are around 3.3k recordings which have 0 rating.","metadata":{}},{"cell_type":"code","source":"meta['type'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_edit = meta['type'].apply(lambda x: x.replace('[', ''))\ntype_edit = type_edit.apply(lambda x: x.replace(']', ''))\ntype_edit = type_edit.apply(lambda x: x.split(',')).reset_index().explode(\"type\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"type_edit['type'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_10 = list(type_edit['type'].value_counts().head(10).reset_index()['index'])\ntop_10_freq = list(type_edit['type'].value_counts().head(10))\ndata = type_edit[type_edit['type'].isin(top_10)]\nfig = px.bar(type_edit, x=top_10, y=top_10_freq, title = \"Top 10 Call Types\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## **Train & Test Data**","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/birdclef-2021/train_soundscape_labels.csv')\ntest = pd.read_csv('../input/birdclef-2021/test.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sites = train['site'].value_counts()\nfig = px.bar(train, x=sites.index, y=sites, title = \"Site Distribution\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Both Sites have equal distribution.","metadata":{}},{"cell_type":"code","source":"types_bird = train['birds'].value_counts()\nfig = px.bar(train, x=types_bird.index, y=types_bird)\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There is quite large 5 seconds window in recordings where there is no call present.","metadata":{}},{"cell_type":"code","source":"test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Only the first three rows are available ; the full test.csv is in the hidden test set.","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"# Let's Explore Audio Data","metadata":{}},{"cell_type":"markdown","source":"### *Librosa vs Scipy*\nI have chosen 'Librosa' because It normalizes the data while reading/loading audio file in the range 1 and -1 where as 'scipy' doesn't.","metadata":{}},{"cell_type":"code","source":"import os\ntrain_short_audio_path = '../input/birdclef-2021/train_short_audio'\naudio_count = []\nbird_species = []\nfor i in os.listdir(train_short_audio_path):\n    bird_species.append(i)\n    audio_cnt = len(os.listdir(train_short_audio_path + os.sep + f\"{i}\"))\n    audio_count.append(audio_cnt)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = px.bar(x=bird_species, y=audio_count, title = \" Audio Count Distribution\")\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Reading Random File\n\nimport librosa\naudio_file = '../input/birdclef-2021/train_short_audio/astfly/XC118723.ogg'\nx , sr = librosa.load(audio_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import IPython.display as play\nplay.Audio(audio_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The audio signal is a three-dimensional signal in which three axes represent time, amplitude and frequency.\nThe data provided of audio cannot be understood by the models directly to convert them into an understandable format feature extraction is used.\nlibrosa.display is used to display the audio files in different formats such as wave plot, spectrogram, or colormap etc. Waveplots let us know the loudness of the audio at a given time.\n\n","metadata":{}},{"cell_type":"markdown","source":"#### <font color = 'orange'>Waveplots</font>\n* Waveplots let us know the loudness of the audio at a given time.\n* librosa.display.waveplot is used to plot waveform of amplitude vs time","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport librosa.display\nplt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(x, sr=sr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n#### <font color = 'orange'>Spectrogram</font>\n* A spectrogram is a visual representation of the spectrum of frequencies of sound or other signals as they vary with time. \n* It‚Äôs a representation of frequencies changing with respect to time for given music signals.\n* .stft() converts data into short term Fourier transform(STFT) so that we can know the amplitude of given frequency at a given time.\n* .specshow() is used to display spectogram.","metadata":{}},{"cell_type":"code","source":"X = librosa.stft(x)\nXdb = librosa.amplitude_to_db(abs(X))\nplt.figure(figsize=(14, 5))\nlibrosa.display.specshow(Xdb, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color = 'orange'>MFCC</font>\n* This feature is one of the most important method to extract a feature of an audio signal and is used majorly whenever working on audio signals. \n* The mel frequency cepstral coefficients (MFCCs) of a signal are a small set of features (usually about 10‚Äì20) which concisely describe the overall shape of a spectral envelope.\n* .mfcc() is used to calculate mfccs of a signal.\n* By printing the shape of mfccs you get how many mfccs are calculated on how many frames. The first value represents the number of mfccs calculated and another value represents a number of frames available.","metadata":{}},{"cell_type":"code","source":"fs=10\nmfccs = librosa.feature.mfcc(x, sr=fs)\nprint(mfccs.shape)\nplt.figure(figsize=(15, 7))\nlibrosa.display.specshow(mfccs, sr=sr, x_axis='time')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### <font color = 'orange'>Chromagram</font>\n* Chromagram closely relates to the twelve different pitch classes. \n* Chroma-based features, which are also referred to as ‚Äúpitch class profiles‚Äù.\n* One main property of chroma features is that they capture harmonic and melodic characteristics of music, while being    robust to changes in timbre and instrumentation.","metadata":{}},{"cell_type":"code","source":"hop_length=12\nchromagram = librosa.feature.chroma_stft(x, sr=sr, hop_length=hop_length)\nplt.figure(figsize=(15, 5))\nlibrosa.display.specshow(chromagram, x_axis='time', y_axis='chroma', hop_length=hop_length, cmap='coolwarm')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### <font color = 'green'>**Refrences**</font>\n\n* https://www.kaggle.com/andradaolteanu/birdcall-recognition-eda-and-audio-fe\n* https://www.kaggle.com/stefankahl/birdclef2021-exploring-the-data","metadata":{}},{"cell_type":"markdown","source":"## If you find this notebook useful, do give me an upvote üëç.\n\n## This notebook will be updated frequently so keep checking for further developments.\n\n## In case of any doubts reach out to me on [LinkedIn](https://www.linkedin.com/in/rajendra-sarpal-rs465/).","metadata":{}}]}