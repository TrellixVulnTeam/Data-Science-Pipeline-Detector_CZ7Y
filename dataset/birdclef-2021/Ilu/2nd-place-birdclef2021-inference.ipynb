{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"MONTH_DIST = 3\nKM_DIST = 350","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:32:27.875575Z","iopub.execute_input":"2021-06-11T05:32:27.875953Z","iopub.status.idle":"2021-06-11T05:32:27.885369Z","shell.execute_reply.started":"2021-06-11T05:32:27.875866Z","shell.execute_reply":"2021-06-11T05:32:27.88447Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install ../input/birds-inference-pip-wheels/torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl ../input/birds-inference-pip-wheels/torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl\n# !pip install ../input/birds-inference-pip-wheels/timm-0.4.8.zip --no-index --no-deps\n!pip install ../input/birdclef21trainmeta/timm-0.4.9_23052021/pytorch-image-models-master --no-index --no-deps\n!pip install ../input/birds-inference-pip-wheels/audiomentations-0.16.0-py3-none-any.whl --no-index --no-deps\n!pip install ../input/birds-inference-pip-wheels/torchlibrosa-0.0.9-py3-none-any.whl --no-index --no-deps","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:32:27.886927Z","iopub.execute_input":"2021-06-11T05:32:27.887288Z","iopub.status.idle":"2021-06-11T05:33:57.779401Z","shell.execute_reply.started":"2021-06-11T05:32:27.887251Z","shell.execute_reply":"2021-06-11T05:33:57.778554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm\ntimm.__version__","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:33:57.781054Z","iopub.execute_input":"2021-06-11T05:33:57.781313Z","iopub.status.idle":"2021-06-11T05:33:58.877017Z","shell.execute_reply.started":"2021-06-11T05:33:57.781287Z","shell.execute_reply":"2021-06-11T05:33:58.876213Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nimport importlib\nimport multiprocessing as mp\n\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport glob\nimport torch\nfrom copy import copy\n\nfrom torch.utils.data import DataLoader","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-11T05:33:58.878579Z","iopub.execute_input":"2021-06-11T05:33:58.878935Z","iopub.status.idle":"2021-06-11T05:33:58.884108Z","shell.execute_reply.started":"2021-06-11T05:33:58.878898Z","shell.execute_reply":"2021-06-11T05:33:58.883189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!cp -r ../input/kaggle-birdclef2021-2nd-place-github/* ./","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:33:58.886115Z","iopub.execute_input":"2021-06-11T05:33:58.886465Z","iopub.status.idle":"2021-06-11T05:33:59.662168Z","shell.execute_reply.started":"2021-06-11T05:33:58.88643Z","shell.execute_reply":"2021-06-11T05:33:59.661179Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append('./configs')\nsys.path.append('./data')\nsys.path.append('./models')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:33:59.665571Z","iopub.execute_input":"2021-06-11T05:33:59.665838Z","iopub.status.idle":"2021-06-11T05:33:59.673005Z","shell.execute_reply.started":"2021-06-11T05:33:59.665809Z","shell.execute_reply":"2021-06-11T05:33:59.672251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta = pd.read_csv(\"../input/birdclef21trainmeta/train_meta_4folded_v3.csv\")\ntrain_meta[[\"year\", \"month\", \"day\"]] = train_meta['date'].str.split(\"-\", expand=True)\ntrain_meta[\"month\"] = train_meta[\"month\"].astype(int)\ntrain_meta","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:33:59.674226Z","iopub.execute_input":"2021-06-11T05:33:59.674695Z","iopub.status.idle":"2021-06-11T05:34:00.684687Z","shell.execute_reply.started":"2021-06-11T05:33:59.674657Z","shell.execute_reply":"2021-06-11T05:34:00.68389Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%checkerror\n\nCOMP_FOLDER = '../input/birdclef-2021/'\nTEST_AUDIO_ROOT = f'{COMP_FOLDER}test_soundscapes/'\ntest_df = pd.read_csv(f'{COMP_FOLDER}test.csv')\ntest_df['birds'] = 'acafly'\nsample_submission = pd.read_csv(COMP_FOLDER + 'sample_submission.csv')\nN_CORES = mp.cpu_count()\nPUBLIC_RUN = False\n\nRAM_CHECK = False\nMIXED_PRECISION = False\nDEVICE = \"cuda\"","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:34:00.687459Z","iopub.execute_input":"2021-06-11T05:34:00.687804Z","iopub.status.idle":"2021-06-11T05:34:00.710011Z","shell.execute_reply.started":"2021-06-11T05:34:00.687769Z","shell.execute_reply":"2021-06-11T05:34:00.709349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%checkerror\n\ntest_fns = [item for item in os.listdir(TEST_AUDIO_ROOT) if item.endswith('.ogg')]\nif len(test_fns) == 0:\n    PUBLIC_RUN = True\n    TEST_AUDIO_ROOT = TEST_AUDIO_ROOT.replace('test','train')\n    test_fns = [item for item in os.listdir(TEST_AUDIO_ROOT) if item.endswith('.ogg')]\n    test_df = pd.read_csv(f'{COMP_FOLDER}train_soundscape_labels.csv', usecols=['row_id','site','audio_id','seconds'])\n    \n    test_df['birds'] = 'acafly'\n    sample_submission = pd.read_csv(COMP_FOLDER + 'train_soundscape_labels.csv',usecols=['row_id'])\n    sample_submission['birds'] = 'nocall'\n    \n    # load train_soundscape_labels to eval in PUBLIC RUN\n    train_soundscape_labels = pd.read_csv(f'{COMP_FOLDER}train_soundscape_labels.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:34:00.712189Z","iopub.execute_input":"2021-06-11T05:34:00.712541Z","iopub.status.idle":"2021-06-11T05:34:00.756874Z","shell.execute_reply.started":"2021-06-11T05:34:00.712506Z","shell.execute_reply":"2021-06-11T05:34:00.756171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# %%checkerror\nfn_starts = {'_'.join(fn.split('_')[:2]):fn for fn in test_fns}\ntest_df['filename'] = (test_df['audio_id'].astype(str) + '_' + test_df['site']).map(fn_starts)\ntest_df[\"month\"] = test_df[\"filename\"].str[-8:-6]\ntest_df[\"month\"] = test_df[\"month\"].astype(int)\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:34:00.757907Z","iopub.execute_input":"2021-06-11T05:34:00.758207Z","iopub.status.idle":"2021-06-11T05:34:00.789044Z","shell.execute_reply.started":"2021-06-11T05:34:00.758176Z","shell.execute_reply":"2021-06-11T05:34:00.788369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ch_binary_ext1_3')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ch_binary_ext1_3/checkpoint_last_seed*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"seresnext26t_32x4d\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_1 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_1 += [preds_]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:34:00.790186Z","iopub.execute_input":"2021-06-11T05:34:00.790609Z","iopub.status.idle":"2021-06-11T05:34:50.537735Z","shell.execute_reply.started":"2021-06-11T05:34:00.790553Z","shell.execute_reply":"2021-06-11T05:34:50.536625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('pp_binary_ext3_1')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/pp_binary_ext3_1/checkpoint_last_seed*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"tf_efficientnet_b0_ns\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts[:5]):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_2 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_2 += [preds_]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:34:50.539349Z","iopub.execute_input":"2021-06-11T05:34:50.539961Z","iopub.status.idle":"2021-06-11T05:35:14.562475Z","shell.execute_reply.started":"2021-06-11T05:34:50.539918Z","shell.execute_reply":"2021-06-11T05:35:14.561493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('pp_binary_ext3_2')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/pp_binary_ext3_2/checkpoint_last_seed*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"seresnext26t_32x4d\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts[:5]):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_3 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_3 += [preds_]","metadata":{"execution":{"iopub.status.busy":"2021-06-11T05:35:14.564066Z","iopub.execute_input":"2021-06-11T05:35:14.564607Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_1 = np.array(preds_1).transpose(1,0,2,3)\npreds_1 = preds_1.reshape(preds_1.shape[0], preds_1.shape[1]*preds_1.shape[2], preds_1.shape[3])\npreds_1.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_2 = np.array(preds_2).transpose(1,0,2,3)\npreds_2 = preds_2.reshape(preds_2.shape[0], preds_2.shape[1]*preds_2.shape[2], preds_2.shape[3])\npreds_2.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_3 = np.array(preds_3).transpose(1,0,2,3)\npreds_3 = preds_3.reshape(preds_3.shape[0], preds_3.shape[1]*preds_3.shape[2], preds_3.shape[3])\npreds_3.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = np.concatenate([preds_1, preds_2, preds_3], axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binary_median = np.median(preds, axis=0).copy()\nbinary_mean = np.mean(preds, axis=0).copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binary_median = binary_median.flatten()\nbinary_mean = binary_mean.flatten()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_6_v2')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ps_6_v2/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"resnet34\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_1 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_1 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v8_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ps_12_v8/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"resnet34\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_2 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_2 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v11_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ps_12_v11/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"tf_efficientnetv2_s_in21k\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_3 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_3 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v13_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ps_12_v13/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"tf_efficientnetv2_m_in21k\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_4 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_4 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v21_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ps_12_v21/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"eca_nfnet_l0\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_5 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_5 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v30_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ch_12_v25a/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"tf_efficientnetv2_s_in21k\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_6 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_6 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v30_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ps_12_v30/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"tf_efficientnetv2_s_in21k\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_7 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_7 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ncfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v30_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ps_12_v32/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"tf_efficientnetv2_s_in21k\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_8 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_8 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = importlib.import_module('default_config')\nimportlib.reload(cfg)\ncfg = importlib.import_module('cfg_ps_12_v30_inf')\nimportlib.reload(cfg)\ncfg = copy(cfg.cfg)\nprint(cfg.model, cfg.dataset, cfg.backbone, cfg.pretrained_weights, cfg.mel_norm)\n\ncfg.val_data_folder = TEST_AUDIO_ROOT\ncfg.pretrained = False\n\nds = importlib.import_module(cfg.dataset)\nimportlib.reload(ds)\n\nCustomDataset = ds.CustomDataset\nbatch_to_device = ds.batch_to_device\n\ncfg.batch_size = 1\n\naug = None\ntest_ds = CustomDataset(test_df, cfg, aug, mode=\"val\")\ntest_dl = DataLoader(test_ds, shuffle=False, batch_size = cfg.batch_size, num_workers = N_CORES)\n\nmodel = importlib.import_module(cfg.model)\nimportlib.reload(model)\nNet = model.Net\n\ndef get_state_dict(sd_fp):\n    sd = torch.load(sd_fp, map_location=\"cpu\")['model']\n    sd = {k.replace(\"module.\", \"\"):v for k,v in sd.items()}\n    return sd\nstate_dicts = []\nbackbones = []\nfor filepath in glob.iglob('../input/2ndplacebirdclef2021-models/cfg_ch_12_v25g/checkpoint_*.pth'):\n    state_dicts.append(filepath)\n    backbones.append(\"tf_efficientnetv2_s_in21k\")\nprint(state_dicts)\n\nnets = []\n\nfor i,state_dict in enumerate(state_dicts):\n    cfg.backbone = backbones[i]\n    net = Net(cfg).eval().cuda()\n    sd = get_state_dict(state_dict)\n    print(\"loading dict\")\n    net.load_state_dict(sd, strict=True)\n    nets += [net]\n    \n# %%checkerror\nfrom scipy.stats.mstats import gmean\n\nwith torch.no_grad():    \n\n    preds_9 = []\n    for batch in tqdm(test_dl):\n        batch = batch_to_device(batch, DEVICE)\n        with torch.cuda.amp.autocast():\n            preds_ = []\n            for net in nets:\n                out = net(batch)['logits']\n                preds_ += [out.cpu().numpy()]\n            \n        preds_9 += [preds_]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_1 = np.array(preds_1).transpose(1,0,2,3)\npreds_2 = np.array(preds_2).transpose(1,0,2,3)\npreds_3 = np.array(preds_3).transpose(1,0,2,3)\npreds_4 = np.array(preds_4).transpose(1,0,2,3)\npreds_5 = np.array(preds_5).transpose(1,0,2,3)\npreds_6 = np.array(preds_6).transpose(1,0,2,3)\npreds_7 = np.array(preds_7).transpose(1,0,2,3)\npreds_8 = np.array(preds_8).transpose(1,0,2,3)\npreds_9 = np.array(preds_9).transpose(1,0,2,3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_preds = [preds_1, preds_2, preds_3, preds_4, preds_5, preds_6, preds_7, preds_8, preds_9]  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_bag_all = []\nfor preds in all_preds:\n    \n    preds = preds.reshape(preds.shape[0], preds.shape[1]*preds.shape[2], preds.shape[3])\n    \n    preds[:,:,275] += preds[:,:,397]\n    preds = preds[:,:,:397]\n    \n    cols = [f\"p{i}\" for i in range(preds.shape[2])]\n    preds_bag = []\n\n    for model in tqdm(range(preds.shape[0])):\n        curr_df = test_df.copy()\n        curr_df[cols] = preds[model]\n        curr_df[cols] = curr_df[cols].fillna(0)\n\n        for c in cols:\n            z1 = curr_df.groupby('audio_id')[c].shift(1)\n            z2 = curr_df.groupby('audio_id')[c].shift(-1)\n            z3 = curr_df.groupby('audio_id')[c].shift(2)\n            z4 = curr_df.groupby('audio_id')[c].shift(-2)\n            z5 = curr_df.groupby('audio_id')[c].shift(3)\n            z6 = curr_df.groupby('audio_id')[c].shift(-3)\n\n            z = curr_df[c]\n\n            idx = (~np.isnan(z5)) & (~np.isnan(z6))\n            z[idx] = np.average([z.fillna(0)[idx], z1.fillna(0)[idx], z2.fillna(0)[idx], z3.fillna(0)[idx], z4.fillna(0)[idx], z5.fillna(0)[idx], z6.fillna(0)[idx]], axis=0, weights=[7,2,2,1,1,0.5,0.5])\n            z = z + curr_df[\"audio_id\"].map(curr_df.groupby(\"audio_id\")[c].mean()*0.65)\n\n            curr_df[c] = z\n\n        p = curr_df[cols].values\n\n        preds_bag.append(p)\n        \n    preds_bag_all.append(preds_bag)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_bag_all_2 = [np.mean(x, axis=0) for x in preds_bag_all]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mean = np.average(preds_bag_all_2, axis=0, weights=[0.8,1,1,1,1,1,1,1,1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_mean.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[cols] = test_mean\ntest_df[cols]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[cols].values.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"binary_median.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bb = binary_mean.reshape(-1,1)\ntest_df[cols] *= (1 + (bb * 0.8))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = np.quantile(test_df[cols].values.flatten(), 0.9981)\nprint(threshold)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_strings = []\nfor i, pred in tqdm(enumerate(test_df[cols].values), total=len(test_df)):\n    th = np.array([threshold] * (len(cfg.birds)-1))\n    \n    if MONTH_DIST < 12:\n        if test_df[\"filename\"].str.contains(\"COL\")[i]:\n            th += (train_meta.loc[abs(train_meta[\"month\"] - test_df[\"month\"][i]) <= MONTH_DIST].groupby(\"primary_label\")[\"COL_dist\"].min() > KM_DIST)*1\n        elif test_df[\"filename\"].str.contains(\"COR\")[i]:\n            th += (train_meta.loc[abs(train_meta[\"month\"] - test_df[\"month\"][i]) <= MONTH_DIST].groupby(\"primary_label\")[\"COR_dist\"].min() > KM_DIST)*1\n        elif test_df[\"filename\"].str.contains(\"SNE\")[i]:\n            th += (train_meta.loc[abs(train_meta[\"month\"] - test_df[\"month\"][i]) <= MONTH_DIST].groupby(\"primary_label\")[\"SNE_dist\"].min() > KM_DIST)*1\n        elif test_df[\"filename\"].str.contains(\"SSW\")[i]:\n            th += (train_meta.loc[abs(train_meta[\"month\"] - test_df[\"month\"][i]) <= MONTH_DIST].groupby(\"primary_label\")[\"SSW_dist\"].min() > KM_DIST)*1\n    else:\n        if test_df[\"filename\"].str.contains(\"COL\")[i]:\n            th += (train_meta.groupby(\"primary_label\")[\"COL_dist\"].min() > KM_DIST)*1\n        elif test_df[\"filename\"].str.contains(\"COR\")[i]:\n            th += (train_meta.groupby(\"primary_label\")[\"COR_dist\"].min() > KM_DIST)*1\n        elif test_df[\"filename\"].str.contains(\"SNE\")[i]:\n            th += (train_meta.groupby(\"primary_label\")[\"SNE_dist\"].min() > KM_DIST)*1\n        elif test_df[\"filename\"].str.contains(\"SSW\")[i]:\n            th += (train_meta.groupby(\"primary_label\")[\"SSW_dist\"].min() > KM_DIST)*1\n    \n    pred_bird_idx = np.where(pred > th)[0]\n    pred_bird_idx_high = np.where(pred > (th*1.10))[0]\n    \n    if len(pred_bird_idx) > 0:\n        pred_bird = ' '.join(list(cfg.birds[pred_bird_idx]))\n        if len(pred_bird_idx_high) == 0:\n            pred_bird = pred_bird + \" nocall\"\n    else:\n        pred_bird = 'nocall'\n\n    pred_strings += [pred_bird]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = sample_submission.copy()\nsubmission['birds'] = pred_strings\nsubmission.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def row_wise_f1_score_micro(y_true, y_pred):\n    \"\"\" author @shonenkov \"\"\"\n    F1 = []\n    for preds, trues in zip(y_pred, y_true):\n        TP, FN, FP = 0, 0, 0\n        preds = preds.split()\n        trues = trues.split()\n        for true in trues:\n            if true in preds:\n                TP += 1\n            else:\n                FN += 1\n        for pred in preds:\n            if pred not in trues:\n                FP += 1\n        F1.append(2*TP / (2*TP + FN + FP))\n    return np.mean(F1)\n\nif PUBLIC_RUN:\n    y_pred = submission['birds'].values\n    y_true = train_soundscape_labels['birds'].values\n    print(row_wise_f1_score_micro(y_true, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PUBLIC_RUN:\n    mask = [~test_df[\"filename\"].isin([\"7019_COR_20190904.ogg\", \"7954_COR_20190923.ogg\", \"31928_COR_20191004.ogg\"])][0]\n    mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if PUBLIC_RUN:\n    y_pred = submission['birds'].values[mask]\n    y_true = train_soundscape_labels['birds'].values[mask]\n    print(row_wise_f1_score_micro(y_true, y_pred))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_birds = \" \".join(pred_strings).split(\" \")\nlen(pred_birds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}