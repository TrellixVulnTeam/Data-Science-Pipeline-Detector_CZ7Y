{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd \n\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\ntrain = pd.read_csv('../input/birdclef-2021/train_metadata.csv',)\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = train[[\"latitude\",\"longitude\"]]\nCorrelation = train.corr(method='kendall')\nprint(Correlation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train['primary_label'].value_counts())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nspecies = train['primary_label'].value_counts()\nfig = go.Figure(data=[go.Bar(y=species.values, x=species.index)],\n                layout=go.Layout(margin=go.layout.Margin(l=0, r=0,\nb=15, t=50)))\n\nfig.update_layout(title='Number of traning samples per species')\nfig.show()                                                        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['secondary_labels'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport descartes\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n\n\n\ncrs = {\"init\" : \"epsg:4326\"}\n\n\nspecies_list = ['norcar', 'houspa', 'wesblu', 'banana']\ndata = train[train['primary_label'].isin(species_list)]\ndata[\"latitude\"] = data[\"latitude\"].astype(float)\ndata[\"longitude\"] = data[\"longitude\"].astype(float)\n\n\ngeometry = [Point(xy) for xy in zip(data[\"longitude\"], data[\"latitude\"])]\n\n\ngeo_df = gpd.GeoDataFrame(data, crs=crs, geometry=geometry)\n\n\nspecies_id = geo_df[\"primary_label\"].value_counts().reset_index()\nspecies_id.insert(0, 'ID', range(0, 0 + len(species_id)))\n\nspecies_id.columns = [\"ID\", \"primary_label\", \"count\"]\ngeo_df = pd.merge(geo_df, species_id, how=\"left\", on=\"primary_label\")\n\n\nfig, ax = plt.subplots(figsize = (16, 10))\n\npalette = iter(sns.hls_palette(len(species_id)))\nfor i in range(len(species_list)):\n    geo_df[geo_df[\"ID\"] == i].plot(ax=ax, \n                                   markersize=20, \n                                   color=next(palette), \n                                   marker=\"o\", \n                                   label = species_id['primary_label'].values[i]);\n    \nax.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_data = train['rating'].values.tolist()\nfig = go.Figure(data=[go.Histogram(x=hist_data)], \n                layout=go.Layout(margin=go.layout.Margin(l=0, r=0, b=10, t=50)))\nfig.update_layout(title='Number of recordings per rating')\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"soundscapes = pd.read_csv('../input/birdclef-2021/train_soundscape_labels.csv',)\nsoundscapes.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(soundscapes['birds'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(soundscapes['birds'].value_counts())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Audio # 1\naudio_path = '../input/birdclef-2021/train_short_audio/acafly/XC109605.ogg'\n\n# Listen to it\nimport IPython.display as ipd\nipd.Audio(audio_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\n\nimport librosa\n\n\nsig, rate= librosa.load(audio_path, sr=32000, offset=None, duration=15)\n\n\nprint('SIGNAL SHAPE:', sig.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport librosa.display\n\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(sig, sr=32000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spec = librosa.stft(sig)\nspec_db = librosa.amplitude_to_db(spec, ref=np.max)\nplt.figure(figsize=(15, 5))\nlibrosa.display.specshow(spec_db, \n                         sr=32000, \n                         x_axis='time', \n                         y_axis='hz', \n                         cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('SPEC SHAPE:', spec_db.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try a few window lengths (should be a power of 2)\nfor win_length in [128, 256, 512, 1024]:\n    \n    # We want 50% overlap between samples\n    hop_length = win_length // 2\n    \n    # Compute spec (win_length implicity also sets n_fft and vice versa)\n    spec = librosa.stft(sig, \n                        n_fft=win_length, \n                        hop_length=hop_length)\n    \n    # Scale to decibel scale\n    spec_db = librosa.amplitude_to_db(spec, ref=np.max)\n    \n    # Show plot\n    plt.figure(figsize=(15, 5))\n    plt.title('Window length: ' + str(win_length) + ', Shape: ' + str(spec_db.shape))\n    librosa.display.specshow(spec_db, \n                             sr=32000, \n                             hop_length=hop_length, \n                             x_axis='time', \n                             y_axis='hz', \n                             cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Desired shape of the input spectrogram\nSPEC_HEIGHT = 64\nSPEC_WIDTH = 256\n\n# Derive num_mels and hop_length from desired spec shape\n# num_mels is easy, that's just spec_height\n# hop_length is a bit more complicated\nNUM_MELS = SPEC_HEIGHT\nHOP_LENGTH = int(32000 * 5 / (SPEC_WIDTH - 1)) # sample rate * duration / spec width - 1 == 627\n\n# High- and low-pass frequencies\n# For many birds, these are a good choice\nFMIN = 500\nFMAX = 12500\n\n# Let's get all three spectrograms\nfor second in [5, 10, 15]:  \n    \n    # Get start and stop sample\n    s_start = (second - 5) * 32000\n    s_end = second * 32000\n\n    # Compute the spectrogram and apply the mel scale\n    mel_spec = librosa.feature.melspectrogram(y=sig[s_start:s_end], \n                                              sr=32000, \n                                              n_fft=1024, \n                                              hop_length=HOP_LENGTH, \n                                              n_mels=NUM_MELS, \n                                              fmin=FMIN, \n                                              fmax=FMAX)\n    \n    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n    # Show the spec\n    plt.figure(figsize=(15, 5))\n    plt.title('Second: ' + str(second) + ', Shape: ' + str(mel_spec_db.shape))\n    librosa.display.specshow(mel_spec_db, \n                             sr=32000, \n                             hop_length=HOP_LENGTH, \n                             x_axis='time', \n                             y_axis='mel',\n                             fmin=FMIN, \n                             fmax=FMAX, \n                             cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nimport pandas as pd\nimport librosa\nimport numpy as np\n\nfrom sklearn.utils import shuffle\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\n# Global vars\nRANDOM_SEED = 1337\nSAMPLE_RATE = 32000\nSIGNAL_LENGTH = 5 # seconds\nSPEC_SHAPE = (48, 128) # height x width\nFMIN = 500\nFMAX = 12500\nMAX_AUDIO_FILES = 1500","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"../input/birdclef-2021/train_metadata.csv\",)\ntrain = train.query('rating>=4')\nbirds_count = {}\nfor bird_species, count in zip(train.primary_label.unique(), \n                               train.groupby('primary_label')['primary_label'].count().values):\n    birds_count[bird_species] = count\nmost_represented_birds = [key for key,value in birds_count.items() if value >= 200] \n\nTRAIN = train.query('primary_label in @most_represented_birds')\nLABELS = sorted(TRAIN.primary_label.unique())\n\n# Let's see how many species and samples we have left\nprint('NUMBER OF SPECIES IN TRAIN DATA:', len(LABELS))\nprint('NUMBER OF SAMPLES IN TRAIN DATA:', len(TRAIN))\nprint('LABELS:', most_represented_birds)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_AUDIO_FILES\nTRAIN = shuffle(TRAIN, random_state=RANDOM_SEED)[:MAX_AUDIO_FILES]\n\ndef get_spectrograms(filepath, primary_label, output_dir):\n    \n    \n    sig, rate = librosa.load(filepath, sr=SAMPLE_RATE, offset=None, duration=15)\n    \n   \n    sig_splits = []\n    for i in range(0, len(sig), int(SIGNAL_LENGTH * SAMPLE_RATE)):\n        split = sig[i:i + int(SIGNAL_LENGTH * SAMPLE_RATE)]\n\n       \n        if len(split) < int(SIGNAL_LENGTH * SAMPLE_RATE):\n            break\n        \n        sig_splits.append(split)\n        \n    \n    s_cnt = 0\n    saved_samples = []\n    for chunk in sig_splits:\n        \n        hop_length = int(SIGNAL_LENGTH * SAMPLE_RATE / (SPEC_SHAPE[1] - 1))\n        mel_spec = librosa.feature.melspectrogram(y=chunk, \n                                                  sr=SAMPLE_RATE, \n                                                  n_fft=1024, \n                                                  hop_length=hop_length, \n                                                  n_mels=SPEC_SHAPE[0], \n                                                  fmin=FMIN, \n                                                  fmax=FMAX)\n    \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n        \n        \n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        \n        save_dir = os.path.join(output_dir, primary_label)\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        save_path = os.path.join(save_dir, filepath.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0] + \n                                 '_' + str(s_cnt) + '.png')\n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\")\n        im.save(save_path)\n        \n        saved_samples.append(save_path)\n        s_cnt += 1\n        \n        \n    return saved_samples\n\nprint('FINAL NUMBER OF AUDIO FILES IN TRAINING DATA:', len(TRAIN)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Audio # 2\naudio_path1 = \"../input/birdclef-2021/train_short_audio/acafly/XC11209.ogg\"\n\n# Listen to it\nimport IPython.display as ipd\nipd.Audio(audio_path1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\n# Librosa is the most versatile audio library for Python \n# and uses FFMPEG to load and open audio files\n# For more information visit: https://librosa.org/doc/latest/index.html\nimport librosa\n\n# Load the first 15 seconds this file using librosa\nsig, rate= librosa.load(audio_path1, sr=32000, offset=None, duration=15)\n\n# The result is a 1D numpy array that conatains audio samples. \n# Take a look at the shape (seconds * sample rate == 15 * 32000 == 480000)\nprint('SIGNAL SHAPE:', sig.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport librosa.display\n\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(sig, sr=32000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spec = librosa.stft(sig)\nspec_db = librosa.amplitude_to_db(spec, ref=np.max)\nplt.figure(figsize=(15, 5))\nlibrosa.display.specshow(spec_db, \n                         sr=32000, \n                         x_axis='time', \n                         y_axis='hz', \n                         cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('SPEC SHAPE:', spec_db.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Try a few window lengths (should be a power of 2)\nfor win_length in [128, 256, 512, 1024]:\n    \n    # We want 50% overlap between samples\n    hop_length = win_length // 2\n    \n    # Compute spec (win_length implicity also sets n_fft and vice versa)\n    spec = librosa.stft(sig, \n                        n_fft=win_length, \n                        hop_length=hop_length)\n    \n    # Scale to decibel scale\n    spec_db = librosa.amplitude_to_db(spec, ref=np.max)\n    \n    # Show plot\n    plt.figure(figsize=(15, 5))\n    plt.title('Window length: ' + str(win_length) + ', Shape: ' + str(spec_db.shape))\n    librosa.display.specshow(spec_db, \n                             sr=32000, \n                             hop_length=hop_length, \n                             x_axis='time', \n                             y_axis='hz', \n                             cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Desired shape of the input spectrogram\nSPEC_HEIGHT = 64\nSPEC_WIDTH = 256\n\n# Derive num_mels and hop_length from desired spec shape\n# num_mels is easy, that's just spec_height\n# hop_length is a bit more complicated\nNUM_MELS = SPEC_HEIGHT\nHOP_LENGTH = int(32000 * 5 / (SPEC_WIDTH - 1)) # sample rate * duration / spec width - 1 == 627\n\n# High- and low-pass frequencies\n# For many birds, these are a good choice\nFMIN = 500\nFMAX = 12500\n\n# Let's get all three spectrograms\nfor second in [5, 10, 15]:  \n    \n    # Get start and stop sample\n    s_start = (second - 5) * 32000\n    s_end = second * 32000\n\n    # Compute the spectrogram and apply the mel scale\n    mel_spec = librosa.feature.melspectrogram(y=sig[s_start:s_end], \n                                              sr=32000, \n                                              n_fft=1024, \n                                              hop_length=HOP_LENGTH, \n                                              n_mels=NUM_MELS, \n                                              fmin=FMIN, \n                                              fmax=FMAX)\n    \n    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n    # Show the spec\n    plt.figure(figsize=(15, 5))\n    plt.title('Second: ' + str(second) + ', Shape: ' + str(mel_spec_db.shape))\n    librosa.display.specshow(mel_spec_db, \n                             sr=32000, \n                             hop_length=HOP_LENGTH, \n                             x_axis='time', \n                             y_axis='mel',\n                             fmin=FMIN, \n                             fmax=FMAX, \n                             cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nimport pandas as pd\nimport librosa\nimport numpy as np\n\nfrom sklearn.utils import shuffle\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\n# Global vars\nRANDOM_SEED = 1337\nSAMPLE_RATE = 32000\nSIGNAL_LENGTH = 5 # seconds\nSPEC_SHAPE = (48, 128) # height x width\nFMIN = 500\nFMAX = 12500\nMAX_AUDIO_FILES = 1500","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/birdclef-2021/train_metadata.csv',)\ntrain = train.query('rating>=4')\nbirds_count = {}\nfor bird_species, count in zip(train.primary_label.unique(), \n                               train.groupby('primary_label')['primary_label'].count().values):\n    birds_count[bird_species] = count\nmost_represented_birds = [key for key,value in birds_count.items() if value >= 200] \n\nTRAIN = train.query('primary_label in @most_represented_birds')\nLABELS = sorted(TRAIN.primary_label.unique())\n\n# Let's see how many species and samples we have left\nprint('NUMBER OF SPECIES IN TRAIN DATA:', len(LABELS))\nprint('NUMBER OF SAMPLES IN TRAIN DATA:', len(TRAIN))\nprint('LABELS:', most_represented_birds)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_AUDIO_FILES\nTRAIN = shuffle(TRAIN, random_state=RANDOM_SEED)[:MAX_AUDIO_FILES]\n\ndef get_spectrograms(filepath, primary_label, output_dir):\n    \n    \n    sig, rate = librosa.load(filepath, sr=SAMPLE_RATE, offset=None, duration=15)\n    \n   \n    sig_splits = []\n    for i in range(0, len(sig), int(SIGNAL_LENGTH * SAMPLE_RATE)):\n        split = sig[i:i + int(SIGNAL_LENGTH * SAMPLE_RATE)]\n\n       \n        if len(split) < int(SIGNAL_LENGTH * SAMPLE_RATE):\n            break\n        \n        sig_splits.append(split)\n        \n    \n    s_cnt = 0\n    saved_samples = []\n    for chunk in sig_splits:\n        \n        hop_length = int(SIGNAL_LENGTH * SAMPLE_RATE / (SPEC_SHAPE[1] - 1))\n        mel_spec = librosa.feature.melspectrogram(y=chunk, \n                                                  sr=SAMPLE_RATE, \n                                                  n_fft=1024, \n                                                  hop_length=hop_length, \n                                                  n_mels=SPEC_SHAPE[0], \n                                                  fmin=FMIN, \n                                                  fmax=FMAX)\n    \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n        \n        \n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        \n        save_dir = os.path.join(output_dir, primary_label)\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        save_path = os.path.join(save_dir, filepath.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0] + \n                                 '_' + str(s_cnt) + '.png')\n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\")\n        im.save(save_path)\n        \n        saved_samples.append(save_path)\n        s_cnt += 1\n        \n        \n    return saved_samples\n\nprint('FINAL NUMBER OF AUDIO FILES IN TRAINING DATA:', len(TRAIN)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}