{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\ndf = pd.read_csv('../input/birdclef-2021/train_metadata.csv',)\ndf.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1 = df['primary_label']\ndf1.unique()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.dtypes","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isnull().sum()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = df[[\"latitude\",\"longitude\"]]\nCorrelation = df.corr(method='kendall')\nprint(Correlation)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(df['primary_label'].value_counts())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.graph_objects as go\nspecies = df['primary_label'].value_counts()\nfig = go.Figure(data=[go.Bar(y=species.values, x=species.index)],\n                layout=go.Layout(margin=go.layout.Margin(l=0, r=0,\nb=15, t=50)))\n\nfig.update_layout()\nfig.show()                                                        ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['secondary_labels'].value_counts()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport descartes\nimport geopandas as gpd\nfrom shapely.geometry import Point, Polygon\n\n\n\n\n\n\nspecies_list = ['acowoo', 'haiwoo', 'gartro1', 'yerwar']\ndata = df[df['primary_label'].isin(species_list)]\ndata[\"latitude\"] = data[\"latitude\"].astype(float)\ndata[\"longitude\"] = data[\"longitude\"].astype(float)\n\n\ngeometry = [Point(xy) for xy in zip(data[\"longitude\"], data[\"latitude\"])]\n\n\ngeo_df = gpd.GeoDataFrame(data, crs=crs, geometry=geometry)\n\n\nspecies_id = geo_df[\"primary_label\"].value_counts().reset_index()\nspecies_id.insert(0, 'ID', range(0, 0 + len(species_id)))\n\nspecies_id.columns = [\"ID\", \"primary_label\", \"count\"]\ngeo_df = pd.merge(geo_df, species_id, how=\"left\", on=\"primary_label\")\n\n\nfig, ax = plt.subplots(figsize = (16, 10))\n\npalette = iter(sns.hls_palette(len(species_id)))\nfor i in range(len(species_list)):\n    geo_df[geo_df[\"ID\"] == i].plot(ax=ax, \n                                   markersize=20, \n                                   color=next(palette), \n                                   marker=\"o\", \n                                   label = species_id['primary_label'].values[i]);\n    \nax.legend()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hist_data = df['rating'].values.tolist()\nfig = go.Figure(data=[go.Histogram(x=hist_data)], \n                layout=go.Layout(margin=go.layout.Margin(l=0, r=0, b=10, t=50)))\nfig.update_layout(title='Number of recordings per rating')\n\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio = pd.read_csv('../input/birdclef-2021/train_soundscape_labels.csv',)\naudio.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(audio['birds'].value_counts())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"audio_path = '../input/birdclef-2021/train_short_audio/acafly/XC109605.ogg'\nimport IPython.display as ipd\nipd.Audio(audio_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport warnings\nwarnings.filterwarnings(action='ignore')\nimport librosa\n\nsig, rate= librosa.load(audio_path, sr=32000, offset=None, duration=15)\n\nprint('SIGNAL SHAPE:', sig.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport librosa.display\n\nplt.figure(figsize=(15, 5))\nlibrosa.display.waveplot(sig, sr=35000)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"spec = librosa.stft(sig)\nspec_db = librosa.amplitude_to_db(spec, ref=np.max)\nplt.figure(figsize=(15, 5))\nlibrosa.display.specshow(spec_db, \n                         sr=35000, \n                         x_axis='time', \n                         y_axis='hz', \n                         cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('SPEC SHAPE:', spec_db.shape)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for win_length in [128, 256, 512, 1024]:\n    \n    hop_length = win_length // 2\n    \n    spec = librosa.stft(sig, \n                        n_fft=win_length, \n                        hop_length=hop_length)\n    \n    spec_db = librosa.amplitude_to_db(spec, ref=np.max)\n    \n    plt.figure(figsize=(15, 5))\n    plt.title('Window length: ' + str(win_length) + ', Shape: ' + str(spec_db.shape))\n    librosa.display.specshow(spec_db, \n                             sr=32000, \n                             hop_length=hop_length, \n                             x_axis='time', \n                             y_axis='hz', \n                             cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SPEC_HEIGHT = 64\nSPEC_WIDTH = 256\n\nNUM_MELS = SPEC_HEIGHT\nHOP_LENGTH = int(32000 * 5 / (SPEC_WIDTH - 1)) \nFMIN = 500\nFMAX = 12500\n\nfor second in [5, 10, 15]:  \n    \n    s_start = (second - 5) * 32000\n    s_end = second * 32000\n\n    mel_spec = librosa.feature.melspectrogram(y=sig[s_start:s_end], \n                                              sr=32000, \n                                              n_fft=1024, \n                                              hop_length=HOP_LENGTH, \n                                              n_mels=NUM_MELS, \n                                              fmin=FMIN, \n                                              fmax=FMAX)\n    \n    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n\n    plt.figure(figsize=(15, 5))\n    plt.title('Second: ' + str(second) + ', Shape: ' + str(mel_spec_db.shape))\n    librosa.display.specshow(mel_spec_db, \n                             sr=32000, \n                             hop_length=HOP_LENGTH, \n                             x_axis='time', \n                             y_axis='mel',\n                             fmin=FMIN, \n                             fmax=FMAX, \n                             cmap=plt.get_cmap('viridis'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nimport pandas as pd\nimport librosa\nimport numpy as np\n\nfrom sklearn.utils import shuffle\nfrom PIL import Image\nfrom tqdm import tqdm\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\nRANDOM_SEED = 1337\nSAMPLE_RATE = 35000\nSIGNAL_LENGTH = 5 # seconds\nSPEC_SHAPE = (48, 128) # height x width\nFMIN = 500\nFMAX = 12500\nMAX_AUDIO_FILES = 1500","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/birdclef-2021/train_metadata.csv',)\ntrain = train.query('rating>=4')\nbirds_count = {}\nfor bird_species, count in zip(train.primary_label.unique(), \n                               train.groupby('primary_label')['primary_label'].count().values):\n    birds_count[bird_species] = count\nmost_represented_birds = [key for key,value in birds_count.items() if value >= 200] \n\nTRAIN = train.query('primary_label in @most_represented_birds')\nLABELS = sorted(TRAIN.primary_label.unique())\n\nprint('NUMBER OF SPECIES IN TRAIN DATA:', len(LABELS))\nprint('NUMBER OF SAMPLES IN TRAIN DATA:', len(TRAIN))\nprint('LABELS:', most_represented_birds)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAX_AUDIO_FILES\nTRAIN = shuffle(TRAIN, random_state=RANDOM_SEED)[:MAX_AUDIO_FILES]\n\ndef get_spectrograms(filepath, primary_label, output_dir):\n    \n    \n    sig, rate = librosa.load(filepath, sr=SAMPLE_RATE, offset=None, duration=15)\n    \n   \n    sig_splits = []\n    for i in range(0, len(sig), int(SIGNAL_LENGTH * SAMPLE_RATE)):\n        split = sig[i:i + int(SIGNAL_LENGTH * SAMPLE_RATE)]\n\n       \n        if len(split) < int(SIGNAL_LENGTH * SAMPLE_RATE):\n            break\n        \n        sig_splits.append(split)\n        \n    \n    s_cnt = 0\n    saved_samples = []\n    for chunk in sig_splits:\n        \n        hop_length = int(SIGNAL_LENGTH * SAMPLE_RATE / (SPEC_SHAPE[1] - 1))\n        mel_spec = librosa.feature.melspectrogram(y=chunk, \n                                                  sr=SAMPLE_RATE, \n                                                  n_fft=1024, \n                                                  hop_length=hop_length, \n                                                  n_mels=SPEC_SHAPE[0], \n                                                  fmin=FMIN, \n                                                  fmax=FMAX)\n    \n        mel_spec = librosa.power_to_db(mel_spec, ref=np.max) \n        \n        \n        mel_spec -= mel_spec.min()\n        mel_spec /= mel_spec.max()\n        \n        \n        save_dir = os.path.join(output_dir, primary_label)\n        if not os.path.exists(save_dir):\n            os.makedirs(save_dir)\n        save_path = os.path.join(save_dir, filepath.rsplit(os.sep, 1)[-1].rsplit('.', 1)[0] + \n                                 '_' + str(s_cnt) + '.png')\n        im = Image.fromarray(mel_spec * 255.0).convert(\"L\")\n        im.save(save_path)\n        \n        saved_samples.append(save_path)\n        s_cnt += 1\n        \n        \n    return saved_samples\n\nprint('FINAL NUMBER OF AUDIO FILES IN TRAINING DATA:', len(TRAIN)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}