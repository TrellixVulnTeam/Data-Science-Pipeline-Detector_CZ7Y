{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from fastai.vision.all import *\nimport librosa as librosa","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Specs","metadata":{}},{"cell_type":"code","source":"def chunk_to_spec(chunk, SPEC_HEIGHT=64,SPEC_WIDTH=256, rate=32000, FMIN=200, FMAX=12500):\n    mel_spec = librosa.feature.melspectrogram(y=chunk, \n                                              sr=32000, \n                                              n_fft=1024, \n                                              hop_length=int(32000 * 5 / (SPEC_WIDTH - 1)), \n                                              n_mels=SPEC_HEIGHT, \n                                              fmin=FMIN, \n                                              fmax=FMAX)\n    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n    return mel_spec_db","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/peak-identification/info_df.csv')\nprint(df.shape)\ndf.head(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fn, l, y, peaks = df.sample().values[0]\nstart_time = min(l/32000 - 5, max(float(peaks.split('#')[0])-2.5, 2.5))\ny, sr = librosa.load(fn, sr=32000, offset=start_time, duration=5)\nplt.imshow(chunk_to_spec(y, SPEC_HEIGHT=128), cmap='inferno')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DataLoaders","metadata":{}},{"cell_type":"code","source":"class TitledImage(fastuple):\n    def show(self, ctx=None, **kwargs): show_titled_image(self, ctx=ctx, **kwargs)\n\nclass ClipTransform(ItemTransform):\n\n    def __init__(self, df):\n        self.df=df\n        self.vocab,self.o2i = uniqueify(df['label'], sort=True, bidir=True)\n        \n    def encodes(self, i, from_np=False):\n        f, l, label, peaks = df.iloc[i].values\n        clip_num = random.choice([0, 0, 0, 1, 1, 2, 3, 4, 5, 6]) # More prob chose big peak\n        start_time = min(l/32000 - 5, max(float(peaks.split('#')[clip_num])-2.5, 2.5))\n        y, sr = librosa.load(f, sr=32000, offset=start_time, duration=5)\n        spec = chunk_to_spec(y,SPEC_HEIGHT=112,SPEC_WIDTH=224)\n        spec -= np.min(spec) \n        spec /= 80 # np.max(spec) # Normalize\n        spec =  torch.unsqueeze(tensor(spec), 0)\n        spec = torch.cat([spec, spec, spec]) # Stack three channels to simulate RGB if using a pretrained model\n        return spec, self.o2i[label]\n    \n    def decodes(self, x):\n        return TitledImage(x[0],self.vocab[x[1]])\n\n\ndf_small = df\nclip_tfm = ClipTransform(df)\ntrain =  df_small.sample(frac=0.8)\ntrain_idx, valid_idx = list(train.index), df_small[~df_small.index.isin(train.index)].index\nprint('train and val size', len(train_idx), len(valid_idx))\ntrain_tl= TfmdLists(train_idx, clip_tfm)\nvalid_tl= TfmdLists(valid_idx, clip_tfm)\ndls = DataLoaders.from_dsets(train_tl, valid_tl, bs=16)\ndls = dls.cuda()\nxb, yb = dls.one_batch()\nprint(xb.shape)\ndls.show_batch(max_n=3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn = cnn_learner(dls, models.resnet18, loss_func=FocalLossFlat(), metrics=[accuracy], cbs=[ShowGraphCallback(), CSVLogger()])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('Model created and ready for training')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.unfreeze()\nlearn.fit_one_cycle(3, slice(1e-4, 1e-3))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.recorder.plot_loss()\nplt.savefig('loss_plot.png')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.save('stage-1')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"learn.remove_cb(CSVLogger) # Not pickleable\nlearn.export('baseline_3e.pkl')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install -q wandb\n# import wandb\n# wandb.init()\n# from fastai.callback.wandb import *\n# # And add cbs=WandbCallback() to log","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}