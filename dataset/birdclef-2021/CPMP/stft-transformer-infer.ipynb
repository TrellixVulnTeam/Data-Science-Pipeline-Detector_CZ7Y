{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/timm-pytorch-image-models/pytorch-image-models-master/","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-14T18:47:01.773663Z","iopub.execute_input":"2021-06-14T18:47:01.773996Z","iopub.status.idle":"2021-06-14T18:47:29.497318Z","shell.execute_reply.started":"2021-06-14T18:47:01.773963Z","shell.execute_reply":"2021-06-14T18:47:29.496462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls ../input\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:29.499123Z","iopub.execute_input":"2021-06-14T18:47:29.499474Z","iopub.status.idle":"2021-06-14T18:47:30.146004Z","shell.execute_reply.started":"2021-06-14T18:47:29.499445Z","shell.execute_reply":"2021-06-14T18:47:30.145231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import argparse\nimport os\nimport sys\nfrom pathlib import Path\n\nos.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.149293Z","iopub.execute_input":"2021-06-14T18:47:30.149579Z","iopub.status.idle":"2021-06-14T18:47:30.15608Z","shell.execute_reply.started":"2021-06-14T18:47:30.149551Z","shell.execute_reply":"2021-06-14T18:47:30.155136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_path = Path('../input/birdclef-2021/')\ncpmp_path = Path('../input/cpmp-birdclef21-2/')\nPERIOD = 5\nIMAGE_HEIGHT = 300\nIMAGE_WIDTH = 2*IMAGE_HEIGHT\n\nPOSWEIGHT=8\nSR=32000","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.157278Z","iopub.execute_input":"2021-06-14T18:47:30.157661Z","iopub.status.idle":"2021-06-14T18:47:30.166338Z","shell.execute_reply.started":"2021-06-14T18:47:30.157621Z","shell.execute_reply":"2021-06-14T18:47:30.16552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\ntorch.__version__","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.170165Z","iopub.execute_input":"2021-06-14T18:47:30.17043Z","iopub.status.idle":"2021-06-14T18:47:30.178689Z","shell.execute_reply.started":"2021-06-14T18:47:30.170404Z","shell.execute_reply":"2021-06-14T18:47:30.177676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport librosa\nimport soundfile as sf\nfrom tqdm import tqdm\npd.options.display.max_columns = 100\n\nfrom skimage.transform import rescale, resize, downscale_local_mean\n#from audiomentations import Compose, AddGaussianSNR, AddGaussianNoise, PitchShift, AddBackgroundNoise, AddShortNoises, Gain\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold\nfrom sklearn.metrics import f1_score\nimport random\nimport time\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nimport timm\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.182289Z","iopub.execute_input":"2021-06-14T18:47:30.182674Z","iopub.status.idle":"2021-06-14T18:47:30.192897Z","shell.execute_reply.started":"2021-06-14T18:47:30.18264Z","shell.execute_reply":"2021-06-14T18:47:30.192099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_torch(seed_value):\n    random.seed(seed_value) # Python\n    np.random.seed(seed_value) # cpu vars\n    torch.manual_seed(seed_value) # cpu  vars    \n    if torch.cuda.is_available(): \n        torch.cuda.manual_seed(seed_value)\n        torch.cuda.manual_seed_all(seed_value) # gpu vars\n    if torch.backends.cudnn.is_available:\n        torch.backends.cudnn.deterministic = True\n        torch.backends.cudnn.benchmark = False","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.194427Z","iopub.execute_input":"2021-06-14T18:47:30.194977Z","iopub.status.idle":"2021-06-14T18:47:30.202822Z","shell.execute_reply.started":"2021-06-14T18:47:30.19494Z","shell.execute_reply":"2021-06-14T18:47:30.202034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(cpmp_path / 'train_001.csv')\ntrain_ff1010 = pd.read_csv(cpmp_path / 'train_ff1010.csv')\ntrain_ff1010['primary_label'] = 'nocall'\n\ncolumns = ['length', 'primary_label', 'secondary_labels', 'filename']\n\ntrain = pd.concat((train[columns], train_ff1010[columns])).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.203716Z","iopub.execute_input":"2021-06-14T18:47:30.204759Z","iopub.status.idle":"2021-06-14T18:47:30.624955Z","shell.execute_reply.started":"2021-06-14T18:47:30.20394Z","shell.execute_reply":"2021-06-14T18:47:30.624184Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"primary_labels = set(train.primary_label.unique())\nsecondary_labels = set([s for labels in train.secondary_labels for s in eval(labels)])\nsecondary_labels - primary_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.626426Z","iopub.execute_input":"2021-06-14T18:47:30.626775Z","iopub.status.idle":"2021-06-14T18:47:30.950588Z","shell.execute_reply.started":"2021-06-14T18:47:30.626741Z","shell.execute_reply":"2021-06-14T18:47:30.949681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"res = [[label for label in eval(secondary_label) if label != 'rocpig1'] \n                             for secondary_label in train['secondary_labels']]\ntrain['secondary_labels'] = res","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:30.952258Z","iopub.execute_input":"2021-06-14T18:47:30.952659Z","iopub.status.idle":"2021-06-14T18:47:31.470418Z","shell.execute_reply.started":"2021-06-14T18:47:30.952608Z","shell.execute_reply":"2021-06-14T18:47:31.469604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BIRD_CODE = {}\nfor i,label in enumerate(sorted(primary_labels)):\n    BIRD_CODE[label] = i\n\nINV_BIRD_CODE = np.array(sorted(primary_labels))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.473727Z","iopub.execute_input":"2021-06-14T18:47:31.473998Z","iopub.status.idle":"2021-06-14T18:47:31.480719Z","shell.execute_reply.started":"2021-06-14T18:47:31.47397Z","shell.execute_reply":"2021-06-14T18:47:31.479832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"INV_BIRD_CODE[220]","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.48199Z","iopub.execute_input":"2021-06-14T18:47:31.482479Z","iopub.status.idle":"2021-06-14T18:47:31.491848Z","shell.execute_reply.started":"2021-06-14T18:47:31.482442Z","shell.execute_reply":"2021-06-14T18:47:31.490623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NOCALL_CODE = BIRD_CODE['nocall']\nNOCALL_CODE","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.493314Z","iopub.execute_input":"2021-06-14T18:47:31.493672Z","iopub.status.idle":"2021-06-14T18:47:31.502116Z","shell.execute_reply.started":"2021-06-14T18:47:31.493639Z","shell.execute_reply":"2021-06-14T18:47:31.501139Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BIRD_CODE","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.503514Z","iopub.execute_input":"2021-06-14T18:47:31.503867Z","iopub.status.idle":"2021-06-14T18:47:31.524861Z","shell.execute_reply.started":"2021-06-14T18:47:31.503832Z","shell.execute_reply":"2021-06-14T18:47:31.524135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['class'] = [BIRD_CODE[label] for label in train.primary_label]\n\ndf = train.groupby('class').size()\ndf = 1. / df\ndf = df / df.mean()\n\nclass_weights = df.values\nclass_weights[BIRD_CODE['nocall']] = 1  # nocall \nlogits_weights = np.log(class_weights).reshape((1, -1))\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.526068Z","iopub.execute_input":"2021-06-14T18:47:31.526436Z","iopub.status.idle":"2021-06-14T18:47:31.587946Z","shell.execute_reply.started":"2021-06-14T18:47:31.526398Z","shell.execute_reply":"2021-06-14T18:47:31.587296Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')\nSEED=0\nFP16=False\nNFOLDS = 5\nTEST_BATCH_SIZE = 32\nWORKERS=2","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.588992Z","iopub.execute_input":"2021-06-14T18:47:31.58932Z","iopub.status.idle":"2021-06-14T18:47:31.596981Z","shell.execute_reply.started":"2021-06-14T18:47:31.589284Z","shell.execute_reply":"2021-06-14T18:47:31.594117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def gem(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1./p)\n\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6, p_trainable=True):\n        super(GeM,self).__init__()\n        if p_trainable:\n            self.p = Parameter(torch.ones(1)*p)\n        else:\n            self.p = p\n        self.eps = eps\n\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)       \n    def __repr__(self):\n        return self.__class__.__name__ + '(' + 'p=' + '{:.4f}'.format(self.p.data.tolist()[0]) + ', ' + 'eps=' + str(self.eps) + ')'\n\n\nclass Backbone(nn.Module):\n\n    \n    def __init__(self, name='resnet18', pretrained=False, deit_token=None, in_chans=3):\n        super(Backbone, self).__init__()\n        self.net = timm.create_model(name, pretrained=pretrained, in_chans=in_chans)\n        \n        if 'regnet' in name:\n            self.out_features = self.net.head.fc.in_features\n        elif name == 'vit_deit_base_distilled_patch16_384' and deit_token=='cat':\n            self.out_features = self.net.head.in_features + self.net.head_dist.in_features\n        elif 'vit' in name:\n            self.out_features = self.net.head.in_features\n        elif 'nfnet' in name:\n            self.out_features = self.net.head.fc.in_features\n        elif 'swin' in name:\n            self.out_features = self.net.head.in_features\n        elif 'rexnet' in name:\n            self.out_features = self.net.head.fc.in_features\n        elif 'csp' in name:\n            self.out_features = self.net.head.fc.in_features\n        elif 'res' in name: #works also for resnest\n            self.out_features = self.net.fc.in_features\n        elif 'efficientnet' in name:\n            self.out_features = self.net.classifier.in_features\n        elif 'densenet' in name:\n            self.out_features = self.net.classifier.in_features\n        elif 'senet' in name:\n            self.out_features = self.net.fc.in_features\n        elif 'inception' in name:\n            self.out_features = self.net.last_linear.in_features\n\n        else:\n            self.out_features = self.net.classifier.in_features\n\n    def forward(self, x):\n        x = self.net.forward_features(x)\n\n        return x\n    \nclass BirdModel(nn.Module):\n    def __init__(self, backbone, out_dim, neck=None, embedding_size=512, gem_pooling=False, \n                 loss=False, pretrained=False, use_pos=True, deit_token=None, in_chans=3):\n        super(BirdModel, self).__init__()\n        self.backbone_name = backbone\n        self.loss = loss\n        self.embedding_size = embedding_size\n        self.out_dim = out_dim\n        self.use_pos = use_pos\n        self.deit_token = deit_token\n        self.in_chans = in_chans\n        self.backbone = Backbone(backbone, pretrained=pretrained, deit_token=deit_token, in_chans=in_chans)\n        \n        if gem_pooling == \"gem\":\n            self.global_pool = GeM(p_trainable=args.p_trainable)\n        else:\n            self.global_pool = nn.AdaptiveAvgPool2d(1)\n\n        \n        # https://www.groundai.com/project/arcface-additive-angular-margin-loss-for-deep-face-recognition\n        if neck == \"option-D\":\n            self.neck = nn.Sequential(\n                nn.Linear(self.backbone.out_features, self.embedding_size, bias=True),\n                nn.BatchNorm1d(self.embedding_size),\n                torch.nn.PReLU()\n            )\n        elif neck == \"option-F\":\n            self.neck = nn.Sequential(\n                nn.Dropout(0.3),\n                nn.Linear(self.backbone.out_features, self.embedding_size, bias=True),\n                nn.BatchNorm1d(self.embedding_size),\n                torch.nn.PReLU()\n            )\n        else:\n            self.neck = nn.Sequential(\n                nn.Linear(self.backbone.out_features, self.embedding_size, bias=False),\n                nn.BatchNorm1d(self.embedding_size),\n            )\n            \n        self.head = nn.Linear(self.embedding_size, out_dim)\n        \n\n    def forward(self, input_dict, get_embeddings=False, get_attentions=False):\n\n        x = input_dict['spect']\n        x = x.unsqueeze(1)\n        if self.use_pos:\n            pos = torch.linspace(0., 1., x.size(2)).to(x.device)\n            pos = pos.half()\n            pos = pos.unsqueeze(0).unsqueeze(0).unsqueeze(-1)\n            pos = pos.expand(x.size(0), 1, x.size(2), x.size(3))\n            if self.in_chans == 2:\n                x = x.expand(-1, 1, -1, -1)\n                x = torch.cat([x, pos], 1)\n            else:\n                x = x.expand(-1, 2, -1, -1)\n                x = torch.cat([x, pos], 1)\n        else:\n            x = x.expand(-1, 3, -1, -1)\n\n        x = self.backbone(x)\n        \n        if 'vit' not in self.backbone_name and 'swin' not in self.backbone_name:\n            x = self.global_pool(x)\n            x = x[:,:,0,0]\n        if 'vit_deit_base_distilled_patch16_384' == self.backbone_name:\n            if self.deit_token == 'sum':\n                x = x[0] + x[1]\n            elif self.deit_token == 'cat':\n                x = torch.cat(x, 1)\n            else:\n                x = x[self.deit_token]\n        \n        x = self.neck(x)\n\n        logits = self.head(x)\n        \n        output_dict = {'logits':logits,\n                      }\n        if self.loss:\n            target = input_dict['target']\n            secondary_mask = input_dict['secondary_mask']\n            loss = criterion(logits, target, secondary_mask)\n            \n            output_dict['loss'] = loss\n            \n        return output_dict","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.598434Z","iopub.execute_input":"2021-06-14T18:47:31.599034Z","iopub.status.idle":"2021-06-14T18:47:31.628027Z","shell.execute_reply.started":"2021-06-14T18:47:31.598999Z","shell.execute_reply":"2021-06-14T18:47:31.627197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_checkpoint(backbone, epoch, fold, seed, fname, use_pos, deit_token):\n    filepath = cpmp_path / ('%s_%d_%d_%d.pt' % (fname, fold, seed, epoch))\n    print('loading ', str(filepath), '...')\n    model = BirdModel(backbone, \n                      out_dim=len(BIRD_CODE), \n                      neck=\"option-F\",\n                      loss=False, \n                      gem_pooling=False,\n                      use_pos=use_pos,\n                      deit_token=deit_token,\n                      pretrained=False).to(device)\n    checkpoint = torch.load(filepath)\n    model.load_state_dict(checkpoint['model'])\n    model.to(device)\n    model.eval()\n    model.half()\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.629419Z","iopub.execute_input":"2021-06-14T18:47:31.629789Z","iopub.status.idle":"2021-06-14T18:47:31.643015Z","shell.execute_reply.started":"2021-06-14T18:47:31.629753Z","shell.execute_reply":"2021-06-14T18:47:31.64216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def list_files(path):\n    return [os.path.join(path, f) for f in os.listdir(path) if f.rsplit('.', 1)[-1] in ['ogg']]\n\nIS_TEST = True\ntest_audio = list_files(input_path / 'test_soundscapes')\nif len(test_audio) == 0:\n    test_audio = list_files(input_path / 'train_soundscapes')\n    IS_TEST = False\n    \nprint('{} FILES IN TEST SET.'.format(len(test_audio)))","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.644242Z","iopub.execute_input":"2021-06-14T18:47:31.644658Z","iopub.status.idle":"2021-06-14T18:47:31.666978Z","shell.execute_reply.started":"2021-06-14T18:47:31.644622Z","shell.execute_reply":"2021-06-14T18:47:31.666175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_clip_sr(file_path):\n    clip, sr_native = sf.read(file_path)\n    clip = librosa.to_mono(clip)\n    clip = clip.astype('float32')\n    sr = 32000\n    return clip, sr\n\ndef get_melspec(clip, sr, period, IMAGE_WIDTH, IMAGE_HEIGHT, fmin, htk, power, n_fft):\n    length = len(clip)\n    if period > length:\n        start = np.random.randint(period - length)\n        tmp = np.zeros(period, dtype=clip.dtype)\n        tmp[start : start + length] = clip\n        clip = tmp\n        \n    win_length = n_fft#//2\n    hop_length = int((len(clip) - win_length + n_fft) / IMAGE_WIDTH) + 1 \n    spect = np.abs(librosa.stft(y=clip, n_fft=n_fft, hop_length=hop_length, win_length=win_length))\n    if spect.shape[1] < IMAGE_WIDTH:\n        #print('too large hop length, len(clip)=', len(clip))\n        hop_length = hop_length - 1\n        spect = np.abs(librosa.stft(y=clip, n_fft=n_fft, hop_length=hop_length, win_length=win_length))\n    if spect.shape[1] > IMAGE_WIDTH:\n        spect = spect[:, :IMAGE_WIDTH]\n    n_mels = IMAGE_HEIGHT // 2\n    spect = np.power(spect, power)\n    spect = librosa.feature.melspectrogram(S=spect, sr=sr, n_fft=n_fft, n_mels=n_mels, fmin=fmin, fmax=16000, htk=htk)\n    spect = librosa.power_to_db(spect)\n    spect = resize(spect, (IMAGE_HEIGHT, IMAGE_WIDTH), preserve_range=True, anti_aliasing=True)\n    spect = spect - spect.min()\n    smax = spect.max()\n    if smax >= 0.001:\n        spect = spect / smax\n    else:\n        spect[...] = 0\n    return spect\n\nclass BirdTestDataset(Dataset):\n    def __init__(self,\n                 file_path,\n                 image_width,\n                 image_height,\n                  period=PERIOD,\n                 fmin=300,\n                 htk=False,\n                 power=2,\n                use_patch=False,\n                  n_fft=1024,\n                 single_window=False,\n                 use_inv_stem=False,\n                ):\n        super(BirdTestDataset, self).__init__()\n        self.file_path = file_path\n        clip, sr = get_clip_sr(file_path)\n        self.clip = clip\n        self.sr = sr\n        self.image_width = image_width\n        self.image_height = image_height\n        self.fmin = fmin\n        self.htk = htk\n        self.power = power\n        self.use_patch = use_patch\n        self.n_fft = n_fft\n        self.single_window = single_window\n        self.use_inv_stem = use_inv_stem\n        period = period * sr\n        self.period = period\n        #print(clip.shape[0] / (period))\n        if single_window:\n            self.starts = np.arange(0, 602.5, 2.5)\n        else:\n            self.starts = np.arange(0, 601.25, 1.25)\n        #self.starts = np.arange(0, 602.5, 2.5)\n        #print(self.starts)\n\n    def __len__(self):\n        if self.single_window:\n            return len(self.starts) - 2\n        else:\n            return len(self.starts) - 4\n\n    def inv_stem(self, x):\n        x1 = x.transpose(0, 1).view(24, 24, 16, 16)\n        y = torch.zeros(384, 384, dtype=x.dtype)\n        for i in range(24):\n            for j in range(24):\n                y[i*16:(i+1)*16, j*16:(j+1)*16] = x1[i, j]\n        return y\n\n    def __getitem__(self, idx: int):\n        start = self.starts[idx]\n        if self.single_window:\n            end = self.starts[idx + 2]\n        else:\n            end = self.starts[idx + 4]\n        \n        clip = self.clip[int(start * self.sr ): int(end * self.sr)]\n        melspec = get_melspec(clip, self.sr, self.period, self.image_width, self.image_height, self.fmin, \n                              self.htk, self.power, self.n_fft)\n\n        if self.use_inv_stem:\n            spect = torch.from_numpy(melspec)\n            spect = self.inv_stem(spect)    \n        else:\n            if self.use_patch:\n                patch_size = self.use_patch\n                spect = np.zeros((384, 384), dtype=np.float32)\n                for i in range(0, 192, patch_size):\n                    spect[2 * i : 2 * i + patch_size, :] = melspec[i : i + patch_size, : 384]\n                    spect[2 * i + patch_size : 2 * i + 2*patch_size, :] = melspec[i : i + patch_size, 384 : ]\n                melspec = spect\n            spect = torch.from_numpy(melspec)\n            \n        return {\n            \"spect\": spect.half(),\n        }\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.668134Z","iopub.execute_input":"2021-06-14T18:47:31.668629Z","iopub.status.idle":"2021-06-14T18:47:31.690792Z","shell.execute_reply.started":"2021-06-14T18:47:31.668595Z","shell.execute_reply":"2021-06-14T18:47:31.689943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test_preds(loader, models, device):\n\n    for model in models:\n        model.eval()\n    LOGITS = []\n    \n    with torch.no_grad():\n        if 1:\n            bar = (range(len(loader)))\n            load_iter = iter(loader)\n            batch = load_iter.next()\n            batch = {k:batch[k].to(device, non_blocking=True) for k in batch.keys() }\n\n            for i in bar:\n                input_dict = batch.copy()\n                if i + 1 < len(loader):\n                    batch = load_iter.next()\n                    batch = {k:batch[k].to(device, non_blocking=True) for k in batch.keys() }\n                    \n                logits = 0\n                for model in models:\n                    logits = logits + model(input_dict)['logits'].detach()\n                logits = logits / len(models)\n                LOGITS.append(logits)\n    \n    LOGITS = torch.cat(LOGITS).cpu().numpy()\n   \n    return LOGITS\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.69243Z","iopub.execute_input":"2021-06-14T18:47:31.692806Z","iopub.status.idle":"2021-06-14T18:47:31.704343Z","shell.execute_reply.started":"2021-06-14T18:47:31.692771Z","shell.execute_reply":"2021-06-14T18:47:31.703689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def window(logits):\n    new_logits = 2*logits[0::2, :]\n    median_logits = logits[1::2, :]\n    new_logits[:-1] += median_logits\n    new_logits[1:] += median_logits\n    new_logits[:1, :] += logits[:1, :]\n    new_logits[-1:, :] += logits[-1:, :]\n    new_logits = new_logits / 4\n    return new_logits","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.706021Z","iopub.execute_input":"2021-06-14T18:47:31.706387Z","iopub.status.idle":"2021-06-14T18:47:31.720924Z","shell.execute_reply.started":"2021-06-14T18:47:31.706352Z","shell.execute_reply":"2021-06-14T18:47:31.72013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_logits(config, models):\n    LOGITS = []\n    RAW_LOGITS = []\n    for file_path in tqdm(test_audio):\n        fmin = config.get('fmin', 300)\n        htk = config.get('htk', False)\n        power = config.get('power', 2)\n        use_patch = config.get('use_patch', False)\n        n_fft = config.get('n_fft', 1024)\n        single_window = config.get('single_window', False)\n        use_inv_stem = config.get('use_inv_stem', False)\n        test_dataset = BirdTestDataset(file_path, config['width'], config['height'], \n                                       fmin=fmin, htk=htk, power=power, use_patch=use_patch, \n                                       n_fft=n_fft, single_window=single_window, use_inv_stem=use_inv_stem,)\n        test_loader = DataLoader(\n            test_dataset,\n            batch_size=TEST_BATCH_SIZE,\n            num_workers=WORKERS,\n            shuffle=False,\n        )\n        logits = test_preds(test_loader, models, device)\n        logits = window(logits)\n        if not single_window:\n            logits = window(logits)\n        LOGITS.append(logits)\n   \n    return LOGITS","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.72229Z","iopub.execute_input":"2021-06-14T18:47:31.722671Z","iopub.status.idle":"2021-06-14T18:47:31.732817Z","shell.execute_reply.started":"2021-06-14T18:47:31.722635Z","shell.execute_reply":"2021-06-14T18:47:31.731865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_pred(LOGITS, thr, incr, weight=0):\n    all_preds = []\n    for file_path, logits in zip(test_audio, LOGITS):\n        fileinfo = file_path.split(os.sep)[-1].rsplit('.', 1)[0].split('_')\n        audio_id = int(fileinfo[0])\n        site = fileinfo[1]\n        #print(audio_id, site)\n        logits = logits + weight * logits_weights\n        logits_max = logits.max(0)\n        logits = logits.copy()\n        for j in range(logits.shape[1]):\n            if logits_max[j] > thr:\n                logits[:, j] += thr - incr\n        for seconds, logit in zip(range(5, 605, 5), logits):\n            row_id = str(audio_id )+ '_' + site + '_' + str(seconds)\n            birds = list(INV_BIRD_CODE[logit >= thr])\n            if 'nocall' in birds and len(birds) > 1:\n                birds = [p for p in birds if p!= 'nocall']\n            elif len(birds) == 0:\n                birds = ['nocall']\n            birds = ' '.join(birds)\n\n            all_preds.append((row_id, site, audio_id, seconds, birds))\n    df = pd.DataFrame().from_records(all_preds)\n    df.columns = ['row_id', 'site', 'audio_id', 'seconds', 'birds']\n    df = df.sort_values(['site', 'audio_id', 'seconds']).reset_index(drop=True)\n    return df","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.733838Z","iopub.execute_input":"2021-06-14T18:47:31.734231Z","iopub.status.idle":"2021-06-14T18:47:31.748668Z","shell.execute_reply.started":"2021-06-14T18:47:31.73418Z","shell.execute_reply":"2021-06-14T18:47:31.747943Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"config = {'fnames':['stft_transformer', ],\n          'backbone':'vit_deit_base_distilled_patch16_384',\n          'width': 576,\n          'height': 256,\n          'use_pos': False,\n          'deit_token':'sum',\n          'use_inv_stem':True,\n}\n\nepoch = 59\ndeit_token = config.get('deit_token', None)\nmodels = [load_checkpoint(config['backbone'], epoch, fold, seed, \n                          fname + '_' + str(fold),\n                          config['use_pos'],\n                          deit_token,\n                         )\n          for fold in range(NFOLDS) \n          for seed, fname in enumerate(config['fnames'])]\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:47:31.750008Z","iopub.execute_input":"2021-06-14T18:47:31.750407Z","iopub.status.idle":"2021-06-14T18:48:27.146108Z","shell.execute_reply.started":"2021-06-14T18:47:31.75037Z","shell.execute_reply":"2021-06-14T18:48:27.14523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"thr = 2.7\nincr = -1.1\nLOGITS = compute_logits(config, models)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T18:48:27.147419Z","iopub.execute_input":"2021-06-14T18:48:27.147749Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = compute_pred(LOGITS, thr, incr)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[['row_id', 'birds']].to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def score(truth, pred):\n    truth = truth.split(' ')\n    pred = pred.split(' ')\n    y = np.zeros(len(BIRD_CODE))\n    for bird in truth:\n        y[BIRD_CODE[bird]] = 1\n    yhat = np.zeros(len(BIRD_CODE))\n    for bird in pred:\n        yhat[BIRD_CODE[bird]] = 1\n    score = f1_score(y, yhat)\n    return score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if not IS_TEST:\n    soundscape = pd.read_csv(input_path / 'train_soundscape_labels.csv')\n    nocall_filter = soundscape.birds == 'nocall'\n    call_filter = soundscape.birds != 'nocall'\n\n\n    score_birds = np.mean([score(truth, pred) for truth,pred in \n                   zip(soundscape.birds[call_filter], df.birds[call_filter])])\n    score_nocall = np.mean([score(truth, pred) for truth,pred in \n                    zip(soundscape.birds[nocall_filter], df.birds[nocall_filter])])\n    score_all = 0.54 * score_nocall + (1 - 0.54) * score_birds\n\n    print('%0.4f %0.4f %0.4f' % (score_all, score_birds, score_nocall))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}