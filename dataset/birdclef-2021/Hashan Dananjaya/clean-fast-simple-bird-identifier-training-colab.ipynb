{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!nvidia-smi","metadata":{"id":"C0vy_lvxVQf5","outputId":"0ad3c95b-49a6-4e37-c750-8b7f79e76f57","execution":{"iopub.status.busy":"2021-06-10T09:30:43.18009Z","iopub.execute_input":"2021-06-10T09:30:43.180424Z","iopub.status.idle":"2021-06-10T09:30:43.916617Z","shell.execute_reply.started":"2021-06-10T09:30:43.180391Z","shell.execute_reply":"2021-06-10T09:30:43.915841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:30:49.320576Z","iopub.execute_input":"2021-06-10T09:30:49.320917Z","iopub.status.idle":"2021-06-10T09:30:50.057873Z","shell.execute_reply.started":"2021-06-10T09:30:49.320885Z","shell.execute_reply":"2021-06-10T09:30:50.056767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q pysndfx SoundFile audiomentations pretrainedmodels efficientnet_pytorch resnest","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:30:53.400244Z","iopub.execute_input":"2021-06-10T09:30:53.400682Z","iopub.status.idle":"2021-06-10T09:31:05.321981Z","shell.execute_reply.started":"2021-06-10T09:30:53.400639Z","shell.execute_reply":"2021-06-10T09:31:05.32092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport librosa as lb\nimport librosa.display as lbd\nimport soundfile as sf\nfrom  soundfile import SoundFile\nimport pandas as pd\nfrom  IPython.display import Audio\nfrom pathlib import Path\n\nimport torch\nfrom torch import nn, optim\nfrom  torch.utils.data import Dataset, DataLoader\n\nfrom resnest.torch import resnest50\n\nfrom matplotlib import pyplot as plt\n\nimport os, random, gc\nimport re, time, json\nfrom  ast import literal_eval\n\n\nfrom IPython.display import Audio\nfrom sklearn.metrics import label_ranking_average_precision_score\n\nfrom tqdm.notebook import tqdm\nimport joblib","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:13.091012Z","iopub.execute_input":"2021-06-10T09:31:13.091377Z","iopub.status.idle":"2021-06-10T09:31:16.423149Z","shell.execute_reply.started":"2021-06-10T09:31:13.091338Z","shell.execute_reply":"2021-06-10T09:31:16.422093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\nseed_everything()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:27.441127Z","iopub.execute_input":"2021-06-10T09:31:27.441498Z","iopub.status.idle":"2021-06-10T09:31:27.450221Z","shell.execute_reply.started":"2021-06-10T09:31:27.441461Z","shell.execute_reply":"2021-06-10T09:31:27.449371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Find paths using\n#Path(\"../\")","metadata":{"execution":{"iopub.status.busy":"2021-06-07T08:29:49.358814Z","iopub.execute_input":"2021-06-07T08:29:49.359209Z","iopub.status.idle":"2021-06-07T08:29:49.367683Z","shell.execute_reply.started":"2021-06-07T08:29:49.359179Z","shell.execute_reply":"2021-06-07T08:29:49.366876Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Static Variables\n\nNUM_CLASSES = 397\nSR = 32_000\nDURATION = 7\n\nMAX_READ_SAMPLES = 5 # Each record will have 10 melspecs at most, you can increase this on Colab with High Memory Enabled\n\nDATA_ROOT = Path(\"../input/birdclef-2021\")\nMEL_PATHS = sorted(Path(\"../input\").glob(\"kkiller-birdclef-mels-computer-d7-part?/rich_train_metadata.csv\"))\nTRAIN_LABEL_PATHS = sorted(Path(\"../input\").glob(\"kkiller-birdclef-mels-computer-d7-part?/LABEL_IDS.json\"))\n\nMODEL_ROOT = Path(\".\")","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:32.130162Z","iopub.execute_input":"2021-06-10T09:31:32.130739Z","iopub.status.idle":"2021-06-10T09:31:32.162898Z","shell.execute_reply.started":"2021-06-10T09:31:32.130702Z","shell.execute_reply":"2021-06-10T09:31:32.16211Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"print(DATA_ROOT)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:39.699981Z","iopub.execute_input":"2021-06-10T09:31:39.700455Z","iopub.status.idle":"2021-06-10T09:31:39.704279Z","shell.execute_reply.started":"2021-06-10T09:31:39.700423Z","shell.execute_reply":"2021-06-10T09:31:39.703591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(MEL_PATHS)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:38.460926Z","iopub.execute_input":"2021-06-10T09:31:38.461249Z","iopub.status.idle":"2021-06-10T09:31:38.466434Z","shell.execute_reply.started":"2021-06-10T09:31:38.461223Z","shell.execute_reply":"2021-06-10T09:31:38.464984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MY\nprint(MEL_PATHS[0])\nprint(MEL_PATHS[1])\nprint(MEL_PATHS[2])\nprint(MEL_PATHS[3])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:43.759916Z","iopub.execute_input":"2021-06-10T09:31:43.760457Z","iopub.status.idle":"2021-06-10T09:31:43.764937Z","shell.execute_reply.started":"2021-06-10T09:31:43.760416Z","shell.execute_reply":"2021-06-10T09:31:43.764286Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN_BATCH_SIZE = 100\nTRAIN_NUM_WORKERS = 2\n\nVAL_BATCH_SIZE = 128\nVAL_NUM_WORKERS = 2\n\nDEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nprint(\"Device:\", DEVICE)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:46.659942Z","iopub.execute_input":"2021-06-10T09:31:46.660294Z","iopub.status.idle":"2021-06-10T09:31:46.666977Z","shell.execute_reply.started":"2021-06-10T09:31:46.660265Z","shell.execute_reply":"2021-06-10T09:31:46.665743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MY\n#convert secondary label string into list\ndf = pd.read_csv(str(MEL_PATHS[0]), index_col=0)\nprint(df.iloc[0,1])\nprint(type(df.iloc[0,1]))\ndf[\"secondary_labels\"] = df[\"secondary_labels\"].apply(literal_eval)\nprint(df.iloc[0,1])\nprint(type(df.iloc[0,1]))\nprint(df.iloc[0,1][0])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:49.524974Z","iopub.execute_input":"2021-06-10T09:31:49.525287Z","iopub.status.idle":"2021-06-10T09:31:49.948259Z","shell.execute_reply.started":"2021-06-10T09:31:49.525261Z","shell.execute_reply":"2021-06-10T09:31:49.947311Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_df(mel_paths=MEL_PATHS, train_label_paths=TRAIN_LABEL_PATHS):\n    df = None\n    LABEL_IDS = {}\n    \n    for file_path in MEL_PATHS:\n        temp = pd.read_csv(str(file_path), index_col=0)\n        temp[\"impath\"] = temp.apply(lambda row: file_path.parent/\"audio_images/{}/{}.npy\".format(row.primary_label, row.filename), axis=1) \n        df = temp if df is None else df.append(temp)\n        \n    for file_path in train_label_paths:\n        with open(str(file_path)) as f:\n          LABEL_IDS.update(json.load(f))\n\n    return LABEL_IDS, df","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:53.230125Z","iopub.execute_input":"2021-06-10T09:31:53.230644Z","iopub.status.idle":"2021-06-10T09:31:53.237774Z","shell.execute_reply.started":"2021-06-10T09:31:53.230598Z","shell.execute_reply":"2021-06-10T09:31:53.236768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MY\nLABEL_IDS_, df_ = get_df()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:31:56.510791Z","iopub.execute_input":"2021-06-10T09:31:56.513061Z","iopub.status.idle":"2021-06-10T09:31:59.008304Z","shell.execute_reply.started":"2021-06-10T09:31:56.513008Z","shell.execute_reply":"2021-06-10T09:31:59.007321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#MY\nprint(df_.shape)\nprint(type(LABEL_IDS_)) #contains all the labels in a dictionary\nprint(LABEL_IDS_.get(\"acafly\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:03.400141Z","iopub.execute_input":"2021-06-10T09:32:03.400518Z","iopub.status.idle":"2021-06-10T09:32:03.405777Z","shell.execute_reply.started":"2021-06-10T09:32:03.400488Z","shell.execute_reply":"2021-06-10T09:32:03.404685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LABEL_IDS, df = get_df()\n\nprint(df.shape)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:08.580011Z","iopub.execute_input":"2021-06-10T09:32:08.58034Z","iopub.status.idle":"2021-06-10T09:32:10.866239Z","shell.execute_reply.started":"2021-06-10T09:32:08.580313Z","shell.execute_reply":"2021-06-10T09:32:10.865611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"primary_label\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:14.72021Z","iopub.execute_input":"2021-06-10T09:32:14.720692Z","iopub.status.idle":"2021-06-10T09:32:14.736691Z","shell.execute_reply.started":"2021-06-10T09:32:14.720657Z","shell.execute_reply":"2021-06-10T09:32:14.735954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"secondary_labels\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:17.180253Z","iopub.execute_input":"2021-06-10T09:32:17.180636Z","iopub.status.idle":"2021-06-10T09:32:17.199235Z","shell.execute_reply.started":"2021-06-10T09:32:17.180605Z","shell.execute_reply":"2021-06-10T09:32:17.198379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"label_id\"].min(), df[\"label_id\"].max()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:21.379806Z","iopub.execute_input":"2021-06-10T09:32:21.380172Z","iopub.status.idle":"2021-06-10T09:32:21.386939Z","shell.execute_reply.started":"2021-06-10T09:32:21.380138Z","shell.execute_reply":"2021-06-10T09:32:21.385968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Need to Study","metadata":{}},{"cell_type":"code","source":"def get_model(name, num_classes=NUM_CLASSES):\n    \"\"\"\n    Loads a pretrained model. \n    Supports ResNest, ResNext-wsl, EfficientNet, ResNext and ResNet.\n\n    Arguments:\n        name {str} -- Name of the model to load\n\n    Keyword Arguments:\n        num_classes {int} -- Number of classes to use (default: {1})\n\n    Returns:\n        torch model -- Pretrained model\n    \"\"\"\n    if \"resnest\" in name:\n        model = getattr(resnest_torch, name)(pretrained=True)\n    elif \"wsl\" in name:\n        model = torch.hub.load(\"facebookresearch/WSL-Images\", name)\n    elif name.startswith(\"resnext\") or  name.startswith(\"resnet\"):\n        model = torch.hub.load(\"pytorch/vision:v0.6.0\", name, pretrained=True)\n    elif name.startswith(\"tf_efficientnet_b\"):\n        model = getattr(timm.models.efficientnet, name)(pretrained=True)\n    elif \"efficientnet-b\" in name:\n        model = EfficientNet.from_pretrained(name)\n    else:\n        model = pretrainedmodels.__dict__[name](pretrained='imagenet')\n\n    if hasattr(model, \"fc\"):\n        nb_ft = model.fc.in_features\n        model.fc = nn.Linear(nb_ft, num_classes)\n    elif hasattr(model, \"_fc\"):\n        nb_ft = model._fc.in_features\n        model._fc = nn.Linear(nb_ft, num_classes)\n    elif hasattr(model, \"classifier\"):\n        nb_ft = model.classifier.in_features\n        model.classifier = nn.Linear(nb_ft, num_classes)\n    elif hasattr(model, \"last_linear\"):\n        nb_ft = model.last_linear.in_features\n        model.last_linear = nn.Linear(nb_ft, num_classes)\n\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:29.260166Z","iopub.execute_input":"2021-06-10T09:32:29.260742Z","iopub.status.idle":"2021-06-10T09:32:29.270494Z","shell.execute_reply.started":"2021-06-10T09:32:29.26071Z","shell.execute_reply":"2021-06-10T09:32:29.269546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_data(df):\n    def load_row(row):\n    # impath = TRAIN_IMAGES_ROOT/f\"{row.primary_label}/{row.filename}.npy\"\n        return row.filename, np.load(str(row.impath))[:MAX_READ_SAMPLES]\n    \n    #in above fn: load the numpy files. Originally 3 dim (13???, 128, 281): ----> Using MAX_READ_SAMPLES we get set of values\n    \n    #joplib use to parallerlize processes\n\n    pool = joblib.Parallel(4)\n    mapper = joblib.delayed(load_row)\n    tasks = [mapper(row) for row in df.itertuples(False)]\n    res = pool(tqdm(tasks))\n    res = dict(res)\n    \n    return res\n","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:40.520742Z","iopub.execute_input":"2021-06-10T09:32:40.52135Z","iopub.status.idle":"2021-06-10T09:32:40.526689Z","shell.execute_reply.started":"2021-06-10T09:32:40.521314Z","shell.execute_reply":"2021-06-10T09:32:40.525786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#My\n# Can get understanding about how to load the numpy files to dictionary\n# Image dimentions and dimention reduction\n\ni=1\nfor row in df.itertuples(False):\n    print(row)\n    print(type(row))\n    \n    def load_row(row):\n    # impath = TRAIN_IMAGES_ROOT/f\"{row.primary_label}/{row.filename}.npy\"\n        return row.filename, np.load(str(row.impath))\n    a = load_row(row)\n    print(type(a))\n#     print(a)\n    print(np.shape(a))\n    print(a[0])\n#     print(a[1])\n    print(a[1].shape)\n   \n    if i==1:\n        break\n    else:\n        pass","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:45.240717Z","iopub.execute_input":"2021-06-10T09:32:45.241101Z","iopub.status.idle":"2021-06-10T09:32:45.280064Z","shell.execute_reply.started":"2021-06-10T09:32:45.241067Z","shell.execute_reply":"2021-06-10T09:32:45.278953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# We cache the train set to reduce training time\n\naudio_image_store = load_data(df)\nlen(audio_image_store)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:32:50.379791Z","iopub.execute_input":"2021-06-10T09:32:50.38014Z","iopub.status.idle":"2021-06-10T09:36:10.516412Z","shell.execute_reply.started":"2021-06-10T09:32:50.380111Z","shell.execute_reply":"2021-06-10T09:36:10.513782Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"shape:\", next(iter(audio_image_store.values())).shape)\nlbd.specshow(next(iter(audio_image_store.values()))[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:36:19.641797Z","iopub.execute_input":"2021-06-10T09:36:19.642187Z","iopub.status.idle":"2021-06-10T09:36:19.812569Z","shell.execute_reply.started":"2021-06-10T09:36:19.642143Z","shell.execute_reply":"2021-06-10T09:36:19.799743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#My \n#images comparison by shape\n\nfor row in df.itertuples(False):\n    \n    def load_row(row):\n    # impath = TRAIN_IMAGES_ROOT/f\"{row.primary_label}/{row.filename}.npy\"\n        return row.filename, np.load(str(row.impath))\n    a = load_row(row)\n    print(\"shape:\", next(iter(a[1].shape)))\n    print(next(iter(a[1])))\n    lbd.specshow(next(iter(a[1])))\n    \n    break","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:36:39.74172Z","iopub.execute_input":"2021-06-10T09:36:39.742129Z","iopub.status.idle":"2021-06-10T09:36:39.863983Z","shell.execute_reply.started":"2021-06-10T09:36:39.74209Z","shell.execute_reply":"2021-06-10T09:36:39.863044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Series([len(x) for x in audio_image_store.values()]).value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:36:45.880772Z","iopub.execute_input":"2021-06-10T09:36:45.881121Z","iopub.status.idle":"2021-06-10T09:36:45.947535Z","shell.execute_reply.started":"2021-06-10T09:36:45.881093Z","shell.execute_reply":"2021-06-10T09:36:45.946377Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#my\naudio_image_store['XC128813.ogg'].shape","metadata":{"execution":{"iopub.status.busy":"2021-06-10T09:36:57.339805Z","iopub.execute_input":"2021-06-10T09:36:57.340147Z","iopub.status.idle":"2021-06-10T09:36:57.345571Z","shell.execute_reply.started":"2021-06-10T09:36:57.340118Z","shell.execute_reply":"2021-06-10T09:36:57.344937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Whats the reason for many different dimentions in the npy array (image) ????","metadata":{}},{"cell_type":"markdown","source":"### Dataset Wrapper","metadata":{}},{"cell_type":"code","source":"class BirdClefDataset(Dataset):\n\n    def __init__(self, audio_image_store, meta, sr=SR, is_train=True, num_classes=NUM_CLASSES, duration=DURATION):\n        \n        self.audio_image_store = audio_image_store\n        self.meta = meta\n        self.sr = sr\n        self.is_train = is_train\n        self.num_classes = num_classes\n        self.duration = duration\n        self.audio_length = self.duration*self.sr\n        \n    #This type of method takes neither a self nor a cls parameter (but of course it’s free to accept an arbitrary number of other parameters).\n    @staticmethod\n    def normalize(image): \n        image = image.astype(\"float32\",copy=False)/ 255.0\n        #normalize image and create 3 stack of layers from one layer----> return (3,128,281)\n        image = np.stack([image,image,image])\n        return image\n    \n    def __len__(self):\n        return len(self.meta)\n    \n    def __getitem__(self,idx):\n        row = self.meta.iloc[idx]\n        image = audio_image_store[row.filename]\n        \n        #gets one layer from available layers (randomly)\n        image = image[np.random.choice(len(image))]\n        image = self.normalize(image)\n        \n        #t is a (397,) numpy array with 0.0025 labels selected label will be 0.995?\n        #why do we do label smoothing here ??????\n        #Label Smoothing is a regularization technique that introduces noise for the labels. This accounts for the fact that datasets may have mistakes in them,\n        t = np.zeros(self.num_classes, dtype=np.float32) + 0.0025 # Label smoothing\n        t[row.label_id] = 0.995\n        \n        return image,t","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:15:09.485174Z","iopub.execute_input":"2021-06-10T10:15:09.485534Z","iopub.status.idle":"2021-06-10T10:15:09.49491Z","shell.execute_reply.started":"2021-06-10T10:15:09.485504Z","shell.execute_reply":"2021-06-10T10:15:09.493542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = BirdClefDataset(audio_image_store, meta=df, sr=SR, duration=DURATION, is_train=True)\nlen(ds)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:20:22.644087Z","iopub.execute_input":"2021-06-10T10:20:22.644451Z","iopub.status.idle":"2021-06-10T10:20:22.651125Z","shell.execute_reply.started":"2021-06-10T10:20:22.64442Z","shell.execute_reply":"2021-06-10T10:20:22.649992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x, y = ds[np.random.choice(len(ds))]\n# x, y = ds[0]\nx.shape, y.shape, np.where(y >= 0.5)","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:24:21.01368Z","iopub.execute_input":"2021-06-10T10:24:21.014231Z","iopub.status.idle":"2021-06-10T10:24:21.023368Z","shell.execute_reply.started":"2021-06-10T10:24:21.014187Z","shell.execute_reply":"2021-06-10T10:24:21.022539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbd.specshow(x[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:25:28.803737Z","iopub.execute_input":"2021-06-10T10:25:28.8041Z","iopub.status.idle":"2021-06-10T10:25:28.891029Z","shell.execute_reply.started":"2021-06-10T10:25:28.804066Z","shell.execute_reply":"2021-06-10T10:25:28.889964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y[:5]","metadata":{"execution":{"iopub.status.busy":"2021-06-10T10:25:51.304414Z","iopub.execute_input":"2021-06-10T10:25:51.304757Z","iopub.status.idle":"2021-06-10T10:25:51.310352Z","shell.execute_reply.started":"2021-06-10T10:25:51.304729Z","shell.execute_reply":"2021-06-10T10:25:51.30973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the model","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}