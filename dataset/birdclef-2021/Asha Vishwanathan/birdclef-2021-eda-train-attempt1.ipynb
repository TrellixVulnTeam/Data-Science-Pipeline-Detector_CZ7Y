{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# A brief Introduction\n\nUsing Stefan's great introduction to data here -> https://www.kaggle.com/stefankahl/birdclef2021-exploring-the-data\nWe already have the following details:\n\n1.     Dataset has 397 different bird species\n2.     There are less than 500 samples per bird call and some have less than 100. Dataset is highly imbalanced\n3.     Each short audio recording is about X mins long. And has multiple bird calls but one of them is prominent and sometimes others  can be heard in the background. The primary bird species is present in primary_label in train_metadata.csv. The secondary labels indicate the other birds heard in the background.\n4.     Data about bird calls - Bird species (primary) and secondary ones heard in background and also type of call\n5.     Data other than bird species - Date & time when it was spotted, location(given by lattitude and longitude), \n6.     Data - Rating indicating quality of the calls, Author or the contributor who recorded","metadata":{}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"# Code adapted from https://www.kaggle.com/drcapa/birdclef-2021-starter\n\nimport numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport soundfile as sf\nimport librosa\nimport librosa.display\nimport IPython.display as display\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils import Sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPool1D, BatchNormalization\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.applications import VGG19, VGG16, ResNet50\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"path = '/kaggle/input/birdclef-2021/'\nos.listdir(path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Helper Functions\n\n","metadata":{}},{"cell_type":"code","source":"def read_ogg_file(file,path=None):\n    \"\"\" Read ogg audio file and return numpay array and samplerate\"\"\"\n    if path :\n        data, samplerate = sf.read(path+file)\n    else:\n        data, samplerate = sf.read(file)\n    return data, samplerate\n\n\ndef plot_audio_file(data, samplerate,label=None):\n    \"\"\" Plot the audio data\"\"\"\n    \n    sr = samplerate\n    fig = plt.figure(figsize=(8, 4))\n    x = range(len(data))\n    y = data\n    plt.plot(x, y)\n    plt.plot(x, y, color='red')\n    plt.legend(loc='upper center')\n    plt.grid()\n    if label:\n        plt.title(label)\n    plt.show()\n    \ndef plot_spectrogram(data, samplerate,label=None):\n    \"\"\" Plot spectrogram with mel scaling \"\"\"\n    \n    sr = samplerate\n    spectrogram = librosa.feature.melspectrogram(data, sr=sr)\n    log_spectrogram = librosa.power_to_db(spectrogram, ref=np.max)\n    librosa.display.specshow(log_spectrogram, sr=sr, x_axis='time', y_axis='mel')\n    if label:\n        plt.title(label)\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Data","metadata":{}},{"cell_type":"code","source":"train_soundscape_labels = pd.read_csv(path+'train_soundscape_labels.csv')\ntrain_meta_short_audio = pd.read_csv(path+'train_metadata.csv')\ntest_data = pd.read_csv(path+'test.csv')\nsamp_subm = pd.read_csv(path+'sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Overview","metadata":{}},{"cell_type":"markdown","source":"Loading the data from excel files","metadata":{}},{"cell_type":"code","source":"print('Number train label samples:', len(train_soundscape_labels))\nprint('Number train meta samples:', len(train_meta_short_audio))\nprint('Number train short audio folders:', len(os.listdir(path+'train_short_audio')))\nprint('Number train audios:', len(os.listdir(path+'train_soundscapes')))\nprint('Number test samples:', len(test_data))","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 397 short audio folders ie. 397 birds. There are 62874 short audio files present inside these folders which correspond to the entries in train_meta file","metadata":{}},{"cell_type":"code","source":"cpt = sum([len(files) for r, d, files in os.walk(path+'train_short_audio')])\nprint(cpt)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.listdir(path+'train_short_audio/caltow')[:2]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_soundscape_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta_short_audio.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Code adapted from https://www.kaggle.com/shahules/bird-watch-complete-eda-fe\n\nimport plotly.graph_objects as go\n\n# Unique eBird codes\nspecies = train_meta_short_audio['primary_label'].value_counts()\n\n# Make bar chart\nfig = go.Figure(data=[go.Bar(y=species.values, x=species.index)],\n                layout=go.Layout(margin=go.layout.Margin(l=0, r=0, b=10, t=50)))\n\n# Show chart\nfig.update_layout(title='Number of traning samples per species')\nfig.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Spectograms of different species\nLets compare different species to see how their spectograms differ","metadata":{}},{"cell_type":"code","source":"species = train_meta_short_audio['primary_label'].unique()[:5]\nprint(species)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"species_sample_filenames = [list(train_meta_short_audio[(train_meta_short_audio.primary_label==each) & (train_meta_short_audio.secondary_labels=='[]')]['filename'])[0] for each in species]\nprint(species_sample_filenames)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Load the data and samplerate and compare spectrograms:","metadata":{}},{"cell_type":"code","source":"# for label,filename in zip(species,species_sample_filenames):\n#     print(label)\n#     data, samplerate = sf.read(path+'train_short_audio/'+label+'/'+filename)\n#     print(data[:8])\n#     print(samplerate)\n#     plot_audio_file(data, samplerate,label)\n#     plot_spectrogram(data, samplerate,label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Display the audio of the file:","metadata":{}},{"cell_type":"code","source":"# display.Audio(path+'train_short_audio/'+label+'/'+filename)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualizing Spectograms of bird calls from same species\nLets check the variation in spectrogram of bird calls from same species to see if their spectograms differ","metadata":{}},{"cell_type":"code","source":"species = 'acafly'\nspecies_sample_filenames = list(train_meta_short_audio[(train_meta_short_audio.primary_label==species) & (train_meta_short_audio.secondary_labels=='[]')]['filename'])[:5]\nprint(species_sample_filenames)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# label = species\n# for filename in species_sample_filenames:\n#     print(label)\n#     data, samplerate = sf.read(path+'train_short_audio/'+label+'/'+filename)\n#     print(data[:8])\n#     print(samplerate)\n#     plot_audio_file(data, samplerate,label)\n#     plot_spectrogram(data, samplerate,label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis of Long Recordings in Train Soundscapes\nOur challenge is to identify which birds are calling in **long** recordings.\n\nThere are 20 long audio files in the folder train_soundscapes. And there are also 20 unique audio ids: ","metadata":{}},{"cell_type":"code","source":"train_soundscape_labels['audio_id'].unique()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Each audio file consists of 120 birds with a lenth of 5 seconds.","metadata":{}},{"cell_type":"code","source":"train_soundscape_labels.groupby(by=['audio_id']).count()['birds'][:4]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"So we have to split the long audio into 120 small audio.","metadata":{}},{"cell_type":"markdown","source":"## EDA on Train Soundscapes\nThe target label birds is a space delimited list of any bird songs present in the 5 second window. So we have to encode the labels. Therefor we look on an example with 3 different birds:","metadata":{}},{"cell_type":"code","source":"print('original label:', train_soundscape_labels.loc[458, 'birds'])\nprint('split into list:', train_soundscape_labels.loc[458, 'birds'].split(' '))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We extract all label of the train data:","metadata":{}},{"cell_type":"code","source":"labels = []\nfor row in train_soundscape_labels.index:\n    labels.extend(train_soundscape_labels.loc[row, 'birds'].split(' '))\nlabels = list(set(labels))\n\nprint('Number of unique bird labels:', len(labels))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We focus on an example. The first audio file is named by","metadata":{}},{"cell_type":"code","source":"file = os.listdir(path+'train_soundscapes')[0]\nfile","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We load the data and samplerate:","metadata":{}},{"cell_type":"code","source":"data, samplerate = read_ogg_file(file,path+'train_soundscapes/')\ndata.shape\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The numpy array has a lenght of 19,200,000. And we know there are 120 samples in each.So every sample consists of 160,000 values. These 160,000 values describes 5 seconds of the audio file.\n\nWe split the file name into the audio_id and site:","metadata":{}},{"cell_type":"code","source":"audio_id = file.split('_')[0]\nsite = file.split('_')[1]\nprint('audio_id:', audio_id, ', site:', site)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We focus on the samples with the label birds unequal to nocall. There are 4 samples","metadata":{}},{"cell_type":"code","source":"train_soundscape_labels[(train_soundscape_labels['audio_id']==int(audio_id)) & (train_soundscape_labels['site']==site) & (train_soundscape_labels['birds']!='nocall')]","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"We want to extract the first example with the id 1771. This bird we can here from 455 seconds to 460 seconds.  ","metadata":{}},{"cell_type":"code","source":"sub_data = data[int(455/5)*160000:int(460/5)*160000]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Plot the audio array:","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(14, 5))\nlibrosa.display.waveplot(sub_data, sr=samplerate)\nplt.grid()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Listen to the bird:","metadata":{}},{"cell_type":"code","source":"display.Audio(sub_data, rate=samplerate)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyzing the short Audio Files","metadata":{}},{"cell_type":"code","source":"species = 'caltow'\nfilename = os.listdir(path+ '/train_short_audio/' + species + '/')[0]\nprint(filename)\ndata, samplerate = read_ogg_file(filename,path+'train_short_audio/'+species+'/')\nprint(data.shape)\ndisplay.Audio(data, rate=samplerate)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_meta_short_audio[train_meta_short_audio['filename']==filename]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Removing the ones which have secondary labels and splitting the format into 5 second audio similar to the long soundscape format\n\nprimary_labels = train_meta_short_audio[train_meta_short_audio['secondary_labels']=='[]']['primary_label']\nfilenames = train_meta_short_audio[train_meta_short_audio['secondary_labels']=='[]']['filename']\n\nsplit_audio_ids = pd.DataFrame()\nall_seconds = []\nall_file_names = []\nall_labels = []\ncnt = 0\nfor primary_label,filename in zip(primary_labels,filenames):\n    fname = '/train_short_audio/' + primary_label + '/' + filename\n    full_path = path + fname\n    # Removing this to reduce time taken for running the notebook\n#     audio_file, audio_sr = read_ogg_file(fname,path)\n#     len_audio_file = len(audio_file)\n#     chunk = list(range(0,len_audio_file,160000))\n#     for i in range(0,len(chunk)-1):\n    for i in range(0,1):\n#         audio_file_short = audio_file[chunk[i]:chunk[i+1]]\n        # Check if the 5 second slot has a bird call here & Remove if not valid (Later)\n        seconds = 5 * (i+1)\n        all_seconds.append(seconds)\n        all_file_names.append(fname)\n        all_labels.append(primary_label)\n    cnt = cnt + 1\n    if cnt % 10000 == 0:\n        print(f\"{cnt} done\")\n        \n# display.Audio(audio_file_short, rate=audio_sr)\nsplit_audio_ids = pd.DataFrame({'row_id':[\"\"]*len(all_file_names),'site':[\"\"]*len(all_file_names),'filename':all_file_names,'seconds':all_seconds,'birds':all_labels})\nprint(len(split_audio_ids))\nsplit_audio_ids.head()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Consolidation across long and short Audios","metadata":{}},{"cell_type":"code","source":"train_sounscapes_filenames = []\n\nfor row in train_soundscape_labels.iterrows():\n    audio_id = row[1]['audio_id']\n    site = row[1]['site']\n    prefix = str(audio_id)+'_'+ str(site)\n    file_list = [s for s in os.listdir(path+\"/train_soundscapes/\") if prefix in s]\n    file = \"\"\n    if len(file_list) > 0:\n        file = file_list[0]\n    train_sounscapes_filenames.append('/train_soundscapes/'+file)\n\ntrain_soundscape_cleaned = train_soundscape_labels\ntrain_soundscape_cleaned['filename']=train_sounscapes_filenames\ntrain_soundscape_cleaned = train_soundscape_cleaned[train_soundscape_cleaned['filename'] != \"\"]\ntrain_soundscape_cleaned.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_soundscapes_all  = pd.concat([train_soundscape_cleaned,split_audio_ids])\ntrain_soundscapes_all['birds_split'] = train_soundscapes_all['birds'].str.split().str.len()\ntrain_soundscapes_all = train_soundscapes_all[train_soundscapes_all['birds_split']==1]\nlabels = pd.get_dummies(train_soundscapes_all['birds'])\n\ntrain_soundscapes_all = pd.concat([train_soundscapes_all,labels],axis=1)\ntrain_soundscapes_all = train_soundscapes_all.reset_index()\nlist_IDs_train, list_IDs_val = train_test_split(list(train_soundscapes_all.index), test_size=0.33, random_state=2021)\nlist_IDs_test = list(samp_subm.index)\ntrain_soundscapes_all.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Parameter\nBased on the EDA we define some parameters:","metadata":{}},{"cell_type":"code","source":"data_lenght = 160000\naudio_lenght = 5\nnum_labels = len(list(labels))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"For the Data Generator we want to define in the next step we need additional parameters:","metadata":{}},{"cell_type":"code","source":"batch_size = 16\nlen(train_soundscapes_all)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train, Val And Test Data","metadata":{}},{"cell_type":"code","source":"class DataGenerator(Sequence):\n    def __init__(self, path, list_IDs, data, batch_size,test=False):\n        self.path = path\n        self.list_IDs = list_IDs\n        self.data = data\n        self.batch_size = batch_size\n        self.indexes = np.arange(len(self.list_IDs))\n        self.test = test\n        \n    def __len__(self):\n        len_ = int(len(self.list_IDs)/self.batch_size)\n        if len_*self.batch_size < len(self.list_IDs):\n            len_ += 1\n        return len_\n    \n    def __getitem__(self, index):\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        list_IDs_temp = [self.list_IDs[k] for k in indexes]\n        X, y = self.__data_generation(list_IDs_temp)\n        X = X.reshape((self.batch_size, 100, 1600//2))\n        return X, y\n    \n    def __data_generation(self, list_IDs_temp):\n        X = np.zeros((self.batch_size, data_lenght//2))\n        y = np.zeros((self.batch_size, num_labels))\n        for i, ID in enumerate(list_IDs_temp):\n            file = str(self.data.loc[ID, 'filename'])\n            if file == \"\":\n                # Dummy for missing test audio files\n                audio_file_fft = np.zeros((data_lenght//2))\n            else:              \n                audio_file, audio_sr = read_ogg_file(file,self.path)\n                audio_file = audio_file[int((self.data.loc[ID, 'seconds']-5)/audio_lenght)*data_lenght:int(self.data.loc[ID, 'seconds']/audio_lenght)*data_lenght]\n                audio_file_fft = np.abs(np.fft.fft(audio_file)[: len(audio_file)//2])\n                # scale data\n                audio_file_fft = (audio_file_fft-audio_file_fft.mean())/audio_file_fft.std()\n            X[i, ] = audio_file_fft\n            if not self.test:\n                y[i, ] = self.data.loc[ID,self.data.columns[8:]].values\n        return X, y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Audio Data Generator\nWe use a Data Generator to load the data on demand.","metadata":{}},{"cell_type":"markdown","source":"Test the Data Generator","metadata":{}},{"cell_type":"code","source":"import random\ntrain_sample_size = 100000\nval_sample_size = 10000\n# list_IDs_train_sample = random.sample(list_IDs_train,train_sample_size)\n# list_IDs_val_sample = random.sample(list_IDs_val,val_sample_size)\nlist_IDs_train_sample = list_IDs_train\nlist_IDs_val_sample = list_IDs_val\ntrain_generator = DataGenerator(path, list_IDs_train_sample, train_soundscapes_all, batch_size)\nval_generator = DataGenerator(path, list_IDs_val_sample, train_soundscapes_all, batch_size)\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"epochs = 1\nlernrate = 2e-3","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv1D(64, input_shape=(100, 1600//2,), kernel_size=5, strides=4, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool1D(pool_size=(4)))\nmodel.add(Conv1D(64, kernel_size=3, activation='relu'))\nmodel.add(BatchNormalization())\nmodel.add(Flatten())\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(num_labels, activation='sigmoid'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile(optimizer = Adam(lr=lernrate),\n              loss='binary_crossentropy',\n              metrics=['binary_accuracy'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit_generator(generator=train_generator, validation_data=val_generator, epochs = epochs, workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analyse Training","metadata":{}},{"cell_type":"code","source":"fig, axs = plt.subplots(1, 2, figsize=(16, 4))\nfig.subplots_adjust(hspace = .2, wspace=.2)\naxs = axs.ravel()\nloss = history.history['loss']\nloss_val = history.history['val_loss']\nepochs = range(1, len(loss)+1)\naxs[0].plot(epochs, loss, 'bo', label='loss_train')\naxs[0].plot(epochs, loss_val, 'ro', label='loss_val')\naxs[0].set_title('Value of the loss function')\naxs[0].set_xlabel('epochs')\naxs[0].set_ylabel('value of the loss function')\naxs[0].legend()\naxs[0].grid()\nacc = history.history['binary_accuracy']\nacc_val = history.history['val_binary_accuracy']\naxs[1].plot(epochs, acc, 'bo', label='accuracy_train')\naxs[1].plot(epochs, acc_val, 'ro', label='accuracy_val')\naxs[1].set_title('Accuracy')\naxs[1].set_xlabel('Epochs')\naxs[1].set_ylabel('Value of accuracy')\naxs[1].legend()\naxs[1].grid()\nplt.show()","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict Test Data","metadata":{}},{"cell_type":"code","source":"# Code adapted from https://www.kaggle.com/stefankahl/birdclef2021-sample-submission\n\ndef list_files(path):\n    return [os.path.join(path, f) for f in os.listdir(path) if f.rsplit('.', 1)[-1] in ['ogg']]\ntest_audio = list_files(path + 'test_soundscapes')\n\nif len(test_audio) == 0:\n    print(\"Using train files...\")\n    test_audio = list_files(path + 'train_soundscapes')\n    \nprint('{} FILES IN TEST SET.'.format(len(test_audio)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split into 5 second segments\n\ntest_seconds = []\ntest_file_names = []\n\ncnt = 0\n\nfor fname in test_audio:\n    audio_file, audio_sr = read_ogg_file(fname)\n    len_audio_file = len(audio_file)\n    chunk = list(range(0,len_audio_file,160000))\n    for i in range(0,len(chunk)-1):\n        seconds = 5 * (i+1)\n        test_seconds.append(seconds)\n        test_file_names.append(fname)\n    cnt = cnt + 1\n    if cnt % 1000 == 0:\n        print(f\"{cnt} done\")\n        \nsplit_test_audio_ids = pd.DataFrame({'row_id':[\"\"]*len(test_file_names),'site':[\"\"]*len(test_file_names),'audio_id':[\"\"]*len(test_file_names),'filename':test_file_names,'seconds':test_seconds,'birds':[\"\"]*len(test_file_names),'birds_split':[1]*len(test_file_names)})\nprint(len(split_test_audio_ids))\n\nsplit_test_audio_ids = split_test_audio_ids.reset_index()\nsplit_test_audio_ids.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_lenght = 160000\naudio_lenght = 5\nnum_labels = len(list(labels))\n\nlist_IDs_test=list(split_test_audio_ids.index)\ntest_generator = DataGenerator(None, list_IDs_test, split_test_audio_ids, batch_size,True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict_generator(test_generator)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set all values greater than 0.5 to 1:","metadata":{}},{"cell_type":"code","source":"y_test = np.where(y_pred > 0.5, 1, 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Generate target label string:","metadata":{}},{"cell_type":"code","source":"print(y_test[:10])\nlabel_names = list(labels)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_ids = []\nlabels = []\nfor i in range(0,len(split_test_audio_ids[:len(y_test)])):\n    row_id = split_test_audio_ids.loc[i,'filename'].split(\"/\")[-1].split(\"_\")[0]\n    site = split_test_audio_ids.loc[i,'filename'].split(\"/\")[-1].split(\"_\")[1]\n    second = split_test_audio_ids.loc[i,'seconds']\n    row_ids.append(str(row_id)+\"_\"+str(site)+\"_\"+str(second))\n    string = ''\n    for col in range(0,len(y_test[i])):\n        if y_test[i][col] == 1:\n            if string == '':\n                string += label_names[col]\n            else:\n                string += ' ' + label_names[col]\n    if string == '':\n        string = 'nocall'\n    labels.append(string)\n\nsample_submission = pd.DataFrame({'row_id':row_ids,'birds':labels})\n\n# sample_submission['birds'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Export","metadata":{}},{"cell_type":"code","source":"output = sample_submission\noutput.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output[:3]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}