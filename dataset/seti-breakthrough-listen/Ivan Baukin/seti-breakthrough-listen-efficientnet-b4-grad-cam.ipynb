{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SETI-Breakthrough Listen. EfficientNet-B4+Grad-CAM\nWe train 1 fold of EfficientNet-B4 with image size 768x768. It only uses Hflip, Vflip, and Mixup augmentation. It uses a cosine train schedule with warmup and 40 epochs. Using full precision, this takes 24 hours to train on 4xV100 Nvidia GPU. (Using mixed precision trains twice as fast but unfortunately hurts accuracy for this model).\n\nThis notebook also demonstrates Grad Cam to show us what image features the model is using to predict targets.","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle')\n! pip install -e /kaggle/input/efficientnet-keras-dataset/efficientnet_kaggle","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2021-09-20T08:28:13.352788Z","iopub.execute_input":"2021-09-20T08:28:13.353121Z","iopub.status.idle":"2021-09-20T08:28:22.866353Z","shell.execute_reply.started":"2021-09-20T08:28:13.353091Z","shell.execute_reply":"2021-09-20T08:28:22.865347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2, os, gc, sys\nfrom sklearn.metrics import roc_auc_score\nimport albumentations as albu\nimport matplotlib.pyplot as plt\nimport pandas as pd, numpy as np\nimport efficientnet.tfkeras as efn\nfrom sklearn.model_selection import KFold\nimport tensorflow as tf, math\nimport tensorflow.keras.backend as K\nprint('TF version',tf.__version__)\nfrom tqdm import tqdm\n\nTRAIN_MODEL = False\nFOLD_0_ONLY = True\nMODEL_PATH = '/kaggle/input/setieb4768model/'\n# IF ONLY INTERESTED IN GRAD CAM, SET BELOW TO FALSE\nPREDICT_OOF = True\nPREDICT_TEST = True","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-20T08:28:22.868176Z","iopub.execute_input":"2021-09-20T08:28:22.868576Z","iopub.status.idle":"2021-09-20T08:28:27.45114Z","shell.execute_reply.started":"2021-09-20T08:28:22.868535Z","shell.execute_reply":"2021-09-20T08:28:27.45029Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"os.environ","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:27.452967Z","iopub.execute_input":"2021-09-20T08:28:27.453314Z","iopub.status.idle":"2021-09-20T08:28:27.46507Z","shell.execute_reply.started":"2021-09-20T08:28:27.453276Z","shell.execute_reply":"2021-09-20T08:28:27.464005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# LIST GPUS TO BE USED\nos.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n\n# EXPERIMENT VERSION NUMBER\nVER = 1003","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:26:32.814217Z","iopub.status.idle":"2021-09-20T08:26:32.814731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE MULTIPLE GPUS\nif os.environ[\"CUDA_VISIBLE_DEVICES\"].count(',') == 0:\n    strategy = tf.distribute.get_strategy()\n    print('single strategy')\nelse:\n    strategy = tf.distribute.MirroredStrategy()\n    print('multiple strategy')","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:00:43.388951Z","iopub.execute_input":"2021-09-12T16:00:43.389408Z","iopub.status.idle":"2021-09-12T16:00:43.396796Z","shell.execute_reply.started":"2021-09-12T16:00:43.38938Z","shell.execute_reply":"2021-09-12T16:00:43.395917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Train and Test","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\nprint('Train shape is', train.shape )\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:00:43.398079Z","iopub.execute_input":"2021-09-12T16:00:43.398441Z","iopub.status.idle":"2021-09-12T16:00:43.445925Z","shell.execute_reply.started":"2021-09-12T16:00:43.398397Z","shell.execute_reply":"2021-09-12T16:00:43.444958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nprint('Test shape is', test.shape )\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:00:43.44734Z","iopub.execute_input":"2021-09-12T16:00:43.447689Z","iopub.status.idle":"2021-09-12T16:00:43.482883Z","shell.execute_reply.started":"2021-09-12T16:00:43.447651Z","shell.execute_reply":"2021-09-12T16:00:43.481835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Loader","metadata":{}},{"cell_type":"code","source":"SIZE = 768\nBASE = '../input/seti-breakthrough-listen/train/'\n\nclass DataGenerator(tf.keras.utils.Sequence):\n    'Generates data for Keras'\n    def __init__(self, df, batch_size=32, shuffle=False, augment=False, visualize=False, size=SIZE, path=BASE,\n                 flipH=False, flipV=False, mixup_prob=0, mixup_alpha=3, mixup_max=True): \n\n        self.df = df.reset_index(drop=True)\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n        self.augment = augment\n        self.mixup_prob = mixup_prob\n        self.mixup_alpha = mixup_alpha\n        self.mixup_max = mixup_max\n        self.visualize = visualize\n        self.size = size\n        self.path = path\n        self.flipH = flipH\n        self.flipV = flipV\n        self.on_epoch_end()\n        \n    def __len__(self):\n        'Denotes the number of batches per epoch'\n        ct = int( np.ceil( len(self.df) / self.batch_size ) )\n        return ct\n\n    def __getitem__(self, index):\n        'Generate one batch of data'\n        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n        X, y = self.__data_generation(indexes)\n        \n        if self.augment: X = self.__augment_batch(X)                       \n        if self.flipH: X = X[:,::-1,:,:]\n        if self.flipV: X = X[:,:,::-1,:]\n            \n        return X,y\n\n    def on_epoch_end(self):\n        'Updates indexes after each epoch'\n        self.indexes = np.arange( len(self.df ) )\n        if self.shuffle: np.random.shuffle(self.indexes)\n            \n    def _get_image(self,row):\n        data = np.load(self.path+row.id[0]+'/'+row.id+'.npy').astype('float32') \n        X = np.zeros((273*3,256),dtype='float32')\n        \n        for k in range(3):\n            if self.visualize:\n                md = np.median(data[2*k,].flatten())\n                q75, q25 = np.percentile(data[2*k,].flatten(), [75 ,25])\n                iqr = q75 - q25\n                tmp = np.clip(data[2*k,],md-2*iqr,md+2*iqr)\n                tmp -= md-2*iqr\n                tmp /= 4*iqr\n            else: \n                tmp = data[2*k,]       \n            X[273*k:273*(k+1),] = tmp\n            \n        X = cv2.resize(X,(self.size,self.size))\n                               \n        return X,float(row.target)\n        \n            \n    def __data_generation(self, indexes):\n        'Generates data containing batch_size samples' \n        \n        X = np.zeros((len(indexes),self.size,self.size,1),dtype='float32')\n        y = np.zeros((len(indexes)),dtype='float32')\n        \n        df = self.df.loc[indexes]\n        for i,(index,row) in enumerate(df.iterrows()):\n            X[i,:,:,0],y[i] = self._get_image(row)\n                                \n        # MIXUP WITHIN BATCH\n        y2 = y.copy(); X2 = X.copy()\n        for i in range(len(indexes)):\n            if np.random.uniform(0,1) < self.mixup_prob:\n                rw = np.random.randint(0,len(indexes),2)\n                img,tar = X2[rw[0],], y2[rw[0]]  \n                img2,tar2 = X2[rw[1],], y2[rw[1]]\n                w = np.random.beta(self.mixup_alpha,self.mixup_alpha)\n                X[i,] = w * img2 + (1-w) * img\n                if self.mixup_max:\n                    y[i] = np.max([tar,tar2])\n                else:\n                    y[i] = w * tar2 + (1-w) * tar\n                    \n        return X,y\n \n    def __random_transform(self, img):\n        composition = albu.Compose([\n            albu.HorizontalFlip(p=0.5),\n            albu.VerticalFlip(p=0.5),\n            #albu.ShiftScaleRotate(rotate_limit=0,scale_limit=0.125,shift_limit=0.0625,p=0.25), \n            #albu.ColorJitter(brightness=0.3, contrast=0.3, saturation=0, hue=0, p=0.25),\n        ])\n        return composition(image=img)\n            \n    def __augment_batch(self, img_batch):\n        for i in range(img_batch.shape[0]):\n            tmp = self.__random_transform(img_batch[i, ])\n            img_batch[i, ] = tmp['image']\n        return img_batch","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-12T16:00:43.484441Z","iopub.execute_input":"2021-09-12T16:00:43.484788Z","iopub.status.idle":"2021-09-12T16:00:43.50945Z","shell.execute_reply.started":"2021-09-12T16:00:43.484752Z","shell.execute_reply":"2021-09-12T16:00:43.508268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display Examples\nWhen displaying example, we use the flag `visualize=True`. We do not use this during training, but when displaying images, this flag makes the colors easier for us to see with our human eye.","metadata":{}},{"cell_type":"code","source":"# DISPLAY EXAMPLES OF DATALOADER\ncols = 4\ntrain_gen = DataGenerator(train, augment=True, shuffle=True, batch_size=4, visualize=True, mixup_prob=1.0)\n# i - номер батча\n# b - сам батч\nfor i,b in enumerate(train_gen):\n    plt.figure(figsize=(20,10))\n    for k in range(cols):\n        plt.subplot(1,cols,k+1)\n        plt.imshow( b[0][k] ) \n        t = b[1][k]\n        plt.title('target = %i'%t,size=16)\n    plt.show()\n    if i>=3: break\n       ","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-09-12T16:00:43.511324Z","iopub.execute_input":"2021-09-12T16:00:43.511733Z","iopub.status.idle":"2021-09-12T16:00:47.688702Z","shell.execute_reply.started":"2021-09-12T16:00:43.511692Z","shell.execute_reply":"2021-09-12T16:00:47.687775Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Models\nIn the model below we can use `tf.keras.layers.Concatenate` instead of `tf.keras.layers.Conv2D` and we can remove `tf.keras.layers.Dropout(0.15)` and achieve the same model performance. So they are not important. The most important thing is mixup augmentation, large image size, and large backbone.","metadata":{}},{"cell_type":"code","source":"def build_model():\n\n    inp = tf.keras.layers.Input(shape=(None,None,1))\n    x = tf.keras.layers.Conv2D(3,3,strides=1,padding='same')(inp)\n    base = efn.EfficientNetB4(weights='imagenet',include_top=False, input_shape=None)\n    x = base(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.15)(x)\n    x = tf.keras.layers.Dense(1, activation='relu', dtype='float32')(x)\n        \n    model = tf.keras.Model(inputs=inp, outputs=x)\n    \n    opt = tf.keras.optimizers.Adam(learning_rate=1e-3)\n    met = tf.keras.metrics.AUC()\n    loss = tf.keras.losses.BinaryCrossentropy()\n    \n    model.compile(loss=loss, optimizer=opt, metrics=met) \n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:00:47.690194Z","iopub.execute_input":"2021-09-12T16:00:47.690519Z","iopub.status.idle":"2021-09-12T16:00:47.700373Z","shell.execute_reply.started":"2021-09-12T16:00:47.690485Z","shell.execute_reply":"2021-09-12T16:00:47.699245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_cam_model():\n\n    inp = tf.keras.layers.Input(shape=(None,None,1))\n    x = tf.keras.layers.Conv2D(3,3,strides=1,padding='same')(inp)\n    x = tf.keras.layers.BatchNormalization()(x)\n    base = efn.EfficientNetB4(weights='imagenet',include_top=False, input_shape=None)\n    x0 = base(x)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x0)\n    x = tf.keras.layers.Dropout(0.15)(x)\n    x = tf.keras.layers.Dense(1, activation='sigmoid', dtype='float32')(x)\n        \n    model = tf.keras.Model(inputs=inp, outputs=[x,x0])\n        \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:00:47.703669Z","iopub.execute_input":"2021-09-12T16:00:47.704042Z","iopub.status.idle":"2021-09-12T16:00:47.712035Z","shell.execute_reply.started":"2021-09-12T16:00:47.704005Z","shell.execute_reply":"2021-09-12T16:00:47.710854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Learning Schedule","metadata":{}},{"cell_type":"code","source":"LR_START = 5e-5\nLR_MAX = 5e-4\nLR_MIN = 5e-7\nLR_RAMPUP_EPOCHS = 3\nLR_SUSTAIN_EPOCHS = 0\nEPOCHS = 40\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        decay_total_epochs = EPOCHS - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS - 1\n        decay_epoch_index = epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS\n        phase = math.pi * decay_epoch_index / decay_total_epochs\n        cosine_decay = 0.5 * (1 + math.cos(phase))\n        lr = (LR_MAX - LR_MIN) * cosine_decay + LR_MIN\n    return lr\n\nrng = [i for i in range(EPOCHS)]\nlr_y = [lrfn(x) for x in rng]\nplt.figure(figsize=(10, 4))\nplt.plot(rng, lr_y, '-o')\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\". \\\n      format(lr_y[0], max(lr_y), lr_y[-1]))\nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose = True)","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:00:47.713545Z","iopub.execute_input":"2021-09-12T16:00:47.713947Z","iopub.status.idle":"2021-09-12T16:00:47.8673Z","shell.execute_reply.started":"2021-09-12T16:00:47.71386Z","shell.execute_reply":"2021-09-12T16:00:47.866285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{}},{"cell_type":"code","source":"FOLDS = 5\nBATCH = 32\nEPOCHS = 40\nBATCH_SIZE = 32\nVAL_BATCH = 32 #make this larger offline\n\nFOLDS = 5\nskf = KFold(n_splits=FOLDS, shuffle=True, random_state=42)\ntrain['fold'] = -1\noof = np.zeros(len(train))\npreds = np.zeros(len(test))\n\nfor fold,(idx_t, idx_v) in enumerate(skf.split(train)):\n    if (not TRAIN_MODEL)&(not PREDICT_OOF)&(not PREDICT_TEST): break\n        \n    K.clear_session()\n    print('#'*25)\n    print('### FOLD',fold+1)\n    print('### train size',len(idx_t),'valid size',len(idx_v))\n    print('#'*25)\n    \n    train_gen = DataGenerator(train.iloc[idx_t], shuffle=True, augment=True, batch_size=BATCH, mixup_prob=1.0)\n    valid_gen = DataGenerator(train.iloc[idx_v], batch_size=VAL_BATCH) \n    test_gen = DataGenerator(test, batch_size=VAL_BATCH, path='../input/seti-breakthrough-listen/test/')\n    \n    sv = tf.keras.callbacks.ModelCheckpoint(\n        'model_fold%i_v%i.h5'%(fold,VER), monitor='val_loss', verbose=1, save_best_only=True,\n        save_weights_only=True, mode='auto', save_freq='epoch'\n    )\n    \n    with strategy.scope():\n        model = build_model()  \n    if TRAIN_MODEL:\n        model.fit(train_gen, epochs=EPOCHS, validation_data=valid_gen, verbose=1, callbacks=[sv,lr_callback]\n             ,use_multiprocessing=True, workers=4)\n               \n    if PREDICT_OOF | PREDICT_TEST:\n        print('Loading model to predict oof and preds...')\n        model.load_weights(MODEL_PATH+'model_fold%i_v%i.h5'%(fold,VER))\n    \n    if PREDICT_OOF:\n        print('Predicting oof with TTAx4...')\n        oof[idx_v] += model.predict(valid_gen,verbose=1).flatten()/4.\n        valid_gen = DataGenerator(train.iloc[idx_v], batch_size=VAL_BATCH, flipH=True) \n        oof[idx_v] += model.predict(valid_gen,verbose=1).flatten()/4.\n        valid_gen = DataGenerator(train.iloc[idx_v], batch_size=VAL_BATCH, flipV=True) \n        oof[idx_v] += model.predict(valid_gen,verbose=1).flatten()/4.\n        valid_gen = DataGenerator(train.iloc[idx_v], batch_size=VAL_BATCH, flipH=True, flipV=True) \n        oof[idx_v] += model.predict(valid_gen,verbose=1).flatten()/4.\n    \n        auc = roc_auc_score(train.target.values[idx_v],oof[idx_v])\n        print(f'Fold {fold+1} AUC =',auc)\n        print('wrote OOF to disk')\n        print('#'*25)\n    \n        # SAVE EACH OOF IN CASE WE STOP TRAINING EARLY\n        train.loc[idx_v,'fold'] = fold\n        train['oof'] = oof\n        train.to_csv(f'oof_v{VER}_f{fold}.csv',index=False)  \n    \n        # LOG FOLD OOF AUC SCORE\n        f = open(f'log_v{VER}.txt','a')\n        f.write(f'Fold {fold+1} AUC = {auc}\\n')\n        f.close()\n        \n    if PREDICT_TEST:    \n        print('Predicting test with TTAx4...')\n        preds += model.predict(test_gen,verbose=1).flatten()/FOLDS/4\n        test_gen = DataGenerator(test, batch_size=VAL_BATCH, path='../input/seti-breakthrough-listen/test/',flipH=True)\n        preds += model.predict(test_gen,verbose=1).flatten()/FOLDS/4\n        test_gen = DataGenerator(test, batch_size=VAL_BATCH, path='../input/seti-breakthrough-listen/test/',flipV=True)\n        preds += model.predict(test_gen,verbose=1).flatten()/FOLDS/4\n        test_gen = DataGenerator(test, batch_size=VAL_BATCH, path='../input/seti-breakthrough-listen/test/',flipH=True,flipV=True)\n        preds += model.predict(test_gen,verbose=1).flatten()/FOLDS/4\n    \n        # SAVE EACH TEST IN CASE WE STOP TRAINING EARLY\n        test['target'] = preds*5/(fold+1)\n        test.to_csv(f'submission_v{VER}_f{fold}.csv',index=False)\n        print('wrote submission to disk')\n        \n    del model, train_gen, valid_gen, test_gen, sv\n    _ = gc.collect()\n    \n    if FOLD_0_ONLY: break","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2021-09-12T16:01:54.417176Z","iopub.execute_input":"2021-09-12T16:01:54.417534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grad Cam OOF Preds","metadata":{}},{"cell_type":"code","source":"# LOAD WEIGHTS INTO GRAD CAM MODEL\nFOLDS = 5\nwith strategy.scope():\n    model = build_cam_model()    \nmodel.load_weights(MODEL_PATH+'model_fold%i_v%i.h5'%(fold,VER))\nlayer_weights = model.layers[-1].get_weights()[0][:,0]","metadata":{"execution":{"iopub.status.busy":"2021-09-12T16:01:34.053808Z","iopub.execute_input":"2021-09-12T16:01:34.054188Z","iopub.status.idle":"2021-09-12T16:01:39.271213Z","shell.execute_reply.started":"2021-09-12T16:01:34.054157Z","shell.execute_reply":"2021-09-12T16:01:39.269899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HELPER FUNCTION\ndef mask2contour(mask, width=5):\n    w = mask.shape[1]\n    h = mask.shape[0]\n    mask2 = np.concatenate([mask[:,width:],np.zeros((h,width))],axis=1)\n    mask2 = np.logical_xor(mask,mask2)\n    mask3 = np.concatenate([mask[width:,:],np.zeros((width,w))],axis=0)\n    mask3 = np.logical_xor(mask,mask3)\n    return np.logical_or(mask2,mask3) \n\nclahe = cv2.createCLAHE(clipLimit=16.0, tileGridSize=(8,8))","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-09-12T16:01:09.353444Z","iopub.execute_input":"2021-09-12T16:01:09.353771Z","iopub.status.idle":"2021-09-12T16:01:09.363447Z","shell.execute_reply.started":"2021-09-12T16:01:09.353741Z","shell.execute_reply":"2021-09-12T16:01:09.362337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GET OOF WITH TARGET EQUAL 1\nPORTION = 512\ntmp = train.iloc[idx_v[:PORTION]]\ntmp = tmp.reset_index(drop=True)\nIDX = tmp.loc[tmp.target==1].index.values\nlen(IDX)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:15:05.484377Z","iopub.execute_input":"2021-08-26T17:15:05.484704Z","iopub.status.idle":"2021-08-26T17:15:05.494671Z","shell.execute_reply.started":"2021-08-26T17:15:05.484673Z","shell.execute_reply":"2021-08-26T17:15:05.493674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# PREDICT OOF SAMPLES FOR GRAD CAM\nvalid_gen = DataGenerator(train.iloc[idx_v[IDX]], batch_size=VAL_BATCH)\np,x = model.predict(valid_gen,verbose=1)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:15:08.88098Z","iopub.execute_input":"2021-08-26T17:15:08.881301Z","iopub.status.idle":"2021-08-26T17:15:14.363515Z","shell.execute_reply.started":"2021-08-26T17:15:08.881273Z","shell.execute_reply":"2021-08-26T17:15:14.36208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SKIP = 0\nSHOW = 32\n\nfor i,k in enumerate(IDX[SKIP:SKIP+SHOW]):\n    \n    plt.figure(figsize=(20,5))\n    \n    # PLOT GRAD CAM\n    img = np.sum(x[i+SKIP,] * layer_weights,axis=-1)\n    img = cv2.resize(img,(320,320))\n    plt.subplot(1,4,4)\n    plt.imshow(img)\n    \n    # GET GRAD CAM CONTOUR\n    cut = np.percentile(img.flatten(), [90])[0]\n    cntr = img.copy()\n    cntr[cntr>=cut] = 100\n    cntr[cntr<cut] = 0\n    cntr = mask2contour(cntr)\n\n    # PLOT ORIGINAL ON CADENCE\n    name = train.iloc[idx_v[k],0]\n    tar = train.iloc[idx_v[k],1]\n    img0 = np.load(BASE+name[0]+'/'+name+'.npy').astype('float32')\n    img = np.vstack(img0[::2])\n    img = cv2.resize(img,(320,320))\n    plt.subplot(1,4,1)\n    plt.imshow(img)\n    plt.title(f'Train ID = {name}',size=14)\n        \n    # PLOT ON CADENCE WITH IMPROVED VISIBILITY FILTER\n    plt.subplot(1,4,2)\n    img = img[1:,1:] - img[:-1,:-1] #emboss\n    img -= np.min(img)\n    img /= np.max(img)\n    img = (img*255).astype('uint8')\n    img = cv2.GaussianBlur(img,(5,5),0)\n    img = clahe.apply(img)\n    mx = np.max(img)\n    if p[i+SKIP,0]>0.5: \n        cntr = cntr[1:,1:]\n        img[cntr>0] = mx\n    plt.imshow(img)\n    plt.title(f'True = {tar}',size=14)\n    \n    # PLOT OFF CADENCE WITH IMPROVED VISIBILITY\n    img = np.vstack(img0[1::2])\n    img = cv2.resize(img,(320,320))\n    plt.subplot(1,4,3)  \n    img = img[1:,1:] - img[:-1,:-1] #emboss\n    img -= np.min(img)\n    img /= np.max(img)\n    img = (img*255).astype('uint8')\n    img = cv2.GaussianBlur(img,(5,5),0)\n    img = clahe.apply(img)\n    plt.imshow(img)\n    plt.title(f'Pred = {p[i+SKIP,0]:.3}',size=14)\n    \n    plt.show()","metadata":{"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-26T17:07:05.421106Z","iopub.status.idle":"2021-08-26T17:07:05.421724Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Grad Cam Test Preds","metadata":{}},{"cell_type":"code","source":"# PREDICT OOF SAMPLES FOR GRAD CAM\nPORTION = 256\ntest_gen = DataGenerator(test.iloc[:PORTION], batch_size=VAL_BATCH, path='../input/seti-breakthrough-listen/test/')\np,x = model.predict(test_gen,verbose=1)\nprint(x.shape)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:15:19.410024Z","iopub.execute_input":"2021-08-26T17:15:19.410341Z","iopub.status.idle":"2021-08-26T17:15:30.496067Z","shell.execute_reply.started":"2021-08-26T17:15:19.410312Z","shell.execute_reply":"2021-08-26T17:15:30.494884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# FIND PREDICTIONS WITH TARGET EQUAL 1\nIDX = np.where(p>0.75)[0]\nlen(IDX)","metadata":{"execution":{"iopub.status.busy":"2021-08-26T17:15:31.395331Z","iopub.execute_input":"2021-08-26T17:15:31.395748Z","iopub.status.idle":"2021-08-26T17:15:31.410022Z","shell.execute_reply.started":"2021-08-26T17:15:31.395712Z","shell.execute_reply":"2021-08-26T17:15:31.407799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SKIP = 0\nSHOW = 32\nBASE2 = '../input/seti-breakthrough-listen/test/'\n\nfor i,k in enumerate(IDX[SKIP:SKIP+SHOW]):\n    \n    plt.figure(figsize=(20,5))\n    \n    # PLOT GRAD CAM\n    img = np.sum(x[k,] * layer_weights,axis=-1)\n    img = cv2.resize(img,(320,320))\n    plt.subplot(1,4,4)\n    plt.imshow(img)\n    \n    # GET GRAD CAM CONTOUR\n    cut = np.percentile(img.flatten(), [90])[0]\n    cntr = img.copy()\n    cntr[cntr>=cut] = 100\n    cntr[cntr<cut] = 0\n    cntr = mask2contour(cntr)\n\n    # PLOT ORIGINAL ON CADENCE\n    name = test.iloc[k,0]\n    img0 = np.load(BASE2+name[0]+'/'+name+'.npy').astype('float32')\n    img = np.vstack(img0[::2])\n    img = cv2.resize(img,(320,320))\n    plt.subplot(1,4,1)\n    plt.imshow(img)\n    plt.title(f'Test ID = {name}',size=14)\n        \n    # PLOT ON CADENCE WITH IMPROVED VISIBILITY FILTER\n    plt.subplot(1,4,2)\n    img = img[1:,1:] - img[:-1,:-1] #emboss\n    img -= np.min(img)\n    img /= np.max(img)\n    img = (img*255).astype('uint8')\n    img = cv2.GaussianBlur(img,(5,5),0)\n    img = clahe.apply(img)\n    mx = np.max(img)\n    if p[k,0]>0.5: \n        cntr = cntr[1:,1:]\n        img[cntr>0] = mx\n    plt.imshow(img)\n    #plt.title(f'True = {tar}',size=14)\n    \n    # PLOT OFF CADENCE WITH IMPROVED VISIBILITY\n    img = np.vstack(img0[1::2])\n    img = cv2.resize(img,(320,320))\n    plt.subplot(1,4,3)  \n    img = img[1:,1:] - img[:-1,:-1] #emboss\n    img -= np.min(img)\n    img /= np.max(img)\n    img = (img*255).astype('uint8')\n    img = cv2.GaussianBlur(img,(5,5),0)\n    img = clahe.apply(img)\n    plt.imshow(img)\n    plt.title(f'Pred = {p[k,0]:.3}',size=14)\n    \n    plt.show()","metadata":{"scrolled":true,"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-08-26T17:15:34.410324Z","iopub.execute_input":"2021-08-26T17:15:34.410661Z","iopub.status.idle":"2021-08-26T17:15:52.350875Z","shell.execute_reply.started":"2021-08-26T17:15:34.410629Z","shell.execute_reply":"2021-08-26T17:15:52.349948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Explanation the Leak in Data","metadata":{}},{"cell_type":"code","source":"INPUT_DIR = \"../input/seti-breakthrough-listen\"\ndf_train = pd.read_csv(os.path.join(INPUT_DIR, \"train_labels.csv\"))\ndf_subm = pd.read_csv(os.path.join(INPUT_DIR, \"sample_submission.csv\"))\ndf_train_pos = df_train[df_train.target == 1]","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:33.940254Z","iopub.execute_input":"2021-09-20T08:28:33.94061Z","iopub.status.idle":"2021-09-20T08:28:34.051118Z","shell.execute_reply.started":"2021-09-20T08:28:33.940579Z","shell.execute_reply":"2021-09-20T08:28:34.050279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Functions for loading and displating samples of data:","metadata":{}},{"cell_type":"code","source":"def load_example(idx):\n    try:\n        x = np.load(os.path.join(INPUT_DIR, \"train\", idx[0], idx + \".npy\"))\n    except:\n        x = np.load(os.path.join(INPUT_DIR, \"test\",  idx[0], idx + \".npy\"))\n    return x.astype(np.float32)\n\n\ndef show_example(x, p=0):\n    \n    x = x.reshape(-1, 256)\n    x = np.clip(x, np.percentile(x, p), np.percentile(x, 100-p)) # clip for better contrast\n    \n    fig, ax = plt.subplots()\n    fig.set_size_inches(18, 3)\n    ax.set_xticks(np.arange(1,6)*273)\n    ax.set_yticks([])\n    ax.grid(True)\n    ax.imshow(x.T, aspect=\"auto\", cmap=\"Greys\")","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:36.262132Z","iopub.execute_input":"2021-09-20T08:28:36.262449Z","iopub.status.idle":"2021-09-20T08:28:36.270243Z","shell.execute_reply.started":"2021-09-20T08:28:36.262419Z","shell.execute_reply":"2021-09-20T08:28:36.269039Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's take a look at one sample which contains a needle with a vety low SNR, definitely not visible by eye, the 5th positive sample in train. Time is the horizontal direction, frequency vertical:","metadata":{}},{"cell_type":"code","source":"idx = df_train_pos.id.iloc[5]\nprint(idx)\nx0 = load_example(idx)\nshow_example(x0, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:37.297646Z","iopub.execute_input":"2021-09-20T08:28:37.297969Z","iopub.status.idle":"2021-09-20T08:28:37.589154Z","shell.execute_reply.started":"2021-09-20T08:28:37.297937Z","shell.execute_reply":"2021-09-20T08:28:37.588398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's doing the \"renormalization\". We start with one normalized reference column and check if this column is found somewhere else in the data:","metadata":{}},{"cell_type":"code","source":"def column_norm(x):\n    ''' normalizes each column of 273 pixels in each of the 6 images in sample x separately \n    to mean==0 and L2 norm==1 '''\n    \n    xn  = x - np.mean(x, axis=1, keepdims=True) # remove mean\n    xn /= np.sqrt(np.sum(xn**2, axis=1, keepdims=True)) # normalize\n    return xn  \n\ndef find_similar_column(col0, xn1):\n    ''' calculates cosine similarity between the normalized reference column col0 and all columns\n        in the column-normalized sample xn1 '''\n    \n    return np.array([ [ np.dot(col0, col1) for col1 in img.T ] for img in xn1 ])","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:39.44764Z","iopub.execute_input":"2021-09-20T08:28:39.448Z","iopub.status.idle":"2021-09-20T08:28:39.456934Z","shell.execute_reply.started":"2021-09-20T08:28:39.44797Z","shell.execute_reply":"2021-09-20T08:28:39.455909Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The normalized sample from above. Still no needle visible.","metadata":{}},{"cell_type":"code","source":"xn0 = column_norm(x0)\nshow_example(xn0, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:40.439681Z","iopub.execute_input":"2021-09-20T08:28:40.439996Z","iopub.status.idle":"2021-09-20T08:28:40.6783Z","shell.execute_reply.started":"2021-09-20T08:28:40.439967Z","shell.execute_reply":"2021-09-20T08:28:40.677392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now let's search the dataset for a copy of normalized column 128 in image 1 of our sample. I use col 128 because it's in the middle of the image. I search only a small subset of the full 60,000 samples dataset to keep running time short because I know from earlier runs where the match will be ;).","metadata":{}},{"cell_type":"code","source":"for idx in tqdm(df_train.id.iloc[50500:51000]):\n    xn1 = column_norm(load_example(idx))\n    cs = find_similar_column(xn0[0,:,128], xn1)\n    csm = cs.max()\n    if csm > 0.9:\n        print(idx, csm, cs.argmax() % 273)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:42.567071Z","iopub.execute_input":"2021-09-20T08:28:42.567421Z","iopub.status.idle":"2021-09-20T08:28:58.172379Z","shell.execute_reply.started":"2021-09-20T08:28:42.56739Z","shell.execute_reply":"2021-09-20T08:28:58.171441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Found a perfect match: sample d87cb86179e9d02. Let's look at it. It is identical to 004933b94083be2  where they overlap It's only shifted by 128-68=60 frequency bins:","metadata":{}},{"cell_type":"code","source":"x1 = load_example(\"d87cb86179e9d02\")\nshow_example(x1, 1)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:28:58.173923Z","iopub.execute_input":"2021-09-20T08:28:58.174425Z","iopub.status.idle":"2021-09-20T08:28:58.397938Z","shell.execute_reply.started":"2021-09-20T08:28:58.174385Z","shell.execute_reply":"2021-09-20T08:28:58.396924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Normalize it and subtract from the normalized sample xn0. Increasing the contrast a little, the needles are easily visible. The noise has been perfectly removed because of the leak.","metadata":{}},{"cell_type":"code","source":"xn1 = column_norm(x1)\nshow_example(xn0 - np.roll(xn1, 128-68, axis=2), 10)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:29:27.058807Z","iopub.execute_input":"2021-09-20T08:29:27.059126Z","iopub.status.idle":"2021-09-20T08:29:27.271634Z","shell.execute_reply.started":"2021-09-20T08:29:27.059095Z","shell.execute_reply":"2021-09-20T08:29:27.270708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Increasing the contrast some more, numerical rounding errors become visible, except for where the artificial signals were inserted. Obviously using rectangles.","metadata":{}},{"cell_type":"code","source":"show_example(xn0 - np.roll(xn1, 128-68, axis=2), 40)","metadata":{"execution":{"iopub.status.busy":"2021-09-20T08:29:34.688997Z","iopub.execute_input":"2021-09-20T08:29:34.689334Z","iopub.status.idle":"2021-09-20T08:29:34.9304Z","shell.execute_reply.started":"2021-09-20T08:29:34.689298Z","shell.execute_reply":"2021-09-20T08:29:34.929507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}