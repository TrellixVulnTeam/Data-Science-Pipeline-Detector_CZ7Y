{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">SETI - Signal Search <br>  EDA & Baseline Model </h1>\n<br>","metadata":{}},{"cell_type":"markdown","source":"## <a name=\"Wheat Detection\">SETI - Signal Search </a>\n\n#### <a name=\"About_Competition\"> Introduction </a>\n\nIn this competition, use your data science skills to help identify anomalous signals in scans of Breakthrough Listen targets. Because there are no confirmed examples of alien signals to use to train machine learning algorithms, the team included some simulated signals (that they call “needles”) in the haystack of data from the telescope. They have identified some of the hidden needles so that you can train your model to find more. The data consist of two-dimensional arrays, so there may be approaches from computer vision that are promising, as well as digital signal processing, anomaly detection, and more. The algorithm that’s successful at identifying the most needles will win a cash prize, but also has the potential to help answer one of the biggest questions in science.\n\n\n\n#### <a name=\"Specific Objectives\">Specific Objectives</a>           \n\nThe main objective of the competition is to develop machine learning-based models to accurately classify anomalous signals in scans of Breakthrough Listen targets.\n\n\n#### <a name=\"dataset_description\">Dataset Description</a>: \n\nIn this competition you are tasked with looking for technosignature signals in cadence snippets taken from the Green Bank Telescope (GBT). Please read the extended description on the Data Information tab for detailed information about the data (that's too lengthy to include here).\n\n#### Files - \n##### train/ -\n  Training set of cadence snippet files stored in numpy float16 format (v1.20.1), one file per cadence snippet id, with corresponding labels found in the train_labels.csv file. \n  \n Each file has dimension (6, 273, 256)\n \n*  1st dimension representing the 6 positions of the cadence\n*  2nd and 3rd dimensions representing the 2D spectrogram.\n \n \n##### test/ - \nthe test set cadence snippet files; you must predict whether or not the cadence contains a \"needle\", which is the target for this competition\n\nsample_submission.csv - a sample submission file in the correct format\ntrain_labels - targets corresponding (by id) to the cadence snippet files found in the train/ folder\n\n\n  1. cadence snippet id of file \n  2. target - 1 or 0\n    \n\n#### <a name=\"target_variable\">Target Variable</a>                                        \n* __Submission data__  \n    1. cadence snippet id of file \n    2. target - 1 or 0\n\nCatagory of Labels :- \n\n","metadata":{}},{"cell_type":"markdown","source":"# Contents\n\n* [<font size=4>EDA</font>](#1)\n    * [Preparing the ground](#1.1)\n\n\n* [<font size=4>Image processing </font>](#2)\n    * [Visualise the data](#2.1)\n","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\n# Data Visualisation libraries \n%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport cv2\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n## Image Augmentation \n\n# skimage\nfrom skimage.io import imshow, imread, imsave\nfrom skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean\nfrom skimage import color,data\nfrom skimage.exposure import adjust_gamma\nfrom skimage.util import random_noise","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH = '../input/seti-breakthrough-listen/'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(PATH+'train_labels.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.target.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"source = df_train['target'].value_counts()\nfig = go.Figure(data=[go.Pie(labels=source.index,values=source.values)])\nfig.update_layout(title='Target distribution')\nfig.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Observation \n\n- Dataset is pretty unbalanced as per above pie chart \n- Need to chose the appropirate sampling strategy while modeling ","metadata":{}},{"cell_type":"code","source":"def get_train_filename_by_id(_id: str) -> str:\n    return f\"{PATH}/train/{_id[0]}/{_id}.npy\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_train_filename_by_id(df_train.iloc[0][\"id\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets find out Shape of training data","metadata":{}},{"cell_type":"code","source":"tmp_filename = get_train_filename_by_id(df_train.iloc[0][\"id\"])\ntr_data = np.load(tmp_filename)\ntr_data.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualise the training data","metadata":{}},{"cell_type":"markdown","source":"## Referance :- \n\n Data plot Code taken from below kernal  \n\n[link](https://www.kaggle.com/ihelon/signal-search-exploratory-data-analysis)","metadata":{}},{"cell_type":"code","source":"def show_cadence(filename: str, label: int) -> None:\n    plt.figure(figsize=(16, 10))\n    arr = np.load(filename)\n    for i in range(6):\n        plt.subplot(6, 1, i + 1)\n        if i == 0:\n            plt.title(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n        plt.imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        plt.xticks([])\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_cadance(df,num_sample:int,target:int) -> None:\n    for i in range(1,num_sample):\n        show_cadence(get_train_filename_by_id(df_train[df_train[\"target\"] == target]['id'][i]),df_train[df_train[\"target\"] == target]['target'][i])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def display_cadance(df,num_sample:int,target:int) -> None:\n    df = df[df['target']==target].sample(num_sample)\n    for idx,row in df.iterrows():\n        show_cadence(get_train_filename_by_id(row[\"id\"]),row[\"target\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<br>\n<h1 style = \"font-size:60px; font-family:Garamond ; font-weight : normal; background-color: #f6f5f5 ; color : #fe346e; text-align: center; border-radius: 100px 100px;\">SETI - Signal Search <br>  Getting Sense of Cadence data </h1>\n<br>","metadata":{}},{"cell_type":"code","source":"display_cadance(df_train,num_sample=5,target=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"display_cadance(df_train,num_sample=5,target=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Lets kick start modeling","metadata":{}},{"cell_type":"markdown","source":"#####  Refence for below model , Kindly upvote below kernal\n\n[link](https://www.kaggle.com/jiny333/pytorch-simple-baseline-resnet-18-trn-infer)","metadata":{}},{"cell_type":"code","source":"!pip install -q pretrainedmodels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import glob\nimport cv2\nfrom sklearn.model_selection import train_test_split\nimport sklearn.metrics\nimport albumentations\n\nimport torch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets, resize=None, augmentations=None): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n        \n        if self.resize is not None:\n            image = np.transpose(image, (1,2,0))\n            image = cv2.resize(image, dsize=self.resize, interpolation=cv2.INTER_CUBIC)        \n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        # pytorch expects CHW instead of HWC\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train['img_pth'] = df_train['id'].apply(lambda x:f'{PATH}/train/{x[0]}/{x}.npy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preparing data for Training & Validation","metadata":{}},{"cell_type":"code","source":"def data_prep(img_paths,tgts,dataclass):\n    \n    images = img_paths.values\n    targets = tgts.values\n    train_images, valid_images, train_targets, valid_targets = train_test_split(images, targets, stratify=targets, random_state=42)\n\n    train_dataset = dataclass(train_images,train_targets,resize=(224,224))\n    train_loader = torch.utils.data.DataLoader(train_dataset,batch_size=16,shuffle=True,num_workers=4)\n\n    valid_dataset = dataclass(valid_images,valid_targets,resize=(224,224))\n    valid_loader = torch.utils.data.DataLoader(valid_dataset,batch_size=16,shuffle=False,num_workers=4)\n    \n    return train_loader,valid_loader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_loader,valid_loader = data_prep(df_train['img_pth'],df_train[\"target\"],ClassificationDataset)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport pretrainedmodels\n\ndef get_model(pretrained):\n    if pretrained:\n        model = pretrainedmodels.__dict__[\"resnet18\"](pretrained='imagenet')\n    else:\n        model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=None)\n        \n    model.last_linear = nn.Sequential(\n        nn.BatchNorm1d(512),\n        nn.Dropout(p=0.25),\n        nn.Linear(in_features=512, out_features=1024),\n        nn.ReLU(),\n        nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=1024, out_features=1)\n    )\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\"\nepochs = 5\n\nmodel = get_model(pretrained=False)\nmodel.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3,bias=False)\nmodel.to(device)\naug = None\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(epochs):\n    train(train_loader, model, optimizer, device=device)\n    predictions, valid_targets = evaluate(valid_loader, model, device=device)\n    roc_auc = sklearn.metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ...working to add another model in this kernal for ROC-AUC comparison ","metadata":{}},{"cell_type":"markdown","source":"# Kindly Upvote if you like this kernal","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}