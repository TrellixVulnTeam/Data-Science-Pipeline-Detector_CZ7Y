{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet >> /dev/null\n\nimport random, os\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nimport tensorflow as tf, math\nimport tensorflow_addons as tfa\nimport efficientnet.tfkeras as efn\nfrom tensorflow.keras.applications import (\n        vgg16,\n        resnet50,\n        inception_v3)\nimport tensorflow.keras.backend as K\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\n\nimport tensorflow_hub as tfhub","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-16T07:25:29.324857Z","iopub.execute_input":"2021-08-16T07:25:29.325349Z","iopub.status.idle":"2021-08-16T07:25:47.270618Z","shell.execute_reply.started":"2021-08-16T07:25:29.325243Z","shell.execute_reply":"2021-08-16T07:25:47.269478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"hub_type = 'feature_vector' # ['classification', 'feature_vector']\nmodel_arch = 'efficientnetv2-s-21k-ft1k'\nDS_GCS_PATH = KaggleDatasets().get_gcs_path(\"efficientnetv2-tfhub-weight-files\")\nMODEL_GCS_PATH = f'{DS_GCS_PATH}/tfhub_models/{model_arch}/{hub_type}'\nMODEL_GCS_PATH","metadata":{"execution":{"iopub.status.busy":"2021-08-16T07:25:47.272435Z","iopub.execute_input":"2021-08-16T07:25:47.27277Z","iopub.status.idle":"2021-08-16T07:25:47.768566Z","shell.execute_reply.started":"2021-08-16T07:25:47.27272Z","shell.execute_reply":"2021-08-16T07:25:47.767573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = \"TPU\" #or \"GPU\"\n\nSEED = 20\n\ntrain_fold = 0\n\nFOLDS = 5\n\nimg_size = (273 * 3, 256 * 2)\nbatch_size = 32 \nEPOCHS = 12\nwarmup = 15\n\nlearning_rate_base =  1e-4\n\n\nEFF_NET = 1\nweights = 'noisy-student' #'noisy-student' 'imagenet'\n\nadd_old_one = False #UPsample 1 target\n\n\ndef seed_everything(seed = 42):\n    random.seed(seed)\n    np.random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(SEED)\n\n\nif DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"execution":{"iopub.status.busy":"2021-08-16T07:25:47.770331Z","iopub.execute_input":"2021-08-16T07:25:47.770619Z","iopub.status.idle":"2021-08-16T07:25:53.125219Z","shell.execute_reply.started":"2021-08-16T07:25:47.770592Z","shell.execute_reply":"2021-08-16T07:25:53.124195Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('seti-old-tfrecords')\nprint(GCS_PATH)\nfiles_all = np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/old_*.tfrec')))\nfiles_all","metadata":{"execution":{"iopub.status.busy":"2021-08-16T07:25:53.128599Z","iopub.execute_input":"2021-08-16T07:25:53.128904Z","iopub.status.idle":"2021-08-16T07:27:40.258701Z","shell.execute_reply.started":"2021-08-16T07:25:53.128876Z","shell.execute_reply":"2021-08-16T07:27:40.257741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mixup(image, label):\n    # input image - is a batch of images of size [n,dim,dim,3] not a single image of [dim,dim,3]\n    # output - a batch of images with mixup applied\n    \n    imgs = []; labs = []\n    for j in range(batch_size * REPLICAS):\n        # CHOOSE RANDOM\n        k = tf.cast( tf.random.uniform([], 0, batch_size), tf.int32)\n        p = tf.random.uniform([], 0.15, 0.35) \n        \n        # MAKE MIXUP IMAGE\n        img1 = image[j,]\n        img2 = image[k,]\n        \n        lab1 =  tf.cast(label[j], tf.float32)\n        lab2 =  tf.cast(label[k], tf.float32)\n        \n        imgs.append((1-p)*img1 + p*img2)\n        labs.append((1-p)*lab1 + p*lab2)\n            \n    # RESHAPE HACK SO TPU COMPILER KNOWS SHAPE OF OUTPUT TENSOR (maybe use Python typing instead?)\n    image2 = tf.reshape(tf.stack(imgs),(batch_size * REPLICAS, img_size[0], img_size[1], 3))\n    label2 = tf.reshape(tf.stack(labs),(batch_size * REPLICAS, 1))\n    \n    return image2,label2\n\ndef prepare_image(img, augment=True, dim=256):    \n    img = tf.io.decode_raw(img, tf.float16)\n    img = tf.reshape(img, [273, 256, 3])\n    img = tf.cast(img, tf.float32)\n    \n    # Already pre-processed \n    #img = tf.clip_by_value(img, clip_value_min=-6.0, clip_value_max=6.0)\n    #img = img / 3.0\n    \n    if augment:\n        \n        channels = tf.unstack(img, axis=-1)\n        \n        if tf.random.uniform([]) > 0.5:\n            channels[0] = tf.reverse(channels[0], [0])\n        if tf.random.uniform([]) > 0.5:\n            channels[0] = tf.reverse(channels[0], [1])\n            \n        if tf.random.uniform([]) > 0.5:\n            channels[1] = tf.reverse(channels[1], [0])\n        if tf.random.uniform([]) > 0.5:\n            channels[1] = tf.reverse(channels[1], [1])\n            \n        if tf.random.uniform([]) > 0.5:\n            channels[2] = tf.reverse(channels[2], [0])\n        if tf.random.uniform([]) > 0.5:\n            channels[2] = tf.reverse(channels[2], [1])\n            \n        channels = tf.random.shuffle(channels)\n        #img = tf.stack(channels, axis = -1)\n        img = tf.stack([channels[0], channels[1], channels[2]], axis = -1)\n    \n    img = tf.unstack(img, axis = 2)\n    img = tf.concat(img, axis = 0)\n    img = tf.expand_dims(img, 2)\n    img = tf.image.grayscale_to_rgb(img)\n    \n    img = tf.image.resize(img, [img_size[0], img_size[1]])\n    \n    #if augment:\n    #    img = tf.image.random_flip_left_right(img)\n    #    img = tf.image.random_flip_up_down(img)\n               \n    img = tf.reshape(img, [dim[0], dim[1], 3])\n            \n    return img\n\ndef count_data_items(filenames):\n    n = [int(filename.split('_')[-1].split('.')[0]) for filename in filenames]\n    return np.sum(n)\n\n\ndef read_labeled_tfrecord(example):\n    tfrec_format = {\n        'signal'   : tf.io.FixedLenFeature([], tf.string),\n        'id'       : tf.io.FixedLenFeature([], tf.string),\n        'target'   : tf.io.FixedLenFeature([], tf.float32),\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['signal'], example['target']\n\n\ndef get_dataset(files, augment = False, shuffle = False, repeat = False, \n                labeled=True, return_image_names=True, batch_size=16, dim=256):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*8)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_names), \n                    num_parallel_calls=AUTO)      \n    \n    ds = ds.map(lambda img, imgname_or_label: (prepare_image(img, augment=augment, dim=dim), \n                                               imgname_or_label), \n                num_parallel_calls=AUTO)\n    \n    ds = ds.batch(batch_size * REPLICAS)\n    ds = ds.prefetch(AUTO)\n    \n    if augment:\n        ds = ds.map(mixup, num_parallel_calls = AUTO)\n        \n    if augment and tf.random.uniform([]) > 0.5:\n        ds = ds.map(lambda img, y: (tfa.image.random_cutout(img, mask_size = (800, 80)), y))\n                    \n    if augment and tf.random.uniform([]) > 0.75:\n        ds = ds.map(lambda img, y: (tfa.image.random_cutout(img, mask_size = (800, 80)), y))\n        \n    return ds\n\nclass cosine_annealing_warmup(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, learning_rate_base, num_warmup_steps, num_training_steps):\n        self.lr = learning_rate_base\n        self.ws = num_warmup_steps\n        self.ts = num_training_steps\n\n    def __call__(self, step):\n        return tf.where(step <= self.ws, self.lr * tf.cast(step, tf.float32) / tf.cast(self.ws, tf.float32), \n            self.lr*0.5*(1+tf.cos(math.pi*0.5*2.0*tf.cast(step - self.ws, tf.float32) / tf.cast(self.ws - self.ts, tf.float32))))\n\n\nEFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6]\n\ndef build_model(dim=128, ef=0, steps_per_epoch=0):\n    \n    inp = tf.keras.layers.Input(shape=(dim[0],dim[1],3))\n    \n    base = EFNS[ef](input_shape=(dim[0],dim[1],3), weights=weights,include_top=False)\n    x = base(inp)\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dropout(0.25)(x)\n    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n    \n    model = tf.keras.Model(inputs=inp,outputs=x)\n    \n#     model = tf.keras.Sequential([\n#             tf.keras.layers.InputLayer(input_shape=[dim[0],dim[1],3]),\n#             tfhub.KerasLayer(MODEL_GCS_PATH , trainable=True),\n#             tf.keras.layers.Dropout(rate=0.5),\n#             tf.keras.layers.Dense(1,activation='sigmoid')\n#         ])\n\n    \n    caw = cosine_annealing_warmup(learning_rate_base = learning_rate_base,\n                                  num_warmup_steps = EPOCHS * steps_per_epoch,\n                                  num_training_steps = int(warmup *  steps_per_epoch))\n    \n    opt = tf.keras.optimizers.Adam(caw)\n    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.05) #label_smoothing=0.05\n    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-08-16T07:27:40.260292Z","iopub.execute_input":"2021-08-16T07:27:40.260734Z","iopub.status.idle":"2021-08-16T07:27:40.477738Z","shell.execute_reply.started":"2021-08-16T07:27:40.260687Z","shell.execute_reply":"2021-08-16T07:27:40.476479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\nVERBOSE = 2\nDISPLAY_PLOT = True\n\nauc_ = []\n\nskf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\nfor fold,(idxT,idxV) in enumerate(skf.split(np.arange(len(files_all)))):\n    \n    if fold != train_fold:\n        continue\n    \n    # DISPLAY FOLD INFO\n    if DEVICE=='TPU':\n        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    print('#'*25); print('#### FOLD',fold+1)\n    \n    # CREATE TRAIN AND VALIDATION SUBSETS\n    #if add_old_one:\n    #    files_train = tf.io.gfile.glob([files_all[x] for x in idxT] + [GCS_PATH + '/old_one_10012.tfrec'])\n    #else:\n    #    files_train = tf.io.gfile.glob([files_all[x] for x in idxT])\n    files_train = tf.io.gfile.glob([files_all[x] for x in idxT])\n    np.random.shuffle(files_train); print('#'*25)\n    files_valid = tf.io.gfile.glob([files_all[x] for x in idxV])\n    \n    steps_per_epoch=count_data_items(files_train)/batch_size//REPLICAS\n    \n    # BUILD MODEL\n    K.clear_session()\n    with strategy.scope():\n        model = build_model(dim=img_size ,ef=5, steps_per_epoch = steps_per_epoch)\n        \n    # SAVE BEST MODEL EACH FOLD\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        'fold-%i.h5'%fold, monitor='val_auc', verbose=0, save_best_only=True,\n         save_weights_only=True, mode='max', save_freq='epoch')\n   \n    # TRAIN\n    history = model.fit(\n        get_dataset(files_train, augment=True, shuffle=True, repeat=True,\n                dim=img_size, batch_size = batch_size), \n        \n        epochs=EPOCHS, callbacks = [sv], #get_lr_callback(batch_size)\n        steps_per_epoch=count_data_items(files_train)/batch_size//REPLICAS,\n        validation_data=get_dataset(files_valid,augment=False,shuffle=False,\n        repeat=False,dim=img_size), \n        verbose=VERBOSE)\n    \n\n    #model.load_weights('fold-%i.h5'%fold)\n    print()\n    print('--------------- MAX AUC :- ', np.max(history.history['val_auc']))\n    print()\n    auc_.append(np.max(history.history['val_auc']))\n    \n    # PLOT TRAINING\n    if DISPLAY_PLOT:\n        plt.figure(figsize=(15,5))\n        plt.plot(np.arange(EPOCHS),history.history['auc'],'-o',label='Train AUC',color='#ff7f0e')\n        plt.plot(np.arange(EPOCHS),history.history['val_auc'],'-o',label='Val AUC',color='#1f77b4')\n        x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=300,color='#1f77b4')\n        plt.ylabel('AUC',size=14); plt.xlabel('Epoch',size=14)\n        plt.legend(loc=2)\n        plt2 = plt.gca().twinx()\n        plt2.plot(np.arange(EPOCHS),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n        plt2.plot(np.arange(EPOCHS),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n        x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n        ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.ylabel('Loss',size=14)\n        plt.legend(loc=3) \n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T07:27:40.479504Z","iopub.execute_input":"2021-08-16T07:27:40.479944Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# auc_","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}