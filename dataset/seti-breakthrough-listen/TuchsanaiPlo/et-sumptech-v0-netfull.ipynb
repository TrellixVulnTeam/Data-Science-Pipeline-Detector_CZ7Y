{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Library\n# ====================================================\nimport sys\nsys.path.append('../input/pytorch-image-models/pytorch-image-models-master')\n\n\nimport pandas as pd\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm.notebook import tqdm\n\nimport albumentations\nfrom sklearn import model_selection\n\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\n\nimport timm\nimport sklearn \n\nimport gc","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#https://www.kaggle.com/abhishek/step-1-create-folds\n\ndef create_folds(data, num_splits):\n    # we create a new column called kfold and fill it with -1\n    data[\"kfold\"] = -1\n    \n    # the next step is to randomize the rows of the data\n    data = data.sample(frac=1).reset_index(drop=True)\n\n    # calculate number of bins by Sturge's rule\n    # I take the floor of the value, you can also\n    # just round it\n    num_bins = int(np.floor(1 + np.log2(len(data))))\n    \n    # bin targets\n    data.loc[:, \"bins\"] = pd.cut(\n        data[\"target\"], bins=num_bins, labels=False\n    )\n    \n    # initiate the kfold class from model_selection module\n    kf = model_selection.StratifiedKFold(n_splits=num_splits)\n    \n    # fill the new kfold column\n    # note that, instead of targets, we use bins!\n    for f, (t_, v_) in enumerate(kf.split(X=data, y=data.bins.values)):\n        data.loc[v_, 'kfold'] = f\n    \n    # drop the bins column\n    data = data.drop(\"bins\", axis=1)\n\n    # return dataframe with folds\n    return data\n\n\ndf_train             = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ndf_train['img_path'] = df_train['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')\ndf_train_fold              = create_folds(df_train,num_splits=5)\n\n\ndel df_train\n\nprint(df_train_fold.groupby(['kfold','target']).size())\ndf_train_fold\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test             = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ndf_test['img_path'] = df_test['id'].apply(lambda x: f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')\n\n\ndf_test","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    input_size  = 224\n    output_size = 256\n\n    batch_size  = 75\n    num_workers  =8\n    #model_name  ='resnet50' \n    model_name  ='nfnet_l0'\n    num_epochs          = 15\n    stop_num_epochs     = 10 \n    seed=42\n    \n    \n    warmup_epochs= 3\n    warmup_lr    = 0\n    base_lr      = 0.0085\n    final_lr     = 0.5e-7\n    \n    \n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# model_names = timm.list_models(pretrained=True)\n# model_names\n\n# print(\"Available Vision Transformer Models: \")\n# timm.list_models(\"vit*\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\n    \nclass LR_Scheduler(object):\n    def __init__(self, optimizer, warmup_epochs, warmup_lr, num_epochs, base_lr, final_lr, iter_per_epoch, constant_predictor_lr=False):\n        self.base_lr = base_lr\n        self.constant_predictor_lr = constant_predictor_lr\n        warmup_iter = iter_per_epoch * warmup_epochs\n        warmup_lr_schedule = np.linspace(warmup_lr, base_lr, warmup_iter)\n        decay_iter = iter_per_epoch * (num_epochs - warmup_epochs)\n        cosine_lr_schedule = final_lr+0.5*(base_lr-final_lr)*(1+np.cos(np.pi*np.arange(decay_iter)/decay_iter))\n        \n        self.lr_schedule = np.concatenate((warmup_lr_schedule, cosine_lr_schedule))\n        self.optimizer = optimizer\n        self.iter = 0\n        self.current_lr = 0\n    def step(self):\n        for param_group in self.optimizer.param_groups:\n\n            if self.constant_predictor_lr and param_group['name'] == 'predictor':\n                param_group['lr'] = self.base_lr\n            else:\n                lr = param_group['lr'] = self.lr_schedule[self.iter]\n        \n        self.iter += 1\n        self.current_lr = lr\n        return lr\n    def get_lr(self):\n        return self.current_lr\n\n        \n\nclass SETIDataset:\n    \n    def __init__(self, image_paths, targets,  augmentations=None): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n        targets = self.targets[item]\n      \n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"label\": torch.tensor(targets, dtype=torch.float),\n        }\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Display sample Dataset","metadata":{}},{"cell_type":"code","source":"fold          = 0\nfold_Batch    = CFG.batch_size\n\ndf_train                  = df_train_fold[df_train_fold.kfold != fold].reset_index(drop=True)\nDict_Target_counts        = df_train['target'].value_counts().to_dict()\ndf_train['weight_sample'] = df_train['target'].apply(lambda x : 1/Dict_Target_counts[x] )\n\n\ndf_valid                  = df_train_fold[df_train_fold.kfold == fold].reset_index(drop=True)\n\n\n\ntrain_dataset = SETIDataset(image_paths=df_train['img_path'], targets=df_train['target'])    \ntrain_sampler =  torch.utils.data.WeightedRandomSampler(df_train['weight_sample'].values, len(train_dataset), replacement=True)\ntrain_loader  = DataLoader(train_dataset, batch_size=CFG.batch_size,sampler=train_sampler,num_workers = 0, pin_memory=True)\n\n\n\ntest_dataset = SETIDataset(image_paths=df_valid ['img_path'], targets=df_valid['target'])    \ntest_loader  = DataLoader(test_dataset, batch_size=CFG.batch_size,num_workers = CFG.num_workers, shuffle = False ,pin_memory=True)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef Plot_scheduler(Datalength = 100)  : \n    model = nn.Sequential(\n              nn.Linear(10,10)\n            )\n\n    optimizer           = torch.optim.Adam(model.parameters(), lr=0.00001)\n    scheduler           = LR_Scheduler(\n            optimizer,\n            CFG.warmup_epochs, \n            CFG.warmup_lr, \n            CFG.num_epochs, \n            CFG.base_lr, \n            CFG.final_lr, \n            Datalength\n        )\n\n    lrs = []\n    plt.figure(figsize=(8,5))\n    \n    for epoch in range(CFG.num_epochs):\n        for it in range(Datalength):\n            lr = scheduler.step()\n        lrs.append(lr)\n    plt.plot(lrs)\n    plt.title('Scheduler lr')\n    plt.xlabel('Epoch')\n    plt.show()\n    \nPlot_scheduler(Datalength = 100)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom matplotlib import pyplot as plt\n\nfor data in train_loader :\n    Batch_image = data['image']\n    Batch_label = data['label']\n    \n   \n    \n    for idx,(image, lable) in  enumerate(zip(Batch_image,Batch_label)) :\n        if idx >= 8 :\n            break\n        plt.figure(figsize=(16, 10))\n        for i in range(6):\n            plt.subplot(1, 6, i + 1)\n            plt.imshow(image[i])\n            if i==0 :\n              plt.title(f'lable = {lable}')\n            plt.axis('off')\n        plt.show() \n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"from collections import OrderedDict\n\n\nfrom torch.optim.optimizer import Optimizer \n    \nclass LARS_simclr(Optimizer):\n    def __init__(self, \n                 named_modules, \n                 lr,\n                 momentum=0.95, # beta? YES\n                 trust_coef=1e-3,\n                 weight_decay=1.5e-6,\n                exclude_bias_from_adaption=True):\n        '''byol: As in SimCLR and official implementation of LARS, we exclude bias # and batchnorm weight from the Lars adaptation and weightdecay'''\n        defaults = dict(momentum=momentum,\n                lr=lr,\n                weight_decay=weight_decay,\n                 trust_coef=trust_coef)\n        parameters = self.exclude_from_model(named_modules, exclude_bias_from_adaption)\n        super(LARS_simclr, self).__init__(parameters, defaults)\n\n    @torch.no_grad() \n    def step(self):\n        for group in self.param_groups: # only 1 group in most cases \n            weight_decay = group['weight_decay']\n            momentum = group['momentum']\n            lr = group['lr']\n\n            trust_coef = group['trust_coef']\n            # print(group['name'])\n            # eps = group['eps']\n            for p in group['params']:\n                # breakpoint()\n                if p.grad is None:\n                    continue\n                global_lr = lr\n                velocity = self.state[p].get('velocity', 0)  \n                # if name in self.exclude_from_layer_adaptation:\n                if self._use_weight_decay(group):\n                    p.grad.data += weight_decay * p.data \n\n                trust_ratio = 1.0 \n                if self._do_layer_adaptation(group):\n                    w_norm = torch.norm(p.data, p=2)\n                    g_norm = torch.norm(p.grad.data, p=2)\n                    trust_ratio = trust_coef * w_norm / g_norm if w_norm > 0 and g_norm > 0 else 1.0 \n                scaled_lr = global_lr * trust_ratio # trust_ratio is the local_lr \n                next_v = momentum * velocity + scaled_lr * p.grad.data \n                update = next_v\n                p.data = p.data - update \n\n\n    def _use_weight_decay(self, group):\n        return False if group['name'] == 'exclude' else True\n    def _do_layer_adaptation(self, group):\n        return False if group['name'] == 'exclude' else True\n\n    def exclude_from_model(self, named_modules, exclude_bias_from_adaption=True):\n        base = [] \n        exclude = []\n        for name, module in named_modules:\n            if type(module) in [nn.BatchNorm1d, nn.BatchNorm2d, nn.BatchNorm3d]:\n                # if isinstance(module, torch.nn.modules.batchnorm._BatchNorm)\n                for name2, param in module.named_parameters():\n                    exclude.append(param)\n            else:\n                for name2, param in module.named_parameters():\n                    if name2 == 'bias':\n                        exclude.append(param)\n                    elif name2 == 'weight':\n                        base.append(param)\n                    else:\n                        pass # non leaf modules \n        return [{\n            'name': 'base',\n            'params': base\n            },{\n            'name': 'exclude',\n            'params': exclude\n        }] if exclude_bias_from_adaption == True else [{\n            'name': 'base',\n            'params': base+exclude \n        }]\n    \n\n\n    \nclass Identity(nn.Module):\n    def __init__(self):\n        super(Identity, self).__init__()\n        \n    def forward(self, x):\n        return x    \n    \n  \n    \nclass Net(nn.Module):\n    def __init__(self, cfg, use_pretrain = False):\n        super(Net, self).__init__() \n        self.cfg = cfg\n\n        # defining our deep learning architecture\n        self.model = timm.create_model(self.cfg.model_name, pretrained=use_pretrain)\n        \n#         for param in self.model.parameters():\n#              param.requires_grad = False\n         \n        if self.cfg.model_name == 'nfnet_l0' :\n           in_feature         =   self.model.head.fc.in_features\n           self.model.head.fc =   Identity()\n        else :\n           in_feature    = self.model.fc.in_features\n           self.model.fc =   Identity()\n        \n        \n        self.head = nn.Sequential(OrderedDict([\n                    ('fc1', nn.Linear(2*in_feature , 2048)),\n                    ('bb1', nn.BatchNorm1d(2048)),\n                    ('added_relu1', nn.ReLU(inplace=True)),\n                     ('fc2', nn.Linear(2048, 1024)),\n                    ('bb2', nn.BatchNorm1d(1024)),\n                    ('added_relu2', nn.ReLU(inplace=True)),\n                    ('fc3', nn.Linear(1024, 512)),\n                    ('bb3', nn.BatchNorm1d(512)),\n                    ('added_relu3', nn.ReLU(inplace=True)),\n                    ('fc_final', nn.Linear(512, self.cfg.output_size )),\n                ]))\n\n       \n       \n        self.classify = nn.Sequential(OrderedDict([\n            ('bb1', nn.BatchNorm1d(self.cfg.output_size)),\n            ('fc1', nn.Linear(self.cfg.output_size , 1)),\n        ]))\n\n    def forward(self, x):\n        \n\n        X1,X2  = F.interpolate(x[:,0:3], (CFG.input_size, CFG.input_size)),F.interpolate(x[:,3:6], (CFG.input_size, CFG.input_size))\n        x1,x2    = self.model(X1), self.model(X2)\n        out      = torch.cat([x1,x2],-1)\n        out      = self.head(out)\n        out      = self.classify(out)\n        return out\n    \n    \n\n\n    \n# model = Net1(CFG, use_pretrain=True).to(CFG.device)\n# model.eval()\n# input  = torch.randn((5,6,CFG.input_size,CFG.input_size)).to(CFG.device)\n# output = model(input)\n# output.shape\n\n# model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef train(model ,fold = 0) :\n\n    df_train                  = df_train_fold[df_train_fold.kfold != fold].reset_index(drop=True)\n    Dict_Target_counts        = df_train['target'].value_counts().to_dict()\n    df_train['weight_sample'] = df_train['target'].apply(lambda x : 1/Dict_Target_counts[x] )\n\n\n    train_dataset = SETIDataset(image_paths=df_train['img_path'], targets=df_train['target'])    \n    train_sampler =  torch.utils.data.WeightedRandomSampler(df_train['weight_sample'].values, len(train_dataset), replacement=True)\n    train_loader  = DataLoader(train_dataset, batch_size=CFG.batch_size,sampler=train_sampler,num_workers = CFG.num_workers, pin_memory=True)\n\n    criterion = nn.BCEWithLogitsLoss()\n    model     = model.to(CFG.device)\n    model.train()\n    \n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n    #optimizer = LARS_simclr(model.named_modules(), weight_decay= 0, lr=1e-4)\n\n\n    lr_scheduler = LR_Scheduler(\n                optimizer,\n                CFG.warmup_epochs, \n                CFG.warmup_lr, \n                CFG.num_epochs, \n                CFG.base_lr, \n                CFG.final_lr, \n                len(train_loader),\n            )\n\n\n\n    local_progress = tqdm(train_loader, desc=f'Training Epoch = {epoch}/{ CFG.num_epochs }', disable= False)\n    data_dict      = {}\n    max_grad_norm  = 10\n\n    for sample_batched in local_progress:\n            Batch_image = sample_batched['image'].to(CFG.device, dtype=torch.float, non_blocking=True)\n            Batch_label = sample_batched['label'].to(CFG.device, dtype=torch.float, non_blocking=True).view(-1, 1)\n            optimizer.zero_grad()\n\n            y_preds     = model(Batch_image)\n            loss        = nn.BCEWithLogitsLoss()(y_preds, Batch_label)\n            loss.backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n            optimizer.step()\n            lr_scheduler.step()\n\n            \n            y_preds = torch.sigmoid(y_preds).round().detach().cpu().numpy().tolist()\n            targets  = Batch_label.detach().cpu().numpy().tolist() \n            \n            acc     = sklearn.metrics.accuracy_score(targets,y_preds)\n            roc_auc = sklearn.metrics.roc_auc_score(targets,y_preds)\n\n            data_dict.update({'train loss':loss.item(), 'acc': acc, 'roc_auc':roc_auc ,'lr':lr_scheduler.get_lr()  })\n            local_progress.set_postfix(data_dict)\n    return model            \n\n\n            \ndef eval(model,fold = 0) :\n     df_valid                  = df_train_fold[df_train_fold.kfold == fold].reset_index(drop=True)\n     test_dataset              = SETIDataset(image_paths=df_valid ['img_path'], targets=df_valid['target'])    \n     test_loader               = DataLoader(test_dataset, batch_size=CFG.batch_size,num_workers = CFG.num_workers, shuffle = False ,pin_memory=True)\n     model.eval()   \n\n     local_progress = tqdm(test_loader, desc=f'Val Epoch = {epoch}/{ CFG.num_epochs }', disable= False)\n     \n     data_dict      = {}\n     final_targets = []\n     final_outputs = []\n     final_losses  = []   \n\n     with torch.no_grad():\n        for sample_batched in local_progress:\n                Batch_image = sample_batched['image'].to(CFG.device, dtype=torch.float, non_blocking=True)\n                Batch_label = sample_batched['label'].to(CFG.device, dtype=torch.float, non_blocking=True).view(-1, 1)\n                y_preds     = model(Batch_image)\n                loss        = nn.BCEWithLogitsLoss()(y_preds, Batch_label)\n                \n                y_preds = torch.sigmoid(y_preds).round().detach().cpu().numpy().tolist()\n                targets  = Batch_label.detach().cpu().numpy().tolist() \n            \n                acc     = sklearn.metrics.accuracy_score(targets,y_preds)\n                \n                \n                final_targets.extend(targets)\n                final_outputs.extend(y_preds)\n                final_losses.append(loss.item())\n                data_dict.update({'val loss': loss.item(), 'acc':acc  })\n                local_progress.set_postfix(data_dict)\n                \n                \n     val_acc     = sklearn.metrics.accuracy_score(final_targets,final_outputs)\n     val_roc_auc = sklearn.metrics.roc_auc_score(final_targets,final_outputs)\n                \n     return val_acc, val_roc_auc\n            \n                \n\n\n\n\n        \n        \n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model     = Net(CFG, use_pretrain=True)\n# best_model_name = \"model.pth\"\n# model.load_state_dict(torch.load(best_model_name))\n\nglobal_progress = tqdm(range(0, CFG.stop_num_epochs), desc=f'Epoch')\n\nbest_roc = -np.inf\nbest_acc = -np.inf\nbest_epoch = -np.inf\nbest_model_name = None\n\nfor epoch in global_progress:\n    model= train(model,fold = 0)\n    val_acc, val_roc_auc = eval(model,fold = 0)\n    print(f\"Epoch = {epoch}  val_roc_auc = {val_roc_auc:.3f} val_acc = {val_acc:.3f}\")\n    if val_roc_auc > best_roc:\n        best_roc = val_roc_auc\n        best_acc = val_acc\n        best_epoch = epoch\n        best_model_name = \"model.pth\"\n        print(f\"Save_best_model : val_roc_auc = {val_roc_auc:.3f} val_acc = {val_acc:.3f}\")\n        torch.save(model.state_dict(),best_model_name)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'The best ROC: {best_roc} The best acc {best_acc} was achieved on epoch: {best_epoch}.')\nprint(f'The Best saved model is: {best_model_name}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del model\ngc.collect() \ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"model  = Net(CFG, use_pretrain=True)\nmodel.load_state_dict(torch.load(best_model_name))\nmodel     = model.to(CFG.device)\nmodel.eval()   \n''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_test             = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ndf_test['img_path'] = df_test['id'].apply(lambda x: f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')\n\n\ntest_dataset              = SETIDataset(image_paths=df_test['img_path'], targets=df_test['target'])    \ntest_loader               = DataLoader(test_dataset, batch_size=CFG.batch_size,num_workers = CFG.num_workers, shuffle = False ,pin_memory=True)\n   \n    \nlocal_progress = tqdm(test_loader, desc=f'Val Epoch = {epoch}/{ CFG.num_epochs }', disable= False)\n\ntemp_preds = None\npredicted_labels = None\n\nwith torch.no_grad():\n    for sample_batched in local_progress:\n            Batch_image = sample_batched['image'].to(CFG.device, dtype=torch.float, non_blocking=True)\n            Batch_label = sample_batched['label'].to(CFG.device, dtype=torch.float, non_blocking=True).view(-1, 1)\n            output      = model(Batch_image)\n            \n            predictions = torch.sigmoid(output).cpu().numpy()\n            \n            if temp_preds is None:\n                temp_preds = predictions\n            else:\n                temp_preds = np.vstack((temp_preds, predictions))\n\n    \nif predicted_labels is None:\n    predicted_labels = temp_preds\nelse:\n    predicted_labels += temp_preds\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.DataFrame()\nsub_df['id'] = df_test['id']\nsub_df['target'] = predicted_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}