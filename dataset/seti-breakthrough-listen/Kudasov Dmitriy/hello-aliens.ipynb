{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport os\n\nfrom tqdm import tqdm\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom matplotlib import colors, cm, pyplot as plt\n\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\n\nfrom sklearn.model_selection import train_test_split\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-13T10:02:42.869857Z","iopub.execute_input":"2021-07-13T10:02:42.870197Z","iopub.status.idle":"2021-07-13T10:02:42.876632Z","shell.execute_reply.started":"2021-07-13T10:02:42.870168Z","shell.execute_reply":"2021-07-13T10:02:42.875789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\nfile_path_train = []\nfile_path_test = []\nfor dirname, _, filenames in os.walk('/kaggle/input/seti-breakthrough-listen/test'):\n    for filename in filenames:\n        file_path_test.append(os.path.join(dirname, filename))\n        \nfor dirname, _, filenames in os.walk('/kaggle/input/seti-breakthrough-listen/train'):\n    for filename in filenames:\n        file_path_train.append(os.path.join(dirname, filename))  ","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:02:42.878221Z","iopub.execute_input":"2021-07-13T10:02:42.878774Z","iopub.status.idle":"2021-07-13T10:02:52.545345Z","shell.execute_reply.started":"2021-07-13T10:02:42.878736Z","shell.execute_reply":"2021-07-13T10:02:52.544482Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ndf['path'] = df['id'].apply(lambda x: \n                            str('../input/seti-breakthrough-listen' \n                                + '/train/' \n                                + str(x[0]) \n                                + '/' + str(x)) \n                            + '.npy')\n\ndf_test = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ndf_test['path'] = df_test['id'].apply(lambda x: \n                            str('../input/seti-breakthrough-listen' \n                                + '/test/' \n                                + str(x[0]) \n                                + '/' + str(x)) \n                            + '.npy')","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:02:52.548752Z","iopub.execute_input":"2021-07-13T10:02:52.54902Z","iopub.status.idle":"2021-07-13T10:02:52.678084Z","shell.execute_reply.started":"2021-07-13T10:02:52.548983Z","shell.execute_reply":"2021-07-13T10:02:52.677196Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sig = df[df.target == 1].sample(df[df.target == 1].shape[0] - 22)\nno_sig = df[df.target == 0].sample(df[df.target == 1].shape[0] - 22 + 64*4)\nnew_df = pd.concat([sig, no_sig], axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:02:52.679709Z","iopub.execute_input":"2021-07-13T10:02:52.680077Z","iopub.status.idle":"2021-07-13T10:02:52.700357Z","shell.execute_reply.started":"2021-07-13T10:02:52.680038Z","shell.execute_reply":"2021-07-13T10:02:52.69961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = np.load(df['path'][0])\nsmth = (data[3][:256] - data[3][:256].min()) / (data[3][:256].max() - data[3][:256].min())","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:02:52.701511Z","iopub.execute_input":"2021-07-13T10:02:52.702005Z","iopub.status.idle":"2021-07-13T10:02:52.714088Z","shell.execute_reply.started":"2021-07-13T10:02:52.701949Z","shell.execute_reply":"2021-07-13T10:02:52.713075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimg= (data[1][:256]) \nplt.imshow(img.astype(\"float\"), cmap=plt.cm.binary, vmin=-0.5, vmax=10)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:02:52.715392Z","iopub.execute_input":"2021-07-13T10:02:52.71587Z","iopub.status.idle":"2021-07-13T10:02:52.846762Z","shell.execute_reply.started":"2021-07-13T10:02:52.715833Z","shell.execute_reply":"2021-07-13T10:02:52.845847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomImageDataset(Dataset):\n    def __init__(self, annotations_file, img_path, transform=None, target_transform=None):\n        self.img_labels = annotations_file\n        self.img_path = img_path\n        self.transform = transform\n        self.target_transform = target_transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        image = np.load(self.img_path[idx])\n        label = self.img_labels[idx]\n        \n        if self.transform:\n            image = self.transform(image)\n        if self.target_transform:\n            label = self.target_transform(label)\n        \n        x1 = image[0][:256]\n        x2 = image[1][:256]\n        x3 = image[2][:256]\n        x4 = image[3][:256]\n        x5 = image[4][:256]\n        x6 = image[5][:256] \n        \n        image = [(x1-x1.min())/(x1.max()-x1.min()),\n                 (x2-x2.min())/(x2.max()-x2.min()),\n                 (x3-x3.min())/(x3.max()-x3.min()),\n                 (x4-x4.min())/(x4.max()-x4.min()),\n                 (x5-x5.min())/(x5.max()-x5.min()),\n                 (x6-x6.min())/(x6.max()-x6.min())]\n        image = torch.tensor(image)\n        label = torch.tensor(label)\n            \n        return image, label\n\n    \nbatch_size = 64    \n    \nfeatures_train, features_test, targets_train, targets_test = train_test_split(new_df['path'].values, \n                                                                              new_df['target'].values, \n                                                                              test_size=0.2)   \n    \ntrain_loader = CustomImageDataset(targets_train ,features_train)\ntest_loader = CustomImageDataset(targets_test, features_test)\n\ntrain_loader = DataLoader(train_loader, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_loader, batch_size=batch_size, shuffle=True)\n\nfor X, y in test_loader:\n    print(\"Shape of X [N, C, H, W]: \", X.shape)\n    print(\"Shape of y: \", y.shape, y.dtype)\n    break","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:02:52.84817Z","iopub.execute_input":"2021-07-13T10:02:52.848507Z","iopub.status.idle":"2021-07-13T10:03:01.56366Z","shell.execute_reply.started":"2021-07-13T10:02:52.848468Z","shell.execute_reply":"2021-07-13T10:03:01.562702Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# batch_size = 100    \n    \n# features_train, features_test, targets_train, targets_test = train_test_split(df.head(1000).path.values, \n#                                                                               df.head(1000).target.values, \n#                                                                               test_size=0.2)   \n    \n# train_loader = CustomImageDataset(targets_train ,features_train)\n# test_loader = CustomImageDataset(targets_test, features_test)\n\n# train_loader = DataLoader(train_loader, batch_size=batch_size, shuffle=True)\n# test_loader = DataLoader(test_loader, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.56738Z","iopub.execute_input":"2021-07-13T10:03:01.569285Z","iopub.status.idle":"2021-07-13T10:03:01.57446Z","shell.execute_reply.started":"2021-07-13T10:03:01.569241Z","shell.execute_reply":"2021-07-13T10:03:01.573361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for i in range(4, 7):\n#    x1, x2, x3, x4, x5, x6, label = CustomImageDataset.__getitem__(Dataset, i)\n#    print(x1, x2, x3, x4, x5, x6, label)\n#CustomImageDataset(df['target'].values, df['path'].values).__len__()\n#train_loader","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.580513Z","iopub.execute_input":"2021-07-13T10:03:01.582919Z","iopub.status.idle":"2021-07-13T10:03:01.588067Z","shell.execute_reply.started":"2021-07-13T10:03:01.582877Z","shell.execute_reply":"2021-07-13T10:03:01.587084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(\"Using {} device\".format(device))","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.592891Z","iopub.execute_input":"2021-07-13T10:03:01.593641Z","iopub.status.idle":"2021-07-13T10:03:01.603439Z","shell.execute_reply.started":"2021-07-13T10:03:01.593604Z","shell.execute_reply":"2021-07-13T10:03:01.602454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        \n        self.feature1 = nn.Sequential(\n            nn.Conv2d(in_channels=6, out_channels=48, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(4),\n            nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(4),\n            nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3, padding=1),\n            nn.ReLU(),\n            nn.MaxPool2d(4)\n        )\n        \n        self.feature2 = nn.Sequential(\n            nn.Linear(192 * 4 * 4, 3100),\n            nn.ReLU(),\n            nn.Linear(3100, 750),\n            nn.ReLU(),\n            nn.Linear(750, 200),\n            nn.ReLU(),\n            nn.Linear(200, 50),\n            nn.ReLU(),\n            nn.Linear(50, 1),\n            nn.Sigmoid()\n        )\n        \n\n        \n    def forward(self, image):\n        \n        x = self.feature1(image.float())\n        \n        x = self.feature2(x.view(-1, 192 * 4 * 4))\n        \n        \n        return x\n\nmodel = CNNModel()\nmodel.to(device)\nprint(model)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.607389Z","iopub.execute_input":"2021-07-13T10:03:01.60794Z","iopub.status.idle":"2021-07-13T10:03:01.802071Z","shell.execute_reply.started":"2021-07-13T10:03:01.607905Z","shell.execute_reply":"2021-07-13T10:03:01.801272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#for a,b in train_loader:\n#    print(a.shape)\n#    a.to(device)\n#    break\n#print(a[1,:,:,:].view(1,6,256,256).shape)\n#data_r = a[1,:,:,:].view(1,6,256,256)\n#data_r = data_r.to(device)\n#pred = model(data_r)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.805646Z","iopub.execute_input":"2021-07-13T10:03:01.807589Z","iopub.status.idle":"2021-07-13T10:03:01.812263Z","shell.execute_reply.started":"2021-07-13T10:03:01.807548Z","shell.execute_reply":"2021-07-13T10:03:01.811503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pred","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.816649Z","iopub.execute_input":"2021-07-13T10:03:01.817199Z","iopub.status.idle":"2021-07-13T10:03:01.824139Z","shell.execute_reply.started":"2021-07-13T10:03:01.817163Z","shell.execute_reply":"2021-07-13T10:03:01.823331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_fn = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.SGD(model.parameters(), lr=1e-3)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.825472Z","iopub.execute_input":"2021-07-13T10:03:01.826137Z","iopub.status.idle":"2021-07-13T10:03:01.831035Z","shell.execute_reply.started":"2021-07-13T10:03:01.826099Z","shell.execute_reply":"2021-07-13T10:03:01.830246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(dataloader, model, loss_fn, optimizer):\n    size = len(dataloader.dataset)\n    for batch, (X, y) in tqdm(enumerate(dataloader), position=0, leave=True, desc='Evaluating'):\n        X, y = X.to(device), y.to(device)\n\n        # Compute prediction error\n        pred = model(X.float())\n        loss = loss_fn(pred.view(batch_size), y.float())\n\n        # Backpropagation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        if batch % 100 == 0:\n            loss, current = loss.item(), batch * len(X)\n            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.832234Z","iopub.execute_input":"2021-07-13T10:03:01.832759Z","iopub.status.idle":"2021-07-13T10:03:01.847459Z","shell.execute_reply.started":"2021-07-13T10:03:01.832723Z","shell.execute_reply":"2021-07-13T10:03:01.846712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def test(dataloader, model):\n    size = len(dataloader.dataset)\n    model.eval()\n    test_loss, correct = 0, 0\n    with torch.no_grad():\n        for X, y in tqdm(dataloader, position=0, leave=True, desc='Evaluating'):\n            X, y = X.to(device), y.to(device)\n            pred = model(X.float())\n\n            test_loss += loss_fn(pred.view(batch_size), y.float()).item()\n            \n            correct += (pred.argmax(1) == y.float()).type(torch.float).sum().item()\n                      \n    test_loss /= size\n    correct /= size\n    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.850216Z","iopub.execute_input":"2021-07-13T10:03:01.851153Z","iopub.status.idle":"2021-07-13T10:03:01.862582Z","shell.execute_reply.started":"2021-07-13T10:03:01.851117Z","shell.execute_reply":"2021-07-13T10:03:01.861663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 10\nfor t in range(epochs):\n    #print(f\"Epoch {t+1}\\n-------------------------------\")\n    train(train_loader, model, loss_fn, optimizer)\n    test(test_loader, model)\nprint(\"Done!\")","metadata":{"execution":{"iopub.status.busy":"2021-07-13T10:03:01.866013Z","iopub.execute_input":"2021-07-13T10:03:01.868322Z","iopub.status.idle":"2021-07-13T13:25:21.414917Z","shell.execute_reply.started":"2021-07-13T10:03:01.868287Z","shell.execute_reply":"2021-07-13T13:25:21.412522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),f'my_model_{epochs}.pt')","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:25:21.416053Z","iopub.status.idle":"2021-07-13T13:25:21.416756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"batch_size = 64\ntest_load = CustomImageDataset(df_test['target'], df_test['path'])\ntest_load = DataLoader(test_load, batch_size=batch_size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:25:21.417828Z","iopub.status.idle":"2021-07-13T13:25:21.418549Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n    \nfinal_targets = []\nfinal_outputs = []\n    \nwith torch.no_grad():\n        \n    for data in tqdm(test_load, position=0, leave=True, desc='Evaluating'):\n        inputs = data[0]\n        targets = data[1]\n        inputs = inputs.to(device, dtype=torch.float)\n            \n        output = model(inputs)\n            \n        output = output.detach().cpu().numpy().tolist()\n            \n        final_outputs.extend(output)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:25:21.419695Z","iopub.status.idle":"2021-07-13T13:25:21.420303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame(final_outputs, columns = ['target'])\nsubmission = pd.concat([df_test['id'], submission], axis=1) ","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:25:21.421437Z","iopub.status.idle":"2021-07-13T13:25:21.422059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-07-13T13:25:21.423149Z","iopub.status.idle":"2021-07-13T13:25:21.42386Z"},"trusted":true},"execution_count":null,"outputs":[]}]}