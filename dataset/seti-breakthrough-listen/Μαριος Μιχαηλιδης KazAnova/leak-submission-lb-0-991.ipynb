{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-17T00:22:04.885897Z","iopub.execute_input":"2021-06-17T00:22:04.88634Z","iopub.status.idle":"2021-06-17T00:22:04.890535Z","shell.execute_reply.started":"2021-06-17T00:22:04.886312Z","shell.execute_reply":"2021-06-17T00:22:04.889973Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df=pd.read_csv(\"../input/seti-breakthrough-listen/train_labels.csv\")\nsubmission=pd.read_csv(\"../input/seti-breakthrough-listen/sample_submission.csv\")\nleak_train=pd.read_csv(\"../input/leak-seti/leak_train.csv\")\nleak_test=pd.read_csv(\"../input/leak-seti/leak_test.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:22:05.251092Z","iopub.execute_input":"2021-06-17T00:22:05.251484Z","iopub.status.idle":"2021-06-17T00:22:05.591674Z","shell.execute_reply.started":"2021-06-17T00:22:05.251455Z","shell.execute_reply":"2021-06-17T00:22:05.59118Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"leak_train","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:22:06.753212Z","iopub.execute_input":"2021-06-17T00:22:06.754662Z","iopub.status.idle":"2021-06-17T00:22:06.793479Z","shell.execute_reply.started":"2021-06-17T00:22:06.754637Z","shell.execute_reply":"2021-06-17T00:22:06.792982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"leak_test","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:22:08.989491Z","iopub.execute_input":"2021-06-17T00:22:08.989894Z","iopub.status.idle":"2021-06-17T00:22:09.0154Z","shell.execute_reply.started":"2021-06-17T00:22:08.98987Z","shell.execute_reply":"2021-06-17T00:22:09.014155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"leak_train.drop(\"id\",axis=1, inplace=True)\nleak_test.drop(\"id\",axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:23:22.793448Z","iopub.execute_input":"2021-06-17T00:23:22.79373Z","iopub.status.idle":"2021-06-17T00:23:22.802573Z","shell.execute_reply.started":"2021-06-17T00:23:22.793696Z","shell.execute_reply":"2021-06-17T00:23:22.802002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"####extract file created time for the numpy files stored in train/test\n#code to extract the leak - it ONLY WORKS IF YOU DOWNLOAD THE DATA LOCALLY - IT DOES NOT WORK INSIDE THE KERNEL\n# I have provided these files as leak_train.csv and leak_test.csv\n\"\"\"\nimport pathlib \n\n#create path column\ntrain_ids=train_df.id.values.tolist()\nnumerical_train=[]\nfor j in range(len(train_ids)):\n            this_id=str(train_ids[j])\n            paths=\"../input/seti-breakthrough-listen/train/\" +  this_id[0] +\"/\" + this_id + \".npy\"\n            fname = pathlib.Path(paths) # <------- extract file created date and other stats related with the file\n            stats=fname.stat()# <------- extract file created date and other stats related with the file\n            stats=[float(j) for j in stats]\n            numerical_train.append(stats)\n            #path_ids.append(paths)\n            \nX=np.array(numerical_train)    \n#train_df[\"path\"]=path_ids\n\n\ntest_ids=submission.id.values.tolist()\nnumerical_test=[]\nfor j in range(len(test_ids)):\n            this_id=str(test_ids[j])\n            paths=\"../input/seti-breakthrough-listen/test/\" +  this_id[0] +\"/\" + this_id + \".npy\"\n            fname = pathlib.Path(paths) # <------- extract file created date and other stats related with the file\n            stats=fname.stat() # <------- extract file created date and other stats related with the file\n            stats=[float(j) for j in stats]            \n            numerical_test.append(stats)\n            \nX_test=np.array(numerical_test) \n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2021-06-16T20:40:59.999358Z","iopub.execute_input":"2021-06-16T20:40:59.999773Z","iopub.status.idle":"2021-06-16T20:42:24.017674Z","shell.execute_reply.started":"2021-06-16T20:40:59.99974Z","shell.execute_reply":"2021-06-16T20:42:24.016409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y=train_df.target","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:23:32.71305Z","iopub.execute_input":"2021-06-17T00:23:32.713402Z","iopub.status.idle":"2021-06-17T00:23:32.717676Z","shell.execute_reply.started":"2021-06-17T00:23:32.713378Z","shell.execute_reply":"2021-06-17T00:23:32.716894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model\nfrom sklearn.ensemble import ExtraTreesClassifier\nmodel=ExtraTreesClassifier(n_estimators=500, criterion='entropy', max_depth=10,\n                                  n_jobs=-1, random_state=432)\nmodel.fit(leak_train.values,y)\ntest_preds=model.predict_proba(leak_test.values)[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:23:33.775484Z","iopub.execute_input":"2021-06-17T00:23:33.77593Z","iopub.status.idle":"2021-06-17T00:23:38.301183Z","shell.execute_reply.started":"2021-06-17T00:23:33.775898Z","shell.execute_reply":"2021-06-17T00:23:38.300002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission[\"target\"]=test_preds\nsubmission.to_csv(\"submission.csv\" , index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:23:38.302398Z","iopub.execute_input":"2021-06-17T00:23:38.302611Z","iopub.status.idle":"2021-06-17T00:23:38.390489Z","shell.execute_reply.started":"2021-06-17T00:23:38.302579Z","shell.execute_reply":"2021-06-17T00:23:38.389244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.status.busy":"2021-06-17T00:23:41.877747Z","iopub.execute_input":"2021-06-17T00:23:41.878107Z","iopub.status.idle":"2021-06-17T00:23:41.891196Z","shell.execute_reply.started":"2021-06-17T00:23:41.878076Z","shell.execute_reply":"2021-06-17T00:23:41.890145Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}