{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 🛸 外星信号搜索 👽 数据分析 & 基线模型 [布尔艺数 BoolArt]\n\n<div align=center>\n<img src=\"https://storage.googleapis.com/kaggle-media/competitions/SETI-Berkeley/DSC_4014-Edit_2.jpg\" width = \"600\" height = \"100\" alt=\"图片名称\">\n</div>\n   \n\n**“我们在宇宙中是孤独的吗?”**这是人类最深刻和永恒的问题之一。","metadata":{}},{"cell_type":"markdown","source":"<a id=\"top\"></a>\n\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h3 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" style='color:white; background:Blue; border:0' role=\"tab\" aria-controls=\"home\"><center>目录导航</center></h3>\n    \n# 目录\n\n* 赛题背景\n* 数据探索\n* 评价指标\n* 基线模型\n* 后续思路\n* 引用","metadata":{}},{"cell_type":"markdown","source":"## 赛题背景\n\n[比赛地址：SETI Breakthrough Listen - E.T. Signal Search](https://www.kaggle.com/c/seti-breakthrough-listen/) \n\n为了搜寻外星信号，我们将数字光谱仪Breakthrough Listen 安装在大型望远镜Green Bank Telescope (GBT)，它从望远镜接收原始数据（每天数百 TB）并执行傅立叶变换以生成光谱图。频谱的数据非常宽，通常会跨越几个 GHz 的无线电频谱，数据文件非常巨大，为了简化数据，比赛数据只抽取其中很小的频谱区域用于预测（被称作snippets，针）。\n\n为了防止来自于人类世界的无线电台，还有 wifi 路由器等无线电信号干扰，Breakthrough Listen 通过交替观测我们的主要目标星和附近三颗恒星来对抗这种干扰，具体方式为：在恒星“A”上观察 5 分钟，然后在恒星“B”上观察 5 分钟，然后回到恒星“A”上 5 分钟，然后是“C” ”，然后回到“A”，然后在“D”星上用 5 分钟结束。一组六个观察值 (ABACAD) 被称为cadence（“节奏”）。由于我们只是为每个节奏提供小范围的频率，因此我们将您将要分析的数据集称为cadence snippets（“节奏片段”）。\n\n<div align=center>\n    <img src=\"https://storage.googleapis.com/kaggle-media/competitions/SETI-Berkeley/Screen%20Shot%202021-05-03%20at%2011.39.42.png\" width = \"500\", height = \"600\">\n</div>\n\n\n上图是距离地球 200 亿公里的航海者一号飞船的cadence snippets。第一个、第三个和第五个面板是“A”目标（航海者一号飞船）。黄色对角线是来自航海者号的无线电信号。当我们指向航天器时它会被检测到，当我们指向远处时它就会消失。这是图中的一条对角线，因为地球和航天器的相对运动会产生多普勒漂移，导致频率随时间变化。而其他地球的人工信号更倾向于保持在固定频率，因此我们可以通过观测是否发生多普勒漂移现象来进行信号甄别。虽然完全根据已经发射的飞船的观测来训练我们的算法会很好，但它们的例子并不多，而且我们还希望能够找到更广泛的信号类型。所以我们进行了数据模拟，在拍摄了数以万计的节奏片段上添加一些类似于航海者一号飞船的信号，这构成了我们的训练数据。","metadata":{}},{"cell_type":"markdown","source":"## 数据探索","metadata":{}},{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:46:18.415048Z","iopub.execute_input":"2021-06-06T02:46:18.415348Z","iopub.status.idle":"2021-06-06T02:46:27.421648Z","shell.execute_reply.started":"2021-06-06T02:46:18.415277Z","shell.execute_reply":"2021-06-06T02:46:27.420706Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os\n# Libraries\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nimport sys\nimport glob\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport cv2\nfrom tqdm import tqdm\nfrom colorama import Fore, Back, Style\nr_ = Fore.WHITE\nfrom plotly.offline import iplot\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nfrom skimage.io import imshow, imread, imsave\nfrom skimage.transform import rotate, AffineTransform, warp,rescale, resize, downscale_local_mean\nfrom skimage import color,data\nfrom skimage.exposure import adjust_gamma\nfrom skimage.util import random_noise\n\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom sklearn.model_selection import StratifiedKFold","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:46:27.425174Z","iopub.execute_input":"2021-06-06T02:46:27.425429Z","iopub.status.idle":"2021-06-06T02:46:32.987174Z","shell.execute_reply.started":"2021-06-06T02:46:27.425402Z","shell.execute_reply":"2021-06-06T02:46:32.986068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(os.listdir(\"../input/seti-breakthrough-listen/\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:46:32.989192Z","iopub.execute_input":"2021-06-06T02:46:32.989549Z","iopub.status.idle":"2021-06-06T02:46:32.996059Z","shell.execute_reply.started":"2021-06-06T02:46:32.989509Z","shell.execute_reply":"2021-06-06T02:46:32.995105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 数据文件\n\n**train/** - 训练集，由numpy float16格式存储的（6,273,256）维度的数组，第1个维度表示6个节奏，第2和3个维度表示频谱信号，每个文件对应的标签可以在train_labels.csv中找到。  \n**test/** - 测试集，数据结构与训练集一致。  \n**sample_submission.csv/** - 提交格式范例。  \n**train_labels/** - 训练集数据标签。","metadata":{}},{"cell_type":"code","source":"def get_train_filename_by_id(_id: str) -> str:\n    return f\"../input/seti-breakthrough-listen/train/{_id[0]}/{_id}.npy\"\n\n\ndef show_cadence(filename: str, label: int) -> None:\n    plt.figure(figsize=(8, 8))\n    arr = np.load(filename)\n    for i in range(6):\n        plt.subplot(6, 1, i + 1)\n        if i == 0:\n            plt.title(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n        plt.imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        plt.text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        plt.xticks([])\n    plt.show()\n    \n    \ndef show_channels(filename: str, label: int) -> None:\n    plt.figure(figsize=(10, 8))\n    plt.suptitle(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n    arr = np.load(filename)\n    for i in range(6):\n        plt.subplot(2, 3, i + 1)\n        plt.imshow(arr[i].astype(float))\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:46:32.99837Z","iopub.execute_input":"2021-06-06T02:46:32.99887Z","iopub.status.idle":"2021-06-06T02:46:33.01057Z","shell.execute_reply.started":"2021-06-06T02:46:32.998829Z","shell.execute_reply":"2021-06-06T02:46:33.009771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 预测标签\n\n共计50165个样本，二分类问题，样本比列约为 10:1","metadata":{}},{"cell_type":"code","source":"train_labels = pd.read_csv(\"../input/seti-breakthrough-listen/train_labels.csv\")\nprint(train_labels.head())\nprint(\"-\" * 20)\nprint(train_labels.shape)\nprint(\"-\" * 20)\nprint(train_labels.target.value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:46:33.011981Z","iopub.execute_input":"2021-06-06T02:46:33.01246Z","iopub.status.idle":"2021-06-06T02:46:33.07797Z","shell.execute_reply.started":"2021-06-06T02:46:33.012425Z","shell.execute_reply":"2021-06-06T02:46:33.076952Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### 可视化","metadata":{}},{"cell_type":"code","source":"# 包含信号的样本\ndf_tmp = train_labels[train_labels[\"target\"] == 1].sample(3)\nfor ind, row in df_tmp.iterrows():\n    show_cadence(get_train_filename_by_id(row[\"id\"]), row[\"target\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:46:33.079514Z","iopub.execute_input":"2021-06-06T02:46:33.079878Z","iopub.status.idle":"2021-06-06T02:46:34.559429Z","shell.execute_reply.started":"2021-06-06T02:46:33.07984Z","shell.execute_reply":"2021-06-06T02:46:34.558566Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 不包含信号的样本\ndf_tmp = train_labels[train_labels[\"target\"] == 0].sample(3)\nfor ind, row in df_tmp.iterrows():\n    show_cadence(get_train_filename_by_id(row[\"id\"]), row[\"target\"])","metadata":{"execution":{"iopub.status.busy":"2021-06-06T02:46:34.56074Z","iopub.execute_input":"2021-06-06T02:46:34.561307Z","iopub.status.idle":"2021-06-06T02:46:35.985526Z","shell.execute_reply.started":"2021-06-06T02:46:34.561255Z","shell.execute_reply":"2021-06-06T02:46:35.984672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### 很容易发现的信号\n\n<div align=center>\n    <img src=\"https://i.imgur.com/5ohQpvE.png\" width = \"500\", height = \"600\">\n</div>\n\n#### 中等难度信号\n\n<div align=center>\n    <img src=\"https://i.imgur.com/Pz6YdoV.png\" width = \"500\", height = \"600\">\n</div>\n\n<div align=center>\n    <img src=\"https://i.imgur.com/81jL2N7.png\" width = \"500\", height = \"600\">\n</div>\n\n\n#### 高难度信号\n\n<div align=center>\n    <img src=\"https://i.imgur.com/Sgu0k7n.png\" width = \"500\", height = \"600\">\n</div>","metadata":{}},{"cell_type":"markdown","source":"## 评价指标\n\n这是一个二分类问题，且存在样本不均衡情况，因此主办方采用了AUC（Area Under the ROC Curve，ROC曲线下面积）作为评价指标。下面简单介绍下AUC的计算与特性。\n\n对于一个二分类问题，我们可以得到如下图所示的的混淆矩阵（confusion matrix）\n\n<div align=center>\n    <img src=\"https://i.loli.net/2021/06/06/82nuZpo1fQxHjNK.png\" width = \"500\", height = \"600\">\n</div>\n\n\n\n- TP(true positive)：真实类别为positive，模型预测的类别也为positive\n- FP(false positive): 预测为positive，但真实类别为negative，真实类别和预测类别不一致\n- FN(false negative): 预测为negative，但真实类别为positive，真实类别和预测类别不一致\n- TN(true negtive): 真实类别为negative，模型预测的类别也为negative\n\n### ROC curve\n\nROC曲线的纵坐标True Positive Rate（TPR）在数值上就等于positive类别的召回率，横坐标False Positive Rate（FPR）在数值上等于(1 - negative class的recall)。曲线通过对分类阈值θ（默认0.5）从大到小或者从小到大依次取值，我们可以得到很多组TPR和FPR的值，将其在图像中依次画出就可以得到一条ROC曲线，阈值θ取值范围为[0,1]。ROC曲线在图像上越接近左上角(0,1)模型越好，即ROC曲线下面与横轴和直线FPR = 1围成的面积（AUC值）越大越好。直观上理解，纵坐标TPR就是recallpositive值，横坐标FPR就是(1 - recallnegative)，前者越大越好，后者整体越小越好，在图像上表示就是曲线越接近左上角(0,1)坐标越好。\n\n要知道哪个模型更好，则需要计算每条曲线的AUC值，一般认为AUC值越大越好。AUC值由定义通过计算ROC曲线、横轴和直线FPR = 1三者围成的面积即可得到，通常取值在0.5-1.0间，越大越好。\n\n<div align=center>\n    <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/3/36/Roc-draft-xkcd-style.svg/1920px-Roc-draft-xkcd-style.svg.png\" width = \"500\", height = \"600\">\n</div>\n\n\n### AUC\nAUC能有效处理不均衡样本，下面模拟几组数据。\n\n- 第1，第2组数据为均衡样本；\n- 第3，第4组数据为不均衡样本；\n\n可以发现，第三组样本哪怕全部预测为正样本，AUC依然只有0.5。","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score, roc_curve, auc\nimport numpy as np\n\nlist_y_true = [\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n    [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n    [1., 0., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\nlist_y_pred = [\n    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], \n    [0.9, 0.9, 0.9, 0.9, 0.1, 0.9, 0.9, 0.1, 0.9, 0.1, 0.1, 0.5],\n    [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],#  IMBALANCE\n    [1., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 0.], #  IMBALANCE\n]\n\nfor y_true, y_pred in zip(list_y_true, list_y_pred):\n    fpr, tpr, _ = roc_curve(y_true, y_pred)\n    roc_auc = auc(fpr, tpr)\n\n    plt.figure(figsize=(5, 5))\n    plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n    plt.xlim([-0.01, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve example')\n    plt.legend(loc=\"lower right\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:32:20.1267Z","iopub.execute_input":"2021-06-05T08:32:20.127043Z","iopub.status.idle":"2021-06-05T08:32:20.869514Z","shell.execute_reply.started":"2021-06-05T08:32:20.127008Z","shell.execute_reply":"2021-06-05T08:32:20.86856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 基线模型\n\n频谱数据可以看成6通道图像，因此我们的基线模型采用计算机视觉的迁移学习网络：EfficientNet-B1，由于模型原本是基于普通3通道图像设计的，因此我们在EfficientNet前添加1x1卷积层，使得通道数量 6 -> 3，修改最后一层全连接网络，输出维度调整为1。","metadata":{}},{"cell_type":"code","source":"# 将输入信号视为二维图像，采用视觉模型EfficientNet做迁移训练；\n\nclass enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(6, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 配置\n\ndef set_seed(seed = 0):\n    '''设置随机数种子，保证模型可复现性'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nrandom_state = set_seed(76)\n\n\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:32:34.729614Z","iopub.execute_input":"2021-06-05T08:32:34.729959Z","iopub.status.idle":"2021-06-05T08:32:34.792075Z","shell.execute_reply.started":"2021-06-05T08:32:34.72992Z","shell.execute_reply":"2021-06-05T08:32:34.791263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ET-search分类数据集\n\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets): \n        self.image_paths = image_paths\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }\n    \ndf_train=pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ndf_train['img_path']=df_train['id'].apply(lambda x:f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:32:34.793476Z","iopub.execute_input":"2021-06-05T08:32:34.793863Z","iopub.status.idle":"2021-06-05T08:32:34.853135Z","shell.execute_reply.started":"2021-06-05T08:32:34.793825Z","shell.execute_reply":"2021-06-05T08:32:34.852295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_name = 'efficientnet-b1'\npretrained_model = {\n    baseline_name: '../input/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth'\n}\n\nmodel = enetv2(baseline_name, out_dim=1)","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:32:52.477153Z","iopub.execute_input":"2021-06-05T08:32:52.477487Z","iopub.status.idle":"2021-06-05T08:32:53.5159Z","shell.execute_reply.started":"2021-06-05T08:32:52.477454Z","shell.execute_reply":"2021-06-05T08:32:53.514982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 训练辅助函数\n\ndef train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n\n\ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:05:23.73942Z","iopub.execute_input":"2021-06-04T08:05:23.739775Z","iopub.status.idle":"2021-06-04T08:05:23.752568Z","shell.execute_reply.started":"2021-06-04T08:05:23.739742Z","shell.execute_reply":"2021-06-04T08:05:23.751292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_name = 'efficientnet-b1'\npretrained_model = {\n    baseline_name: '../input/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth'\n}\nmodels = []\ndevice = \"cuda\"\nepochs = 3\nBatch_Size = 32\nX = df_train.img_path.values\nY = df_train.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\n\nfor train_index, test_index in skf.split(X, Y):\n    \n    model = enetv2(baseline_name, out_dim=1)\n    model.to(device)\n\n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n\n    train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets)\n    valid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\n    for epoch in range(epochs):\n        train(train_loader, model, optimizer, device=device)\n        predictions, valid_targets = evaluate(valid_loader, model, device=device)\n        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        \n    torch.save(model.state_dict(),baseline_name + '-' + str(fold) + '.pt')\n    models.append(model)\n    fold += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-04T08:05:53.828237Z","iopub.execute_input":"2021-06-04T08:05:53.828628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission=pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nsubmission['img_path']=submission['id'].apply(lambda x:f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')\ntest_dataset=ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader=torch.utils.data.DataLoader(test_dataset, batch_size=16,shuffle=False,num_workers=4)\n\nsig=torch.nn.Sigmoid()\nouts=[]\nfor model in models:\n    predictions,valid_targets=evaluate(test_loader, model, device=device)\n    predictions=np.array(predictions)[:,0]\n    out=sig(torch.from_numpy(predictions))\n    out=out.detach().numpy()\n    outs.append(out)\n    \npred=np.mean(np.array(outs),axis=0)\nsubmission.target=pred\nsubmission.drop(['img_path'],axis=1,inplace=True)\nsubmission.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 改进方向\n\n- 尝试多种预训练模型：ResNext, SENet，Vit等；\n- 尝试只使用6个节奏中的，1,3,5节奏；\n- 尝试双塔架构，A模型使用1,3,5节奏，B模型使用2,4,6节奏，并在不同尺寸特征图进行融合，进行预测；\n- 抵抗样本不均衡的策略（损失函数、样本抽样等）；\n- 过拟合；\n- 模型融合；\n- 时间序列模型；\n\n\n**欢迎Follow，后续会持续更新这个比赛的开源内容**","metadata":{}},{"cell_type":"markdown","source":"## Refs\n\n- https://www.kaggle.com/ihelon/signal-search-exploratory-data-analysis\n- https://www.kaggle.com/c/seti-breakthrough-listen/overview/data-information\n- https://www.kaggle.com/c/seti-breakthrough-listen/discussion/238298\n- https://www.cnblogs.com/wuliytTaotao/p/9285227.html\n- https://www.kaggle.com/robert76/efficientnet-pretrained/data","metadata":{}}]}