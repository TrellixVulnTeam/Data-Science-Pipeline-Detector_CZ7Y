{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [SETI Breakthrough Listen - E.T. Signal Search](https://www.kaggle.com/c/seti-breakthrough-listen)\n>Find extraterrestrial signals in data from deep space \n","metadata":{}},{"cell_type":"markdown","source":"# Reference\nThis book was copied from awsaf49's notebook: https://www.kaggle.com/awsaf49/seti-bl-256x256-tfrec-data\n\nCheck this amazing notebook, [How To Create TFRecords](https://www.kaggle.com/cdeotte/how-to-create-tfrecords) by [Chris Deotte](https://www.kaggle.com/cdeotte)","metadata":{}},{"cell_type":"markdown","source":"# Notes\n\nI noticed that this notebook seems to use float32 instead of float16.\nThis notebook outputs size 256, 256, but there should be 273 (?) time values.\nThe original notebook saves snippets 0, 2, and 4 as 3 different \n\n\nIn this notebook the signal is processed using channel-wise representation of size (256, 256, 3).\nAlternately, we could convert channel-wise representation to spatial representations of (3*256, 256, 1).\n\nIt appears that version 2 of this notebook had a bug that reshaped the outputs to size (273, 273, 3).  This version was also saved as a dataset that could be used.\n\nVersion 3 seems to resolve this issue.\n\nVersion 4 included all the snippets and outputs the data in format (546 x 256 x 3) where subsequent ON/OFF snips are concatenated together.","metadata":{}},{"cell_type":"markdown","source":"# How to Create TFRecord","metadata":{}},{"cell_type":"code","source":"SEED  = 42\nFOLDS = 20\n# DIM   = 273 # original notebook resized to 256 time values\n# IMAGE_SIZE = [273,256];\nSNIPS = [0,1,2,3,4,5] # original notebook only used snips [0,2,4]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-13T18:54:44.605216Z","iopub.execute_input":"2021-06-13T18:54:44.605589Z","iopub.status.idle":"2021-06-13T18:54:44.609785Z","shell.execute_reply.started":"2021-06-13T18:54:44.60554Z","shell.execute_reply":"2021-06-13T18:54:44.608784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, shutil\nfrom glob import glob\nfrom sklearn.cluster import KMeans\nfrom tqdm.notebook import tqdm # a progress bar\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:44.642995Z","iopub.execute_input":"2021-06-13T18:54:44.643294Z","iopub.status.idle":"2021-06-13T18:54:44.647731Z","shell.execute_reply.started":"2021-06-13T18:54:44.643269Z","shell.execute_reply":"2021-06-13T18:54:44.646831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntest_label_df  = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:44.655109Z","iopub.execute_input":"2021-06-13T18:54:44.655504Z","iopub.status.idle":"2021-06-13T18:54:44.713665Z","shell.execute_reply.started":"2021-06-13T18:54:44.655379Z","shell.execute_reply":"2021-06-13T18:54:44.712821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths = glob('../input/seti-breakthrough-listen/train/**/*.npy')\ntest_paths = glob('../input/seti-breakthrough-listen/test/**/*.npy')\nlen(train_paths), len(test_paths)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:44.714959Z","iopub.execute_input":"2021-06-13T18:54:44.715212Z","iopub.status.idle":"2021-06-13T18:54:45.074655Z","shell.execute_reply.started":"2021-06-13T18:54:44.715187Z","shell.execute_reply":"2021-06-13T18:54:45.073524Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame({'filepath':train_paths})\ntrain_df['id'] = train_df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\ntrain_df['group'] = train_df.filepath.map(lambda x: x.split('/')[-2])\ntrain_df = pd.merge(train_df, train_label_df, on='id', how='left')\ntrain_df['group_target'] = train_df.group+train_df.target.astype(str)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:45.076462Z","iopub.execute_input":"2021-06-13T18:54:45.076979Z","iopub.status.idle":"2021-06-13T18:54:45.276136Z","shell.execute_reply.started":"2021-06-13T18:54:45.076939Z","shell.execute_reply":"2021-06-13T18:54:45.275316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame({'filepath':test_paths})\ntest_df['id'] = test_df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\ntest_df['group'] = test_df.filepath.map(lambda x: x.split('/')[-2])\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:45.27765Z","iopub.execute_input":"2021-06-13T18:54:45.278224Z","iopub.status.idle":"2021-06-13T18:54:45.338947Z","shell.execute_reply.started":"2021-06-13T18:54:45.278183Z","shell.execute_reply":"2021-06-13T18:54:45.338035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check The Data","metadata":{}},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:45.340152Z","iopub.execute_input":"2021-06-13T18:54:45.340654Z","iopub.status.idle":"2021-06-13T18:54:45.348004Z","shell.execute_reply.started":"2021-06-13T18:54:45.340616Z","shell.execute_reply":"2021-06-13T18:54:45.34714Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.group.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:45.349389Z","iopub.execute_input":"2021-06-13T18:54:45.349769Z","iopub.status.idle":"2021-06-13T18:54:45.367136Z","shell.execute_reply.started":"2021-06-13T18:54:45.349733Z","shell.execute_reply":"2021-06-13T18:54:45.366215Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.groupby(['group','target'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:45.368561Z","iopub.execute_input":"2021-06-13T18:54:45.368961Z","iopub.status.idle":"2021-06-13T18:54:45.391767Z","shell.execute_reply.started":"2021-06-13T18:54:45.36891Z","shell.execute_reply":"2021-06-13T18:54:45.390914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stratified KFold by Groups\n\nKFolds provides train/test indices to split data in train/test sets. It splits dataset into k consecutive folds (without shuffling by default).\nEach fold is then used once as a validation while the k - 1 remaining folds form the training set.\n\nStratified K-Folds provides train/test indices to split data in train/test sets.\nThis cross-validation object is a variation of KFold that returns stratified folds. The folds are made by preserving the percentage of samples for each class.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n    train_df.loc[val_idx,'fold'] = fold\n# train_df.groupby(['fold', 'target'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:45.394405Z","iopub.execute_input":"2021-06-13T18:54:45.394777Z","iopub.status.idle":"2021-06-13T18:54:45.424652Z","shell.execute_reply.started":"2021-06-13T18:54:45.394749Z","shell.execute_reply":"2021-06-13T18:54:45.423827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the signals\nFrom the [dataset information](https://www.kaggle.com/c/seti-breakthrough-listen/overview/data-information),\n>>\nNot all of the “needle” signals look like diagonal lines, and they may not be present for the entirety of all three “A” observations, but what they do have in common is that they are only present in some or all of the “A” observations (panels **1**, **3**, and **5** in the cadence snippets).\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt, cv2\n\ndef load_signal(filepath, snips, dim=None):\n    sgnl = np.load(filepath)\n    sgnl = sgnl[snips,] # only keep certain snips (on/off/all)\n    img  = np.moveaxis(sgnl, 0, -1)\n    img  = img.astype(np.float32) # float16 seems to break imencode below\n    if dim is not None:\n        img = cv2.resize(img, dsize=(dim, dim), interpolation=cv2.INTER_NEAREST)\n    return img\n\ndef combine_signals(sgnl):\n    '''Takes sgnl of type np.array and size (A,B,C) and concatenates snips 0&1, 2&3, and 4&5'''\n    '''Returns: np.array of size (2*A,B,C/2)'''\n    shape = sgnl.shape\n    assert len(shape) == 3\n    assert shape[2] % 2 == 0\n    return sgnl.reshape(shape[0]*2,shape[1],-1)\n\ndef visualize(sgnl):\n    sgnl = sgnl.astype(float)\n    plt.figure(figsize=(20, 10))\n    for idx in range(sgnl.shape[2]):\n        plt.subplot(2, 6, idx+1)\n        plt.imshow(sgnl[...,idx])\n        plt.axis('OFF')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:09:14.105185Z","iopub.execute_input":"2021-06-13T19:09:14.105504Z","iopub.status.idle":"2021-06-13T19:09:14.114828Z","shell.execute_reply.started":"2021-06-13T19:09:14.105478Z","shell.execute_reply":"2021-06-13T19:09:14.113847Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Channels","metadata":{}},{"cell_type":"markdown","source":"## No Resize","metadata":{}},{"cell_type":"code","source":"sgnl = load_signal(train_df[train_df.target==1].filepath.iloc[3], SNIPS, dim=None)\nvisualize(sgnl)\nsgnl.shape, sgnl.dtype","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:45.435967Z","iopub.execute_input":"2021-06-13T18:54:45.436335Z","iopub.status.idle":"2021-06-13T18:54:46.004415Z","shell.execute_reply.started":"2021-06-13T18:54:45.436297Z","shell.execute_reply":"2021-06-13T18:54:46.003361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TFRecord Data","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:46.005763Z","iopub.execute_input":"2021-06-13T18:54:46.006117Z","iopub.status.idle":"2021-06-13T18:54:46.012833Z","shell.execute_reply.started":"2021-06-13T18:54:46.006081Z","shell.execute_reply":"2021-06-13T18:54:46.011871Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writing TFRecord (Train)","metadata":{}},{"cell_type":"code","source":"def train_serialize_example(feature0, feature1, feature2, feature3):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n      'group'         : _bytes_feature(feature2),    \n      'target'        : _int64_feature(feature3),\n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:46.014199Z","iopub.execute_input":"2021-06-13T18:54:46.01457Z","iopub.status.idle":"2021-06-13T18:54:46.023107Z","shell.execute_reply.started":"2021-06-13T18:54:46.014533Z","shell.execute_reply":"2021-06-13T18:54:46.022352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.info()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T18:54:46.024425Z","iopub.execute_input":"2021-06-13T18:54:46.024787Z","iopub.status.idle":"2021-06-13T18:54:46.056664Z","shell.execute_reply.started":"2021-06-13T18:54:46.024751Z","shell.execute_reply":"2021-06-13T18:54:46.055808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show = True\nfolds = train_df.fold.unique().tolist()\nfor fold in tqdm(folds): # create tfrecord for each fold; # tqdm is a progress bar\n    fold_df = train_df[train_df.fold == fold]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n#         samples = 200\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it: # images in fold\n            row = fold_df.iloc[k,:]\n            image      = load_signal(row['filepath'], SNIPS, dim=None)\n            if len(SNIPS) == 6:\n                image      = combine_signals(image)  # combine 6 snips into 3 'supersnips'\n            image      = image[...,::-1] # rgb -> bgr, we'll get the rgb form after decoding the tfrec\n            image_id   = row['id']\n            group      = row['group']\n            target     = np.array(row['target'], dtype = np.uint8)\n            example  = train_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id),\n                str.encode(group),\n                target,\n                )\n            writer.write(example)\n        if show:\n            filepath = 'train%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('/')[-1]\n            filesize = os.path.getsize(filepath)/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:09:17.851881Z","iopub.execute_input":"2021-06-13T19:09:17.852231Z","iopub.status.idle":"2021-06-13T19:26:44.699759Z","shell.execute_reply.started":"2021-06-13T19:09:17.852204Z","shell.execute_reply":"2021-06-13T19:26:44.694309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writing TFRecord (Test)","metadata":{}},{"cell_type":"code","source":"def test_serialize_example(feature0, feature1, feature2):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n      'group'         : _bytes_feature(feature2),    \n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:27:32.341783Z","iopub.execute_input":"2021-06-13T19:27:32.342196Z","iopub.status.idle":"2021-06-13T19:27:32.355856Z","shell.execute_reply.started":"2021-06-13T19:27:32.342151Z","shell.execute_reply":"2021-06-13T19:27:32.354732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show  = True\nfolds = 10\nl     = int(np.ceil(test_df.shape[0]/folds))\nfor fold in tqdm(range(folds)): # create tfrecord for each fold\n    fold_df = test_df.iloc[l*fold:l*(fold+1)]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('test%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it: # images in fold\n            row = fold_df.iloc[k,:]\n            image      = load_signal(row['filepath'], SNIPS, dim=None)\n            if len(SNIPS) == 6:\n                image      = combine_signals(image)  # combine 6 snips into 3 'supersnips'\n            image      = image[...,::-1] # rgb -> bgr, we'll get the rgb form after decoding the tfrec\n            image_id   = row['id']\n            group      = row['group']\n            example  = test_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id),\n                str.encode(group),\n                )\n            writer.write(example)\n        if show:\n            filepath = 'test%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('/')[-1]\n            filesize = os.path.getsize(filepath)/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:28:21.11898Z","iopub.execute_input":"2021-06-13T19:28:21.119351Z","iopub.status.idle":"2021-06-13T19:28:25.255666Z","shell.execute_reply.started":"2021-06-13T19:28:21.119315Z","shell.execute_reply":"2021-06-13T19:28:25.254223Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading TFRecord","metadata":{}},{"cell_type":"code","source":"import re, math\ndef decode_image(image_data):\n    image = tf.image.decode_png(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range # could try float16 instead???\n    # image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\n\ndef prepare_target(target):    \n    target = tf.cast(target, tf.float32)            \n    target = tf.reshape(target, [1])         \n    return target\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    # image  = tf.reshape(image, [DIM, DIM, 3])\n    target = prepare_target(example['target'])\n    return image, target # returns a dataset of (image, label) pairs\n\ndef load_dataset(fileids, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(fileids, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef get_training_dataset(filenames):\n    dataset = load_dataset(filenames, labeled=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(20, seed=SEED)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef count_data_items(fileids):\n    # the number of data items is written in the id of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1)) for fileid in fileids]\n    return np.sum(n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-06-13T19:28:28.950532Z","iopub.execute_input":"2021-06-13T19:28:28.950858Z","iopub.status.idle":"2021-06-13T19:28:28.963461Z","shell.execute_reply.started":"2021-06-13T19:28:28.95083Z","shell.execute_reply":"2021-06-13T19:28:28.962404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual","metadata":{}},{"cell_type":"code","source":"def display_batch(batch, size=2):\n    imgs, tars = batch\n    for img_idx in range(size):\n        plt.figure(figsize=(4*2, 12*2))\n        for idx in range(3):\n            plt.subplot(size, 3, idx+1)\n            plt.title(f'Target:{tars[img_idx].numpy()[0]}')\n            plt.imshow(imgs[img_idx,:, :, idx])\n            plt.text(5, 10, str(idx), bbox={'facecolor': 'white'})\n            plt.xticks([])\n            plt.yticks([])\n        plt.tight_layout()\n        plt.show() ","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:28:39.844091Z","iopub.execute_input":"2021-06-13T19:28:39.844511Z","iopub.status.idle":"2021-06-13T19:28:39.853759Z","shell.execute_reply.started":"2021-06-13T19:28:39.844477Z","shell.execute_reply":"2021-06-13T19:28:39.85276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Total Images","metadata":{}},{"cell_type":"code","source":"# INITIALIZE VARIABLES\nBATCH_SIZE = 32\nAUTO = tf.data.experimental.AUTOTUNE\nTRAINING_FILENAMES = tf.io.gfile.glob('train*.tfrec') # edited to only fetch \"ON\" files, but should work either way\nTEST_FILENAMES     = tf.io.gfile.glob('test*.tfrec')\nprint('There are %i train & %i test images'%(count_data_items(TRAINING_FILENAMES), count_data_items(TEST_FILENAMES)))","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:28:46.240073Z","iopub.execute_input":"2021-06-13T19:28:46.240413Z","iopub.status.idle":"2021-06-13T19:28:46.283886Z","shell.execute_reply.started":"2021-06-13T19:28:46.240386Z","shell.execute_reply":"2021-06-13T19:28:46.28281Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Once Batch Image","metadata":{}},{"cell_type":"code","source":"# DISPLAY TRAIN IMAGES\ntraining_dataset = get_training_dataset(TRAINING_FILENAMES)\ntraining_dataset = training_dataset.unbatch().batch(20)\ntrain_batch = next(iter(training_dataset))\ndisplay_batch(train_batch, 2);","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:28:57.767708Z","iopub.execute_input":"2021-06-13T19:28:57.76807Z","iopub.status.idle":"2021-06-13T19:28:59.707347Z","shell.execute_reply.started":"2021-06-13T19:28:57.768042Z","shell.execute_reply":"2021-06-13T19:28:59.706628Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = train_batch\nnp.unique(label.numpy(), return_counts=True)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T19:29:14.482139Z","iopub.execute_input":"2021-06-13T19:29:14.482618Z","iopub.status.idle":"2021-06-13T19:29:14.490517Z","shell.execute_reply.started":"2021-06-13T19:29:14.482587Z","shell.execute_reply":"2021-06-13T19:29:14.489661Z"},"trusted":true},"execution_count":null,"outputs":[]}]}