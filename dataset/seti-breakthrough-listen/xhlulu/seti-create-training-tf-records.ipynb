{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport pickle\nfrom multiprocessing import Pool\n\nimport numpy as np\nimport tensorflow as tf\nimport pandas as pd\nfrom tqdm.auto import tqdm\nimport json","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nsecrets = UserSecretsClient()\n\nos.environ['KAGGLE_USERNAME'] = secrets.get_secret(\"KAGGLE_USERNAME\")\nos.environ['KAGGLE_KEY'] = secrets.get_secret(\"KAGGLE_KEY\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Helper functions","metadata":{}},{"cell_type":"code","source":"def to_feature(value, dtype):\n    if dtype in ['int', 'int64', 'uint32', 'uint64', 'bool', 'enum']:\n        return tf.train.Feature(int64_list=tf.train.Int64List(value=value))\n    \n    if dtype in ['float', 'double', 'float32', 'float64']:\n        return tf.train.Feature(float_list=tf.train.FloatList(value=value))\n    \n    if dtype in ['string', 'bytes']:\n        return tf.train.Feature(bytes_list=tf.train.BytesList(value=value))\n    \n    else:\n        error_msg = (\n            f\"dtype '{dtype}' not recognized. You need to use a dtype compatible with TF protos.\"\n            \"See: https://www.tensorflow.org/tutorials/load_data/tfrecord\"\n        )\n        raise ValueError(error_msg)\n\ndef to_example(feature):\n    return tf.train.Example(features=tf.train.Features(feature=feature))\n\ndef serialize(example):\n    return example.SerializeToString()\n\ndef deserialize(string):\n    return tf.train.Example.FromString(string)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Initialize Kaggle Dataset Metadata","metadata":{}},{"cell_type":"code","source":"os.makedirs('/kaggle/dataset/', exist_ok=True)\n\n# Change below\nmeta = dict(\n    id=\"xhlulu/seti-tfrecords-train\",\n    title=\"SETI Train Split in TF Records\",\n    isPrivate=False,\n    licenses=[dict(name=\"other\")]\n)\n\nwith open('/kaggle/dataset/dataset-metadata.json', 'w') as f:\n    json.dump(meta, f)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# # First time only:\n# !touch /kaggle/dataset/dummy.txt\n# !kaggle datasets create -p \"/kaggle/dataset\" --dir-mode zip\n# !rm /kaggle/dataset/dummy.txt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Start generating TF Records","metadata":{}},{"cell_type":"code","source":"labels = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"split = 'train'\nn_jobs = 8\n\nN = labels.shape[0]\nchunk_size = np.ceil(N / (n_jobs * 10)).astype(int)\nindices = np.arange(0, N, chunk_size)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def write_record(arg):\n    chunk, idx, chunk_size, split = arg\n    \n    record_path = f\"/kaggle/dataset/{split}-{chunk}.tfrecord\"\n    chunk_df = labels.values[idx: idx+chunk_size]\n    \n    print(\"Starting to write\", record_path)\n    with tf.io.TFRecordWriter(record_path) as writer:\n        for idx, target in chunk_df:\n            path = os.path.join(\"../input/seti-breakthrough-listen\", split, idx[0], idx + '.npy')\n            X = np.load(path)\n            y = target\n\n            feature = {\n                \"X\": to_feature(X.flatten(), 'float'),\n                \"y\": to_feature([y], 'int')\n            }\n\n            example = to_example(feature)\n            serialized = serialize(example)\n            writer.write(serialized)\n        \n    print(\"Finished to write\", record_path)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"args = [\n    (chunk, idx, chunk_size, split)\n    for chunk, idx in enumerate(indices)\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nwith Pool(4) as p:\n    p.map(write_record, args)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Upload dataset","metadata":{}},{"cell_type":"code","source":"!kaggle datasets version -p \"/kaggle/dataset\" -m \"Updated via notebook\" --dir-mode zip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Code for reading TF Records\n\nOnly for reference, not run here","metadata":{}},{"cell_type":"code","source":"# def parse_train_example(example):\n#     feature_description = {\n#         \"X\": tf.io.FixedLenFeature((6, 273, 256), tf.float32),\n#         \"y\": tf.io.FixedLenFeature([], tf.int64)\n#     }\n\n#     example = tf.io.parse_single_example(example, feature_description)\n#     X = tf.transpose(example['X'], (0, 2, 1))\n    \n#     return X, example['y']\n\n# def parse_test_example(example):\n#     feature_description = {\n#         \"X\": tf.io.FixedLenFeature((6, 273, 256), tf.float32)\n#     }\n\n#     example = tf.io.parse_single_example(example, feature_description)\n#     X = tf.transpose(example['X'], (0, 2, 1))\n    \n#     return X\n\n\n# parsed_dataset = (\n#     tf.data.TFRecordDataset([f\"/kaggle/dataset/train-{chunk}.tfrecord\" for chunk in range(4)])\n#     .map(parse_train_example)\n# )","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}