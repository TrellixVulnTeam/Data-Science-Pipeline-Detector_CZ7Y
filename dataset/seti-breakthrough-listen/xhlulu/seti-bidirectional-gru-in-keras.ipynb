{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras import layers","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomDataset(tf.keras.utils.Sequence):\n    def __init__(self, df, directory, batch_size=32, random_state=42, shuffle=True, target=True):\n        np.random.seed(random_state)\n        \n        self.directory = directory\n        self.df = df\n        self.shuffle = shuffle\n        self.target = target\n        self.batch_size = batch_size\n        self.ext = '.npy'\n        \n        self.on_epoch_end()\n    \n    def __len__(self):\n        return np.ceil(self.df.shape[0] / self.batch_size).astype(int)\n    \n    def __getitem__(self, idx):\n        start_idx = idx * self.batch_size\n        batch = self.df[start_idx: start_idx + self.batch_size]\n        \n        signals = []\n\n        for fname in batch.id:\n            path = os.path.join(self.directory, fname[0], fname + self.ext)\n            data = np.load(path)\n            signals.append(data)\n        \n        signals = np.stack(signals).astype('float32')\n        \n        if self.target:\n            return signals, batch.target.values\n        else:\n            return signals\n    \n    def on_epoch_end(self):\n        if self.shuffle:\n            self.df = self.df.sample(frac=1).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    inputs = layers.Input(shape=(6, 273, 256))\n\n    gru1 = layers.Bidirectional(layers.GRU(128, return_sequences=True))\n    gru2 = layers.Bidirectional(layers.GRU(128, return_sequences=True))\n    pool = layers.GlobalAveragePooling1D()\n\n    x = layers.TimeDistributed(gru1, name=\"bi_gru_1\")(inputs)\n    x = layers.TimeDistributed(gru2, name=\"bi_gru_2\")(x)\n    x = layers.TimeDistributed(pool, name=\"pool\")(x)\n    \n    x = layers.Flatten()(x)\n    x = layers.Dense(128, activation=\"relu\")(x)\n    x = layers.Dense(1, activation=\"sigmoid\", name=\"sigmoid\")(x)\n\n    model = tf.keras.Model(inputs=inputs, outputs=x)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\nsub = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_df = train.sample(frac=1).reset_index(drop=True)\n\nsplit = int(sample_df.shape[0] * 0.8)\ntrain_df = sample_df[:split]\nvalid_df = sample_df[split:]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.compile(\"adam\", loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC()])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dset = CustomDataset(\n    train_df, \"../input/seti-breakthrough-listen/train\", batch_size=64)\n\nvalid_dset = CustomDataset(\n    valid_df, \"../input/seti-breakthrough-listen/train\", batch_size=64, shuffle=False)\n\ntest_dset = CustomDataset(\n    sub, \"../input/seti-breakthrough-listen/test\", batch_size=64, target=False, shuffle=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ckpt = tf.keras.callbacks.ModelCheckpoint(\n    \"model_weights.h5\", save_best_only=True, save_weights_only=True,\n)\n\ntrain_history = model.fit(\n    train_dset, \n    use_multiprocessing=True, \n    workers=4, \n    epochs=10,\n    validation_data=valid_dset,\n    callbacks=[ckpt],\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import plotly.express as px\npx.line(train_history.history, y=['auc', 'val_auc'], title=\"Training history\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Submission","metadata":{}},{"cell_type":"code","source":"model.load_weights('model_weights.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_pred = model.predict(\n    test_dset, use_multiprocessing=True, workers=4, verbose=1\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub['target'] = y_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}