{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# [SETI Breakthrough Listen - E.T. Signal Search](https://www.kaggle.com/c/seti-breakthrough-listen)\n>Find extraterrestrial signals in data from deep space \n\n![](https://storage.googleapis.com/kaggle-competitions/kaggle/23652/logos/header.png?t=2021-02-24-19-15-30)","metadata":{}},{"cell_type":"markdown","source":"# Reference\nCheck this amazing notebook, [How To Create TFRecords](https://www.kaggle.com/cdeotte/how-to-create-tfrecords) by [Chris Deotte](https://www.kaggle.com/cdeotte)","metadata":{}},{"cell_type":"markdown","source":"# How to Create TFRecord","metadata":{}},{"cell_type":"code","source":"SEED  = 0\nDIM   = 256","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, shutil\nfrom glob import glob\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntest_label_df  = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths = glob('../input/seti-breakthrough-listen/train/**/*.npy')\ntest_paths = glob('../input/seti-breakthrough-listen/test/**/*.npy')\nlen(train_paths), len(test_paths)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame({'filepath':train_paths})\ntrain_df['id'] = train_df['filepath'].map(lambda x: x.split('/')[-1].split('.')[0])\ntrain_df = pd.merge(train_df, train_label_df, on='id', how='left')\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame({'filepath':test_paths})\ntest_df['id'] = test_df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\ntest_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check The Data","metadata":{}},{"cell_type":"code","source":"train_df['target'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stratified KFold by Groups","metadata":{}},{"cell_type":"markdown","source":"# Check the signals\nFrom the [dataset information](https://www.kaggle.com/c/seti-breakthrough-listen/overview/data-information),\n>>\nNot all of the “needle” signals look like diagonal lines, and they may not be present for the entirety of all three “A” observations, but what they do have in common is that they are only present in some or all of the “A” observations (panels **1**, **3**, and **5** in the cadence snippets).\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt, cv2\n\ndef load_signal(filepath, dim=DIM):\n    sgnl = np.load(filepath)\n    img = np.moveaxis(sgnl, 0, 2)\n    img = img.astype(np.float32)\n    img = (img - img.mean(axis=1).mean(axis=0))/(img.std(axis=1).std(axis=0))\n    if dim is not None:\n        img = cv2.resize(img, dsize=(dim, dim), interpolation=cv2.INTER_NEAREST)\n    return img\n\ndef visualize(sgnl):\n    f, ax = plt.subplots(2,3,figsize=(15, 10))\n    \n    ax[0,0].imshow(sgnl[:,:,0])\n    ax[0,1].imshow(sgnl[:,:,2])\n    ax[0,2].imshow(sgnl[:,:,4])\n    \n    ax[1,0].imshow(sgnl[:,:,1])\n    ax[1,1].imshow(sgnl[:,:,3])\n    ax[1,2].imshow(sgnl[:,:,5])\n    \n    for axis in ax.flatten():\n        axis.axis('OFF')\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Channels","metadata":{}},{"cell_type":"code","source":"mask_positive = train_df['target']==1\nmask_negative = train_df['target']==0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgnl = load_signal(train_df[mask_positive].reset_index(drop=True)['filepath'].iloc[10], dim=256)\nvisualize(sgnl)\nsgnl.shape, sgnl.dtype, sgnl.mean(axis=1).mean(axis=0), sgnl.std(axis=1).std(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sgnl = load_signal(train_df[mask_negative].reset_index(drop=True)['filepath'].iloc[10], dim=256)\nvisualize(sgnl)\nsgnl.shape, sgnl.dtype, sgnl.mean(axis=1).mean(axis=0), sgnl.std(axis=1).std(axis=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TFRecord Data","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writng TFRecord (Train)","metadata":{}},{"cell_type":"code","source":"def train_serialize_example(feature0, feature1, feature2):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n      'target'        : _int64_feature(feature2),\n    }\n    \n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_record_path = 'train.tfrec'\n\nwith tf.io.TFRecordWriter(tf_record_path) as writer:\n\n    for row in tqdm(train_df.itertuples()): \n        \n        _id = row.id\n        _signal = load_signal(row.filepath, dim=DIM)\n        \n        _image_a = _signal[:,:,0::2]\n        _target_a = np.array(row.target, dtype=np.uint8)\n        _example_a = train_serialize_example(\n            cv2.imencode('.png', _image_a)[1].tobytes(),\n            str.encode(_id),\n            _target_a)\n        \n        writer.write(_example_a)\n\nfilesize = os.path.getsize(tf_record_path)/10**6\nprint(tf_record_path,':',np.around(filesize, 2),'MB')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writing TFRecord (Test)","metadata":{}},{"cell_type":"code","source":"def test_serialize_example(feature0, feature1):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n    }\n    \n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf_record_path = 'infer.tfrec'\n\nwith tf.io.TFRecordWriter(tf_record_path) as writer:\n\n    for row in tqdm(test_df.itertuples()): \n        \n        _id = row.id\n        _signal = load_signal(row.filepath, dim=DIM)\n        \n        _image_a = _signal[:,:,0::2]\n        _example_a = test_serialize_example(\n            cv2.imencode('.png', _image_a)[1].tobytes(),\n            str.encode(_id))\n        \n        writer.write(_example_a)\n        \nfilesize = os.path.getsize(tf_record_path)/10**6\nprint(tf_record_path,':',np.around(filesize, 2),'MB')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading TFRecord","metadata":{}},{"cell_type":"code","source":"def parse_example(byte_array):\n    schema = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string), \n        \"image_id\": tf.io.FixedLenFeature([], tf.string),\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  \n    }\n    \n    example = tf.io.parse_single_example(byte_array, schema)\n    \n    image = tf.image.decode_png(example['image'], channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.reshape(image, [DIM, DIM, 3])\n    \n    target = tf.cast(example['target'], tf.float32) \n    target = tf.reshape(target, [1])  \n    \n    return image, target # returns a dataset of (image, label) pairs","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 32\nignore_order = tf.data.Options()\nignore_order.experimental_deterministic = False # disable order, increase speed\n\ndataset = tf.data.TFRecordDataset('train.tfrec', num_parallel_reads=AUTO)\ndataset = dataset.with_options(ignore_order)\n\nsplit = 3 # 3/1 train/validation split\ntrain_dataset = dataset.window(split, split + 1).flat_map(lambda x: x)\ntrain_dataset = train_dataset.map(parse_example)\ntrain_dataset = train_dataset.repeat()\ntrain_dataset = train_dataset.batch(BATCH_SIZE)\ntrain_dataset = train_dataset.prefetch(AUTO)\n\nvalid_dataset = dataset.skip(split).window(1, shift=split + 1).flat_map(lambda x: x)\nvalid_dataset = valid_dataset.map(parse_example)\nvalid_dataset = valid_dataset.batch(BATCH_SIZE)\nvalid_dataset = valid_dataset.prefetch(AUTO)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}