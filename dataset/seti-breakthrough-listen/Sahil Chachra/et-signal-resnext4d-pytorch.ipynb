{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport glob\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm import tqdm\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.models as models\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\nprint('Shape of train dataset :',train_labels.shape)\ntrain_labels.head(5)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels['target'].value_counts()\n\n# We have class imbalance","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ET_Dataset(Dataset):\n    \n    def __init__(self, img_paths, targets, resize=None, augmentations=None):\n        self.img_paths = img_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n    \n    def __len__(self):\n        return len(self.img_paths)\n    \n    def __getitem__(self, item):\n        img = np.load(self.img_paths[item]).astype('float')\n        target = self.targets[item]\n        \n        if self.resize is not None:\n            img = np.transpose(img, (1, 2, 0))\n            img = cv2.resize(img, dsize=self.resize, interpolation=cv2.INTER_CUBIC)\n        \n        if self.augmentations is not None:\n            aug = self.augmentations(image = img)\n            img = augmented[\"img\"]\n        \n        img = np.transpose(img, (2, 0, 1)).astype(np.float32)\n        \n        return {\"image\":torch.tensor(img, dtype=torch.float),\n               \"target\":torch.tensor(target, dtype=torch.long),}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels['img_path'] = train_labels['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')\ntrain_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train_model(data_loader, model, optimizer, criterion, device):\n    loss_arr = []\n    # Setting model to train mode\n    model.train()\n    \n    for data in tqdm(data_loader, leave=True, desc='Training'):\n        inputs = data[\"image\"]\n        target = data[\"target\"]\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        target = target.to(device, dtype=torch.float)\n        \n        # Forward Pass\n        output = model(inputs)\n        loss = criterion(output, target.view(-1, 1))\n        \n        # Backward Pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n        loss_arr.append(loss.item())\n        \n        del inputs, target, output\n    return round(sum(loss_arr)/len(loss_arr), 3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(data_loader, model, device):\n    \n    # Set the model to evaluation mode\n    model.eval()\n    \n    _actual = []\n    _preds = []\n    \n    with torch.no_grad():\n        for data in tqdm(data_loader, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            target = data[\"target\"]\n            \n            inputs = inputs.to(device, dtype=torch.float)\n            target = target.to(device, dtype=torch.float)\n            \n            pred = model(inputs)\n            \n            target = target.detach().cpu().numpy().tolist()\n            pred = pred.detach().cpu().numpy().tolist()\n            \n            _actual.extend(target)\n            _preds.extend(pred)\n    \n    return metrics.roc_auc_score(_actual, _preds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def select_model(model_name, pretrained=True):\n    \n    if model_name.lower()==\"resnext50\":\n        if pretrained:\n            return models.resnext50_32x4d(pretrained=True)\n        else:\n            return models.resnext50_32x4d(pretrained=False)\n    elif model_name.lower()==\"resnet18\":\n        if pretrained:\n            return models.resnet18(pretrained=True)\n        else:\n            return model.resent18(pretrained=False)\n    \n    elif model_name.lower()==\"resnet34\":\n        if pretrained:\n            return models.resnet34(pretrained=True)\n        else:\n            return model.resent34(pretrained=False)\n    \n    elif model_name.lower()==\"resnet50\":\n        if pretrained:\n            return models.resnet50(pretrained=True)\n        else:\n            return model.resent50(pretrained=False)\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_configured_model_resnet(model_name, pretrained=True):\n    model = select_model(model_name, pretrained)\n    model.fc = nn.Sequential(\n        nn.BatchNorm1d(512),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=512, out_features=1024),\n        nn.ReLU(),\n        nn.BatchNorm1d(1024),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=1024, out_features=1)\n    )\n    \n    return model\n\ndef get_configured_model_resnext(model_name, pretrained=True):\n    model = select_model(model_name, pretrained)\n    model.fc = nn.Linear(in_features=2048, out_features=1)\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get data\nimages = train_labels.img_path.values\ntargets = train_labels.target.values\n\naug = None\nbatch_size = 64\n\ntrain_imgs, val_imgs, train_targets, val_targets = train_test_split(images, targets, \n                                                                    stratify=targets,\n                                                                    random_state=42)\n\ntrain_dataset = ET_Dataset(img_paths=train_imgs,\n                                     targets=train_targets,\n                                     resize=(224, 224),\n                                     augmentations=aug)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True, num_workers=4)\n\nval_dataset = ET_Dataset(img_paths=val_imgs,\n                                     targets=val_targets,\n                                     resize=(224, 224),\n                                     augmentations=aug)\n\nval_loader = torch.utils.data.DataLoader(val_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=False, num_workers=4)\n\n# Configure model\ndevice = device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nepochs = 10\nloss_fn = nn.BCEWithLogitsLoss()\nlr = 0.005\n\nmodel = get_configured_model_resnext(model_name = \"resnext50\", pretrained=True)\n# Configure input layer as input has 6 channels and not 3\nmodel.conv1 = nn.Conv2d(6, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\nmodel.to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=lr, amsgrad=True)\nscheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2, verbose=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epoch_loss = []\nfor epoch in range(epochs):\n    mean_loss_batch = train_model(train_loader, model, optimizer, loss_fn, device)\n    scheduler.step(mean_loss_batch)\n    epoch_loss.append(mean_loss_batch)\n    print(\"Epoch : {0}, Current Mean Loss : {1}\".format(epoch+1, mean_loss_batch))\nroc_val = evaluate_model(train_loader, model, device)\nprint(\"ROC AUC value is : \", roc_val)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_training_details(epoch_loss, lr, batch_size, epochs):\n    \n    plt.plot(epoch_loss)\n    plt.xlabel('Loss')\n    plt.ylabel('Epochs')\n    plt.title('Loss vs Epoch')\n    \n    print(\"Batch size {0}, LR = {1} and Epochs = {2}\".format(batch_size, lr, epochs))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_training_details(epoch_loss, lr, batch_size, epochs)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## -- RESNET 18 --\n# Epoch = 10, LR = 1e-3, Batch size = 64, Loss = 0.52, ROC AUC = 0.57\n\n## -- RESMET 50 --\n# Epoch = 10, LR = 1e-2, Batch size = 64, Loss = 0.177, ROC AUC = 0.6025\n# Epoch = 10, LR = 0.005, Batch size = 64, Loss = , ROC AUC = ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate_model_test(data_loader, model, device):\n    \n    # Set the model to evaluation mode\n    model.eval()\n    \n    _actual = []\n    _preds = []\n    \n    with torch.no_grad():\n        for data in tqdm(data_loader, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            target = data[\"target\"]\n            \n            inputs = inputs.to(device, dtype=torch.float)\n            target = target.to(device, dtype=torch.float)\n            \n            pred = model(inputs)\n            \n            target = target.detach().cpu().numpy().tolist()\n            pred = pred.detach().cpu().numpy().tolist()\n            \n            _actual.extend(target)\n            _preds.extend(pred)\n    \n    return _preds, _actual","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')\n\ntest_images = submission.img_path.values\n\ndummy_targets = submission.target.values\n\ntest_dataset = ET_Dataset(img_paths=test_images,\n                                     targets=dummy_targets,\n                                     resize=(224, 224),\n                                     augmentations=aug)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=64,\n                                          shuffle=False,\n                                          num_workers=4)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, valid_targets = evaluate_model_test(test_loader, model, device=device)\n\npredictions = np.array(predictions)\n\npredictions = (predictions - predictions.min()) / (predictions.max() - predictions.min())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target = predictions\n\nsubmission.drop(['img_path'], axis=1, inplace=True)\n\nsubmission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_0.63_state_dict')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'entire_model_0.63')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}