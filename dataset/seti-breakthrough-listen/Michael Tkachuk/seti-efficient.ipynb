{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet\n\nimport numpy as np\nimport numpy.linalg as lin\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nimport pandas as pd\nimport time\nimport os\nimport sklearn\nimport matplotlib.pyplot as plt\nimport albumentations as A\nimport efficientnet.tfkeras as efn\nfrom PIL import Image\nimport random\nfrom kaggle_datasets import KaggleDatasets\n\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport tensorflow.keras.models as models\nimport tensorflow.keras.losses as losses\nimport tensorflow.keras.optimizers as optimizers\nimport tensorflow.keras.metrics as tfmetrics\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense,Input,Dropout,GlobalAveragePooling2D,GlobalMaxPool2D,\\\nBatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.metrics import AUC\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\n\nSEED = 31\nDEVICE = \"CPU\" if 0 else \"TPU\"\nPATH = KaggleDatasets().get_gcs_path(\"seti-tfrec-dataset-256\")\nSHAPE = [528,528]","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-06T15:49:19.124095Z","iopub.execute_input":"2021-06-06T15:49:19.124726Z","iopub.status.idle":"2021-06-06T15:49:35.925536Z","shell.execute_reply.started":"2021-06-06T15:49:19.124584Z","shell.execute_reply":"2021-06-06T15:49:35.924448Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    tf.random.set_seed(SEED)\n    print('seeding done!!!')\nseeding(SEED)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:49:35.927429Z","iopub.execute_input":"2021-06-06T15:49:35.927834Z","iopub.status.idle":"2021-06-06T15:49:35.934558Z","shell.execute_reply.started":"2021-06-06T15:49:35.927788Z","shell.execute_reply":"2021-06-06T15:49:35.933854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## TPU","metadata":{}},{"cell_type":"code","source":"if DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nBATCH = 16\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:54:00.013086Z","iopub.execute_input":"2021-06-06T15:54:00.0135Z","iopub.status.idle":"2021-06-06T15:54:05.698232Z","shell.execute_reply.started":"2021-06-06T15:54:00.013464Z","shell.execute_reply":"2021-06-06T15:54:05.697025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualaize","metadata":{}},{"cell_type":"code","source":"def show_sample(array,label=None):\n    array = array.astype(np.float32)\n    f = plt.figure(figsize=(14,14))\n   \n    for i in range(6):\n        ax = f.add_subplot(6,1,i+1)\n        if i == 0 and label is not None:\n            ax.set_title(f\"label : {label}\")\n        ax.matshow(array[i],aspect=\"auto\")\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:49:41.291268Z","iopub.execute_input":"2021-06-06T15:49:41.291538Z","iopub.status.idle":"2021-06-06T15:49:41.297656Z","shell.execute_reply.started":"2021-06-06T15:49:41.29151Z","shell.execute_reply":"2021-06-06T15:49:41.296979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def new_im(array):\n    im = np.concatenate([array[i] for i in range(6)],axis=0).astype(np.float32)\n    im = A.resize(im,256,256)\n    f = plt.figure(figsize=(7,7))\n    ax = f.add_subplot(111)\n    ax.matshow(im,aspect=\"auto\")\n    plt.show()\n\nnew_im(np.load(\"../input/seti-breakthrough-listen/test/7/7ff1a14a9d96.npy\"))","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:49:41.298529Z","iopub.execute_input":"2021-06-06T15:49:41.298774Z","iopub.status.idle":"2021-06-06T15:49:41.732802Z","shell.execute_reply.started":"2021-06-06T15:49:41.298748Z","shell.execute_reply":"2021-06-06T15:49:41.731836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"count = 0\nlabels = pd.read_csv(\"../input/seti-breakthrough-listen/train_labels.csv\")\nfor i,r in labels.iterrows():\n    if r.target == 1:\n        show_sample(np.load(f\"../input/seti-breakthrough-listen/train/0/{r.id}.npy\"),1)\n        count +=1\n    if count > 1:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:49:41.734112Z","iopub.execute_input":"2021-06-06T15:49:41.734466Z","iopub.status.idle":"2021-06-06T15:49:44.561311Z","shell.execute_reply.started":"2021-06-06T15:49:41.734424Z","shell.execute_reply":"2021-06-06T15:49:44.560169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Augment","metadata":{}},{"cell_type":"code","source":"transformation = A.Compose([\n    A.Blur(p=0.8,blur_limit=(3,7)),\n    A.GaussNoise(p=0.9,var_limit=(160,250)),\n    A.InvertImg(p=0.2),\n    A.MultiplicativeNoise(p=0.9, multiplier=(0.2, 1.4), per_channel=True, elementwise=False),\n    A.RandomBrightness(p=0.8,limit=(-0.2,0.2))\n])\n\n\ndef gauss_noise(x,cache):\n    choices = tf.random.uniform([6],0,1024,dtype=tf.int32)\n    x1 = cache[choices[0]] + cache[choices[1]]\n    x2 = cache[choices[2]] + cache[choices[3]]\n    x3 = cache[choices[4]] + cache[choices[5]]\n\n    noise = tf.stack([x1,x2,x3],axis=-1)\n    x += noise\n    return x  #tf.clip_by_value(x,0,1)\n        \ndef multiply_ch(x,val):\n    return tf.cast(tf.stack([x[:,:,i]*val[i] for i in range(3)],axis=-1),tf.float16)\n\ndef spatial(img,n_holes,size,channel_wise=False):\n    # size: (min,max) of hole dimentions\n    #\n    #\n    \n    dims = img.shape\n    scaling = tf.constant([dims[0]//dims[1],1],dtype=tf.int32)\n    for i in range(n_holes):\n        hole_pivot1 = tf.random.uniform([],0,dims[0]-size[0],dtype=tf.int32)\n        hole_pivot2 = tf.random.uniform([],0,dims[1]-size[1],dtype=tf.int32)\n        hole_pivot = tf.stack([hole_pivot1,hole_pivot2],axis=0)\n        hole_size = tf.random.uniform([2],size[0],size[1],dtype=tf.int32)*scaling\n        hole_end = tf.math.minimum(hole_pivot + hole_size,dims[:2])\n        hole_size = hole_end - hole_pivot\n        top = img[:hole_pivot[0],:,:]\n        bottom = img[hole_end[0]:,:,:]\n        mid_left = img[hole_pivot[0]:hole_end[0],:hole_pivot[1],:]\n        mid_right = img[hole_pivot[0]:hole_end[0],hole_end[1]:,:]\n        mid_mid = tf.zeros([hole_size[0],hole_size[1],3],dtype=tf.float16)\n        mid = tf.concat([mid_left,mid_mid,mid_right],axis=1)\n        img = tf.reshape(tf.concat([top,mid,bottom],axis=0),SHAPE+[3])\n    return img","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:49:44.562951Z","iopub.execute_input":"2021-06-06T15:49:44.563367Z","iopub.status.idle":"2021-06-06T15:49:44.583837Z","shell.execute_reply.started":"2021-06-06T15:49:44.563327Z","shell.execute_reply":"2021-06-06T15:49:44.583108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data","metadata":{}},{"cell_type":"code","source":"def num_of_samples(filenames):\n    s = 0\n    for i in filenames:\n        s += int(i[-14:-10])\n    return s\n\ndef get_dataset(filenames,\n                target=True,\n                transform=True,\n                resize=True,\n                num_holes_param=(6,8),\n                hole_size_param=(16,24),\n               ):\n    ds = tf.data.TFRecordDataset(filenames)\n    feature_descr = {\n        \"image\":tf.io.FixedLenFeature([], tf.string),\n        \"im_name\":tf.io.FixedLenFeature([],tf.string),\n        \"target\":tf.io.FixedLenFeature([],tf.int64,default_value=0)\n    }\n    def parser(example):\n        example = tf.io.parse_single_example(example, feature_descr)\n        if target:\n            return example[\"image\"],example[\"target\"]\n        else: \n            return example[\"image\"],example[\"im_name\"]\n\n    \n    def preproc(img):\n        img = tf.reshape(tf.io.decode_jpeg(img),[273*6,256]+[1])\n        if resize:\n            img = tf.image.resize(\n                    img, SHAPE, method='bicubic')\n        img = tf.image.adjust_contrast(img,3)\n        img = tf.concat([img for _ in range(3)],axis=-1)\n        img = tf.cast(img,tf.float16)/255.0\n        \n        return img\n    \n    normal_cache = tf.random.normal([1024]+SHAPE,0,0.01/np.sqrt(2),dtype=tf.float16)\n    def augment(img):\n        probs = [1.0,0.0,0.0]\n        \n        n_holes = tf.random.uniform([],*num_holes_param,dtype=tf.int32)\n        mult_channel = tf.random.uniform([3],0.8,1.2,dtype=tf.float16)\n        \n        \n        transforms = [\n            lambda x: spatial(x,n_holes,hole_size_param),\n            lambda x: gauss_noise(x,normal_cache),\n            lambda x: multiply_ch(x,mult_channel),\n        ]\n        \n        for p,tr in zip(probs,transforms):\n            if tf.random.uniform([])<p:\n                img = tr(img)\n        \n        return tf.reshape(img,SHAPE+[3])\n    \n\n    ds = ds.map(parser,num_parallel_calls=AUTO)\n    ds = ds.map(lambda x,y:(preproc(x),y),num_parallel_calls=AUTO)\n    if transform:\n        ds = ds.map(lambda x,y:(augment(x),y),num_parallel_calls=AUTO)\n    ds = ds.batch(BATCH*REPLICAS).repeat().prefetch(AUTO)\n    return ds","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:55:11.216583Z","iopub.execute_input":"2021-06-06T15:55:11.216955Z","iopub.status.idle":"2021-06-06T15:55:11.234464Z","shell.execute_reply.started":"2021-06-06T15:55:11.216924Z","shell.execute_reply":"2021-06-06T15:55:11.23338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"filenames = tf.io.gfile.glob(f\"{PATH}/train/*.tfrecords\")\ndataset = get_dataset(filenames)\nprint(\"started\")\nstart = time.time()\nit = list(dataset.take(3))\nprint(time.time()-start)\nfor i in it:\n    count = 0\n    for k in zip(i[0],i[1]):\n        if count > 5:\n            break\n        if k[1]==1:\n            plt.figure(figsize=(7,7))\n            plt.title(str(k[1].numpy()))\n            plt.imshow(k[0].numpy()[:,:,:].astype(np.float32),aspect=\"auto\")\n            count += 1\n","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:55:12.437383Z","iopub.execute_input":"2021-06-06T15:55:12.43776Z","iopub.status.idle":"2021-06-06T15:55:19.69361Z","shell.execute_reply.started":"2021-06-06T15:55:12.437724Z","shell.execute_reply":"2021-06-06T15:55:19.692567Z"},"jupyter":{"outputs_hidden":true,"source_hidden":true}}},{"cell_type":"markdown","source":"## Validation","metadata":{}},{"cell_type":"code","source":"","metadata":{"jupyter":{"source_hidden":true}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"def get_model():\n    shape = tuple(SHAPE+[3])\n    i = Input(shape)\n    efnet = efn.EfficientNetB6(input_shape=shape,weights='imagenet',include_top=False)(i)\n    x = GlobalAveragePooling2D()(efnet)\n    x = BatchNormalization()(x)\n    x = Dense(64,activation=\"swish\")(x)\n    x = Dense(1,activation=\"sigmoid\")(x)\n    model = Model(i,x)\n    model.compile(optimizer=Adam(),\n                  loss=losses.BinaryCrossentropy(),\n                  metrics=[tfmetrics.AUC(name=\"auc\")])\n    return model\n\ndef lr_func(epoch):\n    lrs = [1E-3,1E-3,5E-4,3E-4,1E-4,5E-5,3E-5,1E-5,5E-6]\n    if epoch in range(len(lrs)):\n        return lrs[epoch]\n    else: return 3E-6\n    \ndef lr_fine(epoch):\n    return 2E-6\n        \nlr_sch = tf.keras.callbacks.LearningRateScheduler(lr_func, verbose=False) \nlr_fine_sch = tf.keras.callbacks.LearningRateScheduler(lr_fine, verbose=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:55:20.750555Z","iopub.execute_input":"2021-06-06T15:55:20.750923Z","iopub.status.idle":"2021-06-06T15:55:20.760849Z","shell.execute_reply.started":"2021-06-06T15:55:20.750892Z","shell.execute_reply":"2021-06-06T15:55:20.759845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"m = get_model()\nprint('b')\ni = it[0][0]\nprint('c')\nm(i)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:55:21.80285Z","iopub.execute_input":"2021-06-06T15:55:21.803244Z","iopub.status.idle":"2021-06-06T15:55:46.974071Z","shell.execute_reply.started":"2021-06-06T15:55:21.803209Z","shell.execute_reply":"2021-06-06T15:55:46.972963Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"train_files = tf.io.gfile.glob(f\"{PATH}/train/*.tfrecords\")\ntest_files = tf.io.gfile.glob(f\"{PATH}/test/*.tfrecords\")\n\nsplit = KFold(6,True,random_state=SEED)\nfor fold,(train_idx,val_idx) in enumerate(split.split(train_files)):\n    train = get_dataset(np.array(train_files)[train_idx])\n    val = get_dataset(np.array(train_files)[val_idx],transform=False)\n    with strategy.scope():\n        model = get_model()\n    callbacks = [lr_sch,tf.keras.callbacks.ModelCheckpoint(f\"./weights_{fold}.h5\",\n                                                    monitor='val_auc',\n                                                    verbose=0, \n                                                    save_best_only=True,\n                                                    save_weights_only=True,\n                                                    mode='max',\n                                                    save_freq='epoch')]\n    steps = num_of_samples(np.array(train_files)[train_idx]) // (BATCH*REPLICAS)\n    val_steps = num_of_samples(np.array(train_files)[val_idx]) // (BATCH*REPLICAS)\n    print(f\"steps: {steps}, val_steps: {val_steps}\")\n    model.fit(train,\n              validation_data=val,\n              epochs=6,\n              steps_per_epoch=steps,\n              validation_steps=val_steps,\n              callbacks=callbacks,\n              verbose=2)\n    print(\"making augmentations lighter\")\n    callbacks = [lr_fine_sch,tf.keras.callbacks.ModelCheckpoint(f\"./weights_{fold}.h5\",\n                                                    monitor='val_auc',\n                                                    verbose=0, \n                                                    save_best_only=True,\n                                                    save_weights_only=True,\n                                                    mode='max',\n                                                    save_freq='epoch')]\n    train = get_dataset(np.array(train_files)[train_idx],num_holes_param=(2,4))\n    val = get_dataset(np.array(train_files)[val_idx],transform=False)\n\n    model.fit(train,\n              epochs=4,\n              steps_per_epoch=steps,\n              validation_data=val,\n              validation_steps=val_steps,\n              callbacks=callbacks,\n              verbose=2)\n    \n  ","metadata":{"execution":{"iopub.status.busy":"2021-06-06T15:55:54.594892Z","iopub.execute_input":"2021-06-06T15:55:54.595271Z","iopub.status.idle":"2021-06-06T16:27:45.557728Z","shell.execute_reply.started":"2021-06-06T15:55:54.595231Z","shell.execute_reply":"2021-06-06T16:27:45.553399Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}