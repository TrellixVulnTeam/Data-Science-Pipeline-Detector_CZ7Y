{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h3> Overview </h3>\n\nThis a simple EDA notebook for the [SETI Breakthrough Listen - E.T. Signal Search](https://www.kaggle.com/c/seti-breakthrough-listen/overview) challenge. \n\n<h4> Notebook Structure </h4>\n\n- [data structure](#data)\n    - train/test\n    - train_labels\n    - sample_submission\n\n<h5> Props </h5>\n\nProps to [ihelon](https://www.kaggle.com/ihelon/signal-search-exploratory-data-analysis): I read through his notebook before starting with mine. ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom colorama import Fore, Back, Style\ng_ = Fore.GREEN\nr_ = Fore.RED\nb_ = Fore.BLUE\nm_ = Fore.MAGENTA\nc_ = Fore.CYAN\nimport tqdm\nimport os\nimport glob\n\nroot_path = '/kaggle/input/seti-breakthrough-listen/'\ntrain_path = os.path.join(root_path, \"train\")\ntest_path = os.path.join(root_path, \"test\")\n\n\n# Functions taken and edited from https://www.kaggle.com/ihelon/signal-search-exploratory-data-analysis\n\ndef get_train_filename_by_id(_id: str) -> str:\n    return f\"../input/seti-breakthrough-listen/train/{_id[0]}/{_id}.npy\"\n\ndef show_cadence(filename: str, label: int) -> None:\n    fig, axes = plt.subplots(6, 1, figsize = (16, 10))\n    ax = axes.ravel()\n    arr = np.load(filename)\n    for i in range(6):\n        \n        ax[i].imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        ax[i].text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        if i != 5:\n            ax[i].set_xticks([])\n            \n    fig.text(0.5, -0.02, 'Frequency Range', ha='center', fontsize=18)\n    fig.text(-0.02, 0.5, 'Seconds', va='center', rotation='vertical', fontsize=18)\n\n    plt.suptitle(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n    fig.tight_layout()\n    plt.show()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a id = 'data'></a>\n<h3> Data </h3>\n\nIn this competition you are tasked with looking for technosignature signals in cadence snippets taken from the Green Bank Telescope (GBT). Please read the extended description on the [Data Information tab](https://www.kaggle.com/c/seti-breakthrough-listen/overview/data-information) for detailed information about the data (that's too lengthy to include here).\n\nFiles\n- **train/** - a training set of cadence snippet files stored in `numpy` `float16` format (v1.20.1), one file per cadence snippet id, with corresponding labels found in the `train_labels.csv` file. Each file has dimension (6, 273, 256), with the 1st dimension representing the 6 positions of the cadence, and the 2nd and 3rd dimensions representing the 2D spectrogram.</li>\n- **test/** - the test set cadence snippet files; you must predict whether or not the cadence contains a \"needle\", which is the target for this competition\n- **sample_submission.csv** - a sample submission file in the correct format\n- **train_labels** - targets corresponding (by `id`) to the cadence snippet files found in the `train/` folder","metadata":{}},{"cell_type":"markdown","source":"<h5> train_labels.csv </h5>\n","metadata":{}},{"cell_type":"code","source":"train_labels = pd.read_csv(os.path.join(root_path, 'train_labels.csv'))\ndisplay(train_labels.head(3))\nprint(\"\\t\\t\\t\\t{}{}Number of train labels: {}\".format(r_, Back.BLACK, len(train_labels)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmap_plot = plt.get_cmap('jet_r')\nddt = train_labels.target.value_counts().to_frame()\nplt.style.use('fivethirtyeight')\nfig, ax = plt.subplots(1, 1, figsize = (12, 4))\nsns.countplot(data = train_labels, x = 'target', orient = \"v\", palette = 'pastel', ax = ax)\nplt.suptitle(\"Train target distribution\")\nplt.rcParams.update(plt.rcParamsDefault)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h5> Train </h5>\n\n- number of files\n- example of some signals","metadata":{}},{"cell_type":"code","source":"train_files = glob.glob(train_path + \"/*/*.npy\")\nprint(\"\\t\\t\\t\\t{}{}Number of train files: {}\".format(r_, Back.BLACK, len(train_files)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_target = train_labels.query(\"target == 1\").sample().id.item()\nnegative_target = train_labels.query(\"target == 0\").sample().id.item()\nshow_cadence(get_train_filename_by_id(positive_target), 1)\nshow_cadence(get_train_filename_by_id(negative_target), 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h5> Test </h5>\n\n- number of files\n- example of some signals","metadata":{}},{"cell_type":"code","source":"test_files = glob.glob(test_path + \"/*/*.npy\")\nprint(\"\\t\\t\\t\\t{}{}Number of test files: {}\".format(r_, Back.BLACK, len(test_files)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_cadence(np.random.choice(test_files, 1).item(), None)\nshow_cadence(np.random.choice(test_files, 1).item(), None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h5> Sample submission </h5>","metadata":{}},{"cell_type":"code","source":"sample_sub = pd.read_csv(os.path.join(root_path, 'sample_submission.csv'))\ndisplay(sample_sub.sample(3))\nprint(\"\\t\\t\\t\\t{}{}Number of submission predictions: {}\".format(r_, Back.BLACK, len(sample_sub)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<h4> Data Exploration on a sample of train files </h4>\n\nBased on what is written in the [Data Information tab](https://www.kaggle.com/c/seti-breakthrough-listen/overview/data-information) \n<img src = \"https://i.imgur.com/AKcxEMZ.png\" width=800></img>\n\nit could be interesting to check pointwise difference distribution between images corresponding to positive and negative labels. \n\nGiven an image/array `arr` of size $(6, 273, 256)$:\n\n- Take difference and ravel: `(arr[0] - arr[2]).ravel()`\n- Take difference and ravel: `(arr[0] - arr[4]).ravel()`\n- Take difference and ravel: `(arr[2] - arr[4]).ravel()`\n- concatenate the 3\n- Compare distribution between negative and positive","metadata":{}},{"cell_type":"code","source":"def pointwise_difference(signal):\n    \n    if not isinstance(signal, np.ndarray):\n        raise TypeError(\"signal should be a np.ndarray\")\n    \n    if signal.shape != (6, 273, 256):\n        raise ValueError(\"signal has wrong shape\")\n        \n    return np.concatenate(((signal[0]-signal[2]).ravel(), (signal[0]-signal[4]).ravel(), (signal[2]-signal[4]).ravel()))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\nSAMPLE_SIZE = 1000\n\nsample_positive = np.random.choice(train_labels.query(\"target == 1\").id.tolist(), SAMPLE_SIZE)\nsample_negative = np.random.choice(train_labels.query(\"target == 0\").id.tolist(), SAMPLE_SIZE)\n\nsample_positive_files = list(map(lambda x: get_train_filename_by_id(x), sample_positive))\nsample_negative_files = list(map(lambda x: get_train_filename_by_id(x), sample_negative))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%time\npositives_dist = list(map(lambda x: pointwise_difference(np.load(x)), sample_positive_files))\nprint(\"finished calculating positive label images\")\nnegatives_dist = list(map(lambda x: pointwise_difference(np.load(x)), sample_negative_files))\nprint(\"finished calculating negative label images\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positives_dist = np.concatenate(positives_dist)\nnegatives_dist = np.concatenate(negatives_dist)\n\nquantiles = np.linspace(0.05, 0.95, 19)\n\npositive_dist_df = (pd.DataFrame({\"difference\": np.quantile(positives_dist, quantiles),\n                                  \"quantile\": np.round(quantiles, 3)}))\n\nnegative_dist_df = (pd.DataFrame({\"difference\": np.quantile(negatives_dist, quantiles),\n                                  \"quantile\": np.round(quantiles, 3)}))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax = plt.subplots(1, 1, figsize = (12, 6))\nplt.style.use('fivethirtyeight')\n#sns.kdeplot(np.random.choice(positives_dist, 200000).tolist(), shade=True, alpha=0.5, ax = ax)\n#sns.kdeplot(np.random.choice(negatives_dist, 200000).tolist(), shade=True, alpha=0.2, ax = ax)\n\nsns.kdeplot(positives_dist[:200000].tolist(), shade=True, alpha=0.5, ax = ax)\nsns.kdeplot(negatives_dist[:200000].tolist(), shade=True, alpha=0.2, ax = ax)\n\nplt.legend(labels = ['positive', 'negative'], title='targets', bbox_to_anchor=(1.05, 1), loc='upper left')\nax.set_xlim(-3, 3)\nax.set_title(\"Positive vs Negatives comparison: pixelwise difference\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It seems that positive labelled images/signals have a more widespread distribution","metadata":{}}]}