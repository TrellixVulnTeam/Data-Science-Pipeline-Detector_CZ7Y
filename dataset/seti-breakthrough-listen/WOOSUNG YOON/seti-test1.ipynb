{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport timm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader,random_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-02T01:31:54.843859Z","iopub.execute_input":"2021-06-02T01:31:54.844369Z","iopub.status.idle":"2021-06-02T01:31:56.638668Z","shell.execute_reply.started":"2021-06-02T01:31:54.844305Z","shell.execute_reply":"2021-06-02T01:31:56.637778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I thought it would be nice <br>\nif there was an probability to be sure of their prediction.","metadata":{}},{"cell_type":"code","source":"def dataframe(df, istrain=True):\n    if istrain:\n        mode = 'train'\n    else:\n        mode = 'test'\n    df['filepath'] = df.id.apply(lambda x: '../input/seti-breakthrough-listen/'+ f'{mode}/'+str(x[0])+f'/{x}.npy')\n    return df\ntest_df = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ntest_df = dataframe(test_df, istrain=False)\ntest_df['target'] = 0\ntrain_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntrain_df = dataframe(train_df)\ntrain_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:25:20.841091Z","iopub.execute_input":"2021-06-02T02:25:20.841461Z","iopub.status.idle":"2021-06-02T02:25:20.972965Z","shell.execute_reply.started":"2021-06-02T02:25:20.841424Z","shell.execute_reply":"2021-06-02T02:25:20.971908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class setiDataset(Dataset):\n    def __init__(self, df, transform = None): \n        self.df = df\n        self.transform = transform\n    \n    def fileinfo(self, idx):\n        return self.df.filepath.iloc[idx], self.df.target.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath).astype('float32')\n        return image\n    \n    def __getitem__(self, idx):\n        filepath, target = self.fileinfo(idx)\n        image = self.loadfile(filepath)\n        return  torch.tensor(image, dtype=torch.float), torch.tensor(target, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:19:27.963056Z","iopub.execute_input":"2021-06-02T02:19:27.963526Z","iopub.status.idle":"2021-06-02T02:19:27.974932Z","shell.execute_reply.started":"2021-06-02T02:19:27.963488Z","shell.execute_reply":"2021-06-02T02:19:27.974008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding = 1 if kernel_size == 3 else 0, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.vals = nn.Parameter(torch.zeros(out_channels)) \n        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='leaky_relu')\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.bn(x)\n        x += self.vals.view(1, self.bn.num_features, 1, 1).expand_as(x)\n        x = x * torch.tanh(F.softplus(x))\n        return x\n    \nclass ResBlock(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int):\n        super().__init__()\n        self.conv1 = ConvBlock(in_channels, out_channels, 3)\n        self.conv2 = ConvBlock(out_channels, out_channels, 3)\n\n    def forward(self, x):\n        initial = x\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = x + initial\n        x = x * torch.tanh(F.softplus(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:19:28.955385Z","iopub.execute_input":"2021-06-02T02:19:28.955716Z","iopub.status.idle":"2021-06-02T02:19:28.96572Z","shell.execute_reply.started":"2021-06-02T02:19:28.955687Z","shell.execute_reply":"2021-06-02T02:19:28.964638Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CustomModel(nn.Module):\n    def __init__(self, in_channels = 6, out_channels = 20, res_level = 2, pretrained=True):\n        super(CustomModel,self).__init__()\n        # residual layer\n        self.conv_input = ConvBlock(in_channels, out_channels, 3)\n        self.res_layer = nn.Sequential(\n            *[ResBlock(out_channels, out_channels) for _ in range(res_level)]\n        )\n        self.conv_output = ConvBlock(out_channels, 2, 1)\n        \n        # prob layer\n        self.prob_fc_1 = nn.Linear(2*273*256, 256)\n        self.prob_fc_2 = nn.Linear(256, 1)\n        \n        self.model = timm.create_model('efficientnet_b0', pretrained=pretrained, in_chans=2, num_classes=1)\n\n    def extract(self, x):\n        x = self.conv_input(x)\n        x = self.res_layer(x)\n        x = self.conv_output(x)\n        return x\n    \n    def forward(self, x):\n        # residual layer\n        x = self.extract(x)\n        \n        # prob layer\n        prob = self.prob_fc_2(self.prob_fc_1(torch.flatten(x, start_dim=1)))\n        prob = torch.sigmoid(prob)\n        \n        x = self.model(x)\n        return prob, x","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:19:29.465532Z","iopub.execute_input":"2021-06-02T02:19:29.465887Z","iopub.status.idle":"2021-06-02T02:19:29.474554Z","shell.execute_reply.started":"2021-06-02T02:19:29.465856Z","shell.execute_reply":"2021-06-02T02:19:29.473597Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    model.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        images, targets = data\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        def closure():\n            optimizer.zero_grad()\n            prob, output = model(images)\n            loss1 = nn.BCEWithLogitsLoss(reduction='none')(output, targets.view(-1,1))\n            loss2 = nn.BCEWithLogitsLoss(reduction='none')(-output, targets.view(-1,1))\n            loss = (1-prob/2)*loss1 + (prob/2)*loss2\n            loss = loss.mean()\n            loss.backward()\n            return loss\n        optimizer.step(closure)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:19:30.242011Z","iopub.execute_input":"2021-06-02T02:19:30.242383Z","iopub.status.idle":"2021-06-02T02:19:30.249602Z","shell.execute_reply.started":"2021-06-02T02:19:30.242353Z","shell.execute_reply":"2021-06-02T02:19:30.248659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    validate_losses = 0\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            prob, output = model(images)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            validate_losses += loss.item()\n\n\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n    return final_outputs, final_targets, validate_losses/len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:19:31.049745Z","iopub.execute_input":"2021-06-02T02:19:31.050096Z","iopub.status.idle":"2021-06-02T02:19:31.058734Z","shell.execute_reply.started":"2021-06-02T02:19:31.050045Z","shell.execute_reply":"2021-06-02T02:19:31.057679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submission(data_loader, model, device):\n    model.eval()\n    \n    final_outputs = []\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            \n            prob, output = model(images)\n\n            output = output.detach().cpu().numpy().tolist()\n            final_outputs.extend(output)\n    return final_outputs","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:26:02.866155Z","iopub.execute_input":"2021-06-02T02:26:02.866566Z","iopub.status.idle":"2021-06-02T02:26:02.872635Z","shell.execute_reply.started":"2021-06-02T02:26:02.86653Z","shell.execute_reply":"2021-06-02T02:26:02.871529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device('cpu')\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T01:38:12.387549Z","iopub.execute_input":"2021-06-02T01:38:12.387909Z","iopub.status.idle":"2021-06-02T01:38:12.393152Z","shell.execute_reply.started":"2021-06-02T01:38:12.387877Z","shell.execute_reply":"2021-06-02T01:38:12.392133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmodel = CustomModel()\ncmodel.to(device)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Batch_Size = 16\ninit_dataset = setiDataset(train_df)\nlengths = [int(len(init_dataset)*0.8), int(len(init_dataset)*0.2)]\n\ntrain_dataset, valid_dataset = random_split(init_dataset, lengths)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size, shuffle=False)\noptimizer=  torch.optim.Adam(cmodel.parameters(), lr=3e-4, eps=1e-5)\n\nfor epoch in range(10):\n    print(epoch)\n    train(train_loader, cmodel, optimizer, device)\n    valid_pred, target, valid_loss = evaluate(valid_loader, cmodel, device)\n    roc_auc = metrics.roc_auc_score(target, valid_pred)\n    print(f\"Epoch={epoch}, Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_pred, target, valid_loss = evaluate(valid_loader, cmodel, device)\nroc_auc = metrics.roc_auc_score(target, valid_pred)\nprint(f\"Epoch={epoch}, Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-02T02:19:48.911053Z","iopub.execute_input":"2021-06-02T02:19:48.911428Z","iopub.status.idle":"2021-06-02T02:22:47.067812Z","shell.execute_reply.started":"2021-06-02T02:19:48.911397Z","shell.execute_reply":"2021-06-02T02:22:47.066843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"too slow...\n\nI just want to make below, but too slow.\n\noriginal loss + prob/2 * (opposite loss - orignal loss)","metadata":{}},{"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1+np.exp(-x))\n\ntest_dataset = setiDataset(test_df)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)\npred = submission(test_loader, cmodel, device)\nsub = test_df[['id']].copy()\nsub['target'] = sigmoid(np.array(pred).flatten())\nsub.to_csv('submission.csv', index=None)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}