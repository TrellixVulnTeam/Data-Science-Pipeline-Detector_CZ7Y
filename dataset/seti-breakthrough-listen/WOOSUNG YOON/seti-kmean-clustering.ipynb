{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master/')\n\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\nimport itertools\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn import metrics\nfrom tqdm.notebook import tqdm\n\nfrom sklearn.cluster import MiniBatchKMeans\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.neighbors import NearestNeighbors\n\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import transforms","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-20T00:45:53.45763Z","iopub.execute_input":"2021-07-20T00:45:53.457963Z","iopub.status.idle":"2021-07-20T00:45:55.425854Z","shell.execute_reply.started":"2021-07-20T00:45:53.457931Z","shell.execute_reply":"2021-07-20T00:45:55.424987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getpath(x, mode='train'):\n    if mode == 'train':\n        return f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy'\n    return f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy'\n\ntrain_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntest_df = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\n\ntrain_df['filepath'] = train_df.id.apply(lambda x : getpath(x, 'train'))\ntest_df['filepath'] = test_df.id.apply(lambda x: getpath(x, 'test'))","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:47:14.129607Z","iopub.execute_input":"2021-07-20T00:47:14.129978Z","iopub.status.idle":"2021-07-20T00:47:14.334518Z","shell.execute_reply.started":"2021-07-20T00:47:14.129946Z","shell.execute_reply":"2021-07-20T00:47:14.333684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class setiDataset(Dataset):\n    def __init__(self, df, pesudo_targets=None, isVisual = False): \n        self.df = df\n        self.pesudo_targets = pesudo_targets\n        if not self.pesudo_targets:\n            self.pesudo_targets = [0]*len(self.df)\n            \n        self.isVisual = isVisual\n    \n    def fileinfo(self, idx):\n        return self.df.filepath.iloc[idx]\n\n    def __getitem__(self, idx):\n        filepath = self.fileinfo(idx)\n        image = np.load(filepath).astype('float')\n        image = np.vstack([image[0], image[2], image[4]]).transpose()\n        \n        if self.isVisual:\n            target = self.df.target.iloc[idx]\n            return image, target\n        \n        image = cv2.resize(image, (64, 64), interpolation=cv2.INTER_CUBIC)\n        image = ToTensorV2()(image=image)['image']\n        pesudo_target = self.pesudo_targets[idx]\n        \n        return image, torch.tensor(pesudo_target, dtype=torch.int64)\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:47:59.156844Z","iopub.execute_input":"2021-07-20T00:47:59.157187Z","iopub.status.idle":"2021-07-20T00:47:59.165471Z","shell.execute_reply.started":"2021-07-20T00:47:59.157156Z","shell.execute_reply":"2021-07-20T00:47:59.164653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class models(nn.Module):\n    def __init__(self,model_name = 'mobilenetv3_large_100', pretrained = False, kmeans_clusters = 100):\n        super(models,self).__init__()\n        print(f'Model: {model_name}')\n        self.extract =  timm.create_model(model_name, \n                                          pretrained=pretrained,\n                                          in_chans = 1)\n        self.replace_relu_to_silu(self.extract)\n        self.myfc = nn.Linear(1000, kmeans_clusters)\n        \n    def replace_relu_to_silu(self, model):\n        for child_name, child in model.named_children():\n            if isinstance(child, nn.ReLU):\n                setattr(model, child_name, nn.SiLU(inplace=True))\n            else:\n                self.replace_relu_to_silu(child)\n    \n    def forward(self, x):\n        x = self.extract(x)\n        x = nn.Tanh()(x)\n        x = self.myfc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:49:15.479821Z","iopub.execute_input":"2021-07-20T00:49:15.480191Z","iopub.status.idle":"2021-07-20T00:49:15.490007Z","shell.execute_reply.started":"2021-07-20T00:49:15.480158Z","shell.execute_reply":"2021-07-20T00:49:15.489077Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LabelSmoothing(nn.Module):\n    \"\"\"NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.0):\n        \"\"\"Constructor for the LabelSmoothing module.\n        :param smoothing: label smoothing factor\n        \"\"\"\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n        nll_loss = -logprobs.gather(dim=-1, index=target.unsqueeze(1))\n        nll_loss = nll_loss.squeeze(1)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:49:25.928785Z","iopub.execute_input":"2021-07-20T00:49:25.929118Z","iopub.status.idle":"2021-07-20T00:49:25.937274Z","shell.execute_reply.started":"2021-07-20T00:49:25.929086Z","shell.execute_reply":"2021-07-20T00:49:25.936337Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def feature_evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_outputs = []\n    with torch.no_grad():\n        for data in tqdm(data_loader, position=0, leave=True, desc='Pesudo Targeting'):\n            images, targets = data\n            images = images.to(device, dtype=torch.float)\n            \n            output = model(images)\n            output = output.detach().cpu().numpy().tolist()\n            final_outputs.extend(output)\n        \n    return final_outputs","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:49:32.743958Z","iopub.execute_input":"2021-07-20T00:49:32.744277Z","iopub.status.idle":"2021-07-20T00:49:32.750072Z","shell.execute_reply.started":"2021-07-20T00:49:32.744249Z","shell.execute_reply":"2021-07-20T00:49:32.748985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, criterion, device):\n    model.train()\n    \n    training_loss = 0\n    train_bar = tqdm(data_loader, position=0, leave=True, desc='Training')\n    for idx, data in enumerate(train_bar):\n        images, targets = data\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.int64)\n\n        optimizer.zero_grad()\n        output = model(images)\n        \n        loss = criterion(output, targets)\n        loss.backward()\n        training_loss += loss.item()\n        \n        train_bar.set_description(f'Training, loss: {training_loss/(idx + 1)}')  \n        optimizer.step()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:49:42.139316Z","iopub.execute_input":"2021-07-20T00:49:42.139677Z","iopub.status.idle":"2021-07-20T00:49:42.14743Z","shell.execute_reply.started":"2021-07-20T00:49:42.139644Z","shell.execute_reply":"2021-07-20T00:49:42.146175Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device('cpu')\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:49:50.387158Z","iopub.execute_input":"2021-07-20T00:49:50.387474Z","iopub.status.idle":"2021-07-20T00:49:50.437725Z","shell.execute_reply.started":"2021-07-20T00:49:50.387446Z","shell.execute_reply":"2021-07-20T00:49:50.436905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Batch_Size = 64\ncriterion = LabelSmoothing(smoothing = 0.1)\npca = IncrementalPCA(n_components=50, whiten=True)\nkmeans = MiniBatchKMeans(n_clusters=100, batch_size=4096, init_size=300)\ndf = pd.concat([train_df,test_df]).reset_index(drop=True)\n\nmodel = models(pretrained = True)\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n\nfor epoch in range(5):\n    for trn_df in tqdm(np.array_split(df, 5)):\n        cluster_dataset = setiDataset(trn_df)\n        cluster_loader= torch.utils.data.DataLoader(cluster_dataset, batch_size=Batch_Size, shuffle=False)\n    \n        features = feature_evaluate(cluster_loader, model, device)\n        reduced = pca.fit_transform(features)\n        pesudo_targets = list(kmeans.fit_predict(reduced))\n    \n        train_dataset = setiDataset(trn_df, pesudo_targets=pesudo_targets)\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\n        for sub_epoch in range(3):\n            train(train_loader, model, optimizer, criterion, device)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T00:51:36.520116Z","iopub.execute_input":"2021-07-20T00:51:36.520427Z","iopub.status.idle":"2021-07-20T02:35:41.833279Z","shell.execute_reply.started":"2021-07-20T00:51:36.520398Z","shell.execute_reply":"2021-07-20T02:35:41.826777Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\ncluster_dataset = setiDataset(df)\ncluster_loader= torch.utils.data.DataLoader(cluster_dataset, batch_size=Batch_Size, shuffle=False)\n    \nfeatures = feature_evaluate(cluster_loader, model, device)\nreduced = pca.fit_transform(features)\npesudo_targets = list(kmeans.fit_predict(reduced))\n","metadata":{"execution":{"iopub.status.busy":"2021-07-20T02:35:45.241121Z","iopub.execute_input":"2021-07-20T02:35:45.241441Z","iopub.status.idle":"2021-07-20T02:59:36.20831Z","shell.execute_reply.started":"2021-07-20T02:35:45.241412Z","shell.execute_reply":"2021-07-20T02:59:36.202239Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['cluster'] = pesudo_targets\n\nsns.histplot(data=df, x='cluster', hue='target', multiple=\"stack\")\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T03:00:07.859324Z","iopub.execute_input":"2021-07-20T03:00:07.859674Z","iopub.status.idle":"2021-07-20T03:00:09.430187Z","shell.execute_reply.started":"2021-07-20T03:00:07.859645Z","shell.execute_reply":"2021-07-20T03:00:09.429383Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_cluster(cluster, df, limit=16):\n    tmp_df = df[df.cluster == cluster].reset_index(drop=True)\n    dataset = setiDataset(tmp_df, isVisual=True)\n    \n    fig = plt.figure(figsize=(15, 10))\n    for i in range(limit):\n        image, _ = dataset[i]\n        fig.add_subplot(4, 4, i+1)\n        plt.imshow(image, aspect='auto')\n    fig.suptitle(f'cluster: {cluster}',fontsize=20)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-20T03:00:35.710956Z","iopub.execute_input":"2021-07-20T03:00:35.711347Z","iopub.status.idle":"2021-07-20T03:00:35.720067Z","shell.execute_reply.started":"2021-07-20T03:00:35.711311Z","shell.execute_reply":"2021-07-20T03:00:35.719109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(100):\n    show_cluster(i,df)","metadata":{"execution":{"iopub.status.busy":"2021-07-20T03:00:57.943548Z","iopub.execute_input":"2021-07-20T03:00:57.943989Z","iopub.status.idle":"2021-07-20T03:04:52.391555Z","shell.execute_reply.started":"2021-07-20T03:00:57.943946Z","shell.execute_reply":"2021-07-20T03:04:52.390799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}