{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\n\nfrom sklearn import metrics\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport timm\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset,DataLoader,random_split","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-03T20:26:30.899624Z","iopub.execute_input":"2021-06-03T20:26:30.900137Z","iopub.status.idle":"2021-06-03T20:26:32.680273Z","shell.execute_reply.started":"2021-06-03T20:26:30.900096Z","shell.execute_reply":"2021-06-03T20:26:32.679134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"continued the SETI-test1.\n\nI thought it would more nice modify residual layer to auto-encoder layer.\n\npair (0,1), (2,3), (4,5) 2 images as one set in Encoder.","metadata":{}},{"cell_type":"code","source":"def dataframe(df, istrain=True):\n    if istrain:\n        mode = 'train'\n    else:\n        mode = 'test'\n    df['filepath'] = df.id.apply(lambda x: '../input/seti-breakthrough-listen/'+ f'{mode}/'+str(x[0])+f'/{x}.npy')\n    return df\ntest_df = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ntest_df = dataframe(test_df, istrain=False)\ntest_df['target'] = 0\ntrain_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntrain_df = dataframe(train_df)\ntrain_df.head(2)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:32.682097Z","iopub.execute_input":"2021-06-03T20:26:32.682485Z","iopub.status.idle":"2021-06-03T20:26:32.81212Z","shell.execute_reply.started":"2021-06-03T20:26:32.682457Z","shell.execute_reply":"2021-06-03T20:26:32.811046Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class setiDataset(Dataset):\n    def __init__(self, df, transform = None): \n        self.df = df\n        self.transform = transform\n    \n    def fileinfo(self, idx):\n        return self.df.filepath.iloc[idx], self.df.target.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath).astype('float32')\n        return image\n    \n    def __getitem__(self, idx):\n        filepath, target = self.fileinfo(idx)\n        image = self.loadfile(filepath)\n        return  torch.tensor(image, dtype=torch.float), torch.tensor(target, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:34.331879Z","iopub.execute_input":"2021-06-03T20:26:34.332207Z","iopub.status.idle":"2021-06-03T20:26:34.339636Z","shell.execute_reply.started":"2021-06-03T20:26:34.332175Z","shell.execute_reply":"2021-06-03T20:26:34.338676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Encoder\nclass ConvBlock(nn.Module):\n    def __init__(self, in_channels, out_channels, kernel_size):\n        super().__init__()\n        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, padding = 1 if kernel_size == 3 else 0, bias=False)\n        self.bn = nn.BatchNorm2d(out_channels)\n        self.vals = nn.Parameter(torch.zeros(out_channels)) \n        nn.init.kaiming_normal_(self.conv.weight, mode='fan_in', nonlinearity='leaky_relu')\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = F.leaky_relu(x, 0.1)\n        x = self.bn(x)\n        x += self.vals.view(1, self.bn.num_features, 1, 1).expand_as(x)\n        x = x * torch.tanh(F.softplus(x))\n        return x\n\nclass ResBlock(nn.Module):\n    def __init__(self, in_channels: int, out_channels: int):\n        super().__init__()\n        self.conv1 = ConvBlock(in_channels, out_channels, 3)\n        self.conv2 = ConvBlock(out_channels, out_channels, 3)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = x * torch.tanh(F.softplus(x))\n        return x\n    \nclass Encoder(nn.Module):\n    def __init__(self, in_channels = 2, res_level = 4):\n        super(Encoder,self).__init__()\n        self.res_layer = nn.Sequential(\n            *[ResBlock(in_channels, in_channels) for _ in range(res_level)]\n        )\n    \n    def forward(self, x):\n        x1 = x[:,:2,...]\n        x2 = x[:,2:4,...]\n        x3 = x[:,4:,...]\n        \n        x1 = self.res_layer(x1)\n        x2 = self.res_layer(x2)\n        x3 = self.res_layer(x3)\n        #maybe it would be effective using channelwise \n        \n        x = torch.cat([x1,x2,x3], dim = 1)\n        return x    ","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:35.931649Z","iopub.execute_input":"2021-06-03T20:26:35.93199Z","iopub.status.idle":"2021-06-03T20:26:35.944725Z","shell.execute_reply.started":"2021-06-03T20:26:35.931958Z","shell.execute_reply":"2021-06-03T20:26:35.943637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class effModel(nn.Module):\n    def __init__(self, in_chans = 6, num_classes = 1, pretrained=True):\n        super(effModel,self).__init__()\n        \n        self.model = timm.create_model('efficientnet_b0', \n                                       in_chans=in_chans, \n                                       num_classes=num_classes,\n                                       pretrained=pretrained)\n    \n    def forward(self, x):\n        x = self.model(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:37.38188Z","iopub.execute_input":"2021-06-03T20:26:37.382211Z","iopub.status.idle":"2021-06-03T20:26:37.388175Z","shell.execute_reply.started":"2021-06-03T20:26:37.382179Z","shell.execute_reply":"2021-06-03T20:26:37.386953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, encoder, model, optimizer, device):\n    model.train()\n    encoder.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        images, targets = data\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        def closure():\n            optimizer.zero_grad()\n            encode = encoder(images)\n            output = model(encode)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1,1))\n            loss += 0.15*nn.L1Loss()(encode,images)\n            loss.backward()\n            return loss\n        optimizer.step(closure)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:38.051724Z","iopub.execute_input":"2021-06-03T20:26:38.052056Z","iopub.status.idle":"2021-06-03T20:26:38.0583Z","shell.execute_reply.started":"2021-06-03T20:26:38.052026Z","shell.execute_reply":"2021-06-03T20:26:38.057476Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(data_loader, encoder, model, device):\n    model.eval()\n    encoder.eval()\n    \n    final_targets = []\n    final_outputs = []\n    validate_losses = 0\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = encoder(images)\n            output = model(output)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            validate_losses += loss.item()\n\n\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n    return final_outputs, final_targets, validate_losses/len(data_loader)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:39.591326Z","iopub.execute_input":"2021-06-03T20:26:39.591662Z","iopub.status.idle":"2021-06-03T20:26:39.599021Z","shell.execute_reply.started":"2021-06-03T20:26:39.59163Z","shell.execute_reply":"2021-06-03T20:26:39.597889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def submission(data_loader, encoder, model, device):\n    model.eval()\n    encoder.eval()\n    \n    final_outputs = []\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            \n            output = encoder(images)\n            output = model(output)\n            output = output.detach().cpu().numpy().tolist()\n            final_outputs.extend(output)\n    return final_outputs","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:41.121919Z","iopub.execute_input":"2021-06-03T20:26:41.122242Z","iopub.status.idle":"2021-06-03T20:26:41.131207Z","shell.execute_reply.started":"2021-06-03T20:26:41.122212Z","shell.execute_reply":"2021-06-03T20:26:41.130198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device('cpu')\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:26:42.562073Z","iopub.execute_input":"2021-06-03T20:26:42.562443Z","iopub.status.idle":"2021-06-03T20:26:42.593569Z","shell.execute_reply.started":"2021-06-03T20:26:42.562412Z","shell.execute_reply":"2021-06-03T20:26:42.592403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Batch_Size = 16\ninit_dataset = setiDataset(train_df)\nlengths = [int(len(init_dataset)*0.8), int(len(init_dataset)*0.2)]\n\ntrain_dataset, valid_dataset = random_split(init_dataset, lengths)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size, shuffle=False)\n\nencoder = Encoder()\nencoder.to(device)\nmodel = effModel()\nmodel.to(device)\n\nparams = list(model.parameters()) + list(encoder.parameters())\noptimizer=  torch.optim.Adam(params, lr=1e-4, eps=1e-5)\n\nfor epoch in range(10):\n    print(epoch)\n    train(train_loader, encoder, model, optimizer, device)\n    valid_pred, target, valid_loss = evaluate(valid_loader, encoder, model, device)\n    roc_auc = metrics.roc_auc_score(target, valid_pred)\n    print(f\"Epoch={epoch}, Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image, target = setiDataset(train_df[train_df.target==1].reset_index(drop=True))[1028]\n\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('original, target:1')\n\nimage = image.unsqueeze(dim=0).to(device)\nimage = encoder(image)\nimage = image.to('cpu').view(6,273,256)\nimage = image.detach().numpy()\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('encoder, target:1')\n\nimage, target = setiDataset(train_df[train_df.target==1].reset_index(drop=True))[512]\n\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('original, target:1')\n\nimage = image.unsqueeze(dim=0).to(device)\nimage = encoder(image)\nimage = image.to('cpu').view(6,273,256)\nimage = image.detach().numpy()\nplt.figure(figsize=(16,8))\nplt.subplot(2,3,1)\nplt.imshow(image[0], aspect='auto')\nplt.subplot(2,3,2)\nplt.imshow(image[2], aspect='auto')\nplt.subplot(2,3,3)\nplt.imshow(image[4], aspect='auto')\nplt.show()\nprint('encoder, target:1')","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:28:14.470917Z","iopub.execute_input":"2021-06-03T20:28:14.471256Z","iopub.status.idle":"2021-06-03T20:28:15.343456Z","shell.execute_reply.started":"2021-06-03T20:28:14.471225Z","shell.execute_reply":"2021-06-03T20:28:15.342468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1+np.exp(-x))\n\ntest_dataset = setiDataset(test_df)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=Batch_Size, shuffle=False)\npred = submission(test_loader, encoder, model, device)\nsub = test_df[['id']].copy()\nsub['target'] = sigmoid(np.array(pred).flatten())\nsub.to_csv('submission.csv', index=None)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-03T20:27:08.54009Z","iopub.status.idle":"2021-06-03T20:27:08.540649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}