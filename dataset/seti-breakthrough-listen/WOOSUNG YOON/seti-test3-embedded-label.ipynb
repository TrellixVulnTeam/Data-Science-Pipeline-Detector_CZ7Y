{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nfrom glob import glob\nimport pickle\n\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm.notebook import tqdm\n\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms\nimport itertools","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-08T03:02:47.347724Z","iopub.execute_input":"2021-06-08T03:02:47.348033Z","iopub.status.idle":"2021-06-08T03:02:51.99899Z","shell.execute_reply.started":"2021-06-08T03:02:47.347956Z","shell.execute_reply":"2021-06-08T03:02:51.99814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test for label values. <br>\n(1) embeded label <br>\n(2) label smoothing.\n","metadata":{}},{"cell_type":"markdown","source":"I thought if the model is continuous, zero-image has 0 label output. <br>\nAfter that, when the image has a needle, the output moves to label one from 0.<br>\nEmpty -> 0.5 -> 1 (continous output)\n\nTo apply this idea, <br>\nI believed it is required to give an additional dimension to the model's output. \n\ni.e. label = 0 -> label = (0,0) and label = 1 -> label = (1,1) <br>\n\n- And we may consider models output is a two-dimensional vectors.<br>\n(1) 2d output = (x, y).<br>\n(2) Calculate distance between d1 = (x^2 + y^2) and d2 = ((x-1)^2 + (y-1)^2) <br>\n(3) Taking log_softmax function on (d1, d2). <br>\n(4) Apply BCE Loss <br>\n\nI thought it may nice, <br>\nsince the model can classify zero-images to (0,0) output. <br>\nI hope the decision boundary have eliptic shape.","metadata":{}},{"cell_type":"markdown","source":"Everything is same as a baseline. <br>\n(add calculate distance term on (1) loss function and (2) evaluate function)","metadata":{}},{"cell_type":"code","source":"def getpath(x, mode):\n    return f'../input/seti-breakthrough-listen/{mode}/{x[0]}/{x}.npy'\n\ndef getpath_train(x, mode):\n    return f'../input/seti-pytorch-data/train_images/{x}.npz'\n\ntest_df = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ntest_df['filepath'] = test_df.id.apply(lambda x: getpath(x, 'test'))\n\ntrain_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntrain_df['filepath'] = train_df.id.apply(lambda x: getpath_train(x, 'train'))\nprint(train_df.head())\nprint(test_df.head())","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:13.134028Z","iopub.execute_input":"2021-06-08T03:04:13.134409Z","iopub.status.idle":"2021-06-08T03:04:13.386875Z","shell.execute_reply.started":"2021-06-08T03:04:13.134374Z","shell.execute_reply":"2021-06-08T03:04:13.386048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class setiDataset_train(Dataset):\n    def __init__(self, df, transform = None): \n        self.df = df\n        self.transform = transform\n    \n    def fileinfo(self, idx):\n        return self.df.filepath.iloc[idx], self.df.target.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath)['im'].astype('float')\n        return image\n    \n    def __getitem__(self, idx):\n        filepath, target = self.fileinfo(idx)\n        image = self.loadfile(filepath)\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n            return image , torch.tensor(target, dtype=torch.int64)\n        \n        image = ToTensorV2()(image=image)['image']\n        return  image , torch.tensor(target, dtype=torch.int64)\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:14.137629Z","iopub.execute_input":"2021-06-08T03:04:14.137908Z","iopub.status.idle":"2021-06-08T03:04:14.146938Z","shell.execute_reply.started":"2021-06-08T03:04:14.137882Z","shell.execute_reply":"2021-06-08T03:04:14.146149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class setiDataset_test(Dataset):\n    def __init__(self, df): \n        self.df = df\n    \n    def fileinfo(self, idx):\n        return self.df.filepath.iloc[idx], self.df.target.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath).astype('float16')\n        return image\n    \n    def __getitem__(self, idx):\n        filepath, target = self.fileinfo(idx)\n        image = self.loadfile(filepath)\n        image = np.vstack([image[0], image[2], image[4]]).transpose()\n        image = image.astype('float')\n        \n        image = ToTensorV2()(image=image)['image']\n        return  image , torch.tensor(target, dtype=torch.int64)\n    \n    def __len__(self):\n        return len(self.df)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:15.273677Z","iopub.execute_input":"2021-06-08T03:04:15.27394Z","iopub.status.idle":"2021-06-08T03:04:15.280825Z","shell.execute_reply.started":"2021-06-08T03:04:15.273913Z","shell.execute_reply":"2021-06-08T03:04:15.279958Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.VerticalFlip(p=0.1),\n    A.HorizontalFlip(p=0.1),\n    ToTensorV2()\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:16.080826Z","iopub.execute_input":"2021-06-08T03:04:16.081084Z","iopub.status.idle":"2021-06-08T03:04:16.087042Z","shell.execute_reply.started":"2021-06-08T03:04:16.081059Z","shell.execute_reply":"2021-06-08T03:04:16.086218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class models(nn.Module):\n    def __init__(self,model_name = 'efficientnet_b0', pretrained = False):\n        super(models,self).__init__()\n        print(f'Model: {model_name}')\n        self.backbone =  timm.create_model(model_name, pretrained=pretrained, in_chans = 1, num_classes = 2)\n        \n    def forward(self, x):\n        x = self.backbone(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:16.873563Z","iopub.execute_input":"2021-06-08T03:04:16.873807Z","iopub.status.idle":"2021-06-08T03:04:16.878683Z","shell.execute_reply.started":"2021-06-08T03:04:16.873782Z","shell.execute_reply":"2021-06-08T03:04:16.877882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"LabelSmoothing Source: https://github.com/NVIDIA/DeepLearningExamples\n\nJust add distance values d1, d2 which represent <br>\nd1 = distance between (0,0) and x, <br>\nd2 = distance between (1,1) and x. ","metadata":{}},{"cell_type":"code","source":"class LabelSmoothing(nn.Module):\n    \"\"\"NLL loss with label smoothing.\n    \"\"\"\n    def __init__(self, smoothing=0.0):\n        \"\"\"Constructor for the LabelSmoothing module.\n        :param smoothing: label smoothing factor\n        \"\"\"\n        super(LabelSmoothing, self).__init__()\n        self.confidence = 1.0 - smoothing\n        self.smoothing = smoothing\n\n    def forward(self, x, target):\n        \n        # 2d eliptic distance\n        d1 = torch.sum(x**2, dim =-1).view(-1,1)\n        d2 = torch.sum((x-1)**2, dim = -1).view(-1,1)\n        x  = torch.cat([d2,d1],dim = -1)\n        \n        logprobs = torch.nn.functional.log_softmax(x, dim=-1)\n        nll_loss = -logprobs.gather(dim=-1, index=target.view(-1,1))\n        nll_loss = nll_loss.squeeze(1)\n        smooth_loss = -logprobs.mean(dim=-1)\n        loss = self.confidence * nll_loss + self.smoothing * smooth_loss\n        return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:19.042963Z","iopub.execute_input":"2021-06-08T03:04:19.043238Z","iopub.status.idle":"2021-06-08T03:04:19.050675Z","shell.execute_reply.started":"2021-06-08T03:04:19.043212Z","shell.execute_reply":"2021-06-08T03:04:19.049682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, criterion, device):\n    model.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        images, targets = data\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.int64)\n        def closure():\n            optimizer.zero_grad()\n            output = model(images)\n            loss = criterion(output, targets)\n            loss.backward()\n            return loss\n        optimizer.step(closure)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:25.305247Z","iopub.execute_input":"2021-06-08T03:04:25.305618Z","iopub.status.idle":"2021-06-08T03:04:25.313397Z","shell.execute_reply.started":"2021-06-08T03:04:25.305579Z","shell.execute_reply":"2021-06-08T03:04:25.312634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(data_loader, criterion, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    validate_losses = 0\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.int64)\n            \n            x = model(images)\n            loss = criterion(x, targets)\n            validate_losses += loss.item()\n\n            d1 = torch.sum(x**2, dim =-1).view(-1,1)\n            d2 = torch.sum((x-1)**2, dim = -1).view(-1,1)\n            x  = torch.cat([d2,d1],dim = -1)\n            x = torch.nn.functional.softmax(x, dim=-1)\n            x = x[:,1]\n        \n            x = x.detach().cpu().numpy().tolist()\n            targets = targets.detach().cpu().numpy().tolist()\n            \n            final_outputs.extend(x)\n            final_targets.extend(targets)\n        \n    roc_auc = metrics.roc_auc_score(final_targets, final_outputs)\n    \n    return validate_losses/len(data_loader), roc_auc","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:28.648724Z","iopub.execute_input":"2021-06-08T03:04:28.649024Z","iopub.status.idle":"2021-06-08T03:04:28.658279Z","shell.execute_reply.started":"2021-06-08T03:04:28.648994Z","shell.execute_reply":"2021-06-08T03:04:28.657083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sub_evaluate(data_loader, device):\n    model.eval()\n    \n    final_outputs = []\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            images, targets = data\n\n            images = images.to(device, dtype=torch.float)\n            \n            x = model(images)\n            x = x.detach().cpu().numpy()\n            \n            final_outputs.append(x)\n    final_outputs = np.concatenate(final_outputs)\n    return final_outputs","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:35.956165Z","iopub.execute_input":"2021-06-08T03:04:35.956645Z","iopub.status.idle":"2021-06-08T03:04:35.96331Z","shell.execute_reply.started":"2021-06-08T03:04:35.956607Z","shell.execute_reply":"2021-06-08T03:04:35.96208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"- The output of models <br>\n(x,y) coordinate. (I hope it have eliptical decision boundary.)\n\nUsing distance of two points (0,0), (1,1) to get the AUC .\n","metadata":{}},{"cell_type":"code","source":"Batch_Size = 20\nfold = 0\ncriterion = LabelSmoothing(smoothing=0.1)\ndevice = torch.device(\"cuda\")\n\nmodel = models(model_name = 'efficientnet_b0', pretrained = True)\nmodel.to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=3e-4, eps=1e-5, weight_decay=1e-6)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:04:41.390074Z","iopub.execute_input":"2021-06-08T03:04:41.390411Z","iopub.status.idle":"2021-06-08T03:04:47.275766Z","shell.execute_reply.started":"2021-06-08T03:04:41.390377Z","shell.execute_reply":"2021-06-08T03:04:47.274899Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df['fold'] = np.random.randint(low=0, high = 3, size = len(train_df))\ntrain_fold = train_df[train_df.fold != fold].reset_index(drop=True)\nvalid_fold = train_df[train_df.fold == fold].reset_index(drop=True)\n\ntrain_dataset = setiDataset_train(train_fold, transform = train_transform)\ntrain_loader= torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=True)\nvalid_dataset = setiDataset_train(valid_fold)\nvalid_loader= torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:05:01.567989Z","iopub.execute_input":"2021-06-08T03:05:01.568306Z","iopub.status.idle":"2021-06-08T03:05:01.597629Z","shell.execute_reply.started":"2021-06-08T03:05:01.568274Z","shell.execute_reply":"2021-06-08T03:05:01.596832Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"hold-out validation (2/3: training, 1/3 validate)","metadata":{}},{"cell_type":"code","source":"for epoch in range(3):\n    print(epoch)\n    train(train_loader, model, optimizer, criterion, device)\n    loss, roc_auc = evaluate(valid_loader, criterion, device)\n    print(f'Epoch = {epoch}, Valid Loss = {loss}, AUC = {roc_auc}')","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:05:04.006173Z","iopub.execute_input":"2021-06-08T03:05:04.006512Z","iopub.status.idle":"2021-06-08T03:05:35.138173Z","shell.execute_reply.started":"2021-06-08T03:05:04.00648Z","shell.execute_reply":"2021-06-08T03:05:35.135737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"In my opinion, giving additional dimensions to the 1D label <br>\ncan provide continuity on the decision boundary.\n\nI will check this by visualization of output vectors.","metadata":{}},{"cell_type":"code","source":"# visualize 2-dim output\nr_dataset = setiDataset_train(train_df)\nr_loader= torch.utils.data.DataLoader(r_dataset, batch_size=Batch_Size, shuffle=False)\n\nr_predict =  sub_evaluate(r_loader, device)\ntrain_df['pred_x'] = r_predict[:,0]\ntrain_df['pred_y'] = r_predict[:,1]\n\n\nt_dataset = setiDataset_test(test_df)\nt_loader= torch.utils.data.DataLoader(t_dataset, batch_size=Batch_Size, shuffle=False)\n\nt_predict =  sub_evaluate(t_loader, device)\ntest_df['pred_x'] = t_predict[:,0]\ntest_df['pred_y'] = t_predict[:,1]","metadata":{"execution":{"iopub.status.busy":"2021-06-08T03:05:35.139475Z","iopub.status.idle":"2021-06-08T03:05:35.140025Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\n\nsns.scatterplot(data=train_df, x=\"pred_x\", y=\"pred_y\", hue=\"target\", style=\"target\", size=0.01 ,alpha=0.9).legend(loc=4)\nplt.xlim(-5, 5)\nplt.ylim(-5, 5)\nplt.axhline(y=1, color='r', linewidth=1)\nplt.axvline(x=1, color='r', linewidth=1)\nplt.axhline(y=0, color='g', linewidth=1)\nplt.axvline(x=0, color='g', linewidth=1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T02:26:47.867685Z","iopub.execute_input":"2021-06-08T02:26:47.868018Z","iopub.status.idle":"2021-06-08T02:26:48.887813Z","shell.execute_reply.started":"2021-06-08T02:26:47.867987Z","shell.execute_reply":"2021-06-08T02:26:48.886988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.scatterplot(data=test_df, x=\"pred_x\", y=\"pred_y\", size=0.01 ,alpha=0.9).legend(loc=4)\nplt.xlim(-5, 5)\nplt.ylim(-5, 5)\nplt.axhline(y=1, color='r', linewidth=1)\nplt.axvline(x=1, color='r', linewidth=1)\nplt.axhline(y=0, color='g', linewidth=1)\nplt.axvline(x=0, color='g', linewidth=1)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-08T02:27:33.217537Z","iopub.execute_input":"2021-06-08T02:27:33.217882Z","iopub.status.idle":"2021-06-08T02:27:33.865955Z","shell.execute_reply.started":"2021-06-08T02:27:33.217851Z","shell.execute_reply":"2021-06-08T02:27:33.86507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I have a feeling something is wrong with the labels 0 and 1. <br>\nMaybe I can change (2,-3) and (4, -1) next time.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}