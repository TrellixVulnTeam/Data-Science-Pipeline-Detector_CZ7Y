{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# I propose a baseline of \n# CycleGAN + cspdarknet53 for image classification.\n\n\nI use following materials.\n* Cyclegan's code: https://github.com/Lornatang/CycleGAN-PyTorch (unofficial code) and\n> @inproceedings{CycleGAN2017,\n>   title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networkss},\n>   author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},\n>   booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},\n>   year={2017}\n> }\n* Tensorflow tutorial: https://www.tensorflow.org/tutorials/generative/cyclegan?hl=ko.\n\n* timm pytorch image model with several kaggle notebook.","metadata":{}},{"cell_type":"markdown","source":"![img](https://www.tensorflow.org/tutorials/generative/images/horse2zebra_1.png/)","metadata":{}},{"cell_type":"markdown","source":"At first time, I hope CycleGan do something like this.","metadata":{}},{"cell_type":"markdown","source":"It is not working well now. AUC value oscilate in low value and not converge.\n\nBut it is a prototype. My aim in this project is to update this code.","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nfrom glob import glob\n\nimport pickle\nimport functools\nimport itertools\nimport random\n\nimport json\nimport numpy as np\nimport pandas as pd\nimport random\nimport math\n\nimport cv2\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom skimage.draw import line_aa\nfrom tqdm import tqdm\n\nimport timm\nfrom torch.utils.data import Dataset, DataLoader\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:49:51.889551Z","iopub.execute_input":"2021-05-25T11:49:51.890089Z","iopub.status.idle":"2021-05-25T11:49:53.651014Z","shell.execute_reply.started":"2021-05-25T11:49:51.890002Z","shell.execute_reply":"2021-05-25T11:49:53.649804Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntrain_df['filepath'] = train_df.id.apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')\ntrain_df_0 = train_df[train_df.target==0].copy().reset_index(drop=True)\ntrain_df_1 = train_df[train_df.target==1].copy().reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:49:53.662428Z","iopub.execute_input":"2021-05-25T11:49:53.664398Z","iopub.status.idle":"2021-05-25T11:49:53.760401Z","shell.execute_reply.started":"2021-05-25T11:49:53.664354Z","shell.execute_reply":"2021-05-25T11:49:53.7596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device('cpu')\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:49:53.764444Z","iopub.execute_input":"2021-05-25T11:49:53.766441Z","iopub.status.idle":"2021-05-25T11:49:53.813712Z","shell.execute_reply.started":"2021-05-25T11:49:53.7664Z","shell.execute_reply":"2021-05-25T11:49:53.812826Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class setiDataset(Dataset):\n    def __init__(self, df_0, df_1, transform = None): \n        self.df_0 = df_0\n        self.df_1 = df_1\n        self.transform = transform\n    \n    def fileinfo(self, idx):\n        return self.df_0.filepath.iloc[idx], self.df_1.filepath.iloc[idx]\n    \n    def loadfile(self, filepath):\n        image = np.load(filepath)\n        image = np.vstack([image[0],image[2],image[4]]).astype('float32')\n        image = cv2.resize(image, dsize=(260, 320), interpolation=cv2.INTER_AREA).transpose(1,0)\n        image = np.stack([image,image,image])\n        return image\n    \n    \n    def __getitem__(self, idx):\n        filepath_0, filepath_1 = self.fileinfo(idx)\n        image_0 = self.loadfile(filepath_0)\n        image_1 = self.loadfile(filepath_1)\n        \n        if self.transform:\n            image_0 = image_0.transpose(1,2,0)\n            augmented = self.transform(image=image_0)\n            image_0 = augmented['image']\n            \n            image_1 = image_1.transpose(1,2,0)\n            augmented = self.transform(image=image_1)\n            image_1 = augmented['image']\n            return image_0, image_1, torch.tensor(0, dtype=torch.long), torch.tensor(1, dtype=torch.long)\n\n        return  torch.tensor(image_0, dtype=torch.float), torch.tensor(image_1, dtype=torch.float), torch.tensor(0, dtype=torch.long), torch.tensor(1, dtype=torch.long)\n    \n    def __len__(self):\n        return len(self.df_1)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:49:56.216968Z","iopub.execute_input":"2021-05-25T11:49:56.217412Z","iopub.status.idle":"2021-05-25T11:49:56.230684Z","shell.execute_reply.started":"2021-05-25T11:49:56.217376Z","shell.execute_reply":"2021-05-25T11:49:56.229555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_transform = A.Compose([\n    A.GridDistortion(p=0.75),\n    A.OneOf([\n        A.VerticalFlip(p=1),\n        A.HorizontalFlip(p=1)\n    ], p=0.5),\n    A.ShiftScaleRotate(shift_limit=0.15, scale_limit=0.05, rotate_limit=0, p=0.75),\n    A.pytorch.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:49:58.097387Z","iopub.execute_input":"2021-05-25T11:49:58.097769Z","iopub.status.idle":"2021-05-25T11:49:58.102925Z","shell.execute_reply.started":"2021-05-25T11:49:58.097735Z","shell.execute_reply":"2021-05-25T11:49:58.102016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above code is for augmentation image.<br>\nI apply agumentation on image using albumentations libarary.","metadata":{}},{"cell_type":"code","source":"# for visualization, not training.\nSD = setiDataset(train_df_0, train_df_1)\nSD_aug = setiDataset(train_df_0, train_df_1, transform = train_transform)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:50:02.279377Z","iopub.execute_input":"2021-05-25T11:50:02.279737Z","iopub.status.idle":"2021-05-25T11:50:02.283845Z","shell.execute_reply.started":"2021-05-25T11:50:02.279704Z","shell.execute_reply":"2021-05-25T11:50:02.282865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(2):\n    a = np.random.randint(low=0, high= len(SD))\n    b = np.random.randint(low=0, high= len(SD))\n    image1, _, _, _ = SD[a]\n    image2, _, _, _ = SD_aug[a]\n    plt.figure(figsize=(20,10))\n    plt.subplot(2,2,1)\n    plt.title('Target 0 Image, Original', fontsize=12)\n    plt.imshow(image1[0],aspect='auto')\n    plt.subplot(2,2,2)\n    plt.title('Target 0 Image, Augmented', fontsize=12)\n    plt.imshow(image2[0],aspect='auto')\n    plt.show()\nprint(f'target0. {image1.shape}')\n\nfor i in range(2):\n    a = np.random.randint(low=0, high= len(SD))\n    b = np.random.randint(low=0, high= len(SD))\n    _, image1, _, _ = SD[a]\n    _, image2, _, _ = SD_aug[a]\n    _, image3, _, _ = SD_aug[b]\n    plt.figure(figsize=(20,10))\n    plt.subplot(2,2,1)\n    plt.title('Target 1 Image, Original', fontsize=12)\n    plt.imshow(image1[0],aspect='auto')\n    plt.subplot(2,2,2)\n    plt.title('Target 1 Image, Augmented', fontsize=12)\n    plt.imshow(image2[0],aspect='auto')\n    plt.show()\nprint(f'targe01. {image1.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:50:30.759085Z","iopub.execute_input":"2021-05-25T11:50:30.75944Z","iopub.status.idle":"2021-05-25T11:50:32.490467Z","shell.execute_reply.started":"2021-05-25T11:50:30.759407Z","shell.execute_reply":"2021-05-25T11:50:32.489532Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Images for training change slightly by using augmentation.\n\nAs a baseline, I use a cspdarknet53. <br>\nThe baseline model will check if the image is a needle or not.","metadata":{}},{"cell_type":"code","source":"class cspdarknet_baseline(nn.Module):\n    def __init__(self,model_name = 'cspdarknet53', pretrained = False):\n        super(cspdarknet_baseline,self).__init__()\n        print(f'Model: {model_name}')\n        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n        self.myfc_1 = nn.Linear(1000,1)\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.myfc_1(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:50:50.463253Z","iopub.execute_input":"2021-05-25T11:50:50.463598Z","iopub.status.idle":"2021-05-25T11:50:50.469803Z","shell.execute_reply.started":"2021-05-25T11:50:50.463549Z","shell.execute_reply":"2021-05-25T11:50:50.468618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = cspdarknet_baseline()\nmodel.load_state_dict(torch.load('../input/epoch5/epoch5.pt'))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:50:55.318326Z","iopub.execute_input":"2021-05-25T11:50:55.318695Z","iopub.status.idle":"2021-05-25T11:50:57.978268Z","shell.execute_reply.started":"2021-05-25T11:50:55.318656Z","shell.execute_reply":"2021-05-25T11:50:57.977279Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid(x):\n    return 1/(1+np.exp(-x))","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:18:05.92651Z","iopub.execute_input":"2021-05-25T16:18:05.926884Z","iopub.status.idle":"2021-05-25T16:18:05.932377Z","shell.execute_reply.started":"2021-05-25T16:18:05.92685Z","shell.execute_reply":"2021-05-25T16:18:05.93141Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_0, image_1, target0, target1 = SD[1]\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image_0[0], aspect='auto')\nimage_0 = torch.unsqueeze(image_0, dim=0)\ntarget0 = int(target0.item())\noutput = model(image_0).item()\noutput = sigmoid(output)\nplt.title(f'Target {target0}, Model value: {round(output,4)}', fontsize=12)\n\nplt.subplot(2,2,2)\nplt.imshow(image_1[0], aspect='auto')\nimage_1 = torch.unsqueeze(image_1, dim=0)\ntarget1 = int(target1.item())\noutput = model(image_1).item()\noutput = sigmoid(output)\nplt.title(f'Target {target1}, Model value: {round(output,4)}', fontsize=12)\nplt.show()\nprint(image_1.shape)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:51:49.449368Z","iopub.execute_input":"2021-05-25T11:51:49.449743Z","iopub.status.idle":"2021-05-25T11:51:50.852077Z","shell.execute_reply.started":"2021-05-25T11:51:49.449706Z","shell.execute_reply":"2021-05-25T11:51:50.846469Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The above value in pictures are the prediction of baseline model. <br>\nThe baseline model initially does not work well predict.","metadata":{}},{"cell_type":"markdown","source":"The blow fake image generator model is from\n\nhttps://github.com/Lornatang/CycleGAN-PyTorch\n> @inproceedings{CycleGAN2017,\n>   title={Unpaired Image-to-Image Translation using Cycle-Consistent Adversarial Networkss},\n>   author={Zhu, Jun-Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A},\n>   booktitle={Computer Vision (ICCV), 2017 IEEE International Conference on},\n>   year={2017}\n> }","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.main = nn.Sequential(\n            # Initial convolution block\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(3, 64, 7),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n\n            # Downsampling\n            nn.Conv2d(64, 128, 3, stride=2, padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(128, 256, 3, stride=2, padding=1),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True),\n\n            # Residual blocks\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n            ResidualBlock(256),\n\n            # Upsampling\n            nn.ConvTranspose2d(256, 128, 3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(128, 64, 3, stride=2, padding=1, output_padding=1),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n\n            # Output layer\n            nn.ReflectionPad2d(3),\n            nn.Conv2d(64, 3, 7),\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        return self.main(x)\n\n\nclass ResidualBlock(nn.Module):\n    def __init__(self, in_channels):\n        super(ResidualBlock, self).__init__()\n\n        self.res = nn.Sequential(nn.ReflectionPad2d(1),\n                                 nn.Conv2d(in_channels, in_channels, 3),\n                                 nn.InstanceNorm2d(in_channels),\n                                 nn.ReLU(inplace=True),\n                                 nn.ReflectionPad2d(1),\n                                 nn.Conv2d(in_channels, in_channels, 3),\n                                 nn.InstanceNorm2d(in_channels))\n\n    def forward(self, x):\n        return x + self.res(x)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:52:06.295914Z","iopub.execute_input":"2021-05-25T11:52:06.296261Z","iopub.status.idle":"2021-05-25T11:52:06.308438Z","shell.execute_reply.started":"2021-05-25T11:52:06.296227Z","shell.execute_reply":"2021-05-25T11:52:06.307379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find(\"Conv\") != -1:\n        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n    elif classname.find(\"BatchNorm\") != -1:\n        torch.nn.init.normal_(m.weight, 1.0, 0.02)\n        torch.nn.init.zeros_(m.bias)","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:52:07.625692Z","iopub.execute_input":"2021-05-25T11:52:07.626034Z","iopub.status.idle":"2021-05-25T11:52:07.632623Z","shell.execute_reply.started":"2021-05-25T11:52:07.626003Z","shell.execute_reply":"2021-05-25T11:52:07.631643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The generator has multiple residual block and convolution kernel.","metadata":{}},{"cell_type":"code","source":"Gen_0_t1 = Generator()\nGen_1_t0 = Generator()\nGen_0_t1.apply(weights_init)\nGen_1_t0.apply(weights_init)\nprint('Generator model is created')","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:52:20.873536Z","iopub.execute_input":"2021-05-25T11:52:20.873911Z","iopub.status.idle":"2021-05-25T11:52:21.133952Z","shell.execute_reply.started":"2021-05-25T11:52:20.873876Z","shell.execute_reply":"2021-05-25T11:52:21.132856Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The below is an image converted using a initial generator.","metadata":{}},{"cell_type":"code","source":"fake_image_1 = Gen_0_t1(image_1)\nfake_image_1 = fake_image_1.detach().numpy().reshape(3,260,320)\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image_1.reshape(3,260,320)[0], aspect='auto')\nplt.subplot(2,2,2)\nplt.imshow(fake_image_1[0], aspect='auto')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:52:23.46834Z","iopub.execute_input":"2021-05-25T11:52:23.468694Z","iopub.status.idle":"2021-05-25T11:52:25.12139Z","shell.execute_reply.started":"2021-05-25T11:52:23.468661Z","shell.execute_reply":"2021-05-25T11:52:25.120443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The shape of the input and output is the same. <br>\nSomething is destroyed now but the generator may trained during trainig step.","metadata":{}},{"cell_type":"markdown","source":"The following two training codes for the generator and the model, respectively.","metadata":{}},{"cell_type":"code","source":"def trainGenerator(data_loader, model, Gen_0_t1, Gen_1_t0, optimizer_G, device):\n    model.eval()\n    Gen_0_t1.train()\n    Gen_1_t0.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        image_0, image_1, target_0, target_1 = data\n        \n        image_0 = image_0.to(device, dtype=torch.float)\n        target_0 = target_0.to(device, dtype=torch.float)\n        image_1 = image_1.to(device, dtype=torch.float)\n        target_1 = target_1.to(device, dtype=torch.float)\n        \n        \n        optimizer_G.zero_grad()\n        \n        # Automorphism (Identity) loss\n        auto_image_1 = Gen_0_t1(image_1)\n        loss_identity_1 = nn.L1Loss()(auto_image_1, image_1) * 5.0\n        \n        \n        auto_image_0 = Gen_1_t0(image_0)\n        loss_identity_0 = nn.L1Loss()(auto_image_0, image_0) * 5.0\n        \n\n        # Generating loss\n        fake_image_1 = Gen_0_t1(image_0)\n        model_expect_fake_1 = model(fake_image_1)\n        model_expect_fake_1 = nn.Sigmoid()(model_expect_fake_1)\n        loss_GAN_0_t1 = nn.MSELoss()(model_expect_fake_1, target_1.view(-1,1))\n        \n        \n        fake_image_0 = Gen_1_t0(image_1)\n        model_expect_fake_0 = model(fake_image_0)\n        model_expect_fake_0 = nn.Sigmoid()(model_expect_fake_0)\n        loss_GAN_1_t0 = nn.MSELoss()(model_expect_fake_0, target_0.view(-1,1))\n        \n        \n        \n        # Cycle loss\n        recovered_image_0 = Gen_1_t0(fake_image_1)\n        loss_cycle_010 = nn.L1Loss()(recovered_image_0, image_0) * 10.0\n        \n\n        recovered_image_1 = Gen_1_t0(fake_image_0)\n        loss_cycle_101 = nn.L1Loss()(recovered_image_1, image_1) * 10.0\n\n\n        total_errG = loss_identity_1 + loss_identity_0 + loss_GAN_0_t1 + loss_GAN_1_t0 + loss_cycle_010 + loss_cycle_101\n        total_errG.backward()\n        \n        optimizer_G.step()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:52:34.486552Z","iopub.execute_input":"2021-05-25T11:52:34.4869Z","iopub.status.idle":"2021-05-25T11:52:34.499424Z","shell.execute_reply.started":"2021-05-25T11:52:34.486868Z","shell.execute_reply":"2021-05-25T11:52:34.498542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def trainModel(data_loader, model, optimizer, device):\n    model.train()\n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        image_0, image_1, target_0, target_1 = data\n        \n        images = torch.cat([image_0, image_1], dim = 0)\n        targets = torch.cat([target_0, target_1])\n        images = images.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n    \n        # normal loss\n        output = model(images)\n        loss = nn.BCEWithLogitsLoss()(output, targets.view(-1,1))\n        \n        loss.backward()\n        optimizer.step()\n        \ndef trainModel2(data_loader, model, Gen_0_t1, Gen_1_t0, optimizer, device):\n    Gen_0_t1.eval()\n    Gen_1_t0.eval()\n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        image_0, image_1, target_0, target_1 = data\n        \n        image_1 = image_1.to(device, dtype=torch.float)\n        target_1 = target_1.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n    \n        # Generating loss\n        fake_image_0 = Gen_1_t0(image_1)\n        model_expect_fake_0 = model(fake_image_0)\n        model_expect_fake_0 = nn.Sigmoid()(model_expect_fake_0)\n        loss_model_0 = nn.MSELoss()(model_expect_fake_0,  target_1.view(-1,1)) * 0.5\n        \n        image_0 = image_0.to(device, dtype=torch.float)\n        target_0 = target_0.to(device, dtype=torch.float)\n        fake_image_1 = Gen_0_t1(image_0)\n        model_expect_fake_1 = model(fake_image_1)\n        model_expect_fake_1 = nn.Sigmoid()(model_expect_fake_1)\n        loss_model_1 = nn.MSELoss()(model_expect_fake_1,  target_0.view(-1,1)) * 0.5\n        \n        loss = loss_model_0 + loss_model_1\n        loss.backward()\n        optimizer.step()       ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:52:45.308051Z","iopub.execute_input":"2021-05-25T11:52:45.308399Z","iopub.status.idle":"2021-05-25T11:52:45.320735Z","shell.execute_reply.started":"2021-05-25T11:52:45.308366Z","shell.execute_reply":"2021-05-25T11:52:45.319701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    validate_losses = 0\n    cnt = 0\n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            cnt += 1\n            image_0, image_1, target_0, target_1 = data\n\n            images = torch.cat([image_0, image_1], dim = 0)\n            targets = torch.cat([target_0, target_1])\n            \n            images = images.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(images)\n            loss = nn.BCEWithLogitsLoss()(output, targets.view(-1, 1))\n            validate_losses += loss.item()\n\n\n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n    return final_outputs, final_targets, validate_losses/cnt","metadata":{"execution":{"iopub.status.busy":"2021-05-25T11:54:06.471103Z","iopub.execute_input":"2021-05-25T11:54:06.47148Z","iopub.status.idle":"2021-05-25T11:54:06.479681Z","shell.execute_reply.started":"2021-05-25T11:54:06.471446Z","shell.execute_reply":"2021-05-25T11:54:06.478691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ntry:\n    obj = None\n    gc.collect()\n    torch.cuda.empty_cache()\n    del model\n    del SD_aug\n    del SD\n    del Gen_0_t1\n    del Gen_1_t0\nexcept:\n    pass","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I believe the loss from cyclegan act as a Regulrization of base model's decision boundary.\n\n\nSince the code is not optimized, so the memory keeps fulled.\n\nI use batch size 4...","metadata":{}},{"cell_type":"code","source":"Batch_Size = 4\n\n#cspdarknet53\nmodel = cspdarknet_baseline(pretrained=True)\nmodel.to(device)\noptimizer1 = torch.optim.Adam(model.parameters(), lr=3e-4, eps=1e-5)\noptimizer2 = torch.optim.RMSprop(model.parameters(), lr=5e-6, eps=1e-5)\n\n#Image generator 0 to 1 and 1 to 0.\nGen_0_t1 = Generator()\nGen_1_t0 = Generator()\nGen_0_t1.apply(weights_init)\nGen_1_t0.apply(weights_init)\n\nGen_0_t1.to(device)\nGen_1_t0.to(device)\noptimizer_G = torch.optim.Adam(itertools.chain(Gen_0_t1.parameters(), Gen_1_t0.parameters()),\n                               lr=2e-4, betas=(0.5, 0.999))\n\n\ntrain_df_1 = train_df[train_df.target==1].reset_index(drop=True)\ntrain_df_0 = train_df[train_df.target==0].sample(len(train_df_1)).reset_index(drop=True)\n\n\nskf = StratifiedKFold(n_splits=5)\nX = train_df_1.filepath.values\nY = train_df_0.target.values\n\nfor train_index, test_index in skf.split(X, Y):\n    \n    tra1_df = train_df_1.loc[train_index]\n    tra0_df = train_df_0.loc[train_index]\n    val1_df = train_df_1.loc[test_index]\n    val0_df = train_df_0.loc[test_index]\n    \n    train_dataset = setiDataset(tra0_df, tra1_df, transform = train_transform)\n    train_loader= torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size, shuffle=False)\n    valid_dataset = setiDataset(val0_df, val1_df)\n    valid_loader= torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size, shuffle=False)\n    \n    trainModel(train_loader, model, optimizer1, device)\n    predictions, valid_targets, valid_loss = evaluate(valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Part1: Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")\n    \n    trainGenerator(train_loader,model, Gen_0_t1, Gen_1_t0, optimizer_G, device)\n    trainModel2(train_loader, model, Gen_0_t1, Gen_1_t0, optimizer2, device)\n\n    predictions, valid_targets, valid_loss = evaluate(valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Part2: Valid Loss={valid_loss}, Valid ROC AUC={roc_auc}\")","metadata":{"execution":{"iopub.status.busy":"2021-05-25T12:03:43.58708Z","iopub.execute_input":"2021-05-25T12:03:43.587426Z","iopub.status.idle":"2021-05-25T16:09:20.577036Z","shell.execute_reply.started":"2021-05-25T12:03:43.587394Z","shell.execute_reply":"2021-05-25T16:09:20.576135Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I use validation set dependently with a traning set.<br>\nSo the performance has a strict upper bound of the score after 2 epoch.\n\nI will fix this problem in near future.","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(),'model.pt')\ntorch.save(Gen_0_t1.state_dict(),'Gen_0_t1.pt')\ntorch.save(Gen_1_t0.state_dict(),'Gen_1_t0.pt')  ","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:09:43.219753Z","iopub.execute_input":"2021-05-25T16:09:43.220116Z","iopub.status.idle":"2021-05-25T16:09:43.568438Z","shell.execute_reply.started":"2021-05-25T16:09:43.220078Z","shell.execute_reply":"2021-05-25T16:09:43.567616Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"Finally, I visualization training results for one data.","metadata":{}},{"cell_type":"code","source":"SD = setiDataset(train_df_0, train_df_1)\nimage0, image1, t0, t1 = SD[1]\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image0[0], aspect='auto')\nimage0 = torch.unsqueeze(image0, dim=0)\nimage0 = image0.to('cuda')\noutput = model(image0).item()\noutput = sigmoid(output)\nplt.title(f'Target {0}, Model value: {round(output,4)}', fontsize=12)\n\nplt.subplot(2,2,2)\nGen_0_t1.eval()\nfake_image_1 = Gen_0_t1(image0)\noutput2 = model(fake_image_1).item()\noutput2 = sigmoid(output2)\nfake_image_1 = fake_image_1.detach().cpu().numpy()\nfake_image_1 = fake_image_1.reshape(3,260,320)\nplt.imshow(fake_image_1[0], aspect='auto')\nplt.title(f'Target {0} to Fake 1, Model value: {round(output2,4)}', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:18:29.551487Z","iopub.execute_input":"2021-05-25T16:18:29.551863Z","iopub.status.idle":"2021-05-25T16:18:30.395481Z","shell.execute_reply.started":"2021-05-25T16:18:29.55183Z","shell.execute_reply":"2021-05-25T16:18:30.39452Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Something... hmm","metadata":{}},{"cell_type":"code","source":"SD = setiDataset(train_df_0, train_df_1)\nimage0, image1, t0, t1 = SD[2]\n\nplt.figure(figsize=(20,10))\nplt.subplot(2,2,1)\nplt.imshow(image0[0], aspect='auto')\nimage0 = torch.unsqueeze(image0, dim=0)\nimage0 = image0.to('cuda')\noutput = model(image0).item()\noutput = sigmoid(output)\nplt.title(f'Target {0}, Model value: {round(output,4)}', fontsize=12)\n\nplt.subplot(2,2,2)\nGen_0_t1.eval()\nfake_image_1 = Gen_0_t1(image0)\noutput2 = model(fake_image_1).item()\noutput2 = sigmoid(output2)\nfake_image_1 = fake_image_1.detach().cpu().numpy()\nfake_image_1 = fake_image_1.reshape(3,260,320)\nplt.imshow(fake_image_1[0], aspect='auto')\nplt.title(f'Target {0} to Fake 1, Model value: {round(output2,4)}', fontsize=12)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-05-25T16:19:17.874038Z","iopub.execute_input":"2021-05-25T16:19:17.874375Z","iopub.status.idle":"2021-05-25T16:19:18.362398Z","shell.execute_reply.started":"2021-05-25T16:19:17.874344Z","shell.execute_reply":"2021-05-25T16:19:18.361502Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"???????","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}