{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Want Help in Debugging below errorüôèüôè\n# HELP!!","metadata":{}},{"cell_type":"code","source":"!pip install -q efficientnet\nimport efficientnet.tfkeras as efn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, glob, cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\n\nfrom kaggle_datasets import KaggleDatasets\n\n# ML tools \nimport tensorflow as tf\nfrom keras import backend as K\nfrom keras import layers\nfrom keras.optimizers import Adam\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# config\nSEED= 22\nIMAGE_SIZE= [256, 256]\nBATCH_SIZE=16\nlr= 0.0001\nn_epochs= 5\n\nENCODER_DIM= 512\nDECODER_DIM= 256","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = KaggleDatasets().get_gcs_path('setibl-256x256-tfrec-dataset')\nGCS_PATH","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tfrec= np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/train*.tfrec')))\nTEST_tfrec= np.sort(np.array(tf.io.gfile.glob(GCS_PATH + '/test*.tfrec')))\n\nTRAIN_tfrec, VALID_tfrec= train_test_split(train_tfrec,\n                            test_size=0.2, random_state= SEED)\nlen(TRAIN_tfrec), len(VALID_tfrec)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect hardware, set appropriate distribution strategy (GPU/TPU)\ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n        \n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n    \n    return strategy\n\nTPU=True\nstrategy = auto_select_accelerator()\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')\nBATCH_SIZE= BATCH_SIZE*REPLICAS\nprint(f'BATCH_SIZE: {BATCH_SIZE}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        #img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        return img\n    \n\ndef decode_tfrecord(record_bytes):\n    feature= tf.io.parse_single_example(record_bytes, {\n        'image':  tf.io.FixedLenFeature([], tf.string),\n        'image_id': tf.io.FixedLenFeature([], tf.string),\n        'target' : tf.io.FixedLenFeature([], tf.int64)\n    })\n    # decode the PNG and explicitly reshape to image size (required on TPU)\n    image01 = tf.io.decode_png(feature['image'])    \n    image01 = tf.cast(image01, tf.float32)\n    image01 = tf.image.resize(image01, (IMAGE_SIZE[0], IMAGE_SIZE[1]))\n    Target = feature['target']\n    Target = tf.cast(Target, tf.uint8)\n    return image01, Target\n\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_saturation(img, 0.8, 1.2)\n        img = tf.image.random_brightness(img, 0.1)\n        img = tf.image.random_contrast(img, 0.8, 1.2)\n        return img\n    \n    def augment_with_labels(img, label):\n        return augment(img), label\n    return augment_with_labels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_dataset(bs= BATCH_SIZE):\n    \n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n    augment_fn= build_augmenter()\n    \n    FNAMES_TRAIN_TFRECORDS = TRAIN_tfrec\n    AUTO= tf.data.experimental.AUTOTUNE\n    train_dataset = tf.data.TFRecordDataset(FNAMES_TRAIN_TFRECORDS, num_parallel_reads=AUTO)\n    \n    train_dataset = train_dataset.with_options(ignore_order)\n    train_dataset = train_dataset.map(decode_tfrecord, num_parallel_calls=AUTO)  # optimize automatically\n    train_dataset = train_dataset.map(augment_fn, num_parallel_calls=AUTO)\n    train_dataset = train_dataset.repeat()\n    train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTO)\n    \n    return train_dataset\n\ndef get_val_dataset(bs=BATCH_SIZE):\n    ignore_order = tf.data.Options()\n    \n    FNAMES_TRAIN_TFRECORDS = VALID_tfrec\n    AUTO= tf.data.experimental.AUTOTUNE\n    val_dataset = tf.data.TFRecordDataset(FNAMES_TRAIN_TFRECORDS, num_parallel_reads=AUTO)\n    #val_dataset = val_dataset.prefetch(AUTO)\n    val_dataset = val_dataset.map(decode_tfrecord, num_parallel_calls=AUTO)\n    val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=True)\n    val_dataset = val_dataset.prefetch(AUTO)\n    \n    return val_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model():\n    base = efn.EfficientNetB3(weights='imagenet',include_top=False)   \n    inp = layers.Input(shape = (IMAGE_SIZE[0], IMAGE_SIZE[1], 3))\n    x= base(inp)\n    x= tf.keras.layers.Reshape([-1, ENCODER_DIM], name= 'Reshapev1')(x)\n    x= tf.keras.layers.Permute([2, 1], name= 'Permutev1')(x)\n    x= layers.LSTM(DECODER_DIM, dropout=0.1, recurrent_dropout=0.1)(x)\n    x= layers.Dropout(0.3)(x)\n    x= layers.Dense(1, 'sigmoid')(x)\n    return Model(inp, x)\n\ndef weighted_binary_crossentropy( y_true, y_pred, weight=2.1 ) :\n    y_true = K.clip(y_true, K.epsilon(), 1-K.epsilon())\n    y_pred = K.clip(y_pred, K.epsilon(), 1-K.epsilon())\n    logloss = -(y_true * K.log(y_pred) * weight + (1 - y_true) * K.log(1 - y_pred))\n    return K.mean( logloss, axis=-1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    # Build Datasets\n    train_dataset = get_train_dataset()\n    valid_dataset = get_val_dataset()\n    \n    # Building & Compiling Model\n    model = build_model()\n    model.compile(Adam(lr=lr), loss='bce', metrics=[tf.keras.metrics.AUC(multi_label=True)])\n\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#load one iter sample\nimgs, lbls = next(iter(train_dataset))\nprint(f'imgs.shape: {imgs.shape}, lbls.shape: {lbls.shape}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# cell ref.- https://www.kaggle.com/usharengaraju/seti-eda-baseline-tensorflow-and-tpu\nimport re\n\ndef count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\nNUM_TRAINING_IMAGES = count_data_items(TRAIN_tfrec)\nNUM_VALIDATION_IMAGES = count_data_items(VALID_tfrec)\nNUM_TEST_IMAGES = count_data_items(TEST_tfrec)\nSTEPS_PER_EPOCH = NUM_TRAINING_IMAGES // BATCH_SIZE\nVALID_STEPS= NUM_VALIDATION_IMAGES//BATCH_SIZE\nprint(\n    'Dataset | Training images: {} | Validation images: {} | Unlabeled test images: {}  | STEPS_PER_EPOCH: {}'.format(\n        NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES, STEPS_PER_EPOCH))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"name= 'SETI_ED_model.h5'\n\nrlr = ReduceLROnPlateau(monitor = 'val_loss', factor = 0.1, patience = 2, verbose = 1, \n                                min_delta = 1e-4, min_lr = 1e-6, mode = 'min', cooldown=1)\n        \nckp = ModelCheckpoint(name,monitor = 'val_loss',\n                      verbose = 1, save_best_only = True, mode = 'min')\n        \nes = EarlyStopping(monitor = 'val_loss', min_delta = 1e-4, patience = 5, mode = 'min', \n                    restore_best_weights = True, verbose = 1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,                      \n                    validation_data=valid_dataset,\n                    validation_steps= VALID_STEPS,\n                    epochs=n_epochs, callbacks=[rlr,es,ckp],\n                    steps_per_epoch=STEPS_PER_EPOCH,\n                    verbose=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\"); plt.ylabel(\"Loss\")\nplt.plot( history.history[\"loss\"], label = \"Training Loss\", marker='o')\nplt.plot( history.history[\"val_loss\"], label = \"Validation Loss\", marker='+')\nplt.grid(True); plt.legend(); plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize = (12, 6))\nplt.xlabel(\"Epochs\"); plt.ylabel(\"AUC\")\nplt.plot( history.history[\"auc\"], label = \"Training AUC\" , marker='o')\nplt.plot( history.history[\"val_auc\"], label = \"Validation AUC\", marker='+')\nplt.grid(True);  plt.legend(); plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}