{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"**LB : 0.96**","metadata":{}},{"cell_type":"code","source":"import os\nimport sys\nsys.path = ['effs/EfficientNet-PyTorch/EfficientNet-PyTorch-master',] + sys.path\nimport pandas as pd\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torchvision.models as models\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom sklearn.model_selection import KFold, StratifiedKFold","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nseed = 42\nrandom_state = set_seed(seed)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets): \n        self.image_paths = image_paths\n        self.targets = targets\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","metadata":{"execution":{"iopub.execute_input":"2021-05-11T09:06:24.187231Z","iopub.status.busy":"2021-05-11T09:06:24.186287Z","iopub.status.idle":"2021-05-11T09:06:24.188722Z","shell.execute_reply":"2021-05-11T09:06:24.189156Z"},"papermill":{"duration":0.022642,"end_time":"2021-05-11T09:06:24.189328","exception":false,"start_time":"2021-05-11T09:06:24.166686","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('train_labels.csv')\nprint (df.shape)\ndf['img_path'] = df['id'].apply(lambda x: f'train/{x[0]}/{x}.npy')","metadata":{"execution":{"iopub.execute_input":"2021-05-11T09:06:24.223253Z","iopub.status.busy":"2021-05-11T09:06:24.222684Z","iopub.status.idle":"2021-05-11T09:06:24.306877Z","shell.execute_reply":"2021-05-11T09:06:24.306138Z"},"papermill":{"duration":0.104132,"end_time":"2021-05-11T09:06:24.307063","exception":false,"start_time":"2021-05-11T09:06:24.202931","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.execute_input":"2021-05-11T09:06:24.348212Z","iopub.status.busy":"2021-05-11T09:06:24.347548Z","iopub.status.idle":"2021-05-11T09:06:24.357736Z","shell.execute_reply":"2021-05-11T09:06:24.358202Z"},"papermill":{"duration":0.036227,"end_time":"2021-05-11T09:06:24.358354","exception":false,"start_time":"2021-05-11T09:06:24.322127","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(6, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{"execution":{"iopub.execute_input":"2021-05-11T09:06:24.551579Z","iopub.status.busy":"2021-05-11T09:06:24.550587Z","iopub.status.idle":"2021-05-11T09:06:24.552921Z","shell.execute_reply":"2021-05-11T09:06:24.553476Z"},"papermill":{"duration":0.026913,"end_time":"2021-05-11T09:06:24.553637","exception":false,"start_time":"2021-05-11T09:06:24.526724","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"execution":{"iopub.execute_input":"2021-05-11T09:06:31.97314Z","iopub.status.busy":"2021-05-11T09:06:31.971573Z","iopub.status.idle":"2021-05-11T09:06:31.974102Z","shell.execute_reply":"2021-05-11T09:06:31.974573Z"},"papermill":{"duration":0.02846,"end_time":"2021-05-11T09:06:31.974712","exception":false,"start_time":"2021-05-11T09:06:31.946252","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"baseline_name = 'efficientnet-b0'\npretrained_model = {\n    baseline_name: 'effs/efficientnet-b0-08094119.pth'\n}\nmodels = []\ndevice = \"cuda\"\nepochs = 10\nBatch_Size = 32\nX = df.img_path.values\nY = df.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\n\nfor train_index, test_index in skf.split(X, Y):\n    \n    model = enetv2(baseline_name, out_dim=1)\n    model.to(device)\n\n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n\n    train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets)\n    valid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\n    for epoch in range(epochs):\n        train(train_loader, model, optimizer, device=device)\n        predictions, valid_targets = evaluate(valid_loader, model, device=device)\n        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        \n    torch.save(model.state_dict(),baseline_name + '-' + str(fold) + '.pt')\n    models.append(model)\n    fold += 1","metadata":{"execution":{"iopub.execute_input":"2021-05-11T09:06:32.016713Z","iopub.status.busy":"2021-05-11T09:06:32.015928Z"},"papermill":{"duration":null,"end_time":null,"exception":false,"start_time":"2021-05-11T09:06:31.989411","status":"running"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, valid_targets = evaluate(test_loader, model, device=device)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = np.array(predictions)[:, 0]","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sig = torch.nn.Sigmoid()\nouts = sig(torch.from_numpy(predictions))\nouts = outs.detach().numpy()\nouts","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target = outs\nsubmission.drop(['img_path'], axis=1, inplace=True)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]}]}