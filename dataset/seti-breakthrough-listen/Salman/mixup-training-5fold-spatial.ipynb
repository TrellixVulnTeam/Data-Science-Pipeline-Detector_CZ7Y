{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nsys.path = ['../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',] + sys.path\nimport pandas as pd\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torchvision.models as models\nimport torch.nn as nn\nfrom efficientnet_pytorch import model as enet\nimport random\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport albumentations as A","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.220717,"end_time":"2021-05-11T09:06:24.153506","exception":false,"start_time":"2021-05-11T09:06:20.932789","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-28T08:33:03.415151Z","iopub.execute_input":"2021-05-28T08:33:03.415519Z","iopub.status.idle":"2021-05-28T08:33:06.66449Z","shell.execute_reply.started":"2021-05-28T08:33:03.415434Z","shell.execute_reply":"2021-05-28T08:33:06.663699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nseed = 42\nrandom_state = set_seed(seed)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:33:06.665967Z","iopub.execute_input":"2021-05-28T08:33:06.666313Z","iopub.status.idle":"2021-05-28T08:33:06.676626Z","shell.execute_reply.started":"2021-05-28T08:33:06.666276Z","shell.execute_reply":"2021-05-28T08:33:06.675878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:33:06.678296Z","iopub.execute_input":"2021-05-28T08:33:06.678679Z","iopub.status.idle":"2021-05-28T08:33:06.771596Z","shell.execute_reply.started":"2021-05-28T08:33:06.678628Z","shell.execute_reply":"2021-05-28T08:33:06.770642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_sz = 256\nttransform = A.Compose([\n    A.Resize(img_sz, img_sz, cv2.INTER_NEAREST),\n    A.VerticalFlip(p=0.4),\n    A.HorizontalFlip(p=0.4),\n])\nvtransform = A.Compose([\n    A.Resize(img_sz, img_sz, cv2.INTER_NEAREST)\n])","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:33:06.773373Z","iopub.execute_input":"2021-05-28T08:33:06.773968Z","iopub.status.idle":"2021-05-28T08:33:06.781389Z","shell.execute_reply.started":"2021-05-28T08:33:06.773915Z","shell.execute_reply":"2021-05-28T08:33:06.780519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets, tr): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.tr = tr\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item])\n        image = np.vstack(image).astype(float)\n        image = self.tr(image = image)[\"image\"][np.newaxis, ]\n\n        targets = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","metadata":{"papermill":{"duration":0.022642,"end_time":"2021-05-11T09:06:24.189328","exception":false,"start_time":"2021-05-11T09:06:24.166686","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-28T08:33:06.784407Z","iopub.execute_input":"2021-05-28T08:33:06.784701Z","iopub.status.idle":"2021-05-28T08:33:06.793051Z","shell.execute_reply.started":"2021-05-28T08:33:06.784676Z","shell.execute_reply":"2021-05-28T08:33:06.792325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\nprint (df.shape)\ndf['img_path'] = df['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')","metadata":{"papermill":{"duration":0.104132,"end_time":"2021-05-11T09:06:24.307063","exception":false,"start_time":"2021-05-11T09:06:24.202931","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-28T08:33:06.794346Z","iopub.execute_input":"2021-05-28T08:33:06.794929Z","iopub.status.idle":"2021-05-28T08:33:06.866751Z","shell.execute_reply.started":"2021-05-28T08:33:06.794892Z","shell.execute_reply":"2021-05-28T08:33:06.865786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"papermill":{"duration":0.036227,"end_time":"2021-05-11T09:06:24.358354","exception":false,"start_time":"2021-05-11T09:06:24.322127","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-28T08:33:06.86807Z","iopub.execute_input":"2021-05-28T08:33:06.868406Z","iopub.status.idle":"2021-05-28T08:33:06.885009Z","shell.execute_reply.started":"2021-05-28T08:33:06.868369Z","shell.execute_reply":"2021-05-28T08:33:06.883949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{"papermill":{"duration":0.026913,"end_time":"2021-05-11T09:06:24.553637","exception":false,"start_time":"2021-05-11T09:06:24.526724","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-28T08:33:06.887766Z","iopub.execute_input":"2021-05-28T08:33:06.888104Z","iopub.status.idle":"2021-05-28T08:33:06.894918Z","shell.execute_reply.started":"2021-05-28T08:33:06.888071Z","shell.execute_reply":"2021-05-28T08:33:06.893875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    '''Returns mixed inputs, pairs of targets, and lambda'''\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n\n    batch_size = x.size()[0]\n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n\n    mixed_x = lam * x + (1 - lam) * x[index, :]\n    y_a, y_b = y, y[index]\n    return mixed_x, y_a, y_b, lam\n\n\ndef mixup_criterion(criterion, pred, y_a, y_b, lam):\n    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T08:33:06.896449Z","iopub.execute_input":"2021-05-28T08:33:06.897035Z","iopub.status.idle":"2021-05-28T08:33:06.905321Z","shell.execute_reply.started":"2021-05-28T08:33:06.896993Z","shell.execute_reply":"2021-05-28T08:33:06.904486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        \n        inputs1 = data[\"image\"]\n        targets = data['targets']\n        \n        inputs1, targets_a, targets_b, lam = mixup_data(inputs1, targets.view(-1, 1), use_cuda=True)\n\n        inputs1 = inputs1.to(device, dtype=torch.float)\n        targets_a = targets_a.to(device, dtype=torch.float)\n        targets_b = targets_b.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs1)\n        loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"papermill":{"duration":0.02846,"end_time":"2021-05-11T09:06:31.974712","exception":false,"start_time":"2021-05-11T09:06:31.946252","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-05-28T08:33:06.907797Z","iopub.execute_input":"2021-05-28T08:33:06.908062Z","iopub.status.idle":"2021-05-28T08:33:06.921172Z","shell.execute_reply.started":"2021-05-28T08:33:06.908039Z","shell.execute_reply":"2021-05-28T08:33:06.92037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"paths = [\n 'efficientnet-b0-08094119.pth',\n 'efficientnet-b1-dbc7070a.pth',\n 'efficientnet-b2-27687264.pth',\n 'efficientnet-b3-c8376fa2.pth',\n 'efficientnet-b4-e116e8b3.pth',\n 'efficientnet-b6-c76e70fd.pth',\n 'efficientnet-b5-586e6cc6.pth',\n 'efficientnet-b7-dcc49843.pth',\n]\n\nbaseline_name = 'efficientnet-b0'\npretrained_model = {\n    'efficientnet-b0': '../input/efficientnet-pytorch/' + paths[0]\n}\nmodels = []\ndevice = \"cuda\"\n# df = df.sample(n = 1000).reset_index(drop=True)\nepochs = 10\nBatch_Size = 32\nX = df.img_path.values\nY = df.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\ncriterion = nn.BCEWithLogitsLoss()\nfor train_index, test_index in skf.split(X, Y):\n    \n    model = enetv2(baseline_name, out_dim=1)\n    model.to(device)\n\n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n\n    train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets, tr=ttransform)\n    valid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets, tr=vtransform)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\n    for epoch in range(epochs):\n        train(train_loader, model, optimizer, device=device)\n        predictions, valid_targets = evaluate(valid_loader, model, device=device)\n        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        \n    torch.save(model.state_dict(),baseline_name + '-' + str(fold) + '.pt')\n    models.append(model)\n    fold += 1","metadata":{"papermill":{"duration":null,"end_time":null,"exception":false,"start_time":"2021-05-11T09:06:31.989411","status":"running"},"tags":[],"execution":{"iopub.status.busy":"2021-05-28T08:33:06.922323Z","iopub.execute_input":"2021-05-28T08:33:06.922699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# submission = submission.sample(n = 1000).reset_index(drop=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor each in models:\n    test_dataset = ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values, tr=vtransform)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=4)\n    predictions, valid_targets = evaluate(test_loader, each, device=device)\n    preds.append(predictions)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = []\nfor predictions in preds:\n    predictions = np.array(predictions)[:, 0]\n    sig = torch.nn.Sigmoid()\n    outs = sig(torch.from_numpy(predictions))\n    outs = outs.detach().numpy()\n    outputs.append(outs)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = np.mean(outputs, axis = 0)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target = outputs\nsubmission.drop(['img_path'], axis=1, inplace=True)\nsubmission.to_csv('submission.csv', index=False)","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[],"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"papermill":{"duration":null,"end_time":null,"exception":null,"start_time":null,"status":"pending"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}