{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SETI Signal Search - CNN - 26\n\n## Specific\n\n* in CNN-26 experiment with cutting off left and right side edges as a randomization technique using CNN-18 models)\n  Work in Progress, this is only the base level without the cut-off left and right.\n  Confirming the earlier results from CNN-20, which was using the models from CNN-18 (most successful 0.94\n  submission up to now, without augmented duplication of positives, only randomization of existing training examples)\n* in CNN-25 Plot ROC for oversampling 8 with noise 0.5 (CNN-22)\n* in CNN-24 prepare data for Plot ROC for oversampling 8 with noise 0.5 (CNN-22)\n* in CNN-23 for 1 fold, try noise at 1.0 (5 epochs, last epoch serious drop in AUC, probably too much noise)\n* in CNN-22 we will try a simplistic technique duplicating the positive cases with some variations\n* in CNN-21 we analysed the ROC of the initial training steps\n* in CNN-20 we calculated inferences on epoch 00, 01, 02 and 05 for folds 0 and 1\n* try to understand the ROC curve:\n* CNN-19 3 epochs on the first 2 Folds training effv2 b1 from pretrained timm\n* CNN-18 6th epoch on the all 5 Folds training effv2 b1 from pretrained timm\n* comparing the curves for validation data in a Fold and training data in that Fold\n  to see if we can see and/or understand overfitting.\n  \n## New ideas\n\n* plot ROC for the oversampling case with 0.5\n* plot predictions for full_width, partial_right, partial_left\n* look at FN and FP\n* plot 4 individual predictions vs. average prediction (before and after sigmoid) => and calculate AUC's for them\n\n\n## Global\n\nTry to predict the presence of \"needles\" with a CNN using PyTorch.\n\nFor transfer learning, look at TF EfficientNet and TF EfficientNet V2\n\nIn the list of Pytorch Image models https://paperswithcode.com/lib/timm/ and sorting them by TOP 1 Accuracy, the EfficientNet is the first model that goes under 10 Billion Flops. Also, there are variations from b0 to b8 that I presume will make it possible to trade-off compute cost vs. accuracy.\n\nVery recently (14 May) the V2 was ported to this PyTorch repo. Maybe also testing tf_efficientnetv2_b0 up to tf_efficientnetv2_b3 ?\n\nInspired by https://www.kaggle.com/piantic/train-seti-pytorch-starter-chans-vs-spatial from https://www.kaggle.com/piantic\n\nKFold and initial Convolutional filter inspired by Salman https://www.kaggle.com/micheomaano/mixup-training-5fold-spatial/execution","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T20:03:54.280487Z","iopub.execute_input":"2021-05-24T20:03:54.281095Z","iopub.status.idle":"2021-05-24T20:03:54.291082Z","shell.execute_reply.started":"2021-05-24T20:03:54.281042Z","shell.execute_reply":"2021-05-24T20:03:54.28971Z"}}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nprint(timm.__version__)\n\nimport os\nimport datetime as dt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport matplotlib.ticker as ticker\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast\nfrom torch.optim import Adam\n\nimport cv2\nimport albumentations as A\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.364729Z","iopub.execute_input":"2021-06-17T21:12:26.365097Z","iopub.status.idle":"2021-06-17T21:12:26.377331Z","shell.execute_reply.started":"2021-06-17T21:12:26.365067Z","shell.execute_reply":"2021-06-17T21:12:26.376163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    debug = False\n\n    unskew = False  # False will not trigger adding unskew training data\n    training = False  # False will not trigger an actual training (e.g. do an evaluation)\n    submission = False  # False will only calculate 1 Fold and not do submission\n\n    input_model_cnn = \"18\"\n    evaluation = True  # False will not trigger an evaluation of earlier loaded models\n    \n    input_inferences_cnn = \"20\"\n    visualisation = True  # True will plot ROC curve etc.\n    \n    epochs = 5 # not really relevant if no training ...\n\n    # focus on tf_efficientnetv2_b1 for now\n    model_name = 'tf_efficientnetv2_b1'\n    model_size = 192  # 3, 192, 192\n    valid_model_size = 240  # 3, 240, 240\n\n    batch_size = 64\n    inference_batch_size = 64\n    num_workers = 8\n\n    criterion = nn.BCEWithLogitsLoss()\n\n    seed = 45\n\n    N_FOLDS = 4  # 4 instead of 5, since evaluation is more important to be more sure on the secret Kaggle test set\n    p_horizontal_flip = 0.20  # Not too sure if this is really a good idea (the data seems asymmetric ...)\n    random_gain_positives = 0.30  # a factor for reduction of gain on duplicated positives\n    random_noise_positives = 0.50  # random noise adding on duplicated positives\n    sample_width = 250  # of 256  => probably replace this with controlled side-cutting (CNN-26)\n\n    lr = 8e-5  # maybe too much for final fine-tuning ?","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:36:12.370858Z","iopub.execute_input":"2021-06-17T21:36:12.371224Z","iopub.status.idle":"2021-06-17T21:36:12.378104Z","shell.execute_reply.started":"2021-06-17T21:36:12.371192Z","shell.execute_reply":"2021-06-17T21:36:12.377321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Hyper parameters\n\n| run | folds |   lr  | horiz | width | rnd gain | rnd noise |\n|----:|------:|------:|------:|------:|---------:|----------:|\n| 22  |   4/4 |  8e-5 |  0.10 |   252 |     0.30 |      0.50 |\n| 23  |   1/4 |  8e-5 |  0.20 |   250 |     0.30 |      1.00 |","metadata":{}},{"cell_type":"markdown","source":"# Import data","metadata":{}},{"cell_type":"code","source":"import os\n\nprint(\"os.walk in part of /kaggle/input/\")\n\ndef walk_kaggle_input(dir):\n    for dirname, _, filenames in os.walk(f\"/kaggle/input/{dir}/output\"):\n        for filename in sorted(filenames[0:100]):\n            print(os.path.join(dirname, filename))\n\nwalk_kaggle_input(f\"seti-signal-search-cnn-{CFG.input_model_cnn}\")","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.460778Z","iopub.execute_input":"2021-06-17T21:12:26.461434Z","iopub.status.idle":"2021-06-17T21:12:26.471238Z","shell.execute_reply.started":"2021-06-17T21:12:26.461388Z","shell.execute_reply":"2021-06-17T21:12:26.469554Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/seti-breakthrough-listen'\n\ndef get_file_path(image_id, category):\n    return f\"{BASE_DIR}/{category}/{image_id[0]}/{image_id}.npy\"\n\ndef get_train_file_path(image_id):\n    return get_file_path(image_id, \"train\")\n\ndef get_test_file_path(image_id):\n    return get_file_path(image_id, \"test\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.477037Z","iopub.execute_input":"2021-06-17T21:12:26.477423Z","iopub.status.idle":"2021-06-17T21:12:26.483306Z","shell.execute_reply.started":"2021-06-17T21:12:26.477388Z","shell.execute_reply":"2021-06-17T21:12:26.482084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_original = pd.read_csv(f\"{BASE_DIR}/train_labels.csv\")\nORIGINAL_SIZE = len(train_original)\ntrain_original","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.545601Z","iopub.execute_input":"2021-06-17T21:12:26.545964Z","iopub.status.idle":"2021-06-17T21:12:26.586237Z","shell.execute_reply.started":"2021-06-17T21:12:26.545933Z","shell.execute_reply":"2021-06-17T21:12:26.585484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.unskew:\n    train_positives = train_original[train_original['target'] == 1]\n    train_unskewed = (\n        train_original\n        .append(train_positives)\n        .append(train_positives)\n        .append(train_positives)\n        .append(train_positives)\n        .append(train_positives)\n        .append(train_positives)\n        .append(train_positives)\n        .append(train_positives)\n        .append(train_positives)\n        .reset_index(drop=True)\n    )\n\n    # Shuffle the train, to mix the positive duplicates inbetween originals \n    # drop False allows to know from where this row originates\n    # index 0 => 50164: train_original\n    # index > 50164: one of the extra rounds\n    train = train_unskewed.sample(frac=1, random_state=42).reset_index(drop=False)\n    train.rename(columns={'index': 'original_index'},inplace=True)\nelse:\n    train = train_original.assign(original_index=train_original.index)\n    \ntrain","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.603709Z","iopub.execute_input":"2021-06-17T21:12:26.604346Z","iopub.status.idle":"2021-06-17T21:12:26.622803Z","shell.execute_reply.started":"2021-06-17T21:12:26.604311Z","shell.execute_reply":"2021-06-17T21:12:26.621965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add img_path and show class distribution for augmented train\ntrain['img_path'] = train['id'].apply(get_train_file_path)\n\ndisplay(train.head(1))\nprint(train.head(1)['img_path'].values)\n\ndisplay(train['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.63196Z","iopub.execute_input":"2021-06-17T21:12:26.63254Z","iopub.status.idle":"2021-06-17T21:12:26.685336Z","shell.execute_reply.started":"2021-06-17T21:12:26.632506Z","shell.execute_reply":"2021-06-17T21:12:26.684663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Add img_path and show class distribution for train\ntest = pd.read_csv(f\"{BASE_DIR}/sample_submission.csv\")\n\ntest['img_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(test.head(1))\nprint(test.head(1)['img_path'].values)\n\ndisplay(test['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.686815Z","iopub.execute_input":"2021-06-17T21:12:26.687406Z","iopub.status.idle":"2021-06-17T21:12:26.755843Z","shell.execute_reply.started":"2021-06-17T21:12:26.68734Z","shell.execute_reply":"2021-06-17T21:12:26.754881Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.debug:\n    print('debug!')\n    CFG.epochs = 1\n    CFG.batch_size = 8\n    CFG.inference_batch_size = 16\n    CFG.num_workers = 4\n    \n    train = train.sample(n=193, random_state=CFG.seed).reset_index(drop=True)\n    display(train['target'].value_counts())\n    test = test.head(153)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.757447Z","iopub.execute_input":"2021-06-17T21:12:26.757724Z","iopub.status.idle":"2021-06-17T21:12:26.776109Z","shell.execute_reply.started":"2021-06-17T21:12:26.757697Z","shell.execute_reply":"2021-06-17T21:12:26.774837Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling\n\nInitial Exploratory Data Analysis was done in https://www.kaggle.com/peterv1/seti-signal-search-data-exploration/\n\nUsing the EfficientNet ports to Pytorch from Ross Wightman Ref. https://github.com/rwightman/pytorch-image-models","metadata":{}},{"cell_type":"code","source":"# Make output dir\nOUTPUT_DIR = './output/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.777853Z","iopub.execute_input":"2021-06-17T21:12:26.778186Z","iopub.status.idle":"2021-06-17T21:12:26.786195Z","shell.execute_reply.started":"2021-06-17T21:12:26.778145Z","shell.execute_reply":"2021-06-17T21:12:26.785014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"ttransform = A.Compose([\n    A.RandomCrop(height=1638, width=CFG.sample_width), # cut-off random 6 horizontally\n    A.HorizontalFlip(p=CFG.p_horizontal_flip),\n    A.Resize(CFG.model_size, CFG.model_size, cv2.INTER_NEAREST),\n])\nvtransform = A.Compose([\n    A.Resize(CFG.valid_model_size, CFG.valid_model_size, cv2.INTER_NEAREST)\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.787651Z","iopub.execute_input":"2021-06-17T21:12:26.788059Z","iopub.status.idle":"2021-06-17T21:12:26.797612Z","shell.execute_reply.started":"2021-06-17T21:12:26.788017Z","shell.execute_reply":"2021-06-17T21:12:26.796811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"import random\n  \nclass ClassificationDataset:\n    \n    def __init__(self, img_paths, targets, original_indexes, tr): \n        self.img_paths = img_paths\n        self.targets = targets\n        self.original_indexes = original_indexes\n        self.tr = tr\n\n    def __len__(self):\n        return len(self.img_paths)\n    \n    def __getitem__(self, item):\n        img_path = self.img_paths[item]\n        image = np.load(img_path)\n        image = np.vstack(image).astype(float)\n        image = self.tr(image = image)[\"image\"][np.newaxis, ]\n        target = self.targets[item]\n\n        # in training and for duplicated positive images, do a bit more transformations, make them harder\n        if self.original_indexes is None:\n            original_index = 0\n        else:\n            original_index = self.original_indexes[item]                        \n            if (original_index >= ORIGINAL_SIZE):\n                # reduce the gain\n                zero_to_one = random.uniform(0.0, 1.0)\n                image = image * (1 - CFG.random_gain_positives * zero_to_one)      \n                noise = np.random.normal(0, CFG.random_noise_positives, image.shape)\n                image = image + noise\n            \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"target\": torch.tensor(target, dtype=torch.float),\n            \"img_id\": img_path.split('/')[-1].split('.')[0],\n            \"original_index\": original_index,\n        }","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.798665Z","iopub.execute_input":"2021-06-17T21:12:26.79914Z","iopub.status.idle":"2021-06-17T21:12:26.816381Z","shell.execute_reply.started":"2021-06-17T21:12:26.799111Z","shell.execute_reply":"2021-06-17T21:12:26.815143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preview","metadata":{}},{"cell_type":"code","source":"# Preview some training images via the ClassificationDataset\n\ndisplay(train)\nX = train.img_path.values\ny = train.target.values\ni = train.original_index.values\n\nsample_size = 2\ntrain_index = 100 # some random image\ntrain_images = X[train_index:train_index+sample_size]\ntrain_targets = y[train_index:train_index+sample_size]\ntrain_original_indexes = i[train_index:train_index+sample_size]\n\ntrain_dataset = ClassificationDataset(\n    img_paths=train_images,\n    targets=train_targets,\n    original_indexes=train_original_indexes,\n    tr=ttransform\n)\n\nfor i in range(sample_size):\n    image_target = train_dataset[i]\n    image, target, img_id, original_index = (\n        image_target['image'],\n        image_target['target'],\n        image_target['img_id'],\n        image_target['original_index']\n    )\n    # transpose back from torch format to imshow format\n    plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n    plt.title(f\"target: {target}, img_id: {img_id}, original_index: {original_index}, min: {image.min():.4f}, max: {image.max():.4f}\")\n    plt.show()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:26.818146Z","iopub.execute_input":"2021-06-17T21:12:26.818708Z","iopub.status.idle":"2021-06-17T21:12:27.216213Z","shell.execute_reply.started":"2021-06-17T21:12:26.818584Z","shell.execute_reply":"2021-06-17T21:12:27.215263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview 2 test images via the ClassificationDataset\nX = test.img_path.values\ny = test.target.values\n\nsample_size = 2\ntest_index = 27 # some random image\ntest_images = X[test_index:test_index+sample_size]\ntest_targets = y[test_index:test_index+sample_size]\n\ntest_dataset = ClassificationDataset(img_paths=test_images, targets=test_targets, original_indexes=None, tr=vtransform) # vtransform !\n\nfor i in range(sample_size):\n    image_target = test_dataset[i]\n    image, target = image_target['image'], image_target['target']\n    # transpose back from torch format to imshow format\n    plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n    plt.title(f'target: {target}')\n    plt.show()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:27.218519Z","iopub.execute_input":"2021-06-17T21:12:27.2188Z","iopub.status.idle":"2021-06-17T21:12:27.556636Z","shell.execute_reply.started":"2021-06-17T21:12:27.218774Z","shell.execute_reply":"2021-06-17T21:12:27.555595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class timmv2(nn.Module):\n    def __init__(self, model_name, pretrained):\n        super().__init__()\n        \n        # Existing EfficientNet fixed at 3 channels\n        self.enet = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        \n        # Added a trainable 1 to 3 conv1 layer before\n        # TODO try padding=1 \n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=True)\n        \n        # set the output classifier to 1 feature\n        nb_ft = self.enet.classifier.in_features\n        self.enet.classifier = nn.Linear(nb_ft, 1)\n\n    @autocast()\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.enet(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:27.558221Z","iopub.execute_input":"2021-06-17T21:12:27.558525Z","iopub.status.idle":"2021-06-17T21:12:27.566336Z","shell.execute_reply.started":"2021-06-17T21:12:27.558497Z","shell.execute_reply":"2021-06-17T21:12:27.564904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_make(model_name):\n    model = timmv2(model_name, True) # Start from pre-trained\n    state_dict = {\n        'weight':torch.tensor(\n            [[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]]], requires_grad=True    \n        ),\n        'bias':torch.tensor(\n            [0.2, 0.2, 0.2], requires_grad=True\n        )}\n    model.conv1.load_state_dict(state_dict, strict=True)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:27.568092Z","iopub.execute_input":"2021-06-17T21:12:27.568547Z","iopub.status.idle":"2021-06-17T21:12:27.582273Z","shell.execute_reply.started":"2021-06-17T21:12:27.568499Z","shell.execute_reply":"2021-06-17T21:12:27.58113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_make_custom(model_name, cnn_version, fold=0, epoch=-1):\n    model = timmv2(model_name, False) # Start from SELF-trained\n    \n    prefix = f\"/kaggle/input/seti-signal-search-cnn-{cnn_version}/output\"\n    if epoch >= 0:\n        file_name = f\"{prefix}/tf_efficientnetv2_b1_fold_{fold:02d}_epoch_{epoch:02d}_state.pth\"\n    else:\n        file_name = f\"{prefix}/tf_efficientnetv2_b1_fold_{fold:02d}_state.pth\"\n        \n    # TODO: is map_location cuda OK when model is not yet loaded in GPU ?\n    model.load_state_dict(torch.load(file_name, map_location=torch.device(device))['model'])    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:27.583977Z","iopub.execute_input":"2021-06-17T21:12:27.584381Z","iopub.status.idle":"2021-06-17T21:12:27.593281Z","shell.execute_reply.started":"2021-06-17T21:12:27.584312Z","shell.execute_reply":"2021-06-17T21:12:27.592252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make a custom model and show the conv1 parameters\n\nif CFG.evaluation:\n    model = model_make_custom(CFG.model_name, cnn_version=CFG.input_model_cnn, fold=0, epoch=-1) # only last epoch saved\n    print(list(model.conv1.parameters()))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:27.594934Z","iopub.execute_input":"2021-06-17T21:12:27.595348Z","iopub.status.idle":"2021-06-17T21:12:27.951121Z","shell.execute_reply.started":"2021-06-17T21:12:27.595314Z","shell.execute_reply":"2021-06-17T21:12:27.950038Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate the custom model on a few validation samples\n\nif CFG.evaluation:\n    X = train.img_path.values\n    y = train.target.values\n\n    sample_size = 20\n    train_index = 0 # some random image\n    train_images = X[train_index:train_index+sample_size]\n    train_targets = y[train_index:train_index+sample_size]\n    train_dataset = ClassificationDataset(\n        img_paths=train_images,\n        targets=train_targets,\n        original_indexes=None,\n        tr=vtransform)\n\n    FIG_SIZE = 6\n\n    model.eval() # from model_make_custom above\n\n    for i in range(sample_size):\n        image_target = train_dataset[i]\n        image, target = image_target['image'].unsqueeze(0), image_target['target']\n        if target == torch.tensor(1.0):\n            output = model(image).view(-1)\n            print(output.detach().numpy(), target.detach().numpy(), image_target['img_id'])\n\n            plt.figure(figsize=(FIG_SIZE, FIG_SIZE))\n            plt.axes().yaxis.set_major_locator(ticker.MultipleLocator(40))\n            plt.imshow(image.squeeze(0).numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n            plt.title(f'target: {target}')\n            plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:27.952503Z","iopub.execute_input":"2021-06-17T21:12:27.952816Z","iopub.status.idle":"2021-06-17T21:12:28.837526Z","shell.execute_reply.started":"2021-06-17T21:12:27.952783Z","shell.execute_reply":"2021-06-17T21:12:28.836466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:28.839087Z","iopub.execute_input":"2021-06-17T21:12:28.839452Z","iopub.status.idle":"2021-06-17T21:12:28.844497Z","shell.execute_reply.started":"2021-06-17T21:12:28.839419Z","shell.execute_reply":"2021-06-17T21:12:28.84346Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training with folds","metadata":{}},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, criterion, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data['image']\n        targets = data['target']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        targets = targets.unsqueeze(1)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        \n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:28.846042Z","iopub.execute_input":"2021-06-17T21:12:28.846416Z","iopub.status.idle":"2021-06-17T21:12:28.859322Z","shell.execute_reply.started":"2021-06-17T21:12:28.84635Z","shell.execute_reply":"2021-06-17T21:12:28.858292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(data_loader, model, device):\n    \n    model.eval()\n    \n    final_outputs = []\n    final_targets = []\n    final_img_ids = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data['image']\n            targets = data['target']\n            img_ids = data['img_id']\n\n            inputs = inputs.to(device, dtype=torch.float)\n            output = model(inputs)\n            \n            output = output.detach().cpu().numpy().tolist()\n            targets = targets.numpy().tolist()\n\n            final_outputs.extend(output)\n            final_targets.extend(targets)\n            final_img_ids.extend(img_ids)\n            \n    return final_outputs, final_targets, final_img_ids","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:28.861552Z","iopub.execute_input":"2021-06-17T21:12:28.8619Z","iopub.status.idle":"2021-06-17T21:12:28.871269Z","shell.execute_reply.started":"2021-06-17T21:12:28.86187Z","shell.execute_reply":"2021-06-17T21:12:28.870105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train models for each fold\n\nif CFG.training:\n    models = []\n\n    X = train.img_path.values\n    y = train.target.values\n    i = train.original_index.values\n\n    skf = StratifiedKFold(n_splits=CFG.N_FOLDS)\n\n    fold = 0\n    for train_index, valid_index in skf.split(X, y):\n        print(f\"Starting Fold {fold:02d}\")\n\n        train_images, valid_images = X[train_index], X[valid_index]\n        train_targets, valid_targets = y[train_index], y[valid_index]\n        train_original_indexes = i[train_index]\n\n        train_dataset = ClassificationDataset(\n            img_paths=train_images,\n            targets=train_targets,\n            original_indexes=train_original_indexes,\n            tr=ttransform\n        )\n        valid_dataset = ClassificationDataset(\n            img_paths=valid_images,\n            targets=valid_targets,\n            original_indexes=None,\n            tr=vtransform\n        )\n\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True , num_workers=CFG.num_workers)\n        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n\n        model = model_make(CFG.model_name)\n        model.to(device)\n\n        # TODO higher lr for the conv1 parameters\n        optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n\n        for epoch in range(CFG.epochs):\n            train_fn(train_loader, model, optimizer, CFG.criterion, device=device)\n            predictions, valid_targets, _ = eval_fn(valid_loader, model, device=device)\n            roc_auc = get_score(valid_targets, predictions)\n            print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n            # print(list(model.conv1.parameters()))\n\n            # Save model after each fold and epoch\n            torch.save({'model': model.state_dict()},\n                       OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_state.pth\")\n\n        # append the latest model\n        # TODO: select the \"best\" model (after each epoch), not the last epoch\n        models.append(model)\n        fold += 1\n\n        # for runs without submission, do only 1 fold\n        if (CFG.submission == False) and (fold == 1):\n            break","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:28.872802Z","iopub.execute_input":"2021-06-17T21:12:28.873184Z","iopub.status.idle":"2021-06-17T21:12:28.887691Z","shell.execute_reply.started":"2021-06-17T21:12:28.873153Z","shell.execute_reply":"2021-06-17T21:12:28.886405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Prepare a submission on test data\n\nif CFG.submission:    \n    preds = []\n    for model in models:\n        test_dataset = ClassificationDataset(\n            img_paths=test.img_path.values,\n            targets=test.target.values,\n            original_indexes=None,        \n            tr=vtransform\n        )\n        test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG.inference_batch_size, shuffle=False, num_workers=CFG.num_workers)\n        predictions, valid_targets, _ = eval_fn(test_loader, model, device=device)\n        preds.append(predictions)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:28.889141Z","iopub.execute_input":"2021-06-17T21:12:28.889539Z","iopub.status.idle":"2021-06-17T21:12:28.904848Z","shell.execute_reply.started":"2021-06-17T21:12:28.889508Z","shell.execute_reply":"2021-06-17T21:12:28.903695Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# average the inferences on the 4 fold models\n\nif CFG.submission:\n    outputs = []\n    for predictions in preds:\n        predictions = np.array(predictions)[:, 0]\n        sig = torch.nn.Sigmoid()\n        outs = sig(torch.from_numpy(predictions))\n        outs = outs.detach().numpy()\n        outputs.append(outs)\n\n    # TODO: given the asymmetric nature of the signal (a small signal is still a signal); non-linear averaging might be more relevant here ???\n    outputs = np.mean(outputs, axis = 0)\n    display(outputs[0:10])","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:28.908281Z","iopub.execute_input":"2021-06-17T21:12:28.90863Z","iopub.status.idle":"2021-06-17T21:12:28.921075Z","shell.execute_reply.started":"2021-06-17T21:12:28.908597Z","shell.execute_reply":"2021-06-17T21:12:28.920292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.submission:\n    test.target = outputs\n    test.drop(['img_path'], axis=1, inplace=True)\n    test.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:12:28.922023Z","iopub.execute_input":"2021-06-17T21:12:28.922295Z","iopub.status.idle":"2021-06-17T21:12:28.934841Z","shell.execute_reply.started":"2021-06-17T21:12:28.922267Z","shell.execute_reply":"2021-06-17T21:12:28.933951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate models on validation AND training data for each fold and epoch\n# try to see if and when overfitting occurs\n\nif CFG.evaluation:\n    # read back models from saved files in earlier runs\n    import csv\n\n    valid_results = []\n    train_results = []\n\n    X = train.img_path.values\n    y = train.target.values\n    skf = StratifiedKFold(n_splits=CFG.N_FOLDS)\n\n    fold = 0\n    for train_index, valid_index in skf.split(X, y):\n        print(f\"Starting Fold {fold:02d}\")\n\n        print(len(train_index), len(valid_index))\n        print(train_index[0:5])\n        print(valid_index[0:5])\n\n        train_images, valid_images = X[train_index], X[valid_index]\n        train_targets, valid_targets = y[train_index], y[valid_index]\n\n        train_dataset = ClassificationDataset(\n            img_paths=train_images,\n            targets=train_targets,\n            original_indexes=None,\n            tr=vtransform)  # also vtransform since validation\n        \n        valid_dataset = ClassificationDataset(\n            img_paths=valid_images,\n            targets=valid_targets,\n            original_indexes=None,\n            tr=vtransform)\n\n        # Here, since validation, shuffle False\n        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n        valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n\n        valid_results_per_fold = []\n        train_results_per_fold = []\n\n        # First 5 (0,1,2,3,4) from CNN-22\n        # for epoch in range(CFG.epochs):\n          \n        # For CNN-18 only the data last fold \"05\" is saved\n        for epoch in [5]:\n            # DEBUG !!! \n            epoch_for_model = -1\n            model = model_make_custom(CFG.model_name, CFG.input_model_cnn, fold=fold, epoch=epoch_for_model)\n            model.to(device)\n\n            # Validation over VALID data\n            predictions, targets, img_ids = eval_fn(valid_loader, model, device=device)\n            roc_auc = get_score(targets, predictions)\n            print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n\n            # predictions need to be flattened\n            flat_predictions = []\n            list(map(flat_predictions.extend, predictions))\n            valid_results_per_fold_per_epoch = np.dstack((flat_predictions, targets, img_ids))[0]\n\n            filename = OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_validation.csv\"\n\n            with open(filename, 'w') as f:\n                csv.writer(f).writerows(valid_results_per_fold_per_epoch)\n\n            valid_results_per_fold.append(valid_results_per_fold_per_epoch)\n\n            # Validation over TRAIN data\n            predictions, targets, img_ids = eval_fn(train_loader, model, device=device)\n            roc_auc = get_score(targets, predictions)\n            print(f\"Epoch={epoch}, Train ROC AUC={roc_auc}\")\n\n            # predictions need to be flattened\n            flat_predictions = []\n            list(map(flat_predictions.extend, predictions))\n            train_results_per_fold_per_epoch = np.dstack((flat_predictions, targets, img_ids))[0]\n\n            filename = OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_training.csv\"\n\n            with open(filename, 'w') as f:\n                csv.writer(f).writerows(train_results_per_fold_per_epoch)\n\n            train_results_per_fold.append(train_results_per_fold_per_epoch)\n\n        valid_results.append(valid_results_per_fold)\n        train_results.append(train_results_per_fold)\n\n        fold += 1\n\n        # DEBUG only needed for 2 folds\n        if fold == 2:\n            break","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:36:27.216496Z","iopub.execute_input":"2021-06-17T21:36:27.217054Z","iopub.status.idle":"2021-06-17T21:36:58.446813Z","shell.execute_reply.started":"2021-06-17T21:36:27.217017Z","shell.execute_reply":"2021-06-17T21:36:58.445547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read back Inference of models on validation AND training data for each fold and epoch\n# try to see if and when overfittigng occurs\n\nif CFG.visualisation:\n    \n    INPUT_DIR = f\"/kaggle/input/seti-signal-search-cnn-{CFG.input_inferences_cnn}/output\"\n\n    # DEBUG : Read back form previous cell, is small data\n    INPUT_DIR = OUTPUT_DIR \n    \n    import csv\n\n    valid_results = []\n    train_results = []\n\n    X = train.img_path.values\n    y = train.target.values\n    skf = StratifiedKFold(n_splits=CFG.N_FOLDS) # we still hope this is reliable ...\n\n    fold = 0\n    for train_index, valid_index in skf.split(X, y):    \n        print(f\"Starting Fold {fold:02d}\")\n\n        print(len(train_index), len(valid_index))\n        print(train_index[0:5])\n        print(valid_index[0:5])\n\n        train_images, valid_images = X[train_index], X[valid_index]\n        train_targets, valid_targets = y[train_index], y[valid_index]\n\n        valid_results_per_fold = []\n        train_results_per_fold = []\n\n        #for epoch in range(CFG.epochs):\n        \n        # DEBUG only fold 5 for now\n        for epoch in [5]:\n            \n            # Validation over VALID data\n            valid_results_per_fold_per_epoch = []\n            filename = f\"{INPUT_DIR}/{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_validation.csv\"\n            with open(filename, 'r') as f:\n                data_reader = csv.reader(f)\n                for row in data_reader:\n                    valid_results_per_fold_per_epoch.append(row)\n\n            df_valid_results_per_fold_per_epoch = (\n                pd.DataFrame(valid_results_per_fold_per_epoch, columns = ['predictions', 'targets', 'img_ids'])\n            ) \n            valid_results_per_fold.append(valid_results_per_fold_per_epoch)\n\n            roc_auc = get_score(df_valid_results_per_fold_per_epoch['targets'], df_valid_results_per_fold_per_epoch['predictions'])\n            print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n\n            # Validation over TRAIN data\n            train_results_per_fold_per_epoch = []\n            filename = f\"{INPUT_DIR}/{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_training.csv\"\n            with open(filename, 'r') as f:\n                data_reader = csv.reader(f)\n                for row in data_reader:\n                    train_results_per_fold_per_epoch.append(row)\n\n            df_train_results_per_fold_per_epoch = (\n                pd.DataFrame(train_results_per_fold_per_epoch, columns = ['predictions', 'targets', 'img_ids'])\n            ) \n            train_results_per_fold.append(train_results_per_fold_per_epoch)\n\n            roc_auc = get_score(df_train_results_per_fold_per_epoch['targets'], df_train_results_per_fold_per_epoch['predictions'])\n            print(f\"Epoch={epoch}, Train ROC AUC={roc_auc}\")\n\n        valid_results.append(valid_results_per_fold)\n        train_results.append(train_results_per_fold)\n\n        fold += 1\n\n        # DEBUG only 2 folds have this models calculated\n        if fold == 2:\n            break","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:43:35.649649Z","iopub.execute_input":"2021-06-17T21:43:35.649999Z","iopub.status.idle":"2021-06-17T21:43:35.683006Z","shell.execute_reply.started":"2021-06-17T21:43:35.649967Z","shell.execute_reply":"2021-06-17T21:43:35.681786Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.visualisation:\n    display(len(df_valid_results_per_fold_per_epoch))\n    display(len(df_train_results_per_fold_per_epoch))","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:44:08.803555Z","iopub.execute_input":"2021-06-17T21:44:08.804052Z","iopub.status.idle":"2021-06-17T21:44:08.810049Z","shell.execute_reply.started":"2021-06-17T21:44:08.804012Z","shell.execute_reply":"2021-06-17T21:44:08.809121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if CFG.visualisation:\n    fpr_valid, tpr_valid, threshold_valid = roc_curve(df_valid_results_per_fold_per_epoch['targets'].astype(float).astype(int), df_valid_results_per_fold_per_epoch['predictions'].astype(float))\n    fpr_train, tpr_train, threshold_train = roc_curve(df_train_results_per_fold_per_epoch['targets'].astype(float).astype(int), df_train_results_per_fold_per_epoch['predictions'].astype(float))\n\n    roc_auc_valid = get_score(df_valid_results_per_fold_per_epoch['targets'], df_valid_results_per_fold_per_epoch['predictions'])\n    roc_auc_train = get_score(df_train_results_per_fold_per_epoch['targets'], df_train_results_per_fold_per_epoch['predictions'])\n\n    print(f\"roc_auc_valid = {roc_auc_valid}\")\n    print(f\"roc_auc_train = {roc_auc_train}\")\n    FIG_SIZE = 8\n\n    plt.subplots(1, figsize=(FIG_SIZE, FIG_SIZE))\n\n    plt.title('ROC - validation data')\n    plt.plot(fpr_valid, tpr_valid, 'b')\n    #plt.plot(fpr_valid, threshold_valid / 10.0, 'r')\n    plt.plot([0, 1], ls=\"--\")\n    plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n    plt.xlabel(\"False Positive Rate\" , fontsize=12)\n    plt.ylabel(\"True Positive Rate\" , fontsize=12)\n\n    plt.subplots(1, figsize=(FIG_SIZE, FIG_SIZE))\n\n    plt.title('ROC - train data')\n    plt.plot(fpr_train, tpr_train, 'b')\n    #plt.plot(fpr_train, threshold_train / 10.0, 'r')\n    plt.plot([0, 1], ls=\"--\")\n    plt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\n    plt.xlabel(\"False Positive Rate\" , fontsize=12)\n    plt.ylabel(\"True Positive Rate\" , fontsize=12)\n\n\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-17T21:44:11.979339Z","iopub.execute_input":"2021-06-17T21:44:11.979907Z","iopub.status.idle":"2021-06-17T21:44:12.315895Z","shell.execute_reply.started":"2021-06-17T21:44:11.97987Z","shell.execute_reply":"2021-06-17T21:44:12.315009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}