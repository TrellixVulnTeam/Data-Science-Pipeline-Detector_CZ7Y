{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SETI Signal Search - CNN - 21\n\n## Specific\n\n* in CNN-20 we calculated inferences on epoch 00, 01, 02 and 05 for folds 0 and 1\n* try to understand the ROC curve:\n* CNN-19 3 epochs on the first 2 Folds training effv2 b1 from pretrained timm\n* CNN-18 6th epoch on the all 5 Folds training effv2 b1 from pretrained timm\n* comparing the curves for validation data in a Fold and training data in that Fold\n  to see if we can see and/or understand overfitting.\n\n## Global\n\nTry to predict the presence of \"needles\" with a CNN using PyTorch.\n\nFor transfer learning, look at TF EfficientNet and TF EfficientNet V2\n\nIn the list of Pytorch Image models https://paperswithcode.com/lib/timm/ and sorting them by TOP 1 Accuracy, the EfficientNet is the first model that goes under 10 Billion Flops. Also, there are variations from b0 to b8 that I presume will make it possible to trade-off compute cost vs. accuracy.\n\nVery recently (14 May) the V2 was ported to this PyTorch repo. Maybe also testing tf_efficientnetv2_b0 up to tf_efficientnetv2_b3 ?\n\nInspired by https://www.kaggle.com/piantic/train-seti-pytorch-starter-chans-vs-spatial from https://www.kaggle.com/piantic\n\nKFold and initial Convolutional filter inspired by Salman https://www.kaggle.com/micheomaano/mixup-training-5fold-spatial/execution","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T20:03:54.280487Z","iopub.execute_input":"2021-05-24T20:03:54.281095Z","iopub.status.idle":"2021-05-24T20:03:54.291082Z","shell.execute_reply.started":"2021-05-24T20:03:54.281042Z","shell.execute_reply":"2021-05-24T20:03:54.28971Z"}}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"import os\n\nprint(\"os.walk in part of /kaggle/input/\")\n\ndef walk_kaggle_input(dir):\n    for dirname, _, filenames in os.walk(f\"/kaggle/input/{dir}/output\"):\n        for filename in filenames[0:10]:\n            print(os.path.join(dirname, filename))\n\nwalk_kaggle_input(\"seti-signal-search-cnn-20\")","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.515321Z","iopub.execute_input":"2021-06-13T22:06:59.515645Z","iopub.status.idle":"2021-06-13T22:06:59.525774Z","shell.execute_reply.started":"2021-06-13T22:06:59.515606Z","shell.execute_reply":"2021-06-13T22:06:59.524498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nprint(timm.__version__)\n\nimport os\nimport datetime as dt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport matplotlib.ticker as ticker\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import roc_auc_score, roc_curve\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast\nfrom torch.optim import Adam\n\nimport cv2\nimport albumentations as A\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.541941Z","iopub.execute_input":"2021-06-13T22:06:59.542224Z","iopub.status.idle":"2021-06-13T22:06:59.553152Z","shell.execute_reply.started":"2021-06-13T22:06:59.542197Z","shell.execute_reply":"2021-06-13T22:06:59.552159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data","metadata":{}},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/seti-breakthrough-listen'\n\ndef get_file_path(image_id, category):\n    return f\"{BASE_DIR}/{category}/{image_id[0]}/{image_id}.npy\"\n\ndef get_train_file_path(image_id):\n    return get_file_path(image_id, \"train\")\n\ndef get_test_file_path(image_id):\n    return get_file_path(image_id, \"test\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.560894Z","iopub.execute_input":"2021-06-13T22:06:59.561334Z","iopub.status.idle":"2021-06-13T22:06:59.568888Z","shell.execute_reply.started":"2021-06-13T22:06:59.561301Z","shell.execute_reply":"2021-06-13T22:06:59.567968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(f\"{BASE_DIR}/train_labels.csv\")\n\ntrain['img_path'] = train['id'].apply(get_train_file_path)\n\ndisplay(train.head(1))\nprint(train.head(1)['img_path'].values)\n\ndisplay(train['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.575585Z","iopub.execute_input":"2021-06-13T22:06:59.575859Z","iopub.status.idle":"2021-06-13T22:06:59.659541Z","shell.execute_reply.started":"2021-06-13T22:06:59.575834Z","shell.execute_reply":"2021-06-13T22:06:59.658697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test = pd.read_csv(f\"{BASE_DIR}/sample_submission.csv\")\n\n# test['img_path'] = test['id'].apply(get_test_file_path)\n\n# display(test.head(1))\n# print(test.head(1)['img_path'].values)\n\n# display(test['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.660777Z","iopub.execute_input":"2021-06-13T22:06:59.661087Z","iopub.status.idle":"2021-06-13T22:06:59.663808Z","shell.execute_reply.started":"2021-06-13T22:06:59.66106Z","shell.execute_reply":"2021-06-13T22:06:59.663188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling\n\nInitial Exploratory Data Analysis was done in https://www.kaggle.com/peterv1/seti-signal-search-data-exploration/\n\nUsing the EfficientNet ports to Pytorch from Ross Wightman Ref. https://github.com/rwightman/pytorch-image-models","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    debug = False\n\n    epochs = 6\n    \n    model_name = 'tf_efficientnet_b0' # pretrained b0, b1, b2, b3 increasing size\n    model_size = 224\n    test_model_size = 224\n\n    model_name = 'tf_efficientnetv2_b0'\n    # input_size=(3, 192, 192), test_input_size=(3, 224, 224), pool_size=(6, 6)\n    model_size = 192\n    test_model_size = 224\n\n    model_name = 'tf_efficientnetv2_b1'\n    # input_size=(3, 192, 192), test_input_size=(3, 240, 240), pool_size=(6, 6)\n    model_size = 192\n    test_model_size = 240\n    \n    batch_size = 64\n    inference_batch_size = 64\n    num_workers = 8\n    \n    criterion = nn.BCEWithLogitsLoss()\n    \n    seed = 45\n    \n    N_FOLDS = 5\n    p_horizontal_flip = 0.30\n    \n    lr = 5e-5\n\nif CFG.debug:\n    print('debug!')\n    CFG.epochs = 1\n    CFG.N_FOLDS = 4\n    CFG.batch_size = 8\n    CFG.inference_batch_size = 16\n    CFG.num_workers = 4\n\n    train = train.sample(n=193, random_state=CFG.seed).reset_index(drop=True)\n    if 'test' in locals():\n        test = test.head(153)\n    else:\n        print(\"test dataset is not loaded!\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.665371Z","iopub.execute_input":"2021-06-13T22:06:59.665784Z","iopub.status.idle":"2021-06-13T22:06:59.676089Z","shell.execute_reply.started":"2021-06-13T22:06:59.665758Z","shell.execute_reply":"2021-06-13T22:06:59.675133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make output dir\nOUTPUT_DIR = './output/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.677607Z","iopub.execute_input":"2021-06-13T22:06:59.67793Z","iopub.status.idle":"2021-06-13T22:06:59.691319Z","shell.execute_reply.started":"2021-06-13T22:06:59.677901Z","shell.execute_reply":"2021-06-13T22:06:59.690632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"ttransform = A.Compose([\n    A.RandomCrop(height=1638, width=250), # cut-off random 6 horizontally\n    A.Resize(CFG.model_size, CFG.model_size, cv2.INTER_NEAREST),\n    A.HorizontalFlip(p=CFG.p_horizontal_flip),\n])\nvtransform = A.Compose([\n    A.Resize(CFG.test_model_size, CFG.test_model_size, cv2.INTER_NEAREST)\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.692232Z","iopub.execute_input":"2021-06-13T22:06:59.692584Z","iopub.status.idle":"2021-06-13T22:06:59.702961Z","shell.execute_reply.started":"2021-06-13T22:06:59.692558Z","shell.execute_reply":"2021-06-13T22:06:59.702108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class ClassificationDataset:\n    \n    def __init__(self, img_paths, targets, tr): \n        self.img_paths = img_paths\n        self.targets = targets\n        self.tr = tr\n\n    def __len__(self):\n        return len(self.img_paths)\n    \n    def __getitem__(self, item):\n        img_path = self.img_paths[item]\n        image = np.load(img_path)\n        image = np.vstack(image).astype(float)\n        image = self.tr(image = image)[\"image\"][np.newaxis, ]\n        \n        target = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"target\": torch.tensor(target, dtype=torch.float),\n            \"img_id\": img_path.split('/')[-1].split('.')[0]\n        }","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.705895Z","iopub.execute_input":"2021-06-13T22:06:59.706513Z","iopub.status.idle":"2021-06-13T22:06:59.716124Z","shell.execute_reply.started":"2021-06-13T22:06:59.706465Z","shell.execute_reply":"2021-06-13T22:06:59.715441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preview","metadata":{}},{"cell_type":"code","source":"# Preview 5 training images via the ClassificationDataset\nX = train.img_path.values\ny = train.target.values\n\nsample_size = 5\ntrain_index = 130 # some random image\ntrain_images = X[train_index:train_index+sample_size]\ntrain_targets = y[train_index:train_index+sample_size]\n\n# Validation transformation (this Notebook is about analysis, not training)\ntrain_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform)\n\nfor i in range(sample_size):\n    image_target = train_dataset[i]\n    image, target = image_target['image'], image_target['target']\n    # transpose back from torch format to imshow format\n    plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n    plt.title(f'target: {target}')\n    plt.show()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:06:59.717328Z","iopub.execute_input":"2021-06-13T22:06:59.71783Z","iopub.status.idle":"2021-06-13T22:07:00.812438Z","shell.execute_reply.started":"2021-06-13T22:06:59.717775Z","shell.execute_reply":"2021-06-13T22:07:00.811423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview 2 test images via the ClassificationDataset\n# X = test.img_path.values\n# y = test.target.values\n\n# sample_size = 2\n# test_index = 27 # some random image\n# test_images = X[test_index:test_index+sample_size]\n# test_targets = y[test_index:test_index+sample_size]\n\n# test_dataset = ClassificationDataset(img_paths=test_images, targets=test_targets, tr=vtransform, ) # vtransform !\n\n# for i in range(sample_size):\n#     image_target = test_dataset[i]\n#     image, target = image_target['image'], image_target['target']\n#     # transpose back from torch format to imshow format\n#     plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n#     plt.title(f'target: {target}')\n#     plt.show()\n# image.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.815478Z","iopub.execute_input":"2021-06-13T22:07:00.81594Z","iopub.status.idle":"2021-06-13T22:07:00.820313Z","shell.execute_reply.started":"2021-06-13T22:07:00.815893Z","shell.execute_reply":"2021-06-13T22:07:00.81936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class timmv2(nn.Module):\n    def __init__(self, model_name, pretrained):\n        super().__init__()\n        \n        # Existing EfficientNet fixed at 3 channels\n        self.enet = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        \n        # Added a trainable 1 to 3 conv1 layer before\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=True)\n        \n        # set the output classifier to 1 feature\n        nb_ft = self.enet.classifier.in_features\n        self.enet.classifier = nn.Linear(nb_ft, 1)\n\n    @autocast()\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.enet(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.822546Z","iopub.execute_input":"2021-06-13T22:07:00.82296Z","iopub.status.idle":"2021-06-13T22:07:00.836327Z","shell.execute_reply.started":"2021-06-13T22:07:00.822914Z","shell.execute_reply":"2021-06-13T22:07:00.835691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_make(model_name):\n    model = timmv2(model_name, True) # Start from pre-trained\n    state_dict = {\n        'weight':torch.tensor(\n            [[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]]], requires_grad=True    \n        ),\n        'bias':torch.tensor(\n            [0.2, 0.2, 0.2], requires_grad=True\n        )}\n    model.conv1.load_state_dict(state_dict, strict=True)\n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.837513Z","iopub.execute_input":"2021-06-13T22:07:00.837781Z","iopub.status.idle":"2021-06-13T22:07:00.848455Z","shell.execute_reply.started":"2021-06-13T22:07:00.837755Z","shell.execute_reply":"2021-06-13T22:07:00.847822Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_make_custom(model_name, cnn_version, fold=0, epoch=-1):\n    model = timmv2(model_name, False) # Start from SELF-trained\n    \n    prefix = f\"/kaggle/input/seti-signal-search-cnn-{cnn_version}/output\"\n    if epoch >= 0:\n        file_name = f\"{prefix}/tf_efficientnetv2_b1_fold_{fold:02d}_epoch_{epoch:02d}_state.pth\"\n    else:\n        file_name = f\"{prefix}/tf_efficientnetv2_b1_fold_{fold:02d}_state.pth\"\n        \n    # TODO: is map_location cuda OK when model is not yet loaded in GPU ?\n    model.load_state_dict(torch.load(file_name, map_location=torch.device(device))['model'])    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.849503Z","iopub.execute_input":"2021-06-13T22:07:00.849861Z","iopub.status.idle":"2021-06-13T22:07:00.862403Z","shell.execute_reply.started":"2021-06-13T22:07:00.849836Z","shell.execute_reply":"2021-06-13T22:07:00.861765Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# model = model_make_custom(CFG.model_name, cnn_version=\"18\")\n\n# list(model.conv1.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.863295Z","iopub.execute_input":"2021-06-13T22:07:00.863652Z","iopub.status.idle":"2021-06-13T22:07:00.873001Z","shell.execute_reply.started":"2021-06-13T22:07:00.863621Z","shell.execute_reply":"2021-06-13T22:07:00.872429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# X = train.img_path.values\n# y = train.target.values\n\n# sample_size = 30\n# train_index = 0 # some random image\n# train_images = X[train_index:train_index+sample_size]\n# train_targets = y[train_index:train_index+sample_size]\n# train_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=vtransform)\n\n# FIG_SIZE = 6\n\n# model.eval() # from model_make_custom above\n\n# for i in range(sample_size):\n#     image_target = train_dataset[i]\n#     image, target = image_target['image'].unsqueeze(0), image_target['target']\n#     if target == torch.tensor(1.0):\n#         output = model(image).view(-1)\n#         print(output.detach().numpy(), target.detach().numpy(), image_target['img_id'])\n \n#         plt.figure(figsize=(FIG_SIZE, FIG_SIZE))\n#         plt.axes().yaxis.set_major_locator(ticker.MultipleLocator(40))\n#         plt.imshow(image.squeeze(0).numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n#         plt.title(f'target: {target}')\n#         plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.873915Z","iopub.execute_input":"2021-06-13T22:07:00.874298Z","iopub.status.idle":"2021-06-13T22:07:00.883194Z","shell.execute_reply.started":"2021-06-13T22:07:00.874261Z","shell.execute_reply":"2021-06-13T22:07:00.88263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.884084Z","iopub.execute_input":"2021-06-13T22:07:00.884456Z","iopub.status.idle":"2021-06-13T22:07:00.898087Z","shell.execute_reply.started":"2021-06-13T22:07:00.884418Z","shell.execute_reply":"2021-06-13T22:07:00.897474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training with folds","metadata":{}},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, criterion, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data['image']\n        targets = data['target']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        targets = targets.unsqueeze(1)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        \n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.898976Z","iopub.execute_input":"2021-06-13T22:07:00.899233Z","iopub.status.idle":"2021-06-13T22:07:00.909437Z","shell.execute_reply.started":"2021-06-13T22:07:00.899198Z","shell.execute_reply":"2021-06-13T22:07:00.908693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(data_loader, model, device):\n    \n    model.eval()\n    \n    final_outputs = []\n    final_targets = []\n    final_img_ids = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data['image']\n            targets = data['target']\n            img_ids = data['img_id']\n\n            inputs = inputs.to(device, dtype=torch.float)\n            output = model(inputs)\n            \n            output = output.detach().cpu().numpy().tolist()\n            targets = targets.numpy().tolist()\n\n            final_outputs.extend(output)\n            final_targets.extend(targets)\n            final_img_ids.extend(img_ids)\n            \n    return final_outputs, final_targets, final_img_ids","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.910515Z","iopub.execute_input":"2021-06-13T22:07:00.910932Z","iopub.status.idle":"2021-06-13T22:07:00.920467Z","shell.execute_reply.started":"2021-06-13T22:07:00.910892Z","shell.execute_reply":"2021-06-13T22:07:00.9198Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train models for each fold\n# DEBUG don't do training for real\n\n# models = []\n\n# X = train.img_path.values\n# y = train.target.values\n# skf = StratifiedKFold(n_splits=CFG.N_FOLDS)\n\n# fold = 0\n# for train_index, valid_index in skf.split(X, y):\n#     print(f\"Starting Fold {fold:02d}\")\n    \n#     train_images, valid_images = X[train_index], X[valid_index]\n#     train_targets, valid_targets = y[train_index], y[valid_index]\n\n#     train_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform)\n#     valid_dataset = ClassificationDataset(img_paths=valid_images, targets=valid_targets, tr=vtransform)\n    \n#     train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True , num_workers=CFG.num_workers)\n#     valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n\n#     optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n\n#     model = model_make(CFG.model_name)\n#     model.to(device)\n\n#     for epoch in range(CFG.epochs):\n#         train_fn(train_loader, model, optimizer, criterion, device=device)\n#         predictions, valid_targets, _ = eval_fn(valid_loader, model, device=device)\n#         roc_auc = get_score(valid_targets, predictions)\n#         print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n#         # print(list(model.conv1.parameters()))\n        \n#         # Save model after each fold and epoch\n#         torch.save({'model': model.state_dict()},\n#                    OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_state.pth\")\n        \n#     # append the latest model\n#     # TODO: select the \"best\" model (after each epoch), not the last epoch\n#     models.append(model)\n#     fold += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.921505Z","iopub.execute_input":"2021-06-13T22:07:00.921882Z","iopub.status.idle":"2021-06-13T22:07:00.947195Z","shell.execute_reply.started":"2021-06-13T22:07:00.921857Z","shell.execute_reply":"2021-06-13T22:07:00.946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evaluate models on validation AND training data for each fold and epoch\n# try to see if and when overfittigng occurs\n\n# DEBUG don't do evaluation for real (read back from saved files in CNN-20)\n\n# import csv\n\n# valid_results = []\n# train_results = []\n\n# X = train.img_path.values\n# y = train.target.values\n# skf = StratifiedKFold(n_splits=CFG.N_FOLDS)\n\n# fold = 0\n# for train_index, valid_index in skf.split(X, y):\n#     print(f\"Starting Fold {fold:02d}\")\n\n#     print(len(train_index), len(valid_index))\n#     print(train_index[0:5])\n#     print(valid_index[0:5])\n    \n#     train_images, valid_images = X[train_index], X[valid_index]\n#     train_targets, valid_targets = y[train_index], y[valid_index]\n\n#     train_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform)\n#     valid_dataset = ClassificationDataset(img_paths=valid_images, targets=valid_targets, tr=vtransform)\n\n#     # Here, since validation, shuffle False\n#     train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n#     valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n\n#     valid_results_per_fold = []\n#     train_results_per_fold = []\n    \n#     # First 3 (0,1,2) from CNN-19\n#     # epoch 6 (faked here as epoch 4) from CNN-18\n#     for epoch in range(4):\n#         if (epoch < 3):\n#             model = model_make_custom(CFG.model_name, \"19\", fold=fold, epoch=epoch)\n#         elif (epoch == 3):\n#             epoch = 5 # only the sixth one was saved in CNN-18\n#             model = model_make_custom(CFG.model_name, \"18\", fold=fold)\n            \n#         model.to(device)\n\n#         # Validation over VALID data\n#         predictions, targets, img_ids = eval_fn(valid_loader, model, device=device)\n#         roc_auc = get_score(targets, predictions)\n#         print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n\n#         # predictions need to be flattened\n#         flat_predictions = []\n#         list(map(flat_predictions.extend, predictions))\n#         valid_results_per_fold_per_epoch = np.dstack((flat_predictions, targets, img_ids))[0]\n\n#         filename = OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_validation.csv\"\n        \n#         with open(filename, 'w') as f:\n#             csv.writer(f).writerows(valid_results_per_fold_per_epoch)\n        \n#         valid_results_per_fold.append(valid_results_per_fold_per_epoch)\n\n#         # Validation over TRAIN data\n#         predictions, targets, img_ids = eval_fn(train_loader, model, device=device)\n#         roc_auc = get_score(targets, predictions)\n#         print(f\"Epoch={epoch}, Train ROC AUC={roc_auc}\")\n\n#         # predictions need to be flattened\n#         flat_predictions = []\n#         list(map(flat_predictions.extend, predictions))\n#         train_results_per_fold_per_epoch = np.dstack((flat_predictions, targets, img_ids))[0]\n\n#         filename = OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_training.csv\"\n        \n#         with open(filename, 'w') as f:\n#             csv.writer(f).writerows(train_results_per_fold_per_epoch)\n        \n#         train_results_per_fold.append(train_results_per_fold_per_epoch)\n        \n#     valid_results.append(valid_results_per_fold)\n#     train_results.append(train_results_per_fold)\n\n#     fold += 1\n    \n#     # DEBUG only 2 folds have this models calculated\n#     if fold == 2:\n#         break","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.948273Z","iopub.execute_input":"2021-06-13T22:07:00.948542Z","iopub.status.idle":"2021-06-13T22:07:00.995673Z","shell.execute_reply.started":"2021-06-13T22:07:00.948517Z","shell.execute_reply":"2021-06-13T22:07:00.994733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Read back Evaluation of models on validation AND training data for each fold and epoch\n# try to see if and when overfittigng occurs\n\ncnn_version = 20\nINPUT_DIR = f\"/kaggle/input/seti-signal-search-cnn-{cnn_version}/output\"\n\nimport csv\n\nvalid_results = []\ntrain_results = []\n\nX = train.img_path.values\ny = train.target.values\nskf = StratifiedKFold(n_splits=CFG.N_FOLDS) # we still hope this is reliable ...\n\nfold = 0\nfor train_index, valid_index in skf.split(X, y):    \n    print(f\"Starting Fold {fold:02d}\")\n\n    print(len(train_index), len(valid_index))\n    print(train_index[0:5])\n    print(valid_index[0:5])\n    \n    train_images, valid_images = X[train_index], X[valid_index]\n    train_targets, valid_targets = y[train_index], y[valid_index]\n\n    valid_results_per_fold = []\n    train_results_per_fold = []\n    \n    # First 3 (0,1,2) model from CNN-19 => evals in CNN-20\n    # epoch 6 (fake 4) model from CNN-18 => evals in CNN-20\n    for epoch in range(4):\n        if (epoch < 3):\n            pass\n        elif (epoch == 3):\n            epoch = 5 # only the sixth one was saved in CNN-18\n            \n        # Validation over VALID data\n        valid_results_per_fold_per_epoch = []\n        filename = f\"{INPUT_DIR}/{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_validation.csv\"\n        with open(filename, 'r') as f:\n            data_reader = csv.reader(f)\n            for row in data_reader:\n                valid_results_per_fold_per_epoch.append(row)\n                \n        df_valid_results_per_fold_per_epoch = (\n            pd.DataFrame(valid_results_per_fold_per_epoch, columns = ['predictions', 'targets', 'img_ids'])\n        ) \n        valid_results_per_fold.append(valid_results_per_fold_per_epoch)\n\n        roc_auc = get_score(df_valid_results_per_fold_per_epoch['targets'], df_valid_results_per_fold_per_epoch['predictions'])\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n            \n        # Validation over TRAIN data\n        train_results_per_fold_per_epoch = []\n        filename = f\"{INPUT_DIR}/{CFG.model_name}_fold_{fold:02d}_epoch_{epoch:02d}_training.csv\"\n        with open(filename, 'r') as f:\n            data_reader = csv.reader(f)\n            for row in data_reader:\n                train_results_per_fold_per_epoch.append(row)\n                \n        df_train_results_per_fold_per_epoch = (\n            pd.DataFrame(train_results_per_fold_per_epoch, columns = ['predictions', 'targets', 'img_ids'])\n        ) \n        train_results_per_fold.append(train_results_per_fold_per_epoch)\n\n        roc_auc = get_score(df_train_results_per_fold_per_epoch['targets'], df_train_results_per_fold_per_epoch['predictions'])\n        print(f\"Epoch={epoch}, Train ROC AUC={roc_auc}\")\n        \n    valid_results.append(valid_results_per_fold)\n    train_results.append(train_results_per_fold)\n\n    fold += 1\n    \n    # DEBUG only 2 folds have this models calculated\n    if fold == 2:\n        break","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:00.997177Z","iopub.execute_input":"2021-06-13T22:07:00.997737Z","iopub.status.idle":"2021-06-13T22:07:04.10553Z","shell.execute_reply.started":"2021-06-13T22:07:00.997698Z","shell.execute_reply":"2021-06-13T22:07:04.104453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(valid_results_per_fold[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:04.107039Z","iopub.execute_input":"2021-06-13T22:07:04.107439Z","iopub.status.idle":"2021-06-13T22:07:04.113945Z","shell.execute_reply.started":"2021-06-13T22:07:04.107397Z","shell.execute_reply":"2021-06-13T22:07:04.113069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(train_results_per_fold[0])","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:04.115579Z","iopub.execute_input":"2021-06-13T22:07:04.116024Z","iopub.status.idle":"2021-06-13T22:07:04.124133Z","shell.execute_reply.started":"2021-06-13T22:07:04.115988Z","shell.execute_reply":"2021-06-13T22:07:04.123491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fpr_valid, tpr_valid, threshold_valid = roc_curve(df_valid_results_per_fold_per_epoch['targets'].astype(float).astype(int), df_valid_results_per_fold_per_epoch['predictions'].astype(float))\nfpr_train, tpr_train, threshold_train = roc_curve(df_train_results_per_fold_per_epoch['targets'].astype(float).astype(int), df_train_results_per_fold_per_epoch['predictions'].astype(float))\n\nFIG_SIZE = 8\n\nplt.subplots(1, figsize=(FIG_SIZE, FIG_SIZE))\n\nplt.title('ROC - validation data')\nplt.plot(fpr_valid, tpr_valid, 'b')\n#plt.plot(fpr_valid, threshold_valid / 10.0, 'r')\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.xlabel(\"False Positive Rate\" , fontsize=12)\nplt.ylabel(\"True Positive Rate\" , fontsize=12)\n\nplt.subplots(1, figsize=(FIG_SIZE, FIG_SIZE))\n\nplt.title('ROC - train data')\nplt.plot(fpr_train, tpr_train, 'b')\n#plt.plot(fpr_train, threshold_train / 10.0, 'r')\nplt.plot([0, 1], ls=\"--\")\nplt.plot([0, 0], [1, 0] , c=\".7\"), plt.plot([1, 1] , c=\".7\")\nplt.xlabel(\"False Positive Rate\" , fontsize=12)\nplt.ylabel(\"True Positive Rate\" , fontsize=12)\n\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T22:07:04.126763Z","iopub.execute_input":"2021-06-13T22:07:04.127086Z","iopub.status.idle":"2021-06-13T22:07:04.451556Z","shell.execute_reply.started":"2021-06-13T22:07:04.127057Z","shell.execute_reply":"2021-06-13T22:07:04.45053Z"},"trusted":true},"execution_count":null,"outputs":[]}]}