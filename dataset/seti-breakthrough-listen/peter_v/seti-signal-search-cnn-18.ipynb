{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SETI Signal Search - CNN - 18\n\n## Specific\n\n* Use EfficientNet from timm https://www.kaggle.com/kozodoi/timm-pytorch-image-models\n* try network v2 and also look at the parameters\n\n## Global\n\nTry to predict the presence of \"needles\" with a CNN using PyTorch.\n\nFor transfer learning, look at TF EfficientNet and TF EfficientNet V2\n\nIn the list of Pytorch Image models https://paperswithcode.com/lib/timm/ and sorting them by TOP 1 Accuracy, the EfficientNet is the first model that goes under 10 Billion Flops. Also, there are variations from b0 to b8 that I presume will make it possible to trade-off compute cost vs. accuracy.\n\nVery recently (14 May) the V2 was ported to this PyTorch repo. Maybe also testing tf_efficientnetv2_b0 up to tf_efficientnetv2_b3 ?\n\nInspired by https://www.kaggle.com/piantic/train-seti-pytorch-starter-chans-vs-spatial from https://www.kaggle.com/piantic\n\nKFold and initial Convolutional filter inspired by Salman https://www.kaggle.com/micheomaano/mixup-training-5fold-spatial/execution","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-05-24T20:03:54.280487Z","iopub.execute_input":"2021-05-24T20:03:54.281095Z","iopub.status.idle":"2021-05-24T20:03:54.291082Z","shell.execute_reply.started":"2021-05-24T20:03:54.281042Z","shell.execute_reply":"2021-05-24T20:03:54.28971Z"}}},{"cell_type":"markdown","source":"# Libraries","metadata":{}},{"cell_type":"code","source":"# import os\n\n# print(\"os.walk in /kaggle/input/\")\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames[0:1]:\n#         print(os.path.join(dirname, filename))","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:05.185881Z","iopub.execute_input":"2021-06-11T22:45:05.186349Z","iopub.status.idle":"2021-06-11T22:45:05.190096Z","shell.execute_reply.started":"2021-06-11T22:45:05.186259Z","shell.execute_reply":"2021-06-11T22:45:05.189192Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('/kaggle/input/timm-pytorch-image-models/pytorch-image-models-master')\nimport timm\nprint(timm.__version__)\n\nimport os\nimport datetime as dt\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nfrom tqdm import tqdm\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold, StratifiedKFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.cuda.amp import autocast\nfrom torch.optim import Adam\n\nimport cv2\nimport albumentations as A\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:05.204864Z","iopub.execute_input":"2021-06-11T22:45:05.205134Z","iopub.status.idle":"2021-06-11T22:45:10.192018Z","shell.execute_reply.started":"2021-06-11T22:45:05.205108Z","shell.execute_reply":"2021-06-11T22:45:10.191232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Import data","metadata":{}},{"cell_type":"code","source":"BASE_DIR = '/kaggle/input/seti-breakthrough-listen'\n\ndef get_file_path(image_id, category):\n    return f\"{BASE_DIR}/{category}/{image_id[0]}/{image_id}.npy\"\n\ndef get_train_file_path(image_id):\n    return get_file_path(image_id, \"train\")\n\ndef get_test_file_path(image_id):\n    return get_file_path(image_id, \"test\")\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.193516Z","iopub.execute_input":"2021-06-11T22:45:10.193848Z","iopub.status.idle":"2021-06-11T22:45:10.199063Z","shell.execute_reply.started":"2021-06-11T22:45:10.193812Z","shell.execute_reply":"2021-06-11T22:45:10.198005Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(f\"{BASE_DIR}/train_labels.csv\")\ntest = pd.read_csv(f\"{BASE_DIR}/sample_submission.csv\")\n\ntrain['img_path'] = train['id'].apply(get_train_file_path)\ntest['img_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(train.head(1))\ndisplay(test.head(1))\nprint(train.head(1)['img_path'].values)\nprint(test.head(1)['img_path'].values)\n\ndisplay(train['target'].value_counts())\ndisplay(test['target'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.201083Z","iopub.execute_input":"2021-06-11T22:45:10.201457Z","iopub.status.idle":"2021-06-11T22:45:10.478446Z","shell.execute_reply.started":"2021-06-11T22:45:10.201417Z","shell.execute_reply":"2021-06-11T22:45:10.477678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling\n\nInitial Exploratory Data Analysis was done in https://www.kaggle.com/peterv1/seti-signal-search-data-exploration/\n\nUsing the EfficientNet ports to Pytorch from Ross Wightman Ref. https://github.com/rwightman/pytorch-image-models","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"class CFG:\n    debug = False\n\n    epochs = 6 # per fold ! (takes 11 minutes enet-b0 ... risk of going just over the 9 hours time-out)\n    \n    model_name = 'tf_efficientnet_b0' # pretrained b0, b1, b2, b3 increasing size\n    model_size = 224\n    test_model_size = 224\n\n    model_name = 'tf_efficientnetv2_b0'\n    # input_size=(3, 192, 192), test_input_size=(3, 224, 224), pool_size=(6, 6)\n    model_size = 192\n    test_model_size = 224\n\n    model_name = 'tf_efficientnetv2_b1'\n    # input_size=(3, 192, 192), test_input_size=(3, 240, 240), pool_size=(6, 6)\n    model_size = 192\n    test_model_size = 240\n    \n    batch_size = 64\n    inference_batch_size = 64\n    num_workers = 8\n    \n    seed = 45\n    \n    N_FOLDS = 5\n    p_horizontal_flip = 0.30\n    \n    lr = 5e-5\n\nif CFG.debug:\n    print('debug!')\n    CFG.epochs = 1\n    CFG.N_FOLDS = 4\n    CFG.batch_size = 8\n    CFG.inference_batch_size = 16\n    CFG.num_workers = 4\n\n    train = train.sample(n=193, random_state=CFG.seed).reset_index(drop=True)\n    test = test.head(153)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.480051Z","iopub.execute_input":"2021-06-11T22:45:10.480411Z","iopub.status.idle":"2021-06-11T22:45:10.487481Z","shell.execute_reply.started":"2021-06-11T22:45:10.480373Z","shell.execute_reply":"2021-06-11T22:45:10.486627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make output dir\nOUTPUT_DIR = './output/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.488856Z","iopub.execute_input":"2021-06-11T22:45:10.489427Z","iopub.status.idle":"2021-06-11T22:45:10.501853Z","shell.execute_reply.started":"2021-06-11T22:45:10.489389Z","shell.execute_reply":"2021-06-11T22:45:10.500969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"ttransform = A.Compose([\n    A.RandomCrop(height=1638, width=250), # cut-of random 6 horizontally\n    A.Resize(CFG.model_size, CFG.model_size, cv2.INTER_NEAREST),\n    A.HorizontalFlip(p=CFG.p_horizontal_flip),\n])\nvtransform = A.Compose([\n    A.Resize(CFG.test_model_size, CFG.test_model_size, cv2.INTER_NEAREST)\n])","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.505202Z","iopub.execute_input":"2021-06-11T22:45:10.505484Z","iopub.status.idle":"2021-06-11T22:45:10.512418Z","shell.execute_reply.started":"2021-06-11T22:45:10.505453Z","shell.execute_reply":"2021-06-11T22:45:10.511576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class ClassificationDataset:\n    \n    def __init__(self, img_paths, targets, tr): \n        self.img_paths = img_paths\n        self.targets = targets\n        self.tr = tr\n\n    def __len__(self):\n        return len(self.img_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.img_paths[item])\n        image = np.vstack(image).astype(float)\n        image = self.tr(image = image)[\"image\"][np.newaxis, ]\n        \n        target = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"target\": torch.tensor(target, dtype=torch.float),\n        }","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.514801Z","iopub.execute_input":"2021-06-11T22:45:10.515073Z","iopub.status.idle":"2021-06-11T22:45:10.523133Z","shell.execute_reply.started":"2021-06-11T22:45:10.515023Z","shell.execute_reply":"2021-06-11T22:45:10.52226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preview","metadata":{}},{"cell_type":"code","source":"# Preview 3 training images in the via the ClassificationDataset\nX = train.img_path.values\ny = train.target.values\n\nsample_size = 2\ntrain_index = 30 # some random image\ntrain_images = X[train_index:train_index+sample_size]\ntrain_targets = y[train_index:train_index+sample_size]\ntrain_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform, )\n\nfor i in range(sample_size):\n    image_target = train_dataset[i]\n    image, target = image_target['image'], image_target['target']\n    # transpose back from torch format to imshow format\n    plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n    plt.title(f'target: {target}')\n    plt.show()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.526241Z","iopub.execute_input":"2021-06-11T22:45:10.526491Z","iopub.status.idle":"2021-06-11T22:45:10.915915Z","shell.execute_reply.started":"2021-06-11T22:45:10.526467Z","shell.execute_reply":"2021-06-11T22:45:10.915014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Preview 3 test images in the via the ClassificationDataset\nX = test.img_path.values\ny = test.target.values\n\nsample_size = 2\ntest_index = 27 # some random image\ntest_images = X[test_index:test_index+sample_size]\ntest_targets = y[test_index:test_index+sample_size]\n\ntest_dataset = ClassificationDataset(img_paths=test_images, targets=test_targets, tr=vtransform, ) # vtransform !\n\nfor i in range(sample_size):\n    image_target = test_dataset[i]\n    image, target = image_target['image'], image_target['target']\n    # transpose back from torch format to imshow format\n    plt.imshow(image.numpy().transpose((1, 2, 0))[:,:,0]) # only 1 axis\n    plt.title(f'target: {target}')\n    plt.show()\nimage.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:10.917922Z","iopub.execute_input":"2021-06-11T22:45:10.918298Z","iopub.status.idle":"2021-06-11T22:45:11.404768Z","shell.execute_reply.started":"2021-06-11T22:45:10.91826Z","shell.execute_reply":"2021-06-11T22:45:11.403934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"# pre-loaded with previous training ...\n# model = SETImodel(model_name=CFG.encoder, pretrained=False)\n# file_name = '/kaggle/input/seti-signal-search-cnn-11/output/tf_efficientnet_b0_epoch_07_state.pth'\n# model.load_state_dict(torch.load(file_name, map_location=torch.device(device))['model'])","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:11.407624Z","iopub.execute_input":"2021-06-11T22:45:11.410309Z","iopub.status.idle":"2021-06-11T22:45:11.414796Z","shell.execute_reply.started":"2021-06-11T22:45:11.410267Z","shell.execute_reply":"2021-06-11T22:45:11.414065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class timmv2(nn.Module):\n    def __init__(self, model_name, pretrained):\n        super().__init__()\n        \n        # Existing EfficientNet fixed at 3 channels\n        self.enet = timm.create_model(model_name, pretrained=pretrained, in_chans=3)\n        \n        # Added a trainable 1 to 3 conv1 layer before\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=True)\n        \n        # set the output classifier to 1 feature\n        nb_ft = self.enet.classifier.in_features\n        self.enet.classifier = nn.Linear(nb_ft, 1)\n\n    @autocast()\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.enet(x)\n        \n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:11.417444Z","iopub.execute_input":"2021-06-11T22:45:11.418052Z","iopub.status.idle":"2021-06-11T22:45:11.431527Z","shell.execute_reply.started":"2021-06-11T22:45:11.417997Z","shell.execute_reply":"2021-06-11T22:45:11.430573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def model_make(model_name):\n    model = timmv2(model_name, True)\n    state_dict = {\n        'weight':torch.tensor(\n            [[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]],[[\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n                [ -0.03, 0.1,  -0.03],\n            ]]], requires_grad=True    \n        ),\n        'bias':torch.tensor(\n            [0.2, 0.2, 0.2], requires_grad=True\n        )}\n    model.conv1.load_state_dict(state_dict, strict=True)\n    return model\n\nmodel = model_make(CFG.model_name)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:11.435865Z","iopub.execute_input":"2021-06-11T22:45:11.437874Z","iopub.status.idle":"2021-06-11T22:45:13.363404Z","shell.execute_reply.started":"2021-06-11T22:45:11.437833Z","shell.execute_reply":"2021-06-11T22:45:13.362518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(model.conv1.parameters())","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:13.364683Z","iopub.execute_input":"2021-06-11T22:45:13.365022Z","iopub.status.idle":"2021-06-11T22:45:13.400116Z","shell.execute_reply.started":"2021-06-11T22:45:13.364985Z","shell.execute_reply":"2021-06-11T22:45:13.399091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = train.img_path.values\ny = train.target.values\n\nsample_size = 10\ntrain_index = 30 # some random image\ntrain_images = X[train_index:train_index+sample_size]\ntrain_targets = y[train_index:train_index+sample_size]\ntrain_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=vtransform, )\n\nmodel.eval()\n\nfor i in range(sample_size):\n    image_target = train_dataset[i]\n    image, target = image_target['image'].unsqueeze(0), image_target['target']\n    output = model(image).view(-1)\n    print(output, target)","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:13.401681Z","iopub.execute_input":"2021-06-11T22:45:13.402047Z","iopub.status.idle":"2021-06-11T22:45:14.816655Z","shell.execute_reply.started":"2021-06-11T22:45:13.401996Z","shell.execute_reply":"2021-06-11T22:45:14.815783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:14.817817Z","iopub.execute_input":"2021-06-11T22:45:14.818153Z","iopub.status.idle":"2021-06-11T22:45:14.824117Z","shell.execute_reply.started":"2021-06-11T22:45:14.818121Z","shell.execute_reply":"2021-06-11T22:45:14.823008Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training with folds","metadata":{}},{"cell_type":"code","source":"def train_fn(data_loader, model, optimizer, criterion, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data['image']\n        targets = data['target']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        targets = targets.unsqueeze(1)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        \n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()        ","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:14.825544Z","iopub.execute_input":"2021-06-11T22:45:14.826002Z","iopub.status.idle":"2021-06-11T22:45:14.834081Z","shell.execute_reply.started":"2021-06-11T22:45:14.825956Z","shell.execute_reply":"2021-06-11T22:45:14.833289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def eval_fn(data_loader, model, device):\n    \n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data['image']\n            targets = data['target']\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            targets = targets.unsqueeze(1)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:14.835552Z","iopub.execute_input":"2021-06-11T22:45:14.835994Z","iopub.status.idle":"2021-06-11T22:45:14.847327Z","shell.execute_reply.started":"2021-06-11T22:45:14.835952Z","shell.execute_reply":"2021-06-11T22:45:14.846459Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\n\nX = train.img_path.values\ny = train.target.values\nskf = StratifiedKFold(n_splits=CFG.N_FOLDS)\ncriterion = nn.BCEWithLogitsLoss()\n\nfold = 0\nfor train_index, valid_index in skf.split(X, y):\n    \n    model = model_make(CFG.model_name)\n    model.to(device)\n\n    train_images, valid_images = X[train_index], X[valid_index]\n    train_targets, valid_targets = y[train_index], y[valid_index]\n\n    train_dataset = ClassificationDataset(img_paths=train_images, targets=train_targets, tr=ttransform)\n    valid_dataset = ClassificationDataset(img_paths=valid_images, targets=valid_targets, tr=vtransform)\n    \n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=CFG.batch_size, shuffle=True , num_workers=CFG.num_workers)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=CFG.lr)\n\n    for epoch in range(CFG.epochs):\n        train_fn(train_loader, model, optimizer, criterion, device=device)\n        predictions, valid_targets = eval_fn(valid_loader, model, device=device)\n        roc_auc = get_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        print(list(model.conv1.parameters()))\n        \n    torch.save({'model': model.state_dict()},\n               OUTPUT_DIR+f\"{CFG.model_name}_fold_{fold:02d}_state.pth\")\n    models.append(model)\n    fold += 1","metadata":{"execution":{"iopub.status.busy":"2021-06-11T22:45:14.850234Z","iopub.execute_input":"2021-06-11T22:45:14.850486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor model in models:\n    test_dataset = ClassificationDataset(img_paths=test.img_path.values, targets=test.target.values, tr=vtransform)\n    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=CFG.inference_batch_size, shuffle=False, num_workers=CFG.num_workers)\n    predictions, valid_targets = eval_fn(test_loader, model, device=device)\n    preds.append(predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"outputs = []\nfor predictions in preds:\n    predictions = np.array(predictions)[:, 0]\n    sig = torch.nn.Sigmoid()\n    outs = sig(torch.from_numpy(predictions))\n    outs = outs.detach().numpy()\n    outputs.append(outs)\n    \n# TODO: given the asymmetric nature of the signal (a small signal is still a signal); non-linear averaging might be more relevant here ???\noutputs = np.mean(outputs, axis = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(outputs[0:10])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.target = outputs\ntest.drop(['img_path'], axis=1, inplace=True)\ntest.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}