{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"This is a simple baseline using Resnet-18. The source code on this notebook is based on @abhishek Abhishek Thakur's [AAAMLP](https://github.com/abhi1thakur/approachingalmost) textbook.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q pretrainedmodels","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pretrainedmodels\nimport albumentations","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets, resize=None, augmentations=None): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.resize = resize\n        self.augmentations = augmentations\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item]).astype(float)\n\n        targets = self.targets[item]\n        \n        if self.resize is not None:\n            image = np.transpose(image, (1,2,0))\n            image = cv2.resize(image, dsize=self.resize, interpolation=cv2.INTER_CUBIC)        \n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n            \n        # pytorch expects CHW instead of HWC\n        image = np.transpose(image, (2, 0, 1)).astype(np.float32)\n        \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels['img_path'] = train_labels['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataloader = ClassificationDataset(image_paths=train_labels['img_path'], targets=train_labels['target'], resize=(256, 256))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        inputs = data[\"image\"]\n        targets = data['targets']\n        \n        inputs = inputs.to(device, dtype=torch.float)\n        targets = targets.to(device, dtype=torch.float)\n        \n        optimizer.zero_grad()\n        outputs = model(inputs)\n        loss = nn.BCEWithLogitsLoss()(outputs, targets.view(-1, 1))\n        loss.backward()\n        optimizer.step()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn\nimport pretrainedmodels\n\ndef get_model(pretrained):\n    if pretrained:\n        model = pretrainedmodels.__dict__[\"resnet18\"](pretrained='imagenet')\n    else:\n        model = pretrainedmodels.__dict__[\"resnet18\"](pretrained=None)\n        \n    model.last_linear = nn.Sequential(\n        nn.BatchNorm1d(512),\n        nn.Dropout(p=0.25),\n        nn.Linear(in_features=512, out_features=1024),\n        nn.ReLU(),\n        nn.BatchNorm1d(1024, eps=1e-05, momentum=0.1),\n        nn.Dropout(p=0.5),\n        nn.Linear(in_features=1024, out_features=1)\n    )\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train","metadata":{}},{"cell_type":"code","source":"device = \"cuda\"\n\nepochs = 5\n\nimages = train_labels.img_path.values\n\ntargets = train_labels.target.values\n\nmodel = get_model(pretrained=False)\nmodel.conv1 = nn.Conv2d(6, 64, kernel_size=7, stride=2, padding=3,bias=False)\n\nmodel.to(device)\n\n# mean = (0.485, 0.456, 0.406)\n# std = (0.229, 0.224, 0.225)\n\n# aug = albumentations.Compose([albumentations.Normalize(mean, std, max_pixel_value=255.0, always_apply=True)])\naug = None\n\ntrain_images, valid_images, train_targets, valid_targets = train_test_split(images, targets, stratify=targets, random_state=42)\n\ntrain_dataset = ClassificationDataset(image_paths=train_images,\n                                     targets=train_targets,\n                                     resize=(224, 224),\n                                     augmentations=aug)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset,\n                                          batch_size=16,\n                                          shuffle=True,\n                                          num_workers=4)\n\nvalid_dataset = ClassificationDataset(image_paths=valid_images,\n                                     targets=valid_targets,\n                                     resize=(224, 224),\n                                     augmentations=aug)\n\nvalid_loader = torch.utils.data.DataLoader(valid_dataset,\n                                          batch_size=16,\n                                          shuffle=False,\n                                          num_workers=4)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\nfor epoch in range(epochs):\n    train(train_loader, model, optimizer, device=device)\n    predictions, valid_targets = evaluate(valid_loader, model, device=device)\n    roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n    print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model.state_dict(),f'resnet18_{epochs}.pt')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Inference","metadata":{}},{"cell_type":"code","source":"submission = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = submission.img_path.values\n\ndummy_targets = submission.target.values\n\ntest_dataset = ClassificationDataset(image_paths=test_images,\n                                     targets=dummy_targets,\n                                     resize=(224, 224),\n                                     augmentations=aug)\n\ntest_loader = torch.utils.data.DataLoader(test_dataset,\n                                          batch_size=16,\n                                          shuffle=False,\n                                          num_workers=4)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions, valid_targets = evaluate(test_loader, model, device=device)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# normalize\npredictions = np.array(predictions)\n\npredictions = (predictions - predictions.min()) / (predictions.max() - predictions.min())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target = predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.drop(['img_path'], axis=1, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}