{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# With Efficient net, I am able to get 98% Accuracy.\n# Prior to this,I Tried to classify wihtout training network, just by using image net weights can get only 50% accuracy.\n# By Training all layers in the network I am able to ge 98 % accurcy.\n# Instead of Dense layer at the end,used Convolution + Dense Layer.\n","metadata":{}},{"cell_type":"code","source":"!pip install -U efficientnet","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:39:35.74328Z","iopub.execute_input":"2021-07-17T06:39:35.74369Z","iopub.status.idle":"2021-07-17T06:39:43.718167Z","shell.execute_reply.started":"2021-07-17T06:39:35.743604Z","shell.execute_reply":"2021-07-17T06:39:43.717244Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -q --upgrade wandb \n\nimport wandb\nprint(wandb.__version__)\nfrom wandb.keras import WandbCallback\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:39:43.719927Z","iopub.execute_input":"2021-07-17T06:39:43.720298Z","iopub.status.idle":"2021-07-17T06:39:58.20941Z","shell.execute_reply.started":"2021-07-17T06:39:43.720258Z","shell.execute_reply":"2021-07-17T06:39:58.208526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wandb.login()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:39:58.211376Z","iopub.execute_input":"2021-07-17T06:39:58.211733Z","iopub.status.idle":"2021-07-17T06:39:58.215399Z","shell.execute_reply.started":"2021-07-17T06:39:58.211694Z","shell.execute_reply":"2021-07-17T06:39:58.214614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.model_selection import StratifiedKFold\nimport tensorflow_addons as tfa\nfrom sklearn.utils import class_weight\nimport os \n\nimport efficientnet.keras as efn\nfrom sklearn.metrics import confusion_matrix\n\nimport glob","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:52.01289Z","iopub.execute_input":"2021-07-17T06:40:52.01325Z","iopub.status.idle":"2021-07-17T06:40:52.018453Z","shell.execute_reply.started":"2021-07-17T06:40:52.013215Z","shell.execute_reply":"2021-07-17T06:40:52.017557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:57.175323Z","iopub.execute_input":"2021-07-17T06:40:57.175677Z","iopub.status.idle":"2021-07-17T06:40:57.182831Z","shell.execute_reply.started":"2021-07-17T06:40:57.175645Z","shell.execute_reply":"2021-07-17T06:40:57.181687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# How to enable data generator for TPU usage\nStep1- to use TPU : https://www.kaggle.com/product-feedback/163416\nhttps://www.kaggle.com/manjunathns/tensorflow-tpu-seti-efficientnet-train/edit","metadata":{}},{"cell_type":"code","source":"AUTO_ENCODER = True\nEFFNET = False\n\ntrain_csv = \"../input/seti-breakthrough-listen/train_labels.csv\"\ntrain_df_master = pd.read_csv( train_csv)\ntrain_df_master[\"path\"] = train_df_master[\"id\"].apply( lambda x: \"../input/seti-breakthrough-listen/train/\"+ str(x[0]) +\"/\"+x +\".npy\" )\ntrain_df_master.head()\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:59.454075Z","iopub.execute_input":"2021-07-17T06:40:59.454438Z","iopub.status.idle":"2021-07-17T06:40:59.536718Z","shell.execute_reply.started":"2021-07-17T06:40:59.454405Z","shell.execute_reply":"2021-07-17T06:40:59.535682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Lets Visualize few numpy files","metadata":{}},{"cell_type":"code","source":"def create_heat_map( file_name,target  ):\n    data = np.load( file_name  )\n    plt.figure( figsize =( 16,8), dpi = 80 )\n    for i in range( 0, 6):\n        plt.subplot( 1, 6, i +1)\n        sns.heatmap( data [ i ] )\n        plt.suptitle ( file_name +\" = \"+ str ( target) )\n    plt.show()\n#create_heat_map ( train_df_master[\"path\"].iloc[np.random.randint (1000) ]  )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:41:01.676059Z","iopub.execute_input":"2021-07-17T06:41:01.676428Z","iopub.status.idle":"2021-07-17T06:41:01.682931Z","shell.execute_reply.started":"2021-07-17T06:41:01.676378Z","shell.execute_reply":"2021-07-17T06:41:01.681833Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range ( 0,4 ):\n    if i % 2 == 0 & False :\n        shape = train_df_master[train_df_master[\"target\"] == 0 ].shape[0]\n        file_name = train_df_master[\"path\"].iloc[ shape]\n        target = 0\n    else:\n        shape = train_df_master[train_df_master[\"target\"] == 1 ].shape[0]\n        file_name = train_df_master[\"path\"].iloc[ shape ]\n        target = 1\n        \n    create_heat_map( file_name, target  )\n        ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:01.203843Z","iopub.execute_input":"2021-07-17T06:40:01.204234Z","iopub.status.idle":"2021-07-17T06:40:21.390682Z","shell.execute_reply.started":"2021-07-17T06:40:01.204197Z","shell.execute_reply":"2021-07-17T06:40:21.384113Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure( figsize=(10,5), dpi = 80 ) \nsns.countplot( train_df_master['target'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.393032Z","iopub.execute_input":"2021-07-17T06:40:21.393518Z","iopub.status.idle":"2021-07-17T06:40:21.510674Z","shell.execute_reply.started":"2021-07-17T06:40:21.393467Z","shell.execute_reply":"2021-07-17T06:40:21.509696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"*  Objetive is to identify anomally, and we have 6 channels.\n*  In that channels 1,3,5 are man made & channel 0,2,4 are from man made + outer space.\n*  Good part is, any channel 0,2,4 might have signal from Extra terestrial [ET]orall channels .\n*  So for auto Encoder instead of taking entire image  -->not working ,asimgaedimension + network size too big tohandle \n     1. We can start training Auto Encoder using channel bychannel\n     2. We could use all channels from target 0.\n\n*  This way we can reduce the complexity of model to very small. as we are not lookign at image in3 Dimention. Rather we are going look at it only in 2 Dimension\n* Same method will be applied by using any latest Pretrained models ","metadata":{}},{"cell_type":"code","source":"## perform over sample \nif True:\n    \n    anamolly_df  = train_df_master[ train_df_master[\"target\"] == 1]\n    train_df_master = pd.concat (  [ train_df_master,anamolly_df,anamolly_df,anamolly_df ])\n    train_df_master.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:41:07.468178Z","iopub.execute_input":"2021-07-17T06:41:07.468512Z","iopub.status.idle":"2021-07-17T06:41:07.48631Z","shell.execute_reply.started":"2021-07-17T06:41:07.468482Z","shell.execute_reply":"2021-07-17T06:41:07.48548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure( figsize=(10,5), dpi = 80 ) \nsns.countplot( train_df_master['target'])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:41:08.981996Z","iopub.execute_input":"2021-07-17T06:41:08.982338Z","iopub.status.idle":"2021-07-17T06:41:09.092255Z","shell.execute_reply.started":"2021-07-17T06:41:08.982304Z","shell.execute_reply":"2021-07-17T06:41:09.091414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG= {\n    \n    \"IMG_LENGTH\" :  273,#256\n    \"IMG_WIDTH\" : 256,\n    \"CHANNELS\" : 3,\n    \"RANDOM_STATE\" : 100,\n    \"BATCH_SIZE\"  :100,\n    \"FOLDS\" : 5,\n    \"LEARNING_RATE\" : 0.1\n}\n\nCFG_ENCODE_DECODE= {\n    \n    \"IMG_LENGTH\" :  256,\n    \"IMG_WIDTH\" : 256,\n    \"CHANNELS\" : 3,\n    \"RANDOM_SATE\" : 100,\n    \"BATCH_SIZE\"  :50,\n    \"FOLDS\" : 5,\n    \"LEARNING_RATE\" : 0.1\n}\n    \n    ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:41:11.586644Z","iopub.execute_input":"2021-07-17T06:41:11.586966Z","iopub.status.idle":"2021-07-17T06:41:11.594315Z","shell.execute_reply.started":"2021-07-17T06:41:11.586933Z","shell.execute_reply":"2021-07-17T06:41:11.593441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1. Building data generator","metadata":{}},{"cell_type":"code","source":"\ntrain_df,test_df = train_test_split ( train_df_master, train_size = 0.8, random_state= CFG[\"RANDOM_STATE\"],shuffle = True,stratify = train_df_master[\"target\"])\nval_df, test_df = train_test_split ( test_df, test_size = 0.2 , random_state= CFG[\"RANDOM_STATE\"],shuffle = True,stratify = test_df[\"target\"])\n\n\nprint (\"number of samples for train data set  = {} \".format(len ( train_df) ) )\nprint (\"number of samples for test data set  = {} \".format(len ( test_df)))\nprint (\"number of samples for validation data set  = {} \".format(len ( val_df ) ) )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:41:14.746679Z","iopub.execute_input":"2021-07-17T06:41:14.747014Z","iopub.status.idle":"2021-07-17T06:41:14.82407Z","shell.execute_reply.started":"2021-07-17T06:41:14.746981Z","shell.execute_reply":"2021-07-17T06:41:14.823246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Creating data generator which can work on Both TPU + GPU\n\ndef decode_numpy(  ):\n    \n    def read_image(file_name ):\n        #print ( file_name)\n        np_data =  tf.io.read_file ( file_name )\n        np_data = tf.io.decode_raw( np_data, tf.float16 )\n        np_data = tf.reshape( np_data[64:], (6, 273, 256 )) # (6, 273, 256 ) is data origional shape \n        #np_data = tf.concat ( (np_data[0],np_data[2],np_data[4]), axis = 0)\n        #np_data = tf.stack([np_data[0],np_data[2],np_data[4]] ,axis = 2 ) \n        np_data = tf.stack([np_data[0],np_data[2],np_data[4]] ,axis = 2 )\n        #np_data = tf.concat([np_data[0],np_data[2],np_data[4]] ,axis = -1  )\n        #np_data = tf.stack([np_data,np_data,np_data] ,axis = 2 )\n        np_data = tf.reshape( np_data, ( CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"] ))\n        #np_data = tf.image.r(np_data)\n        return np_data   #(819, 256)is output shape \n        \n    def decode( file_name, target ):\n        return read_image ( file_name ), target#tf.cast(target, tf.float32) \n    \n    return decode\n\ndef data_augmentation( ):\n    \n    def add_augmentation( image ):\n        \n        image = tf.image.random_flip_up_down( image,seed= CFG[\"RANDOM_STATE\"] )\n        image = tf.image.random_flip_left_right( image ,seed= CFG[\"RANDOM_STATE\"] )\n        image = tf.image.random_contrast( image,lower =0.1,upper = 0.5 ,seed= CFG[\"RANDOM_STATE\"] )\n        image = tf.image.random_saturation( image,lower =5,upper = 7 ,seed= CFG[\"RANDOM_STATE\"])\n        #image = tf.image.random_crop( value = image , size = (3,3), seed=CFG[\"RANDOM_STATE\"] )\n        return image\n    def call_add_augmentation( data, target ):\n        return add_augmentation( data), target \n    \n    return  call_add_augmentation\n\ndef datagenerator_rev_01(df,test = False ):\n    file_list = df[\"path\"].to_list() \n    target = df[\"target\"].to_list() \n    decode_tf = decode_numpy()\n    augment_fn = data_augmentation()\n    \n    datagen = tf.data.Dataset.from_tensor_slices( (file_list,target ))\n    datagen = datagen.map( decode_tf ,num_parallel_calls= tf.data.AUTOTUNE )\n    datagen = datagen.map(augment_fn, num_parallel_calls= tf.data.AUTOTUNE ) if not test else datagen\n    datagen = datagen.repeat() if not test else datagen\n    datagen = datagen.shuffle(1024) if not test else datagen\n    datagen = datagen.batch(CFG[\"BATCH_SIZE\"]).prefetch(tf.data.AUTOTUNE )\n    return  datagen\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.74325Z","iopub.execute_input":"2021-07-17T06:40:21.743792Z","iopub.status.idle":"2021-07-17T06:40:21.75655Z","shell.execute_reply.started":"2021-07-17T06:40:21.743749Z","shell.execute_reply":"2021-07-17T06:40:21.755639Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Creating data generator which can work on Both TPU + GPU\n\ndef decode_numpy_auto_ecoder(  ):\n    \n    def read_image(file_name ):\n        #print ( file_name)\n        np_data =  tf.io.read_file ( file_name )\n        np_data = tf.io.decode_raw( np_data, tf.float16 )\n        np_data = tf.reshape( np_data[64:], (6, 273, 256 )) # (6, 273, 256 ) is data origional shape \n        np_data = tf.stack([np_data[1],np_data[3],np_data[5]] ,axis = 2 )\n        np_data = np_data[np.random.randint(3) ]\n        np_data = tf.stack([np_data,np_data,np_data] ,axis = 2 )\n        np_data = tf.image.resize(np_data,( CFG_ENCODE_DECODE[\"IMG_LENGTH\"], CFG_ENCODE_DECODE[\"IMG_WIDTH\"] ) )\n        return tf.data.Dataset.from_tensors( np_data[:,:,0:1] ) #(256, 256)is output shape \n        \n    def decode( file_name ):\n        return read_image ( file_name )\n    \n    return decode\n\ndef input_output():\n    \n    def auto_encode_input_output(data):\n        return data,data\n    \n    return auto_encode_input_output\n\n\ndef Auto_Encoder_Data_Generator(df,test = False,channel =None ):\n    file_list = df[\"path\"].to_list() \n    target = df[\"target\"].to_list() \n    decode_tf = decode_numpy_auto_ecoder()\n    \n    io_for_auto_encode =input_output()\n    \n    data_gen = tf.data.Dataset.from_tensor_slices( (file_list  ) )\n    data_gen = data_gen.interleave(decode_tf,num_parallel_calls=tf.data.AUTOTUNE) \n    data_gen = data_gen.map( io_for_auto_encode,num_parallel_calls=tf.data.AUTOTUNE )\n    data_gen = data_gen.shuffle( 30 ,seed = CFG_ENCODE_DECODE[\"RANDOM_SATE\"], reshuffle_each_iteration = True ) if not test else data_gen\n    data_gen = data_gen.batch( CFG_ENCODE_DECODE[\"BATCH_SIZE\"]) if not test else data_gen\n    data_gen = data_gen.prefetch( tf.data.AUTOTUNE )\n    data_gen = data_gen.repeat() if not test else data_gen\n    \n    \n    \n    return  data_gen\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.758125Z","iopub.execute_input":"2021-07-17T06:40:21.758585Z","iopub.status.idle":"2021-07-17T06:40:21.772223Z","shell.execute_reply.started":"2021-07-17T06:40:21.758546Z","shell.execute_reply":"2021-07-17T06:40:21.771178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if False:\n    \n    def read_numpy_data( file_name_result ):\n\n        #random_int = np.random.randint(3)\n        #channel = [1,3,5]\n        file_name=file_name_result\n        data = np.load( file_name.numpy() ).astype( np.float16 )    \n        data =np.vstack ( (data[0],data[2],data[4]) )\n        #data = np.vstack( (data,data,data) )\n        return  np.dstack ( [ data, data, data] ) \n\n\n\n    def resize_image( df_dict ):\n\n        [image, ] =  tf.py_function( read_numpy_data,  [ df_dict[\"path\"] ], [tf.float16] )\n        image.set_shape( ( CFG.IMG_LENGTH,CFG.IMG_WIDTH, CFG.CHANNELS ) )\n        image = tf.image.resize( image , ( CFG.IMG_LENGTH,CFG.IMG_WIDTH ) )\n        label = df_dict[\"target\"]\n        label = tf.cast( label, tf.int16 )\n\n        return  image, label \n\n    def data_augmentation( ):\n\n        def add_augmentation( image ):\n\n            #image = tf.image.random_flip_up_down( image )\n            #image = tf.image.random_flip_up_down( image )\n            #image = tf.image.random_contrast( image )\n            return image\n        def call_add_augmentation( data, target ):\n            return add_augmentation( data), target \n\n        return  call_add_augmentation\n\n\n    def create_tf_dataset( dataframe, test =False  ):\n\n        augment_fn = data_augmentation()\n\n        tf_dataset = tf.data.Dataset.from_tensor_slices ( dict ( dataframe[ [\"path\",\"target\"] ] ) ) \n        \n        if test :\n        \n            tf_dataset = ( tf_dataset\n                          .map( resize_image,num_parallel_calls= tf.data.AUTOTUNE)\n                          .batch( CFG.BATCH_SIZE )\n                          .prefetch( tf.data.AUTOTUNE)\n                         )\n        else:\n            tf_dataset = ( tf_dataset\n                          .shuffle (1024)\n                          .map( resize_image,num_parallel_calls= tf.data.AUTOTUNE)\n                          .batch( CFG.BATCH_SIZE )\n                          .prefetch( tf.data.AUTOTUNE)\n                         )\n        tf_dataset = tf_dataset.map (augment_fn,num_parallel_calls= tf.data.AUTOTUNE )\n\n        return  tf_dataset  \n\n    train_data_gen = create_tf_dataset( train_df ) \n    val_data_gen = create_tf_dataset( val_df ) \n    test_data_gen = create_tf_dataset ( test_df, test = True ) ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.773775Z","iopub.execute_input":"2021-07-17T06:40:21.774335Z","iopub.status.idle":"2021-07-17T06:40:21.789802Z","shell.execute_reply.started":"2021-07-17T06:40:21.774294Z","shell.execute_reply":"2021-07-17T06:40:21.788906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.000075, lr_min=0.000001, lr_rampup_epochs=20, lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max #* strategy.num_replicas_in_sync\n    \n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.791301Z","iopub.execute_input":"2021-07-17T06:40:21.791776Z","iopub.status.idle":"2021-07-17T06:40:21.800674Z","shell.execute_reply.started":"2021-07-17T06:40:21.791695Z","shell.execute_reply":"2021-07-17T06:40:21.799697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    \n    \n    input_mo = tf.keras.layers.Input(shape= (  CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"] ) )\n\n    efff_net =tf.keras.applications.EfficientNetB0(include_top = False, \n                                                   weights =\"imagenet\" , \n                                                   input_shape = ( CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"]) ,\n                                                   input_tensor = input_mo,\n                                                   classes=2,\n                                                   pooling = True,\n                                                   #classifier_activation='softmax',\n                                                   drop_connect_rate= 0.1\n                                                  )\n\n    for layer in  efff_net.layers  :\n        #if not isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = True\n        \n\n    model = tf.keras.Sequential( [ efff_net,\n            tf.keras.layers.GlobalMaxPool2D(),\n            #tf.keras.layers.Dropout(0.25 ),\n\n            #tf.keras.layers.Dense(600, activation='relu'),\n            #tf.keras.layers.Flatten(),\n            #tf.keras.layers.Dropout(0.2 ),\n            tf.keras.layers.Dense(32, activation='relu'),\n            \n            tf.keras.layers.Dense(1, activation='sigmoid')\n            \n            ])    \n    \n    \n    #model.summary()\n    \n    #model.compile(optimizer, \n    #              loss=tfa.losses.SigmoidFocalCrossEntropy(), \n    #              metrics=[tf.keras.metrics.AUC(curve='ROC')])\n    \n    return ( model )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.802208Z","iopub.execute_input":"2021-07-17T06:40:21.802668Z","iopub.status.idle":"2021-07-17T06:40:21.814712Z","shell.execute_reply.started":"2021-07-17T06:40:21.802628Z","shell.execute_reply":"2021-07-17T06:40:21.813685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model_effnet_07():\n    \n    \n    #input_ = layers.Input((3*273,256,3))\n    input_ = tf.keras.layers.Input((273,256,3))\n    \n    #x = efn.EfficientNetB0(input_shape=(3*273,256,3),weights='noisy-student',include_top=False)(input_)\n    x = efn.EfficientNetB7(input_shape=(273,256,3),weights='noisy-student',include_top=False)(input_)\n    #x = layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.GlobalMaxPool2D()(x)\n    x = tf.keras.layers.Dense(32)(x)\n    x = tf.keras.layers.Activation(\"relu\")(x)\n    \n    x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n    \n    model = tf.keras.models.Model(inputs=input_, outputs=x)   \n    \n    \n    #model.summary()\n    \n    #model.compile(optimizer, \n    #              loss=tfa.losses.SigmoidFocalCrossEntropy(), \n    #              metrics=[tf.keras.metrics.AUC(curve='ROC')])\n    \n    return ( model )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.815919Z","iopub.execute_input":"2021-07-17T06:40:21.816367Z","iopub.status.idle":"2021-07-17T06:40:21.825288Z","shell.execute_reply.started":"2021-07-17T06:40:21.816308Z","shell.execute_reply":"2021-07-17T06:40:21.824138Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#x = efn.EfficientNetB0(input_shape=(273,256,3),weights='noisy-student',include_top=False)(input_)\n\n\ndef get_model_noisy_student_weights():\n    \n    \n    input_mo = tf.keras.layers.Input(shape= (  CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"] ) )\n\n    efff_net =efn.EfficientNetB0(include_top = False, \n                                                   weights =\"noisy-student\" , \n                                                   input_shape = ( CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"]) ,\n                                                   input_tensor = input_mo,\n                                                   classes=2,\n                                                   pooling = True,\n                                                   #classifier_activation='softmax',\n                                                   #drop_connect_rate= 0.1\n                                                  )\n\n    for layer in  efff_net.layers  :\n        #if not isinstance(layer, tf.keras.layers.BatchNormalization):\n        layer.trainable = False\n        \n\n    model = tf.keras.Sequential( [#tf.keras.layers.GaussianNoise( stddev=0.3 ),\n                                  efff_net,\n                                  tf.keras.layers.Flatten(),\n                                  #tf.keras.layers.GlobalAveragePooling2D(),\n            \n            #tf.keras.layers.Dropout(0.25 ),\n            tf.keras.layers.Dense(1000, activation='relu'),\n            tf.keras.layers.Dropout(0.1 ),\n            tf.keras.layers.Dense(100, activation='relu'),\n            tf.keras.layers.Dropout(0.1 ),\n            tf.keras.layers.Dense(32, activation='relu'),\n            \n            tf.keras.layers.Dense(1, activation='sigmoid')\n            \n            ])    \n    \n    \n    #x = layers.GlobalAveragePooling2D()(x)\n    \n    #x = layers.Dense(32)(x)\n    #x = layers.Activation(\"relu\")(x)\n    \n    #x = layers.Dense(1, activation=\"sigmoid\")(x)\n    \n    \n    return ( model )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.826767Z","iopub.execute_input":"2021-07-17T06:40:21.827193Z","iopub.status.idle":"2021-07-17T06:40:21.839034Z","shell.execute_reply.started":"2021-07-17T06:40:21.827145Z","shell.execute_reply":"2021-07-17T06:40:21.838229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_1 = get_model_noisy_student_weights()\n#model_1.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.840624Z","iopub.execute_input":"2021-07-17T06:40:21.841103Z","iopub.status.idle":"2021-07-17T06:40:21.8509Z","shell.execute_reply.started":"2021-07-17T06:40:21.841064Z","shell.execute_reply":"2021-07-17T06:40:21.85009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if False:\n    \n\n    CFG[\"BATCH_SIZE\"] =100\n\n    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(  patience=3,\n                                                        min_lr= 0.000001,\n                                                        monitor='val_loss', \n                                                        factor=0.6, \n                                                        verbose=1,\n                                                        mode='auto', \n                                                       )\n\n    train_df_2 = train_df[[\"path\",\"target\"]].iloc[:30000]\n    val_df_2 = val_df[[\"path\",\"target\"]].iloc[:5000]\n\n    CFG['model_name'] = 'efficientnetb0-folds'\n    CFG['group'] = 'K-Fold-EnetB0'\n    CFG['run_name'] = 'baseline-k-fold'\n    model = get_model()\n\n    class_weight_for_train = {0:1, 1: (train_df_2[train_df_2[\"target\"]==0].shape[0]/train_df_2[train_df_2[\"target\"]==1].shape[0]) }\n    CFG[\"TRAIN_STEPS\"] = int ( train_df_2.shape[0]/CFG[\"BATCH_SIZE\"] ) + (1 if train_df_2.shape[0]% CFG[\"BATCH_SIZE\"] != 0 else 0)\n    CFG[\"VAL_STEPS\"] = int ( val_df_2.shape[0]/CFG[\"BATCH_SIZE\"] ) + (1 if val_df_2.shape[0]% CFG[\"BATCH_SIZE\"] != 0 else 0)\n\n    train_data_gen = datagenerator_rev_01( train_df_2 ) \n    val_data_gen = datagenerator_rev_01( val_df_2 ) \n\n\n\n    #model = get_model()\n\n    model.build( ( None, CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"]) )\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.0006000000284984708)#0.001) #tf.keras.optimizers.Adam(learning_rate=0.1)\n    model.compile( optimizer= optimizer,loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint( f'model{1}.h5', save_best_only=True, monitor='val_loss', mode='min')\n\n\n    model_history = model.fit_generator(train_data_gen,\n                                        #class_weight= class_weight_for_train,\n                                         steps_per_epoch= CFG[\"TRAIN_STEPS\"], \n                                         epochs =5, \n                                         validation_data= val_data_gen,\n                                         validation_steps = CFG[\"VAL_STEPS\"],\n                                         callbacks=[ checkpoint,lr_reducer]\n                                       )\n\n    # Initialize W&B run\n    run = wandb.init(project='kaggle-seti', \n                     config=CFG,\n                     group=CFG['group'], \n                     job_type='train',\n                     name=CFG['run_name'])\n\n    # Evaluate\n    loss, auc = model.evaluate( val_data_gen, steps = CFG[\"VAL_STEPS\"])\n    wandb.log({'Val AUC-ROC': auc})\n\n    # Save model\n    model_name = CFG['model_name']\n    MODEL_PATH= f'models/{model_name}'\n    os.makedirs(MODEL_PATH, exist_ok=True)\n    count_models = len(os.listdir(MODEL_PATH))\n\n    model.save(f'{MODEL_PATH}/{model_name}_{count_models}.h5')\n\n    run.finish()\n\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.852296Z","iopub.execute_input":"2021-07-17T06:40:21.852696Z","iopub.status.idle":"2021-07-17T06:40:21.869232Z","shell.execute_reply.started":"2021-07-17T06:40:21.852658Z","shell.execute_reply":"2021-07-17T06:40:21.868357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if False:\n    TEST_STEPS = int ( test_df.shape[0]/CFG[\"BATCH_SIZE\"] ) + (1 if test_df.shape[0]% CFG[\"BATCH_SIZE\"] != 0 else 0)\n    test_data_gen = datagenerator_rev_01 ( test_df[[\"path\",\"target\"]],True )    \n    prediction = model.predict_classes( test_data_gen, batch_size = CFG[\"BATCH_SIZE\"] )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.874841Z","iopub.execute_input":"2021-07-17T06:40:21.875195Z","iopub.status.idle":"2021-07-17T06:40:21.881519Z","shell.execute_reply.started":"2021-07-17T06:40:21.875121Z","shell.execute_reply":"2021-07-17T06:40:21.880514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if False:\n    test_predict_df = test_df\n    test_predict_df[\"prediction\"]= prediction\n    test_predict_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.883844Z","iopub.execute_input":"2021-07-17T06:40:21.884168Z","iopub.status.idle":"2021-07-17T06:40:21.890917Z","shell.execute_reply.started":"2021-07-17T06:40:21.884128Z","shell.execute_reply":"2021-07-17T06:40:21.889623Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if False: confusion_matrix( test_predict_df[\"target\"], test_predict_df[\"prediction\"])","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.892799Z","iopub.execute_input":"2021-07-17T06:40:21.893271Z","iopub.status.idle":"2021-07-17T06:40:21.899034Z","shell.execute_reply.started":"2021-07-17T06:40:21.893227Z","shell.execute_reply":"2021-07-17T06:40:21.897857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    #input_ = layers.Input((3*273,256,3))\n    input_ = tf.keras.layers.Input((273,256,3))\n    \n    #x = efn.EfficientNetB0(input_shape=(3*273,256,3),weights='noisy-student',include_top=False)(input_)\n    x = efn.EfficientNetB0(input_shape=(273,256,3),weights='noisy-student',include_top=False)(input_)\n    #x = layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.GlobalMaxPool2D()(x)\n    x = tf.keras.layers.Dense(32)(x)\n    x = tf.keras.layers.Activation(\"relu\")(x)\n    \n    x = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n    \n    model = tf.keras.models.Model(inputs=input_, outputs=x)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.900854Z","iopub.execute_input":"2021-07-17T06:40:21.901314Z","iopub.status.idle":"2021-07-17T06:40:21.911193Z","shell.execute_reply.started":"2021-07-17T06:40:21.901273Z","shell.execute_reply":"2021-07-17T06:40:21.909661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Mode building with Efficient net with pre trained model \n\nif EFFNET :\n    \n    nosy_eff_net = create_model ()\n    #nosy_eff_net.build( ( None, CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"]) )\n    nosy_eff_net.load_weights(\"../input/seti-tpu-rev-02/model_TPU_REV_02.h5\")\n\n    \n    CFG[\"BATCH_SIZE\"] =75\n\n    lr_reducer = tf.keras.callbacks.ReduceLROnPlateau(  patience=1,\n                                                        min_lr= 0.0000001,\n                                                        monitor='val_loss', \n                                                        factor=0.6, \n                                                        verbose=1,\n                                                        mode='auto', \n                                                       )\n\n    train_df_2 = train_df[[\"path\",\"target\"]]#.iloc[:30000]\n    val_df_2 = val_df[[\"path\",\"target\"]]#.iloc[:5000]\n\n    CFG['model_name'] = 'efficientnetb0-folds_nosy_oversample'\n    CFG['group'] = 'K-Fold-EnetB0_nosy'\n    CFG['run_name'] = 'baseline-k-fold_nosy'\n\n\n    #class_weight_for_train = {0:1, 1: (train_df_2[train_df_2[\"target\"]==0].shape[0]/train_df_2[train_df_2[\"target\"]==1].shape[0]) }\n    CFG[\"TRAIN_STEPS\"] = int ( train_df_2.shape[0]/CFG[\"BATCH_SIZE\"] ) + (1 if train_df_2.shape[0]% CFG[\"BATCH_SIZE\"] != 0 else 0)\n    CFG[\"VAL_STEPS\"] = int ( val_df_2.shape[0]/CFG[\"BATCH_SIZE\"] ) + (1 if val_df_2.shape[0]% CFG[\"BATCH_SIZE\"] != 0 else 0)\n\n    train_data_gen = datagenerator_rev_01( train_df_2 ) \n    val_data_gen = datagenerator_rev_01( val_df_2 ) \n\n\n\n\n    #0.0006000000284984708\n    optimizer = tf.keras.optimizers.Adam(learning_rate= 0.0003600000170990825  ) #tf.keras.optimizers.Adam(learning_rate=0.1)\n    nosy_eff_net.compile( optimizer= optimizer,loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint( f'model{1}.h5', save_best_only=True, monitor='val_loss', mode='min')\n\n\n    model_history = nosy_eff_net.fit_generator(train_data_gen,\n                                        #class_weight= class_weight_for_train,\n                                         steps_per_epoch= CFG[\"TRAIN_STEPS\"], \n                                         epochs =5, \n                                         validation_data= val_data_gen,\n                                         validation_steps = CFG[\"VAL_STEPS\"],\n                                         callbacks=[ checkpoint,lr_reducer]\n                                       )\n    nosy_eff_net.save(\"./nosy_eff_net_with_guassian_noise_over_sample_part_2.h5\")\n    # Initialize W&B run\n    run = wandb.init(project='kaggle-seti', \n                     config=CFG,\n                     group=CFG['group'], \n\n                     job_type='train',\n                     name=CFG['run_name'])\n\n    # Evaluate\n    loss, auc = nosy_eff_net.evaluate( val_data_gen, steps = CFG[\"VAL_STEPS\"])\n    wandb.log({'Val AUC-ROC': auc})\n\n    # Save model\n    model_name = CFG['model_name']\n    MODEL_PATH= f'models/{model_name}'\n    os.makedirs(MODEL_PATH, exist_ok=True)\n    count_models = len(os.listdir(MODEL_PATH))\n\n    nosy_eff_net.save(f'{MODEL_PATH}/{model_name}_{count_models}.h5')\n\n    run.finish()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.912701Z","iopub.execute_input":"2021-07-17T06:40:21.913549Z","iopub.status.idle":"2021-07-17T06:40:21.927456Z","shell.execute_reply.started":"2021-07-17T06:40:21.913504Z","shell.execute_reply":"2021-07-17T06:40:21.926582Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET :\n    nosy_eff_net = get_model_effnet_07()\n    nosy_eff_net.load_weights(\"../input/setitpurev03/model_TPU_REV_03.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.928738Z","iopub.execute_input":"2021-07-17T06:40:21.929121Z","iopub.status.idle":"2021-07-17T06:40:21.939057Z","shell.execute_reply.started":"2021-07-17T06:40:21.929066Z","shell.execute_reply":"2021-07-17T06:40:21.937959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET :\n    submission_df = pd.read_csv(\"../input/seti-breakthrough-listen/sample_submission.csv\")\n    submission_df[\"path\"] = submission_df[\"id\"].apply( lambda x: \"../input/seti-breakthrough-listen/test/\"+ str(x[0]) +\"/\"+x +\".npy\" )\n    submission_df[\"target\"] = [1]*submission_df.shape[0]\n    submission_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.940693Z","iopub.execute_input":"2021-07-17T06:40:21.941142Z","iopub.status.idle":"2021-07-17T06:40:21.948547Z","shell.execute_reply.started":"2021-07-17T06:40:21.941107Z","shell.execute_reply":"2021-07-17T06:40:21.947596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET : submission_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.949953Z","iopub.execute_input":"2021-07-17T06:40:21.950362Z","iopub.status.idle":"2021-07-17T06:40:21.958594Z","shell.execute_reply.started":"2021-07-17T06:40:21.950326Z","shell.execute_reply":"2021-07-17T06:40:21.957758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET : CFG[\"BATCH_SIZE\"] = 50","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.9598Z","iopub.execute_input":"2021-07-17T06:40:21.960508Z","iopub.status.idle":"2021-07-17T06:40:21.966557Z","shell.execute_reply.started":"2021-07-17T06:40:21.960396Z","shell.execute_reply":"2021-07-17T06:40:21.965795Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" if EFFNET :\n    fial_submission_data_gen = datagenerator_rev_01 ( submission_df[[\"path\",\"target\"]], True ) \n    final_prediction = nosy_eff_net.predict( fial_submission_data_gen, batch_size = CFG[\"BATCH_SIZE\"] )\n    submission_df[\"target\"]= final_prediction\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.967849Z","iopub.execute_input":"2021-07-17T06:40:21.968282Z","iopub.status.idle":"2021-07-17T06:40:21.975738Z","shell.execute_reply.started":"2021-07-17T06:40:21.968244Z","shell.execute_reply":"2021-07-17T06:40:21.974924Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET : submission_df.head(10)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.978211Z","iopub.execute_input":"2021-07-17T06:40:21.978611Z","iopub.status.idle":"2021-07-17T06:40:21.98467Z","shell.execute_reply.started":"2021-07-17T06:40:21.978575Z","shell.execute_reply":"2021-07-17T06:40:21.983551Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET :\n    final_submission = submission_df[[\"id\",\"target\"]]\n    final_submission.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.987971Z","iopub.execute_input":"2021-07-17T06:40:21.988305Z","iopub.status.idle":"2021-07-17T06:40:21.9947Z","shell.execute_reply.started":"2021-07-17T06:40:21.988276Z","shell.execute_reply":"2021-07-17T06:40:21.99357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET : final_submission.to_csv(\"./sample_submission.csv\",index = False)","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:21.996277Z","iopub.execute_input":"2021-07-17T06:40:21.99698Z","iopub.status.idle":"2021-07-17T06:40:22.003781Z","shell.execute_reply.started":"2021-07-17T06:40:21.996936Z","shell.execute_reply":"2021-07-17T06:40:22.002771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET : test_data_gen = datagenerator_rev_01( test_df[[\"path\",\"target\"]], True ) ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:22.006241Z","iopub.execute_input":"2021-07-17T06:40:22.006972Z","iopub.status.idle":"2021-07-17T06:40:22.013675Z","shell.execute_reply.started":"2021-07-17T06:40:22.006924Z","shell.execute_reply":"2021-07-17T06:40:22.012532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nosy_eff_net = get_model_noisy_student_weights ()\n#nosy_eff_net.load_weights(\"../input/train-model-weight-for-seti-anomally-detection/PRETRAINED_MODEL_WEIGHTS.h5\")","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:22.015139Z","iopub.execute_input":"2021-07-17T06:40:22.015905Z","iopub.status.idle":"2021-07-17T06:40:22.021881Z","shell.execute_reply.started":"2021-07-17T06:40:22.015753Z","shell.execute_reply":"2021-07-17T06:40:22.021161Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nif EFFNET : prediction_df = nosy_eff_net.predict_classes(test_data_gen ) ","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:22.023203Z","iopub.execute_input":"2021-07-17T06:40:22.023848Z","iopub.status.idle":"2021-07-17T06:40:22.431738Z","shell.execute_reply.started":"2021-07-17T06:40:22.023808Z","shell.execute_reply":"2021-07-17T06:40:22.430007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET : test_df[\"prediction\"] = prediction_df","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:22.433064Z","iopub.status.idle":"2021-07-17T06:40:22.433581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if EFFNET : confusion_matrix ( test_df[\"target\"],test_df[\"prediction\"] )","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:22.435175Z","iopub.status.idle":"2021-07-17T06:40:22.435827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#import neural_structured_learning as nsl\nCFG[\"BATCH_SIZE\"] =100\n\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(  patience=1,\n                                                    min_lr= 0.000001,\n                                                    monitor='val_loss', \n                                                    factor=0.5, \n                                                    verbose=1,\n                                                    mode='auto', \n                                                   )\n\n#lr_reducer = build_lrfn()\n\nKFOLD = StratifiedKFold( n_splits= CFG[\"FOLDS\"],shuffle = True, random_state= CFG[\"RANDOM_STATE\"] )    \nkfold_history = []\nCFG['model_name'] = 'efficientnetb0-folds'\nCFG['group'] = 'K-Fold-EnetB0'\nCFG['run_name'] = 'baseline-k-fold'\nmodel_1 = get_model()\n\nfor i , (train_index,val_index) in enumerate( KFOLD.split( train_df,train_df[\"target\"] ) ):\n    \n    \n    train = train_df.iloc[train_index]\n    val = train_df.iloc[val_index]\n    \n    class_weight_for_train = {0:1, 1: (train[train[\"target\"]==0].shape[0]/train[train[\"target\"]==1].shape[0]) }\n    \n    print ( \"class weight =={}\",class_weight_for_train )\n    print ( \"Curent fold =={}\".format( i))\n    \n    CFG[\"TRAIN_STEPS\"] = int ( train.shape[0]/CFG[\"BATCH_SIZE\"] ) + (1 if train.shape[0]% CFG[\"BATCH_SIZE\"] != 0 else 0)\n    CFG[\"VAL_STEPS\"] = int ( val.shape[0]/CFG[\"BATCH_SIZE\"] ) + (1 if val.shape[0]% CFG[\"BATCH_SIZE\"] != 0 else 0)\n\n\n    train_data_gen = datagenerator_rev_01( train[[\"path\",\"target\"]] ) \n    val_data_gen = datagenerator_rev_01( val[[\"path\",\"target\"]] ) \n    #test_data_gen = datagenerator_rev_01 ( test_df[[\"path\",\"target\"]])    \n\n    \n    model_1 = get_model()\n    \n    \n    model_1.build( ( None, CFG[\"IMG_LENGTH\"], CFG[\"IMG_WIDTH\"], CFG[\"CHANNELS\"]) )\n    optimizer = tf.keras.optimizers.Adam(learning_rate=0.05) #tf.keras.optimizers.Adam(learning_rate=0.1)\n    model_1.compile( optimizer= optimizer,loss=\"binary_crossentropy\", metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint( f'model{i}.h5', save_best_only=True, monitor='val_loss', mode='min')\n\n\n    model_history = model_1.fit_generator(train_data_gen,\n                                                  class_weight= class_weight_for_train,#{0: 0.5514850705113055, 1: 5.355776587605202},\n                                                 steps_per_epoch= CFG[\"TRAIN_STEPS\"], \n                                                 epochs =5, \n                                                 validation_data= val_data_gen,\n                                                 validation_steps = CFG[\"VAL_STEPS\"],\n                                                callbacks=[ checkpoint,lr_reducer#tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1),\n                                                              #tf.keras.callbacks.ModelCheckpoint( \"../ZIP_MODEL/model2.h5\", \n                                                               #                              monitor='loss', \n                                                               #                              verbose=0,\n                                                               #                              save_best_only=True, \n                                                               #                              save_weights_only=True,\n                                                               #                              mode='auto', \n                                                               #                              save_freq='epoch',\n                                                                                             #monitor='val_loss', \n                                                                                             #mode='min'\n                                                                #\n                                                                #                            )\n                                      ] )\n    \n    # Initialize W&B run\n    run = wandb.init(project='kaggle-seti', \n                     config=CFG,\n                     group=CFG['group'], \n                     job_type='train',\n                     name=CFG['run_name'])\n    \n    # Evaluate\n    loss, auc = model_1.evaluate( val_data_gen, steps = CFG[\"VAL_STEPS\"])\n    wandb.log({'Val AUC-ROC': auc})\n    \n    # Save model\n    model_name = CFG['model_name']\n    MODEL_PATH = f'models/{model_name}'\n    os.makedirs(MODEL_PATH, exist_ok=True)\n    count_models = len(os.listdir(MODEL_PATH))\n    \n    model_1.save(f'{MODEL_PATH}/{model_name}_{count_models}.h5')\n\n    # Get Prediction on validation set\n    #_oof_df = get_predictions(model, validloader, valid_df)\n    #oof_df = pd.concat([oof_df, _oof_df])\n    \n    run.finish()\n    \n    #kfold_history.append( model_1 )","metadata":{"execution":{"iopub.status.busy":"2021-07-08T10:39:34.39597Z","iopub.status.idle":"2021-07-08T10:39:34.396495Z"}}},{"cell_type":"code","source":"encoder_decoder_model = tf.keras.Sequential(\n            [ tf.keras.layers.Input( shape=  ( CFG_ENCODE_DECODE[\"IMG_LENGTH\"],CFG_ENCODE_DECODE[\"IMG_WIDTH\"] ,1 ), name= \"encoder_input_layer\" ) ,\n              tf.keras.layers.Conv2D(filters = 256, kernel_size = (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"encoder_layer_01\"),\n              tf.keras.layers.Conv2D(filters = 128, kernel_size = (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"encoder_layer_02\"),\n              tf.keras.layers.Conv2D(filters = 64, kernel_size =  (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"encoder_layer_03\") ,\n              tf.keras.layers.Conv2D(filters = 32, kernel_size =  (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"encoder_layer_04\") ,\n              tf.keras.layers.Conv2D(filters = 16, kernel_size =  (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"encoder_layer_05\"),\n              #tf.keras.layers.Conv2D(filters = 8, kernel_size =  (4,4), strides = 2,padding = \"valid\",name =\"encoder_layer_65\"),\n              #tf.keras.layers.Conv1D(filters = 8, kernel_size = (4,4), strides = 3,padding = \"same\",activation =\"relu\"),\n\n              tf.keras.layers.Conv2DTranspose(filters = 16, kernel_size = (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"decoder_layer_01\"),\n              tf.keras.layers.Conv2DTranspose(filters = 32, kernel_size = (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"decoder_layer_02\"),\n              tf.keras.layers.Conv2DTranspose(filters = 64, kernel_size = (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"decoder_layer_03\"),\n              tf.keras.layers.Conv2DTranspose(filters = 128, kernel_size = (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"decoder_layer_04\"),\n              tf.keras.layers.Conv2DTranspose(filters = 256, kernel_size = (4,4), strides = 2,padding = \"valid\",activation =\"relu\",name =\"decoder_layer_05\"),\n              #tf.keras.layers.Conv2DTranspose(filters = 512, kernel_size = (4,4), strides = 2,padding = \"valid\",name =\"decoder_layer_06\"),\n              tf.keras.layers.Conv2DTranspose(filters = 1, kernel_size = 3, strides = 1,padding = \"valid\",activation =\"relu\",name =\"output_layer\")\n            ]\n                    )\nencoder_decoder_model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:42:03.214875Z","iopub.execute_input":"2021-07-17T06:42:03.21522Z","iopub.status.idle":"2021-07-17T06:42:03.398818Z","shell.execute_reply.started":"2021-07-17T06:42:03.215187Z","shell.execute_reply":"2021-07-17T06:42:03.397898Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_2= train_df.iloc[:30000]\nval_df_2 = val_df.iloc[:4000]\ntrain_data_gen = Auto_Encoder_Data_Generator( train_df_2 )\nval_data_gen = Auto_Encoder_Data_Generator( val_df_2 )\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(  patience=4,\n                                                        min_lr= 0.0000001,\n                                                        monitor='val_loss', \n                                                        factor=0.6, \n                                                        verbose=1,\n                                                        mode='auto', \n                                                       )\n\nCFG_ENCODE_DECODE[\"TRAIN_STEPS\"] = int ( train_df_2.shape[0]/CFG_ENCODE_DECODE[\"BATCH_SIZE\"] ) + (1 if train_df_2.shape[0] % CFG_ENCODE_DECODE[\"BATCH_SIZE\"] != 0 else 0)\nCFG_ENCODE_DECODE[\"VAL_STEPS\"] = int ( val_df_2.shape[0]/CFG_ENCODE_DECODE[\"BATCH_SIZE\"] ) + (1 if val_df_2.shape[0]% CFG_ENCODE_DECODE[\"BATCH_SIZE\"] != 0 else 0)\n\noptimizer = tf.keras.optimizers.Adam(learning_rate= 0.01  )\n\nencoder_decoder_model.compile( optimizer= optimizer,loss=\"mse\", metrics=[tf.keras.metrics.MeanSquaredError()])\n\ncheckpoint = tf.keras.callbacks.ModelCheckpoint( f'model{1}.h5', save_best_only=True, monitor='val_loss', mode='min')\n\nencoder_decoder_model.fit(train_data_gen,\n                        #class_weight= class_weight_for_train,\n                         steps_per_epoch= CFG_ENCODE_DECODE[\"TRAIN_STEPS\"], \n                         epochs =5, \n                         validation_data= val_data_gen,\n                         validation_steps = CFG_ENCODE_DECODE[\"VAL_STEPS\"],\n                         callbacks=[ lr_reducer]\n                       )\n    \nencoder_decoder_model.save(\"./encoder_decoder.h5\" )\n","metadata":{"execution":{"iopub.status.busy":"2021-07-17T07:59:21.125347Z","iopub.execute_input":"2021-07-17T07:59:21.125733Z","iopub.status.idle":"2021-07-17T08:53:37.042161Z","shell.execute_reply.started":"2021-07-17T07:59:21.125701Z","shell.execute_reply":"2021-07-17T08:53:37.039461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CFG[\"BATCH_SIZE\"]","metadata":{"execution":{"iopub.status.busy":"2021-07-17T06:40:22.44143Z","iopub.status.idle":"2021-07-17T06:40:22.441983Z"},"trusted":true},"execution_count":null,"outputs":[]}]}