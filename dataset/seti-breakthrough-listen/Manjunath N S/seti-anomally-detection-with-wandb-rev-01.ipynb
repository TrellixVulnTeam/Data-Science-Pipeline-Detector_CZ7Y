{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# In this Notebook, you have 3 section.\n# 1. with Efficient Net archtecture --> to learn tranfer learning\n*     1. With Transfer Learning I am able to achieve only 90% Accuracy.\n*     2. Try to handle imbalanced data using class weight\n\n# 2. Tried to build own model --> I couldn't get all things good. have tryafter efficient net\n# 3. Tried to create Encoder + Decoder Archtecture. But result is very bad, have to work on model building \n# Note, code doesn't have submission part yet ","metadata":{"execution":{"iopub.status.busy":"2021-05-26T11:14:57.87473Z","iopub.execute_input":"2021-05-26T11:14:57.875169Z","iopub.status.idle":"2021-05-26T11:14:58.548095Z","shell.execute_reply.started":"2021-05-26T11:14:57.875137Z","shell.execute_reply":"2021-05-26T11:14:58.546898Z"}}},{"cell_type":"markdown","source":"# 1. Using Efficient Net to classifcation","metadata":{}},{"cell_type":"code","source":"TF Record Basics :https://www.kaggle.com/ryanholbrook/tfrecords-basics","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* 1. All required libraries ","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Dense, BatchNormalization, Conv2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom functools import partial\n\nimport numpy as np\nfrom os import path\nimport os\n\nimport tensorflow_addons as tfa\nfrom functools import partial\nfrom kaggle_datasets import KaggleDatasets","metadata":{"execution":{"iopub.status.busy":"2021-06-16T11:17:11.440583Z","iopub.execute_input":"2021-06-16T11:17:11.440984Z","iopub.status.idle":"2021-06-16T11:17:11.447151Z","shell.execute_reply.started":"2021-06-16T11:17:11.440947Z","shell.execute_reply":"2021-06-16T11:17:11.446224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# setting ploting background \nsns.set_style(\"dark\")\nTPU = True","metadata":{"execution":{"iopub.status.busy":"2021-06-16T11:17:15.470204Z","iopub.execute_input":"2021-06-16T11:17:15.470693Z","iopub.status.idle":"2021-06-16T11:17:15.474223Z","shell.execute_reply.started":"2021-06-16T11:17:15.47066Z","shell.execute_reply":"2021-06-16T11:17:15.473513Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Reading Data & Visualising  images ","metadata":{}},{"cell_type":"markdown","source":"*  Reading data set to pandas dataframe, and updating file path ","metadata":{}},{"cell_type":"code","source":"train_csv = \"../input/seti-breakthrough-listen/train_labels.csv\"\ntrain_df_master = pd.read_csv( train_csv)\ntrain_df_master.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T14:13:50.293617Z","iopub.execute_input":"2021-06-15T14:13:50.294057Z","iopub.status.idle":"2021-06-15T14:13:50.385775Z","shell.execute_reply.started":"2021-06-15T14:13:50.294022Z","shell.execute_reply":"2021-06-15T14:13:50.384593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_master.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-15T14:13:52.808514Z","iopub.execute_input":"2021-06-15T14:13:52.808882Z","iopub.status.idle":"2021-06-15T14:13:52.815446Z","shell.execute_reply.started":"2021-06-15T14:13:52.808854Z","shell.execute_reply":"2021-06-15T14:13:52.814162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Upading each image path","metadata":{}},{"cell_type":"code","source":"train_df_master[\"path\"] = train_df_master[\"id\"].apply( lambda x: \"../input/seti-breakthrough-listen/train/\"+ str(x[0]) +\"/\"+x +\".npy\" )\ntrain_df_master.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-15T14:13:54.448891Z","iopub.execute_input":"2021-06-15T14:13:54.449604Z","iopub.status.idle":"2021-06-15T14:13:54.524543Z","shell.execute_reply.started":"2021-06-15T14:13:54.449552Z","shell.execute_reply":"2021-06-15T14:13:54.5233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***** Checking is file path constructed is correct or not by verifying file path using pathexist function","metadata":{}},{"cell_type":"code","source":"for x in range( 1, 5 ):    \n    file_to_check = train_df_master[\"path\"] [ np.random.randint ( 0, train_df_master.shape[0] ) ]\n    \n    if( path.exists ( file_to_check ) ):\n        print ( \"{} file exists...!\".format( file_to_check.split(\"/\")[-1] ) )\n    else:\n        print ( \"{} file Does not exists...!\".format( file_to_check.split(\"/\")[-1] ) )","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:20:59.629259Z","iopub.execute_input":"2021-06-14T13:20:59.629627Z","iopub.status.idle":"2021-06-14T13:20:59.651692Z","shell.execute_reply.started":"2021-06-14T13:20:59.629573Z","shell.execute_reply":"2021-06-14T13:20:59.650674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***** random file exists which confirms file path constructio correct we can preceeed to other operations","metadata":{}},{"cell_type":"markdown","source":"#  Lets visualise random images ","metadata":{}},{"cell_type":"code","source":"def create_heatmap(file_to_load,target ):\n    data= np.load( file_to_load ).astype( np.float32 )\n    fig = plt.figure( figsize = (5,5) , dpi = 80 )\n    \n    fig.suptitle( file_to_load +\"\\b target ==\" +str (target) )\n    \n    print ( file_to_load,target  )\n    data = np.vstack ( (data[1], data[3], data[5] ))\n    print ( \"Shape after vertical stack = {}\".format ( data.shape))\n    #data = np.resize( data, (256,256,3))\n    #for i in range( 0, 6 ):\n    plt.subplot( 1, 1,1 )\n    plt.imshow( data, interpolation='nearest', aspect='auto' )\n    \n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:18:28.685658Z","iopub.execute_input":"2021-06-14T13:18:28.686007Z","iopub.status.idle":"2021-06-14T13:18:28.692522Z","shell.execute_reply.started":"2021-06-14T13:18:28.685959Z","shell.execute_reply":"2021-06-14T13:18:28.691366Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(0,4):\n    \n    if i % 2== 0 :\n        \n        file_name, target = train_df_master[ [\"path\",\"target\"] ].iloc[  np.random.randint(train_df_master.shape[0] ) ].values \n        \n    else:\n        target,file_name = train_df_master[ train_df_master[\"target\"]== 1] [[\"target\",\"path\"]] .iloc[  np.random.randint(train_df_master[ train_df_master[\"target\"]== 1] [[\"target\",\"path\"]].shape[0] ) ].values \n        \n    create_heatmap ( file_name, target)    ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:18:30.893944Z","iopub.execute_input":"2021-06-14T13:18:30.894326Z","iopub.status.idle":"2021-06-14T13:18:32.647643Z","shell.execute_reply.started":"2021-06-14T13:18:30.894294Z","shell.execute_reply":"2021-06-14T13:18:32.646884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# * Creating generator for efficient net classification ","metadata":{}},{"cell_type":"code","source":"   \ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n   \n    \nexcept:\n    strategy = tf.distribute.get_strategy()\n    \nprint('Number of replicas:', strategy.num_replicas_in_sync)\n\n\n\nclass CONFIG():\n    \n    SAMPLE_SIZE= 10000\n    IMAGE_WIDTH = 819\n    IMAGE_HEIGHT= 256\n    BATCH_SIZE = 100 \n    RANDOM_STATE = 200\n    CHANNEL = 3\n    \n    \n\ntrain_df_2 = train_df_master.head( CONFIG.SAMPLE_SIZE )\ntrain_df,test_df  = train_test_split( train_df_2, test_size = 0.2,random_state= CONFIG.RANDOM_STATE, shuffle= True ,stratify= train_df_2[\"target\"] )\nvaldation_df,test_df = train_test_split( test_df, test_size = 0.1, random_state= CONFIG.RANDOM_STATE, shuffle= True ,stratify= test_df[\"target\"] )\n\nclass_weights = compute_class_weight('balanced', \n                                    classes=np.unique(train_df['target'].values),\n                                    y=train_df['target'].values)\n\nclass_weights_dict = {key: val for key, val in zip(np.unique(train_df['target'].values), class_weights)}\nclass_weights_dict     ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:21:06.539555Z","iopub.execute_input":"2021-06-14T13:21:06.540054Z","iopub.status.idle":"2021-06-14T13:21:06.601957Z","shell.execute_reply.started":"2021-06-14T13:21:06.540013Z","shell.execute_reply":"2021-06-14T13:21:06.600665Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.shape","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:42:48.483056Z","iopub.execute_input":"2021-06-14T12:42:48.483489Z","iopub.status.idle":"2021-06-14T12:42:48.491318Z","shell.execute_reply.started":"2021-06-14T12:42:48.483453Z","shell.execute_reply":"2021-06-14T12:42:48.489823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Checking distribution of Target variable between train , test & validation split ","metadata":{}},{"cell_type":"code","source":"fig, ax  = plt.subplots( nrows = 1, ncols = 3, figsize = ( 15, 5 ), dpi = 90  )\nax[0].set_title( label = \"Train Sample Distribution\")\nsns.countplot( train_df[\"target\"]  ,ax = ax[0])\nax[1].set_title( label = \"Test Sample Distribution\")\nsns.countplot( test_df[\"target\"]  ,ax = ax[1])\nax[2].set_title( label = \"Validation Sample Distribution\")\nsns.countplot( valdation_df[\"target\"]  ,ax = ax[2])\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-13T11:24:00.093301Z","iopub.execute_input":"2021-06-13T11:24:00.093691Z","iopub.status.idle":"2021-06-13T11:24:00.531842Z","shell.execute_reply.started":"2021-06-13T11:24:00.093661Z","shell.execute_reply":"2021-06-13T11:24:00.530732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Data generator & takingonly axis 0,2,4 from numpy arrya of 6  channels.\n# Channel 1,3,5 are signal coming from man made sources","metadata":{}},{"cell_type":"code","source":"'''\ndef Read_numpy_image( file_name_list, traget_list, train = False ):\n    \n    def gen():\n        for each_file, target in zip( file_name_list,traget_list ):\n            \n            data = np.load( file_name )\n            data = np.dstack( (data[0],data[2], data[3]) )\n            data = np.resize(data, ( CONFIG.IMAGE_WIDTH,CONFIG.IMAGE_HEIGHT, 3 ) )\n        \n            yield  data, target \n            \n    return ( gen )\n\n\ndef map_func ( x, y  ):\n    return ( x, y )\n\n\n\ndef DATA_SET_GENERATOR ( df ):\n    \n        AUTOTUNE = tf.data.AUTOTUNE\n        train_dataset = tf.data.Dataset.from_generator(generator=Read_numpy_image( file_name_list= df[\"path\"], \n                                                                                   traget_list = df[\"target\"] \n                                                                                 ),\n                                                      output_types = ( np.float32,np.float32),\n                                                      output_shapes= ( ( CONFIG.IMAGE_WIDTH, CONFIG.IMAGE_HEIGHT,3 ), 1)\n                                                      )\n        train_dataset.map( map_func=map_func,\n                            num_parallel_calls=AUTOTUNE,\n                            # Order does not matter.\n                            deterministic=False#,\n                            #prefetch(AUTO)\n                         )\n        train_dataset = train_dataset.batch( CONFIG.BATCH_SIZE, drop_remainder=False)\n        # Prefetch some batches.\n        train_dataset = train_dataset.prefetch(AUTOTUNE)\n    \n        return ( train_dataset )\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-05T08:36:53.222652Z","iopub.execute_input":"2021-06-05T08:36:53.223002Z","iopub.status.idle":"2021-06-05T08:36:53.228844Z","shell.execute_reply.started":"2021-06-05T08:36:53.222973Z","shell.execute_reply":"2021-06-05T08:36:53.227894Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef read_numpy_data( file_name_result ):\n\n    file_name=file_name_result\n    data = np.load( file_name.numpy() ).astype( np.float32 )    \n    data = np.vstack( ( data[1], data[3], data[5] ) )\n    return  np.dstack ( [ data, data, data] ) \n\n\n\ndef resize_image( df_dict ):\n\n    [image, ] =  tf.py_function( read_numpy_data,  [ df_dict[\"path\"] ], [tf.float32] )\n    image.set_shape( ( CONFIG.IMAGE_HEIGHT,CONFIG.IMAGE_WIDTH, CONFIG.CHANNEL ) )\n    image = tf.image.resize( image , ( CONFIG.IMAGE_HEIGHT,CONFIG.IMAGE_WIDTH ) )\n    label = df_dict[\"target\"]\n    label = tf.cast( label, tf.int16 )\n\n    return  image, label \n\n\n\n\ndef create_tf_dataset( dataframe ):\n\n    tf_dataset = tf.data.Dataset.from_tensor_slices ( dict ( dataframe[ [\"path\",\"target\"] ] ) ) \n    tf_dataset = ( tf_dataset\n                  .shuffle (1024)\n                  .map( resize_image,num_parallel_calls= tf.data.AUTOTUNE)\n                  .batch( CONFIG.BATCH_SIZE )\n                  .prefetch( tf.data.AUTOTUNE)\n                 )\n\n    return  tf_dataset  \n\ntrain_dataset = create_tf_dataset ( train_df )\ntest_dataset = create_tf_dataset ( test_df )\n\nval_dataset = create_tf_dataset ( valdation_df )\n\n\n\n\nTRAIN_STEPS_PER_EPOCH= int ( train_df.shape[0]/CONFIG.BATCH_SIZE )\nVALIDATION_STEPS_PER_EPOCH = int ( valdation_df.shape[0]/CONFIG.BATCH_SIZE )\n\nif ( TRAIN_STEPS_PER_EPOCH * CONFIG.BATCH_SIZE ) !=  train_df.shape[0]: TRAIN_STEPS_PER_EPOCH= TRAIN_STEPS_PER_EPOCH+1\nif ( VALIDATION_STEPS_PER_EPOCH * CONFIG.BATCH_SIZE ) !=  valdation_df.shape[0]: VALIDATION_STEPS_PER_EPOCH= VALIDATION_STEPS_PER_EPOCH+1\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:21:13.037681Z","iopub.execute_input":"2021-06-14T13:21:13.038199Z","iopub.status.idle":"2021-06-14T13:21:15.505751Z","shell.execute_reply.started":"2021-06-14T13:21:13.038139Z","shell.execute_reply":"2021-06-14T13:21:15.504758Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Creating Tes, Train & validation Tensor data ","metadata":{}},{"cell_type":"code","source":"'''\ntrain_dataset = DATA_SET_GENERATOR ( train_df )\ntest_dataset = DATA_SET_GENERATOR ( test_df )\nval_dataset = DATA_SET_GENERATOR ( valdation_df )\n\nTRAIN_STEPS_PER_EPOCH= int ( train_df.shape[0]/CONFIG.BATCH_SIZE )\nVALIDATION_STEPS_PER_EPOCH = int ( valdation_df.shape[0]/CONFIG.BATCH_SIZE )\nif ( TRAIN_STEPS_PER_EPOCH * CONFIG.BATCH_SIZE ) !=  train_df.shape[0]: TRAIN_STEPS_PER_EPOCH= TRAIN_STEPS_PER_EPOCH+1\nif ( VALIDATION_STEPS_PER_EPOCH * CONFIG.BATCH_SIZE ) !=  valdation_df.shape[0]: VALIDATION_STEPS_PER_EPOCH= VALIDATION_STEPS_PER_EPOCH+1\n'''","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:05:13.365776Z","iopub.execute_input":"2021-06-05T09:05:13.366089Z","iopub.status.idle":"2021-06-05T09:05:13.371161Z","shell.execute_reply.started":"2021-06-05T09:05:13.36606Z","shell.execute_reply":"2021-06-05T09:05:13.370104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# UseEfficient net to start classification ","metadata":{}},{"cell_type":"code","source":"def build_lrfn(lr_start=0.00001, lr_max=0.000075, lr_min=0.000001, lr_rampup_epochs=20, lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * strategy.num_replicas_in_sync\n    \n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) * lr_exp_decay ** (epoch - lr_rampup_epochs - lr_sustain_epochs) + lr_min\n        return lr\n    \n    return lrfn","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:21:17.74633Z","iopub.execute_input":"2021-06-14T13:21:17.746868Z","iopub.status.idle":"2021-06-14T13:21:17.754513Z","shell.execute_reply.started":"2021-06-14T13:21:17.746806Z","shell.execute_reply":"2021-06-14T13:21:17.753288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_train_val_loss_plot( history):\n    \n    key = list ( history.history.keys() )\n    \n    key = [ key[1],key[3] ]\n    sns.lineplot (x = range(0, len(history.history[key[0]] )), y = history.history[key[0]] ) \n    sns.lineplot (x = range(0, len(history.history[key[1]] )), y = history.history[key[1]] ) \n    plt.legend( key, loc =\"upper right\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(key[0])\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-12T05:36:01.687739Z","iopub.execute_input":"2021-06-12T05:36:01.688181Z","iopub.status.idle":"2021-06-12T05:36:01.696203Z","shell.execute_reply.started":"2021-06-12T05:36:01.68815Z","shell.execute_reply":"2021-06-12T05:36:01.694514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0001)\n\nnew_eff_model.compile( optimizer=optimizer, loss=\"binary_crossentropy\",metrics=['accuracy'])","metadata":{"execution":{"iopub.status.busy":"2021-06-11T03:58:58.710628Z","iopub.execute_input":"2021-06-11T03:58:58.711035Z","iopub.status.idle":"2021-06-11T03:58:58.739212Z","shell.execute_reply.started":"2021-06-11T03:58:58.711004Z","shell.execute_reply":"2021-06-11T03:58:58.736876Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrfn = build_lrfn()\n\nmodel_history = new_eff_model.fit_generator(train_dataset,\n                                             class_weight= class_weights_dict,\n                                             steps_per_epoch= TRAIN_STEPS_PER_EPOCH, \n                                             epochs = 10, \n                                             validation_data= val_dataset,\n                                             validation_steps = VALIDATION_STEPS_PER_EPOCH,\n                                            callbacks=[ tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1),\n                                                      tf.keras.callbacks.ModelCheckpoint( os.path.join(\"./model.h5\"), \n                                                                                         monitor='train_loss', \n                                                                                         verbose=0,\n                                                                                         save_best_only=True, \n                                                                                         save_weights_only=False,\n                                                                                         mode='auto', \n                                                                                         save_freq='epoch'\n                                                                                        )\n                                                      ]\n                                        )","metadata":{"execution":{"iopub.status.busy":"2021-06-08T14:32:40.70951Z","iopub.execute_input":"2021-06-08T14:32:40.709822Z","iopub.status.idle":"2021-06-08T14:44:17.620199Z","shell.execute_reply.started":"2021-06-08T14:32:40.709793Z","shell.execute_reply":"2021-06-08T14:44:17.6194Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"efff_net.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-14T12:47:59.909557Z","iopub.execute_input":"2021-06-14T12:47:59.909991Z","iopub.status.idle":"2021-06-14T12:48:00.302617Z","shell.execute_reply.started":"2021-06-14T12:47:59.909958Z","shell.execute_reply":"2021-06-14T12:48:00.301287Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_train_val_loss_plot ( model_history )","metadata":{"execution":{"iopub.status.busy":"2021-06-08T14:45:04.100301Z","iopub.execute_input":"2021-06-08T14:45:04.100624Z","iopub.status.idle":"2021-06-08T14:45:04.124849Z","shell.execute_reply.started":"2021-06-08T14:45:04.100594Z","shell.execute_reply":"2021-06-08T14:45:04.123633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"horizontal_flip = tf.keras.layers.experimental.preprocessing.RandomFlip( \"horizontal_and_vertical\", seed=CONFIG.RANDOM_STATE )\nrandom_rotation = tf.keras.layers.experimental.preprocessing.RandomRotation ( 0.2 )\ncontrast = tf.keras.layers.experimental.preprocessing.RandomContrast( factor = 0.2,  seed=CONFIG.RANDOM_STATE  )\nnoise = tf.keras.layers.GaussianNoise( stddev= 0.2 )","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:21:21.92093Z","iopub.execute_input":"2021-06-14T13:21:21.921293Z","iopub.status.idle":"2021-06-14T13:21:22.372487Z","shell.execute_reply.started":"2021-06-14T13:21:21.921239Z","shell.execute_reply":"2021-06-14T13:21:22.371361Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ninput_mo = tf.keras.layers.Input(shape= ( CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.CHANNEL) )\n\nefff_net =tf.keras.applications.EfficientNetB7(include_top = False, \n                                               weights =\"imagenet\" , \n                                               input_shape = ( CONFIG.IMAGE_HEIGHT, CONFIG.IMAGE_WIDTH, CONFIG.CHANNEL) ,\n                                               input_tensor = input_mo,\n                                               classes=2\n                                              )\n\nfor i ,layer in enumerate ( efff_net.layers ) :\n    if i> 700:\n        layer.trainable = False\n    else:\n        layer.trainable = False\n        #horizontal_flip,random_rotation,contrast,\n  \nmodel = tf.keras.Sequential( [horizontal_flip,random_rotation,contrast,noise,efff_net,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        tf.keras.layers.Dense(512, activation= 'tanh'), \n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(200, activation= 'tanh'),\n        tf.keras.layers.Dropout(0.25),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(100, activation= 'tanh'),\n        tf.keras.layers.Dense(1, activation='tanh')\n        ])    \n        \n        \n#efff_net( inputs = input_mo)\n#eff_net_output = tf.keras.layers.Flatten()( efff_net.layers[-1].output )\n\n\n#x = layers.GlobalAveragePooling2D()( efff_net.layers[-1].output )\n#x = layers.Dropout(0.5)(x)\n    \n#outputs = layers.Dense(1 )(x)\n#outputs = layers.Activation('sigmoid', dtype='float32', name='predictions')(outputs)\n\n#layer_1 = tf.keras.layers.Dense( units =500,activation = \"relu\" , use_bias = True ) (eff_net_output) \n#layer_2 = tf.keras.layers.Dropout( rate= 0.05 )  ( layer_1 )\n#layer_3 =  tf.keras.layers.Dense( units =100,activation = \"relu\" , use_bias = True )  ( layer_2 )\n#layer_4 =  tf.keras.layers.Dropout( rate= 0.05 )  ( layer_3 )\n#layer_5 =  tf.keras.layers.Dense( units =1,activation = \"sigmoid\" , use_bias = True ) ( layer_4 ) \n#layer_6 =  tf.keras.layers.Dropout( rate= 0.25 )  ( layer_5 )\n#layer_7 =  tf.keras.layers.Dense( units =1,activation = \"sigmoid\" , use_bias = True )  ( layer_6 )\n\n#new_eff_model_2 = models.Model( inputs = input_mo, outputs = outputs )\n\noptimizer = tf.keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0001)\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:21:24.384866Z","iopub.execute_input":"2021-06-14T13:21:24.385226Z","iopub.status.idle":"2021-06-14T13:21:36.595237Z","shell.execute_reply.started":"2021-06-14T13:21:24.385194Z","shell.execute_reply":"2021-06-14T13:21:36.594137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.compile( optimizer= \"adam\", #optimizer\n                        loss=\"binary_crossentropy\",\n                        metrics=[tf.keras.metrics.AUC(curve='ROC')])\n","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:21:36.597113Z","iopub.execute_input":"2021-06-14T13:21:36.597484Z","iopub.status.idle":"2021-06-14T13:21:36.637846Z","shell.execute_reply.started":"2021-06-14T13:21:36.597444Z","shell.execute_reply":"2021-06-14T13:21:36.636811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n#import neural_structured_learning as nsl\n\nlrfn = build_lrfn()\n\n# Wrap the model with adversarial regularization.\n#adv_config = nsl.configs.make_adv_reg_config(multiplier=0.2, adv_step_size=0.05)\n#adv_model = nsl.keras.AdversarialRegularization(model, adv_config=adv_config)\n\n#adv_model.compile( optimizer= \"adam\", #optimizer\n#                        loss=\"binary_crossentropy\",\n#                        metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n\nmodel_history2 = model.fit_generator(train_dataset,\n                                              class_weight= class_weights_dict,\n                                             steps_per_epoch= TRAIN_STEPS_PER_EPOCH, \n                                             epochs =10, \n                                             validation_data= val_dataset,\n                                             validation_steps = VALIDATION_STEPS_PER_EPOCH,\n                                            callbacks=[ tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1),\n                                  tf.keras.callbacks.ModelCheckpoint( \"./model2.h5\", \n                                                                     monitor='train_loss', \n                                                                     verbose=0,\n                                                                     save_best_only=True, \n                                                                     save_weights_only=True,\n                                                                     mode='auto', \n                                                                     save_freq='epoch'\n                                                                    )\n                                  ]\n                        )","metadata":{"execution":{"iopub.status.busy":"2021-06-14T13:21:36.639826Z","iopub.execute_input":"2021-06-14T13:21:36.640289Z","iopub.status.idle":"2021-06-14T13:22:13.94529Z","shell.execute_reply.started":"2021-06-14T13:21:36.640247Z","shell.execute_reply":"2021-06-14T13:22:13.94228Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_train_val_loss_plot ( model_history2 )","metadata":{"execution":{"iopub.status.busy":"2021-06-09T11:20:22.482453Z","iopub.execute_input":"2021-06-09T11:20:22.482797Z","iopub.status.idle":"2021-06-09T11:20:22.749964Z","shell.execute_reply.started":"2021-06-09T11:20:22.482765Z","shell.execute_reply":"2021-06-09T11:20:22.748953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" predict = model.predict( test_dataset ) ","metadata":{"execution":{"iopub.status.busy":"2021-06-09T11:21:07.389771Z","iopub.execute_input":"2021-06-09T11:21:07.390095Z","iopub.status.idle":"2021-06-09T11:21:09.006961Z","shell.execute_reply.started":"2021-06-09T11:21:07.390061Z","shell.execute_reply":"2021-06-09T11:21:09.005823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def confusion_matrix ( model, test_data, ):\n    \n    predicted_data = model.predict( test_data )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Thanks to UPGRAD, from one othere project I got this code, hoping it will work for Auto encoder architecture neural network \n\ndef data_generator_Rev_01( file_list , image_width,image_length, num_channel):\n    \n    def generator():\n        \n\n            #batch_data = np.zeros( (  image_width, image_length, num_channel ) )\n            #batch_file_list = np.random.permutation ( file_list )\n\n            #for count , each_file in enumerate( batch_file_list) :\n            for each_file in file_list:\n                \n                np_data = np.load( each_file ).astype( np.float32 )    \n                np_data = np.dstack( ( np_data[0], np_data[2], np_data[4] ) ) #( np_data[0], np_data[2], np_data[4] )\n\n                np_data = np.resize( np_data,( image_width,image_length, num_channel ) )\n\n                yield np_data,np_data\n            \n    return ( generator )\n\n\n\ndef map_func( x ):\n    return x","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:37:11.761221Z","iopub.execute_input":"2021-06-08T13:37:11.761816Z","iopub.status.idle":"2021-06-08T13:37:11.768107Z","shell.execute_reply.started":"2021-06-08T13:37:11.761766Z","shell.execute_reply":"2021-06-08T13:37:11.76726Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n#file_list = train_df[train_df[\"target\"] == 0][\"path\"].values()\ngen = data_generator_Rev_01 ( file_list = file_list,\n                                #batch_size = CONFIG[\"BATCH_SIZE\"],\n                                image_width = CONFIG[\"image_width\"], \n                                image_length = CONFIG[\"image_height\"], \n                                num_channel = CONFIG[\"num_channel\"]\n                               )\ndataset = tf.data.Dataset.from_generator(\n    generator=gen, \n    output_types=(np.float32, np.int32), \n    output_shapes=( ( CONFIG[\"image_width\"],CONFIG[\"image_height\"],3 ), ( CONFIG[\"image_width\"],CONFIG[\"image_height\"],3 ) )\n)\n\n# Parallelize the augmentation.\ndataset = dataset.map(\n    map_func, \n    num_parallel_calls=AUTOTUNE,\n    # Order does not matter.\n    deterministic=False#,\n    #prefetch(AUTO)\n)\ndataset = dataset.batch( CONFIG[\"BATCH_SIZE\"], drop_remainder=False)\n# Prefetch some batches.\ndataset = dataset.prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-06-08T13:37:34.818089Z","iopub.execute_input":"2021-06-08T13:37:34.818473Z","iopub.status.idle":"2021-06-08T13:37:34.848832Z","shell.execute_reply.started":"2021-06-08T13:37:34.818418Z","shell.execute_reply":"2021-06-08T13:37:34.847144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data is already normailsed to have mean of 0, not doing any preprocessing on the each images.\n# Will start wriing generator function for Encoders. Because of below reason\n* Avalable generator wont work for Autoencoder, tried few they didn't work. Found one code f using TFrecod, it was to heay for me.\n* So i took one of generator code I got from Upgrad assignment,","metadata":{}},{"cell_type":"markdown","source":"* Each numpy file has 6 channels, not all channels are use full found few discussion thread mentioning using only 3 channels.\n* I'll be exploring with 3 channels first, later I can expand to 6 channels\n* discussion therad : \n* https://www.kaggle.com/c/seti-breakthrough-listen/discussion/239173\n* https://www.kaggle.com/c/seti-breakthrough-listen/discussion/238241","metadata":{}},{"cell_type":"markdown","source":"channels ABACAD. select only cannel B,C &D","metadata":{}},{"cell_type":"markdown","source":"# Got this facinating link to for data generator.\nhttps://stackoverflow.com/questions/64356769/tensorflow2-x-custom-data-generator-with-multiprocessing\n\nmy method was taking 160s, were as method in the above link takes 37s. close 6 time faster wow.\n\nFunction implemented with above method is with \"data_generator_Rev_01\"","metadata":{}},{"cell_type":"code","source":"## Thanks to UPGRAD, from one othere project I got this code, hoping it will work for Auto encoder architecture neural network \n\ndef data_generator( file_list, batch_size,image_width, image_length, num_channel = 3 ):\n    \n    \n    number_of_batches = int ( len ( file_list )/ batch_size )\n    \n    leftoved_file_count = 0\n    \n    if (number_of_batches * batch_size) == len( file_list ):\n        leftover= False\n    else:\n        leftover = True\n        leftoved_file_count = len ( file_list ) -  (number_of_batches * batch_size)\n    \n    \n    while True:\n        \n        for each_batch in range( 0, number_of_batches ):\n            \n            if  leftover & ( each_batch == number_of_batches -1 )  :\n                \n                batch_data = np.zeros( ( leftoved_file_count, image_width, image_length, num_channel ) ) # [ Batch number]\n                batch_file_list = np.random.permutation ( file_list[ : - leftoved_file_count ] )\n                \n                \n            else:\n                \n                batch_data = np.zeros( ( batch_size, image_width, image_length, num_channel ) )\n                batch_file_list = np.random.permutation ( file_list[ ( each_batch * batch_size ) : (batch_size * (each_batch+ 1 ) ) ] )\n            \n            for count , each_file in enumerate( batch_file_list) :\n                \n                np_data = np.load( each_file ).astype( np.float32 )    \n                np_data = np.dstack( ( np_data[0], np_data[2], np_data[4] ) )\n                \n                batch_data[count] = resize( np_data,( image_width,image_length, num_channel ) )\n        \n        yield batch_data","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:19:30.441233Z","iopub.execute_input":"2021-06-05T09:19:30.44159Z","iopub.status.idle":"2021-06-05T09:19:30.449823Z","shell.execute_reply.started":"2021-06-05T09:19:30.441556Z","shell.execute_reply":"2021-06-05T09:19:30.448921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = { \"BATCH_SIZE\" : 50, \"image_width\": 224, \"image_height\": 224,\"num_channel\" : 3, \"sample_size\" : 1000, }","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:19:36.211957Z","iopub.execute_input":"2021-06-05T09:19:36.212291Z","iopub.status.idle":"2021-06-05T09:19:36.216382Z","shell.execute_reply.started":"2021-06-05T09:19:36.212258Z","shell.execute_reply":"2021-06-05T09:19:36.21545Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data_x = data_generator ( file_list = np.random.permutation (train_df[\"path\"]) [: CONFIG[\"sample_size\"]],\n                                batch_size = CONFIG[\"BATCH_SIZE\"],\n                                image_width = CONFIG[\"image_width\"], \n                                image_length = CONFIG[\"image_height\"], \n                                num_channel = CONFIG[\"num_channel\"]\n                               )\n\nif CONFIG[\"sample_size\"] % CONFIG[\"BATCH_SIZE\"] == 0 :\n    num_steps = int( CONFIG[\"sample_size\"]/CONFIG[\"BATCH_SIZE\"]) \nelse:\n    num_steps = int( CONFIG[\"sample_size\"] /CONFIG[\"BATCH_SIZE\"])  + 1","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:19:37.585039Z","iopub.execute_input":"2021-06-05T09:19:37.585354Z","iopub.status.idle":"2021-06-05T09:19:37.593074Z","shell.execute_reply.started":"2021-06-05T09:19:37.585327Z","shell.execute_reply":"2021-06-05T09:19:37.591676Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#next ( train_data_x )","metadata":{"execution":{"iopub.status.busy":"2021-05-29T13:02:23.21067Z","iopub.execute_input":"2021-05-29T13:02:23.211168Z","iopub.status.idle":"2021-05-29T13:02:23.214496Z","shell.execute_reply.started":"2021-05-29T13:02:23.211132Z","shell.execute_reply":"2021-05-29T13:02:23.213617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_input  =   ( CONFIG[\"image_height\"], CONFIG[\"image_width\"], CONFIG[\"num_channel\"])\nencoder = models.Sequential()\nencoder.add( layers.Conv2D ( filters = 224 , kernel_size = 2, padding =\"same\",strides = 1, activation = \"tanh\",use_bias = True, input_shape = model_input  ) )\n#encoder.add( layers.BatchNormalization ( ) )\nencoder.add( layers.Conv2D ( filters = 128 , kernel_size = 3, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_02\" )\n#encoder.add( layers.BatchNormalization ( ) )\nencoder.add( layers.Conv2D ( filters = 64 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_03\")\n#encoder.add( layers.BatchNormalization ( ) si\nencoder.add( layers.Conv2D ( filters = 32 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_04\")\n#encoder.add( layers.BatchNormalization ( ) )\nencoder.add( layers.Conv2D ( filters = 16 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_04\")\nencoder.add( layers.Conv2D ( filters = 8 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_04\")\n#decoder = models.Sequential()\nencoder.add( layers.Conv2DTranspose ( filters = 8 , kernel_size =4 , padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_04\")                    \n#encoder.add( layers.BatchNormalization ( ) )\nencoder.add( layers.Conv2DTranspose ( filters = 16 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_03\")\n#encoder.add( layers.BatchNormalization ( ) )\nencoder.add( layers.Conv2DTranspose ( filters = 32 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True ) )#, name=\"layer_02\" )\n#encoder.add( layers.BatchNormalization ( ) )\nencoder.add( layers.Conv2DTranspose ( filters = 64 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True) )\n#encoder.add( layers.BatchNormalization ( ) )\nencoder.add( layers.Conv2DTranspose ( filters = 128 , kernel_size =3, padding =\"same\",strides = 2,activation = \"tanh\",use_bias = True) )\nencoder.add( layers.Conv2DTranspose ( filters = 3 , kernel_size = 2, padding =\"same\",strides = 1,activation = \"tanh\",use_bias = True) )\n\n\nencoder.compile ( optimizer= \"adam\", \n               loss=\"mse\"\n               )\n\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:21:00.493727Z","iopub.execute_input":"2021-06-03T12:21:00.494058Z","iopub.status.idle":"2021-06-03T12:21:00.669888Z","shell.execute_reply.started":"2021-06-03T12:21:00.494027Z","shell.execute_reply":"2021-06-03T12:21:00.669123Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#encoder.fit( train_data_x,train_data_x,epochs = 10  ,steps_per_epoch = num_steps ,verbose=1)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T11:38:12.450589Z","iopub.execute_input":"2021-05-30T11:38:12.451003Z","iopub.status.idle":"2021-05-30T11:38:12.456145Z","shell.execute_reply.started":"2021-05-30T11:38:12.450955Z","shell.execute_reply":"2021-05-30T11:38:12.454986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"## Thanks to UPGRAD, from one othere project I got this code, hoping it will work for Auto encoder architecture neural network \n\ndef data_generator_Rev_01( file_list , image_width,image_length, num_channel):\n    \n    def generator():\n        \n\n            #batch_data = np.zeros( (  image_width, image_length, num_channel ) )\n            #batch_file_list = np.random.permutation ( file_list )\n\n            #for count , each_file in enumerate( batch_file_list) :\n            for each_file in file_list:\n                \n                np_data = np.load( each_file ).astype( np.float32 )    \n                np_data = np.dstack( ( np_data[0], np_data[2], np_data[4] ) ) #( np_data[0], np_data[2], np_data[4] )\n\n                np_data = np.resize( np_data,( image_width,image_length, num_channel ) )\n\n                yield np_data,np_data\n            \n    return ( generator )\n\n\n\ndef map_func( x, y):\n    return x, y","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:23:13.081038Z","iopub.execute_input":"2021-06-03T12:23:13.081393Z","iopub.status.idle":"2021-06-03T12:23:13.087553Z","shell.execute_reply.started":"2021-06-03T12:23:13.081358Z","shell.execute_reply":"2021-06-03T12:23:13.086364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_list = train_df[train_df[\"target\"] == 0][\"path\"].values [: CONFIG[\"sample_size\"]]","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:21:22.407868Z","iopub.execute_input":"2021-06-03T12:21:22.408181Z","iopub.status.idle":"2021-06-03T12:21:22.41725Z","shell.execute_reply.started":"2021-06-03T12:21:22.408151Z","shell.execute_reply":"2021-06-03T12:21:22.416121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n#file_list = train_df[train_df[\"target\"] == 0][\"path\"].values()\ngen = data_generator_Rev_01 ( file_list = file_list,\n                                #batch_size = CONFIG[\"BATCH_SIZE\"],\n                                image_width = CONFIG[\"image_width\"], \n                                image_length = CONFIG[\"image_height\"], \n                                num_channel = CONFIG[\"num_channel\"]\n                               )\ndataset = tf.data.Dataset.from_generator(\n    generator=gen, \n    output_types=(np.float32, np.int32), \n    output_shapes=( ( CONFIG[\"image_width\"],CONFIG[\"image_height\"],3 ), ( CONFIG[\"image_width\"],CONFIG[\"image_height\"],3 ) )\n)\n\n# Parallelize the augmentation.\ndataset = dataset.map(\n    map_func, \n    num_parallel_calls=AUTOTUNE,\n    # Order does not matter.\n    deterministic=False#,\n    #prefetch(AUTO)\n)\ndataset = dataset.batch( CONFIG[\"BATCH_SIZE\"], drop_remainder=False)\n# Prefetch some batches.\ndataset = dataset.prefetch(AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:23:16.359278Z","iopub.execute_input":"2021-06-03T12:23:16.359679Z","iopub.status.idle":"2021-06-03T12:23:16.390109Z","shell.execute_reply.started":"2021-06-03T12:23:16.359646Z","shell.execute_reply":"2021-06-03T12:23:16.389312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lrfn = build_lrfn()\nAuto_Encoder_History = encoder.fit_generator( dataset ,\n                                             epochs = 30 ,\n                                             callbacks=[ tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=1)] )","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:23:18.650955Z","iopub.execute_input":"2021-06-03T12:23:18.65134Z","iopub.status.idle":"2021-06-03T12:29:06.199021Z","shell.execute_reply.started":"2021-06-03T12:23:18.651295Z","shell.execute_reply":"2021-06-03T12:29:06.19812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reference :https://www.kaggle.com/akhileshdkapse/seti-cnn-encoder-decoder-model-tpu\n#https://www.kaggle.com/awsaf49/seti-bl-tf-starter-tpu\n#https://machinelearningmastery.com/learning-rate-for-deep-learning-neural-networks/","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"loss_value = Auto_Encoder_History.history[\"loss\"]\nsns.lineplot( y = loss_value ,x = range( 0, len(loss_value) )  )","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:35:02.390633Z","iopub.execute_input":"2021-06-03T12:35:02.391038Z","iopub.status.idle":"2021-06-03T12:35:02.582086Z","shell.execute_reply.started":"2021-06-03T12:35:02.390999Z","shell.execute_reply":"2021-06-03T12:35:02.581124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def data_generator_for_predictor( file_list,image_width, image_length, num_channel = 3 ):\n    \n        #batch_data = np.zeros( (  image_width, image_length, num_channel ) )\n\n        np_data = np.load( file_list ).astype( np.float32 )    \n        np_data = np.dstack( ( np_data[1], np_data[3], np_data[5] ) )\n\n        batch_data = np.resize( np_data,( 1 ,image_width,image_length, num_channel ) )\n\n        return ( batch_data )","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:35:27.487313Z","iopub.execute_input":"2021-06-03T12:35:27.487669Z","iopub.status.idle":"2021-06-03T12:35:27.494823Z","shell.execute_reply.started":"2021-06-03T12:35:27.487636Z","shell.execute_reply":"2021-06-03T12:35:27.491995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"file_path_name = train_df [\"path\"].iloc [ np.random.randint( 1000) ]\nfile_path_name = train_df[train_df[\"target\"] == 0 ] [\"path\"].iloc [10  ]\n\nd = data_generator_for_predictor( file_path_name,\n                                image_width = CONFIG[\"image_width\"], \n                                image_length = CONFIG[\"image_height\"], \n                                num_channel = CONFIG[\"num_channel\"]\n                                )\ndecode_data = encoder.predict( d )\nmean_absoulte_error = tf.keras.losses.MeanAbsoluteError()\nmean_absoulte_error( decode_data[0] , d[ 0 ] )","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:35:38.081496Z","iopub.execute_input":"2021-06-03T12:35:38.081826Z","iopub.status.idle":"2021-06-03T12:35:38.145551Z","shell.execute_reply.started":"2021-06-03T12:35:38.081796Z","shell.execute_reply":"2021-06-03T12:35:38.144741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len( list ( train_df[\"path\"][:100] ) )","metadata":{"execution":{"iopub.status.busy":"2021-05-30T12:10:05.498285Z","iopub.execute_input":"2021-05-30T12:10:05.498637Z","iopub.status.idle":"2021-05-30T12:10:05.50539Z","shell.execute_reply.started":"2021-05-30T12:10:05.4986Z","shell.execute_reply":"2021-05-30T12:10:05.504326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mean_absoulte_error = tf.keras.losses.MeanAbsoluteError()\nloss_value = []\ntrain_df_2 = train_df.head( 100 )\nfor each_file in train_df[\"path\"][:100]:\n    d = data_generator_for_predictor( each_file,\n                                image_width = CONFIG[\"image_width\"], \n                                image_length = CONFIG[\"image_height\"], \n                                num_channel = CONFIG[\"num_channel\"]\n                                )\n    decode_data = encoder.predict( d )\n\n    loss_value.append( mean_absoulte_error( decode_data[0] , d[ 0 ] ).numpy() )\n\ntrain_df_2[\"MAE\"] = loss_value","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:35:44.593686Z","iopub.execute_input":"2021-06-03T12:35:44.594008Z","iopub.status.idle":"2021-06-03T12:35:49.054376Z","shell.execute_reply.started":"2021-06-03T12:35:44.593976Z","shell.execute_reply":"2021-06-03T12:35:49.052053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_2.head()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:35:49.055754Z","iopub.execute_input":"2021-06-03T12:35:49.056012Z","iopub.status.idle":"2021-06-03T12:35:49.067308Z","shell.execute_reply.started":"2021-06-03T12:35:49.055981Z","shell.execute_reply":"2021-06-03T12:35:49.066386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize=( 10,10))\nsns.lineplot (data = train_df_2, y=\"MAE\",x =\"id\" , hue = \"target\" )\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-03T12:35:52.967524Z","iopub.execute_input":"2021-06-03T12:35:52.967891Z","iopub.status.idle":"2021-06-03T12:35:56.497029Z","shell.execute_reply.started":"2021-06-03T12:35:52.967859Z","shell.execute_reply":"2021-06-03T12:35:56.496258Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_2[ ( train_df_2[\"MAE\"]>0.6) & (train_df_2[\"taget\"] == 1 ) ]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target = train_df [ train_df[\"path\"] ==file_path_name ][\"target\"].values[0]\ncreate_heatmap ( file_path_name, target)","metadata":{"execution":{"iopub.status.busy":"2021-05-30T05:07:36.312026Z","iopub.execute_input":"2021-05-30T05:07:36.312347Z","iopub.status.idle":"2021-05-30T05:07:38.242846Z","shell.execute_reply.started":"2021-05-30T05:07:36.312315Z","shell.execute_reply":"2021-05-30T05:07:38.241872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n  \"../input/seti-breakthrough-listen/train/\",\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  #image_size=(img_height, img_width),\n  batch_size=30)","metadata":{"execution":{"iopub.status.busy":"2021-05-28T12:27:47.140617Z","iopub.execute_input":"2021-05-28T12:27:47.141007Z","iopub.status.idle":"2021-05-28T12:28:04.837274Z","shell.execute_reply.started":"2021-05-28T12:27:47.140978Z","shell.execute_reply":"2021-05-28T12:28:04.832586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:42:10.381318Z","iopub.execute_input":"2021-05-29T12:42:10.382022Z","iopub.status.idle":"2021-05-29T12:42:10.387044Z","shell.execute_reply.started":"2021-05-29T12:42:10.381974Z","shell.execute_reply":"2021-05-29T12:42:10.386334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"a[1] = np.zeros( (2,2,3))","metadata":{"execution":{"iopub.status.busy":"2021-05-29T12:42:34.462803Z","iopub.execute_input":"2021-05-29T12:42:34.463313Z","iopub.status.idle":"2021-05-29T12:42:34.467737Z","shell.execute_reply.started":"2021-05-29T12:42:34.463272Z","shell.execute_reply":"2021-05-29T12:42:34.466737Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_path = \"../input/seti-breakthrough-listen/train_labels.csv\"\ndf = pd.read_csv( data_path, sep = \",\")","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:54.881954Z","iopub.execute_input":"2021-05-27T13:04:54.88229Z","iopub.status.idle":"2021-05-27T13:04:54.945652Z","shell.execute_reply.started":"2021-05-27T13:04:54.88226Z","shell.execute_reply":"2021-05-27T13:04:54.944608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:54.947115Z","iopub.execute_input":"2021-05-27T13:04:54.947415Z","iopub.status.idle":"2021-05-27T13:04:54.974416Z","shell.execute_reply.started":"2021-05-27T13:04:54.947387Z","shell.execute_reply":"2021-05-27T13:04:54.973342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print (\"number of signal with target 1 = {}\".format( df[ df[\"target\"] == 1 ].shape) )\nprint (\"number of signal with target 0 = {}\".format( df[ df[\"target\"] == 0 ].shape) )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:54.975848Z","iopub.execute_input":"2021-05-27T13:04:54.976165Z","iopub.status.idle":"2021-05-27T13:04:55.008658Z","shell.execute_reply.started":"2021-05-27T13:04:54.976136Z","shell.execute_reply":"2021-05-27T13:04:55.007573Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.set_style(\"darkgrid\")","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.010178Z","iopub.execute_input":"2021-05-27T13:04:55.01084Z","iopub.status.idle":"2021-05-27T13:04:55.015348Z","shell.execute_reply.started":"2021-05-27T13:04:55.010792Z","shell.execute_reply":"2021-05-27T13:04:55.013932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure( figsize = ( 8,10) , dpi =80 )\nax = fig.add_subplot ( 111)\nplt.title( \" Count of Anomally & non Anamolly data \")\nsns.countplot( df[\"target\"], ax = ax  )\nax.xaxis.set_tick_params( labelsize = 20 )\nax.yaxis.set_tick_params( labelsize = 20 )\nax.yaxis.label.set_fontsize( 20 )\nax.xaxis.label.set_fontsize( 20 )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.01948Z","iopub.execute_input":"2021-05-27T13:04:55.019971Z","iopub.status.idle":"2021-05-27T13:04:55.395675Z","shell.execute_reply.started":"2021-05-27T13:04:55.019932Z","shell.execute_reply":"2021-05-27T13:04:55.394595Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.tail()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.397466Z","iopub.execute_input":"2021-05-27T13:04:55.397811Z","iopub.status.idle":"2021-05-27T13:04:55.4076Z","shell.execute_reply.started":"2021-05-27T13:04:55.397781Z","shell.execute_reply":"2021-05-27T13:04:55.406412Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_path =\"../input/seti-breakthrough-listen/train/\"\ndf[\"path\"]= df[\"id\"].apply( lambda x: train_path+x[0]+\"/\"+ x +\".npy\" )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.409289Z","iopub.execute_input":"2021-05-27T13:04:55.409751Z","iopub.status.idle":"2021-05-27T13:04:55.457768Z","shell.execute_reply.started":"2021-05-27T13:04:55.409706Z","shell.execute_reply":"2021-05-27T13:04:55.456708Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.459391Z","iopub.execute_input":"2021-05-27T13:04:55.459853Z","iopub.status.idle":"2021-05-27T13:04:55.471579Z","shell.execute_reply.started":"2021-05-27T13:04:55.459807Z","shell.execute_reply":"2021-05-27T13:04:55.470382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.load( df[\"path\"].iloc[ np.random.randint(df.shape[0] )] ).shape","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.473154Z","iopub.execute_input":"2021-05-27T13:04:55.473462Z","iopub.status.idle":"2021-05-27T13:04:55.538658Z","shell.execute_reply.started":"2021-05-27T13:04:55.473433Z","shell.execute_reply":"2021-05-27T13:04:55.537624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_heatmap():\n    data= np.load( df[\"path\"].iloc[ np.random.randint(df.shape[0] )] )\n    fig, axis = plt.subplots( nrows = 1, ncols = 6 , dpi = 80 , figsize  =(20,5))\n    axis = axis.flatten()\n    for i,each_axis in enumerate( axis) :    sns.heatmap( data[i], ax = each_axis )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.539789Z","iopub.execute_input":"2021-05-27T13:04:55.540082Z","iopub.status.idle":"2021-05-27T13:04:55.546872Z","shell.execute_reply.started":"2021-05-27T13:04:55.540046Z","shell.execute_reply":"2021-05-27T13:04:55.54575Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"create_heatmap()\ncreate_heatmap()\ncreate_heatmap()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:04:55.548423Z","iopub.execute_input":"2021-05-27T13:04:55.548954Z","iopub.status.idle":"2021-05-27T13:05:09.850492Z","shell.execute_reply.started":"2021-05-27T13:04:55.548921Z","shell.execute_reply":"2021-05-27T13:05:09.849263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"## IMPORTING REQUIRED TENSOR FLOW \n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom  tensorflow.keras import layers,models\nfrom sklearn.model_selection import train_test_split\nimport datetime\nimport os","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:20:15.198176Z","iopub.execute_input":"2021-06-05T09:20:15.198497Z","iopub.status.idle":"2021-06-05T09:20:15.201974Z","shell.execute_reply.started":"2021-06-05T09:20:15.198456Z","shell.execute_reply":"2021-06-05T09:20:15.201334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG = {\"image_height\" : 224,\n          \"image_width\"  : 224,\n          \"batch_size\" :100,\n          \"random_state\" :  100\n         }","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:20:11.635257Z","iopub.execute_input":"2021-06-05T09:20:11.635604Z","iopub.status.idle":"2021-06-05T09:20:11.639574Z","shell.execute_reply.started":"2021-06-05T09:20:11.635574Z","shell.execute_reply":"2021-06-05T09:20:11.638602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df,train_df  = train_test_split ( train_df[ [\"path\",\"target\" ] ], \n                             test_size= 0.8, \n                             random_state= CONFIG[\"random_state\"], \n                             shuffle =True )","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:20:45.566386Z","iopub.execute_input":"2021-06-05T09:20:45.566729Z","iopub.status.idle":"2021-06-05T09:20:45.579678Z","shell.execute_reply.started":"2021-06-05T09:20:45.5667Z","shell.execute_reply":"2021-06-05T09:20:45.57875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def creat_plot(path):\n    data= np.load( path )\n    fig, axis = plt.subplots( nrows = 1, ncols = 6 , dpi = 80 , figsize  =(20,5))\n    axis = axis.flatten()\n    for i,each_axis in enumerate( axis) :    sns.heatmap( data[i], ax = each_axis )","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:20:47.905842Z","iopub.execute_input":"2021-06-05T09:20:47.906175Z","iopub.status.idle":"2021-06-05T09:20:47.911636Z","shell.execute_reply.started":"2021-06-05T09:20:47.906146Z","shell.execute_reply":"2021-06-05T09:20:47.910464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Visualizing the data for random samples after resizingdata","metadata":{}},{"cell_type":"code","source":"creat_plot(train_df[\"path\"].iloc [10] )\ncreat_plot(train_df[\"path\"].iloc[20] )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:10.144329Z","iopub.execute_input":"2021-05-27T13:05:10.144772Z","iopub.status.idle":"2021-05-27T13:05:19.806434Z","shell.execute_reply.started":"2021-05-27T13:05:10.14473Z","shell.execute_reply":"2021-05-27T13:05:19.805413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print ( \"Number of file for training = {}\".format( train_df.shape ))\nprint ( \"Number of file has anamoly  = {}\".format( test_df.shape ))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:19.810058Z","iopub.execute_input":"2021-05-27T13:05:19.810373Z","iopub.status.idle":"2021-05-27T13:05:19.816265Z","shell.execute_reply.started":"2021-05-27T13:05:19.810343Z","shell.execute_reply":"2021-05-27T13:05:19.815309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure( figsize = ( 15,8) , dpi =80 )\nax = fig.add_subplot ( 121)\nplt.title( \" Count of Anomally & non Anamolly data in train_data  \")\nsns.countplot( train_df[\"target\"], ax = ax  )\nax.xaxis.set_tick_params( labelsize = 20 )\nax.yaxis.set_tick_params( labelsize = 20 )\nax.yaxis.label.set_fontsize( 20 )\nax.xaxis.label.set_fontsize( 20 )\n\nax = fig.add_subplot ( 122)\nplt.title( \" Count of Anomally & non Anamolly data in test data  \")\nsns.countplot( test_df[\"target\"], ax = ax  )\nax.xaxis.set_tick_params( labelsize = 20 )\nax.yaxis.set_tick_params( labelsize = 20 )\nax.yaxis.label.set_fontsize( 20 )\nax.xaxis.label.set_fontsize( 20 )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:19.818138Z","iopub.execute_input":"2021-05-27T13:05:19.818467Z","iopub.status.idle":"2021-05-27T13:05:20.112813Z","shell.execute_reply.started":"2021-05-27T13:05:19.818429Z","shell.execute_reply":"2021-05-27T13:05:20.111873Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_numpy_data( file_name_result ):\n    \n    file_name=file_name_result\n    data = np.load( file_name.numpy() ).astype( np.float32 )    \n    data = np.dstack( ( data[0], data[2], data[4] ) )\n    return ( data )\n    ","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:20:51.819399Z","iopub.execute_input":"2021-06-05T09:20:51.819988Z","iopub.status.idle":"2021-06-05T09:20:51.825035Z","shell.execute_reply.started":"2021-06-05T09:20:51.819942Z","shell.execute_reply":"2021-06-05T09:20:51.824387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def resize_image( df_dict ):\n    \n    [image, ] =  tf.py_function( read_numpy_data,  [ df_dict[\"path\"] ], [tf.float32] )\n    image.set_shape(( 273, 256, 3 ) )\n    image = tf.image.resize( image , ( CONFIG[\"image_height\"],  CONFIG[\"image_width\"] ) )\n    label =  df_dict[\"target\"]#.reshape((-1,1))\n    label = tf.cast( label, tf.float32 ), (-1,1) \n  \n    return ( image, label )","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:21:36.841572Z","iopub.execute_input":"2021-06-05T09:21:36.841921Z","iopub.status.idle":"2021-06-05T09:21:36.846977Z","shell.execute_reply.started":"2021-06-05T09:21:36.841892Z","shell.execute_reply":"2021-06-05T09:21:36.845994Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_tf_dataset( dataframe ):\n    \n    tf_dataset = tf.data.Dataset.from_tensor_slices ( dict ( dataframe[ [\"path\",\"target\"] ] ) ) \n    tf_dataset = ( tf_dataset\n                  .shuffle (1024)\n                  .map( resize_image,num_parallel_calls= tf.data.AUTOTUNE)\n                  .batch( CONFIG[\"batch_size\"] )\n                  .prefetch(tf.data.AUTOTUNE)\n                 )\n    \n    return ( tf_dataset )","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:21:44.115431Z","iopub.execute_input":"2021-06-05T09:21:44.115926Z","iopub.status.idle":"2021-06-05T09:21:44.120702Z","shell.execute_reply.started":"2021-06-05T09:21:44.115885Z","shell.execute_reply":"2021-06-05T09:21:44.119799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_tf_dataset = create_tf_dataset ( train_df )\ntest_tf_dataset = create_tf_dataset ( test_df )","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:21:46.46515Z","iopub.execute_input":"2021-06-05T09:21:46.465465Z","iopub.status.idle":"2021-06-05T09:21:46.568084Z","shell.execute_reply.started":"2021-06-05T09:21:46.465436Z","shell.execute_reply":"2021-06-05T09:21:46.5674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG[\"model_name\"] = \"model_1\"\nCONFIG[\"group\"] = \"model_1\"\nCONFIG[\"run_name\"] = \"model_1_baseline\"","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:21:49.103533Z","iopub.execute_input":"2021-06-05T09:21:49.103867Z","iopub.status.idle":"2021-06-05T09:21:49.107538Z","shell.execute_reply.started":"2021-06-05T09:21:49.103839Z","shell.execute_reply":"2021-06-05T09:21:49.106834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEFAULT_MODEL = False\nif DEFAULT_MODEL: ## bulding model \n    model_input  = (  CONFIG[\"image_height\"], CONFIG[\"image_width\"], 3 )\n    model = models.Sequential()\n    model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 3,3), padding =\"valid\",activation = \"relu\",use_bias = True, input_shape = model_input  ) )\n    model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 4,4), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_02\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 5,5), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_03\")\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 6,6), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 7,7), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 8,8), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 9,9), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 12,12), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 15,15), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 15,15), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 20,20), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 25,25), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 20,20), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 25,25), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    #model.add( layers.Conv2D ( filters = 32 , kernel_size = ( 25,25), padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_05\" )\n    model.add( layers.Flatten () )\n    model.add( layers.Dense  ( units = 32 , use_bias = True, activation = \"relu\"))#,name =\"dense_01\")\n    model.add( layers.Dense  ( units = 16 , use_bias = True, activation = \"sigmoid\") )#,name =\"dense_02\" )\n    model.add( layers.Dense  ( units = 8 , use_bias = True, activation = \"sigmoid\") )#,name =\"dense_03\" )\n    model.add( layers.Dense  ( units = 1 , use_bias = True, activation = \"sigmoid\") )#,name =\"dense_04\" )\n\n\n\n    model.compile ( optimizer= \"adam\", \n                   loss= \"binary_crossentropy\",\n                   metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\n    model.summary()","metadata":{"execution":{"iopub.status.busy":"2021-06-05T09:25:48.702496Z","iopub.execute_input":"2021-06-05T09:25:48.702824Z","iopub.status.idle":"2021-06-05T09:25:48.710686Z","shell.execute_reply.started":"2021-06-05T09:25:48.702795Z","shell.execute_reply":"2021-06-05T09:25:48.709507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n## initilisize WandB\nif DEFAULT_MODEL: ## bulding model \n    wandb_store = wandb.init( project = \"SETI_Breakthrough_Listening\",\n                            config = CONFIG,\n                            group =CONFIG[\"group\"],\n                            job_type=\"train\",\n                            name=CONFIG[\"run_name\"]\n                            )\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:20.771629Z","iopub.execute_input":"2021-05-27T13:05:20.771937Z","iopub.status.idle":"2021-05-27T13:05:20.79152Z","shell.execute_reply.started":"2021-05-27T13:05:20.771909Z","shell.execute_reply":"2021-05-27T13:05:20.790402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nif DEFAULT_MODEL: ## bulding model \n    model.fit( train_tf_dataset ,epochs = 10 , callbacks= [ WandbCallback(log_weights=True) ])\n\n    # Saving model\n\n    model_path = \"./WandB/\"+CONFIG[\"model_name\"]\n    os.makedirs(model_path,exist_ok = True )\n    model_count = len ( os.listdir( model_path )) +1\n    model.save(model_path +\"model_count\" +\".h5\" )\n\n    wandb_store.finish()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:20.792921Z","iopub.execute_input":"2021-05-27T13:05:20.793634Z","iopub.status.idle":"2021-05-27T13:05:20.806219Z","shell.execute_reply.started":"2021-05-27T13:05:20.793591Z","shell.execute_reply":"2021-05-27T13:05:20.804904Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG[\"model_name\"] = \"encoder_decoder\"\nCONFIG[\"group\"] = \"encoder_decoder\"\nCONFIG[\"run_name\"] = \"encoder_decore_structure\"","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:20.808153Z","iopub.execute_input":"2021-05-27T13:05:20.808817Z","iopub.status.idle":"2021-05-27T13:05:20.821741Z","shell.execute_reply.started":"2021-05-27T13:05:20.808774Z","shell.execute_reply":"2021-05-27T13:05:20.820512Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Auto_Encoder (tf.keras.Model ):\n    \n    def __init__(self, image_height , image_width, dimension ):\n        \n        super( Auto_Encoder, self ).__init__( )\n        self.model_input  = (  image_height, image_width, dimension )\n                             \n        self.encoder_model=  self.encoder_func()\n        \n        #self.encoder_out_put_shape = self.encoder_model.output_shape\n        self.decoder_model = self.decoder_func()\n    \n    def encoder_func(self ):\n        \n        model_input  = self.model_input #(  CONFIG[\"image_height\"], CONFIG[\"image_width\"], 3 )\n        encoder = models.Sequential()\n        encoder.add( layers.Conv2D ( filters = 128 , kernel_size = 2, padding =\"same\",strides = 2, activation = \"relu\",use_bias = True, input_shape = model_input  ) )\n        encoder.add( layers.Conv2D ( filters = 64 , kernel_size = 2, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_02\" )\n        encoder.add( layers.Conv2D ( filters = 32 , kernel_size = 2, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_03\")\n        encoder.add( layers.Conv2D ( filters = 16 , kernel_size = 2, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\n        encoder.add( layers.Conv2D ( filters = 8 , kernel_size = 2, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\n\n        return ( encoder )\n                             \n    def decoder_func ( self):\n         \n        decoder = models.Sequential() \n        decoder.add( layers.Conv2DTranspose ( filters = 8 , kernel_size = 2 , padding =\"valid\",activation = \"relu\",use_bias = True, input_shape = self.encoder_model.output_shape[1:]  ) )#, name=\"layer_04\")                    \n        decoder.add( layers.Conv2DTranspose ( filters = 16 , kernel_size = 2, padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_03\")\n        decoder.add( layers.Conv2DTranspose ( filters = 32 , kernel_size = 2, padding =\"valid\",activation = \"relu\",use_bias = True ) )#, name=\"layer_02\" )\n        decoder.add( layers.Conv2DTranspose ( filters = 64 , kernel_size = 2, padding =\"valid\",activation = \"relu\",use_bias = True) )\n        decoder.add( layers.Conv2DTranspose ( filters = 128 , kernel_size =2, padding =\"valid\",activation = \"relu\",use_bias = True) )\n        decoder.add( layers.Conv2DTranspose ( filters = 3 , kernel_size = 223, padding =\"valid\",activation = \"relu\",use_bias = True) )\n        \n        return( decoder )\n    \n    def call(self, x):\n        encoded = self.encoder_model(x)\n        decoded = self.decoder_model(encoded)\n        return decoded","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:20.823344Z","iopub.execute_input":"2021-05-27T13:05:20.823766Z","iopub.status.idle":"2021-05-27T13:05:20.840968Z","shell.execute_reply.started":"2021-05-27T13:05:20.823732Z","shell.execute_reply":"2021-05-27T13:05:20.840169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_input  =   ( CONFIG[\"image_height\"], CONFIG[\"image_width\"], 6) \nencoder = models.Sequential()\nencoder.add( layers.Conv2D ( filters = 128 , kernel_size = 2, padding =\"same\",strides = 1, activation = \"relu\",use_bias = True, input_shape = model_input  ) )\nencoder.add( layers.Conv2D ( filters = 64 , kernel_size = 3, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_02\" )\nencoder.add( layers.Conv2D ( filters = 32 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_03\")\nencoder.add( layers.Conv2D ( filters = 16 , kernel_size = 5, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\nencoder.add( layers.Conv2D ( filters = 8 , kernel_size = 6, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\n\n#decoder = models.Sequential()\nencoder.add( layers.Conv2DTranspose ( filters = 8 , kernel_size = 6 , padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")                    \nencoder.add( layers.Conv2DTranspose ( filters = 16 , kernel_size = 5, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_03\")\nencoder.add( layers.Conv2DTranspose ( filters = 32 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_02\" )\nencoder.add( layers.Conv2DTranspose ( filters = 64 , kernel_size = 3, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True) )\nencoder.add( layers.Conv2DTranspose ( filters = 128 , kernel_size =2, padding =\"same\",strides = 1,activation = \"relu\",use_bias = True) )\nencoder.add( layers.Conv2DTranspose ( filters = 6 , kernel_size = 2, padding =\"same\",strides = 1,activation = \"relu\",use_bias = True) )\n        \n\nencoder.compile ( optimizer= \"adam\", \n               loss= \"binary_crossentropy\",\n               metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\nencoder.summary()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:20.84213Z","iopub.execute_input":"2021-05-27T13:05:20.84258Z","iopub.status.idle":"2021-05-27T13:05:21.06918Z","shell.execute_reply.started":"2021-05-27T13:05:20.842534Z","shell.execute_reply":"2021-05-27T13:05:21.068154Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nmodel_input  =   ( CONFIG[\"image_height\"], CONFIG[\"image_width\"], 3 )\nencoder = models.Sequential()\nencoder.add( layers.Conv2D ( filters = 128 , kernel_size = 2, padding =\"same\",strides = 1, activation = \"relu\",use_bias = True, input_shape = model_input  ) )\nencoder.add( layers.Conv2D ( filters = 64 , kernel_size = 3, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_02\" )\nencoder.add( layers.Conv2D ( filters = 32 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_03\")\nencoder.add( layers.Conv2D ( filters = 16 , kernel_size = 5, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\nencoder.add( layers.Conv2D ( filters = 8 , kernel_size = 6, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")\n\n#decoder = models.Sequential()\nencoder.add( layers.Conv2DTranspose ( filters = 8 , kernel_size = 6 , padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_04\")                    \nencoder.add( layers.Conv2DTranspose ( filters = 16 , kernel_size = 5, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_03\")\nencoder.add( layers.Conv2DTranspose ( filters = 32 , kernel_size = 4, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True ) )#, name=\"layer_02\" )\nencoder.add( layers.Conv2DTranspose ( filters = 64 , kernel_size = 3, padding =\"same\",strides = 2,activation = \"relu\",use_bias = True) )\nencoder.add( layers.Conv2DTranspose ( filters = 128 , kernel_size =2, padding =\"same\",strides = 1,activation = \"relu\",use_bias = True) )\nencoder.add( layers.Conv2DTranspose ( filters = 3 , kernel_size = 10, padding =\"same\",strides = 1,activation = \"relu\",use_bias = True) )\n        \n\nencoder.compile ( optimizer= \"adam\", \n               loss= \"binary_crossentropy\",\n               metrics=[tf.keras.metrics.AUC(curve='ROC')])\n\nencoder.summary()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:21.071635Z","iopub.execute_input":"2021-05-27T13:05:21.072428Z","iopub.status.idle":"2021-05-27T13:05:21.080312Z","shell.execute_reply.started":"2021-05-27T13:05:21.072379Z","shell.execute_reply":"2021-05-27T13:05:21.079218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CONFIG[\"batch_size\"] = 50\ndef resize_image( df_dict ):\n    \n    [image, ] =  tf.py_function( read_numpy_data,  [ df_dict[\"path\"] ], [tf.float32] )\n    image.set_shape(( 273, 256, 3 ) )\n    image = tf.image.resize( image , ( CONFIG[\"image_height\"],  CONFIG[\"image_width\"] ) )\n    label =  df_dict[\"target\"]#.reshape((-1,1))\n    label = tf.cast( label, tf.float32 ), (-1,1) \n  \n    return  (image,image)\n            \ndef create_tf_dataset( dataframe ):\n    \n    tf_dataset = tf.data.Dataset.from_tensor_slices ( dict ( dataframe[ [\"path\",\"target\"] ] ) ) \n    tf_dataset = ( tf_dataset\n                  .shuffle (1024)\n                  .map( resize_image,num_parallel_calls= tf.data.AUTOTUNE)\n                  .batch( CONFIG[\"batch_size\"] )\n                  .prefetch(tf.data.AUTOTUNE)\n                  \n                 )\n    \n    return ( tf_dataset )\n\n            \ntrain_tf_dataset = create_tf_dataset ( train_df.head(200) )\ntest_tf_dataset = create_tf_dataset ( test_df.head(50) )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:21.08162Z","iopub.execute_input":"2021-05-27T13:05:21.081894Z","iopub.status.idle":"2021-05-27T13:05:21.213435Z","shell.execute_reply.started":"2021-05-27T13:05:21.081867Z","shell.execute_reply":"2021-05-27T13:05:21.212403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\ntrain_generator1 = train_datagen.flow_from_directory(\n        \"../input/seti-breakthrough-listen/train/\",\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode=None,\n        shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:28:21.887843Z","iopub.execute_input":"2021-05-27T13:28:21.888359Z","iopub.status.idle":"2021-05-27T13:28:22.42055Z","shell.execute_reply.started":"2021-05-27T13:28:21.888326Z","shell.execute_reply":"2021-05-27T13:28:22.4194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\nCONFIG[\"model_name\"] = \"encoder_decoder\"\nCONFIG[\"group\"] = \"encoder_decoder\"\nCONFIG[\"run_name\"] = \"encoder_decore_structure\"\n\nwandb_store = wandb.init( project = \"SETI_Breakthrough_Listening\",\n                            config = CONFIG,\n                            group =CONFIG[\"group\"],\n                            job_type=\"train\",\n                            name=CONFIG[\"run_name\"]\n                            )\n\nencoder.fit( train_generator1,train_generator1 ,epochs = 10 , callbacks= [ WandbCallback(log_weights=True) ])\n\n# Saving model\n\nmodel_path = \"./WandB/\"+CONFIG[\"model_name\"]\nos.makedirs(model_path,exist_ok = True )\nmodel_count = len ( os.listdir( model_path )) +1\nmodel.save(model_path +\"model_count\" +\".h5\" )\n\nwandb_store.finish()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:37.538523Z","iopub.execute_input":"2021-05-27T13:05:37.538908Z","iopub.status.idle":"2021-05-27T13:05:37.544882Z","shell.execute_reply.started":"2021-05-27T13:05:37.538874Z","shell.execute_reply":"2021-05-27T13:05:37.543768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import utils\n#import numpy as np","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:37.546475Z","iopub.execute_input":"2021-05-27T13:05:37.546893Z","iopub.status.idle":"2021-05-27T13:05:37.560414Z","shell.execute_reply.started":"2021-05-27T13:05:37.54686Z","shell.execute_reply":"2021-05-27T13:05:37.559089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator ( utils.Sequence) :\n    \n    def __init__ (self, data_list, batch_size, #required_channels = [1, 3, 5 ] , \n                  image_height = 224, image_width = 224, \n                  shuffle = True,num_channel = 3  ):\n        \n        self.data_list = data_list\n        self.batch_size = batch_size\n        #self.channels_required = required_channels\n        self.image_width = image_width\n        self.image_height = image_height\n        self.shuffle = True \n        self.num_channel =num_channel \n        self.is_there_left_over = False # this to check is there any left images after creating batch slices \n        \n        self.number_of_batches = 0\n        \n        \n    def on_epoch_end(self):\n        self.indices = np.arrange( len(self.data_list ))\n        \n        if self.shuffle :\n            np.random.shuffle( self.indices )\n    \n    def __len__(self ):\n        \n        number_of_batch =int ( len( self.data_list)/ self.batch_size )\n        \n        ''' below if loop to check for remaining data after slicing with respectto batch'''\n        if number_of_batch * self.batch_size !=len( self.data_list):\n            number_of_batch = number_of_batch +1\n            self.is_there_left_over = True\n        \n        self.number_of_batches = number_of_batch\n        \n        return ( number_of_batch  )\n    \n    def __getitem__(self, idx = 0  ):\n        \n        x = np.empty( ( self.batch_size, self.image, self.num_channel ) )\n        \n        if self.is_there_left_over & (idx == (self.number_of_batches - 1 ) ) :\n            \n            indices = self.indices [ idx * self.batch_size :  ]\n            \n        else:\n            \n            indices = self.indices [ idx * self.batch_size : ( idx +1 )* self.batch_size ]\n        \n        for i, path in enumerate ( indices):\n            x[i] = self.read_image( path )\n        \n        return x \n            \n    def read_image ( self, path ):\n        \n        file_name=file_name_result\n        data = np.load( path ).astype( np.float32 )    \n        data = np.dstack( ( data[0], data[2], data[4] ) )\n        \n        return ( data )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:37.562113Z","iopub.execute_input":"2021-05-27T13:05:37.562565Z","iopub.status.idle":"2021-05-27T13:05:37.582234Z","shell.execute_reply.started":"2021-05-27T13:05:37.562521Z","shell.execute_reply":"2021-05-27T13:05:37.581216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:37.583456Z","iopub.execute_input":"2021-05-27T13:05:37.583752Z","iopub.status.idle":"2021-05-27T13:05:37.601192Z","shell.execute_reply.started":"2021-05-27T13:05:37.583725Z","shell.execute_reply":"2021-05-27T13:05:37.600084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_stack_image (  path ):\n        \n        file_name=file_name_result\n        data = np.load( path ).astype( np.float32 )    \n        data = np.dstack( ( data[0], data[2], data[4] ) )\n        \n        return ( data )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:37.605046Z","iopub.execute_input":"2021-05-27T13:05:37.605416Z","iopub.status.idle":"2021-05-27T13:05:37.616446Z","shell.execute_reply.started":"2021-05-27T13:05:37.605383Z","shell.execute_reply":"2021-05-27T13:05:37.615301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_gen = ImageDataGenerator( preprocessing_function =  read_stack_image )\ntrain_x = data_gen.flow_from_directory ( \"../input/seti-breakthrough-listen/train/\", target_size = ( 224,224), \n                                         batch_size = 20, #color_mode =\"rgb\",\n                                        shuffle = True, classes =[\"test\"],\n                                       )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:32:31.550247Z","iopub.execute_input":"2021-05-27T13:32:31.550649Z","iopub.status.idle":"2021-05-27T13:32:31.65904Z","shell.execute_reply.started":"2021-05-27T13:32:31.550615Z","shell.execute_reply":"2021-05-27T13:32:31.658257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x.next()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:39.040798Z","iopub.execute_input":"2021-05-27T13:05:39.041121Z","iopub.status.idle":"2021-05-27T13:05:39.04623Z","shell.execute_reply.started":"2021-05-27T13:05:39.041082Z","shell.execute_reply":"2021-05-27T13:05:39.045565Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_x = DataGenerator( data_list = train_df[\"path\"], batch_size = 20 )\ntest_x = DataGenerator( data_list = test_df[\"path\"], batch_size = 20 )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:39.047233Z","iopub.execute_input":"2021-05-27T13:05:39.04769Z","iopub.status.idle":"2021-05-27T13:05:39.060211Z","shell.execute_reply.started":"2021-05-27T13:05:39.047647Z","shell.execute_reply":"2021-05-27T13:05:39.059254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\n\nCONFIG[\"model_name\"] = \"encoder_decoder\"\nCONFIG[\"group\"] = \"encoder_decoder\"\nCONFIG[\"run_name\"] = \"encoder_decore_structure\"\n\nwandb_store = wandb.init( project = \"SETI_Breakthrough_Listening\",\n                            config = CONFIG,\n                            group =CONFIG[\"group\"],\n                            job_type=\"train\",\n                            name=CONFIG[\"run_name\"]\n                            )\n\nencoder.fit( train_x ,epochs = 10 , callbacks= [ WandbCallback(log_weights=True) ])\n\n# Saving model\n\nmodel_path = \"./WandB/\"+CONFIG[\"model_name\"]\nos.makedirs(model_path,exist_ok = True )\nmodel_count = len ( os.listdir( model_path )) +1\nmodel.save(model_path +\"model_count\" +\".h5\" )\n\nwandb_store.finish()\n'''","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:05:39.061921Z","iopub.execute_input":"2021-05-27T13:05:39.062545Z","iopub.status.idle":"2021-05-27T13:05:39.074692Z","shell.execute_reply.started":"2021-05-27T13:05:39.062487Z","shell.execute_reply":"2021-05-27T13:05:39.073896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train_df[\"path\"]\nimport tensorflow as tf","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:08:07.364154Z","iopub.execute_input":"2021-05-27T13:08:07.364562Z","iopub.status.idle":"2021-05-27T13:08:07.368368Z","shell.execute_reply.started":"2021-05-27T13:08:07.364525Z","shell.execute_reply":"2021-05-27T13:08:07.367451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"AUTO = tf.data.experimental.AUTOTUNE\ntrain_dataset = tf.data.TFRecordDataset ( list (train_df[\"path\"] ), num_parallel_reads= AUTO )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:39:47.507397Z","iopub.execute_input":"2021-05-27T13:39:47.507802Z","iopub.status.idle":"2021-05-27T13:39:47.561593Z","shell.execute_reply.started":"2021-05-27T13:39:47.507772Z","shell.execute_reply":"2021-05-27T13:39:47.560787Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list ( train_df[\"path\"] )[:10]","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:40:14.238157Z","iopub.execute_input":"2021-05-27T13:40:14.238763Z","iopub.status.idle":"2021-05-27T13:40:14.255559Z","shell.execute_reply.started":"2021-05-27T13:40:14.23871Z","shell.execute_reply":"2021-05-27T13:40:14.254462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_stack_image (  path ):\n        \n        #file_name=file_name_result\n        #data = np.load( path ).astype( np.float32 )    \n        #data = np.dstack( ( data[0], data[2], data[4] ) )\n        \n        return ( []  )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:36:54.261206Z","iopub.execute_input":"2021-05-27T13:36:54.263337Z","iopub.status.idle":"2021-05-27T13:36:54.267165Z","shell.execute_reply.started":"2021-05-27T13:36:54.263297Z","shell.execute_reply":"2021-05-27T13:36:54.266207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for raw_record in train_dataset.take(10):\n  print(repr(raw_record))","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:41:03.645412Z","iopub.execute_input":"2021-05-27T13:41:03.645774Z","iopub.status.idle":"2021-05-27T13:41:03.823664Z","shell.execute_reply.started":"2021-05-27T13:41:03.645745Z","shell.execute_reply":"2021-05-27T13:41:03.822106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_dataset.map( read_stack_image, num_parallel_calls= AUTO )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:36:56.011498Z","iopub.execute_input":"2021-05-27T13:36:56.011904Z","iopub.status.idle":"2021-05-27T13:36:56.095759Z","shell.execute_reply.started":"2021-05-27T13:36:56.011873Z","shell.execute_reply":"2021-05-27T13:36:56.093423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.preprocessing.image import ImageDataGenerator\n\n\n\ntrain_datagen = ImageDataGenerator()","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:26:45.526955Z","iopub.execute_input":"2021-05-27T13:26:45.527311Z","iopub.status.idle":"2021-05-27T13:26:45.531962Z","shell.execute_reply.started":"2021-05-27T13:26:45.527274Z","shell.execute_reply":"2021-05-27T13:26:45.530989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_datagen.flow_from_directory( \"../input/seti-breakthrough-listen/train/\",  )","metadata":{"execution":{"iopub.status.busy":"2021-05-27T13:26:53.28954Z","iopub.execute_input":"2021-05-27T13:26:53.289946Z","iopub.status.idle":"2021-05-27T13:26:53.29945Z","shell.execute_reply.started":"2021-05-27T13:26:53.289914Z","shell.execute_reply":"2021-05-27T13:26:53.298583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tf.keras.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class DataGenerator ( utils.Sequence) :\n    \n    def __init__ (self, data_list, batch_size, #required_channels = [1, 3, 5 ] , \n                  image_height = 224, image_width = 224, \n                  shuffle = True,num_channel = 3  ):\n        \n        self.data_list = data_list\n        self.batch_size = batch_size\n        #self.channels_required = required_channels\n        self.image_width = image_width\n        self.image_height = image_height\n        self.shuffle = True \n        self.num_channel =num_channel \n        self.is_there_left_over = False # this to check is there any left images after creating batch slices \n        \n        self.number_of_batches = 0\n        \n        \n    def on_epoch_end(self):\n        self.indices = np.arrange( len(self.data_list ))\n        \n        if self.shuffle :\n            np.random.shuffle( self.indices )\n    \n    def __len__(self ):\n        \n        number_of_batch =int ( len( self.data_list)/ self.batch_size )\n        \n        ''' below if loop to check for remaining data after slicing with respectto batch'''\n        if number_of_batch * self.batch_size !=len( self.data_list):\n            number_of_batch = number_of_batch +1\n            self.is_there_left_over = True\n        \n        self.number_of_batches = number_of_batch\n        \n        return ( number_of_batch  )\n    \n    def __getitem__(self, idx = 0  ):\n        \n        x = np.empty( ( self.batch_size, self.image, self.num_channel ) )\n        \n        if self.is_there_left_over & (idx == (self.number_of_batches - 1 ) ) :\n            \n            indices = self.indices [ idx * self.batch_size :  ]\n            \n        else:\n            \n            indices = self.indices [ idx * self.batch_size : ( idx +1 )* self.batch_size ]\n        \n        for i, path in enumerate ( indices):\n            x[i] = self.read_image( path )\n        \n        return x \n            \n    def read_image ( self, path ):\n        \n        file_name=file_name_result\n        data = np.load( path ).astype( np.float32 )    \n        data = np.dstack( ( data[0], data[2], data[4] ) )\n        \n        return ( data )","metadata":{},"execution_count":null,"outputs":[]}]}