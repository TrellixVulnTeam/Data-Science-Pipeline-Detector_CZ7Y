{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import cv2\nimport os\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nimport codecs\nfrom tqdm import tqdm","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:13.878696Z","iopub.execute_input":"2021-06-16T07:29:13.879129Z","iopub.status.idle":"2021-06-16T07:29:14.723682Z","shell.execute_reply.started":"2021-06-16T07:29:13.87909Z","shell.execute_reply":"2021-06-16T07:29:14.722835Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_labels = pd.read_csv(\"../input/seti-breakthrough-listen/train_labels.csv\")\ntrain_labels.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:14.725132Z","iopub.execute_input":"2021-06-16T07:29:14.725467Z","iopub.status.idle":"2021-06-16T07:29:14.782593Z","shell.execute_reply.started":"2021-06-16T07:29:14.725433Z","shell.execute_reply":"2021-06-16T07:29:14.781841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ddt = train_labels[\"target\"].value_counts().to_frame()\nfig, ax = plt.subplots(1,1,figsize=(12,4))\nsns.countplot(data = train_labels, x = \"target\", orient = \"v\", palette = \"pastel\", ax=ax)\nplt.suptitle(\"Train target distribution\")","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:14.784363Z","iopub.execute_input":"2021-06-16T07:29:14.78472Z","iopub.status.idle":"2021-06-16T07:29:14.912296Z","shell.execute_reply.started":"2021-06-16T07:29:14.784682Z","shell.execute_reply":"2021-06-16T07:29:14.911413Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # Train set","metadata":{}},{"cell_type":"code","source":"train_files = glob.glob(\"../input/seti-breakthrough-listen/train\" + \"/*/*.npy\")\nprint(\"Number of train files:{}\".format(len(train_files)))","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:14.913931Z","iopub.execute_input":"2021-06-16T07:29:14.914274Z","iopub.status.idle":"2021-06-16T07:29:16.3969Z","shell.execute_reply.started":"2021-06-16T07:29:14.914239Z","shell.execute_reply":"2021-06-16T07:29:16.395808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"># Test set","metadata":{}},{"cell_type":"code","source":"test_files = glob.glob(\"../input/seti-breakthrough-listen/test\" + \"/*/*.npy\")\nprint(\"Number of test files:{}\".format(len(test_files)))","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:16.401108Z","iopub.execute_input":"2021-06-16T07:29:16.401476Z","iopub.status.idle":"2021-06-16T07:29:18.016014Z","shell.execute_reply.started":"2021-06-16T07:29:16.401438Z","shell.execute_reply":"2021-06-16T07:29:18.015089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_train_filename_by_id(_id: str) -> str:\n    return f\"../input/seti-breakthrough-listen/train/{_id[0]}/{_id}.npy\"\n\ndef show_cadence(filename: str, label: int) -> None:\n    fig, axes = plt.subplots(6, 1, figsize = (16, 10))\n    ax = axes.ravel()\n    arr = np.load(filename)\n    for i in range(6):\n        \n        ax[i].imshow(arr[i].astype(float), interpolation='nearest', aspect='auto')\n        ax[i].text(5, 100, [\"ON\", \"OFF\"][i % 2], bbox={'facecolor': 'white'})\n        if i != 5:\n            ax[i].set_xticks([])\n            \n    fig.text(0.5, -0.02, 'Frequency Range', ha='center', fontsize=18)\n    fig.text(-0.02, 0.5, 'Seconds', va='center', rotation='vertical', fontsize=18)\n\n    plt.suptitle(f\"ID: {os.path.basename(filename)} TARGET: {label}\", fontsize=18)\n    fig.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:18.017242Z","iopub.execute_input":"2021-06-16T07:29:18.017634Z","iopub.status.idle":"2021-06-16T07:29:18.028215Z","shell.execute_reply.started":"2021-06-16T07:29:18.017593Z","shell.execute_reply":"2021-06-16T07:29:18.027372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_target=train_labels.query(\"target==1\").sample().id.item()\nnegative_target=train_labels.query(\"target==0\").sample().id.item()\nshow_cadence(get_train_filename_by_id(positive_target), 1)\nshow_cadence(get_train_filename_by_id(negative_target), 0)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:18.029625Z","iopub.execute_input":"2021-06-16T07:29:18.030132Z","iopub.status.idle":"2021-06-16T07:29:19.469589Z","shell.execute_reply.started":"2021-06-16T07:29:18.030089Z","shell.execute_reply":"2021-06-16T07:29:19.46423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install efficientnet_pytorch","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:19.472226Z","iopub.execute_input":"2021-06-16T07:29:19.472599Z","iopub.status.idle":"2021-06-16T07:29:28.403921Z","shell.execute_reply.started":"2021-06-16T07:29:19.472563Z","shell.execute_reply":"2021-06-16T07:29:28.402999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport random\nimport sys\nfrom sklearn.metrics import roc_auc_score \nfrom sklearn.model_selection import StratifiedKFold\nfrom efficientnet_pytorch import model as enet\nfrom torch.utils.data import Dataset, DataLoader","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:28.406088Z","iopub.execute_input":"2021-06-16T07:29:28.406375Z","iopub.status.idle":"2021-06-16T07:29:29.810804Z","shell.execute_reply.started":"2021-06-16T07:29:28.406336Z","shell.execute_reply":"2021-06-16T07:29:29.809968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nrandom_state = set_seed(2020)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:29.812001Z","iopub.execute_input":"2021-06-16T07:29:29.812321Z","iopub.status.idle":"2021-06-16T07:29:29.821007Z","shell.execute_reply.started":"2021-06-16T07:29:29.812287Z","shell.execute_reply":"2021-06-16T07:29:29.820279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nDEVICE","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:29.822537Z","iopub.execute_input":"2021-06-16T07:29:29.823312Z","iopub.status.idle":"2021-06-16T07:29:29.873229Z","shell.execute_reply.started":"2021-06-16T07:29:29.823275Z","shell.execute_reply":"2021-06-16T07:29:29.872365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # DATASET","metadata":{}},{"cell_type":"code","source":"sample_train_id = train_labels.query(\"target==1\").sample().id.item()\nsample = np.load(f\"../input/seti-breakthrough-listen/train/{sample_train_id[0]}/{sample_train_id}.npy\")\nsample.shape\nnp.array([np.abs(sample).max() for i in range(sample.shape[0])]).reshape(sample.shape[0],1,1)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:29.874519Z","iopub.execute_input":"2021-06-16T07:29:29.874908Z","iopub.status.idle":"2021-06-16T07:29:29.966818Z","shell.execute_reply.started":"2021-06-16T07:29:29.874869Z","shell.execute_reply":"2021-06-16T07:29:29.966124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import albumentations as A\nttransform = A.Compose([\n    A.ShiftScaleRotate(p=0.8, shift_limit_x=(-0.2, 0.2), shift_limit_y=(-0.2, 0.2), scale_limit=(-0.20, 0.20), rotate_limit=(-20, 20), interpolation=1, border_mode=0, value=0, mask_value=0)\n#     A.RandomResizedCrop(p=1.0, height=320, width=320, scale=(0.9, 1.0), ratio=(0.75, 1.3333333333333333), interpolation=1)\n])\n\nclass ETDataSet(Dataset):\n    def __init__(self, image_paths, targets):\n        self.image_paths = image_paths\n        self.targets = targets\n        \n    def __len__(self):\n        return len(self.targets)\n    \n    def __getitem__(self, item):\n        image = np.load(self.image_paths[item]).astype(np.float32)\n        image = np.vstack(image).transpose((1,0)).astype(np.float32)[np.newaxis,]\n#         image = ttransform(image = image)[\"image\"]\n        targets = self.targets[item]\n#         image = image / np.array([np.abs(image).max() for i in range(6)]).reshape(6,1,1)\n        \n        return torch.tensor(image,dtype=torch.float), torch.tensor(targets,dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:29.967989Z","iopub.execute_input":"2021-06-16T07:29:29.968381Z","iopub.status.idle":"2021-06-16T07:29:31.061963Z","shell.execute_reply.started":"2021-06-16T07:29:29.968324Z","shell.execute_reply":"2021-06-16T07:29:31.061143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/seti-breakthrough-listen/train_labels.csv\")\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.063167Z","iopub.execute_input":"2021-06-16T07:29:31.063517Z","iopub.status.idle":"2021-06-16T07:29:31.096655Z","shell.execute_reply.started":"2021-06-16T07:29:31.06348Z","shell.execute_reply":"2021-06-16T07:29:31.095707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train[\"image_path\"] = df_train[\"id\"].apply(lambda x:f\"../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy\")\ndf_train.head(5)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.097945Z","iopub.execute_input":"2021-06-16T07:29:31.098297Z","iopub.status.idle":"2021-06-16T07:29:31.131719Z","shell.execute_reply.started":"2021-06-16T07:29:31.098262Z","shell.execute_reply":"2021-06-16T07:29:31.130615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df_train_pos = df_train[df_train[\"target\"] == 1]\n# df_train_pos_arr = []\n# for i in range(df_train_pos.shape[0]):\n#     df_train_pos_arr.append(np.load(df_train_pos[\"image_path\"].iloc[i]))\n# df_train_pos_arr = np.array(df_train_pos_arr)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.133175Z","iopub.execute_input":"2021-06-16T07:29:31.133525Z","iopub.status.idle":"2021-06-16T07:29:31.137763Z","shell.execute_reply.started":"2021-06-16T07:29:31.13349Z","shell.execute_reply":"2021-06-16T07:29:31.136387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import os\n# diff = df_train[df_train[\"target\"] == 0].shape[0] - df_train_pos.shape[0]\n\n# savePath = \"./new_pos\"\n# if not os.path.exists(savePath):\n#     os.makedirs(savePath)\n\n# total_index = df_train.shape[0]\n# for i in range(diff//5):\n#     index = np.random.choice(df_train_pos_arr.shape[0], 5)\n#     new_pos = (df_train_pos_arr[index] * 1/5).sum(axis = 0)\n#     new_file_path = f\"{savePath}/{i}.npy\"\n#     np.save(new_file_path,new_pos)\n#     df_train.loc[total_index + i] = [\"1\",1,new_file_path]","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.139239Z","iopub.execute_input":"2021-06-16T07:29:31.139693Z","iopub.status.idle":"2021-06-16T07:29:31.147868Z","shell.execute_reply.started":"2021-06-16T07:29:31.139657Z","shell.execute_reply":"2021-06-16T07:29:31.147036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"># focal loss","metadata":{}},{"cell_type":"code","source":"class FocalLoss(nn.Module):\n    def __init__(self, gamma = 2, alpha = 0.2, reduction = \"mean\"):\n        super(FocalLoss, self).__init__()\n        self.gamma = gamma\n        self.alpha = alpha\n        self.reduction = reduction\n#         self.criterion = nn.BCEWithLogitsLoss(reduction = \"none\")\n        \n    \n    def forward(self, preds, targets):\n        targets = targets.reshape(-1,1)\n        \n        pt = torch.sigmoid(preds)\n        loss =  - self.alpha * (1 - pt) ** self.gamma * targets * torch.log(pt) - (1 - self.alpha) *  pt ** self.gamma * (1 - targets) * torch.log(1 - pt)\n#         loss = self.criterion(preds, targets) * weights\n        \n        if self.reduction == \"mean\":\n            loss = torch.mean(loss)\n        else:\n            loss = torch.sum(loss)\n        return loss","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.149235Z","iopub.execute_input":"2021-06-16T07:29:31.149759Z","iopub.status.idle":"2021-06-16T07:29:31.158728Z","shell.execute_reply.started":"2021-06-16T07:29:31.149717Z","shell.execute_reply":"2021-06-16T07:29:31.157992Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"># Mixup Data","metadata":{}},{"cell_type":"code","source":"def mixup_data(x, y, alpha=1.0, use_cuda=True):\n    \"Returns mixed inputs, pairs of targets and lambda\"\n    if alpha > 0:\n        lam = np.random.beta(alpha, alpha)\n    else:\n        lam = 1\n    \n    batch_size = x.size()[0]\n    \n    if use_cuda:\n        index = torch.randperm(batch_size).cuda()\n    else:\n        index = torch.randperm(batch_size)\n        \n    mixed_x = lam  * x + (1-lam) * x[index,:]\n    y, y_shuffle = y, y[index]\n    return mixed_x, y, y_shuffle, lam\n\ndef mixup_criterion(criterion, pred, y, y_shuffle, lam):\n    y = y.view(-1,1)\n    y_shuffle = y_shuffle.view(-1,1)\n    loss = lam * criterion(pred, y) + (1 - lam) * criterion(pred, y_shuffle)\n    return loss.mean()","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.159792Z","iopub.execute_input":"2021-06-16T07:29:31.160256Z","iopub.status.idle":"2021-06-16T07:29:31.172311Z","shell.execute_reply.started":"2021-06-16T07:29:31.16022Z","shell.execute_reply":"2021-06-16T07:29:31.171477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"># BackBone","metadata":{}},{"cell_type":"code","source":"class backbone(nn.Module):\n    def __init__(self, pretrain, out_dim):\n        super(backbone, self).__init__()\n        self.enet = enet.EfficientNet.from_pretrained(pretrain)\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity()\n        self.conv = nn.Conv2d(1, 3, kernel_size = 3, padding = 3, bias = False)\n        \n    def forward(self, x):\n        x = self.conv(x)\n        x = self.enet(x)\n        x = self.myfc(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.173534Z","iopub.execute_input":"2021-06-16T07:29:31.173971Z","iopub.status.idle":"2021-06-16T07:29:31.18287Z","shell.execute_reply.started":"2021-06-16T07:29:31.173937Z","shell.execute_reply":"2021-06-16T07:29:31.181991Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"># Criterion and train","metadata":{}},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss()\n# criterion = FocalLoss()\n\ndef train(train_loader, val_loader, model, optimizer, device, fold_idx, epoch, scheduler):\n    model.train()\n    with codecs.open('log.out','a') as f:\n        f.write(\"\\n\\n\")\n    best_roc_auc  = 0\n    check_point = 1\n    loss = -1\n\n    for epoch_idx in range(epoch):\n        \n        \n        process_bar = tqdm(train_loader, position=0, leave=True, desc=\"Training\")\n        for datas,labels in process_bar:\n            datas = datas.to(device).float()\n            labels = labels.to(device).float()\n            \n            optimizer.zero_grad()\n\n            if np.random.randint(1, 10) >= 5:\n                mixed_x, y, y_shuffle, lam = mixup_data(datas, labels,use_cuda = True)\n                \n                outputs = model(mixed_x)\n                loss_now = mixup_criterion(criterion, outputs, y, y_shuffle, lam)\n                \n            else:\n                outputs = model(datas)\n                loss_now = criterion(outputs, labels.reshape(-1,1))\n            \n \n            \n            if loss == -1:\n                loss = loss_now.data.item()\n            else:\n                loss = 0.9 * loss + 0.1 * loss_now.data.item()\n            \n            process_bar.set_postfix(loss = loss)\n            process_bar.update()\n            \n            loss_now.backward()\n            optimizer.step()\n            scheduler.step()\n\n\n        preds, valid_targets = evaluate(val_loader, model, device=DEVICE)\n        roc_auc = roc_auc_score(valid_targets, preds)\n        print(f\"valid auc is:{roc_auc}\")\n\n        with codecs.open(\"log.out\",\"a\") as f:\n            f.write(f\"Fold{fold_idx}, Epoch={epoch_idx}, Check_point={check_point}, Valid_ROC_AUC={roc_auc}\\n\")\n\n        if roc_auc > best_roc_auc:\n            torch.save(model.state_dict(), \"./efnet-\" + str(fold_idx) + \".pth\")\n            best_roc_auc = roc_auc\n\n            \ndef evaluate(data_loader, model, device):\n    model.eval()\n    total_labels = []\n    total_outputs = []\n    \n    with torch.no_grad():\n        for datas, labels in tqdm(data_loader, position=0, leave=True, desc=\"Evaluating\"):\n            datas = datas.to(device).float()\n\n            outputs = model(datas)\n            outputs = outputs.detach().cpu().numpy().tolist()\n            labels = labels.detach().cpu().numpy().tolist()\n\n            total_labels.extend(labels)\n            total_outputs.extend(outputs)\n    \n    return total_outputs, total_labels","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.184019Z","iopub.execute_input":"2021-06-16T07:29:31.18452Z","iopub.status.idle":"2021-06-16T07:29:31.199722Z","shell.execute_reply.started":"2021-06-16T07:29:31.184484Z","shell.execute_reply":"2021-06-16T07:29:31.198915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"backbone_name = \"efficientnet-b0\"\n\nepochs = 4\nbatch_size = 16","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:31.200834Z","iopub.execute_input":"2021-06-16T07:29:31.201282Z","iopub.status.idle":"2021-06-16T07:29:31.21363Z","shell.execute_reply.started":"2021-06-16T07:29:31.201245Z","shell.execute_reply":"2021-06-16T07:29:31.212752Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df_train.image_path.values\nY = df_train.target.values\nprint(X)\nprint(Y)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:38.946221Z","iopub.execute_input":"2021-06-16T07:29:38.946578Z","iopub.status.idle":"2021-06-16T07:29:38.955646Z","shell.execute_reply.started":"2021-06-16T07:29:38.94655Z","shell.execute_reply":"2021-06-16T07:29:38.954697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits = 5)\nfold = 0\n\nfor train_idx, val_idx in skf.split(X,Y):\n    model = backbone(backbone_name, out_dim=1)\n    model.to(DEVICE)\n    model = nn.DataParallel(model)\n    \n    train_images, valid_images = X[train_idx], X[val_idx]\n    train_targets, valid_targets = Y[train_idx], Y[val_idx]\n    \n    train_dataset = ETDataSet(image_paths = train_images, targets = train_targets)\n    valid_dataset = ETDataSet(image_paths = valid_images, targets = valid_targets)\n    \n    train_loader = DataLoader(dataset = train_dataset,\n                             batch_size = batch_size,\n                             shuffle = True,\n                             num_workers=3)\n    valid_loader = DataLoader(dataset = valid_dataset,\n                             batch_size = batch_size,\n                             shuffle = False,\n                             num_workers=3)\n    optimizer = torch.optim.Adam(model.parameters(), lr = 1e-4)\n    scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.0001, max_lr=5e-5, gamma=0.9, cycle_momentum=False,\n                                                  step_size_up=1400,step_size_down=1400, mode=\"triangular2\")\n    if fold in [0,1,2]:\n        pass\n    else:\n        train(train_loader, valid_loader, model, optimizer, DEVICE, fold, epochs, scheduler)\n    \n    fold += 1\n    print(\"\")","metadata":{"execution":{"iopub.status.busy":"2021-06-16T02:44:32.99056Z","iopub.execute_input":"2021-06-16T02:44:32.99113Z","iopub.status.idle":"2021-06-16T06:46:33.072994Z","shell.execute_reply.started":"2021-06-16T02:44:32.991093Z","shell.execute_reply":"2021-06-16T06:46:33.069648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nsubmission = pd.read_csv(\"../input/seti-breakthrough-listen/sample_submission.csv\")\nsubmission[\"img_path\"] = submission[\"id\"].apply(lambda x:f\"../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy\")\n\ntest_dataset = ETDataSet(image_paths = submission.img_path.values, targets = submission.target.values)\ntest_loader = DataLoader(dataset = test_dataset,\n                        batch_size = 32,\n                        shuffle = False,\n                        num_workers = 1)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:29:45.180267Z","iopub.execute_input":"2021-06-16T07:29:45.180626Z","iopub.status.idle":"2021-06-16T07:29:45.230397Z","shell.execute_reply.started":"2021-06-16T07:29:45.180595Z","shell.execute_reply":"2021-06-16T07:29:45.229584Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nfor path in glob.glob(\"../input/et-model-pth/efnet-*\"):\n    model = backbone(backbone_name, out_dim = 1)\n    model.to(DEVICE)\n    model = nn.DataParallel(model)\n    print(path)\n    model.load_state_dict(torch.load(path))\n    models.append(model)\n    \nsigmoid = torch.nn.Sigmoid()\nouts = []\nfor model in models:\n    predictions, valid_targets = evaluate(test_loader,model, DEVICE)\n    predictions = np.array(predictions)[:,0]\n    out = sigmoid(torch.from_numpy(predictions))\n    out = out.detach().numpy()\n    outs.append(out)\n\npred = np.mean(np.array(outs), axis=0)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T07:30:53.173141Z","iopub.execute_input":"2021-06-16T07:30:53.17348Z","iopub.status.idle":"2021-06-16T08:23:23.619214Z","shell.execute_reply.started":"2021-06-16T07:30:53.173447Z","shell.execute_reply":"2021-06-16T08:23:23.617367Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.target = pred\nsubmission.drop([\"img_path\"], axis=1 ,inplace = True)\nsubmission.to_csv('./submission.csv', index = False)","metadata":{"execution":{"iopub.status.busy":"2021-06-16T08:30:57.978862Z","iopub.execute_input":"2021-06-16T08:30:57.979237Z","iopub.status.idle":"2021-06-16T08:30:58.922433Z","shell.execute_reply.started":"2021-06-16T08:30:57.979197Z","shell.execute_reply":"2021-06-16T08:30:58.921546Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}