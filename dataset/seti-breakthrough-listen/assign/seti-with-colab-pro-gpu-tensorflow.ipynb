{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. you must setting with high-memory mode (25GB)\n## 2. if you use GPU, you must use colab PRO\n## 3. before unzip, do not store over 5.1GB data\n## 4. upload your API kaggle.json  on  default folder (content/) \n> #### maybe, you have to launch once more(?)\n## after preprocessing, you can freely restart you session.\n## actually numpy memmap reading is \"very\" slow(250s reading one cycle of train dataset).\n> #### So most of time with small model, P100 and V100 have small difference.\n> #### but, use V100 if you can\n\n### download ~ 15min\n### unzip & processing ~ 1.1 hour\n### output shape = (None, 3, 273, 256)\n> ### if you want to use as (None, 273, 256, 3), \n> > ### than use tf.keras.layers.Permute((2,3,1))\n## if you restart, do not change validation_rate","metadata":{}},{"cell_type":"code","source":"!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2021-05-29T03:17:14.364157Z","iopub.execute_input":"2021-05-29T03:17:14.364785Z","iopub.status.idle":"2021-05-29T03:17:15.106578Z","shell.execute_reply.started":"2021-05-29T03:17:14.364738Z","shell.execute_reply":"2021-05-29T03:17:15.104884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom matplotlib import pyplot as plt\nimport tensorflow as tf\nimport keras\nimport keras.layers as L\nimport math, random\nfrom tensorflow.keras.utils import Sequence\nfrom tensorflow.keras.preprocessing import image\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split\nimport plotly.express as px\nimport seaborn as sns\nimport os, gc, time\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        # 프로그램 시작시에 메모리 증가가 설정되어야만 합니다\n        print(e)\n!pip install -q -U tensorflow-addons\nimport tensorflow_addons as tfa\n\nfrom tensorflow.keras.mixed_precision import experimental as mixed_precision#!\npolicy = mixed_precision.Policy('mixed_float16')#!\nmixed_precision.set_policy(policy)#!\n\nrandom.seed(0)\nnp.random.seed(0)\ntf.random.set_seed(0)","metadata":{"id":"uJD6PHenv1uh","outputId":"68bf8652-470c-497c-8a07-65ec38f9a723","execution":{"iopub.status.busy":"2021-05-29T03:17:15.110674Z","iopub.execute_input":"2021-05-29T03:17:15.111203Z","iopub.status.idle":"2021-05-29T03:17:22.05261Z","shell.execute_reply.started":"2021-05-29T03:17:15.111139Z","shell.execute_reply":"2021-05-29T03:17:22.051248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n# preprocessing","metadata":{}},{"cell_type":"code","source":"def id_to_path(idxs,train=True):\n    for idx in idxs:\n        path = ''\n        if train:\n            folder = 'train/'\n        else:\n            folder = 'test/'\n        path+=folder+idx[0]+'/'+idx+'.npy'\n        if os.path.exists(path): yield path\ndef as_numpy_dataset(idxs, is_train):\n  loading = [np.load(path, mmap_mode = 'r') for path in id_to_path(idxs, is_train)]\n  print(loading[0].dtype, loading[0].shape )\n  loading = [I[::2] for I in loading]\n  tmp_result = np.asarray(loading)\n  print(tmp_result.dtype)\n  if tmp_result.dtype == np.float16: return tmp_result\n  return tmp_result.astype(np.float16)","metadata":{"id":"_R2Rx2cdumgH","execution":{"iopub.status.busy":"2021-05-29T03:17:35.783592Z","iopub.execute_input":"2021-05-29T03:17:35.783966Z","iopub.status.idle":"2021-05-29T03:17:35.792232Z","shell.execute_reply.started":"2021-05-29T03:17:35.783925Z","shell.execute_reply":"2021-05-29T03:17:35.791216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"validation_rate = 0.118 # do not change after build dataset \ntry:\n  sample_submission = pd.read_csv('sample_submission.csv')\n  test_idx = sample_submission['id'].values\n  tests_DT = np.memmap('test_mmap', dtype = 'float16', mode = 'r', shape = (len(test_idx), 3, 273, 256) )\nexcept:\n  !sudo mv kaggle.json  ../root/.kaggle/kaggle.json \n  !pip install --upgrade --force-reinstall --no-deps kaggle\n  !kaggle competitions download -c seti-breakthrough-listen\n  \n  !unzip seti-breakthrough-listen.zip  -x train/*\n  sample_submission = pd.read_csv('sample_submission.csv')\n  test_idx = sample_submission['id'].values\n  tmp_DT = as_numpy_dataset(test_idx, is_train  = False)\n  tests_DT = np.memmap('test_mmap', dtype = tmp_DT.dtype, mode = 'w+', shape = tmp_DT.shape)\n  tests_DT[:] = tmp_DT[:]\n  tests_DT.flush()\n  del tmp_DT\n  !sudo rm -r test\n  \ntry:\n  train_labels =pd.read_csv('train_labels.csv')\n  train_idx =  train_labels['id'].values\n  y = train_labels['target'].values\n  x_train,x_valid, y_train,y_valid = train_test_split(train_idx,y,test_size=validation_rate,random_state=42)\n  x_train, y_train = [np.asarray(I) for I in zip(*sorted(list(zip(x_train, y_train))))]\n  x_valid, y_valid = [np.asarray(I) for I in zip(*sorted(list(zip(x_valid, y_valid))))]\n\n  valid_DT = np.memmap('valid_mmap', dtype = 'float16', mode = 'r', shape = (y_valid.shape[0], 3, 273, 256))\n  valid_DT = valid_DT, y_valid\n\n  train_DT = np.memmap('train_mmap', dtype = 'float16', mode = 'r', shape = (y_train.shape[0], 3, 273, 256))\n  #train_DT = np.array(train_DT), y_train\n  train_DT = train_DT, y_train\nexcept:\n  #train_idx가 정렬되어있기 때문에 분리처리후 병합\n  !sudo rm -r train\n  train_labels = pd.read_csv('train_labels.csv')\n  train_idx =  train_labels['id'].values\n  y = train_labels['target'].values\n  x_train,x_valid, y_train,y_valid = train_test_split(train_idx,y,test_size=validation_rate,random_state=42)\n  x_train, y_train = [np.asarray(I) for I in zip(*sorted(list(zip(x_train, y_train))))]\n  x_valid, y_valid = [np.asarray(I) for I in zip(*sorted(list(zip(x_valid, y_valid))))]\n  \n\n  !unzip seti-breakthrough-listen.zip train/[0-9]/*\n  tmp_train_DT = as_numpy_dataset(x_train, is_train  = True)\n\n  gc.collect();time.sleep(5)\n  valid_DT = as_numpy_dataset(x_valid, is_train  = True)\n  !sudo rm -r train \n\n\n\n  !unzip seti-breakthrough-listen.zip train/[^0-9]/*\n  !sudo rm seti-breakthrough-listen.zip\n\n  tmp_DT = np.concatenate([valid_DT, as_numpy_dataset(x_valid, is_train  = True)], axis = 0); del valid_DT\n  valid_DT = np.memmap('valid_mmap', dtype = tmp_DT.dtype, mode = 'w+', shape = tmp_DT.shape)\n  valid_DT[:] = tmp_DT[:]\n  valid_DT.flush()\n  valid_DT = valid_DT, y_valid\n  del tmp_DT\n  gc.collect();time.sleep(5)\n\n  ##미리 처리된것 저장\n  train_DT1 = np.memmap('tmp_train_dt1', dtype = tmp_train_DT.dtype, mode = 'w+', shape = tmp_train_DT.shape)\n  train_DT1[:] = tmp_train_DT[:]\n  train_DT1.flush()\n  del tmp_train_DT\n  gc.collect();time.sleep(5)\n\n  ##새로 생성\n  tmp_train_DT = as_numpy_dataset(x_train, is_train  = True)\n  train_DT2 = np.memmap('tmp_train_dt2', dtype = tmp_train_DT.dtype, mode = 'w+', shape = tmp_train_DT.shape)\n  train_DT2[:] = tmp_train_DT[:]\n  train_DT2.flush()\n  del tmp_train_DT\n  gc.collect();time.sleep(5)\n\n  train_DT = np.concatenate([train_DT1, train_DT2], axis = 0)\n  !sudo rm -r train \n\n  train_DT_mmap = np.memmap('train_mmap', dtype = train_DT.dtype, mode = 'w+', shape = train_DT.shape)\n  train_DT_mmap[:] = train_DT[:]\n  train_DT_mmap.flush()\n  del train_DT, train_DT1, train_DT2\n  !sudo rm -r tmp_train_dt1\n  !sudo rm -r tmp_train_dt2\n  train_DT = train_DT_mmap, y_train","metadata":{"id":"W88SCw53ui_t","execution":{"iopub.status.busy":"2021-05-29T03:17:36.459192Z","iopub.execute_input":"2021-05-29T03:17:36.459601Z","iopub.status.idle":"2021-05-29T03:17:41.584396Z","shell.execute_reply.started":"2021-05-29T03:17:36.459564Z","shell.execute_reply":"2021-05-29T03:17:41.58212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## tf.data.Dataset setting","metadata":{"id":"VxsghC73mnyq"}},{"cell_type":"code","source":"BATCH_SIZE = 16\ntrain_dataset = tf.data.Dataset.from_tensor_slices(train_DT).shuffle(512).batch(BATCH_SIZE, True).prefetch(tf.data.experimental.AUTOTUNE)\nvalid_dataset = tf.data.Dataset.from_tensor_slices(valid_DT).batch(BATCH_SIZE).prefetch(33)\ntest_dataset  = tf.data.Dataset.from_tensor_slices(tests_DT).batch(BATCH_SIZE).prefetch(32)","metadata":{"id":"i-gFqviomnys","execution":{"iopub.status.busy":"2021-05-29T03:17:41.585561Z","iopub.status.idle":"2021-05-29T03:17:41.58612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# model define","metadata":{}},{"cell_type":"code","source":"ACT = (lambda X: X * tf.keras.activations.tanh(tf.keras.activations.softplus(X)))\nACTL = tf.keras.layers.Lambda(ACT)\nACT_cosnorm = lambda x: tf.keras.activations.elu(x, alpha=0.05)\n\n@tf.function\ndef make_norm(Val, axis):\n    mean = tf.reduce_mean(tf.stop_gradient(Val), axis, True)\n    return (Val - mean) / (1e-6 + tf.norm((Val - mean),2, axis, True) )\n\nclass coscnn(tf.keras.layers.Layer):\n    def __init__(self, d, kk, ss, padding = 'VALID'):\n        super(coscnn, self).__init__()\n        self.args = [[1,*kk,1], [1,*ss,1], [1,1,1,1], padding]\n        self.num_outputs = d\n    def build(self, input_shape):\n        last_shape = int(input_shape[-1]) * self.args[0][-3] * self.args[0][-2]\n        self.kernel = self.add_weight(\n            shape=(last_shape, self.num_outputs), initializer=\"he_normal\", trainable=True\n        )\n        self.bias = self.add_weight(shape=(self.num_outputs,), initializer=\"zeros\", trainable=True)\n        if len(input_shape) == 4:\n          self.extracter = lambda inputs : tf.image.extract_patches(inputs, *self.args)\n        if len(input_shape) == 5:\n          self.extracter = TimeDistributed(Lambda(lambda inputs : tf.image.extract_patches(inputs, *self.args)))\n    def call(self, inp):\n        return make_norm(self.extracter(inp), -1) @ make_norm(self.kernel, 0) + self.bias","metadata":{"id":"S0-X3jd4mnys","execution":{"iopub.status.busy":"2021-05-29T03:17:45.250251Z","iopub.execute_input":"2021-05-29T03:17:45.250837Z","iopub.status.idle":"2021-05-29T03:17:45.266459Z","shell.execute_reply.started":"2021-05-29T03:17:45.250795Z","shell.execute_reply":"2021-05-29T03:17:45.265497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import *\nfrom tensorflow.keras.models import *\nwide = .781\nX = IN = Input((3, 273, 256))\nX = tf.expand_dims(X, -1)\nX = coscnn(128, (13, 8), (13, 8), 'VALID')(X)#21x32\nprint(X.shape)\nX = ACT_cosnorm(X)\n\nDrops = Dropout(0.25)(tf.reduce_mean(tf.ones_like(X), -1, True))#pixel wise dropout\nX = X * Drops\n\nX = tf.concat(tf.unstack(X, axis = 1), axis = -1)\n\nX = Conv2D(int(512 * wide), 3, 1, padding = 'same', use_bias = False, kernel_initializer = 'he_normal')(X)\nX = ACT(BatchNormalization()(X))\nX = Conv2D(int(256 * wide), 3, 1, padding = 'same', use_bias = False, kernel_initializer = 'he_normal')(X)\nX = ACT(BatchNormalization()(X))\nX = Conv2D(int(512 * wide), 3, 1, padding = 'same', use_bias = False, kernel_initializer = 'he_normal')(X)\nX = ACT(BatchNormalization()(X))\nX = AveragePooling2D(padding = 'same')(X)#11x16\n\n\nX = Conv2D(int(1024 * wide), 3, 1, padding = 'same', use_bias = False, kernel_initializer = 'he_normal')(X)\nX = ACT(BatchNormalization()(X))\nX = Conv2D(int(512 * wide), 3, 1, padding = 'same', use_bias = False, kernel_initializer = 'he_normal')(X)\nX = ACT(BatchNormalization()(X))\nX = Conv2D(int(1024 * wide), 3, 1, padding = 'same', use_bias = False, kernel_initializer = 'he_normal')(X)\nX = ACT(BatchNormalization()(X))\nX = AveragePooling2D(padding = 'same')(X)#6x8\nX = Flatten()(X)\n\nX = Dense(1, dtype='float32', use_bias = False)(X)\nX = Activation('sigmoid', dtype='float32')(X)\nmodel = Model(IN, X)\nmodel.summary()\n\nEPOCHS = 20\nclass FCA(tf.keras.optimizers.schedules.LearningRateSchedule):\n    def __init__(self, total_step, initial_learning_rate):\n        self.total_step = total_step\n        self.initial_learning_rate = initial_learning_rate\n\n    def __call__(self, step):\n        return tf.where(\n            tf.less(self.total_step * 72 / 100, step)\n            ,self.initial_learning_rate * (1-tf.cos(((step - self.total_step) / (self.total_step * 28 / 100) * 3.1415926535)))/2\n            ,self.initial_learning_rate\n        )\n\ndef loss(y_true, y_pred):\n    return tf.keras.losses.binary_crossentropy(y_true, y_pred, from_logits=False, label_smoothing=0.1)\ntotal_run = y_train.shape[0] // BATCH_SIZE * EPOCHS\n\nopt = tfa.optimizers.RectifiedAdam(FCA(total_run, 0.001), weight_decay=0.0005, clipnorm = 0.01, total_steps = total_run, warmup_proportion=0.02)\nopt = tfa.optimizers.Lookahead(opt, sync_period=6, slow_step_size=0.5)\nopt = mixed_precision.LossScaleOptimizer(opt, loss_scale='dynamic')\nmodel.compile(optimizer=opt, loss=loss, metrics=[keras.metrics.AUC()])","metadata":{"id":"urNtB0X2mnyt","outputId":"232b5176-e83f-4438-9aa5-8f81ebed0bba","execution":{"iopub.status.busy":"2021-05-29T03:17:46.788292Z","iopub.execute_input":"2021-05-29T03:17:46.789001Z","iopub.status.idle":"2021-05-29T03:17:47.418412Z","shell.execute_reply.started":"2021-05-29T03:17:46.788958Z","shell.execute_reply":"2021-05-29T03:17:47.416687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def auc_plot(auc,val_auc):\n    plt.plot(auc)\n    plt.plot(val_auc)\n    plt.xlabel('epochs')\n    plt.ylabel('auc')\n    plt.title('auc vs epochs')\n    plt.legend(['auc','val_auc'])\n    plt.show()\ndef loss_plot(loss,val_loss):\n    plt.plot(loss)\n    plt.plot(val_loss)\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.title('loss vs epochs')\n    plt.legend(['loss','val_loss'])\n    plt.show()","metadata":{"_kg_hide-input":true,"id":"O-FZXR4amnyu","execution":{"iopub.status.busy":"2021-05-29T03:17:48.126516Z","iopub.execute_input":"2021-05-29T03:17:48.126913Z","iopub.status.idle":"2021-05-29T03:17:48.134649Z","shell.execute_reply.started":"2021-05-29T03:17:48.126871Z","shell.execute_reply":"2021-05-29T03:17:48.133241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_dataset,epochs=EPOCHS,validation_data=valid_dataset)","metadata":{"id":"xqrPsTH8mnyu","outputId":"5803d0de-eeb9-422f-cd9d-47d552db9954","execution":{"iopub.status.busy":"2021-05-29T03:17:50.169841Z","iopub.execute_input":"2021-05-29T03:17:50.17029Z","iopub.status.idle":"2021-05-29T03:17:50.20755Z","shell.execute_reply.started":"2021-05-29T03:17:50.170252Z","shell.execute_reply":"2021-05-29T03:17:50.206453Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# cosine normalizing filter result","metadata":{}},{"cell_type":"code","source":"filters = model.layers[2].kernel\nf_min, f_max = tf.reduce_min(filters), tf.reduce_max(filters)\nprint(f_min, f_max)\nfilters = (filters - f_min) / (f_max - f_min)\nn_filters, ix = 64, 1\nfig, axss = plt.subplots(8, 8, figsize=(15,15))\nfor i, ax in zip(range(n_filters), [J for I in axss for J in I]):\n    # get the filter\n    f = filters[:, i]\n    f = tf.reshape(f, (13, 8))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    # plot filter channel in grayscale\n    ax.imshow(f, cmap='gray')\n# show the figure\nplt.show()","metadata":{"id":"G4ZekynwRUfC","outputId":"3fe862f8-500a-45cb-ae81-d2ec0d751cd1","execution":{"iopub.status.busy":"2021-05-29T03:17:52.676942Z","iopub.execute_input":"2021-05-29T03:17:52.677485Z","iopub.status.idle":"2021-05-29T03:17:55.468344Z","shell.execute_reply.started":"2021-05-29T03:17:52.677447Z","shell.execute_reply":"2021-05-29T03:17:55.467216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"auc_plot(history.history['auc'],history.history['val_auc'])\nloss_plot(history.history['loss'],history.history['val_loss'])","metadata":{"id":"Ug4FN4jImnyv","outputId":"5563019e-a1e2-4c5e-9b96-9c41399175c2","execution":{"iopub.status.busy":"2021-05-29T03:17:55.469967Z","iopub.execute_input":"2021-05-29T03:17:55.470299Z","iopub.status.idle":"2021-05-29T03:17:55.503011Z","shell.execute_reply.started":"2021-05-29T03:17:55.470268Z","shell.execute_reply":"2021-05-29T03:17:55.501231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# output distribution","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\n@tf.function\ndef pred(img):return model(img, training = False)","metadata":{"id":"dIGDhcgIxOeY","execution":{"iopub.status.busy":"2021-05-29T03:18:02.009966Z","iopub.execute_input":"2021-05-29T03:18:02.010379Z","iopub.status.idle":"2021-05-29T03:18:02.016068Z","shell.execute_reply.started":"2021-05-29T03:18:02.010345Z","shell.execute_reply":"2021-05-29T03:18:02.01483Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = [[],[]]\nfor img, labs in train_dataset.take(33):\n  for I, lab in zip(pred(img), labs):  \n    result[lab].append(I)\nax = sns.distplot(result[0], bins = 10, label = 0, color = sns.color_palette(\"RdBu\", 9)[1])\nax = sns.distplot(result[1], bins = 10, label = 1, color = sns.color_palette(\"RdBu\", 9)[-2])","metadata":{"id":"zLWEBUN_DViM","outputId":"cbecedca-b38e-4339-c2e0-3c68f8e68771","execution":{"iopub.status.busy":"2021-05-29T03:18:02.76979Z","iopub.execute_input":"2021-05-29T03:18:02.770392Z","iopub.status.idle":"2021-05-29T03:18:02.817022Z","shell.execute_reply.started":"2021-05-29T03:18:02.770355Z","shell.execute_reply":"2021-05-29T03:18:02.814352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"result = [[],[]]\nfor img, labs in valid_dataset.take(33):\n  for I, lab in zip(pred(img), labs):  \n    result[lab].append(I)\nax = sns.distplot(result[0], bins = 10, label = 0, color = sns.color_palette(\"RdBu\", 9)[1])\nax = sns.distplot(result[1], bins = 10, label = 1, color = sns.color_palette(\"RdBu\", 9)[-2])","metadata":{"id":"PvuDR0DzDZyj","outputId":"fa9f357d-6fcb-4804-f620-7e5cf52362ac","execution":{"iopub.status.busy":"2021-05-29T03:18:03.653716Z","iopub.execute_input":"2021-05-29T03:18:03.654116Z","iopub.status.idle":"2021-05-29T03:18:03.692078Z","shell.execute_reply.started":"2021-05-29T03:18:03.654081Z","shell.execute_reply":"2021-05-29T03:18:03.690288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(test_dataset)","metadata":{"id":"FDbtQMjpmnyv","execution":{"iopub.status.busy":"2021-05-29T03:18:04.238024Z","iopub.execute_input":"2021-05-29T03:18:04.238439Z","iopub.status.idle":"2021-05-29T03:18:04.272923Z","shell.execute_reply.started":"2021-05-29T03:18:04.238405Z","shell.execute_reply":"2021-05-29T03:18:04.27115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = preds.reshape(-1)","metadata":{"id":"K69aEao6mnyv","execution":{"iopub.status.busy":"2021-05-29T03:18:04.793322Z","iopub.execute_input":"2021-05-29T03:18:04.793672Z","iopub.status.idle":"2021-05-29T03:18:04.827724Z","shell.execute_reply.started":"2021-05-29T03:18:04.793643Z","shell.execute_reply":"2021-05-29T03:18:04.826125Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id':sample_submission['id'],'target':preds})","metadata":{"id":"r2cvTIGYmnyv","execution":{"iopub.status.busy":"2021-05-29T03:18:05.333991Z","iopub.execute_input":"2021-05-29T03:18:05.334352Z","iopub.status.idle":"2021-05-29T03:18:05.374164Z","shell.execute_reply.started":"2021-05-29T03:18:05.334321Z","shell.execute_reply":"2021-05-29T03:18:05.372257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"id":"DVZeuftSmnyv","outputId":"dd50e7f0-5c0f-4221-a7af-c1673eab4bd6","execution":{"iopub.status.busy":"2021-05-29T03:18:06.375488Z","iopub.execute_input":"2021-05-29T03:18:06.375881Z","iopub.status.idle":"2021-05-29T03:18:06.412371Z","shell.execute_reply.started":"2021-05-29T03:18:06.375849Z","shell.execute_reply":"2021-05-29T03:18:06.410954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission.to_csv('submission.csv',index=False)","metadata":{"id":"7F-T6zKMmnyv","execution":{"iopub.status.busy":"2021-05-29T03:18:07.332943Z","iopub.execute_input":"2021-05-29T03:18:07.333381Z","iopub.status.idle":"2021-05-29T03:18:07.369658Z","shell.execute_reply.started":"2021-05-29T03:18:07.333345Z","shell.execute_reply":"2021-05-29T03:18:07.367747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#preds = model.predict(test_dataset)\n#preds = preds.reshape(-1)\nplt.figure(figsize=(10,5))\nplt.hist(submission.target,bins=100, range = [0,1]);","metadata":{"id":"ly88AoehPewb","outputId":"747491c7-73a2-47db-9d77-8d4f6000734a","execution":{"iopub.status.busy":"2021-05-29T03:18:07.841155Z","iopub.execute_input":"2021-05-29T03:18:07.841549Z","iopub.status.idle":"2021-05-29T03:18:07.876955Z","shell.execute_reply.started":"2021-05-29T03:18:07.841516Z","shell.execute_reply":"2021-05-29T03:18:07.875359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# submit","metadata":{}},{"cell_type":"code","source":"!kaggle competitions submit -c seti-breakthrough-listen -f submission.csv -m \"from colab - training result\"","metadata":{"id":"80VVwSVQnS0s","outputId":"6672c92a-a79c-4365-b184-a6d214898c33","execution":{"iopub.status.busy":"2021-05-29T03:18:08.694211Z","iopub.execute_input":"2021-05-29T03:18:08.694636Z","iopub.status.idle":"2021-05-29T03:18:09.760024Z","shell.execute_reply.started":"2021-05-29T03:18:08.694598Z","shell.execute_reply":"2021-05-29T03:18:09.758715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# References","metadata":{"id":"6iGy81Nxmnyv"}},{"cell_type":"markdown","source":"### https://www.kaggle.com/assign\n### https://www.kaggle.com/assign/seti-with-colab-pro-gpu-tensorflow","metadata":{}}]}