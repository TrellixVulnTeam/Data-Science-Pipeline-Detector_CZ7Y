{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/rwightman/pytorch-image-models\nimport timm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-16T15:12:01.189283Z","iopub.execute_input":"2021-08-16T15:12:01.189686Z","iopub.status.idle":"2021-08-16T15:12:15.400951Z","shell.execute_reply.started":"2021-08-16T15:12:01.189589Z","shell.execute_reply":"2021-08-16T15:12:15.399983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nimport os\nimport math\nimport time\nimport random\nimport gc\nfrom collections import defaultdict\n\nimport numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nsns.set()\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom tqdm.notebook import tqdm\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:15.402487Z","iopub.execute_input":"2021-08-16T15:12:15.402839Z","iopub.status.idle":"2021-08-16T15:12:17.217961Z","shell.execute_reply.started":"2021-08-16T15:12:15.402804Z","shell.execute_reply":"2021-08-16T15:12:17.217124Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    seed = 46\n    debug = False\n    n_fold = 4\n    n_epoch = 3\n    height = 384\n    width = 384\n    model_name = \"tf_efficientnetv2_s_in21k\"\n    lr = 1e-4\n    weight_decay = 1e-4\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nprint(f\"Using device {CFG.device}\")\n\ndef seed_torch(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(CFG.seed)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:17.219857Z","iopub.execute_input":"2021-08-16T15:12:17.220228Z","iopub.status.idle":"2021-08-16T15:12:17.27102Z","shell.execute_reply.started":"2021-08-16T15:12:17.220192Z","shell.execute_reply":"2021-08-16T15:12:17.27023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntrain[\"target\"] = 0\ntrain['file_path'] = train['id'].apply(lambda x:\n                                      f\"../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy\")\ntest = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\ntest[\"target\"] = 1\ntest['file_path'] = test['id'].apply(lambda x:\n                                    f\"../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy\")\ncols = [\"id\", \"file_path\", \"target\"]\ntrain = pd.concat([train[cols], test[cols]], axis=0).reset_index(drop=True)\ndel test\nprint(train['target'].value_counts())\n\nif CFG.debug:\n    CFG.n_epoch = 2\n    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)\n\nskf = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor fold, (_, val_index) in enumerate(skf.split(train, train[\"target\"])):\n    train.loc[val_index, 'fold'] = fold\ntrain['fold'] = train['fold'].astype(int)\ntrain.groupby(['fold', 'target']).size()","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:17.272906Z","iopub.execute_input":"2021-08-16T15:12:17.273376Z","iopub.status.idle":"2021-08-16T15:12:17.469704Z","shell.execute_reply.started":"2021-08-16T15:12:17.27334Z","shell.execute_reply":"2021-08-16T15:12:17.468936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_transforms(da: bool):\n    if da:\n        return A.Compose([\n            A.Resize(CFG.height, CFG.width),\n            A.HorizontalFlip(p=0.5),\n            A.VerticalFlip(p=0.5),\n            ToTensorV2(),\n        ])\n\n    else:\n        return A.Compose([\n            A.Resize(CFG.height, CFG.width),\n            ToTensorV2(),\n        ])\n\nclass SETIDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[\"target\"].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = np.load(self.file_names[idx]).astype(np.float32) # (6, 273, 256)\n        image = np.vstack(image).transpose((1, 0)) # (256, 1638)\n        if self.transform:\n            image = self.transform(image=image)['image']\n        else:\n            image = image[np.newaxis,:,:]\n            image = torch.from_numpy(image).float()\n        \n        label = torch.tensor(self.labels[idx]).float()\n        return image, label\n","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:17.470983Z","iopub.execute_input":"2021-08-16T15:12:17.471344Z","iopub.status.idle":"2021-08-16T15:12:17.480675Z","shell.execute_reply.started":"2021-08-16T15:12:17.471309Z","shell.execute_reply":"2021-08-16T15:12:17.47966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SETIModel(nn.Module):\n    def __init__(self, pretrained=True):\n        super().__init__()\n        self.backbone = timm.create_model(CFG.model_name, pretrained=pretrained, in_chans=1)\n        self.backbone.classifier = nn.Linear(self.backbone.classifier.in_features, 1)\n\n    def forward(self, x):\n        return self.backbone(x)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:17.482088Z","iopub.execute_input":"2021-08-16T15:12:17.482474Z","iopub.status.idle":"2021-08-16T15:12:17.492671Z","shell.execute_reply.started":"2021-08-16T15:12:17.482436Z","shell.execute_reply":"2021-08-16T15:12:17.491855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def criterion(outputs, targets):\n    return nn.BCEWithLogitsLoss()(outputs, targets)\n\ndef train_one_epoch(model, optimizer, dataloader, epoch):\n    model.train()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, labels) in bar:         \n        images = images.to(CFG.device)\n        labels = labels.to(CFG.device)\n        batch_size = images.size(0)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs.view(-1), labels)\n        loss.backward()\n        optimizer.step()\n                \n        running_loss += loss.item() * batch_size\n        dataset_size += batch_size \n        epoch_loss = running_loss/dataset_size\n        bar.set_postfix(Epoch=epoch, Train_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])\n    gc.collect()\n    \n    return epoch_loss\n\n@torch.no_grad()\ndef valid_one_epoch(model, dataloader, epoch):\n    model.eval()\n    \n    dataset_size = 0\n    running_loss = 0.0\n    \n    TARGETS = []\n    PREDS = []\n    \n    bar = tqdm(enumerate(dataloader), total=len(dataloader))\n    for step, (images, labels) in bar:        \n        images = images.to(CFG.device)\n        labels = labels.to(CFG.device)\n        batch_size = images.size(0)\n        \n        outputs = model(images)\n        loss = criterion(outputs.view(-1), labels)\n        \n        running_loss += loss.item() * batch_size\n        dataset_size += batch_size\n        \n        epoch_loss = running_loss/dataset_size\n        \n        PREDS.append(outputs.sigmoid().cpu().detach().numpy())\n        TARGETS.append(labels.view(-1).cpu().detach().numpy())\n        \n        bar.set_postfix(Epoch=epoch, Valid_Loss=epoch_loss,\n                        LR=optimizer.param_groups[0]['lr'])   \n    \n    TARGETS = np.concatenate(TARGETS)\n    PREDS = np.concatenate(PREDS)\n    val_auc = roc_auc_score(TARGETS, PREDS)\n    gc.collect()\n    \n    return epoch_loss, val_auc, PREDS","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:17.493924Z","iopub.execute_input":"2021-08-16T15:12:17.494297Z","iopub.status.idle":"2021-08-16T15:12:17.508688Z","shell.execute_reply.started":"2021-08-16T15:12:17.49426Z","shell.execute_reply":"2021-08-16T15:12:17.507839Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def run(model, optimizer, train_loader, valid_loader, fold):    \n    best_epoch_auc = 0\n    best_preds = None\n    history = defaultdict(list)\n    \n    for epoch in range(1, CFG.n_epoch + 1): \n        gc.collect()\n        train_epoch_loss = train_one_epoch(model, optimizer, train_loader, epoch)\n        valid_epoch_loss, valid_epoch_auc, preds = valid_one_epoch(model, valid_loader, epoch)\n        history['Train Loss'].append(train_epoch_loss)\n        history['Valid Loss'].append(valid_epoch_loss)\n        history['Valid AUC'].append(valid_epoch_auc)\n        \n        print(f'Valid AUC: {valid_epoch_auc}')\n        \n        if valid_epoch_auc >= best_epoch_auc:\n            print(f\"Validation AUC Improved ({best_epoch_auc} ---> {valid_epoch_auc})\")\n            best_epoch_auc = valid_epoch_auc\n            best_preds = preds\n            torch.save(model.state_dict(), f\"{CFG.model_name}_{fold}.pth\")\n            print(\"Model Saved\")\n            \n        print()\n        torch.cuda.empty_cache()\n        gc.collect()\n\n    print(f\"Best AUC for Fold {fold}: {best_epoch_auc:.4f}\")\n    \n    return best_preds, history\n\ndef prepare_data(fold):\n    df_train = train[train.fold != fold].reset_index(drop=True)\n    df_valid = train[train.fold == fold].reset_index(drop=True)\n    \n    train_dataset = SETIDataset(df_train, transform=get_transforms(True))\n    valid_dataset = SETIDataset(df_valid, transform=get_transforms(False))\n\n    train_loader = DataLoader(train_dataset, batch_size=32, \n                              num_workers=4, shuffle=True, pin_memory=True)\n    valid_loader = DataLoader(valid_dataset, batch_size=128, \n                              num_workers=4, shuffle=False, pin_memory=True)\n    \n    return train_loader, valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:17.511093Z","iopub.execute_input":"2021-08-16T15:12:17.511525Z","iopub.status.idle":"2021-08-16T15:12:17.521967Z","shell.execute_reply.started":"2021-08-16T15:12:17.511492Z","shell.execute_reply":"2021-08-16T15:12:17.521137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"pred\"] = 0\nscores = []\nhistories = []\nfor fold in range(CFG.n_fold):\n    print(f\"===== fold {fold} ======\")\n    model = SETIModel()\n    model.to(CFG.device)\n    train_loader, valid_loader = prepare_data(fold=fold)\n    optimizer = torch.optim.AdamW(\n        model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay\n    )\n    preds, history = run(model, optimizer, train_loader, valid_loader, fold)\n    train.loc[train.fold == fold, \"pred\"] = preds\n    histories.append(history)\n    scores.append(np.max(history['Valid AUC']))\n    \n    torch.cuda.empty_cache()\n    gc.collect()\n\nprint(\"===== Result Summary =====\")\nprint(f\"Average AUC: {np.mean(scores):.5f} | Std: {np.std(scores):.5f}\")","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:12:17.523425Z","iopub.execute_input":"2021-08-16T15:12:17.523956Z","iopub.status.idle":"2021-08-16T15:15:43.060431Z","shell.execute_reply.started":"2021-08-16T15:12:17.523918Z","shell.execute_reply":"2021-08-16T15:15:43.059539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"OOF AUC: {roc_auc_score(train.target, train.pred):.6f}\")\ndisplay(train)\ntrain[[\"id\", \"target\", \"pred\"]].to_csv(\"oof.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:15:43.06193Z","iopub.execute_input":"2021-08-16T15:15:43.062513Z","iopub.status.idle":"2021-08-16T15:15:43.09378Z","shell.execute_reply.started":"2021-08-16T15:15:43.062474Z","shell.execute_reply":"2021-08-16T15:15:43.093026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"colors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\nfig = plt.figure()\nfor i in range(CFG.n_fold):\n    plt.plot(histories[i]['Train Loss'], label=f'Train {i}', c=colors[i], linestyle=\"-\", marker=\".\")\n    plt.plot(histories[i]['Valid Loss'], label=f'Valid {i}', c=colors[i], linestyle=\"--\", marker=\".\")\n    \nplt.legend()\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.title('Loss Curve');","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:15:43.094977Z","iopub.execute_input":"2021-08-16T15:15:43.095461Z","iopub.status.idle":"2021-08-16T15:15:43.388844Z","shell.execute_reply.started":"2021-08-16T15:15:43.095424Z","shell.execute_reply":"2021-08-16T15:15:43.387882Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure()\nfor i in range(CFG.n_fold):\n    plt.plot(histories[i]['Valid AUC'], label=str(i), marker=\".\")\nplt.legend()\nplt.ylabel('AUC')\nplt.xlabel('Epoch')\nplt.title('AUC Curve');","metadata":{"execution":{"iopub.status.busy":"2021-08-16T15:15:43.390238Z","iopub.execute_input":"2021-08-16T15:15:43.390575Z","iopub.status.idle":"2021-08-16T15:15:43.605184Z","shell.execute_reply.started":"2021-08-16T15:15:43.390541Z","shell.execute_reply":"2021-08-16T15:15:43.604246Z"},"trusted":true},"execution_count":null,"outputs":[]}]}