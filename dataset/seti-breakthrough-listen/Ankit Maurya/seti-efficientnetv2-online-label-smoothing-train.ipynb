{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport sys\nimport pandas as pd\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom tqdm import tqdm\nimport torch\nimport torchvision.models as models\nimport torch.nn as nn\nimport random\nfrom sklearn.model_selection import KFold, StratifiedKFold\nimport albumentations as A","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":3.22704,"end_time":"2021-06-02T18:55:21.372972","exception":false,"start_time":"2021-06-02T18:55:18.145932","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:06:57.886353Z","iopub.execute_input":"2021-06-06T10:06:57.886714Z","iopub.status.idle":"2021-06-06T10:07:01.299146Z","shell.execute_reply.started":"2021-06-06T10:06:57.886639Z","shell.execute_reply":"2021-06-06T10:07:01.298354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/rwightman/pytorch-image-models","metadata":{"papermill":{"duration":11.054477,"end_time":"2021-06-02T18:55:32.444126","exception":false,"start_time":"2021-06-02T18:55:21.389649","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:01.301857Z","iopub.execute_input":"2021-06-06T10:07:01.302454Z","iopub.status.idle":"2021-06-06T10:07:13.531423Z","shell.execute_reply.started":"2021-06-06T10:07:01.302419Z","shell.execute_reply":"2021-06-06T10:07:13.530583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import timm","metadata":{"papermill":{"duration":0.702465,"end_time":"2021-06-02T18:55:33.168053","exception":false,"start_time":"2021-06-02T18:55:32.465588","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:13.53481Z","iopub.execute_input":"2021-06-06T10:07:13.535084Z","iopub.status.idle":"2021-06-06T10:07:14.175175Z","shell.execute_reply.started":"2021-06-06T10:07:13.535056Z","shell.execute_reply":"2021-06-06T10:07:14.17434Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def set_seed(seed = 0):\n    '''Sets the seed of the entire notebook so results are the same every time we run.\n    This is for REPRODUCIBILITY.'''\n    np.random.seed(seed)\n    random_state = np.random.RandomState(seed)\n    random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    return random_state\n\nseed = 42\nrandom_state = set_seed(seed)","metadata":{"papermill":{"duration":0.024905,"end_time":"2021-06-02T18:55:33.205474","exception":false,"start_time":"2021-06-02T18:55:33.180569","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:14.176603Z","iopub.execute_input":"2021-06-06T10:07:14.176946Z","iopub.status.idle":"2021-06-06T10:07:14.187259Z","shell.execute_reply.started":"2021-06-06T10:07:14.176908Z","shell.execute_reply":"2021-06-06T10:07:14.186454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if torch.cuda.is_available():\n    device = torch.device(\"cuda\")\n    print(\"GPU is available\")\nelse:\n    device = torch.device(\"cpu\")\n    print(\"GPU not available, CPU used\")","metadata":{"papermill":{"duration":0.066547,"end_time":"2021-06-02T18:55:33.284688","exception":false,"start_time":"2021-06-02T18:55:33.218141","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:14.190952Z","iopub.execute_input":"2021-06-06T10:07:14.191318Z","iopub.status.idle":"2021-06-06T10:07:14.233991Z","shell.execute_reply.started":"2021-06-06T10:07:14.191283Z","shell.execute_reply":"2021-06-06T10:07:14.233107Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_sz = 256\nttransform = A.Compose([\n    A.Resize(img_sz, img_sz, cv2.INTER_NEAREST),\n    A.VerticalFlip(p=0.4),\n    A.HorizontalFlip(p=0.4),\n])\nvtransform = A.Compose([\n    A.Resize(img_sz, img_sz, cv2.INTER_NEAREST)\n])","metadata":{"papermill":{"duration":0.02124,"end_time":"2021-06-02T18:55:33.319399","exception":false,"start_time":"2021-06-02T18:55:33.298159","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:14.23546Z","iopub.execute_input":"2021-06-06T10:07:14.235945Z","iopub.status.idle":"2021-06-06T10:07:14.241871Z","shell.execute_reply.started":"2021-06-06T10:07:14.235908Z","shell.execute_reply":"2021-06-06T10:07:14.240836Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nclass ClassificationDataset:\n    \n    def __init__(self, image_paths, targets, tr): \n        self.image_paths = image_paths\n        self.targets = targets\n        self.tr = tr\n\n    def __len__(self):\n        return len(self.image_paths)\n    \n    def __getitem__(self, item):      \n        image = np.load(self.image_paths[item])\n        image = np.vstack(image).astype(float)\n        image = self.tr(image = image)[\"image\"][np.newaxis, ]\n\n        targets = self.targets[item]\n                \n        return {\n            \"image\": torch.tensor(image, dtype=torch.float),\n            \"targets\": torch.tensor(targets, dtype=torch.long),\n        }","metadata":{"papermill":{"duration":0.022623,"end_time":"2021-06-02T18:55:33.354534","exception":false,"start_time":"2021-06-02T18:55:33.331911","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:14.243048Z","iopub.execute_input":"2021-06-06T10:07:14.243553Z","iopub.status.idle":"2021-06-06T10:07:14.251935Z","shell.execute_reply.started":"2021-06-06T10:07:14.243516Z","shell.execute_reply":"2021-06-06T10:07:14.250962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\nprint (df.shape)\ndf['img_path'] = df['id'].apply(lambda x: f'../input/seti-breakthrough-listen/train/{x[0]}/{x}.npy')","metadata":{"papermill":{"duration":0.090015,"end_time":"2021-06-02T18:55:33.456944","exception":false,"start_time":"2021-06-02T18:55:33.366929","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:14.253171Z","iopub.execute_input":"2021-06-06T10:07:14.253701Z","iopub.status.idle":"2021-06-06T10:07:14.327176Z","shell.execute_reply.started":"2021-06-06T10:07:14.253667Z","shell.execute_reply":"2021-06-06T10:07:14.326334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"papermill":{"duration":0.031516,"end_time":"2021-06-02T18:55:33.501733","exception":false,"start_time":"2021-06-02T18:55:33.470217","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:14.328449Z","iopub.execute_input":"2021-06-06T10:07:14.328782Z","iopub.status.idle":"2021-06-06T10:07:14.345774Z","shell.execute_reply.started":"2021-06-06T10:07:14.328746Z","shell.execute_reply":"2021-06-06T10:07:14.344696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self,baseline_name , out_dim):\n        super(enetv2, self).__init__()\n        self.enet = timm.create_model(baseline_name , pretrained=True)\n#         self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n        self.myfc = nn.Linear(self.enet.classifier.in_features, out_dim)\n        self.enet.classifier = nn.Identity()\n        self.conv1 = nn.Conv2d(1, 3, kernel_size=3, stride=1, padding=3, bias=False)\n\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.extract(x)\n        x = self.myfc(x)\n        return x","metadata":{"papermill":{"duration":0.022338,"end_time":"2021-06-02T18:55:33.537305","exception":false,"start_time":"2021-06-02T18:55:33.514967","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:07:14.347198Z","iopub.execute_input":"2021-06-06T10:07:14.347563Z","iopub.status.idle":"2021-06-06T10:07:14.355405Z","shell.execute_reply.started":"2021-06-06T10:07:14.347528Z","shell.execute_reply":"2021-06-06T10:07:14.354312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch import Tensor\n\n\nclass OnlineLabelSmoothing(nn.Module):\n    \"\"\"\n    Implements Online Label Smoothing from paper\n    https://arxiv.org/pdf/2011.12562.pdf\n    \"\"\"\n\n    def __init__(self, alpha: float, n_classes: int, smoothing: float = 0.1):\n        \"\"\"\n        :param alpha: Term for balancing soft_loss and hard_loss\n        :param n_classes: Number of classes of the classification problem\n        :param smoothing: Smoothing factor to be used during first epoch in soft_loss\n        \"\"\"\n        super(OnlineLabelSmoothing, self).__init__()\n        assert 0 <= alpha <= 1, 'Alpha must be in range [0, 1]'\n        self.a = alpha\n        self.n_classes = n_classes\n        # Initialize soft labels with normal LS for first epoch\n        # self.supervise = (1 - smoothing) * torch.eye(n_classes) + smoothing / n_classes\n\n        # With alpha / (n_classes - 1) ----> Alternative\n        self.register_buffer('supervise', torch.zeros(n_classes, n_classes))\n        self.supervise.fill_(smoothing / (n_classes - 1))\n        self.supervise.fill_diagonal_(1 - smoothing)\n\n        # Update matrix is used to supervise next epoch\n        self.register_buffer('update', torch.zeros_like(self.supervise))\n        # For normalizing we need a count for each class\n        self.register_buffer('idx_count', torch.zeros(n_classes))\n        self.hard_loss = nn.CrossEntropyLoss()\n\n    def forward(self, y_h: Tensor, y: Tensor):\n        # Calculate the final loss\n        soft_loss = self.soft_loss(y_h, y)\n        hard_loss = self.hard_loss(y_h, y)\n        return self.a * hard_loss + (1 - self.a) * soft_loss\n\n    def soft_loss(self, y_h: Tensor, y: Tensor):\n        \"\"\"\n        Calculates the soft loss and calls step\n        to update `update`.\n        :param y_h: Predicted logits.\n        :param y: Ground truth labels.\n        :return: Calculates the soft loss based on current supervise matrix.\n        \"\"\"\n        y_h = y_h.log_softmax(dim=-1)\n        with torch.no_grad():\n            self.step(y_h.exp(), y)\n            true_dist = torch.index_select(self.supervise, 1, y).swapaxes(-1, -2)\n        return torch.mean(torch.sum(-true_dist * y_h, dim=-1))\n\n    def step(self, y_h: Tensor, y: Tensor) -> None:\n        \"\"\"\n        Updates `update` with the probabilities\n        of the correct predictions and updates `idx_count` counter for\n        later normalization.\n        Steps:\n            1. Calculate correct classified examples.\n            2. Filter `y_h` based on the correct classified.\n            3. Add `y_h_f` rows to the `j` (based on y_h_idx) column of `memory`.\n            4. Keep count of # samples added for each `y_h_idx` column.\n            5. Average memory by dividing column-wise by result of step (4).\n        Note on (5): This is done outside this function since we only need to\n                     normalize at the end of the epoch.\n        \"\"\"\n        # 1. Calculate predicted classes\n        y_h_idx = y_h.argmax(dim=-1)\n        # 2. Filter only correct\n        mask = torch.eq(y_h_idx, y)\n        y_h_c = y_h[mask]\n        y_h_idx_c = y_h_idx[mask]\n        # 3. Add y_h probabilities rows as columns to `memory`\n        self.update.index_add_(1, y_h_idx_c, y_h_c.swapaxes(-1, -2))\n        # 4. Update `idx_count`\n        self.idx_count.index_add_(0, y_h_idx_c, torch.ones_like(y_h_idx_c, dtype=torch.float32))\n\n    def next_epoch(self) -> None:\n        \"\"\"\n        This function should be called at the end of the epoch.\n        It basically sets the `supervise` matrix to be the `update`\n        and re-initializes to zero this last matrix and `idx_count`.\n        \"\"\"\n        # 5. Divide memory by `idx_count` to obtain average (column-wise)\n        self.idx_count[torch.eq(self.idx_count, 0)] = 1  # Avoid 0 denominator\n        # Normalize by taking the average\n        # TODO: Softmax instead of average\n        self.update /= self.idx_count\n        self.idx_count.zero_()\n        self.supervise = self.update\n        self.update = self.update.clone().zero_()","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:07:14.356795Z","iopub.execute_input":"2021-06-06T10:07:14.357493Z","iopub.status.idle":"2021-06-06T10:07:14.373447Z","shell.execute_reply.started":"2021-06-06T10:07:14.357402Z","shell.execute_reply":"2021-06-06T10:07:14.372576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# criterion = OnlineLabelSmoothing(alpha=0.5, n_classes=2)","metadata":{"execution":{"iopub.status.busy":"2021-06-06T10:07:14.374815Z","iopub.execute_input":"2021-06-06T10:07:14.375157Z","iopub.status.idle":"2021-06-06T10:07:14.406094Z","shell.execute_reply.started":"2021-06-06T10:07:14.375124Z","shell.execute_reply":"2021-06-06T10:07:14.405468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(data_loader, model, optimizer, device):\n    \n    model.train()\n    \n    for data in tqdm(data_loader, position=0, leave=True, desc='Training'):\n        \n        inputs1 = data[\"image\"]\n        labels = data['targets']\n        \n\n\n        inputs1 = inputs1.to(device, dtype=torch.float)\n        labels = labels.to(device)\n\n        \n        optimizer.zero_grad()\n        outputs = model(inputs1)\n#         outputs.type_as(labels)\n        loss = criterion(outputs.view(-1),labels.float())\n        loss.backward()\n        optimizer.step()\n#     criterion.next_epoch()\n        \ndef evaluate(data_loader, model, device):\n    model.eval()\n    \n    final_targets = []\n    final_outputs = []\n    \n    with torch.no_grad():\n        \n        for data in tqdm(data_loader, position=0, leave=True, desc='Evaluating'):\n            inputs = data[\"image\"]\n            targets = data[\"targets\"]\n            inputs = inputs.to(device, dtype=torch.float)\n            targets = targets.to(device, dtype=torch.float)\n            \n            output = model(inputs)\n            \n            targets = targets.detach().cpu().numpy().tolist()\n            output = output.detach().cpu().numpy().tolist()\n            \n            final_targets.extend(targets)\n            final_outputs.extend(output)\n            \n    return final_outputs, final_targets","metadata":{"papermill":{"duration":0.025253,"end_time":"2021-06-02T18:55:33.611238","exception":false,"start_time":"2021-06-02T18:55:33.585985","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:17:28.083857Z","iopub.execute_input":"2021-06-06T10:17:28.084198Z","iopub.status.idle":"2021-06-06T10:17:28.095224Z","shell.execute_reply.started":"2021-06-06T10:17:28.084165Z","shell.execute_reply":"2021-06-06T10:17:28.092632Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nbaseline_name = 'tf_efficientnetv2_b0'\n\nmodels = []\ndevice = \"cuda\"\n# df = df.sample(n = 1000).reset_index(drop=True)\nepochs = 10\nBatch_Size = 32\nX = df.img_path.values\nY = df.target.values\nskf = StratifiedKFold(n_splits=5)\nfold = 0\nroc_auc_c = 0\ncriterion = nn.BCEWithLogitsLoss()\nfor train_index, test_index in skf.split(X, Y):\n    roc_auc_c = 0\n    print('#'*15,fold,'#'*15)\n    \n    model = enetv2(baseline_name ,out_dim=1)\n    model.to(device)\n\n    train_images, valid_images = X[train_index], X[test_index]\n    train_targets, valid_targets = Y[train_index], Y[test_index]\n\n    train_dataset = ClassificationDataset(image_paths=train_images, targets=train_targets, tr=ttransform)\n    valid_dataset = ClassificationDataset(image_paths=valid_images, targets=valid_targets, tr=vtransform)\n    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=Batch_Size,shuffle=True, num_workers=4)\n    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=Batch_Size,shuffle=False, num_workers=4)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=5e-4)\n\n    for epoch in range(epochs):\n        train(train_loader, model, optimizer, device=device)\n        predictions, valid_targets = evaluate(valid_loader, model, device=device)\n        roc_auc = metrics.roc_auc_score(valid_targets, predictions)\n        print(f\"Epoch={epoch}, Valid ROC AUC={roc_auc}\")\n        \n        if  roc_auc> roc_auc_c:\n            roc_auc_c = roc_auc\n            bst_model = model\n    torch.save(bst_model.state_dict(),baseline_name + '-' +str(\"{:.4f}\".format(roc_auc_c))+'-'+str(fold) + '.pt')\n    models.append(bst_model)\n    fold += 1","metadata":{"papermill":{"duration":26662.592423,"end_time":"2021-06-03T02:19:56.216761","exception":false,"start_time":"2021-06-02T18:55:33.624338","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2021-06-06T10:17:30.211854Z","iopub.execute_input":"2021-06-06T10:17:30.212174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\nsubmission['img_path'] = submission['id'].apply(lambda x: f'../input/seti-breakthrough-listen/test/{x[0]}/{x}.npy')\ntest_dataset = ClassificationDataset(image_paths=submission.img_path.values, targets=submission.target.values)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=4)\n\nsig = torch.nn.Sigmoid()\nouts = []\nfor model in models:\n    predictions, valid_targets = evaluate(test_loader, model, device=device)\n    predictions = np.array(predictions)[:, 0]\n    out = sig(torch.from_numpy(predictions))\n    out = out.detach().numpy()\n    outs.append(out)","metadata":{"papermill":{"duration":20.979859,"end_time":"2021-06-03T02:20:37.664394","exception":false,"start_time":"2021-06-03T02:20:16.684535","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = np.mean(np.array(outs), axis=0)\nsubmission.target = pred\nsubmission.drop(['img_path'], axis=1, inplace=True)\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{},"execution_count":null,"outputs":[]}]}