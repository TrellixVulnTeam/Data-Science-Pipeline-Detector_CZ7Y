{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q efficientnet >> /dev/null","metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2021-05-22T17:46:45.510687Z","iopub.status.busy":"2021-05-22T17:46:45.498221Z","iopub.status.idle":"2021-05-22T17:46:53.964528Z","shell.execute_reply":"2021-05-22T17:46:53.963436Z","shell.execute_reply.started":"2021-05-20T15:18:51.678507Z"},"papermill":{"duration":8.506681,"end_time":"2021-05-22T17:46:53.964736","exception":false,"start_time":"2021-05-22T17:46:45.458055","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"![](https://miro.medium.com/max/875/0*DGvAEv6WuMBHT8n8)","metadata":{}},{"cell_type":"markdown","source":"![](https://www.programmersought.com/images/596/988fcb122f3cc6ad6f32ef84b9277a7c.png)","metadata":{}},{"cell_type":"markdown","source":"https://www.kaggle.com/awsaf49/seti-bl-spatial-info-tf-tpu","metadata":{}},{"cell_type":"code","source":"class SpatialAttentionModule(tf.keras.layers.Layer):\n    def __init__(self, kernel_size=3):\n        '''\n        paper: https://arxiv.org/abs/1807.06521\n        code: https://gist.github.com/innat/99888fa8065ecbf3ae2b297e5c10db70\n        '''\n        super(SpatialAttentionModule, self).__init__()\n        self.conv1 = tf.keras.layers.Conv2D(64, kernel_size=kernel_size, \n                                            use_bias=False, \n                                            kernel_initializer='he_normal',\n                                            strides=1, padding='same', \n                                            activation=tf.nn.relu6)\n        self.conv2 = tf.keras.layers.Conv2D(32, kernel_size=kernel_size, \n                                            use_bias=False, \n                                            kernel_initializer='he_normal',\n                                            strides=1, padding='same', \n                                            activation=tf.nn.relu6)\n        self.conv3 = tf.keras.layers.Conv2D(16, kernel_size=kernel_size, \n                                            use_bias=False, \n                                            kernel_initializer='he_normal',\n                                            strides=1, padding='same', \n                                            activation=tf.nn.relu6)\n        self.conv4 = tf.keras.layers.Conv2D(1, kernel_size=kernel_size,  \n                                            use_bias=False,\n                                            kernel_initializer='he_normal',\n                                            strides=1, padding='same', \n                                            activation=tf.math.sigmoid)\n\n    def call(self, inputs):\n        avg_out = tf.reduce_mean(inputs, axis=3)\n        max_out = tf.reduce_max(inputs,  axis=3)\n        x = tf.stack([avg_out, max_out], axis=3) \n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        return self.conv4(x)\n    \n# A custom layer\nclass ChannelAttentionModule(tf.keras.layers.Layer):\n    def __init__(self, ratio=8):\n        '''\n        paper: https://arxiv.org/abs/1807.06521\n        code: https://gist.github.com/innat/99888fa8065ecbf3ae2b297e5c10db70\n        '''\n        super(ChannelAttentionModule, self).__init__()\n        self.ratio = ratio\n        self.gapavg = tf.keras.layers.GlobalAveragePooling2D()\n        self.gmpmax = tf.keras.layers.GlobalMaxPooling2D()\n        \n    def build(self, input_shape):\n        self.conv1 = tf.keras.layers.Conv2D(input_shape[-1]//self.ratio, \n                                            kernel_size=1, \n                                            strides=1, padding='same',\n                                            use_bias=True, activation=tf.nn.relu)\n    \n        self.conv2 = tf.keras.layers.Conv2D(input_shape[-1], \n                                            kernel_size=1, \n                                            strides=1, padding='same',\n                                            use_bias=True, activation=tf.nn.relu)\n        super(ChannelAttentionModule, self).build(input_shape)\n\n    def call(self, inputs):\n        # compute gap and gmp pooling \n        gapavg = self.gapavg(inputs)\n        gmpmax = self.gmpmax(inputs)\n        gapavg = tf.keras.layers.Reshape((1, 1, gapavg.shape[1]))(gapavg)   \n        gmpmax = tf.keras.layers.Reshape((1, 1, gmpmax.shape[1]))(gmpmax)   \n        # forward passing to the respected layers\n        gapavg_out = self.conv2(self.conv1(gapavg))\n        gmpmax_out = self.conv2(self.conv1(gmpmax))\n        return tf.math.sigmoid(gapavg_out + gmpmax_out)\n    \n    def get_output_shape_for(self, input_shape):\n        return self.compute_output_shape(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        output_len = input_shape[3]\n        return (input_shape[0], output_len)\n# Original Src: https://github.com/bfelbo/DeepMoji/blob/master/deepmoji/attlayer.py\n# Adoped and Modified: https://www.kaggle.com/c/human-protein-atlas-image-classification/discussion/77269#454482\nclass AttentionWeightedAverage2D(tf.keras.layers.Layer):\n    def __init__(self, **kwargs):\n        self.init = tf.keras.initializers.get('uniform')\n        super(AttentionWeightedAverage2D, self).__init__(** kwargs)\n\n    def build(self, input_shape):\n        self.input_spec = [tf.keras.layers.InputSpec(ndim=4)]\n        assert len(input_shape) == 4\n        self.W = self.add_weight(shape=(input_shape[3], 1),\n                                 name='{}_W'.format(self.name),\n                                 initializer=self.init)\n        self._trainable_weights = [self.W]\n        super(AttentionWeightedAverage2D, self).build(input_shape)\n\n    def call(self, x):\n        # computes a probability distribution over the timesteps\n        # uses 'max trick' for numerical stability\n        # reshape is done to avoid issue with Tensorflow\n        # and 2-dimensional weights\n        logits  = K.dot(x, self.W)\n        x_shape = K.shape(x)\n        logits  = K.reshape(logits, (x_shape[0], x_shape[1], x_shape[2]))\n        ai      = K.exp(logits - K.max(logits, axis=[1,2], keepdims=True))\n        \n        att_weights    = ai / (K.sum(ai, axis=[1,2], keepdims=True) + K.epsilon())\n        weighted_input = x * K.expand_dims(att_weights)\n        result         = K.sum(weighted_input, axis=[1,2])\n        return result\n\n    def get_output_shape_for(self, input_shape):\n        return self.compute_output_shape(input_shape)\n\n    def compute_output_shape(self, input_shape):\n        output_len = input_shape[3]\n        return (input_shape[0], output_len)","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:00.933223Z","iopub.status.busy":"2021-05-22T17:47:00.763706Z","iopub.status.idle":"2021-05-22T17:47:00.954029Z","shell.execute_reply":"2021-05-22T17:47:00.953293Z","shell.execute_reply.started":"2021-05-20T15:19:09.183786Z"},"papermill":{"duration":0.224425,"end_time":"2021-05-22T17:47:00.954185","exception":false,"start_time":"2021-05-22T17:47:00.72976","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{"papermill":{"duration":0.031279,"end_time":"2021-05-22T17:47:01.016522","exception":false,"start_time":"2021-05-22T17:47:00.985243","status":"completed"},"tags":[]}},{"cell_type":"code","source":"# USE VERBOSE=0 for silent, VERBOSE=1 for interactive, VERBOSE=2 for commit\nVERBOSE      = 0\nDISPLAY_PLOT = True\n\nDEVICE = \"TPU\" #or \"GPU\"\n\n# USE DIFFERENT SEED FOR DIFFERENT STRATIFIED KFOLD\nSEED = 42\n\n# NUMBER OF FOLDS. USE 2, 5, 10\nFOLDS = 5\n\n# WHICH IMAGE SIZES TO LOAD EACH FOLD\n# CHOOSE 128, 192, 256, 384, 512, 512 \nIMG_SIZES = [[273, 256]]*FOLDS\n\n\n# BATCH SIZE AND EPOCHS\nBATCH_SIZES = [32]*FOLDS\nEPOCHS      = [18]*FOLDS\n\n# WHICH EFFICIENTNET B? TO USE\nEFF_NETS = [5]*FOLDS\n\n# Augmentations\nAUGMENT   = True\nTRANSFORM = True\n\n# Transormations\nROT_    = 0.0\nSHR_    = 2.0\nHZOOM_  = 8.0\nWZOOM_  = 8.0\nHSHIFT_ = 8.0\nWSHIFT_ = 8.0\n\n# Dropout\nPROBABILITY = 0.75\nCT          = 16\nSZ          = 0.08\n\n#bri, contrast\nsat  = (0.7, 1.3)\ncont = (0.8, 1.2)\nbri  =  0.1\n\n# WEIGHTS FOR FOLD MODELS WHEN PREDICTING TEST\nWGTS = [1/FOLDS]*FOLDS\n\n# TEST TIME AUGMENTATION STEPS\nTTA = 11","metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2021-05-22T17:47:01.086172Z","iopub.status.busy":"2021-05-22T17:47:01.08546Z","iopub.status.idle":"2021-05-22T17:47:01.087578Z","shell.execute_reply":"2021-05-22T17:47:01.088073Z","shell.execute_reply.started":"2021-05-20T15:20:05.967181Z"},"papermill":{"duration":0.041132,"end_time":"2021-05-22T17:47:01.088243","exception":false,"start_time":"2021-05-22T17:47:01.047111","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reproducibility\nNot very helpful for **TPU** ","metadata":{"papermill":{"duration":0.029995,"end_time":"2021-05-22T17:47:01.14883","exception":false,"start_time":"2021-05-22T17:47:01.118835","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def seeding(SEED):\n    np.random.seed(SEED)\n    random.seed(SEED)\n    os.environ['PYTHONHASHSEED'] = str(SEED)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = str(SEED)\n    tf.random.set_seed(SEED)\n    print('seeding done!!!')\nseeding(SEED)","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:01.212849Z","iopub.status.busy":"2021-05-22T17:47:01.212169Z","iopub.status.idle":"2021-05-22T17:47:01.218972Z","shell.execute_reply":"2021-05-22T17:47:01.218257Z","shell.execute_reply.started":"2021-05-20T15:20:16.739781Z"},"papermill":{"duration":0.039891,"end_time":"2021-05-22T17:47:01.219159","exception":false,"start_time":"2021-05-22T17:47:01.179268","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TPU Configs","metadata":{"papermill":{"duration":0.03094,"end_time":"2021-05-22T17:47:01.281826","exception":false,"start_time":"2021-05-22T17:47:01.250886","status":"completed"},"tags":[]}},{"cell_type":"code","source":"if DEVICE == \"TPU\":\n    print(\"connecting to TPU...\")\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        print('Running on TPU ', tpu.master())\n    except ValueError:\n        print(\"Could not connect to TPU\")\n        tpu = None\n\n    if tpu:\n        try:\n            print(\"initializing  TPU ...\")\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"TPU initialized\")\n        except _:\n            print(\"failed to initialize TPU\")\n    else:\n        DEVICE = \"GPU\"\n\nif DEVICE != \"TPU\":\n    print(\"Using default strategy for CPU and single GPU\")\n    strategy = tf.distribute.get_strategy()\n\nif DEVICE == \"GPU\":\n    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n    \n\nAUTO     = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:01.41137Z","iopub.status.busy":"2021-05-22T17:47:01.357353Z","iopub.status.idle":"2021-05-22T17:47:07.048412Z","shell.execute_reply":"2021-05-22T17:47:07.047878Z","shell.execute_reply.started":"2021-05-20T15:20:19.00466Z"},"papermill":{"duration":5.735907,"end_time":"2021-05-22T17:47:07.048561","exception":false,"start_time":"2021-05-22T17:47:01.312654","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"GCS_PATH = [None]*FOLDS\nfor i,k in enumerate(IMG_SIZES):\n    GCS_PATH[i] = KaggleDatasets().get_gcs_path('setibl-%ix%i-tfrec-dataset'%(k[0],k[1]))\nfiles_train = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/train*.tfrec')))\nfiles_test  = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[0] + '/test*.tfrec')))\nnum_train_files = len(files_train)\nnum_test_files  = len(files_test)\nprint('train_files:',num_train_files)\nprint('test_files:',num_test_files)","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:07.191186Z","iopub.status.busy":"2021-05-22T17:47:07.190447Z","iopub.status.idle":"2021-05-22T17:47:09.095843Z","shell.execute_reply":"2021-05-22T17:47:09.095057Z","shell.execute_reply.started":"2021-05-20T15:20:24.580638Z"},"papermill":{"duration":1.951259,"end_time":"2021-05-22T17:47:09.096003","exception":false,"start_time":"2021-05-22T17:47:07.144744","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntest_label_df  = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')\n\ntrain_paths = glob('../input/seti-breakthrough-listen/train/**/*.npy')\ntest_paths = glob('../input/seti-breakthrough-listen/test/**/*.npy')\n\ntrain_df = pd.DataFrame({'filepath':train_paths})\ntrain_df['id'] = train_df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\ntrain_df['group'] = train_df.filepath.map(lambda x: x.split('/')[-2])\ntrain_df = pd.merge(train_df, train_label_df, on='id', how='left')\n\nprint(f'num_train: {len(train_paths)}\\nnum_test : {len(test_paths)}')","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:09.231227Z","iopub.status.busy":"2021-05-22T17:47:09.230544Z","iopub.status.idle":"2021-05-22T17:47:13.972144Z","shell.execute_reply":"2021-05-22T17:47:13.972846Z","shell.execute_reply.started":"2021-05-20T15:20:26.32501Z"},"papermill":{"duration":4.780774,"end_time":"2021-05-22T17:47:13.973081","exception":false,"start_time":"2021-05-22T17:47:09.192307","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_mat(rotation, shear, height_zoom, width_zoom, height_shift, width_shift):\n    # returns 3x3 transformmatrix which transforms indicies\n        \n    # CONVERT DEGREES TO RADIANS\n    rotation = math.pi * rotation / 180.\n    shear    = math.pi * shear    / 180.\n\n    def get_3x3_mat(lst):\n        return tf.reshape(tf.concat([lst],axis=0), [3,3])\n    \n    # ROTATION MATRIX\n    c1   = tf.math.cos(rotation)\n    s1   = tf.math.sin(rotation)\n    one  = tf.constant([1],dtype='float32')\n    zero = tf.constant([0],dtype='float32')\n    \n    rotation_matrix = get_3x3_mat([c1,   s1,   zero, \n                                   -s1,  c1,   zero, \n                                   zero, zero, one])    \n    # SHEAR MATRIX\n    c2 = tf.math.cos(shear)\n    s2 = tf.math.sin(shear)    \n    \n    shear_matrix = get_3x3_mat([one,  s2,   zero, \n                                zero, c2,   zero, \n                                zero, zero, one])        \n    # ZOOM MATRIX\n    zoom_matrix = get_3x3_mat([one/height_zoom, zero,           zero, \n                               zero,            one/width_zoom, zero, \n                               zero,            zero,           one])    \n    # SHIFT MATRIX\n    shift_matrix = get_3x3_mat([one,  zero, height_shift, \n                                zero, one,  width_shift, \n                                zero, zero, one])\n    \n    return K.dot(K.dot(rotation_matrix, shear_matrix), \n                 K.dot(zoom_matrix,     shift_matrix))\n\n\ndef transform(image, DIM=IMG_SIZES[0]):    \n    # input image - is one image of size [dim,dim,3] not a batch of [b,dim,dim,3]\n    # output - image randomly rotated, sheared, zoomed, and shifted\n    \n    # fixed for non-square image thanks to Chris Deotte\n    DIM = [3*DIM[0], DIM[1]]\n    \n    if DIM[0]!=DIM[1]:\n        pad = (DIM[0]-DIM[1])//2\n        image = tf.pad(image, [[0, 0], [pad, pad+1],[0, 0]])\n        \n    NEW_DIM = DIM[0]\n    \n    XDIM = NEW_DIM%2 #fix for size 331\n    \n    rot = ROT_ * tf.random.normal([1], dtype='float32')\n    shr = SHR_ * tf.random.normal([1], dtype='float32') \n    h_zoom = 1.0 + tf.random.normal([1], dtype='float32') / HZOOM_\n    w_zoom = 1.0 + tf.random.normal([1], dtype='float32') / WZOOM_\n    h_shift = HSHIFT_ * tf.random.normal([1], dtype='float32') \n    w_shift = WSHIFT_ * tf.random.normal([1], dtype='float32') \n\n    # GET TRANSFORMATION MATRIX\n    m = get_mat(rot,shr,h_zoom,w_zoom,h_shift,w_shift) \n\n    # LIST DESTINATION PIXEL INDICES\n    x   = tf.repeat(tf.range(NEW_DIM//2, -NEW_DIM//2,-1), NEW_DIM)\n    y   = tf.tile(tf.range(-NEW_DIM//2, NEW_DIM//2), [NEW_DIM])\n    z   = tf.ones([NEW_DIM*NEW_DIM], dtype='int32')\n    idx = tf.stack( [x,y,z] )\n    \n    # ROTATE DESTINATION PIXELS ONTO ORIGIN PIXELS\n    idx2 = K.dot(m, tf.cast(idx, dtype='float32'))\n    idx2 = K.cast(idx2, dtype='int32')\n    idx2 = K.clip(idx2, -NEW_DIM//2+XDIM+1, NEW_DIM//2)\n    \n    # FIND ORIGIN PIXEL VALUES           \n    idx3 = tf.stack([NEW_DIM//2-idx2[0,], NEW_DIM//2-1+idx2[1,]])\n    d    = tf.gather_nd(image, tf.transpose(idx3))\n    \n    if DIM[0]!=DIM[1]:\n        image = tf.reshape(d,[NEW_DIM, NEW_DIM,3])\n        image = image[:, pad:DIM[1]+pad,:]\n    image = tf.reshape(image, [*DIM, 3])\n        \n    return image","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:16.392243Z","iopub.status.busy":"2021-05-22T17:47:16.391524Z","iopub.status.idle":"2021-05-22T17:47:16.413261Z","shell.execute_reply":"2021-05-22T17:47:16.412717Z","shell.execute_reply.started":"2021-05-20T15:20:32.230225Z"},"papermill":{"duration":0.063051,"end_time":"2021-05-22T17:47:16.41341","exception":false,"start_time":"2021-05-22T17:47:16.350359","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_labeled_tfrecord(example):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_id'                     : tf.io.FixedLenFeature([], tf.string),\n        'target'                       : tf.io.FixedLenFeature([], tf.int64)\n    }           \n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['image'], example['target']\n\n\ndef read_unlabeled_tfrecord(example, return_image_id):\n    tfrec_format = {\n        'image'                        : tf.io.FixedLenFeature([], tf.string),\n        'image_id'                     : tf.io.FixedLenFeature([], tf.string),\n    }\n    example = tf.io.parse_single_example(example, tfrec_format)\n    return example['image'], example['image_id'] if return_image_id else 0\n\n \ndef prepare_image(img, augment=True, dim=IMG_SIZES[0]):    \n    img = tf.image.decode_png(img, channels=3)\n    \n    # converting channel information to spatial information\n    img = tf.concat([img[...,idx] for idx in range(3)], axis=0)\n    img = tf.stack([img for _ in range(3)], axis=-1)\n    img = tf.reshape(img, [dim[0]*3,dim[1], 3])\n    \n    img = tf.cast(img, tf.float32) / 255.0\n    \n    if augment:\n        img = transform(img,DIM=dim) if TRANSFORM else img\n        img = tf.image.random_flip_left_right(img)\n        #img = tf.image.random_hue(img, 0.01)\n        img = tf.image.random_saturation(img, sat[0], sat[1])\n        img = tf.image.random_contrast(img, cont[0], cont[1])\n        img = tf.image.random_brightness(img, bri)      \n                      \n    img = tf.reshape(img, [dim[0]*3,dim[1], 3])\n            \n    return img\n\ndef count_data_items(fileids):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1)) \n         for fileid in fileids]\n    return np.sum(n)","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:16.740258Z","iopub.status.busy":"2021-05-22T17:47:16.739566Z","iopub.status.idle":"2021-05-22T17:47:16.752565Z","shell.execute_reply":"2021-05-22T17:47:16.753139Z","shell.execute_reply.started":"2021-05-20T15:20:32.278503Z"},"papermill":{"duration":0.054877,"end_time":"2021-05-22T17:47:16.753316","exception":false,"start_time":"2021-05-22T17:47:16.698439","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data Pipeline","metadata":{"papermill":{"duration":0.03899,"end_time":"2021-05-22T17:47:16.831224","exception":false,"start_time":"2021-05-22T17:47:16.792234","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def get_dataset(files, augment = False, shuffle = False, repeat = False, \n                labeled=True, return_image_ids=True, batch_size=16, dim=IMG_SIZES[0]):\n    \n    ds = tf.data.TFRecordDataset(files, num_parallel_reads=AUTO)\n    ds = ds.cache()\n    \n    if repeat:\n        ds = ds.repeat()\n    \n    if shuffle: \n        ds = ds.shuffle(1024*2, seed=SEED)\n        opt = tf.data.Options()\n        opt.experimental_deterministic = False\n        ds = ds.with_options(opt)\n        \n    if labeled: \n        ds = ds.map(read_labeled_tfrecord, num_parallel_calls=AUTO)\n    else:\n        ds = ds.map(lambda example: read_unlabeled_tfrecord(example, return_image_ids), \n                    num_parallel_calls=AUTO)      \n    \n    ds = ds.map(lambda img, imgid_or_label: (prepare_image(img, augment=augment, dim=dim), \n                                               imgid_or_label), \n                num_parallel_calls=AUTO)\n    if labeled and augment:\n        ds = ds.map(lambda img, label: (dropout(img, DIM=dim, PROBABILITY = PROBABILITY, CT = CT, SZ = SZ), label),\n                    num_parallel_calls=AUTO)\n    \n    ds = ds.batch(batch_size * REPLICAS)\n    ds = ds.prefetch(AUTO)\n    return ds","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:16.911936Z","iopub.status.busy":"2021-05-22T17:47:16.911198Z","iopub.status.idle":"2021-05-22T17:47:16.920636Z","shell.execute_reply":"2021-05-22T17:47:16.921235Z","shell.execute_reply.started":"2021-05-20T15:20:32.295527Z"},"papermill":{"duration":0.051437,"end_time":"2021-05-22T17:47:16.921412","exception":false,"start_time":"2021-05-22T17:47:16.869975","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualization\n","metadata":{"papermill":{"duration":0.038751,"end_time":"2021-05-22T17:47:16.9999","exception":false,"start_time":"2021-05-22T17:47:16.961149","status":"completed"},"tags":[]}},{"cell_type":"code","source":"def display_batch(batch, size=3):\n    imgs, tars = batch\n    idx=0\n    for img_idx in range(size):\n        idx+=1\n        plt.figure(figsize=(5*2, 15*2))\n        plt.subplot(size, 1, idx)\n        plt.title(f'id:{tars[img_idx].numpy().decode(\"utf-8\")}')\n        plt.imshow(imgs[img_idx,:, :, 0].numpy().transpose(1, 0))\n        plt.text(5, 15, str(idx), bbox={'facecolor': 'white'})\n        plt.xticks([])\n        plt.yticks([])\n        plt.tight_layout()\n        plt.show()\n    plt.savefig('fig.png') if idx==1 else None","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:17.081871Z","iopub.status.busy":"2021-05-22T17:47:17.081213Z","iopub.status.idle":"2021-05-22T17:47:17.088227Z","shell.execute_reply":"2021-05-22T17:47:17.088744Z","shell.execute_reply.started":"2021-05-20T15:20:32.316927Z"},"papermill":{"duration":0.049451,"end_time":"2021-05-22T17:47:17.088912","exception":false,"start_time":"2021-05-22T17:47:17.039461","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 0\nds = get_dataset(files_train, augment=True, shuffle=True, repeat=True,labeled=False,return_image_ids=True,\n                dim=IMG_SIZES[fold], batch_size = BATCH_SIZES[fold])\nds = ds.unbatch().batch(20)\nbatch = next(iter(ds))\ndisplay_batch(batch, 3);","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:17.170706Z","iopub.status.busy":"2021-05-22T17:47:17.170069Z","iopub.status.idle":"2021-05-22T17:47:22.0549Z","shell.execute_reply":"2021-05-22T17:47:22.055388Z","shell.execute_reply.started":"2021-05-20T15:20:32.79579Z"},"papermill":{"duration":4.927572,"end_time":"2021-05-22T17:47:22.055553","exception":false,"start_time":"2021-05-22T17:47:17.127981","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = get_dataset(files_train, augment=True, shuffle=True, repeat=True,labeled=True,return_image_ids=True,\n                dim=IMG_SIZES[fold], batch_size = BATCH_SIZES[fold])\nds = ds.unbatch().batch(20)\nbatch = next(iter(ds))","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:22.164794Z","iopub.status.busy":"2021-05-22T17:47:22.164157Z","iopub.status.idle":"2021-05-22T17:47:26.656597Z","shell.execute_reply":"2021-05-22T17:47:26.655495Z","shell.execute_reply.started":"2021-05-20T15:20:38.890266Z"},"papermill":{"duration":4.548091,"end_time":"2021-05-22T17:47:26.656796","exception":false,"start_time":"2021-05-22T17:47:22.108705","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EFNS = [efn.EfficientNetB0, efn.EfficientNetB1, efn.EfficientNetB2, efn.EfficientNetB3, \n        efn.EfficientNetB4, efn.EfficientNetB5, efn.EfficientNetB6, efn.EfficientNetB7]\n\ndef build_model(dim=IMG_SIZES[0],ef = 0):\n    dim = [dim[0]*3, dim[1]]\n    inp = tf.keras.layers.Input(shape=(*dim,3))\n    base = EFNS[ef](input_shape=(*dim,3),weights='imagenet',include_top=False)\n    x = base(inp)\n    CAN  = ChannelAttentionModule()\n    SPN = SpatialAttentionModule()\n    AWG  = AttentionWeightedAverage2D()\n    canx   = CAN(x)*x\n    spnx   = SPN(canx)*canx\n    gapx = tf.keras.layers.GlobalAveragePooling2D()(spnx)\n    wvgx   = tf.keras.layers.GlobalAveragePooling2D()(SPN(canx))\n    avg = tf.keras.layers.Average()([gapx, wvgx])\n    awg = AWG(x)\n    x = tf.keras.layers.Add()([avg, awg])\n    x = tf.keras.layers.BatchNormalization()(x)\n    \n#     x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    x = tf.keras.layers.Dense(32, activation = 'relu')(x)\n    x = tf.keras.layers.Dense(1,activation='sigmoid')(x)\n    model = tf.keras.Model(inputs=inp,outputs=x)\n    opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=0.01) \n    model.compile(optimizer=opt,loss=loss,metrics=['AUC'])\n    return model","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:27.003158Z","iopub.status.busy":"2021-05-22T17:47:27.002411Z","iopub.status.idle":"2021-05-22T17:47:27.005851Z","shell.execute_reply":"2021-05-22T17:47:27.005316Z","shell.execute_reply.started":"2021-05-20T15:26:10.724689Z"},"papermill":{"duration":0.069032,"end_time":"2021-05-22T17:47:27.005994","exception":false,"start_time":"2021-05-22T17:47:26.936962","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = build_model(dim=IMG_SIZES[fold],ef=EFF_NETS[fold])","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:27.118715Z","iopub.status.busy":"2021-05-22T17:47:27.116715Z","iopub.status.idle":"2021-05-22T17:47:35.979023Z","shell.execute_reply":"2021-05-22T17:47:35.979672Z","shell.execute_reply.started":"2021-05-20T15:26:13.03268Z"},"papermill":{"duration":8.921291,"end_time":"2021-05-22T17:47:35.979845","exception":false,"start_time":"2021-05-22T17:47:27.058554","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.execute_input":"2021-05-22T17:47:36.102864Z","iopub.status.busy":"2021-05-22T17:47:36.102237Z","iopub.status.idle":"2021-05-22T17:47:36.150862Z","shell.execute_reply":"2021-05-22T17:47:36.149858Z","shell.execute_reply.started":"2021-05-20T15:26:34.873215Z"},"papermill":{"duration":0.111418,"end_time":"2021-05-22T17:47:36.151057","exception":false,"start_time":"2021-05-22T17:47:36.039639","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_lr_callback(batch_size=8, plot=False):\n    lr_start   = 0.000005\n    lr_max     = 0.00000125 * REPLICAS * batch_size\n    lr_min     = 0.000001\n    lr_ramp_ep = 5\n    lr_sus_ep  = 0\n    lr_decay   = 0.8\n   \n    def lrfn(epoch):\n        if epoch < lr_ramp_ep:\n            lr = (lr_max - lr_start) / lr_ramp_ep * epoch + lr_start\n            \n        elif epoch < lr_ramp_ep + lr_sus_ep:\n            lr = lr_max\n            \n        else:\n            lr = (lr_max - lr_min) * lr_decay**(epoch - lr_ramp_ep - lr_sus_ep) + lr_min\n            \n        return lr\n    if plot:\n        plt.figure(figsize=(10,5))\n        plt.plot(np.arange(EPOCHS[0]), [lrfn(epoch) for epoch in np.arange(EPOCHS[0])], marker='o')\n        plt.xlabel('epoch'); plt.ylabel('learnig rate')\n        plt.title('Learning Rate Scheduler')\n        plt.show()\n\n    lr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=False)\n    return lr_callback\n\n_=get_lr_callback(BATCH_SIZES[0], plot=True )","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:36.44871Z","iopub.status.busy":"2021-05-22T17:47:36.432997Z","iopub.status.idle":"2021-05-22T17:47:36.570365Z","shell.execute_reply":"2021-05-22T17:47:36.569837Z","shell.execute_reply.started":"2021-05-20T15:28:32.907387Z"},"papermill":{"duration":0.234008,"end_time":"2021-05-22T17:47:36.570499","exception":false,"start_time":"2021-05-22T17:47:36.336491","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = KFold(n_splits=FOLDS,shuffle=True,random_state=SEED)\noof_pred = []; oof_tar = []; oof_val = []; oof_f1 = []; oof_ids = []; oof_folds = [] \npreds = np.zeros((count_data_items(files_test),1))\n\nfor fold,(idxT,idxV) in enumerate(skf.split(np.arange(num_train_files))):\n    # DISPLAY FOLD INFO\n    if DEVICE=='TPU':\n        if tpu: tf.tpu.experimental.initialize_tpu_system(tpu)\n    \n    # CREATE TRAIN AND VALIDATION SUBSETS\n    files_train = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in idxT])\n    np.random.shuffle(files_train);\n    files_valid = tf.io.gfile.glob([GCS_PATH[fold] + '/train%.2i*.tfrec'%x for x in idxV])\n    files_test = np.sort(np.array(tf.io.gfile.glob(GCS_PATH[fold] + '/test*.tfrec')))\n    \n    print('#'*25); print('#### FOLD',fold+1)\n    print('#### Image Size: (%i, %i) | model: %s | batch_size %i'%\n          (IMG_SIZES[fold][0]*3,IMG_SIZES[fold][1],EFNS[EFF_NETS[fold]].__name__,BATCH_SIZES[fold]*REPLICAS))\n    train_images = count_data_items(files_train)\n    val_images   = count_data_items(files_valid)\n    print('#### Training: %i | Validation: %i'%(train_images, val_images))\n    \n    # BUILD MODEL\n    K.clear_session()\n    with strategy.scope():\n        model = build_model(dim=IMG_SIZES[fold],ef=EFF_NETS[fold])\n    print('#'*25)   \n    # SAVE BEST MODEL EACH FOLD\n    sv = tf.keras.callbacks.ModelCheckpoint(\n        'fold-%i.h5'%fold, monitor='val_auc', verbose=0, save_best_only=True,\n        save_weights_only=True, mode='max', save_freq='epoch')\n   \n    # TRAIN\n    print('Training...')\n    history = model.fit(\n        get_dataset(files_train, augment=AUGMENT, shuffle=True, repeat=True,\n                dim=IMG_SIZES[fold], batch_size = BATCH_SIZES[fold]), \n        epochs=EPOCHS[fold], \n        callbacks = [sv,get_lr_callback(BATCH_SIZES[fold])], \n        steps_per_epoch=count_data_items(files_train)/BATCH_SIZES[fold]//REPLICAS,\n        validation_data=get_dataset(files_valid,augment=False,shuffle=False,\n                repeat=False,dim=IMG_SIZES[fold]), \n        #class_weight = {0:1,1:2},\n        verbose=VERBOSE\n    )\n    \n    # Loading best model for inference\n    print('Loading best model...')\n    model.load_weights('fold-%i.h5'%fold)  \n    \n    # PREDICT OOF USING TTA\n    print('Predicting OOF with TTA...')\n    ds_valid = get_dataset(files_valid,labeled=False,return_image_ids=False,augment=AUGMENT,\n            repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold]*2)\n    ct_valid = count_data_items(files_valid); STEPS = TTA * ct_valid/BATCH_SIZES[fold]/2/REPLICAS\n    pred = model.predict(ds_valid,steps=STEPS,verbose=VERBOSE)[:TTA*ct_valid,] \n    oof_pred.append( np.mean(pred.reshape((ct_valid,TTA),order='F'),axis=1) )                 \n    \n    # GET OOF TARGETS AND idS\n    ds_valid = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n            labeled=True, return_image_ids=True)\n    oof_tar.append( np.array([target.numpy() for img, target in iter(ds_valid.unbatch())]) )\n    oof_folds.append( np.ones_like(oof_tar[-1],dtype='int8')*fold )\n    ds = get_dataset(files_valid, augment=False, repeat=False, dim=IMG_SIZES[fold],\n                labeled=False, return_image_ids=True)\n    oof_ids.append( np.array([img_id.numpy().decode(\"utf-8\") for img, img_id in iter(ds.unbatch())]))\n    \n    # PREDICT TEST USING TTA\n    print('Predicting Test with TTA...')\n    ds_test = get_dataset(files_test,labeled=False,return_image_ids=False,augment=AUGMENT,\n            repeat=True,shuffle=False,dim=IMG_SIZES[fold],batch_size=BATCH_SIZES[fold]*2)\n    ct_test = count_data_items(files_test); STEPS = TTA * ct_test/BATCH_SIZES[fold]/2/REPLICAS\n    pred = model.predict(ds_test,steps=STEPS,verbose=VERBOSE)[:TTA*ct_test,] \n    preds[:,0] += np.mean(pred.reshape((ct_test,TTA),order='F'),axis=1) * WGTS[fold]\n    \n    # REPORT RESULTS\n    auc = roc_auc_score(oof_tar[-1],oof_pred[-1])\n    oof_val.append(np.max( history.history['val_auc'] ))\n    print('#### FOLD %i OOF AUC without TTA = %.3f, with TTA = %.3f'%(fold+1,oof_val[-1],auc))\n    \n    # PLOT TRAINING\n    if DISPLAY_PLOT:\n        plt.figure(figsize=(15,5))\n        plt.plot(np.arange(len(history.history['auc'])),history.history['auc'],'-o',label='Train auc',color='#ff7f0e')\n        plt.plot(np.arange(len(history.history['auc'])),history.history['val_auc'],'-o',label='Val auc',color='#1f77b4')\n        x = np.argmax( history.history['val_auc'] ); y = np.max( history.history['val_auc'] )\n        xdist = plt.xlim()[1] - plt.xlim()[0]; ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=200,color='#1f77b4'); plt.text(x-0.03*xdist,y-0.13*ydist,'max auc\\n%.2f'%y,size=14)\n        plt.ylabel('auc',size=14); plt.xlabel('Epoch',size=14)\n        plt.legend(loc=2)\n        plt2 = plt.gca().twinx()\n        plt2.plot(np.arange(len(history.history['auc'])),history.history['loss'],'-o',label='Train Loss',color='#2ca02c')\n        plt2.plot(np.arange(len(history.history['auc'])),history.history['val_loss'],'-o',label='Val Loss',color='#d62728')\n        x = np.argmin( history.history['val_loss'] ); y = np.min( history.history['val_loss'] )\n        ydist = plt.ylim()[1] - plt.ylim()[0]\n        plt.scatter(x,y,s=200,color='#d62728'); plt.text(x-0.03*xdist,y+0.05*ydist,'min loss',size=14)\n        plt.ylabel('Loss',size=14)\n        plt.title('FOLD %i - Image Size (%i, %i), %s'%\n                (fold+1,IMG_SIZES[fold][0]*3,IMG_SIZES[fold][1],EFNS[EFF_NETS[fold]].__name__),size=18)\n        plt.legend(loc=3)\n        plt.savefig(f'fig{fold}.png')\n        plt.show()","metadata":{"_kg_hide-input":true,"execution":{"iopub.execute_input":"2021-05-22T17:47:36.851714Z","iopub.status.busy":"2021-05-22T17:47:36.843711Z","iopub.status.idle":"2021-05-23T00:48:38.819152Z","shell.execute_reply":"2021-05-23T00:48:38.818494Z"},"papermill":{"duration":25262.067771,"end_time":"2021-05-23T00:48:38.821408","exception":false,"start_time":"2021-05-22T17:47:36.753637","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# COMPUTE OVERALL OOF AUC\noof = np.concatenate(oof_pred); true = np.concatenate(oof_tar);\nids = np.concatenate(oof_ids); folds = np.concatenate(oof_folds)\nauc = roc_auc_score(true,oof)\nprint('Overall OOF AUC with TTA = %.3f'%auc)\n\n# SAVE OOF TO DISK\ndf_oof = pd.DataFrame(dict(image_id = ids, target=true, pred = oof, fold=folds))\ndf_oof.to_csv('oof.csv',index=False)\ndf_oof.head()","metadata":{"execution":{"iopub.execute_input":"2021-05-23T00:48:39.012394Z","iopub.status.busy":"2021-05-23T00:48:39.01141Z","iopub.status.idle":"2021-05-23T00:48:39.338329Z","shell.execute_reply":"2021-05-23T00:48:39.337692Z"},"papermill":{"duration":0.434465,"end_time":"2021-05-23T00:48:39.338469","exception":false,"start_time":"2021-05-23T00:48:38.904004","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds = get_dataset(files_test, augment=False, repeat=False, dim=IMG_SIZES[fold],\n                 labeled=False, return_image_ids=True)\n\nimage_ids = np.array([img_id.numpy().decode(\"utf-8\") \n                        for img, img_id in iter(ds.unbatch())])","metadata":{"execution":{"iopub.execute_input":"2021-05-23T00:48:39.83867Z","iopub.status.busy":"2021-05-23T00:48:39.837896Z","iopub.status.idle":"2021-05-23T00:50:30.373029Z","shell.execute_reply":"2021-05-23T00:50:30.372398Z"},"papermill":{"duration":110.625228,"end_time":"2021-05-23T00:50:30.373193","exception":false,"start_time":"2021-05-23T00:48:39.747965","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.DataFrame({'id':image_ids, 'target':preds[:,0]})\nsubmission = submission.sort_values('id') \nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","metadata":{"execution":{"iopub.execute_input":"2021-05-23T00:50:30.550028Z","iopub.status.busy":"2021-05-23T00:50:30.548951Z","iopub.status.idle":"2021-05-23T00:50:30.769998Z","shell.execute_reply":"2021-05-23T00:50:30.769356Z"},"papermill":{"duration":0.313692,"end_time":"2021-05-23T00:50:30.770136","exception":false,"start_time":"2021-05-23T00:50:30.456444","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,5))\nplt.hist(submission.target,bins=100);","metadata":{"execution":{"iopub.execute_input":"2021-05-23T00:50:31.104754Z","iopub.status.busy":"2021-05-23T00:50:31.103144Z","iopub.status.idle":"2021-05-23T00:50:31.433179Z","shell.execute_reply":"2021-05-23T00:50:31.432589Z"},"papermill":{"duration":0.417198,"end_time":"2021-05-23T00:50:31.43333","exception":false,"start_time":"2021-05-23T00:50:31.016132","status":"completed"},"tags":[]},"execution_count":null,"outputs":[]}]}