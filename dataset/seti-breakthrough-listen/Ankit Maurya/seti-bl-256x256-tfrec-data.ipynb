{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"SEED  = 42\nFOLDS = 20\nDIM   = 256","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-07-16T10:39:02.389711Z","iopub.execute_input":"2021-07-16T10:39:02.390111Z","iopub.status.idle":"2021-07-16T10:39:02.399091Z","shell.execute_reply.started":"2021-07-16T10:39:02.390026Z","shell.execute_reply":"2021-07-16T10:39:02.397928Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing Packages","metadata":{}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os, shutil\nfrom glob import glob\nfrom sklearn.cluster import KMeans\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import LabelEncoder","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:02.418488Z","iopub.execute_input":"2021-07-16T10:39:02.418853Z","iopub.status.idle":"2021-07-16T10:39:03.627488Z","shell.execute_reply.started":"2021-07-16T10:39:02.418817Z","shell.execute_reply":"2021-07-16T10:39:03.626819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_label_df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\ntest_label_df  = pd.read_csv('../input/seti-breakthrough-listen/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:03.628641Z","iopub.execute_input":"2021-07-16T10:39:03.628961Z","iopub.status.idle":"2021-07-16T10:39:03.721157Z","shell.execute_reply.started":"2021-07-16T10:39:03.62893Z","shell.execute_reply":"2021-07-16T10:39:03.720249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_paths = glob('../input/seti-breakthrough-listen/train/**/*.npy')\ntest_paths = glob('../input/seti-breakthrough-listen/test/**/*.npy')\nlen(train_paths), len(test_paths)","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:17.494292Z","iopub.execute_input":"2021-07-16T10:39:17.494621Z","iopub.status.idle":"2021-07-16T10:39:21.463585Z","shell.execute_reply.started":"2021-07-16T10:39:17.49459Z","shell.execute_reply":"2021-07-16T10:39:21.462783Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df = pd.DataFrame({'filepath':train_paths})\ntrain_df['id'] = train_df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\ntrain_df['group'] = train_df.filepath.map(lambda x: x.split('/')[-2])\ntrain_df = pd.merge(train_df, train_label_df, on='id', how='left')\ntrain_df['group_target'] = train_df.group+train_df.target.astype(str)\ntrain_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:24.641578Z","iopub.execute_input":"2021-07-16T10:39:24.641944Z","iopub.status.idle":"2021-07-16T10:39:24.882943Z","shell.execute_reply.started":"2021-07-16T10:39:24.641911Z","shell.execute_reply":"2021-07-16T10:39:24.881971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = pd.DataFrame({'filepath':test_paths})\ntest_df['id'] = test_df.filepath.map(lambda x: x.split('/')[-1].split('.')[0])\ntest_df['group'] = test_df.filepath.map(lambda x: x.split('/')[-2])\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:35.194082Z","iopub.execute_input":"2021-07-16T10:39:35.194424Z","iopub.status.idle":"2021-07-16T10:39:35.253797Z","shell.execute_reply.started":"2021-07-16T10:39:35.194394Z","shell.execute_reply":"2021-07-16T10:39:35.253036Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check The Data","metadata":{}},{"cell_type":"code","source":"train_df.target.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:37.169667Z","iopub.execute_input":"2021-07-16T10:39:37.170173Z","iopub.status.idle":"2021-07-16T10:39:37.180282Z","shell.execute_reply.started":"2021-07-16T10:39:37.170141Z","shell.execute_reply":"2021-07-16T10:39:37.179057Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.group.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:38.061683Z","iopub.execute_input":"2021-07-16T10:39:38.062068Z","iopub.status.idle":"2021-07-16T10:39:38.07636Z","shell.execute_reply.started":"2021-07-16T10:39:38.062033Z","shell.execute_reply":"2021-07-16T10:39:38.075393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.groupby(['group','target'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:38.754611Z","iopub.execute_input":"2021-07-16T10:39:38.755189Z","iopub.status.idle":"2021-07-16T10:39:38.778483Z","shell.execute_reply.started":"2021-07-16T10:39:38.755144Z","shell.execute_reply":"2021-07-16T10:39:38.77771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Stratified KFold by Groups","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\ntrain_df['fold'] = -1\nfor fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):\n    train_df.loc[val_idx,'fold'] = fold\n# train_df.groupby(['fold', 'target'])['id'].count()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:40.50493Z","iopub.execute_input":"2021-07-16T10:39:40.505517Z","iopub.status.idle":"2021-07-16T10:39:40.547986Z","shell.execute_reply.started":"2021-07-16T10:39:40.505481Z","shell.execute_reply":"2021-07-16T10:39:40.547177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Check the signals\nFrom the [dataset information](https://www.kaggle.com/c/seti-breakthrough-listen/overview/data-information),\n>>\nNot all of the “needle” signals look like diagonal lines, and they may not be present for the entirety of all three “A” observations, but what they do have in common is that they are only present in some or all of the “A” observations (panels **1**, **3**, and **5** in the cadence snippets).\n\n","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt, cv2\n\ndef load_signal(filepath, dim=DIM):\n    sgnl = np.load(filepath)\n    sgnl = sgnl[::2,] # we're taking only 1, 3, 5\n    img  = np.moveaxis(sgnl, 0, -1)\n    img  = img.astype(np.float32)\n    if dim is not None:\n        img = cv2.resize(img, dsize=(dim, dim), interpolation=cv2.INTER_NEAREST)\n    return img\n\ndef visualize(sgnl):\n    sgnl = sgnl.astype(float)\n    plt.figure(figsize=(20, 10))\n    for idx in range(3):\n        plt.subplot(2, 6, idx+1)\n        plt.imshow(sgnl[...,idx])\n        plt.axis('OFF')\n    plt.tight_layout()\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:42.705999Z","iopub.execute_input":"2021-07-16T10:39:42.706605Z","iopub.status.idle":"2021-07-16T10:39:42.867499Z","shell.execute_reply.started":"2021-07-16T10:39:42.706569Z","shell.execute_reply":"2021-07-16T10:39:42.866808Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualize Channels","metadata":{}},{"cell_type":"markdown","source":"## No Resize","metadata":{}},{"cell_type":"code","source":"sgnl = load_signal(train_df[train_df.target==1].filepath.iloc[2], dim=None)\nvisualize(sgnl)\nsgnl.shape, sgnl.dtype","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:45.641066Z","iopub.execute_input":"2021-07-16T10:39:45.641419Z","iopub.status.idle":"2021-07-16T10:39:46.070607Z","shell.execute_reply.started":"2021-07-16T10:39:45.641389Z","shell.execute_reply":"2021-07-16T10:39:46.069937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resize","metadata":{}},{"cell_type":"code","source":"sgnl = load_signal(train_df[train_df.target==1].filepath.iloc[2], dim=DIM)\nvisualize(sgnl)\nsgnl.shape, sgnl.dtype","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:39:50.344487Z","iopub.execute_input":"2021-07-16T10:39:50.345064Z","iopub.status.idle":"2021-07-16T10:39:50.798093Z","shell.execute_reply.started":"2021-07-16T10:39:50.345017Z","shell.execute_reply":"2021-07-16T10:39:50.797044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# TFRecord Data","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\ndef _bytes_feature(value):\n    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n    if isinstance(value, type(tf.constant(0))):\n        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    \"\"\"Returns a float_list from a float / double.\"\"\"\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:40:48.877858Z","iopub.execute_input":"2021-07-16T10:40:48.878189Z","iopub.status.idle":"2021-07-16T10:40:54.61907Z","shell.execute_reply.started":"2021-07-16T10:40:48.878161Z","shell.execute_reply":"2021-07-16T10:40:54.617892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writng TFRecord (Train)","metadata":{}},{"cell_type":"code","source":"def train_serialize_example(feature0, feature1, feature2, feature3):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n      'group'         : _bytes_feature(feature2),    \n      'target'        : _int64_feature(feature3),\n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:40:54.620743Z","iopub.execute_input":"2021-07-16T10:40:54.621163Z","iopub.status.idle":"2021-07-16T10:40:54.626926Z","shell.execute_reply.started":"2021-07-16T10:40:54.621118Z","shell.execute_reply":"2021-07-16T10:40:54.625948Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show=True\nfolds = train_df.fold.unique().tolist()\nfor fold in tqdm(folds): # create tfrecord for each fold\n    fold_df = train_df[train_df.fold==fold]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('train%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n#         samples = 200\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it: # images in fold\n            row = fold_df.iloc[k,:]\n            image      = load_signal(row['filepath'], dim=DIM)\n            image      = image[...,::-1] # rgb -> bgr, we'll get the rgb form after decoding the tfrec\n            image_id   = row['id']\n            group      = row['group']\n            target     = np.array(row['target'], dtype=np.uint8)\n            example  = train_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id),\n                str.encode(group),\n                target,\n                )\n            writer.write(example)\n        if show:\n            filepath = 'train%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('/')[-1]\n            filesize = os.path.getsize(filepath)/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","metadata":{"execution":{"iopub.status.busy":"2021-07-16T10:40:54.629275Z","iopub.execute_input":"2021-07-16T10:40:54.629806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Writing TFRecord (Test)","metadata":{}},{"cell_type":"code","source":"def test_serialize_example(feature0, feature1, feature2):\n    feature = {\n      'image'         : _bytes_feature(feature0),\n      'image_id'      : _bytes_feature(feature1),\n      'group'         : _bytes_feature(feature2),    \n  }\n    example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n    return example_proto.SerializeToString()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show  = True\nfolds = 10\nl     = int(np.ceil(test_df.shape[0]/folds))\nfor fold in tqdm(range(folds)): # create tfrecord for each fold\n    fold_df = test_df.iloc[l*fold:l*(fold+1)]\n    if show:\n        print(); print('Writing TFRecord of fold %i :'%(fold))  \n    with tf.io.TFRecordWriter('test%.2i-%i.tfrec'%(fold,fold_df.shape[0])) as writer:\n        samples = fold_df.shape[0]\n#         samples = 200\n        it = tqdm(range(samples)) if show else range(samples)\n        for k in it: # images in fold\n            row = fold_df.iloc[k,:]\n            image      = load_signal(row['filepath'], dim=DIM)\n            image      = image[...,::-1] # rgb -> bgr, we'll get the rgb form after decoding the tfrec\n            image_id   = row['id']\n            group      = row['group']\n            example  = test_serialize_example(\n                cv2.imencode('.png', image)[1].tobytes(),\n                str.encode(image_id),\n                str.encode(group),\n                )\n            writer.write(example)\n        if show:\n            filepath = 'test%.2i-%i.tfrec'%(fold,fold_df.shape[0])\n            filename = filepath.split('/')[-1]\n            filesize = os.path.getsize(filepath)/10**6\n            print(filename,':',np.around(filesize, 2),'MB')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Reading TFRecord","metadata":{}},{"cell_type":"code","source":"import re, math\ndef decode_image(image_data):\n    image = tf.image.decode_png(image_data, channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n    return image\ndef prepare_target(target):    \n    target = tf.cast(target, tf.float32)            \n    target = tf.reshape(target, [1])         \n    return target\n\ndef read_labeled_tfrecord(example):\n    LABELED_TFREC_FORMAT = {\n        \"image\" : tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n        \"target\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n    }\n    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n    image = decode_image(example['image'])\n    image  = tf.reshape(image, [DIM, DIM, 3])\n    target = prepare_target(example['target'])\n    return image, target # returns a dataset of (image, label) pairs\n\ndef load_dataset(fileids, labeled=True, ordered=False):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    if not ordered:\n        ignore_order.experimental_deterministic = False # disable order, increase speed\n\n    dataset = tf.data.TFRecordDataset(fileids, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_labeled_tfrecord)\n    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n    return dataset\n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n    dataset = dataset.shuffle(20, seed=SEED)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef count_data_items(fileids):\n    # the number of data items is written in the id of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fileid).group(1)) for fileid in fileids]\n    return np.sum(n)","metadata":{"_kg_hide-input":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visual","metadata":{}},{"cell_type":"code","source":"def display_batch(batch, size=2):\n    imgs, tars = batch\n    for img_idx in range(size):\n        plt.figure(figsize=(4*2, 12*2))\n        for idx in range(3):\n            plt.subplot(size, 3, idx+1)\n            plt.title(f'Target:{tars[img_idx].numpy()[0]}')\n            plt.imshow(imgs[img_idx,:, :, idx])\n            plt.text(5, 10, str(idx), bbox={'facecolor': 'white'})\n            plt.xticks([])\n            plt.yticks([])\n        plt.tight_layout()\n        plt.show() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Total Images","metadata":{}},{"cell_type":"code","source":"# INITIALIZE VARIABLES\nIMAGE_SIZE= [DIM,DIM];\nBATCH_SIZE = 32\nAUTO = tf.data.experimental.AUTOTUNE\nTRAINING_FILENAMES = tf.io.gfile.glob('train*.tfrec')\nTEST_FILENAMES     = tf.io.gfile.glob('test*.tfrec')\nprint('There are %i train & %i test images'%(count_data_items(TRAINING_FILENAMES), count_data_items(TEST_FILENAMES)))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Once Batch Image","metadata":{}},{"cell_type":"code","source":"# DISPLAY TRAIN IMAGES\ntraining_dataset = get_training_dataset()\ntraining_dataset = training_dataset.unbatch().batch(20)\ntrain_batch = next(iter(training_dataset))\ndisplay_batch(train_batch, 2);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img, label = train_batch\nnp.unique(label.numpy(), return_counts=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}