{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install timm","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:21:55.836471Z","iopub.execute_input":"2021-08-12T11:21:55.836953Z","iopub.status.idle":"2021-08-12T11:22:04.287042Z","shell.execute_reply.started":"2021-08-12T11:21:55.836915Z","shell.execute_reply":"2021-08-12T11:22:04.285649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!git clone https://github.com/lessw2020/Ranger-Deep-Learning-Optimizer.git","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:04.291592Z","iopub.execute_input":"2021-08-12T11:22:04.291899Z","iopub.status.idle":"2021-08-12T11:22:05.097675Z","shell.execute_reply.started":"2021-08-12T11:22:04.291864Z","shell.execute_reply":"2021-08-12T11:22:05.095277Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append('./Ranger-Deep-Learning-Optimizer')","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.102668Z","iopub.execute_input":"2021-08-12T11:22:05.105557Z","iopub.status.idle":"2021-08-12T11:22:05.119429Z","shell.execute_reply.started":"2021-08-12T11:22:05.105485Z","shell.execute_reply":"2021-08-12T11:22:05.115539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport cv2\nfrom collections import defaultdict\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data\nfrom torch.utils.data import Dataset,DataLoader\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torch.optim.optimizer import Optimizer, required\n\nfrom transformers import AdamW\nfrom transformers import get_linear_schedule_with_warmup,get_cosine_schedule_with_warmup\nfrom transformers import get_cosine_with_hard_restarts_schedule_with_warmup,get_constant_schedule_with_warmup\n\nimport timm\nfrom ranger.ranger2020 import Ranger","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.125681Z","iopub.execute_input":"2021-08-12T11:22:05.127374Z","iopub.status.idle":"2021-08-12T11:22:05.145655Z","shell.execute_reply.started":"2021-08-12T11:22:05.127308Z","shell.execute_reply":"2021-08-12T11:22:05.143887Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"SEED = 1000\ndevice= torch.device('cuda')\nSIZE = 384\n\nROOT_DIR = '../input/seti-breakthrough-listen'\n\n#### DATALOADER #####\nTRAIN_BATCH_SIZE = 16\nVALID_BATCH_SIZE = 32\nNUM_WORKERS=4\n\n### GENERAL ######\nEPOCHS = 20\nLR = 5.0e-06\nMAX_LR = 1e-3\n\n##### \nSCHEDULER = 'linear'\n\n##### Model Params ######\nmodel_params = dict(\n    backbone='tf_efficientnet_b3_ns',\n    in_channels=1,\n    out_dim=1,\n    pretrained=True\n)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.151669Z","iopub.execute_input":"2021-08-12T11:22:05.154856Z","iopub.status.idle":"2021-08-12T11:22:05.17043Z","shell.execute_reply.started":"2021-08-12T11:22:05.154794Z","shell.execute_reply":"2021-08-12T11:22:05.169037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Utils","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.177435Z","iopub.execute_input":"2021-08-12T11:22:05.180418Z","iopub.status.idle":"2021-08-12T11:22:05.191684Z","shell.execute_reply.started":"2021-08-12T11:22:05.180305Z","shell.execute_reply":"2021-08-12T11:22:05.19012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AverageMeter(object):\n    def __init__(self):\n        self.reset()\n    \n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n    \n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum / self.count","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.197931Z","iopub.execute_input":"2021-08-12T11:22:05.201405Z","iopub.status.idle":"2021-08-12T11:22:05.213414Z","shell.execute_reply.started":"2021-08-12T11:22:05.201328Z","shell.execute_reply":"2021-08-12T11:22:05.21189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RocAucMeter(object):\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.y_true = np.array([0,1])\n        self.y_pred = np.array([0.5,0.5])\n        self.score = 0\n\n    def update(self, y_true, y_pred):\n        y_true = y_true.detach().cpu().numpy().astype(int)\n        y_pred = y_pred.sigmoid().detach().cpu().numpy()\n     \n        self.y_true = np.hstack((self.y_true, y_true))\n        self.y_pred = np.hstack((self.y_pred, y_pred))\n        self.score = roc_auc_score(self.y_true, self.y_pred)\n    \n    @property\n    def avg(self):\n        return self.score","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.221717Z","iopub.execute_input":"2021-08-12T11:22:05.224744Z","iopub.status.idle":"2021-08-12T11:22:05.239616Z","shell.execute_reply.started":"2021-08-12T11:22:05.224661Z","shell.execute_reply":"2021-08-12T11:22:05.238085Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"def get_train_transform(size=SIZE):\n    return A.Compose([\n        A.HorizontalFlip(p=0.5),\n        A.VerticalFlip(p=0.5),\n        A.ShiftScaleRotate(shift_limit=0.0625, scale_limit=0.2, rotate_limit=90, p=0.5),\n        A.RandomBrightnessContrast(p=0.25),\n        A.Cutout(p=0.3),\n        A.Resize(size,size,always_apply=True),\n        ToTensorV2()\n    ])\ndef get_valid_transform(size=SIZE):\n    return A.Compose([\n        A.Resize(size,size,always_apply=True),\n        ToTensorV2()\n    ])","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.246385Z","iopub.execute_input":"2021-08-12T11:22:05.249572Z","iopub.status.idle":"2021-08-12T11:22:05.262834Z","shell.execute_reply.started":"2021-08-12T11:22:05.249523Z","shell.execute_reply":"2021-08-12T11:22:05.261538Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"class SetiDataset(torch.utils.data.Dataset):\n    def __init__(self,df,transform,read_type='all',selected_dims=None):\n        self.df = df\n        self.transform = transform\n        self.read_type = read_type\n        self.selected_dims = selected_dims\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        \n        id_ = row.id\n        path = f\"{ROOT_DIR}/train/{id_[0]}/{id_}.npy\"\n        label = row.target\n        \n        if self.read_type == 'selected':\n            img = self.read_selected_cadence(path,self.selected_dims)\n        else:\n            img = self.read_all_cadence(path)\n            \n        img = self.transform(image=img)[\"image\"]\n        \n        return img,torch.tensor(label,dtype=torch.float)\n\n    def read_all_cadence(self, path):\n        \"\"\"Read cadence file and reshape\"\"\"\n        img = np.load(path)  # shape: (6, 273, 256)\n        img = np.vstack(img)  # shape: (1638, 256)\n        img = img.transpose(1, 0)  # shape: (256, 1638)\n        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 1638, 1)\n        return img\n    \n    def read_selected_cadence(self, path ,selected_dims=[0,2,4]):\n        \"\"\"Read cadence file and reshape\"\"\"\n        img = np.load(path)[selected_dims]  # shape: (3, 273, 256)\n        img = np.vstack(img)  # shape: (819, 256)\n        img = img.transpose(1, 0)  # shape: (256, 819)\n        img = img.astype(\"f\")[..., np.newaxis]  # shape: (256, 819, 1)\n        return img","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-08-12T11:22:05.268675Z","iopub.execute_input":"2021-08-12T11:22:05.271665Z","iopub.status.idle":"2021-08-12T11:22:05.291754Z","shell.execute_reply.started":"2021-08-12T11:22:05.271599Z","shell.execute_reply":"2021-08-12T11:22:05.29065Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset_checker(dataset):\n    img,label = dataset[9]\n    print(img.shape)\n    print(label)\n    img = img.permute(1,2,0).detach().numpy()\n    fig, ax = plt.subplots(figsize=(16, 8),  nrows=1, ncols=2)\n    ax[0].imshow(img)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.297875Z","iopub.execute_input":"2021-08-12T11:22:05.301149Z","iopub.status.idle":"2021-08-12T11:22:05.311142Z","shell.execute_reply.started":"2021-08-12T11:22:05.301101Z","shell.execute_reply":"2021-08-12T11:22:05.3101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# df = pd.read_csv('../input/seti-breakthrough-listen/train_labels.csv')\n# d = SetiDataset(df,transform=get_train_transform(),read_type='selected',selected_dims=[0,2,4])\n# dataset_checker(d)\n\n# del d,df","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.31696Z","iopub.execute_input":"2021-08-12T11:22:05.32017Z","iopub.status.idle":"2021-08-12T11:22:05.327232Z","shell.execute_reply.started":"2021-08-12T11:22:05.320123Z","shell.execute_reply":"2021-08-12T11:22:05.325712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_loader(fold):\n    df = pd.read_csv('../input/seti-splits-old-new/5folds_split_new.csv')\n    \n    train = df[df['fold']!=fold]\n    valid = df[df['fold']==fold]\n    \n    train_dataset = SetiDataset(\n        train,\n        transform=get_train_transform(),\n        read_type='selected',\n        selected_dims=[0,2,4]\n    )\n    \n    valid_dataset = SetiDataset(\n        valid,\n        transform=get_valid_transform(),\n        read_type='selected',\n        selected_dims=[0,2,4]\n    )\n    \n    train_loader = DataLoader(\n        train_dataset,\n        batch_size  = TRAIN_BATCH_SIZE,\n        drop_last   = False,\n        num_workers = NUM_WORKERS,\n        pin_memory  = True,\n    )\n    \n    valid_loader = DataLoader(\n        valid_dataset,\n        batch_size  = VALID_BATCH_SIZE,\n        drop_last   = False,\n        num_workers = NUM_WORKERS,\n        pin_memory  = True,\n    )\n    \n    return train_loader,valid_loader","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.333236Z","iopub.execute_input":"2021-08-12T11:22:05.335993Z","iopub.status.idle":"2021-08-12T11:22:05.34985Z","shell.execute_reply.started":"2021-08-12T11:22:05.335943Z","shell.execute_reply":"2021-08-12T11:22:05.348408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"class enetv2(nn.Module):\n    def __init__(self, backbone,in_channels,out_dim,pretrained=True):\n        super(enetv2, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels, 6, 3, stride=1, padding=1, bias=False)\n        self.conv2 = nn.Conv2d(6, 12, 3, stride=1, padding=1, bias=False)\n        self.conv3 = nn.Conv2d(12, 36, 3, stride=1, padding=1, bias=False)\n        self.mybn1 = nn.BatchNorm2d(6)\n        self.mybn2 = nn.BatchNorm2d(12)\n        self.mybn3 = nn.BatchNorm2d(36)\n\n        self.enet = timm.create_model(backbone, pretrained=pretrained,in_chans=in_channels)\n        self.enet.conv_stem.weight = nn.Parameter(self.enet.conv_stem.weight.repeat(1, 36, 1, 1))\n\n        self.dropout = nn.Dropout(0.5)\n        self.enet.blocks[5] = nn.Identity()\n        self.enet.blocks[6] = nn.Sequential(\n            nn.Conv2d(self.enet.blocks[4][2].conv_pwl.out_channels, self.enet.conv_head.in_channels, 1),\n            nn.BatchNorm2d(self.enet.conv_head.in_channels),\n            nn.ReLU6(),\n        )\n        self.myfc = nn.Linear(self.enet.classifier.in_features, out_dim)\n        self.enet.classifier = nn.Identity()\n\n    def extract(self, x):\n        x = F.relu6(self.mybn1(self.conv1(x)))\n        x = F.relu6(self.mybn2(self.conv2(x)))\n        x = F.relu6(self.mybn3(self.conv3(x)))\n        x = self.enet(x)\n        return x\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(self.dropout(x))\n        return x","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.35583Z","iopub.execute_input":"2021-08-12T11:22:05.359244Z","iopub.status.idle":"2021-08-12T11:22:05.38305Z","shell.execute_reply.started":"2021-08-12T11:22:05.359197Z","shell.execute_reply":"2021-08-12T11:22:05.381975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Function","metadata":{}},{"cell_type":"code","source":"def train_fn(dataloader,model,criterion,optimizer,device,scheduler,epoch):\n    model.train()\n    loss_score = AverageMeter()\n    auc_score = RocAucMeter()\n    \n    tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n    for bi,d in tk0:\n        \n        batch_size = d[0].shape[0]\n\n        images = d[0]\n        targets = d[1]\n\n        images = images.to(device)\n        targets = targets.to(device)\n\n        optimizer.zero_grad()\n\n        output = model(images)\n        \n        loss = criterion(output,targets.view(-1,1))\n        \n        loss.backward()\n        optimizer.step()\n        \n        loss_score.update(loss.detach().item(), batch_size)\n        auc_score.update(targets,output.squeeze(-1))\n        tk0.set_postfix(Train_Loss=loss_score.avg,Train_AUC=auc_score.avg,Epoch=epoch,LR=optimizer.param_groups[0]['lr'])\n        \n        if scheduler is not None:\n                scheduler.step()\n        \n    return loss_score","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.389507Z","iopub.execute_input":"2021-08-12T11:22:05.3929Z","iopub.status.idle":"2021-08-12T11:22:05.40761Z","shell.execute_reply.started":"2021-08-12T11:22:05.392854Z","shell.execute_reply":"2021-08-12T11:22:05.406245Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(dataloader,model,criterion,device,epoch):\n        model.eval()\n        loss_score = AverageMeter()\n        auc_score = RocAucMeter()\n        \n        tk0 = tqdm(enumerate(dataloader), total=len(dataloader))\n        with torch.no_grad():\n            for bi,d in tk0:\n\n                batch_size = d[0].shape[0]\n \n                image = d[0]\n                labels = d[1]\n\n                image = image.to(device)\n                labels = labels.to(device)\n\n                out = model(image)\n                loss = criterion(out,labels.view(-1,1))\n                \n                loss_score.update(loss.detach().item(), batch_size)\n                auc_score.update(labels,out.squeeze(-1))\n                \n                tk0.set_postfix(Valid_Loss=loss_score.avg,Valid_AUC=auc_score.avg,Epoch=epoch)\n        \n        return loss_score.avg,auc_score.avg","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.409521Z","iopub.execute_input":"2021-08-12T11:22:05.410018Z","iopub.status.idle":"2021-08-12T11:22:05.425567Z","shell.execute_reply.started":"2021-08-12T11:22:05.409969Z","shell.execute_reply":"2021-08-12T11:22:05.423424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Engine","metadata":{}},{"cell_type":"code","source":"def run(fold):\n    seed_everything(SEED)\n    \n    train_loader,valid_loader = get_loader(fold)\n    \n    seed_everything(SEED)\n    \n    # Defining Model for specific fold\n    model = enetv2(**model_params)\n    model.to(device)\n    \n    #DEfining criterion\n    criterion = nn.BCEWithLogitsLoss()\n    criterion.to(device)\n    \n    #optimizer = torch.optim.Adam(model.parameters(), lr=scheduler_params['lr_start'])\n    optimizer = Ranger(model.parameters(), lr= LR,weight_decay=1.0e-02)\n    \n    #Defining LR SCheduler\n    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n        optimizer,\n        steps_per_epoch = len(train_loader),\n        epochs=EPOCHS,\n        max_lr=MAX_LR,\n        pct_start= 0.1,\n        anneal_strategy = 'cos',\n        div_factor = 1.0e+3,\n        final_div_factor= 1.0e+3\n    )\n    \n    # THE ENGINE LOOP\n    best_auc = 0 \n    for epoch in range(EPOCHS):\n        train_loss = train_fn(train_loader, model,criterion, optimizer, device,scheduler=scheduler,epoch=epoch)\n        valid_loss,valid_auc = evaluate(valid_loader, model, criterion,device,epoch=epoch)\n        \n        if valid_auc > best_auc:\n            best_auc = valid_auc\n            torch.save(model.state_dict(),f\"model_{model_params['backbone']}_IMG_SIZE_{SIZE}.bin\")\n            print('best model found for epoch {}'.format(epoch))","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.427781Z","iopub.execute_input":"2021-08-12T11:22:05.428316Z","iopub.status.idle":"2021-08-12T11:22:05.44918Z","shell.execute_reply.started":"2021-08-12T11:22:05.428269Z","shell.execute_reply":"2021-08-12T11:22:05.447862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"run(fold=0)","metadata":{"execution":{"iopub.status.busy":"2021-08-12T11:22:05.454685Z","iopub.execute_input":"2021-08-12T11:22:05.457939Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}