{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport time\nimport warnings\nimport numpy as np\nfrom nltk.corpus import stopwords\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.preprocessing import normalize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.manifold import TSNE\nimport seaborn as sns\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics.classification import accuracy_score, log_loss\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import SGDClassifier\nfrom imblearn.over_sampling import SMOTE\nfrom collections import Counter\nfrom scipy.sparse import hstack\nfrom sklearn.multiclass import OneVsRestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import StratifiedKFold \nfrom collections import Counter, defaultdict\nfrom sklearn.calibration import CalibratedClassifierCV\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nimport math\nfrom sklearn.metrics import normalized_mutual_info_score\nfrom sklearn.ensemble import RandomForestClassifier\nwarnings.filterwarnings(\"ignore\")\n\nfrom mlxtend.classifier import StackingClassifier\n\nfrom sklearn import model_selection\nfrom sklearn.linear_model import LogisticRegression","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndata_variants = pd.read_csv('../input/training_variants')\n\ndata_text =pd.read_csv(\"../input/training_text\",sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_variants.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_text.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_text['LENGTH'] = data_text['TEXT'].str.len()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_text.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new = pd.merge(left = data_variants, right = data_text,how='left',on= 'ID')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(data_new[data_new.isnull().any(axis = 1) == False],hue = 'Class')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new[data_new.isnull().any(axis = 1) == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.loc[data_new['TEXT'].isnull(),'TEXT']  = data_new['Gene'] + \" \" + data_new['Variation']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new[data_new.isnull().any(axis = 1) == True]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new['LENGTH'] = data_new['TEXT'].str.len()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re\nimport nltk\n#nltk.download('stopwords')\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ndef text_processing(data_new):\n    review = data_new\n    review = re.sub('[^a-zA-Z0-9\\n]',' ',review)\n    review = review.lower()\n    review = review.split()\n    review = [word for word in review if not word in set(stopwords.words('english'))]\n    review = ' '.join(review)\n    return review\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#data_new['TEXT1'] = data_new['TEXT'].apply(lambda x : text_processing(str(x)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# we create a output array that has exactly same size as the CV data\ny_cv = [1,3,4,2,1,7,5,6,8,9,5]\ncv_data_len = 11\ncv_predicted_y = np.zeros((cv_data_len,9))\nfor i in range(cv_data_len):\n    rand_probs = np.random.rand(1,9)\n    cv_predicted_y[i] = ((rand_probs/sum(sum(rand_probs)))[0])\nprint(\"Log loss on Cross Validation Data using Random Model\",log_loss(y_cv,cv_predicted_y, eps=1e-15))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_predicted_y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new['Gene'] = data_new['Gene'].str.replace(' ','_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new['Variation'] = data_new['Variation'].str.replace(' ','_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_new.head(10)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train,X_test,y_train,y_test = train_test_split(data_new,data_new['Class'],test_size = 0.2,stratify = data_new['Class'], random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.groupby(['Class'])['Class'].value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.groupby(['Class'])['Class'].value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val,X_test_val,y_train_val,y_test_val = train_test_split(X_train,y_train,test_size = 0.2, stratify = y_train, random_state = 0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val.groupby(['Class'])['Class'].value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val.groupby(['Class'])['Class'].value_counts().plot(kind = 'bar')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfTransformer,TfidfVectorizer,CountVectorizer","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#count_vec_gene = CountVectorizer(decode_error='ignore',stop_words='english',min_df=3,ngram_range=(1,1),analyzer='word',max_features=2000)\ncount_vec_gene = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val_gene_cv = count_vec_gene.fit_transform(X_train_val['Gene'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val_gene_cv.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val_gene_cv = count_vec_gene.transform(X_test_val['Gene'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val_gene_cv[:10][3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_gene_cv = count_vec_gene.transform(X_test['Gene'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_gene_cv[:10][3]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n#count_vec_var = CountVectorizer(decode_error='ignore',stop_words='english',min_df=3,ngram_range=(1,1),analyzer='word',max_features=2000)\ncount_vec_var = CountVectorizer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val_var_cv = count_vec_var.fit_transform(X_train_val['Variation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val_var_cv = count_vec_var.transform(X_test_val['Variation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_var_cv = count_vec_var.transform(X_test['Variation'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_var_cv","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#count_vec_text = CountVectorizer(decode_error='ignore',stop_words='english',min_df=3,ngram_range=(1,2),max_df = 0.8,analyzer='word')\ncount_vec_text = CountVectorizer(min_df=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val_text_cv = count_vec_text.fit_transform(X_train_val['TEXT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val_text_cv = count_vec_text.transform(X_test_val['TEXT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_text_cv = count_vec_text.transform(X_test['TEXT'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val_text_cv.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_1 = hstack((normalize(X_train_val_gene_cv),normalize(X_train_val_var_cv)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_2 = hstack((training_data_1,normalize(X_train_val_text_cv)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy import sparse","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val_len = sparse.coo_matrix(X_train_val['LENGTH']).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train_val_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_final = hstack((normalize(training_data_2),normalize(X_train_val_len)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_data_final","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data_1 = hstack((normalize(X_test_val_gene_cv),normalize(X_test_val_var_cv)))\nvalidation_data_2 = hstack((validation_data_1,normalize(X_test_val_text_cv)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val_len = sparse.coo_matrix(X_test_val['LENGTH']).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_val_len","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data_2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"validation_data_final = hstack((validation_data_2,normalize(X_test_val_len)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data_1 = hstack((normalize(X_test_gene_cv),normalize(X_test_var_cv)))\ntesting_data_2 = hstack((testing_data_1,normalize(X_test_text_cv)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_test_len = sparse.coo_matrix(X_test['LENGTH']).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"testing_data_final = hstack((testing_data_2,normalize(X_test_len)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, log_loss, confusion_matrix, precision_score\nalphas = [0.0001,0.001,0.01,0.1,1,10,1000]\naccuracy_array = []\nlog_loss_array = []\nfor i in alphas:\n    classifier = MultinomialNB(alpha=i)    \n    classifier.fit(training_data_final,y_train_val)\n    sig_clf = CalibratedClassifierCV(classifier, method=\"sigmoid\")\n    sig_clf.fit(training_data_final,y_train_val)\n    y_pred = sig_clf.predict(validation_data_final)\n    y_pred_prob = sig_clf.predict_proba(validation_data_final)\n    accuracy_array.append(accuracy_score(y_test_val,y_pred))\n    lg = log_loss(y_test_val,y_pred_prob,eps=1e-15)\n    log_loss_array.append(lg)\n    print('Validation Accuracy at alpha {} :'.format(i),accuracy_score(y_test_val,y_pred) )\n    print('Validation Log Loss :', log_loss(y_test_val,y_pred_prob,eps=1e-15))\n    cm = confusion_matrix(y_test_val, y_pred)\n    #recall = np.diag(cm) / np.sum(cm, axis = 1)\n    #precision = np.diag(cm) / np.sum(cm, axis = 0)\n    #print('Precision :',precision_score(y_test_val, y_pred, average=None))\n    #print('Recall :',np.mean(recall))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    classifier = MultinomialNB(alpha=0.001)    \n    classifier.fit(training_data_final,y_train_val)\n    sig_clf = CalibratedClassifierCV(classifier, method=\"sigmoid\")\n    sig_clf.fit(training_data_final,y_train_val)\n    y_pred = sig_clf.predict(testing_data_final)\n    y_pred_prob = sig_clf.predict_proba(testing_data_final)\n    print('Validation Accuracy at alpha {} :'.format(0.001),accuracy_score(y_test,y_pred) )\n    print('Validation Log Loss :', log_loss(y_test,y_pred_prob,eps=1e-15))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, log_loss, confusion_matrix, precision_score\nalphas = [0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10,1000]\naccuracy_array = []\nlog_loss_array = []\nfor i in alphas:\n    classifier = SGDClassifier( alpha=i, penalty='l2', loss='log', random_state=42)\n    classifier.fit(training_data_final,y_train_val)\n    sig_clf = CalibratedClassifierCV(classifier, method=\"sigmoid\")\n    sig_clf.fit(training_data_final,y_train_val)\n    y_pred = sig_clf.predict(validation_data_final)\n    y_pred_prob = sig_clf.predict_proba(validation_data_final)\n    accuracy_array.append(accuracy_score(y_test_val,y_pred))\n    lg = log_loss(y_test_val,y_pred_prob,eps=1e-15)\n    log_loss_array.append(lg)\n    print('Validation Accuracy at alpha {} :'.format(i),accuracy_score(y_test_val,y_pred) )\n    print('Validation Log Loss :', log_loss(y_test_val,y_pred_prob,eps=1e-15))\n    cm = confusion_matrix(y_test_val, y_pred)\n    #recall = np.diag(cm) / np.sum(cm, axis = 1)\n    #precision = np.diag(cm) / np.sum(cm, axis = 0)\n    #print('Precision :',precision_score(y_test_val, y_pred, average=None))\n    #print('Recall :',np.mean(recall))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    classifier = SGDClassifier(class_weight='balanced', alpha=1e-05, penalty='l2', loss='log', random_state=42)\n    classifier.fit(training_data_final,y_train_val)\n    sig_clf = CalibratedClassifierCV(classifier, method=\"sigmoid\")\n    sig_clf.fit(training_data_final,y_train_val)\n    y_pred = sig_clf.predict(testing_data_final)\n    y_pred_prob = sig_clf.predict_proba(testing_data_final)\n    print('Validation Accuracy at alpha {} :'.format(0.001),accuracy_score(y_test,y_pred) )\n    print('Validation Log Loss :', log_loss(y_test,y_pred_prob,eps=1e-15))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, log_loss, confusion_matrix, precision_score\nalphas = [100,300,1000,1500]\naccuracy_array = []\nlog_loss_array = []\nfor i in alphas:\n    classifier = RandomForestClassifier(n_estimators=i, criterion='gini', max_depth=3, random_state=42, n_jobs=-1)\n    classifier.fit(training_data_final,y_train_val)\n    sig_clf = CalibratedClassifierCV(classifier, method=\"sigmoid\")\n    sig_clf.fit(training_data_final,y_train_val)\n    y_pred = sig_clf.predict(validation_data_final)\n    y_pred_prob = sig_clf.predict_proba(validation_data_final)\n    accuracy_array.append(accuracy_score(y_test_val,y_pred))\n    lg = log_loss(y_test_val,y_pred_prob,eps=1e-15)\n    log_loss_array.append(lg)\n    print('Validation Accuracy at alpha {} :'.format(i),accuracy_score(y_test_val,y_pred) )\n    print('Validation Log Loss :', log_loss(y_test_val,y_pred_prob,eps=1e-15))\n    cm = confusion_matrix(y_test_val, y_pred)\n    #recall = np.diag(cm) / np.sum(cm, axis = 1)\n    #precision = np.diag(cm) / np.sum(cm, axis = 0)\n    #print('Precision :',precision_score(y_test_val, y_pred, average=None))\n    #print('Recall :',np.mean(recall))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"    classifier = RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=10, random_state=42, n_jobs=-1)\n    classifier.fit(training_data_final,y_train_val)\n    sig_clf = CalibratedClassifierCV(classifier, method=\"sigmoid\")\n    sig_clf.fit(training_data_final,y_train_val)\n    y_pred = sig_clf.predict(testing_data_final)\n    y_pred_prob = sig_clf.predict_proba(testing_data_final)\n    print('Validation Accuracy at alpha {} :'.format(0.001),accuracy_score(y_test,y_pred) )\n    print('Validation Log Loss :', log_loss(y_test,y_pred_prob,eps=1e-15))\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = MultinomialNB(alpha=0.001)\nclf1.fit(training_data_final,y_train_val)\nsig_clf1 = CalibratedClassifierCV(clf1, method=\"sigmoid\")\n\nclf2 = SGDClassifier(class_weight='balanced', alpha=1e-05, penalty='l2', loss='log', random_state=42)\nclf2.fit(training_data_final,y_train_val)\nsig_clf2 = CalibratedClassifierCV(clf2, method=\"sigmoid\")\n\n\nclf3 = RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=10, random_state=42, n_jobs=-1)\nclf3.fit(training_data_final,y_train_val)\nsig_clf3 = CalibratedClassifierCV(clf3, method=\"sigmoid\")\n\nsig_clf1.fit(training_data_final,y_train_val)\nprint(\"Naive Bayes :  Log Loss: %0.2f\" % (log_loss(y_test_val, sig_clf1.predict_proba(validation_data_final))))\nsig_clf2.fit(training_data_final,y_train_val)\nprint(\"Support vector machines : Log Loss: %0.2f\" % (log_loss(y_test_val, sig_clf2.predict_proba(validation_data_final))))\nsig_clf3.fit(training_data_final,y_train_val)\nprint(\"Random Forest : Log Loss: %0.2f\" % (log_loss(y_test_val, sig_clf3.predict_proba(validation_data_final))))\nprint(\"-\"*50)\nalpha = [0.0001,0.001,0.01,0.1,1,10] \nbest_alpha = 999\nfor i in alpha:\n    lr = LogisticRegression(C=i)\n    sclf = StackingClassifier(classifiers=[sig_clf1, sig_clf2, sig_clf3], meta_classifier=lr, use_probas=True)\n    sclf.fit(training_data_final,y_train_val)\n    print(\"Stacking Classifer : for the value of alpha: %f Log Loss: %0.3f\" % (i, log_loss(y_test_val, sclf.predict_proba(validation_data_final))))\n    log_error =log_loss(y_test_val, sclf.predict_proba(validation_data_final))\n    if best_alpha > log_error:\n        best_alpha = log_error","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf1 = MultinomialNB(alpha=0.001)\nclf1.fit(training_data_final,y_train_val)\nsig_clf1 = CalibratedClassifierCV(clf1, method=\"sigmoid\")\n\nclf2 = SGDClassifier(class_weight='balanced', alpha=1e-05, penalty='l2', loss='log', random_state=42)\nclf2.fit(training_data_final,y_train_val)\nsig_clf2 = CalibratedClassifierCV(clf2, method=\"sigmoid\")\n\n\nclf3 = RandomForestClassifier(n_estimators=300, criterion='gini', max_depth=10, random_state=42, n_jobs=-1)\nclf3.fit(training_data_final,y_train_val)\nsig_clf3 = CalibratedClassifierCV(clf3, method=\"sigmoid\")\n\nsig_clf1.fit(training_data_final,y_train_val)\nsig_clf2.fit(training_data_final,y_train_val)\nsig_clf3.fit(training_data_final,y_train_val)\nlr = LogisticRegression(C=0.1)\nsclf = StackingClassifier(classifiers=[sig_clf1, sig_clf2, sig_clf3], meta_classifier=lr, use_probas=True)\nsclf.fit(training_data_final,y_train_val)\nprint(\"Stacking Classifer : for the value of alpha: %f Log Loss: %0.3f\" % (i, log_loss(y_test, sclf.predict_proba(testing_data_final))))\nprint(\"Stacking Classifer : for the value of alpha: %f Accuracy: %0.3f\" % (i, accuracy_score(y_test, sclf.predict(testing_data_final))))\n\n    ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}