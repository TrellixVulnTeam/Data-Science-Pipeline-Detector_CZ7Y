{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd #Importing all the needed libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords\nfrom bs4 import BeautifulSoup\nimport re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=pd.read_csv('../input/perosonalisedcancerdetection/training_variants') #Importing the data\ntext_data=pd.read_csv('../input/perosonalisedcancerdetection/training_text',sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=pd.read_csv('../input/perosonalisedcancerdetection/stage2_test_variants.csv') #Importing the data\ntest_text_data=pd.read_csv('../input/perosonalisedcancerdetection/stage2_test_text.csv',sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data=test_data.join(test_text_data,lsuffix='_')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.shape #data has 3321 data points","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.columns  #has following features where class is dependent variable","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"text_data.shape #Text ahs 2 features one is id and other is actual text.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=data.join(text_data,lsuffix='_') #Joining the data.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data[data['Variation']=='Truncating Mutations']['Class'].value_counts() #Just a insight that specific type of variation belongs to which group.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.Class.value_counts() #Total classes 1-9.(9 classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\nenc=OneHotEncoder()\nenc1=OneHotEncoder() #importing the encoders","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#all_Genes=list(data['Gene']+test_data['Gene'])\nGene_vocab=pd.concat([test_data['Gene'],data['Gene']],ignore_index=True)\nenc.fit(Gene_vocab.values.reshape(-1,1))\nVariation_vocab=pd.concat([test_data['Variation'],data['Variation']],ignore_index=True)\nenc1.fit(Variation_vocab.values.reshape(-1,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded=enc.transform(data['Gene'].values.reshape(-1,1))\nadd=data.shape[1]\nfor i in range(0,encoded.shape[1]):\n    data[add] = pd.arrays.SparseArray(encoded[:, i].toarray().ravel())\n    add+=1 #Converting the Gene feature as one hot encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded=enc1.transform(data['Variation'].values.reshape(-1,1))\nadd=data.shape[1]\nfor i in range(0,encoded.shape[1]):\n    data[add] = pd.arrays.SparseArray(encoded[:, i].toarray().ravel())\n    add+=1  #Converting the Gene feature as one hot encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(x): #Basic pre-processing the text feature\n        x=str(x).lower()\n        x=x.replace(',000,000','m').replace(',000','k').replace(\"'\",\"`\").replace(\"won't\",'will not').replace(\"can't\",\"can not\").replace('cannot','can not').replace(\"n't\",'not').replace(\"what's\",\"what is\").replace(\"it's\",\"it is\").replace(\"'ve\",\"have\").replace(\"i'm\",\"i am\").replace(\"'re\",\"are\").replace(\"he's\",\"he is\").replace(\"she's\",\"she is \").replace(\"'s\",\"own\").replace(\"%\",\" precent\").replace(\"₹\",\" rupeee\").replace(\"$\",\"dollar\").replace(\"€\",\"euro\").replace(\"'ll\",\"will\")\n        porter = PorterStemmer()\n        pattern = re.compile('\\W')\n    \n        if type(x) == type(''):\n            x = re.sub(pattern, ' ', x)\n        if type(x) == type(''):\n          x = porter.stem(x)\n          example1 = BeautifulSoup(x)\n          x = example1.get_text()\n        return str(x)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data['text']=data['TEXT'].apply(preprocess) #applying the text pre-processing to each feature.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['Gene','Variation','ID','ID_'],inplace=True) #Dropping the already encoded features.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import gensim\n# Load Google's pre-trained Word2Vec model.\nw2v_model_our_corpus = gensim.models.KeyedVectors.load_word2vec_format(r'../input/word2vec-google/GoogleNews-vectors-negative300.bin', binary=True)  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def sent_vectorizer(sent, w2v_model_our_corpus): #Get the sentence vectors\n    sent_vec = np.zeros(300)\n    numw = 0\n    for w in sent.split():\n        try:\n            sent_vec = np.add(sent_vec, w2v_model_our_corpus[w])\n            numw+=1\n        except:\n            pass\n    return sent_vec/ np.sqrt(sent_vec.dot(sent_vec))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded=enc.transform(test_data['Gene'].values.reshape(-1,1))\nadd=test_data.shape[1]\nfor i in range(0,encoded.shape[1]):\n    test_data[add] = pd.arrays.SparseArray(encoded[:, i].toarray().ravel())\n    add+=1 #Converting the Gene feature as one hot encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"encoded=enc1.transform(test_data['Variation'].values.reshape(-1,1))\nadd=test_data.shape[1]\nfor i in range(0,encoded.shape[1]):\n    test_data[add] = pd.arrays.SparseArray(encoded[:, i].toarray().ravel())\n    add+=1  #Converting the Gene feature as one hot encoded","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data['text']=test_data['TEXT'].apply(preprocess)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data.drop(columns=['Gene','Variation','ID','ID_'],axis=1,inplace=True) #Dropping the already encoded features.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm #Converting the sentences into vectors. \nV=[]\nfor sentence in tqdm(data['text']):\n    V.append(sent_vectorizer(sentence, w2v_model_our_corpus))\nV_test=[]\nfor sentence in tqdm(test_data['text']):\n    V_test.append(sent_vectorizer(sentence, w2v_model_our_corpus))\nV_test=np.array(V_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train=data['Class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data.drop(columns=['TEXT','text','Class'],axis=1,inplace=True) #dropping not needed features from train set\ntest_data.drop(columns=['TEXT','text'],axis=1,inplace=True) #dropping not needed features from test set","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from scipy.sparse import hstack #Stacking one-hot encoded Gene and variation feature with the sentence vectors whihc we got from \nX_train=hstack([data,V]) #Pre-trained Word2Vec model. \nX_test=hstack([test_data,V_test])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catboost import CatBoostClassifier  #Importing the classifier.\nlr=CatBoostClassifier()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.calibration import CalibratedClassifierCV\ncr=CalibratedClassifierCV(lr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cr.fit(X=X_train,y=y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predsCalibrated=cr.predict_proba(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids=np.arange(1,987)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ids=pd.Series(ids)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class1=pd.Series(predsCalibrated[:,0])\nclass2=pd.Series(predsCalibrated[:,1])\nclass3=pd.Series(predsCalibrated[:,2])\nclass4=pd.Series(predsCalibrated[:,3])\nclass5=pd.Series(predsCalibrated[:,4])\nclass6=pd.Series(predsCalibrated[:,5])\nclass7=pd.Series(predsCalibrated[:,6])\nclass8=pd.Series(predsCalibrated[:,7])\nclass9=pd.Series(predsCalibrated[:,8])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds=pd.DataFrame(data={'ID':ids,'class1':class1,'class2':class2,'class3':class3,'class4':class4,'class5':class5,'class6':class6,'class7':class7,'class8':class8,'class9':class9})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds.to_csv('Submissions.csv')","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}