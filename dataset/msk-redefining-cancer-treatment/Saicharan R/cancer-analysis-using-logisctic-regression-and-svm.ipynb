{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"#reading the training file\ntraining_text_data=pd.read_csv(\"/kaggle/input/msk-redefining-cancer-treatment/training_text\",sep='\\|\\|', header=None,skiprows=1,names=[\"ID\",\"Text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the training text data \ntraining_text_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading the training_variants file\ntraining_variants_data=pd.read_csv(\"/kaggle/input/msk-redefining-cancer-treatment/training_variants\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the training variant data \ntraining_variants_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merging training text data and training variant data\ntotal_data=pd.merge(left=training_text_data,\n    right=training_variants_data,\n    how='inner',\n    on=\"ID\",)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking total merged data\ntotal_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(total_data['Text'][0])\nprint(total_data['Gene'][0])\n#from the Below , we can see that all the Gene column values are present in Text data column,Hence I am ignoring Gene Column","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for null values on our data\ntotal_data.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(total_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#imputing gene row value to null data of text rows as for all other columns, Gene values are present in Text data\ntotal_data['Text'] = total_data.apply(lambda row: row['Gene'] if pd.isnull(row['Text']) else row['Text'],\n    axis=1\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#we can see  no missing values in our data\ntotal_data.isnull().sum()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking the shape of our data\ntotal_data.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"total_data.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking class column as dependent variable ie which needs to be find out from all other columns in our data\ny=total_data.Class\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#taking Text and Variation as independent variables or Predictive columns to train the data\nX=total_data[[\"Text\",\"Variation\",]]\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# splitting into test and train\nfrom sklearn.model_selection  import train_test_split\nfrom imblearn.over_sampling import SMOTE\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# vectorizing the sentences; removing stop words\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Definig vectorizing object for Text column\nvect_text= CountVectorizer(stop_words ='english')\n\n#Defining vectorizing object for Variation column\nvect_variation= CountVectorizer(stop_words ='english')\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizing  for Text column which gives the count of repeated words for each row\nvect_text.fit(X_train[\"Text\"])\nvect_text.fit(X_test[\"Text\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#vectorizing for Variation column  which gives the count of repeated words for each row\nvect_variation.fit(X_train[\"Variation\"])\nvect_variation.fit(X_test[\"Variation\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vect_text.vocabulary_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vect_variation.vocabulary_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transforming count of Variation words in to matrix\nvariation_tranform_train=vect_variation.transform(X_train[\"Variation\"])\nvariation_tranform_test=vect_variation.transform(X_test[\"Variation\"])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#transforming count of Text words in to matrix\ntext_transformed_train= vect_text.transform(X_train[\"Text\"])\ntext_transformed_test=vect_text.transform(X_test[\"Text\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merging train data of two Matrix horixzontally to train the model\nimport scipy.sparse as sp\nx_train_final = sp.hstack((variation_tranform_train,text_transformed_train))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_train_final.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merging test data of two Matrix horixzontally to train the model\nimport scipy.sparse as sp\nx_test_final = sp.hstack((variation_tranform_test,text_transformed_test))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(x_test_final.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's run Linear SVM model using the selected variables\nfrom sklearn import metrics\nfrom sklearn import svm\nfrom sklearn.metrics import classification_report\nsvc_model=svm.LinearSVC()\nsvc_model.fit(x_train_final,y_train)\n\n#predicting the Test data using our trained Linear SVM model\ny_pred_class = svc_model.predict(x_test_final)\n\nprint(classification_report(y_test, y_pred_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Let's run Logistic regression model using the selected variables\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nlogsk = LogisticRegression()\nlogsk.fit(x_train_final,y_train)\ny_pred_class = logsk.predict(x_test_final)\nprint(classification_report(y_test, y_pred_class))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tuning Logistic regression model using grid search","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#tunig naive bayes algorithm\n# GridSearchCV to find optimal max_depth\n#from sklearn.model_selection import KFold\n#from sklearn.model_selection import GridSearchCV\n\n\n# specify number of folds for k-fold CV\n#logsk = LogisticRegression()\n\n# parameters to build the model on\n#grid={\"C\":np.logspace(-3,3,7)}\n# instantiate the model\n\n\n\n# fit tree on training data\n#logis = GridSearchCV(logsk,grid,\n                  # scoring=\"accuracy\")\n#logis.fit(x_train_final, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# scores of GridSearch CV\n#scores = logis.cv_results_\n#pd.DataFrame(scores).head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#reading stage 2 test data\ntest_text_data=pd.read_csv(\"/kaggle/input/msk-redefining-cancer-treatment/stage2_test_text.csv\",sep='\\|\\|', header=None,skiprows=1,names=[\"ID\",\"Text\"])\ntest_variant_data=pd.read_csv(\"/kaggle/input/msk-redefining-cancer-treatment/stage2_test_variants.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#checking for any missing values in test data\ntest_text_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_variant_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#merging two tables of stage 2 test data\ntest_total_data=pd.merge(left=test_text_data,\n    right=test_variant_data,\n    how='inner',\n    on=\"ID\",)\ntest_total_data.head()\nlen(test_total_data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_total_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#final_vect_variation= CountVectorizer(stop_words='english')\n#final_vect_text= CountVectorizer(stop_words='english')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#final_vect_variation.fit(test_total_data[\"Text\"])\n#final_vect_text.fit(test_total_data[\"Variation\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generating matrix with the vectorizor object used for training data so that we get same number columns for test data as in Training data\nfinal_variation_tranform_test=vect_variation.transform(test_total_data[\"Variation\"])\nfinal_text_transformed_test=vect_text.transform(test_total_data[\"Text\"])\n\n#concatinating two columns data.\nimport scipy.sparse as sp\nx_train_final_submission = sp.hstack((final_variation_tranform_test,final_text_transformed_test))\n\n#checking the shapes of stage 2 test data and train data\nprint(\"shape of train data\",x_train_final.shape)\nprint(\"shape of stage 2 test data\",x_train_final_submission.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#building the Logistic regression model for predicting stage 2 test as it is giving more accuracy compared ot SVM as shown above.\nlogsk_final = LogisticRegression()\nlogsk_final.fit(x_train_final,y_train)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#predicting the stage 2 test data\ny_pred_test = logsk_final.predict_proba(x_train_final_submission)\nprint(y_pred_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#convert the predicted columns in to data frame\ny_pred_test=pd.DataFrame(y_pred_test)  \ny_pred_test.head(10)\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#renaming the columns\ny_pred_test.rename(columns={0:'class1',1:'class2',2:'class3',3:'class4',4:'class5',5:'class6',6:'class7',7:'class8',8:'class9'}, \n                 inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_total_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_test.head()\nSubmission_File=pd.concat([test_total_data,y_pred_test],axis=1)\nSubmission_File.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#dropiing all other coulumns except predicted class column\nSubmission_File=Submission_File.drop(columns=[\"Text\",\"Gene\",\"Variation\"])\nSubmission_File.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting ID column in to int type\nSubmission_File[\"ID\"]=Submission_File[\"ID\"].astype(int)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission_File.tail()\n#Submission_File = Submission_File[:-1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#converting the data frame in to csv file\nSubmission_File.to_csv('Submission_File',sep=',',header=True,index=None)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Submission_File.to_csv(r'Submission_File.csv',index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#generating or exporting the file for submission \nfrom IPython.display import FileLink\nFileLink(r'Submission_File.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}