{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Задача:\n\nРазработать алгоритмы классификации генетических мутаций на основе клинических данных (текста). Предсказать класс, в котором была генетическая мутация.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Описание файлов:\n\n- **training_variants** - содержит описание генетических мутаций, используемых для обучения. \nПоля: \nID - идентификатор строки, который используется для связи мутации с клиническими данными, Gene - ген, в котором находится эта генетическая мутация, Variation - изменение аминокислот для этой мутации, Class - 1-9 класс, в котором эта генетическая мутация была классифицирована\n- **training_text** - файл с разделителями в виде двойной трубы (||), содержащий клинические данные (текст), используемые для классификации генетических мутаций. \nПоля: \nID - идентификатор строки, используемой для связи клинических данных с генетической мутацией, Text - клинические данные, используемые для классификации генетической мутации)\n- **test_variants** - содержит описание генетических мутаций, используемых для обучения. \nID - идентификатор строки, который используется для связи мутации с клиническими данными, Gene - ген, в котором находится эта генетическая мутация, Variation - изменение аминокислот для этой мутации\n- **test_text** - файл с разделителями в виде двойной трубы (||), содержащий клинические данные (текст), используемые для классификации генетических мутаций.  \nПоля: \nID - идентификатор строки, используемой для связи клинических данных с генетической мутацией, Text - клинические данные, используемые для классификации генетической мутации)\n- **submissionSample** - пример файла отправки в правильном формате (итоговый файл, куда заливаем наши результаты)","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!pip install py7zr","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#Импортирование библиотек\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport string\nfrom nltk.corpus import stopwords\nimport nltk\nfrom collections import Counter\nimport sklearn\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.corpus import wordnet\nfrom nltk.stem import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.decomposition import TruncatedSVD\nfrom sklearn.model_selection import GridSearchCV, train_test_split, ShuffleSplit, KFold\nimport xgboost as xgb\nfrom sklearn.metrics import classification_report, confusion_matrix, log_loss\nimport pickle\nimport py7zr","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 1. Exploratory Data Analysis","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## Загрузка данных","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Тренировочные данные","execution_count":null},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"training_variants = pd.read_csv('/kaggle/input/msk-redefining-cancer-treatment/training_variants.zip')\ntraining_text =pd.read_csv(\"/kaggle/input/msk-redefining-cancer-treatment/training_text.zip\",sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_variants.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"training_text.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Собираем информацию о мутациях в генах с информацией о них в научных статьях","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.merge(training_variants, training_text, how = 'left', on = 'ID').fillna('')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train.shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тестовые данные","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"test_var = pd.read_csv('/kaggle/input/msk-redefining-cancer-treatment/test_variants.zip')\ntest_text =pd.read_csv(\"/kaggle/input/msk-redefining-cancer-treatment/test_text.zip\",sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)\ntest = pd.merge(test_var, test_text, how = 'left', on = 'ID').fillna('')\ntest.head()\"\"\";","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with py7zr.SevenZipFile('../input/msk-redefining-cancer-treatment/stage2_test_text.csv.7z', mode='r') as z:\n    z.extractall()\nwith py7zr.SevenZipFile('../input/msk-redefining-cancer-treatment/stage2_test_variants.csv.7z', mode='r') as z:\n    z.extractall()\n\ntest_variants = pd.read_csv(\"./stage2_test_variants.csv\")\ntest_text =pd.read_csv(\"./stage2_test_text.csv\",sep=\"\\|\\|\",engine=\"python\",names=[\"ID\",\"TEXT\"],skiprows=1)\ntest = pd.merge(test_variants, test_text, how = 'left', on = 'ID').fillna('')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.concat([train, test]).reset_index(drop=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#График распределения классов\nmy_colors = list('rgbkymc')\ndf_all.Class.value_counts(sort=False).plot(kind='bar', color=my_colors);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.Class.value_counts(sort=False) / df_all.shape[0]*100","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 2. Предобработка текстовых данных","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"https://www.kaggle.com/sudalairajkumar/getting-started-with-text-preprocessing","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":" def preprocessing_text(text):\n    PUNCT_TO_REMOVE = string.punctuation\n    STOPWORDS = set(stopwords.words('english'))\n    \n    #Приводим текст к нижнему регистру\n    text = text.lower()\n    \n    #Удаляем символы пунктуации, они нам не нужны\n    text = text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n    \n    #Удаление стопслов\n    text = \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n    \n    #Удаление редких слов\n    cnt = Counter()\n    n_rare_words = 10\n    RAREWORDS = set([w for (w, wc) in cnt.most_common()[:-n_rare_words-1:-1]])\n    text = \" \".join([word for word in str(text).split() if word not in RAREWORDS])\n    \n    #Stemming - приводим слова к базовой форме\n    #stemmer = PorterStemmer()\n    #text = \" \".join([stemmer.stem(word) for word in text.split()])\n    \n    #Lemmatization - подобно стемматизации, но гарантия того, что слово принадлежит этому языку, работает медленнее\n    #lemmatizer = WordNetLemmatizer()\n    #wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n    #pos_tagged_text = nltk.pos_tag(text.split())    \n    #text = \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n    return text","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.loc[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preprocessing_text(df_all.TEXT[0])[:120]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\ndf_all['clean_text'] = df_all.TEXT.apply(lambda x: preprocessing_text(x))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Функция для подсчета слова в тексте, модет использоваться в качестве дополнительного генерирования фичей","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def count_words(TEXT, Gene_Var):\n    wordlist = TEXT.split(' ')\n    cnt = 0\n    for s in wordlist:\n        if (Gene_Var==s):\n            cnt+=1\n    return cnt","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Что можно еще добавить? как пример\n\n#df_all['Gene_cnt'] = df_all.apply(lambda x: count_words(x['TEXT'], x['Gene']), axis=1)\n#df_all['Variation_cnt'] = df_all.apply(lambda x: count_words(x['TEXT'], x['Variation']), axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Векторизация текста","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def Vectorize_text(text, max_features=250, ngram_range=(1, 2), min_df=1):\n    X_vect = list(text)\n    tfidf = TfidfVectorizer(min_df=min_df, ngram_range=ngram_range, max_features=max_features)\n    #X_vect = tfidf.fit_transform(text).toarray() \n    X_vect = pd.DataFrame(tfidf.fit_transform(X_vect).toarray(), index=text.index)      \n    return X_vect","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('df_all.pickle', 'wb') as handle:\n    pickle.dump(df_all, handle, protocol=pickle.HIGHEST_PROTOCOL)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_features = Vectorize_text(df_all['clean_text'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidf_features","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Декомпозиция","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"svd = TruncatedSVD(n_components=50, n_iter=5, random_state=0)\ntruncated_tfidf = svd.fit_transform(tfidf_features)\ndf_tfidf_col_name = [\"tfidf_\"+str(i) for i in range(50)]\ndf_tfidf = pd.DataFrame(truncated_tfidf)\ndf_tfidf.columns = df_tfidf_col_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tfidf[:4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Мешок слов","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"count_vectorizer = CountVectorizer(min_df=1, ngram_range=(1,1))\ncount_features = count_vectorizer.fit_transform(df_all['clean_text'])\ncount_svd = TruncatedSVD(n_components=50, n_iter=5, random_state=10)\ncount_bow = count_svd.fit_transform(count_features)\ndf_bow_col_name = [\"bow_\"+str(i) for i in range(50)]\ndf_bow = pd.DataFrame(count_bow)\ndf_bow.columns = df_bow_col_name","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_bow[:4]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Закодируем Gene и Variation, чтобы привести информацию в двоичный вид","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = pd.get_dummies(df_all, columns=['Gene', 'Variation'], drop_first=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Соединяем таблицы","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all = df_all.join(df_tfidf)\ndf_all = df_all.join(df_bow)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all[:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_all.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = df_all.iloc[:train.shape[0]]\nX = df_train.iloc[:,4:]\ny = df_train['Class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = df_all.iloc[train.shape[0]:]\nX_test = df_test.iloc[:,4:]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# 3. Обучение","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"## XGBClassifier","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Разбиваем на тренировочные данные и данные для валидации модели","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"#X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=10)\nX_train = X.copy()\ny_train = y.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Делаем поиск оптимальных гиперпараметров","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"\"\"\"\ndef score_func(estimator, X, y):\n    score1 = log_loss(y,estimator.predict(X,\n                           ntree_limit=estimator.best_ntree_limit),\n                          labels=list(range(1,10)))\n    return -score1\n\nxgb = XGBClassifier(\n    objective = 'multi:softprob',\n    eval_metric = 'mlogloss',\n    num_class = 9,\n    nthread=4,\n    seed=10\n)\n\nparameters = {\n    'max_depth': range (4, 7, 1),\n    'learning_rate': [0.1, 0.01, 0.05]\n}\n\ngrid_search = GridSearchCV(\n    estimator=xgb,\n    param_grid=parameters,\n    scoring = score_func,\n    n_jobs = 10,\n    cv = 3,\n    verbose=True\n)\n\ngrid_search.fit(X_train, y_train)\"\"\";","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Классы распознаются с 0, поэтому вычитаем 1, чтобы корректно запустился алгоритм, после, мы ее прибавим к нашему предикту","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = y_train-1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_param = {'objective': 'multi:softprob',\n          'eval_metric' : 'mlogloss',\n          'learning_rate' : 0.05,\n          'max_depth' : 5,\n          'num_class' : 9,\n          'nthread': 4,\n          'seed': 10}\n\ndtrain_xgb = xgb.DMatrix(X_train, label=y_train)\n\nxbg_result = xgb.cv(xgb_param, \n                    dtrain_xgb, \n                    num_boost_round=300, \n                    nfold=3,\n                    stratified=True, \n                    early_stopping_rounds=50, \n                    verbose_eval=100, \n                    show_stdv=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Выбираем номер наилучшего раунда","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"num_round_xgb = len(xbg_result['test-mlogloss-mean'])\nprint('num boost rounds xgb=' + str(num_round_xgb))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Тренируем нашу итоговую модель","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgb_cl = xgb.train(xgb_param, dtrain_xgb, num_boost_round=num_round_xgb)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Подготавливаем тестовые данные, чтобы модель воспринимала формат входных тестовых данных как и у тренировочных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"xgtest = xgb.DMatrix(X_test)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Предикт наших тестовых данных","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred = xgb_cl.predict(xgtest)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Создаем наш датафрейм и записываем итоговые результаты","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = ['class1', 'class2', 'class3', 'class4','class5', 'class6', 'class7', 'class8','class9']\nsubmit = pd.DataFrame(y_pred, columns=classes)\nsubmit['ID'] = test['ID'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submit = submit[['ID', 'class1', 'class2', 'class3', 'class4','class5', 'class6', 'class7', 'class8','class9']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Иииии записываем в наш файл! :)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submit.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}