{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Importing Libraries for loading dataset\nimport numpy as np\nimport pandas as pd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Iporting libraries for Data Visualisation\nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error, r2_score","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing training and validation set\nBuldozer_datasets = pd.read_csv('../input/bluebook-for-bulldozers/TrainAndValid.csv', low_memory=False)\nBuldozer_datasets.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring the data\nBuldozer_datasets.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing values\nBuldozer_datasets.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Plotting a scatter graph for comparism of data format\nfig, ax = plt.subplots()\nax.scatter(Buldozer_datasets[\"saledate\"][:1000], Buldozer_datasets['SalePrice'][:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets.saledate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the data set again with the correct saledate format\n# with time pharse data\nBuldozer_datasets = pd.read_csv('../input/bluebook-for-bulldozers/TrainAndValid.csv', low_memory=False, parse_dates=[\"saledate\"])\nBuldozer_datasets.head()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking to ensure the date format is correct\nBuldozer_datasets.saledate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets.saledate.dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ploting the same scatter plot with the correct date format\nfig, ax = plt.subplots()\nax.scatter(Buldozer_datasets[\"saledate\"][:1000], Buldozer_datasets['SalePrice'][:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Loading the transpose of the datasets\nBuldozer_datasets.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets.saledate.head(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort dataset in date order\nBuldozer_datasets.sort_values(by=[\"saledate\"], inplace=True, ascending=True)\nBuldozer_datasets.saledate.head(20)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Copy the original dataset\nBuldozer_datasets_df = Buldozer_datasets.copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df[\"saleYear\"]=Buldozer_datasets_df.saledate.dt.year\nBuldozer_datasets_df[\"saleMonth\"]=Buldozer_datasets_df.saledate.dt.month\nBuldozer_datasets_df[\"saleDay\"]=Buldozer_datasets_df.saledate.dt.day\nBuldozer_datasets_df[\"saleDayOfWeek\"]=Buldozer_datasets_df.saledate.dt.dayofweek\nBuldozer_datasets_df[\"saleDayOfYear\"]=Buldozer_datasets_df.saledate.dt.dayofyear\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.drop(\"saledate\", axis=1, inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.head(20).T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Exploring state in he buldozer dataset\nBuldozer_datasets_df.state.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting strings into categories data\npd.api.types.is_string_dtype(Buldozer_datasets_df[\"UsageBand\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the columns which contain strings\nfor label, content in Buldozer_datasets_df.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)\n        \n# .items() treats a dataset like a dictionary","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Converting strings values to categorical values\nfor label, content in Buldozer_datasets_df.items():\n    if pd.api.types.is_string_dtype(content):\n        Buldozer_datasets_df[label] = content.astype(\"category\").cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.state.cat.categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.state.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Access all the data in the form of numbers\nBuldozer_datasets_df.state.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing values\nBuldozer_datasets_df.isna().sum()/len(Buldozer_datasets_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save Preprocessed data\nBuldozer_datasets_df.to_csv(\"Buldozer_datasets.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing training and validation set\nBuldozer_datasets_df = pd.read_csv('./Buldozer_datasets.csv', low_memory=False)\nBuldozer_datasets_df.head().T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for missing values\nBuldozer_datasets_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Checking for missing data\n# Check for numerical data first\nfor label, content in Buldozer_datasets_df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for which numerical column has null values\nfor label, content in Buldozer_datasets_df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill numerical row with median\nfor label, content in Buldozer_datasets_df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum(): \n            \n            # Add a binary column which tells us if the data is missing\n            Buldozer_datasets_df[label+\"_is_missing\"] = pd.isnull(content)\n    \n            # Fill missing numerical values with median \n            Buldozer_datasets_df[label] = content.fillna(content.median())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check if there is any null numerical value\nfor label, content in Buldozer_datasets_df.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check how many examples are missing\nBuldozer_datasets_df.auctioneerID_is_missing.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill all the numeric missing values\nBuldozer_datasets_df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finding and turning category variables into numbers\nfor label, content in Buldozer_datasets_df.items():\n        if not pd.api.types.is_numeric_dtype(content):\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Categorical(Buldozer_datasets_df[\"state\"]).codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in Buldozer_datasets_df.items():\n    if not pd.api.types.is_numeric_dtype(content):\n            \n            # Add a binary column which tells us if the data is missing\n            Buldozer_datasets_df[label+\"_is_missing\"] = pd.isnull(content)\n    \n            # Turn categories into numbers and add 1 \n            Buldozer_datasets_df[label] = pd.Categorical(content).codes +1  ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# See if all missing data are being resolved\nBuldozer_datasets_df.isna().sum()[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Instantiate model\nmodel = RandomForestRegressor(n_jobs=-1, random_state=42)\n\n# Fit the model\nmodel.fit(Buldozer_datasets_df.drop(\"SalePrice\", axis=1), Buldozer_datasets_df[\"SalePrice\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Score the model\n# Calculating the coefficient of determination (R^2)\nmodel.score(Buldozer_datasets_df.drop(\"SalePrice\", axis=1), Buldozer_datasets_df[\"SalePrice\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into train and validation set\nBuldozer_datasets_df.saleYear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Buldozer_datasets_df.saleYear.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating your own train and validation set\ndf_val = Buldozer_datasets_df[Buldozer_datasets_df.saleYear == 2012]\ndf_train = Buldozer_datasets_df[Buldozer_datasets_df.saleYear != 2012]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into X and Y\nX_train, y_train = df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\nX_valid, y_valid = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice\n\nX_train.shape, y_train.shape, X_valid.shape, y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating evaluation function(the competition uses RMLSE)\n\ndef RMSLE(y_test, y_preds):\n    \n    \"\"\"\n    Calculate the RMSLE between predictions and true labels\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n    \n    \n# Create function to evaluate model on a few different level\ndef show_scores(model):\n    train_preds = model.predict(X_train)\n    val_preds = model.predict(X_valid)\n    \n    scores = {\"Training MAE\": mean_absolute_error(y_train, train_preds),\n             \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n             \"Training RMSLE\": RMSLE(y_train, train_preds),\n             \"Valid RMSLE\": RMSLE(y_valid, val_preds),\n             \"Training R^2\": r2_score(y_train, train_preds),\n             \"Valid R^2\": r2_score(y_valid, val_preds)}\n    return scores","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tune the hyperparameters\n# Change the mix samples value\nmodel = RandomForestRegressor(n_jobs=-1,\n                             random_state=42,\n                             max_samples= 10000)\nmodel","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Show the scores\nshow_scores(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Hyperparameter tunning with RandomizedSearchCV\n\nrf_grid ={\"n_estimators\":np.arange(10, 100, 10),\n          \"max_depth\":[None, 3, 5, 10],\n          \"min_samples_split\":np.arange(2, 20, 2),\n          \"min_samples_leaf\":np.arange(1, 20, 2),\n          \"max_features\":[0.5, 1, \"sqrt\", \"auto\"],\n          \"max_samples\":[10000]}\n\n# Instatiate RandomizedSearchCV model\nrs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n                                                    random_state=42),\n                              param_distributions = rf_grid,\n                              n_iter = 2,\n                              cv = 5,\n                              verbose = True)\n                              \n# Fit the RandomizedSearchCV\nrs_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the best model hyperparmeters\nrs_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Evaluate the RandomizedSearchCV model\nshow_scores(model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n# Most Ideal hyperparameter\nIdeal_model = RandomForestRegressor(n_estimators=10,\n                                    min_samples_split=2,\n                                    min_samples_leaf=19,\n                                    max_samples=None,\n                                    max_features=0.5,\n                                    n_jobs=-1,\n                                    random_state=42)\n# Fit the model\nIdeal_model.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_scores(Ideal_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing test csv\ntest_csv = pd.read_csv('../input/bluebook-for-bulldozers/Test.csv', low_memory=False, parse_dates=[\"saledate\"])\ntest_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions on the test datasets\ntest_preds = Ideal_model.predict(test_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(df):\n    \"\"\"\n    Perform transformation on df and return transormed df.\n    \"\"\"\n    df[\"saleYear\"]=df.saledate.dt.year\n    df[\"saleMonth\"]=df.saledate.dt.month\n    df[\"saleDay\"]=df.saledate.dt.day\n    df[\"saleDayOfWeek\"]=df.saledate.dt.dayofweek\n    df[\"saleDayOfYear\"]=df.saledate.dt.dayofyear\n    \n    df.drop(\"saledate\", axis=1, inplace=True)\n    \n    # Fill the numeric rows with median\n    for label, content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum(): \n            \n                # Add a binary column which tells us if the data is missing\n                df[label+\"_is_missing\"] = pd.isnull(content)\n    \n                # Fill missing numerical values with median \n                df[label] = content.fillna(content.median())\n    \n        # Filled categorical missing data and turn categories into numbers\n        if not pd.api.types.is_numeric_dtype(content):\n                df[label+\"_is_missing\"] = pd.isnull(content)\n            \n                # We would add +1 to the categorical code because pandas encode missing data as -1\n                df[label] = pd.Categorical(content).codes+1\n            \n        return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Process the test data\ntest_csv = preprocess_data(test_csv)\ntest_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can find how he column differ using set\nset(X_train.columns) - set(test_csv.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# manually adjust the missing ones\ntest_csv[\"Backhoe_Mounting_is_missing\"] = False\ntest_csv[\"state_is_missing\"] = False\ntest_csv[\"fiSecondaryDesc_is_missing\"] = False\ntest_csv[\"fiProductClassDesc_is_missing\"] = False\ntest_csv[\"fiModelSeries_is_missing\"] = False\ntest_csv[\"fiModelDescriptor_is_missing\"] = False\ntest_csv[\"fiModelDesc_is_missing\"] = False\ntest_csv[\"fiBaseModel_is_missing\"] = False\ntest_csv[\"autioneerID_is_missing\"] = False\ntest_csv[\"UsageBand_is_missingg\"] = False\ntest_csv[\"Undercarriage_Pad_Width_is_missing\"] = False\ntest_csv[\"Turbocharged_is_missing\"] = False\ntest_csv[\"Travel_Controls_is_missing\"] = False\ntest_csv[\"Transmission_is_missing\"] = False\ntest_csv[\"Track_Type_is_missing\"] = False\ntest_csv[\"Tire_Size_is_missing\"] = False\ntest_csv[\"Tip_Control_is_missing\"] = False\ntest_csv[\"Thumb_is_missing\"] = False\ntest_csv[\"Stick_is_missing\"] = False\ntest_csv[\"Stick_Length_is_missing\"] = False\ntest_csv[\"Steering_Controls_is_missing\"] = False\ntest_csv[\"Scarifier_is_missing\"] = False\ntest_csv[\"Ripper_is_missing\"] = False\ntest_csv[\"Ride_Control_is_missing\"] = False\ntest_csv[\"Pushblock_is_missing\"] = False\ntest_csv[\"ProductSize_is_missing\"] = False\ntest_csv[\"ProductGroup_is_missing\"] = False\ntest_csv[\"ProductGroupDesc_is_missing\"] = False\ntest_csv[\"Pattern_Changer_is_missing\"] = False\ntest_csv[\"Pad_Type_is_missing\"] = False\ntest_csv[\"MachineHoursCurrentMeter_is_missing\"] = False\ntest_csv[\"Hydraulics_is_missing\"] = False\ntest_csv[\"Hydraulics_Flow_is_missing\"] = False\ntest_csv[\"Grouser_Type_is_missing\"] = False\ntest_csv[\"Grouser_Tracks_is_missing\"] = False\ntest_csv[\"Forks_is_missing\"] = False\ntest_csv[\"Engine_Horsepower_is_missing\"] = False\ntest_csv[\"Enclosure_is_missing\"] = False\ntest_csv[\"Enclosure_Type_is_missing\"] = False\ntest_csv[\"Drive_System_is_missing\"] = False\ntest_csv[\"Differential_Type_is_missing\"] = False\ntest_csv[\"Coupler_is_missing\"] = False\ntest_csv[\"Coupler_System_is_missing\"] = False\ntest_csv[\"Blade_Width_is_missing\"] = False\ntest_csv[\"Blade_Type_is_missing\"] = False\ntest_csv[\"Blade_Extension_is_missing\"] = False\ntest_csv[\"Backhoe_Mounting_is_missing\"] = False\ntest_csv[\"autioneerID_is_missing\"] = False\ntest_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can find how he column differ using set again\nset(X_train.columns) - set(test_csv.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv[\"autioneerID_is_missing\"] = False\ntest_csv[\"UsageBand_is_missing\"] = False\ntest_csv.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Finally we make prdictions on the data\n# Make predictions on the test datasets\ntest_preds = model.predict(test_csv)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_csv.dtypes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}