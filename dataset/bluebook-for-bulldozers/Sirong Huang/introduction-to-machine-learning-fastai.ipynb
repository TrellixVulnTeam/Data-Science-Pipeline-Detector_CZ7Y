{"cells":[{"metadata":{"trusted":true,"_uuid":"0f2517f665e8f54d5835f627124c2f7b060e6bda"},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\ndatafolder = \"../input\"\n!ls {datafolder}","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd\n\nfrom fastai.tabular.transform import *\nfrom fastai.tabular.data import TabularDataBunch\n\nfrom sklearn import metrics\nfrom sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"a264d39564bbb86ac807d77c9676340034e83e23"},"cell_type":"markdown","source":"## Data import & first look"},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"df_raw = pd.read_csv(f'{datafolder}/train/Train.csv', low_memory=False, parse_dates=['saledate'])\ndf_raw.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c5cc54db2665e1e97d07c7ef9b1f4c8f4d20a50a"},"cell_type":"code","source":"# show first 10 rows\ndisplay(df_raw.iloc[:10])\n# summary statistics of each variable \ndisplay(df_raw.describe(include='all').T)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b20f1007d945f80c07d7c8f9abfd465942a8ab96"},"cell_type":"markdown","source":"## Performance measurement - Loss function\n\n- The loss function is:  **root mean squared log error** <=> **percentage price difference**\n- Log difference describes percentage increase/decrease, which is more meaning than absolute number when comparing price \n  - log(a) - log(b) = log(a/b) "},{"metadata":{"trusted":true,"_uuid":"b9af81d71b96820df0391a43f67b65f43ba78010"},"cell_type":"code","source":"# Personally I think creating a new variable is better than replacing SalePrice with log(SalePrice) in place,\n# because it avoids being transformed by log twice without giving error when the cell is rerun\ndf_raw['logSalePrice'] = np.log(df_raw['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"cc717467ffd9e0a54b3080c515fbe1657924ed3f"},"cell_type":"markdown","source":"## Feature engineering\n\n### Principle\n1. Convert to numerical values\n    - most machine learning model only accept numerical datatype, therefore we must convert any other type of data to numerical values\n2. The more features the merrier\n    -  include all the possible features you can think of that might be helpful, redundancy is not a concern (subject to imperical testing)\n3. Fill missing values (NA)\n4. Normalization (eg. 0 mean, 1 standard deivation)\n\n### Practice\nDocs: https://docs.fast.ai/tabular.transform.html\n<br>\nfrom fastai.tabular.transform import *\n1.  - categorical -> numerical\n        - Categorify()\n    - datetime -> numerical\n        - add_datepart()\n2. __data scientist's job!__\n3. FillMissing()\n    - categorical \n        - NA=-1 by default\n        - +1 to all categories\n        - now NA=0\n    - numerical\n        - NA replaced by median by default\n        - other strategies: mean, mode, specific number etc.\n4. Normalize()\n\n### Automate everything!\nfrom fastai.tabular import \n"},{"metadata":{"trusted":true,"_uuid":"47232d11cfeb0d5c86db579996e73eafcc542e93"},"cell_type":"code","source":"# display the datatype and number of NAs of a dataframe\ndef info(df):\n    datatypes = pd.Series(df.dtypes, name='datatype')\n    na_count = pd.Series(df.isna().sum(), name='na_count')\n    with pd.option_context('display.max_rows',1000,'display.max_columns',1000):\n        display(pd.concat([datatypes, na_count],axis=1))\ninfo(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f9abdeb1bca884fbe29a106eca7de840511e93a5"},"cell_type":"code","source":"# return list of columns of specific datatypes \ndef datatype(df):\n    date_cols = df.select_dtypes(include=['datetime']).columns.tolist()\n    num_cols = df.select_dtypes(include=['number','bool']).columns.tolist()\n    cat_cols = df.select_dtypes(include=['object']).columns.tolist() # may contain other type of data\n    print(f\"Date columns: {date_cols} \\n\\nNumerical columns:{num_cols} \\n\\nString columns: {cat_cols}\")\n    return date_cols, num_cols, cat_cols\ndate_cols, num_cols, cat_cols = datatype(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d0432ca367a19fdb6e642c6f7543940bf1a8e1f9"},"cell_type":"code","source":"# converts datetime dtype to numerical/boolean dtype \n# in the mean time, adds bunch of generic features generated from datetime\nadd_datepart(df_raw, 'saledate')\n\n# converts string to categorical dtype\ncat_to_num = Categorify(cat_cols, num_cols)\ncat_to_num(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fcb0867980a66542201cf06e99b8c3c524c29ce0"},"cell_type":"code","source":"# now all the dtype are acceptable by machine learning models\ninfo(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ce436cd188db1816aa717d903b0fb1531ed98000"},"cell_type":"code","source":"# fill missing values \nfillNA = FillMissing(cat_cols,num_cols)\nfillNA(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d47f080c6b287f462860e186c2067b08583f25d7"},"cell_type":"code","source":"# x: features y: labels \nx = df_raw.drop(['logSalePrice','SalePrice'],axis=1) \ny = df_raw['logSalePrice']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8a14192c441142800bf8ecb1385b017f9073fb74"},"cell_type":"code","source":"# automate all\npreprocessing = [Categorify, FillMissing, Normalize]\ndata = TabularDataBunch.from_df(f'{datafolder}/train/', df_raw, dep_var='logSalePrice', valid_idx=range(len(df)-2000, len(df_raw)-1),\n                                procs=preprocessing, cat_names=cat_cols)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"57de69c30d52f1c27b316e61bae9f5dffae446c9"},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"243068b280641b62f9e468ccfe40eb30bc342a80"},"cell_type":"markdown","source":"## Random Forest\n\n\"bagging of weaker decision tress\"\n- bootstrapping(draw with replacement) of weaker decisions trees trained on a subset of the data\n- the less correlated the the tress are, the better (most importantly)\n- the more accurate the trees are, the better \n\n### Pros:\n- works well universally\n- suitable for any data type and both classification and regression problem\n- little to no statistical assumptions such as independence, normal distributed, linear relationship, interaction modeled etc.\n- requires little to no preprocessing such as normalization etc. \n- doesn't tend to overfit, easy to prevent overfitting \n- don't require validation set, it can tell how well it generalize on the training data alone\n\n### How: "},{"metadata":{"trusted":true,"_uuid":"4f6c620ab025cf34dca3f302e4840b688a46fb73"},"cell_type":"code","source":"#randomforest = RandomForestRegressor(n_jobs=-1) # n_jobs=-1: use all CPUs, n_jobs=1: no parallelism\n#randomforest.fit(x, y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ec65d574f911c16f997028606a261dcfe1bd84c7"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0a9ac0bf2319833e3ced99964a480e292f736523"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3ae1794ea2134429ff881fdc586944ed795128c6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a8832b362d6acb3995502804ae7ab85f6f287886"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}