{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"scrolled":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport sklearn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df = pd.read_csv('../input/bluebook-for-bulldozers/TrainAndValid.csv',low_memory=False)\ndf.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nax.scatter(df['saledate'][:1000],df['SalePrice'][:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true},"cell_type":"code","source":"df['SalePrice'].plot.hist()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.saledate.dtype","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Parsing Dates\n\nwhen we work with the time series data, we want to enrich the time & date component as much as possible.\n\nwe can do that by telling pandas which of our columns has dates in it using `parse_dates` parameter.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Import data again but this time parse dates\ndf = pd.read_csv('../input/bluebook-for-bulldozers/TrainAndValid.csv',low_memory=False,\n                parse_dates=['saledate'])\ndf.saledate.dtype\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df['saledate'][:5]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig,ax = plt.subplots()\nax.scatter(df['saledate'][:1000],df['SalePrice'][:1000])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head().T","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Sort DataFrame by saledate\nWhen working with time series data, it's a good idea to sort it by date.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Sort dataframe by date order.\ndf.sort_values(by=['saledate'],inplace=True,ascending=True)\ndf.saledate.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make a copy of the original DataFrame.\ndf_tmp = df.copy()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Add datetime parameters for saledate column","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp['saleYear'] = df_tmp.saledate.dt.year\ndf_tmp['saleMonth'] = df_tmp.saledate.dt.month\ndf_tmp['saleDay'] = df_tmp.saledate.dt.day\ndf_tmp['saleDayOfWeek'] = df_tmp.saledate.dt.dayofweek\ndf_tmp['saleDayOfYear'] = df_tmp.saledate.dt.dayofyear","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.head().T","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now we can remove saledate\ndf_tmp.drop('saledate',axis=1,inplace=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.state.value_counts()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Modelling","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor\n\nmodel = RandomForestRegressor(n_jobs=-1,\n                             random_state=42)\nmodel.fit(df_tmp.drop('SalePrice',axis=1),df_tmp['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Convert String to categories\n\nOne way we can turn all of our data into numbers is by converting them into pandas categories.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.api.types.is_string_dtype(df_tmp['UsageBand'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Find the columns which contains strings\nfor label, content in df_tmp.items():\n    if pd.api.types.is_string_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for label, content in df_tmp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_tmp[label] = content.astype('category').cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.state.cat.categories","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.state.cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# check missing data\ndf_tmp.isnull().sum()/len(df_tmp)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Fill missing values","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Fill numeric columns first","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"for label,content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for which nuemeric columns have null values:\nfor label,content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Fill missing rows with median\nfor label,content in df_tmp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            df_tmp[label+'_is_missing'] = pd.isnull(content)\n            df_tmp[label] = content.fillna(content.median())\n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.isna().sum()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Filling and turning categorical variables into numbers","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Check for columns which aren't numeric:\nfor label,content in df_tmp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pd.Categorical(df_tmp['state']).codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Turn categorical variables into numbers and fill missing\nfor label,content in df_tmp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        df_tmp[label+'_is_missing'] = pd.isnull(content)\n        df_tmp[label] = pd.Categorical(content).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(n_jobs=-1,\n                             random_state=42)\nmodel.fit(df_tmp.drop('SalePrice',axis=1),df_tmp['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.score(df_tmp.drop('SalePrice',axis=1),df_tmp['SalePrice'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_tmp.saleYear.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Splitting data into training and validation sets\ndf_val = df_tmp[df_tmp.saleYear== 2012]\ndf_train = df_tmp[df_tmp.saleYear != 2012]\nlen(df_val), len(df_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Split into X and y\nX_train,y_train = df_train.drop('SalePrice',axis=1),df_train['SalePrice']\nX_valid,y_valid = df_val.drop('SalePrice',axis=1),df_val['SalePrice']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Building an evaluation Function","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"# Creating a RMSLE\nfrom sklearn.metrics import mean_squared_log_error,mean_absolute_error,r2_score\ndef rmsle(y_test,y_preds):\n    \n    return np.sqrt(mean_squared_log_error(y_test,y_preds))\ndef show_scores(model):\n    train_preds = model.predict(X_train)\n    val_preds = model.predict(X_valid)\n    scores = {'Training MAE':mean_absolute_error(y_train,train_preds),\n             'Valid MAE':mean_absolute_error(y_valid,val_preds),\n             'Traing RMSLE':rmsle(y_train,train_preds),\n             'valid Rmsle':rmsle(y_valid,val_preds),\n             'Training R^2': r2_score(y_train,train_preds),\n             'valid R^2':r2_score(y_valid,val_preds)}\n    return scores","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Testing model on a subset( to Tune Hyperparameters)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nmodel = RandomForestRegressor(n_jobs=-1,\n                             random_state=42)\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = RandomForestRegressor(n_jobs=-1,\n                             random_state=42,\n                              max_samples=10000,)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\n\nmodel.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_scores(model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Hyperparameter Tuning with RandomizedSearchCV","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import RandomizedSearchCV\n\nrf_grid ={'n_estimators':np.arange(10,100,10),\n         'max_depth':[None,3,5,10],\n         'min_samples_split':np.arange(2,20,2),\n         'min_samples_leaf':np.arange(1,20,2),\n         'max_features':[0.5,1,'sqrt','auto'],\n         'max_samples':[10000]}\nrs_model = RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n                                                   random_state=42,),\n                                                   param_distributions=rf_grid,\n                                                   n_iter=5,\n                                                   cv=5,\n                                                   verbose=True)\nrs_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rs_model.best_params_","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_scores(rs_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%time\nideal_model = RandomForestRegressor(n_estimators=90,\n                                   min_samples_split= 2,\n                                    min_samples_leaf= 13,\n                                   max_samples= 10000,\n                                   max_features= 'sqrt',\n                                   max_depth= None,\n                                   n_jobs=-1)\nideal_model.fit(X_train,y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"show_scores(ideal_model)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Make predictions on Test Data","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test = pd.read_csv('../input/bluebook-for-bulldozers/Test.csv',\n                     low_memory=False,\n                     parse_dates=['saledate'])\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = ideal_model.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### preprocessing the data (getting the test dataset as training data)","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_data(df):\n    \"\"\"\n    Perform transformations on df and return transformed df.\n    \n    \"\"\"\n    # parse date\n    df['saleYear'] = df.saledate.dt.year\n    df['saleMonth'] = df.saledate.dt.month\n    df['saleDay'] = df.saledate.dt.day\n    df['saleDayOfWeek'] = df.saledate.dt.dayofweek\n    df['saleDayOfYear'] = df.saledate.dt.dayofyear\n    \n    df.drop('saledate',axis=1,inplace=True)\n    \n    # Fill the numeric rows with median\n    for label,content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                df[label+'_is_missing']=pd.isnull(content)\n                df[label] = content.fillna(content.median())\n                \n    # Fill categorical missing data and turn categories into numbers\n    for label,content in df.items():\n        if not pd.api.types.is_numeric_dtype(content):\n            df[label+'_is_missing']=pd.isnull(content)\n            #we add +1 to category code\n            df[label] = pd.Categorical(content).codes+1\n            \n    \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# process test data\ndf_test = preprocess_data(df_test)\ndf_test.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Make predictions on updated test data\ntest_preds = ideal_model.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# We can find how the columns differ using sets\nset(X_train.columns)-set(df_test.columns)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Manually adjust df_test to have auctioneerID_is_missing column\ndf_test['auctioneerID_is_missing']=False\ndf_test","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds = ideal_model.predict(df_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Format the predictions into the same format Kaggle is after:\ndf_preds = pd.DataFrame()\ndf_preds['SalesID'] =df_test['SalesID']\ndf_preds['SalesPrice'] = test_preds\ndf_preds\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}