{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Random Forest"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\n\nfrom IPython.display import display\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn import metrics\nfrom fastai.tabular import cont_cat_split, add_datepart","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw_train = pd.read_csv(\"../input/train/Train.csv\", parse_dates=[\"saledate\"], low_memory=False)\ndf_raw_test = pd.read_csv(\"../input/Test.csv\", parse_dates=[\"saledate\"], low_memory=False)\ndf_raw_valid = pd.read_csv(\"../input/Valid.csv\", parse_dates=[\"saledate\"], low_memory=False)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Feature Engineering\n* `fastai` does the work of splitting dates into subcomponents\n* find continuous and categorical variables. \n* fill `nan` with the median for continuous variables\n* make sure categorical variables are the right type.\n* drop null columns"},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_features(frame):\n    df = frame.copy()\n    df = add_datepart(df, 'saledate') \n    cont_cols, cat_cols = cont_cat_split(df)\n\n    for col in cont_cols:\n        if pd.isnull(df[col]).sum(): \n            df.drop(col, axis=1)\n        df[col] = df[col].fillna(df[col].median())\n\n    df[cat_cols] = df[cat_cols].astype('category')\n    for col in cat_cols:\n        df[col] = df[col].cat.codes + 1\n        \n    return df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_train = build_features(df_raw_train)\ndf_test = build_features(df_raw_test)\ndf_valid = build_features(df_raw_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.makedirs(\"tmp\", exist_ok=True)\ndf_train.to_feather(\"tmp/features\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, train_test_split\n\nlabel = 'SalePrice'\n\ndf_train[label] = np.log(df_train[label])\n\n# split based on time\ndef split_vals(a, n): \n    return a[:n].copy(), a[n:].copy()\n\nn_valid = 12000\nn_trn = len(df_train) - n_valid\n\n# cols_to_drop = [c for c in df_train.columns if c[-3:] == \"_na\"] + [label]\nx = df_train.drop(label, axis=1)\ny = df_train[label]\n\nfeature_cols = x.columns\n\nx_train, x_valid = split_vals(x, n_trn)\ny_train, y_valid = split_vals(y, n_trn)\n\n[x.shape for x in [x_train, x_valid]]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def rmse(x, y): \n    return np.sqrt(metrics.mean_squared_error(x, y))\n\ndef print_score(m):\n    res = [rmse(m.predict(x_train), y_train),\n           rmse(m.predict(x_valid), y_valid),\n           m.score(x_train, y_train),\n           m.score(x_valid, y_valid)]\n    \n    if hasattr(m, \"oob_score_\"):\n        res.append(m.oob_score_)\n    print(res)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rgs = ExtraTreesRegressor(n_estimators=10, n_jobs=-1)\n%time rgs.fit(x_train, y_train)\n\nprint_score(rgs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_test[label] = rgs.predict(df_test[feature_cols])\ndf_test[['SalesID', label]].to_csv(\"submission.csv\", index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}