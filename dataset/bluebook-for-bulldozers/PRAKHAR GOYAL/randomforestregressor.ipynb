{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn_pandas import DataFrameMapper\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler\nfrom sklearn.ensemble import forest\nfrom sklearn.tree import export_graphviz","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw = pd.read_csv(\"/kaggle/input/bluebook-for-bulldozers/TrainAndValid.csv\" , low_memory=False   , parse_dates=[\"saledate\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.saledate","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw[\"sale_year\"] = df_raw.saledate.dt.year\ndf_raw[\"sale_date\"] = df_raw.saledate.dt.day\ndf_raw[\"sale_month\"] = df_raw.saledate.dt.month","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw1 = df_raw.drop('saledate',axis = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw1.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pandas.api.types import is_string_dtype,is_numeric_dtype","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def train_cats(df):\n    for l,c in df.items():\n        df[l] = c.astype('category').cat.as_ordered()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_cats(df_raw1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw.SalePrice = np.log(df_raw.SalePrice)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.ensemble import RandomForestRegressor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw1.isnull().sum().sort_index()/len(df_raw)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def scale_vars(df, mapper):\n    warnings.filterwarnings('ignore', category=sklearn.exceptions.DataConversionWarning)\n    if mapper is None:\n        map_f = [([n],StandardScaler()) for n in df.columns if is_numeric_dtype(df[n])]\n        mapper = DataFrameMapper(map_f).fit(df)\n    df[mapper.transformed_names_] = mapper.transform(df)\n    return mapper","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_sample(df,n):\n    idxs = sorted(np.random.permutation(len(df))[:n])\n    return df.iloc[idxs].copy()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def numericalize(df, col, name, max_n_cat):\n    if not is_numeric_dtype(col) and ( max_n_cat is None or len(col.cat.categories)>max_n_cat):\n        df[name] = pd.Categorical(col).codes+1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fix_missing(df,col,name,na_dict):\n    if is_numeric_dtype(col):\n        if pd.isnull(col).sum() or (name in na_dict):\n            df[name+'_na'] = pd.isnull(col)\n            if name in na_dict:\n                filler = na_dict[name]\n            else:\n                col.median()\n            df[name] = col.fillna(filler)\n            na_dict[name] = filler\n    return na_dict        \n            \n            \n                \n            \n            ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def proc_df(df, y_fld=None, skip_flds=None, ignore_flds=None, do_scale=False, na_dict=None, \n            preproc_fn=None, max_n_cat=None, subset=None, mapper=None):\n    \n    if not ignore_flds:\n        ignore_flds=[]\n    if not skip_flds:\n        skip_flds=[]\n    if subset:\n        df = get_sample(df,subset)\n    else:\n        df = df.copy()\n    ignored_flds = df.loc[:,ignore_flds]\n    df.drop(ignore_flds,axis = 1, inplace = True)\n    if preproc_fn:\n        preproc_fn(df)\n    if y_fld is None:\n        y = None\n    else:\n        if not is_numeric_dtype(df[y_fld]):\n            df[y_fld] = pd.Categorical(df[y_fld]).codes\n        y = df[y_fld].values\n        skip_flds += [y_fld]\n    df.drop(skip_flds , axis=1,inplace = True)\n    \n    if na_dict is None:\n        na_dict={}\n    else:\n        na_dict = na_dict.copy()\n    na_dict_initial = na_dict.copy()\n    for l,c in df.items():\n        na_dict = fix_missing(df,c,l,na_dict)\n    if len(na_dict_initial.keys()) > 0:\n        df.drop([a + '_na' for a in list(set(na_dict.keys()) - set(na_dict_initial.keys()))], axis = 1, inplace = True)\n    if do_scale:\n        mapper = scale_vars(df,mapper)\n    for l,c in df.items():\n        numericalize(df,c,l,max_n_cat)\n    df = pd.get_dummies(df,dummy_na = True)\n    df = pd.concat([ignored_flds, df], axis=1)\n    res = [df,y,na_dict]\n    if do_scale:\n        res = res+[mapper]\n    return res    \n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df , y , nas = proc_df(df_raw1, 'SalePrice')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_jobs=-1)\nm.fit(df,y)\nm.score(df,y)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_vals(a,n):\n    return a[:n].copy(), a[n:].copy()\nn_valid = 12000\nn_trn = len(df) - n_valid\nraw_train, raw_valid  = split_vals(df_raw1, n_trn)\nX_train, X_valid = split_vals(df, n_trn)\ny_train, y_valid = split_vals(y, n_trn)\nX_train.shape,X_valid.shape,y_train.shape,y_valid.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import math\ndef rmse(x,y):\n    return math.sqrt(((x-y)**2).mean())\ndef print_score(m):\n    res = [rmse(m.predict(X_train),y_train), rmse(m.predict(X_valid) , y_valid)]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_jobs=-1)\n%time m.fit(X_train, y_train)\nprint_score(m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":4}