{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# ðŸšœ Predicting the Sale Price of Bulldozers using Machine Learning\nIn this notebook, we're going to go through an example machine learning project with the goal of predicting the sale price of bulldozers.\n\n### 1. Problem defition\nHow well can we predict the future sale price of a bulldozer, given its characteristics and previous examples of how much similar bulldozers have been sold for?\n\n### 2. Data\nThe data is downloaded from the Kaggle Bluebook for Bulldozers competition: https://www.kaggle.com/c/bluebook-for-bulldozers/data\n\nThere are 3 main datasets:\n\n* Train.csv is the training set, which contains data through the end of 2011.\n* Valid.csv is the validation set, which contains data from January 1, 2012 - April 30, 2012 You make predictions on this set throughout the majority of the competition. Our score on this set is used to create the public leaderboard.\n* Test.csv is the test set, which won't be released until the last week of the competition. It contains data from May 1, 2012 - November 2012. Your score on the test set determines your final rank for the competition.\n\n\n### 3. Evaluation\nThe evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n\nFor more on the evaluation of this project check: https://www.kaggle.com/c/bluebook-for-bulldozers/overview/evaluation\n\nNote: The goal for most regression evaluation metrics is to minimize the error. For example, our goal for this project will be to build a machine learning model which minimises RMSLE.\n\n### 4. Features\nKaggle provides a data dictionary detailing all of the features of the dataset. You can view this data dictionary on Google Sheets: https://docs.google.com/spreadsheets/d/18ly-bLR8sbDJLITkWG7ozKm8l3RyieQ2Fpgix-beSYI/edit?usp=sharing","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.ensemble import RandomForestRegressor","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:24:49.580217Z","iopub.execute_input":"2021-05-24T17:24:49.580597Z","iopub.status.idle":"2021-05-24T17:24:50.906458Z","shell.execute_reply.started":"2021-05-24T17:24:49.580566Z","shell.execute_reply":"2021-05-24T17:24:50.905397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# import Data (training and validation sets)\ndf = pd.read_csv(\"../input/bluebook-for-bulldozers/TrainAndValid.csv\", low_memory=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:24:50.907988Z","iopub.execute_input":"2021-05-24T17:24:50.908283Z","iopub.status.idle":"2021-05-24T17:24:56.182688Z","shell.execute_reply.started":"2021-05-24T17:24:50.908255Z","shell.execute_reply":"2021-05-24T17:24:56.181592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:24:56.184195Z","iopub.execute_input":"2021-05-24T17:24:56.184458Z","iopub.status.idle":"2021-05-24T17:24:57.268575Z","shell.execute_reply.started":"2021-05-24T17:24:56.184432Z","shell.execute_reply":"2021-05-24T17:24:57.267365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:24:57.270652Z","iopub.execute_input":"2021-05-24T17:24:57.271064Z","iopub.status.idle":"2021-05-24T17:24:58.353159Z","shell.execute_reply.started":"2021-05-24T17:24:57.271024Z","shell.execute_reply":"2021-05-24T17:24:58.352093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax =  plt.subplots()\nax.scatter(df[\"saledate\"][:1000], df.SalePrice[:1000])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:24:58.354541Z","iopub.execute_input":"2021-05-24T17:24:58.354828Z","iopub.status.idle":"2021-05-24T17:25:01.583805Z","shell.execute_reply.started":"2021-05-24T17:24:58.354799Z","shell.execute_reply":"2021-05-24T17:25:01.582772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.SalePrice.plot.hist();","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:01.585659Z","iopub.execute_input":"2021-05-24T17:25:01.586107Z","iopub.status.idle":"2021-05-24T17:25:01.826472Z","shell.execute_reply.started":"2021-05-24T17:25:01.586063Z","shell.execute_reply":"2021-05-24T17:25:01.825369Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Parsing Dates\nWhen we work with timeseries data, we want to enrich the time and Date coponent\nas much a possible\n\nWe can do that by telling pandas which of our columns has dates in it using 'pars date' parameter","metadata":{}},{"cell_type":"code","source":"# Import data but this time parae dates\n\ndf=pd.read_csv(\"../input/bluebook-for-bulldozers/TrainAndValid.csv\", low_memory=False, parse_dates=[\"saledate\"] )","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:01.828146Z","iopub.execute_input":"2021-05-24T17:25:01.828626Z","iopub.status.idle":"2021-05-24T17:25:06.508422Z","shell.execute_reply.started":"2021-05-24T17:25:01.828581Z","shell.execute_reply":"2021-05-24T17:25:06.507358Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.saledate.dtype","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:06.511058Z","iopub.execute_input":"2021-05-24T17:25:06.511351Z","iopub.status.idle":"2021-05-24T17:25:06.517837Z","shell.execute_reply.started":"2021-05-24T17:25:06.511322Z","shell.execute_reply":"2021-05-24T17:25:06.516784Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.saledate[:1000]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:06.520302Z","iopub.execute_input":"2021-05-24T17:25:06.520777Z","iopub.status.idle":"2021-05-24T17:25:06.534449Z","shell.execute_reply.started":"2021-05-24T17:25:06.520736Z","shell.execute_reply":"2021-05-24T17:25:06.533466Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, ax= plt.subplots()\n\nax.scatter(df.saledate[:1000], df.SalePrice[:1000])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:06.535909Z","iopub.execute_input":"2021-05-24T17:25:06.536235Z","iopub.status.idle":"2021-05-24T17:25:06.734055Z","shell.execute_reply.started":"2021-05-24T17:25:06.536206Z","shell.execute_reply":"2021-05-24T17:25:06.73299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:06.73548Z","iopub.execute_input":"2021-05-24T17:25:06.735808Z","iopub.status.idle":"2021-05-24T17:25:06.769905Z","shell.execute_reply.started":"2021-05-24T17:25:06.735752Z","shell.execute_reply":"2021-05-24T17:25:06.768805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head().T","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:06.771393Z","iopub.execute_input":"2021-05-24T17:25:06.771817Z","iopub.status.idle":"2021-05-24T17:25:06.798918Z","shell.execute_reply.started":"2021-05-24T17:25:06.771775Z","shell.execute_reply":"2021-05-24T17:25:06.797858Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.saledate.head(20)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:06.800278Z","iopub.execute_input":"2021-05-24T17:25:06.800611Z","iopub.status.idle":"2021-05-24T17:25:06.817272Z","shell.execute_reply.started":"2021-05-24T17:25:06.800576Z","shell.execute_reply":"2021-05-24T17:25:06.816563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Sort DataFrame by saledateÂ¶\nWhen working with time series data, it's a good idea to sort it by date.","metadata":{}},{"cell_type":"code","source":"df.sort_values(by=[\"saledate\"], inplace=True, ascending=True)\ndf.saledate.head(20\n                )","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:06.818571Z","iopub.execute_input":"2021-05-24T17:25:06.818844Z","iopub.status.idle":"2021-05-24T17:25:07.22033Z","shell.execute_reply.started":"2021-05-24T17:25:06.818818Z","shell.execute_reply":"2021-05-24T17:25:07.219437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make a copy of the original dataframe\n\nWe make a copy of the original dataframe so when we manipulate the copy, we've still got our original data.\n","metadata":{}},{"cell_type":"code","source":"df_temp= df.copy()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:07.221551Z","iopub.execute_input":"2021-05-24T17:25:07.221846Z","iopub.status.idle":"2021-05-24T17:25:07.434259Z","shell.execute_reply.started":"2021-05-24T17:25:07.22181Z","shell.execute_reply":"2021-05-24T17:25:07.433295Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"### Add datetime param for 'saledate' column","metadata":{}},{"cell_type":"code","source":"df_temp[\"saleYear\"]= df_temp.saledate.dt.year\ndf_temp[\"saleMonth\"]= df_temp.saledate.dt.month\ndf_temp[\"saleDay\"]= df_temp.saledate.dt.day\ndf_temp[\"saleDayOfWeek\"]= df_temp.saledate.dt.dayofweek\ndf_temp[\"saleDayOfYear\"]= df_temp.saledate.dt.dayofyear","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:07.4359Z","iopub.execute_input":"2021-05-24T17:25:07.436314Z","iopub.status.idle":"2021-05-24T17:25:07.651675Z","shell.execute_reply.started":"2021-05-24T17:25:07.436269Z","shell.execute_reply":"2021-05-24T17:25:07.650445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.head().T","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:07.653338Z","iopub.execute_input":"2021-05-24T17:25:07.653831Z","iopub.status.idle":"2021-05-24T17:25:07.692029Z","shell.execute_reply.started":"2021-05-24T17:25:07.653772Z","shell.execute_reply":"2021-05-24T17:25:07.690979Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now we have enriched our DF with Dattime deatures, we can remove saledate\n\ndf_temp.drop(\"saledate\", axis=1, inplace=True)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:07.693638Z","iopub.execute_input":"2021-05-24T17:25:07.694061Z","iopub.status.idle":"2021-05-24T17:25:07.923753Z","shell.execute_reply.started":"2021-05-24T17:25:07.694028Z","shell.execute_reply":"2021-05-24T17:25:07.922817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check values of different dataset columns\ndf_temp.state.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:07.925033Z","iopub.execute_input":"2021-05-24T17:25:07.925304Z","iopub.status.idle":"2021-05-24T17:25:08.017641Z","shell.execute_reply.started":"2021-05-24T17:25:07.925278Z","shell.execute_reply":"2021-05-24T17:25:08.016398Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. Modelling\n\nWe've done enough EDA (we could always do more) but let's start to do some model-driven EDA","metadata":{}},{"cell_type":"code","source":"\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convert string to categories\nOne way we can turn all of our data into numbers is by converting them into pandas catgories.\n\nWe can check the different datatypes compatible with pandas here: https://pandas.pydata.org/pandas-docs/stable/reference/general_utility_functions.html#data-types-related-functionality","metadata":{}},{"cell_type":"code","source":"df_temp.head().T","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:08.019147Z","iopub.execute_input":"2021-05-24T17:25:08.0196Z","iopub.status.idle":"2021-05-24T17:25:08.057177Z","shell.execute_reply.started":"2021-05-24T17:25:08.019549Z","shell.execute_reply":"2021-05-24T17:25:08.056088Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.api.types.is_string_dtype(df_temp[\"UsageBand\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:08.058559Z","iopub.execute_input":"2021-05-24T17:25:08.058879Z","iopub.status.idle":"2021-05-24T17:25:08.064723Z","shell.execute_reply.started":"2021-05-24T17:25:08.058849Z","shell.execute_reply":"2021-05-24T17:25:08.063916Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to find out which columns contain strings\n\nfor labels, content in df_temp.items():\n    if pd.api.types.is_string_dtype(content):\n        print(labels)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:08.066074Z","iopub.execute_input":"2021-05-24T17:25:08.06664Z","iopub.status.idle":"2021-05-24T17:25:08.08697Z","shell.execute_reply.started":"2021-05-24T17:25:08.066531Z","shell.execute_reply":"2021-05-24T17:25:08.086031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This will turn all of the s tring value into category values\n\nfor label, content in df_temp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_temp[label]= content.astype(\"category\").cat.as_ordered()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:08.092328Z","iopub.execute_input":"2021-05-24T17:25:08.092651Z","iopub.status.idle":"2021-05-24T17:25:14.895157Z","shell.execute_reply.started":"2021-05-24T17:25:08.092622Z","shell.execute_reply":"2021-05-24T17:25:14.894024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:14.897995Z","iopub.execute_input":"2021-05-24T17:25:14.898317Z","iopub.status.idle":"2021-05-24T17:25:15.081032Z","shell.execute_reply.started":"2021-05-24T17:25:14.898287Z","shell.execute_reply":"2021-05-24T17:25:15.079955Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.state.cat.categories","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.082225Z","iopub.execute_input":"2021-05-24T17:25:15.082483Z","iopub.status.idle":"2021-05-24T17:25:15.090856Z","shell.execute_reply.started":"2021-05-24T17:25:15.082458Z","shell.execute_reply":"2021-05-24T17:25:15.089866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.state.cat.codes","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.092098Z","iopub.execute_input":"2021-05-24T17:25:15.092379Z","iopub.status.idle":"2021-05-24T17:25:15.110225Z","shell.execute_reply.started":"2021-05-24T17:25:15.092353Z","shell.execute_reply":"2021-05-24T17:25:15.108932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Thanks to pandas categories() we now have a way to access all of our data in form of numbers. But we still have a bunch of missing data","metadata":{}},{"cell_type":"code","source":"# CHeck null percentage\ndf_temp.isnull().sum()/len(df_temp)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.111703Z","iopub.execute_input":"2021-05-24T17:25:15.111997Z","iopub.status.idle":"2021-05-24T17:25:15.187979Z","shell.execute_reply.started":"2021-05-24T17:25:15.11197Z","shell.execute_reply":"2021-05-24T17:25:15.187016Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Save df_temp to a new csv ","metadata":{}},{"cell_type":"code","source":"#Export current tmp csv\n\n#df_temp.to_csv(\"data/train_tmp.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.189318Z","iopub.execute_input":"2021-05-24T17:25:15.189675Z","iopub.status.idle":"2021-05-24T17:25:15.193437Z","shell.execute_reply.started":"2021-05-24T17:25:15.189642Z","shell.execute_reply":"2021-05-24T17:25:15.192471Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"# Import reprocessed data\n\n#df_temp= pd.read_csv(\"data/train_tmp.csv\", low_memory=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.194859Z","iopub.execute_input":"2021-05-24T17:25:15.19514Z","iopub.status.idle":"2021-05-24T17:25:15.21006Z","shell.execute_reply.started":"2021-05-24T17:25:15.195112Z","shell.execute_reply":"2021-05-24T17:25:15.209055Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"df_temp.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.211603Z","iopub.execute_input":"2021-05-24T17:25:15.211991Z","iopub.status.idle":"2021-05-24T17:25:15.265427Z","shell.execute_reply.started":"2021-05-24T17:25:15.211949Z","shell.execute_reply":"2021-05-24T17:25:15.264384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Fill missing values\n\n### Fill numeric missing values first","metadata":{}},{"cell_type":"code","source":"for label, content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        print(label)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.267132Z","iopub.execute_input":"2021-05-24T17:25:15.26757Z","iopub.status.idle":"2021-05-24T17:25:15.275715Z","shell.execute_reply.started":"2021-05-24T17:25:15.267525Z","shell.execute_reply":"2021-05-24T17:25:15.274543Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check for which numeric columns have null values\n\nfor label,content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(label)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.277815Z","iopub.execute_input":"2021-05-24T17:25:15.278332Z","iopub.status.idle":"2021-05-24T17:25:15.298535Z","shell.execute_reply.started":"2021-05-24T17:25:15.278267Z","shell.execute_reply":"2021-05-24T17:25:15.297034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Fill numeric rows with median\n\nfor label,content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            #Add a binary columns which tells us if the data was missing or not\n            df_temp[label+\"_is_missing\"]= pd.isnull(content)\n            #Fill missing numeric values with median\n            df_temp[label] = content.fillna(content.median())","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.300032Z","iopub.execute_input":"2021-05-24T17:25:15.300463Z","iopub.status.idle":"2021-05-24T17:25:15.343924Z","shell.execute_reply.started":"2021-05-24T17:25:15.300421Z","shell.execute_reply":"2021-05-24T17:25:15.343048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for label,content in df_temp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n            print(labels)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.345219Z","iopub.execute_input":"2021-05-24T17:25:15.345758Z","iopub.status.idle":"2021-05-24T17:25:15.365002Z","shell.execute_reply.started":"2021-05-24T17:25:15.345724Z","shell.execute_reply":"2021-05-24T17:25:15.363954Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.head().T","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.366378Z","iopub.execute_input":"2021-05-24T17:25:15.366726Z","iopub.status.idle":"2021-05-24T17:25:15.42048Z","shell.execute_reply.started":"2021-05-24T17:25:15.366694Z","shell.execute_reply":"2021-05-24T17:25:15.419518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lets fill all missing categorical values\nfor label, content in df_temp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        print(label)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.42168Z","iopub.execute_input":"2021-05-24T17:25:15.421986Z","iopub.status.idle":"2021-05-24T17:25:15.433561Z","shell.execute_reply.started":"2021-05-24T17:25:15.421953Z","shell.execute_reply":"2021-05-24T17:25:15.430185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Turn categorical values into numbers and fill missing\n# +1 is done to convert -1 to 0. pd.Categories fills empty vales with Code -1. As we do not want any negative data in our \n#evaluation we are going to add 1 to it so that it becomes 0\nfor label, content in df_temp.items():\n    if not pd.api.types.is_numeric_dtype(content):\n        #Add binary column to indicate wether sampple has missing values\n        df_temp[label+\"is_missing\"]= pd.isnull(content)\n        #Turn categories into number and add+1\n        df_temp[label] =pd.Categorical(content).codes +1","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.435068Z","iopub.execute_input":"2021-05-24T17:25:15.435446Z","iopub.status.idle":"2021-05-24T17:25:15.509775Z","shell.execute_reply.started":"2021-05-24T17:25:15.435411Z","shell.execute_reply":"2021-05-24T17:25:15.508659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.Categorical(df_temp[\"state\"]).codes +1\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.511553Z","iopub.execute_input":"2021-05-24T17:25:15.511866Z","iopub.status.idle":"2021-05-24T17:25:15.525038Z","shell.execute_reply.started":"2021-05-24T17:25:15.511836Z","shell.execute_reply":"2021-05-24T17:25:15.523951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.info()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.526424Z","iopub.execute_input":"2021-05-24T17:25:15.526806Z","iopub.status.idle":"2021-05-24T17:25:15.545331Z","shell.execute_reply.started":"2021-05-24T17:25:15.526773Z","shell.execute_reply":"2021-05-24T17:25:15.543279Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.head().T","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.546863Z","iopub.execute_input":"2021-05-24T17:25:15.547429Z","iopub.status.idle":"2021-05-24T17:25:15.57552Z","shell.execute_reply.started":"2021-05-24T17:25:15.547396Z","shell.execute_reply":"2021-05-24T17:25:15.574454Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_temp.isna().sum()[:20]","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.577061Z","iopub.execute_input":"2021-05-24T17:25:15.577362Z","iopub.status.idle":"2021-05-24T17:25:15.656741Z","shell.execute_reply.started":"2021-05-24T17:25:15.577334Z","shell.execute_reply":"2021-05-24T17:25:15.655653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Now that all of our data is numeric, as well as dataframe has no missing values, we should be able to biuld a ML model","metadata":{}},{"cell_type":"code","source":"%%time\n# Instantiate model \n\n#model= RandomForestRegressor(n_jobs=-1,\n#                            random_state=42)\n\n#model.fit(df_temp.drop(\"SalePrice\", axis=1), df_temp[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.65818Z","iopub.execute_input":"2021-05-24T17:25:15.658582Z","iopub.status.idle":"2021-05-24T17:25:15.664534Z","shell.execute_reply.started":"2021-05-24T17:25:15.658548Z","shell.execute_reply":"2021-05-24T17:25:15.66331Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#score the model\n#model.score(df_temp.drop(\"SalePrice\", axis=1), df_temp[\"SalePrice\"])","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.666544Z","iopub.execute_input":"2021-05-24T17:25:15.667064Z","iopub.status.idle":"2021-05-24T17:25:15.67934Z","shell.execute_reply.started":"2021-05-24T17:25:15.667012Z","shell.execute_reply":"2021-05-24T17:25:15.67813Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Question:** WHy the above value, does not hold water/true/reliable?\nBecause we have done our scoring/evaluation on the same datset on which we trianed our model","metadata":{}},{"cell_type":"code","source":"## splitting data into train and validation sets\ndf_temp.saleYear.value_counts()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.680581Z","iopub.execute_input":"2021-05-24T17:25:15.680883Z","iopub.status.idle":"2021-05-24T17:25:15.703964Z","shell.execute_reply.started":"2021-05-24T17:25:15.680854Z","shell.execute_reply":"2021-05-24T17:25:15.702738Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split data into training and validation\ndf_val=df_temp[df_temp.saleYear==2012]\ndf_train=df_temp[df_temp.saleYear!=2012]\n\nlen(df_val), len(df_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.705682Z","iopub.execute_input":"2021-05-24T17:25:15.706014Z","iopub.status.idle":"2021-05-24T17:25:15.807128Z","shell.execute_reply.started":"2021-05-24T17:25:15.705983Z","shell.execute_reply":"2021-05-24T17:25:15.806349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Split data into X and y\nX_train, y_train =df_train.drop(\"SalePrice\", axis=1), df_train.SalePrice\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.808103Z","iopub.execute_input":"2021-05-24T17:25:15.808513Z","iopub.status.idle":"2021-05-24T17:25:15.857955Z","shell.execute_reply.started":"2021-05-24T17:25:15.808463Z","shell.execute_reply":"2021-05-24T17:25:15.856768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_valid, y_valid = df_val.drop(\"SalePrice\", axis=1), df_val.SalePrice","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.859428Z","iopub.execute_input":"2021-05-24T17:25:15.85988Z","iopub.status.idle":"2021-05-24T17:25:15.875299Z","shell.execute_reply.started":"2021-05-24T17:25:15.859829Z","shell.execute_reply":"2021-05-24T17:25:15.874314Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train.shape , y_train.shape, X_valid.shape, y_valid.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.877017Z","iopub.execute_input":"2021-05-24T17:25:15.877456Z","iopub.status.idle":"2021-05-24T17:25:15.888101Z","shell.execute_reply.started":"2021-05-24T17:25:15.877411Z","shell.execute_reply":"2021-05-24T17:25:15.887226Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Building an evalluation function\n","metadata":{}},{"cell_type":"code","source":"#create an evaluation function so that we can use this functionality multiple times over different params\nfrom sklearn.metrics import mean_absolute_error, mean_squared_log_error, r2_score\n\ndef rmsle(y_test, y_preds):\n    \"\"\"\n    Calcs rmsle between ppredictions and true labels.\n    \"\"\"\n    return np.sqrt(mean_squared_log_error(y_test, y_preds))\n\n#Create function to evaluate model on a few diff levels\n\ndef show_scores(model):\n    train_preds= model.predict(X_train)\n    val_preds = model.predict(X_valid)\n    scores={\"Training MAE\": mean_absolute_error(y_train, train_preds),\n           \"Valid MAE\": mean_absolute_error(y_valid, val_preds),\n           \"Training RMSLE\": rmsle(y_train, train_preds),\n           \"Valid RMSLE\": rmsle(y_valid, val_preds),\n           \"Training R2\": r2_score(y_train, train_preds),\n           \"Valid R2\": r2_score(y_valid, val_preds)}\n    return scores","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.889482Z","iopub.execute_input":"2021-05-24T17:25:15.889989Z","iopub.status.idle":"2021-05-24T17:25:15.900154Z","shell.execute_reply.started":"2021-05-24T17:25:15.889954Z","shell.execute_reply":"2021-05-24T17:25:15.898982Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Testing our model on a subset (to tune hyperparams)","metadata":{}},{"cell_type":"code","source":"#this takes far too long for experimenting\n#%%time\n#model= RandomForestRegressor(n_jobs=-1,\n#                            random_state=42)\n\n#model.fit(X_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.901433Z","iopub.execute_input":"2021-05-24T17:25:15.901742Z","iopub.status.idle":"2021-05-24T17:25:15.918288Z","shell.execute_reply.started":"2021-05-24T17:25:15.901714Z","shell.execute_reply":"2021-05-24T17:25:15.917541Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Change max samples value","metadata":{}},{"cell_type":"code","source":"model= RandomForestRegressor(n_jobs=-1, random_state=42,\n                            max_samples=10000)\n\n","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.919273Z","iopub.execute_input":"2021-05-24T17:25:15.91967Z","iopub.status.idle":"2021-05-24T17:25:15.932786Z","shell.execute_reply.started":"2021-05-24T17:25:15.919642Z","shell.execute_reply":"2021-05-24T17:25:15.931777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#Cutting down on max_samples to see how much it imporoves training time\nmodel.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:15.933863Z","iopub.execute_input":"2021-05-24T17:25:15.93428Z","iopub.status.idle":"2021-05-24T17:25:30.469405Z","shell.execute_reply.started":"2021-05-24T17:25:15.934251Z","shell.execute_reply":"2021-05-24T17:25:30.46756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nshow_scores(model)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:30.470823Z","iopub.execute_input":"2021-05-24T17:25:30.471226Z","iopub.status.idle":"2021-05-24T17:25:38.074648Z","shell.execute_reply.started":"2021-05-24T17:25:30.471192Z","shell.execute_reply":"2021-05-24T17:25:38.073588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# HyperParameters tuning with RandomizedSerarchCV","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:38.075756Z","iopub.execute_input":"2021-05-24T17:25:38.076071Z","iopub.status.idle":"2021-05-24T17:25:38.080218Z","shell.execute_reply.started":"2021-05-24T17:25:38.076006Z","shell.execute_reply":"2021-05-24T17:25:38.079382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfrom sklearn.model_selection import RandomizedSearchCV\n\n# Different Random forest regressor hyper params\nrf_grid={\"n_estimators\":np.arange(10, 100, 10),\n        \"max_depth\":[None, 3, 5, 10],\n        \"min_samples_split\":np.arange(2,10,2),\n        \"min_samples_leaf\": np.arange(1,20,2),\n        \"max_features\":[0.5,1,\"sqrt\",\"auto\"],\n        \"max_samples\":[10000]}\n\n#Intantiate Randomized search CV model\nrs_model= RandomizedSearchCV(RandomForestRegressor(n_jobs=-1,\n                                                  random_state=42),\n                                                  param_distributions=rf_grid,\n                                                  n_iter=5,\n                                                  cv=5,\n                                                  verbose=True)\n#Fit the randomizedSearchCV model\nrs_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:25:38.081431Z","iopub.execute_input":"2021-05-24T17:25:38.081967Z","iopub.status.idle":"2021-05-24T17:28:15.911297Z","shell.execute_reply.started":"2021-05-24T17:25:38.081936Z","shell.execute_reply":"2021-05-24T17:28:15.909961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Finding the best model params\nrs_model.best_params_","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:28:15.913368Z","iopub.execute_input":"2021-05-24T17:28:15.913833Z","iopub.status.idle":"2021-05-24T17:28:15.920263Z","shell.execute_reply.started":"2021-05-24T17:28:15.913784Z","shell.execute_reply":"2021-05-24T17:28:15.919266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Evaluate the randomized search models(only trained on 10000 examples)\nshow_scores(rs_model)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:28:15.921477Z","iopub.execute_input":"2021-05-24T17:28:15.921769Z","iopub.status.idle":"2021-05-24T17:28:22.012224Z","shell.execute_reply.started":"2021-05-24T17:28:15.921742Z","shell.execute_reply":"2021-05-24T17:28:22.011095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Train a model with the best HyperParams\n**Note** These were found after a 100 iterations of RandomizedSearchCV","metadata":{}},{"cell_type":"code","source":"%%time\n# Most ideal parameters:\nideal_model=RandomForestRegressor(n_estimators=40,\n                                 min_samples_leaf=1,\n                                 min_samples_split=14,\n                                 max_features=0.5,\n                                 n_jobs=-1,\n                                 max_samples=None,\n                                 random_state=42)\n\nideal_model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:28:22.013638Z","iopub.execute_input":"2021-05-24T17:28:22.013952Z","iopub.status.idle":"2021-05-24T17:29:20.68948Z","shell.execute_reply.started":"2021-05-24T17:28:22.013922Z","shell.execute_reply":"2021-05-24T17:29:20.688772Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_scores(ideal_model)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:20.690731Z","iopub.execute_input":"2021-05-24T17:29:20.691227Z","iopub.status.idle":"2021-05-24T17:29:27.058597Z","shell.execute_reply.started":"2021-05-24T17:29:20.691194Z","shell.execute_reply":"2021-05-24T17:29:27.057629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# The 'Valid RMSLE' value is what we are looking for and it is around  0.2452416398953833, which is very close and puts our code in top 30 of the submissions","metadata":{}},{"cell_type":"markdown","source":"# Make preds on test data","metadata":{}},{"cell_type":"code","source":"#import test data\ndf_test = pd.read_csv(\"../input/bluebook-for-bulldozers/Test.csv\", low_memory=False, parse_dates=[\"saledate\"])\ndf_test.shape","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.061254Z","iopub.execute_input":"2021-05-24T17:29:27.061611Z","iopub.status.idle":"2021-05-24T17:29:27.214501Z","shell.execute_reply.started":"2021-05-24T17:29:27.061579Z","shell.execute_reply":"2021-05-24T17:29:27.213484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Make predictions over test dataset","metadata":{}},{"cell_type":"markdown","source":"### test_preds= ideal_model.predict(df_test)\n\nThis will not work as it has not been manipulated, filtered or cleaned","metadata":{}},{"cell_type":"markdown","source":"## Preprocessing the data(getting the test dataset in the same form of our training dataset)","metadata":{}},{"cell_type":"code","source":"def preprocess_data(df):\n    \"\"\"\n    Performs transformations on df and returns transformed df.\n    \"\"\"\n    df[\"saleYear\"] = df.saledate.dt.year\n    df[\"saleMonth\"] = df.saledate.dt.month\n    df[\"saleDay\"] = df.saledate.dt.day\n    df[\"saleDayOfWeek\"] = df.saledate.dt.dayofweek\n    df[\"saleDayOfYear\"] = df.saledate.dt.dayofyear\n    \n    df.drop(\"saledate\", axis=1, inplace=True)\n    \n    # Fill the numeric rows with median\n    for label, content in df.items():\n        if pd.api.types.is_numeric_dtype(content):\n            if pd.isnull(content).sum():\n                # Add a binary column which tells us if the data was missing or not\n                df[label+\"_is_missing\"] = pd.isnull(content)\n                # Fill missing numeric values with median\n                df[label] = content.fillna(content.median())\n    \n        # Filled categorical missing data and turn categories into numbers\n        if not pd.api.types.is_numeric_dtype(content):\n            df[label+\"_is_missing\"] = pd.isnull(content)\n            # We add +1 to the category code because pandas encodes missing categories as -1\n            df[label] = pd.Categorical(content).codes+1\n    \n    return df","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.215619Z","iopub.execute_input":"2021-05-24T17:29:27.215883Z","iopub.status.idle":"2021-05-24T17:29:27.225201Z","shell.execute_reply.started":"2021-05-24T17:29:27.215858Z","shell.execute_reply":"2021-05-24T17:29:27.223856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Process test data\ndf_test= preprocess_data(df_test)\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.226974Z","iopub.execute_input":"2021-05-24T17:29:27.227396Z","iopub.status.idle":"2021-05-24T17:29:27.486521Z","shell.execute_reply.started":"2021-05-24T17:29:27.227345Z","shell.execute_reply":"2021-05-24T17:29:27.485556Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# we can find how the columns differ using sets\nset(X_train.columns) - set(df_test.columns)","metadata":{}},{"cell_type":"code","source":"df_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.48796Z","iopub.execute_input":"2021-05-24T17:29:27.488343Z","iopub.status.idle":"2021-05-24T17:29:27.521459Z","shell.execute_reply.started":"2021-05-24T17:29:27.488302Z","shell.execute_reply":"2021-05-24T17:29:27.520561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#manually adjust df_test to have auctioneerID_is_missing columns\n\ndf_test[\"auctioneerID_is_missing\"]=False\ndf_test.head()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.52278Z","iopub.execute_input":"2021-05-24T17:29:27.523073Z","iopub.status.idle":"2021-05-24T17:29:27.55219Z","shell.execute_reply.started":"2021-05-24T17:29:27.523043Z","shell.execute_reply":"2021-05-24T17:29:27.55121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Finally now our test df has same features as training df, we can make preds","metadata":{}},{"cell_type":"code","source":"test_preds= ideal_model.predict(df_test)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.55364Z","iopub.execute_input":"2021-05-24T17:29:27.554069Z","iopub.status.idle":"2021-05-24T17:29:27.787611Z","shell.execute_reply.started":"2021-05-24T17:29:27.554025Z","shell.execute_reply":"2021-05-24T17:29:27.786626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_preds)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.788914Z","iopub.execute_input":"2021-05-24T17:29:27.789214Z","iopub.status.idle":"2021-05-24T17:29:27.796137Z","shell.execute_reply.started":"2021-05-24T17:29:27.789185Z","shell.execute_reply":"2021-05-24T17:29:27.79485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Format preds into same format Kaggle has asked\n","metadata":{}},{"cell_type":"code","source":"df_preds= pd.DataFrame()\ndf_preds[\"SalesID\"] = df_test[\"SalesID\"]\ndf_preds[\"SalesPrice\"]= test_preds\ndf_preds","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.79948Z","iopub.execute_input":"2021-05-24T17:29:27.799816Z","iopub.status.idle":"2021-05-24T17:29:27.821548Z","shell.execute_reply.started":"2021-05-24T17:29:27.799786Z","shell.execute_reply":"2021-05-24T17:29:27.820591Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Save the predictions as per the competition format and check out the results\n#df_preds.to_csv(\"data/bluebook_for_bulldozer_test_predictions.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.828528Z","iopub.execute_input":"2021-05-24T17:29:27.828828Z","iopub.status.idle":"2021-05-24T17:29:27.832665Z","shell.execute_reply.started":"2021-05-24T17:29:27.828802Z","shell.execute_reply":"2021-05-24T17:29:27.831564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Feature Importance\n\nwhich diff attributes of the data were most important when it comes to predicting target variables(SalesPrice)","metadata":{}},{"cell_type":"code","source":"len(ideal_model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.834043Z","iopub.execute_input":"2021-05-24T17:29:27.834561Z","iopub.status.idle":"2021-05-24T17:29:27.95243Z","shell.execute_reply.started":"2021-05-24T17:29:27.834527Z","shell.execute_reply":"2021-05-24T17:29:27.951421Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(X_train.columns)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.953791Z","iopub.execute_input":"2021-05-24T17:29:27.954105Z","iopub.status.idle":"2021-05-24T17:29:27.959612Z","shell.execute_reply.started":"2021-05-24T17:29:27.954074Z","shell.execute_reply":"2021-05-24T17:29:27.958658Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Helper function for plotting feature importance\n\n\ndef plot_features(columns, importances, n=20):\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importances\": importances})\n          .sort_values(\"feature_importances\", ascending=False)\n          .reset_index(drop=True))\n    \n    # Plot the dataframe\n    fig, ax = plt.subplots()\n    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature importance\")\n    ax.invert_yaxis()","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.961166Z","iopub.execute_input":"2021-05-24T17:29:27.961859Z","iopub.status.idle":"2021-05-24T17:29:27.973436Z","shell.execute_reply.started":"2021-05-24T17:29:27.961815Z","shell.execute_reply":"2021-05-24T17:29:27.972255Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_features(X_train.columns, ideal_model.feature_importances_)","metadata":{"execution":{"iopub.status.busy":"2021-05-24T17:29:27.974828Z","iopub.execute_input":"2021-05-24T17:29:27.975282Z","iopub.status.idle":"2021-05-24T17:29:28.353685Z","shell.execute_reply.started":"2021-05-24T17:29:27.97524Z","shell.execute_reply":"2021-05-24T17:29:28.352636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def plot_features(columns, importances, n=20):\n    df = (pd.DataFrame({\"features\": columns,\n                        \"feature_importances\": importances})\n          .sort_values(\"feature_importances\", ascending=False)\n          .reset_index(drop=True))\n    \n    # Plot the dataframe\n    fig, ax = plt.subplots()\n    ax.barh(df[\"features\"][:n], df[\"feature_importances\"][:20])\n    ax.set_ylabel(\"Features\")\n    ax.set_xlabel(\"Feature importance\")\n    ax.invert_yaxis()","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"**Question to finish: Why knowing the feature importances of a trained machine learning model is helpful?**\n\nFinal challenge/extension: What other machine learning models could you try on our dataset? Hint: https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html check out the regression section of this map, or try to look at something like CatBoost.ai or XGBooost.ai.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}