{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Objective of this notebook is to learn how to split the data into train/valid/test dataset\n\n### Method 1. Splitting the data randomly\n1. Using Sklearn --> train_test_split\n2. Using Fast_ml --> train_valid_test_split\n\n### Method 2. Splitting the data using the temporal component\n1. Custom Code\n2. Using Fast_ml --> train_valid_test_split","metadata":{}},{"cell_type":"code","source":"!pip install fast_ml --upgrade","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', 1000)\n\n\nfrom fast_ml.utilities import display_all\nfrom fast_ml import eda\n\n\nimport os\n'''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n'''","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/bluebook-for-bulldozers/TrainAndValid.csv', parse_dates=['saledate'], low_memory=False)\ndf.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_summary = eda.df_info(df)\ndisplay_all(df_summary)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Method 1. Splitting the data randomly","metadata":{}},{"cell_type":"markdown","source":"## i. Using Sklearn --> train_test_split","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\ntrain_size=0.8\n\nX = df.drop(columns = ['SalePrice']).copy()\ny = df['SalePrice']\n\n# In the first step we will split the data in training and remaining dataset\nX_train, X_rem, y_train, y_rem = train_test_split(X,y, train_size=0.8)\n\n# Now since we want the valid and test size to be equal (10% each of overall data). \n# we have to define valid_size=0.5 (that is 50% of remaining data)\ntest_size = 0.5\nX_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)\n\nprint(X_train.shape), print(y_train.shape)\nprint(X_valid.shape), print(y_valid.shape)\nprint(X_test.shape), print(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ii. Using Fast_ml --> train_valid_test_split","metadata":{}},{"cell_type":"code","source":"from fast_ml.model_development import train_valid_test_split\n\nX_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df, target = 'SalePrice', \n                                                                            train_size=0.8, valid_size=0.1, test_size=0.1)\n\nprint(X_train.shape), print(y_train.shape)\nprint(X_valid.shape), print(y_valid.shape)\nprint(X_test.shape), print(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Method 2. Splitting the data using the temporal component\n\nNow, let's say you want to split the data in order to capture the sale date pattern. Most recent sales you want to put in the test set so that you are mimicing the production behavior. You are going to train model on historical data and predict in the future date","metadata":{}},{"cell_type":"markdown","source":"## i. Custom Code","metadata":{}},{"cell_type":"code","source":"train_size = 0.8\nvalid_size=0.1\n\ntrain_index = int(len(df)*train_size)\n\ndf.sort_values(by = 'saledate', ascending=True, inplace=True)\n\ndf_train = df[0:train_index]\ndf_rem = df[train_index:]\n\nvalid_index = int(len(df)*valid_size)\n\ndf_valid = df[train_index:train_index+valid_index]\n\ndf_test = df[train_index+valid_index:]\n\nX_train, y_train = df_train.drop(columns='SalePrice').copy(), df_train['SalePrice'].copy()\nX_valid, y_valid = df_valid.drop(columns='SalePrice').copy(), df_valid['SalePrice'].copy()\nX_test, y_test = df_test.drop(columns='SalePrice').copy(), df_test['SalePrice'].copy()\n        \nprint(X_train.shape), print(y_train.shape)\nprint(X_valid.shape), print(y_valid.shape)\nprint(X_test.shape), print(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## ii. Using Fast_ml --> train_valid_test_split","metadata":{}},{"cell_type":"code","source":"X_train, y_train, X_valid, y_valid, X_test, y_test = train_valid_test_split(df, target = 'SalePrice', method='sorted', sort_by_col='saledate',\n                                                                            train_size=0.8, valid_size=0.1, test_size=0.1)\n\n        \nprint(X_train.shape), print(y_train.shape)\nprint(X_valid.shape), print(y_valid.shape)\nprint(X_test.shape), print(y_test.shape)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}