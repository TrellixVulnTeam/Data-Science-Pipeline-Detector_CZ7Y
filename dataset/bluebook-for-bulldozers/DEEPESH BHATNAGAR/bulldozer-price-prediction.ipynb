{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Importing libraries for data exploration and anlysis\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport sklearn as sk\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n#Model from SciKit-Learn\nfrom sklearn.ensemble import RandomForestRegressor \nfrom sklearn.linear_model import Lasso\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn import feature_selection\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.model_selection import train_test_split\n\n# Metrics evaluations from SciKit Learn\nfrom sklearn.metrics import accuracy_score,precision_score\nfrom sklearn.metrics import mean_squared_log_error, mean_absolute_error\n\n# for displaying graph in the notebook\n%matplotlib inline\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Problem Definition - Blue Book for Bulldozers\nPredict the auction sale price for a piece of heavy equipment to create a \"blue book\" for bulldozers,based on the charactetistics and past sales data.\n\n\n## Kaggle Link\n - https://www.kaggle.com/c/bluebook-for-bulldozers/data\n\n\n## Data Source\nData is downloaded from Kaggle Blue Book for Bulldozers as per description below.The data for this competition is split into below parts:\n - TrainAndValid.csv\n - Test.csv\n\n## Model Evaluation\nThe evaluation metric for this competition is the RMSLE (root mean squared log error) between the actual and predicted auction prices.\n    - `Root Mean Square Error(RMSE)` : It is a measure of the squared difference between the prediction from our model and the actual value.\n    - `Root Mean Square Logistic Error (RMLSE)` : It is a measure of the squared difference between the log of the prediction from our model and the log of the actual value.\n\n## Program Execution Strategy\n 1. Data Acquisition- Getting the data ready\n 2. Handling NaN data and convert categorical data into Numeric\n 3. Choosing the right maching learning estimator/aglorithm/model for this problem\n 4. Fitting your chosen machine learning model to data and using it to make a prediction\n 5. Evaluting a machine learning model\n 6. Improving predictions through experimentation (hyperparameter tuning)\n 7. Picking the right evaluation metric\n 8. Feature Engineering - determining the important features","metadata":{}},{"cell_type":"markdown","source":"# Data Acquisition & Transformation","metadata":{}},{"cell_type":"code","source":"#Importing Source data - TrainAndValid and view into row and column \ndf_bpp=pd.read_csv(\"/kaggle/input/bluebook-for-bulldozers/TrainAndValid.csv\",\n              low_memory=False,\n              parse_dates=[\"saledate\"])\n#number of rows, number of columns\ndf_bpp.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Pre-Processing and Analysis (EDA)","metadata":{}},{"cell_type":"code","source":"#viewing bulldozer data elements\ndf_bpp.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#return the first n rows\ndf_bpp.head(3).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualization ~ pattern reconization","metadata":{}},{"cell_type":"code","source":"ax = plt.subplot()\nax.scatter(df_bpp[\"SalesID\"][:500], df_bpp [\"SalePrice\"][:500] , color=\"violet\");\nplt.title(\"History of SalesPrice by Sales ID\")\nplt.xlabel(\"Sales ID\")\nplt.ylabel(\"Sales Pricing\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Plot the distribution of Sales Price\nplt.figure(figsize=(10, 6))\nsns.histplot(df_bpp['SalePrice'],color='lightblue');","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ax =  plt.subplot()\nax.scatter(df_bpp[\"ModelID\"][:500], df_bpp [\"SalePrice\"][:500] , color=\"lightgreen\")\nplt.title(\"Sales by Model Type\")\nplt.xlabel(\"Model Type\");\nplt.ylabel(\"Sales Pricing\");","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Handling - Missing & Encode Categorical data\nHandling NaN data and convert categorical data into Numeric","metadata":{}},{"cell_type":"code","source":"#concise summary of bull dozer data\ndf_bpp.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# converting string value into category values\nfor label, content in df_bpp.items():\n    if pd.api.types.is_string_dtype(content):\n        df_bpp[label] = content.astype(\"category\").cat.as_ordered() ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill the numeric rows with mean\nfor label, content in df_bpp.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n# Add a binary column which tells us if the data was missing or not\n            df_bpp[label] = pd.isnull(content)\n# Fill missing numeric values with median\n            df_bpp[label] = content.fillna(content.mean())\n    \n# Filled categorical missing data and turn categories into numbers\n    if not pd.api.types.is_numeric_dtype(content):\n        df_bpp[label] = pd.isnull(content)\n# We add +1 to the category code because pandas encodes missing categories as -1\n        df_bpp[label] = pd.Categorical(content).codes+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#number of rows, number of columns\ndf_bpp.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#return the first n rows ~ 3\ndf_bpp.head(3).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Categorisation of data into feature and label","metadata":{}},{"cell_type":"code","source":"#splitting the data into X and Y\n#X , Y = df_bpp_transformed.drop([\"SalePrice\"],axis=1),df_bpp_transformed.SalePrice\nX , Y = df_bpp.drop([\"SalePrice\"],axis=1),df_bpp.SalePrice\nX.shape, Y.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#splitting the data into train and test with 25% reserved for testing and 75% for training\n#Training data to train our Random Forest Model on and Validation data to validate the performance of our Model.\nX_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25, random_state=42)\nX_train.shape,X_test.shape,y_train.shape,y_test.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Selecting Estimator ~ Random Forest Regression \n Applying Machine Learning Alrorithms to find the patten in predicting the price of bulldozer based on the feature.","metadata":{}},{"cell_type":"code","source":"## Applying RandomForest Regressor Model\nmodel_rf= RandomForestRegressor(n_jobs=-1,verbose=2,random_state=42)\n\n#fitting the data into model\nmodel_rf.fit (X_train,y_train)\n\n#scoring the RandomForest Regressor Model\nprint(f\"Random Forest Model Accuracy : {model_rf.score(X_test,y_test)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting label data through RandomForestRegressor\ny_pred=model_rf.predict(X_test)\ny_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter Tuning\n* The best way to think about hyperparameters is like the settings of an algorithm that can be adjusted to optimize performance, just as we might\n* Random search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model. It is similar to grid search, and yet it has proven to yield better results comparatively.","metadata":{}},{"cell_type":"code","source":"#Setting parameters for RandomForest through RandomizedSearchCV model to imporve the accuracy\n# Different RandomForestRegressor hyperparameters\nrandom_grid = {\"n_estimators\": np.arange(10, 100, 10),\n           \"max_depth\": [None, 3, 5, 10],\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2),\n           \"max_features\": [0.5, 1, \"sqrt\", \"auto\"]}\n#displaying the random grid parameters for the estimators\nrandom_grid","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random search of parameters, using 3 fold cross validation,and search across 2 different combinations\nrscv_para = RandomizedSearchCV(estimator = RandomForestRegressor(), param_distributions = random_grid, \n                               n_iter = 2, cv = 5, verbose=True, n_jobs = -1)\n# Fit the random search model with revised parameters\nrscv_para.fit(X_train, y_train)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#finding the best hyper parameters for RandomForest Regressor\nrscv_para.best_params_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fitting the model with optimal hyper parameters\nmodel_rf_optimal=RandomForestRegressor(n_estimators= 30,min_samples_split=4,min_samples_leaf= 3,\n                                     max_features='sqrt',max_depth= None,n_jobs=-1,verbose=2,\n                                     random_state=42)\n#fit the ideal model\nmodel_rf_optimal.fit(X_train,y_train)\n\n#revised score post optimization of the hyper parameters\nprint(f\"Optimsed RandomForestRegressor model Accuracy : {model_rf_optimal.score(X_test,y_test)*100:.2f}%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predicting label data through Optimised RandomForestRegressor\ny_Optimal_pred=model_rf_optimal.predict(X_test)\ny_Optimal_pred","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluting a machine learning model","metadata":{}},{"cell_type":"markdown","source":"## RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"# mean absolute error (MAE) is a measure of errors between paired observations expressing the same phenomenon.\nmean_absolute_error(y_test, y_pred,sample_weight=None,multioutput='uniform_average')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MSLE-computes a risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.\nmean_squared_log_error(y_test,y_pred,sample_weight=None,multioutput='uniform_average')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimised RandomForestRegressor","metadata":{}},{"cell_type":"code","source":"# mean absolute error (MAE) is a measure of errors between paired observations expressing the same phenomenon.\nmean_absolute_error(y_test, y_Optimal_pred,sample_weight=None,multioutput='uniform_average')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# MSLE-computes a risk metric corresponding to the expected value of the squared logarithmic (quadratic) error or loss.\nmean_squared_log_error(y_test,y_Optimal_pred,sample_weight=None,multioutput='uniform_average')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predictions - SalesPrice","metadata":{}},{"cell_type":"code","source":" # import test data and view row and column count\ndf_bpp_tst=pd.read_csv(\"/kaggle/input/bluebook-for-bulldozers/Test.csv\",\n                        low_memory=False,\n                        parse_dates=[\"saledate\"])\n# #number of rows, number of columns\ndf_bpp_tst.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#number of rows, number of columns\ndf_bpp_tst.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#return the first n rows\ndf_bpp_tst.head(3).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#concise summary of bull dozer test data\ndf_bpp_tst.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Now converting string value into category values\nfor label, content in df_bpp_tst.items():\n    if pd.api.types.is_string_dtype(content):\n        df_bpp_tst[label] = content.astype(\"category\").cat.as_ordered()  ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Fill the numeric rows with mean\nfor label, content in df_bpp_tst.items():\n    if pd.api.types.is_numeric_dtype(content):\n        if pd.isnull(content).sum():\n# Add a binary column which tells us if the data was missing or not\n            df_bpp_tst[label] = pd.isnull(content)\n# Fill missing numeric values with median\n            df_bpp_tst[label] = content.fillna(content.mean())\n    \n# Filled categorical missing data and turn categories into numbers\n    if not pd.api.types.is_numeric_dtype(content):\n        df_bpp_tst[label] = pd.isnull(content)\n# We add +1 to the category code because pandas encodes missing categories as -1\n        df_bpp_tst[label] = pd.Categorical(content).codes+1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#return the first n rows\ndf_bpp_tst.head(3).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shape of transformed test data\ndf_bpp_tst.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function is applied to the predict the salesprice through test data\ndf_pred=model_rf.predict(df_bpp_tst)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# formatting in the desired format\ndf_pred_sp=pd.DataFrame()\ndf_pred_sp [\"SalesID\"]= df_bpp_tst.SalesID\ndf_pred_sp [\"SalesPrice\"]= df_pred\ndf_pred_sp","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#export predictied data to file\ndf_pred_sp.to_csv(\"/kaggle/working/predict_salesprice.csv\",index=0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Engineering\n* Feature importance refers to techniques that assign a score to input features based on how useful they are at predicting a target variable\n* scikit learn random forest regressor feature importance for 'SalesPrice' of Bulldozer","metadata":{}},{"cell_type":"code","source":"model_rf.feature_importances_","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating dictory to map the column with optimal feature rating\nfeature_dict=dict(zip((df_bpp.columns),list(model_rf.feature_importances_)))\nfeature_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Visulaization of Important features\nfeature_df=pd.DataFrame(feature_dict,index=[0])\nfeature_df.T.plot.line(title=\"Price Prediction Feature Importance\", legend=False,color='blue');","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}