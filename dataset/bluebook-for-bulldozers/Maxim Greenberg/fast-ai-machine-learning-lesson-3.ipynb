{"cells":[{"metadata":{},"cell_type":"markdown","source":"### For those who are studing the machine learning course by Jeremy Howard and want to follow with Kaggle Kernels - you can use this notebook for lesson 3.\n(I am relatively new in the field, so I just forked the first lesson and copy-pasted the lesson which is available in the git-hub. All the relevant links below. Enjoy!\n\nhttp://course18.fast.ai/lessonsml1/lessonsml1.html\n\nhttps://www.kaggle.com/miwojc/fast-ai-machine-learning-lesson-1\n\nhttps://github.com/fastai/fastai/tree/master/courses/ml1","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"**Important: This notebook will only work with fastai-0.7.x. Do not try to run any fastai-1.x code from this path in the repository because it will load fastai-0.7.x**","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"# Random Forest from scratch!","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext autoreload\n%autoreload 2","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nfrom fastai.imports import *\nfrom fastai.structured import *\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom IPython.display import display\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Load in our data from last lesson","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = \"../input/buldozersraw/\"\n!dir {PATH}","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Note: df_raw is after processing with add_datepart() and train_cat() for details see lesson 1","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"df_raw = pd.read_feather('../input/buldozersraw//bulldozers-raw')\ndf_trn, y_trn, nas = proc_df(df_raw, 'SalePrice')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def split_vals(a,n): return a[:n], a[n:]\nn_valid = 12000\nn_trn = len(df_trn)-n_valid\nX_train, X_valid = split_vals(df_trn, n_trn)\ny_train, y_valid = split_vals(y_trn, n_trn)\nraw_train, raw_valid = split_vals(df_raw, n_trn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_sub = X_train[['YearMade', 'MachineHoursCurrentMeter']]","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Basic data structures","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class TreeEnsemble():\n    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n        \"\"\"\n        x is the data set\n        y is the target variable\n        n_trees is the number of predictors (trees)\n        sample_sz is the number of samples\n        min_leaf is the minimum number of rows in one leaf\n        \"\"\"\n        np.random.seed(42)\n        self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n        self.trees = [self.create_tree() for i in range(n_trees)]\n\n    def create_tree(self):\n        rnd_idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n        return DecisionTree(self.x.iloc[rnd_idxs], self.y[rnd_idxs], min_leaf=self.min_leaf)\n        \n    def predict(self, x):\n        return np.mean([t.predict(x) for t in self.trees], axis=0)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecisionTree():\n    def __init__(self, x, y, idxs=None, min_leaf=5):\n        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = TreeEnsemble(X_train, y_train, n_trees=10, sample_sz=1000, min_leaf=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.trees[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecisionTree():\n    def __init__(self, x, y, idxs=None, min_leaf=5):\n        if idxs is None: idxs=np.arange(len(y))\n        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf\n        self.n,self.c = len(idxs), x.shape[1]\n        self.val = np.mean(y[idxs])\n        self.score = float('inf')\n        self.find_varsplit()\n        \n    # This just does one decision; we'll make it recursive later\n    def find_varsplit(self):\n        for i in range(self.c): self.find_better_split(i)\n            \n    # We'll write this later!\n    def find_better_split(self, var_idx): pass\n    \n    @property\n    def split_name(self): return self.x.columns[self.var_idx]\n    \n    @property\n    def split_col(self): return self.x.values[self.idxs,self.var_idx]\n\n    @property\n    def is_leaf(self): return self.score == float('inf')\n    \n    def __repr__(self):\n        s = f'n: {self.n}; val:{self.val}'\n        if not self.is_leaf:\n            s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'\n        return s","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = TreeEnsemble(X_train, y_train, n_trees=10, sample_sz=1000, min_leaf=3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.trees[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.trees[0].idxs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Single branch","execution_count":null},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Find best split given variable","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"ens = TreeEnsemble(x_sub, y_train, 1, 1000)\ntree = ens.trees[0]\nx_samp,y_samp = tree.x, tree.y\nx_samp.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=1, max_depth=1, bootstrap=False)\nm.fit(x_samp, y_samp)\ndraw_tree(m.estimators_[0], x_samp, precision=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_better_split(self, var_idx):\n    x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n\n    for i in range(self.n):\n        lhs = x<=x[i]\n        rhs = x>x[i]\n        if rhs.sum()<self.min_leaf or lhs.sum()<self.min_leaf: continue\n        lhs_std = y[lhs].std()\n        rhs_std = y[rhs].std()\n        curr_score = lhs_std*lhs.sum() + rhs_std*rhs.sum()\n        if curr_score<self.score: \n            self.var_idx = var_idx\n            self.score = curr_score\n            self.split = x[i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit find_better_split(tree,1)\ntree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_better_split(tree,0); tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"### Speeding things up","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = TreeEnsemble(x_sub, y_train, 1, 1000).trees[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)\n\ndef find_better_split(self, var_idx):\n    x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n    \n    sort_idx = np.argsort(x)\n    sort_y,sort_x = y[sort_idx], x[sort_idx]\n    rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()\n    lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0.\n\n    for i in range(0,self.n-self.min_leaf):\n        xi,yi = sort_x[i],sort_y[i]\n        lhs_cnt += 1; rhs_cnt -= 1\n        lhs_sum += yi; rhs_sum -= yi\n        lhs_sum2 += yi**2; rhs_sum2 -= yi**2\n        if i<self.min_leaf-1 or xi==sort_x[i+1]:\n            continue\n            \n        lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n        rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n        curr_score = lhs_std*lhs_cnt + rhs_std*rhs_cnt\n        if curr_score<self.score: \n            self.var_idx,self.score,self.split = var_idx,curr_score,xi","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit find_better_split(tree,1)\ntree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"find_better_split(tree,0); tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DecisionTree.find_better_split = find_better_split","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = TreeEnsemble(x_sub, y_train, 1, 1000).trees[0]; tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"## Full single tree","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=1, max_depth=2, bootstrap=False)\nm.fit(x_samp, y_samp)\ndraw_tree(m.estimators_[0], x_samp, precision=2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def find_varsplit(self):\n    for i in range(self.c): self.find_better_split(i)\n    if self.is_leaf: return\n    x = self.split_col\n    lhs = np.nonzero(x<=self.split)[0]\n    rhs = np.nonzero(x>self.split)[0]\n    self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n    self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"DecisionTree.find_varsplit = find_varsplit","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree = TreeEnsemble(x_sub, y_train, 1, 1000).trees[0]; tree","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.lhs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.rhs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.lhs.lhs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tree.lhs.rhs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Predictions","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"cols = ['MachineID', 'YearMade', 'MachineHoursCurrentMeter', 'ProductSize', 'Enclosure',\n        'Coupler_System', 'saleYear']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time tree = TreeEnsemble(X_train[cols], y_train, 1, 1000).trees[0]\nx_samp,y_samp = tree.x, tree.y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=1, max_depth=3, bootstrap=False)\nm.fit(x_samp, y_samp)\ndraw_tree(m.estimators_[0], x_samp, precision=2, ratio=0.9, size=7)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict(self, x): return np.array([self.predict_row(xi) for xi in x])\nDecisionTree.predict = predict","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"if something:\n    x= do1()\nelse:\n    x= do2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = do1() if something else do2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x = something ? do1() : do2()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_row(self, xi):\n    if self.is_leaf: return self.val\n    t = self.lhs if xi[self.var_idx]<=self.split else self.rhs\n    return t.predict_row(xi)\n\nDecisionTree.predict_row = predict_row","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%time preds = tree.predict(X_valid[cols].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(preds, y_valid, alpha=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.r2_score(preds, y_valid)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m = RandomForestRegressor(n_estimators=1, min_samples_leaf=5, bootstrap=False)\n%time m.fit(x_samp, y_samp)\npreds = m.predict(X_valid[cols].values)\nplt.scatter(preds, y_valid, alpha=0.05)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.r2_score(preds, y_valid)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Putting it together","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"class TreeEnsemble():\n    def __init__(self, x, y, n_trees, sample_sz, min_leaf=5):\n        np.random.seed(42)\n        self.x,self.y,self.sample_sz,self.min_leaf = x,y,sample_sz,min_leaf\n        self.trees = [self.create_tree() for i in range(n_trees)]\n\n    def create_tree(self):\n        idxs = np.random.permutation(len(self.y))[:self.sample_sz]\n        return DecisionTree(self.x.iloc[idxs], self.y[idxs], \n                    idxs=np.array(range(self.sample_sz)), min_leaf=self.min_leaf)\n        \n    def predict(self, x):\n        return np.mean([t.predict(x) for t in self.trees], axis=0)\n\ndef std_agg(cnt, s1, s2): return math.sqrt((s2/cnt) - (s1/cnt)**2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class DecisionTree():\n    def __init__(self, x, y, idxs, min_leaf=5):\n        self.x,self.y,self.idxs,self.min_leaf = x,y,idxs,min_leaf\n        self.n,self.c = len(idxs), x.shape[1]\n        self.val = np.mean(y[idxs])\n        self.score = float('inf')\n        self.find_varsplit()\n        \n    def find_varsplit(self):\n        for i in range(self.c): self.find_better_split(i)\n        if self.score == float('inf'): return\n        x = self.split_col\n        lhs = np.nonzero(x<=self.split)[0]\n        rhs = np.nonzero(x>self.split)[0]\n        self.lhs = DecisionTree(self.x, self.y, self.idxs[lhs])\n        self.rhs = DecisionTree(self.x, self.y, self.idxs[rhs])\n    \n    def find_better_split(self, var_idx):\n        x,y = self.x.values[self.idxs,var_idx], self.y[self.idxs]\n        sort_idx = np.argsort(x)\n        sort_y,sort_x = y[sort_idx], x[sort_idx]\n        rhs_cnt,rhs_sum,rhs_sum2 = self.n, sort_y.sum(), (sort_y**2).sum()\n        lhs_cnt,lhs_sum,lhs_sum2 = 0,0.,0.\n\n        for i in range(0,self.n-self.min_leaf):\n            xi,yi = sort_x[i],sort_y[i]\n            lhs_cnt += 1; rhs_cnt -= 1\n            lhs_sum += yi; rhs_sum -= yi\n            lhs_sum2 += yi**2; rhs_sum2 -= yi**2\n            if i<self.min_leaf-1 or xi==sort_x[i+1]:\n                continue\n\n            lhs_std = std_agg(lhs_cnt, lhs_sum, lhs_sum2)\n            rhs_std = std_agg(rhs_cnt, rhs_sum, rhs_sum2)\n            curr_score = lhs_std*lhs_cnt + rhs_std*rhs_cnt\n            if curr_score<self.score: \n                self.var_idx,self.score,self.split = var_idx,curr_score,xi\n    @property\n    def split_name(self): return self.x.columns[self.var_idx]\n    \n    @property\n    def split_col(self): return self.x.values[self.idxs,self.var_idx]\n\n    @property\n    def is_leaf(self): return self.score == float('inf')\n    \n    def __repr__(self):\n        s = f'n: {self.n}; val:{self.val}'\n        if not self.is_leaf:\n            s += f'; score:{self.score}; split:{self.split}; var:{self.split_name}'\n        return s\n\n    def predict(self, x):\n        return np.array([self.predict_row(xi) for xi in x])\n     \n    def predict_row(self, xi):\n        if self.is_leaf: return self.val\n        t = self.lhs if xi[self.var_idx]<=self.split else self.rhs\n        return t.predict_row(xi)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ens = TreeEnsemble(X_train[cols], y_train, 5, 1000)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"preds = ens.predict(X_valid[cols].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_valid, preds, alpha=0.1, s=6);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"metrics.r2_score(y_valid, preds)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext Cython","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def fib1(n):\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a + b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%cython\ndef fib2(n):\n    a, b = 0, 1\n    while b < n:\n        a, b = b, a + b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%cython\ndef fib3(int n):\n    cdef int b = 1\n    cdef int a = 0\n    cdef int t = 0\n    while b < n:\n        t = a\n        a = b\n        b = t + b","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit fib1(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit fib2(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%timeit fib3(50)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}