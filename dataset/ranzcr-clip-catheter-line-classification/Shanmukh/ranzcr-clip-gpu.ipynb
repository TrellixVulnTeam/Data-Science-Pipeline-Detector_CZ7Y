{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport os\nimport PIL","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pretrained_model =  tf.keras.applications.EfficientNetB7(\n        weights=None,\n        include_top=False ,\n        input_shape=[150,150, 3]\n    )","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"INPUT_DIR = \"../input/ranzcr-clip-catheter-line-classification/\"\n\ntrain_df = pd.read_csv(INPUT_DIR+\"train.csv\")\ntrain_df.index = train_df[\"StudyInstanceUID\"]\ndel train_df[\"StudyInstanceUID\"]\n\ntrain_annot_df = pd.read_csv(INPUT_DIR+\"train_annotations.csv\")\ntrain_annot_df.index = train_annot_df[\"StudyInstanceUID\"]\ndel train_annot_df[\"StudyInstanceUID\"]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_annot_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"classes = list(train_df.columns[:-1])\nclasses_normal= [name for name in classes[:-1] if name.split(\" - \")[1] == \"Normal\"]\nclasses_abnormal= [name for name in classes[:-1] if name.split(\" - \")[1] == \"Abnormal\"]\nclasses_borderline = [name for name in classes[:-1] if name.split(\" - \")[1] == \"Borderline\"]\nclasses_count = train_df[classes].sum(axis = 0)\nnum_classes = len(classes_count)\n\n\nprint(\"Number of Classes: {}\".format(num_classes))\nclasses_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"patient_ids = train_df[\"PatientID\"].unique()\npatientwise_count = train_df['PatientID'].value_counts()\nnum_patients = len(patientwise_count)\nprint(\"Number of patients: \",num_patients)\npatientwise_count","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_img_path = INPUT_DIR + \"train/\"\ntest_img_path = INPUT_DIR +\"test/\"\ntrain_files = os.listdir(train_img_path)\ntest_files = os.listdir(test_img_path)\n\nnum_train_files = len(train_files)\nnum_test_files = len(test_files)\n\nprint(\"Number of training images: {}\".format(num_train_files))\nprint(\"Number of test images: {}\".format(num_test_files))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"labels = []\n\nfor name in train_files:\n    label = np.array(train_df.loc[name[:-4]][classes].values)\n    labels.append(label)\nlabels = np.array(labels).astype(\"float32\")\nprint(\"Train Labels Shape:\",labels.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nheight,width=128,128\nbatch_size=32\n\nfor i in range(16):\n    img = tf.keras.preprocessing.image.load_img(train_img_path+train_files[i],target_size=(height,width,3))\n    arr = tf.keras.preprocessing.image.img_to_array(img)\n    ax = plt.subplot(4,4,i+1)\n    plt.imshow(arr.astype(\"uint8\"))\n    plt.axis(\"off\")\n    title  = classes[np.argmax(labels[i])]\n    plt.title(title)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img_arr = []\nimg_arr_gray = []\nfor name in train_files:\n    img = tf.keras.preprocessing.image.load_img(train_img_path+name,target_size=(height,width,3))\n    arr = np.array(tf.keras.preprocessing.image.img_to_array(img))\n    #img_arr.append(arr.astype(\"float32\"))\n    \n    arr_gray = np.array(tf.image.rgb_to_grayscale(arr)).reshape(height,width).astype(\"float32\")\n    img_arr_gray.append(arr_gray)\n    \n#img_arr = np.array(img_arr)\nimg_arr_gray = np.array(img_arr_gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure(figsize=(10,10))\nimg = tf.keras.preprocessing.image.load_img(train_img_path+train_files[0],target_size=(height,width,3))\narr = tf.keras.preprocessing.image.img_to_array(img)\nplt.subplot(1,2,1)\nplt.imshow(arr.astype(\"uint8\"))\nplt.axis(\"off\")\nplt.title(\"ORIGINAL\")\n\narr_gray = np.array(tf.image.rgb_to_grayscale(arr)).reshape(height,width)\nplt.subplot(1,2,2)\nplt.imshow(arr_gray.astype(\"uint8\"),cmap=\"gray\")\nplt.axis(\"off\")\nplt.title(\"GRAY SCALE\")\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"EPOCHS=100\n\ndef create_callbacks(model_save_path,verbose=1):\n    \n    verbose = int(verbose>0)\n    \n    if not os.path.exists(model_save_path):\n        os.makedirs(model_save_path)\n    \n    cpk_path = f'{model_save_path}/model.h5'\n\n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath=cpk_path,\n        monitor='val_auc',\n        mode='max',\n        save_best_only=True,\n        verbose=verbose\n    )\n\n    reducelr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor='val_auc',\n        mode='max',\n        factor=0.1,\n        patience=3,\n        verbose=0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor='val_auc',\n        mode='max',\n        patience=10, \n        verbose=verbose\n    )\n    \n    callbacks = [checkpoint, reducelr, earlystop]\n    \n    return callbacks\n\ncallbacks = create_callbacks(\"./\",verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score,f1_score\nimport tensorflow_addons as tfa\n\nf1 = tfa.metrics.F1Score(num_classes=11)\n\ndef roc_metric(labels, predictions):\n    return roc_auc_score(labels, predictions)\n\ndef f1_metric(labels, predictions):\n    return f1_score(labels, predictions)\nauc = tf.keras.metrics.AUC(multi_label=True)\n\ndef loss_fn(y_true,y_pred):\n        return tf.nn.sigmoid_cross_entropy_with_logits(labels=y_true,logits=y_pred)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.optimizers import SGD\n\nwith tf.device('/device:GPU:0'):\n    data_augmentation = tf.keras.models.Sequential([\n       layers.experimental.preprocessing.RandomFlip(\"horizontal\",input_shape=(height, width,1)),\n       layers.experimental.preprocessing.RandomRotation(0.1),\n       layers.experimental.preprocessing.RandomZoom(0.1),\n       layers.experimental.preprocessing.RandomContrast(0.2),\n       layers.experimental.preprocessing.RandomTranslation(0.2,0.2, fill_mode='reflect', interpolation='bilinear'),\n       layers.experimental.preprocessing.RandomFlip(mode=\"horizontal\")\n\n    ])\n    \n    pretrained_model =  tf.keras.applications.EfficientNetB3(\n        weights=None,\n        include_top=False ,\n        input_shape=[height,width,3]\n    )\n    \n    inputs = tf.keras.Input(shape = (height,width,1))\n    x = data_augmentation(inputs)\n    x = layers.experimental.preprocessing.Rescaling(1/255.)(x)\n    x = layers.Conv2D(3,(3,3),padding='same')(x)\n    x = pretrained_model(x)\n    x = layers.GlobalAveragePooling2D()(x)\n    outputs = layers.Dense(num_classes,activation=\"sigmoid\")(x)\n    \n    model = tf.keras.Model(inputs,outputs)\n    \n    \n    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n    \n    model.compile(\n        optimizer=sgd,\n        loss = \"binary_crossentropy\",\n        metrics=[auc]\n    )\n\n    \n    history=model.fit(\n        x = img_arr_gray,\n        y = labels,\n        validation_split = 0.2,\n        shuffle = True,\n        batch_size=batch_size,                        \n        epochs=EPOCHS,\n        verbose=1,\n        callbacks = [callbacks]\n       )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_img_arr_gray = []\nfor name in test_files:\n    img = tf.keras.preprocessing.image.load_img(test_img_path+name,target_size=(height,width,3))\n    arr = np.array(tf.keras.preprocessing.image.img_to_array(img))\n    #test_img_arr.append(arr.astype(\"float32\"))\n    \n    arr_gray = np.array(tf.image.rgb_to_grayscale(arr)).reshape(height,width).astype(\"float32\")\n    test_img_arr_gray.append(arr_gray)\n    \n#test_img_arr = np.array(img_arr)\ntest_img_arr_gray = np.array(test_img_arr_gray)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = model.predict(test_img_arr_gray)\ntest_index = [name[:-4] for name in test_files]\ntest_df = pd.DataFrame(result,index=test_index,columns=classes)\ntest_df.index.name = \"StudyInstanceUID\"\ntest_df.head()\ntest_df.to_csv(\"./submission.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.remove(\"./model.h5\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}