{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n'''for dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))'''\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from glob import glob\nimport os\n\n# for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# to open the images\nimport cv2\nfrom PIL import Image\nimport scipy as sp\nimport gc\n\nfrom skimage.filters import laplace, difference_of_gaussians\nimport tensorflow_addons as tfa\n# to display all the columns of the dataframe in the notebook\npd.pandas.set_option('display.max_columns', None)\n# data preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\nimport tensorflow as tf\n\n# evaluate model and separate train and test\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, roc_auc_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom tensorflow.keras.layers import Layer, Input\nfrom tensorflow.keras.initializers import RandomUniform, Initializer, Constant\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, Dropout, BatchNormalization, Activation, DepthwiseConv2D, Flatten\nimport tensorflow.keras.backend as K\n\nfrom sklearn.metrics import classification_report, roc_auc_score\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.callbacks import LearningRateScheduler, ReduceLROnPlateau","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"catherer_path = '/kaggle/input/ranzcr-clip-catheter-line-classification'\ntrain_path = os.path.join(catherer_path,'train')\ntest_path = os.path.join(catherer_path,'test')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load train.csv data\ntrain_csv_path = os.path.join(catherer_path,'train.csv')\ntrain_df = pd.read_csv(train_csv_path)\n\n# classes to predict\nclasses = [col for col in train_df.columns if col not in ['StudyInstanceUID','PatientID']]\nprint(classes)\n\n# add the .jpg to the file names in the dataset\ntrain_df['path_name'] = train_df['StudyInstanceUID'].apply(lambda x:os.path.join(train_path,x+'.jpg'))\nprint(\"Example of a path name : {}\".format(train_df['path_name'][0]))\n# shape of the train data\nprint(\"\\nShape of train dataframe : {}\\n\".format(train_df.shape))\nprint(\"check for null values :\")\nprint(train_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Load test.csv data\ntest_csv_path = os.path.join(catherer_path,'sample_submission.csv')\ntest_df = pd.read_csv(test_csv_path)\n\n# add the .jpg to the file names in the test dataset\ntest_df['path_name'] = test_df['StudyInstanceUID'].apply(lambda x:os.path.join(test_path,x+'.jpg'))\nprint(\"\\nShape of test dataframe : {}\\n\".format(test_df.shape))\nprint(\"check for null values :\")\nprint(test_df.isnull().sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im_path = train_df['path_name'].iloc[200]\nim_example = Image.open(im_path)\nprint(\"Image size = {}\".format(im_example.size))\nplt.figure(figsize=(12,8))\nplt.imshow(im_example,cmap='Greys')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# image size\nim_width= 256\nim_height = 256\n# batch size\nbatch_size = 32\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, X_valid = train_test_split(train_df,test_size=0.2,shuffle=True)\nprint(X_train.shape)\nprint(X_valid.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df = tf.data.Dataset.from_tensor_slices((X_train['path_name'].values, X_train[classes].values))\n\nValid_df = tf.data.Dataset.from_tensor_slices((X_valid['path_name'].values, X_valid[classes].values))\n\nTest_df = tf.data.Dataset.from_tensor_slices((test_df['path_name'].values))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data_train(image_path, label):\n    # returns an image (type EagerTensor) and its labels\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = tf.image.resize(img, size=[256,256], method=tf.image.ResizeMethod.BICUBIC,\n                         preserve_aspect_ratio=False)  \n    img = tf.cast(img,tf.float32)\n    #img = tf.image.resize(img, [im_height,im_width])\n    #img = tf.image.random_hue(image, 0.01)\n    #img = tf.image.random_saturation(image, 0.70, 1.30)\n    #img = tf.image.random_contrast(image, 0.80, 1.20)\n    #img = tf.image.random_brightness(image, 0.10)\n    \n    #-----Contrast Stretching------\n    \n    mins = tf.reduce_min(img)\n    maxs = tf.reduce_max(img)\n    img = ((img-mins)*(180.0-70.0)/(maxs-mins)) + 70.0\n    \n    img = img/255.0\n    \n    #img = tf.image.per_image_standardization(img)\n    \n    return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def process_data_valid(image_path, label):\n    # No image modification for the vaidation data\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3) \n    img = tf.image.resize(img, size=[256,256], method=tf.image.ResizeMethod.BICUBIC,\n                         preserve_aspect_ratio=False)  \n    img = tf.cast(img,tf.float32)\n    img = tf.reshape(img,(256,256,3))\n    mins = tf.reduce_min(img)\n    maxs = tf.reduce_max(img)\n    img = ((img-mins)*(180.0-70.0)/(maxs-mins)) + 70.0\n    img = img/255.0\n    #img = tf.image.per_image_standardization(img)    \n\n    return img, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"Train_df2 = Train_df.map(process_data_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\nValid_df2 = Valid_df.map(process_data_valid, num_parallel_calls=tf.data.experimental.AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#plt.figure(figsize=(10,10))\nfor img, label in Train_df2.take(1):\n    image = np.array(img)\n    \nplt.figure(figsize=(10,10))    \nplt.imshow(image, cmap='gray')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def configure_for_performance(ds, batch_size = 32):\n    \n    ds = ds.cache('/kaggle/dump.tfcache') \n    ds = ds.repeat()\n    ds = ds.shuffle(buffer_size=1024)\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n    \n    return ds\n\ntrain_ds_batch = configure_for_performance(Train_df2)\nvalid_ds_batch = Valid_df2.batch(32*2)\n#test_ds_batch = Test_df.batch(32*2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"inputs = Input(shape=(256,256,3))\n\nx1 = Conv2D(32,(3,3),activation='relu', padding='SAME', strides=2)(inputs) \n\ndef bottleneck_block(x, expand, squeeze, kernel, resize):\n    m = Conv2D(expand, (1,1), padding='SAME')(x)\n    m = BatchNormalization()(m)\n    m = Activation('relu')(m)\n    m = DepthwiseConv2D(kernel, padding='SAME')(m)\n    m = BatchNormalization()(m)\n    m = Activation('relu')(m)\n    if resize==True:\n        m = Conv2D(squeeze, (1,1),strides=2, padding='SAME')(m)\n    else:\n        m = Conv2D(squeeze, (1,1), padding='SAME')(m)\n    m = BatchNormalization()(m)\n    return m\n\nx1 = bottleneck_block(x1, 16,16, (3,3), resize=False)\n\nx1 = bottleneck_block(x1, 144,24, (3,3), resize=True)\nx1 = bottleneck_block(x1, 144,24, (3,3), resize=False)\n\nx1 = bottleneck_block(x1, 240,40, (5,5), resize=True)\nx1 = bottleneck_block(x1, 240,40, (5,5), resize=False)\n\nx1 = bottleneck_block(x1, 480,80, (3,3), resize=False)\nx1 = bottleneck_block(x1, 480,80, (3,3), resize=False)\nx1 = bottleneck_block(x1, 480,80, (3,3), resize=False)\n\nx1 = bottleneck_block(x1, 672,112, (5,5), resize=True)\nx1 = bottleneck_block(x1, 672,112, (5,5), resize=False)\nx1 = bottleneck_block(x1, 672,112, (5,5), resize=False)\n\nx1 = bottleneck_block(x1, 1152,192, (5,5), resize=True)\nx1 = bottleneck_block(x1, 1152,192, (5,5), resize=False)\nx1 = bottleneck_block(x1, 1152,192, (5,5), resize=False)\nx1 = bottleneck_block(x1, 1152,192, (5,5), resize=False)\n\nx1 = bottleneck_block(x1, 1920,320, (3,3), resize=False)\n\nx1=Flatten()(x1)\n#x1 = Dense(256, activation='relu')(x1)\n#x1 = Dense(128, activation='relu')(x1)\noutputs = Dense(11, activation='softmax')(x1)\n\nmodel_scratch = tf.keras.Model(inputs=inputs, outputs=outputs)\n\nmodel_scratch.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#image_batch, label_batch = next(iter(train_ds_batch))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"annealer_lrs = LearningRateScheduler(lambda x: 1e-4 * 0.9 ** x)\nannealer_lr_scheduler = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_auc', \n                                                            factor = 0.1, \n                                                            patience = 2, \n                                                            mode = 'max')\n\nmodel_scratch.compile(loss=tf.keras.losses.categorical_crossentropy,\n                  optimizer='Adam',\n                 metrics=['AUC'])\nhistory = model_scratch.fit(\n                          train_ds_batch, \n                          validation_data = valid_ds_batch, \n                          epochs = 10, \n                          callbacks = [annealer_lrs],\n                          steps_per_epoch = 256\n                      )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}