{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Library Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport torch, torchvision\nfrom torchvision import transforms\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader as DL\nfrom torch.nn.utils import weight_norm as WN\nimport torch.nn.functional as F\n\nimport gc\nimport os\nimport cv2\nfrom time import time\n\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nseed = 42","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Helper Functions"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"def breaker():\n    print(\"\\n\" + 50*\"-\" + \"\\n\")\n\ndef head(x, no_of_ele=5):\n    print(x[:no_of_ele])\n    \ndef getImages(file_path=None, file_names=None, size=None):\n    images = []\n    for name in file_names:\n        try:\n            image = cv2.imread(file_path + name + \".jpg\", cv2.IMREAD_GRAYSCALE)\n        except AttributeError:\n            print(file_path + name)\n        if size:\n            image = cv2.resize(image, dsize=(size, size), interpolation=cv2.INTER_LANCZOS4)\n        images.append(image.reshape(size, size, 1))\n    return np.array(images)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Data Handling"},{"metadata":{},"cell_type":"markdown","source":"**Loading Image Data**"},{"metadata":{"trusted":true},"cell_type":"code","source":"start_time = time()\n\nss = pd.read_csv(\"../input/ranzcr-clip-catheter-line-classification/sample_submission.csv\")\n\nts_img_names = ss[\"StudyInstanceUID\"].values\nts_images = getImages(\"../input/ranzcr-clip-catheter-line-classification/test/\", \n                      ts_img_names, \n                      size=384)\n\nbreaker()\nprint(\"Time Taken to read data : {:.2f} minutes\".format((time() - start_time)/60))\nbreaker()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Dataset Template**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class DS(Dataset):\n    def __init__(this, X=None, y=None, transform=None, mode=\"train\"):\n        this.mode = mode\n        this.transform = transform\n        this.X = X\n        if mode == \"train\":\n            this.y = y\n                 \n    def __len__(this):\n        return this.X.shape[0]\n    \n    def __getitem__(this, idx):\n        img = this.transform(this.X[idx])\n        if this.mode == \"train\":\n            return img, torch.FloatTensor(this.y[idx])\n        else:\n            return img","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# CNN Configuration and Setup"},{"metadata":{},"cell_type":"markdown","source":"**Config**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CFG():\n    tr_batch_size = 64\n    # va_batch_size = 128\n    ts_batch_size = 64\n    \n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    \n    in_channels = 1\n    OL = 11\n    \n    def __init__(this, filter_sizes=[64, 128, 256, 512], HL=[2048], epochs=50, n_folds=5):\n        this.filter_sizes = filter_sizes\n        this.HL = HL\n        this.epochs = epochs\n        this.n_folds = n_folds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Setup**"},{"metadata":{"trusted":true},"cell_type":"code","source":"class CNN(nn.Module):\n    def __init__(this, in_channels=1, filter_sizes=None, HL=None, OL=None, use_DP=True, DP=0.50):\n        \n        super(CNN, this).__init__()\n        \n        this.use_DP = use_DP\n        \n        this.DP_ = nn.Dropout(p=DP)\n        this.MP_ = nn.MaxPool2d(kernel_size=2)\n        \n        this.CN1 = nn.Conv2d(in_channels=in_channels, out_channels=filter_sizes[0], kernel_size=3, stride=1, padding=1)\n        this.BN1 = nn.BatchNorm2d(num_features=filter_sizes[0], eps=1e-5)\n        \n        this.CN2 = nn.Conv2d(in_channels=filter_sizes[0], out_channels=filter_sizes[1], kernel_size=3, stride=1, padding=1)\n        this.BN2 = nn.BatchNorm2d(num_features=filter_sizes[1], eps=1e-5)\n        \n        this.CN3 = nn.Conv2d(in_channels=filter_sizes[1], out_channels=filter_sizes[2], kernel_size=3, stride=1, padding=1)\n        this.BN3 = nn.BatchNorm2d(num_features=filter_sizes[2], eps=1e-5)\n        \n        this.CN4 = nn.Conv2d(in_channels=filter_sizes[2], out_channels=filter_sizes[3], kernel_size=3, stride=1, padding=1)\n        this.BN4 = nn.BatchNorm2d(num_features=filter_sizes[3], eps=1e-5)\n        \n        this.CN5 = nn.Conv2d(in_channels=filter_sizes[3], out_channels=filter_sizes[3], kernel_size=3, stride=1, padding=1)\n        this.BN5 = nn.BatchNorm2d(num_features=filter_sizes[3], eps=1e-5)\n        \n        this.CN6 = nn.Conv2d(in_channels=filter_sizes[3], out_channels=filter_sizes[3], kernel_size=3, stride=1, padding=1)\n        this.BN6 = nn.BatchNorm2d(num_features=filter_sizes[3], eps=1e-5)\n        \n        this.CN7 = nn.Conv2d(in_channels=filter_sizes[3], out_channels=filter_sizes[3], kernel_size=3, stride=1, padding=1)\n        this.BN7 = nn.BatchNorm2d(num_features=filter_sizes[3], eps=1e-5)\n        \n        this.FC1 = nn.Linear(in_features=filter_sizes[3] * 3 * 3, out_features=HL[0])\n        this.FC2 = nn.Linear(in_features=HL[0], out_features=OL)\n        \n    def getOptimizer(this, lr=1e-3, wd=0):\n        return optim.Adam(this.parameters(), lr=lr, weight_decay=wd)\n    \n    def getStepLR(this, optimizer=None, step_size=5, gamma=0.1):\n        return optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=step_size, gamma=gamma)\n    \n    def getMultiStepLR(this, optimizer=None, milestones=None, gamma=0.1):\n        return optim.lr_scheduler.MultiStepLR(optimizer=optimizer, milestones=milestones, gamma=gamma)\n    \n    def getPlateauLR(this, optimizer=None, patience=5, eps=1e-8):\n        return optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=patience, eps=1e-8, verbose=True)\n    \n    def forward(this, x):\n        if this.use_DP:\n            x = F.relu(this.MP_(this.BN1(this.CN1(x))))\n            x = F.relu(this.MP_(this.BN2(this.CN2(x))))\n            x = F.relu(this.MP_(this.BN3(this.CN3(x))))\n            x = F.relu(this.MP_(this.BN4(this.CN4(x))))\n            x = F.relu(this.MP_(this.BN5(this.CN5(x))))\n            x = F.relu(this.MP_(this.BN6(this.CN6(x))))\n            x = F.relu(this.MP_(this.BN7(this.CN7(x))))\n            \n            x = x.view(x.shape[0], -1)\n            \n            x = F.relu(this.DP_(this.FC1(x)))\n            x = this.FC2(x)\n            \n            return x\n        else:\n            x = F.relu(this.MP_(this.BN1(this.CN1(x))))\n            x = F.relu(this.MP_(this.BN2(this.CN2(x))))\n            x = F.relu(this.MP_(this.BN3(this.CN3(x))))\n            x = F.relu(this.MP_(this.BN4(this.CN4(x))))\n            x = F.relu(this.MP_(this.BN5(this.CN5(x))))\n            x = F.relu(this.MP_(this.BN6(this.CN6(x))))\n            x = F.relu(this.MP_(this.BN7(this.CN7(x))))\n            \n            x = x.view(x.shape[0], -1)\n            \n            x = F.relu(this.FC1(x))\n            x = this.FC2(x)\n            \n            return x","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**Predict Function**"},{"metadata":{"trusted":true},"cell_type":"code","source":"def predict_(model=None, dataloader=None, device=None, path=None):\n    if path:\n        model.load_state_dict(torch.load(path))\n\n    model.to(device)\n    model.eval()\n\n    y_pred = torch.zeros(1, 11).to(device)\n\n    for X in dataloader:\n        X = X.to(device)\n        with torch.no_grad():\n            Pred = torch.sigmoid(model(X))\n        y_pred = torch.cat((y_pred, Pred), dim=0)\n    \n    return y_pred[1:].detach().cpu().numpy()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submission "},{"metadata":{"trusted":true},"cell_type":"code","source":"cfg = CFG(filter_sizes=[64, 128, 256, 512], HL=[4096], epochs=None, n_folds=None)\n\ntransform = transforms.Compose([transforms.ToTensor(), ])\n\nts_data_setup = DS(X=ts_images, y=None, transform=transform, mode=\"test\")\nts_data = DL(ts_data_setup, batch_size=cfg.ts_batch_size, shuffle=False)\n\nmodel = CNN(filter_sizes=cfg.filter_sizes, HL=cfg.HL, OL=cfg.OL)\n\ny_pred = []\nepochs = [34, 36, 40, 42, 44, 46]\n\nfor epoch in epochs:\n    y_pred.append(predict_(model=model, dataloader=ts_data, device=cfg.device, path=\"../input/rccl-384-train/Epoch_{}.pt\".format(epoch)))\ny_pred = np.divide(np.sum(np.array(y_pred), axis=0), len(epochs))\ny_pred = np.clip(y_pred, 1e-15, 1-1e-15)\n\nss.iloc[:, 1:] = y_pred\nss.to_csv(\"./submission.csv\", index=False)\nss.head(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}