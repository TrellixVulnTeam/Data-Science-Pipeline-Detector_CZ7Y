{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nfrom matplotlib import image\nfrom matplotlib import pyplot\nimport os\nimport cv2\nimport random\nimport concurrent.futures\nimport time\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nprint(tf.__version__)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/ranzcr-clip-catheter-line-classification/train_tfrecords'\nfilepath = os.listdir(PATH)\n\nraw_dataset = tf.data.TFRecordDataset([os.path.join(PATH,ele) for ele in filepath])\n\nfor raw_record in raw_dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(raw_record.numpy())\n    print(example)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":""},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nBATCH_SIZE = 32\nSHUFFLE_BUFFER = 2000\nNUM_CLASSES = 11\nIMAGE_SIZE = 1024\ndef _parse_function(proto):\n    keys_to_features = {'image': tf.io.FixedLenFeature([], tf.string),\n                        \"CVC - Abnormal\": tf.io.FixedLenFeature([], tf.int64),\n                        \"CVC - Borderline\": tf.io.FixedLenFeature([], tf.int64),\n                        \"CVC - Normal\": tf.io.FixedLenFeature([], tf.int64),\n                        \"ETT - Abnormal\": tf.io.FixedLenFeature([], tf.int64),\n                        \"ETT - Borderline\": tf.io.FixedLenFeature([], tf.int64),\n                        \"ETT - Normal\": tf.io.FixedLenFeature([], tf.int64),\n                        \"NGT - Abnormal\": tf.io.FixedLenFeature([], tf.int64),\n                        \"NGT - Borderline\": tf.io.FixedLenFeature([], tf.int64),\n                        \"NGT - Incompletely Imaged\": tf.io.FixedLenFeature([], tf.int64),\n                        \"NGT - Normal\": tf.io.FixedLenFeature([], tf.int64),\n                        \"StudyInstanceUID\": tf.io.FixedLenFeature([], tf.string),\n                        \"Swan Ganz Catheter Present\": tf.io.FixedLenFeature([], tf.int64)}\n    parsed_features = tf.io.parse_single_example(proto, keys_to_features)\n    image = decode_image(parsed_features['image'])\n    \n    CVC_Abnormal = tf.cast(parsed_features['CVC - Abnormal'], tf.uint8)\n    CVC_Borderline = tf.cast(parsed_features['CVC - Borderline'], tf.uint8)\n    CVC_Normal = tf.cast(parsed_features['CVC - Normal'], tf.uint8)\n    ETT_Abnormal = tf.cast(parsed_features['ETT - Abnormal'], tf.uint8)\n    ETT_Borderline = tf.cast(parsed_features['ETT - Borderline'], tf.uint8)\n    ETT_Normal = tf.cast(parsed_features['ETT - Normal'], tf.uint8)\n    NGT_Abnormal = tf.cast(parsed_features['NGT - Abnormal'], tf.uint8)\n    NGT_Borderline = tf.cast(parsed_features['NGT - Borderline'], tf.uint8)\n    NGT_Incompletely_Imaged = tf.cast(parsed_features['NGT - Incompletely Imaged'], tf.uint8)\n    NGT_Normal = tf.cast(parsed_features['NGT - Normal'], tf.uint8)\n    StudyInstanceUID = tf.cast(parsed_features['StudyInstanceUID'], tf.string)\n    Swan_Ganz_Catheter_Present = tf.cast(parsed_features['Swan Ganz Catheter Present'], tf.uint8)\n    label=[CVC_Abnormal, CVC_Borderline, CVC_Normal, ETT_Abnormal, ETT_Borderline, ETT_Normal,\\\n          NGT_Abnormal, NGT_Borderline, NGT_Incompletely_Imaged, NGT_Normal, Swan_Ganz_Catheter_Present]\n    return image, label\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.cast(image, tf.uint8)  \n    image = tf.reshape(image, [IMAGE_SIZE, IMAGE_SIZE, 3])\n    return image\ndef create_dataset(filepath):    \n    dataset = tf.data.TFRecordDataset(filepath)\n    dataset = dataset.map(_parse_function, num_parallel_calls=4)\n    dataset = dataset.shuffle(SHUFFLE_BUFFER)\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n    iterator2 = tf.compat.v1.data.make_one_shot_iterator(dataset)\n    image, label = iterator.get_next()\n    return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.python import keras as keras\nfrom tensorflow.keras.applications import MobileNetV2\n\nPATH = '../input/ranzcr-clip-catheter-line-classification/train_tfrecords'\nfn = os.listdir(PATH)\nfilepath = [os.path.join(PATH, ele) for ele in fn]\ntrain_path, val_path = train_test_split(filepath, test_size=3, train_size=13, random_state=None, shuffle=False, stratify=None)\ntrain_image, train_label = create_dataset(train_path)\nval_image, val_label = create_dataset(val_path)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"PATH = '../input/ranzcr-clip-catheter-line-classification/train_tfrecords'\nfn = os.listdir(PATH)\nlen(fn)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\ntf.config.experimental_connect_to_cluster(resolver)\ntf.tpu.experimental.initialize_tpu_system(resolver)\nprint(\"All devices: \", tf.config.list_logical_devices('TPU'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 100\nBATCH_SIZE = 8\nrandom_rotation = tf.keras.layers.experimental.preprocessing.RandomRotation(3.142/2, seed=SEED)\nrandom_flip = tf.keras.layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\", seed=SEED)\nrandom_zoom = tf.keras.layers.experimental.preprocessing.RandomZoom((0, 0.25), seed=SEED)\nrandom_translate = tf.keras.layers.experimental.preprocessing.RandomTranslation((-0, 0.25), (-0, 0.25), seed=SEED)\nwith tf.device('/cpu:0'):\n    train_dataset = tf.data.Dataset.from_tensor_slices((train_image, train_label))\n    train_dataset = train_dataset.shuffle(BATCH_SIZE).batch(BATCH_SIZE)\n    del train_image, train_label\n    val_dataset = tf.data.Dataset.from_tensor_slices((val_image, val_label))\n    val_dataset = val_dataset.shuffle(8).batch(8)\n    del val_image, val_label\ndef normalize(imgs, label):\n    #imgs = random_rotation.call(imgs)\n    #imgs = random_flip.call(imgs)\n    #imgs = random_zoom.call(imgs)\n    #imgs = random_translate.call(imgs)\n    return tf.cast(imgs, tf.float16)/255, label\ntrain_dataset = train_dataset.map(normalize, num_parallel_calls=4)\nval_dataset = val_dataset.map(normalize, num_parallel_calls=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"strategy = tf.distribute.MirroredStrategy()\nwith strategy.scope():\n    base_model = tf.keras.applications.MobileNetV2(include_top=False, input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3),\\\n                                                   weights='imagenet', pooling = 'max', alpha=1.3)\n    model = tf.keras.Sequential([\n        base_model,\n        tf.keras.layers.Dense(11, activation='sigmoid')\n    ])\n    optimizer = tf.keras.optimizers.Adam(0.00001)\n    epoch_auc = tf.keras.metrics.AUC(num_thresholds=200)\n    val_epoch_auc = tf.keras.metrics.AUC(num_thresholds=200)\n    loss_object = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n    val_loss = tf.keras.losses.CategoricalCrossentropy()\n\ntrain_loss_history = []\nval_loss_history = []\ndist_train_dataset = strategy.experimental_distribute_dataset(train_dataset)\ndist_val_dataset = strategy.experimental_distribute_dataset(val_dataset)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score\nwith strategy.scope():\n    def compute_loss(labels, predictions):\n        per_example_loss = loss_object(labels, predictions)\n        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=BATCH_SIZE)\ndef compute_acc(labels, predictions):\n    return accuracy_score(labels, predictions)\ndef train_step(inputs):\n    images, labels = inputs\n    with tf.GradientTape() as tape:\n        logits = model(images, training=True)\n        loss_value = compute_loss(labels, logits)\n    epoch_auc.update_state(labels, logits)\n    train_loss_history.append(loss_value)\n    grads = tape.gradient(loss_value, model.trainable_variables)\n    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n    return loss_value\n@tf.function\ndef distributed_train_step(dist_inputs):\n    per_replica_losses = strategy.run(train_step, args=(dist_inputs,))\n    loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n                         axis=None)\n    return loss\ndef val_step(inputs):\n    images, labels = inputs\n    logits = model(images, training=False)\n    loss_value = loss_object(labels, logits)\n    val_loss.update_states(loss_value)\n    val_epoch_auc.update_state(labels, logits)\n    val_loss_history.append(loss_value)\n@tf.function\ndef distributed_val_step(dist_inputs):\n    per_replica_losses = strategy.run(val_step, args=(dist_inputs,))\n    loss = strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses,\n                         axis=None)\n    return loss\ndef train(epochs, verbose=1):\n    for epoch in range(epochs):\n        start = time.time()\n        i = 0\n        print ('\\nEpoch {}/{} '.format(epoch+1, epochs))\n        ####################### Train Loop #########################\n        num_batches = 0\n        loss = 0.0\n        for data in dist_train_dataset:\n            print(len(data))\n            loss += distributed_train_step(data)\n            num_batches += 1\n            auc = epoch_auc.result()\n            percent = float(i+1) * 100 / len(train_dataset)\n            arrow   = '-' * int(percent/100 * 20 - 1) + '>'\n            spaces  = ' ' * (20 - len(arrow))\n            if(verbose):    \n                print('\\rTraining: [%s%s] %d %% - Training Loss: %f - Training AUC: %f'% (arrow, spaces, percent, loss/num_batches, auc), end='', flush=True)\n            i += 1\n        if(not verbose):\n            print(' Epoch Loss: ', loss.numpy())\n        i = 0\n        if(verbose):\n            print(\" -\", int(time.time()-start), \"s\", end=\"\")\n            print()\n        start = time.time()\n        \n        ####################### Validation Loop #########################\n        for data in dist_val_dataset:\n            distributed_val_step(data)\n            auc = val_epoch_auc.result()\n            loss = val_loss.result()\n            percent = float(i+1) * 100 / len(val_dataset)\n            arrow   = '-' * int(percent/100 * 20 - 1) + '>'\n            spaces  = ' ' * (20 - len(arrow))\n            if(verbose):    \n                print('\\rValidate: [%s%s] %d %% - Validation Loss: %f - Validation AUC: %f'% (arrow, spaces, percent, loss, auc), end='', flush=True)\n            i += 1\n        if(verbose):\n            print(\" -\", int(time.time()-start), \"s\")\n            \n        epoch_auc.reset_states()\n        val_epoch_auc.reset_states()\n        val_loss.reset_states()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train(50, verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.save('./mobilenetv2.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for data in dist_train_dataset:\n    print(data)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}