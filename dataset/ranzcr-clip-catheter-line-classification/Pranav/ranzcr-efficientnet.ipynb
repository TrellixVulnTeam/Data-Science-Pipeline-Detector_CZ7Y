{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nimport seaborn as sns\nfrom functools import partial\nimport matplotlib.pyplot as plt","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"try: # detect TPUs\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept ValueError: # no TPU found, detect GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"AUTOTUNE = tf.data.experimental.AUTOTUNE\nIMAGE_SIZE = [512,512]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from kaggle_datasets import KaggleDatasets\nGCS_PATH = KaggleDatasets().get_gcs_path('ranzcr-clip-catheter-line-classification')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_records = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train.csv')\ntrain_records.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_columns = train_records.columns.values[1:12]\ntarget_columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.barplot(train_records['Swan Ganz Catheter Present'].unique(),train_records['Swan Ganz Catheter Present'].value_counts())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_records['Swan Ganz Catheter Present'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = train_records.groupby(['Swan Ganz Catheter Present']).count()\nclass_weights['StudyInstanceUID'] = class_weights['StudyInstanceUID'].values/train_records.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_weights = class_weights.drop('PatientID',axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"cl_w = {0:class_weights.values[0],1:class_weights.values[1]}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"img = plt.imread('../input/ranzcr-clip-catheter-line-classification/train/1.2.826.0.1.3680043.8.498.10000428974990117276582711948006105617.jpg')\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def submit_gen(model,dataset_path):\n    test_data = os.listdir(dataset_path)\n    pred_array=[]\n    for i in test_data:\n        img = tf.keras.preprocessing.image.load_img(\n            dataset_path+i,target_size=(512,512))\n        img_array = tf.keras.preprocessing.image.img_to_array(img)\n        img_array = tf.expand_dims(img_array, 0)\n        prediction = np.squeeze(model.predict(img_array))\n        name_c = np.where(prediction>0.6,1,0)\n        pred_array.append(name_c)\n    return pred_array,test_data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"gs_filenames = tf.io.gfile.glob(GCS_PATH + \"/train_tfrecords/*.tfrec\")\ngs_filenames","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"split_ind = int(0.9* len(gs_filenames))\nTRAINING_FILENAMES, VALID_FILENAMES = gs_filenames[:split_ind], gs_filenames[split_ind:]\ndataset = tf.data.TFRecordDataset(filenames=TRAINING_FILENAMES)\nval_dataset = tf.data.TFRecordDataset(filenames=VALID_FILENAMES)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in dataset.take(1):\n    example = tf.train.Example()\n    example.ParseFromString(i.numpy())\n    #print(example)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_feature_description = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'StudyInstanceUID': tf.io.FixedLenFeature([], tf.string),\n    'CVC - Abnormal': tf.io.FixedLenFeature([], tf.int64),\n     'CVC - Borderline': tf.io.FixedLenFeature([], tf.int64),\n     'CVC - Normal': tf.io.FixedLenFeature([], tf.int64),\n     'ETT - Abnormal': tf.io.FixedLenFeature([], tf.int64),\n     'ETT - Borderline': tf.io.FixedLenFeature([], tf.int64),\n    'ETT - Normal': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Abnormal': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Borderline': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Incompletely Imaged': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Normal': tf.io.FixedLenFeature([], tf.int64),\n    'Swan Ganz Catheter Present':tf.io.FixedLenFeature([],tf.int64)\n    \n}\ndef return_target_features(example):\n    target_features = []\n    for i in target_columns:\n        target_features.append(example[i])\n    feature = tf.cast(target_features,tf.int32)\n    #feature = tf.reshape(feature,(11,1))\n    return feature\n\ndef _parse_image_function(example_proto):\n    # Parse the input tf.train.Example proto using the dictionary above.\n    example = tf.io.parse_single_example(example_proto, image_feature_description)\n    image = tf.image.decode_jpeg(example['image'],channels=3)\n    image = tf.cast(image, tf.float32)\n    image = tf.image.resize(image,(IMAGE_SIZE))\n    feature = return_target_features(example)\n    return image,feature","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"parsed_image_dataset = dataset.map(partial( _parse_image_function),num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_image_dataset = val_dataset.map(partial( _parse_image_function),num_parallel_calls=AUTOTUNE)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n    tf.keras.layers.experimental.preprocessing.RandomHeight(factor=0.1,),\n    tf.keras.layers.experimental.preprocessing.RandomWidth(factor=0.1,),\n    #tf.keras.layers.experimental.preprocessing.Rescaling(scale=1./255)\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def augment(x):\n    image = tf.image.random_flip_left_right(x)\n    image = tf.image.random_brightness(image, 0.1, seed=None)\n    return image","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_dataset(dataset,aug=True):    \n    # Set the number of datapoints you want to load and shuffle \n    dataset = dataset.shuffle(4096)\n    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n    # Set the batchsize\n    dataset = dataset.batch(64)\n    if(aug==True):\n        dataset = dataset.map(lambda x,y: (augment(x),y))\n        #dataset = dataset.map(lambda x,y:(data_augmentation.call(x),y))\n    return dataset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = create_dataset(parsed_image_dataset,True)\nvalidation_dataset = create_dataset(val_image_dataset,False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with strategy.scope():\n    base = tf.keras.applications.EfficientNetB4(include_top=False,input_shape=(*IMAGE_SIZE,3),\n                                                weights='imagenet'\n                                            )\n    base.trainable = False\n    inputs = tf.keras.layers.Input([*IMAGE_SIZE, 3])\n    #input_layer = data_augmentation(inputs)\n    pre_layer = tf.keras.applications.efficientnet.preprocess_input(inputs)\n    base_model = base(pre_layer)\n    #base_model = tf.keras.layers.GlobalAveragePooling2D()(base_model)\n    base_model = tf.keras.layers.Flatten()(base_model)\n    base_model = tf.keras.layers.Dropout(0.1)(base_model)\n    base_model = tf.keras.layers.Dense(512,activation='relu')(base_model)\n    base_model = tf.keras.layers.Dropout(0.1)(base_model)\n    base_model = tf.keras.layers.BatchNormalization()(base_model)\n    base_model = tf.keras.layers.Dense(128,activation='relu')(base_model)\n    base_model = tf.keras.layers.Dense(64,activation='relu')(base_model)\n    base_model = tf.keras.layers.Dense(11,activation='sigmoid')(base_model)\n    \n    model_efficientnet_net = tf.keras.Model(inputs=inputs,outputs=base_model)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_efficientnet_net.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_learning_rate_e = 0.005\nlr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n    initial_learning_rate_e, decay_steps=100, decay_rate=0.96, staircase=True\n)\n\ncheckpoint_cb_e = tf.keras.callbacks.ModelCheckpoint(\n    \"efficientnetb4_best_model.h5\", save_best_only=True\n)\n\nearly_stopping_cb_e = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                           patience = 5, mode = 'min', verbose = 1,\n                           restore_best_weights = True)\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                              patience = 2, min_delta = 0.001, \n                              mode = 'min', verbose = 1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base.trainable = False","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_efficientnet_net.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=5e-3),\n              loss='binary_crossentropy',\n              metrics=['AUC'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tf.config.set_soft_device_placement(False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs=25\nhistory = model_efficientnet_net.fit(\n      train_dataset,\n      epochs=epochs,\n      validation_data = validation_dataset,\n      callbacks=[checkpoint_cb_e, early_stopping_cb_e,reduce_lr],\n      #class_weight = cl_w\n      #steps_per_epoch = 600\n      #validation_data = val_generator,\n    )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_efficientnet_net.save('efficientb4.h5')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}