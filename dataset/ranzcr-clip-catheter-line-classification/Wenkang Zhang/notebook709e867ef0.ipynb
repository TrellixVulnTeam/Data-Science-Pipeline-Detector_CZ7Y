{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# Basics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os # File/directory scanning and editting\n\n# Image Processing\nfrom PIL import Image \nimport cv2 as cv\n\n# Image Displaying\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path1='../input/ranzcr-clip-catheter-line-classification/train/1.2.826.0.1.3680043.8.498.10000428974990117276582711948006105617.jpg'\npath2='../input/ranzcr-clip-catheter-line-classification/train/1.2.826.0.1.3680043.8.498.10001065121843652267743449160233082683.jpg'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## Step 1:\n\npicture_height = 3567 # Manually set\npicture_width = 3827 # Manually set\n\n## Note: I coded, as below, for a program to find the largest dimensions. \n##   It takes about 5-10 minutes to run, so to save the valuable kernel time,\n##   I manually set the values above, according to the result of the program below.\n\n## Code to identify the largest photo\n# for dirname, _, filenames in os.walk(train_path):\n#     for filename in filenames:\n#         temp_img = mpimg.imread(os.path.join(dirname, filename))\n#         (temp_height, temp_width) = temp_img.shape\n#         if temp_height > picture_height:\n#             picture_height = temp_height\n#         if temp_width > picture_width:\n#             picture_width = temp_width\n\n# for dirname, _, filenames in os.walk(test_path):\n#     for filename in filenames:\n#         temp_img = mpimg.imread(os.path.join(dirname, filename))\n#         (temp_height, temp_width) = temp_img.shape\n#         if temp_height > picture_height:\n#             picture_height = temp_height\n#         if temp_width > picture_width:\n#             picture_width = temp_width","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 2:\n\n# We will use some example images. I'll label them, img_1 and img_2\n# We will read them, and then convert them to a numpy array.\n\n# img_1 = \"/kaggle/input/ranzcr-clip-catheter-line-classification/train/1.2.826.0.1.3680043.8.498.17952552645001544825751321016030941058.jpg\"\n# img_2 = '/kaggle/input/ranzcr-clip-catheter-line-classification/train/1.2.826.0.1.3680043.8.498.10370758874574386468962321364924311754.jpg'\n\n\n# For this purpose, I will use the PIL (Pillow), library\n\nimg_1 = Image.open(path1)\nimg_2 = Image.open(path2)\n\n# print(img_1.mode) # Prints the mode of the images (RGB, HSV, L, P, ...)\n# print(img_2.mode)\n# # The mode of the photos is \"L\", which are grayscale images with 8-bit pixels\n\nimg_1_np = np.array(img_1)\nimg_2_np = np.array(img_2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Step 3\n\nimg_1_np = np.pad(img_1_np, ((0, picture_height - img_1_np.shape[0]),(0, picture_width - img_1_np.shape[1])))\nimg_2_np = np.pad(img_2_np, ((0, picture_height - img_2_np.shape[0]),(0, picture_width - img_2_np.shape[1])))\nprint(img_1_np, \"\\n\\n\\n\")\nprint(img_2_np)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Optional Step 4:\n# Now we can convert back to a PIL Image, and display it using matplot, along with the original image:\n\nnew_img_1 = Image.fromarray(img_1_np)\nnew_img_2 = Image.fromarray(img_2_np)\n\n# You can see the padding below, comparing the two images.\n# The white space, is space that is not part of the photo,\n# and the black is padding\n\nfig, ((ax1, ax2),(ax3, ax4)) = plt.subplots(nrows = 2, ncols = 2, sharex = True, sharey = True, figsize = (15, 15), dpi = 150, num = 1)\nax1.imshow(img_1, cmap = \"gray\") # Images are gray scale, ensuring that matplotlib displays them as such\nax2.imshow(new_img_1, cmap = \"gray\")\nax3.imshow(img_2, cmap = \"gray\")\nax4.imshow(new_img_2, cmap = \"gray\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"clahe = cv.createCLAHE(clipLimit=15.0, tileGridSize=(8,8))\n\nclahe_img_1 = clahe.apply(img_1_np)\nclahe_img_2 = clahe.apply(img_2_np)\n\nfig, ((new_ax1,  new_ax2),(new_ax3, new_ax4)) = plt.subplots(nrows = 2, ncols = 2, sharex = True, sharey = True, figsize = (20, 20), dpi = 150, num = 1)\nnew_ax1.imshow(clahe_img_1, cmap = \"gray\") # Images are gray scale, ensuring that matplotlib displays them as such\nnew_ax2.imshow(new_img_1, cmap = \"gray\")\nnew_ax3.imshow(clahe_img_2, cmap = \"gray\")\nnew_ax4.imshow(new_img_2, cmap = \"gray\")\n\n# Images on the left are the images with contrast applied, on the right are the non-contrasted images\n# I recommend values from 2 - 20\n# Notice, the difference in how well it works. In the top image, \n# you get black spots, for seemingly no reason, yet in the bottom \n# image, the spine becomes clearer.\n# Most importantly, the lines in both images become clearer for the catheters/tubing.","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}