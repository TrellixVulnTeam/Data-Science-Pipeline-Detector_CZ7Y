{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\nimport gc\nimport cv2\nimport cuml\nimport glob\nimport numpy as np\nimport pandas as pd\nfrom numba import cuda\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.ensemble import RandomForestClassifier","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/ranzcr-clip-catheter-line-classification","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Load train and test as DataFrames"},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train.csv')\ntest = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/sample_submission.csv')\nprint(train.shape)\nprint(test.shape)\ntrain.head(10)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check distribution of labels in train"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check first image in train"},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"img = cv2.imread('../input/ranzcr-clip-catheter-line-classification/train/'+train.StudyInstanceUID.values[0]+'.jpg')\nplt.imshow(img)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\n\nannot = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train_annotations.csv')\nprint(annot.shape)\nannot.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Process average of cateter position to be used as a mask."},{"metadata":{"trusted":true},"cell_type":"code","source":"RES = np.zeros( (512,512) )\nfor i in tqdm(range(annot.shape[0])):\n    img = cv2.imread('../input/ranzcr-clip-catheter-line-classification/train/'+annot.StudyInstanceUID.values[i]+'.jpg')\n    img[:] = 0\n    data = eval(annot.data.values[i])\n    for i in range(len(data)-1):\n        img = cv2.line(img, (data[i][1],data[i][0]), (data[i+1][1],data[i+1][0]), (255,255,255), 20 )\n    img = cv2.resize(img,(512,512))\n    RES += img[:,:,0]\n    \nRES /= annot.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.clip(RES,0,1))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask = RES.copy()\nmask[mask>0.5] = 1.\nmask[mask<1] = 0\nmask = mask.astype(np.uint8)\nmask = np.stack( (mask,mask,mask), 2 )\n\ndel RES\ngc.collect()\nplt.imshow(mask)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Lets extract features from the images using transfer learning from pretrained Imagenet models."},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.applications.mobilenet import preprocess_input\n\ndir(keras.applications)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!ls ../input/keras-pretrained-models/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nfrom keras.applications.mobilenet import preprocess_input\n\n# Instantiate model\nbase = keras.applications.Xception( weights=None,  include_top=True)\n\n# Load pretrained imagenet weights\nbase.load_weights('../input/keras-pretrained-models/Xception_Top_ImageNet.h5')\nbase.trainable = False\n\nmodel = keras.Model(inputs=base.input, outputs=base.get_layer('avg_pool').output)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Inefficient, but easy to understand for loop to extract features from train images"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path = '../input/ranzcr-clip-catheter-line-classification/train/'\n\nemb_train = np.zeros( (train.shape[0],2048), dtype=np.float32 )\nfor n, filename in tqdm(enumerate(train.StudyInstanceUID.values), total=train.shape[0]):\n    img = cv2.imread(train_path+filename+'.jpg')\n    img = cv2.resize(img,(512,512))\n    img *= mask\n    img = preprocess_input(img)[np.newaxis]\n    emb_train[n] = model.predict(img)[0]\n    \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Extract features from test images"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_path = '../input/ranzcr-clip-catheter-line-classification/test/'\n\nemb_test = np.zeros( (test.shape[0],2048), dtype=np.float32 )\nfor n, filename in tqdm(enumerate(test.StudyInstanceUID.values), total=test.shape[0]):\n    img = cv2.imread(test_path+filename+'.jpg')\n    img = cv2.resize(img,(512,512))\n    img *= mask\n    img = preprocess_input(img)[np.newaxis]\n    emb_test[n] = model.predict(img)[0]\n    \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Delete model and release memory"},{"metadata":{"trusted":true},"cell_type":"code","source":"del model\ngc.collect()\nkeras.backend.clear_session() \ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# I found this trick to clear all Keras allocated memory in GPU."},{"metadata":{"trusted":true},"cell_type":"code","source":"cuda.select_device(0)\ncuda.close()\ncuda.select_device(0)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check labels names"},{"metadata":{"trusted":true},"cell_type":"code","source":"train.head()\ntargets = train.columns[1:-1]\nprint(targets)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Split train and valid set: 95%/5%"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_index = np.where( (np.arange(emb_train.shape[0])%20)!=7 )[0]\nvalid_index = np.where( (np.arange(emb_train.shape[0])%20)==7 )[0]\nlen(train_index), len(valid_index)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Fit each label and predict test using the embeddings features"},{"metadata":{"trusted":true},"cell_type":"code","source":"ytarget = train[targets].values[valid_index]\nypred = np.zeros( (len(valid_index), len(targets)) )\n\nfor n, target in tqdm(enumerate(targets), total=len(targets)):\n    \n    rf = cuml.ensemble.RandomForestClassifier(n_estimators=250, max_features=500, n_bins=16, output_type='numpy')\n    \n    rf.fit( emb_train[train_index], train[target].values[train_index] )\n    \n    ypred[:,n] = rf.predict_proba(emb_train[valid_index])[:,1]\n    test[target] = rf.predict_proba(emb_test)[:,1]\n    \n    print(n, roc_auc_score( ytarget[:,n], ypred[:,n] ), target )\n    \n    del rf\n    gc.collect()\n    \nprint( 'Final AUC:', roc_auc_score( ytarget.flatten(), ypred.flatten() ) )","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Check test predictions distribution"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.mean()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Submit"},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}