{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport random\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import KFold\nimport tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow_addons as tfa\nfrom keras.applications.xception import Xception as BaseModel\nfrom keras.applications.xception import preprocess_input\nfrom kaggle_datasets import KaggleDatasets\nimport itertools","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\nprint(\"Tensorflow version \" + tf.__version__)\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"SEED = 42\n\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    \nseed_everything(SEED)\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\n\n\nDEBUG = False\nIMG_SIZE = 900\nNUM_CLASSES = 11\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"feature_map = {\n    'image': tf.io.FixedLenFeature([], tf.string),\n    'image_annotation': tf.io.FixedLenFeature([], tf.string),\n    'StudyInstanceUID': tf.io.FixedLenFeature([], tf.string),  \n    'ETT - Abnormal': tf.io.FixedLenFeature([], tf.int64),\n    'ETT - Borderline': tf.io.FixedLenFeature([], tf.int64),\n    'ETT - Normal': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Abnormal': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Borderline': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Incompletely Imaged': tf.io.FixedLenFeature([], tf.int64),\n    'NGT - Normal': tf.io.FixedLenFeature([], tf.int64),\n    'CVC - Abnormal': tf.io.FixedLenFeature([], tf.int64),\n    'CVC - Borderline': tf.io.FixedLenFeature([], tf.int64),\n    'CVC - Normal': tf.io.FixedLenFeature([], tf.int64),\n    'Swan Ganz Catheter Present': tf.io.FixedLenFeature([], tf.int64)}\n\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels=3)\n    image = tf.image.resize(image, [IMG_SIZE, IMG_SIZE])\n    image = tf.reshape(image, [IMG_SIZE, IMG_SIZE, 3])\n    return tf.cast(image, tf.float32)\n\ndef read_tfrecord(example):\n    example = tf.io.parse_single_example(example, feature_map)\n    image = decode_image(example['image_annotation'])\n    target = [\n        example['ETT - Abnormal'],\n        example['ETT - Borderline'],\n        example['ETT - Normal'],\n        example['NGT - Abnormal'],\n        example['NGT - Borderline'],\n        example['NGT - Incompletely Imaged'],\n        example['NGT - Normal'],\n        example['CVC - Abnormal'],\n        example['CVC - Borderline'],\n        example['CVC - Normal'],\n        example['Swan Ganz Catheter Present']]\n    return image, tf.cast(target, tf.float32)\n\n\ndef data_augment(img, target):\n    img = tf.image.random_flip_left_right(img)\n    return img, target\n\ndef preprocess_input_image(img, target):\n    return preprocess_input(img), target\n\ndef get_dataset(filenames, shuffled=False, repeated=False, \n                cached=False, augmented=False):\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTOTUNE)\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTOTUNE)\n    if cached:\n        dataset = dataset.cache()\n    if shuffled:\n        dataset = dataset.shuffle(1024, seed=SEED)\n    dataset = dataset.map(preprocess_input_image, num_parallel_calls=AUTOTUNE)\n    if augmented:\n        dataset = dataset.map(data_augment, num_parallel_calls=AUTOTUNE)\n    \n    if repeated:\n        dataset = dataset.repeat()\n    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n    dataset = dataset.prefetch(AUTOTUNE)\n    return dataset\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_model():\n    with strategy.scope():\n        base_model = BaseModel(input_shape=(IMG_SIZE,IMG_SIZE,3), include_top=False, weights='imagenet')\n        x = base_model.output\n        x = L.GlobalAveragePooling2D()(x)\n        x = L.Dropout(0.5)(x)\n        outputs = L.Dense(NUM_CLASSES, activation=\"sigmoid\")(x)\n    \n        model = tf.keras.models.Model(inputs=base_model.input, outputs=outputs)\n        model.compile(\n            optimizer=tf.keras.optimizers.Adam(lr=1e-3),\n            loss=tfa.losses.SigmoidFocalCrossEntropy(alpha = 0.5, gamma = 2, reduction=tf.keras.losses.Reduction.NONE),\n            metrics=[tf.keras.metrics.AUC(multi_label=True)])\n        # model.summary()\n    return model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"GCS_DS_PATH = KaggleDatasets().get_gcs_path(\"ranzcr-annotation-900-tfrecords\")\nTF_REC_DS_PATH = GCS_DS_PATH\n\ntfrec_files = []\nfor fold in range(5):\n    training_files = [TF_REC_DS_PATH + f'/{fold}_{num}.tfrec' for num in range(0,5)]\n    random.shuffle(training_files)\n    tfrec_files.append(training_files)\n\nlen(tfrec_files)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fold_item_counts = [6018,5939,6033,6176,5917]\n\n# annotation\nfold_item_counts = [1804, 1783, 1809, 1851, 1848]\nfor fold in range(5):\n\n    tf.keras.backend.clear_session()\n    \n    train_filenames = list(itertools.chain.from_iterable([tfrec_files[i] for i in range(5) if i != fold]))\n    val_filenames = tfrec_files[fold]\n    random.shuffle(train_filenames)\n\n    train_dataset = get_dataset(train_filenames, shuffled=True, augmented=True, repeated=True)\n    val_dataset = get_dataset(val_filenames, shuffled=False, cached=True)\n\n    steps_per_epoch = (sum(fold_item_counts) - fold_item_counts[fold]) // BATCH_SIZE\n    validation_steps = fold_item_counts[fold] // BATCH_SIZE\n    \n    model = get_model()\n    \n#     es = tf.keras.callbacks.EarlyStopping(monitor='val_loss', verbose=1, patience=3)\n    sv = tf.keras.callbacks.ModelCheckpoint(f'teacher_model_{fold}.h5', monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False)\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', verbose=1, factor=0.1, patience=2, min_delta=0.0001, min_lr=1e-6)\n\n    history = model.fit(\n        train_dataset,\n        steps_per_epoch=steps_per_epoch,\n        epochs=20,\n        callbacks=[reduce_lr, sv],\n        validation_data=val_dataset,\n    )\n\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}