{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"image_size = 512\nbatch_size = 32\nnum_workers = 4","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')\nimport os\nimport sys\nimport time\nimport cv2\nimport PIL.Image\nimport random\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport albumentations\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\nimport gc\nfrom sklearn.metrics import roc_auc_score\n%matplotlib inline\nimport seaborn as sns\nfrom pylab import rcParams\nimport timm\nfrom warnings import filterwarnings\nfrom sklearn.preprocessing import LabelEncoder\nimport math\nimport glob\nfilterwarnings(\"ignore\")\n\ndevice = torch.device('cuda') ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = False\n    print(f'Setting all seeds to be {seed} to reproduce...')\nseed_everything(42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"transforms_valid = albumentations.Compose([\n    albumentations.Resize(image_size, image_size),\n    albumentations.Normalize()\n])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RANZCRDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        \n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        img = cv2.imread(row.file_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=img)\n            img = res['image']\n                \n        img = img.astype(np.float32)\n        img = img.transpose(2,0,1)\n        \n        if self.mode == 'test':\n            return torch.tensor(img).float()\n        else:\n            return torch.tensor(img).float(), torch.tensor(row.PatientID).float()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ArcModule(nn.Module):\n    def __init__(self, in_features, out_features, s=10, m=0):\n        super().__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_normal_(self.weight)\n\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.th = torch.tensor(math.cos(math.pi - m))\n        self.mm = torch.tensor(math.sin(math.pi - m) * m)\n\n    def forward(self, inputs, labels):\n        cos_th = F.linear(inputs, F.normalize(self.weight))\n        cos_th = cos_th.clamp(-1, 1)\n        sin_th = torch.sqrt(1.0 - torch.pow(cos_th, 2))\n        cos_th_m = cos_th * self.cos_m - sin_th * self.sin_m\n        # print(type(cos_th), type(self.th), type(cos_th_m), type(self.mm))\n        cos_th_m = torch.where(cos_th > self.th, cos_th_m, cos_th - self.mm)\n\n        cond_v = cos_th - self.th\n        cond = cond_v <= 0\n        cos_th_m[cond] = (cos_th - self.mm)[cond]\n\n        if labels.dim() == 1:\n            labels = labels.unsqueeze(-1)\n        onehot = torch.zeros(cos_th.size()).cuda()\n        labels = labels.type(torch.LongTensor).cuda()\n        onehot.scatter_(1, labels, 1.0)\n        outputs = onehot * cos_th_m + (1.0 - onehot) * cos_th\n        outputs = outputs * self.s\n        return outputs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MetricLearningModel(nn.Module):\n\n    def __init__(self, channel_size, out_feature, dropout=0.5, backbone='densenet121', pretrained=False):\n        super(MetricLearningModel, self).__init__()\n        self.backbone = timm.create_model(backbone, pretrained=pretrained)\n        self.channel_size = channel_size\n        self.out_feature = out_feature\n        self.in_features = self.backbone.classifier.in_features\n        self.margin = ArcModule(in_features=self.channel_size, out_features = self.out_feature)\n        self.bn1 = nn.BatchNorm2d(self.in_features)\n        self.dropout = nn.Dropout2d(dropout, inplace=True)\n        self.fc1 = nn.Linear(self.in_features * 16 * 16 , self.channel_size)\n        self.bn2 = nn.BatchNorm1d(self.channel_size)\n        \n    def forward(self, x, labels=None):\n        features = self.backbone.features(x)\n        features = self.bn1(features)\n        features = self.dropout(features)\n        features = features.view(features.size(0), -1)\n        features = self.fc1(features)\n        features = self.bn2(features)\n        features = F.normalize(features)\n        if labels is not None:\n            return self.margin(features, labels)\n        return features\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MetricLearningModel(image_size, 30805)\nmodel.load_state_dict(torch.load('../input/feature-extractor/dense121_feature_extractor.pth', map_location='cuda:0'))\nmodel.to(device);","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/sample_submission.csv')\ntest['file_path'] = test.StudyInstanceUID.apply(lambda x: os.path.join('../input/ranzcr-clip-catheter-line-classification/test',x) + '.jpg')\ndataset_test = RANZCRDataset(test, 'test', transform=transforms_valid)\ntest_loader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=False, num_workers=num_workers, pin_memory=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def generate_test_features(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    \n    FEAS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for batch_idx, (images) in enumerate(bar):\n\n            images = images.to(device)\n\n            features = model(images)\n\n            FEAS += [features.detach().cpu()]\n\n    FEAS = torch.cat(FEAS).cpu().numpy()\n    \n    return FEAS","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"FEAS = generate_test_features(test_loader)\nFEAS = torch.tensor(FEAS).cuda()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chestx_df = pd.read_csv('../input/data/Data_Entry_2017.csv')\nchestx_df['file_path'] = sorted(glob.glob('../input/data/images_*/*/*'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"chestx_features = np.load('../input/chest-x-features/chest_x_features.npy')\nchestx_features = torch.tensor(chestx_features).cuda()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"idx = (FEAS@chestx_features.T).argmax(1)\ntest['chest_x_image'] = chestx_df.loc[idx.detach().cpu()]['Image Index'].values\ntest['chest_x_file_path'] = chestx_df.loc[idx.detach().cpu()]['file_path'].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#ensemble offline csv\ndef get_df(model_type):\n    csv_paths = glob.glob(f'../input/chestx-preds/*_{model_type}*')\n    assert len(csv_paths) == 5, \"num folds not equal 5\"\n    df = pd.read_csv(csv_paths[0])\n    for col in df.columns.tolist()[1:]:\n        mean = df[col].dropna().values.mean()\n        df[col] = df[col].fillna(mean)\n\n    for path in csv_paths[1:]:\n        df1 = pd.read_csv(path)\n        for col in df1.columns.tolist()[1:]:\n            mean = df1[col].dropna().values.mean()\n            df1[col] = df1[col].fillna(mean)\n        df.iloc[:, 1:] += df1.iloc[:, 1:]\n    df.iloc[:, 1:] /= len(csv_paths)\n    return df\n\nif 1:\n    s1024_df = get_df('1024_f')\n    s1024b_df = get_df('1024_b')\n    b5_df = get_df('b5_f')\n    b5b_df = get_df('b5_b_')\n    sheep_df = get_df('sheep_')\n    b7_df = get_df('b7_')\n    sheep1_df = get_df('sheep1_')\n\n    offline_df = b5_df.copy()\n    offline_df.iloc[:, 1:] = 0.5*b5_df.iloc[:, 1:]**0.5 + 0.5*b5b_df.iloc[:, 1:]**0.5 \\\n            + 1*sheep_df.iloc[:, 1:]**0.5 + 0.5*sheep1_df.iloc[:, 1:]**0.5 \\\n            + 1*b7_df.iloc[:, 1:]**0.5  + 0.5*s1024_df.iloc[:, 1:]**0.5  + 0.5*s1024b_df.iloc[:, 1:]**0.5\n    \n    offline_df.iloc[:, 1:] /= 4.5\n    \n    #0.5-b5, 0.5-b5b, 1-s, 0.5-s1, 0.5-1024, 0.5-1024b, 1-b7","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_mapping_df = pd.read_csv('../input/ranzrc-offline/train_mapping.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"offline_df = offline_df.rename(columns={\"StudyInstanceUID\": \"file_path\"})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"remove_cols = ['similarity_score', 'StudyInstanceUID', 'follow_up_number', 'chest_x_labels', \n 'chest_x_patient_age', 'chest_x_image', 'chest_x_patient_id', 'PatientID']\ntrain_mapping_df = train_mapping_df.drop_duplicates(subset=['chest_x_image'])\ntrain_mapping_df = train_mapping_df.drop(remove_cols, axis=1)\ntrain_mapping_df['file_path'] = train_mapping_df['file_path'].apply(lambda x: x.replace('chestx/',''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"offline_df = pd.concat([offline_df, train_mapping_df])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test['file_path'] = test['chest_x_file_path']\ntest['file_path'] = test['file_path'].apply(lambda x: x.replace('../input/data/',''))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = ['ETT - Abnormal',\n 'ETT - Borderline',\n 'ETT - Normal',\n 'NGT - Abnormal',\n 'NGT - Borderline',\n 'NGT - Incompletely Imaged',\n 'NGT - Normal',\n 'CVC - Abnormal',\n 'CVC - Borderline',\n 'CVC - Normal',\n 'Swan Ganz Catheter Present']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test[target_cols] = offline_df.set_index('file_path').loc[test.file_path][target_cols].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test = test.drop(['file_path', 'chest_x_image', 'chest_x_file_path'], axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}