{"cells":[{"metadata":{},"cell_type":"markdown","source":"credits: dionysis kokkoris"},{"metadata":{"_uuid":"5945e1f8-114d-42af-a31d-9fb50b2c7dfd","_cell_guid":"a5be22ec-0b32-44c1-9854-877d142d2c51","trusted":true},"cell_type":"code","source":"# to handle datasets\nimport pandas as pd\nimport numpy as np\n\n# navigate folders\nfrom glob import glob\nimport os\n\n# for plotting\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# to open the images\nimport cv2\n\n# to display all the columns of the dataframe in the notebook\npd.pandas.set_option('display.max_columns', None)\n# data preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\n\n# evaluate model and separate train and test\nfrom sklearn.metrics import confusion_matrix\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, Flatten\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Model\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.preprocessing import image\nfrom keras.utils import np_utils","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"4071023a-e25e-4f22-8d99-5cb9d4d117bf","_cell_guid":"87612683-6288-41a5-8faf-1188d34fa4ab","trusted":true},"cell_type":"code","source":"train=pd.read_csv('../input/ranzcr-clip-catheter-line-classification/train.csv')\ntest=pd.read_csv('../input/ranzcr-clip-catheter-line-classification/sample_submission.csv')\ntrain['images']='../input/ranzcr-clip-catheter-line-classification/train/'+train['StudyInstanceUID']+'.jpg'\ntest['images']='../input/ranzcr-clip-catheter-line-classification/test/'+test['StudyInstanceUID']+'.jpg'\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y=train[['ETT - Abnormal', 'ETT - Borderline',\n       'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal',\n       'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present']]\ny=y.values","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"87e814a4-2556-44b4-89c7-13faeaedf1cd","_cell_guid":"c3bf9f34-0485-4757-893d-8027aa132547","trusted":true},"cell_type":"code","source":"def im_resize(df, n):\n    #print(df[n])\n    im = cv2.imread(df[n])\n    im = cv2.resize(im, (IMAGE_SIZE, IMAGE_SIZE))\n    #plt.imshow(im)\n    #plt.show()\n\n    return im\ndef create_dataset(df, image_size):\n    # functions creates dataset as required for cnn\n    tmp = np.zeros((len(df), image_size, image_size,3), dtype='float32')\n\n    for n in range(0, len(df)):\n        im = im_resize(df, n)\n        tmp[n] = im\n  \n    print('Dataset Images shape: {} size: {:,}'.format(tmp.shape, tmp.size))\n    return tmp","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"108f676c-e1af-4b50-a074-26278b2e1e61","_cell_guid":"9b1a734e-89c3-4820-ba21-fb8e5d8bc3bd","trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 150\n# X=create_dataset(train['images'],150)\n\nX = np.load('../input/ranzcr-numpy-150/X.npy',mmap_mode=\"r\")\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"https://stackoverflow.com/questions/9244397/memory-overflow-when-using-numpy-load-in-a-loop/65893798#65893798"},{"metadata":{"trusted":true},"cell_type":"code","source":"# import gc\n# d = dict()\n# for o in gc.get_objects():\n#     name = type(o).__name__\n#     if name not in d:\n#         d[name] = 1\n#     else:\n#         d[name] += 1\n\n# items = d.items()\n# #items.sort(key=lambda x:x[1])\n# for key, value in items:\n#     print(key, value)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"afa70d6e-d076-4e11-b3d5-1ab2a8afdfe0","_cell_guid":"99ac5068-35d0-4cf4-b7d6-5535b3ccde8c","trusted":true},"cell_type":"code","source":"xt=create_dataset(test['images'],150 )\n# xt = np.load('../input/ranzcr-numpy-150/xt.npy',mmap_mode=\"r\")\n# xt.shape","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"0007e403-f96a-436d-9342-867e27ebeea0","_cell_guid":"01136cb6-b4fb-4925-980a-9163eb504b41","trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 150\nkernel_size = (3,3)\npool_size= (2,2)\nfirst_filters = 32\nsecond_filters = 64\nthird_filters = 128\n\ndropout_conv = 0.3\ndropout_dense = 0.3\n\nmodel = Sequential()\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu', \n                 input_shape = (IMAGE_SIZE, IMAGE_SIZE, 3)))\nmodel.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\n#model.add(Conv2D(first_filters, kernel_size, activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size)) \nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(second_filters, kernel_size, activation ='relu'))\n#model.add(Conv2D(second_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(Conv2D(third_filters, kernel_size, activation ='relu'))\n#model.add(Conv2D(third_filters, kernel_size, activation ='relu'))\nmodel.add(MaxPooling2D(pool_size = pool_size))\nmodel.add(Dropout(dropout_conv))\n\nmodel.add(Flatten())\nmodel.add(Dense(256, activation = \"relu\"))\nmodel.add(Dropout(dropout_dense))\nmodel.add(Dense(11, activation = \"softmax\"))\n\nmodel.summary()\nmodel.compile(Adam(lr=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\nhistory = model.fit(X, y,batch_size=32,epochs = 10,validation_split=0.1)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(history.history.keys())\n# summarize history for accuracy\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n# summarize history for loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ynew = model.predict_proba(xt)\nlabels = test.columns[1:12]\ntest[labels]=ynew\ntest=test.drop('images',axis=1)\ntest.to_csv(\"submission.csv\",index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}