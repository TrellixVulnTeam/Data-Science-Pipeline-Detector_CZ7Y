{"cells":[{"metadata":{},"cell_type":"markdown","source":"**[xhlulu](https://www.kaggle.com/xhlulu) <br>\n[Copied From Here](https://www.kaggle.com/c/ranzcr-clip-catheter-line-classification/discussion/204950)**"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import os\n\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\n\ntf.config.experimental.list_physical_devices()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Decoder for Image\ndef build_decoder(with_labels = True , size=300):\n        \n        def decode(path):\n            \n            file_path = tf.io.read_file(path)\n            img = tf.image.decode_jpeg(file_path, channels=3)\n            \n            img = tf.cast(img, tf.float32) / 255.0\n            img = tf.image.resize(img,(size,size))\n            \n            return img\n        \n        def decode_with_labels(path, label):\n            return decode(path), label\n        \n        return decode_with_labels if with_labels else decode\n\ndef build_augmenter(with_labels = True):\n    def img_aug(img):\n        img = tf.image.random_jpeg_quality(img,75,95)\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        img = tf.image.random_brightness(img,0.1)\n        return img\n    def aug_with_labels(img,labels):\n        return img_aug(img) , labels\n    \n    return aug_with_labels if with_labels else img_aug(img)\n\n#Builder for Dataset    \ndef builder(target,labels=None,bsize=16,decoder=None,augment=True,cache_dir=\"\",cache=True):\n    \n    if cache_dir != \"\" and cache == True:\n        os.makedirs(cache_dir,exist_ok=True)\n        \n    if decoder is None :\n        decoder = build_decoder(decoder is not None)\n    if augment is True :\n        augmenter = build_augmenter(with_labels = True)\n    auto = tf.data.experimental.AUTOTUNE\n    slices = target if labels is None else (target , labels)\n    \n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decoder , num_parallel_calls=auto)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augmenter, num_parallel_calls=auto) if augment else dset\n    dset = dset.batch(bsize).prefetch(auto)\n    \n    return dset","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = r\"/kaggle/input/ranzcr-clip-catheter-line-classification/train/\"\ntest_dir = r\"/kaggle/input/ranzcr-clip-catheter-line-classification/test/\"\n\ntrain_df = pd.read_csv(\"/kaggle/input/ranzcr-clip-catheter-line-classification/train.csv\")\nsample_df = pd.read_csv(\"/kaggle/input/ranzcr-clip-catheter-line-classification/sample_submission.csv\")\nprint(\"Train Shape : \",train_df.shape)\nprint(train_df.nunique())\ntrain_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Change StudyInstanceUID to match file name for flow_from_dataframe\nif not \".jpg\" in train_df.iloc[0,0]:\n    train_df.iloc[:,0] = train_dir + train_df[\"StudyInstanceUID\"] + \".jpg\"\n\nsample_target = test_dir + sample_df[\"StudyInstanceUID\"] + \".jpg\"\nshuffle(train_df)\ninput_size = [224,240,360,300,380,456,528,600]\nlabels = train_df.columns[1:-1]\nimg_size = input_size[4]\nbatch = 16\nrandom = 13\n\nprint(train_df.loc[0,\"StudyInstanceUID\"])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_x , valid_x , train_y , valid_y = train_test_split(train_df.iloc[:,0],np.array(train_df.iloc[:,1:-1]),test_size=.2,random_state=random)\nprint(train_x[0])\nprint(train_y[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_decode = build_decoder(with_labels=True,size=img_size)\ntest_decode = build_decoder(with_labels=False , size=img_size)\nc_dir = \"/kaggle/tf_cache\"\n\ntrain = builder(train_x,labels=train_y,bsize=batch,decoder=train_decode,cache_dir=c_dir,cache=True)\nvalid = builder(valid_x,labels=valid_y,bsize=batch,decoder=train_decode,augment=False,cache_dir=c_dir, cache=True)\ntest = builder(sample_target,bsize=batch,decoder=test_decode,augment=False,cache=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.callbacks import EarlyStopping,ReduceLROnPlateau\nimport tensorflow.keras.applications.efficientnet as efn","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"weight_path = \"../input/tfkeras-efficientnet-weights/efficientnetb4_notop.h5\"\nmodel = Sequential([efn.EfficientNetB4(input_shape=(img_size, img_size, 3),weights=weight_path\n                    ,include_top=False,drop_connect_rate=0.6),                    \n                tf.keras.layers.GlobalAveragePooling2D(),\n                tf.keras.layers.Dense(len(labels), activation='sigmoid') ])\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics=[tf.keras.metrics.AUC(multi_label=True)],run_eagerly=None)\nmodel.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#from tensorflow.keras.utils import plot_model\n#plot_model(model,show_shapes=True, show_layer_names=True, rankdir='TB', expand_nested=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Create Callback\ncheckpoint = tf.keras.callbacks.ModelCheckpoint(\n    'model_b4.h5', save_best_only=True, monitor='val_auc', mode='max')\n\nlr_reducer = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor=\"val_auc\", patience=3, min_lr=1e-6, mode='max')\n\ncallbacks_list=[checkpoint,lr_reducer]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"history = model.fit(train,validation_data=valid,steps_per_epoch=len(train),epochs=20\n                    ,callbacks=callbacks_list,verbose=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.load_weights('model_b4.h5')\nmodel.save(\"model_b4.h5\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"hist_df = pd.DataFrame(history.history)\nhist_df.to_csv('history.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sample_df[labels] = model.predict(test, verbose=1)\nsample_df.to_csv('submission.csv', index=False)\n\nsample_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}