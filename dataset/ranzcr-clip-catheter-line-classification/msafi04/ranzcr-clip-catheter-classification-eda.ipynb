{"cells":[{"metadata":{},"cell_type":"markdown","source":"__Competition Goal__\n\nDetect the presence and position of catheters and lines on chest x-rays"},{"metadata":{},"cell_type":"markdown","source":"__Competition Metric__\n\nSubmissions are evaluated on __area under the ROC curve__ between the predicted probability and the observed target."},{"metadata":{},"cell_type":"markdown","source":"__Competition Rules__\n\n- CPU Notebook <= 9 hours run-time\n- GPU Notebook <= 9 hours run-time\n- TPUs will not be available for making submissions to this competition. You are still welcome to use them for training models. For a walk-through on how to train on TPUs and run inference/submit on GPUs, see our TPU Docs.\n- No internet access enabled on submission\n- External data, freely & publicly available, is allowed. This includes pre-trained models.\n- Submission file must be named submission.csv"},{"metadata":{},"cell_type":"markdown","source":"__Target Labels__\n\n- ETT - Abnormal - endotracheal tube placement abnormal\n- ETT - Borderline - endotracheal tube placement borderline abnormal\n- ETT - Normal - endotracheal tube placement normal\n- NGT - Abnormal - nasogastric tube placement abnormal\n- NGT - Borderline - nasogastric tube placement borderline abnormal\n- NGT - Incompletely Imaged - nasogastric tube placement inconclusive due to imaging\n- NGT - Normal - nasogastric tube placement borderline normal\n- CVC - Abnormal - central venous catheter placement abnormal\n- CVC - Borderline - central venous catheter placement borderline abnormal\n- CVC - Normal - central venous catheter placement normal\n- Swan Ganz Catheter Present"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"%matplotlib inline\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nimport os, json, re, math\n\nfrom tqdm import tqdm\nfrom glob import glob\nimport gc\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom IPython.display import display\n\nplt.rcParams[\"figure.figsize\"] = (12,8)\nplt.rcParams['axes.titlesize'] = 16\n\nfrom kaggle_datasets import KaggleDatasets\n\nfrom time import time, strftime, gmtime\nstart = time()\nimport datetime\nprint(str(datetime.datetime.now()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"print(os.listdir('/kaggle/input/'))\nprint(os.listdir('/kaggle/input/ranzcr-clip-catheter-line-classification/'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_dir = '/kaggle/input/ranzcr-clip-catheter-line-classification/'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv(base_dir + 'train.csv')\ntrain","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"targets = ['ETT - Abnormal', 'ETT - Borderline',\n       'ETT - Normal', 'NGT - Abnormal', 'NGT - Borderline',\n       'NGT - Incompletely Imaged', 'NGT - Normal', 'CVC - Abnormal',\n       'CVC - Borderline', 'CVC - Normal', 'Swan Ganz Catheter Present',\n       ]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of unique PatientID: ', train['PatientID'].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Number of unique Images in Train: ', train['StudyInstanceUID'].nunique())\nprint('Number of unique Images in Test: ', len(os.listdir(base_dir + 'test')))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Labels Count__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train[targets].sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ax = sns.countplot(x = \"variable\", hue = \"value\", data = pd.melt(train[targets]))\nax.grid()\nax.set_xticklabels(targets, rotation = 90)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Visualization__"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images(UID, lbl):\n    files = np.random.choice(UID, 12)\n\n    plt.figure(figsize = (16, 12))\n\n    for i, im in enumerate(files):\n        plt.subplot(3, 4, i + 1)\n        img = cv2.imread(base_dir + 'train/' + im + '.jpg')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (512, 512))\n        plt.imshow(img)\n        plt.title(f'{lbl}', fontsize = 10)\n    plt.suptitle(f'Train Images: {lbl}', fontsize = 16)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for lbl in targets:\n    temp = train['StudyInstanceUID'].loc[train[lbl] == 1]\n    display_images(temp.values, lbl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Visualization with annotations__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_annot = pd.read_csv(base_dir + 'train_annotations.csv')\ntrain_annot","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import ast\n\ndef display_images_annot(temp, lbl):\n    files = np.random.choice(temp['StudyInstanceUID'], 3)\n\n    plt.figure(figsize = (12, 8))\n\n    for i, uid in enumerate(files):\n        plt.subplot(1, 3, i + 1)\n        img = cv2.imread(base_dir + 'train/' + uid + '.jpg')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.imshow(img)\n        \n        annot = train_annot[train_annot['StudyInstanceUID'] == uid]['data'].values[0]\n        annot = np.array(ast.literal_eval(annot))\n        plt.scatter(annot[:, 0], annot[:, 1])\n        plt.title(f'{lbl}', fontsize = 10)\n    plt.suptitle(f'{lbl} with Annotations', fontsize = 16, y = 0.75)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for lbl in targets:\n    temp = train_annot[train_annot['label'] == lbl]\n    display_images_annot(temp, lbl)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Images with more than one labels__"},{"metadata":{"trusted":true},"cell_type":"code","source":"train_more = train[train[targets].sum(axis = 1) > 1]\ntrain_no = train[train[targets].sum(axis = 1) == 0]\nprint('Number of Images with more than one labels: ', len(train_more))\nprint('Number of Images with NO labels: ', len(train_no))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#print(train_more[targets].loc[5].eq(1).astype(int).sum())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images_more(df):\n    idx = np.random.choice(df.index, 12)\n    \n    \n    plt.figure(figsize = (16, 12))\n\n    for i, ind in enumerate(idx):\n        plt.subplot(3, 4, i + 1)\n        im = train_more['StudyInstanceUID'].loc[ind]\n        img = cv2.imread(base_dir + 'train/' + im + '.jpg')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (512, 512))\n        plt.imshow(img)\n        lbl_num = df[targets].loc[5].eq(1).astype(int).sum()\n        plt.title(f'Number of Labels: {lbl_num}', fontsize = 10)\n    plt.suptitle(f'Train Images with more than one label', fontsize = 16)\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_images_more(train_more)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"__Train Images with no Labels__"},{"metadata":{"trusted":true},"cell_type":"code","source":"def display_images_no(df):\n    idx = np.random.choice(df.index, 12)\n    \n    \n    plt.figure(figsize = (16, 12))\n\n    for i, ind in enumerate(idx):\n        plt.subplot(3, 4, i + 1)\n        im = train_no['StudyInstanceUID'].loc[ind]\n        img = cv2.imread(base_dir + 'train/' + im + '.jpg')\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = cv2.resize(img, (512, 512))\n        plt.imshow(img)\n        #plt.title(f'Number of Labels: {lbl_num}', fontsize = 10)\n    plt.suptitle(f'Train Images with NO labels', fontsize = 16)\n    plt.show()\n    print(train_no['StudyInstanceUID'].values)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"display_images_no(train_no)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"finish = time()\nprint(strftime(\"%H:%M:%S\", gmtime(finish - start)))","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}