{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"tez_path = '../input/tez-lib/'\neffnet_path = '../input/efficientnet-pytorch/'\ntimm_path = '../input/timm-pytorch-image-models/pytorch-image-models-master/'\n\nimport sys\nsys.path.append(tez_path)\nsys.path.append(effnet_path)\nsys.path.append(timm_path)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import os\nimport albumentations\nimport pandas as pd\nimport numpy as np\nimport timm\nimport cv2\n\nimport tez\nfrom tez.datasets import ImageDataset\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom efficientnet_pytorch import EfficientNet\nfrom albumentations.pytorch import ToTensorV2\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"INPUT_PATH = \"../input/ranzcr-clip-catheter-line-classification/\"\nIMAGE_PATH = \"../input/ranzcr-clip-catheter-line-classification/test/\"\nMODEL_PATH = \"../input/ranzcr-model/\"\nIMAGE_SIZE = 600\nlabel = 11","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv(os.path.join(INPUT_PATH, \"sample_submission.csv\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class RanzcrModel1(tez.Model):\n    def __init__(self):\n        super().__init__()\n\n        self.effnet = EfficientNet.from_name(\"efficientnet-b5\")\n\n        self.effnet._conv_stem.in_channels = 3\n        weight = self.effnet._conv_stem.weight.mean(3, keepdim=True)\n        self.effnet._conv_stem.weight = torch.nn.Parameter(weight)\n\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(2048, 11)\n\n    def forward(self, image, targets=None):\n        batch_size, _, _, _ = image.shape\n\n        x = self.effnet.extract_features(image)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        outputs = self.out(self.dropout(x))\n        return outputs, None, {}\n    \nclass RanzcrModel2(tez.Model):\n    def __init__(self):\n        super().__init__()\n\n        self.effnet = EfficientNet.from_name(\"efficientnet-b4\")\n\n        self.effnet._conv_stem.in_channels = 3\n        weight = self.effnet._conv_stem.weight.mean(3, keepdim=True)\n        self.effnet._conv_stem.weight = torch.nn.Parameter(weight)\n\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(1792, 11)\n\n    def forward(self, image, targets=None):\n        batch_size, _, _, _ = image.shape\n\n        x = self.effnet.extract_features(image)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        outputs = self.out(self.dropout(x))\n        return outputs, None, {}\n    \nclass RanzcrModel3(tez.Model):\n    def __init__(self,model_name='resnet200d', pretrained=False, num_classes=11):\n        super().__init__()\n\n        self.model = timm.create_model(model_name, pretrained=pretrained)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, num_classes)\n        self.criterion = nn.BCEWithLogitsLoss()\n        \n    def forward(self, image, targets=None):\n        bs = image.size(0)\n        features = self.model(image)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        #if targets != None:\n        #    loss = self.criterion(output, targets)\n        #    metrics = self.monitor_metrics(output, targets)\n        #    return output, loss, metrics\n        return output, None, None","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_aug = albumentations.Compose(\n    [\n        albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n        albumentations.HorizontalFlip(p=0.5),\n        albumentations.VerticalFlip(p=0.5),\n        albumentations.Transpose(p=0.5),\n        albumentations.ShiftScaleRotate(p=0.5),\n       albumentations.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=10, val_shift_limit=10, p=0.7),\n       albumentations.RandomBrightnessContrast(brightness_limit=(-0.2,0.2), contrast_limit=(-0.2, 0.2), p=0.7),\n       albumentations.CLAHE(clip_limit=(1,4), p=0.5),\n       albumentations.OneOf([\n           albumentations.OpticalDistortion(distort_limit=1.0),\n           albumentations.GridDistortion(num_steps=5, distort_limit=1.),\n           albumentations.ElasticTransform(alpha=3),\n       ], p=0.2),\n        albumentations.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n        ),\n        ToTensorV2(),\n    ],\n    p=1.0,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_image_paths = \"../input/ranzcr-clip-catheter-line-classification/test\"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n'''\nmodel1 = RanzcrModel1()\nmodel1.load(os.path.join(MODEL_PATH, \"efficentnet-b5_fold0.bin\"))\n\nmodel2 = RanzcrModel1()\nmodel2.load(os.path.join(MODEL_PATH, \"efficentnet-b5_fold1.bin\"))\n\nmodel3 = RanzcrModel1()\nmodel3.load(os.path.join(MODEL_PATH, \"efficentnet-b5_fold2.bin\"))\n\nmodel4 = RanzcrModel1()\nmodel4.load(os.path.join(MODEL_PATH, \"efficentnet-b5_fold3.bin\"))\n\nmodel5 = RanzcrModel1()\nmodel5.load(os.path.join(MODEL_PATH, \"efficentnet-b5_fold4.bin\"))\n\nmodel6 = RanzcrModel2()\nmodel6.load(os.path.join(MODEL_PATH, \"efficientnet-b4_fold0.bin\"))\n\nmodel7 = RanzcrModel2()\nmodel7.load(os.path.join(MODEL_PATH, \"efficientnet-b4_fold1.bin\"))\n\nmodel8 = RanzcrModel2()\nmodel8.load(os.path.join(MODEL_PATH, \"efficientnet-b4_fold2.bin\"))\n\nmodel9 = RanzcrModel2()\nmodel9.load(os.path.join(MODEL_PATH, \"efficientnet-b4_fold3.bin\"))\n\nmodel10 = RanzcrModel2()\nmodel10.load(os.path.join(MODEL_PATH, \"efficientnet-b4_fold4.bin\"))\n\n\nmodel11 = RanzcrModel3(\"resnet34d\")\nmodel11.load(os.path.join(MODEL_PATH, \"resnet34d_fold0.bin\"))\n\nmodel12 = RanzcrModel3(\"resnet34d\")\nmodel12.load(os.path.join(MODEL_PATH, \"resnet34d_fold1.bin\"))\n\nmodel13 = RanzcrModel3(\"resnet34d\")\nmodel13.load(os.path.join(MODEL_PATH, \"resnet34d_fold2.bin\"))\n\nmodel14 = RanzcrModel3(\"resnet34d\")\nmodel14.load(os.path.join(MODEL_PATH, \"resnet34d_fold3.bin\"))\n\nmodel15 = RanzcrModel3(\"resnet34d\")\nmodel15.load(os.path.join(MODEL_PATH, \"resnet34d_fold4.bin\"))\n\nmodel16 = RanzcrModel3(\"resnet50d\")\nmodel16.load(os.path.join(MODEL_PATH, \"resnet50d_fold0.bin\"))\n\nmodel17 = RanzcrModel3(\"resnet50d\")\nmodel17.load(os.path.join(MODEL_PATH, \"resnet50d_fold1.bin\"))\n\nmodel18 = RanzcrModel3(\"resnet50d\")\nmodel18.load(os.path.join(MODEL_PATH, \"resnet50d_fold2.bin\"))\n\nmodel19 = RanzcrModel3(\"resnet50d\")\nmodel19.load(os.path.join(MODEL_PATH, \"resnet50d_fold3.bin\"))\n\nmodel20 = RanzcrModel3(\"resnet50d\")\nmodel20.load(os.path.join(MODEL_PATH, \"resnet50d_fold4.bin\"))\n'''\n\nmodel21 = RanzcrModel3()\nmodel21.load(os.path.join(MODEL_PATH, \"resnet_model_fold0.bin\"))\n\nmodel22 = RanzcrModel3()\nmodel22.load(os.path.join(MODEL_PATH, \"resnet_model_fold1.bin\"))\n\nmodel23 = RanzcrModel3()\nmodel23.load(os.path.join(MODEL_PATH, \"resnet_model_fold2.bin\"))\n\nmodel24 = RanzcrModel3()\nmodel24.load(os.path.join(MODEL_PATH, \"resnet_model_fold3.bin\"))\n\nmodel25 = RanzcrModel3()\nmodel25.load(os.path.join(MODEL_PATH, \"resnet_model_fold4.bin\"))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader, Dataset\n\nclass TestDataset(Dataset):\n    def __init__(self, df,image_path, transform=None):\n        self.df = df\n        self.file_names = df['StudyInstanceUID'].values\n        self.transform = transform\n        self.image_path = image_path\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_name = self.file_names[idx]\n        file_path = f'{self.image_path}/{file_name}.jpg'\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        label = torch.tensor([[0]]).float()\n        return {\n                \"image\": image,\n                \"targets\": label,\n            }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Approach 1\nfinal_preds = None\n#model_list = [model1, model2, model3, model4, model5, model6, model7, model8, model9, model10, \nmodel_list  = [model21,model22, model23, model24, model25]\nmodel_out = None\nfor model in model_list:\n    for j in range(10):\n        test_dataset = TestDataset(\n            df,\n            image_path=test_image_paths,\n            transform=test_aug,\n        )\n        preds = model.predict(test_dataset, batch_size=6, n_jobs=-1)\n        temp_preds = None\n        for p in preds:\n            if temp_preds is None:\n                temp_preds = p\n            else:\n                temp_preds = np.vstack((temp_preds, p))\n        if final_preds is None:\n            final_preds = temp_preds\n        else:\n            final_preds += temp_preds\n    final_preds /= 10\n    if model_out is None:\n        model_out = final_preds\n    else:\n        model_out += final_preds\n        \nmodel_out /= 5","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"target_cols = df.columns[1:]\n\nfor i in range(model_out.shape[1]):\n    df.loc[:, target_cols[i]] = model_out[:, i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('submission.csv', index=False)\ndf.head()","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}