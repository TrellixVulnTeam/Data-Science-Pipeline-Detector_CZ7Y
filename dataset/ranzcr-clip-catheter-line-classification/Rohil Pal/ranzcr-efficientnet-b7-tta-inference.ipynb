{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('../input/timm-pytorch-image-models/pytorch-image-models-master')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# necessary imports\nimport os\nimport gc\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\n\nimport timm\n\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nDATA_DIR = \"../input/ranzcr-clip-catheter-line-classification\"\n\nplt.style.use('bmh')\nplt.rcParams['figure.figsize'] = [20, 13]\nSEED = 421","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMAGE_SIZE = 600\nBATCH_SIZE = 2\nMODEL_NAME = \"efficientnet_b7\"\nMODEL_PATH_effnetb7 = \"../input/ranzcr-final-timm-efficientnetb7/timm-effnet-b7-res600-final.pt\"\nTTA = True","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_df = pd.read_csv(os.path.join(DATA_DIR, \"sample_submission.csv\"))\nprint (input_df.info())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utility function"},{"metadata":{"trusted":true},"cell_type":"code","source":"def plot_input_images(imgs: torch.Tensor, title_string: str, nrow: int = 4) -> None:\n    image_grid = make_grid(imgs, nrow=nrow, padding=10, pad_value=1)\n    \n    # transform from CHW -> HWC\n    plt.imshow(image_grid.permute(1, 2, 0), cmap=plt.cm.bone)\n    plt.title(title_string)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Test datasets for both models"},{"metadata":{"trusted":true},"cell_type":"code","source":"CLASSES = [col for col in input_df.columns if col not in ['StudyInstanceUID']]\n\n\nclass RanczrDataset(Dataset):\n    def __init__(self, df, data_dir, transform=None, is_test=False, is_rgb=False):\n        super().__init__()\n        self.df = df\n        self.data_dir = data_dir\n        self.transform = transform\n        self.is_test = is_test\n        self.is_rgb = is_rgb\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        data = {}\n        \n        img_name = self.df['StudyInstanceUID'][index]\n        \n        if not self.is_test:\n            targets = self.df.loc[index, CLASSES].values.astype(np.uint8)\n        \n            targets = torch.from_numpy(targets)\n            \n            data['targets'] = targets\n            \n        img_path = os.path.join(self.data_dir, img_name+\".jpg\")\n        \n        \n        if self.is_rgb:\n            image = cv2.imread(img_path)\n            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        else:\n            image = Image.open(img_path)\n            \n        if self.transform:\n            image = self.transform(image)\n        \n        data['image'] = image\n        \n        return data","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Transforms"},{"metadata":{"trusted":true},"cell_type":"code","source":"test_effnet_transforms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485], std=[0.229])\n])\n\n# test_resnet200d_transforms = transforms.Compose([\n#     transforms.ToPILImage(),\n#     transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n#     transforms.ToTensor(),\n#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n# ])\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Visualising test dataset samples for both models"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating the dataset object\ntest_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_effnet_transforms, is_test=True)\n\n# creating the test dataloader\ntest_loader1 = DataLoader(dataset=test_dataset, batch_size=8, num_workers=0, shuffle=False)\n\nbatch = next(iter(test_loader1))\n\nplot_input_images(batch['image'], title_string='batch images', nrow=8)\n\ndel batch\ndel test_dataset\ndel test_loader1\ngc.collect()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # creating the dataset object\n# test_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_resnet200d_transforms, is_test=True, is_rgb=True)\n\n# # creating the test dataloader\n# test_loader2 = DataLoader(dataset=test_dataset, batch_size=8, num_workers=0, shuffle=False)\n\n# batch = next(iter(test_loader2))\n\n# plot_input_images(batch['image'], title_string='batch images', nrow=8)\n\n# del batch\n# del test_dataset\n# del test_loader2\n# gc.collect()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"class Effnetb7(nn.Module):\n    def __init__(self, model_name='efficientnet_b7'):\n        super(Effnetb7, self).__init__()\n        \n        self.effnet = timm.create_model(model_name, pretrained=False, in_chans=1).as_sequential()[:-2]\n        \n        self.dropout = nn.Dropout(p=0.5)\n        self.dense = nn.Linear(2560, len(CLASSES))\n        \n        \n    def forward(self, images):\n        pooled_features= self.effnet(images)\n        \n        outputs = self.dense(self.dropout(pooled_features))\n        \n        return outputs\n    \n# class RANZCRResNet200D(nn.Module):\n#     def __init__(self, model_name='resnet200d', out_dim=11, pretrained=False):\n#         super().__init__()\n#         self.model = timm.create_model(model_name, pretrained=False)\n#         n_features = self.model.fc.in_features\n#         self.model.global_pool = nn.Identity()\n#         self.model.fc = nn.Identity()\n#         self.pooling = nn.AdaptiveAvgPool2d(1)\n#         self.fc = nn.Linear(n_features, out_dim)\n\n#     def forward(self, x):\n#         bs = x.size(0)\n#         features = self.model(x)\n#         pooled_features = self.pooling(features).view(bs, -1)\n#         output = self.fc(pooled_features)\n#         return output","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\neffnetb7 = Effnetb7()\neffnetb7.load_state_dict(torch.load(MODEL_PATH_effnetb7, map_location='cuda:0'))\neffnetb7 = effnetb7.to(device)\n# resnet200d = RANZCRResNet200D()\n# resnet200d.load_state_dict(torch.load(MODEL_PATH_resnet200d, map_location='cuda:0'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Utilities"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Adapted from https://www.kaggle.com/underwearfitting/resnet200d-public-benchmark-2xtta-lb0-965#Utils\n\ndef inference_func(model, test_loader, device):\n    model.eval()\n    bar = tqdm(test_loader)\n    LOGITS = []\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, data in enumerate(bar):\n            x = data['image'].to(device)\n            logits = model(x)\n            LOGITS.append(logits.cpu())\n            PREDS += [logits.sigmoid().detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        LOGITS = torch.cat(LOGITS).cpu().numpy()\n    return PREDS\n\ndef tta_inference_func(model, test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    PREDS = []\n    LOGITS = []\n\n    with torch.no_grad():\n        for batch_idx, data in enumerate(bar):\n            x = data['image'].to(device)\n            x = torch.stack([x,x.flip(2),x.flip(3)],0) # TTA: vflip and hflip\n            x = x.view(-1, 1, IMAGE_SIZE, IMAGE_SIZE)\n            logits = model(x)\n            logits = logits.view(BATCH_SIZE, 3, -1).mean(1)\n            PREDS += [logits.sigmoid().detach().cpu()]\n            LOGITS.append(logits.cpu())\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        \n    return PREDS","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"### Predictions for Efficientnet-b7"},{"metadata":{"trusted":true},"cell_type":"code","source":"# creating the dataset object\ntest_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_effnet_transforms, is_test=True)\n\n# creating the test dataloader\ntest_loader_effnet = DataLoader(dataset=test_dataset, batch_size=2, num_workers=0, shuffle=False)\n\ntest_preds = None\nif TTA:\n    print ('Using TTA')\n    test_preds = tta_inference_func(effnetb7, test_loader_effnet)\nelse:\n    test_preds = inference_func(effnetb7, test_loader_effnet)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_preds","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission = pd.read_csv('../input/ranzcr-clip-catheter-line-classification/sample_submission.csv')\n\nfor i in range(test_preds.shape[1]):\n    submission.loc[:, CLASSES[i]] = test_preds[:, i]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# # creating the dataset object\n# test_dataset = RanczrDataset(input_df, os.path.join(DATA_DIR, \"test\"), test_resnet200d_transforms, is_test=True, is_rgb=True)\n\n# # creating the test dataloader\n# test_loader_resnet200d = DataLoader(dataset=test_dataset, batch_size=2, num_workers=0, shuffle=False)\n\n# predictions_resnet200d = inference_func(resnet200d.to(device), test_loader_resnet200d, device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# predictions = (2 * predictions_resnet200d + predictions_effnetb7) / 3.0","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}