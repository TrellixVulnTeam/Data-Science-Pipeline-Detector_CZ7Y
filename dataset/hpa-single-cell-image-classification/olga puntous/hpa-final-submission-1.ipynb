{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":" ## Hello to everyone ! this is our first kaggle competition test.\n \nIn this notebook we are testing our baseline solution. We trained 18 models (1 model for each label,models are based on efficient net architecture) on selection of monolabel dataset. Training datasets were data augmented and equilibrated. In this notebook we are making predictions using loop of 18 binary models.\n\nWe will appreciate every critical comment or remark! \n\nThank you!","metadata":{}},{"cell_type":"markdown","source":"# Install Libraries","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"!pip install \"../input/keras-application/Keras_Applications-1.0.8-py3-none-any.whl\"\n!pip install \"../input/efficientnet111/efficientnet-1.1.1-py3-none-any.whl\"\n!pip install \"../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n!pip install \"../input/hpapytorchzoozip/pytorch_zoo-master\"\n!pip install \"../input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n#!pip install \"../input/tfexplainforoffline/tf_explain-0.2.1-py3-none-any.whl\"","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, glob\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom pycocotools import _mask as coco_mask\nimport random\nimport base64\nimport numpy as np\nimport typing as t\nimport zlib\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei\nimport cv2\n\nfrom keras.optimizers import Adam\nfrom keras.callbacks import Callback\nfrom efficientnet.keras import EfficientNetB0\nfrom keras.layers import Dense, Flatten\nfrom keras.models import Model, load_model\nfrom albumentations import Compose, VerticalFlip, HorizontalFlip, Rotate, GridDistortion\nfrom IPython.display import Image, display\nimport gc\nfrom tqdm.auto import tqdm\nfrom tensorflow.python.framework import ops\nimport matplotlib.pyplot as plt \nfrom PIL import Image\n\n%matplotlib inline\n\nprint(\"Done--------\")","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gpus = tf.config.experimental.list_physical_devices('GPU')\nfor gpu in gpus:\n    tf.config.experimental.set_memory_growth(gpu, True)\n    tf.compat.v1.disable_eager_execution()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DEBUT","metadata":{}},{"cell_type":"code","source":"# DEBUT\nTEST_IMGS_FOLDER = '../input/hpa-single-cell-image-classification/test/'\nTRAIN_IMGS_FOLDER = '../input/hpa-single-cell-image-classification/train/'\nIMG_HEIGHT = IMG_WIDTH = 128\nMODELS_folder=\"../input/single-labelmodelsaved/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os, glob\n#Generer le dataframe avec les ID, taille des images\n# Capture all the relevant full image paths for the competition dataset\nTEST_IMG_PATHS = sorted([os.path.join(TEST_IMGS_FOLDER, f_name) for f_name in os.listdir(TEST_IMGS_FOLDER)])\nprint(f\"\\n... Recall that 4 training images compose one example (R,G,B,Y) ...\")\nprint(f\"... \\t– i.e. The first 4 training files are:\")\nfor path in [x.rsplit('/',1)[1] for x in TEST_IMG_PATHS[:4]]: print(f\"... \\t\\t– {path}\")\nprint(f\"\\n... The number of training images is {len(TEST_IMG_PATHS)} i.e. {len(TEST_IMG_PATHS)//4} 4-channel images ...\")\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#liste des ID\nid_test=[]\nfor i in TEST_IMG_PATHS:\n    id=i.split(\"/\")\n    id=id[-1]\n    id=id.split(\"_\")\n    id=id[0]\n    if id not in id_test:\n        id_test.append(id)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Creer le dataset Submission\nsubmission_dataset=pd.DataFrame(columns=['ID', 'ImageWidth',\"ImageHeight\"])\n\nsubmission_dataset['ID']=id_test\nsubmission_dataset","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"I will try to look if submission is working only with 3 images.","metadata":{}},{"cell_type":"code","source":"submission_dataset=submission_dataset.sample(3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nsubmission_dataset['ImageWidth']=submission_dataset['ID'].apply(lambda x:(np.array(Image.open(TEST_IMGS_FOLDER + x + '_red.png'))).shape[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_dataset['ImageHeight']=submission_dataset['ID'].apply(lambda x:(np.array(Image.open(TEST_IMGS_FOLDER + x + '_red.png'))).shape[1])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def open_rgby_test(image_id): #a function that reads RGBY image with resizing\n    colors = ['red','green','blue','yellow']\n    img = [cv2.imread(os.path.join(TEST_IMGS_FOLDER, f'{image_id}_{color}.png'), cv2.IMREAD_GRAYSCALE) for color in colors]\n    img = np.stack(img, axis=-1)\n    #img_resized = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n    #img_resized=img_resized/255\n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def open_rgby(image_id): #a function that reads RGBY image with resizing\n    colors = ['red','green','blue','yellow']\n    img = [cv2.imread(os.path.join(TEST_IMGS_FOLDER, f'{image_id}_{color}.png'), cv2.IMREAD_GRAYSCALE) for color in colors]\n    img = np.stack(img, axis=-1)\n    img_resized = cv2.resize(img, (IMG_HEIGHT, IMG_WIDTH))\n    img_resized=img_resized/255\n    return img_resized","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_masks(img, test=True):\n    try:\n        print(\"trying--------\")      \n        images = [[img[:, :, 0] ],\n                  [img[:, :, 3] ],\n                  [img[:, :, 2] ]]\n        print(\"trying done--------\")      \n        nuc_segmentations = segmentator.pred_nuclei(images[2])\n        cell_segmentations = segmentator.pred_cells(images)\n        cell_masks = []\n        for i in tqdm(range(len(cell_segmentations)), desc='Labeling cells..'):\n            _, cell_mask = label_cell(nuc_segmentations[i], cell_segmentations[i])\n            cell_masks.append(cell_mask)\n        return cell_masks\n    except:\n        raise ValueError('Segmentation failed')\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_binary_mask(mask: np.ndarray) -> t.Text:\n  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n\n  # check input mask --\n  if mask.dtype != np.bool:\n    raise ValueError(\n        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n        mask.dtype)\n\n  mask = np.squeeze(mask)\n  if len(mask.shape) != 2:\n    raise ValueError(\n        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n        mask.shape)\n\n  # convert input mask to expected COCO API input --\n  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n  mask_to_encode = mask_to_encode.astype(np.uint8)\n  mask_to_encode = np.asfortranarray(mask_to_encode)\n\n  # RLE encode mask --\n  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n  # compress and base64 encoding --\n  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n  base64_str = base64.b64encode(binary_str)\n  return base64_str.decode('ascii')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GENERE LE DF DE MASK","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission_dataset=submission_dataset.loc[0:3,]\n#submission_dataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# instanciation du model de segmentation en réutilisant les poids préentrainés\nNUC_MODEL = '../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth'\nCELL_MODEL = '../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth'\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    scale_factor=0.25,\n    device='cuda',\n    padding=True,\n    multi_channel_model=True\n)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_dataset['MASK']=submission_dataset['ID'].apply(lambda x:get_masks(open_rgby_test(str(x))))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_dataset['MASK_BINAIRE']=submission_dataset['MASK'].apply(lambda x:x[0]>0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_dataset['MASK_BINAIRE_ENCODE']=submission_dataset['MASK_BINAIRE'].apply(lambda x:encode_binary_mask(x))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GENERE LA PREDICTION","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model=[]\nN=7000\nlabels=np.arange(18)\nlabels\n\nfor label in tqdm(labels):    \n    model.append(load_model(\"../input/single-labelmodelsaved/model_label_{}_monolabel_{}.h5\".format(label,N)))\n    submission_dataset['prediction_{}'.format(label)]=submission_dataset['ID'].apply(lambda x: model[label].predict(np.expand_dims((open_rgby(str(x))),0),use_multiprocessing=True))\n    submission_dataset['prediction_result_{}'.format(label)]=submission_dataset['prediction_{}'.format(label)].apply(lambda x: 1 if x>0.5 else 0) \n    \n#sub_dataset[df].to_csv('./sub_dataset_{}_{}'.format(label,df))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# POUR LABEL 18\nfor index,row in submission_dataset.iterrows():\n    total=0\n    for j in range (18):\n        colonne=\"prediction_result_{}\".format(j)\n        total=total + row[colonne]\n    if total==0:\n        submission_dataset.loc[index,'prediction_result_18']=1\n    else:\n        submission_dataset.loc[index,'prediction_result_18']=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# GENERE LA PREDICTION STRING","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"liste_prediction=[\"prediction_result_{}\".format(i) for i in range(19)]\nliste_label=[i for i in range(19)]\nsubmission_dataset['PredictionString']=\"\"\n\n#pour genérer la liste\nfor index,row in submission_dataset.iterrows():\n    k=0\n    predstring=''\n    for i in liste_prediction:\n        pred=row[i]\n        if pred==1:\n            enc=row['MASK_BINAIRE_ENCODE'] \n            label=liste_label[k]\n            predstring = predstring + str(label) + ' 1.0 ' + enc + ' '\n            k=k+1\n    #print(index, predstring)\n    submission_dataset.loc[index,'PredictionString']=predstring","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#GENERE LE submission csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sample=submission_dataset.loc[:,['ID','ImageWidth','ImageHeight','PredictionString']]\nsubmission_sample.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission_sample.rename(columns={'ImageHeight_x': 'ImageHeight','ImageWidth_x':'ImageWidth','SubmissionString':'PredictionString'}, inplace=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#submission_sample.loc[225,'PredictionString'].split(' ')[5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_sample.to_csv('submission.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#test=pd.read_csv('./submission.csv')\n#test.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}