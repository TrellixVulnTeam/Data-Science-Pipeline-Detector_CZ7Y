{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# A simplistic experiment on cell image segmentation\n# To form the image with RGB format, we simply concatenate \n# the input filter images with R-G-B sequence order and forming\n# a new image. We chose one of the RGB filter color cell images \n# as the mask and segmenting the RGB color cell image. We designed \n# a simple Up and Down tensorflow layer stack for encoding and\n# decoding purpose. We both show the concatednated images and \n# segmented images in this experiment.\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\n# using python csv library for writing results\nimport csv\n# loading data in windows environment\nimport pathlib\nimport re\nprint (tf.__version__)\nfrom kaggle_datasets import KaggleDatasets\nimport PIL.Image\nimport cv2\nfrom io import StringIO\n# Hardware platform: You may want to scale your training onto multiple GPUs on one machine, \n# or multiple machines in a network (with 0 or more GPUs each), or on Cloud TPUs.\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\n\nif tpu:\n    # Passing in the name of the CloudTPU\n    tf.config.experimental_connect_to_cluster(tpu)\n    # The TPU initialization code has to be at the beginning of the program\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    # A distribution strategy is an abstraction that can be used to drive models on CPU, GPUs or TPUs\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.experimental.CentralStorageStrategy()\n    print (\"GPU VERSION\")\n    \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nGCS_DS_PATH = KaggleDatasets().get_gcs_path('hpa-single-cell-image-classification')\nGCS_PATH = GCS_DS_PATH + '/train_tfrecords'\n#TEST_GCS_PATH = GCS_DS_PATH + '/test_tfrecords'\nAUTO = tf.data.experimental.AUTOTUNE\n\n#TRAINING_FILENAMES = tf.io.gfile.glob(\"../input/cassava-leaf-disease-classification/\" + 'train_tfrecords/*.tfrec')\nTRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/*.tfrec')\n#TEST_NAMES = tf.io.gfile.glob(\"../input/cassava-leaf-disease-classification/\" + 'test_images/*.jpg')\n\nIMG_HEIGHT=2048\nIMG_WIDTH=2048\n\n\"\"\"\nReading the tfrecord data, creating dataset from\ntfrecord data.\n\n\"\"\"\nDATASET = tf.data.TFRecordDataset(TRAINING_FILENAMES)\n#for dat in DATASET.take(1):\n    #V = tf.train.Example()\n    #V.ParseFromString(dat.numpy())\n    #print (V)\n\ndef mapping_image_id(dat):\n    TFREC_MAP = {\"image\": tf.io.FixedLenFeature([], tf.string),\n                 \"target\": tf.io.FixedLenFeature([], tf.string),\n                 \"image_name\": tf.io.FixedLenFeature([], tf.string),\n                }\n    parsed_dat = tf.io.parse_single_example(dat, TFREC_MAP)\n    image = tf.io.decode_png(parsed_dat['image'], channels=3)\n    # Normalizing Image\n    image = tf.cast(image/255, dtype=tf.float32)\n    # Parsing the target data\n    target = parsed_dat['target']\n    # Parsing the image name\n    name = parsed_dat['image_name']\n    #target = tf.cast(target, dtype=tf.int32)\n    return image, target, name\n\n# Processing Input Training Data\ntrain_data_set = tf.data.TFRecordDataset(TRAINING_FILENAMES, num_parallel_reads=AUTO)\n#train_img = train_data_set.map(mapping_image)\n#train_img = train_img.batch(8000)\n#train_target = train_data_set.map(mapping_id)\n#train_target = train_target.batch(8000)\ntrain_data = train_data_set.map(mapping_image_id)\n\n# Creating training and testing dataset.\n# Getting ready for model data input.\ndef data_input(S):\n    # Image List\n    I=[]\n    # Name List\n    N=[]\n    # Label List\n    L=[]\n    K=0\n    # Scaning through dataset\n    for dat, lab, name in train_data:\n        # exit when exceeding length \n        if (K>=S):\n            break\n        #re_image = tf.image.central_crop(dat, 0.5)\n        #re_image = tf.image.resize_with_pad(dat, IMG_HEIGHT,IMG_WIDTH, method=tf.image.ResizeMethod.BICUBIC,antialias=True)\n        #re_image = tf.reshape(re_image, shape=[1,IMG_HEIGHT, IMG_WIDTH,3])\n        #re_image = re_image[0].numpy()\n        #IMG.append(re_image)\n        #L.append(lab)\n        I.append(dat)\n        N.append(name.numpy().decode('utf-8'))\n        L.append(lab.numpy().decode('utf-8'))\n        #print (L)\n        # Adding Image to the list\n        # Adding Name to the list\n        #W = name.numpy().decode('utf-8')\n        #W = W.split('_')\n        #if (W[1]=='green'):\n            #print (W[0])\n            #I.append(dat)\n            #N.append(W)\n            #LL = lab.numpy().decode('utf-8')\n            #LL = LL.split('|')\n            #LZ = int(LL[0])\n            #L.append(LZ)\n            #K=K+1\n            #print (K)\n        #N.append(name.numpy().decode('utf-8'))\n        # Adding Label to the list\n        K = K + 1\n    return I, N, L\n\nDATA_SIZE = 9\n\n# Color green files\ngreen_files = tf.io.gfile.glob('../input/hpa-single-cell-image-classification/train/*_green.png')\n# Color yellow files\nyellow_files = tf.io.gfile.glob('../input/hpa-single-cell-image-classification/train/*_yellow.png')\n# Color blue files\nblue_files = tf.io.gfile.glob('../input/hpa-single-cell-image-classification/train/*_blue.png')\n# Color red files\nred_files = tf.io.gfile.glob('../input/hpa-single-cell-image-classification/train/*_red.png')\n\n\nyellow_files.sort()\ngreen_files.sort()\nblue_files.sort()\nred_files.sort()\n\n# Load Data Images\ndef LoadImages(S):\n    Images = []\n    for index in range(S):\n        IMG = tf.io.read_file(filenames[index])\n        # Decoding the image\n        #IMG = tf.io.decode_png(IMG, channels=3)\n        # Resize the image\n        # IMG = tf.cast(IMG/255, dtype=tf.float32)\n        #IMG = tf.image.resize(IMG, [1024,1024],method='bicubic')\n        Images.append(IMG)\n    return Images\n\n#Generate color red cell images\ndef Gen_color_Img(S, names):\n    Images = []\n    for index in range(S):\n        # Read the raw data\n        IMG = tf.io.read_file(names[index])\n        # Decoding the raw data\n        IMG = tf.io.decode_png(IMG, channels=1)\n        # Resize the image\n        IMG = tf.image.resize(IMG, [2048,2048],method='bicubic')\n        Images.append(IMG)\n    return Images\n# Generate color red images\nRED_CELL = Gen_color_Img(DATA_SIZE, red_files)\n# Generate color green images\nGREEN_CELL = Gen_color_Img(DATA_SIZE, green_files)\n# Generate color blue images\nBLUE_CELL = Gen_color_Img(DATA_SIZE, blue_files)\n# Generate color yellow images\nYELLOW_CELL = Gen_color_Img(DATA_SIZE, yellow_files)\n\n\"\"\"\nLeft here\n\"\"\"\ndef input_data_processing(S):\n    DATA = []\n    for index in range(S):\n        IMG = tf.concat([RED_CELL[index], GREEN_CELL[index], BLUE_CELL[index]], 2)\n        DATA.append(IMG)\n    plt.show()\n    return DATA\n\n# Displaying the cell image\ndef Display_M(dat, data_size):\n    fig = plt.figure(figsize=(18,18))\n    for Z in range(data_size):\n        ax = fig.add_subplot(3,3,Z+1)\n        plt.imshow(dat[Z])\n        plt.title(\"Unsegmented {}\".format(Z))\n    plt.show()\n    \n# Processing input data\ninput_data = input_data_processing(DATA_SIZE)\n# Display data\nDisplay_M(input_data, DATA_SIZE)\n# Convert to tensor\ninput_data = tf.convert_to_tensor(input_data)\n\n# Creating mask\ndef LoadFilters(F,S):\n    Images = []\n    for index in range(S):\n        IMG = tf.io.read_file(F[index])\n        # Decoding the image\n        IMG = tf.io.decode_png(IMG, channels=3)\n        Images.append(IMG)\n    return Images\n\nmask_cell = LoadFilters(red_files,DATA_SIZE)\nmask_cell = tf.convert_to_tensor(mask_cell)\n#green_imgs.reverse()\n\n# Extracting Data\n#IMG, NAME, LAB = data_input(DATA_SIZE)\n#print (NAME)\n#LAB = np.array(LAB)\n#print (LAB.shape)\n\n#IMG = tf.convert_to_tensor(IMG)\n#print (IMG.shape)\n        \n# Showing the cell image      \n\n# Encoder Stack\ndef down_sample(b_id):\n    init = tf.random_normal_initializer(0., 0.02)\n    X = tf.keras.Sequential()\n    X.add(tf.keras.layers.DepthwiseConv2D(kernel_size=(3,3),kernel_initializer=init, padding='same',name='Conv2D_{}'.format(b_id), strides=(2,2)))\n    X.add(tf.keras.layers.BatchNormalization(axis=1, name='batch_norm_{}'.format(b_id)))\n    X.add(tf.keras.layers.ReLU(max_value=6.0,name='relu_{}'.format(b_id)))\n    return X\n\n# Decoder Stack\ndef up_sample(filters, b_id):\n    X = tf.keras.Sequential()\n    X.add(tf.keras.layers.Conv2DTranspose(filters, kernel_size=(3,3), padding='same', name='Transpose_Conv2D_{}'.format(b_id),strides=(2,2)))\n    X.add(tf.keras.layers.BatchNormalization(axis=1,name='batch_norm_transpose_{}'.format(b_id)))\n    X.add(tf.keras.layers.ReLU(max_value=6.0,name='relu_{}'.format(b_id)))\n    return X\n\n# Generate Data for model\ndef gen_data_patch(S, IMG_DATA):\n    DATA = []\n    for dat in range(S):\n        #IMG_K = tf.image.resize(IMG_DATA[dat], [2048,2048],method='bicubic')\n        DATA.append(IMG_DATA[dat])\n    DATA = tf.convert_to_tensor(DATA)\n    return DATA\n\n# Color red data\nRED_DATA = gen_data_patch(DATA_SIZE, RED_CELL)\n# Color green data\nGREEN_DATA = gen_data_patch(DATA_SIZE, GREEN_CELL)\n# Color blue data\nBLUE_DATA = gen_data_patch(DATA_SIZE, BLUE_CELL)\n# Color yellow data\nYELLOW_DATA = gen_data_patch(DATA_SIZE, YELLOW_CELL)\n\nwith strategy.scope():\n    b_id = 0\n    model_input = tf.keras.layers.Input(shape=[IMG_WIDTH,IMG_HEIGHT,3]) #2048X2048\n    # Color green cell input\n    model_input_green = tf.keras.layers.Input(shape=[IMG_WIDTH,IMG_HEIGHT,1]) #2048X2048\n    # Color red cell input\n    model_input_red = tf.keras.layers.Input(shape=[IMG_WIDTH,IMG_HEIGHT,1]) #2048X2048\n    # Color yellow cell input\n    model_input_mask = tf.keras.layers.Input(shape=[IMG_WIDTH,IMG_HEIGHT,3]) #2048X2048\n    \n    # Concatenate layer\n    the_input = tf.keras.layers.concatenate([model_input, model_input_mask])\n    \n    # model input\n\n    \n    # Encoder Layer\n    down_layers = [down_sample(b_id+1), #512X512\n                   down_sample(b_id+2), #256X256\n                   down_sample(b_id+3), #128X128\n                   down_sample(b_id+4), #64X64\n                   down_sample(b_id+5), #32X32\n                   down_sample(b_id+6), #16X16\n                  ]\n    # Decoder Layer\n    up_layers = [up_sample(512,b_id+4),#32X32\n                 up_sample(256,b_id+5),#64X64\n                 up_sample(128,b_id+6),#128X128\n                 up_sample(64,b_id+7),#256X256\n                 up_sample(32,b_id+8),#512X512\n                ]\n    \n    # Generator building block\n    #X = the_input\n    X = the_input\n    down_out = []\n    for layers in down_layers:\n        X = layers(X)\n        down_out.append(X)\n    Z = down_out[-1]\n    # Reversing for the concatenate layer\n    down_out = reversed(down_out[:-1])\n    \n    # Building the Generator\n    for up, down in zip(up_layers, down_out):\n        Z = up(Z)\n        Z = tf.keras.layers.Concatenate()([Z, down])\n        \n    # Final output layer\n    Z = tf.keras.layers.Conv2DTranspose(3, kernel_size=(3,3), padding='same', name='Transpose_Conv2D_{}'.format(b_id),strides=(2,2))(Z)\n    model_opt_func = tf.keras.optimizers.SGD(lr=0.0001)\n    model = tf.keras.Model(inputs=[model_input, model_input_mask], outputs=Z)\n    #model.compile(optimizer=model_opt_func, loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics=['accuracy'])\n    #model.summary()\n\n# Displaying the cell image\ndef Display_S(dat, g_id):\n    fig = plt.figure(figsize=(18,18))\n    for Z in range(g_id):\n        ax = fig.add_subplot(3,3,Z+1)\n        plt.imshow(dat[Z])\n        plt.title(\"Segmented {}\".format(Z))\n    plt.show()\n\n# Model output\ngen_out = model([input_data,mask_cell],  training=False)\n\n# Displaying the model result\nDisplay_S(gen_out, DATA_SIZE)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]}]}