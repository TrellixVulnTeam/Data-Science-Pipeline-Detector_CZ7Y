{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\npackage_path = '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master'\nsys.path.append(package_path)\n\n!ls ../input/efficientnet-pytorch/EfficientNet-PyTorch\n\n%cd /kaggle/input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master\nfrom efficientnet_pytorch import EfficientNet\n%cd -","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom fastai.vision.all import *\nimport pickle\nimport os","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Get Image ID path\ndef get_x(r): return path/'cells'/(r['image_id']+'_'+str(r['cell_id'])+'.jpg')\n\n#Get Image labels\ndef get_y(r): return r['image_labels'].split('|')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Trained efficient model import\nexport_learner = load_learner('../input/hpaweights/effb5_e2.pkl',cpu=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Segemented Test Dataset\npath = Path('../input/hpa-cell-tiles-test-with-enc-dataset')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read dataset\ndf = pd.read_csv(path/'cell_df.csv')\ndf.to_csv('cell_df.csv', index=False)\n\n#Test dataloader \ntest_dl = export_learner.dls.test_dl(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds, _ = export_learner.get_preds(dl=test_dl)\npreds.shape\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cls_prds = torch.argmax(preds, dim=-1)\nlen(cls_prds), cls_prds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\nsample_submission.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['cls'] = cls_prds\n#assign pred column to class and bbox encorded string\ndf['pred'] = df[['cls', 'enc']].apply(lambda r: str(r[0]) + ' 1 ' + r[1], axis=1)\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm = df.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()\nsubm.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.merge(\n    sample_submission,\n    subm,\n    how=\"left\",\n    left_on='ID',\n    right_on='image_id',\n)\nsub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def isNaN(num):\n    return num != num\nfor i, row in sub.iterrows():\n    if isNaN(row['pred']): continue\n    sub.PredictionString.loc[i] = row['pred']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = sub[sample_submission.columns]\nsub.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission_1.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cell_df = pd.read_csv('cell_df.csv')\ncell_df.head()\ncell_df['cls'] = ''","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.0\n\nfor i in range(preds.shape[0]): \n    p = torch.nonzero(preds[i] > threshold).squeeze().numpy().tolist()\n    if type(p) != list: p = [p]\n    if len(p) == 0: cls = [(preds[i].argmax().item(), preds[i].max().item())]\n    else: cls = [(x, preds[i][x].item()) for x in p]\n    cell_df['cls'].loc[i] = cls","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine(r):\n    cls = r[0]\n    enc = r[1]\n    classes = [str(c[0]) + ' ' + str(c[1]) + ' ' + enc for c in cls]\n    return ' '.join(classes)\n\ncell_df['pred'] = cell_df[['cls', 'enc']].apply(combine, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm = cell_df.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.merge(\n    sample_submission,\n    subm,\n    how=\"left\",\n    left_on='ID',\n    right_on='image_id',\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, row in sub.iterrows():\n    if isNaN(row['pred']): continue\n    sub.PredictionString.loc[i] = row['pred']","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = sub[sample_submission.columns]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del export_learner\ntorch.cuda.empty_cache(),test_dl\n#Installing Keras application and tensorlfow efficient Model\n!pip install /kaggle/input/kerasapplications -q\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n#Import tensorlfow  and efficient\nimport tensorflow as tf; print(f\"\\t\\tâ€“ TENSORFLOW VERSION: {tf.__version__}\");\nimport efficientnet.tfkeras as efn\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Below function automatically use available gpu and tpu for tensorflow\ndef auto_select_accelerator():\n    try:\n        tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n        tf.config.experimental_connect_to_cluster(tpu)\n        tf.tpu.experimental.initialize_tpu_system(tpu)\n        strategy = tf.distribute.experimental.TPUStrategy(tpu)\n        print(\"Running on TPU:\", tpu.master())\n    except ValueError:\n        strategy = tf.distribute.get_strategy()\n    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n    return strategy\n\n#Below Function use to read images from dataset for infernce in model\ndef build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n    def decode(path):\n        file_bytes = tf.io.read_file(path)\n        if ext == 'png':\n            img = tf.image.decode_png(file_bytes, channels=3)\n        elif ext in ['jpg', 'jpeg']:\n            img = tf.image.decode_jpeg(file_bytes, channels=3)\n        else:\n            raise ValueError(\"Image extension not supported\")\n\n        img = tf.cast(img, tf.float32) / 255.0\n        img = tf.image.resize(img, target_size)\n\n        return img\n\n    def decode_with_labels(path, label):\n        return decode(path), label\n\n    return decode_with_labels if with_labels else decode\n\n#below function use to apply  aguments to images to give more variance to model\n#We use flip agumentation\ndef build_augmenter(with_labels=True):\n    def augment(img):\n        img = tf.image.random_flip_left_right(img)\n        img = tf.image.random_flip_up_down(img)\n        return img\n\n    def augment_with_labels(img, label):\n        return augment(img), label\n\n    return augment_with_labels if with_labels else augment\n\n#Building utility function for testing dataset with batch size =32\ndef build_dataset(paths, labels=None, bsize=32, cache=True,\n                  decode_fn=None, augment_fn=None,\n                  augment=True, repeat=True, shuffle=1024, \n                  cache_dir=\"\"):\n    if cache_dir != \"\" and cache is True:\n        os.makedirs(cache_dir, exist_ok=True)\n\n    if decode_fn is None:\n        decode_fn = build_decoder(labels is not None)\n\n    if augment_fn is None:\n        augment_fn = build_augmenter(labels is not None)\n\n    AUTO = tf.data.experimental.AUTOTUNE\n    slices = paths if labels is None else (paths, labels)\n\n    dset = tf.data.Dataset.from_tensor_slices(slices)\n    dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n    dset = dset.cache(cache_dir) if cache else dset\n    dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n    dset = dset.repeat() if repeat else dset\n    dset = dset.shuffle(shuffle) if shuffle else dset\n    dset = dset.batch(bsize).prefetch(AUTO)\n\n    return dset","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"COMPETITION_NAME = \"hpa-single-cell-image-classification\"\nstrategy = auto_select_accelerator()\nBATCH_SIZE = strategy.num_replicas_in_sync * 16\n\nIMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)\n\nload_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\nsub_df = sub.copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = sub_df.drop(sub_df.columns[1:],axis=1)\nfor i in range(19):\n    sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\ntest_paths = load_dir + \"/test/\" + sub_df['ID'] + '_green.png'\nlabel_cols = sub_df.columns[1:]\ntest_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]))\ndtest = build_dataset(\n        test_paths, bsize=BATCH_SIZE, repeat=False, \n        shuffle=False, augment=False, cache=False,\n        decode_fn=test_decoder\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    model = tf.keras.models.load_model(\n        '../input/hpa-classification-efnb7-train/model_green.h5'\n    )","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()\nsub_df[label_cols] = model.predict(dtest, verbose=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.merge(sub, sub_df, on = 'ID', how = 'left')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in range(sub.shape[0]):\n    if sub.loc[i,'PredictionString'] == '0 1 eNoLCAgIMAEABJkBdQ==':\n        continue\n    a = sub.loc[i,'PredictionString']\n    b = a.split()\n    for j in range(int(len(a.split())/3)):\n        for k in range(19):\n            if int(b[0 + 3 * j]) == k:\n\n                c = b[0 + 3 * j + 1]               \n                b[0 + 3 * j + 1] = str(sub.loc[i,f'{k}'] * 0.6 + float(c) * 0.4)# * 0.9 + float(c) * 0.1\n\n    sub.loc[i,'PredictionString'] = ' '.join(b)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = sub[['ID','ImageWidth','ImageHeight','PredictionString']]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.to_csv('submission.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}