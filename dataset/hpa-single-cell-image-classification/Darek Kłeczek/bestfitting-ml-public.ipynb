{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"!git clone https://github.com/CellProfiling/HPA-competition-solutions.git","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import sys\nsys.path.append('./HPA-competition-solutions/bestfitting/src/')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Need to restart the kernel after this"},{"metadata":{"trusted":true},"cell_type":"code","source":"from config.config import *\nfrom networks.densenet import *\nfrom networks.resnet_ml import *\nfrom datasets.tool import *\nfrom torch.utils.data import Dataset\nimport pandas as pd\nimport torchvision\nfrom tqdm import tqdm\nimport torch\nimport cv2\nimport os","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opj = os.path.join","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def read_rgby_test(img_id):\n    img_dir = '../input/hpa-public-768-excl-0-16/hpa_public_excl_0_16_768/small'\n    suffix = '.png'\n    colors = ['red', 'green', 'blue', 'yellow']\n    flags = cv2.IMREAD_GRAYSCALE\n    img = [cv2.imread(opj(img_dir, img_id + '_' + color + suffix), flags)\n           for color in colors]\n    img = np.stack(img, axis=-1)\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ProteinTestDataset(Dataset):\n    def __init__(self,\n                 test_df,\n                 img_size=512,\n                 transform=None,\n                 in_channels=4\n                 ):\n        self.test_df = test_df\n        self.img_size = img_size\n        self.in_channels = in_channels\n        self.transform = transform\n\n    def __getitem__(self, index):\n        img_id = self.test_df.ID.loc[index]\n        image = read_rgby_test(img_id)\n        image = cv2.resize(image, (512,512))\n        image = image / 255.0\n        image = image_to_tensor(image)\n        return image\n\n    def __len__(self):\n        return len(self.test_df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = pd.read_csv('../input/hpa-public-768-excl-0-16/hpa_public_excl_0_16_768.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#DEBUG\n# df = df.iloc[:30]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_dataset = ProteinTestDataset(\n    df\n)\ntest_loader = torch.utils.data.DataLoader(\n    test_dataset,\n    sampler=torch.utils.data.SequentialSampler(test_dataset),\n    batch_size=4,\n    drop_last=False,\n    num_workers=2,\n    pin_memory=True,\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def convert_probs(all_probs):\n    new_probs = np.zeros((all_probs.shape[0],19))\n    new_probs[:,:8] = all_probs[:,:8]\n    new_probs[:,8] = all_probs[:,11]\n    new_probs[:,9] = (all_probs[:,12] + all_probs[:,13]) / 2\n    new_probs[:,10] = all_probs[:,14]\n    new_probs[:,11] = all_probs[:,17]\n    new_probs[:,12] = all_probs[:,19]\n    new_probs[:,13] = (all_probs[:,21] + all_probs[:,22]) / 2\n    new_probs[:,14] = all_probs[:,23]\n    new_probs[:,15] = all_probs[:,24]\n    new_probs[:,16] = all_probs[:,25]\n    new_probs[:,17] = (all_probs[:,8] + all_probs[:,9] + all_probs[:,10] + all_probs[:,26]) / 4\n    new_probs[:,18] = 1 - np.max(all_probs, axis=-1)\n    return new_probs","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dm = torchvision.models.resnet50(pretrained=True)\nmodel = class_resnet50_dropout(num_classes=12815, in_channels=4, pretrained_file='/root/.cache/torch/hub/checkpoints/resnet50-19c8e357.pth')\nweights = torch.load('../input/bestfittingml/045.pth')\nmodel.load_state_dict(weights['state_dict'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.set_configs(extract_feature=True)\nmodel.cuda() # .cuda()\nmodel.eval()\n\nwith torch.no_grad():\n    all_feats = []\n    for it, iter_data in tqdm(enumerate(test_loader, 0), total=len(test_loader)):\n        images = iter_data\n        images = Variable(images.cuda(), volatile=True) ### .cuda()\n        outputs = model(images)\n        logits, feats = outputs\n        feats = feats.data.cpu().numpy()\n        all_feats.append(feats)\n    all_feats = np.vstack(all_feats)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"all_feats.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nwith open('feats_ext.pickle', 'wb') as handle:\n    pickle.dump(all_feats, handle)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.to_csv('feats_df_ext.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}