{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    my first published notebook\n    if you find an error, write"},{"metadata":{"trusted":true},"cell_type":"markdown","source":"        based on:\n\n1. http://www.kaggle.com/its7171/mmdetection-for-segmentation-training\n1. https://www.kaggle.com/sreevishnudamodaran/vinbigdata-fusing-bboxes-coco-dataset\n1. https://www.kaggle.com/anandsm7/hpa-starter-pytorch-eda-classification-nfnets"},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install ../input/mmcoco/mmpycocotools/","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from collections import defaultdict\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport PIL\nfrom PIL import Image\nimport shutil\nimport csv\nimport threading\nfrom threading import Thread\nimport sqlite3\nimport datetime\nfrom tqdm import tqdm\nfrom itertools import groupby\nfrom pycocotools import mask as mutils\nfrom pycocotools.coco import COCO\nfrom pycocotools.cocoeval import COCOeval\nimport pickle\nimport cv2\nfrom multiprocessing import Pool\nimport matplotlib.pyplot as plt\nimport json\nfrom multiprocessing import Process, Queue","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train = pd.read_csv('../input/hpa-single-cell-image-classification/train.csv')\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# создать столбец с количеством лейблов изображения\ntrain['label_count'] = train['Label'].apply(lambda x: len(x.split(\"|\")))\ntrain.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# количество одиночных лейблов\na = train[train['label_count'] == 1]['label_count'].count()\na","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#количество составных лейблов\nb = train[train['label_count'] > 1]['label_count'].count()\nb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#now lets compare between single vs multi label distribution\n# теперь давайте сравним распределение по одной и по нескольким меткам\nlabels = train[\"Label\"].apply(lambda x: x.split(\"|\"))\nlabels_count = defaultdict(int)\n\n# Update the counter \nfor label in labels:\n    if len(label) > 1:\n        for l in label:\n            labels_count[LABELS[int(l)]]+=1\n    else:\n        labels_count[LABELS[int(label[0])]]+=1\n        \nplt.figure(figsize=(10, 8))\nplt.xticks(rotation=45)\nplt.title(\"Target counts\")\nsns.barplot(list(labels_count.keys()),list(labels_count.values()))\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train['Label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"massive = []\nfor i in range(18):\n    f = len(train[train['Label'] == f'{i}'])\n    massive.append(f)\n    print(f'{i} - {f}')\nsum = 0\n\nsum = 0\nfor i in massive:\n    sum += int(i)\nprint(sum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"d = len(train[train['Label'] == '11'])\nd","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"h = train.loc[train.Label == '11']\nh","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# посмотреть изображение с лейблом 11\ndef show_image():\n    sns.reset_orig()\n    #get image id\n    im_id = 'b6a469d8-bbad-11e8-b2ba-ac1f6b6435d0'\n\n    cdict1 = {'red':   ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0))}\n\n    cdict2 = {'red':   ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0))}\n\n    cdict3 = {'red':   ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0))}\n\n    cdict4 = {'red': ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'green': ((0.0,  0.0, 0.0),\n                       (0.75, 1.0, 1.0),\n                       (1.0,  1.0, 1.0)),\n\n             'blue':  ((0.0,  0.0, 0.0),\n                       (1.0,  0.0, 0.0))}\n\n    plt.register_cmap(name='greens', data=cdict1)\n    plt.register_cmap(name='reds', data=cdict2)\n    plt.register_cmap(name='blues', data=cdict3)\n    plt.register_cmap(name='yellows', data=cdict4)\n\n    #get each image channel as a greyscale image (second argument 0 in imread)\n    # получить каждый канал изображения как изображение в оттенках серого (второй аргумент 0 в imread)\n    green = cv2.imread('../input/hpa-single-cell-image-classification/train/{}_green.png'.format(im_id), 0)\n    red = cv2.imread('../input/hpa-single-cell-image-classification/train/{}_red.png'.format(im_id), 0)\n    blue = cv2.imread('../input/hpa-single-cell-image-classification/train/{}_blue.png'.format(im_id), 0)\n    yellow = cv2.imread('../input/hpa-single-cell-image-classification/train/{}_yellow.png'.format(im_id), 0)\n\n\n    #display each channel separately\n    # отображать каждый канал отдельно\n    fig, ax = plt.subplots(nrows = 2, ncols=2, figsize=(15, 15))\n    ax[0, 0].imshow(green, cmap=\"greens\")\n    ax[0, 0].set_title(\"Protein of interest\", fontsize=18)\n    ax[0, 1].imshow(red, cmap=\"reds\")\n    ax[0, 1].set_title(\"Microtubules\", fontsize=18)\n    ax[1, 0].imshow(blue, cmap=\"blues\")\n    ax[1, 0].set_title(\"Nucleus\", fontsize=18)\n    ax[1, 1].imshow(yellow, cmap=\"yellows\")\n    ax[1, 1].set_title(\"Endoplasmic reticulum\", fontsize=18)\n    for i in range(2):\n        for j in range(2):\n            ax[i, j].set_xticklabels([])\n            ax[i, j].set_yticklabels([])\n            ax[i, j].tick_params(left=False, bottom=False)\n    plt.show()\n    \n\nshow_image()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Create a selection from images with 1 label\n    Создаем выборку из изображений с 1 меткой"},{"metadata":{"trusted":true},"cell_type":"code","source":"my_dict = {}\nwith open(\"../input/hpa-single-cell-image-classification/train.csv\",\"r\") as f:\n    cr = csv.reader(f, delimiter=',', lineterminator='\\n')\n    next(f, None)\n    for row in cr:\n        if len(row[1]) <= 2 and int(row[1]) < 18:\n            a = row[1].strip('\", ')\n            my_dict.setdefault(row[0].strip('\" '),[]).append(a)\nwith open(\"./train_1.csv\", \"w\") as f:\n    writer = csv.writer(f,delimiter=',')\n    writer.writerow(('ID', 'Label'))\n    for i,j in my_dict.items():\n        d=\" \"\n        t = d.join(j)\n        writer.writerow([i]+[t])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"con = sqlite3.connect('./bas.db')\ncursorObj = con.cursor()\ncursorObj.execute('CREATE TABLE IF NOT EXISTS tabel(id INTEGER PRIMARY KEY AUTOINCREMENT, IDS REAL not NULL, LABEL REAL not NULL)')\ncon.commit()\nwith open(\"./train_1.csv\",\"r\") as fg:\n    cr = csv.reader(fg, delimiter=',', lineterminator='\\n')\n    next(fg, None)\n    for a, b in cr:\n        cursorObj.execute(\"INSERT INTO tabel(IDS, LABEL) VALUES (?,?)\", (a, b))  # Добавляем без id - он добавится сам\ncon.commit()\ncursorObj.close()\ncon.close()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"con = sqlite3.connect('./bas.db')\ncursorObj = con.cursor()\ndatas = {}\nfor i in range(18):\n    cursorObj.execute(f\"SELECT DISTINCT id, IDS, LABEL FROM tabel WHERE LABEL= '{i}' LIMIT 200\")\n    rows = cursorObj.fetchall()\n    for a, b, c in rows[0:180]:\n        if c == 0.0:\n            v = '18'\n            d = '1'\n            datas.setdefault(b.strip('\" '),[]).append([v, d])\n        else:   \n            d = '1'\n            datas.setdefault(b.strip('\" '),[]).append([c, d])\n    for f, g, h in rows[181:200]:\n        if h == 0.0:\n            y = '18'\n            i = '2'\n            datas.setdefault(g.strip('\" '),[]).append([y, i])\n        else:\n            i = '2'\n            datas.setdefault(g.strip('\" '),[]).append([h, i])\ncon.commit()\ncursorObj.close()\ncon.close() \n\nwith open(\"./train_2.csv\", \"w\") as f:\n    writer = csv.writer(f, delimiter=',')\n    writer.writerow(('id', 'label', 'val_tr'))\n    for k,l in datas.items():\n        q = int(l[0][0])\n        r = l[0][1]\n        writer.writerow([k]+[q]+[r])","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Selecting images for training\n    Отбираем изображения для тренировки"},{"metadata":{"trusted":true},"cell_type":"code","source":"!mkdir ./otbor","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths = pd.read_csv('./train_2.csv')\nfiles = '../input/hpa-single-cell-image-classification/train/'\noutp = './otbor/'\nimagepaths = paths['id']\nimagepaths.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, path in tqdm(enumerate(imagepaths)):\n    img_a  = f'{files}{path}_red.png'\n    img_b  = f'{files}{path}_green.png'\n    img_c  = f'{files}{path}_blue.png'\n    img_d  = f'{files}{path}_yellow.png'\n    shutil.copy2(img_a, outp)\n    shutil.copy2(img_b, outp)\n    shutil.copy2(img_c, outp)\n    shutil.copy2(img_d, outp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for RGB images\n# для RGB images\nfor i, path in tqdm(enumerate(imagepaths)):\n    img_a  = f'{files}{path}.jpg'\n    shutil.copy2(img_a, outp)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"paths_m = pd.read_csv('../input/train-rgb-200/train_2.csv')\nfiles_m = '../input/train-rgb-200/xotb_200_m'\noutp_m = './otbor_m/'\nimagepaths = paths_m['id']\nimagepaths.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, path in tqdm(enumerate(imagepaths)):\n    img_m  = f'{files_m}{path}.npz'\n    shutil.copy2(img_m, outp_m)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%%bash\ncd ./\nzip -r ./otbor_m ./*","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(r'./otbor_m.zip')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    Create annotation files\n    Создаем файлы аннотаций"},{"metadata":{"trusted":true},"cell_type":"code","source":"cell_dir = '../input/otbor200/xotb_200_m/'\nim_dir = '../input/otbor200/xotb_200/'\ntr = pd.read_csv('./train_2.csv')\n#out_dir = './otbor_m'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.loc[tr['id']=='b6a469d8-bbad-11e8-b2ba-ac1f6b6435d0']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_set = tr.loc[tr['val_tr']== 1]\ntr_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr_set.label.value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_set = tr.loc[tr['val_tr']== 2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"val_set['label'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Class 0 has been moved to number 18 (important). remember to return it to number 0 after checking the model\n# Класс 0 был перемещен на  номер 18 (важно). не забыть вернуть его на номер 0 после проверки модели\nlabels = {\n0: \"back\",\n1: \"Nuclear membrane\",\n2: \"Nucleoli\",\n3: \"Nucleoli fibrillar center\",\n4: \"Nuclear speckles\",\n5: \"Nuclear bodies\",\n6: \"Endoplasmic reticulum\",\n7: \"Golgi apparatus\",\n8: \"Intermediate filaments\",\n9: \"Actin filaments\",\n10: \"Microtubules\",\n11: \"Mitotic spindle\",\n12: \"Centrosome\",\n13: \"Plasma membrane\",\n14: \"Mitochondria\",\n15: \"Aggresome\",\n16: \"Cytosol\",\n17: \"Vesicles and punctate cytosolic patterns\",\n18: \"Nucleoplasm\"\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"now = datetime.datetime.now()\n\ndata = dict(\n    images=[\n        # license, url, file_name, height, width, date_captured, id\n    ],\n    type='instances',\n    annotations=[\n        # segmentation, area, iscrowd, image_id, bbox, category_id, id\n    ],\n    categories=[\n        # supercategory, id, name\n    ],\n)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class_name_to_id = {}\nfor i, each_label in enumerate(labels):\n    class_name = each_label\n    class_id = i\n    class_name_to_id[class_name] = class_id\n    data['categories'].append(dict(\n        supercategory=None,\n        id=class_id,\n        name=str(class_name),\n    ))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Определены следующие функции API:\n# encode - Кодировать двоичные маски с помощью RLE.\n# decode - декодировать двоичные маски, закодированные с помощью RLE.\n# merge - вычислить объединение или пересечение закодированных масок.\n# iou - вычислить пересечение по объединению масок.\n# area - Расчетная область закодированных масок.\n# toBbox - получить ограничивающие рамки, окружающие закодированные маски.\n# frPyObjects - Преобразование многоугольника, bbox и несжатого RLE в закодированную маску RLE.\n\n#  Rs     = encode( masks )\n#  masks  = decode( Rs )\n#  R      = merge( Rs, intersect=false )\n#  o      = iou( dt, gt, iscrowd )\n#  a      = area( Rs )\n#  bbs    = toBbox( Rs )\n#  Rs     = frPyObjects( [pyObjects], h, w )\n\n# In the API the following formats are used:\n#  Rs      - [dict] Run-length encoding of binary masks\n#  R       - dict Run-length encoding of binary mask\n#  masks   - [hxwxn] Binary mask(s) (must have type np.ndarray(dtype=uint8) in column-major order)\n#  iscrowd - [nx1] list of np.ndarray. 1 indicates corresponding gt image has crowd region to ignore\n#  bbs     - [nx4] Bounding box(es) stored as [x y w h]\n#  poly    - Polygon stored as [[x1 y1 x2 y2...],[x1 y1 ...],...] (2D list)\n#  dt,gt   - May be either bounding boxes or encoded masks\n# Both poly and bbs are 0-indexed (bbox=[0 0 1 1] encloses first pixel).","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_out_file = './train_annotations.json'\nval_out_file = './val_annotations.json'\ndata_val = data.copy()\ndata_val['images'] = []\ndata_val['annotations'] = []\ndata_train = data.copy()\ndata_train['images'] = []\ndata_train['annotations'] = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print utility from public notebook\n# утилита печати из общедоступной записной книжки\ndef print_masked_img(image_id, mask):\n    img = load_RGBY_image(image_id, im_dir)\n    \n    plt.figure(figsize=(35, 35))\n    plt.subplot(1, 3, 1)\n    plt.imshow(img)\n    plt.title('Image')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 2)\n    plt.imshow(mask)\n    plt.title('Mask')\n    plt.axis('off')\n    \n    plt.subplot(1, 3, 3)\n    plt.imshow(img)\n    plt.imshow(mask, alpha=0.6)\n    plt.title('Image + Mask')\n    plt.axis('off')\n    plt.show()\n    \n# image loader, using rgb only here\n# загрузчик изображений, здесь используется только rgb\ndef load_RGBY_image(image_id, train_or_test = im_dir, image_size=None):\n    stacked_images = read_img(image_id, train_or_test, image_size)\n    #red = read_img(image_id, \"red\", train_or_test, image_size)\n    #green = read_img(image_id, \"green\", train_or_test, image_size)\n    #blue = read_img(image_id, \"blue\", train_or_test, image_size)\n    #yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n    #stacked_images = np.transpose(np.array([red, green, blue]), (1,2,0))\n    return stacked_images\n\n# \n# def read_img(image_id, color, train_or_test = im_dir, image_size=None):\ndef read_img(image_id, im_dir, image_size=None):\n    filename = f'{im_dir}/{image_id}.jpg'\n    #filename = f'{im_dir}/{image_id}_{color}.png'\n    assert os.path.exists(filename), f'not found {filename}'\n    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n    if image_size is not None:\n        img = cv2.resize(img, (image_size, image_size))\n    if img.max() > 255:\n        img_max = img.max()\n        img = (img/255).astype('uint8')\n    return img","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"image_id = '0051ccbc-bbbb-11e8-b2ba-ac1f6b6435d0'\ncell_mask = np.load('../input/otbor200/xotb_200_m/0051ccbc-bbbb-11e8-b2ba-ac1f6b6435d0.npz')['arr_0']\nprint_masked_img(image_id, cell_mask)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"MAX_GREEN = 64 # filter out dark green cells # отфильтровать темно-зеленые клетки\ndef get_rles_from_mask(image_id, class_id):\n    mask = np.load(f'{cell_dir}/{image_id}.npz')['arr_0']\n    rle_list = []\n    mask_ids = np.unique(mask)\n    for val in mask_ids:\n        #print(val)\n        if val == 0:\n            continue\n        binary_mask = np.where(mask == val, 1, 0).astype(np.uint8)\n        rle = coco_rle_encode(binary_mask)\n        rle_list.append(rle)\n    return rle_list, mask.shape[0], mask.shape[1]\n\ndef coco_rle_encode(mask):\n    rle = {'counts': [], 'size': list(mask.shape)}\n    counts = rle.get('counts')\n    for i, (value, elements) in enumerate(groupby(mask.ravel(order='F'))):\n        if i == 0 and value == 1:\n            counts.append(0)\n        counts.append(len(list(elements)))\n    return rle\n\n# make annotation helper called multi processes\n# делаем помощник по аннотации, называемый несколькими процессами\ndef mk_ann(idx):\n    image_id = tr_set.iloc[idx].id\n    class_id = tr_set.iloc[idx].label\n    anno = coco_json(image_id, class_id)\n    return anno, idx, image_id","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert segmentation mask image to run length encoding\n# преобразовать изображение маски сегментации в кодировку длины прогона\n# this part would take several DAYS, depends on your CPU power. below is an easier and faster way\n# эта часть займет несколько ДНЕЙ, в зависимости от мощности вашего процессора. ниже более простой и быстрый способ\ndef coco_json(image_id, class_id):\n    #for idx in range(len(tr_set)):\n#         image_id = tr_set.iloc[idx].ID\n#         class_id = tr_set.iloc[idx].Label\n    rles, height, width = get_rles_from_mask(image_id, class_id)\n    if len(rles) == 0:\n        ## Add Images to annotation\n        data_train['images'].append(dict(\n            file_name = image_id+'.jpg',\n            width = width,\n            height = height,\n            date_captured=None,\n            id=idx))\n        data_train['annotations'].append(dict())\n    else:\n        data_train['images'].append(dict(\n                file_name = image_id+'.jpg',\n                width = width,\n                height = height,\n                date_captured=None,\n                id=idx))\n        rles = mutils.frPyObjects(rles, height, width)\n        bboxes = mutils.toBbox(rles)\n    #     bboxes[:, 2] += bboxes[:, 0]\n    #     bboxes[:, 3] += bboxes[:, 1]\n        for bb, rl in zip(bboxes, rles):\n            w = bb[2]\n            h = bb[3]\n            bbox =[\n                    bb[0],\n                    bb[1],\n                    w,\n                    h]\n            area = (w)*(h)\n            data_train['annotations'].append(dict(id=len(data_train['annotations']),\n                                                  area=area, \n                                                  bbox=bbox,\n                                                  iscrowd= 0, #1,\n                                                  image_id=idx,\n                                                  category_id=int(class_id)))\n                                                  #segmentation = rl ))\n        return data_train\n\n\n#     with open(train_out_file, 'w') as f:\n#         json.dump(data_train, f, indent=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# this part would take several hours, depends on your CPU power.\nMAX_THRE = 4 # set your avarable CPU count.\np = Pool(processes=MAX_THRE)\nannos = []\nlen_df = len(tr_set)\nfor anno, idx, image_id in p.imap(mk_ann, range(len(tr_set))):\n    if len(anno['annotations']) > 0:\n        annos.append(anno)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(f'./custom_trn1.pkl', 'wb') as f:\n    pickle.dump(data_train, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(train_out_file, 'w') as f:\n    json.dump(data_train, f, indent=4)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"repeat the same with val_set"},{"metadata":{},"cell_type":"markdown","source":"    pickle set\n    faster way\n    более быстрый способ"},{"metadata":{},"cell_type":"markdown","source":"    replace val_set with tr_set to create train annotations\n    заменить val_set на tr_set чтобы создать аннотации для train"},{"metadata":{"trusted":true},"cell_type":"code","source":"cell_dir = '../input/otbor200/xotb_200_m'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# convert segmentation mask image to run length encoding\n# преобразовать изображение маски сегментации в кодировку длины прогона\nMAX_GREEN = 64 # filter out dark green cells # отфильтровать темно-зеленые клетки\ndef get_rles_from_mask(image_id, class_id):\n    mask = np.load(f'{cell_dir}/{image_id}.npz')['arr_0']\n    #if class_id != '18':\n        #green_img = read_img(image_id, 'green')\n    rle_list = []\n    mask_ids = np.unique(mask)\n    for val in mask_ids:\n        if val == 0:\n            continue\n        binary_mask = np.where(mask == val, 1, 0).astype(bool)\n        #if class_id != '18':\n            #masked_img = green_img * binary_mask\n            #print(val, green_img.max(),masked_img.max())\n            #f masked_img.max() < MAX_GREEN:\n                #continue\n        rle = coco_rle_encode(binary_mask)\n        rle_list.append(rle)\n    return rle_list, mask.shape[0], mask.shape[1]\n\ndef coco_rle_encode(mask):\n    rle = {'counts': [], 'size': list(mask.shape)}\n    counts = rle.get('counts')\n    for i, (value, elements) in enumerate(groupby(mask.ravel(order='F'))):\n        if i == 0 and value == 1:\n            counts.append(0)\n        counts.append(len(list(elements)))\n    return rle\n\n# mmdet custom dataset generator\n# mmdet генератор пользовательских наборов данных\ndef mk_mmdet_custom_data(image_id, class_id):\n    rles, height, width = get_rles_from_mask(image_id, class_id)\n    if len(rles) == 0:\n        return {\n            'file_name': image_id+'.jpg',\n            'width': width,\n            'height': height,\n            'ann': {}\n        }\n    rles = mutils.frPyObjects(rles, height, width)\n    bboxes = mutils.toBbox(rles) \n    bboxes[:, 2] += bboxes[:, 0] # voc format\n    bboxes[:, 3] += bboxes[:, 1] # voc format\n    return {\n        'file_name': image_id+'.jpg',\n        'width': width,\n        'height': height,\n        'ann':\n            {\n                'bboxes': np.array(bboxes, dtype=np.float32),\n                'labels': np.zeros(len(bboxes)), # dummy data.(will be replaced later) # фиктивные данные. (будут заменены позже)\n                'masks': rles\n            }\n    }","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# make annotation helper called multi processes\n# делаем помощник по аннотации, называемый несколькими процессами\ndef mk_ann(idx):\n    image_id = val_set.iloc[idx].id\n    class_id = val_set.iloc[idx].label\n    anno = mk_mmdet_custom_data(image_id, class_id)\n   # img = load_RGBY_image(image_id, im_dir)\n   # cv2.imwrite(f'{out_dir}/{image_id}.jpg', img)\n    return anno, idx, image_id","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"   Create annotations for training a model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# this part would take several hours, depends on your CPU power.\nMAX_THRE = 4 # set your avarable CPU count.\np = Pool(processes=MAX_THRE)\nannos = []\nlen_df = len(val_set)\nfor anno, idx, image_id in p.imap(mk_ann, range(len(val_set))):\n    if len(anno['ann']) > 0:\n        annos.append(anno)\n    print(f'{idx+1}/{len_df}, {image_id}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lbl_cnt_dict = val_set.set_index('id').to_dict()['label']\ntrn_annos = []\nval_annos = []\n#val_len = int(len(annos)*0.01)\nfor idx in range(len(annos)):\n    ann = annos[idx]\n    filename = ann['file_name'].replace('.jpg','').replace('.png','')\n    #label_ids = lbl_cnt_dict[filename]\n    label_id = lbl_cnt_dict[filename]\n    len_ann = len(ann['ann']['bboxes'])\n    bboxes = ann['ann']['bboxes']\n    masks = ann['ann']['masks']\n    # asign image level labels to each cells\n    # присвоить метки уровня изображения каждой ячейке\n    # print(label_ids)\n    # for cnt, label_id in tqdm(enumerate(label_ids.split('|'))):\n          #label_id = int(label_id)\n#     if cnt == 0:\n    ann['ann']['labels'] = np.full(len_ann, label_id)\n#     else:\n#     ann['ann']['bboxes'] = np.concatenate([ann['ann']['bboxes'],bboxes])\n#     ann['ann']['labels'] = np.concatenate([ann['ann']['labels'],np.full(len_ann, label_id)])\n#     ann['ann']['masks'] = ann['ann']['masks'] + masks    \n#     if idx < val_len:\n#         val_annos.append(ann)\n#     else:\n    trn_annos.append(ann)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"    val_set change to tr_set 4 cells above to create train annotations\n      val_set поменять на tr_set в 4 ячейках выше, чтобы создать аннотации для train"},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(f'./coco_val.pkl', 'wb') as f:\n    pickle.dump(trn_annos, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(f'./coco_train.pkl', 'wb') as f:\n    pickle.dump(trn_annos, f)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"sum = 0\nfor i in range(len(objects)):\n    d = int(objects[i]['ann']['labels'][0])\n    sum += 1\nprint(sum)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Read the annotations\nfile_path = \"../input/pickles1/mmdet_val.pkl\"\nwith open(file_path, 'rb') as f:\n    data = pickle.load(f)\nprint(data[0])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mask_list = data[0]['ann']['bboxes'][0]\n#mask_list = mask_list.decode(\"utf-8\")\n#mask_list.dumps()\n#mask_list.item(0)\nmask_list.tolist()\n#label = data[0]['ann']['labels'].tolist()\n#label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rls = data[0]['ann']['masks']\nrls = mutils.decode(rls)\nrls","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rls = data[0]['ann']['masks'][0]\nrlsa = mutils.decode(rls) #.astype(bool)\nrlsa\n#a = rls[0].tolist()\n#np.count_nonzero(a)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for idx in range(5):\n    image_id = data[0]['file_name'].replace('.jpg','').replace('.png','')\n    rls = data[0]['ann']['masks'][idx]\n    rlsa = mutils.decode(rls)\n    print_masked_img(image_id, rlsa)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"color = (255,0,0)\nimgs = []\n\nimage_id = data[0]['file_name'].replace('.jpg','').replace('.png','')\nprint(image_id)\nrls = data[0]['ann']['bboxes'][2].tolist()\n#x,y,w,h = rls\nx = rls[0]\ny = rls[1]\nh = rls[2]\nw = rls[3]\na = int(x)\nb = int(y)\nc = int(h)\nd = int(w)\nprint(f'{x},{y},{h},{w}')\nimg = read_img(image_id, im_dir)\nfr = cv2.rectangle(img,(x,y),(h,w),color,2)\nwindow_name = 'image'\nplt.figure(figsize=(25, 25))\nplt.subplot(1, 3, 1)\nplt.imshow(fr)\nplt.title('Image')\nplt.axis('off')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = pd.read_pickle('data/coco_trn1a.pkl')\nvalid_set = pd.read_pickle('data/coco__val_ful1a.pkl')\ntrain_out_file = 'data/train_annotations.json'\nval_out_file = 'data/val_annotations.json'\ndata_valid = data.copy()\ndata_valid['images'] = []\ndata_valid['annotations'] = []\ndata_train = data.copy()\ndata_train['images'] = []\ndata_train['annotations'] = []","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# преобразовать изображение маски сегментации в кодировку длины прогона\n# this part would take several hours, depends on your CPU power.\n# this part would take several hours, depends on your CPU power.\nfor idx, var in tqdm(enumerate(valid_set)):\n    # print(f'{idx} - {var}')\n#for idx in range(len(tr_set)):\n    image_id = valid_set[idx]['file_name']\n    class_id = valid_set[idx]['ann']['labels'][0]\n    width = valid_set[idx]['width']\n    height = valid_set[idx]['height']\n    data_valid['images'].append(dict(\n            file_name = image_id,\n            width = width,\n            height = height,\n            date_captured=None,\n            id=idx))\n    bboxes = valid_set[idx]['ann']['bboxes'].astype(float)\n    #rls = tr_set[idx]['ann']['masks']['counts']\n    #rlsa = mutils.decode(rls)\n    for i, bb in enumerate(bboxes):\n        # print(f'{bb} - {i}')\n    #for bb, rl in zip(bboxes, rles):\n        x = float(bb[0])\n        y = float(bb[1])\n        w = float(bb[2])-x\n        h = float(bb[3])-y\n        bbox =[x, y, w, h]\n        #bbox = np.array(bbox, dtype=np.float64)\n        #print(bb)\n        area = (w)*(h)\n        #print(f'{bb[0]} {bb[1]} {w} {h} {area}')\n        data_valid['annotations'].append(dict(id=len(data_valid['annotations']),\n                                              area=area, \n                                              bbox=bbox,\n                                              iscrowd= 0, #1,\n                                              image_id=idx,\n                                              category_id=int(class_id)))\n                                              #segmentation = rl ))\n        #return data_valid","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(val_out_file, 'w') as f:\n    json.dump(data_valid, f, indent=4)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# преобразовать изображение маски сегментации в кодировку длины прогона\n# this part would take several hours, depends on your CPU power.\n# this part would take several hours, depends on your CPU power.\nfor idx, var in tqdm(enumerate(train_set)):\n    # print(f'{idx} - {var}')\n#for idx in range(len(tr_set)):\n    image_id = train_set[idx]['file_name']\n    class_id = train_set[idx]['ann']['labels'][0]\n    width = train_set[idx]['width']\n    height = train_set[idx]['height']\n    data_train['images'].append(dict(\n            file_name = image_id,\n            width = width,\n            height = height,\n            date_captured=None,\n            id=idx))\n    bboxes = train_set[idx]['ann']['bboxes'].astype(float)\n    #rls = tr_set[idx]['ann']['masks']['counts']\n    #rlsa = mutils.decode(rls)\n    for i, bb in enumerate(bboxes):\n        # print(f'{bb} - {i}')\n    #for bb, rl in zip(bboxes, rles):\n        x = float(bb[0])\n        y = float(bb[1])\n        w = float(bb[2])-x\n        h = float(bb[3])-y\n        bbox =[x, y, w, h]\n        #bbox = np.array(bbox, dtype=np.float64)\n        #print(bb)\n        area = (w)*(h)\n        #print(f'{bb[0]} {bb[1]} {w} {h} {area}')\n        data_train['annotations'].append(dict(id=len(data_train['annotations']),\n                                              area=area, \n                                              bbox=bbox,\n                                              iscrowd= 0, #1,\n                                              image_id=idx,\n                                              category_id=int(class_id)))\n                                              #segmentation = rl ))\n        #return data_train","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open(train_out_file, 'w') as f:\n    json.dump(data_train, f, indent=4)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}