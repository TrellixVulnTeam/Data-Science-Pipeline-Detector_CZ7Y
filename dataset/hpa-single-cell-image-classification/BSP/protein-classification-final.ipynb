{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport tensorflow as tf\nimport time\nimport glob\nimport os\nimport PIL\nimport matplotlib.pyplot as plt\nimport tensorflow_hub as hub\nfrom kaggle_datasets import KaggleDatasets","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# detect and init the TPU\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver()\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# instantiate a distribution strategy\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path='../input/hpa-single-cell-image-classification'\ntrain_data=pd.read_csv(train_path+'/train.csv')\n\ntrain_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['path']=GCS_DS_PATH+'/train/'+train_data['ID']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data['Label'] = train_data['Label'].str.replace('|', ' ')\ntrain_image=glob.glob(train_path + '/train/*.png')\n\ndef format_column(train_data):\n    for i in range(0,19):\n        train_data[i]=0\n    return train_data \n\ntrain_data=format_column(train_data)\n\nval=[i.strip('').split() for y in  train_data.Label for i in [y] ]\nfor ind,num in enumerate(val):\n    for each in num:\n       \n        train_data[int(each)][ind]=1\n        ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label=train_data.iloc[:,3:]\ntrain_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path=train_data['ID'][train_data[0]==1].reset_index( drop=True)[1]\nred=PIL.Image.open((train_path +'/train/'+str(path)+'_red.png'))\ngreen=PIL.Image.open((train_path +'/train/'+str(path)+'_green.png'))\nblue=PIL.Image.open((train_path +'/train/'+str(path)+'_blue.png'))\nim = np.stack((\n                red,\n                green,\n                blue),-1)\nplt.imshow(im)\nplt.show()\nplt.clf() #will make the plot window empty\n\ntime.sleep(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path=train_data['ID'][train_data[18]==1].reset_index( drop=True)[1]\nred=PIL.Image.open((train_path +'/train/'+str(path)+'_red.png'))\ngreen=PIL.Image.open((train_path +'/train/'+str(path)+'_green.png'))\nblue=PIL.Image.open((train_path +'/train/'+str(path)+'_blue.png'))\nim = np.stack((\n                red,\n                green,\n                blue),-1)\nplt.imshow(im)\nplt.show()\nplt.clf() #will make the plot window empty\n\ntime.sleep(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path=train_data['ID'][(train_data[0]==1) & (train_data[15]==1)].reset_index( drop=True)[1]\nred=PIL.Image.open((train_path +'/train/'+str(path)+'_red.png'))\ngreen=PIL.Image.open((train_path +'/train/'+str(path)+'_green.png'))\nblue=PIL.Image.open((train_path +'/train/'+str(path)+'_blue.png'))\nim = np.stack((\n                red,\n                green,\n                blue),-1)\nplt.imshow(im)\nplt.show()\nplt.clf() #will make the plot window empty\n\ntime.sleep(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"path=train_data['ID'][(train_data[10]==1) & (train_data[3]==1)].reset_index( drop=True)[1]\nred=PIL.Image.open((train_path +'/train/'+str(path)+'_red.png'))\ngreen=PIL.Image.open((train_path +'/train/'+str(path)+'_green.png'))\nblue=PIL.Image.open((train_path +'/train/'+str(path)+'_blue.png'))\nim = np.stack((\n                red,\n                green,\n                blue),-1)\nplt.imshow(im)\nplt.show()\nplt.clf() #will make the plot window empty\n\ntime.sleep(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_inputs=train_data['path']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import train_test_split\ntrain_path,val_path, train_target, val_target = train_test_split(train_inputs.values,train_label.values, test_size=0.2, random_state=42)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_path","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f'Shape of train: {train_path.shape}')\nprint(f'Shape of val: {train_target.shape}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def load_data(train_path, target):\n    red = tf.squeeze(tf.image.decode_png(tf.io.read_file(train_path+'_red.png'), channels=1), [2])\n    blue = tf.squeeze(tf.image.decode_png(tf.io.read_file(train_path+'_blue.png'), channels=1), [2])\n    green = tf.squeeze(tf.image.decode_png(tf.io.read_file(train_path+'_green.png'), channels=1), [2])\n    img = tf.stack((\n                red,\n                green,\n                blue), axis=2)\n    return img, target\n\n\nAUTO = tf.data.experimental.AUTOTUNE\ntrain=tf.data.Dataset.from_tensor_slices((train_path, train_target)).map(load_data, num_parallel_calls=AUTO)\nval=tf.data.Dataset.from_tensor_slices((val_path, val_target)).map(load_data, num_parallel_calls=AUTO)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"IMG_SIZE = 512 # All images will be resized to 512*512\n#Resize the images to a fixed input size, and rescale the input channels to a range of [-1,1]\ndef aug_format_example(image, label=None):\n    \n\n    image = tf.cast(image, tf.float32)\n    image = (image/255) \n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    image = tf.image.random_contrast(image, lower=0.3, upper=1.2)\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.random_brightness(image, max_delta=0.5)\n\n   \n   \n    if label is None :\n        return image\n    else:\n        return image, label","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"BATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\ntrain=train.map(aug_format_example,num_parallel_calls=AUTO).batch(BATCH_SIZE).prefetch(buffer_size=AUTO)\nval=val.map(aug_format_example,num_parallel_calls=AUTO).batch(BATCH_SIZE).prefetch(buffer_size=AUTO)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Inspect a batch of data:\nfor image_batch, label_batch in train.take(1):\n    pass\n\nimage_batch.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Define the checkpoint directory to store the checkpoints\n\ncheckpoint_dir = './training_checkpoints'\n# Name of the checkpoint files\ncheckpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n\ndef build_lrfn(lr_start=0.00001, lr_max=0.00005, \n               lr_min=0.00001, lr_rampup_epochs=5, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n    lr_max = lr_max * tpu_strategy.num_replicas_in_sync\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nSTEPS_PER_EPOCH = train_label.shape[0] // BATCH_SIZE","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Callback for printing the LR at the end of each epoch.\nclass PrintLR(tf.keras.callbacks.Callback):\n  def on_epoch_end(self, epoch, logs=None):\n    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n                                                      model.optimizer.lr.numpy()))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"callbacks = [\n    \n    tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n                                       save_weights_only=True),\n    tf.keras.callbacks.LearningRateScheduler(lrfn,verbose=1),\n    PrintLR()\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.keras.applications import DenseNet121\nimport tensorflow.keras.layers as L\n\nwith tpu_strategy.scope():\n    model = tf.keras.Sequential([DenseNet121(input_shape=(512, 512, 3),\n                                             weights='imagenet',\n                                             include_top=False),\n                                 L.GlobalAveragePooling2D(),\n                                 L.Dense(train_target.shape[1],\n                                         activation='softmax')])\n        \n    model.compile(optimizer='adam',\n                  loss = 'categorical_crossentropy',\n                  metrics=['categorical_accuracy'])\n    model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"initial_epochs = 20\nvalidation_steps=20\n\nloss0,accuracy0 = model.evaluate(val, steps = validation_steps)\n\nprint(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\nhistory = model.fit(train,\n                    epochs=initial_epochs,\n                    callbacks=callbacks,\n                    \n                    validation_data=val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}