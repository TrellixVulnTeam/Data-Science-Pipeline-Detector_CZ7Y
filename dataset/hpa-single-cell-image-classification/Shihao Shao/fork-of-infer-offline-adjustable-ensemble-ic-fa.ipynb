{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm_csv = pd.read_csv('../input/hpapublic-csv/submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list_subm = subm_csv.ID.to_list()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/input/kerasapplications -q\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n!pip install -q \"/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n!pip install -q \"/kaggle/input/hpapytorchzoozip/pytorch_zoo-master\"\n!pip install -q \"/kaggle/input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n\n#!wget \"https://www.kaggleusercontent.com/kf/60257229/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..CiJyNbJXntOyTTiedEu0RA.9ehsk6hfDsNYbo2hw344h9FJN_gNQ_7JbmG5addEB5yMS2GEVsiYEbCYtTZrl_GWl2rm_BlEfgGn-uvzr1m1MsAgen97qAVX-FG6bCguUWThX4Sj1YbOtZYUO_bdvn63ce9n18_BC5CB2BfcmjCXIEamsaM-LF0PlOmlJ42WSrnyX7A3sUlBAV8AXgaeku0F17F3qEGClYYro9kQPAgT4Wg2zQVegDNtpE_52kj0mOVagAoWPw5N8sD2ueY4HrY4uTgNvQwHKQq60ce3Wu0XVODROcpZZSDIpfarofwUZQhSe4GmnoxHJA4kBN_kG1_0YdnsvOKCVmLoVC7BmChqPr-9llQhyT6pBVRIhCBXanH2dYHy-bLxZPXXmH-bYgVuxNTt3wKR-LcVScafukQfwg_tHBOAxb5U7a7ZuV7zfDY5HjwMrhjdd0JkerXrBCvOhsC5NQ4H9eIUB0csEZhQwEQmGk6u9w0NvDS-7gdz71b-qsI7Atk4TNTa9yEoJbgXZH6kRRHlb9kpjA3XCPcnV5j0Mwjli-qdqJj_uXwd66CLpy9wvnRaniqm8bOlf7wVfGCXZqdEjFp1WlYcWuoKKdsMZv-6-SVXA52_suOaMq1pf7HodgDobeohQBGZQuzLv_xRZnOUZPlwAE0OZa_vB9W7a48mwPWnS6Lh0llFaHk.3bLf-RBpLBwqm6-8VMCrwA/model_green.h5\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei\nimport glob\nimport tensorflow_addons as tfa","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ONLY_PUBLIC = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import base64\nfrom pycocotools import mask as mutils\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib\ndef encode_binary_mask(mask: np.ndarray) -> t.Text:\n  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n\n  # check input mask --\n  if mask.dtype != np.bool:\n    raise ValueError(\n        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n        mask.dtype)\n\n  mask = np.squeeze(mask)\n  if len(mask.shape) != 2:\n    raise ValueError(\n        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n        mask.shape)\n\n  # convert input mask to expected COCO API input --\n  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n  mask_to_encode = mask_to_encode.astype(np.uint8)\n  mask_to_encode = np.asfortranarray(mask_to_encode)\n\n  # RLE encode mask --\n  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n  # compress and base64 encoding --\n  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n  base64_str = base64.b64encode(binary_str)\n  return base64_str.decode()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decreasing_non_label(pred):\n  '''\n  expect shape(dls.c,)\n  '''\n  #pred = pred.numpy()\n  avg = torch.mean(pred)\n  \n  pred[pred<avg] -= 4\n  \n  return pred\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode_less_memory(img):\n    pixels = img.T.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\ndef enc2mask(encs, shape):\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for m,enc in enumerate(encs):\n        if isinstance(enc,np.float) and np.isnan(enc): continue\n        s = enc.split()\n        for i in range(len(s)//2):\n            start = int(s[2*i]) - 1\n            length = int(s[2*i+1])\n            img[start:start+length] = 1 + m\n    return img.reshape(shape).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def macro_f1(y, y_hat, thresh=0.5):\n    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n    \n    Args:\n        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        thresh: probability value above which we predict positive\n        \n    Returns:\n        macro_f1 (scalar Tensor): value of macro F1 for the batch\n    \"\"\"\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os.path\nimport urllib\nimport zipfile\n\nimport numpy as np\nimport scipy.ndimage as ndi\nfrom skimage import filters, measure, segmentation\nfrom skimage.morphology import (binary_erosion, closing, disk,\n                                remove_small_holes, remove_small_objects)\nimport torch\nHIGH_THRESHOLD = 0.4\nLOW_THRESHOLD = HIGH_THRESHOLD - 0.25\n\n\ndef download_with_url(url_string, file_path, unzip=False):\n    \"\"\"Download file with a link.\"\"\"\n    with urllib.request.urlopen(url_string) as response, open(\n        file_path, \"wb\"\n    ) as out_file:\n        data = response.read()  # a `bytes` object\n        out_file.write(data)\n\n    if unzip:\n        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n            zip_ref.extractall(os.path.dirname(file_path))\n\n\ndef __fill_holes(image):\n    \"\"\"Fill_holes for labelled image, with a unique number.\"\"\"\n    boundaries = segmentation.find_boundaries(image)\n    image = np.multiply(image, np.invert(boundaries))\n    image = ndi.binary_fill_holes(image > 0)\n    image = ndi.label(image)[0]\n    return image\n\n\n\n\n\ndef label_cell2(nuclei_pred, cell_pred):\n    \"\"\"Label the cells and the nuclei.\n    Keyword arguments:\n    nuclei_pred -- a 3D numpy array of a prediction from a nuclei image.\n    cell_pred -- a 3D numpy array of a prediction from a cell image.\n    Returns:\n    A tuple containing:\n    nuclei-label -- A nuclei mask data array.\n    cell-label  -- A cell mask data array.\n    0's in the data arrays indicate background while a continous\n    strech of a specific number indicates the area for a specific\n    cell.\n    The same value in cell mask and nuclei mask refers to the identical cell.\n    NOTE: The nuclei labeling from this function will be sligthly\n    different from the values in :func:`label_nuclei` as this version\n    will use information from the cell-predictions to make better\n    estimates.\n    \"\"\"\n    def __wsh(\n        mask_img,\n        threshold,\n        border_img,\n        seeds,\n        threshold_adjustment=0.35,\n        small_object_size_cutoff=10,\n    ):\n        img_copy = np.copy(mask_img)\n        m = seeds * border_img  # * dt\n        img_copy[m <= threshold + threshold_adjustment] = 0\n        img_copy[m > threshold + threshold_adjustment] = 1\n        img_copy = img_copy.astype(np.bool)\n        img_copy = remove_small_objects(img_copy, small_object_size_cutoff).astype(\n            np.uint8\n        )\n\n        mask_img[mask_img <= threshold] = 0\n        mask_img[mask_img > threshold] = 1\n        mask_img = mask_img.astype(np.bool)\n        mask_img = remove_small_holes(mask_img, 63)\n        mask_img = remove_small_objects(mask_img, 1).astype(np.uint8)\n        markers = ndi.label(img_copy, output=np.uint32)[0]\n        labeled_array = segmentation.watershed(\n            mask_img, markers, mask=mask_img, watershed_line=True\n        )\n        return labeled_array\n\n    nuclei_label = __wsh(\n        nuclei_pred[..., 2] / 255.0,\n        0.4,\n        1 - (nuclei_pred[..., 1] + cell_pred[..., 1]) / 255.0 > 0.05,\n        nuclei_pred[..., 2] / 255,\n        threshold_adjustment=-0.25,\n        small_object_size_cutoff=32,\n    )\n\n    # for hpa_image, to remove the small pseduo nuclei\n    nuclei_label = remove_small_objects(nuclei_label, 157)\n    nuclei_label = measure.label(nuclei_label)\n    # this is to remove the cell borders' signal from cell mask.\n    # could use np.logical_and with some revision, to replace this func.\n    # Tuned for segmentation hpa images\n    threshold_value = max(0.22, filters.threshold_otsu(cell_pred[..., 2] / 255) * 0.5)\n    # exclude the green area first\n    cell_region = np.multiply(\n        cell_pred[..., 2] / 255 > threshold_value,\n        np.invert(np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8)),\n    )\n    sk = np.asarray(cell_region, dtype=np.int8)\n    distance = np.clip(cell_pred[..., 2], 255 * threshold_value, cell_pred[..., 2])\n    cell_label = segmentation.watershed(-distance, nuclei_label, mask=sk)\n    cell_label = remove_small_objects(cell_label, 344).astype(np.uint8)\n    selem = disk(2)\n    cell_label = closing(cell_label, selem)\n    cell_label = __fill_holes(cell_label)\n    # this part is to use green channel, and extend cell label to green channel\n    # benefit is to exclude cells clear on border but without nucleus\n    sk = np.asarray(\n        np.add(\n            np.asarray(cell_label > 0, dtype=np.int8),\n            np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8),\n        )\n        > 0,\n        dtype=np.int8,\n    )\n    cell_label = segmentation.watershed(-distance, cell_label, mask=sk)\n    cell_label = __fill_holes(cell_label)\n    cell_label = np.asarray(cell_label > 0, dtype=np.uint8)\n    cell_label = measure.label(cell_label)\n    cell_label = remove_small_objects(cell_label, 344) # was 344\n    cell_label = measure.label(cell_label)\n    cell_label = np.asarray(cell_label, dtype=np.uint16)\n    #nuclei_label = np.multiply(cell_label > 0, nuclei_label) > 0\n    #nuclei_label = measure.label(nuclei_label)\n    #nuclei_label = remove_small_objects(nuclei_label, 157)\n    #nuclei_label = np.multiply(cell_label, nuclei_label > 0)\n\n    return cell_label#nuclei_label, cell_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir cell_tile\ncell_dir = 'cell_tile'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUC_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth\"\nCELL_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\nsegmentator = cellsegmentator.CellSegmentator(\n        NUC_MODEL,\n        CELL_MODEL,\n        scale_factor=0.25,\n        device=\"cuda\",\n        padding=True,\n        multi_channel_model=True,\n    )\ni_df = pd.read_csv(\"../input/hpa-single-cell-image-classification/sample_submission.csv\")\nif ONLY_PUBLIC==True:\n    i_df = pd.read_csv(\"../input/hpa-sample-submission-with-extra-metadata/updated_sample_submission.csv\")\nbs = 40\nbs_now=0\nimage_list=[]\nmt = []\ner = []\nnu = []\nID_list=[]\nfor i in tqdm(i_df.index):\n    ID = i_df.loc[i,'ID']\n    #if len(i_df)==559:\n    #    continue\n    if len(glob.glob('../input/hpscell-tile-in-image/cell_tile/'+ID+'.npz'))>0:\n        continue\n    W= int(i_df[i_df['ID']==ID]['ImageWidth'].values[0])\n    H= int(i_df[i_df['ID']==ID]['ImageHeight'].values[0])\n    ID_list.append(ID)\n    name = '../input/hpa-single-cell-image-classification/test' + '/' +ID+ '_red.png'\n    mt.append(name)\n    er.append(name.replace('red', 'yellow'))\n    nu.append(name.replace('red', 'blue'))\n    images = [mt, er, nu]\n    bs_now+=1\n    if bs_now>=bs:\n        \n        # For nuclei\n        nuc_segmentations = segmentator.pred_nuclei(images[2])\n\n        # For full cells\n        cell_segmentations = segmentator.pred_cells(images)\n\n        \n        \n        \n        cell_mask=[]\n        for j, pred in enumerate(cell_segmentations):\n            size = cell_segmentations[j].shape[0]\n            cell_mask_ = label_cell2(cv2.resize(nuc_segmentations[j],(512,512)), cv2.resize(cell_segmentations[j],(512,512)))\n            cell_mask_ = cv2.resize(cell_mask_,(size,size),interpolation=cv2.INTER_NEAREST)\n            cell_mask.append(cell_mask_)\n        for id_,mask in zip(ID_list,cell_mask):\n            np.savez_compressed(f'{cell_dir}/{id_}', mask)\n        \n        # clear\n        \n        image_list=[]\n        mt = []\n        er = []\n        nu = []\n        ID_list=[]\n        bs_now=0\nif bs_now>0:\n        nuc_segmentations = segmentator.pred_nuclei(images[2])\n\n        # For full cells\n        cell_segmentations = segmentator.pred_cells(images)\n\n        \n        \n        cell_mask=[]\n        for j, pred in enumerate(cell_segmentations):\n            size = cell_segmentations[j].shape[0]\n            cell_mask_ = label_cell2(cv2.resize(nuc_segmentations[j],(512,512)), cv2.resize(cell_segmentations[j],(512,512)))\n            cell_mask_ = cv2.resize(cell_mask_,(size,size),interpolation=cv2.INTER_NEAREST)\n            cell_mask.append(cell_mask_)\n        for id_,mask in zip(ID_list,cell_mask):\n            np.savez_compressed(f'{cell_dir}/{id_}', mask)\n        \n        # clear\n        \n        image_list=[]\n        mt = []\n        er = []\n        nu = []\n        ID_list=[]\n        bs_now=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel CELL_MODEL\ndel NUC_MODEL\ndel cellsegmentator\n#del NUC\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntry:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"Running on TPU:\", tpu.master())\nexcept ValueError:\n            strategy = tf.distribute.get_strategy()\n            print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n'''\n\n\n'''\nmodel = tf.keras.models.load_model(\n            '../input/hpa-classification-efnb7-train/model_green.h5',compile = False\n        )\n'''\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n        try:\n            # Currently, memory growth needs to be the same across GPUs\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n            print(len(gpus), \"... Physical GPUs,\", len(logical_gpus), \"Logical GPUs ...\\n\")\n        except RuntimeError as e:\n            # Memory growth must be set before GPUs have been initialized\n            print(e)\n\n\nmodel = tf.keras.models.load_model(\n            '../input/download-model/model_RGB_0.0502.h5'\n        )\n'''\nmodel_4 = tf.keras.models.load_model(\n            '../input/hpa-training-tpu-pseude-label-t/model_RGB_0.0635.h5'\n        )\nmodel_2 = tf.keras.models.load_model(\n            '../input/atlasmodel/model_RGB.h5'\n        )\n    \nmodel_3 = tf.keras.models.load_model('../input/hpa-training-tpu/model_RGB_0.2217.h5')\n#model_4 = tf.keras.models.load_model('../input/atlasmodel/model_RGB_0.1139.h5')\nmodel_g = tf.keras.models.load_model('../input/fork-of-hpa-training-tpu-2/model_RGB_0.2440.h5')\n'''\n'''\nmodel_whole = tf.keras.models.load_model(\n            '../input/hpa-classification-efnb7-train-tfrec/model_green.h5'\n        )\n'''\nmodel_whole_2 = tf.keras.models.load_model(\n            '../input/atlasmodel/model_green.h5'\n        )\n'''\nmodel_whole_3 = tf.keras.models.load_model(\n            '../input/download-model3/model_green.h5'\n        )\nmodel_whole_4 = tf.keras.models.load_model(\n            '../input/hpa-classification-efnb7-train-noisy/model_green.h5'\n        )\n'''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for TF model\nimport time\nNUC_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth\"\nCELL_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\n\ni_df = pd.read_csv(\"../input/hpa-single-cell-image-classification/sample_submission.csv\")\nif len(i_df)==559:\n with open('submission.csv', 'w') as outf:\n    print('ID,ImageWidth,ImageHeight,PredictionString', file=outf)\n print('ready to submit')\n \nelse:\n if ONLY_PUBLIC==True:\n    i_df = pd.read_csv(\"../input/hpa-sample-submission-with-extra-metadata/updated_sample_submission.csv\")\n with open('submission.csv', 'w') as outf:\n  print('ID,ImageWidth,ImageHeight,PredictionString', file=outf)\n  for ind in tqdm(i_df.index):\n    \n    ID = i_df.iloc[ind][\"ID\"]\n    W = i_df.iloc[ind][\"ImageWidth\"]\n    H = i_df.iloc[ind][\"ImageHeight\"]\n    \n    if ID in list_subm:\n        ps = subm_csv[subm_csv['ID']==ID]['PredictionString'].values[0]\n        #print(subm_csv[subm_csv['ID']==ID]['PredictionString'], file=outf)\n        print(f'{ID},{W},{H},{ps}', file=outf)\n        continue\n    \n    green = plt.imread('../input/hpa-single-cell-image-classification/test/'+ID+'_green.png')\n    red = plt.imread('../input/hpa-single-cell-image-classification/test/'+ID+'_red.png')\n    blue = plt.imread('../input/hpa-single-cell-image-classification/test/'+ID+'_blue.png')\n    green = green[:,:,np.newaxis]\n    \n    blue = blue[:,:,np.newaxis]\n    red = red[:,:,np.newaxis]\n    all_ = np.concatenate((red,green,blue),axis=-1)\n    del red,blue\n    \n    \n    w = i_df.iloc[ind][\"ImageWidth\"]\n    h = i_df.iloc[ind][\"ImageHeight\"]\n    '''\n    mt = glob.glob('../input/hpa-single-cell-image-classification/test' + '/' +ID+ '_red.png')\n    er = [f.replace('red', 'yellow') for f in mt]\n    nu = [f.replace('red', 'blue') for f in mt]\n    images = [mt, er, nu]\n    '''\n    #ensemble the image-wise\n    all_whole = np.concatenate((green,green,green),axis=-1)\n    all_whole_720 = cv2.resize(all_whole,(720,720),\n                              interpolation = cv2.INTER_AREA)\n    all_whole_720 = np.expand_dims(all_whole_720,axis=0)\n    all_whole_512 = cv2.resize(all_whole,(512,512),\n                              interpolation = cv2.INTER_AREA)\n    all_whole_512 = np.expand_dims(all_whole_512,axis=0)\n    all_whole = cv2.resize(all_whole,(600,600),\n                              interpolation = cv2.INTER_AREA)\n    \n    all_whole = np.expand_dims(all_whole,axis=0)\n    #pred_whole = model_whole.predict(all_whole)\n    pred_whole2 = model_whole_2.predict(all_whole)\n    #pred_whole3 = model_whole_3.predict(all_whole_720)\n    #pred_whole4 = model_whole_4.predict(all_whole)\n    pred_whole = (pred_whole2)/1.\n    \n    del all_whole,all_whole_720,all_whole_512\n    \n    # For nuclei\n    #nuc_segmentations = segmentator.pred_nuclei(images[2])\n\n    # For full cells\n    #cell_segmentations = segmentator.pred_cells(images)\n\n    # post-processing\n    \n    \n    #nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n    #FOVname = os.path.basename(mt[i]).replace('red','predictedmask')\n    #imageio.imwrite(os.path.join(save_dir,FOVname), cell_mask) \n    file_ =glob.glob('../input/hpscell-tile-in-image/cell_tile/'+ID+'.npz')\n    if len(file_)>0:\n        cell_mask = np.load(file_[0])['arr_0']\n    else:\n        cell_mask = np.load(f'{cell_dir}/{ID}.npz')['arr_0']\n    pred_strs = []\n    \n    for i in range(1,cell_mask.max()+1):\n          x,y=(cell_mask==i).nonzero()\n          cell_mask_s = cell_mask==i\n          cell_mask_s_ = cell_mask_s[:,:,np.newaxis]\n          i_c = cell_mask_s_ * all_\n          \n            \n            \n            \n          i_c_720 = cv2.resize(i_c,(720,720),\n                              interpolation = cv2.INTER_AREA)\n          i_c_720 = np.stack([i_c_720[:,:,1],i_c_720[:,:,1],i_c_720[:,:,1]],axis=2)\n          i_c_720 = np.expand_dims(i_c_720,axis=0)  \n          \n          i_c = cv2.resize(i_c,(600,600),\n                              interpolation = cv2.INTER_AREA)\n          i_c = np.stack([i_c[:,:,1],i_c[:,:,1],i_c[:,:,1]],axis=2)\n          i_c = np.expand_dims(i_c,axis=0)\n          \n            \n            \n        \n          pred_ic = model_whole_2.predict(i_c)\n          #pred_ic2 = model_whole.predict(i_c)\n          #pred_ic3 = model_whole_3.predict(i_c_720)\n          #print(pred_ic)\n        \n          del i_c,i_c_720\n          \n          lenx=x.max()-x.min()+1\n          leny=y.max()-y.min()+1\n          xx=x.min()\n          yy=y.min()\n\n          interest=cell_mask[xx:xx+lenx,yy:yy+leny]\n          all_g=all_[xx:xx+lenx,yy:yy+leny]\n          if lenx>leny:\n              pad=lenx-leny\n              interest=np.pad(interest,((0,0),(pad//2,pad-pad//2)), 'constant', constant_values=(0))\n              all_g=np.pad(all_g,((0,0),(pad//2,pad-pad//2),(0,0)), 'constant', constant_values=(0))\n          elif leny>lenx:\n              pad=leny-lenx\n              interest=np.pad(interest,((pad//2,pad-pad//2),(0,0)), 'constant', constant_values=(0))\n              all_g=np.pad(all_g,((pad//2,pad-pad//2),(0,0),(0,0)), 'constant', constant_values=(0))\n          interest = interest[:,:,np.newaxis]\n          interest=(interest==i)\n\n          all_g=interest*all_g\n\n          \n          del interest\n          \n\n          \n\n\n\n\n          all_g = cv2.resize(all_g,(256,256),\n                              interpolation = cv2.INTER_AREA)\n          #all_g = np.transpose(all_g,(2,0,1))\n          all_green = np.stack([all_g[:,:,1],all_g[:,:,1],all_g[:,:,1]],axis=2)\n          all_g = np.expand_dims(all_g,axis=0)\n          all_green = np.expand_dims(all_green,axis=0)\n          #all_g=(torch.from_numpy(all_g)).to(device)\n          #model.eval()\n          pred_c  = 0\n\n          \n          pred = model.predict(all_g)\n          #pred2 = model_2.predict(all_g)\n          #pred3 = model_3.predict(all_g)\n          #pred4 = model_4.predict(all_g)\n          #pred4 = model_4.predict(all_g)\n          #predg = model_g.predict(all_green)\n          pred = (pred+pred_ic)/2.\n          # Only get the argmax one\n          pred = pred*0.6 + pred_whole*0.4\n          pred_c = pred[0]\n            \n          del all_g,all_green\n          \n          #pred_c = decreasing_non_label(pred_c)\n            \n          rle = encode_binary_mask(cell_mask_s)\n          \n            \n          #set non-green to class 18\n          '''\n          green_channel = all_g[:,:,1]\n          green_channel[green_channel<0.1]=0.\n          if np.sum(green_channel)<0.5:\n                pred_c = [0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,1.0]\n          '''\n          \n          \n          for class_id in range(19):\n            #cnf = torch.sigmoid(pred_c[class_id])\n            cnf = pred_c[class_id]\n            pred_strs.append(f'{class_id} {cnf} {rle}')\n            \n    print(f'{ID},{w},{h},{\" \".join(pred_strs)}', file=outf)\n    gc.collect()\n    \n'''\nlocal_file = 'submission.csv'\n\ndf_submit = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv', index_col='ID')\ndf_local  = pd.read_csv(local_file, index_col='ID')\ndf_local=df_local[['ImageWidth','ImageHeight','PredictionString']]\ndf_submit.loc[df_local.index.values] = df_local.values  \n\n\ndf_submit.to_csv('submission.csv')\n'''\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}