{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q \"../input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys\nsys.path.append(\"../input/hpapytorchzoozip/pytorch_zoo-master\")\nsys.path.append('../input/timmlast')\nsys.path.append('../input/ttach-kaggle/ttach')\nimport ttach\nimport timm\nimport pytorch_zoo","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sys.path.append(\"../input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\")\nimport hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport os\nimport tqdm\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc\nimport base64\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib\n\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torch.nn as nn\n\nfrom collections import OrderedDict\nimport ttach as tta","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Cell Classification","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT = '../input/hpa-single-cell-image-classification/'\ntrain_or_test = 'test'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_cropped_cell(img, msk):\n    bmask = msk.astype(int)[...,None]\n    masked_img = img * bmask\n    true_points = np.argwhere(bmask)\n    top_left = true_points.min(axis=0)\n    bottom_right = true_points.max(axis=0)\n    cropped_arr = masked_img[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1]\n    return cropped_arr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stats(cropped_cell):\n    x = (cropped_cell/255.0).reshape(-1,3).mean(0)\n    x2 = ((cropped_cell/255.0)**2).reshape(-1,3).mean(0)\n    return x, x2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_img(image_id, color, train_or_test='test', image_size=None):\n    filename = f'{ROOT}/{train_or_test}/{image_id}_{color}.png'\n    assert os.path.exists(filename), f'not found {filename}'\n    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n    if image_size is not None:\n        img = cv2.resize(img, (image_size, image_size))\n    if img.max() > 255:\n        img_max = img.max()\n        img = (img/255).astype('uint8')\n    return img","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def encode_binary_mask(mask: np.ndarray) -> t.Text:\n  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n\n  # check input mask --\n  if mask.dtype != np.bool:\n    raise ValueError(\n        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n        mask.dtype)\n\n  mask = np.squeeze(mask)\n  if len(mask.shape) != 2:\n    raise ValueError(\n        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n        mask.shape)\n\n  # convert input mask to expected COCO API input --\n  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n  mask_to_encode = mask_to_encode.astype(np.uint8)\n  mask_to_encode = np.asfortranarray(mask_to_encode)\n\n  # RLE encode mask --\n  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n  # compress and base64 encoding --\n  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n  base64_str = base64.b64encode(binary_str)\n  return base64_str.decode('ascii')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import warnings\nfrom torch.serialization import SourceChangeWarning\nwarnings.filterwarnings(\"ignore\", category=SourceChangeWarning)\nNUC_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth\"\nCELL_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    scale_factor=0.25,\n    device=\"cuda\",\n    padding=True,\n    multi_channel_model=True,\n);\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def read_sample_image_seg(filename):\n    \n    '''\n    read individual images\n    of different filters (R, B, Y)\n    and stack them for segmentation.\n    ---------------------------------\n    Arguments:\n    filename -- sample image file path\n    \n    Returns:\n    stacked_images -- stacked (RBY) image path in lists.\n    '''\n    \n    red = os.path.join(ROOT, 'test/') + filename + \"_red.png\"\n    blue = os.path.join(ROOT, 'test/') + filename + \"_blue.png\"\n    yellow = os.path.join(ROOT, 'test/') + filename + \"_yellow.png\"\n\n    stacked_images = [[red], [yellow], [blue]]\n    return stacked_images, red, blue, yellow\n\n# segment cell \ndef segmentCell(image, segmentator):\n    \n    '''\n    segment cell and nuclei from\n    microtubules, endoplasmic reticulum,\n    and nuclei (R, B, Y) filters.\n    ------------------------------------\n    Argument:\n    image -- (R, B, Y) list of image arrays\n    segmentator -- CellSegmentator class object\n    \n    Returns:\n    cell_mask -- segmented cell mask\n    '''\n    \n    nuc_segmentations = segmentator.pred_nuclei(image[2])\n    cell_segmentations = segmentator.pred_cells(image)\n    nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n    \n    gc.collect(); del nuc_segmentations; del cell_segmentations; del nuclei_mask\n    \n    return cell_mask","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir cells","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_tot,x2_tot = [],[]\nlbls = []\nnum_files = len(df)\nall_cells = []\n\n\nfor idx in tqdm.tqdm(range(num_files)):\n    image_id = df.iloc[idx].ID\n    ryb, r, b, y = read_sample_image_seg(image_id)\n    cell_mask = segmentCell(ryb, segmentator)\n\n    red = read_img(image_id, \"red\", train_or_test, None)\n    green = read_img(image_id, \"green\", train_or_test, None)\n    blue = read_img(image_id, \"blue\", train_or_test, None)\n    #yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n    stacked_image = np.transpose(np.array([blue, green, red]), (1,2,0))\n\n    for j in range(1, np.max(cell_mask) + 1):\n        bmask = (cell_mask == j)\n        enc = encode_binary_mask(bmask)\n        cropped_cell = get_cropped_cell(stacked_image, bmask)\n        fname = f'{image_id}_{j}.jpg'\n        cv2.imwrite(\"cells/\"+fname,cropped_cell)\n        x, x2 = get_stats(cropped_cell)\n        x_tot.append(x)\n        x2_tot.append(x2)\n        all_cells.append({\n            'image_id': image_id,\n            'fname': fname,\n            'r_mean': x[0],\n            'g_mean': x[1],\n            'b_mean': x[2],\n            'cell_id': j,\n            'size1': cropped_cell.shape[0],\n            'size2': cropped_cell.shape[1],\n            'enc': enc,\n        })\n\n#image stats\nimg_avr =  np.array(x_tot).mean(0)\nimg_std =  np.sqrt(np.array(x2_tot).mean(0) - img_avr**2)\ncell_df = pd.DataFrame(all_cells)\ncell_df.to_csv('cell_df.csv', index=False)\nprint('mean:',img_avr, ', std:', img_std)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('./cell_df.csv')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"valid_transforms = A.Compose([\n                        A.Resize(width=224, height=224),\n                        A.Normalize(),\n                        ToTensorV2(),\n                        ])\n\nclass CellDataset(Dataset):\n    def __init__(self, data_dir, csv_file, transform=None):\n        super().__init__()\n\n        self.data_dir = data_dir\n        self.df = csv_file\n        self.transforms = transform           \n        #self.cell_types = self.df[['0','1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18']].values\n        self.img_ids = self.df['image_id'].values\n        self.cell_ids = self.df['cell_id'].values\n\n    def __len__(self):\n        return len(self.img_ids)\n        #return 100\n\n    def get_image(self, index):\n        # image_id = self.img_ids[index % self.__len__()]\n        # cell_id = self.cell_ids[index % self.__len__()]\n        image_id = self.img_ids[index]\n        cell_id = self.cell_ids[index]\n        \n        img_path = os.path.join(self.data_dir, 'cells', image_id + '_' + str(cell_id) + '.jpg')\n        \n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        img = self.transforms(image=img)\n        img = img['image']\n        \n        return img\n\n    def __getitem__(self, index):\n\n        x = self.get_image(index)\n        #y = self.cell_types[index]\n        #y = torch.from_numpy(y).float()\n        return x","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = CellDataset(data_dir='', csv_file=df, transform=valid_transforms)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loader = DataLoader(test_dataset,\n                         batch_size=8,\n                         shuffle=False,\n                         num_workers=4,\n                         drop_last=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self, name = 'efficientnet_b0', num_classes=19):\n        super(Net, self).__init__()\n        self.model = timm.create_model(name, pretrained=False, num_classes=num_classes)\n\n    def forward(self, x):\n        out = self.model(x)\n\n        return out\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from collections import OrderedDict\ndef update_state_dict(state_dict):\n    \n    new_state_dict = OrderedDict()\n    for key in state_dict.keys():\n        new_state_dict['.'.join(key.split('.')[1:])] = state_dict[key]\n    \n    return new_state_dict","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_b1_f0 = Net(name = 'efficientnet_b1')\nmodel_b1_f0.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b1-224-fold-0/epoch1-valid_loss_epoch0.118.pth')))\nmodel_b1_f0.cuda();\nmodel_b1_f0.eval();\n\nmodel_b1_f1 = Net(name = 'efficientnet_b1')\nmodel_b1_f1.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b1-224-fold-1/epoch1-valid_loss_epoch0.117.pth')))\nmodel_b1_f1.cuda();\nmodel_b1_f1.eval();\n\nmodel_b1_f2 = Net(name = 'efficientnet_b1')\nmodel_b1_f2.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b1-224-fold-4/epoch1-valid_loss_epoch0.119.pth')))\nmodel_b1_f2.cuda();\nmodel_b1_f2.eval();\n\nmodel_b1_f3 = Net(name = 'efficientnet_b1')\nmodel_b1_f3.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b1-224-fold-3/epoch1-valid_loss_epoch0.116.pth')))\nmodel_b1_f3.cuda();\nmodel_b1_f3.eval();\n\nmodel_b1_f4 = Net(name = 'efficientnet_b1')\nmodel_b1_f4.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b1-224-fold-44/epoch1-valid_loss_epoch0.117.pth')))\nmodel_b1_f4.cuda();\nmodel_b1_f4.eval();\n\n\n\nmodel_b0_f0 = Net(name = 'efficientnet_b0')\nmodel_b0_f0.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b0-224-fold-0/epoch1-valid_loss_epoch0.119.pth')))\nmodel_b0_f0.cuda();\nmodel_b0_f0.eval();\n\n\nmodel_b0_f1 = Net(name = 'efficientnet_b0')\nmodel_b0_f1.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b0-224-fold-1/epoch1-valid_loss_epoch0.118.pth')))\nmodel_b0_f1.cuda();\nmodel_b0_f1.eval();\n\nmodel_b0_f2 = Net(name = 'efficientnet_b0')\nmodel_b0_f2.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b0-224-fold-2/epoch1-valid_loss_epoch0.120.pth')))\nmodel_b0_f2.cuda();\nmodel_b0_f2.eval();\n\nmodel_b0_f3 = Net(name = 'efficientnet_b0')\nmodel_b0_f3.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b0-224-fold-3/epoch1-valid_loss_epoch0.117.pth')))\nmodel_b0_f3.cuda();\nmodel_b0_f3.eval();\n\nmodel_b0_f4 = Net(name = 'efficientnet_b0')\nmodel_b0_f4.load_state_dict(update_state_dict(torch.load('../input/efficientnet-b0-224-fold-4/epoch8-valid_loss_epoch0.117.pth')))\nmodel_b0_f4.cuda();\nmodel_b0_f4.eval();","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred = torch.FloatTensor()\npred = pred.cuda()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tta1 = tta.ClassificationTTAWrapper(model_b1_f0, tta.aliases.flip_transform())\ntta2 = tta.ClassificationTTAWrapper(model_b1_f1, tta.aliases.flip_transform())\ntta3 = tta.ClassificationTTAWrapper(model_b1_f2, tta.aliases.flip_transform())\ntta4 = tta.ClassificationTTAWrapper(model_b1_f3, tta.aliases.flip_transform())\ntta5 = tta.ClassificationTTAWrapper(model_b1_f4, tta.aliases.flip_transform())\ntta6 = tta.ClassificationTTAWrapper(model_b0_f0, tta.aliases.flip_transform())\ntta7 = tta.ClassificationTTAWrapper(model_b0_f1, tta.aliases.flip_transform())\ntta8 = tta.ClassificationTTAWrapper(model_b0_f2, tta.aliases.flip_transform())\ntta9 = tta.ClassificationTTAWrapper(model_b0_f3, tta.aliases.flip_transform())\ntta10 = tta.ClassificationTTAWrapper(model_b0_f4, tta.aliases.flip_transform())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with torch.no_grad():\n    for inp in tqdm.tqdm(test_loader):\n        bs, c, h, w = inp.size()\n        input_var = torch.autograd.Variable(inp.view(-1, c, h, w).cuda())\n        \n        # output = model(input_var)\n        output = (tta1(input_var)+tta2(input_var)+\\\n                    tta3(input_var)+tta4(input_var)+\\\n                    tta5(input_var)+tta6(input_var)+\\\n                    tta7(input_var)+tta8(input_var)+tta9(input_var)+tta10(input_var))/10\n        output_mean = output.view(bs, -1)\n        pred = torch.cat((pred, output_mean.data), 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_torch = torch.sigmoid(pred.cpu())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def isNaN(num):\n    return num != num","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cell_df = pd.read_csv('./cell_df.csv')\ncell_df['cls'] = ''","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold = 0.0\n\nfor i in range(pred_torch.shape[0]): \n    p = torch.nonzero(pred_torch[i] > threshold).squeeze().numpy().tolist()\n    if type(p) != list: p = [p]\n    if len(p) == 0: cls = [(pred_torch[i].argmax().item(), pred_torch[i].max().item())]\n    else: cls = [(x, pred_torch[i][x].item()) for x in p]\n    cell_df['cls'].loc[i] = cls","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def combine(r):\n    cls = r[0]\n    enc = r[1]\n    classes = [str(c[0]) + ' ' + str(c[1]) + ' ' + enc for c in cls]\n    return ' '.join(classes)\n\ncombine(cell_df[['cls', 'enc']].loc[24]);","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cell_df['pred'] = cell_df[['cls', 'enc']].apply(combine, axis=1)\ncell_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"subm = cell_df.groupby(['image_id'])['pred'].apply(lambda x: ' '.join(x)).reset_index()\n# subm = subm.loc[3:]\nsubm.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\nsample_submission.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = pd.merge(\n    sample_submission,\n    subm,\n    how=\"left\",\n    left_on='ID',\n    right_on='image_id',\n)\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def isNaN(num):\n    return num != num\n\nfor i, row in sub.iterrows():\n    if isNaN(row['pred']): continue\n    sub.PredictionString.loc[i] = row['pred']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = sub[sample_submission.columns]\nsub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sub.to_csv('submission.csv', index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm -r cells","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!rm cell_df.csv","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Image Classificaion","metadata":{}},{"cell_type":"code","source":"ss_df = sub","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/input/kerasapplications -q\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nprint(\"\\n... INSTALLING AND IMPORTING CELL-PROFILER TOOL (HPACELLSEG) ...\\n\")\ntry:\n    import hpacellseg.cellsegmentator as cellsegmentator\n    from hpacellseg.utils import label_cell\nexcept:\n    !pip install -q \"/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n    !pip install -q \"/kaggle/input/hpapytorchzoozip/pytorch_zoo-master\"\n    !pip install -q \"/kaggle/input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n    import hpacellseg.cellsegmentator as cellsegmentator\n    from hpacellseg.utils import label_cell\n\nprint(\"\\n... OTHER IMPORTS STARTING ...\\n\")\nprint(\"\\n\\tVERSION INFORMATION\")\n\n# Machine Learning and Data Science Imports\nimport tensorflow as tf; print(f\"\\t\\t– TENSORFLOW VERSION: {tf.__version__}\");\nimport pandas as pd; pd.options.mode.chained_assignment = None;\nimport numpy as np; print(f\"\\t\\t– NUMPY VERSION: {np.__version__}\");\nimport torch\n\nimport pandas as pd\nimport os\n\nimport efficientnet.tfkeras as efn\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\n\n# Built In Imports\nfrom collections import Counter\nfrom datetime import datetime\nimport multiprocessing\nfrom glob import glob\nimport warnings\nimport requests\nimport imageio\nimport IPython\nimport urllib\nimport zipfile\nimport pickle\nimport random\nimport shutil\nimport string\nimport math\nimport tqdm\nimport time\nimport gzip\nimport sys\nimport ast\nimport csv; csv.field_size_limit(sys.maxsize)\nimport io\nimport os\nimport gc\nimport re\n\n# Visualization Imports\nfrom matplotlib.colors import ListedColormap\nimport matplotlib.patches as patches\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport plotly.express as px\nimport seaborn as sns\nfrom PIL import Image\nimport matplotlib; print(f\"\\t\\t– MATPLOTLIB VERSION: {matplotlib.__version__}\");\nimport plotly\nimport PIL\nimport cv2\n\n# Submission Imports\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport base64\nimport zlib\n\n# PRESETS\nLBL_NAMES = [\"Nucleoplasm\", \"Nuclear Membrane\", \"Nucleoli\", \"Nucleoli Fibrillar Center\", \"Nuclear Speckles\", \"Nuclear Bodies\", \"Endoplasmic Reticulum\", \"Golgi Apparatus\", \"Intermediate Filaments\", \"Actin Filaments\", \"Microtubules\", \"Mitotic Spindle\", \"Centrosome\", \"Plasma Membrane\", \"Mitochondria\", \"Aggresome\", \"Cytosol\", \"Vesicles\", \"Negative\"]\nINT_2_STR = {x:LBL_NAMES[x] for x in np.arange(19)}\nINT_2_STR_LOWER = {k:v.lower().replace(\" \", \"_\") for k,v in INT_2_STR.items()}\nSTR_2_INT_LOWER = {v:k for k,v in INT_2_STR_LOWER.items()}\nSTR_2_INT = {v:k for k,v in INT_2_STR.items()}\nFIG_FONT = dict(family=\"Helvetica, Arial\", size=14, color=\"#7f7f7f\")\nLABEL_COLORS = [px.colors.label_rgb(px.colors.convert_to_RGB_255(x)) for x in sns.color_palette(\"Spectral\", len(LBL_NAMES))]\nLABEL_COL_MAP = {str(i):x for i,x in enumerate(LABEL_COLORS)}\n\nprint(\"\\n\\n... IMPORTS COMPLETE ...\\n\")\n\n##### THIS IS FOR PROTOTYPING AND PUBLIC LB PROBING #####\nONLY_PUBLIC = True\n##### THIS IS FOR PROTOTYPING AND PUBLIC LB PROBING#####\n\nif ONLY_PUBLIC:\n    print(\"\\n... ONLY INFERRING ON PUBLIC TEST DATA (USING PRE-PROCESSED DF) ...\\n\")\nelse:\n    # Stop Tensorflow From Eating All The Memory\n    gpus = tf.config.experimental.list_physical_devices('GPU')\n    if gpus:\n        try:\n            # Currently, memory growth needs to be the same across GPUs\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n            print(len(gpus), \"... Physical GPUs,\", len(logical_gpus), \"Logical GPUs ...\\n\")\n        except RuntimeError as e:\n            # Memory growth must be set before GPUs have been initialized\n            print(e)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n\nif sub_df.shape[0] != 559:\n    def auto_select_accelerator():\n        try:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"Running on TPU:\", tpu.master())\n        except ValueError:\n            strategy = tf.distribute.get_strategy()\n        print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n        return strategy\n\n\n    def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n        def decode(path):\n            file_bytes = tf.io.read_file(path)\n            if ext == 'png':\n                img = tf.image.decode_png(file_bytes, channels=3)\n            elif ext in ['jpg', 'jpeg']:\n                img = tf.image.decode_jpeg(file_bytes, channels=3)\n            else:\n                raise ValueError(\"Image extension not supported\")\n\n            img = tf.cast(img, tf.float32) / 255.0\n            img = tf.image.resize(img, target_size)\n\n            return img\n\n        def decode_with_labels(path, label):\n            return decode(path), label\n\n        return decode_with_labels if with_labels else decode\n\n\n    def build_augmenter(with_labels=True):\n        def augment(img):\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            return img\n\n        def augment_with_labels(img, label):\n            return augment(img), label\n\n        return augment_with_labels if with_labels else augment\n\n\n    def build_dataset(paths, labels=None, bsize=32, cache=True,\n                      decode_fn=None, augment_fn=None,\n                      augment=True, repeat=True, shuffle=1024, \n                      cache_dir=\"\"):\n        if cache_dir != \"\" and cache is True:\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if decode_fn is None:\n            decode_fn = build_decoder(labels is not None)\n\n        if augment_fn is None:\n            augment_fn = build_augmenter(labels is not None)\n\n        AUTO = tf.data.experimental.AUTOTUNE\n        slices = paths if labels is None else (paths, labels)\n\n        dset = tf.data.Dataset.from_tensor_slices(slices)\n        dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n        dset = dset.cache(cache_dir) if cache else dset\n        dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n        dset = dset.repeat() if repeat else dset\n        dset = dset.shuffle(shuffle) if shuffle else dset\n        dset = dset.batch(bsize).prefetch(AUTO)\n\n        return dset\n\n    COMPETITION_NAME = \"hpa-single-cell-image-classification\"\n    strategy = auto_select_accelerator()\n    BATCH_SIZE = strategy.num_replicas_in_sync * 16\n\n    IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)\n\n    load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n    sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n    #sub_df = ss_df.copy()\n\n    sub_df = sub_df.drop(sub_df.columns[1:],axis=1)\n\n    for i in range(19):\n        sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\n\n\n    test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_green.png'\n    # Get the multi-labels\n    label_cols = sub_df.columns[1:]\n\n    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]))\n    dtest = build_dataset(\n        test_paths, bsize=BATCH_SIZE, repeat=False, \n        shuffle=False, augment=False, cache=False,\n        decode_fn=test_decoder\n    )\n\n    with strategy.scope():\n        model = tf.keras.models.load_model(\n            '../input/hpa-classification-efnb7-train/model_green.h5'\n        )\n\n    model.summary()\n    sub_df[label_cols] = model.predict(dtest, verbose=1)\n\n    sub_df.head()\n\n    ss_df = pd.merge(ss_df, sub_df, on = 'ID', how = 'left')\n\n    for i in range(ss_df.shape[0]):\n        if ss_df.loc[i,'PredictionString'] == '0 1 eNoLCAgIMAEABJkBdQ==':\n            continue\n        a = ss_df.loc[i,'PredictionString']\n        b = a.split()\n        for j in range(int(len(a.split())/3)):\n            for k in range(19):\n                if int(b[0 + 3 * j]) == k:\n\n                    c = b[0 + 3 * j + 1]               \n                    b[0 + 3 * j + 1] = str(ss_df.loc[i,f'{k}'] * 0.6 + float(c) * 0.4)# * 0.9 + float(c) * 0.1\n\n        ss_df.loc[i,'PredictionString'] = ' '.join(b)\n\n    ss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\n    ss_df.to_csv('submission.csv',index = False)\nelse:\n    def auto_select_accelerator():\n        try:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"Running on TPU:\", tpu.master())\n        except ValueError:\n            strategy = tf.distribute.get_strategy()\n        print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n\n        return strategy\n\n\n    def build_decoder(with_labels=True, target_size=(300, 300), ext='jpg'):\n        def decode(path):\n            file_bytes = tf.io.read_file(path)\n            if ext == 'png':\n                img = tf.image.decode_png(file_bytes, channels=3)\n            elif ext in ['jpg', 'jpeg']:\n                img = tf.image.decode_jpeg(file_bytes, channels=3)\n            else:\n                raise ValueError(\"Image extension not supported\")\n\n            img = tf.cast(img, tf.float32) / 255.0\n            img = tf.image.resize(img, target_size)\n\n            return img\n\n        def decode_with_labels(path, label):\n            return decode(path), label\n\n        return decode_with_labels if with_labels else decode\n\n\n    def build_augmenter(with_labels=True):\n        def augment(img):\n            img = tf.image.random_flip_left_right(img)\n            img = tf.image.random_flip_up_down(img)\n            return img\n\n        def augment_with_labels(img, label):\n            return augment(img), label\n\n        return augment_with_labels if with_labels else augment\n\n\n    def build_dataset(paths, labels=None, bsize=32, cache=True,\n                      decode_fn=None, augment_fn=None,\n                      augment=True, repeat=True, shuffle=1024, \n                      cache_dir=\"\"):\n        if cache_dir != \"\" and cache is True:\n            os.makedirs(cache_dir, exist_ok=True)\n\n        if decode_fn is None:\n            decode_fn = build_decoder(labels is not None)\n\n        if augment_fn is None:\n            augment_fn = build_augmenter(labels is not None)\n\n        AUTO = tf.data.experimental.AUTOTUNE\n        slices = paths if labels is None else (paths, labels)\n\n        dset = tf.data.Dataset.from_tensor_slices(slices)\n        dset = dset.map(decode_fn, num_parallel_calls=AUTO)\n        dset = dset.cache(cache_dir) if cache else dset\n        dset = dset.map(augment_fn, num_parallel_calls=AUTO) if augment else dset\n        dset = dset.repeat() if repeat else dset\n        dset = dset.shuffle(shuffle) if shuffle else dset\n        dset = dset.batch(bsize).prefetch(AUTO)\n\n        return dset\n\n    COMPETITION_NAME = \"hpa-single-cell-image-classification\"\n    strategy = auto_select_accelerator()\n    BATCH_SIZE = strategy.num_replicas_in_sync * 16\n\n    IMSIZE = (224, 240, 260, 300, 380, 456, 528, 600)\n\n    load_dir = f\"/kaggle/input/{COMPETITION_NAME}/\"\n    sub_df = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n    sub_df = ss_df.copy()\n\n    sub_df = sub_df.drop(sub_df.columns[1:],axis=1)\n\n    for i in range(19):\n        sub_df[f'{i}'] = pd.Series(np.zeros(sub_df.shape[0]))\n\n\n    test_paths = load_dir + \"/test/\" + sub_df['ID'] + '_green.png'\n    # Get the multi-labels\n    label_cols = sub_df.columns[1:]\n\n    test_decoder = build_decoder(with_labels=False, target_size=(IMSIZE[7], IMSIZE[7]))\n    dtest = build_dataset(\n        test_paths, bsize=BATCH_SIZE, repeat=False, \n        shuffle=False, augment=False, cache=False,\n        decode_fn=test_decoder\n    )\n\n    with strategy.scope():\n        model = tf.keras.models.load_model(\n            '../input/hpa-classification-efnb7-train/model_green.h5'\n        )\n\n    model.summary()\n    sub_df[label_cols] = model.predict(dtest, verbose=1)\n\n    sub_df.head()\n\n    ss_df = pd.merge(ss_df, sub_df, on = 'ID', how = 'left')\n\n    for i in range(ss_df.shape[0]):\n        if ss_df.loc[i,'PredictionString'] == '0 1 eNoLCAgIMAEABJkBdQ==':\n            continue\n        a = ss_df.loc[i,'PredictionString']\n        b = a.split()\n        for j in range(int(len(a.split())/3)):\n            for k in range(19):\n                if int(b[0 + 3 * j]) == k:\n\n                    c = b[0 + 3 * j + 1]               \n                    b[0 + 3 * j + 1] = str(ss_df.loc[i,f'{k}'] * 0.6 + float(c) * 0.4)# * 0.9 + float(c) * 0.1\n\n        ss_df.loc[i,'PredictionString'] = ' '.join(b)\n\n    ss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\n    ss_df.to_csv('submission.csv',index = False)","metadata":{},"execution_count":null,"outputs":[]}]}