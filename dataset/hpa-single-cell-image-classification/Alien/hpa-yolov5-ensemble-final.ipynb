{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport glob\nimport cv2\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install /kaggle/input/kerasapplications -q\n!pip install /kaggle/input/efficientnet-keras-source-code/ -q --no-deps\n!pip install -q \"/kaggle/input/pycocotools/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\"\n!pip install -q \"/kaggle/input/hpapytorchzoozip/pytorch_zoo-master\"\n!pip install -q \"/kaggle/input/hpacellsegmentatormaster/HPA-Cell-Segmentation-master\"\n\n#!wget \"https://www.kaggleusercontent.com/kf/60257229/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..CiJyNbJXntOyTTiedEu0RA.9ehsk6hfDsNYbo2hw344h9FJN_gNQ_7JbmG5addEB5yMS2GEVsiYEbCYtTZrl_GWl2rm_BlEfgGn-uvzr1m1MsAgen97qAVX-FG6bCguUWThX4Sj1YbOtZYUO_bdvn63ce9n18_BC5CB2BfcmjCXIEamsaM-LF0PlOmlJ42WSrnyX7A3sUlBAV8AXgaeku0F17F3qEGClYYro9kQPAgT4Wg2zQVegDNtpE_52kj0mOVagAoWPw5N8sD2ueY4HrY4uTgNvQwHKQq60ce3Wu0XVODROcpZZSDIpfarofwUZQhSe4GmnoxHJA4kBN_kG1_0YdnsvOKCVmLoVC7BmChqPr-9llQhyT6pBVRIhCBXanH2dYHy-bLxZPXXmH-bYgVuxNTt3wKR-LcVScafukQfwg_tHBOAxb5U7a7ZuV7zfDY5HjwMrhjdd0JkerXrBCvOhsC5NQ4H9eIUB0csEZhQwEQmGk6u9w0NvDS-7gdz71b-qsI7Atk4TNTa9yEoJbgXZH6kRRHlb9kpjA3XCPcnV5j0Mwjli-qdqJj_uXwd66CLpy9wvnRaniqm8bOlf7wVfGCXZqdEjFp1WlYcWuoKKdsMZv-6-SVXA52_suOaMq1pf7HodgDobeohQBGZQuzLv_xRZnOUZPlwAE0OZa_vB9W7a48mwPWnS6Lh0llFaHk.3bLf-RBpLBwqm6-8VMCrwA/model_green.h5\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei\nimport glob\nimport tensorflow_addons as tfa","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ONLY_PUBLIC = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import base64\nfrom pycocotools import mask as mutils\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib\ndef encode_binary_mask(mask: np.ndarray) -> t.Text:\n  \"\"\"Converts a binary mask into OID challenge encoding ascii text.\"\"\"\n\n  # check input mask --\n  if mask.dtype != np.bool:\n    raise ValueError(\n        \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n        mask.dtype)\n\n  mask = np.squeeze(mask)\n  if len(mask.shape) != 2:\n    raise ValueError(\n        \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n        mask.shape)\n\n  # convert input mask to expected COCO API input --\n  mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n  mask_to_encode = mask_to_encode.astype(np.uint8)\n  mask_to_encode = np.asfortranarray(mask_to_encode)\n\n  # RLE encode mask --\n  encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n  # compress and base64 encoding --\n  binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n  base64_str = base64.b64encode(binary_str)\n  return base64_str.decode() + ' '","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decreasing_non_label(pred):\n  '''\n  expect shape(dls.c,)\n  '''\n  #pred = pred.numpy()\n  avg = torch.mean(pred)\n  \n  pred[pred<avg] -= 4\n  \n  return pred\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport efficientnet.tfkeras as efn\nfrom tqdm import tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def rle_encode_less_memory(img):\n    pixels = img.T.flatten()\n    pixels[0] = 0\n    pixels[-1] = 0\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\ndef enc2mask(encs, shape):\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for m,enc in enumerate(encs):\n        if isinstance(enc,np.float) and np.isnan(enc): continue\n        s = enc.split()\n        for i in range(len(s)//2):\n            start = int(s[2*i]) - 1\n            length = int(s[2*i+1])\n            img[start:start+length] = 1 + m\n    return img.reshape(shape).T","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow import keras","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def macro_f1(y, y_hat, thresh=0.5):\n    \"\"\"Compute the macro F1-score on a batch of observations (average F1 across labels)\n    \n    Args:\n        y (int32 Tensor): labels array of shape (BATCH_SIZE, N_LABELS)\n        y_hat (float32 Tensor): probability matrix from forward propagation of shape (BATCH_SIZE, N_LABELS)\n        thresh: probability value above which we predict positive\n        \n    Returns:\n        macro_f1 (scalar Tensor): value of macro F1 for the batch\n    \"\"\"\n    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n    macro_f1 = tf.reduce_mean(f1)\n    return macro_f1","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os.path\nimport urllib\nimport zipfile\n\nimport numpy as np\nimport scipy.ndimage as ndi\nfrom skimage import filters, measure, segmentation\nfrom skimage.morphology import (binary_erosion, closing, disk,\n                                remove_small_holes, remove_small_objects)\nimport torch\nHIGH_THRESHOLD = 0.4\nLOW_THRESHOLD = HIGH_THRESHOLD - 0.25\n\n\ndef download_with_url(url_string, file_path, unzip=False):\n    \"\"\"Download file with a link.\"\"\"\n    with urllib.request.urlopen(url_string) as response, open(\n        file_path, \"wb\"\n    ) as out_file:\n        data = response.read()  # a `bytes` object\n        out_file.write(data)\n\n    if unzip:\n        with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n            zip_ref.extractall(os.path.dirname(file_path))\n\n\ndef __fill_holes(image):\n    \"\"\"Fill_holes for labelled image, with a unique number.\"\"\"\n    boundaries = segmentation.find_boundaries(image)\n    image = np.multiply(image, np.invert(boundaries))\n    image = ndi.binary_fill_holes(image > 0)\n    image = ndi.label(image)[0]\n    return image\n\n\n\n\n\ndef label_cell2(nuclei_pred, cell_pred):\n    \"\"\"Label the cells and the nuclei.\n    Keyword arguments:\n    nuclei_pred -- a 3D numpy array of a prediction from a nuclei image.\n    cell_pred -- a 3D numpy array of a prediction from a cell image.\n    Returns:\n    A tuple containing:\n    nuclei-label -- A nuclei mask data array.\n    cell-label  -- A cell mask data array.\n    0's in the data arrays indicate background while a continous\n    strech of a specific number indicates the area for a specific\n    cell.\n    The same value in cell mask and nuclei mask refers to the identical cell.\n    NOTE: The nuclei labeling from this function will be sligthly\n    different from the values in :func:`label_nuclei` as this version\n    will use information from the cell-predictions to make better\n    estimates.\n    \"\"\"\n    def __wsh(\n        mask_img,\n        threshold,\n        border_img,\n        seeds,\n        threshold_adjustment=0.35,\n        small_object_size_cutoff=10,\n    ):\n        img_copy = np.copy(mask_img)\n        m = seeds * border_img  # * dt\n        img_copy[m <= threshold + threshold_adjustment] = 0\n        img_copy[m > threshold + threshold_adjustment] = 1\n        img_copy = img_copy.astype(np.bool)\n        img_copy = remove_small_objects(img_copy, small_object_size_cutoff).astype(\n            np.uint8\n        )\n\n        mask_img[mask_img <= threshold] = 0\n        mask_img[mask_img > threshold] = 1\n        mask_img = mask_img.astype(np.bool)\n        mask_img = remove_small_holes(mask_img, 63)\n        mask_img = remove_small_objects(mask_img, 1).astype(np.uint8)\n        markers = ndi.label(img_copy, output=np.uint32)[0]\n        labeled_array = segmentation.watershed(\n            mask_img, markers, mask=mask_img, watershed_line=True\n        )\n        return labeled_array\n\n    nuclei_label = __wsh(\n        nuclei_pred[..., 2] / 255.0,\n        0.4,\n        1 - (nuclei_pred[..., 1] + cell_pred[..., 1]) / 255.0 > 0.05,\n        nuclei_pred[..., 2] / 255,\n        threshold_adjustment=-0.25,\n        small_object_size_cutoff=32,\n    )\n\n    # for hpa_image, to remove the small pseduo nuclei\n    nuclei_label = remove_small_objects(nuclei_label, 157)\n    nuclei_label = measure.label(nuclei_label)\n    # this is to remove the cell borders' signal from cell mask.\n    # could use np.logical_and with some revision, to replace this func.\n    # Tuned for segmentation hpa images\n    threshold_value = max(0.22, filters.threshold_otsu(cell_pred[..., 2] / 255) * 0.5)\n    # exclude the green area first\n    cell_region = np.multiply(\n        cell_pred[..., 2] / 255 > threshold_value,\n        np.invert(np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8)),\n    )\n    sk = np.asarray(cell_region, dtype=np.int8)\n    distance = np.clip(cell_pred[..., 2], 255 * threshold_value, cell_pred[..., 2])\n    cell_label = segmentation.watershed(-distance, nuclei_label, mask=sk)\n    cell_label = remove_small_objects(cell_label, 344).astype(np.uint8)\n    selem = disk(2)\n    cell_label = closing(cell_label, selem)\n    cell_label = __fill_holes(cell_label)\n    # this part is to use green channel, and extend cell label to green channel\n    # benefit is to exclude cells clear on border but without nucleus\n    sk = np.asarray(\n        np.add(\n            np.asarray(cell_label > 0, dtype=np.int8),\n            np.asarray(cell_pred[..., 1] / 255 > 0.05, dtype=np.int8),\n        )\n        > 0,\n        dtype=np.int8,\n    )\n    cell_label = segmentation.watershed(-distance, cell_label, mask=sk)\n    cell_label = __fill_holes(cell_label)\n    cell_label = np.asarray(cell_label > 0, dtype=np.uint8)\n    cell_label = measure.label(cell_label)\n    cell_label = remove_small_objects(cell_label, 344) # was 344\n    cell_label = measure.label(cell_label)\n    cell_label = np.asarray(cell_label, dtype=np.uint16)\n    #nuclei_label = np.multiply(cell_label > 0, nuclei_label) > 0\n    #nuclei_label = measure.label(nuclei_label)\n    #nuclei_label = remove_small_objects(nuclei_label, 157)\n    #nuclei_label = np.multiply(cell_label, nuclei_label > 0)\n\n    return cell_label#nuclei_label, cell_label","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!mkdir cell_tile\ncell_dir = 'cell_tile'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NUC_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_nuclei_v1.pth\"\nCELL_MODEL = \"../input/hpacellsegmentatormodelweights/dpn_unet_cell_3ch_v1.pth\"\nsegmentator = cellsegmentator.CellSegmentator(\n        NUC_MODEL,\n        CELL_MODEL,\n        scale_factor=0.25,\n        device=\"cuda\",\n        padding=True,\n        multi_channel_model=True,\n    )\ni_df = pd.read_csv(\"../input/hpa-single-cell-image-classification/sample_submission.csv\")\nif ONLY_PUBLIC==True:\n    i_df = pd.read_csv(\"../input/hpa-sample-submission-with-extra-metadata/updated_sample_submission.csv\")\nbs = 40\nbs_now=0\nimage_list=[]\nmt = []\ner = []\nnu = []\nID_list=[]\nfor i in tqdm(i_df.index):\n    ID = i_df.loc[i,'ID']\n    #if len(i_df)==559:\n    #    continue\n    if len(glob.glob('../input/cell-tile-fast-cegmentor/cell_tile/'+ID+'.npz'))>0:\n        continue\n    W= int(i_df[i_df['ID']==ID]['ImageWidth'].values[0])\n    H= int(i_df[i_df['ID']==ID]['ImageHeight'].values[0])\n    ID_list.append(ID)\n    name = '../input/hpa-single-cell-image-classification/test' + '/' +ID+ '_red.png'\n    mt.append(name)\n    er.append(name.replace('red', 'yellow'))\n    nu.append(name.replace('red', 'blue'))\n    images = [mt, er, nu]\n    bs_now+=1\n    if bs_now>=bs:\n        \n        # For nuclei\n        nuc_segmentations = segmentator.pred_nuclei(images[2])\n\n        # For full cells\n        cell_segmentations = segmentator.pred_cells(images)\n\n        \n        \n        \n        cell_mask=[]\n        for j, pred in enumerate(cell_segmentations):\n            size = cell_segmentations[j].shape[0]\n            cell_mask_ = label_cell2(cv2.resize(nuc_segmentations[j],(512,512)), cv2.resize(cell_segmentations[j],(512,512)))\n            cell_mask_ = cv2.resize(cell_mask_,(size,size),interpolation=cv2.INTER_NEAREST)\n            cell_mask.append(cell_mask_)\n        for id_,mask in zip(ID_list,cell_mask):\n            np.savez_compressed(f'{cell_dir}/{id_}', mask)\n        \n        # clear\n        \n        image_list=[]\n        mt = []\n        er = []\n        nu = []\n        ID_list=[]\n        bs_now=0\nif bs_now>0:\n        nuc_segmentations = segmentator.pred_nuclei(images[2])\n\n        # For full cells\n        cell_segmentations = segmentator.pred_cells(images)\n\n        \n        \n        cell_mask=[]\n        for j, pred in enumerate(cell_segmentations):\n            size = cell_segmentations[j].shape[0]\n            cell_mask_ = label_cell2(cv2.resize(nuc_segmentations[j],(512,512)), cv2.resize(cell_segmentations[j],(512,512)))\n            cell_mask_ = cv2.resize(cell_mask_,(size,size),interpolation=cv2.INTER_NEAREST)\n            cell_mask.append(cell_mask_)\n        for id_,mask in zip(ID_list,cell_mask):\n            np.savez_compressed(f'{cell_dir}/{id_}', mask)\n        \n        # clear\n        \n        image_list=[]\n        mt = []\n        er = []\n        nu = []\n        ID_list=[]\n        bs_now=0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ndel CELL_MODEL\ndel NUC_MODEL\ndel cellsegmentator\n#del NUC\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\ntry:\n            tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n            tf.config.experimental_connect_to_cluster(tpu)\n            tf.tpu.experimental.initialize_tpu_system(tpu)\n            strategy = tf.distribute.experimental.TPUStrategy(tpu)\n            print(\"Running on TPU:\", tpu.master())\nexcept ValueError:\n            strategy = tf.distribute.get_strategy()\n            print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n'''\n\n\n'''\nmodel = tf.keras.models.load_model(\n            '../input/hpa-classification-efnb7-train/model_green.h5',compile = False\n        )\n'''\n\ngpus = tf.config.experimental.list_physical_devices('GPU')\nif gpus:\n        try:\n            # Currently, memory growth needs to be the same across GPUs\n            for gpu in gpus:\n                tf.config.experimental.set_memory_growth(gpu, True)\n            logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n            print(len(gpus), \"... Physical GPUs,\", len(logical_gpus), \"Logical GPUs ...\\n\")\n        except RuntimeError as e:\n            # Memory growth must be set before GPUs have been initialized\n            print(e)\n\n\nmodel = tf.keras.models.load_model(\n            '../input/download-model/model_RGB_0.0502.h5'\n        )\n\nmodel_4 = tf.keras.models.load_model(\n            '../input/hpa-training-tpu-pseude-label-t/model_RGB_0.0635.h5'\n        )\nmodel_2 = tf.keras.models.load_model(\n            '../input/atlasmodel/model_RGB.h5'\n        )\n    \nmodel_3 = tf.keras.models.load_model('../input/hpa-training-tpu/model_RGB_0.2217.h5')\n#model_4 = tf.keras.models.load_model('../input/atlasmodel/model_RGB_0.1139.h5')\nmodel_g = tf.keras.models.load_model('../input/fork-of-hpa-training-tpu-2/model_RGB_0.2440.h5')\n\nmodel_whole = tf.keras.models.load_model(\n            '../input/hpa-classification-efnb7-train-tfrec/model_green.h5'\n        )\n\nmodel_whole_2 = tf.keras.models.load_model(\n            '../input/atlasmodel/model_green.h5'\n        )\n\nmodel_whole_3 = tf.keras.models.load_model(\n            '../input/download-model3/model_green.h5'\n        )\n# model_whole_4 = tf.keras.models.load_model(\n#             '../input/hpa-classification-efnb7-train-noisy/model_green.h5'\n#         )\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def pred_string(ID, high, width):\n    \n\n    ID = ID\n    W = width\n    H = high\n    \n\n    green = plt.imread('../input/hpa-single-cell-image-classification/test/'+ID+'_green.png')\n    red = plt.imread('../input/hpa-single-cell-image-classification/test/'+ID+'_red.png')\n    blue = plt.imread('../input/hpa-single-cell-image-classification/test/'+ID+'_blue.png')\n    green = green[:,:,np.newaxis]\n    blue = blue[:,:,np.newaxis]\n    red = red[:,:,np.newaxis]\n    all_ = np.concatenate((red,green,blue),axis=-1)\n    w = width\n    h = high\n    mt = glob.glob('../input/hpa-single-cell-image-classification/test' + '/' +ID+ '_red.png')\n    er = [f.replace('red', 'yellow') for f in mt]\n    nu = [f.replace('red', 'blue') for f in mt]\n    images = [mt, er, nu]\n    \n    #ensemble the image-wise\n    all_whole = np.concatenate((green,green,green),axis=-1)\n    all_whole_720 = cv2.resize(all_whole,(720,720),\n                              interpolation = cv2.INTER_AREA)\n    all_whole_720 = np.expand_dims(all_whole_720,axis=0)\n    all_whole_512 = cv2.resize(all_whole,(512,512),\n                              interpolation = cv2.INTER_AREA)\n    all_whole_512 = np.expand_dims(all_whole_512,axis=0)\n    all_whole = cv2.resize(all_whole,(600,600),\n                              interpolation = cv2.INTER_AREA)\n    \n    all_whole = np.expand_dims(all_whole,axis=0)\n    pred_whole = model_whole.predict(all_whole)\n    pred_whole2 = model_whole_2.predict(all_whole)\n    pred_whole3 = model_whole_3.predict(all_whole_720)\n    #pred_whole4 = model_whole_4.predict(all_whole)\n    pred_whole = pred_whole+pred_whole2+pred_whole3\n    # For nuclei\n    #nuc_segmentations = segmentator.pred_nuclei(images[2])\n\n    # For full cells\n    #cell_segmentations = segmentator.pred_cells(images)\n\n    # post-processing\n    \n    \n    #nuclei_mask, cell_mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n    #FOVname = os.path.basename(mt[i]).replace('red','predictedmask')\n    #imageio.imwrite(os.path.join(save_dir,FOVname), cell_mask) \n    file_ =glob.glob('../input/cell-tile-fast-cegmentor/cell_tile/'+ID+'.npz')\n    if len(file_)>0:\n        cell_mask = np.load(file_[0])['arr_0']\n    else:\n        cell_mask = np.load(f'{cell_dir}/{ID}.npz')['arr_0']\n    pred_strs = []\n    for i in range(1,cell_mask.max()+1):\n          x,y=(cell_mask==i).nonzero()\n          cell_mask_s = cell_mask==i\n          cell_mask_s_ = cell_mask_s[:,:,np.newaxis]\n          i_c = cell_mask_s_ * all_\n          \n            \n            \n            \n#           i_c_720 = cv2.resize(i_c,(720,720),\n#                               interpolation = cv2.INTER_AREA)\n#           i_c_720 = np.stack([i_c_720[:,:,1],i_c_720[:,:,1],i_c_720[:,:,1]],axis=2)\n#           i_c_720 = np.expand_dims(i_c_720,axis=0)  \n          \n          i_c = cv2.resize(i_c,(600,600),\n                              interpolation = cv2.INTER_AREA)\n          i_c = np.stack([i_c[:,:,1],i_c[:,:,1],i_c[:,:,1]],axis=2)\n          i_c = np.expand_dims(i_c,axis=0)\n          \n            \n            \n        \n          pred_ic = model_whole_2.predict(i_c)\n          #pred_ic2 = model_whole.predict(i_c)\n          #pred_ic3 = model_whole_3.predict(i_c_720)\n          #print(pred_ic)\n          lenx=x.max()-x.min()+1\n          leny=y.max()-y.min()+1\n          xx=x.min()\n          yy=y.min()\n\n          interest=cell_mask[xx:xx+lenx,yy:yy+leny]\n          all_g=all_[xx:xx+lenx,yy:yy+leny]\n          if lenx>leny:\n              pad=lenx-leny\n              interest=np.pad(interest,((0,0),(pad//2,pad-pad//2)), 'constant', constant_values=(0))\n              all_g=np.pad(all_g,((0,0),(pad//2,pad-pad//2),(0,0)), 'constant', constant_values=(0))\n          elif leny>lenx:\n              pad=leny-lenx\n              interest=np.pad(interest,((pad//2,pad-pad//2),(0,0)), 'constant', constant_values=(0))\n              all_g=np.pad(all_g,((pad//2,pad-pad//2),(0,0),(0,0)), 'constant', constant_values=(0))\n          interest = interest[:,:,np.newaxis]\n          interest=(interest==i)\n\n          all_g=interest*all_g\n\n          \n          \n\n          \n\n\n\n\n          all_g = cv2.resize(all_g,(256,256),\n                              interpolation = cv2.INTER_AREA)\n          #all_g = np.transpose(all_g,(2,0,1))\n          all_green = np.stack([all_g[:,:,1],all_g[:,:,1],all_g[:,:,1]],axis=2)\n          all_g = np.expand_dims(all_g,axis=0)\n          all_green = np.expand_dims(all_green,axis=0)\n          #all_g=(torch.from_numpy(all_g)).to(device)\n          #model.eval()\n          pred_c  = 0\n\n          \n          pred = model.predict(all_g)\n          pred2 = model_2.predict(all_g)\n          pred3 = model_3.predict(all_g)\n          pred4 = model_4.predict(all_g)\n          #pred4 = model_4.predict(all_g)\n          predg = model_g.predict(all_green)\n          pred = pred+pred2+pred3+pred4+predg+pred_ic\n          #pred2 = model_2.predict(all_g)\n          #pred3 = model_3.predict(all_g)\n          #pred4 = model_4.predict(all_g)\n          #pred4 = model_4.predict(all_g)\n          #predg = model_g.predict(all_green)\n          #pred = (pred+pred_ic)/2.\n          # Only get the argmax one\n          pred = pred + pred_whole\n          pred_c = pred[0]\n          #pred_c = decreasing_non_label(pred_c)\n            \n          rle = encode_binary_mask(cell_mask_s)\n          \n            \n          #set non-green to class 18\n          '''\n          green_channel = all_g[:,:,1]\n          green_channel[green_channel<0.1]=0.\n          if np.sum(green_channel)<0.5:\n                pred_c = [0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,0.,1.0]\n          '''\n          \n          \n          for class_id in range(19):\n            #cnf = torch.sigmoid(pred_c[class_id])\n            cnf = pred_c[class_id]\n            pred_strs.append(f'{class_id} {cnf} {rle}{xx+(lenx-1)/2} {yy+(leny-1)/2} ')\n            \n    return ''.join(pred_strs)[:-1]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pred_string('0040581b-f1f2-4fbe-b043-b6bfea5404bb',2048,2048)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imlist = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\ndf_imlist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if len(df_imlist) == 558:\n    debug = True\n    df_imlist = df_imlist[:3]\nelse:\n    debug = False","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time \nstart = time.time()\n\ndf_imlist['PredictionString'] =  df_imlist.apply(\n    lambda row: pred_string(row['ID'],row['ImageHeight'],row['ImageWidth']),\n    axis=1\n)\n\n\n\n\nend = time.time()\n\nprint((end - start)/559)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_imlist","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_imlist.to_csv('submission.csv',index = False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndel model, model_4, model_2, model_3, model_g\ndel model_whole, model_whole_2, model_whole_3 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df_imlist","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# xmid, ymid / ImageWidth,ImageHeight\nfor i in range(df.shape[0]):\n        a = df.loc[i,'PredictionString']\n        b = a.split()\n        for j in range(int(len(a.split())/5)):\n            c = b[5 * j + 3]\n            d = b[5 * j + 4]\n            b[5 * j + 3] = str( float(c) / df.loc[i,'ImageWidth'] )\n            b[5 * j + 4] = str( float(d) / df.loc[i,'ImageHeight'] )\n        df.loc[i,'PredictionString'] = ' '.join(b)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss_df = df ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"debug = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numba import cuda\nimport torch\ncuda.select_device(0)\ncuda.close()\ncuda.select_device(0)\n#torch.cuda.empty_cache()\n\n\nimport numpy as np, pandas as pd\nfrom glob import glob\nimport shutil, os\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import GroupKFold\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport cv2\n\nif debug:\n    test_df = pd.read_csv(f'/kaggle/input/hpa-single-cell-image-classification/sample_submission.csv')\n    test_df = test_df[:3]\nelse:\n    test_df = pd.read_csv(f'/kaggle/input/hpa-single-cell-image-classification/sample_submission.csv')\n\n\ntest_df['ID'] = test_df['ID'] +'_green'\ndf = test_df.copy()\n\nsave_dir_train = '/kaggle/tmp/0/'\nos.makedirs(save_dir_train, exist_ok=True)\n\n\n# save 512 green png\nfor i in range(df.shape[0]):\n    image_id = df.loc[i,'ID']\n\n    img = cv2.imread(f'/kaggle/input/hpa-single-cell-image-classification/test/{image_id}.png')\n\n\n    img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_CUBIC)\n    cv2.imwrite(save_dir_train + image_id +'.png',img)\n\ndim = 512 #1024, 256, 'original'\ntest_dir = f'/kaggle/tmp/0'\nweights_dir = '/kaggle/input/hpa-yolov5-train-all-fine/yolov5/runs/train/exp/weights/last.pt'\n\nshutil.copytree('/kaggle/input/yolov5-official-v31-dataset/yolov5', '/kaggle/working/yolov5')\nos.chdir('/kaggle/working/yolov5') # install dependencies\n\nimport torch\n#from IPython.display import Image, clear_output  # to display images\n\n#clear_output()\n#print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))\n\n\n!python detect.py --weights $weights_dir\\\n--img 512\\\n--conf 0.001\\\n--iou 0.5\\\n--source $test_dir\\\n--save-txt --save-conf --exist-ok\ndef yolo2voc(image_height, image_width, bboxes):\n    \"\"\"\n    yolo => [xmid, ymid, w, h] (normalized)\n    voc  => [x1, y1, x2, y1]\n\n    \"\"\" \n    bboxes = bboxes.copy().astype(float) # otherwise all value will be 0 as voc_pascal dtype is np.int\n\n    bboxes[..., [0, 2]] = bboxes[..., [0, 2]]* image_width\n    bboxes[..., [1, 3]] = bboxes[..., [1, 3]]* image_height\n\n    bboxes[..., [0, 1]] = bboxes[..., [0, 1]] - bboxes[..., [2, 3]]/2\n    bboxes[..., [2, 3]] = bboxes[..., [0, 1]] + bboxes[..., [2, 3]]\n\n    return bboxes\nimage_ids = []\nPredictionStrings = []\n\nfor file_path in tqdm(glob('runs/detect/exp/labels/*.txt')):\n    image_id = file_path.split('/')[-1].split('.')[0]\n    w, h = test_df.loc[test_df.ID==image_id,['ImageWidth', 'ImageHeight']].values[0]\n    f = open(file_path, 'r')\n    data = np.array(f.read().replace('\\n', ' ').strip().split(' ')).astype(np.float32).reshape(-1, 6)\n    data = data[:, [0, 5, 1, 2, 3, 4]]\n    bboxes = list(np.round(np.concatenate((data[:, :2], np.round(yolo2voc(h, w, data[:, 2:]))), axis =1).reshape(-1), 12).astype(str))\n    for idx in range(len(bboxes)):\n        bboxes[idx] = str(int(float(bboxes[idx]))) if idx%6!=1 else bboxes[idx]\n    image_ids.append(image_id)\n    PredictionStrings.append(' '.join(bboxes))\n\n\npred_df = pd.DataFrame({'ID':image_ids,\n                        'PredictionString':PredictionStrings})\nprint(pred_df)\n#shutil.rmtree('/kaggle/working/yolov5')\nif debug:\n    df1 = pd.read_csv('/kaggle/input/hpa-single-cell-image-classification/sample_submission.csv')\n    df1 = df1[:3]\nelse:\n    df1 = pd.read_csv('/kaggle/input/hpa-single-cell-image-classification/sample_submission.csv')\ndf1 = df1.drop(['PredictionString'], axis=1)\ndf1['ID'] = df1['ID'] + '_green'\ndf1 = pd.merge(df1, pred_df, on = 'ID', how = 'left').fillna(\"0 0 0 0 1 1\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#yolo output xmid ymid\n\nfor i in range(df1.shape[0]):\n    list1 = []\n    a = df1.loc[i, 'PredictionString'].split()\n    for j in range(int(len(a) / 6)):\n        list1.append(a[j * 6])\n        list1.append(a[j * 6 + 1])\n        x_mid = str((int(a[j * 6 + 2]) + int(a[j * 6 + 4])) / 2 / df1.loc[i, 'ImageWidth'])\n        y_mid = str((int(a[j * 6 + 3]) + int(a[j * 6 + 5])) / 2 / df1.loc[i, 'ImageWidth'])\n        list1.append(x_mid)\n        list1.append(y_mid)\n    df1.loc[i, 'PredictionString'] = ' '.join(list1)\n\nfor i in range(df1.shape[0]):\n    df1.loc[i,'ID'] = df1.loc[i,'ID'][:-6]\n\n\ndf1 = df1.sort_values(by=['ID']).reset_index(drop=True)\n\ncuda.select_device(0)\ncuda.close()\ncuda.select_device(0)\n\n\ndf = ss_df.sort_values(by=['ID']).reset_index(drop=True)\nfrom sklearn.neighbors import KNeighborsClassifier\n\n\n# get conf=0 df\ndf2 = df.copy()\nfor i in range(df2.shape[0]):\n        list1 = []\n        a = df2.loc[i,'PredictionString']\n        b = a.split()\n        for j in range(int(len(a.split())/5)):\n            list1.append(b[0 + 5 * j])\n            list1.append('0')\n            list1.append(b[0 + 5 * j +1])\n            list1.append(b[0 + 5 * j +2])\n            list1.append(b[0 + 5 * j +3])\n        df2.loc[i,'PredictionString'] = ' '.join(list1)\n#cell xmid ymid ,yolo xmid ymid KNN n=1\nfor i in range(df.shape[0]):\n    list1 = []\n    a = df.loc[i,'PredictionString'].split()\n    \n    for j in range(int(len(df.loc[i, 'PredictionString'].split()) / 19 / 5)):\n        list2 = []\n        list2.append(float(a[95 * j + 3]))\n        list2.append(float(a[95 * j + 4]))\n        list1.append(list2)\n    list3 = list(range(0,int(len(df.loc[i, 'PredictionString'].split()) / 19 / 5)))\n    mm1 = []\n    b = df1.loc[i,'PredictionString'].split()\n    for j in range(int(len(df1.loc[i, 'PredictionString'].split()) / 4)):\n        mm2 = []\n        mm2.append(float(b[4 * j +2]))\n        mm2.append(float(b[4 * j +3]))\n        mm1.append(mm2)\n    neigh = KNeighborsClassifier(n_neighbors=1)\n    neigh.fit(list1, list3)\n    c = neigh.predict(mm1)\n    d = df2.loc[i, 'PredictionString'].split()\n    e = df1.loc[i, 'PredictionString'].split()\n    for j in range(int(len(df1.loc[i, 'PredictionString'].split()) / 4)):\n        f = float(d[c[j] * 19 * 5 + int(e[4 * j]) * 5 + 1])\n        g = float(e[4 * j + 1])\n        # One cell has two confidence values, choose the larger one\n        if g > f:\n            d[c[j] * 19 * 5 + int(e[4 * j]) * 5 + 1] = str(g) \n    df2.loc[i,'PredictionString'] = ' '.join(d)\n\n#Confidence weighted average\nfor i in range(df.shape[0]):\n    a = df.loc[i,'PredictionString']\n    b = a.split()\n    df2_str = df2.loc[i,'PredictionString']\n    df2_split = df2_str.split()\n    for j in range(int(len(a.split())/5)):\n        for k in range(19):\n            if int(b[0 + 5 * j]) == k:\n                c = b[0 + 5 * j + 1]  \n                df2_conf = df2_split[0 + 5 * j + 1]\n                b[0 + 5 * j + 1] = str(float(c) + float(df2_conf))# * 0.9 + float(c) * 0.1\n\n    df.loc[i,'PredictionString'] = ' '.join(b)\n    \n# drop xmid ymid\nfor i in range(df.shape[0]):\n    list1 = []\n    a = df.loc[i,'PredictionString']\n    b = a.split()\n    for j in range(int(len(a.split())/5)):\n        list1.append(b[0 + 5 * j])\n        list1.append(b[0 + 5 * j +1])\n        list1.append(b[0 + 5 * j +2])\n    df.loc[i,'PredictionString'] = ' '.join(list1)\nss_df = df   \n\n\nss_df = ss_df[['ID','ImageWidth','ImageHeight','PredictionString']]\nss_df.to_csv('/kaggle/working/submission.csv',index = False)  \nshutil.rmtree('/kaggle/working/yolov5')","metadata":{},"execution_count":null,"outputs":[]}]}