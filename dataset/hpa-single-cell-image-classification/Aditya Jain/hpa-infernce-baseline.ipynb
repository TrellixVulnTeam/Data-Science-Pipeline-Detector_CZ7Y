{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install ../input/pycocotool/pycocotools-2.0-cp37-cp37m-linux_x86_64.whl\n!pip install -q \"../input/zoohpa/pytorch_zoo-master\"\n!pip install -q \"../input/effpytorch/EfficientNet-PyTorch-master\"\n!pip install \"../input/hpacellsegmentatorraman/HPA-Cell-Segmentation/\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport pytorch_lightning as pl\nimport torchvision.models as models\n\n\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset\n\n\nfrom skimage import io\nfrom skimage.transform import resize\nfrom skimage.color import rgb2gray,gray2rgb\n\nfrom matplotlib import pyplot as plt\n\nimport csv\nimport pandas as pd\nimport numpy as np\nimport cv2","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#import sys\n#import os\n#sys.path.insert(1, '../input/cellsegm/HPA-Cell-Segmentation-master')\n\n#import hpacellseg.cellsegmentator as cellsegmentator\n#from hpacellseg.utils import label_cell, label_nuclei\n\nfrom hpacellseg.cellsegmentator import *\nfrom hpacellseg import cellsegmentator, utils\n\nimport base64\n\n\nfrom pycocotools import _mask as coco_mask\nimport typing as t\nimport zlib\n\n\nNUC_MODEL = '../input/requiredfiles/nuclei-model.pth'\nCELL_MODEL = '../input/requiredfiles/cell-model.pth'\n\n# segmentator = cellsegmentator.CellSegmentator(\n#     NUC_MODEL,\n#     CELL_MODEL,\n#     scale_factor=0.25,\n#     device=\"cuda\",\n#     padding=True,\n#     multi_channel_model=True,\n# )\n\n\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    device=\"cuda\",\n    multi_channel_model=True,\n)\ndef extract_data_from_folder_and_create_csv(path = \"../input/hpa-single-cell-image-classification/test/\"):\n    filelist= [file for file in os.listdir(path) if file.endswith('.png')]\n    \n    trimmed_list = [None]*(int(len(filelist)/4))\n    count = 0\n    for i in (filelist):\n        trim_str = i.partition('_')[0]\n        #print(trim_str)\n        if trim_str not in trimmed_list: \n            #trimmed_list.append(trim_str) \n            trimmed_list[count] = trim_str\n            count +=1\n    return trimmed_list\n\ndef extract_data_from_csv(csvpath):\n    fields = [] \n    rows = [] \n    filename = csvpath\n    with open(filename, 'r') as csvfile: \n        # creating a csv reader object \n        csvreader = csv.reader(csvfile) \n\n        fields = next(csvreader)\n        # extracting each data row one by one \n        for row in csvreader: \n            rows.append(row) \n            \n    return rows\n\n# reading csv file\ndef get_segmented_image_and_label(container,index):\n    \n    '''\n    Takes csv_path and index as an input\n    Returns Segmented image and label if there is only single label\n    '''\n\n    Data = container[index]\n    image_id = Data[0]\n    #print(Data)\n    img_blue = io.imread(\"../input/hpa-single-cell-image-classification/test/\"+ image_id+\"_blue.png\")\n    img_green = io.imread(\"../input/hpa-single-cell-image-classification/test/\"+ image_id+\"_green.png\")\n    img_red = io.imread(\"../input/hpa-single-cell-image-classification/test/\"+ image_id+\"_red.png\")\n    img_yellow = io.imread(\"../input/hpa-single-cell-image-classification/test/\"+ image_id+\"_yellow.png\")\n    divider = 1\n\n    img_blue_resized = resize(img_blue, (img_blue.shape[0] // divider, img_blue.shape[1] // divider),\n                   anti_aliasing=True)\n    img_green_resized = resize(img_green, (img_green.shape[0] // divider, img_green.shape[1] // divider),\n                   anti_aliasing=True)\n    img_red_resized = resize(img_green, (img_red.shape[0] // divider, img_red.shape[1] // divider),\n                   anti_aliasing=True)\n    img_yellow_resized = resize(img_yellow, (img_yellow.shape[0] // divider, img_yellow.shape[1] // divider),\n                   anti_aliasing=True)\n\n\n    rgb = np.dstack((img_blue_resized,img_green_resized + img_yellow_resized,img_red_resized))\n\n    \n    nuc_segmentations = segmentator.pred_nuclei([rgb[:,:,2]])\n\n    # For full cells\n    cell_segmentations = segmentator.pred_cells([rgb],precombined = True)\n\n\n    #for i, pred in enumerate(cell_segmentations):\n    nuclei_mask, cell_mask = utils.label_cell(nuc_segmentations[0], cell_segmentations[0])\n\n\n    return rgb,cell_mask,image_id\n\n\n\n\ndef binary_mask_to_rle(mask):\n    #print(\"Before\")\n    #print(mask)\n    mask[mask >= 1] = 1\n    mask = mask.astype(np.bool) \n    #print(\"After\")\n    #print(mask)\n#     if mask.dtype != np.bool:\n#         raise ValueError(\n#         \"encode_binary_mask expects a binary mask, received dtype == %s\" %\n#         mask.dtype)\n    \n    \n    mask = np.squeeze(mask)\n    \n#     if len(mask.shape) != 2:\n#         raise ValueError(\n#         \"encode_binary_mask expects a 2d mask, received shape == %s\" %\n#         mask.shape)\n\n    # convert input mask to expected COCO API input --\n    \n    mask_to_encode = mask.reshape(mask.shape[0], mask.shape[1], 1)\n    #print(mask_to_encode.shape)\n    mask_to_encode = mask_to_encode.astype(np.uint8)\n    mask_to_encode = np.asfortranarray(mask_to_encode)\n    #print(mask_to_encode)\n    # RLE encode mask --\n    encoded_mask = coco_mask.encode(mask_to_encode)[0][\"counts\"]\n\n    # compress and base64 encoding --\n    binary_str = zlib.compress(encoded_mask, zlib.Z_BEST_COMPRESSION)\n    base64_str = base64.b64encode(binary_str)\n    return base64_str.decode('ascii')\n\n\ndef convert_to_binary(seg_mask):\n    cell_mask = seg_mask[..., np.newaxis] # Added a dimension for channel\n    _,thresh = cv2.threshold(cell_mask,0,255,cv2.THRESH_BINARY) # binarize\n    \n    #thresh_norm = cv2.normalize(src=thresh, dst=None, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_8U)\n    return thresh","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Class Architecture\nfrom efficientnet_pytorch import EfficientNet\n\nclass EffNet(pl.LightningModule):\n    \n    def __init__(self,learning_rate=1e-4):\n        super().__init__()\n        self.effnet = EfficientNet.from_name('efficientnet-b3')\n        in_features = self.effnet._fc.in_features\n        self.effnet._fc = nn.Linear(in_features,19)\n        self.train_acc = pl.metrics.Accuracy()\n        self.valid_acc = pl.metrics.Accuracy()\n        self.learning_rate = learning_rate\n\n            \n    def forward(self, x):\n        raw_predit = self.effnet(x)\n        return raw_predit\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=(self.learning_rate))\n        #optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n        #scheduler = torch.optim.lr_scheduler.CyclicLR(optimizer, base_lr=0.01, max_lr=0.1)\n        \n        #return [optimizer], [scheduler]\n        return optimizer\n    \n    def loss_function(self,x_hat, x):\n        creterion = nn.CrossEntropyLoss()\n        loss = creterion(x_hat,x)\n        return loss\n        \n    def training_step(self, train_batch, batch_idx):\n        x, y = train_batch\n        y_hat = self(x)\n        loss = self.loss_function(y_hat, y)\n        self.log('train_loss', loss, on_step=True, on_epoch=True,prog_bar=True,logger=True)\n        self.train_acc(y_hat, y)\n        self.log('train_acc', self.train_acc, on_step=True, on_epoch=True,prog_bar=True,logger=True)\n        #log = {'train_loss' : loss, 'train_acc': self.train_acc}\n        #return {'train_log':log}\n        return loss\n\n    def validation_step(self, val_batch, batch_idx):\n        x, y = val_batch\n        y_hat = self(x) \n        loss = self.loss_function(y_hat, y)\n        self.log('val_loss', loss, on_step=True, on_epoch=True,prog_bar=True,logger=True)\n        self.valid_acc(y_hat, y)\n        self.log('val_acc', self.valid_acc,on_step=True, on_epoch=True,prog_bar=True,logger=True)\n        #log = {'val_loss' : loss, 'val_acc': self.valid_acc}\n        #return {'val_log':log}\n        return loss\n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model = EffNet(3e-4)\n#import time\n\n#Testing \n\n#sub = pd.DataFrame()\nsub = pd.read_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\n#container = extract_data_from_folder_and_create_csv()\n#container.sort()\ncontainer = extract_data_from_csv('../input/hpa-single-cell-image-classification/sample_submission.csv')\npretrained_model = EffNet.load_from_checkpoint(checkpoint_path = '../input/fresh-epoch-0/epoch0-step3725.ckpt')\npretrained_model.eval()\npretrained_model.freeze()\n\nmy_transform = transforms.Compose([\n    transforms.ToPILImage(),\n    transforms.Resize((224,224)),\n    transforms.ToTensor()])\n\n\nm = nn.Softmax()\n\nif(len(container) > 559):\n    for idx in range(len(container)):#\n        #start_t = time.time()\n        rgb,seg_mask,imageid = get_segmented_image_and_label(container,idx)\n        #seg_t = time.time()\n        #print(\"Seg: \",(seg_t - start_t))\n        thresholded = convert_to_binary(seg_mask)\n        contours, hierarchy = cv2.findContours(thresholded.astype(np.uint8).copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n        predictionstring = []\n\n        cv2.drawContours(thresholded, contours, -1, color=(0,0,0),thickness=-1)\n    #     print(len(contours))\n    #     print(len(np.unique(seg_mask)) - 1)\n#         fig, ax = plt.subplots(1,2, figsize=(20,50))\n        for i,c in enumerate(contours):\n            rle = \"\"\n            x, y, w, h = cv2.boundingRect(c)\n\n            cropped_rgb = rgb[y:y+h,x:x+w]\n\n#             ax[0].imshow(cropped_rgb)\n#             ax[0].axis('off')\n            cv2.drawContours(thresholded, contours, i, color=(255,255,255),thickness=-1)\n\n\n\n#             ax[1].imshow(thresholded)\n#             ax[1].axis('off')\n\n\n\n            torch_img = torch.from_numpy(cropped_rgb)\n            torch_img = torch_img.permute(2,1,0)\n\n            transfromed_sample = my_transform(torch_img)\n\n            rle = binary_mask_to_rle(thresholded)\n\n\n            transfromed_sample = transfromed_sample.unsqueeze(0)\n            y_hat = pretrained_model(transfromed_sample)\n            conf = m(y_hat)\n            y_hat_ = torch.argmax(y_hat,dim=1)\n            #y_hat_top_4 = torch.topk(conf, 4)\n            #print(y_hat)\n            #print(y_hat_top_4)\n            conf_hat = torch.argmax(conf,dim=1)\n            x = conf[0][conf_hat].numpy().tolist()\n\n\n            predictionstring.extend([\" \".join([str(y_hat_[0].numpy()),str(x[0]),rle])])\n\n        #looping = time.time()\n        #print(\"Looping:\",(looping - start_t))\n\n        predictionstring = \" \".join(predictionstring)\n        sub.loc[idx,'PredictionString'] = predictionstring\n\n\nsub.to_csv('./submission.csv',index=False)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}