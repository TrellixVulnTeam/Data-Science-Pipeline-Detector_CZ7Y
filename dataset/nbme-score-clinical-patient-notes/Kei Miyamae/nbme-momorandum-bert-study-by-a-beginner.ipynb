{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Intoroduction\nThis notebook is my own guide to understand BERT.  \nMaybe it helps a beginner like me.  \nI forgot to mention offset mapping, so I added a comment.","metadata":{}},{"cell_type":"markdown","source":"私自身が初心者のため、自分用のガイドとして作成しています。  \n初歩すぎですが、忘備録とします。  \nオフセットマッピングに関する記述を書き忘れていたたためコメントを追加しました。","metadata":{}},{"cell_type":"markdown","source":"## References  \n[NBME / Deberta-base baseline [train]](https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train)  \n[[NBME]BERT_for_beginners](https://www.kaggle.com/tomohiroh/nbme-bert-for-beginners)","metadata":{}},{"cell_type":"code","source":"import os\n\ndata_path = \"../input/nbme-score-clinical-patient-notes\"\nprint(\"File list of data_path:\\n\", os.listdir(data_path))\nprint('\\n')\n\nforMyself = False\n    \n#絶対pathと相対pathについてコンペの度に忘れるのでメモしておく。\nif forMyself:\n    # current path\n    print(\"Name of currnt path:\\n\", os.getcwd())\n    print(\"File list of current path:\\n\", os.listdir(os.getcwd()))\n    print(\"File list of current path:\\n\", os.listdir('./')) #これは同じ階層\n    # １つ上の path\n    print('\\n')\n    print(os.listdir('/kaggle'))\n    print(os.listdir('../'))\n    # 最上位path\n    print(\"\\n\", os.listdir('/'))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:57:10.253086Z","iopub.execute_input":"2022-03-12T10:57:10.25335Z","iopub.status.idle":"2022-03-12T10:57:10.261081Z","shell.execute_reply.started":"2022-03-12T10:57:10.253322Z","shell.execute_reply":"2022-03-12T10:57:10.260165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### **Preperations**","metadata":{}},{"cell_type":"markdown","source":"* I transcribed the code from namaka's notebook and checked the operation of BERT.\n\n* namakaさんのノートブックからコードを転記してBERTの動作確認をおこないます。","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    model=\"bert-base-uncased\"\n    max_len=512\n    batch_size=12\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:57:10.266089Z","iopub.execute_input":"2022-03-12T10:57:10.266579Z","iopub.status.idle":"2022-03-12T10:57:10.271593Z","shell.execute_reply.started":"2022-03-12T10:57:10.266535Z","shell.execute_reply":"2022-03-12T10:57:10.27089Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Library\n# ====================================================\nimport gc\nimport random\nimport ast\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\n\nimport matplotlib.pyplot as plt\n\nfrom tqdm.auto import tqdm\n\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\nimport tokenizers\nimport transformers\nfrom transformers import AutoTokenizer, AutoModel, AutoConfig\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n#%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:57:10.274875Z","iopub.execute_input":"2022-03-12T10:57:10.27527Z","iopub.status.idle":"2022-03-12T10:57:17.002092Z","shell.execute_reply.started":"2022-03-12T10:57:10.27524Z","shell.execute_reply":"2022-03-12T10:57:17.001357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Utils\n# ====================================================\ndef seed_everything(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    \nseed_everything(seed=42)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:57:17.003164Z","iopub.execute_input":"2022-03-12T10:57:17.003377Z","iopub.status.idle":"2022-03-12T10:57:17.010973Z","shell.execute_reply.started":"2022-03-12T10:57:17.003352Z","shell.execute_reply":"2022-03-12T10:57:17.010335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ====================================================\n# Data Loading\n# ====================================================\ntrain = pd.read_csv(os.path.join(data_path,'train.csv'))\nfeatures = pd.read_csv(os.path.join(data_path,'features.csv'))\npatient_notes = pd.read_csv(os.path.join(data_path,'patient_notes.csv'))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:58:40.504198Z","iopub.execute_input":"2022-03-12T10:58:40.504986Z","iopub.status.idle":"2022-03-12T10:58:40.890355Z","shell.execute_reply.started":"2022-03-12T10:58:40.504947Z","shell.execute_reply":"2022-03-12T10:58:40.889497Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Change anotation and location to list.\n\n* annotationとlocationをリストに変換します。","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# Change anotation and location to list\n# ====================================================\nprint(f\"train.shape: {train.shape}\")\ndisplay(train.head()) #printと異なりデータフレームの表形式で表示\n\n#train\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval)\ntrain['location'] = train['location'].apply(ast.literal_eval)\n\nprint(f\"train.shape: {train.shape}\")\ndisplay(train.head()) #printと異なりデータフレームの表形式で表示","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:58:43.385507Z","iopub.execute_input":"2022-03-12T10:58:43.385767Z","iopub.status.idle":"2022-03-12T10:58:43.837046Z","shell.execute_reply.started":"2022-03-12T10:58:43.38574Z","shell.execute_reply":"2022-03-12T10:58:43.836325Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(features, on = ['feature_num', 'case_num'], how = 'left')\ntrain = train.merge(patient_notes, on = ['pn_num', 'case_num'], how = 'left')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:58:52.490873Z","iopub.execute_input":"2022-03-12T10:58:52.491138Z","iopub.status.idle":"2022-03-12T10:58:52.518481Z","shell.execute_reply.started":"2022-03-12T10:58:52.491107Z","shell.execute_reply":"2022-03-12T10:58:52.517829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Count the number of elements in the annotarion.\n>  \n* anotationの要素数をカウントする列をつくります。","metadata":{}},{"cell_type":"code","source":"train['annotation_length'] = train['annotation'].apply(len)\n#anotationの文字数ではなく要素数。\ntrain[train['annotation_length']==2][0:3]","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:58:55.224757Z","iopub.execute_input":"2022-03-12T10:58:55.225122Z","iopub.status.idle":"2022-03-12T10:58:55.251926Z","shell.execute_reply.started":"2022-03-12T10:58:55.225095Z","shell.execute_reply":"2022-03-12T10:58:55.25105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## **Tokenizer**","metadata":{}},{"cell_type":"markdown","source":"* Define tokenizer.\n>  \n* tokenizerを定義します。AutoTokenizerでモデルを選べばやってくれるようです。","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# tokenizer\n# ====================================================\ntokenizer = AutoTokenizer.from_pretrained(CFG.model)\nCFG.tokenizer = tokenizer","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:57:46.525151Z","iopub.execute_input":"2022-03-12T10:57:46.525433Z","iopub.status.idle":"2022-03-12T10:57:52.371199Z","shell.execute_reply.started":"2022-03-12T10:57:46.525402Z","shell.execute_reply":"2022-03-12T10:57:52.370477Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Outputs of tokenizer\n* Check the tokenizer output.\n* Special_token is CLS at the beginning of the sentence and SEP at the end of the sentence.To tokenize the 'pn_history' and 'feature_text', SEP is used twice.  \n* ##tokens represent a connection to the previous lexicon.  \n>  \n* tokenizerの出力をチェックします。\n* Special_tokenはCLSと文末のSEP。'pn_history'と'feature_text'をtokenizeするため、SEPは2回はいります。\n* ##トークンは、前の語彙との繋がりを表します。","metadata":{}},{"cell_type":"code","source":"text1 = train['pn_history'][0]\ntext2 = 'This is a feature text.'\nprint(\"Text1:\\n\",text1, \"\\nText2:\\n\",text2)\nprint(\"#\"*100)\ntokenized_text = tokenizer.tokenize(text1, text2, add_special_tokens=True)\nprint(\"Tokenized:\\n\", tokenized_text)\nprint(\"#\"*100)\nprint(\"Encoded:\\n\", tokenizer.encode(text1))\nprint(\"#\"*100)\n\n#special tokens\ns1 = tokenizer.all_special_ids\nprint(\"Special tokens:\")\nfor s in s1:\n    print(f'{s} --> {tokenizer.decode(s)}')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:59:00.037241Z","iopub.execute_input":"2022-03-12T10:59:00.037967Z","iopub.status.idle":"2022-03-12T10:59:00.889239Z","shell.execute_reply.started":"2022-03-12T10:59:00.037927Z","shell.execute_reply":"2022-03-12T10:59:00.888579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Operation tests\n* Text can be entered in pairs (pn_history and feature_text). Sentence connections can be analyzed. \n* Output is in dictionary format.  \n* attention_mask corresponds to input_id, with 1 for meaningful tokens and 0 for padding.  \n* Token_type_id is set to 0 for the token position in the preceding text and 1 for the following text.\n* As for the numbers, interesting results.\n>  \n* textの入力はペアでも可能(pn_historyとfeature_text)。文のつながりを解析できます。 \n* 出力は辞書形式。  \n* attention_maskはinput_idに対応し、意味のあるトークンは1、パッディングは0となります。  \n* Token_type_id先行するテキストのトークン位置には0を、後続テキストには1がセットされます。\n* 数字については、おもしろい結果になりました。","metadata":{}},{"cell_type":"code","source":"text1 = \"This is a pen.\"\ntext2 = \"So, we must keep learning.\"\ntext3 = \"12345678 9 date is 20220314\"\ntokenizer_output = tokenizer(text1, text2, add_special_tokens=True)\nprint(\"tokenizer output with special_tokens:\\n\", tokenizer_output)\n\ntokenizer_output2 = tokenizer(text3, add_special_tokens=True)\nprint(\"\\ntokenizer output2:\\n\", tokenizer_output2)\n\nprint(\"\\n\")\nfor i in tokenizer_output2['input_ids']:\n    print(tokenizer.decode(i))","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:59:09.459796Z","iopub.execute_input":"2022-03-12T10:59:09.4602Z","iopub.status.idle":"2022-03-12T10:59:09.466565Z","shell.execute_reply.started":"2022-03-12T10:59:09.46017Z","shell.execute_reply":"2022-03-12T10:59:09.465779Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* sequence_ids() has special_token = None, first sentence = 0, next sentence = 1. Note that padding is also special_token and therefore None.\n>  \n* sequence_ids()はspecial_token = None、最初の文章 = 0、次の文章 = 1 となります。文章だけを識別します。paddingもspecial_tokenなのでNoneとなることに注意。","metadata":{}},{"cell_type":"code","source":"print(tokenizer_output.items())\n\nseq = tokenizer_output.sequence_ids()\nprint(\"Sequence ids:\\n\", seq)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:59:14.009902Z","iopub.execute_input":"2022-03-12T10:59:14.010695Z","iopub.status.idle":"2022-03-12T10:59:14.015962Z","shell.execute_reply.started":"2022-03-12T10:59:14.010654Z","shell.execute_reply":"2022-03-12T10:59:14.015252Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Padding is the number 0 of the special token. \n* The token is aligned with the number of elements specified by max_length.\n* return_offsets_mapping = True would return a tuple indicating the positional relationship between the token and the original sentence. specilal_token is now (0,0).\n>  \n* パッディングはスペシャルトークンの0番です。 \n* max_lengthで指定するした要素数にtokenをそろえます。\n* return_offsets_mapping = True とするとトークンともとの文章の位置関係を示す、タプルを返します。specilal_tokenは(0,0)となりました。","metadata":{}},{"cell_type":"code","source":"#lenは文字数でなくてtoken数であることに注意！\ntext1_len = len(tokenizer.encode(text1, add_special_tokens = False))\ntext2_len = len(tokenizer.encode(text2, add_special_tokens = False))\n\nmax_len = text1_len + text2_len + 10\n\ntokenizer_output = tokenizer(text1, text2, \n                             add_special_tokens = True,\n                             max_length = max_len,\n                             padding= \"max_length\",\n                             return_offsets_mapping = True)\nprint(\"tokenizer output with padding:\\n\", tokenizer_output)\nprint(f'tokens:\\n {tokenizer.decode(tokenizer_output[\"input_ids\"])}')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T10:59:49.238259Z","iopub.execute_input":"2022-03-12T10:59:49.238843Z","iopub.status.idle":"2022-03-12T10:59:49.246602Z","shell.execute_reply.started":"2022-03-12T10:59:49.238803Z","shell.execute_reply":"2022-03-12T10:59:49.245896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Equalize the number of tokens\n* Extract the maximum number of characters for each pn_history and feature_text. Match the number of characters.\n>  \n* 学習にそなえて、pn_historyとfeature_textそれぞれについて最大文字数を抽出します。その文字数にそろえます。  \n* special_token=Falseでエンコードし、実際はCLSが1回、SEPが2回はいるので最大数は3足します。","metadata":{}},{"cell_type":"code","source":"# nakama's code\n# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n# ====================================================\n# Define max_len\n# ====================================================\nprint(patient_notes['pn_history'].isnull().sum())\nprint(features['feature_text'].isnull().sum())\n\nfor text_col in ['pn_history']:\n    pn_history_lengths = []\n    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes))\n    for text in tk0:\n        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])#カルテの語数\n        pn_history_lengths.append(length)\n    #LOGGER.info(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n\nfor text_col in ['feature_text']:\n    features_lengths = []\n    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n    for text in tk0:\n        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n        features_lengths.append(length)\n    #LOGGER.info(f'{text_col} max(lengths): {max(features_lengths)}')\n\nCFG.max_len = max(pn_history_lengths) + max(features_lengths) + 3\n# cls & sep & sep\n\nprint(CFG.max_len)\n# model=\"microsoft/deberta-base\" -> 466 モデルによって最大文字数は異なる。","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:00:00.164251Z","iopub.execute_input":"2022-03-12T11:00:00.16471Z","iopub.status.idle":"2022-03-12T11:00:29.834235Z","shell.execute_reply.started":"2022-03-12T11:00:00.164662Z","shell.execute_reply":"2022-03-12T11:00:29.83336Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"いちおうグラフ化","metadata":{}},{"cell_type":"code","source":"fig = plt.figure(figsize=(8, 3))\nfig.add_subplot(121)\nplt.hist(pn_history_lengths)\nfig.add_subplot(122)\nplt.hist(features_lengths)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:00:32.284259Z","iopub.execute_input":"2022-03-12T11:00:32.284561Z","iopub.status.idle":"2022-03-12T11:00:32.849106Z","shell.execute_reply.started":"2022-03-12T11:00:32.284525Z","shell.execute_reply":"2022-03-12T11:00:32.848371Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Inputs and lebels","metadata":{}},{"cell_type":"markdown","source":"* Define inputs to the model.\n\n* モデルへの入力を定義します。","metadata":{}},{"cell_type":"code","source":"# nakama's code\n# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n#\ndef prepare_input(cfg, text, feature_text):\n    inputs = cfg.tokenizer(text, feature_text, \n                           add_special_tokens=True,\n                           max_length=CFG.max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long) #torch.longに変換\n    return inputs\n\n\ndef create_label(cfg, text, annotation_length, location_list):\n    encoded = cfg.tokenizer(text,\n                            add_special_tokens=True,\n                            max_length=CFG.max_len,\n                            padding=\"max_length\",\n                            return_offsets_mapping=True)\n    offset_mapping = encoded['offset_mapping']\n    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n    label = np.zeros(len(offset_mapping))\n    label[ignore_idxes] = -1\n    if annotation_length != 0:\n        for location in location_list:\n            for loc in [s.split() for s in location.split(';')]:\n                start_idx = -1\n                end_idx = -1\n                start, end = int(loc[0]), int(loc[1])\n                for idx in range(len(offset_mapping)):\n                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                        start_idx = idx - 1\n                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                        end_idx = idx + 1\n                if start_idx == -1:\n                    start_idx = end_idx\n                if (start_idx != -1) & (end_idx != -1):\n                    label[start_idx:end_idx] = 1\n    return torch.tensor(label, dtype=torch.float)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:00:36.128409Z","iopub.execute_input":"2022-03-12T11:00:36.128703Z","iopub.status.idle":"2022-03-12T11:00:36.141492Z","shell.execute_reply.started":"2022-03-12T11:00:36.128672Z","shell.execute_reply":"2022-03-12T11:00:36.140674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* inputs are tokens of pn_history and feature_text. The number of tokens (not the number of characters) is padded to be the same.\n* label is calculated from annotation/location/offset_mapping and the description part about feature_text in pn_history is set to 1.\n>  \n* inputsはpn_historyとfeature_textのトークン。トークンの数（文字数ではない）はパディングして同じにしてあります。\n* label は annotation/location/offsets_mappingから算出され、pn_history のfeture_textに関する記述部分を1と設定されます。","metadata":{}},{"cell_type":"code","source":"text =train['pn_history'][0]\nfeature_text = train['feature_text'][0]\n\ninputs = prepare_input(CFG, text, feature_text)\nprint(inputs.keys())","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:00:41.255162Z","iopub.execute_input":"2022-03-12T11:00:41.255442Z","iopub.status.idle":"2022-03-12T11:00:41.268035Z","shell.execute_reply.started":"2022-03-12T11:00:41.25541Z","shell.execute_reply":"2022-03-12T11:00:41.267171Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* inputs are defined as torch.long\n>  \n* inputsは学習のため、torch.longとして定義します。","metadata":{}},{"cell_type":"code","source":"for k, v in inputs.items():\n    print(k, \"\\n\", v[0:10],\".....\", v.dtype)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:00:46.697493Z","iopub.execute_input":"2022-03-12T11:00:46.698144Z","iopub.status.idle":"2022-03-12T11:00:46.731838Z","shell.execute_reply.started":"2022-03-12T11:00:46.698093Z","shell.execute_reply":"2022-03-12T11:00:46.731234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"text = train['pn_history'][0]\nannotation_length = train['annotation_length'][0]\nlocation_list = train['location'][0]\ntrain['annotation']\nlabel = create_label(CFG, text, annotation_length, location_list)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:00:50.260061Z","iopub.execute_input":"2022-03-12T11:00:50.260762Z","iopub.status.idle":"2022-03-12T11:00:50.277273Z","shell.execute_reply.started":"2022-03-12T11:00:50.260725Z","shell.execute_reply":"2022-03-12T11:00:50.276661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Check the meaning of label.\n>  \n* labelの中身を確認してみます。\n* ラベルは、return_offsets_mapping=True を使用して作成します。","metadata":{}},{"cell_type":"code","source":"print(\"annotation location: \", location_list)\nprint(f'location{location_list} is --> {text[696:724]}')\n\nprint(f'\\nlabel = 1: {np.where(label == 1)}')\ntokenized_text = tokenizer.tokenize(text, add_special_tokens=True)\nprint(f'tokenized_text[181:187]: {tokenized_text[181:187]}')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:00:53.288057Z","iopub.execute_input":"2022-03-12T11:00:53.288713Z","iopub.status.idle":"2022-03-12T11:00:53.304322Z","shell.execute_reply.started":"2022-03-12T11:00:53.288668Z","shell.execute_reply":"2022-03-12T11:00:53.303382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"markdown","source":"* Define a dataset, passing inputs and lebel to the dataloader.\n>  \n* データセットを定義します。inputsとlebelをローダーにわたします。","metadata":{}},{"cell_type":"code","source":"# nakama's code\n# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n#\nclass TrainDataset(Dataset):\n    def __init__(self, cfg, df):\n        self.cfg = cfg\n        self.feature_texts = df['feature_text'].values\n        self.pn_historys = df['pn_history'].values\n        self.annotation_lengths = df['annotation_length'].values\n        self.locations = df['location'].values\n\n    def __len__(self):\n        return len(self.feature_texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.cfg, \n                               self.pn_historys[item], \n                               self.feature_texts[item])\n        label = create_label(self.cfg, \n                             self.pn_historys[item], \n                             self.annotation_lengths[item], \n                             self.locations[item])\n        return inputs, label","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:01:00.390731Z","iopub.execute_input":"2022-03-12T11:01:00.391226Z","iopub.status.idle":"2022-03-12T11:01:00.399105Z","shell.execute_reply.started":"2022-03-12T11:01:00.391191Z","shell.execute_reply":"2022-03-12T11:01:00.398208Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model","metadata":{}},{"cell_type":"markdown","source":"* Let's look at the structure of the model.\n>  \n* モデルの構造をみてみます。torchsummaryXをインストールします。","metadata":{}},{"cell_type":"code","source":"pip install -q torchsummaryX","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:01:06.253164Z","iopub.execute_input":"2022-03-12T11:01:06.253463Z","iopub.status.idle":"2022-03-12T11:01:16.68993Z","shell.execute_reply.started":"2022-03-12T11:01:06.253418Z","shell.execute_reply":"2022-03-12T11:01:16.688993Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchsummaryX import summary","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:01:18.702582Z","iopub.execute_input":"2022-03-12T11:01:18.702891Z","iopub.status.idle":"2022-03-12T11:01:18.710812Z","shell.execute_reply.started":"2022-03-12T11:01:18.702859Z","shell.execute_reply":"2022-03-12T11:01:18.709932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* Defines the model, using the pre-trained specified in AutoConfig, AutoModel.\n* output_hidden_states=True to get the output for encoder layers including the final layer. Normally, only the final layer is used, so the outputs of the other layers are used for accuracy improvement studies after the baseline study.\n>  \n* モデルを定義します。AutoConfig, AutoModelで指定したpretrainedを使用したモデルが定義されます。\n* output_hidden_states=True で最終層を含めたencoder層の出力が取得されます。通常は最終層のみになりますので、ベースライン検討後の精度改善検討時に他の層の出力を使用します。","metadata":{}},{"cell_type":"code","source":"config = AutoConfig.from_pretrained(CFG.model)\nconfig.update({\"output_hidden_states\": True})\nmodel = AutoModel.from_pretrained(CFG.model, config = config)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:01:20.744327Z","iopub.execute_input":"2022-03-12T11:01:20.744672Z","iopub.status.idle":"2022-03-12T11:01:34.864875Z","shell.execute_reply.started":"2022-03-12T11:01:20.744642Z","shell.execute_reply":"2022-03-12T11:01:34.863922Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.config","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:01:38.46027Z","iopub.execute_input":"2022-03-12T11:01:38.460599Z","iopub.status.idle":"2022-03-12T11:01:38.467727Z","shell.execute_reply.started":"2022-03-12T11:01:38.460565Z","shell.execute_reply":"2022-03-12T11:01:38.466912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"s = summary(model, torch.zeros((1, CFG.max_len), dtype=torch.long))","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-03-12T11:08:11.14786Z","iopub.execute_input":"2022-03-12T11:08:11.149202Z","iopub.status.idle":"2022-03-12T11:08:12.176413Z","shell.execute_reply.started":"2022-03-12T11:08:11.149126Z","shell.execute_reply":"2022-03-12T11:08:12.1756Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* encoder.layers0 - 12 (transformers) are displayed.\n\n* encoder.layer0 ～ 12(transformers) が表示される。","metadata":{}},{"cell_type":"code","source":"display(s)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:08:26.09968Z","iopub.execute_input":"2022-03-12T11:08:26.100272Z","iopub.status.idle":"2022-03-12T11:08:26.224069Z","shell.execute_reply.started":"2022-03-12T11:08:26.10023Z","shell.execute_reply":"2022-03-12T11:08:26.22351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Try out the output of the model","metadata":{}},{"cell_type":"markdown","source":"* Check the output of the model.\n\n* モデルの出力を確認しましょう。ミニバッチサイズは1にしました。","metadata":{}},{"cell_type":"code","source":"# ====================================================\n# CV split\n# ====================================================\nFold = GroupKFold(n_splits=CFG.n_fold)\ngroups = train['pn_num'].values\nfor n, (train_index, val_index) in enumerate(\n    Fold.split(train, train['location'], groups)):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:11:00.258645Z","iopub.execute_input":"2022-03-12T11:11:00.258953Z","iopub.status.idle":"2022-03-12T11:11:00.280847Z","shell.execute_reply.started":"2022-03-12T11:11:00.258921Z","shell.execute_reply":"2022-03-12T11:11:00.279999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 0\nCFG.batch_size = 1\n\nfolds = train.copy()\n\ntrain_folds = folds[folds['fold'] != fold].reset_index(drop=True)\ntrain_dataset = TrainDataset(CFG, train_folds)\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=CFG.batch_size,\n                          shuffle = False,#動作確認用\n                          num_workers=0, pin_memory=True, drop_last=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:11:31.40756Z","iopub.execute_input":"2022-03-12T11:11:31.408429Z","iopub.status.idle":"2022-03-12T11:11:31.423951Z","shell.execute_reply.started":"2022-03-12T11:11:31.408389Z","shell.execute_reply":"2022-03-12T11:11:31.4234Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#trainローダの中身\nbatch_iterator = iter(train_loader)\ninputs, label = next(batch_iterator)\nprint(inputs.keys())\nprint(label.size())","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:11:44.565914Z","iopub.execute_input":"2022-03-12T11:11:44.566516Z","iopub.status.idle":"2022-03-12T11:11:44.586251Z","shell.execute_reply.started":"2022-03-12T11:11:44.566466Z","shell.execute_reply":"2022-03-12T11:11:44.585449Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = model(**inputs)","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:11:47.768977Z","iopub.execute_input":"2022-03-12T11:11:47.769343Z","iopub.status.idle":"2022-03-12T11:11:49.085508Z","shell.execute_reply.started":"2022-03-12T11:11:47.769289Z","shell.execute_reply":"2022-03-12T11:11:49.084539Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"* By specifying output_hidden_states=True, hidden_states other than the last layer could be extracted.\n>  \n* output_hidden_states=True を指定することにより 最終層以外のhidden_statesも取り出せました。","metadata":{}},{"cell_type":"code","source":"print(f'BERT model output: {y.keys()}')\nprint(f'max_len = {CFG.max_len}')\nprint(f'last_hidden_state --> {y[\"last_hidden_state\"].size()}')\nprint(f'pooler_output     --> {y[\"pooler_output\"].size()}')\nprint(f'hidden_states     --> {len(y[\"hidden_states\"])}')\n\nfor i in range(len(y[\"hidden_states\"])):\n    print(f'hidden_states-{i}     --> {y[\"hidden_states\"][i].size()}')","metadata":{"execution":{"iopub.status.busy":"2022-03-12T11:11:56.785303Z","iopub.execute_input":"2022-03-12T11:11:56.785638Z","iopub.status.idle":"2022-03-12T11:11:56.794407Z","shell.execute_reply.started":"2022-03-12T11:11:56.785603Z","shell.execute_reply":"2022-03-12T11:11:56.793081Z"},"trusted":true},"execution_count":null,"outputs":[]}]}