{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Required Libraries ","metadata":{}},{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nprint(pd.__version__)\npd.options.display.max_columns = 300\npd.options.display.max_colwidth = 200\npd.options.display.min_rows = 200\npd.options.display.max_rows = 500\n\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport matplotlib.pyplot as plt\nimport ast\nimport os\nfrom difflib import get_close_matches\n\nimport os\nimport spacy.displacy\nimport pandas as pd\nimport seaborn as sns\nimport json\nimport warnings\nfrom IPython.core.display import display, HTML\n\nDATA_ROOT = os.path.join(\n    '..', 'input', 'nbme-score-clinical-patient-notes')\n\nTRAIN_PATH = os.path.join(DATA_ROOT, 'train.csv')\nTEST_PATH = os.path.join(DATA_ROOT, 'test.csv')\nFEATURE_PATH = os.path.join(DATA_ROOT, 'features.csv')\nPATIENT_NOTES_PATH = os.path.join(DATA_ROOT, 'patient_notes.csv')\n\ntrain = pd.read_csv(TRAIN_PATH)\ntest = pd.read_csv(TEST_PATH)\nfeatures = pd.read_csv(FEATURE_PATH)\npatient_notes = pd.read_csv(PATIENT_NOTES_PATH)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-24T01:37:32.627654Z","iopub.execute_input":"2022-03-24T01:37:32.628112Z","iopub.status.idle":"2022-03-24T01:37:43.701668Z","shell.execute_reply.started":"2022-03-24T01:37:32.628025Z","shell.execute_reply":"2022-03-24T01:37:43.700661Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/train.csv\")                    \nnotes = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv\")\nfeatures = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/features.csv\")\ntest = pd.read_csv(\"/kaggle/input/nbme-score-clinical-patient-notes/test.csv\")\n\nprint(\"Length of Train and Notes \",len(train), len(notes))\ntrain_merged = pd.merge(train, notes, \n                        on = [\"case_num\", \"pn_num\"], \n                        how = \"inner\")\ntrain_merged = pd.merge(train_merged, features[[\"feature_num\",\"feature_text\"]], \n                        on = [\"feature_num\"], \n                        how = \"left\")\nprint(len(train_merged))\ntrain_merged.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:37:43.703464Z","iopub.execute_input":"2022-03-24T01:37:43.70377Z","iopub.status.idle":"2022-03-24T01:37:44.158764Z","shell.execute_reply.started":"2022-03-24T01:37:43.703719Z","shell.execute_reply":"2022-03-24T01:37:44.157921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:25.062908Z","iopub.execute_input":"2022-03-24T01:38:25.063225Z","iopub.status.idle":"2022-03-24T01:38:25.074502Z","shell.execute_reply.started":"2022-03-24T01:38:25.063194Z","shell.execute_reply":"2022-03-24T01:38:25.073502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Find Unique cases, pn numbers, features numbers, cases with & without annotations","metadata":{}},{"cell_type":"code","source":"print(f\"Unique case num: {train_merged.case_num.nunique()}\")\nprint(f\"Unique pn num: {train_merged.pn_num.nunique()}\")\nprint(f\"Unique feature num: {train_merged.feature_num.nunique()}\")\nprint(f\"Cases with annotation: {train_merged.location[train_merged.location != '[]'].shape[0]}\")\nprint(f\"Cases without annotation: {train_merged.location[train_merged.location == '[]'].shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:27.101333Z","iopub.execute_input":"2022-03-24T01:38:27.10219Z","iopub.status.idle":"2022-03-24T01:38:27.118479Z","shell.execute_reply.started":"2022-03-24T01:38:27.102131Z","shell.execute_reply":"2022-03-24T01:38:27.117357Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_merged['find_f_txt_pn'] = train_merged.apply(lambda x: [el for el in x[\"feature_text\"].lower().replace(\"-\",\" \").split(\" or \") if el in x[\"pn_history\"].lower()], axis=1)\n\ntrain_merged[train_merged.location == '[]'][['feature_text','find_f_txt_pn']]\\\n    .explode('find_f_txt_pn')\\\n    .groupby(['feature_text','find_f_txt_pn']).size()\\\n    .reset_index().set_axis(['feature_text','find_f_txt_pn','cnt'],axis='columns')\\\n    .sort_values(['cnt'],ascending=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:27.839753Z","iopub.execute_input":"2022-03-24T01:38:27.840028Z","iopub.status.idle":"2022-03-24T01:38:28.22077Z","shell.execute_reply.started":"2022-03-24T01:38:27.839999Z","shell.execute_reply":"2022-03-24T01:38:28.219908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def annotate_sample(note_num):\n    note_num = int(note_num)\n    warnings.filterwarnings('ignore')\n    patient_df = train[train[\"pn_num\"] == note_num].copy()\n    patient_df = patient_df.merge(features[['feature_num', 'feature_text']], on='feature_num')\n    # WK: location should be a list of str, which some \";\" should be handled and turned to \",\"\n    patient_df[\"location\"] = patient_df[\"location\"].str.replace(\"'\", '\"').str.replace(';', '\",\"').apply(json.loads)  # WK: list of str,    annotation = patient_df[\"feature_text\"]\n    annotation = patient_df[\"feature_text\"]\n    ents = []\n    for idx, row in patient_df.iterrows():\n        spans = row['location']\n        label = row['feature_text']\n        for span in spans:\n            start_loc = span.split()[0]\n            end_loc = span.split()[1]\n            ents.append({\n                'start': int(start_loc),\n                'end': int(end_loc),\n                'label': label\n            })\n    doc = {\n        'text': patient_notes[patient_notes[\"pn_num\"] == note_num][\"pn_history\"].iloc[0],\n        \"ents\": ents\n    }\n    p1 = sns.color_palette('hls', annotation.nunique(), desat=1).as_hex()\n    p2 = sns.color_palette('hls', annotation.nunique(), desat=0.5).as_hex()\n    colors = {k: f\"linear-gradient(90deg, {c1}, {c2})\" for k, c1, c2 in zip(annotation.unique(), p1, p2)}\n    options = {\"colors\": colors}\n    spacy.displacy.render(doc, style=\"ent\", options=options, manual=True, jupyter=True)\nfrom ipywidgets import interact, interactive, fixed, interact_manual\nimport ipywidgets as widgets\ncase_numbers = list(map(str, patient_notes['case_num'].unique()))\ncase_num_selector = widgets.Dropdown(\n    options=case_numbers,\n    value=case_numbers[0],\n    description='Case No:',\n)\n\ndef update_note_selector():\n    note_numbers = list(\n        map(\n            str, \n            train[train['case_num'] == int(case_num_selector.value)]['pn_num'].unique()))\n\n    note_num_selector = widgets.Dropdown(\n        options=note_numbers,\n        value=note_numbers[0],\n        description='Note No:',\n    )\n\n    return note_num_selector\n\nnote_num_selector = update_note_selector()\n\ndef on_case_no_change(change):\n    if change['type'] == 'change' and change['name'] == 'value':\n        print(\"changed to %s\" % change['new'])\n        note_numbers = list(\n            map(\n                str, \n                train[train['case_num'] == int(case_num_selector.value)]['pn_num'].unique()))\n        note_num_selector.options=note_numbers\n        note_num_selector.value=note_numbers[0]\n\n\n        \ndef on_change(change):\n    if change['type'] == 'change' and change['name'] == 'value':\n        print(\"changed to %s\" % change['new'])\n\n        \n\n        \ncase_num_selector.observe(on_case_no_change)\nnote_num_selector.observe(on_change)\n\ndisplay(case_num_selector)\ndisplay(note_num_selector)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:28.532934Z","iopub.execute_input":"2022-03-24T01:38:28.533218Z","iopub.status.idle":"2022-03-24T01:38:28.575633Z","shell.execute_reply.started":"2022-03-24T01:38:28.533181Z","shell.execute_reply":"2022-03-24T01:38:28.575042Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"annotate_sample(note_num_selector.value)","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:29.681689Z","iopub.execute_input":"2022-03-24T01:38:29.682057Z","iopub.status.idle":"2022-03-24T01:38:29.700726Z","shell.execute_reply.started":"2022-03-24T01:38:29.682017Z","shell.execute_reply":"2022-03-24T01:38:29.699593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Number of cases for each feature_text in train data","metadata":{}},{"cell_type":"code","source":"train_merged\\\n    .groupby('feature_text').agg({'id':['count']})\\\n    .reset_index().set_axis(['feature_text','count'],axis='columns')\\\n    .sort_values('count',ascending=True)\\\n    .plot(kind='barh',figsize=(12,24),\n          x='feature_text', \n          y='count', \n          title ='count of feature_text')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:35.852603Z","iopub.execute_input":"2022-03-24T01:38:35.853135Z","iopub.status.idle":"2022-03-24T01:38:39.050511Z","shell.execute_reply.started":"2022-03-24T01:38:35.853088Z","shell.execute_reply":"2022-03-24T01:38:39.049667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_merged[['feature_text','annotation']]\\\n         .query(\"annotation != '[]'\")\\\n         .assign(annotation = lambda x: [[''] if e == '[]' else ast.literal_eval(e) for e in x['annotation']])\\\n         .explode('annotation')\\\n         .assign(annotation = lambda x: x['annotation'].str.lower())\\\n         .groupby(['feature_text','annotation']).size()\\\n         .reset_index()\\\n         .set_axis(['feature_text','annotation', 'cnt'], axis='columns')\\\n         .assign(rnk = lambda x: x.groupby('feature_text').cnt.transform('rank',method='max', ascending=False))\\\n         .sort_values(['feature_text','cnt'], ascending=[True, False])\\\n         .query(\"rnk<6\")\\\n         .groupby(\"feature_text\").agg({\"annotation\":lambda x: list(x),\n                                       \"cnt\":lambda x: list(x)})\\\n         .reset_index()\\\n         .set_axis(['feature_text','top 5 annotation','top 5 annotation cnt'], \n                   axis='columns')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:39.052553Z","iopub.execute_input":"2022-03-24T01:38:39.052859Z","iopub.status.idle":"2022-03-24T01:38:39.324791Z","shell.execute_reply.started":"2022-03-24T01:38:39.052817Z","shell.execute_reply":"2022-03-24T01:38:39.323974Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count of feature_text in train data\ntrain_merged.assign(no_ann = lambda x: x['location'] == '[]' )\\\n    .groupby('feature_text').agg({'no_ann':['count',lambda z:100*np.mean(z)]})\\\n    .reset_index().set_axis(['feature_text','count','no_ann_pct'],axis='columns')\\\n    .sort_values('no_ann_pct',ascending=True)\\\n    .plot(kind='barh',figsize=(12,24),\n          x='feature_text', \n          y='no_ann_pct', \n          title ='% missing annotations across feature_text',\n          color='red')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:39.325897Z","iopub.execute_input":"2022-03-24T01:38:39.326156Z","iopub.status.idle":"2022-03-24T01:38:42.425745Z","shell.execute_reply.started":"2022-03-24T01:38:39.326127Z","shell.execute_reply":"2022-03-24T01:38:42.425153Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_merged_split_words = \\\ntrain_merged[['feature_text','annotation']]\\\n         .query(\"annotation != '[]'\")\\\n         .assign(annotation = lambda x: [[''] if e == '[]' else ast.literal_eval(e) for e in x['annotation']])\\\n         .explode('annotation')\\\n         .assign(annotation = lambda x: [str(y).lower().split() for y in x['annotation']])\\\n         .explode('annotation')\\\n         .groupby(['feature_text','annotation']).size()\\\n         .reset_index()\\\n         .set_axis(['feature_text','annotation', 'cnt'], axis='columns')\\\n         .assign(rnk = lambda x: x.groupby('feature_text').cnt.transform('rank',method='max', ascending=False))\\\n         .sort_values(['feature_text','cnt'], ascending=[True, False])\n\ntrain_merged_split_words.query(\"rnk<6\")\\\n         .groupby(\"feature_text\").agg({\"annotation\":lambda x: list(x),\n                                       \"cnt\":lambda x: list(x)})\\\n         .reset_index()\\\n         .set_axis(['feature_text','top 5 annotation','top 5 annotation cnt'], \n                   axis='columns')","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:42.427449Z","iopub.execute_input":"2022-03-24T01:38:42.427837Z","iopub.status.idle":"2022-03-24T01:38:42.940733Z","shell.execute_reply.started":"2022-03-24T01:38:42.427808Z","shell.execute_reply":"2022-03-24T01:38:42.939805Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_close_matches_(lst):\n    similar_lst = []\n    while len(lst) > 1:\n        ref_word = lst[0]\n        lst = lst[1:]\n        matches = get_close_matches(ref_word, lst, cutoff = 0.75)\n        if len(matches) > 0:\n            similar_lst.append( matches+[ref_word] )\n            lst = list(set(lst) - set(matches))\n    return similar_lst\n\n#get_close_matches_(['ape', 'apple', 'peach', 'puppy','appl'])","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:42.942186Z","iopub.execute_input":"2022-03-24T01:38:42.94248Z","iopub.status.idle":"2022-03-24T01:38:42.949845Z","shell.execute_reply.started":"2022-03-24T01:38:42.942442Z","shell.execute_reply":"2022-03-24T01:38:42.948915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_merged_split_words\\\n    .groupby(\"feature_text\")\\\n    .apply(lambda x: list(x[\"annotation\"]))\\\n    .reset_index()\\\n    .set_axis(['feature_text','annotation words'], axis='columns')\\\n    .assign(similar_wrds = lambda x: [get_close_matches_(x_) for x_ in x['annotation words']])\\\n    [['feature_text','similar_wrds']]\\\n    .explode('similar_wrds')\\\n    .assign(len_ = lambda x: [len(x_) if isinstance(x_, list) else 0 for x_ in x['similar_wrds']])\\\n    .sort_values('len_',ascending=False)[['feature_text','similar_wrds']]","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:42.951112Z","iopub.execute_input":"2022-03-24T01:38:42.951429Z","iopub.status.idle":"2022-03-24T01:38:43.61001Z","shell.execute_reply.started":"2022-03-24T01:38:42.951397Z","shell.execute_reply":"2022-03-24T01:38:43.609007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport os, re, ast, glob, itertools, spacy, transformers, torch\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\n\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n\nDATA_PATH = \"../input/nbme-score-clinical-patient-notes/\"\nOUT_PATH = \"../input/nbme-roberta-large/\"\nWEIGHTS_FOLDER = \"../input/nbme-roberta-large/\"","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:43.611195Z","iopub.execute_input":"2022-03-24T01:38:43.61141Z","iopub.status.idle":"2022-03-24T01:38:44.074821Z","shell.execute_reply.started":"2022-03-24T01:38:43.611383Z","shell.execute_reply":"2022-03-24T01:38:44.074021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"raw","source":"","metadata":{}},{"cell_type":"markdown","source":"# Prepration","metadata":{}},{"cell_type":"code","source":"\n\ndef process_feature_text(text):\n    text = re.sub('I-year', '1-year', text)\n    text = re.sub('-OR-', \" or \", text)\n    text = re.sub('-', ' ', text)\n    return text\n\ndef clean_spaces(text):\n    text = re.sub('\\n', ' ', text)\n    text = re.sub('\\t', ' ', text)\n    text = re.sub('\\r', ' ', text)\n    return text\n\ndef load_and_prepare_test(root=\"\"):\n    patient_notes = pd.read_csv(root + \"patient_notes.csv\")\n    features = pd.read_csv(root + \"features.csv\")\n    df = pd.read_csv(root + \"test.csv\")\n\n    df = df.merge(features, how=\"left\", on=[\"case_num\", \"feature_num\"])\n    df = df.merge(patient_notes, how=\"left\", on=[\"case_num\", \"pn_num\"])\n\n    df[\"pn_history\"] = df[\"pn_history\"].apply(lambda x: x.strip())\n    df[\"feature_text\"] = df[\"feature_text\"].apply(process_feature_text)\n    df[\"feature_text\"] = df[\"feature_text\"].apply(clean_spaces)\n    df[\"clean_text\"] = df[\"pn_history\"].apply(clean_spaces)\n    df[\"target\"] = \"\"\n    return df","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:44.076939Z","iopub.execute_input":"2022-03-24T01:38:44.077303Z","iopub.status.idle":"2022-03-24T01:38:44.089358Z","shell.execute_reply.started":"2022-03-24T01:38:44.077246Z","shell.execute_reply":"2022-03-24T01:38:44.088329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"\n\ndef token_pred_to_char_pred(token_pred, offsets):\n    char_pred = np.zeros((np.max(offsets), token_pred.shape[1]))\n    for i in range(len(token_pred)):\n        s, e = int(offsets[i][0]), int(offsets[i][1])\n        char_pred[s:e] = token_pred[i]\n        if token_pred.shape[1] == 3:\n            s += 1\n            char_pred[s: e, 1], char_pred[s: e, 2] = (np.max(char_pred[s: e, 1:], 1), np.min(char_pred[s: e, 1:], 1),)\n    return char_pred\n\ndef labels_to_sub(labels):\n    all_spans = []\n    for label in labels:\n        indices = np.where(label > 0)[0]\n        indices_grouped = [list(g) for _, g in itertools.groupby(indices, key=lambda n, c=itertools.count(): n - next(c))]\n        spans = [f\"{min(r)} {max(r) + 1}\" for r in indices_grouped]\n        all_spans.append(\";\".join(spans))\n    return all_spans\n\ndef char_target_to_span(char_target):\n    spans = []\n    start, end = 0, 0\n    for i in range(len(char_target)):\n        if char_target[i] == 1 and char_target[i - 1] == 0:\n            if end:\n                spans.append([start, end])\n            start = i\n            end = i + 1\n        elif char_target[i] == 1:\n            end = i + 1\n        else:\n            if end:\n                spans.append([start, end])\n            start, end = 0, 0\n    return spans\n\ndef post_process_spaces(target, text):\n    target = np.copy(target)\n\n    if len(text) > len(target):\n        padding = np.zeros(len(text) - len(target))\n        target = np.concatenate([target, padding])\n    else:\n        target = target[:len(text)]\n\n    if text[0] == \" \":\n        target[0] = 0\n    if text[-1] == \" \":\n        target[-1] = 0\n\n    for i in range(1, len(text) - 1):\n        if text[i] == \" \":\n            if target[i] and not target[i - 1]:\n                target[i] = 0\n\n            if target[i] and not target[i + 1]:\n                target[i] = 0\n\n            if target[i - 1] and target[i + 1]:\n                target[i] = 1\n    return target\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:44.091053Z","iopub.execute_input":"2022-03-24T01:38:44.092032Z","iopub.status.idle":"2022-03-24T01:38:44.113537Z","shell.execute_reply.started":"2022-03-24T01:38:44.091955Z","shell.execute_reply":"2022-03-24T01:38:44.11266Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Tokenization ","metadata":{}},{"cell_type":"code","source":"\n\ndef get_tokenizer(name, precompute=False, df=None, folder=None):\n    if folder is None:\n        tokenizer = AutoTokenizer.from_pretrained(name)\n    else:\n        tokenizer = AutoTokenizer.from_pretrained(folder)\n\n    tokenizer.name = name\n\n    tokenizer.special_tokens = {\n        \"sep\": tokenizer.sep_token_id,\n        \"cls\": tokenizer.cls_token_id,\n        \"pad\": tokenizer.pad_token_id,\n    }\n\n    if precompute:\n        tokenizer.precomputed = precompute_tokens(df, tokenizer)\n    else:\n        tokenizer.precomputed=None\n        \n    return tokenizer\n\ndef precompute_tokens(df, tokenizer):\n    feature_texts = df[\"feature_text\"].unique()\n    ids = {}\n    offsets = {}\n\n    for feature_text in feature_texts:\n        encoding = tokenizer(\n            feature_text,\n            return_token_type_ids=True,\n            return_offsets_mapping=True,\n            return_attention_mask=False,\n            add_special_tokens=False,\n        )\n        ids[feature_text] = encoding[\"input_ids\"]\n        offsets[feature_text] = encoding[\"offset_mapping\"]\n\n    texts = df[\"clean_text\"].unique()\n\n    for text in texts:\n        encoding = tokenizer(\n            text,\n            return_token_type_ids=True,\n            return_offsets_mapping=True,\n            return_attention_mask=False,\n            add_special_tokens=False,\n        )\n\n        ids[text] = encoding[\"input_ids\"]\n        offsets[text] = encoding[\"offset_mapping\"]\n        \n    return {\"ids\": ids, \"offsets\": offsets}\n\ndef encodings_from_precomputed(feature_text, text, precomputed, tokenizer, max_len=300):\n    tokens = tokenizer.special_tokens\n\n    if \"roberta\" in tokenizer.name:\n        qa_sep = [tokens[\"sep\"], tokens[\"sep\"]]\n    else:\n        qa_sep = [tokens[\"sep\"]]\n\n    input_ids = [tokens[\"cls\"]] + precomputed[\"ids\"][feature_text] + qa_sep\n    n_question_tokens = len(input_ids)\n\n    input_ids += precomputed[\"ids\"][text]\n    input_ids = input_ids[: max_len - 1] + [tokens[\"sep\"]]\n\n    if \"roberta\" not in tokenizer.name:\n        token_type_ids = np.ones(len(input_ids))\n        token_type_ids[:n_question_tokens] = 0\n        token_type_ids = token_type_ids.tolist()\n    else:\n        token_type_ids = [0] * len(input_ids)\n\n    offsets = [(0, 0)] * n_question_tokens + precomputed[\"offsets\"][text]\n    offsets = offsets[: max_len - 1] + [(0, 0)]\n\n    padding_length = max_len - len(input_ids)\n    if padding_length > 0:\n        input_ids = input_ids + ([tokens[\"pad\"]] * padding_length)\n        token_type_ids = token_type_ids + ([0] * padding_length)\n        offsets = offsets + ([(0, 0)] * padding_length)\n\n    encoding = {\n        \"input_ids\": input_ids,\n        \"token_type_ids\": token_type_ids,\n        \"offset_mapping\": offsets,\n    }\n\n    return encoding","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:44.11604Z","iopub.execute_input":"2022-03-24T01:38:44.116362Z","iopub.status.idle":"2022-03-24T01:38:44.1356Z","shell.execute_reply.started":"2022-03-24T01:38:44.116307Z","shell.execute_reply":"2022-03-24T01:38:44.134906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# torch Dataset","metadata":{}},{"cell_type":"code","source":"\n\nclass PatientNoteDataset(Dataset):\n    def __init__(self, df, tokenizer, max_len):\n        self.df = df\n        self.max_len = max_len\n        self.tokenizer = tokenizer\n        self.texts = df['clean_text'].values\n        self.feature_text = df['feature_text'].values\n        self.char_targets = df['target'].values.tolist()\n\n    def __getitem__(self, idx):\n        text = self.texts[idx]\n        feature_text = self.feature_text[idx]\n        char_target = self.char_targets[idx]\n\n        if self.tokenizer.precomputed is None:\n            encoding = self.tokenizer(\n                feature_text, text,\n                return_token_type_ids=True,\n                return_offsets_mapping=True,\n                return_attention_mask=False,\n                truncation=\"only_second\",\n                max_length=self.max_len,\n                padding=\"max_length\",\n            )\n            raise NotImplementedError(\"Fix issues with question offsets.\")\n        else:\n            encoding = encodings_from_precomputed(feature_text, text, self.tokenizer.precomputed, self.tokenizer, max_len=self.max_len)\n\n        return {\n            \"ids\": torch.tensor(encoding[\"input_ids\"], dtype=torch.long),\n            \"token_type_ids\": torch.tensor(encoding[\"token_type_ids\"], dtype=torch.long),\n            \"target\": torch.tensor([0], dtype=torch.float),\n            \"offsets\": np.array(encoding[\"offset_mapping\"]),\n            \"text\": text,\n        }\n\n    def __len__(self):\n        return len(self.texts)\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:44.137014Z","iopub.execute_input":"2022-03-24T01:38:44.137759Z","iopub.status.idle":"2022-03-24T01:38:44.152026Z","shell.execute_reply.started":"2022-03-24T01:38:44.137723Z","shell.execute_reply":"2022-03-24T01:38:44.151137Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plot Predictions","metadata":{}},{"cell_type":"code","source":"\n\ndef plot_annotation(df, pn_num):\n    options = {\"colors\": {}}\n\n    df_text = df[df[\"pn_num\"] == pn_num].reset_index(drop=True)\n\n    text = df_text[\"pn_history\"][0]\n    ents = []\n\n    for spans, feature_text, feature_num in df_text[[\"span\", \"feature_text\", \"feature_num\"]].values:\n        for s in spans:\n            ents.append({\"start\": int(s[0]), \"end\": int(s[1]), \"label\": feature_text})\n\n        options[\"colors\"][feature_text] =  f\"rgb{tuple(np.random.randint(100, 255, size=3))}\"\n\n    doc = {\"text\": text, \"ents\": sorted(ents, key=lambda i: i[\"start\"])}\n    \n    # spacy.displacy.render(doc, style=\"ent\", options=options, manual=True, jupyter=True)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:44.153068Z","iopub.execute_input":"2022-03-24T01:38:44.153668Z","iopub.status.idle":"2022-03-24T01:38:44.168676Z","shell.execute_reply.started":"2022-03-24T01:38:44.153637Z","shell.execute_reply":"2022-03-24T01:38:44.167644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Development","metadata":{}},{"cell_type":"code","source":"\n\nclass NERTransformer(nn.Module):\n    def __init__(self, model, num_classes=1, config_file=None, pretrained=True):\n        super().__init__()\n        self.name = model\n        self.pad_idx = 1 if \"roberta\" in self.name else 0\n\n        transformers.logging.set_verbosity_error()\n\n        if config_file is None:\n            config = AutoConfig.from_pretrained(model, output_hidden_states=True)\n        else:\n            config = torch.load(config_file)\n\n        if pretrained:\n            self.transformer = AutoModel.from_pretrained(model, config=config)\n        else:\n            self.transformer = AutoModel.from_config(config)\n\n        self.nb_features = config.hidden_size\n\n        self.logits = nn.Linear(self.nb_features, num_classes)\n\n    def forward(self, tokens, token_type_ids):\n        hidden_states = self.transformer(tokens, attention_mask=(tokens != self.pad_idx).long(), token_type_ids=token_type_ids)[-1]\n\n        features = hidden_states[-1]\n\n        logits = self.logits(features)\n\n        return logits\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:44.170447Z","iopub.execute_input":"2022-03-24T01:38:44.171116Z","iopub.status.idle":"2022-03-24T01:38:44.185397Z","shell.execute_reply.started":"2022-03-24T01:38:44.171069Z","shell.execute_reply":"2022-03-24T01:38:44.184525Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Weights","metadata":{}},{"cell_type":"code","source":"\n\ndef load_model_weights(model, filename, verbose=1, cp_folder=\"\", strict=True):\n    if verbose:\n        print(f\"\\n -> Loading weights from {os.path.join(cp_folder,filename)}\\n\")\n    try:\n        model.load_state_dict(torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\"), strict=strict)\n    except RuntimeError:\n        model.encoder.fc = torch.nn.Linear(model.nb_ft, 1)\n        model.load_state_dict(torch.load(os.path.join(cp_folder, filename), map_location=\"cpu\"), strict=strict)\n    return model\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:44.903794Z","iopub.execute_input":"2022-03-24T01:38:44.904121Z","iopub.status.idle":"2022-03-24T01:38:44.911222Z","shell.execute_reply.started":"2022-03-24T01:38:44.904073Z","shell.execute_reply":"2022-03-24T01:38:44.910402Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict Function","metadata":{}},{"cell_type":"code","source":"\n\ndef predict(model, dataset, data_config, activation=\"softmax\"):\n    model.eval()\n    loader = DataLoader(dataset, batch_size=data_config[\"val_bs\"], shuffle=False, num_workers=2, pin_memory=True)\n    preds = []\n    with torch.no_grad():\n        for data in tqdm(loader):\n            ids, token_type_ids = data[\"ids\"], data[\"token_type_ids\"]\n            y_pred = model(ids.cuda(), token_type_ids.cuda())\n            if activation == \"sigmoid\":\n                y_pred = y_pred.sigmoid()\n            elif activation == \"softmax\":\n                y_pred = y_pred.softmax(-1)\n            preds += [token_pred_to_char_pred(y, offsets) for y, offsets in zip(y_pred.detach().cpu().numpy(), data[\"offsets\"].numpy())]\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:45.448267Z","iopub.execute_input":"2022-03-24T01:38:45.448524Z","iopub.status.idle":"2022-03-24T01:38:45.457369Z","shell.execute_reply.started":"2022-03-24T01:38:45.448496Z","shell.execute_reply":"2022-03-24T01:38:45.456351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference Test","metadata":{}},{"cell_type":"code","source":"\n\ndef inference_test(df, exp_folder, config, cfg_folder=None):\n    preds = []\n\n    if cfg_folder is not None:\n        model_config_file = cfg_folder + config.name.split('/')[-1] + \"/config.pth\"\n        tokenizer_folder = cfg_folder + config.name.split('/')[-1] + \"/tokenizers/\"\n    else:\n        model_config_file, tokenizer_folder = None, None\n\n    tokenizer = get_tokenizer(config.name, precompute=config.precompute_tokens, df=df, folder=tokenizer_folder)\n    dataset = PatientNoteDataset(df, tokenizer, max_len=config.max_len)\n    model = NERTransformer(config.name, num_classes=config.num_classes, config_file=model_config_file, pretrained=False).cuda()\n    model.zero_grad()\n\n    weights = sorted(glob.glob(exp_folder + \"*.pt\"))\n\n    for weight in weights:\n        model = load_model_weights(model, weight)\n        pred = predict(model, dataset, data_config=config.data_config, activation=config.loss_config[\"activation\"])\n        preds.append(pred)\n    return preds","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:46.067613Z","iopub.execute_input":"2022-03-24T01:38:46.067878Z","iopub.status.idle":"2022-03-24T01:38:46.077399Z","shell.execute_reply.started":"2022-03-24T01:38:46.06785Z","shell.execute_reply":"2022-03-24T01:38:46.076798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Main Code","metadata":{}},{"cell_type":"code","source":"\n\n\n# if __name__ == \"__main__\":\n#     class Config:\n#         # Architecture.\n#         name = \"roberta-large\"\n#         num_classes = 1\n#         # Texts.\n#         max_len = 310\n#         precompute_tokens = True\n#         # Training.\n#         loss_config = {\"activation\": \"sigmoid\"}\n#         data_config = {\"val_bs\": 16 if \"large\" in name else 32, \"pad_token\": 1 if \"roberta\" in name else 0}\n#         verbose = 1\n\n#     df_test = load_and_prepare_test(root=DATA_PATH)\n\n#     preds = inference_test(df_test, WEIGHTS_FOLDER, Config, cfg_folder=OUT_PATH)[0]\n\n#     df_test[\"preds\"] = preds\n#     df_test[\"preds\"] = df_test.apply(lambda x: x[\"preds\"][:len(x[\"clean_text\"])], 1)\n#     df_test[\"preds\"] = df_test[\"preds\"].apply(lambda x: (x > 0.5).flatten())\n\n#     try:\n#         df_test[\"span\"] = df_test[\"preds\"].apply(char_target_to_span)\n#         plot_annotation(df_test, df_test[\"pn_num\"][0])\n#     except:\n#         pass\n\n#     df_test[\"preds_pp\"] = df_test.apply(lambda x: post_process_spaces(x[\"preds\"], x[\"clean_text\"]), 1)\n\n#     try:\n#         df_test[\"span\"] = df_test[\"preds_pp\"].apply(char_target_to_span)\n#         plot_annotation(df_test, df_test[\"pn_num\"][0])\n#     except:\n#         pass\n\n#     # Kaggle Submission.\n#     df_test['location'] = labels_to_sub(df_test[\"preds_pp\"].values)\n\n#     sub = pd.read_csv(DATA_PATH + \"sample_submission.csv\")\n\n#     sub = sub[[\"id\"]].merge(df_test[[\"id\", \"location\"]], how=\"left\", on=\"id\")\n\n#     sub.to_csv(\"submission.csv\", index=False)\n\n#     sub.head()\n","metadata":{"execution":{"iopub.status.busy":"2022-03-24T01:38:46.806926Z","iopub.execute_input":"2022-03-24T01:38:46.80721Z","iopub.status.idle":"2022-03-24T01:38:53.94894Z","shell.execute_reply.started":"2022-03-24T01:38:46.807181Z","shell.execute_reply":"2022-03-24T01:38:53.947969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:42:50.234961Z","iopub.execute_input":"2022-03-22T17:42:50.235234Z","iopub.status.idle":"2022-03-22T17:42:50.69323Z","shell.execute_reply.started":"2022-03-22T17:42:50.235204Z","shell.execute_reply":"2022-03-22T17:42:50.69229Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:42:50.752343Z","iopub.execute_input":"2022-03-22T17:42:50.752682Z","iopub.status.idle":"2022-03-22T17:42:50.789173Z","shell.execute_reply.started":"2022-03-22T17:42:50.752642Z","shell.execute_reply":"2022-03-22T17:42:50.7886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2022-03-22T17:42:51.089088Z","iopub.execute_input":"2022-03-22T17:42:51.089808Z","iopub.status.idle":"2022-03-22T17:42:51.107671Z","shell.execute_reply.started":"2022-03-22T17:42:51.089769Z","shell.execute_reply":"2022-03-22T17:42:51.106885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}