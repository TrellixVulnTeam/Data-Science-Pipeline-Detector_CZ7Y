{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-05T16:23:07.53211Z","iopub.execute_input":"2022-04-05T16:23:07.53253Z","iopub.status.idle":"2022-04-05T16:23:07.572517Z","shell.execute_reply.started":"2022-04-05T16:23:07.53243Z","shell.execute_reply":"2022-04-05T16:23:07.571319Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**import libraries**","metadata":{}},{"cell_type":"code","source":"import gc\nimport json\nimport math\nimport string\nimport pickle\nimport warnings\nimport spacy\nimport random\nimport itertools\nwarnings.filterwarnings(\"ignore\")\n\npd.set_option('display.max_rows',20)\npd.set_option('display.max_columns',500)\npd.set_option('display.width',1000)\n\nfrom sklearn.metrics import f1_score\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import AdamW\nfrom torch.utils.data import DataLoader,Dataset\nfrom sklearn.model_selection import train_test_split\nimport tokenizers \nimport transformers\nimport tensorflow as tf\nimport tensorflow_addons as tfa\nfrom transformers import models\nfrom transformers import AutoTokenizer, AutoConfig, TFAutoModel\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:07.875747Z","iopub.execute_input":"2022-04-05T16:23:07.876195Z","iopub.status.idle":"2022-04-05T16:23:23.251373Z","shell.execute_reply.started":"2022-04-05T16:23:07.876162Z","shell.execute_reply":"2022-04-05T16:23:23.250396Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Load Data**","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')\ntest=pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/test.csv')\nfeatures=pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\npatient_notes=pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\nsample_submission=pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:23.253637Z","iopub.execute_input":"2022-04-05T16:23:23.255316Z","iopub.status.idle":"2022-04-05T16:23:23.93592Z","shell.execute_reply.started":"2022-04-05T16:23:23.255266Z","shell.execute_reply":"2022-04-05T16:23:23.934846Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**config**","metadata":{}},{"cell_type":"code","source":"# ---------- Model ---------- \nMODEL_NAME = 'microsoft/deberta-base'\nTOKENIZER_PATH = \"microsoft/deberta-base_tokenizer\"\nMAX_LEN = 512\n\n# ---------- Training ----------\nBATCH_SIZE = 8\nEPOCHS = 10\nLEARNING_RATE = 2e-5\nCLIP_NORM = 1000\n\n# ---------- Dataset ----------\nseed=42\nn_fold=5\ntrn_fold=[0, 1, 2, 3, 4]\n\ndebug=False\n\nif debug:\n    EPOCHS = 5\n    trn_fold = [0]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:23.937344Z","iopub.execute_input":"2022-04-05T16:23:23.93764Z","iopub.status.idle":"2022-04-05T16:23:23.945476Z","shell.execute_reply.started":"2022-04-05T16:23:23.937584Z","shell.execute_reply":"2022-04-05T16:23:23.944347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Helper functions for scoring","metadata":{}},{"cell_type":"code","source":"import ast\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval) # Construct an object from a string\ntrain['location'] = train['location'].apply(ast.literal_eval) # Construct an object from a string\nprint(f\"train.shape: {train.shape}\")\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:23.948384Z","iopub.execute_input":"2022-04-05T16:23:23.949011Z","iopub.status.idle":"2022-04-05T16:23:24.480964Z","shell.execute_reply.started":"2022-04-05T16:23:23.948963Z","shell.execute_reply":"2022-04-05T16:23:24.479675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.483086Z","iopub.execute_input":"2022-04-05T16:23:24.483817Z","iopub.status.idle":"2022-04-05T16:23:24.498873Z","shell.execute_reply.started":"2022-04-05T16:23:24.483771Z","shell.execute_reply":"2022-04-05T16:23:24.496487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.500338Z","iopub.execute_input":"2022-04-05T16:23:24.500587Z","iopub.status.idle":"2022-04-05T16:23:24.515607Z","shell.execute_reply.started":"2022-04-05T16:23:24.500533Z","shell.execute_reply":"2022-04-05T16:23:24.51441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"patient_notes.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.516803Z","iopub.execute_input":"2022-04-05T16:23:24.517059Z","iopub.status.idle":"2022-04-05T16:23:24.529339Z","shell.execute_reply.started":"2022-04-05T16:23:24.516996Z","shell.execute_reply":"2022-04-05T16:23:24.528092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Merging**","metadata":{}},{"cell_type":"code","source":"train=train.merge(features,on=['feature_num','case_num'],how='left')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.531434Z","iopub.execute_input":"2022-04-05T16:23:24.531764Z","iopub.status.idle":"2022-04-05T16:23:24.571341Z","shell.execute_reply.started":"2022-04-05T16:23:24.531719Z","shell.execute_reply":"2022-04-05T16:23:24.570093Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=train.merge(patient_notes,on=['case_num','pn_num'],how='left')\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.572811Z","iopub.execute_input":"2022-04-05T16:23:24.573218Z","iopub.status.idle":"2022-04-05T16:23:24.612673Z","shell.execute_reply.started":"2022-04-05T16:23:24.573176Z","shell.execute_reply":"2022-04-05T16:23:24.611677Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['annotation_length'] = train['annotation'].apply(len)\ntrain.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.617088Z","iopub.execute_input":"2022-04-05T16:23:24.617843Z","iopub.status.idle":"2022-04-05T16:23:24.649158Z","shell.execute_reply.started":"2022-04-05T16:23:24.617794Z","shell.execute_reply":"2022-04-05T16:23:24.648073Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pn_history'][5910]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.651252Z","iopub.execute_input":"2022-04-05T16:23:24.65157Z","iopub.status.idle":"2022-04-05T16:23:24.66453Z","shell.execute_reply.started":"2022-04-05T16:23:24.651526Z","shell.execute_reply":"2022-04-05T16:23:24.663335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idx=5910\n\nlocations = train.loc[idx,'location']\npn_history= train.loc[idx,'pn_history']\n\nstart_pos = []\nend_pos = []\nfor location in locations:\n    for loc in [s.split() for s in location.split(';')]:\n        start_pos.append(int(loc[0]))\n        end_pos.append(int(loc[1]))\n\n\nents = []\nfor i in range(len(start_pos)):\n    ents.append({\n        'start': int(start_pos[i]), \n        'end' : int(end_pos[i]),\n        \"label\" : \"Annotation\"\n    })\ndoc = {\n    'text' : pn_history,\n    \"ents\" : ents\n}\n\ncolors = {\"Annotation\": \"linear-gradient(0deg, #888, #eeaaaa)\"} \noptions = {\"colors\": colors}\nspacy.displacy.render(doc, style=\"ent\", options=options , manual=True, jupyter=True);","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.66631Z","iopub.execute_input":"2022-04-05T16:23:24.66655Z","iopub.status.idle":"2022-04-05T16:23:24.682321Z","shell.execute_reply.started":"2022-04-05T16:23:24.66652Z","shell.execute_reply":"2022-04-05T16:23:24.681048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"locations","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.684399Z","iopub.execute_input":"2022-04-05T16:23:24.685054Z","iopub.status.idle":"2022-04-05T16:23:24.698963Z","shell.execute_reply.started":"2022-04-05T16:23:24.684984Z","shell.execute_reply":"2022-04-05T16:23:24.697797Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train,test=train_test_split(train[['pn_history','feature_text','annotation_length','location']],\n                           test_size=0.2,\n                           random_state=seed)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.700505Z","iopub.execute_input":"2022-04-05T16:23:24.701047Z","iopub.status.idle":"2022-04-05T16:23:24.718848Z","shell.execute_reply.started":"2022-04-05T16:23:24.700978Z","shell.execute_reply":"2022-04-05T16:23:24.717769Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.720848Z","iopub.execute_input":"2022-04-05T16:23:24.721477Z","iopub.status.idle":"2022-04-05T16:23:24.738214Z","shell.execute_reply.started":"2022-04-05T16:23:24.721431Z","shell.execute_reply":"2022-04-05T16:23:24.737284Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['feature_text'][1]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.739965Z","iopub.execute_input":"2022-04-05T16:23:24.740522Z","iopub.status.idle":"2022-04-05T16:23:24.749687Z","shell.execute_reply.started":"2022-04-05T16:23:24.740478Z","shell.execute_reply":"2022-04-05T16:23:24.748433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['pn_history'][1]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.7519Z","iopub.execute_input":"2022-04-05T16:23:24.754889Z","iopub.status.idle":"2022-04-05T16:23:24.762555Z","shell.execute_reply.started":"2022-04-05T16:23:24.75484Z","shell.execute_reply":"2022-04-05T16:23:24.761342Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\ntokenizer.save_pretrained(f'{TOKENIZER_PATH}')\n\nconfig = AutoConfig.from_pretrained(MODEL_NAME)\nconfig.save_pretrained(f'{TOKENIZER_PATH}')","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:24.764857Z","iopub.execute_input":"2022-04-05T16:23:24.765503Z","iopub.status.idle":"2022-04-05T16:23:33.277043Z","shell.execute_reply.started":"2022-04-05T16:23:24.765459Z","shell.execute_reply":"2022-04-05T16:23:33.27606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**preprocess the data**","metadata":{}},{"cell_type":"code","source":"# ------------------------- prepare_location ------------------------------\n\ndef prepare_location(locations: str):\n    \"\"\"\n    This function returns list of tuples of locations\n    \"\"\"\n    location_tuple_list = []\n    for location in locations:\n        for loc in [s.split() for s in location.split(';')]:\n            start, end = int(loc[0]), int(loc[1])\n            location_tuple_list.append((start, end))\n    \n    return location_tuple_list\n# ------------------------- prepare_input ------------------------------\n\ndef prepare_input(pn_history: str, feature_text: str):\n    \"\"\"\n    This function tokenizes pn_history and feature text and\n    returns numpy array of input_ids and attention_masks\n    \"\"\"\n    tokens = tokenizer(\n        pn_history,\n        feature_text,\n        max_length=MAX_LEN,\n        padding=\"max_length\",\n        add_special_tokens=True,\n    )\n    \n    input_ids = tokens['input_ids']\n    attention_mask = tokens[\"attention_mask\"]\n    return (np.array(input_ids), np.array(attention_mask))\n\n# ------------------------- prepare_labels ------------------------------\n\ndef prepare_labels(pn_history, annotation_length, location_list):\n    \"\"\"\n    This function creates labels with are vectors of zeros (no entity)\n    and ones (entity)\n    \"\"\"\n    tokenized = tokenizer(\n        pn_history,\n        add_special_tokens=True,\n        max_length=MAX_LEN,\n        padding=\"max_length\",\n        return_offsets_mapping=True\n    )\n    offset_mapping = tokenized[\"offset_mapping\"]\n    label = np.zeros(len(offset_mapping))\n    if annotation_length != 0:\n        locations = prepare_location(location_list)\n        for location in locations:\n            start_idx, end_idx = -1, -1\n            start, end = location\n            for idx in range(len(offset_mapping)):\n                if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                    start_idx = idx - 1\n                if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                    end_idx = idx + 1\n            if start_idx == -1:\n                start_idx = end_idx\n            if (start_idx != -1) & (end_idx != -1):\n                label[start_idx:end_idx] = 1\n            \n    return np.array(label)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:33.278516Z","iopub.execute_input":"2022-04-05T16:23:33.278912Z","iopub.status.idle":"2022-04-05T16:23:33.296384Z","shell.execute_reply.started":"2022-04-05T16:23:33.278843Z","shell.execute_reply":"2022-04-05T16:23:33.295133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Dataset_generator(dataframe: pd.DataFrame):\n    def arg_generator():\n        pn_history = dataframe[\"pn_history\"].values\n        feature_text = dataframe[\"feature_text\"].values\n        annotation_length = dataframe['annotation_length'].values\n        location = dataframe['location'].values\n\n        for i in range(len(dataframe)):\n            inputs, masks = prepare_input(pn_history[i], feature_text[i])\n            labels = prepare_labels(pn_history[i], annotation_length[i], location[i])\n            yield (inputs, masks), labels\n    return arg_generator","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:33.298684Z","iopub.execute_input":"2022-04-05T16:23:33.299762Z","iopub.status.idle":"2022-04-05T16:23:33.311096Z","shell.execute_reply.started":"2022-04-05T16:23:33.299704Z","shell.execute_reply":"2022-04-05T16:23:33.310116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ds_training = tf.data.Dataset.from_generator(\n        Dataset_generator(train),\n        output_signature=(\n            (\n                tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"inputs\"),\n                tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"attention_masks\"),\n            ),\n            tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"labels\"),\n        )\n    )\nds_training = ds_training.batch(BATCH_SIZE)\n\nds_valid = tf.data.Dataset.from_generator(\n        Dataset_generator(test),\n        output_signature=(\n            (\n                tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"inputs\"),\n                tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"attention_masks\"),\n            ),\n            tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"labels\"),\n        )\n    )\n\nds_valid = ds_valid.batch(BATCH_SIZE)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:33.312613Z","iopub.execute_input":"2022-04-05T16:23:33.313698Z","iopub.status.idle":"2022-04-05T16:23:43.056802Z","shell.execute_reply.started":"2022-04-05T16:23:33.313653Z","shell.execute_reply":"2022-04-05T16:23:43.055856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_save= tf.keras.callbacks.ModelCheckpoint(\n    './model_deberta.h5', \n    save_best_only = True, \n    save_weights_only = False,\n    monitor = 'val_loss', \n    mode = 'min', verbose = 1\n)\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor='val_loss', \n    min_delta=1e-5, \n    patience=5, \n    verbose=1,\n    mode='auto', \n    restore_best_weights=True\n)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(\n    monitor='val_loss', \n    factor=0.5, \n    patience=2, \n    mode='auto', \n    min_delta=0.001,\n    verbose = 1\n)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:43.061766Z","iopub.execute_input":"2022-04-05T16:23:43.064416Z","iopub.status.idle":"2022-04-05T16:23:43.076053Z","shell.execute_reply.started":"2022-04-05T16:23:43.06437Z","shell.execute_reply":"2022-04-05T16:23:43.074739Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metrics\nclass F1Score(tf.keras.metrics.Metric):\n    def __init__(self, name='f1', **kwargs):\n        super(F1Score, self).__init__(name=name, **kwargs)\n        self.f1 = tfa.metrics.F1Score(num_classes=2, average='micro', threshold=0.50)\n\n    def update_state(self, y_true, y_pred, sample_weight=None):\n        y_true = tf.reshape(y_true, (-1,MAX_LEN))\n        y_pred = tf.reshape(y_pred, (-1,MAX_LEN))\n        self.f1.update_state(y_true, y_pred)\n        \n    def reset_state(self):\n        self.f1.reset_state()\n    \n    def result(self):\n        return self.f1.result()\n    \nmetrics = [\n    F1Score(), \n    tf.keras.metrics.Recall(thresholds=[0.5]), \n    tf.keras.metrics.Precision(thresholds=[0.5])\n]","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:43.082823Z","iopub.execute_input":"2022-04-05T16:23:43.085896Z","iopub.status.idle":"2022-04-05T16:23:43.154808Z","shell.execute_reply.started":"2022-04-05T16:23:43.085846Z","shell.execute_reply":"2022-04-05T16:23:43.153857Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_model():\n    input_tokens=tf.keras.layers.Input(shape=(MAX_LEN,),dtype=tf.int32)\n    attention_mask=tf.keras.layers.Input(shape=(MAX_LEN,),dtype=tf.int32)\n    \n    config=AutoConfig.from_pretrained(MODEL_NAME,output_hiddin_states=True)\n    backbone=TFAutoModel.from_pretrained(MODEL_NAME,config=config)\n    \n    out=backbone(input_tokens,attention_mask=attention_mask)[0]\n    out=tf.keras.layers.Dropout(0.2)(out)\n    out=tf.keras.layers.Dense(1,activation='sigmoid')(out)\n    \n    return tf.keras.Model(inputs=[input_tokens,attention_mask],outputs=out)\n\nmodel=create_model()\nmodel.summary()\noptimizer = tf.keras.optimizers.Adam(LEARNING_RATE, clipnorm=CLIP_NORM)\nloss = tf.keras.losses.BinaryCrossentropy(reduction=\"none\")\nmodel.compile(optimizer=optimizer,loss=loss,metrics=metrics)","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:23:43.158856Z","iopub.execute_input":"2022-04-05T16:23:43.160208Z","iopub.status.idle":"2022-04-05T16:24:19.445123Z","shell.execute_reply.started":"2022-04-05T16:23:43.160164Z","shell.execute_reply":"2022-04-05T16:24:19.443966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his=model.fit(ds_training,epochs=EPOCHS,validation_data=ds_valid,callbacks=[model_save,early_stop,reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T16:24:19.446963Z","iopub.execute_input":"2022-04-05T16:24:19.447325Z","iopub.status.idle":"2022-04-05T22:04:09.860434Z","shell.execute_reply.started":"2022-04-05T16:24:19.447252Z","shell.execute_reply":"2022-04-05T22:04:09.859354Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/nbme-score-clinical-patient-notes/test.csv')\ntest = test.merge(features, on=['feature_num', 'case_num'], how='left')\ntest = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:04:09.862295Z","iopub.execute_input":"2022-04-05T22:04:09.862841Z","iopub.status.idle":"2022-04-05T22:04:09.915825Z","shell.execute_reply.started":"2022-04-05T22:04:09.862795Z","shell.execute_reply":"2022-04-05T22:04:09.91481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"his=model.fit(ds_training,epochs=EPOCHS,validation_data=ds_valid,callbacks=[model_save,early_stop,reduce_lr])","metadata":{"execution":{"iopub.status.busy":"2022-04-05T22:04:09.917593Z","iopub.execute_input":"2022-04-05T22:04:09.917917Z","iopub.status.idle":"2022-04-06T01:49:40.138819Z","shell.execute_reply.started":"2022-04-05T22:04:09.917871Z","shell.execute_reply":"2022-04-06T01:49:40.137768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create the generator which yields inputs for test dataset\ndef Dataset_generator_test(dataframe: pd.DataFrame):\n    def arg_generator_test():\n        pn_history = dataframe[\"pn_history\"].values\n        feature_text = dataframe[\"feature_text\"].values\n        \n        for i in range(len(dataframe)):\n            inputs, masks = prepare_input(pn_history[i], feature_text[i])\n            labels = prepare_labels(pn_history[i], 0, '') # just to build BatchDataset  \n            yield (inputs, masks),labels\n    return arg_generator_test\n\n\n\nds_test = tf.data.Dataset.from_generator(\n        Dataset_generator_test(test),\n         output_signature=(\n                    (\n                        tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"inputs\"),\n                        tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"attention_masks\"),\n                    ),\n                    tf.TensorSpec(shape=(MAX_LEN,), dtype=tf.dtypes.int32, name=\"labels\"),\n                )\n            )\nds_test = ds_test.batch(BATCH_SIZE)\n\nidxx=0\nfor dst in ds_test.take(1):\n    inputs_masks,labels = dst # ignore labels\n    inputs_ids=inputs_masks[0]\n    attention_masks=inputs_masks[1]\n    print(\"inputs_ids shape=\",inputs_ids.shape)\n    print(\"-----------------------------------------------------------\")\n    print(\"attention_masks shape=\",attention_masks.shape)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T01:49:40.144184Z","iopub.execute_input":"2022-04-06T01:49:40.144945Z","iopub.status.idle":"2022-04-06T01:49:40.23064Z","shell.execute_reply.started":"2022-04-06T01:49:40.14489Z","shell.execute_reply":"2022-04-06T01:49:40.229707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Thanks yasufuminakama \n# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\n\ndef get_char_probs(texts, predictions, tokenizer):\n    results = [np.zeros(len(t)) for t in texts]\n    for i, (text, prediction) in enumerate(zip(texts, predictions)):\n        encoded = tokenizer(text, \n                            add_special_tokens=True,\n                            return_offsets_mapping=True)\n        for idx, (offset_mapping, pred) in enumerate(zip(encoded['offset_mapping'], prediction)):\n            start = offset_mapping[0]\n            end = offset_mapping[1]\n            results[i][start:end] = pred\n    return results\n\n\ndef get_results(char_probs, th=0.5):\n    results = []\n    for char_prob in char_probs:\n        result = np.where(char_prob >= th)[0] + 1\n        result = [list(g) for _, g in itertools.groupby(result, key=lambda n, c=itertools.count(): n - next(c))]\n        result = [f\"{min(r)} {max(r)}\" for r in result]\n        result = \";\".join(result)\n        results.append(result)\n    return results","metadata":{"execution":{"iopub.status.busy":"2022-04-06T01:49:40.232672Z","iopub.execute_input":"2022-04-06T01:49:40.232968Z","iopub.status.idle":"2022-04-06T01:49:40.245119Z","shell.execute_reply.started":"2022-04-06T01:49:40.232924Z","shell.execute_reply":"2022-04-06T01:49:40.243956Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict(ds_test)\npreds = preds.reshape(len(test), MAX_LEN)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T01:49:40.246308Z","iopub.execute_input":"2022-04-06T01:49:40.247312Z","iopub.status.idle":"2022-04-06T01:49:47.267572Z","shell.execute_reply.started":"2022-04-06T01:49:40.247242Z","shell.execute_reply":"2022-04-06T01:49:47.266585Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_probs = get_char_probs(test['pn_history'].values, preds, tokenizer)\nresults = get_results(char_probs, th=0.5)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T01:49:47.269129Z","iopub.execute_input":"2022-04-06T01:49:47.269435Z","iopub.status.idle":"2022-04-06T01:49:47.284834Z","shell.execute_reply.started":"2022-04-06T01:49:47.269395Z","shell.execute_reply":"2022-04-06T01:49:47.283499Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission = pd.read_csv('../input/nbme-score-clinical-patient-notes/sample_submission.csv')\nsubmission['location'] = results\ndisplay(submission.head())\nsubmission[['id', 'location']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-06T01:49:47.286414Z","iopub.execute_input":"2022-04-06T01:49:47.286905Z","iopub.status.idle":"2022-04-06T01:49:47.315351Z","shell.execute_reply.started":"2022-04-06T01:49:47.28686Z","shell.execute_reply":"2022-04-06T01:49:47.313059Z"},"trusted":true},"execution_count":null,"outputs":[]}]}