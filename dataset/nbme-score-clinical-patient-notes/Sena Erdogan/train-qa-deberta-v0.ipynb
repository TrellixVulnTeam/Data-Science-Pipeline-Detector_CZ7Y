{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\ntransformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n\ninput_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n\nconvert_file = input_dir / \"convert_slow_tokenizer.py\"\nconversion_path = transformers_path/convert_file.name\n\nif conversion_path.exists():\n    conversion_path.unlink()\n\nshutil.copy(convert_file, transformers_path)\ndeberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n\nfor filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n    if str(filename).startswith(\"deberta\"):\n        filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n    else:\n        filepath = deberta_v2_path/filename\n    if filepath.exists():\n        filepath.unlink()\n\n    shutil.copy(input_dir/filename, filepath)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:04.821831Z","iopub.execute_input":"2022-03-17T07:05:04.822479Z","iopub.status.idle":"2022-03-17T07:05:04.892915Z","shell.execute_reply.started":"2022-03-17T07:05:04.822376Z","shell.execute_reply":"2022-03-17T07:05:04.891854Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-17T07:05:04.895125Z","iopub.execute_input":"2022-03-17T07:05:04.895566Z","iopub.status.idle":"2022-03-17T07:05:04.918075Z","shell.execute_reply.started":"2022-03-17T07:05:04.895519Z","shell.execute_reply":"2022-03-17T07:05:04.916984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\nfrom tqdm import tqdm\nfrom transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoConfig","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:04.919662Z","iopub.execute_input":"2022-03-17T07:05:04.920349Z","iopub.status.idle":"2022-03-17T07:05:12.902425Z","shell.execute_reply.started":"2022-03-17T07:05:04.920304Z","shell.execute_reply":"2022-03-17T07:05:12.901505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\n# os.system('pip uninstall -y transformers')\n# os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:12.905372Z","iopub.execute_input":"2022-03-17T07:05:12.905691Z","iopub.status.idle":"2022-03-17T07:05:12.980675Z","shell.execute_reply.started":"2022-03-17T07:05:12.90565Z","shell.execute_reply":"2022-03-17T07:05:12.979636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from transformers.models.deberta_v2 import DebertaV2TokenizerFast\n\ntokenizer = DebertaV2TokenizerFast.from_pretrained(\"microsoft/deberta-v3-large\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:08:22.141176Z","iopub.execute_input":"2022-03-06T16:08:22.141953Z","iopub.status.idle":"2022-03-06T16:08:24.730002Z","shell.execute_reply.started":"2022-03-06T16:08:22.141909Z","shell.execute_reply":"2022-03-06T16:08:24.729153Z"}}},{"cell_type":"markdown","source":"!pip download transformers==4.16.2\n!pip download tokenizers==0.11.0","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:08:24.731214Z","iopub.execute_input":"2022-03-06T16:08:24.731764Z","iopub.status.idle":"2022-03-06T16:08:34.725527Z","shell.execute_reply.started":"2022-03-06T16:08:24.731724Z","shell.execute_reply":"2022-03-06T16:08:34.724575Z"}}},{"cell_type":"code","source":"train = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval)\ntrain['location'] = train['location'].apply(ast.literal_eval)\nfeatures = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\ndef preprocess_features(features):\n    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n    return features\nfeatures = preprocess_features(features)\npatient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nprint(f\"train.shape: {train.shape}\")\ndisplay(train.head())\nprint(f\"features.shape: {features.shape}\")\ndisplay(features.head())\nprint(f\"patient_notes.shape: {patient_notes.shape}\")\ndisplay(patient_notes.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:12.982197Z","iopub.execute_input":"2022-03-17T07:05:12.982466Z","iopub.status.idle":"2022-03-17T07:05:14.082235Z","shell.execute_reply.started":"2022-03-17T07:05:12.982426Z","shell.execute_reply":"2022-03-17T07:05:14.081165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(patient_notes.pn_history.unique())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.084016Z","iopub.execute_input":"2022-03-17T07:05:14.084541Z","iopub.status.idle":"2022-03-17T07:05:14.183145Z","shell.execute_reply.started":"2022-03-17T07:05:14.084494Z","shell.execute_reply":"2022-03-17T07:05:14.182169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train.pn_num.unique()))\nprint(len(patient_notes.pn_num.unique()))","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.184947Z","iopub.execute_input":"2022-03-17T07:05:14.185422Z","iopub.status.idle":"2022-03-17T07:05:14.196077Z","shell.execute_reply.started":"2022-03-17T07:05:14.185379Z","shell.execute_reply":"2022-03-17T07:05:14.194485Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(features, on=['feature_num', 'case_num'], how='left')\ntrain = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.197966Z","iopub.execute_input":"2022-03-17T07:05:14.198365Z","iopub.status.idle":"2022-03-17T07:05:14.24569Z","shell.execute_reply.started":"2022-03-17T07:05:14.198315Z","shell.execute_reply":"2022-03-17T07:05:14.244646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# incorrect annotation\ntrain.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\ntrain.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n\ntrain.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\ntrain.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n\ntrain.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\ntrain.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n\ntrain.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\ntrain.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n\ntrain.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\ntrain.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n\ntrain.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\ntrain.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n\ntrain.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\ntrain.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n\ntrain.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\ntrain.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n\ntrain.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\ntrain.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n\ntrain.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\ntrain.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n\ntrain.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\ntrain.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n\ntrain.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\ntrain.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n\ntrain.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\ntrain.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n\ntrain.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\ntrain.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n\ntrain.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\ntrain.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n\ntrain.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\ntrain.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n\ntrain.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\ntrain.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n\ntrain.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\ntrain.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n\ntrain.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\ntrain.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n\ntrain.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\ntrain.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n\ntrain.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\ntrain.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n\ntrain.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\ntrain.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n\ntrain.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\ntrain.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n\ntrain.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\ntrain.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n\ntrain.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\ntrain.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n\ntrain.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\ntrain.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n\ntrain.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\ntrain.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n\ntrain.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\ntrain.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n\ntrain.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\ntrain.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n\ntrain.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\ntrain.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n\ntrain.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\ntrain.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n\ntrain.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\ntrain.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n\ntrain.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\ntrain.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n\ntrain.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\ntrain.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n\ntrain.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\ntrain.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n\ntrain.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\ntrain.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n\ntrain.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\ntrain.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n\ntrain.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\ntrain.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n\ntrain.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\ntrain.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n\ntrain.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\ntrain.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n\ntrain.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\ntrain.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n\ntrain.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\ntrain.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.247569Z","iopub.execute_input":"2022-03-17T07:05:14.248105Z","iopub.status.idle":"2022-03-17T07:05:14.358613Z","shell.execute_reply.started":"2022-03-17T07:05:14.248063Z","shell.execute_reply":"2022-03-17T07:05:14.357674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['annotation_length'] = train['annotation'].apply(len)\ndisplay(train['annotation_length'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.363054Z","iopub.execute_input":"2022-03-17T07:05:14.363386Z","iopub.status.idle":"2022-03-17T07:05:14.381207Z","shell.execute_reply.started":"2022-03-17T07:05:14.363352Z","shell.execute_reply":"2022-03-17T07:05:14.37999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#annotation length'i fazla olanların seyreltebiliriz\n#train[train['annotation_length'] == 8].loc[10640]['annotation']","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.383064Z","iopub.execute_input":"2022-03-17T07:05:14.383888Z","iopub.status.idle":"2022-03-17T07:05:14.389693Z","shell.execute_reply.started":"2022-03-17T07:05:14.383841Z","shell.execute_reply":"2022-03-17T07:05:14.38824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train[train['annotation_length'] == 7].loc[6320]['annotation']","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.391575Z","iopub.execute_input":"2022-03-17T07:05:14.392653Z","iopub.status.idle":"2022-03-17T07:05:14.401078Z","shell.execute_reply.started":"2022-03-17T07:05:14.392524Z","shell.execute_reply":"2022-03-17T07:05:14.399959Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"for text_col in ['pn_history']:\n    pn_history_lengths = []\n    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes))\n    for text in tk0:\n        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n        pn_history_lengths.append(length)\n    print(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n\nfor text_col in ['feature_text']:\n    features_lengths = []\n    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n    for text in tk0:\n        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n        features_lengths.append(length)\n    print(f'{text_col} max(lengths): {max(features_lengths)}')\n    \nmax_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls & sep & sep","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:01:06.021246Z","iopub.execute_input":"2022-03-06T16:01:06.021843Z","iopub.status.idle":"2022-03-06T16:01:32.485716Z","shell.execute_reply.started":"2022-03-06T16:01:06.021805Z","shell.execute_reply":"2022-03-06T16:01:32.484934Z"}}},{"cell_type":"markdown","source":"max_len","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:01:32.487033Z","iopub.execute_input":"2022-03-06T16:01:32.487631Z","iopub.status.idle":"2022-03-06T16:01:32.493504Z","shell.execute_reply.started":"2022-03-06T16:01:32.487592Z","shell.execute_reply":"2022-03-06T16:01:32.492802Z"}}},{"cell_type":"code","source":"max_len=354","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.402718Z","iopub.execute_input":"2022-03-17T07:05:14.403264Z","iopub.status.idle":"2022-03-17T07:05:14.411729Z","shell.execute_reply.started":"2022-03-17T07:05:14.403219Z","shell.execute_reply":"2022-03-17T07:05:14.410586Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def prepare_input(tokenizer, max_len, text, feature_text):\n    inputs = tokenizer(text, feature_text, \n                           add_special_tokens=True,\n                           max_length=max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\ndef create_label(tokenizer, max_len,text, annotation_length, location_list):\n    encoded = tokenizer(text,\n                            add_special_tokens=True,\n                            max_length=max_len,\n                            padding=\"max_length\",\n                            return_offsets_mapping=True)\n    offset_mapping = encoded['offset_mapping']\n    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n    label = np.zeros(len(offset_mapping))\n    label[ignore_idxes] = -1\n    if annotation_length != 0:\n        for location in location_list:\n            for loc in [s.split() for s in location.split(';')]:\n                start_idx = -1\n                end_idx = -1\n                start, end = int(loc[0]), int(loc[1])\n                for idx in range(len(offset_mapping)):\n                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                        start_idx = idx - 1\n                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                        end_idx = idx + 1\n                if start_idx == -1:\n                    start_idx = end_idx\n                if (start_idx != -1) & (end_idx != -1):\n                    label[start_idx:end_idx] = 1\n    return torch.tensor(label, dtype=torch.float)\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, df):\n        self.feature_texts = df['feature_text'].values\n        self.pn_historys = df['pn_history'].values\n        self.annotation_lengths = df['annotation_length'].values\n        self.locations = df['location'].values\n\n    def __len__(self):\n        return len(self.feature_texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.pn_historys[item], \n                               self.feature_texts[item])\n        label = create_label(self.pn_historys[item], \n                             self.annotation_lengths[item], \n                             self.locations[item])\n        return inputs, label","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:42:46.392149Z","iopub.execute_input":"2022-03-06T14:42:46.392509Z","iopub.status.idle":"2022-03-06T14:42:46.411055Z","shell.execute_reply.started":"2022-03-06T14:42:46.392455Z","shell.execute_reply":"2022-03-06T14:42:46.410335Z"}}},{"cell_type":"markdown","source":"class CustomModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(\"microsoft/deberta-v3-large\", output_hidden_states=True)\n        self.model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/deberta-v3-large\")\n        self.fc_dropout = nn.Dropout(0.2)\n        self.fc = nn.Linear(self.config.hidden_size, 1)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        return last_hidden_states\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:42:46.412409Z","iopub.execute_input":"2022-03-06T14:42:46.412661Z","iopub.status.idle":"2022-03-06T14:42:46.42557Z","shell.execute_reply.started":"2022-03-06T14:42:46.412627Z","shell.execute_reply":"2022-03-06T14:42:46.424937Z"}}},{"cell_type":"code","source":"test_df = train.head(5).copy()\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.413614Z","iopub.execute_input":"2022-03-17T07:05:14.414053Z","iopub.status.idle":"2022-03-17T07:05:14.438877Z","shell.execute_reply.started":"2022-03-17T07:05:14.414005Z","shell.execute_reply":"2022-03-17T07:05:14.437975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all_full = train[train['annotation'].str.len() >= 1]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.440713Z","iopub.execute_input":"2022-03-17T07:05:14.441052Z","iopub.status.idle":"2022-03-17T07:05:14.464785Z","shell.execute_reply.started":"2022-03-17T07:05:14.441009Z","shell.execute_reply":"2022-03-17T07:05:14.463906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all_one_annotation = train[train['annotation_length'] == 1].copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.465781Z","iopub.execute_input":"2022-03-17T07:05:14.46601Z","iopub.status.idle":"2022-03-17T07:05:14.477178Z","shell.execute_reply.started":"2022-03-17T07:05:14.465982Z","shell.execute_reply":"2022-03-17T07:05:14.476143Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(train_all_full.shape)\nprint(train_all_one_annotation.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.478783Z","iopub.execute_input":"2022-03-17T07:05:14.479582Z","iopub.status.idle":"2022-03-17T07:05:14.488009Z","shell.execute_reply.started":"2022-03-17T07:05:14.479537Z","shell.execute_reply":"2022-03-17T07:05:14.486798Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(train_all_one_annotation, test_size=0.2, random_state=42)\ntrain_df.reset_index(inplace=True, drop=True)\nval_df.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.489684Z","iopub.execute_input":"2022-03-17T07:05:14.490239Z","iopub.status.idle":"2022-03-17T07:05:14.502564Z","shell.execute_reply.started":"2022-03-17T07:05:14.490194Z","shell.execute_reply":"2022-03-17T07:05:14.501588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model = CustomModel()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:42:46.463986Z","iopub.execute_input":"2022-03-06T14:42:46.464455Z","iopub.status.idle":"2022-03-06T14:43:17.209324Z","shell.execute_reply.started":"2022-03-06T14:42:46.464422Z","shell.execute_reply":"2022-03-06T14:43:17.208622Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":"train_dataset = TrainDataset(train_df)\nvalid_dataset = TrainDataset(val_df)\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=128,\n                          shuffle=True,\n                          num_workers=4, pin_memory=True, drop_last=True)\nvalid_loader = DataLoader(valid_dataset,\n                              batch_size=128,\n                              shuffle=False,\n                              num_workers=4, pin_memory=True, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T15:28:59.359519Z","iopub.execute_input":"2022-03-06T15:28:59.35999Z","iopub.status.idle":"2022-03-06T15:28:59.366473Z","shell.execute_reply.started":"2022-03-06T15:28:59.359955Z","shell.execute_reply":"2022-03-06T15:28:59.365559Z"}}},{"cell_type":"markdown","source":"from transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:43:17.220212Z","iopub.execute_input":"2022-03-06T14:43:17.220557Z","iopub.status.idle":"2022-03-06T14:43:17.234951Z","shell.execute_reply.started":"2022-03-06T14:43:17.220509Z","shell.execute_reply":"2022-03-06T14:43:17.234285Z"}}},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.505996Z","iopub.execute_input":"2022-03-17T07:05:14.506226Z","iopub.status.idle":"2022-03-17T07:05:14.510935Z","shell.execute_reply.started":"2022-03-17T07:05:14.506197Z","shell.execute_reply":"2022-03-17T07:05:14.509705Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#female ve F ile male M male,M farklı kayıtlar olarak girilmiş, birleştirilebilir","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.513163Z","iopub.execute_input":"2022-03-17T07:05:14.513633Z","iopub.status.idle":"2022-03-17T07:05:14.520788Z","shell.execute_reply.started":"2022-03-17T07:05:14.513587Z","shell.execute_reply":"2022-03-17T07:05:14.519518Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_contexts = train_df['pn_history'].copy().tolist()\ntrain_questions = train_df['feature_text'].copy().tolist()\ntrain_answers = train_df['annotation'].copy().tolist()\n\nval_contexts = val_df['pn_history'].copy().tolist()\nval_questions = val_df['feature_text'].copy().tolist()\nval_answers = val_df['annotation'].copy().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.522888Z","iopub.execute_input":"2022-03-17T07:05:14.523384Z","iopub.status.idle":"2022-03-17T07:05:14.53536Z","shell.execute_reply.started":"2022-03-17T07:05:14.52334Z","shell.execute_reply":"2022-03-17T07:05:14.53425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.537055Z","iopub.execute_input":"2022-03-17T07:05:14.537648Z","iopub.status.idle":"2022-03-17T07:05:14.557555Z","shell.execute_reply.started":"2022-03-17T07:05:14.537603Z","shell.execute_reply":"2022-03-17T07:05:14.55631Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#annotation lenghti 1 olanlarla deneyelim önce, burada kötü çıkarsa diğerlerinde daha kötü de çıkabilir\n#annotation cevap \n#pn_hist metin \n#feature soru","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.55926Z","iopub.execute_input":"2022-03-17T07:05:14.560335Z","iopub.status.idle":"2022-03-17T07:05:14.567917Z","shell.execute_reply.started":"2022-03-17T07:05:14.560278Z","shell.execute_reply":"2022-03-17T07:05:14.56662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int((train_df.loc[0].location[0].split( ))[-1])","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.569581Z","iopub.execute_input":"2022-03-17T07:05:14.570726Z","iopub.status.idle":"2022-03-17T07:05:14.579885Z","shell.execute_reply.started":"2022-03-17T07:05:14.570679Z","shell.execute_reply":"2022-03-17T07:05:14.578889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge annotation and location train answers dict tutan bir array olacak \ntrain_answers_new = [{'text': train_df.loc[i].annotation, 'answer_start':int((train_df.loc[i].location[0].split( ))[0]), 'answer_end':  int((train_df.loc[i].location[0].split( ))[-1])} for i in range(0, train_df.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:14.58183Z","iopub.execute_input":"2022-03-17T07:05:14.58243Z","iopub.status.idle":"2022-03-17T07:05:18.288878Z","shell.execute_reply.started":"2022-03-17T07:05:14.582382Z","shell.execute_reply":"2022-03-17T07:05:18.287945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge annotation and location train answers dict tutan bir array olacak \nval_answers_new = [{'text': val_df.loc[i].annotation, 'answer_start':int((val_df.loc[i].location[0].split( ))[0]), 'answer_end':  int((val_df.loc[i].location[0].split( ))[-1]) } for i in range(0, val_df.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:18.292517Z","iopub.execute_input":"2022-03-17T07:05:18.292767Z","iopub.status.idle":"2022-03-17T07:05:19.226967Z","shell.execute_reply.started":"2022-03-17T07:05:18.292723Z","shell.execute_reply":"2022-03-17T07:05:19.22606Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertForQuestionAnswering, DistilBertTokenizerFast\nmodel = DistilBertForQuestionAnswering.from_pretrained(\"../input/distilbertbaseuncased/\")\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"../input/distilbertbaseuncased/\")","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:19.23075Z","iopub.execute_input":"2022-03-17T07:05:19.231007Z","iopub.status.idle":"2022-03-17T07:05:22.199818Z","shell.execute_reply.started":"2022-03-17T07:05:19.230963Z","shell.execute_reply":"2022-03-17T07:05:22.198905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\nval_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:22.205702Z","iopub.execute_input":"2022-03-17T07:05:22.206517Z","iopub.status.idle":"2022-03-17T07:05:26.829264Z","shell.execute_reply.started":"2022-03-17T07:05:22.206474Z","shell.execute_reply":"2022-03-17T07:05:26.828272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_token_positions(encodings, answers):\n    # initialize lists to contain the token indices of answer start/end\n    start_positions = []\n    end_positions = []\n    for i in range(len(answers)):\n        # append start/end token position using char_to_token method\n        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n\n        # if start position is None, the answer passage has been truncated\n        if start_positions[-1] is None:\n            start_positions[-1] = tokenizer.model_max_length\n        # end position cannot be found, char_to_token found space, so shift position until found\n        shift = 1\n        while end_positions[-1] is None:\n            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n            shift += 1\n    # update our encodings object with the new token-based start/end positions\n    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:26.830934Z","iopub.execute_input":"2022-03-17T07:05:26.831254Z","iopub.status.idle":"2022-03-17T07:05:26.839634Z","shell.execute_reply.started":"2022-03-17T07:05:26.831214Z","shell.execute_reply":"2022-03-17T07:05:26.838642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply function to our data\nadd_token_positions(train_encodings, train_answers_new)\nadd_token_positions(val_encodings, val_answers_new)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:26.841211Z","iopub.execute_input":"2022-03-17T07:05:26.8421Z","iopub.status.idle":"2022-03-17T07:05:26.905876Z","shell.execute_reply.started":"2022-03-17T07:05:26.842057Z","shell.execute_reply":"2022-03-17T07:05:26.904978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings.keys()","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:26.908063Z","iopub.execute_input":"2022-03-17T07:05:26.908531Z","iopub.status.idle":"2022-03-17T07:05:26.916016Z","shell.execute_reply.started":"2022-03-17T07:05:26.908491Z","shell.execute_reply":"2022-03-17T07:05:26.914945Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mediumdan aldığımız kodda bu vardı\n#https://towardsdatascience.com/how-to-fine-tune-a-q-a-transformer-86f91ec92997\nclass TrainDatasetV2(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n\n# build datasets for both our training and validation sets\ntrain_dataset = TrainDatasetV2(train_encodings)\nval_dataset = TrainDatasetV2(val_encodings)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:26.917931Z","iopub.execute_input":"2022-03-17T07:05:26.918545Z","iopub.status.idle":"2022-03-17T07:05:26.927897Z","shell.execute_reply.started":"2022-03-17T07:05:26.918494Z","shell.execute_reply":"2022-03-17T07:05:26.926936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/deberta-v3-large\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:08:41.241502Z","iopub.execute_input":"2022-03-06T16:08:41.242082Z","iopub.status.idle":"2022-03-06T16:09:06.249904Z","shell.execute_reply.started":"2022-03-06T16:08:41.242045Z","shell.execute_reply":"2022-03-06T16:09:06.249107Z"}}},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# move model over to detected device\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:26.929569Z","iopub.execute_input":"2022-03-17T07:05:26.930886Z","iopub.status.idle":"2022-03-17T07:05:32.131943Z","shell.execute_reply.started":"2022-03-17T07:05:26.930746Z","shell.execute_reply":"2022-03-17T07:05:32.130977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# activate training mode of model\nmodel.train()\n# initialize adam optimizer with weight decay (reduces chance of overfitting)\noptim = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:32.13344Z","iopub.execute_input":"2022-03-17T07:05:32.133847Z","iopub.status.idle":"2022-03-17T07:05:32.141625Z","shell.execute_reply.started":"2022-03-17T07:05:32.133802Z","shell.execute_reply":"2022-03-17T07:05:32.140365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initialize data loader for training data\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:32.143578Z","iopub.execute_input":"2022-03-17T07:05:32.144299Z","iopub.status.idle":"2022-03-17T07:05:32.158166Z","shell.execute_reply.started":"2022-03-17T07:05:32.144252Z","shell.execute_reply":"2022-03-17T07:05:32.15701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):\n    # set model to train mode\n    model.train()\n    # setup loop (we use tqdm for the progress bar)\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        # initialize calculated gradients (from prev step)\n        optim.zero_grad()\n        # pull all the tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        # train model on batch and return outputs (incl. loss)\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        start_positions=start_positions,\n                        end_positions=end_positions)\n        # extract loss\n        loss = outputs[0]\n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        # update parameters\n        optim.step()\n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:05:32.161065Z","iopub.execute_input":"2022-03-17T07:05:32.16156Z","iopub.status.idle":"2022-03-17T07:12:38.322983Z","shell.execute_reply.started":"2022-03-17T07:05:32.161512Z","shell.execute_reply":"2022-03-17T07:12:38.322002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:02:10.901611Z","iopub.status.idle":"2022-03-06T16:02:10.902389Z","shell.execute_reply.started":"2022-03-06T16:02:10.902127Z","shell.execute_reply":"2022-03-06T16:02:10.902154Z"}}},{"cell_type":"markdown","source":"valid_loader","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:02:10.903882Z","iopub.status.idle":"2022-03-06T16:02:10.904616Z","shell.execute_reply.started":"2022-03-06T16:02:10.90437Z","shell.execute_reply":"2022-03-06T16:02:10.904396Z"}}},{"cell_type":"code","source":"model.eval()\n# initialize validation set data loader\nval_loader = DataLoader(val_dataset, batch_size=4)\n# initialize list to store accuracies\nacc = []\n# loop through batches\nfor batch in val_loader:\n    # we don't need to calculate gradients as we're not training\n    with torch.no_grad():\n        # pull batched items from loader\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        # we will use true positions for accuracy calc\n        start_true = batch['start_positions'].to(device)\n        end_true = batch['end_positions'].to(device)\n        # make predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        # pull prediction tensors out and argmax to get predicted tokens\n        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n        # calculate accuracy for both and append to accuracy list\n        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n# calculate average accuracy in total\nacc = sum(acc)/len(acc)","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:12:38.324977Z","iopub.execute_input":"2022-03-17T07:12:38.325537Z","iopub.status.idle":"2022-03-17T07:12:48.071537Z","shell.execute_reply.started":"2022-03-17T07:12:38.325493Z","shell.execute_reply":"2022-03-17T07:12:48.07056Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:12:48.073379Z","iopub.execute_input":"2022-03-17T07:12:48.073704Z","iopub.status.idle":"2022-03-17T07:12:48.080507Z","shell.execute_reply.started":"2022-03-17T07:12:48.073647Z","shell.execute_reply":"2022-03-17T07:12:48.07949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'FINE_TUNED_DISTILBERT_QA_V0')","metadata":{"execution":{"iopub.status.busy":"2022-03-17T07:12:48.08227Z","iopub.execute_input":"2022-03-17T07:12:48.082892Z","iopub.status.idle":"2022-03-17T07:12:48.623942Z","shell.execute_reply.started":"2022-03-17T07:12:48.082816Z","shell.execute_reply":"2022-03-17T07:12:48.62298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}