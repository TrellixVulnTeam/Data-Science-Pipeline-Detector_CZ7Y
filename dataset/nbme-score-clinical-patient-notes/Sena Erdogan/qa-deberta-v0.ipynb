{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import shutil\nfrom pathlib import Path\n\ntransformers_path = Path(\"/opt/conda/lib/python3.7/site-packages/transformers\")\n\ninput_dir = Path(\"../input/deberta-v2-3-fast-tokenizer\")\n\nconvert_file = input_dir / \"convert_slow_tokenizer.py\"\nconversion_path = transformers_path/convert_file.name\n\nif conversion_path.exists():\n    conversion_path.unlink()\n\nshutil.copy(convert_file, transformers_path)\ndeberta_v2_path = transformers_path / \"models\" / \"deberta_v2\"\n\nfor filename in ['tokenization_deberta_v2.py', 'tokenization_deberta_v2_fast.py', \"deberta__init__.py\"]:\n    if str(filename).startswith(\"deberta\"):\n        filepath = deberta_v2_path/str(filename).replace(\"deberta\", \"\")\n    else:\n        filepath = deberta_v2_path/filename\n    if filepath.exists():\n        filepath.unlink()\n\n    shutil.copy(input_dir/filename, filepath)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:24.176342Z","iopub.execute_input":"2022-03-09T13:33:24.176667Z","iopub.status.idle":"2022-03-09T13:33:24.195371Z","shell.execute_reply.started":"2022-03-09T13:33:24.176628Z","shell.execute_reply":"2022-03-09T13:33:24.194668Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-09T13:33:24.198532Z","iopub.execute_input":"2022-03-09T13:33:24.198903Z","iopub.status.idle":"2022-03-09T13:33:24.223418Z","shell.execute_reply.started":"2022-03-09T13:33:24.198876Z","shell.execute_reply":"2022-03-09T13:33:24.222759Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import ast\nfrom tqdm import tqdm\nfrom transformers import AutoModelForQuestionAnswering, TrainingArguments, Trainer, AutoConfig","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:24.224793Z","iopub.execute_input":"2022-03-09T13:33:24.225193Z","iopub.status.idle":"2022-03-09T13:33:31.45258Z","shell.execute_reply.started":"2022-03-09T13:33:24.225159Z","shell.execute_reply":"2022-03-09T13:33:31.451824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport gc\nimport re\nimport ast\nimport sys\nimport copy\nimport json\nimport time\nimport math\nimport string\nimport pickle\nimport random\nimport joblib\nimport itertools\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)\nfrom tqdm.auto import tqdm\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import Parameter\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD, AdamW\nfrom torch.utils.data import DataLoader, Dataset\n\n# os.system('pip uninstall -y transformers')\n# os.system('python -m pip install --no-index --find-links=../input/nbme-pip-wheels transformers')\nimport tokenizers\nimport transformers\nprint(f\"tokenizers.__version__: {tokenizers.__version__}\")\nprint(f\"transformers.__version__: {transformers.__version__}\")\nfrom transformers import get_linear_schedule_with_warmup, get_cosine_schedule_with_warmup\n%env TOKENIZERS_PARALLELISM=true\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:31.453975Z","iopub.execute_input":"2022-03-09T13:33:31.454242Z","iopub.status.idle":"2022-03-09T13:33:31.521476Z","shell.execute_reply.started":"2022-03-09T13:33:31.454208Z","shell.execute_reply":"2022-03-09T13:33:31.520771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"from transformers.models.deberta_v2 import DebertaV2TokenizerFast\n\ntokenizer = DebertaV2TokenizerFast.from_pretrained(\"microsoft/deberta-v3-large\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:08:22.141176Z","iopub.execute_input":"2022-03-06T16:08:22.141953Z","iopub.status.idle":"2022-03-06T16:08:24.730002Z","shell.execute_reply.started":"2022-03-06T16:08:22.141909Z","shell.execute_reply":"2022-03-06T16:08:24.729153Z"}}},{"cell_type":"markdown","source":"!pip download transformers==4.16.2\n!pip download tokenizers==0.11.0","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:08:24.731214Z","iopub.execute_input":"2022-03-06T16:08:24.731764Z","iopub.status.idle":"2022-03-06T16:08:34.725527Z","shell.execute_reply.started":"2022-03-06T16:08:24.731724Z","shell.execute_reply":"2022-03-06T16:08:34.724575Z"}}},{"cell_type":"code","source":"train = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\ntrain['annotation'] = train['annotation'].apply(ast.literal_eval)\ntrain['location'] = train['location'].apply(ast.literal_eval)\nfeatures = pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv')\ndef preprocess_features(features):\n    features.loc[27, 'feature_text'] = \"Last-Pap-smear-1-year-ago\"\n    return features\nfeatures = preprocess_features(features)\npatient_notes = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nprint(f\"train.shape: {train.shape}\")\ndisplay(train.head())\nprint(f\"features.shape: {features.shape}\")\ndisplay(features.head())\nprint(f\"patient_notes.shape: {patient_notes.shape}\")\ndisplay(patient_notes.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:31.523793Z","iopub.execute_input":"2022-03-09T13:33:31.52405Z","iopub.status.idle":"2022-03-09T13:33:32.741748Z","shell.execute_reply.started":"2022-03-09T13:33:31.524006Z","shell.execute_reply":"2022-03-09T13:33:32.74101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(patient_notes.pn_history.unique())","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:32.742863Z","iopub.execute_input":"2022-03-09T13:33:32.743547Z","iopub.status.idle":"2022-03-09T13:33:32.832752Z","shell.execute_reply.started":"2022-03-09T13:33:32.74351Z","shell.execute_reply":"2022-03-09T13:33:32.832007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(train.pn_num.unique()))\nprint(len(patient_notes.pn_num.unique()))","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:32.833878Z","iopub.execute_input":"2022-03-09T13:33:32.834145Z","iopub.status.idle":"2022-03-09T13:33:32.843191Z","shell.execute_reply.started":"2022-03-09T13:33:32.834095Z","shell.execute_reply":"2022-03-09T13:33:32.842155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = train.merge(features, on=['feature_num', 'case_num'], how='left')\ntrain = train.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:32.845044Z","iopub.execute_input":"2022-03-09T13:33:32.845454Z","iopub.status.idle":"2022-03-09T13:33:32.884947Z","shell.execute_reply.started":"2022-03-09T13:33:32.845413Z","shell.execute_reply":"2022-03-09T13:33:32.884274Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# incorrect annotation\ntrain.loc[338, 'annotation'] = ast.literal_eval('[[\"father heart attack\"]]')\ntrain.loc[338, 'location'] = ast.literal_eval('[[\"764 783\"]]')\n\ntrain.loc[621, 'annotation'] = ast.literal_eval('[[\"for the last 2-3 months\"]]')\ntrain.loc[621, 'location'] = ast.literal_eval('[[\"77 100\"]]')\n\ntrain.loc[655, 'annotation'] = ast.literal_eval('[[\"no heat intolerance\"], [\"no cold intolerance\"]]')\ntrain.loc[655, 'location'] = ast.literal_eval('[[\"285 292;301 312\"], [\"285 287;296 312\"]]')\n\ntrain.loc[1262, 'annotation'] = ast.literal_eval('[[\"mother thyroid problem\"]]')\ntrain.loc[1262, 'location'] = ast.literal_eval('[[\"551 557;565 580\"]]')\n\ntrain.loc[1265, 'annotation'] = ast.literal_eval('[[\\'felt like he was going to \"pass out\"\\']]')\ntrain.loc[1265, 'location'] = ast.literal_eval('[[\"131 135;181 212\"]]')\n\ntrain.loc[1396, 'annotation'] = ast.literal_eval('[[\"stool , with no blood\"]]')\ntrain.loc[1396, 'location'] = ast.literal_eval('[[\"259 280\"]]')\n\ntrain.loc[1591, 'annotation'] = ast.literal_eval('[[\"diarrhoe non blooody\"]]')\ntrain.loc[1591, 'location'] = ast.literal_eval('[[\"176 184;201 212\"]]')\n\ntrain.loc[1615, 'annotation'] = ast.literal_eval('[[\"diarrhea for last 2-3 days\"]]')\ntrain.loc[1615, 'location'] = ast.literal_eval('[[\"249 257;271 288\"]]')\n\ntrain.loc[1664, 'annotation'] = ast.literal_eval('[[\"no vaginal discharge\"]]')\ntrain.loc[1664, 'location'] = ast.literal_eval('[[\"822 824;907 924\"]]')\n\ntrain.loc[1714, 'annotation'] = ast.literal_eval('[[\"started about 8-10 hours ago\"]]')\ntrain.loc[1714, 'location'] = ast.literal_eval('[[\"101 129\"]]')\n\ntrain.loc[1929, 'annotation'] = ast.literal_eval('[[\"no blood in the stool\"]]')\ntrain.loc[1929, 'location'] = ast.literal_eval('[[\"531 539;549 561\"]]')\n\ntrain.loc[2134, 'annotation'] = ast.literal_eval('[[\"last sexually active 9 months ago\"]]')\ntrain.loc[2134, 'location'] = ast.literal_eval('[[\"540 560;581 593\"]]')\n\ntrain.loc[2191, 'annotation'] = ast.literal_eval('[[\"right lower quadrant pain\"]]')\ntrain.loc[2191, 'location'] = ast.literal_eval('[[\"32 57\"]]')\n\ntrain.loc[2553, 'annotation'] = ast.literal_eval('[[\"diarrhoea no blood\"]]')\ntrain.loc[2553, 'location'] = ast.literal_eval('[[\"308 317;376 384\"]]')\n\ntrain.loc[3124, 'annotation'] = ast.literal_eval('[[\"sweating\"]]')\ntrain.loc[3124, 'location'] = ast.literal_eval('[[\"549 557\"]]')\n\ntrain.loc[3858, 'annotation'] = ast.literal_eval('[[\"previously as regular\"], [\"previously eveyr 28-29 days\"], [\"previously lasting 5 days\"], [\"previously regular flow\"]]')\ntrain.loc[3858, 'location'] = ast.literal_eval('[[\"102 123\"], [\"102 112;125 141\"], [\"102 112;143 157\"], [\"102 112;159 171\"]]')\n\ntrain.loc[4373, 'annotation'] = ast.literal_eval('[[\"for 2 months\"]]')\ntrain.loc[4373, 'location'] = ast.literal_eval('[[\"33 45\"]]')\n\ntrain.loc[4763, 'annotation'] = ast.literal_eval('[[\"35 year old\"]]')\ntrain.loc[4763, 'location'] = ast.literal_eval('[[\"5 16\"]]')\n\ntrain.loc[4782, 'annotation'] = ast.literal_eval('[[\"darker brown stools\"]]')\ntrain.loc[4782, 'location'] = ast.literal_eval('[[\"175 194\"]]')\n\ntrain.loc[4908, 'annotation'] = ast.literal_eval('[[\"uncle with peptic ulcer\"]]')\ntrain.loc[4908, 'location'] = ast.literal_eval('[[\"700 723\"]]')\n\ntrain.loc[6016, 'annotation'] = ast.literal_eval('[[\"difficulty falling asleep\"]]')\ntrain.loc[6016, 'location'] = ast.literal_eval('[[\"225 250\"]]')\n\ntrain.loc[6192, 'annotation'] = ast.literal_eval('[[\"helps to take care of aging mother and in-laws\"]]')\ntrain.loc[6192, 'location'] = ast.literal_eval('[[\"197 218;236 260\"]]')\n\ntrain.loc[6380, 'annotation'] = ast.literal_eval('[[\"No hair changes\"], [\"No skin changes\"], [\"No GI changes\"], [\"No palpitations\"], [\"No excessive sweating\"]]')\ntrain.loc[6380, 'location'] = ast.literal_eval('[[\"480 482;507 519\"], [\"480 482;499 503;512 519\"], [\"480 482;521 531\"], [\"480 482;533 545\"], [\"480 482;564 582\"]]')\n\ntrain.loc[6562, 'annotation'] = ast.literal_eval('[[\"stressed due to taking care of her mother\"], [\"stressed due to taking care of husbands parents\"]]')\ntrain.loc[6562, 'location'] = ast.literal_eval('[[\"290 320;327 337\"], [\"290 320;342 358\"]]')\n\ntrain.loc[6862, 'annotation'] = ast.literal_eval('[[\"stressor taking care of many sick family members\"]]')\ntrain.loc[6862, 'location'] = ast.literal_eval('[[\"288 296;324 363\"]]')\n\ntrain.loc[7022, 'annotation'] = ast.literal_eval('[[\"heart started racing and felt numbness for the 1st time in her finger tips\"]]')\ntrain.loc[7022, 'location'] = ast.literal_eval('[[\"108 182\"]]')\n\ntrain.loc[7422, 'annotation'] = ast.literal_eval('[[\"first started 5 yrs\"]]')\ntrain.loc[7422, 'location'] = ast.literal_eval('[[\"102 121\"]]')\n\ntrain.loc[8876, 'annotation'] = ast.literal_eval('[[\"No shortness of breath\"]]')\ntrain.loc[8876, 'location'] = ast.literal_eval('[[\"481 483;533 552\"]]')\n\ntrain.loc[9027, 'annotation'] = ast.literal_eval('[[\"recent URI\"], [\"nasal stuffines, rhinorrhea, for 3-4 days\"]]')\ntrain.loc[9027, 'location'] = ast.literal_eval('[[\"92 102\"], [\"123 164\"]]')\n\ntrain.loc[9938, 'annotation'] = ast.literal_eval('[[\"irregularity with her cycles\"], [\"heavier bleeding\"], [\"changes her pad every couple hours\"]]')\ntrain.loc[9938, 'location'] = ast.literal_eval('[[\"89 117\"], [\"122 138\"], [\"368 402\"]]')\n\ntrain.loc[9973, 'annotation'] = ast.literal_eval('[[\"gaining 10-15 lbs\"]]')\ntrain.loc[9973, 'location'] = ast.literal_eval('[[\"344 361\"]]')\n\ntrain.loc[10513, 'annotation'] = ast.literal_eval('[[\"weight gain\"], [\"gain of 10-16lbs\"]]')\ntrain.loc[10513, 'location'] = ast.literal_eval('[[\"600 611\"], [\"607 623\"]]')\n\ntrain.loc[11551, 'annotation'] = ast.literal_eval('[[\"seeing her son knows are not real\"]]')\ntrain.loc[11551, 'location'] = ast.literal_eval('[[\"386 400;443 461\"]]')\n\ntrain.loc[11677, 'annotation'] = ast.literal_eval('[[\"saw him once in the kitchen after he died\"]]')\ntrain.loc[11677, 'location'] = ast.literal_eval('[[\"160 201\"]]')\n\ntrain.loc[12124, 'annotation'] = ast.literal_eval('[[\"tried Ambien but it didnt work\"]]')\ntrain.loc[12124, 'location'] = ast.literal_eval('[[\"325 337;349 366\"]]')\n\ntrain.loc[12279, 'annotation'] = ast.literal_eval('[[\"heard what she described as a party later than evening these things did not actually happen\"]]')\ntrain.loc[12279, 'location'] = ast.literal_eval('[[\"405 459;488 524\"]]')\n\ntrain.loc[12289, 'annotation'] = ast.literal_eval('[[\"experienced seeing her son at the kitchen table these things did not actually happen\"]]')\ntrain.loc[12289, 'location'] = ast.literal_eval('[[\"353 400;488 524\"]]')\n\ntrain.loc[13238, 'annotation'] = ast.literal_eval('[[\"SCRACHY THROAT\"], [\"RUNNY NOSE\"]]')\ntrain.loc[13238, 'location'] = ast.literal_eval('[[\"293 307\"], [\"321 331\"]]')\n\ntrain.loc[13297, 'annotation'] = ast.literal_eval('[[\"without improvement when taking tylenol\"], [\"without improvement when taking ibuprofen\"]]')\ntrain.loc[13297, 'location'] = ast.literal_eval('[[\"182 221\"], [\"182 213;225 234\"]]')\n\ntrain.loc[13299, 'annotation'] = ast.literal_eval('[[\"yesterday\"], [\"yesterday\"]]')\ntrain.loc[13299, 'location'] = ast.literal_eval('[[\"79 88\"], [\"409 418\"]]')\n\ntrain.loc[13845, 'annotation'] = ast.literal_eval('[[\"headache global\"], [\"headache throughout her head\"]]')\ntrain.loc[13845, 'location'] = ast.literal_eval('[[\"86 94;230 236\"], [\"86 94;237 256\"]]')\n\ntrain.loc[14083, 'annotation'] = ast.literal_eval('[[\"headache generalized in her head\"]]')\ntrain.loc[14083, 'location'] = ast.literal_eval('[[\"56 64;156 179\"]]')","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:32.88641Z","iopub.execute_input":"2022-03-09T13:33:32.88678Z","iopub.status.idle":"2022-03-09T13:33:32.980301Z","shell.execute_reply.started":"2022-03-09T13:33:32.886745Z","shell.execute_reply":"2022-03-09T13:33:32.979601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['annotation_length'] = train['annotation'].apply(len)\ndisplay(train['annotation_length'].value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:32.982021Z","iopub.execute_input":"2022-03-09T13:33:32.982418Z","iopub.status.idle":"2022-03-09T13:33:32.998614Z","shell.execute_reply.started":"2022-03-09T13:33:32.982382Z","shell.execute_reply":"2022-03-09T13:33:32.99799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#annotation length'i fazla olanların seyreltebiliriz\n#train[train['annotation_length'] == 8].loc[10640]['annotation']","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:32.999967Z","iopub.execute_input":"2022-03-09T13:33:33.0003Z","iopub.status.idle":"2022-03-09T13:33:33.011483Z","shell.execute_reply.started":"2022-03-09T13:33:33.000266Z","shell.execute_reply":"2022-03-09T13:33:33.010753Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#train[train['annotation_length'] == 7].loc[6320]['annotation']","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.012593Z","iopub.execute_input":"2022-03-09T13:33:33.012892Z","iopub.status.idle":"2022-03-09T13:33:33.021945Z","shell.execute_reply.started":"2022-03-09T13:33:33.012857Z","shell.execute_reply":"2022-03-09T13:33:33.021158Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"for text_col in ['pn_history']:\n    pn_history_lengths = []\n    tk0 = tqdm(patient_notes[text_col].fillna(\"\").values, total=len(patient_notes))\n    for text in tk0:\n        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n        pn_history_lengths.append(length)\n    print(f'{text_col} max(lengths): {max(pn_history_lengths)}')\n\nfor text_col in ['feature_text']:\n    features_lengths = []\n    tk0 = tqdm(features[text_col].fillna(\"\").values, total=len(features))\n    for text in tk0:\n        length = len(tokenizer(text, add_special_tokens=False)['input_ids'])\n        features_lengths.append(length)\n    print(f'{text_col} max(lengths): {max(features_lengths)}')\n    \nmax_len = max(pn_history_lengths) + max(features_lengths) + 3 # cls & sep & sep","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:01:06.021246Z","iopub.execute_input":"2022-03-06T16:01:06.021843Z","iopub.status.idle":"2022-03-06T16:01:32.485716Z","shell.execute_reply.started":"2022-03-06T16:01:06.021805Z","shell.execute_reply":"2022-03-06T16:01:32.484934Z"}}},{"cell_type":"markdown","source":"max_len","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:01:32.487033Z","iopub.execute_input":"2022-03-06T16:01:32.487631Z","iopub.status.idle":"2022-03-06T16:01:32.493504Z","shell.execute_reply.started":"2022-03-06T16:01:32.487592Z","shell.execute_reply":"2022-03-06T16:01:32.492802Z"}}},{"cell_type":"code","source":"max_len=354","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.023587Z","iopub.execute_input":"2022-03-09T13:33:33.02395Z","iopub.status.idle":"2022-03-09T13:33:33.029007Z","shell.execute_reply.started":"2022-03-09T13:33:33.023915Z","shell.execute_reply":"2022-03-09T13:33:33.027934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"def prepare_input(tokenizer, max_len, text, feature_text):\n    inputs = tokenizer(text, feature_text, \n                           add_special_tokens=True,\n                           max_length=max_len,\n                           padding=\"max_length\",\n                           return_offsets_mapping=False)\n    for k, v in inputs.items():\n        inputs[k] = torch.tensor(v, dtype=torch.long)\n    return inputs\n\n\ndef create_label(tokenizer, max_len,text, annotation_length, location_list):\n    encoded = tokenizer(text,\n                            add_special_tokens=True,\n                            max_length=max_len,\n                            padding=\"max_length\",\n                            return_offsets_mapping=True)\n    offset_mapping = encoded['offset_mapping']\n    ignore_idxes = np.where(np.array(encoded.sequence_ids()) != 0)[0]\n    label = np.zeros(len(offset_mapping))\n    label[ignore_idxes] = -1\n    if annotation_length != 0:\n        for location in location_list:\n            for loc in [s.split() for s in location.split(';')]:\n                start_idx = -1\n                end_idx = -1\n                start, end = int(loc[0]), int(loc[1])\n                for idx in range(len(offset_mapping)):\n                    if (start_idx == -1) & (start < offset_mapping[idx][0]):\n                        start_idx = idx - 1\n                    if (end_idx == -1) & (end <= offset_mapping[idx][1]):\n                        end_idx = idx + 1\n                if start_idx == -1:\n                    start_idx = end_idx\n                if (start_idx != -1) & (end_idx != -1):\n                    label[start_idx:end_idx] = 1\n    return torch.tensor(label, dtype=torch.float)\n\n\nclass TrainDataset(Dataset):\n    def __init__(self, df):\n        self.feature_texts = df['feature_text'].values\n        self.pn_historys = df['pn_history'].values\n        self.annotation_lengths = df['annotation_length'].values\n        self.locations = df['location'].values\n\n    def __len__(self):\n        return len(self.feature_texts)\n\n    def __getitem__(self, item):\n        inputs = prepare_input(self.pn_historys[item], \n                               self.feature_texts[item])\n        label = create_label(self.pn_historys[item], \n                             self.annotation_lengths[item], \n                             self.locations[item])\n        return inputs, label","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:42:46.392149Z","iopub.execute_input":"2022-03-06T14:42:46.392509Z","iopub.status.idle":"2022-03-06T14:42:46.411055Z","shell.execute_reply.started":"2022-03-06T14:42:46.392455Z","shell.execute_reply":"2022-03-06T14:42:46.410335Z"}}},{"cell_type":"markdown","source":"class CustomModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.config = AutoConfig.from_pretrained(\"microsoft/deberta-v3-large\", output_hidden_states=True)\n        self.model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/deberta-v3-large\")\n        self.fc_dropout = nn.Dropout(0.2)\n        self.fc = nn.Linear(self.config.hidden_size, 1)\n        self._init_weights(self.fc)\n        \n    def _init_weights(self, module):\n        if isinstance(module, nn.Linear):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.bias is not None:\n                module.bias.data.zero_()\n        elif isinstance(module, nn.Embedding):\n            module.weight.data.normal_(mean=0.0, std=self.config.initializer_range)\n            if module.padding_idx is not None:\n                module.weight.data[module.padding_idx].zero_()\n        elif isinstance(module, nn.LayerNorm):\n            module.bias.data.zero_()\n            module.weight.data.fill_(1.0)\n        \n    def feature(self, inputs):\n        outputs = self.model(**inputs)\n        last_hidden_states = outputs[0]\n        return last_hidden_states\n\n    def forward(self, inputs):\n        feature = self.feature(inputs)\n        output = self.fc(self.fc_dropout(feature))\n        return output","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:42:46.412409Z","iopub.execute_input":"2022-03-06T14:42:46.412661Z","iopub.status.idle":"2022-03-06T14:42:46.42557Z","shell.execute_reply.started":"2022-03-06T14:42:46.412627Z","shell.execute_reply":"2022-03-06T14:42:46.424937Z"}}},{"cell_type":"code","source":"test_df = train.head(5).copy()\ntest_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.033993Z","iopub.execute_input":"2022-03-09T13:33:33.034226Z","iopub.status.idle":"2022-03-09T13:33:33.050447Z","shell.execute_reply.started":"2022-03-09T13:33:33.034196Z","shell.execute_reply":"2022-03-09T13:33:33.049526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all_full = train[train['annotation'].str.len() >= 1]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.052436Z","iopub.execute_input":"2022-03-09T13:33:33.052712Z","iopub.status.idle":"2022-03-09T13:33:33.071308Z","shell.execute_reply.started":"2022-03-09T13:33:33.052677Z","shell.execute_reply":"2022-03-09T13:33:33.070659Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_all_one_annotation = train[train['annotation_length'] == 1].copy()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.072602Z","iopub.execute_input":"2022-03-09T13:33:33.072846Z","iopub.status.idle":"2022-03-09T13:33:33.0796Z","shell.execute_reply.started":"2022-03-09T13:33:33.072813Z","shell.execute_reply":"2022-03-09T13:33:33.07875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\nprint(train_all_full.shape)\nprint(train_all_one_annotation.shape)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.081241Z","iopub.execute_input":"2022-03-09T13:33:33.081589Z","iopub.status.idle":"2022-03-09T13:33:33.090202Z","shell.execute_reply.started":"2022-03-09T13:33:33.081552Z","shell.execute_reply":"2022-03-09T13:33:33.089269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\ntrain_df, val_df = train_test_split(train_all_one_annotation, test_size=0.2, random_state=42)\ntrain_df.reset_index(inplace=True, drop=True)\nval_df.reset_index(inplace=True, drop=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.091696Z","iopub.execute_input":"2022-03-09T13:33:33.092332Z","iopub.status.idle":"2022-03-09T13:33:33.102071Z","shell.execute_reply.started":"2022-03-09T13:33:33.092293Z","shell.execute_reply":"2022-03-09T13:33:33.101053Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model = CustomModel()\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:42:46.463986Z","iopub.execute_input":"2022-03-06T14:42:46.464455Z","iopub.status.idle":"2022-03-06T14:43:17.209324Z","shell.execute_reply.started":"2022-03-06T14:42:46.464422Z","shell.execute_reply":"2022-03-06T14:43:17.208622Z"},"jupyter":{"outputs_hidden":true}}},{"cell_type":"markdown","source":"train_dataset = TrainDataset(train_df)\nvalid_dataset = TrainDataset(val_df)\n\ntrain_loader = DataLoader(train_dataset,\n                          batch_size=128,\n                          shuffle=True,\n                          num_workers=4, pin_memory=True, drop_last=True)\nvalid_loader = DataLoader(valid_dataset,\n                              batch_size=128,\n                              shuffle=False,\n                              num_workers=4, pin_memory=True, drop_last=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-06T15:28:59.359519Z","iopub.execute_input":"2022-03-06T15:28:59.35999Z","iopub.status.idle":"2022-03-06T15:28:59.366473Z","shell.execute_reply.started":"2022-03-06T15:28:59.359955Z","shell.execute_reply":"2022-03-06T15:28:59.365559Z"}}},{"cell_type":"markdown","source":"from transformers import DefaultDataCollator\n\ndata_collator = DefaultDataCollator()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T14:43:17.220212Z","iopub.execute_input":"2022-03-06T14:43:17.220557Z","iopub.status.idle":"2022-03-06T14:43:17.234951Z","shell.execute_reply.started":"2022-03-06T14:43:17.220509Z","shell.execute_reply":"2022-03-06T14:43:17.234285Z"}}},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.103791Z","iopub.execute_input":"2022-03-09T13:33:33.104159Z","iopub.status.idle":"2022-03-09T13:33:33.108082Z","shell.execute_reply.started":"2022-03-09T13:33:33.104122Z","shell.execute_reply":"2022-03-09T13:33:33.107173Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#female ve F ile male M male,M farklı kayıtlar olarak girilmiş, birleştirilebilir","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.109658Z","iopub.execute_input":"2022-03-09T13:33:33.10998Z","iopub.status.idle":"2022-03-09T13:33:33.11654Z","shell.execute_reply.started":"2022-03-09T13:33:33.109948Z","shell.execute_reply":"2022-03-09T13:33:33.115615Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_contexts = train_df['pn_history'].copy().tolist()\ntrain_questions = train_df['feature_text'].copy().tolist()\ntrain_answers = train_df['annotation'].copy().tolist()\n\nval_contexts = val_df['pn_history'].copy().tolist()\nval_questions = val_df['feature_text'].copy().tolist()\nval_answers = val_df['annotation'].copy().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.118181Z","iopub.execute_input":"2022-03-09T13:33:33.118517Z","iopub.status.idle":"2022-03-09T13:33:33.126928Z","shell.execute_reply.started":"2022-03-09T13:33:33.118477Z","shell.execute_reply":"2022-03-09T13:33:33.126067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.128495Z","iopub.execute_input":"2022-03-09T13:33:33.129147Z","iopub.status.idle":"2022-03-09T13:33:33.146498Z","shell.execute_reply.started":"2022-03-09T13:33:33.129072Z","shell.execute_reply":"2022-03-09T13:33:33.145534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#annotation lenghti 1 olanlarla deneyelim önce, burada kötü çıkarsa diğerlerinde daha kötü de çıkabilir\n#annotation cevap \n#pn_hist metin \n#feature soru","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.148552Z","iopub.execute_input":"2022-03-09T13:33:33.148762Z","iopub.status.idle":"2022-03-09T13:33:33.154516Z","shell.execute_reply.started":"2022-03-09T13:33:33.148739Z","shell.execute_reply":"2022-03-09T13:33:33.153617Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"int((train_df.loc[0].location[0].split( ))[-1])","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.156005Z","iopub.execute_input":"2022-03-09T13:33:33.156422Z","iopub.status.idle":"2022-03-09T13:33:33.164821Z","shell.execute_reply.started":"2022-03-09T13:33:33.156385Z","shell.execute_reply":"2022-03-09T13:33:33.163895Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge annotation and location train answers dict tutan bir array olacak \ntrain_answers_new = [{'text': train_df.loc[i].annotation, 'answer_start':int((train_df.loc[i].location[0].split( ))[0]), 'answer_end':  int((train_df.loc[i].location[0].split( ))[-1])} for i in range(0, train_df.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:33.167421Z","iopub.execute_input":"2022-03-09T13:33:33.167743Z","iopub.status.idle":"2022-03-09T13:33:35.488967Z","shell.execute_reply.started":"2022-03-09T13:33:33.167707Z","shell.execute_reply":"2022-03-09T13:33:35.488267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#merge annotation and location train answers dict tutan bir array olacak \nval_answers_new = [{'text': val_df.loc[i].annotation, 'answer_start':int((val_df.loc[i].location[0].split( ))[0]), 'answer_end':  int((val_df.loc[i].location[0].split( ))[-1]) } for i in range(0, val_df.shape[0])]","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:35.491095Z","iopub.execute_input":"2022-03-09T13:33:35.491509Z","iopub.status.idle":"2022-03-09T13:33:36.082347Z","shell.execute_reply.started":"2022-03-09T13:33:35.491472Z","shell.execute_reply":"2022-03-09T13:33:36.081634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import DistilBertForQuestionAnswering, DistilBertTokenizerFast\nmodel = DistilBertForQuestionAnswering.from_pretrained(\"../input/distilbertbaseuncased/\")\ntokenizer = DistilBertTokenizerFast.from_pretrained(\"../input/distilbertbaseuncased/\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:36.083665Z","iopub.execute_input":"2022-03-09T13:33:36.083894Z","iopub.status.idle":"2022-03-09T13:33:40.987873Z","shell.execute_reply.started":"2022-03-09T13:33:36.083863Z","shell.execute_reply":"2022-03-09T13:33:40.987133Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings = tokenizer(train_contexts, train_questions, truncation=True, padding=True)\nval_encodings = tokenizer(val_contexts, val_questions, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:40.989136Z","iopub.execute_input":"2022-03-09T13:33:40.989384Z","iopub.status.idle":"2022-03-09T13:33:45.563114Z","shell.execute_reply.started":"2022-03-09T13:33:40.989353Z","shell.execute_reply":"2022-03-09T13:33:45.562386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def add_token_positions(encodings, answers):\n    # initialize lists to contain the token indices of answer start/end\n    start_positions = []\n    end_positions = []\n    for i in range(len(answers)):\n        # append start/end token position using char_to_token method\n        start_positions.append(encodings.char_to_token(i, answers[i]['answer_start']))\n        end_positions.append(encodings.char_to_token(i, answers[i]['answer_end']))\n\n        # if start position is None, the answer passage has been truncated\n        if start_positions[-1] is None:\n            start_positions[-1] = tokenizer.model_max_length\n        # end position cannot be found, char_to_token found space, so shift position until found\n        shift = 1\n        while end_positions[-1] is None:\n            end_positions[-1] = encodings.char_to_token(i, answers[i]['answer_end'] - shift)\n            shift += 1\n    # update our encodings object with the new token-based start/end positions\n    encodings.update({'start_positions': start_positions, 'end_positions': end_positions})\n","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:45.564203Z","iopub.execute_input":"2022-03-09T13:33:45.566295Z","iopub.status.idle":"2022-03-09T13:33:45.573678Z","shell.execute_reply.started":"2022-03-09T13:33:45.566262Z","shell.execute_reply":"2022-03-09T13:33:45.57297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# apply function to our data\nadd_token_positions(train_encodings, train_answers_new)\nadd_token_positions(val_encodings, val_answers_new)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:45.575031Z","iopub.execute_input":"2022-03-09T13:33:45.575563Z","iopub.status.idle":"2022-03-09T13:33:45.629395Z","shell.execute_reply.started":"2022-03-09T13:33:45.575522Z","shell.execute_reply":"2022-03-09T13:33:45.628729Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_encodings.keys()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:45.631803Z","iopub.execute_input":"2022-03-09T13:33:45.632253Z","iopub.status.idle":"2022-03-09T13:33:45.639754Z","shell.execute_reply.started":"2022-03-09T13:33:45.632213Z","shell.execute_reply":"2022-03-09T13:33:45.639035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#mediumdan aldığımız kodda bu vardı\n#https://towardsdatascience.com/how-to-fine-tune-a-q-a-transformer-86f91ec92997\nclass TrainDatasetV2(torch.utils.data.Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n\n    def __len__(self):\n        return len(self.encodings.input_ids)\n\n# build datasets for both our training and validation sets\ntrain_dataset = TrainDatasetV2(train_encodings)\nval_dataset = TrainDatasetV2(val_encodings)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:45.641278Z","iopub.execute_input":"2022-03-09T13:33:45.641544Z","iopub.status.idle":"2022-03-09T13:33:45.649053Z","shell.execute_reply.started":"2022-03-09T13:33:45.641508Z","shell.execute_reply":"2022-03-09T13:33:45.647965Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"model = AutoModelForQuestionAnswering.from_pretrained(\"microsoft/deberta-v3-large\")","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:08:41.241502Z","iopub.execute_input":"2022-03-06T16:08:41.242082Z","iopub.status.idle":"2022-03-06T16:09:06.249904Z","shell.execute_reply.started":"2022-03-06T16:08:41.242045Z","shell.execute_reply":"2022-03-06T16:09:06.249107Z"}}},{"cell_type":"code","source":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n# move model over to detected device\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:45.650464Z","iopub.execute_input":"2022-03-09T13:33:45.650903Z","iopub.status.idle":"2022-03-09T13:33:50.743643Z","shell.execute_reply.started":"2022-03-09T13:33:45.650847Z","shell.execute_reply":"2022-03-09T13:33:50.742969Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# activate training mode of model\nmodel.train()\n# initialize adam optimizer with weight decay (reduces chance of overfitting)\noptim = AdamW(model.parameters(), lr=5e-5)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:50.744899Z","iopub.execute_input":"2022-03-09T13:33:50.745307Z","iopub.status.idle":"2022-03-09T13:33:50.750866Z","shell.execute_reply.started":"2022-03-09T13:33:50.745271Z","shell.execute_reply":"2022-03-09T13:33:50.749842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#initialize data loader for training data\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:50.752165Z","iopub.execute_input":"2022-03-09T13:33:50.752423Z","iopub.status.idle":"2022-03-09T13:33:50.76682Z","shell.execute_reply.started":"2022-03-09T13:33:50.752388Z","shell.execute_reply":"2022-03-09T13:33:50.766031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for epoch in range(3):\n    # set model to train mode\n    model.train()\n    # setup loop (we use tqdm for the progress bar)\n    loop = tqdm(train_loader, leave=True)\n    for batch in loop:\n        # initialize calculated gradients (from prev step)\n        optim.zero_grad()\n        # pull all the tensor batches required for training\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        start_positions = batch['start_positions'].to(device)\n        end_positions = batch['end_positions'].to(device)\n        # train model on batch and return outputs (incl. loss)\n        outputs = model(input_ids, attention_mask=attention_mask,\n                        start_positions=start_positions,\n                        end_positions=end_positions)\n        # extract loss\n        loss = outputs[0]\n        # calculate loss for every parameter that needs grad update\n        loss.backward()\n        # update parameters\n        optim.step()\n        # print relevant info to progress bar\n        loop.set_description(f'Epoch {epoch}')\n        loop.set_postfix(loss=loss.item())","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:33:50.77005Z","iopub.execute_input":"2022-03-09T13:33:50.770686Z","iopub.status.idle":"2022-03-09T13:40:49.617709Z","shell.execute_reply.started":"2022-03-09T13:33:50.770649Z","shell.execute_reply":"2022-03-09T13:40:49.617022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"training_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    learning_rate=2e-5,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=16,\n    num_train_epochs=3,\n    weight_decay=0.01,\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=valid_dataset,\n    tokenizer=tokenizer,\n    data_collator=data_collator,\n)\n\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:02:10.901611Z","iopub.status.idle":"2022-03-06T16:02:10.902389Z","shell.execute_reply.started":"2022-03-06T16:02:10.902127Z","shell.execute_reply":"2022-03-06T16:02:10.902154Z"}}},{"cell_type":"markdown","source":"valid_loader","metadata":{"execution":{"iopub.status.busy":"2022-03-06T16:02:10.903882Z","iopub.status.idle":"2022-03-06T16:02:10.904616Z","shell.execute_reply.started":"2022-03-06T16:02:10.90437Z","shell.execute_reply":"2022-03-06T16:02:10.904396Z"}}},{"cell_type":"code","source":"model.eval()\n# initialize validation set data loader\nval_loader = DataLoader(val_dataset, batch_size=4)\n# initialize list to store accuracies\nacc = []\n# loop through batches\nfor batch in val_loader:\n    # we don't need to calculate gradients as we're not training\n    with torch.no_grad():\n        # pull batched items from loader\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        # we will use true positions for accuracy calc\n        start_true = batch['start_positions'].to(device)\n        end_true = batch['end_positions'].to(device)\n        # make predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        # pull prediction tensors out and argmax to get predicted tokens\n        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n        # calculate accuracy for both and append to accuracy list\n        acc.append(((start_pred == start_true).sum()/len(start_pred)).item())\n        acc.append(((end_pred == end_true).sum()/len(end_pred)).item())\n# calculate average accuracy in total\nacc = sum(acc)/len(acc)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:49.618991Z","iopub.execute_input":"2022-03-09T13:40:49.619723Z","iopub.status.idle":"2022-03-09T13:40:59.272133Z","shell.execute_reply.started":"2022-03-09T13:40:49.619686Z","shell.execute_reply":"2022-03-09T13:40:59.27142Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"acc","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.273253Z","iopub.execute_input":"2022-03-09T13:40:59.273504Z","iopub.status.idle":"2022-03-09T13:40:59.279506Z","shell.execute_reply.started":"2022-03-09T13:40:59.27347Z","shell.execute_reply":"2022-03-09T13:40:59.278778Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.read_csv('../input/nbme-score-clinical-patient-notes/test.csv')\ntest.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.280876Z","iopub.execute_input":"2022-03-09T13:40:59.281419Z","iopub.status.idle":"2022-03-09T13:40:59.307321Z","shell.execute_reply.started":"2022-03-09T13:40:59.281375Z","shell.execute_reply":"2022-03-09T13:40:59.306701Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.merge(features, on=['feature_num', 'case_num'], how='left')\ntest = test.merge(patient_notes, on=['pn_num', 'case_num'], how='left')\ndisplay(test.head())","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.308608Z","iopub.execute_input":"2022-03-09T13:40:59.309058Z","iopub.status.idle":"2022-03-09T13:40:59.332793Z","shell.execute_reply.started":"2022-03-09T13:40:59.309023Z","shell.execute_reply":"2022-03-09T13:40:59.332152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_contexts = test_df['pn_history'].copy().tolist()\ntest_questions = test_df['feature_text'].copy().tolist()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.337178Z","iopub.execute_input":"2022-03-09T13:40:59.337373Z","iopub.status.idle":"2022-03-09T13:40:59.342004Z","shell.execute_reply.started":"2022-03-09T13:40:59.337349Z","shell.execute_reply":"2022-03-09T13:40:59.341151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_encodings = tokenizer(test_contexts, test_questions, truncation=True, padding=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.343628Z","iopub.execute_input":"2022-03-09T13:40:59.343896Z","iopub.status.idle":"2022-03-09T13:40:59.356609Z","shell.execute_reply.started":"2022-03-09T13:40:59.343863Z","shell.execute_reply":"2022-03-09T13:40:59.355818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = TrainDatasetV2(test_encodings)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.35826Z","iopub.execute_input":"2022-03-09T13:40:59.358733Z","iopub.status.idle":"2022-03-09T13:40:59.362479Z","shell.execute_reply.started":"2022-03-09T13:40:59.358697Z","shell.execute_reply":"2022-03-09T13:40:59.361679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.eval()\n# initialize validation set data loader\ntest_loader = DataLoader(test_dataset, batch_size=4)\n# initialize list to store accuracies\npreds_start = []\npreds_end = []\n# loop through batches\nfor batch in test_loader:\n    # we don't need to calculate gradients as we're not training\n    with torch.no_grad():\n        # pull batched items from loader\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        # make predictions\n        outputs = model(input_ids, attention_mask=attention_mask)\n        # pull prediction tensors out and argmax to get predicted tokens\n        start_pred = torch.argmax(outputs['start_logits'], dim=1)\n        end_pred = torch.argmax(outputs['end_logits'], dim=1)\n        \n        start_np = start_pred.detach().cpu().numpy()\n        end_np = end_pred.detach().cpu().numpy()\n        \n        preds_start.extend(start_np)\n        preds_end.extend(end_np)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.364231Z","iopub.execute_input":"2022-03-09T13:40:59.3649Z","iopub.status.idle":"2022-03-09T13:40:59.401058Z","shell.execute_reply.started":"2022-03-09T13:40:59.364863Z","shell.execute_reply":"2022-03-09T13:40:59.400393Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_start","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.402353Z","iopub.execute_input":"2022-03-09T13:40:59.402789Z","iopub.status.idle":"2022-03-09T13:40:59.408398Z","shell.execute_reply.started":"2022-03-09T13:40:59.402752Z","shell.execute_reply":"2022-03-09T13:40:59.407593Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds_end","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.410054Z","iopub.execute_input":"2022-03-09T13:40:59.410761Z","iopub.status.idle":"2022-03-09T13:40:59.419349Z","shell.execute_reply.started":"2022-03-09T13:40:59.410722Z","shell.execute_reply":"2022-03-09T13:40:59.418576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.420649Z","iopub.execute_input":"2022-03-09T13:40:59.421068Z","iopub.status.idle":"2022-03-09T13:40:59.433636Z","shell.execute_reply.started":"2022-03-09T13:40:59.421032Z","shell.execute_reply":"2022-03-09T13:40:59.432967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['start'] = preds_start\ntest['end'] = preds_end\n\ntest['start'] = test['start'].astype(\"string\")\ntest['end'] = test['end'].astype(\"string\")","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.43496Z","iopub.execute_input":"2022-03-09T13:40:59.435809Z","iopub.status.idle":"2022-03-09T13:40:59.445504Z","shell.execute_reply.started":"2022-03-09T13:40:59.435772Z","shell.execute_reply":"2022-03-09T13:40:59.444763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test['location'] = test['start'] +\" \"+test['end']","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.446684Z","iopub.execute_input":"2022-03-09T13:40:59.447427Z","iopub.status.idle":"2022-03-09T13:40:59.455381Z","shell.execute_reply.started":"2022-03-09T13:40:59.447391Z","shell.execute_reply":"2022-03-09T13:40:59.454674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[['id', 'location']].to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-09T13:40:59.456624Z","iopub.execute_input":"2022-03-09T13:40:59.457049Z","iopub.status.idle":"2022-03-09T13:40:59.468659Z","shell.execute_reply.started":"2022-03-09T13:40:59.457011Z","shell.execute_reply":"2022-03-09T13:40:59.467988Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#modeli private kaydedelim yeni train ve inference notebookları açalım \n#discussion ve code kısmını okuyalım \n#deberta base ","metadata":{},"execution_count":null,"outputs":[]}]}