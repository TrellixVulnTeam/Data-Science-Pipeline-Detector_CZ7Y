{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np \nimport pandas as pd\nfrom sklearn.preprocessing import  LabelEncoder\nfrom tqdm.auto import tqdm\nimport random\nimport os\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport dill\nimport tensorflow.keras.backend as K\nfrom tqdm.auto import tqdm\nfrom tensorflow.keras import mixed_precision\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, AutoConfig,TFAutoModel\nimport json","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-02-03T04:36:40.7811Z","iopub.execute_input":"2022-02-03T04:36:40.781499Z","iopub.status.idle":"2022-02-03T04:36:48.28775Z","shell.execute_reply.started":"2022-02-03T04:36:40.781408Z","shell.execute_reply":"2022-02-03T04:36:48.28683Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\n\ntry: # detect TPUs\n    tpu  = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu )\n    tf.tpu.experimental.initialize_tpu_system(tpu )\n    strategy = tf.distribute.TPUStrategy(tpu )\n    print('Using TPU')\nexcept ValueError: # detect GPUs\n    tpu = None\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"jupyter":{"source_hidden":true,"outputs_hidden":true},"execution":{"iopub.status.busy":"2022-02-03T04:36:48.2893Z","iopub.execute_input":"2022-02-03T04:36:48.289516Z","iopub.status.idle":"2022-02-03T04:36:48.340538Z","shell.execute_reply.started":"2022-02-03T04:36:48.289491Z","shell.execute_reply":"2022-02-03T04:36:48.339765Z"},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=999\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nos.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\ntf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:48.341753Z","iopub.execute_input":"2022-02-03T04:36:48.34215Z","iopub.status.idle":"2022-02-03T04:36:48.34821Z","shell.execute_reply.started":"2022-02-03T04:36:48.342119Z","shell.execute_reply":"2022-02-03T04:36:48.347637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = False ","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:48.349343Z","iopub.execute_input":"2022-02-03T04:36:48.349658Z","iopub.status.idle":"2022-02-03T04:36:48.358835Z","shell.execute_reply.started":"2022-02-03T04:36:48.34963Z","shell.execute_reply":"2022-02-03T04:36:48.357774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Load dataframes","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/features.csv\")\npatient_notes = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/patient_notes.csv\")\ntest = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/test.csv\")\ntrain= pd.read_csv(\"../input/nbme-score-clinical-patient-notes/train.csv\")\nsample_submission= pd.read_csv(\"../input/nbme-score-clinical-patient-notes/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:48.361047Z","iopub.execute_input":"2022-02-03T04:36:48.361327Z","iopub.status.idle":"2022-02-03T04:36:49.625361Z","shell.execute_reply.started":"2022-02-03T04:36:48.361291Z","shell.execute_reply":"2022-02-03T04:36:49.624548Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.merge(patient_notes,on=['case_num','pn_num']).merge(features,on=['case_num','feature_num'])\ntrain = train.merge(patient_notes,on=['case_num','pn_num']).merge(features,on=['case_num','feature_num'])","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:49.626489Z","iopub.execute_input":"2022-02-03T04:36:49.626788Z","iopub.status.idle":"2022-02-03T04:36:49.678548Z","shell.execute_reply.started":"2022-02-03T04:36:49.626756Z","shell.execute_reply":"2022-02-03T04:36:49.677814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:49.679749Z","iopub.execute_input":"2022-02-03T04:36:49.68003Z","iopub.status.idle":"2022-02-03T04:36:49.698948Z","shell.execute_reply.started":"2022-02-03T04:36:49.679992Z","shell.execute_reply":"2022-02-03T04:36:49.698338Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"MODEL_NAME = 'bert-base-uncased'\nDATA_PATH = \"../input/nbmebertv1\"\nDATA_EXISTS = os.path.exists(DATA_PATH)\nSEQUENCE_LENGTH = 512","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:49.699832Z","iopub.execute_input":"2022-02-03T04:36:49.700457Z","iopub.status.idle":"2022-02-03T04:36:49.704371Z","shell.execute_reply.started":"2022-02-03T04:36:49.700422Z","shell.execute_reply":"2022-02-03T04:36:49.703707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DATA_EXISTS:\n    tokenizer = AutoTokenizer.from_pretrained(DATA_PATH+\"/my_tokenizer/\",normalization=True)\n    config = AutoConfig.from_pretrained(DATA_PATH+\"/my_tokenizer/config.json\")\nelse:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,normalization=True)\n    config = AutoConfig.from_pretrained(MODEL_NAME)\n    tokenizer.save_pretrained('my_tokenizer')\n    config.save_pretrained('my_tokenizer')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:49.705565Z","iopub.execute_input":"2022-02-03T04:36:49.705861Z","iopub.status.idle":"2022-02-03T04:36:49.768801Z","shell.execute_reply.started":"2022-02-03T04:36:49.705832Z","shell.execute_reply":"2022-02-03T04:36:49.767977Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encode the label","metadata":{}},{"cell_type":"code","source":"EMPTY =  'EMPTY'\nCLASSES = [EMPTY,]+features.feature_num.unique().tolist()\n\nif DATA_EXISTS:\n    label_encoder = dill.load(open(DATA_PATH+\"/label_encoder.dill\",'rb'))\nelse:\n    # label_encoder\n    label_encoder = LabelEncoder()\n    # Encode labels\n    label_encoder.fit(CLASSES)\n    dill.dump(label_encoder,open('label_encoder.dill','wb'))\ntrain['TARGET']= label_encoder.transform(train['feature_num'])\ntest['TARGET']= label_encoder.transform(test['feature_num'])\nN_CLASSES = len(label_encoder.classes_)\nEMPTY_IDX = label_encoder.transform([EMPTY,]) [0]","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:49.770088Z","iopub.execute_input":"2022-02-03T04:36:49.770589Z","iopub.status.idle":"2022-02-03T04:36:49.798442Z","shell.execute_reply.started":"2022-02-03T04:36:49.770543Z","shell.execute_reply":"2022-02-03T04:36:49.797636Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_location(locations):\n    for x in [\"[\",\"]\",\"'\"]:\n        locations = locations.replace(x,'')\n    locations = locations.replace(',',';')\n    locations = locations.split(\";\")\n    res = []\n    for location in locations:\n        if location:\n            x,y = location.split()\n            res.append((int(x),int(y)))\n    return sorted(res,key=lambda x:x[0])\n    ","metadata":{"_kg_hide-input":true,"jupyter":{"source_hidden":true},"execution":{"iopub.status.busy":"2022-02-03T04:36:49.79975Z","iopub.execute_input":"2022-02-03T04:36:49.80047Z","iopub.status.idle":"2022-02-03T04:36:49.807672Z","shell.execute_reply.started":"2022-02-03T04:36:49.800424Z","shell.execute_reply":"2022-02-03T04:36:49.806768Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DATA_EXISTS:\n    sequences = np.load(open(DATA_PATH+\"/sequences.npy\",'rb'))\n    masks = np.load(open(DATA_PATH+\"/masks.npy\",'rb'))\n    labels = np.load(open(DATA_PATH+\"/labels.npy\",'rb'))\nelse:\n    sequences, labels, masks = [], [], []\n    for g1 in tqdm(train.groupby('pn_num')):\n        gdf = g1[1]\n        pn_history  = gdf.iloc[0].pn_history\n\n        tokens = tokenizer.encode_plus(pn_history, max_length=SEQUENCE_LENGTH, padding='max_length',truncation=True, return_offsets_mapping=True)\n        sequence = tokens['input_ids']\n        attention_mask = tokens['attention_mask']\n        label = np.array([EMPTY_IDX for _ in range(SEQUENCE_LENGTH)])\n\n        # BUILD THE TARGET ARRAY\n        offsets = tokens['offset_mapping']\n        label_empty = True\n        for index, row in gdf.iterrows():\n            TARGET = row.TARGET\n            for i, (w_start, w_end) in enumerate(offsets):\n                for start,end in decode_location(row.location):\n                    if w_start < w_end and (w_start >= start) and (end >= w_end):\n                        label[i] = TARGET\n                        label_empty = False\n                    if w_start >= w_end:\n                        break\n        if not label_empty:\n            sequences.append(sequence)\n            masks.append(attention_mask)\n            labels.append(label)\n\n    sequences = np.array(sequences).astype(np.int32)\n    masks = np.array(masks).astype(np.uint8)\n    labels = np.array(tf.keras.utils.to_categorical(labels,N_CLASSES)).astype(np.uint8)\n\n    np.save(open(\"sequences.npy\",'wb'), sequences)\n    np.save(open(\"masks.npy\",'wb'), masks)\n    np.save(open(\"labels.npy\",'wb'), labels)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:49.809364Z","iopub.execute_input":"2022-02-03T04:36:49.809678Z","iopub.status.idle":"2022-02-03T04:36:50.443614Z","shell.execute_reply.started":"2022-02-03T04:36:49.809639Z","shell.execute_reply":"2022-02-03T04:36:50.442921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    \n    tokens = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'tokens', dtype=tf.int32)\n    attention = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'attention', dtype=tf.int32)\n    \n    if DATA_EXISTS:\n        config = AutoConfig.from_pretrained(DATA_PATH+\"/my_tokenizer/config.json\")\n        backbone = TFAutoModel.from_config(config)\n    else:\n        config = AutoConfig.from_pretrained(MODEL_NAME)\n        backbone = TFAutoModel.from_pretrained(MODEL_NAME,config=config)\n    \n    out = backbone(tokens, attention_mask=attention)[0]\n    out = tf.keras.layers.Dropout(0.2)(out)\n    out = tf.keras.layers.Dense(N_CLASSES, activation='softmax')(out)\n    \n    model = tf.keras.Model([tokens,attention],out)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:50.444567Z","iopub.execute_input":"2022-02-03T04:36:50.445108Z","iopub.status.idle":"2022-02-03T04:36:50.452941Z","shell.execute_reply.started":"2022-02-03T04:36:50.445074Z","shell.execute_reply":"2022-02-03T04:36:50.452104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"if TRAIN:\n    with strategy.scope():\n        model = build_model()\n\n        callback = tf.keras.callbacks.EarlyStopping(monitor='loss',mode='min', patience=3)\n\n        # Compile the model\n        model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n                      loss=tf.keras.losses.categorical_crossentropy,metrics=['acc',])\n\n        history = model.fit((sequences,masks),labels,\n                            batch_size=12,\n                            epochs=10,\n                            callbacks=[callback,])\n\n        model.save_weights(f'model.h5')","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:50.455658Z","iopub.execute_input":"2022-02-03T04:36:50.455909Z","iopub.status.idle":"2022-02-03T04:36:50.466159Z","shell.execute_reply.started":"2022-02-03T04:36:50.455881Z","shell.execute_reply":"2022-02-03T04:36:50.465642Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"if not TRAIN:\n    model = build_model()\n    model.load_weights(DATA_PATH+\"/model.h5\")","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:36:50.467088Z","iopub.execute_input":"2022-02-03T04:36:50.4674Z","iopub.status.idle":"2022-02-03T04:37:05.758553Z","shell.execute_reply.started":"2022-02-03T04:36:50.467373Z","shell.execute_reply":"2022-02-03T04:37:05.757589Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_sequences, test_masks, test_offsets = [], [],[]\nrow_ids = []\ntargets = []\n\nfor g1 in tqdm(test.groupby('pn_num')):\n    gdf = g1[1]\n    pn_history  = gdf.iloc[0].pn_history\n    targets.append([])\n    row_ids.append([])\n    \n    test_tokens = tokenizer.encode_plus(pn_history, max_length=SEQUENCE_LENGTH, padding='max_length',truncation=True, return_offsets_mapping=True)\n    test_sequence = test_tokens['input_ids']\n    test_attention_mask = test_tokens['attention_mask'] \n\n    # BUILD THE TARGET ARRAY\n    offset = test_tokens['offset_mapping']\n    \n    for index, row in gdf.iterrows():\n        targets[-1].append(row.TARGET)\n        row_ids[-1].append(row.id)\n         \n    test_sequences.append(test_sequence)\n    test_masks.append(test_attention_mask)\n    test_offsets.append(offset)\n\ntest_sequences = np.array(test_sequences).astype(np.int32)\ntest_masks = np.array(test_masks).astype(np.uint8)\ntargets_to_row_ids = [dict(zip(a,b)) for a,b in zip(targets,row_ids)]","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:37:05.75983Z","iopub.execute_input":"2022-02-03T04:37:05.760151Z","iopub.status.idle":"2022-02-03T04:37:05.814263Z","shell.execute_reply.started":"2022-02-03T04:37:05.760123Z","shell.execute_reply":"2022-02-03T04:37:05.813441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = model.predict((test_sequences,test_masks),batch_size=16)\npreds = np.argmax(preds,axis=-1)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:37:05.815593Z","iopub.execute_input":"2022-02-03T04:37:05.815835Z","iopub.status.idle":"2022-02-03T04:37:11.245808Z","shell.execute_reply.started":"2022-02-03T04:37:05.815806Z","shell.execute_reply":"2022-02-03T04:37:11.245187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_position(pos):\n    return \";\".join([\" \".join(np.array(p).astype(str)) for p in pos])\n\n\ndef translate(preds,targets_to_row_ids,offsets):\n    all_ids = []\n    all_pos = []\n\n    for k in range(len(preds)):\n        offset = offsets[k]\n        pred = preds[k]\n        targets_to_ids = targets_to_row_ids[k]\n        \n        prediction = {targets_to_ids[t]:[] for t in targets_to_ids}\n        i = 0\n        while i<SEQUENCE_LENGTH:\n            label = pred[i]\n            \n            if label == EMPTY_IDX:\n                i += 1\n                continue\n            if label in targets_to_ids:\n                key = targets_to_ids[label]\n                start = offset[i][0]\n                while i<SEQUENCE_LENGTH:\n                    if pred[i] != label:\n                        break\n                    else:\n                        end = max(offset[i])\n                    i += 1\n                if  end == 0:\n                    break\n                prediction[key].append((start,end))\n            else:\n                i+=1\n        for key in prediction:\n            all_ids.append(key)\n            all_pos.append(decode_position(prediction[key]))\n    df = pd.DataFrame({\n        \"id\":all_ids,\n        \"location\": all_pos\n    })\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-02-03T04:37:11.247208Z","iopub.execute_input":"2022-02-03T04:37:11.247529Z","iopub.status.idle":"2022-02-03T04:37:11.260009Z","shell.execute_reply.started":"2022-02-03T04:37:11.247488Z","shell.execute_reply":"2022-02-03T04:37:11.258865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = translate(preds,targets_to_row_ids,test_offsets)\nsub.to_csv('submission.csv',index=False)\nsub.head(50)","metadata":{"execution":{"iopub.status.busy":"2022-02-03T04:37:11.261048Z","iopub.execute_input":"2022-02-03T04:37:11.261248Z","iopub.status.idle":"2022-02-03T04:37:11.289739Z","shell.execute_reply.started":"2022-02-03T04:37:11.261223Z","shell.execute_reply":"2022-02-03T04:37:11.289206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}