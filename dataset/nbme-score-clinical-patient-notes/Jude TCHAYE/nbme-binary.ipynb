{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.preprocessing import  LabelEncoder\nfrom tqdm.auto import tqdm\nimport random\nimport os\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport dill\nimport tensorflow.keras.backend as K\nfrom tqdm.auto import tqdm\nfrom tensorflow.keras import mixed_precision\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom transformers import AutoTokenizer, AutoConfig,TFAutoModel\nimport json\nfrom sklearn.model_selection import StratifiedKFold,KFold\nimport gc\nimport string\nimport tensorflow_addons as tfa\nimport re\nimport ast\n#from sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n%env TOKENIZERS_PARALLELISM=true","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:04.830554Z","iopub.execute_input":"2022-04-26T12:43:04.831159Z","iopub.status.idle":"2022-04-26T12:43:12.394926Z","shell.execute_reply.started":"2022-04-26T12:43:04.831061Z","shell.execute_reply":"2022-04-26T12:43:12.394185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection._split import _BaseKFold, _RepeatedSplits\nfrom sklearn.utils.validation import check_random_state, column_or_1d\nfrom sklearn.utils.multiclass import type_of_target\nfrom collections import defaultdict\n\nclass StratifiedGroupKFold(_BaseKFold):\n    \"\"\"Stratified K-Folds iterator variant with non-overlapping groups.\n    This cross-validation object is a variation of StratifiedKFold attempts to\n    return stratified folds with non-overlapping groups. The folds are made by\n    preserving the percentage of samples for each class.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    The difference between GroupKFold and StratifiedGroupKFold is that\n    the former attempts to create balanced folds such that the number of\n    distinct groups is approximately the same in each fold, whereas\n    StratifiedGroupKFold attempts to create folds which preserve the\n    percentage of samples for each class as much as possible given the\n    constraint of non-overlapping groups between splits.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of folds. Must be at least 2.\n    shuffle : bool, default=False\n        Whether to shuffle each class's samples before splitting into batches.\n        Note that the samples within each split will not be shuffled.\n        This implementation can only shuffle groups that have approximately the\n        same y distribution, no global shuffle will be performed.\n    random_state : int or RandomState instance, default=None\n        When `shuffle` is True, `random_state` affects the ordering of the\n        indices, which controls the randomness of each fold for each class.\n        Otherwise, leave `random_state` as `None`.\n        Pass an int for reproducible output across multiple function calls.\n        See :term:`Glossary <random_state>`.\n    Examples\n    --------\n    >>> import numpy as np\n    >>> from sklearn.model_selection import StratifiedGroupKFold\n    >>> X = np.ones((17, 2))\n    >>> y = np.array([0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n    >>> groups = np.array([1, 1, 2, 2, 3, 3, 3, 4, 5, 5, 5, 5, 6, 6, 7, 8, 8])\n    >>> cv = StratifiedGroupKFold(n_splits=3)\n    >>> for train_idxs, test_idxs in cv.split(X, y, groups):\n    ...     print(\"TRAIN:\", groups[train_idxs])\n    ...     print(\"      \", y[train_idxs])\n    ...     print(\" TEST:\", groups[test_idxs])\n    ...     print(\"      \", y[test_idxs])\n    TRAIN: [1 1 2 2 4 5 5 5 5 8 8]\n           [0 0 1 1 1 0 0 0 0 0 0]\n     TEST: [3 3 3 6 6 7]\n           [1 1 1 0 0 0]\n    TRAIN: [3 3 3 4 5 5 5 5 6 6 7]\n           [1 1 1 1 0 0 0 0 0 0 0]\n     TEST: [1 1 2 2 8 8]\n           [0 0 1 1 0 0]\n    TRAIN: [1 1 2 2 3 3 3 6 6 7 8 8]\n           [0 0 1 1 1 1 1 0 0 0 0 0]\n     TEST: [4 5 5 5 5]\n           [1 0 0 0 0]\n    Notes\n    -----\n    The implementation is designed to:\n    * Mimic the behavior of StratifiedKFold as much as possible for trivial\n      groups (e.g. when each group contains only one sample).\n    * Be invariant to class label: relabelling ``y = [\"Happy\", \"Sad\"]`` to\n      ``y = [1, 0]`` should not change the indices generated.\n    * Stratify based on samples as much as possible while keeping\n      non-overlapping groups constraint. That means that in some cases when\n      there is a small number of groups containing a large number of samples\n      the stratification will not be possible and the behavior will be close\n      to GroupKFold.\n    See also\n    --------\n    StratifiedKFold: Takes class information into account to build folds which\n        retain class distributions (for binary or multiclass classification\n        tasks).\n    GroupKFold: K-fold iterator variant with non-overlapping groups.\n    \"\"\"\n\n    def __init__(self, n_splits=5, shuffle=False, random_state=None):\n        super().__init__(n_splits=n_splits, shuffle=shuffle, random_state=random_state)\n\n    def _iter_test_indices(self, X, y, groups):\n        # Implementation is based on this kaggle kernel:\n        # https://www.kaggle.com/jakubwasikowski/stratified-group-k-fold-cross-validation\n        # and is a subject to Apache 2.0 License. You may obtain a copy of the\n        # License at http://www.apache.org/licenses/LICENSE-2.0\n        # Changelist:\n        # - Refactored function to a class following scikit-learn KFold\n        #   interface.\n        # - Added heuristic for assigning group to the least populated fold in\n        #   cases when all other criteria are equal\n        # - Swtch from using python ``Counter`` to ``np.unique`` to get class\n        #   distribution\n        # - Added scikit-learn checks for input: checking that target is binary\n        #   or multiclass, checking passed random state, checking that number\n        #   of splits is less than number of members in each class, checking\n        #   that least populated class has more members than there are splits.\n        rng = check_random_state(self.random_state)\n        y = np.asarray(y)\n        type_of_target_y = type_of_target(y)\n        allowed_target_types = (\"binary\", \"multiclass\")\n        if type_of_target_y not in allowed_target_types:\n            raise ValueError(\n                \"Supported target types are: {}. Got {!r} instead.\".format(\n                    allowed_target_types, type_of_target_y\n                )\n            )\n\n        y = column_or_1d(y)\n        _, y_inv, y_cnt = np.unique(y, return_inverse=True, return_counts=True)\n        if np.all(self.n_splits > y_cnt):\n            raise ValueError(\n                \"n_splits=%d cannot be greater than the\"\n                \" number of members in each class.\" % (self.n_splits)\n            )\n        n_smallest_class = np.min(y_cnt)\n        if self.n_splits > n_smallest_class:\n            warnings.warn(\n                \"The least populated class in y has only %d\"\n                \" members, which is less than n_splits=%d.\"\n                % (n_smallest_class, self.n_splits),\n                UserWarning,\n            )\n        n_classes = len(y_cnt)\n\n        _, groups_inv, groups_cnt = np.unique(\n            groups, return_inverse=True, return_counts=True\n        )\n        y_counts_per_group = np.zeros((len(groups_cnt), n_classes))\n        for class_idx, group_idx in zip(y_inv, groups_inv):\n            y_counts_per_group[group_idx, class_idx] += 1\n\n        y_counts_per_fold = np.zeros((self.n_splits, n_classes))\n        groups_per_fold = defaultdict(set)\n\n        if self.shuffle:\n            rng.shuffle(y_counts_per_group)\n\n        # Stable sort to keep shuffled order for groups with the same\n        # class distribution variance\n        sorted_groups_idx = np.argsort(\n            -np.std(y_counts_per_group, axis=1), kind=\"mergesort\"\n        )\n\n        for group_idx in sorted_groups_idx:\n            group_y_counts = y_counts_per_group[group_idx]\n            best_fold = self._find_best_fold(\n                y_counts_per_fold=y_counts_per_fold,\n                y_cnt=y_cnt,\n                group_y_counts=group_y_counts,\n            )\n            y_counts_per_fold[best_fold] += group_y_counts\n            groups_per_fold[best_fold].add(group_idx)\n\n        for i in range(self.n_splits):\n            test_indices = [\n                idx\n                for idx, group_idx in enumerate(groups_inv)\n                if group_idx in groups_per_fold[i]\n            ]\n            yield test_indices\n\n    def _find_best_fold(self, y_counts_per_fold, y_cnt, group_y_counts):\n        best_fold = None\n        min_eval = np.inf\n        min_samples_in_fold = np.inf\n        for i in range(self.n_splits):\n            y_counts_per_fold[i] += group_y_counts\n            # Summarise the distribution over classes in each proposed fold\n            std_per_class = np.std(y_counts_per_fold / y_cnt.reshape(1, -1), axis=0)\n            y_counts_per_fold[i] -= group_y_counts\n            fold_eval = np.mean(std_per_class)\n            samples_in_fold = np.sum(y_counts_per_fold[i])\n            is_current_fold_better = (\n                fold_eval < min_eval\n                or np.isclose(fold_eval, min_eval)\n                and samples_in_fold < min_samples_in_fold\n            )\n            if is_current_fold_better:\n                min_eval = fold_eval\n                min_samples_in_fold = samples_in_fold\n                best_fold = i\n        return best_fold","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:12.396882Z","iopub.execute_input":"2022-04-26T12:43:12.397328Z","iopub.status.idle":"2022-04-26T12:43:12.418915Z","shell.execute_reply.started":"2022-04-26T12:43:12.39729Z","shell.execute_reply":"2022-04-26T12:43:12.418356Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# NEW on TPU in TensorFlow 24: shorter cross-compatible TPU/GPU/multi-GPU/cluster-GPU detection code\n\ntry: # detect TPUs\n    tpu  = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    tf.config.experimental_connect_to_cluster(tpu )\n    tf.tpu.experimental.initialize_tpu_system(tpu )\n    strategy = tf.distribute.TPUStrategy(tpu )\n    print('Using TPU')\nexcept ValueError: # detect GPUs\n    tpu = None\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # default strategy that works on CPU and single GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)\n\n\nAUTO = tf.data.experimental.AUTOTUNE\nREPLICAS = strategy.num_replicas_in_sync\nprint(f'REPLICAS: {REPLICAS}')","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:12.419945Z","iopub.execute_input":"2022-04-26T12:43:12.420278Z","iopub.status.idle":"2022-04-26T12:43:17.386513Z","shell.execute_reply.started":"2022-04-26T12:43:12.420248Z","shell.execute_reply":"2022-04-26T12:43:17.385368Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"seed=1234\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nos.environ['TF_ENABLE_AUTO_MIXED_PRECISION'] = '1'\ntf.config.optimizer.set_experimental_options({\"auto_mixed_precision\": True})\nprint('Mixed precision enabled')","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:17.388637Z","iopub.execute_input":"2022-04-26T12:43:17.388879Z","iopub.status.idle":"2022-04-26T12:43:17.39451Z","shell.execute_reply.started":"2022-04-26T12:43:17.388845Z","shell.execute_reply":"2022-04-26T12:43:17.393649Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TRAIN = False ","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:17.395674Z","iopub.execute_input":"2022-04-26T12:43:17.396369Z","iopub.status.idle":"2022-04-26T12:43:17.405926Z","shell.execute_reply.started":"2022-04-26T12:43:17.396335Z","shell.execute_reply":"2022-04-26T12:43:17.405151Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":" # Load dataframes","metadata":{}},{"cell_type":"code","source":"features = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/features.csv\")\npatient_notes = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/patient_notes.csv\")\ntest = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/test.csv\")\ntrain= pd.read_csv(\"../input/nbme-score-clinical-patient-notes/train.csv\")\nsample_submission= pd.read_csv(\"../input/nbme-score-clinical-patient-notes/sample_submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:17.407241Z","iopub.execute_input":"2022-04-26T12:43:17.408049Z","iopub.status.idle":"2022-04-26T12:43:18.171161Z","shell.execute_reply.started":"2022-04-26T12:43:17.407979Z","shell.execute_reply":"2022-04-26T12:43:18.170403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# https://www.kaggle.com/yasufuminakama/nbme-deberta-base-baseline-train\nfeatures.loc[27, 'feature_text'] = 'Last-Pap-smear-1-year-ago'\n\n# incorrect annotation\ntrain.loc[338, 'location'] = ('[[764 783]]')\n\ntrain.loc[621, 'location'] = ('[[77 100]]')\n\ntrain.loc[655, 'location'] = ('[[285 292;301 312], [285 287;296 312]]')\n\ntrain.loc[1262, 'location'] = ('[[551 557;565 580]]')\n\ntrain.loc[1265, 'location'] = ('[[131 135;181 212]]')\n\ntrain.loc[1396, 'location'] = ('[[259 280]]')\n\ntrain.loc[1591, 'location'] = ('[[176 184;201 212]]')\n\ntrain.loc[1615, 'location'] = ('[[249 257;271 288]]')\n\ntrain.loc[1664, 'location'] = ('[[822 824;907 924]]')\n\ntrain.loc[1714, 'location'] = ('[[101 129]]')\n\ntrain.loc[1929, 'location'] = ('[[531 539;549 561]]')\n\ntrain.loc[2134, 'location'] = ('[[540 560;581 593]]')\n\ntrain.loc[2191, 'location'] = ('[[32 57]]')\n\ntrain.loc[2553, 'location'] = ('[[308 317;376 384]]')\n\ntrain.loc[3124, 'location'] = ('[[549 557]]')\n\ntrain.loc[3858, 'location'] = ('[[102 123], [102 112;125 141], [102 112;143 157], [102 112;159 171]]')\n\ntrain.loc[4373, 'location'] = ('[[33 45]]')\n\ntrain.loc[4763, 'location'] = ('[[5 16]]')\n\ntrain.loc[4782, 'location'] = ('[[175 194]]')\n\ntrain.loc[4908, 'location'] = ('[[700 723]]')\n\ntrain.loc[6016, 'location'] = ('[[225 250]]')\n\ntrain.loc[6192, 'location'] = ('[[197 218;236 260]]')\n\ntrain.loc[6380, 'location'] = ('[[480 482;507 519], [480 482;499 503;512 519], [480 482;521 531], [480 482;533 545], [480 482;564 582]]')\n\ntrain.loc[6562, 'location'] = ('[[290 320;327 337], [290 320;342 358]]')\n\ntrain.loc[6862, 'location'] = ('[[288 296;324 363]]')\n\ntrain.loc[7022, 'location'] = ('[[108 182]]')\n\ntrain.loc[7422, 'location'] = ('[[102 121]]')\n\ntrain.loc[8876, 'location'] = ('[[481 483;533 552]]')\n\ntrain.loc[9027, 'location'] = ('[[92 102], [123 164]]')\n\ntrain.loc[9938, 'location'] = ('[[89 117], [122 138], [368 402]]')\n\ntrain.loc[9973, 'location'] = ('[[344 361]]')\n\ntrain.loc[10513, 'location'] = ('[[600 611], [607 623]]')\n\ntrain.loc[11551, 'location'] = ('[[386 400;443 461]]')\n\ntrain.loc[11677, 'location'] = ('[[160 201]]')\n\ntrain.loc[12124, 'location'] = ('[[325 337;349 366]]')\n\ntrain.loc[12279, 'location'] = ('[[405 459;488 524]]')\n\ntrain.loc[12289, 'location'] = ('[[353 400;488 524]]')\n\ntrain.loc[13238, 'location'] = ('[[293 307], [321 331]]')\n\ntrain.loc[13297, 'location'] = ('[[182 221], [182 213;225 234]]')\n\ntrain.loc[13299, 'location'] = ('[[79 88], [409 418]]')\n\ntrain.loc[13845, 'location'] = ('[[86 94;230 236], [86 94;237 256]]')\n\ntrain.loc[14083, 'location'] = ('[[56 64;156 179]]')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:18.172672Z","iopub.execute_input":"2022-04-26T12:43:18.17294Z","iopub.status.idle":"2022-04-26T12:43:18.220079Z","shell.execute_reply.started":"2022-04-26T12:43:18.172903Z","shell.execute_reply":"2022-04-26T12:43:18.21936Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = test.merge(patient_notes,on=['case_num','pn_num']).merge(features,on=['case_num','feature_num'])\ntrain = train.merge(patient_notes,on=['case_num','pn_num']).merge(features,on=['case_num','feature_num'])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:18.223137Z","iopub.execute_input":"2022-04-26T12:43:18.223423Z","iopub.status.idle":"2022-04-26T12:43:18.265513Z","shell.execute_reply.started":"2022-04-26T12:43:18.223382Z","shell.execute_reply":"2022-04-26T12:43:18.264678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:18.267117Z","iopub.execute_input":"2022-04-26T12:43:18.267408Z","iopub.status.idle":"2022-04-26T12:43:18.288655Z","shell.execute_reply.started":"2022-04-26T12:43:18.267369Z","shell.execute_reply":"2022-04-26T12:43:18.287875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(['case_num','feature_num']).count()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:18.292637Z","iopub.execute_input":"2022-04-26T12:43:18.292858Z","iopub.status.idle":"2022-04-26T12:43:18.327834Z","shell.execute_reply.started":"2022-04-26T12:43:18.292831Z","shell.execute_reply":"2022-04-26T12:43:18.326906Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenizer","metadata":{}},{"cell_type":"code","source":"#MODEL_NAME = \"bert-large-uncased\"\nMODEL_NAME = \"roberta-large\"\nDATA_PATH = \"../input/nbmebinary\"\nDATA_EXISTS = os.path.exists(DATA_PATH)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:18.329324Z","iopub.execute_input":"2022-04-26T12:43:18.329691Z","iopub.status.idle":"2022-04-26T12:43:18.335455Z","shell.execute_reply.started":"2022-04-26T12:43:18.329651Z","shell.execute_reply":"2022-04-26T12:43:18.334493Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DATA_EXISTS and TRAIN:\n    ! cp -r ../input/nbmebinary/my_tokenizer .\n    ! cp ../input/nbmebinary/*.dill .","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:18.337487Z","iopub.execute_input":"2022-04-26T12:43:18.337814Z","iopub.status.idle":"2022-04-26T12:43:20.026502Z","shell.execute_reply.started":"2022-04-26T12:43:18.337772Z","shell.execute_reply":"2022-04-26T12:43:20.025498Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN and not DATA_EXISTS:\n    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME,do_lower_case=True)\n    config = AutoConfig.from_pretrained(MODEL_NAME)\n    tokenizer.save_pretrained('my_tokenizer')\n    config.save_pretrained('my_tokenizer')\nelse:\n    tokenizer = AutoTokenizer.from_pretrained(DATA_PATH+\"/my_tokenizer\",do_lower_case=True)\n    config = AutoConfig.from_pretrained(DATA_PATH+\"/my_tokenizer/config.json\")\ntokenizer.special_tokens = {\n        \"sep\": tokenizer.sep_token_id,\n        \"cls\": tokenizer.cls_token_id,\n        \"pad\": tokenizer.pad_token_id,\n}","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.029279Z","iopub.execute_input":"2022-04-26T12:43:20.029834Z","iopub.status.idle":"2022-04-26T12:43:20.252103Z","shell.execute_reply.started":"2022-04-26T12:43:20.029793Z","shell.execute_reply":"2022-04-26T12:43:20.251242Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tok = tokenizer(\"jude le s\",\"jude le s\",\n        return_token_type_ids=True,\n        return_offsets_mapping=True,\n        return_attention_mask=False,\n        add_special_tokens=True,\n)\ntok","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.253598Z","iopub.execute_input":"2022-04-26T12:43:20.253849Z","iopub.status.idle":"2022-04-26T12:43:20.270486Z","shell.execute_reply.started":"2022-04-26T12:43:20.253814Z","shell.execute_reply":"2022-04-26T12:43:20.269807Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def filter_offset(offsets):\n    a,b = 0,0\n    arr = []\n    lp = True\n    for x,y in offsets:\n        if a<=x and b<=y and lp:\n            a,b = x,y\n            arr.append((-1,-1))\n        else:\n            lp = False\n            arr.append((x,y))\n    return arr\nfilter_offset(tok[\"offset_mapping\"])","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.271875Z","iopub.execute_input":"2022-04-26T12:43:20.272143Z","iopub.status.idle":"2022-04-26T12:43:20.281756Z","shell.execute_reply.started":"2022-04-26T12:43:20.272108Z","shell.execute_reply":"2022-04-26T12:43:20.280925Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Build data","metadata":{}},{"cell_type":"code","source":"FEATURES = features.feature_num.unique().tolist()\nSEQUENCE_LENGTH = 512","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.283117Z","iopub.execute_input":"2022-04-26T12:43:20.283754Z","iopub.status.idle":"2022-04-26T12:43:20.289784Z","shell.execute_reply.started":"2022-04-26T12:43:20.283706Z","shell.execute_reply":"2022-04-26T12:43:20.289019Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_location(locations):\n    for x in [\"[\",\"]\",\"'\"]:\n        locations = locations.replace(x,'')\n    locations = locations.replace(',',';')\n    locations = locations.split(\";\")\n    res = []\n    for location in locations:\n        if location:\n            x,y = location.split()\n            res.append((int(x),int(y)))\n    return sorted(res,key=lambda x:x[0])\n\ndef process_feature_text(text):\n    text = re.sub('I-year', '1-year', text)\n    text = re.sub('-OR-', \" or \", text)\n    text = re.sub('-', ' ', text)\n    return text\n\ndef clean_spaces(txt):\n    txt = re.sub('\\n', ' ', txt)\n    txt = re.sub('\\t', ' ', txt)\n    txt = re.sub('\\r', ' ', txt)\n    return txt\n\ndef prepare_df(df):\n    df['feature_text'] = df['feature_text'].apply(process_feature_text)\n    df['feature_text'] = df['feature_text'].apply(clean_spaces)\n    df['pn_history'] = df['pn_history'].apply(clean_spaces)\n    return df","metadata":{"_kg_hide-input":true,"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:20.291175Z","iopub.execute_input":"2022-04-26T12:43:20.29178Z","iopub.status.idle":"2022-04-26T12:43:20.303558Z","shell.execute_reply.started":"2022-04-26T12:43:20.291733Z","shell.execute_reply":"2022-04-26T12:43:20.302771Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = prepare_df(train)\ntest = prepare_df(test)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.304771Z","iopub.execute_input":"2022-04-26T12:43:20.305248Z","iopub.status.idle":"2022-04-26T12:43:20.521509Z","shell.execute_reply.started":"2022-04-26T12:43:20.305207Z","shell.execute_reply":"2022-04-26T12:43:20.520802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_data(df,train=True):\n    input_ids_arr,token_type_ids_arr,answers =[],[],[]\n    row_ids,feature_ids ,case_ids,offsets_arr = [],[],[],[]\n    \n    for g1 in tqdm(df.groupby('pn_num')):\n        gdf = g1[1]\n        pn_history  = gdf.iloc[0].pn_history\n\n        for index, row in gdf.iterrows():\n            feature_text = row.feature_text\n            \n            tokens = tokenizer(\n                    feature_text,pn_history,\n                    return_token_type_ids=True,\n                    return_offsets_mapping=True,\n                    return_attention_mask=False,\n                    add_special_tokens=True,\n                    padding='max_length',\n                    max_length=SEQUENCE_LENGTH\n            )\n            \n            input_ids = np.array(tokens['input_ids'],dtype=np.int32)\n            token_type_ids = np.array(tokens['token_type_ids'],dtype=np.uint8)\n            offsets = filter_offset(tokens['offset_mapping'])\n            answer_mask = np.zeros(SEQUENCE_LENGTH,dtype=np.uint8)\n            # Answer mask\n            if train:\n                for i, (w_start, w_end) in enumerate(offsets):\n                    if w_end==-1:\n                        continue\n                    for start,end in decode_location(row.location):\n                        start,end = start,end\n                        if w_start < w_end and (w_start >= start) and (end >= w_end):\n                            answer_mask[i] = 1\n                        if w_start >= w_end:\n                            break\n            row_ids.append(row.id)\n            input_ids_arr.append(input_ids)\n            token_type_ids_arr.append(token_type_ids)\n            answers.append(answer_mask)\n            feature_ids.append(row.feature_num)\n            case_ids.append(row.case_num)\n            offsets_arr.append(offsets)\n            \n    input_ids_arr = np.array(input_ids_arr,dtype=np.int32)\n    token_type_ids_arr = np.array(token_type_ids_arr,dtype=np.uint8)\n    answers = np.array(answers,dtype=np.uint8)\n    feature_ids = np.array(feature_ids,dtype=np.int32)\n    case_ids = np.array(case_ids,dtype=np.int32)\n    if train:\n        return feature_ids,case_ids,input_ids_arr,token_type_ids_arr,answers\n    else:\n        return row_ids,offsets_arr,feature_ids,input_ids_arr,token_type_ids_arr","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:20.522624Z","iopub.execute_input":"2022-04-26T12:43:20.522856Z","iopub.status.idle":"2022-04-26T12:43:20.538622Z","shell.execute_reply.started":"2022-04-26T12:43:20.522825Z","shell.execute_reply":"2022-04-26T12:43:20.537856Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DATA_EXISTS:\n    data = dill.load(open(DATA_PATH+\"/data.dill\",'rb'))\nelse:\n    data = build_data(train)\n    dill.dump(data,open('data.dill','wb'))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.540097Z","iopub.execute_input":"2022-04-26T12:43:20.540358Z","iopub.status.idle":"2022-04-26T12:43:20.604746Z","shell.execute_reply.started":"2022-04-26T12:43:20.54032Z","shell.execute_reply":"2022-04-26T12:43:20.604004Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data[-1].sum(axis=-1).max()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.607119Z","iopub.execute_input":"2022-04-26T12:43:20.607634Z","iopub.status.idle":"2022-04-26T12:43:20.623237Z","shell.execute_reply.started":"2022-04-26T12:43:20.607595Z","shell.execute_reply":"2022-04-26T12:43:20.622571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV split","metadata":{}},{"cell_type":"code","source":"def to_dataset(data,batch_size=32 if tpu else 4,shuffle=True):\n    ds = tf.data.Dataset.from_tensor_slices(data).map(lambda a,b,c:((a,b),c))\n    size = len(ds)\n    steps = size//batch_size\n    ds = ds.repeat()\n    if shuffle:\n        ds = ds.shuffle(size)\n    ds = ds.batch(batch_size).prefetch(buffer_size=AUTO)\n    return ds,steps","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.62592Z","iopub.execute_input":"2022-04-26T12:43:20.626182Z","iopub.status.idle":"2022-04-26T12:43:20.634222Z","shell.execute_reply.started":"2022-04-26T12:43:20.626131Z","shell.execute_reply":"2022-04-26T12:43:20.633487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_splits = 5\ncv = StratifiedGroupKFold(n_splits=n_splits,shuffle=True,random_state=seed)\nfeature_ids,case_ids,input_ids_arr,token_type_ids_arr,answers = data\ndata_splits = []","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.637452Z","iopub.execute_input":"2022-04-26T12:43:20.637914Z","iopub.status.idle":"2022-04-26T12:43:20.642876Z","shell.execute_reply.started":"2022-04-26T12:43:20.637886Z","shell.execute_reply":"2022-04-26T12:43:20.642112Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"groups = train['pn_num'].values\nfor n, (train_index, val_index) in enumerate(cv.split(feature_ids , feature_ids,case_ids)):\n    train_data = input_ids_arr[train_index],token_type_ids_arr[train_index],answers[train_index]\n    test_data = input_ids_arr[val_index],token_type_ids_arr[val_index],answers[val_index]\n    data_splits.append((to_dataset(train_data),to_dataset(test_data,shuffle=False)))\n    del train_data,test_data","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:20.644397Z","iopub.execute_input":"2022-04-26T12:43:20.644767Z","iopub.status.idle":"2022-04-26T12:43:21.070543Z","shell.execute_reply.started":"2022-04-26T12:43:20.644729Z","shell.execute_reply":"2022-04-26T12:43:21.069707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Define Model","metadata":{}},{"cell_type":"code","source":"def build_model():\n    \n    tokens = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'tokens', dtype=tf.int32)\n    token_type_id = tf.keras.layers.Input(shape=(SEQUENCE_LENGTH,), name = 'token_type_id', dtype=tf.int32)\n    \n    if not TRAIN:\n        config = AutoConfig.from_pretrained(DATA_PATH+\"/my_tokenizer/config.json\")\n        backbone = TFAutoModel.from_config(config)\n    else:\n        print(f\"Loading {MODEL_NAME}...\")\n        config = AutoConfig.from_pretrained(MODEL_NAME)\n        backbone = TFAutoModel.from_pretrained(MODEL_NAME,config=config)\n    # Freez some layers\n    #backbone.roberta.embeddings.trainable = False\n    #for w in backbone.roberta.weights:\n    #    for i in range(0,12):\n    #        name = f'/layer_._{i}/'\n    #        if w.name.find(name) != -1 :\n    #            #print(i,w.name)\n     #           w._trainable = False\n                \n    attention = tf.keras.layers.Lambda(lambda x : tf.cast(x != tokenizer.pad_token_id,tf.float32))(tokens)\n    out = backbone(tokens, attention_mask=attention,token_type_ids=token_type_id)[0]\n    \n    out = tf.keras.layers.Dropout(0.2)(out)\n    out = tf.keras.layers.Dense(1, activation='sigmoid')(out)\n    \n    model = tf.keras.Model([tokens,token_type_id],out)\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:21.071699Z","iopub.execute_input":"2022-04-26T12:43:21.071941Z","iopub.status.idle":"2022-04-26T12:43:21.082435Z","shell.execute_reply.started":"2022-04-26T12:43:21.071908Z","shell.execute_reply":"2022-04-26T12:43:21.08163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#build_model().summary()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:21.083901Z","iopub.execute_input":"2022-04-26T12:43:21.084495Z","iopub.status.idle":"2022-04-26T12:43:21.089859Z","shell.execute_reply.started":"2022-04-26T12:43:21.084457Z","shell.execute_reply":"2022-04-26T12:43:21.089003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class MyModel(keras.Model):\n    def __init__(self,th=0.8):\n        super(MyModel,self).__init__()\n        self.model = build_model()\n        self.th = th\n        \n    def call(self, inputs, training=True):\n        return self.model(inputs, training=training)\n    \n    @tf.function\n    def pseudo_label(self,data):\n        (tokens,token_type_id),y = data\n        mask = y == 0\n        mask = tf.reduce_all(mask,axis=-1)\n        if tf.reduce_any(mask):\n            y_ps = self((tokens,token_type_id),training=False)\n            y_ps = tf.reshape(y_ps,tf.shape(y))\n            y_ps = tf.cast(y_ps >= self.th,y.dtype)\n\n            mask = tf.repeat(mask[:,None],SEQUENCE_LENGTH,axis=-1)\n            mask = tf.cast(mask,y_ps.dtype)\n            y = y + (y_ps*mask)\n            return (tokens,token_type_id),y\n        else:\n            return data\n    \n    def train_step(self, data):\n        data = self.pseudo_label(data)\n        return super().train_step(data)\n        \n    def get_config(self):\n        return {}","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:21.091444Z","iopub.execute_input":"2022-04-26T12:43:21.092057Z","iopub.status.idle":"2022-04-26T12:43:21.102818Z","shell.execute_reply.started":"2022-04-26T12:43:21.09202Z","shell.execute_reply":"2022-04-26T12:43:21.102074Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model training","metadata":{}},{"cell_type":"code","source":"gc.collect()","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:21.107444Z","iopub.execute_input":"2022-04-26T12:43:21.107941Z","iopub.status.idle":"2022-04-26T12:43:21.328918Z","shell.execute_reply.started":"2022-04-26T12:43:21.107913Z","shell.execute_reply":"2022-04-26T12:43:21.328Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras import backend as K\n\ndef recall_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n    recall = true_positives / (possible_positives + K.epsilon())\n    return recall\n\ndef precision_m(y_true, y_pred):\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n    precision = true_positives / (predicted_positives + K.epsilon())\n    return precision\n\ndef f1_m(y_true, y_pred):\n    precision = precision_m(y_true, y_pred)\n    recall = recall_m(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:21.330359Z","iopub.execute_input":"2022-04-26T12:43:21.330698Z","iopub.status.idle":"2022-04-26T12:43:21.339689Z","shell.execute_reply.started":"2022-04-26T12:43:21.33066Z","shell.execute_reply":"2022-04-26T12:43:21.338806Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 30\ninit_lr = 1e-7","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:21.341931Z","iopub.execute_input":"2022-04-26T12:43:21.342482Z","iopub.status.idle":"2022-04-26T12:43:21.348838Z","shell.execute_reply.started":"2022-04-26T12:43:21.342441Z","shell.execute_reply":"2022-04-26T12:43:21.348Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    val_key = \"val_f1_m\"\n    scores = []\n    with strategy.scope():\n        i = 0\n        for (train_ds,steps_per_epoch),(test_ds,steps) in data_splits:\n            print(f\">>>>SPLIT : {i+1}\")\n            model = MyModel()#build_model()\n            \n            x = np.zeros((1,SEQUENCE_LENGTH)),np.zeros((1,SEQUENCE_LENGTH))\n            model(x);\n            model.load_weights(f\"../input/nbmebinary/model{i}.h5\")\n            \n            callback = tf.keras.callbacks.EarlyStopping(monitor=val_key,mode='max', patience=10)\n            ckp_callback = tf.keras.callbacks.ModelCheckpoint(\n                                                    filepath=f'model{i}.h5',\n                                                    save_weights_only=True,\n                                                    monitor=val_key,\n                                                    mode='max',\n                                                    options=tf.train.CheckpointOptions(experimental_io_device='/job:localhost'),\n                                                    save_best_only=True)\n            reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=val_key,mode='max',factor=0.2,patience=5, min_lr=1e-6)\n            callbacks=[callback,ckp_callback,reduce_lr]\n            # Compile the model\n            model.compile(optimizer=tf.keras.optimizers.Adam(init_lr),\n                          loss=tf.keras.losses.BinaryCrossentropy(),\n                          metrics=['acc',f1_m])\n\n            history = model.fit(train_ds,\n                                steps_per_epoch=steps_per_epoch,\n                                validation_data=test_ds,\n                                validation_steps=steps,\n                                epochs=epochs,\n                                callbacks=callbacks)\n            scores.append(max(history.history[val_key]))\n            i += 1","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:55.083272Z","iopub.execute_input":"2022-04-26T12:43:55.08384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if TRAIN:\n    print(scores)\n    print(f\"CV Score : {np.mean(scores)}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.807805Z","iopub.status.idle":"2022-04-26T12:43:41.808107Z","shell.execute_reply.started":"2022-04-26T12:43:41.807937Z","shell.execute_reply":"2022-04-26T12:43:41.807971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submit","metadata":{}},{"cell_type":"code","source":"#test = train","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.810177Z","iopub.status.idle":"2022-04-26T12:43:41.81081Z","shell.execute_reply.started":"2022-04-26T12:43:41.810575Z","shell.execute_reply":"2022-04-26T12:43:41.810599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row_ids,offsets,feature_ids,input_ids,token_type_ids = build_data(test,train=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.812009Z","iopub.status.idle":"2022-04-26T12:43:41.812626Z","shell.execute_reply.started":"2022-04-26T12:43:41.812392Z","shell.execute_reply":"2022-04-26T12:43:41.812416Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"input_ids.shape,token_type_ids.shape","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.813818Z","iopub.status.idle":"2022-04-26T12:43:41.814428Z","shell.execute_reply.started":"2022-04-26T12:43:41.814198Z","shell.execute_reply":"2022-04-26T12:43:41.814222Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = MyModel()\npath =  DATA_PATH if not TRAIN else \".\"","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.815601Z","iopub.status.idle":"2022-04-26T12:43:41.81621Z","shell.execute_reply.started":"2022-04-26T12:43:41.815972Z","shell.execute_reply":"2022-04-26T12:43:41.815996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model((input_ids[:2],token_type_ids[:2]));","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.817377Z","iopub.status.idle":"2022-04-26T12:43:41.817979Z","shell.execute_reply.started":"2022-04-26T12:43:41.81774Z","shell.execute_reply":"2022-04-26T12:43:41.817764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"preds = []\nfor i in range(n_splits):\n    print(f\"SPLIT {i}\")\n    model.load_weights(path+f\"/model{i}.h5\")\n    pred = model.predict((input_ids,token_type_ids),batch_size=16)\n    preds.append(pred)\npreds = np.mean(preds,axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.819165Z","iopub.status.idle":"2022-04-26T12:43:41.819771Z","shell.execute_reply.started":"2022-04-26T12:43:41.819539Z","shell.execute_reply":"2022-04-26T12:43:41.819563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_special_ids = set(tokenizer.all_special_ids)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.820991Z","iopub.status.idle":"2022-04-26T12:43:41.821619Z","shell.execute_reply.started":"2022-04-26T12:43:41.821385Z","shell.execute_reply":"2022-04-26T12:43:41.82141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def decode_position(pos):\n    return \";\".join([\" \".join(np.array(p).astype(str)) for p in pos])\n\ndef prediction_pad(preds,spans=5):\n    if len(preds)<2:\n        return preds\n    preds = sorted(preds)\n    stop = False\n    while not stop:\n        stop = True\n        for i in range(len(preds)-1):\n            pred1 = preds[i]\n            pred2 = preds[i+1]\n            if pred2[0]-pred1[1] <= spans:\n                new_pred = (pred1[0],max(pred1[1],pred2[1]))\n                preds = preds[:i]+[new_pred,]+preds[i+2:]\n                stop = False\n                break\n    return preds\n\n\ndef translate(preds,row_ids,input_ids,offsets,token_type_ids,feature_ids):\n    all_ids = []\n    all_pos = []\n    preds = preds[:,:,0]\n\n    for k in range(len(preds)):\n        offset = offsets[k]\n        pred = preds[k]\n        row_id = row_ids[k]\n        input_id = input_ids[k]\n        token_type_id = token_type_ids[k]\n        feature_id = feature_ids[k]\n        prediction = []\n        pred = (pred>0.5).astype(np.uint8)\n        \n        i = 0\n        while i<SEQUENCE_LENGTH:\n            if int(input_id[i]) in all_special_ids:\n                i += 1\n                continue\n            if pred[i] == 0:\n                i += 1\n                continue\n            if offset[i][0] == -1:\n                i += 1\n                continue\n            if pred[i] == 1:\n                start = min(offset[i])\n                end = max(offset[i])\n                while i<SEQUENCE_LENGTH:\n                    if pred[i] != 1:\n                        break\n                    elif int(input_id[i]) in all_special_ids:\n                        break\n                    else:\n                        end = max(offset[i])\n                    i += 1\n                prediction.append((start,end))\n                i += 1\n            else:\n                i+=1\n        all_ids.append(row_id)\n        all_pos.append(decode_position(prediction_pad(prediction)))\n            \n    df = pd.DataFrame({\n        \"id\":all_ids,\n        \"location\": all_pos\n    })\n    return df","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2022-04-26T12:43:41.822855Z","iopub.status.idle":"2022-04-26T12:43:41.823468Z","shell.execute_reply.started":"2022-04-26T12:43:41.823237Z","shell.execute_reply":"2022-04-26T12:43:41.823261Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub = translate(preds,row_ids,input_ids,offsets,token_type_ids,feature_ids)\nsub.to_csv('submission.csv',index=False)\nsub.head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.824667Z","iopub.status.idle":"2022-04-26T12:43:41.825295Z","shell.execute_reply.started":"2022-04-26T12:43:41.825066Z","shell.execute_reply":"2022-04-26T12:43:41.825091Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sort_values(by=\"id\").reset_index()[[\"id\",\"location\"]].head(5)","metadata":{"execution":{"iopub.status.busy":"2022-04-26T12:43:41.826481Z","iopub.status.idle":"2022-04-26T12:43:41.827087Z","shell.execute_reply.started":"2022-04-26T12:43:41.826836Z","shell.execute_reply":"2022-04-26T12:43:41.826859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}