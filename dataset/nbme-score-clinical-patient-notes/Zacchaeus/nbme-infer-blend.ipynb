{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip uninstall -y transformers\n!pip install -q ../input/nbme-git/transformers-4.19.0.dev0-py3-none-any.whl\n!cp ../input/nbme-git/nbme/src/* ./\n!ls","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-02T17:01:16.214939Z","iopub.execute_input":"2022-05-02T17:01:16.215345Z","iopub.status.idle":"2022-05-02T17:01:54.251756Z","shell.execute_reply.started":"2022-05-02T17:01:16.215244Z","shell.execute_reply":"2022-05-02T17:01:54.250936Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from data_utils import NBMEDatasetInfer, preprocess_features, prepare_input\nfrom model_utils import NBMEModel\nfrom transformers import AutoTokenizer, TrainingArguments, Trainer, DataCollatorForTokenClassification\nfrom torch.utils.data import DataLoader, Dataset\nimport pandas as pd\nimport torch\nimport torch.nn.functional as F\nfrom tqdm import tqdm\nimport numpy as np\nfrom eval_utils import get_char_logits, get_predictions, my_get_results\nimport os\nimport itertools\ntorch.set_grad_enabled(False)\nDEBUG = False\nBS = 4\n\n# # blend-2 0.8937\n# CHECKPOINTS = [\n#     '../input/hf-models/facebook_bart-large',\n#     '../input/huggingface-deberta-variants/deberta-base/deberta-base',\n#     '../input/roberta-transformers-pytorch/roberta-base',\n#     '../input/roberta-transformers-pytorch/roberta-large',\n#     '../input/hf-models/facebook_muppet-roberta-large',\n# ]\n# PATHS = [\n#     '../input/3a81-bart-large',\n#     '../input/pl-3a81-deberta-base',\n#     '../input/pl-3a81-roberta-base',\n#     '../input/pl-b7ce-roberta-large',\n#     '../input/pl-b7ce-muppet-roberta-large',\n# ]\n# FIXOFFS = [\n#     False,\n#     False,\n#     False,\n#     False,\n#     False,\n# ]\n# WEIGHTS = {\n#     'w0': 0.2610187004907005, \n#     'w1': 0.97620912150936, \n#     'w2': 0.3940880203235138, \n#     'w3': 0.4616469943029971, \n#     'w4': 0.8740497164412215,\n# }\n\n# # blend-3 0.8940\n# CHECKPOINTS = [\n#     '../input/hf-models/facebook_bart-large',\n#     '../input/huggingface-deberta-variants/deberta-base/deberta-base',\n#     '../input/roberta-transformers-pytorch/roberta-base',\n#     '../input/hf-models/facebook_bart-large-mnli/',\n#     '../input/roberta-transformers-pytorch/roberta-large',\n#     '../input/hf-models/facebook_muppet-roberta-large',\n# ]\n# PATHS = [\n#     '../input/3a81-bart-large',\n#     '../input/pl-3a81-deberta-base',\n#     '../input/pl-3a81-roberta-base',\n#     '../input/pl-3a81-bart-large-mnli',\n#     '../input/pl-b7ce-roberta-large',\n#     '../input/pl-b7ce-muppet-roberta-large',\n# ]\n# FIXOFFS = [\n#     False,\n#     False,\n#     False,\n#     False,\n#     False,\n#     False,\n# ]\n# WEIGHTS = {\n#     'w0': 0.3290705659298224, \n#     'w1': 0.8982042839509254, \n#     'w2': 0.2806373725161175, \n#     'w3': 0.712216288704943, \n#     'w4': 0.8471567075865541, \n#     'w5': 0.08386150855273114,\n# }\n\n# blend-4 0.8961\n# CHECKPOINTS = [\n#     '../input/roberta-transformers-pytorch/roberta-large',\n#     '../input/huggingface-deberta-variants/deberta-base/deberta-base',\n#     '../input/hf-models/nghuyong_ernie-2.0-large-en',\n#     '../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli',\n#     '../input/hf-models/microsoft_deberta-v3-large',\n# ]\n# PATHS = [\n#     '../input/pl-b7ce-roberta-large',\n#     '../input/pl-3a81-deberta-base',\n#     '../input/pl-3a81-ernie2-large-en',\n#     '../input/pl-3a81-deberta-large-mnli',\n#     '../input/pl-3a81-deberta-v3-large',\n# ]\n# FIXOFFS = [\n#     False,\n#     False,\n#     True,\n#     False,\n#     False,\n# ]\n# WEIGHTS = {\n#     'w0': 0.33915131925799213, \n#     'w1': 0.6919711522755465, \n#     'w2': 0.6449311288255997, \n#     'w3': 0.30586354998287263, \n#     'w4': 0.8212312568166007\n# }\n\n# CHECKPOINTS = [\n#     '../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge',\n# ]\n# PATHS = [\n#     '../input/pl-3a81-deberta-xlarge',\n# ]\n# FIXOFFS = [\n#     False,\n# ]\n# WEIGHTS = {\n#     'w0': 1, \n# }\n\n# blend-14 0.8967\n# CHECKPOINTS = [\n#     '../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli',\n#     '../input/hf-models/microsoft_deberta-v3-large',\n#     '../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge',\n#     '../input/deberta-v2-xlarge',\n# ]\n# PATHS = [\n#     '../input/pl-3a81-deberta-large-mnli',\n#     '../input/pl-3a81-deberta-v3-large',\n#     '../input/pl-3a81-deberta-xlarge',\n#     '../input/pl-3a81-deberta-v2-xlarge-mnli',\n# ]\n# FIXOFFS = [\n#     False,\n#     False,\n#     False,\n#     False,\n# ]\n# WEIGHTS = {\n#     'w0': 0.24077767284607712, \n#     'w1': 0.6090344856736725, \n#     'w2': 0.9677762586972335, \n#     'w3': 0.18805287188563702\n# }\n# WEIGHTS = {\n#     'w0': 1, \n#     'w1': 1, \n#     'w2': 1, \n#     'w3': 1\n# }\n\n# blend-20 0.8967\nCHECKPOINTS = [\n    '../input/hf-models/microsoft_deberta-v3-large',\n    '../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge',\n    '../input/deberta-v2-xlarge',\n]\nPATHS = [\n    '../input/pl-3a81-deberta-v3-large',\n    '../input/pl-3a81-deberta-xlarge',\n    '../input/pl-3a81-deberta-v2-xlarge-mnli',\n]\nFIXOFFS = [\n    False,\n    False,\n    False,\n]\nWEIGHTS = {'w0': 0.569056721365786, \n           'w1': 0.93844655010746, \n           'w2': 0.200064955738199}","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:01:54.255322Z","iopub.execute_input":"2022-05-02T17:01:54.25553Z","iopub.status.idle":"2022-05-02T17:02:01.02163Z","shell.execute_reply.started":"2022-05-02T17:01:54.255505Z","shell.execute_reply":"2022-05-02T17:02:01.020874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if DEBUG:\n    test_df = pd.read_csv('../input/nbme-score-clinical-patient-notes/train.csv')\nelse:\n    test_df = pd.read_csv('../input/nbme-score-clinical-patient-notes/test.csv')\nfeatures = preprocess_features(pd.read_csv('../input/nbme-score-clinical-patient-notes/features.csv'))\npn = pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\ntest_df = test_df.merge(pn, on='pn_num', how='left')\ntest_df = test_df.merge(features, on='feature_num', how='left')\ntest_df['len'] = test_df['pn_history'].apply(len) + test_df['feature_text'].apply(len)\ntest_df = test_df.sort_values(by=['len']).reset_index(drop=True)\ntest_df","metadata":{"execution":{"iopub.status.busy":"2022-05-02T17:02:01.023131Z","iopub.execute_input":"2022-05-02T17:02:01.02341Z","iopub.status.idle":"2022-05-02T17:02:01.724342Z","shell.execute_reply.started":"2022-05-02T17:02:01.023375Z","shell.execute_reply":"2022-05-02T17:02:01.723679Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"char_logits_blend = [np.zeros(len(text)) for text in test_df.pn_history.values]\nfor i, ckpt in enumerate(CHECKPOINTS):\n    model_path = PATHS[i]\n    w = WEIGHTS[f'w{i}']\n    print(f'{model_path} - weight = {w}')\n    tokenizer = AutoTokenizer.from_pretrained(ckpt, trim_offsets=False)\n    test_dataset = NBMEDatasetInfer(tokenizer, test_df)\n    maxlen = max([len(x['input_ids']) for x in test_dataset])\n    test_dataloader = DataLoader(test_dataset, batch_size=BS, shuffle=False, collate_fn=DataCollatorForTokenClassification(tokenizer), pin_memory=True)\n    model = NBMEModel(ckpt).cuda()\n    preds_folds = []\n    if DEBUG:\n        s, e = 0, 1\n    else:\n        s, e = 0, 5\n    for fold in range(s, e):\n        model.load_state_dict(torch.load(os.path.join(model_path, f'{fold}.pt')))\n        model.eval()\n        preds = []\n        for b in tqdm(test_dataloader, total=len(test_dataset)//BS+1):\n            b = {k: v.cuda() for k, v in b.items()}\n            pred = model(**b).logits #[bs, maxlen, 1]\n            pred = pred.view(pred.shape[0], pred.shape[1]) #[bs, maxlen]\n            pred = F.pad(input=pred, pad=(0, maxlen-pred.shape[1]), mode='constant', value=-100).cpu().numpy()\n            preds.append(pred)\n        preds = np.concatenate(preds, axis=0) #[n, maxlen]\n        preds_folds.append(preds)\n    preds_folds = np.stack(preds_folds)\n    print('preds_folds shape:', preds_folds.shape)\n    preds = np.mean(preds_folds, axis=0)\n    char_logits = get_char_logits(test_df['pn_history'].values, preds, tokenizer, do_fix_offsets=FIXOFFS[i])\n    for j in range(len(test_df)):\n        char_logits_blend[j] += w * char_logits[j]","metadata":{"execution":{"iopub.status.busy":"2022-04-30T19:35:51.618133Z","iopub.execute_input":"2022-04-30T19:35:51.618876Z","iopub.status.idle":"2022-04-30T19:36:51.480557Z","shell.execute_reply.started":"2022-04-30T19:35:51.618839Z","shell.execute_reply":"2022-04-30T19:36:51.479816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results = my_get_results(char_logits_blend, test_df.pn_history.values, th=0)\ntest_df['location'] = results\nsub = pd.read_csv(\"../input/nbme-score-clinical-patient-notes/sample_submission.csv\")\nsub = sub[['id']].merge(test_df[['id', \"location\"]], how=\"left\", on=\"id\")\nsub.to_csv('submission.csv', index=False)\nsub","metadata":{"execution":{"iopub.status.busy":"2022-04-30T19:39:23.591591Z","iopub.execute_input":"2022-04-30T19:39:23.591872Z","iopub.status.idle":"2022-04-30T19:39:23.627839Z","shell.execute_reply.started":"2022-04-30T19:39:23.591842Z","shell.execute_reply":"2022-04-30T19:39:23.627023Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}