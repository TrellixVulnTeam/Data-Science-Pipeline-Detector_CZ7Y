{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np \nimport seaborn as sns\nfrom  tqdm import  tqdm\nimport matplotlib.pyplot as plt\nimport ast\nfrom sklearn.model_selection import StratifiedKFold\nimport os\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom datetime import datetime\nfrom collections import Counter\nimport gc\nfrom pathlib import Path\n\nfrom dataclasses import dataclass, field\nfrom typing import Optional\nfrom itertools import chain\nfrom functools import partial\nfrom ast import literal_eval\nimport torch.nn as f\nimport torch\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nfrom sklearn.metrics import precision_recall_fscore_support\n# import plotly.express as px\n# import plotly.offline as pyo\n# pyo.init_notebook_mode()\nimport pandas as pd\nimport numpy as np\n# from datasets import load_dataset, Dataset\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import (\n    AutoConfig,\n    AutoTokenizer,\n    DataCollatorForTokenClassification,\n    HfArgumentParser,\n    Trainer,\n    TrainingArguments,\n    set_seed,\n    logging,\n)\nfrom transformers.modeling_outputs import TokenClassifierOutput\n\nlogging.set_verbosity(logging.WARNING)\n%env TOKENIZERS_PARALLELISM=true\ntr=False","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:23:58.448229Z","iopub.execute_input":"2022-03-21T07:23:58.448531Z","iopub.status.idle":"2022-03-21T07:23:58.467241Z","shell.execute_reply.started":"2022-03-21T07:23:58.448499Z","shell.execute_reply":"2022-03-21T07:23:58.466032Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# No train test split was done , this is just for making training easy as i found others very difficult to interpret \"uses distill bert/roberta large\"","metadata":{}},{"cell_type":"code","source":"df=pd.read_csv(\"../input/nbme-score-clinical-patient-notes/features.csv\")\nprint(df.info())\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:32.053417Z","iopub.execute_input":"2022-03-21T07:26:32.054178Z","iopub.status.idle":"2022-03-21T07:26:32.080415Z","shell.execute_reply.started":"2022-03-21T07:26:32.054142Z","shell.execute_reply":"2022-03-21T07:26:32.079441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notes=pd.read_csv('../input/nbme-score-clinical-patient-notes/patient_notes.csv')\nprint(notes.info())\nnotes.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:34.603771Z","iopub.execute_input":"2022-03-21T07:26:34.604268Z","iopub.status.idle":"2022-03-21T07:26:35.375466Z","shell.execute_reply.started":"2022-03-21T07:26:34.604234Z","shell.execute_reply":"2022-03-21T07:26:35.374461Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train=pd.read_csv(\"../input/nbme-score-clinical-patient-notes/train.csv\")\nprint(train.info())\ntrain.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:35.483175Z","iopub.execute_input":"2022-03-21T07:26:35.484067Z","iopub.status.idle":"2022-03-21T07:26:35.582988Z","shell.execute_reply.started":"2022-03-21T07:26:35.484019Z","shell.execute_reply":"2022-03-21T07:26:35.581912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sample=pd.read_csv(\"data/sample_submission.csv\")\n# print(sample.info())\n# sample.head(3)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:39.05143Z","iopub.execute_input":"2022-03-21T07:26:39.051785Z","iopub.status.idle":"2022-03-21T07:26:39.056772Z","shell.execute_reply.started":"2022-03-21T07:26:39.051737Z","shell.execute_reply":"2022-03-21T07:26:39.055721Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"print(df.case_num.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.000628Z","iopub.execute_input":"2022-03-15T10:34:37.001653Z","iopub.status.idle":"2022-03-15T10:34:37.016476Z","shell.execute_reply.started":"2022-03-15T10:34:37.001597Z","shell.execute_reply":"2022-03-15T10:34:37.015144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for y in range(10):\n    for x in df[df.case_num==y][['case_num','feature_text']].values:\n        print(x[0],x[1])\n    print(\"*\"*50)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.018203Z","iopub.execute_input":"2022-03-15T10:34:37.018705Z","iopub.status.idle":"2022-03-15T10:34:37.086352Z","shell.execute_reply.started":"2022-03-15T10:34:37.01865Z","shell.execute_reply":"2022-03-15T10:34:37.085709Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# patient notes","metadata":{}},{"cell_type":"code","source":"notes.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.088829Z","iopub.execute_input":"2022-03-15T10:34:37.089183Z","iopub.status.idle":"2022-03-15T10:34:37.104986Z","shell.execute_reply.started":"2022-03-15T10:34:37.089109Z","shell.execute_reply":"2022-03-15T10:34:37.104105Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(notes.pn_num.value_counts())==notes.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.108393Z","iopub.execute_input":"2022-03-15T10:34:37.10904Z","iopub.status.idle":"2022-03-15T10:34:37.129177Z","shell.execute_reply.started":"2022-03-15T10:34:37.109002Z","shell.execute_reply":"2022-03-15T10:34:37.128355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(notes.case_num.value_counts())==notes.shape[0]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.135432Z","iopub.execute_input":"2022-03-15T10:34:37.142069Z","iopub.status.idle":"2022-03-15T10:34:37.149421Z","shell.execute_reply.started":"2022-03-15T10:34:37.142029Z","shell.execute_reply":"2022-03-15T10:34:37.148487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(notes.case_num.value_counts())","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.151018Z","iopub.execute_input":"2022-03-15T10:34:37.151593Z","iopub.status.idle":"2022-03-15T10:34:37.16259Z","shell.execute_reply.started":"2022-03-15T10:34:37.151555Z","shell.execute_reply":"2022-03-15T10:34:37.161777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.bar(notes.groupby('case_num').count().index,notes.groupby('case_num').count()['pn_num'])","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.165281Z","iopub.execute_input":"2022-03-15T10:34:37.1666Z","iopub.status.idle":"2022-03-15T10:34:37.500139Z","shell.execute_reply.started":"2022-03-15T10:34:37.166549Z","shell.execute_reply":"2022-03-15T10:34:37.499501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for x in notes.groupby('case_num').get_group(0.0)[[\"case_num\",'pn_history']].values[:3]:\n    print(x[0],\":-\",x[1])\n    print(\"*\"*50)\n    print(\"\\n\")","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.503814Z","iopub.execute_input":"2022-03-15T10:34:37.505741Z","iopub.status.idle":"2022-03-15T10:34:37.525481Z","shell.execute_reply.started":"2022-03-15T10:34:37.505701Z","shell.execute_reply":"2022-03-15T10:34:37.524731Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notes.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.526766Z","iopub.execute_input":"2022-03-15T10:34:37.527005Z","iopub.status.idle":"2022-03-15T10:34:37.538731Z","shell.execute_reply.started":"2022-03-15T10:34:37.526968Z","shell.execute_reply":"2022-03-15T10:34:37.534791Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.540119Z","iopub.execute_input":"2022-03-15T10:34:37.54038Z","iopub.status.idle":"2022-03-15T10:34:37.548396Z","shell.execute_reply.started":"2022-03-15T10:34:37.540345Z","shell.execute_reply":"2022-03-15T10:34:37.547362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notes.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.549756Z","iopub.execute_input":"2022-03-15T10:34:37.550397Z","iopub.status.idle":"2022-03-15T10:34:37.55716Z","shell.execute_reply.started":"2022-03-15T10:34:37.550359Z","shell.execute_reply":"2022-03-15T10:34:37.556152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new=pd.merge(df,notes,on='case_num',how=\"inner\")\nnew.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.558633Z","iopub.execute_input":"2022-03-15T10:34:37.559371Z","iopub.status.idle":"2022-03-15T10:34:37.632143Z","shell.execute_reply.started":"2022-03-15T10:34:37.55933Z","shell.execute_reply":"2022-03-15T10:34:37.63116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# train","metadata":{}},{"cell_type":"code","source":"train.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.633528Z","iopub.execute_input":"2022-03-15T10:34:37.633879Z","iopub.status.idle":"2022-03-15T10:34:37.640215Z","shell.execute_reply.started":"2022-03-15T10:34:37.633835Z","shell.execute_reply":"2022-03-15T10:34:37.639425Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(train.shape)\ntrain.head(5)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.641684Z","iopub.execute_input":"2022-03-15T10:34:37.642513Z","iopub.status.idle":"2022-03-15T10:34:37.6615Z","shell.execute_reply.started":"2022-03-15T10:34:37.642469Z","shell.execute_reply":"2022-03-15T10:34:37.660727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cn=train.groupby('case_num').get_group(1.0)\nprint(cn.shape)\ncn.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.663004Z","iopub.execute_input":"2022-03-15T10:34:37.663269Z","iopub.status.idle":"2022-03-15T10:34:37.679703Z","shell.execute_reply.started":"2022-03-15T10:34:37.663231Z","shell.execute_reply":"2022-03-15T10:34:37.678744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cn['pn_num'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.681049Z","iopub.execute_input":"2022-03-15T10:34:37.681348Z","iopub.status.idle":"2022-03-15T10:34:37.689522Z","shell.execute_reply.started":"2022-03-15T10:34:37.68131Z","shell.execute_reply":"2022-03-15T10:34:37.688521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cn[cn['pn_num']==cn['pn_num'].iloc[42]]\n","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.691392Z","iopub.execute_input":"2022-03-15T10:34:37.691725Z","iopub.status.idle":"2022-03-15T10:34:37.709952Z","shell.execute_reply.started":"2022-03-15T10:34:37.691668Z","shell.execute_reply":"2022-03-15T10:34:37.709186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"notes[notes['pn_num']==10019]['pn_history'].values[0][854:887]","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.711373Z","iopub.execute_input":"2022-03-15T10:34:37.711651Z","iopub.status.idle":"2022-03-15T10:34:37.718962Z","shell.execute_reply.started":"2022-03-15T10:34:37.711616Z","shell.execute_reply":"2022-03-15T10:34:37.718022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[df['case_num']==1]['feature_text']","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.720911Z","iopub.execute_input":"2022-03-15T10:34:37.721577Z","iopub.status.idle":"2022-03-15T10:34:37.73061Z","shell.execute_reply.started":"2022-03-15T10:34:37.721488Z","shell.execute_reply":"2022-03-15T10:34:37.729799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Datset prep","metadata":{}},{"cell_type":"code","source":"#https://www.kaggle.com/nbroad/qa-ner-hybrid-train-nbme/notebook           ","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:37.732598Z","iopub.execute_input":"2022-03-15T10:34:37.73298Z","iopub.status.idle":"2022-03-15T10:34:37.739227Z","shell.execute_reply.started":"2022-03-15T10:34:37.732883Z","shell.execute_reply":"2022-03-15T10:34:37.738368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#missing stuff\nmissing_annotations = train[\"annotation\"]==\"[]\"\nmissing_locations = train[\"location\"]==\"[]\"\nboth_missing = (train[\"annotation\"] == train[\"location\"])&missing_annotations\n\nsum(missing_annotations), sum(missing_locations), sum(both_missing)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:51.229237Z","iopub.execute_input":"2022-03-21T07:26:51.229778Z","iopub.status.idle":"2022-03-21T07:26:51.254363Z","shell.execute_reply.started":"2022-03-21T07:26:51.229744Z","shell.execute_reply":"2022-03-21T07:26:51.253304Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"skf = StratifiedKFold(n_splits=5, random_state=18, shuffle=True)\n\n\nsplits = list(skf.split(X=notes, y=notes['case_num']))\n\nnotes[\"fold\"] = -1\n\nfor fold, (_, val_idx) in enumerate(skf.split(notes, y=notes[\"case_num\"])):\n    notes.loc[val_idx, \"fold\"] = fold\n    \ncounts = notes.groupby([\"fold\", \"pn_num\"], as_index=False).count()\n\n# If the number of rows is the same as the number of \n# unique pn_num, then each pn_num is only in one fold.\n# Also if all the counts=1\nprint(counts.shape, counts.pn_num.nunique(), counts.case_num.unique())\ncounts","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:53.682161Z","iopub.execute_input":"2022-03-21T07:26:53.682472Z","iopub.status.idle":"2022-03-21T07:26:53.758246Z","shell.execute_reply.started":"2022-03-21T07:26:53.682435Z","shell.execute_reply":"2022-03-21T07:26:53.757265Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"t=train.merge(notes, how=\"left\").merge(df,how='left')","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:56.620038Z","iopub.execute_input":"2022-03-21T07:26:56.62117Z","iopub.status.idle":"2022-03-21T07:26:56.654857Z","shell.execute_reply.started":"2022-03-21T07:26:56.621089Z","shell.execute_reply":"2022-03-21T07:26:56.653689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged = train.merge(notes, how=\"left\")\nmerged = merged.merge(df, how=\"left\")\n\nmerged.head(10)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:58.175367Z","iopub.execute_input":"2022-03-21T07:26:58.175888Z","iopub.status.idle":"2022-03-21T07:26:58.230888Z","shell.execute_reply.started":"2022-03-21T07:26:58.175837Z","shell.execute_reply":"2022-03-21T07:26:58.229893Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.loc[338, \"anno_list\"] =  '[\"father heart attack\"]'\nmerged.loc[338, \"loc_list\"] =  '[\"764 783\"]'\n\nmerged.loc[621, \"anno_list\"] =  '[\"for the last 2-3 months\", \"over the last 2 months\"]'\nmerged.loc[621, \"loc_list\"] =  '[\"77 100\", \"398 420\"]'\n\nmerged.loc[655, \"anno_list\"] =  '[\"no heat intolerance\", \"no cold intolerance\"]'\nmerged.loc[655, \"loc_list\"] =  '[\"285 292;301 312\", \"285 287;296 312\"]'\n\nmerged.loc[1262, \"anno_list\"] =  '[\"mother thyroid problem\"]'\nmerged.loc[1262, \"loc_list\"] =  '[\"551 557;565 580\"]'\n\nmerged.loc[1265, \"anno_list\"] =  '[\\'felt like he was going to \"pass out\"\\']'\nmerged.loc[1265, \"loc_list\"] =  '[\"131 135;181 212\"]'\n\nmerged.loc[1396, \"anno_list\"] =  '[\"stool , with no blood\"]'\nmerged.loc[1396, \"loc_list\"] =  '[\"259 280\"]'\n\nmerged.loc[1591, \"anno_list\"] =  '[\"diarrhoe non blooody\"]'\nmerged.loc[1591, \"loc_list\"] =  '[\"176 184;201 212\"]'\n\nmerged.loc[1615, \"anno_list\"] =  '[\"diarrhea for last 2-3 days\"]'\nmerged.loc[1615, \"loc_list\"] =  '[\"249 257;271 288\"]'\n\nmerged.loc[1664, \"anno_list\"] =  '[\"no vaginal discharge\"]'\nmerged.loc[1664, \"loc_list\"] =  '[\"822 824;907 924\"]'\n\nmerged.loc[1714, \"anno_list\"] =  '[\"started about 8-10 hours ago\"]'\nmerged.loc[1714, \"loc_list\"] =  '[\"101 129\"]'\n\nmerged.loc[1929, \"anno_list\"] =  '[\"no blood in the stool\"]'\nmerged.loc[1929, \"loc_list\"] =  '[\"531 539;549 561\"]'\n\nmerged.loc[2134, \"anno_list\"] =  '[\"last sexually active 9 months ago\"]'\nmerged.loc[2134, \"loc_list\"] =  '[\"540 560;581 593\"]'\n\nmerged.loc[2191, \"anno_list\"] =  '[\"right lower quadrant pain\"]'\nmerged.loc[2191, \"loc_list\"] =  '[\"32 57\"]'\n\nmerged.loc[2553, \"anno_list\"] =  '[\"diarrhoea no blood\"]'\nmerged.loc[2553, \"loc_list\"] =  '[\"308 317;376 384\"]'\n\nmerged.loc[3124, \"anno_list\"] =  '[\"sweating\"]'\nmerged.loc[3124, \"loc_list\"] =  '[\"549 557\"]'\n\nmerged.loc[3858, \"anno_list\"] =  '[\"previously as regular\", \"previously eveyr 28-29 days\", \"previously lasting 5 days\", \"previously regular flow\"]'\nmerged.loc[3858, \"loc_list\"] =  '[\"102 123\", \"102 112;125 141\", \"102 112;143 157\", \"102 112;159 171\"]'\n\nmerged.loc[4373, \"anno_list\"] =  '[\"for 2 months\"]'\nmerged.loc[4373, \"loc_list\"] =  '[\"33 45\"]'\n\nmerged.loc[4763, \"anno_list\"] =  '[\"35 year old\"]'\nmerged.loc[4763, \"loc_list\"] =  '[\"5 16\"]'\n\nmerged.loc[4782, \"anno_list\"] =  '[\"darker brown stools\"]'\nmerged.loc[4782, \"loc_list\"] =  '[\"175 194\"]'\n\nmerged.loc[4908, \"anno_list\"] =  '[\"uncle with peptic ulcer\"]'\nmerged.loc[4908, \"loc_list\"] =  '[\"700 723\"]'\n\nmerged.loc[6016, \"anno_list\"] =  '[\"difficulty falling asleep\"]'\nmerged.loc[6016, \"loc_list\"] =  '[\"225 250\"]'\n\nmerged.loc[6192, \"anno_list\"] =  '[\"helps to take care of aging mother and in-laws\"]'\nmerged.loc[6192, \"loc_list\"] =  '[\"197 218;236 260\"]'\n\nmerged.loc[6380, \"anno_list\"] =  '[\"No hair changes\", \"No skin changes\", \"No GI changes\", \"No palpitations\", \"No excessive sweating\"]'\nmerged.loc[6380, \"loc_list\"] =  '[\"480 482;507 519\", \"480 482;499 503;512 519\", \"480 482;521 531\", \"480 482;533 545\", \"480 482;564 582\"]'\n\nmerged.loc[6562, \"anno_list\"] =  '[\"stressed due to taking care of her mother\", \"stressed due to taking care of husbands parents\"]'\nmerged.loc[6562, \"loc_list\"] =  '[\"290 320;327 337\", \"290 320;342 358\"]'\n\nmerged.loc[6862, \"anno_list\"] =  '[\"stressor taking care of many sick family members\"]'\nmerged.loc[6862, \"loc_list\"] =  '[\"288 296;324 363\"]'\n\nmerged.loc[7022, \"anno_list\"] =  '[\"heart started racing and felt numbness for the 1st time in her finger tips\"]'\nmerged.loc[7022, \"loc_list\"] =  '[\"108 182\"]'\n\nmerged.loc[7422, \"anno_list\"] =  '[\"first started 5 yrs\"]'\nmerged.loc[7422, \"loc_list\"] =  '[\"102 121\"]'\n\nmerged.loc[8876, \"anno_list\"] =  '[\"No shortness of breath\"]'\nmerged.loc[8876, \"loc_list\"] =  '[\"481 483;533 552\"]'\n\nmerged.loc[9027, \"anno_list\"] =  '[\"recent URI\", \"nasal stuffines, rhinorrhea, for 3-4 days\"]'\nmerged.loc[9027, \"loc_list\"] =  '[\"92 102\", \"123 164\"]'\n\nmerged.loc[9938, \"anno_list\"] =  '[\"irregularity with her cycles\", \"heavier bleeding\", \"changes her pad every couple hours\"]'\nmerged.loc[9938, \"loc_list\"] =  '[\"89 117\", \"122 138\", \"368 402\"]'\n\nmerged.loc[9973, \"anno_list\"] =  '[\"gaining 10-15 lbs\"]'\nmerged.loc[9973, \"loc_list\"] =  '[\"344 361\"]'\n\nmerged.loc[10513, \"anno_list\"] =  '[\"weight gain\", \"gain of 10-16lbs\"]'\nmerged.loc[10513, \"loc_list\"] =  '[\"600 611\", \"607 623\"]'\n\nmerged.loc[11551, \"anno_list\"] =  '[\"seeing her son knows are not real\"]'\nmerged.loc[11551, \"loc_list\"] =  '[\"386 400;443 461\"]'\n\nmerged.loc[11677, \"anno_list\"] =  '[\"saw him once in the kitchen after he died\"]'\nmerged.loc[11677, \"loc_list\"] =  '[\"160 201\"]'\n\nmerged.loc[12124, \"anno_list\"] =  '[\"tried Ambien but it didnt work\"]'\nmerged.loc[12124, \"loc_list\"] =  '[\"325 337;349 366\"]'\n\nmerged.loc[12279, \"anno_list\"] =  '[\"heard what she described as a party later than evening these things did not actually happen\"]'\nmerged.loc[12279, \"loc_list\"] =  '[\"405 459;488 524\"]'\n\nmerged.loc[12289, \"anno_list\"] =  '[\"experienced seeing her son at the kitchen table these things did not actually happen\"]'\nmerged.loc[12289, \"loc_list\"] =  '[\"353 400;488 524\"]'\n\nmerged.loc[13238, \"anno_list\"] =  '[\"SCRACHY THROAT\", \"RUNNY NOSE\"]'\nmerged.loc[13238, \"loc_list\"] =  '[\"293 307\", \"321 331\"]'\n\nmerged.loc[13297, \"anno_list\"] =  '[\"without improvement when taking tylenol\", \"without improvement when taking ibuprofen\"]'\nmerged.loc[13297, \"loc_list\"] =  '[\"182 221\", \"182 213;225 234\"]'\n\nmerged.loc[13299, \"anno_list\"] =  '[\"yesterday\", \"yesterday\"]'\nmerged.loc[13299, \"loc_list\"] =  '[\"79 88\", \"409 418\"]'\n\nmerged.loc[13845, \"anno_list\"] =  '[\"headache global\", \"headache throughout her head\"]'\nmerged.loc[13845, \"loc_list\"] =  '[\"86 94;230 236\", \"86 94;237 256\"]'\n\nmerged.loc[14083, \"anno_list\"] =  '[\"headache generalized in her head\"]'\nmerged.loc[14083, \"loc_list\"] =  '[\"56 64;156 179\"]'","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:58.521095Z","iopub.execute_input":"2022-03-21T07:26:58.521708Z","iopub.status.idle":"2022-03-21T07:26:58.630592Z","shell.execute_reply.started":"2022-03-21T07:26:58.521643Z","shell.execute_reply":"2022-03-21T07:26:58.629744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged[\"anno_list\"] = [literal_eval(x) if isinstance(x, str) else x for x in merged[\"annotation\"]]\nmerged[\"loc_list\"] = [literal_eval(x) if isinstance(x, str) else x for x in merged[\"location\"]]\n\nmerged = merged[merged[\"anno_list\"].map(len)!=0].copy().reset_index(drop=True)\n\nmerged.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-21T07:26:59.034634Z","iopub.execute_input":"2022-03-21T07:26:59.035414Z","iopub.status.idle":"2022-03-21T07:26:59.581405Z","shell.execute_reply.started":"2022-03-21T07:26:59.035358Z","shell.execute_reply":"2022-03-21T07:26:59.580317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def process_feature_text(text):\n    return text.replace(\"-\", \" \")\nmerged[\"feature_text\"] = [process_feature_text(x) for x in merged[\"feature_text\"]]","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:26:59.929046Z","iopub.execute_input":"2022-03-21T07:26:59.92976Z","iopub.status.idle":"2022-03-21T07:26:59.941937Z","shell.execute_reply.started":"2022-03-21T07:26:59.929726Z","shell.execute_reply":"2022-03-21T07:26:59.940983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.shape","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:00.901086Z","iopub.execute_input":"2022-03-21T07:27:00.901379Z","iopub.status.idle":"2022-03-21T07:27:00.908489Z","shell.execute_reply.started":"2022-03-21T07:27:00.901346Z","shell.execute_reply":"2022-03-21T07:27:00.907353Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Read CSV","metadata":{}},{"cell_type":"code","source":"merged[\"anno_list\"] = [literal_eval(x) if isinstance(x, str) else x for x in merged[\"annotation\"]]\nmerged[\"loc_list\"] = [literal_eval(x) if isinstance(x, str) else x for x in merged[\"location\"]]\n\nmerged = merged[merged[\"anno_list\"].map(len)!=0].copy().reset_index(drop=True)\n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:02.509141Z","iopub.execute_input":"2022-03-21T07:27:02.510324Z","iopub.status.idle":"2022-03-21T07:27:02.730346Z","shell.execute_reply.started":"2022-03-21T07:27:02.510266Z","shell.execute_reply":"2022-03-21T07:27:02.729428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer=AutoTokenizer.from_pretrained(\"roberta-large\")","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:03.382808Z","iopub.execute_input":"2022-03-21T07:27:03.383372Z","iopub.status.idle":"2022-03-21T07:27:11.635769Z","shell.execute_reply.started":"2022-03-21T07:27:03.383336Z","shell.execute_reply":"2022-03-21T07:27:11.634801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fn(x):\n    return len(x.split())","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:13.011212Z","iopub.execute_input":"2022-03-21T07:27:13.011882Z","iopub.status.idle":"2022-03-21T07:27:13.017316Z","shell.execute_reply.started":"2022-03-21T07:27:13.011835Z","shell.execute_reply":"2022-03-21T07:27:13.01596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def loc_list_to_ints(loc_list):\n    to_return = []\n    \n    for loc_str in loc_list:\n        loc_strs = loc_str.split(\";\")\n        \n        for loc in loc_strs:\n            start, end = loc.split()\n            to_return.append((int(start), int(end)))\n        \n    return to_return\n\ndef process_feature_text(text):\n    return text.replace(\"-\", \" \")\n    \n\ndef tokenize_and_add_labels(example, tokenizer=tokenizer):\n    \n    tokenized_inputs = tokenizer(\n        example[\"feature_text\"],\n        example[\"text\"],\n        truncation=\"only_second\",\n        max_length=416,\n        padding=\"max_length\",\n        return_offsets_mapping=True,\n       \n    )\n    \n    # labels should be float\n    labels = [0.0]*len(tokenized_inputs[\"input_ids\"])\n    tokenized_inputs[\"locations\"] = loc_list_to_ints(example[\"loc_list\"])\n    tokenized_inputs[\"sequence_ids\"] = [0  if i==0 or i==None  else 1 for i in tokenized_inputs.sequence_ids() ]\n    \n    for idx, (seq_id, offsets) in enumerate(zip(tokenized_inputs[\"sequence_ids\"], tokenized_inputs[\"offset_mapping\"])):\n        if seq_id is None or seq_id == 0:\n            labels[idx] = -100.0 # don't calculate loss on question part or special tokens\n            continue\n            \n        exit = False\n        token_start, token_end = offsets\n        for feature_start, feature_end in tokenized_inputs[\"locations\"]:\n            if exit: \n                break\n            if token_start <= feature_start < token_end or token_start < feature_end <= token_end or feature_start <= token_start < feature_end:\n                labels[idx] = 1.0 # labels should be float\n                exit = True\n            \n    \n    tokenized_inputs[\"labels\"] = labels\n    \n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:13.631746Z","iopub.execute_input":"2022-03-21T07:27:13.63244Z","iopub.status.idle":"2022-03-21T07:27:13.645073Z","shell.execute_reply.started":"2022-03-21T07:27:13.632372Z","shell.execute_reply":"2022-03-21T07:27:13.643938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.rename(columns ={'pn_history':'text'},inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:15.970485Z","iopub.execute_input":"2022-03-21T07:27:15.97147Z","iopub.status.idle":"2022-03-21T07:27:15.977301Z","shell.execute_reply.started":"2022-03-21T07:27:15.971431Z","shell.execute_reply":"2022-03-21T07:27:15.975693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"first = merged[merged['fold']==0].iloc[37]\nexample = {\n    \"feature_text\": first.feature_text,\n    \"text\": first.text,\n    \"loc_list\": first.loc_list,\n    \"annotations\": first.anno_list,\n}\nprint(example, \"\\n\\n\")\ntokenized = partial(tokenize_and_add_labels, tokenizer=tokenizer)(example)\n\n\ntokens = tokenizer.tokenize(example[\"feature_text\"], example[\"text\"], add_special_tokens=True)\n\nprint(\"Locations\")\nprint(example[\"loc_list\"], \"\\n\")\n\nprint(\"Annotations\")\nprint(example[\"annotations\"], \"\\n\")\n\nprint(\"Token | Label | Token Offsets\")\nzipped = list(zip(tokens, tokenized[\"labels\"], tokenized[\"offset_mapping\"]))\n[x for x in zipped if x[1]>0]","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-21T07:27:16.35147Z","iopub.execute_input":"2022-03-21T07:27:16.35231Z","iopub.status.idle":"2022-03-21T07:27:16.381527Z","shell.execute_reply.started":"2022-03-21T07:27:16.352273Z","shell.execute_reply":"2022-03-21T07:27:16.380465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:17.412104Z","iopub.execute_input":"2022-03-21T07:27:17.412756Z","iopub.status.idle":"2022-03-21T07:27:17.419865Z","shell.execute_reply.started":"2022-03-21T07:27:17.412721Z","shell.execute_reply":"2022-03-21T07:27:17.418869Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"merged.columns","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:21.23365Z","iopub.execute_input":"2022-03-21T07:27:21.23394Z","iopub.status.idle":"2022-03-21T07:27:21.242967Z","shell.execute_reply.started":"2022-03-21T07:27:21.233908Z","shell.execute_reply":"2022-03-21T07:27:21.241868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\ndef tokenize(idx,tensor=True):\n    \n    l1,l2,l3,l4,l5,l6=[],[],[],[],[],[]\n    for x in idx:\n        first= merged[['feature_text',\"text\",'loc_list','anno_list','pn_num']].iloc[x].values\n        example = {\n        \"feature_text\": first[0],\n        \"text\": first[1],\n        \"loc_list\": first[2],\n        \"annotations\": first[3],\n        \"pn_num\":first[4]\n           \n                    }\n      \n        dict1=tokenize_and_add_labels(example)\n#         l4.append(example['text'])\n        l1.append(dict1['input_ids'])\n        l2.append(dict1['attention_mask'])\n        l3.append(dict1['offset_mapping'])\n        l4.append(example['pn_num'])\n       # l4.append(dict1['locations']) 'location':l4\n        l5.append(dict1['sequence_ids'])\n        l6.append(dict1['labels'])\n    encoded= {'input_ids':l1,'attention_mask':l2,'offset_mapping':l3,'sequence_ids':l5,'labels':l6,'pn_num':l4}\n    \n    if tensor :\n        encoded = {key: torch.as_tensor(val) for key, val in encoded.items()}\n    return encoded\n\n\nfold_0=merged[merged['fold']==0].index\nfold_0=tokenize(fold_0,tensor=True)\nprint(len(fold_0['input_ids']))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-03-21T07:27:24.334803Z","iopub.execute_input":"2022-03-21T07:27:24.335151Z","iopub.status.idle":"2022-03-21T07:27:31.656149Z","shell.execute_reply.started":"2022-03-21T07:27:24.335104Z","shell.execute_reply":"2022-03-21T07:27:31.654246Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class scoreDataset(Dataset):\n    def __init__(self, tokenized_ds):\n        self.data = tokenized_ds\n\n    def __getitem__(self, index):\n        \n       \n        item = {k: self.data[k][index] for k in self.data.keys()}\n        return item\n\n    def __len__(self):\n        return len(self.data['input_ids'])","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:31.658339Z","iopub.execute_input":"2022-03-21T07:27:31.658851Z","iopub.status.idle":"2022-03-21T07:27:31.666068Z","shell.execute_reply.started":"2022-03-21T07:27:31.658804Z","shell.execute_reply":"2022-03-21T07:27:31.66489Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nds = scoreDataset(fold_0)\nds = DataLoader(ds, batch_size=3, \n                    shuffle=True, num_workers=0, pin_memory=True)\n\n\n\n\nval = scoreDataset(fold_0)\nval = DataLoader(val, batch_size=3, \n                    shuffle=False, num_workers=0, pin_memory=True)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:31.668252Z","iopub.execute_input":"2022-03-21T07:27:31.668996Z","iopub.status.idle":"2022-03-21T07:27:31.682355Z","shell.execute_reply.started":"2022-03-21T07:27:31.668952Z","shell.execute_reply":"2022-03-21T07:27:31.681185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for batch in val:\n    print(batch['labels'])\n    break","metadata":{"execution":{"iopub.status.busy":"2022-03-15T10:34:51.42613Z","iopub.execute_input":"2022-03-15T10:34:51.427086Z","iopub.status.idle":"2022-03-15T10:34:55.992926Z","shell.execute_reply.started":"2022-03-15T10:34:51.427045Z","shell.execute_reply":"2022-03-15T10:34:55.99209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training\n","metadata":{}},{"cell_type":"code","source":"from transformers import  DistilBertModel,RobertaModel\nclass NeuralNetwork(f.Module):\n    def __init__(self):\n        super(NeuralNetwork, self).__init__()\n        self.dense=f.Linear(1024,1)\n        self.backbone= RobertaModel.from_pretrained(\"roberta-large\")#DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n        self.dropout = f.Dropout(.2)\n    def forward(self, input_ids=None,attention_mask=None):\n        out=self.backbone(input_ids,attention_mask)\n        out=self.dropout(out[0])\n        \n        out=self.dense(out)\n        return out","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:31.684777Z","iopub.execute_input":"2022-03-21T07:27:31.685225Z","iopub.status.idle":"2022-03-21T07:27:31.694795Z","shell.execute_reply.started":"2022-03-21T07:27:31.685167Z","shell.execute_reply":"2022-03-21T07:27:31.69332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net=NeuralNetwork()","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:25:36.417437Z","iopub.execute_input":"2022-03-21T07:25:36.418578Z","iopub.status.idle":"2022-03-21T07:26:29.762281Z","shell.execute_reply.started":"2022-03-21T07:25:36.418521Z","shell.execute_reply":"2022-03-21T07:26:29.761262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sigmoid(z):\n    return f.Sigmoid()(z)\n\ndef compute_metrics(eval_prediction):\n    \"\"\"\n    This only gets the scores at the token level.\n    The actual leaderboard score is based at the character level.\n    The CV score at the character level is handled in the evaluate\n    function of the trainer.\n    \"\"\"\n    predictions, y_true = eval_prediction\n    predictions = sigmoid(predictions)    \n   # y_true = y_true.astype(int)\n    \n    y_pred = [\n        [int(p>0.5) for (p,l) in zip(pred, label) if l != -100]\n        for pred, label in zip(predictions, y_true)\n    ]\n\n    # Remove ignored index (special tokens)\n    y_true = [\n        [l for l in label if l != -100]\n        for label in y_true\n    ]\n\n    results = precision_recall_fscore_support(list(chain(*y_true)), list(chain(*y_pred)), average=\"binary\")\n    return {\n            \"token_precision\": results[0],\n            \"token_recall\": results[1],\n            \"token_f1\": results[2]\n        }\n\ndef get_location_predictions(dataset, preds):\n    \"\"\"\n    It's easier to run CV if we don't convert predictions into\n    the format expected at test time.\n    \"\"\"\n    all_predictions = []\n    for pred, offsets, seq_ids in zip(preds, dataset[\"offset_mapping\"], dataset[\"sequence_ids\"]):\n        pred = sigmoid(pred)\n        start_idx = None\n        current_preds = []\n        for p, o, s_id in zip(pred, offsets, seq_ids):\n            if s_id is None or s_id == 0:\n                continue\n                \n            if p > 0.5:\n                if start_idx is None:\n                    start_idx = o[0]\n                end_idx = o[1]\n            elif start_idx is not None:\n                current_preds.append((start_idx, end_idx))\n                start_idx = None\n        \n        if start_idx is not None:\n            current_preds.append((start_idx, end_idx))\n\n        all_predictions.extend(current_preds)\n    \n    return all_predictions\ndef calculate_char_CV(dataset):\n    \"\"\"\n    Some tokenizers include the leading space as the start of the\n    offset_mapping, so there is code to ignore that space.\n    \"\"\"\n    all_labels = []\n    all_preds = []\n   \n    \n    \n    for batch in tqdm(dataset):\n        with torch.no_grad():\n            logits=net(batch['input_ids'].to(device),batch['attention_mask'].to(device))\n        l1=[]\n        for no  in batch['pn_num']:\n           \n            l1.append(merged[merged['pn_num']==no.numpy()].text.iloc[1])\n            \n#         for x in batch['input_ids']:\n#                 text=tokenizer.decode(batch['input_ids'][0]).split()\n#                 start=text.index('[SEP]')\n#                 end=text[start+1:].index('[SEP]')\n#                 text=\" \".join(text[start+1:start+end+1])\n#                 l1.append(text)\n        batch['text']=np.array(l1)\n        predictions=get_location_predictions(batch,logits)\n#         print(\"predictions\",predictions)\n#         print(\"\\n\")\n        for preds, offsets, seq_ids, labels, text in zip(\n                predictions, \n                batch[\"offset_mapping\"], \n                batch[\"sequence_ids\"], \n                batch[\"labels\"], \n                batch[\"text\"]\n            ):\n                try:\n#                     print(\"length\",len(text))\n#                     print(text)\n#                     print(\"\\n\")\n                   \n                    num_chars = max(list(chain(*offsets)))\n                    char_labels = np.zeros((num_chars))\n                    count=0\n                    for o, s_id, label in zip(offsets, seq_ids, labels):\n                        \n                        if s_id is None or s_id == 0: # ignore question part of input\n                            continue\n                        if int(label) == 1:\n                           \n                        \n                            char_labels[o[0]:o[1]] = 1\n                            if text[o[0]].isspace() and o[0]>0 and char_labels[o[0]-1]!=1:\n                                char_labels[o[0]] = 0\n                        count+=1\n                    char_preds = np.zeros((num_chars))\n#                     print(preds)\n#                     print(preds[0])\n                    char_preds[preds[0]:preds[1]] = 1\n                    if text[preds[0]].isspace():\n                            char_preds[preds[0]] = 0\n\n                    all_labels.extend(char_labels)\n                    all_preds.extend(char_preds)\n                except Exception as e:\n                    import traceback\n\n                    traceback.print_exc()\n                    print(len(text))\n                   \n\n#                     print(precision_recall_fscore_support(all_labels, all_preds, average=\"binary\"))\n\n    results = precision_recall_fscore_support(all_labels, all_preds, average=\"binary\")\n    return {\n                \"precision\": results[0],\n                \"recall\": results[1],\n                \"f1\": results[2]\n            } \n","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:34.876665Z","iopub.execute_input":"2022-03-21T07:27:34.876949Z","iopub.status.idle":"2022-03-21T07:27:34.904732Z","shell.execute_reply.started":"2022-03-21T07:27:34.876916Z","shell.execute_reply":"2022-03-21T07:27:34.903728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net.to(device)\n#net.load_state_dict(torch.load(\"pytorch_model_e4.bin\"))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:36.646926Z","iopub.execute_input":"2022-03-21T07:27:36.647219Z","iopub.status.idle":"2022-03-21T07:27:42.09988Z","shell.execute_reply.started":"2022-03-21T07:27:36.647179Z","shell.execute_reply":"2022-03-21T07:27:42.099034Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(model, optimizer, dl_train, epoch):\n    \n    time_start = time.time()\n    \n    # Set learning rate to the one in config for this epoch\n    for g in optimizer.param_groups: \n        g['lr'] = config['learning_rates'][epoch]\n    lr = optimizer.param_groups[0]['lr']\n    \n    \n    epoch_prefix = f\"[Epoch {epoch+1:2d} / {config['epochs']:2d}]\"\n    print(f\"{epoch_prefix} Starting epoch {epoch+1:2d} with LR = {lr}\")\n    \n    # Put model in training mode\n    model.train()\n    \n    # Accumulator variables\n    tr_loss, tr_accuracy = 0, 0\n    nb_tr_examples, nb_tr_steps = 0, 0\n    tr_f1 ,tr_p,tr_r=0,0,0\n    loop=tqdm(enumerate(dl_train),leave=False,total=2022//3)\n    for idx, batch in loop:\n        \n        ids = batch['input_ids'].to(config['device'], dtype = torch.long)\n        mask = batch['attention_mask'].to(config['device'], dtype = torch.long)\n        labels = batch['labels'].to(config['device'], dtype = torch.float)\n\n        tr_logits = model(input_ids=ids, attention_mask=mask, )\n        loss_fct = torch.nn.BCEWithLogitsLoss(reduction=\"none\")\n        loss = loss_fct(tr_logits.view(-1, 1), labels.view(-1, 1))\n        \n        # this ignores the part of the sequence that got -100 as labels\n        loss = torch.masked_select(loss, labels.view(-1, 1) > -1).mean()\n        tr_loss += loss.item()\n\n        nb_tr_steps += 1\n        nb_tr_examples += labels.size(0)\n        loss_step = tr_loss/nb_tr_steps\n        \n#         if idx % 200 == 0:\n            \n#             print(f\"{epoch_prefix}     Steps: {idx:4d} --> Loss: {loss_step:.4f}\")\n           \n   \n        # compute training accuracy\n        \n        tmp_tr_accuracy = compute_metrics((tr_logits.to('cpu'),batch['labels'].to('cpu')))\n        tr_f1 += tmp_tr_accuracy['token_f1']\n        tr_p+=tmp_tr_accuracy['token_precision']\n        tr_r+=tmp_tr_accuracy['token_recall']\n        loop.set_description(f\"Epoch[{epoch}/{config['epochs']:2d}]\")\n        loop.set_postfix(loss=loss_step)\n       # wandb.log({'Train Loss (Step)': loss_step, 'Train Accuracy (Step)' : tr_accuracy / nb_tr_steps})\n        \n      #  gradient clipping\n#         torch.nn.utils.clip_grad_norm_(\n#            parameters=model.parameters(), max_norm=config['max_grad_norm']\n#        )\n        \n        # backward pass\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n        \n\n    epoch_loss = tr_loss / nb_tr_steps\n    tr_f1 = tr_f1 / nb_tr_steps\n    tr_p = tr_f1 / nb_tr_steps\n    tr_r = tr_f1 / nb_tr_steps\n       \n    torch.save(model.state_dict(), f'pytorch_model_e{epoch}.bin')\n    torch.cuda.empty_cache()\n    gc.collect()\n\n    elapsed = time.time() - time_start\n    \n    print(epoch_prefix)\n    print(f\"{epoch_prefix} Training loss    : {epoch_loss:.4f}\")\n    print(f\"{epoch_prefix} Training f1: {tr_f1:.4f}\")\n    print(f\"{epoch_prefix} Training precision : {tr_p:.4f}\")\n    print(f\"{epoch_prefix} Training recall: {tr_r:.4f}\")\n    print(f\"{epoch_prefix} Model saved to pytorch_model_e{epoch}.bin  [{elapsed/60:.2f} mins]\")\n    #wandb.log({'Train Loss (Epoch)': epoch_loss, 'Train Accuracy (Epoch)' : tr_accuracy})\n    print(epoch_prefix)\n    \n    \n\n  \n        \n     ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:42.105588Z","iopub.execute_input":"2022-03-21T07:27:42.111886Z","iopub.status.idle":"2022-03-21T07:27:42.135158Z","shell.execute_reply.started":"2022-03-21T07:27:42.111835Z","shell.execute_reply":"2022-03-21T07:27:42.133962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(val):\n    print(calculate_char_CV(val))","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:27:42.136833Z","iopub.execute_input":"2022-03-21T07:27:42.137157Z","iopub.status.idle":"2022-03-21T07:27:42.152298Z","shell.execute_reply.started":"2022-03-21T07:27:42.137113Z","shell.execute_reply":"2022-03-21T07:27:42.151388Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr=True\nif tr:\n    config = {'train_batch_size': 4,\n              'valid_batch_size': 2,\n              'epochs': 5,\n              'learning_rates': [2.5e-5, 2.5e-5, 2.5e-6, 2.5e-6, 2.5e-7],\n              'max_grad_norm': 10,\n              'device': 'cuda' if torch.cuda.is_available() else 'cpu',\n\n              }\n    net=NeuralNetwork()\n    optimizer = torch.optim.Adam(params=net.parameters(), lr=config['learning_rates'][0])\n    import time\n    folds=np.unique(merged['fold'])\n    for fold in folds:\n        d=merged[merged['fold']==fold].index\n        d=tokenize(d,tensor=True)\n\n        ds = scoreDataset(d)\n        ds = DataLoader(ds, batch_size=3, \n                            shuffle=True, num_workers=0, pin_memory=True)\n\n\n\n\n        val = scoreDataset(d)\n        val = DataLoader(val, batch_size=3, \n                            shuffle=False, num_workers=0, pin_memory=True)\n\n        print(len(d['input_ids']))\n        for epoch in range(config['epochs']):\n            train(net.to(device),optimizer,ds,epoch)\n        evaluate(val)\n        torch.save(net.state_dict(), f'fold_{fold}.bin')\n        print(f\" Model saved to pytorch_model_e{fold}.bin]\")\nelse:\n   \n    net.load_state_dict(torch.load(\"../input/nbme-score-clinical-patient-notes/pytorch_model_e4.bin\")) ","metadata":{"execution":{"iopub.status.busy":"2022-03-21T07:32:10.876491Z","iopub.execute_input":"2022-03-21T07:32:10.876798Z","iopub.status.idle":"2022-03-21T10:22:04.737135Z","shell.execute_reply.started":"2022-03-21T07:32:10.876768Z","shell.execute_reply":"2022-03-21T10:22:04.735097Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"all_=merged.index\nall_=tokenize(all_,tensor=True)\nall_ = scoreDataset(all_)\nall_ = DataLoader(all_, batch_size=3, \n                    shuffle=False, num_workers=0, pin_memory=True)\nevaluate(all_)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:36:12.960565Z","iopub.execute_input":"2022-03-21T10:36:12.96089Z","iopub.status.idle":"2022-03-21T10:50:21.490344Z","shell.execute_reply.started":"2022-03-21T10:36:12.960849Z","shell.execute_reply":"2022-03-21T10:50:21.488108Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df=merged[merged['pn_num']==16].iloc[:5]\ntest=tokenize(test_df.index,tensor=True)\ntest = scoreDataset(test)\ntest = DataLoader(test, batch_size=1, \n                        shuffle=False, num_workers=0, pin_memory=True)\ndef gen(loader,net,test) :\n    loc_=[]\n    for batch in loader:\n        with torch.no_grad():\n                \n                logits=net(batch['input_ids'].to(device),batch['attention_mask'].to(device))\n        loc=get_location_predictions(batch,logits)\n        temp=[]\n        str1=''\n\n        if len(loc)>1:\n            for x in loc:\n                str1+=str(x[0].numpy()) +\" \"+str(x[1].numpy())+\";\"\n            str1=str1[:-1]\n        else:\n              for x in loc:\n                str1=str(x[0].numpy()) +\" \"+str(x[1].numpy())\n\n        temp.append(str1)\n        loc_.append(temp[0])\n   \n    df=pd.DataFrame({'id':test_df.id,'location':loc_})\n    return df\ngen(test,net,test_df)","metadata":{"execution":{"iopub.status.busy":"2022-03-21T10:50:21.934198Z","iopub.execute_input":"2022-03-21T10:50:21.93557Z","iopub.status.idle":"2022-03-21T10:50:22.353345Z","shell.execute_reply.started":"2022-03-21T10:50:21.93552Z","shell.execute_reply":"2022-03-21T10:50:22.352304Z"},"trusted":true},"execution_count":null,"outputs":[]}]}