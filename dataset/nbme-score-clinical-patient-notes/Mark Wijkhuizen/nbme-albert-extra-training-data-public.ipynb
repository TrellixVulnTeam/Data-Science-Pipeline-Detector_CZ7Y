{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Hello Fellow kagglers,\n\nThis notebook demonstrates how to generate extra training data by predicting the labels for unannotated patient notes using a model trained on the annotated training data. The labels are soft, meaning the probabilities are not thresholded. The training data is also included, to add correctly labelled data to the non-annoateted training data.\n\nThere are ~42000 patient notes, of which only 1000 are annotated. Using all patient notes will result in 42x more training data, which will contain errors, but training on a TPU with a large batch size should smoothen out the errors and will result in better performance than just using the annotated training data.\n\n[Preprocessing Notebook](https://www.kaggle.com/markwijkhuizen/nbme-preprocessing-albert)\n\n[Training Notebook](https://www.kaggle.com/markwijkhuizen/nbme-albert-large-training-tpu)\n\n[Inference Notebook](https://www.kaggle.com/markwijkhuizen/nbme-albert-inference-public)\n\n**V6**\n* Using beter weights with LB 0.854 score","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn import metrics\n\nfrom tqdm.notebook import tqdm\nfrom nltk.tokenize import word_tokenize, sent_tokenize\nfrom transformers import PreTrainedTokenizerFast, TFAlbertModel, AlbertConfig\nfrom sklearn.model_selection import train_test_split\n\nimport re\nimport os\nimport random\nimport math\n\ntqdm.pandas()\n\nAUTO = tf.data.experimental.AUTOTUNE","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:19.630388Z","iopub.execute_input":"2022-02-25T12:33:19.630707Z","iopub.status.idle":"2022-02-25T12:33:19.641925Z","shell.execute_reply.started":"2022-02-25T12:33:19.630676Z","shell.execute_reply":"2022-02-25T12:33:19.640834Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"SEQ_LENGTH = 512","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:19.644783Z","iopub.execute_input":"2022-02-25T12:33:19.645663Z","iopub.status.idle":"2022-02-25T12:33:19.653567Z","shell.execute_reply.started":"2022-02-25T12:33:19.645613Z","shell.execute_reply":"2022-02-25T12:33:19.652127Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\n\n# Add Ordinal Encoding\nfeatures['feature_num_ordinal'] = features['feature_num'].astype('category').cat.codes\n\nN_LABELS = len(features)\nprint(f'N_LABELS: {N_LABELS}')","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:19.655159Z","iopub.execute_input":"2022-02-25T12:33:19.655731Z","iopub.status.idle":"2022-02-25T12:33:19.675748Z","shell.execute_reply.started":"2022-02-25T12:33:19.655663Z","shell.execute_reply":"2022-02-25T12:33:19.674681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"albert_config = AlbertConfig(\n  hidden_size = 4096,\n  intermediate_size = 16384,\n  num_attention_heads = 64,\n)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:19.677425Z","iopub.execute_input":"2022-02-25T12:33:19.678166Z","iopub.status.idle":"2022-02-25T12:33:19.684423Z","shell.execute_reply.started":"2022-02-25T12:33:19.678118Z","shell.execute_reply":"2022-02-25T12:33:19.683191Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_model():\n    # Clear Backend\n    tf.keras.backend.clear_session()\n\n    # enable XLA optmizations\n    tf.config.optimizer.set_jit(True)\n    \n    # Input Layer\n    input_ids = tf.keras.layers.Input(shape = (SEQ_LENGTH), dtype=tf.int32, name='input_ids')\n    attention_mask = tf.keras.layers.Input(shape=SEQ_LENGTH, dtype=tf.int32, name='attention_mask')\n\n    # AlBERT Model\n    albert = TFAlbertModel(albert_config)\n\n    # Get the last hidden state\n    last_hidden_state = albert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n\n    do = tf.keras.layers.Dropout(0.00, name='dropout')(last_hidden_state)\n\n    output = tf.keras.layers.Dense(N_LABELS, activation='sigmoid', name='head/classifier')(do)\n\n    model = tf.keras.models.Model(inputs=[input_ids, attention_mask], outputs=[output])\n    \n    model.load_weights('/kaggle/input/nbme-albert-large-training-tpu-dataset/model.h5')\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:19.688226Z","iopub.execute_input":"2022-02-25T12:33:19.689469Z","iopub.status.idle":"2022-02-25T12:33:19.70016Z","shell.execute_reply.started":"2022-02-25T12:33:19.689313Z","shell.execute_reply":"2022-02-25T12:33:19.699149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = get_model()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:19.70182Z","iopub.execute_input":"2022-02-25T12:33:19.704469Z","iopub.status.idle":"2022-02-25T12:33:29.719373Z","shell.execute_reply.started":"2022-02-25T12:33:19.704414Z","shell.execute_reply":"2022-02-25T12:33:29.718408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.summary()","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:29.722275Z","iopub.execute_input":"2022-02-25T12:33:29.722532Z","iopub.status.idle":"2022-02-25T12:33:29.740077Z","shell.execute_reply.started":"2022-02-25T12:33:29.7225Z","shell.execute_reply":"2022-02-25T12:33:29.738975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tf.keras.utils.plot_model(model, show_shapes=True, show_dtype=True, show_layer_names=True, expand_nested=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:29.742842Z","iopub.execute_input":"2022-02-25T12:33:29.743083Z","iopub.status.idle":"2022-02-25T12:33:29.97447Z","shell.execute_reply.started":"2022-02-25T12:33:29.743055Z","shell.execute_reply":"2022-02-25T12:33:29.973302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')\ntrain = train.set_index(['case_num', 'pn_num'])\n\ndisplay(train.head())","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:29.976688Z","iopub.execute_input":"2022-02-25T12:33:29.978646Z","iopub.status.idle":"2022-02-25T12:33:30.026439Z","shell.execute_reply.started":"2022-02-25T12:33:29.978587Z","shell.execute_reply":"2022-02-25T12:33:30.025436Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Patient Notes","metadata":{}},{"cell_type":"code","source":"patient_notes = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\n# Set Case Number and Patient Number as Index for Convenient Access\npatient_notes = patient_notes.set_index(['case_num', 'pn_num'])\n\npatient_notes['pn_history_clean'] = patient_notes['pn_history'].str.lower()\n\ndisplay(patient_notes.head())\n\ndisplay(patient_notes.info())","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:30.027837Z","iopub.execute_input":"2022-02-25T12:33:30.028485Z","iopub.status.idle":"2022-02-25T12:33:30.453365Z","shell.execute_reply.started":"2022-02-25T12:33:30.028431Z","shell.execute_reply":"2022-02-25T12:33:30.452289Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Tokenize","metadata":{}},{"cell_type":"code","source":"tokenizer = PreTrainedTokenizerFast.from_pretrained('/kaggle/input/nbme-preprocessing-albert-public/tokenizer')","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:30.455677Z","iopub.execute_input":"2022-02-25T12:33:30.456037Z","iopub.status.idle":"2022-02-25T12:33:30.552087Z","shell.execute_reply.started":"2022-02-25T12:33:30.455989Z","shell.execute_reply":"2022-02-25T12:33:30.551061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This function tokenize the text according to a AlBERT model tokenizer\ndef tokenize(note):\n    return tokenizer(\n            note,\n            padding = 'max_length',\n            truncation = True,\n            max_length = SEQ_LENGTH,\n            return_offsets_mapping = True,\n        )","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:30.554478Z","iopub.execute_input":"2022-02-25T12:33:30.554707Z","iopub.status.idle":"2022-02-25T12:33:30.564782Z","shell.execute_reply.started":"2022-02-25T12:33:30.554675Z","shell.execute_reply":"2022-02-25T12:33:30.563777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"# Only element above this threshold will be included\n# Thus predictions below 0.01 will not be included in the soft labels\nTHRESHOLD = 0.05\n\n# Maximum Annotations Per Patient Note\nMAX_ANNOTATIONS = 1024","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:30.569021Z","iopub.execute_input":"2022-02-25T12:33:30.56927Z","iopub.status.idle":"2022-02-25T12:33:30.574814Z","shell.execute_reply.started":"2022-02-25T12:33:30.569238Z","shell.execute_reply":"2022-02-25T12:33:30.573663Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train Test Split\nSEED = 42\ntrain_idxs = train.index.unique()\ntest_size = 100 / len(train_idxs)\n_, val_indices = train_test_split(train_idxs, test_size=test_size, random_state=SEED)\nprint(f'val_indices shape: {val_indices.shape}, val_indices length: {len(val_indices)}')","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:30.579877Z","iopub.execute_input":"2022-02-25T12:33:30.580643Z","iopub.status.idle":"2022-02-25T12:33:30.60389Z","shell.execute_reply.started":"2022-02-25T12:33:30.580588Z","shell.execute_reply":"2022-02-25T12:33:30.602608Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Labels are generated using sparse tensors, which saves only the indices and values of non-zero (not strictly) elements. The labels are of size \\[Number of Tokens, Number of Features\\], but only a handful of elements are actually non-zero, less than 0.1%. By only saving those elements a huge amount of memory is saved by excluding those 99%+ of zero's.\n\nI can highly recommend to dive into Sparse Tensors, as sparse tensors are common in the data science field. Getting familiar with the Sparse Tensor data can save you a lot of computing resources in the future!\n\nMore on Sparse Tensors can be found in the [Tensorflow Documentation](https://www.tensorflow.org/api_docs/python/tf/sparse/SparseTensor)","metadata":{}},{"cell_type":"code","source":"SIZE = len(patient_notes)\nval_indeces_set = set(val_indices)\n\n# Excluding Validation\nX_extra_no_val = np.zeros([SIZE - len(val_indices), SEQ_LENGTH], dtype=np.int32)\ny_extra_indices_no_val = np.full(shape=[SIZE - len(val_indices), MAX_ANNOTATIONS, 2], fill_value=-1, dtype=np.int16)\ny_extra_values_no_val = np.full(shape=[SIZE - len(val_indices), MAX_ANNOTATIONS], fill_value=-1, dtype=np.float32)\n\n# Including Validation\nX_extra = np.zeros([SIZE, SEQ_LENGTH], dtype=np.int32)\ny_extra_indices = np.full(shape=[SIZE, MAX_ANNOTATIONS, 2], fill_value=-1, dtype=np.int16)\ny_extra_values = np.full(shape=[SIZE, MAX_ANNOTATIONS], fill_value=-1, dtype=np.float32)\n\nprint(f'X_extra shape: {X_extra.shape}, y_extra_indices shape: {y_extra_indices.shape}, y_extra_values shape: {y_extra_values.shape}')\n\nidx_no_val = 0\nfor idx, (row_idx, row) in enumerate(tqdm(patient_notes.iterrows(), total=len(patient_notes))):\n    pn_history_clean = row['pn_history_clean']\n    \n    # Tokenize patient note\n    tokens = tokenize(pn_history_clean)\n    \n    input_ids = tokens['input_ids']\n    attention_mask = tokens['attention_mask']\n    \n    # Get the prediction\n    y_pred = model.predict_on_batch({\n            'input_ids': np.array([input_ids]),\n            'attention_mask': np.array([attention_mask]),\n        }).squeeze()\n    \n    # Cast to Integer\n    input_ids = np.array(input_ids, dtype=np.int32)\n    \n    # Create a Sparse Tensor as label to reduce memory usage\n    y_pred_i = (y_pred > THRESHOLD).astype(np.int32)\n    # Get the indices of element above the threshold\n    y_pred_i = tf.sparse.from_dense(y_pred_i).indices.numpy()\n    \n    # Gather the values of elements above the threshold\n    y_extra_v = tf.gather_nd(y_pred, tf.where(y_pred > THRESHOLD))\n    \n    # Length of elements above the threshold\n    y_extra_len = len(tf.where(y_pred > THRESHOLD))\n    \n    # Assign input_ids, indices and values to the extra training data\n    X_extra[idx] = input_ids\n    y_extra_indices[idx, :y_extra_len] = y_pred_i\n    y_extra_values[idx, :y_extra_len] = y_extra_v\n    \n    # Add to No Val\n    # Exclude Validation Samples\n    if row_idx in val_indeces_set:\n        X_extra_no_val[idx_no_val] = input_ids\n        y_extra_indices_no_val[idx_no_val, :y_extra_len] = y_pred_i\n        y_extra_values_no_val[idx_no_val, :y_extra_len] = y_extra_v\n        idx_no_val += 1","metadata":{"execution":{"iopub.status.busy":"2022-02-25T12:33:30.606058Z","iopub.execute_input":"2022-02-25T12:33:30.606866Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Save Extra Training Data","metadata":{}},{"cell_type":"code","source":"# Save X_extra and y_extra\nnp.save('./X_extra_no_val.npy', X_extra_no_val)\nnp.save('./y_extra_indices_no_val.npy', y_extra_indices_no_val)\nnp.save('./y_extra_values_no_val.npy', y_extra_values_no_val)\n\n# Save X_extra and y_extra\nnp.save('./X_extra.npy', X_extra)\nnp.save('./y_extra_indices.npy', y_extra_indices)\nnp.save('./y_extra_values.npy', y_extra_values)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}