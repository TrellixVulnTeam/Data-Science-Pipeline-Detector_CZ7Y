{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-21T18:57:45.660404Z","iopub.execute_input":"2022-04-21T18:57:45.661082Z","iopub.status.idle":"2022-04-21T18:57:49.930954Z","shell.execute_reply.started":"2022-04-21T18:57:45.660994Z","shell.execute_reply":"2022-04-21T18:57:49.930069Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Vocabulary","metadata":{}},{"cell_type":"code","source":"total_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_vocabulary.csv')\n\ntotal_annotation_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_annotation_vocabulary.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:49.932399Z","iopub.execute_input":"2022-04-21T18:57:49.932654Z","iopub.status.idle":"2022-04-21T18:57:50.000438Z","shell.execute_reply.started":"2022-04-21T18:57:49.932621Z","shell.execute_reply":"2022-04-21T18:57:49.99844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Input Data","metadata":{}},{"cell_type":"code","source":"patient_notes_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nfeatures_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\n\ntrain_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:50.001672Z","iopub.execute_input":"2022-04-21T18:57:50.001932Z","iopub.status.idle":"2022-04-21T18:57:50.605815Z","shell.execute_reply.started":"2022-04-21T18:57:50.001896Z","shell.execute_reply":"2022-04-21T18:57:50.605099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Functions","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef take_pacient_note(pacient_note_num: int) -> dict:\n    pacient_note = patient_notes_df[patient_notes_df['pn_num'] == pacient_note_num].reset_index()['pn_history'][0]\n    return pacient_note\n\ndef get_training_patient_note_numbers(case_number):\n    return train_df[train_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_all_feature_numbers(case_number):\n    return features_df[features_df['case_num'] == case_number]['feature_num'].to_numpy()\n\ndef get_all_patient_note_numbers(case_number):\n    return patient_notes_df[patient_notes_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_feature_annotations(patient_note_num, feature_number):\n    aux_df = train_df[train_df['pn_num'] == patient_note_num]\n    return ast.literal_eval(aux_df[aux_df['feature_num'] == feature_number].reset_index()['annotation'][0])\n\ndef get_all_training_annotations(case_number):\n    return [ast.literal_eval(x) for x in train_df[train_df['case_num'] == case_number]['annotation'].to_numpy()]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:50.607772Z","iopub.execute_input":"2022-04-21T18:57:50.607995Z","iopub.status.idle":"2022-04-21T18:57:50.618537Z","shell.execute_reply.started":"2022-04-21T18:57:50.607965Z","shell.execute_reply":"2022-04-21T18:57:50.617851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Truncated Vocabulary","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/nbme-truncated-vocabulary/truncated.vocabulary', 'rb') as truncated_vocabulary_file:\n    truncated_vocabulary = pickle.load(truncated_vocabulary_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:50.620263Z","iopub.execute_input":"2022-04-21T18:57:50.620579Z","iopub.status.idle":"2022-04-21T18:57:50.633751Z","shell.execute_reply.started":"2022-04-21T18:57:50.620541Z","shell.execute_reply":"2022-04-21T18:57:50.632987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Lookup Table","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nnum_oov_buckets = 1000\n\ndef create_lookup_table(truncated_vocabulary):\n    words = tf.constant(truncated_vocabulary)\n    word_ids = tf.range(len(truncated_vocabulary), dtype=tf.int64)\n    vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n    \n    return tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n\nlookup_table = create_lookup_table(truncated_vocabulary)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:50.63524Z","iopub.execute_input":"2022-04-21T18:57:50.635973Z","iopub.status.idle":"2022-04-21T18:57:52.995827Z","shell.execute_reply.started":"2022-04-21T18:57:50.635937Z","shell.execute_reply":"2022-04-21T18:57:52.994885Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lookup_table","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:52.997026Z","iopub.execute_input":"2022-04-21T18:57:52.997509Z","iopub.status.idle":"2022-04-21T18:57:53.006627Z","shell.execute_reply.started":"2022-04-21T18:57:52.997472Z","shell.execute_reply":"2022-04-21T18:57:53.005929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Maps","metadata":{}},{"cell_type":"code","source":"import pickle\n\ndef load_input_output_trainning_maps(case_number):\n    with open(f'/kaggle/input/nbme-map-trainning-inputs-and-outputs/input.map.case.{case_number}', 'rb') as input_map_file:\n        input_map = pickle.load(input_map_file)\n\n    with open(f'/kaggle/input/nbme-map-trainning-inputs-and-outputs/output.map.case.{case_number}', 'rb') as output_map_file:\n        output_map = pickle.load(output_map_file)\n        \n    return (input_map, output_map)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:53.007719Z","iopub.execute_input":"2022-04-21T18:57:53.00816Z","iopub.status.idle":"2022-04-21T18:57:53.016057Z","shell.execute_reply.started":"2022-04-21T18:57:53.008122Z","shell.execute_reply":"2022-04-21T18:57:53.015316Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Creating Batch","metadata":{}},{"cell_type":"code","source":"defined_padding = 5\n\ndef get_batch(input_map, output_map, feature_number):\n    X = []\n    y = []\n    for patient_note_number in input_map:\n        for i, out in enumerate(output_map[(patient_note_number, feature_number)]):\n            X.append(input_map[patient_note_number][i:i + 2 * defined_padding + 1].numpy())\n            y.append([output_map[(patient_note_number, feature_number)][i].numpy()])\n\n    X = np.array(X)\n    y = np.array(y)\n    \n    return (X, y)","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:53.017111Z","iopub.execute_input":"2022-04-21T18:57:53.017416Z","iopub.status.idle":"2022-04-21T18:57:53.029265Z","shell.execute_reply.started":"2022-04-21T18:57:53.017346Z","shell.execute_reply":"2022-04-21T18:57:53.028619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Training","metadata":{}},{"cell_type":"code","source":"vocab_size = len(truncated_vocabulary)\nembed_size = 5\n\ndef create_model():\n    model = keras.models.Sequential([\n        keras.layers.Embedding(vocab_size + num_oov_buckets,embed_size,input_shape=[None]),\n        keras.layers.Bidirectional(keras.layers.GRU(2*defined_padding + 1, return_sequences=True)),\n        keras.layers.Bidirectional(keras.layers.GRU(2*defined_padding + 1)),\n        keras.layers.Dense(1, activation=\"sigmoid\")\n    ])\n\n    model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n    \n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:53.031581Z","iopub.execute_input":"2022-04-21T18:57:53.031904Z","iopub.status.idle":"2022-04-21T18:57:53.040759Z","shell.execute_reply.started":"2022-04-21T18:57:53.031851Z","shell.execute_reply":"2022-04-21T18:57:53.039964Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_high(X,y,cut_value, mark_decision):\n    X_choosed = []\n    y_choosed = []\n    for i, y_value in enumerate(y):\n        if y_value > cut_value:\n            if mark_decision:\n                y_choosed.append([1])\n                X_choosed.append(X[i])\n            else:\n                y_choosed.append(y[i])\n                X_choosed.append(X[i])\n\n    y_choosed = np.array(y_choosed)\n    X_choosed = np.array(X_choosed)\n    \n    return X_choosed, y_choosed","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:53.042083Z","iopub.execute_input":"2022-04-21T18:57:53.042876Z","iopub.status.idle":"2022-04-21T18:57:53.050278Z","shell.execute_reply.started":"2022-04-21T18:57:53.042839Z","shell.execute_reply":"2022-04-21T18:57:53.049633Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def find_low(X,y,cut_value, mark_decision):\n    X_choosed = []\n    y_choosed = []\n    for i, y_value in enumerate(y):\n        if y_value < cut_value:\n            if mark_decision:\n                y_choosed.append([0])\n                X_choosed.append(X[i])\n            else:\n                y_choosed.append(y[i])\n                X_choosed.append(X[i])\n                \n\n    y_choosed = np.array(y_choosed)\n    X_choosed = np.array(X_choosed)\n    \n    return X_choosed, y_choosed","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:53.051583Z","iopub.execute_input":"2022-04-21T18:57:53.051918Z","iopub.status.idle":"2022-04-21T18:57:53.059762Z","shell.execute_reply.started":"2022-04-21T18:57:53.051881Z","shell.execute_reply":"2022-04-21T18:57:53.05896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def shuffle_batch(X,y):\n    p = np.random.permutation(len(X))\n    return X[p], y[p]","metadata":{"execution":{"iopub.status.busy":"2022-04-21T18:57:53.061268Z","iopub.execute_input":"2022-04-21T18:57:53.061548Z","iopub.status.idle":"2022-04-21T18:57:53.070996Z","shell.execute_reply.started":"2022-04-21T18:57:53.061512Z","shell.execute_reply":"2022-04-21T18:57:53.070272Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import Sequence\n\nclass EquilibriumSequence(Sequence):\n\n    def __init__(self, full_X, full_y, low_cut=0.5, high_cut=0.5, mark_decision=False):\n        X_high, y_high  = find_high(X, y, high_cut, mark_decision)\n        X_low,  y_low   = find_low(X, y, low_cut, mark_decision)\n        \n        len_high = len(X_high)\n        len_low  = len(X_low)\n        \n        if len_high > len_low:\n            self.X_big, self.y_big     = X_high, y_high\n            self.X_small, self.y_small = X_low,  y_low\n        else:\n            self.X_big, self.y_big     = X_low,  y_low\n            self.X_small, self.y_small = X_high, y_high\n            \n        self.X_big, self.y_big     = shuffle_batch(self.X_big,   self.y_big)\n        self.X_small, self.y_small = shuffle_batch(self.X_small, self.y_small)\n        \n    def __len__(self):\n#         if len(self.X_small) == 0:\n#             return 1\n#         else:\n#             return len(self.X_big) // len(self.X_small)\n        return 1\n\n    def __getitem__(self, idx):\n        small_size = len(self.X_small)\n        \n        if small_size == 0:\n            X = self.X_big\n            y = self.y_big\n        else:\n            X_big_batch = self.X_big[idx * small_size : (idx + 1 ) * small_size]\n            y_big_batch = self.y_big[idx * small_size : (idx + 1 ) * small_size]\n            X = np.concatenate((X_big_batch, self.X_small), axis=0)\n            y = np.concatenate((y_big_batch, self.y_small), axis=0) \n        \n        \n        X, y = shuffle_batch(X, y)\n\n        return X, y","metadata":{"execution":{"iopub.status.busy":"2022-04-21T19:04:45.808353Z","iopub.execute_input":"2022-04-21T19:04:45.808868Z","iopub.status.idle":"2022-04-21T19:04:45.821709Z","shell.execute_reply.started":"2022-04-21T19:04:45.80883Z","shell.execute_reply":"2022-04-21T19:04:45.819249Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for case_number in range(10):\n    for feature_number in get_all_feature_numbers(case_number):\n        print(f\"Getting data for case {case_number} and feature {feature_number}\")\n        \n        input_map, output_map = load_input_output_trainning_maps(case_number)\n        X, y = get_batch(input_map, output_map, feature_number)\n        \n        print(f\"Fitting model for case {case_number} and feature {feature_number}\")\n        model = create_model()\n        \n        model.fit(EquilibriumSequence(X,y),epochs=4)\n        \n        print(f\"Evaluation model for case {case_number} and feature {feature_number}\")\n        model.evaluate(X,y)\n        \n        print(f\"Saving model for case {case_number} and feature {feature_number}\")\n        model.save(f\"/kaggle/working/model_for_case_{case_number}_and_feature_{feature_number}\")\n        print(f\"Saved model for case {case_number} and feature {feature_number}\")","metadata":{"execution":{"iopub.status.busy":"2022-04-21T16:40:00.58505Z","iopub.execute_input":"2022-04-21T16:40:00.585513Z","iopub.status.idle":"2022-04-21T16:40:27.242331Z","shell.execute_reply.started":"2022-04-21T16:40:00.585478Z","shell.execute_reply":"2022-04-21T16:40:27.239021Z"},"trusted":true},"execution_count":null,"outputs":[]}]}