{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-04-22T00:17:23.756771Z","iopub.execute_input":"2022-04-22T00:17:23.757142Z","iopub.status.idle":"2022-04-22T00:17:28.939167Z","shell.execute_reply.started":"2022-04-22T00:17:23.757059Z","shell.execute_reply":"2022-04-22T00:17:28.938386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Vocabulary","metadata":{}},{"cell_type":"code","source":"total_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_vocabulary.csv')\n\ntotal_annotation_vocabulary_df = pd.read_csv('/kaggle/input/nbme-creating-vocabulary/total_annotation_vocabulary.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:28.942366Z","iopub.execute_input":"2022-04-22T00:17:28.942581Z","iopub.status.idle":"2022-04-22T00:17:28.997784Z","shell.execute_reply.started":"2022-04-22T00:17:28.942555Z","shell.execute_reply":"2022-04-22T00:17:28.997099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Load Input Data","metadata":{}},{"cell_type":"code","source":"patient_notes_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/patient_notes.csv')\n\nfeatures_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/features.csv')\n\ntrain_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/train.csv')\n\ntest_df = pd.read_csv('/kaggle/input/nbme-score-clinical-patient-notes/test.csv')","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:28.999364Z","iopub.execute_input":"2022-04-22T00:17:28.999605Z","iopub.status.idle":"2022-04-22T00:17:29.709185Z","shell.execute_reply.started":"2022-04-22T00:17:28.999572Z","shell.execute_reply":"2022-04-22T00:17:29.708136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Functions","metadata":{}},{"cell_type":"code","source":"import ast\n\ndef take_pacient_note(pacient_note_num: int) -> dict:\n    pacient_note = patient_notes_df[patient_notes_df['pn_num'] == pacient_note_num].reset_index()['pn_history'][0]\n    return pacient_note\n\ndef get_training_patient_note_numbers(case_number):\n    return train_df[train_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_all_feature_numbers(case_number):\n    return features_df[features_df['case_num'] == case_number]['feature_num'].to_numpy()\n\ndef get_all_test_patient_note_numbers(case_number):\n    return list(set(test_df[test_df['case_num'] == case_number]['pn_num'].to_numpy()))\n\ndef get_all_patient_note_numbers(case_number):\n    return patient_notes_df[patient_notes_df['case_num'] == case_number]['pn_num'].to_numpy()\n\ndef get_feature_annotations(patient_note_num, feature_number):\n    aux_df = train_df[train_df['pn_num'] == patient_note_num]\n    return ast.literal_eval(aux_df[aux_df['feature_num'] == feature_number].reset_index()['annotation'][0])\n\ndef get_all_training_annotations(case_number):\n    return [ast.literal_eval(x) for x in train_df[train_df['case_num'] == case_number]['annotation'].to_numpy()]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:29.711441Z","iopub.execute_input":"2022-04-22T00:17:29.711741Z","iopub.status.idle":"2022-04-22T00:17:29.726682Z","shell.execute_reply.started":"2022-04-22T00:17:29.711703Z","shell.execute_reply":"2022-04-22T00:17:29.725294Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"list(set(get_all_test_patient_note_numbers(0)))","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:29.728004Z","iopub.execute_input":"2022-04-22T00:17:29.728247Z","iopub.status.idle":"2022-04-22T00:17:29.753073Z","shell.execute_reply.started":"2022-04-22T00:17:29.728214Z","shell.execute_reply":"2022-04-22T00:17:29.752321Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing Open Data","metadata":{}},{"cell_type":"code","source":"def preprocessing(X_batch):\n    X_out_batch = tf.strings.lower(X_batch)\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\n\\r\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"\\r\\n\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"[^a-zA-Z0-9-']\", b\" \")\n    X_out_batch = tf.strings.regex_replace(X_out_batch, b\"-\", b\" - \")\n    X_out_batch = tf.strings.split(X_out_batch)\n    return X_out_batch","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:29.754836Z","iopub.execute_input":"2022-04-22T00:17:29.756523Z","iopub.status.idle":"2022-04-22T00:17:29.769438Z","shell.execute_reply.started":"2022-04-22T00:17:29.756482Z","shell.execute_reply":"2022-04-22T00:17:29.768099Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining Truncated Vocabulary","metadata":{}},{"cell_type":"code","source":"import pickle\n\nwith open('/kaggle/input/nbme-truncated-vocabulary/truncated.vocabulary', 'rb') as truncated_vocabulary_file:\n    truncated_vocabulary = pickle.load(truncated_vocabulary_file)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:29.772256Z","iopub.execute_input":"2022-04-22T00:17:29.772506Z","iopub.status.idle":"2022-04-22T00:17:29.790254Z","shell.execute_reply.started":"2022-04-22T00:17:29.772474Z","shell.execute_reply":"2022-04-22T00:17:29.789418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Lookup Table","metadata":{}},{"cell_type":"code","source":"import tensorflow as tf\n\nnum_oov_buckets = 1000\n\ndef create_lookup_table(truncated_vocabulary):\n    words = tf.constant(truncated_vocabulary)\n    len_vocabulary = len(truncated_vocabulary)\n    word_ids = tf.range(len_vocabulary, dtype=tf.int64)\n    vocab_init = tf.lookup.KeyValueTensorInitializer(words, word_ids)\n    table = tf.lookup.StaticVocabularyTable(vocab_init, num_oov_buckets)\n    \n    vocab = dict(zip(word_ids.numpy(), words.numpy()))\n    \n    return len_vocabulary, vocab, table\n\nlen_vocabulary, vocab, lookup_table = create_lookup_table(truncated_vocabulary)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:29.793565Z","iopub.execute_input":"2022-04-22T00:17:29.794055Z","iopub.status.idle":"2022-04-22T00:17:32.041647Z","shell.execute_reply.started":"2022-04-22T00:17:29.793812Z","shell.execute_reply":"2022-04-22T00:17:32.040764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"vocab[len_vocabulary - 1]","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.042866Z","iopub.execute_input":"2022-04-22T00:17:32.043367Z","iopub.status.idle":"2022-04-22T00:17:32.050269Z","shell.execute_reply.started":"2022-04-22T00:17:32.043327Z","shell.execute_reply":"2022-04-22T00:17:32.049347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lookup_table","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.054579Z","iopub.execute_input":"2022-04-22T00:17:32.054855Z","iopub.status.idle":"2022-04-22T00:17:32.061508Z","shell.execute_reply.started":"2022-04-22T00:17:32.054827Z","shell.execute_reply":"2022-04-22T00:17:32.060604Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# From Text And To Text","metadata":{}},{"cell_type":"code","source":"def add_padding(input_string, padding_size):\n    padding = \" <pad> \"* padding_size\n    string_with_padding = padding + input_string + padding\n    \n    return string_with_padding\n    ","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.063066Z","iopub.execute_input":"2022-04-22T00:17:32.063552Z","iopub.status.idle":"2022-04-22T00:17:32.069133Z","shell.execute_reply.started":"2022-04-22T00:17:32.063516Z","shell.execute_reply":"2022-04-22T00:17:32.068232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padding_size = 5\n\ndef get_X(coded_input_tensor):\n    X = []\n    for i in range(len(coded_input_tensor) - 2*padding_size):\n        X.append(coded_input_tensor[i:i + 2 * padding_size + 1].numpy())\n\n    X = np.array(X)\n    \n    return X","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.071173Z","iopub.execute_input":"2022-04-22T00:17:32.071748Z","iopub.status.idle":"2022-04-22T00:17:32.078579Z","shell.execute_reply.started":"2022-04-22T00:17:32.071641Z","shell.execute_reply":"2022-04-22T00:17:32.077675Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"padding_size = 5\n\ndef get_input_from_text(input_string):\n    string_padded = add_padding(input_string, padding_size)\n    tensor_input = preprocessing(string_padded)\n    coded_input_tensor = lookup_table.lookup(tensor_input)\n    \n    return get_X(coded_input_tensor)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.080153Z","iopub.execute_input":"2022-04-22T00:17:32.080407Z","iopub.status.idle":"2022-04-22T00:17:32.086878Z","shell.execute_reply.started":"2022-04-22T00:17:32.080373Z","shell.execute_reply":"2022-04-22T00:17:32.086061Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_word(word_id):\n    if word_id < len_vocabulary:\n        return vocab[word_id].decode(\"utf-8\")\n    else:\n        return \"\"","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.088626Z","iopub.execute_input":"2022-04-22T00:17:32.088919Z","iopub.status.idle":"2022-04-22T00:17:32.095274Z","shell.execute_reply.started":"2022-04-22T00:17:32.088885Z","shell.execute_reply":"2022-04-22T00:17:32.094382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Generate Submission File","metadata":{}},{"cell_type":"code","source":"def load_model(case_number, feature_number):\n    model = keras.models.load_model(\n        f\"/kaggle/input/nbme-train-all-models-from-trainning/model_for_case_{case_number}_and_feature_{feature_number}\")\n    return model","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.096741Z","iopub.execute_input":"2022-04-22T00:17:32.09704Z","iopub.status.idle":"2022-04-22T00:17:32.103955Z","shell.execute_reply.started":"2022-04-22T00:17:32.097005Z","shell.execute_reply":"2022-04-22T00:17:32.103178Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_sequences(y_pred, X, cut_prob, input_text):\n    sequences = []\n    sequence = []\n    started_interval = False\n    act_place = 0\n    lower_input_text = tf.strings.lower(input_text).numpy().decode(\"utf-8\")\n    \n    for i, y_value in enumerate(y):\n        word = get_word(X[i][padding_size])\n        place = lower_input_text.find(word)\n        lower_input_text = lower_input_text[place:]\n        act_place = act_place + place \n        \n        if y_value > cut_prob:\n            if started_interval == False:\n                started_interval = True\n                start_place = act_place\n            end_place = act_place + len(word)\n            sequence = [start_place, end_place]\n        else:\n            started_interval = False\n            if sequence:\n                sequences.append(sequence)\n            sequence = []\n\n    if sequence:\n        sequences.append(sequence)\n    \n    return sequences","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.105102Z","iopub.execute_input":"2022-04-22T00:17:32.10566Z","iopub.status.idle":"2022-04-22T00:17:32.115803Z","shell.execute_reply.started":"2022-04-22T00:17:32.105585Z","shell.execute_reply":"2022-04-22T00:17:32.114962Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def sequences_to_text(sequences):\n    text = []\n    for sequence in sequences:\n        text.append(f\"{sequence[0]} {sequence[1]}\")\n    \n    return \";\".join(text)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.117034Z","iopub.execute_input":"2022-04-22T00:17:32.117332Z","iopub.status.idle":"2022-04-22T00:17:32.1265Z","shell.execute_reply.started":"2022-04-22T00:17:32.117299Z","shell.execute_reply":"2022-04-22T00:17:32.125641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def text_id(patient_note_number, feature_number):\n    feature = str(feature_number)\n    feature = \"0\"*(3-len(feature)) + feature\n    pn = str(patient_note_number)\n    pn = \"0\"*(5-len(pn)) + pn\n    \n    return pn + \"_\" + feature","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.129532Z","iopub.execute_input":"2022-04-22T00:17:32.12978Z","iopub.status.idle":"2022-04-22T00:17:32.135732Z","shell.execute_reply.started":"2022-04-22T00:17:32.129746Z","shell.execute_reply":"2022-04-22T00:17:32.134654Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cut_prob = 0.5\n\nsubmission = pd.DataFrame(columns=[\"id\",\"location\"])\nfor case_number in range(10):\n    try:\n        patient_note_numbers = get_all_test_patient_note_numbers(case_number)\n        for feature_number in get_all_feature_numbers(case_number):\n            try:\n                print(f\"Loading model for case {case_number} and feature {feature_number}\")\n                if patient_note_numbers:\n                    model = load_model(case_number, feature_number)\n\n                for patient_note_number in patient_note_numbers:\n                    try:\n                        print(f\"Predicting for patient_note_number {patient_note_number}\")\n                        input_text = take_pacient_note(patient_note_number)\n                        X = get_input_from_text(input_text)\n\n                        y = model.predict(X)\n                        \n                        sequences = get_sequences(y, X, cut_prob, input_text)\n                        print(sequences)\n\n                        text_sequences = sequences_to_text(sequences)\n                        print(text_sequences)\n\n                        ident = text_id(patient_note_number, feature_number)\n                        print(ident)\n\n                        print(f\"Writing df for patient_note_number {patient_note_number} and feature_number {feature_number}\")\n                        submission = submission.append({\"id\": ident, \"location\": text_sequences}, ignore_index = True)\n                    except:\n                        continue\n            except:\n                continue\n    except:\n        continue\n            \nprint(f\"Saving dataframe to csv - making submission file\")\nsubmission.sort_values(\"id\", inplace=True)\nsubmission.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2022-04-22T00:17:32.137294Z","iopub.execute_input":"2022-04-22T00:17:32.137779Z","iopub.status.idle":"2022-04-22T00:18:58.792359Z","shell.execute_reply.started":"2022-04-22T00:17:32.137696Z","shell.execute_reply":"2022-04-22T00:18:58.791675Z"},"trusted":true},"execution_count":null,"outputs":[]}]}